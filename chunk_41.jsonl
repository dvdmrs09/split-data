{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninstall or update a tar package that has an md5.", "response": "def install_package(tar_url, folder, md5_url='{tar_url}.md5',\n                    on_download=lambda: None, on_complete=lambda: None):\n    \"\"\"\n    Install or update a tar package that has an md5\n\n    Args:\n        tar_url (str): URL of package to download\n        folder (str): Location to extract tar. Will be created if doesn't exist\n        md5_url (str): URL of md5 to use to check for updates\n        on_download (Callable): Function that gets called when downloading a new update\n        on_complete (Callable): Function that gets called when a new download is complete\n\n    Returns:\n        bool: Whether the package was updated\n    \"\"\"\n    data_file = join(folder, basename(tar_url))\n\n    md5_url = md5_url.format(tar_url=tar_url)\n    try:\n        remote_md5 = download(md5_url).decode('utf-8').split(' ')[0]\n    except (UnicodeDecodeError, URLError):\n        raise ValueError('Invalid MD5 url: ' + md5_url)\n    if remote_md5 != calc_md5(data_file):\n        on_download()\n        if isfile(data_file):\n            try:\n                with tarfile.open(data_file) as tar:\n                    for i in reversed(list(tar)):\n                        try:\n                            os.remove(join(folder, i.path))\n                        except OSError:\n                            pass\n            except (OSError, EOFError):\n                pass\n\n        download_extract_tar(tar_url, folder, data_file)\n        on_complete()\n        if remote_md5 != calc_md5(data_file):\n            raise ValueError('MD5 url does not match tar: ' + md5_url)\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess 3 cells and return a value from 0 to 7.", "response": "def _process_cell(i, state, finite=False):\n    \"\"\"Process 3 cells and return a value from 0 to 7. \"\"\"\n    op_1 = state[i - 1]\n    op_2 = state[i]\n    if i == len(state) - 1:\n        if finite:\n            op_3 = state[0]\n        else:\n            op_3 = 0\n    else:\n        op_3 = state[i + 1]\n    result = 0\n    for i, val in enumerate([op_3, op_2, op_1]):\n        if val:\n            result += 2**i\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _remove_lead_trail_false(bool_list):\n    # The internet can be a wonderful place...\n    for i in (0, -1):\n        while bool_list and not bool_list[i]:\n            bool_list.pop(i)\n    return bool_list", "response": "Remove leading and trailing false s from a list."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake a list a certain size", "response": "def _crop_list_to_size(l, size):\n    \"\"\"Make a list a certain size\"\"\"\n    for x in range(size - len(l)):\n        l.append(False)\n    for x in range(len(l) - size):\n        l.pop()\n    return l"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing a state and return the next state", "response": "def process(self, state):\n        \"\"\"Process a state and return the next state\nUsage:\n\n    out = rule_110.process([True, False, True])\n    len(out)  # 5, because a False is added to either side\n    out == [True, True, True, True, False]\n    out = rule_110.process([False, True, False, True])\n    len(out)  # still 5, because leading / trailing False's are removed\n    out2 = rule_110.process([1, 0, 1])  # Any data type in the list is okay, as\n                                        # long as it's boolean value is correct\n    out == out2\n\"\"\"\n        if not isinstance(state, list):\n            raise TypeError(\"state must be list\")\n        if self.finite_canvas:\n            state = _crop_list_to_size(state, self.canvas_size)\n        else:\n            state = _remove_lead_trail_false(state)\n            state.insert(0, self.default_val)\n            state.append(self.default_val)\n        new_state = []\n        for i in range(0, len(state)):\n            result = _process_cell(i, state, finite=self.finite_canvas)\n            new_state.append(self.rules[result])\n        return new_state"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates over the state of the current state.", "response": "def iterate(self, state):\n        \"\"\"Process a starting state over and over again. Example:\n\n        for x in rule_110.iterate(state):\n            # Do something with the current state here\n            # Note: You should break this yourself\n        # This breaks automatically if the previous state was the same as the\n        # current one, but that's not gonna happen on an infinite canvas\n\"\"\"\n        cur_state = state\n        old_state = cur_state\n        while True:\n            cur_state = self.process(cur_state)\n            if old_state == cur_state:\n                break\n            old_state = cur_state\n            yield cur_state"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef submit(self, command_line, name = None, array = None, dependencies = [], exec_dir = None, log_dir = None, dry_run = False, stop_on_failure = False, **kwargs):\n    # remove duplicate dependencies\n    dependencies = sorted(list(set(dependencies)))\n\n    # add job to database\n    self.lock()\n    job = add_job(self.session, command_line=command_line, name=name, dependencies=dependencies, array=array, exec_dir=exec_dir, log_dir=log_dir, stop_on_failure=stop_on_failure)\n    logger.info(\"Added job '%s' to the database\", job)\n\n    if dry_run:\n      print(\"Would have added the Job\", job, \"to the database to be executed locally.\")\n      self.session.delete(job)\n      logger.info(\"Deleted job '%s' from the database due to dry-run option\", job)\n      job_id = None\n    else:\n      job_id = job.unique\n\n    # return the new job id\n    self.unlock()\n    return job_id", "response": "Submits a job to the local machine."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resubmit(self, job_ids = None, also_success = False, running_jobs = False, new_command=None, keep_logs=False, **kwargs):\n    self.lock()\n    # iterate over all jobs\n    jobs = self.get_jobs(job_ids)\n    if new_command is not None:\n      if len(jobs) == 1:\n        jobs[0].set_command_line(new_command)\n      else:\n        logger.warn(\"Ignoring new command since no single job id was specified\")\n    accepted_old_status = ('submitted', 'success', 'failure') if also_success else ('submitted', 'failure',)\n    for job in jobs:\n      # check if this job needs re-submission\n      if running_jobs or job.status in accepted_old_status:\n        if job.queue_name != 'local' and job.status == 'executing':\n          logger.error(\"Cannot re-submit job '%s' locally since it is still running in the grid. Use 'jman stop' to stop it\\'s execution!\", job)\n        else:\n          # re-submit job to the grid\n          logger.info(\"Re-submitted job '%s' to the database\", job)\n          if not keep_logs:\n            self.delete_logs(job)\n          job.submit('local')\n\n    self.session.commit()\n    self.unlock()", "response": "Re - submit jobs to the grid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreset the status of the jobs to submitted when they are labeled as executing.", "response": "def stop_jobs(self, job_ids=None):\n    \"\"\"Resets the status of the job to 'submitted' when they are labeled as 'executing'.\"\"\"\n    self.lock()\n\n    jobs = self.get_jobs(job_ids)\n    for job in jobs:\n      if job.status in ('executing', 'queued', 'waiting') and job.queue_name == 'local':\n        logger.info(\"Reset job '%s' (%s) in the database\", job.name, self._format_log(job.id))\n        job.submit()\n\n    self.session.commit()\n    self.unlock()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop_job(self, job_id, array_id = None):\n    self.lock()\n\n    job, array_job = self._job_and_array(job_id, array_id)\n    if job is not None:\n      if job.status in ('executing', 'queued', 'waiting'):\n        logger.info(\"Reset job '%s' (%s) in the database\", job.name, self._format_log(job.id))\n        job.status = 'submitted'\n\n      if array_job is not None and array_job.status in ('executing', 'queued', 'waiting'):\n        logger.debug(\"Reset array job '%s' in the database\", array_job)\n        array_job.status = 'submitted'\n      if array_job is None:\n        for array_job in job.array:\n          if array_job.status in ('executing', 'queued', 'waiting'):\n            logger.debug(\"Reset array job '%s' in the database\", array_job)\n            array_job.status = 'submitted'\n\n    self.session.commit()\n    self.unlock()", "response": "Resets the status of the given job to submitted when they are labeled as executing."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting the code for this job on the local machine.", "response": "def _run_parallel_job(self, job_id, array_id = None, no_log = False, nice = None, verbosity = 0):\n    \"\"\"Executes the code for this job on the local machine.\"\"\"\n    environ = copy.deepcopy(os.environ)\n    environ['JOB_ID'] = str(job_id)\n    if array_id:\n      environ['SGE_TASK_ID'] = str(array_id)\n    else:\n      environ['SGE_TASK_ID'] = 'undefined'\n\n    # generate call to the wrapper script\n    command = [self.wrapper_script, '-l%sd'%(\"v\"*verbosity), self._database, 'run-job']\n\n    if nice is not None:\n      command = ['nice', '-n%d'%nice] + command\n\n    job, array_job = self._job_and_array(job_id, array_id)\n    if job is None:\n      # rare case: job was deleted before starting\n      return None\n\n    logger.info(\"Starting execution of Job '%s' (%s)\", job.name, self._format_log(job_id, array_id, len(job.array)))\n    # create log files\n    if no_log or job.log_dir is None:\n      out, err = sys.stdout, sys.stderr\n    else:\n      makedirs_safe(job.log_dir)\n      # create line-buffered files for writing output and error status\n      if array_job is not None:\n        out, err = open(array_job.std_out_file(), 'w', 1), open(array_job.std_err_file(), 'w', 1)\n      else:\n        out, err = open(job.std_out_file(), 'w', 1), open(job.std_err_file(), 'w', 1)\n\n    # return the subprocess pipe to the process\n    try:\n      return subprocess.Popen(command, env=environ, stdout=out, stderr=err, bufsize=1)\n    except OSError as e:\n      logger.error(\"Could not execute job '%s' (%s) locally\\n- reason:\\t%s\\n- command line:\\t%s\\n- directory:\\t%s\\n- command:\\t%s\", job.name, self._format_log(job_id, array_id, len(job.array)), e, \" \".join(job.get_command_line()), \".\" if job.exec_dir is None else job.exec_dir, \" \".join(command))\n      job.finish(117, array_id) # ASCII 'O'\n      return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_scheduler(self, parallel_jobs = 1, job_ids = None, sleep_time = 0.1, die_when_finished = False, no_log = False, nice = None, verbosity = 0):\n    running_tasks = []\n    finished_tasks = set()\n    try:\n\n      # keep the scheduler alive until every job is finished or the KeyboardInterrupt is caught\n      while True:\n        # Flag that might be set in some rare cases, and that prevents the scheduler to die\n        repeat_execution = False\n        # FIRST, try if there are finished processes\n        for task_index in range(len(running_tasks)-1, -1, -1):\n          task = running_tasks[task_index]\n          process = task[0]\n\n          if process.poll() is not None:\n            # process ended\n            job_id = task[1]\n            array_id = task[2] if len(task) > 2 else None\n            self.lock()\n            job, array_job = self._job_and_array(job_id, array_id)\n            if job is not None:\n              jj = array_job if array_job is not None else job\n              result = \"%s (%d)\" % (jj.status, jj.result) if jj.result is not None else \"%s (?)\" % jj.status\n              if jj.status not in ('success', 'failure'):\n                logger.error(\"Job '%s' (%s) finished with status '%s' instead of 'success' or 'failure'. Usually this means an internal error. Check your wrapper_script parameter!\", job.name, self._format_log(job_id, array_id), jj.status)\n                raise StopIteration(\"Job did not finish correctly.\")\n              logger.info(\"Job '%s' (%s) finished execution with result '%s'\", job.name, self._format_log(job_id, array_id), result)\n            self.unlock()\n            finished_tasks.add(job_id)\n            # in any case, remove the job from the list\n            del running_tasks[task_index]\n\n        # SECOND, check if new jobs can be submitted; THIS NEEDS TO LOCK THE DATABASE\n        if len(running_tasks) < parallel_jobs:\n          # get all unfinished jobs:\n          self.lock()\n          jobs = self.get_jobs(job_ids)\n          # put all new jobs into the queue\n          for job in jobs:\n            if job.status == 'submitted' and job.queue_name == 'local':\n              job.queue()\n\n          # get all unfinished jobs that are submitted to the local queue\n          unfinished_jobs = [job for job in jobs if job.status in ('queued', 'executing') and job.queue_name == 'local']\n          for job in unfinished_jobs:\n            if job.array:\n              # find array jobs that can run\n              queued_array_jobs = [array_job for array_job in job.array if array_job.status == 'queued']\n              if not len(queued_array_jobs):\n                job.finish(0, -1)\n                repeat_execution = True\n              else:\n                # there are new array jobs to run\n                for i in range(min(parallel_jobs - len(running_tasks), len(queued_array_jobs))):\n                  array_job = queued_array_jobs[i]\n                  # start a new job from the array\n                  process = self._run_parallel_job(job.unique, array_job.id, no_log=no_log, nice=nice, verbosity=verbosity)\n                  if process is None:\n                    continue\n                  running_tasks.append((process, job.unique, array_job.id))\n                  # we here set the status to executing manually to avoid jobs to be run twice\n                  # e.g., if the loop is executed while the asynchronous job did not start yet\n                  array_job.status = 'executing'\n                  job.status = 'executing'\n                  if len(running_tasks) == parallel_jobs:\n                    break\n            else:\n              if job.status == 'queued':\n                # start a new job\n                process = self._run_parallel_job(job.unique, no_log=no_log, nice=nice, verbosity=verbosity)\n                if process is None:\n                  continue\n                running_tasks.append((process, job.unique))\n                # we here set the status to executing manually to avoid jobs to be run twice\n                # e.g., if the loop is executed while the asynchronous job did not start yet\n                job.status = 'executing'\n            if len(running_tasks) == parallel_jobs:\n              break\n\n          self.session.commit()\n          self.unlock()\n\n        # if after the submission of jobs there are no jobs running, we should have finished all the queue.\n        if die_when_finished and not repeat_execution and len(running_tasks) == 0:\n          logger.info(\"Stopping task scheduler since there are no more jobs running.\")\n          break\n\n        # THIRD: sleep the desired amount of time before re-checking\n        time.sleep(sleep_time)\n\n    # This is the only way to stop: you have to interrupt the scheduler\n    except (KeyboardInterrupt, StopIteration):\n      if hasattr(self, 'session'):\n        self.unlock()\n      logger.info(\"Stopping task scheduler due to user interrupt.\")\n      for task in running_tasks:\n        logger.warn(\"Killing job '%s' that was still running.\", self._format_log(task[1], task[2] if len(task) > 2 else None))\n        try:\n          task[0].kill()\n        except OSError as e:\n          logger.error(\"Killing job '%s' was not successful: '%s'\", self._format_log(task[1], task[2] if len(task) > 2 else None), e)\n        self.stop_job(task[1])\n      # stop all jobs that are currently running or queued\n      self.stop_jobs(job_ids)\n\n    # check the result of the jobs that we have run, and return the list of failed jobs\n    self.lock()\n    jobs = self.get_jobs(finished_tasks)\n    failures = [job.unique for job in jobs if job.status != 'success']\n    self.unlock()\n    return sorted(failures)", "response": "Starts the scheduler which is constantly checking for jobs that should be ran."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef makeDependencyMap(aMap):\n  index = {}\n  for i in aMap.keys():\n    iNode = index.get(i,None)\n    if not iNode:\n      iNode = Node(i)\n      index[i] = iNode\n    for c in aMap[i]:\n      cNode = index.get(c,None)\n      if not cNode:\n        cNode = Node(c)\n        index[c] = cNode\n      iNode.addChild(cNode)\n  return index", "response": "Create a dependency data structure for a given item."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dependencyOrder(aMap, aList = None):\n  dependencyMap = makeDependencyMap(aMap)\n  outputList = []\n  if not aList:\n    aList = aMap.keys()\n  items = []\n  v = BottomUpVisitor()\n  for item in aList:\n    try:\n      v.visit(dependencyMap[item])\n    except KeyError:\n      outputList.append(item)\n  outputList = [x.item for x in v.history]+outputList\n  return outputList", "response": "Given a list of items in aMap returns a list of items that are dependancies of that item."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addChild(self,item):\n    if not isinstance(item,Node):\n      item = Node(item)\n    if item in self.children:\n      return item\n    self.children.append(item)\n    item.parents.add(self)\n    return item", "response": "Add a child to this node."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a HTML mesasge to plain text.", "response": "def html_to_text(html, base_url='', bodywidth=CONFIG_DEFAULT):\n    \"\"\"\n    Convert a HTML mesasge to plain text.\n    \"\"\"\n    def _patched_handle_charref(c):\n        self = h\n        charref = self.charref(c)\n        if self.code or self.pre:\n            charref = cgi.escape(charref)\n        self.o(charref, 1)\n\n    def _patched_handle_entityref(c):\n        self = h\n        entityref = self.entityref(c)\n        if self.code or self.pre:  # this expression was inversed.\n            entityref = cgi.escape(entityref)\n        self.o(entityref, 1)\n\n    h = HTML2Text(baseurl=base_url, bodywidth=config.BODY_WIDTH if bodywidth is CONFIG_DEFAULT else bodywidth)\n    h.handle_entityref = _patched_handle_entityref\n    h.handle_charref = _patched_handle_charref\n    return h.handle(html).rstrip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_fields(text, context, autoescape=None, errors='inline'):\n    raise_errors = errors == 'raise'\n    ignore_errors = errors == 'ignore'\n    inline_errors = errors == 'inline'\n\n    if autoescape is None:\n        # When passing a real template context, use it's autoescape setting.\n        # Otherwise, default to true.\n        autoescape = getattr(context, 'autoescape', True)\n\n    is_safe_string = isinstance(text, SafeData)\n    if is_safe_string and autoescape:\n        escape_function = conditional_escape\n        escape_error = lambda x: u\"<span style='color:red;'>{0}</span>\".format(x)\n    else:\n        escape_function = force_text\n        escape_error = six.text_type\n\n    # Using str.format() may raise a KeyError when some fields are not provided.\n    # Instead, simulate its' behavior to make sure all items that were found will be replaced.\n    start = 0\n    new_text = []\n    for match in RE_FORMAT.finditer(text):\n        new_text.append(text[start:match.start()])\n        start = match.end()\n\n        # See if the element was found\n        key = match.group('var')\n        try:\n            value = context[key]\n        except KeyError:\n            logger.debug(\"Missing key %s in email template %s!\", key, match.group(0))\n            if raise_errors:\n                raise\n            elif ignore_errors:\n                new_text.append(match.group(0))\n            elif inline_errors:\n                new_text.append(escape_error(\"!!missing {0}!!\".format(key)))\n            continue\n\n        # See if further processing is needed.\n        attr = match.group('attr')\n        if attr:\n            try:\n                value = getattr(value, attr)\n            except AttributeError:\n                logger.debug(\"Missing attribute %s in email template %s!\", attr, match.group(0))\n                if raise_errors:\n                    raise\n                elif ignore_errors:\n                    new_text.append(match.group(0))\n                elif inline_errors:\n                    new_text.append(escape_error(\"!!invalid attribute {0}.{1}!!\".format(key, attr)))\n                continue\n\n        format = match.group('format')\n        if format:\n            try:\n                template = u\"{0\" + format + \"}\"\n                value = template.format(value)\n            except ValueError:\n                logger.debug(\"Invalid format %s in email template %s!\", format, match.group(0))\n                if raise_errors:\n                    raise\n                elif ignore_errors:\n                    new_text.append(match.group(0))\n                elif inline_errors:\n                    new_text.append(escape_error(\"!!invalid format {0}!!\".format(format)))\n                continue\n        else:\n            value = escape_function(value)\n\n        # Add the value\n        new_text.append(value)\n\n    # Add remainder, and join\n    new_text.append(text[start:])\n    new_text = u\"\".join(new_text)\n\n    # Convert back to safestring if it was passed that way\n    if is_safe_string:\n        return mark_safe(new_text)\n    else:\n        return new_text", "response": "Replace fields in a string with the values in the context."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_email_template(email_template, base_url, extra_context=None, user=None):\n    dummy_request = _get_dummy_request(base_url, user)\n    context_user = user or extra_context.get('user', None)\n\n    context_data = {\n        'request': dummy_request,\n        'email_template': email_template,\n        'email_format': 'html',\n        'user': user,\n        # Common replacements\n        'first_name': context_user.first_name if context_user else '',\n        'last_name': context_user.last_name if context_user else '',\n        'full_name': context_user.get_full_name() if context_user else '',\n        'email': context_user.email if context_user else '',\n        'site': extra_context.get('site', None) or {\n            'domain': dummy_request.get_host(),\n            'name': dummy_request.get_host(),\n        }\n    }\n    if extra_context:\n        context_data.update(extra_context)\n\n    # Make sure the templates and i18n are identical to the emailtemplate language.\n    # This is the same as the current Django language, unless the object was explicitly fetched in a different language.\n    with switch_language(email_template):\n        # Get the body content\n        context_data['body'] = _render_email_placeholder(dummy_request, email_template, base_url, context_data)\n        context_data['subject'] = subject = replace_fields(email_template.subject, context_data, autoescape=False)\n\n        # Merge that with the HTML templates.\n        context = RequestContext(dummy_request).flatten()\n        context.update(context_data)\n        html = render_to_string(email_template.get_html_templates(), context, request=dummy_request)\n        html, url_changes = _make_links_absolute(html, base_url)\n\n        # Render the Text template.\n        # Disable auto escaping\n        context['email_format'] = 'text'\n        text = render_to_string(email_template.get_text_templates(), context, request=dummy_request)\n        text = _make_text_links_absolute(text, url_changes)\n\n        return EmailContent(subject, text, html)", "response": "Render an email template."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a dummy request.", "response": "def _get_dummy_request(base_url, user):\n    \"\"\"\n    Create a dummy request.\n    Use the ``base_url``, so code can use ``request.build_absolute_uri()`` to create absolute URLs.\n    \"\"\"\n    split_url = urlsplit(base_url)\n    is_secure = split_url[0] == 'https'\n    dummy_request = RequestFactory(HTTP_HOST=split_url[1]).get('/', secure=is_secure)\n    dummy_request.is_secure = lambda: is_secure\n    dummy_request.user = user or AnonymousUser()\n    dummy_request.site = None  # Workaround for wagtail.contrib.settings.context_processors\n    return dummy_request"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake all links absolute.", "response": "def _make_links_absolute(html, base_url):\n    \"\"\"\n    Make all links absolute.\n    \"\"\"\n    url_changes = []\n\n    soup = BeautifulSoup(html)\n    for tag in soup.find_all('a', href=True):\n        old = tag['href']\n        fixed = urljoin(base_url, old)\n        if old != fixed:\n            url_changes.append((old, fixed))\n            tag['href'] = fixed\n\n    for tag in soup.find_all('img', src=True):\n        old = tag['src']\n        fixed = urljoin(base_url, old)\n        if old != fixed:\n            url_changes.append((old, fixed))\n            tag['src'] = fixed\n\n    return mark_safe(six.text_type(soup)), url_changes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef string_to_datetime(date):\n    if date is None:\n        return None\n    if isinstance(date, datetime.datetime):\n        if not date.tzinfo:\n            date = date.replace(tzinfo=UTC)\n        return date\n    if isinstance(date, list):\n        date = 'T'.join(date)\n    if isinstance(date, basestring):\n        if len(date) <= len('2000-01-01'):\n            return (datetime.datetime\n                    .strptime(date, '%Y-%m-%d')\n                    .replace(tzinfo=UTC))\n        else:\n            try:\n                parsed = isodate.parse_datetime(date)\n            except ValueError:\n                # e.g. '2012-01-10 12:13:14Z' becomes '2012-01-10T12:13:14Z'\n                parsed = isodate.parse_datetime(\n                    re.sub('(\\d)\\s(\\d)', r'\\1T\\2', date)\n                )\n            if not parsed.tzinfo:\n                parsed = parsed.replace(tzinfo=UTC)\n            return parsed\n    raise ValueError(\"date not a parsable string\")", "response": "Return a datetime. datetime instance with tzinfo."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef date_to_string(date):\n    if isinstance(date, datetime.datetime):\n        # Create an ISO 8601 datetime string\n        date_str = date.strftime('%Y-%m-%dT%H:%M:%S')\n        tzstr = date.strftime('%z')\n        if tzstr:\n            # Yes, this is ugly. And no, I haven't found a better way to have a\n            # truly ISO 8601 datetime with timezone in Python.\n            date_str = '%s%s:%s' % (date_str, tzstr[0:3], tzstr[3:5])\n    elif isinstance(date, datetime.date):\n        # Create an ISO 8601 date string\n        date_str = date.strftime('%Y-%m-%d')\n    else:\n        raise TypeError('Argument is not a date or datetime. ')\n\n    return date_str", "response": "Transform a date or datetime object into a string and return it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a datetime. date object from the last 6 digits of a uuid.", "response": "def uuid_to_date(uuid, century='20'):\n    \"\"\"Return a date created from the last 6 digits of a uuid.\n\n    Arguments:\n        uuid The unique identifier to parse.\n        century The first 2 digits to assume in the year. Default is '20'.\n\n    Examples:\n        >>> uuid_to_date('e8820616-1462-49b6-9784-e99a32120201')\n        datetime.date(2012, 2, 1)\n\n        >>> uuid_to_date('e8820616-1462-49b6-9784-e99a32120201', '18')\n        datetime.date(1812, 2, 1)\n\n    \"\"\"\n    day = int(uuid[-2:])\n    month = int(uuid[-4:-2])\n    year = int('%s%s' % (century, uuid[-6:-4]))\n\n    return datetime.date(year=year, month=month, day=day)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a line to the. gitignore file of the repo AttributeNames.", "response": "def add_to_gitignore(line: str):\n    \"\"\"\n    Adds a line to the .gitignore file of the repo\n\n    Args:\n        line: line to add\n    \"\"\"\n    if not line.endswith('\\n'):\n        line = f'{line}\\n'\n    if GIT_IGNORE.exists():\n        if line in GIT_IGNORE.read_text(encoding='utf8'):\n            return\n        previous_content = GIT_IGNORE.read_text(encoding='utf8')\n    else:\n        previous_content = ''\n    GIT_IGNORE.write_text(previous_content + line, encoding='utf8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hardware_info():\n    try:\n        if sys.platform == 'darwin':\n            out = _mac_hardware_info()\n        elif sys.platform == 'win32':\n            out = _win_hardware_info()\n        elif sys.platform in ['linux', 'linux2']:\n            out = _linux_hardware_info()\n        else:\n            out = {}\n    except:\n        return {}\n    else:\n        return out", "response": "Returns basic hardware information about the computer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clear_i2b2_tables(tables: I2B2Tables, uploadid: int) -> None:\n    # This is a static function to support the removefacts operation\n    print(\"Deleted {} patient_dimension records\"\n          .format(PatientDimension.delete_upload_id(tables, uploadid)))\n    print(\"Deleted {} patient_mapping records\"\n          .format(PatientMapping.delete_upload_id(tables, uploadid)))\n    print(\"Deleted {} observation_fact records\"\n          .format(ObservationFact.delete_upload_id(tables, uploadid)))\n    print(\"Deleted {} visit_dimension records\"\n          .format(VisitDimension.delete_upload_id(tables, uploadid)))\n    print(\"Deleted {} encounter_mapping records\"\n          .format(EncounterMapping.delete_upload_id(tables, uploadid)))", "response": "Remove all entries in the i2b2 tables for uploadid."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_parser() -> FileAwareParser:\n    parser = FileAwareParser(description=\"Clear data from FHIR observation fact table\", prog=\"removefacts\",\n                             use_defaults=False)\n    parser.add_argument(\"-ss\", \"--sourcesystem\", metavar=\"SOURCE SYSTEM CODE\", help=\"Sourcesystem code\")\n    parser.add_argument(\"-u\", \"--uploadid\", metavar=\"UPLOAD IDENTIFIER\",\n                        help=\"Upload identifer -- uniquely identifies this batch\", type=int,\n                        nargs='*')\n    add_connection_args(parser, strong_config_file=False)\n    parser.add_argument(\"-p\", \"--testprefix\", metavar=\"SS PREFIX\",\n                        help=f\"Sourcesystem_cd prefix for test suite functions (Default: {default_test_prefix}\")\n    parser.add_argument(\"--testlist\", help=\"List leftover test suite entries\", action=\"store_true\")\n    parser.add_argument(\"--removetestlist\", help=\"Remove leftover test suite entries\", action=\"store_true\")\n    return parser", "response": "Create a command line parser for the FHIR observation fact table."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_facts(argv: List[str]) -> bool:\n    parser = create_parser()\n    local_opts = parser.parse_args(argv)                        # Pull everything from the actual command line\n    if not (local_opts.uploadid or local_opts.sourcesystem or local_opts.testlist or local_opts.removetestlist):\n        parser.error(\"Option must be one of: -ss, -u, --testlist, --removetestlist\")\n\n    if (local_opts.testlist or local_opts.removetestlist) and (local_opts.uploadid or local_opts.sourcesystem):\n        parser.error(\"Cannot combine -ss or -u option with testlist options.  Use -p to specify ss prefix\")\n\n    opts, _ = parser.parse_known_args(parser.decode_file_args(argv))     # Include the options file\n    if opts is None:\n        return False\n    opts.uploadid = local_opts.uploadid\n    opts.sourcesystem = local_opts.sourcesystem\n\n    process_parsed_args(opts, parser.error)           # Update CRC and Meta table connection information\n\n    if opts.uploadid:\n        for uploadid in opts.uploadid:\n            print(\"---> Removing entries for id {}\".format(uploadid))\n            clear_i2b2_tables(I2B2Tables(opts), uploadid)\n    if opts.sourcesystem:\n        print(\"---> Removing entries for sourcesystem_cd {}\".format(opts.sourcesystem))\n        clear_i2b2_sourcesystems(I2B2Tables(opts), opts.sourcesystem)\n    if opts.testlist:\n        opts.testprefix = opts.testprefix if (opts and opts.testprefix) else default_test_prefix\n        print(f\"---> Listing orphan test elements for sourcesystem_cd starting with {opts.testprefix}\")\n        list_test_artifacts(opts)\n    if opts.removetestlist:\n        opts.testprefix = opts.testprefix if (opts and opts.testprefix) else default_test_prefix\n        print(f\"---> Removing orphan test elements for sourcesystem_cd starting with {opts.testprefix}\")\n        remove_test_artifacts(opts)\n    return True", "response": "Convert a set of FHIR resources into their corresponding i2b2 counterparts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npost identity raw document", "response": "async def add(client: Client, identity_signed_raw: str) -> ClientResponse:\n    \"\"\"\n    POST identity raw document\n\n    :param client: Client to connect to the api\n    :param identity_signed_raw: Identity raw document\n    :return:\n    \"\"\"\n    return await client.post(MODULE + '/add', {'identity': identity_signed_raw}, rtype=RESPONSE_AIOHTTP)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def certify(client: Client, certification_signed_raw: str) -> ClientResponse:\n    return await client.post(MODULE + '/certify', {'cert': certification_signed_raw}, rtype=RESPONSE_AIOHTTP)", "response": "POST certification raw document\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrevoking a single certificate.", "response": "async def revoke(client: Client, revocation_signed_raw: str) -> ClientResponse:\n    \"\"\"\n    POST revocation document\n\n    :param client: Client to connect to the api\n    :param revocation_signed_raw: Certification raw document\n    :return:\n    \"\"\"\n    return await client.post(MODULE + '/revoke', {'revocation': revocation_signed_raw}, rtype=RESPONSE_AIOHTTP)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def lookup(client: Client, search: str) -> dict:\n    return await client.get(MODULE + '/lookup/%s' % search, schema=LOOKUP_SCHEMA)", "response": "Get the UID and Public key of a node"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the certifiers of a given UID or public key", "response": "async def certifiers_of(client: Client, search: str) -> dict:\n    \"\"\"\n    GET UID/Public key certifiers\n\n    :param client: Client to connect to the api\n    :param search: UID or public key\n    :return:\n    \"\"\"\n    return await client.get(MODULE + '/certifiers-of/%s' % search, schema=CERTIFICATIONS_SCHEMA)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def requirements(client: Client, search: str) -> dict:\n    return await client.get(MODULE + '/requirements/%s' % search, schema=REQUIREMENTS_SCHEMA)", "response": "Get list of requirements for a given UID or Public key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting Identity data written in the blockchain", "response": "async def identity_of(client: Client, search: str) -> dict:\n    \"\"\"\n    GET Identity data written in the blockchain\n\n    :param client: Client to connect to the api\n    :param search: UID or public key\n    :return:\n    \"\"\"\n    return await client.get(MODULE + '/identity-of/%s' % search, schema=IDENTITY_OF_SCHEMA)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns a command while transfering control till the execution is complete.", "response": "def run(command, **kwargs):\n  \"\"\"Excecutes the given command while transfering control, till the execution is complete.\n  \"\"\"\n  print command\n  p = Popen(shlex.split(command), **kwargs)\n  p.wait()\n\n  return p.returncode"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npull data from a table and generates rows.", "response": "def data(tableid,\n         variables=dict(),\n         stream=False,\n         descending=False,\n         lang=DEFAULT_LANGUAGE):\n    \"\"\"Pulls data from a table and generates rows.\n\n    Variables is a dictionary mapping variable codes to values.\n\n    Streaming:\n    Values must be chosen for all variables when streaming\n    \"\"\"\n    # bulk is also in csv format, but the response is streamed\n    format = 'BULK' if stream else 'CSV'\n\n    request = Request('data', tableid, format,\n                      timeOrder='Descending' if descending else None,\n                      valuePresentation='CodeAndValue',\n                      lang=lang,\n                      **variables)\n\n    return (Data(datum, lang=lang) for datum in request.csv)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef subjects(subjects=None,\n             recursive=False,\n             include_tables=False,\n             lang=DEFAULT_LANGUAGE):\n    \"\"\"List subjects from the subject hierarchy.\n\n    If subjects is not given, the root subjects will be used.\n\n    Returns a generator.\n    \"\"\"\n    request = Request('subjects', *subjects,\n                      recursive=recursive,\n                      includeTables=include_tables,\n                      lang=lang)\n\n    return (Subject(subject, lang=lang) for subject in request.json)", "response": "List subjects from the subject hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfetching metadata for statbank table", "response": "def tableinfo(tableid, lang=DEFAULT_LANGUAGE):\n    \"\"\"Fetch metadata for statbank table\n\n    Metadata includes information about variables,\n    which can be used when extracting data.\n    \"\"\"\n    request = Request('tableinfo', tableid, lang=lang)\n\n    return Tableinfo(request.json, lang=lang)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tables(subjects=None,\n           pastDays=None,\n           include_inactive=False,\n           lang=DEFAULT_LANGUAGE):\n    \"\"\"Find tables placed under given subjects.\n    \"\"\"\n    request = Request('tables',\n                      subjects=subjects,\n                      pastDays=pastDays,\n                      includeInactive=include_inactive,\n                      lang=lang)\n\n    return (Table(table, lang=lang) for table in request.json)", "response": "Find tables placed under given subjects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess method request and return json with results", "response": "def request_method(self, method: str,\n                       **method_kwargs: Union[str, int]) -> dict:\n        \"\"\"\n        Process method request and return json with results\n\n        :param method: str: specifies the method, example: \"users.get\"\n        :param method_kwargs: dict: method parameters,\n        example: \"users_id=1\", \"fields='city, contacts'\"\n        \"\"\"\n        response = self.session.send_method_request(method, method_kwargs)\n        self.check_for_errors(method, method_kwargs, response)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef request_get_user(self, user_ids) -> dict:\n        method_params = {'user_ids': user_ids}\n        response = self.session.send_method_request('users.get', method_params)\n        self.check_for_errors('users.get', method_params, response)\n        return response", "response": "Method to get users by ID"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn src in hex dump.", "response": "def hexdump(src, length=16, sep='.'):\n    \"\"\"\n    Returns src in hex dump.\n    From https://gist.github.com/ImmortalPC/c340564823f283fe530b\n\n    :param length: Nb Bytes by row.\n    :param sep: For the text part, sep will be used for non ASCII char.\n    :return: The hexdump\n    \"\"\"\n    result = []\n\n    for i in range(0, len(src), length):\n        sub_src = src[i:i + length]\n        hexa = ''\n        for h in range(0, len(sub_src)):\n            if h == length / 2:\n                hexa += ' '\n            h = sub_src[h]\n            if not isinstance(h, int):\n                h = ord(h)\n            h = hex(h).replace('0x', '')\n            if len(h) == 1:\n                h = '0' + h\n            hexa += h + ' '\n\n        hexa = hexa.strip(' ')\n        text = ''\n        for c in sub_src:\n            if not isinstance(c, int):\n                c = ord(c)\n            if 0x20 <= c < 0x7F:\n                text += chr(c)\n            else:\n                text += sep\n        result.append(('%08X:  %-' + str(length * (2 + 1) + 1) + 's  |%s|')\n                      % (i, hexa, text))\n\n    return '\\n'.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_spy(group, port, verbose):\n    # Create the socket\n    socket, group = multicast.create_multicast_socket(group, port)\n    print(\"Socket created:\", group, \"port:\", port)\n\n    # Set the socket as non-blocking\n    socket.setblocking(0)\n\n    # Prepare stats storage\n    stats = {\n        \"total_bytes\": 0,\n        \"total_count\": 0,\n        \"sender_bytes\": {},\n        \"sender_count\": {},\n    }\n\n    print(\"Press Ctrl+C to exit\")\n    try:\n        loop_nb = 0\n        while True:\n            if loop_nb % 50 == 0:\n                loop_nb = 0\n                print(\"Reading...\")\n\n            loop_nb += 1\n\n            ready = select.select([socket], [], [], .1)\n            if ready[0]:\n                # Socket is ready\n                data, sender = socket.recvfrom(1024)\n                len_data = len(data)\n\n                # Store stats\n                stats[\"total_bytes\"] += len_data\n                stats[\"total_count\"] += 1\n\n                try:\n                    stats[\"sender_bytes\"][sender] += len_data\n                    stats[\"sender_count\"][sender] += 1\n                except KeyError:\n                    stats[\"sender_bytes\"][sender] = len_data\n                    stats[\"sender_count\"][sender] = 1\n\n                print(\"Got\", len_data, \"bytes from\", sender[0], \"port\",\n                      sender[1], \"at\", datetime.datetime.now())\n                if verbose:\n                    print(hexdump(data))\n    except KeyboardInterrupt:\n        # Interrupt\n        print(\"Ctrl+C received: bye !\")\n\n    # Print statistics\n    print(\"Total number of packets:\", stats[\"total_count\"])\n    print(\"Total read bytes.......:\", stats[\"total_bytes\"])\n\n    for sender in stats[\"sender_count\"]:\n        print(\"\\nSender\", sender[0], \"from port\", sender[1])\n        print(\"\\tTotal packets:\", stats[\"sender_count\"][sender])\n        print(\"\\tTotal bytes..:\", stats[\"sender_bytes\"][sender])\n\n    return 0", "response": "Runs the spy on the multicast group and port."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(argv=None):\n    parser = argparse.ArgumentParser(description=\"Multicast packets spy\")\n\n    parser.add_argument(\"-g\", \"--group\", dest=\"group\", default=\"239.0.0.1\",\n                        help=\"Multicast target group (address)\")\n    parser.add_argument(\"-p\", \"--port\", type=int, dest=\"port\", default=42000,\n                        help=\"Multicast target port\")\n\n    parser.add_argument(\"-d\", \"--debug\", action=\"store_true\", dest=\"debug\",\n                        help=\"Set logger to DEBUG level\")\n    parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\", dest=\"verbose\",\n                        help=\"Verbose output\")\n\n    # Parse arguments\n    args = parser.parse_args(argv)\n\n    # Configure the logger\n    if args.debug:\n        logging.basicConfig(level=logging.DEBUG)\n    else:\n        logging.basicConfig(level=logging.WARNING)\n\n    try:\n        return run_spy(args.group, args.port, args.verbose)\n    except Exception as ex:\n        logging.exception(\"Error running spy: %s\", ex)\n\n    return 1", "response": "Entry point for the daemon."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a list of dicts of stim_name = DeconStim and stack them together. returns a single dict of stim_name = DeconStim and stack them together. returns None if no stimuli are present in the list", "response": "def stack_decon_stims(stim_list):\n    '''take a ``list`` (in order of runs) of ``dict``s of stim_name:DeconStim and stack them together. returns\n    a single ``dict`` of stim_name:decon_stim\n\n    As in, takes:\n    [\n        # Run 1\n        { \"stim1\": decon_stim1a, \"stim2\": decon_stim2a },\n        # Run 2\n        { \"stim1\": decon_stim1b, \"stim2\": decon_stim2b, \"stim3\": decon_stim3 }\n    ]\n\n    And makes:\n        { \"stim1\": decon_stim1, \"stim2\": decon_stim2, \"stim3\": decon_stim3 }\n\n    If a stimulus is not present in a run, it will fill that run with an empty stimulus\n    '''\n    stim_names = list(set(nl.flatten([stims.keys() for stims in stim_list])))\n\n    stim_dict = {}\n    for stim_name in stim_names:\n        types = list(set([stims[stim_name].type() for stims in stim_list if stim_name in stims]))\n        if len(types)>1:\n            nl.notify('Error: Trying to stack stimuli of different types! (%s)' % stim_name,level=nl.level.error)\n            return None\n        type = types[0]\n\n        stim_stack = []\n        for i in xrange(len(stim_list)):\n            if stim_name in stim_list[i]:\n                stim_stack.append(stim_list[i][stim_name])\n            else:\n                stim_stack.append(stim_list[i].values()[0].blank_stim(type=type))\n        stim_dict[stim_name] = copy.copy(stim_stack[0])\n        for stim in stim_stack[1:]:\n            stim_dict[stim_name] = stim_dict[stim_name].concat_stim(stim)\n    return stim_dict.values()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntaking an input : class : Decon object and uses 3dBlurToFWHM to make the output as close as possible to fwhm", "response": "def smooth_decon_to_fwhm(decon,fwhm,cache=True):\n    '''takes an input :class:`Decon` object and uses ``3dBlurToFWHM`` to make the output as close as possible to ``fwhm``\n    returns the final measured fwhm. If ``cache`` is ``True``, will save the blurred input file (and use it again in the future)'''\n    if os.path.exists(decon.prefix):\n        return\n    blur_dset = lambda dset: nl.suffix(dset,'_smooth_to_%.2f' % fwhm)\n\n    with nl.notify('Running smooth_decon_to_fwhm analysis (with %.2fmm blur)' % fwhm):\n        tmpdir = tempfile.mkdtemp()\n        try:\n            cwd = os.getcwd()\n            random_files = [re.sub(r'\\[\\d+\\]$','',str(x)) for x in nl.flatten([x for x in decon.__dict__.values() if isinstance(x,basestring) or isinstance(x,list)]+[x.values() for x in decon.__dict__.values() if isinstance(x,dict)])]\n            files_to_copy = [x for x in random_files if os.path.exists(x) and x[0]!='/']\n            files_to_copy += [blur_dset(dset) for dset in decon.input_dsets if os.path.exists(blur_dset(dset))]\n            # copy crap\n            for file in files_to_copy:\n                try:\n                    shutil.copytree(file,tmpdir)\n                except OSError as e:\n                    shutil.copy(file,tmpdir)\n                shutil.copy(file,tmpdir)\n\n            copyback_files = [decon.prefix,decon.errts]\n            with nl.run_in(tmpdir):\n                if os.path.exists(decon.prefix):\n                    os.remove(decon.prefix)\n\n                # Create the blurred inputs (or load from cache)\n                if cache and all([os.path.exists(os.path.join(cwd,blur_dset(dset))) for dset in decon.input_dsets]):\n                    # Everything is already cached...\n                    nl.notify('Using cache\\'d blurred datasets')\n                else:\n                    # Need to make them from scratch\n                    with nl.notify('Creating blurred datasets'):\n                        old_errts = decon.errts\n                        decon.errts = 'residual.nii.gz'\n                        decon.prefix = os.path.basename(decon.prefix)\n                        # Run once in place to get the residual dataset\n                        decon.run()\n                        running_reps = 0\n                        for dset in decon.input_dsets:\n                            info = nl.dset_info(dset)\n                            residual_dset = nl.suffix(dset,'_residual')\n                            nl.run(['3dbucket','-prefix',residual_dset,'%s[%d..%d]'%(decon.errts,running_reps,running_reps+info.reps-1)],products=residual_dset)\n                            cmd = ['3dBlurToFWHM','-quiet','-input',dset,'-blurmaster',residual_dset,'-prefix',blur_dset(dset),'-FWHM',fwhm]\n                            if decon.mask:\n                                if decon.mask=='auto':\n                                    cmd += ['-automask']\n                                else:\n                                    cmd += ['-mask',decon.mask]\n                            nl.run(cmd,products=blur_dset(dset))\n                            running_reps += info.reps\n                            if cache:\n                                copyback_files.append(blur_dset(dset))\n                    decon.errts = old_errts\n                decon.input_dsets = [blur_dset(dset) for dset in decon.input_dsets]\n                for d in [decon.prefix,decon.errts]:\n                    if os.path.exists(d):\n                        try:\n                            os.remove(d)\n                        except:\n                            pass\n                decon.run()\n                for copyfile in copyback_files:\n                    if os.path.exists(copyfile):\n                        shutil.copy(copyfile,cwd)\n                    else:\n                        nl.notify('Warning: deconvolve did not produce expected file %s' % decon.prefix,level=nl.level.warning)\n        except:\n            raise\n        finally:\n            shutil.rmtree(tmpdir,True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef command_list(self):\n        '''returns the 3dDeconvolve command as a list\n\n        The list returned can be run by passing it into a subprocess-like command\n        (e.g., neural.run())\n        '''\n        cmd = ['3dDeconvolve']\n\n        cmd += ['-jobs',multiprocessing.cpu_count()]\n        cmd += self.opts\n        if(len(self.input_dsets)):\n            cmd += ['-input'] + ['%s[%d..%d]' % (dset,self.partial[dset][0],self.partial[dset][1]) if dset in self.partial else dset for dset in self.input_dsets]\n        else:\n            cmd += ['-nodata']\n            if self.reps:\n                cmd += [str(self.reps)]\n                if self.TR:\n                    cmd += [str(self.TR)]\n        if self.censor_file:\n            censor_file = self.censor_file\n            if self.partial:\n                # This assumes only one dataset!\n                with open(censor_file) as inf:\n                    censor = inf.read().split()[self.partial.values()[0][0]:self.partial.values()[0][1]+1]\n                    with tempfile.NamedTemporaryFile(delete=False) as f:\n                        f.write('\\n'.join(censor))\n                        censor_file = f.name\n                        self._del_files.append(f.name)\n            cmd += ['-censor', censor_file]\n        nfirst = self.nfirst\n        if len(self.input_dsets) and self.input_dsets[0] in self.partial:\n            nfirst -= self.partial[self.input_dsets[0]][0]\n        if nfirst<0:\n            nfirst = 0\n        cmd += ['-nfirst',str(nfirst)]\n        if self.mask:\n            if self.mask=='auto':\n                cmd += ['-automask']\n            else:\n                cmd += ['-mask',self.mask]\n        cmd += ['-polort',str(self.polort)]\n\n        stim_num = 1\n\n        all_stims = list(self.decon_stims)\n        all_stims += [DeconStim(stim,column_file=self.stim_files[stim],base=(stim in self.stim_base)) for stim in self.stim_files]\n        for stim in self.stim_times:\n            decon_stim = DeconStim(stim,times_file=self.stim_times[stim])\n            decon_stim.times_model = self.models[stim] if stim in self.models else self.model_default\n            decon_stim.AM1 = (stim in self.stim_am1)\n            decon_stim.AM2 = (stim in self.stim_am2)\n            decon_stim.base = (stim in self.stim_base)\n            all_stims.append(decon_stim)\n\n        if self.partial:\n            for i in xrange(len(self.input_dsets)):\n                if self.input_dsets[i] in self.partial:\n                    new_stims = []\n                    for stim in all_stims:\n                        stim = stim.partial(self.partial[self.input_dsets[i]][0],self.partial[self.input_dsets[i]][1],i)\n                        if stim:\n                            new_stims.append(stim)\n                    all_stims = new_stims\n\n        cmd += ['-num_stimts',len(all_stims)]\n\n        stimautoname = lambda d,s: 'stimfile_auto-%d-%s_' % (d,s.name) + str(datetime.datetime.now()).replace(\" \",\"_\").replace(\":\",\".\")\n\n        for stim in all_stims:\n            column_file = stim.column_file\n            if stim.column!=None:\n                column_file = stimautoname(stim_num,stim)\n                with open(column_file,\"w\") as f:\n                    f.write('\\n'.join([str(x) for x in stim.column]))\n            if column_file:\n                cmd += ['-stim_file',stim_num,column_file,'-stim_label',stim_num,stim.name]\n                if stim.base:\n                    cmd += ['-stim_base',stim_num]\n                stim_num += 1\n                continue\n            times_file = stim.times_file\n            if stim.times!=None:\n                times = list(stim.times)\n                if '__iter__' not in dir(times[0]):\n                    # a single list\n                    times = [times]\n                times_file = stimautoname(stim_num,stim)\n                with open(times_file,\"w\") as f:\n                    f.write('\\n'.join([' '.join([str(x) for x in y]) if len(y)>0 else '*' for y in times]))\n            if times_file:\n                opt = '-stim_times'\n                if stim.AM1:\n                    opt = '-stim_times_AM1'\n                if stim.AM2:\n                    opt = '-stim_times_AM2'\n                cmd += [opt,stim_num,times_file,stim.times_model]\n                cmd += ['-stim_label',stim_num,stim.name]\n                if stim.base:\n                    cmd += ['-stim_base',stim_num]\n                stim_num += 1\n\n        strip_number = r'[-+]?(\\d+)?\\*?(\\w+)(\\[.*?\\])?'\n        all_glts = {}\n        stim_names = [stim.name for stim in all_stims]\n        if self.validate_glts:\n            for glt in self.glts:\n                ok = True\n                for stim in self.glts[glt].split():\n                    m = re.match(strip_number,stim)\n                    if m:\n                        stim = m.group(2)\n                    if stim not in stim_names:\n                        ok = False\n                if ok:\n                    all_glts[glt] = self.glts[glt]\n        else:\n            all_glts = self.glts\n\n        cmd += ['-num_glt',len(all_glts)]\n\n        glt_num = 1\n        for glt in all_glts:\n            cmd += ['-gltsym','SYM: %s' % all_glts[glt],'-glt_label',glt_num,glt]\n            glt_num += 1\n\n        if self.bout:\n            cmd += ['-bout']\n        if self.tout:\n            cmd += ['-tout']\n        if self.vout:\n            cmd += ['-vout']\n        if self.rout:\n            cmd += ['-rout']\n\n        if self.errts:\n            cmd += ['-errts', self.errts]\n\n        if self.prefix:\n            cmd += ['-bucket', self.prefix]\n\n        return [str(x) for x in cmd]", "response": "returns the 3dDeconvolve command as a list\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self):\n        '''runs 3dDeconvolve through the neural.utils.run shortcut'''\n        out = nl.run(self.command_list(),products=self.prefix)\n        if out and out.output:\n            sds_list = re.findall(r'Stimulus: (.*?) *\\n +h\\[ 0\\] norm\\. std\\. dev\\. = +(\\d+\\.\\d+)',out.output)\n            self.stim_sds = {}\n            for s in sds_list:\n                self.stim_sds[s[0]] = float(s[1])", "response": "runs 3dDeconvolve through the neural. utils. run shortcut"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef type(self):\n        '''returns kind of stim (\"column\" or \"times\"), based on what parameters are set'''\n        if self.column!=None or self.column_file:\n            return \"column\"\n        if self.times!=None or self.times_file:\n            return \"times\"\n        return None", "response": "returns kind of stimulation or times based on what parameters are set"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the file into self. column", "response": "def read_file(self):\n        '''if this is stored in a file, read it into self.column'''\n        column_selector = r'(.*)\\[(\\d+)\\]$'\n        if self.column_file:\n            column = None\n            m = re.match(column_selector,self.column_file)\n            file = self.column_file\n            if m:\n                file = m.group(1)\n                column = int(m.group(2))\n            with open(file) as f:\n                lines = f.read().split('\\n')\n                if column!=None:\n                    lines = [x.split()[column] for x in lines]\n                self.column = [nl.numberize(x) for x in lines]\n            self.column_file = None\n        if self.times_file:\n            with open(self.times_file) as f:\n                self.times = [[nl.numberize(x) for x in y.split()] for y in f.read().split('\\n')]\n            self.times_file = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef concat_stim(self,decon_stim):\n        '''concatenate this to another :class:`DeconStim` of the same \"type\"'''\n        if self.type()!=decon_stim.type():\n            nl.notify('Error: Trying to concatenate stimuli of different types! %s (%s) with %s (%s)' % (self.name,self.type(),decon_stim.name,decon_stim.type()),level=nl.level.error)\n            return None\n        concat_stim = copy.copy(self)\n        if self.name=='Blank':\n            concat_stim = copy.copy(decon_stim)\n\n        self.read_file()\n        if self.type()==\"column\":\n            # if an explicit # of reps is given, concat to that\n            reps = [x.reps if x.reps else len(x.column) for x in [self,decon_stim]]\n            concat_stim.column = self.column[:reps[0]] + decon_stim.column[:reps[1]]\n            return concat_stim\n        if self.type()==\"times\":\n            if len(self.times)==0 or '__iter__' not in dir(self.times[0]):\n                self.times = [self.times]\n            if len(decon_stim.times)==0 or '__iter__' not in dir(decon_stim.times[0]):\n                decon_stim.times = [decon_stim.times]\n            concat_stim.times = self.times + decon_stim.times\n            return concat_stim\n        return None", "response": "concatenate this to another."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef partial(self,start=0,end=None,run=0):\n        '''chops the stimulus by only including time points ``start`` through ``end`` (in reps, inclusive; ``None``=until the end)\n        if using stim_times-style simulus, will change the ``run``'th run. If a column, will just chop the column'''\n        self.read_file()\n        decon_stim = copy.copy(self)\n        if start<0:\n            start = 0\n        if self.type()==\"column\":\n            decon_stim.column_file = None\n            if end>=len(decon_stim.column):\n                end = None\n            if end==None:\n                decon_stim.column = decon_stim.column[start:]\n            else:\n                decon_stim.column = decon_stim.column[start:end+1]\n            if len(decon_stim.column)==0:\n                return None\n        if self.type()==\"times\":\n            if self.TR==None:\n                nl.notify('Error: cannot get partial segment of a stim_times stimulus without a TR',level=nl.level.error)\n                return None\n            def time_in(a):\n                first_number = r'^(\\d+(\\.\\d+)?)'\n                if isinstance(a,basestring):\n                    m = re.match(first_number,a)\n                    if m:\n                        a = m.group(1)\n                    else:\n                        nl.notify('Warning: cannot intepret a number from the stim_time: \"%s\"' % a,level=nl.level.warning)\n                        return False\n                a = float(a)/self.TR\n                if a>=start and (end==None or a<=end):\n                    return True\n                return False\n\n            decon_stim.times_file = None\n            if len(decon_stim.times)==0 or '__iter__' not in dir(decon_stim.times[0]):\n                decon_stim.times = [decon_stim.times]\n            decon_stim.times[run] = [x for x in decon_stim.times[run] if time_in(x)]\n            if len(nl.flatten(decon_stim.times))==0:\n                return None\n        return decon_stim", "response": "returns a copy of the stimulus with only including time points start through end and inclusive ; None = until the end"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall the notification method of the current object", "response": "def notify(self):\n        \"\"\"\n        Calls the notification method\n\n        :return: True if the notification method has been called\n        \"\"\"\n        if self.__method is not None:\n            self.__method(self.__peer)\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef observeState(self, call=None):\n        def _observe(call):\n            self.__observers.add(\"*\", call)\n            return call\n\n        if call is not None:\n            return _observe(call)\n        else:\n            return _observe", "response": "Decorator to register an observer to the any changes in the current state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef observeElements(self, what, call=None):\n        def _observe(call):\n            self.__observers.add(what, call)\n            return call\n\n        toEvaluate = []\n        if isinstance(what, str):\n            toEvaluate.append(what)\n        else:\n            toEvaluate = what\n\n        if not self.areObservableElements(toEvaluate):\n            msg = 'Could not find observable element named \"{0}\" in {1}'\n            raise ValueError(msg.format(what, self.__class__))\n\n        if call is not None:\n            return _observe(call)\n        else:\n            return _observe", "response": "This is a private method that registers an observer function to a specific state field or a list of state fields."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the JobManager and sets up the basic infrastructure", "response": "def setup(args):\n  \"\"\"Returns the JobManager and sets up the basic infrastructure\"\"\"\n\n  kwargs = {'wrapper_script' : args.wrapper_script, 'debug' : args.verbose==3, 'database' : args.database}\n  if args.local:\n    jm = local.JobManagerLocal(**kwargs)\n  else:\n    jm = sge.JobManagerSGE(**kwargs)\n\n  # set-up logging\n  if args.verbose not in range(0,4):\n    raise ValueError(\"The verbosity level %d does not exist. Please reduce the number of '--verbose' parameters in your call to maximum 3\" % level)\n\n  # set up the verbosity level of the logging system\n  log_level = {\n      0: logging.ERROR,\n      1: logging.WARNING,\n      2: logging.INFO,\n      3: logging.DEBUG\n    }[args.verbose]\n\n  handler = logging.StreamHandler()\n  handler.setFormatter(logging.Formatter(\"%(asctime)s %(levelname)s %(name)s: %(message)s\"))\n  logger.addHandler(handler)\n  logger.setLevel(log_level)\n\n  return jm"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the memory required for the memfree field.", "response": "def get_memfree(memory, parallel):\n  \"\"\"Computes the memory required for the memfree field.\"\"\"\n  number = int(memory.rstrip(string.ascii_letters))\n  memtype = memory.lstrip(string.digits)\n  if not memtype:\n    memtype = \"G\"\n  return \"%d%s\" % (number*parallel, memtype)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsubmitting a job to the queue.", "response": "def submit(args):\n  \"\"\"Submission command\"\"\"\n\n  # set full path to command\n  if args.job[0] == '--':\n    del args.job[0]\n  if not os.path.isabs(args.job[0]):\n    args.job[0] = os.path.abspath(args.job[0])\n\n  jm = setup(args)\n  kwargs = {\n      'queue': args.qname,\n      'cwd': True,\n      'verbosity' : args.verbose,\n      'name': args.name,\n      'env': args.env,\n      'memfree': args.memory,\n      'io_big': args.io_big,\n  }\n\n  if args.array is not None:         kwargs['array'] = get_array(args.array)\n  if args.exec_dir is not None:      kwargs['exec_dir'] = args.exec_dir\n  if args.log_dir is not None:       kwargs['log_dir'] = args.log_dir\n  if args.dependencies is not None:  kwargs['dependencies'] = args.dependencies\n  if args.qname != 'all.q':          kwargs['hvmem'] = args.memory\n  # if this is a GPU queue and args.memory is provided, we set gpumem flag\n  # remove 'G' last character from the args.memory string\n  if args.qname in ('gpu', 'lgpu', 'sgpu', 'gpum') and args.memory is not None:\n    kwargs['gpumem'] = args.memory\n    # don't set these for GPU processing or the maximum virtual memroy will be\n    # set on ulimit\n    kwargs.pop('memfree', None)\n    kwargs.pop('hvmem', None)\n  if args.parallel is not None:\n    kwargs['pe_opt'] = \"pe_mth %d\" % args.parallel\n    if args.memory is not None:\n      kwargs['memfree'] = get_memfree(args.memory, args.parallel)\n  kwargs['dry_run'] = args.dry_run\n  kwargs['stop_on_failure'] = args.stop_on_failure\n\n  # submit the job(s)\n  for _ in range(args.repeat):\n    job_id = jm.submit(args.job, **kwargs)\n    dependencies = kwargs.get('dependencies', [])\n    dependencies.append(job_id)\n    kwargs['dependencies'] = dependencies\n\n  if args.print_id:\n    print (job_id, end='')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resubmit(args):\n  jm = setup(args)\n\n  kwargs = {\n      'cwd': True,\n      'verbosity' : args.verbose\n  }\n  if args.qname is not None:\n    kwargs['queue'] = args.qname\n  if args.memory is not None:\n    kwargs['memfree'] = args.memory\n    if args.qname not in (None, 'all.q'):\n      kwargs['hvmem'] = args.memory\n    # if this is a GPU queue and args.memory is provided, we set gpumem flag\n    # remove 'G' last character from the args.memory string\n    if args.qname in ('gpu', 'lgpu', 'sgpu', 'gpum') and args.memory is not None:\n      kwargs['gpumem'] = args.memory\n      # don't set these for GPU processing or the maximum virtual memroy will be\n      # set on ulimit\n      kwargs.pop('memfree', None)\n      kwargs.pop('hvmem', None)\n  if args.parallel is not None:\n    kwargs['pe_opt'] = \"pe_mth %d\" % args.parallel\n    kwargs['memfree'] = get_memfree(args.memory, args.parallel)\n  if args.io_big:\n    kwargs['io_big'] = True\n  if args.no_io_big:\n    kwargs['io_big'] = False\n\n  jm.resubmit(get_ids(args.job_ids), args.also_success, args.running_jobs, args.overwrite_command, keep_logs=args.keep_logs, **kwargs)", "response": "Re - submits the jobs with the given ids."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_scheduler(args):\n  if not args.local:\n    raise ValueError(\"The execute command can only be used with the '--local' command line option\")\n  jm = setup(args)\n  jm.run_scheduler(parallel_jobs=args.parallel, job_ids=get_ids(args.job_ids), sleep_time=args.sleep_time, die_when_finished=args.die_when_finished, no_log=args.no_log_files, nice=args.nice, verbosity=args.verbose)", "response": "Runs the scheduler on the local machine."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list(args):\n  jm = setup(args)\n  jm.list(job_ids=get_ids(args.job_ids), print_array_jobs=args.print_array_jobs, print_dependencies=args.print_dependencies, status=args.status, long=args.long, print_times=args.print_times, ids_only=args.ids_only, names=args.names)", "response": "Lists the jobs in the given database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nuse qstat to get the status of the requested jobs.", "response": "def communicate(args):\n  \"\"\"Uses qstat to get the status of the requested jobs.\"\"\"\n  if args.local:\n    raise ValueError(\"The communicate command can only be used without the '--local' command line option\")\n  jm = setup(args)\n  jm.communicate(job_ids=get_ids(args.job_ids))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreporting the results of the finished jobs.", "response": "def report(args):\n  \"\"\"Reports the results of the finished (and unfinished) jobs.\"\"\"\n  jm = setup(args)\n  jm.report(job_ids=get_ids(args.job_ids), array_ids=get_ids(args.array_ids), output=not args.errors_only, error=not args.output_only, status=args.status, name=args.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop(args):\n  if args.local:\n    raise ValueError(\"Stopping commands locally is not supported (please kill them yourself)\")\n  jm = setup(args)\n  jm.stop_jobs(get_ids(args.job_ids))", "response": "Stops the jobs with the given ids."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes the jobs from the job manager.", "response": "def delete(args):\n  \"\"\"Deletes the jobs from the job manager. If the jobs are still running in the grid, they are stopped.\"\"\"\n  jm = setup(args)\n  # first, stop the jobs if they are running in the grid\n  if not args.local and 'executing' in args.status:\n    stop(args)\n  # then, delete them from the database\n  jm.delete(job_ids=get_ids(args.job_ids), array_ids=get_ids(args.array_ids), delete_logs=not args.keep_logs, delete_log_dir=not args.keep_log_dir, status=args.status)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts the wrapper script to execute a job.", "response": "def run_job(args):\n  \"\"\"Starts the wrapper script to execute a job, interpreting the JOB_ID and SGE_TASK_ID keywords that are set by the grid or by us.\"\"\"\n  jm = setup(args)\n  job_id = int(os.environ['JOB_ID'])\n  array_id = int(os.environ['SGE_TASK_ID']) if os.environ['SGE_TASK_ID'] != 'undefined' else None\n  jm.run_job(job_id, array_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize from a list of options with random weights.", "response": "def with_random_weights(cls, options):\n        \"\"\"\n        Initialize from a list of options with random weights.\n\n        The weights assigned to each object are uniformally random\n        integers between ``1`` and ``len(options)``\n\n        Args:\n            options (list): The list of options of any type this object\n                can return with the ``get()`` method.\n\n        Returns:\n            SoftOptions: A newly constructed instance\n        \"\"\"\n        return cls([(value, random.randint(1, len(options)))\n                    for value in options])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bounded_uniform(cls, lowest, highest, weight_interval=None):\n        if weight_interval is None:\n            weights = [(lowest, 1), (highest, 1)]\n        else:\n            i = lowest\n            weights = []\n            while i < highest:\n                weights.append((i, 1))\n                i += weight_interval\n            weights.append((highest, 1))\n        return cls(weights)", "response": "Initialize with a uniform distribution between two values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rgb_to_hex(cls, color):\n        return '#{0:02x}{1:02x}{2:02x}'.format(\n            cls._bound_color_value(color[0]),\n            cls._bound_color_value(color[1]),\n            cls._bound_color_value(color[2])).upper()", "response": "Converts an rgb color tuple to a hexadecimal string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget an rgb color tuple according to the probability distribution.", "response": "def get(self):\n        \"\"\"\n        Get an rgb color tuple according to the probability distribution.\n\n        Returns:\n            tuple(int, int, int): A ``(red, green, blue)`` tuple.\n\n        Example:\n            >>> color = SoftColor(([(0, 1), (255, 10)],),\n            ...                   ([(0, 1), (255, 10)],),\n            ...                   ([(0, 1), (255, 10)],))\n            >>> color.get()                                    # doctest: +SKIP\n            (234, 201, 243)\n        \"\"\"\n        if isinstance(self.red, SoftInt):\n            red = self.red.get()\n        else:\n            red = self.red\n        if isinstance(self.green, SoftInt):\n            green = self.green.get()\n        else:\n            green = self.green\n        if isinstance(self.blue, SoftInt):\n            blue = self.blue.get()\n        else:\n            blue = self.blue\n        return (red, green, blue)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngrows up your markup", "response": "def grow(files: hug.types.multiple, in_ext: hug.types.text=\"short\", out_ext: hug.types.text=\"html\",\n         out_dir: hug.types.text=\"\", recursive: hug.types.smart_boolean=False):\n    \"\"\"Grow up your markup\"\"\"\n    if files == ['-']:\n        print(text(sys.stdin.read()))\n        return\n\n    print(INTRO)\n    if recursive:\n        files = iter_source_code(files, in_ext)\n\n    for file_name in files:\n        with open(file_name, 'r') as input_file:\n            output_file_name = \"{0}.{1}\".format(os.path.join(out_dir, \".\".join(file_name.split('.')[:-1])), out_ext)\n            with open(output_file_name, 'w') as output_file:\n                print(\"   |-> [{2}]: {3} '{0}' -> '{1}' till it's not short...\".format(file_name, output_file_name,\n                                                                                       'HTML', 'Growing'))\n                output_file.write(text(input_file.read()))\n\n    print(\"   |\")\n    print(\"   |                 >>> Done Growing! :) <<<\")\n    print(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_csv_arg_preprocess(abspath, memory_usage=100 * 1000 * 1000):\n    if memory_usage < 1000 * 1000:\n        raise ValueError(\"Please specify a valid memory usage for read_csv, \"\n                         \"the value should larger than 1MB and less than \"\n                         \"your available memory.\")\n\n    size = os.path.getsize(abspath)  # total size in bytes\n    n_time = math.ceil(size * 1.0 / memory_usage)  # at lease read n times\n\n    lines = count_lines(abspath)  # total lines\n    chunksize = math.ceil(lines / n_time)  # lines to read each time\n\n    if chunksize >= lines:\n        iterator = False\n        chunksize = None\n    else:\n        iterator = True\n    return iterator, chunksize", "response": "Automatically decide if we need to use iterator mode to read a csv file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_prettytable(df):\n    pt = PrettyTable()\n    pt.field_names = df.columns\n    for tp in zip(*(l for col, l in df.iteritems())):\n        pt.add_row(tp)\n    return pt", "response": "Convert DataFrame into PrettyTable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cli():\n    with open_client(cache_dir=get_cache_dir()) as client:\n        tip = client.frog_tip()\n\n    terminal_width = click.termui.get_terminal_size()[0]\n    wisdom = make_frog_fresco(tip, width=terminal_width)\n\n    click.echo(wisdom)", "response": "\\ n\\ n Frogsay generates an ASCII picture of a FROG tip."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking specified document for validity.", "response": "def verify_document(self, document: Document) -> bool:\n        \"\"\"\n        Check specified document\n        :param duniterpy.documents.Document document:\n        :return:\n        \"\"\"\n        signature = base64.b64decode(document.signatures[0])\n        prepended = signature + bytes(document.raw(), 'ascii')\n\n        try:\n            self.verify(prepended)\n            return True\n        except ValueError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify_ws2p_head(self, head: Any) -> bool:\n        signature = base64.b64decode(head.signature)\n        inline = head.inline()\n        prepended = signature + bytes(inline, 'ascii')\n\n        try:\n            self.verify(prepended)\n            return True\n        except ValueError:\n            return False", "response": "Check specified document contains a valid WS2P head."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_spss_headerfile(path, **kwargs):\n    headers_clean = {}\n    try:\n        with codecs.open(path, 'r', kwargs.get('encoding', 'latin-1')) as file_:\n            raw_file = file_.read()\n            raw_splited = exclude_empty_values(raw_file.split('.\\r\\n'))\n\n            # suposse that by default spss leyend is in position 0.\n            leyend = parse_spss_header_leyend(\n                raw_leyend=raw_splited.pop(kwargs.get('leyend_position', 0)),\n                leyend=headers_clean)\n\n            if not leyend:\n                raise Exception('Empty leyend')\n\n            # only want VARIABLE(S) LABEL(S) & VALUE(S) LABEL(S)\n            for label in [x for x in raw_splited if 'label' in x.lower()]:\n                values = parse_spss_header_labels(\n                    raw_labels=label,\n                    headers=leyend)\n\n    except Exception as ex:\n        logger.error('Fail to parse spss headerfile - {}'.format(ex), header_file=path)\n        headers_clean = {}\n\n    return headers_clean", "response": "Parse spss header file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing spss data file", "response": "def parse_spss_datafile(path, **kwargs):\n    \"\"\"\n    Parse spss data file\n\n    Arguments:\n        path {str} -- path al fichero de cabecera.\n        **kwargs {[dict]} -- otros argumentos que puedan llegar\n    \"\"\"\n    data_clean = []\n    with codecs.open(path, 'r', kwargs.get('encoding', 'latin-1')) as file_:\n        raw_file = file_.read()\n        data_clean = raw_file.split('\\r\\n')\n    return exclude_empty_values(data_clean)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a pdf file to a list of strings using the pdfminer lib.", "response": "def pdf_to_text(pdf_filepath='', **kwargs):\n    \"\"\"\n    Parse pdf to a list of strings using the pdfminer lib.\n\n    Args:\n        no_laparams=False,\n        all_texts=None,\n        detect_vertical=None, word_margin=None, char_margin=None,\n        line_margin=None, boxes_flow=None, codec='utf-8',\n        strip_control=False, maxpages=0, page_numbers=None, password=\"\",\n        scale=1.0, rotation=0, layoutmode='normal', debug=False,\n        disable_caching=False,\n    \"\"\"\n\n    result = []\n    try:\n        if not os.path.exists(pdf_filepath):\n            raise ValueError(\"No valid pdf filepath introduced..\")\n\n        # TODO: REVIEW THIS PARAMS\n        # update params if not defined\n        kwargs['outfp'] = kwargs.get('outfp', StringIO())\n        kwargs['laparams'] = kwargs.get('laparams', pdfminer.layout.LAParams())\n        kwargs['imagewriter'] = kwargs.get('imagewriter', None)\n        kwargs['output_type'] = kwargs.get('output_type', \"text\")\n        kwargs['codec'] = kwargs.get('codec', 'utf-8')\n        kwargs['disable_caching'] = kwargs.get('disable_caching', False)\n\n        with open(pdf_filepath, \"rb\") as f_pdf:\n            pdfminer.high_level.extract_text_to_fp(f_pdf, **kwargs)\n\n        result = kwargs.get('outfp').getvalue()\n\n    except Exception:\n        logger.error('fail pdf to text parsing')\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlimiting row passing a value.", "response": "def pdf_row_limiter(rows, limits=None, **kwargs):\n    \"\"\"\n    Limit row passing a value. In this case we dont implementate a best effort\n    algorithm because the posibilities are infite with a data text structure\n    from a pdf.\n    \"\"\"\n    limits = limits or [None, None]\n\n    upper_limit = limits[0] if limits else None\n    lower_limit = limits[1] if len(limits) > 1 else None\n\n    return rows[upper_limit: lower_limit]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pdf_to_dict(pdf_filepath, **kwargs):\n\n    \"\"\"\n    Main method to parse a pdf file to a dict.\n    \"\"\"\n\n    callbacks = {\n        'pdf_to_text': pdf_to_text,\n        'pdf_row_format': pdf_row_format,\n        'pdf_row_limiter': pdf_row_limiter,\n        'pdf_row_parser': pdf_row_parser,\n        'pdf_row_cleaner': pdf_row_cleaner\n        }\n\n    callbacks.update(kwargs.get('alt_callbacks', {}))\n    rows = kwargs.get('rows', [])\n\n    if not rows:\n        # pdf to string\n        rows_str = callbacks.get('pdf_to_text')(pdf_filepath, **kwargs)\n\n        # string to list of rows\n        rows = callbacks.get('pdf_row_format')(rows_str, **kwargs)\n\n    # apply limits\n    rows = callbacks.get('pdf_row_limiter')(rows, **kwargs)\n\n    # Parse data from rows to dict\n    rows = callbacks.get('pdf_row_parser')(rows, **kwargs)\n\n    # apply cleaner\n    rows = callbacks.get('pdf_row_cleaner')(rows)\n\n    return rows", "response": "Parse a pdf file to a dict."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stashed(func):\n\n    @functools.wraps(func)\n    def _wrapper(*args, **kwargs):\n        if CTX.stash and not CTX.repo.stashed:\n            CTX.repo.stash(func.__name__)\n            try:\n                func(*args, **kwargs)\n            finally:\n                CTX.repo.unstash()\n        else:\n            func(*args, **kwargs)\n\n    return _wrapper", "response": "Decorator to stash changed files between a destructive repo operation\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dynamic_load(name):\n    pieces = name.split('.')\n    item = pieces[-1]\n    mod_name = '.'.join(pieces[:-1])\n\n    mod = __import__(mod_name, globals(), locals(), [item])\n    return getattr(mod, item)", "response": "Equivalent of from X import Y"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_to_rows(src, size):\n\n    row = []\n    for item in src:\n        row.append(item)\n        if len(row) == size:\n            yield row\n            row = []\n\n    if row:\n        yield row", "response": "A generator that takes a enumerable item and returns a series of rows. Useful for turning a list into a series of rows."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef head_tail_middle(src):\n\n    if len(src) == 0:\n        return None, [], None\n\n    if len(src) == 1:\n        return src[0], [], None\n\n    if len(src) == 2:\n        return src[0], [], src[1]\n\n    return src[0], src[1:-1], src[-1]", "response": "Returns a tuple consisting of the head of a enumerable the middle of the enumerable as a list and the tail of the enumerable."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the calcemissions of the current record set.", "response": "def calcemissions(rates: xarray.DataArray, sim) -> Tuple[xarray.DataArray, np.ndarray, np.ndarray]:\n    if not sim.reacreq:\n        return 0., 0., 0.\n\n    ver = None\n    lamb = None\n    br = None\n    \"\"\"\n    Franck-Condon factor\n    http://chemistry.illinoisstate.edu/standard/che460/handouts/460-Feb28lec-S13.pdf\n    http://assign3.chem.usyd.edu.au/spectroscopy/index.php\n    \"\"\"\n# %% METASTABLE\n    if 'metastable' in sim.reacreq:\n        ver, lamb, br = getMetastable(rates, ver, lamb, br, sim.reactionfn)\n# %% PROMPT ATOMIC OXYGEN EMISSIONS\n    if 'atomic' in sim.reacreq:\n        ver, lamb, br = getAtomic(rates, ver, lamb, br, sim.reactionfn)\n# %% N2 1N EMISSIONS\n    if 'n21ng' in sim.reacreq:\n        ver, lamb, br = getN21NG(rates, ver, lamb, br, sim.reactionfn)\n# %% N2+ Meinel band\n    if 'n2meinel' in sim.reacreq:\n        ver, lamb, br = getN2meinel(rates, ver, lamb, br, sim.reactionfn)\n# %% N2 2P (after Vallance Jones, 1974)\n    if 'n22pg' in sim.reacreq:\n        ver, lamb, br = getN22PG(rates, ver, lamb, br, sim.reactionfn)\n# %% N2 1P\n    if 'n21pg' in sim.reacreq:\n        ver, lamb, br = getN21PG(rates, ver, lamb, br, sim.reactionfn)\n# %% Remove NaN wavelength entries\n    if ver is None:\n        raise ValueError('you have not selected any reactions to generate VER')\n# %% sort by wavelength, eliminate NaN\n    lamb, ver, br = sortelimlambda(lamb, ver, br)\n# %% assemble output\n    dfver = xarray.DataArray(data=ver, coords=[('alt_km', rates.alt_km),\n                                               ('wavelength_nm', lamb)])\n\n    return dfver, ver, br"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getMetastable(rates, ver: np.ndarray, lamb, br, reactfn: Path):\n    with h5py.File(reactfn, 'r') as f:\n        A = f['/metastable/A'][:]\n        lambnew = f['/metastable/lambda'].value.ravel(order='F')  # some are not 1-D!\n\n    \"\"\"\n    concatenate along the reaction dimension, axis=-1\n    \"\"\"\n    vnew = np.concatenate((A[:2] * rates.loc[..., 'no1s'].values[:, None],\n                           A[2:4] * rates.loc[..., 'no1d'].values[:, None],\n                           A[4:] * rates.loc[..., 'noii2p'].values[:, None]), axis=-1)\n\n    assert vnew.shape == (rates.shape[0], A.size)\n\n    return catvl(rates.alt_km, ver, vnew, lamb, lambnew, br)", "response": "get the metastable from the reaction file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getAtomic(rates, ver, lamb, br, reactfn):\n    with h5py.File(reactfn, 'r') as f:\n        lambnew = f['/atomic/lambda'].value.ravel(order='F')  # some are not 1-D!\n\n    vnew = np.concatenate((rates.loc[..., 'po3p3p'].values[..., None],\n                           rates.loc[..., 'po3p5p'].values[..., None]), axis=-1)\n\n    return catvl(rates.alt_km, ver, vnew, lamb, lambnew, br)", "response": "prompt atomic emissions (nm)\n    844.6 777.4"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getN21NG(rates, ver, lamb, br, reactfn):\n    with h5py.File(str(reactfn), 'r', libver='latest') as f:\n        A = f['/N2+1NG/A'].value\n        lambdaA = f['/N2+1NG/lambda'].value.ravel(order='F')\n        franckcondon = f['/N2+1NG/fc'].value\n\n    return doBandTrapz(A, lambdaA, franckcondon, rates.loc[..., 'p1ng'], lamb, ver, rates.alt_km, br)", "response": "get N21NG from H5py"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getN21PG(rates, ver, lamb, br, reactfn):\n\n    with h5py.File(str(reactfn), 'r', libver='latest') as fid:\n        A = fid['/N2_1PG/A'].value\n        lambnew = fid['/N2_1PG/lambda'].value.ravel(order='F')\n        franckcondon = fid['/N2_1PG/fc'].value\n\n    tau1PG = 1 / np.nansum(A, axis=1)\n    \"\"\"\n    solve for base concentration\n    confac=[1.66;1.56;1.31;1.07;.77;.5;.33;.17;.08;.04;.02;.004;.001];  %Cartwright, 1973b, stop at nuprime==12\n    Gattinger and Vallance Jones 1974\n    confac=array([1.66,1.86,1.57,1.07,.76,.45,.25,.14,.07,.03,.01,.004,.001])\n    \"\"\"\n\n    consfac = franckcondon/franckcondon.sum()  # normalize\n    losscoef = (consfac / tau1PG).sum()\n    N01pg = rates.loc[..., 'p1pg'] / losscoef\n\n    scalevec = (A * consfac[:, None]).ravel(order='F')  # for clarity (verified with matlab)\n\n    vnew = scalevec[None, None, :] * N01pg.values[..., None]\n\n    return catvl(rates.alt_km, ver, vnew, lamb, lambnew, br)", "response": "get N21PG from reaction file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef doBandTrapz(Aein, lambnew, fc, kin, lamb, ver, z, br):\n    tau = 1/np.nansum(Aein, axis=1)\n\n    scalevec = (Aein * tau[:, None] * fc[:, None]).ravel(order='F')\n\n    vnew = scalevec[None, None, :]*kin.values[..., None]\n\n    return catvl(z, ver, vnew, lamb, lambnew, br)", "response": "This function is used to do band trapz."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning to set a default namespace / include for a given resource.", "response": "def uconf(**kwargs):\n    \"\"\"\n        Function to set a default namespace/include.\n        It returns a decorator with the namespace/include argument already set.\n        Arguments:\n            - include: A custom URL list, previously\n                       set on the module's urls.py;\n            - namespace: the URL's namespace.\n    \"\"\"\n    if len(kwargs) != 1:\n        # this function must have exactly\n        # one specific argument (namespace or include)\n        raise TypeError(\n            'uconf() takes exactly 1 argument. ({} given)'.format(len(kwargs))\n        )\n    # gets the argument name\n    arg_name = list(kwargs.keys()).pop(0)\n    # checks if it has a valid name (it must be 'namespace' or 'include')\n    if arg_name not in ['include', 'namespace']:\n        # if it's not a valid name, raise a TypeError\n        raise TypeError(\n            'Invalid argument: {}'.format(arg_name)\n        )\n    # creates the decorator with namespace/include already set.\n    return partial(umap, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pep8(amend: bool = False, stage: bool = False):\n    _pep8(amend, stage)", "response": "Runs Pyup s Safety tool."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef searchTag(self,HTAG=\"#arenaNETmundial\"):\n        search = t.search(q=HTAG,count=100,result_type=\"recent\")\n        ss=search[:]\n        search = t.search(q=HTAG,count=150,max_id=ss[-1]['id']-1,result_type=\"recent\")\n        #search = t.search(q=HTAG,count=150,since_id=ss[-1]['id'],result_type=\"recent\")\n        while seach:\n            ss+=search[:]\n            search = t.search(q=HTAG,count=150,max_id=ss[-1]['id']-1,result_type=\"recent\")", "response": "Set Twitter search or stream criteria for the selection of tweets"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef download(self,\n                 url,\n                 dest_path=None):\n        \"\"\"\n        :param url:\n        :type url: str\n        :param dest_path:\n        :type dest_path: str\n        \"\"\"\n        if os.path.exists(dest_path):\n            os.remove(dest_path)\n\n        resp = get(url, stream=True)\n        size = int(resp.headers.get(\"content-length\"))\n        label = \"Downloading {filename} ({size:.2f}MB)\".format(\n            filename=os.path.basename(dest_path),\n            size=size / float(self.chunk_size) / self.chunk_size\n        )\n\n        with open_file(dest_path, 'wb') as file:\n            content_iter = resp.iter_content(chunk_size=self.chunk_size)\n            with progressbar(content_iter,\n                             length=size / self.chunk_size,\n                             label=label) as bar:\n                for chunk in bar:\n                    if chunk:\n                        file.write(chunk)\n                        file.flush()", "response": "Downloads the content of the url to dest_path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef upload(self,\n               url,\n               method=\"POST\",\n               file_path=None):\n        \"\"\"\n        :param url:\n        :type url: str\n        :param method:\n        :type method: str\n        :param file_path:\n        :type file_path: str\n        \"\"\"\n        if not os.path.exists(file_path):\n            raise RuntimeError(\"\")\n\n        with open_file(file_path, 'rb') as file:\n            size = os.path.getsize(file_path)\n            label = \"Uploading {filename} ({size:.2f}MB)\".format(\n                filename=os.path.basename(file_path),\n                size=size / float(self.chunk_size) / self.chunk_size\n            )\n\n            if method == \"PUT\":\n                resp = put(url, data=file)\n            elif method == \"POST\":\n                resp = post(url, data=file)\n\n            content_iter = resp.iter_content(chunk_size=self.chunk_size)\n\n            with progressbar(content_iter,\n                             length=size / self.chunk_size,\n                             label=label) as bar:\n                for _ in bar:\n                    pass", "response": "Uploads a file to the specified url."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload and run CREATE OR REPLACE function commands from files", "response": "def load_stored_proc(op, filelist):\n    \"\"\"\n    Takes the alembic op object as arguments and a list of files as arguments\n    Load and run CREATE OR REPLACE function commands from files\n    \"\"\"\n    for filename in filelist:\n        sqlfile = get_local_filepath(filename)\n        # Capturing \"file not exists\" here rather than allowing\n        # an exception to be thrown. Some of the rollback scripts\n        # would otherwise throw unhelpful exceptions when a SQL\n        # file is removed from the repo.\n        if not os.path.isfile(sqlfile):\n            warnings.warn(\n                \"Did not find %r. Continuing migration.\" % sqlfile,\n                UserWarning,\n                2\n            )\n            continue\n        with open(sqlfile, 'r') as stored_proc:\n            op.execute(stored_proc.read())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rmtree_errorhandler(func, path, exc_info):\n    exctype, value = exc_info[:2]\n    # On Python 2.4, it will be OSError number 13\n    # On all more recent Pythons, it'll be WindowsError number 5\n    if not ((exctype is WindowsError and value.args[0] == 5) or\n            (exctype is OSError and value.args[0] == 13)):\n        raise\n    # file type should currently be read only\n    if ((os.stat(path).st_mode & stat.S_IREAD) != stat.S_IREAD):\n        raise\n    # convert to read/write\n    os.chmod(path, stat.S_IWRITE)\n    # use the original function to repeat the operation\n    func(path)", "response": "This function is used to remove the files in. svn and the directories in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef display_path(path):\n    path = os.path.normcase(os.path.abspath(path))\n    if path.startswith(os.getcwd() + os.path.sep):\n        path = '.' + path[len(os.getcwd()):]\n    return path", "response": "Gives the display value for a given path making it relative to cwd\n    if possible."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_pathext(default_pathext=None):\n    if default_pathext is None:\n        default_pathext = os.pathsep.join([ '.COM', '.EXE', '.BAT', '.CMD' ])\n    pathext = os.environ.get('PATHEXT', default_pathext)\n    return pathext", "response": "Returns the path extensions from environment or a default"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nask the message interactively with the given possible responses", "response": "def ask(message, options):\n    \"\"\"Ask the message interactively, with the given possible responses\"\"\"\n    while 1:\n        if os.environ.get('PIP_NO_INPUT'):\n            raise Exception('No input was expected ($PIP_NO_INPUT set); question: %s' % message)\n        response = raw_input(message)\n        response = response.strip().lower()\n        if response not in options:\n            print('Your response (%r) was not one of the expected responses: %s' % (\n                response, ', '.join(options)))\n        else:\n            return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_installed_distributions(local_only=True, skip=('setuptools', 'pip', 'python')):\n    if local_only:\n        local_test = dist_is_local\n    else:\n        local_test = lambda d: True\n    return [d for d in pkg_resources.working_set if local_test(d) and d.key not in skip]", "response": "Return a list of installed Distribution objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the location of the distribution.", "response": "def dist_location(dist):\n    \"\"\"\n    Get the site-packages location of this distribution. Generally\n    this is dist.location, except in the case of develop-installed\n    packages, where dist.location is the source code location, and we\n    want to know where the egg-link file is.\n\n    \"\"\"\n    egg_link = egg_link_path(dist)\n    if os.path.exists(egg_link):\n        return egg_link\n    return dist.location"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unzip_file(filename, location, flatten=True):\n    if not os.path.exists(location):\n        os.makedirs(location)\n    zipfp = open(filename, 'rb')\n    try:\n        zip = zipfile.ZipFile(zipfp)\n        leading = has_leading_dir(zip.namelist()) and flatten\n        for name in zip.namelist():\n            data = zip.read(name)\n            fn = name\n            if leading:\n                fn = split_leading_dir(name)[1]\n            fn = os.path.join(location, fn)\n            dir = os.path.dirname(fn)\n            if not os.path.exists(dir):\n                os.makedirs(dir)\n            if fn.endswith('/') or fn.endswith('\\\\'):\n                # A directory\n                if not os.path.exists(fn):\n                    os.makedirs(fn)\n            else:\n                fp = open(fn, 'wb')\n                try:\n                    fp.write(data)\n                finally:\n                    fp.close()\n    finally:\n        zipfp.close()", "response": "Unzip the file located at filename to the destination location"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef untar_file(filename, location):\n    if not os.path.exists(location):\n        os.makedirs(location)\n    if filename.lower().endswith('.gz') or filename.lower().endswith('.tgz'):\n        mode = 'r:gz'\n    elif filename.lower().endswith('.bz2') or filename.lower().endswith('.tbz'):\n        mode = 'r:bz2'\n    elif filename.lower().endswith('.tar'):\n        mode = 'r'\n    else:\n        logger.warn('Cannot determine compression type for file %s' % filename)\n        mode = 'r:*'\n    tar = tarfile.open(filename, mode)\n    try:\n        # note: python<=2.5 doesnt seem to know about pax headers, filter them\n        leading = has_leading_dir([\n            member.name for member in tar.getmembers()\n            if member.name != 'pax_global_header'\n        ])\n        for member in tar.getmembers():\n            fn = member.name\n            if fn == 'pax_global_header':\n                continue\n            if leading:\n                fn = split_leading_dir(fn)[1]\n            path = os.path.join(location, fn)\n            if member.isdir():\n                if not os.path.exists(path):\n                    os.makedirs(path)\n            else:\n                try:\n                    fp = tar.extractfile(member)\n                except (KeyError, AttributeError):\n                    e = sys.exc_info()[1]\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    logger.warn(\n                        'In the tar file %s the member %s is invalid: %s'\n                        % (filename, member.name, e))\n                    continue\n                if not os.path.exists(os.path.dirname(path)):\n                    os.makedirs(os.path.dirname(path))\n                destfp = open(path, 'wb')\n                try:\n                    shutil.copyfileobj(fp, destfp)\n                finally:\n                    destfp.close()\n                fp.close()\n    finally:\n        tar.close()", "response": "Untar a file into a new location"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _value_properties_are_referenced(val):\n    if ((u'properties' in val.keys()) and\n            (u'$ref' in val['properties'].keys())):\n        return True\n    return False", "response": "Check if the value properties are referenced in the node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _value_is_type_text(val):\n    if ((u'type' in val.keys()) and\n            (val['type'].lower() == u\"text\")):\n        return True\n    return False", "response": "Check if the value is of type text."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the given permits have one whose category_code and status_code match with the given ones .", "response": "def _has_desired_permit(permits, acategory, astatus):\n    \"\"\"\n    return True if permits has one whose\n    category_code and status_code match with the given ones\n    \"\"\"\n    if permits is None:\n        return False\n    for permit in permits:\n        if permit.category_code == acategory and\\\n           permit.status_code == astatus:\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a compact representation of the given addresses.", "response": "def __compact_notification_addresses(addresses_):\n    \"\"\"\n    Input::\n\n        {\n            'default': 'http://domain/notice',\n            'event1': 'http://domain/notice',\n            'event2': 'http://domain/notice',\n            'event3': 'http://domain/notice3',\n            'event4': 'http://domain/notice3'\n        }\n\n    Output::\n\n        {\n            'default': 'http://domain/notice',\n            'event1,event2': 'http://domain/notice',\n            'event3,event4': 'http://domain/notice3'\n        }\n\n    \"\"\"\n    result = {}\n    addresses = dict(addresses_)\n    default = addresses.pop('default', None)\n\n    for key, value in __reverse_group_dict(addresses).items():\n        result[','.join(value)] = key\n\n    if default:\n        result['default'] = default\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_migrations_offline():\n    url = os.environ['DATABASE_URI']\n    context.configure(\n        url=url, target_metadata=target_metadata, literal_binds=True)\n\n    with context.begin_transaction():\n        context.run_migrations()", "response": "Run migrations in offline mode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_migrations_online():\n    alembic_config = config.get_section(config.config_ini_section)\n    alembic_config['sqlalchemy.url'] = os.environ['DATABASE_URI']\n\n    connectable = engine_from_config(\n        alembic_config,\n        prefix='sqlalchemy.',\n        poolclass=pool.NullPool)\n\n    with connectable.connect() as connection:\n        context.configure(\n            connection=connection,\n            target_metadata=target_metadata\n        )\n\n        with context.begin_transaction():\n            context.run_migrations()", "response": "Run migrations in online mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef makeRetweetNetwork(tweets):\n    G=x.DiGraph()\n    G_=x.DiGraph()\n    for tweet in tweets:\n        text=tweet[\"text\"]\n        us=tweet[\"user\"][\"screen_name\"]\n        if text.startswith(\"RT @\"):\n            prev_us=text.split(\":\")[0].split(\"@\")[1]\n            #print(us,prev_us,text)\n            if G.has_edge(prev_us,us):\n                G[prev_us][us][\"weight\"]+=1\n                G_[prev_us][us][\"weight\"]+=1\n            else:\n                G.add_edge(prev_us, us, weight=1.)\n                G_.add_edge(prev_us, us, weight=1.)\n        if us not in G_.nodes():\n            G_.add_node(us)\n    return G,G_", "response": "Receives tweets returns directed retweet networks."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef makeNetwork(self):\n        if \"weight\" in self.data_friendships.keys():\n            self.G=G=x.DiGraph()\n        else:\n            self.G=G=x.Graph()\n        F=self.data_friends\n        for friendn in range(self.n_friends):\n            if \"posts\" in F.keys():\n                G.add_node(F[\"name\"][friendn],\n                             label=F[\"label\"][friendn],\n                             posts=F[\"posts\"][friendn])\n            elif \"agerank\" in F.keys():\n                G.add_node(F[\"name\"][friendn],\n                             label=F[\"label\"][friendn],\n                             gender=F[\"sex\"][friendn],\n                             locale=F[\"locale\"][friendn], \n                             agerank=F[\"agerank\"][friendn])\n            else:\n                G.add_node(F[\"name\"][friendn],\n                             label=F[\"label\"][friendn],\n                             gender=F[\"sex\"][friendn],\n                             locale=F[\"locale\"][friendn])\n        F=self.data_friendships\n        for friendshipn in range(self.n_friendships):\n            if \"weight\" in F.keys():\n                G.add_edge(F[\"node1\"][friendshipn],F[\"node2\"][friendshipn],weight=F[\"weight\"][friendshipn])\n            else:\n                G.add_edge(F[\"node1\"][friendshipn],F[\"node2\"][friendshipn])", "response": "Makes a network object from. gdf loaded data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload file from url and save as fname.", "response": "def downlad_file(url, fname):\n    \"\"\"Download file from url and save as fname.\"\"\"\n    print(\"Downloading {} as {}\".format(url, fname))\n    response = urlopen(url)\n    download = response.read()\n    with open(fname, 'wb') as fh:\n        fh.write(download)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nunzip the zip_fname in the current directory.", "response": "def unzip_file(zip_fname):\n    \"\"\"Unzip the zip_fname in the current directory.\"\"\" \n    print(\"Unzipping {}\".format(zip_fname))\n    with zipfile.ZipFile(zip_fname) as zf:\n        zf.extractall()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef install_from_zip(url):\n    fname = 'tmp.zip'\n    downlad_file(url, fname)\n    unzip_file(fname)\n    print(\"Removing {}\".format(fname))\n    os.unlink(fname)", "response": "Download and unzip from url."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the physical name of item.", "response": "def phys_name(self, item: str) -> str:\n        \"\"\"Return the physical (mapped) name of item.\n\n        :param item: logical table name\n        :return: physical name of table\n        \"\"\"\n        v = self.__dict__[item]\n        return v if v is not None else item"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef all_tables(self) -> List[str]:\n        return sorted([k for k in self.__dict__.keys()\n                       if k not in _I2B2Tables._funcs and not k.startswith(\"_\")])", "response": "Returns a list of all known tables."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the system status", "response": "def system_status():  # noqa: E501\n    \"\"\"Retrieve the system status\n\n    Retrieve the system status # noqa: E501\n\n\n    :rtype: Response\n    \"\"\"\n    if(not hasAccess()):\n        return redirectUnauthorized()\n\n    body = State.config.serialize([\"driver\", \"log\", \"log-file\", \"log-colorize\"])\n    body.update({'debug': State.options.debug, 'sensitive': State.options.sensitive})\n    return Response(status=200, body=body)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_refresh(self, timeout, callback, *callback_args):\n        GObject.timeout_add(timeout, callback, *callback_args)", "response": "This method is used to set the refresh timeout for the current entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_menu_item(self, command, title):\n        m_item = Gtk.MenuItem()\n        m_item.set_label(title)\n        m_item.connect('activate', command)\n        self.menu.append(m_item)\n        self.menu.show_all()", "response": "Add mouse right click menu item."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_seperator(self):\n        m_item = Gtk.SeparatorMenuItem()\n        self.menu.append(m_item)\n        self.menu.show_all()", "response": "Add separator between labels in menu that called on right mouse click."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef right_click_event_statusicon(self, icon, button, time):\n\n        def pos(menu, aicon):\n            \"\"\"Just return menu\"\"\"\n            return Gtk.StatusIcon.position_menu(menu, aicon)\n\n        self.menu.popup(None, None, pos, icon, button, time)", "response": "Right click event handler for statusicon"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nimplementing how we will check standard battery condition.", "response": "def check_battery(self):\n        \"\"\"\n        Implement how we will check battery condition. Now it just trying to check standard battery\n        in /sys\n        \"\"\"\n        self.charging = False if \\\n            subprocess.getoutput(\"cat /sys/class/power_supply/BAT0/status\") == 'Discharging' \\\n            else True\n        percent = subprocess.getoutput(\"cat /sys/class/power_supply/BAT0/capacity\")\n        if not self.charging:\n            for val in self.dischlist:\n                if int(percent) <= int(val):\n                    self.indicator.set_icon(self.dischformat.format(value=val))\n                    break\n        else:\n            for val in self.chlist:\n                if int(percent) <= int(val):\n                    self.indicator.set_icon(self.chformat.format(value=val))\n                    break\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying the tooltip for the current system panel.", "response": "def tooltip_query(self, widget, x, y, keyboard_mode, tooltip):\n        \"\"\"\n        Set tooltip which appears when you hover mouse curson onto icon in system panel.\n        \"\"\"\n        tooltip.set_text(subprocess.getoutput(\"acpi\"))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshows version numbers for APS Journals API in Python for Humans.", "response": "def about():\n    \"\"\"\n    About box for aps. Gives version numbers for\n    aps, NumPy, SciPy, Cython, and MatPlotLib.\n    \"\"\"\n    print(\"\")\n    print(\"aps: APS Journals API in Python for Humans\")\n    print(\"Copyright (c) 2017 and later.\")\n    print(\"Xiao Shang\")\n    print(\"\")\n    print(\"aps Version:        %s\" % aps.__version__)\n    print(\"Numpy Version:      %s\" % numpy.__version__)\n    print(\"Scipy Version:      %s\" % scipy.__version__)\n    try:\n        import Cython\n        cython_ver = Cython.__version__\n    except:\n        cython_ver = 'None'\n    print(\"Cython Version:     %s\" % cython_ver)\n    try:\n        import matplotlib\n        matplotlib_ver = matplotlib.__version__\n    except:\n        matplotlib_ver = 'None'\n    print(\"Matplotlib Version: %s\" % matplotlib_ver)\n    print(\"Python Version:     %d.%d.%d\" % sys.version_info[0:3])\n    print(\"Number of CPUs:     %s\" % hardware_info()['cpus'])\n#    print(\"BLAS Info:          %s\" % _blas_info())\n    print(\"Platform Info:      %s (%s)\" % (platform.system(),\n                                           platform.machine()))\n    aps_install_path = os.path.dirname(inspect.getsourcefile(aps))\n    print(\"Installation path:  %s\" % aps_install_path)\n    print(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef success(headers = None, data = ''):\n    passed_headers = {} if headers is None else headers\n    if isinstance(data, dict): data = json.dumps(data)\n    ret_headers = {'status' : 'ok'}\n    ret_headers.update(passed_headers)\n    return server_responce(ret_headers, data)", "response": "Generate success JSON to send to client"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsynchronises access to the user file between processes", "response": "def lock_access(repository_path, callback):\n    \"\"\" Synchronise access to the user file between processes, this specifies\n    which user is allowed write access at the current time \"\"\"\n\n    with open(cpjoin(repository_path, 'lock_file'), 'w') as fd:\n        try:\n            fcntl.flock(fd, fcntl.LOCK_EX | fcntl.LOCK_NB)\n            returned = callback()\n            fcntl.flock(fd, fcntl.LOCK_UN)\n            return returned\n        except IOError:\n            return fail(lock_fail_msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites or clear the user lock file", "response": "def update_user_lock(repository_path, session_token):\n    \"\"\" Write or clear the user lock file \"\"\" # NOTE ALWAYS use within lock access callback\n\n    # While the user lock file should ALWAYS be written only within a lock_access\n    # callback, it is sometimes read asynchronously. Because of this updates to\n    # the file must be atomic. Write plus move is used to achieve this.\n    real_path = cpjoin(repository_path, 'user_file')\n    tmp_path  = cpjoin(repository_path, 'new_user_file')\n\n    with open(tmp_path, 'w') as fd2:\n        if session_token is None: fd2.write('')\n        else: fd2.write(json.dumps({'session_token' : session_token, 'expires' : int(time.time()) + 30}))\n        fd2.flush()\n    os.rename(tmp_path, real_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nallows a user to acquire the lock if no other user is currently using it.", "response": "def can_aquire_user_lock(repository_path, session_token):\n    \"\"\" Allow a user to acquire the lock if no other user is currently using it, if the original\n    user is returning, presumably after a network error, or if the lock has expired.  \"\"\"\n    # NOTE ALWAYS use within lock access callback\n\n    user_file_path = cpjoin(repository_path, 'user_file')\n    if not os.path.isfile(user_file_path): return True\n    with open(user_file_path, 'r') as fd2:\n        content = fd2.read()\n        if len(content) == 0: return True\n        try: res = json.loads(content)\n        except ValueError: return True\n        if res['expires'] < int(time.time()): return True\n        elif res['session_token'] == session_token: return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef varify_user_lock(repository_path, session_token):\n\n    with open(cpjoin(repository_path, 'user_file'), 'r') as fd2:\n        content = fd2.read()\n        if len(content) == 0: return False\n        try: res = json.loads(content)\n        except ValueError: return False\n        return res['session_token'] == session_token and int(time.time()) < int(res['expires'])\n    return False", "response": "Verify that a returning user has a valid token and their lock has not expired"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconnect to SQLite database and return a connection object.", "response": "def auth_db_connect(db_path):\n    \"\"\" An SQLite database is used to store authentication transient data,\n    this is tokens, strings of random data which are signed by the client,\n    and session_tokens which identify authenticated users \"\"\"\n\n    def dict_factory(cursor, row): return {col[0] : row[idx] for idx,col in enumerate(cursor.description)}\n    conn = db.connect(db_path)\n    conn.row_factory = dict_factory\n    if not auth_db_connect.init:\n        conn.execute('create table if not exists tokens (expires int, token text, ip text)')\n        conn.execute('create table if not exists session_tokens (expires int, token text, ip text, username text)')\n        auth_db_connect.init = True\n    return conn"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef begin_auth():\n\n    repository    = request.headers['repository']\n    if repository not in config['repositories']: return fail(no_such_repo_msg)\n\n    # ==\n    repository_path = config['repositories'][repository]['path']\n    conn = auth_db_connect(cpjoin(repository_path, 'auth_transient.db')); gc_tokens(conn)\n\n    # Issue a new token\n    auth_token = base64.b64encode(pysodium.randombytes(35)).decode('utf-8')\n    conn.execute(\"insert into tokens (expires, token, ip) values (?,?,?)\",\n                 (time.time() + 30, auth_token, request.environ['REMOTE_ADDR']))\n    conn.commit()\n\n    return success({'auth_token' : auth_token})", "response": "Request authentication token to sign"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef authenticate():\n\n    client_ip     = request.environ['REMOTE_ADDR']\n    repository    = request.headers['repository']\n    if repository not in config['repositories']: return fail(no_such_repo_msg)\n\n    # ==\n    repository_path = config['repositories'][repository]['path']\n    conn = auth_db_connect(cpjoin(repository_path, 'auth_transient.db')); gc_tokens(conn)\n    gc_tokens(conn)\n\n    # Allow resume of an existing session\n    if 'session_token' in request.headers:\n        session_token = request.headers['session_token']\n\n        conn.execute(\"delete from session_tokens where expires < ?\", (time.time(),)); conn.commit()\n        res = conn.execute(\"select * from session_tokens where token = ? and ip = ?\", (session_token, client_ip)).fetchall()\n        if res != []: return success({'session_token'  : session_token})\n        else:         return fail(user_auth_fail_msg)\n\n    # Create a new session\n    else:\n        user       = request.headers['user']\n        auth_token = request.headers['auth_token']\n        signiture  = request.headers['signature']\n\n        try:\n            public_key = config['users'][user]['public_key']\n\n            # signature\n            pysodium.crypto_sign_verify_detached(base64.b64decode(signiture), auth_token, base64.b64decode(public_key))\n\n            # check token was previously issued by this system and is still valid\n            res = conn.execute(\"select * from tokens where token = ? and ip = ? \", (auth_token, client_ip)).fetchall()\n\n            # Validate token matches one we sent\n            if res == [] or len(res) > 1: return fail(user_auth_fail_msg)\n\n            # Does the user have permission to use this repository?\n            if repository not in config['users'][user]['uses_repositories']: return fail(user_auth_fail_msg)\n\n            # Everything OK\n            conn.execute(\"delete from tokens where token = ?\", (auth_token,)); conn.commit()\n\n            # generate a session token and send it to the client\n            session_token = base64.b64encode(pysodium.randombytes(35))\n            conn.execute(\"insert into session_tokens (token, expires, ip, username) values (?,?,?, ?)\",\n                         (session_token, time.time() + extend_session_duration, client_ip, user))\n            conn.commit()\n            return success({'session_token'  : session_token})\n\n        except Exception: # pylint: disable=broad-except\n            return fail(user_auth_fail_msg)", "response": "This function handles two things either validate a pre - existing session token or create a new session token from a signed authentication token."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef have_authenticated_user(client_ip, repository, session_token):\n\n    if repository not in config['repositories']: return False\n\n    repository_path = config['repositories'][repository]['path']\n    conn = auth_db_connect(cpjoin(repository_path, 'auth_transient.db'))\n\n    # Garbage collect session tokens. We must not garbage collect the authentication token of the client\n    # which is currently doing a commit. Large files can take a long time to upload and during this time,\n    # the locks expiration is not being updated thus can expire. This is a problem here as session tokens\n    # table is garbage collected every time a user authenticates. It does not matter if the user_lock\n    # expires while the client also holds the flock, as it is updated to be in the future at the end of\n    # the current operation. We exclude any tokens owned by the client which currently owns the user\n    # lock for this reason.\n    user_lock = read_user_lock(repository_path)\n    active_commit = user_lock['session_token'] if user_lock != None else None\n\n    if active_commit != None: conn.execute(\"delete from session_tokens where expires < ? and token != ?\", (time.time(), active_commit))\n    else:                     conn.execute(\"delete from session_tokens where expires < ?\", (time.time(),))\n\n    # Get the session token\n    res = conn.execute(\"select * from session_tokens where token = ? and ip = ?\", (session_token, client_ip)).fetchall()\n\n    if res != [] and repository in config['users'][res[0]['username']]['uses_repositories']:\n        conn.execute(\"update session_tokens set expires = ? where token = ? and ip = ?\",\n                     (time.time() + extend_session_duration, session_token, client_ip))\n\n        conn.commit() # to make sure the update and delete have the same view\n\n        return res[0]\n\n    conn.commit()\n    return False", "response": "Check if a client has authenticated the user"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind changes since the revision it is currently holding", "response": "def find_changed():\n    \"\"\" Find changes since the revision it is currently holding \"\"\"\n\n    session_token = request.headers['session_token']\n    repository    = request.headers['repository']\n\n    #===\n    current_user = have_authenticated_user(request.environ['REMOTE_ADDR'], repository, session_token)\n    if current_user is False: return fail(user_auth_fail_msg)\n\n    #===\n    repository_path = config['repositories'][repository]['path']\n    body_data = request.get_json()\n\n    #===\n    data_store = versioned_storage(repository_path)\n    head = data_store.get_head()\n    if head == 'root': return success({}, {'head' : 'root', 'sorted_changes' : {'none' : []}})\n\n    # Find changed items\n    client_changes = json.loads(body_data['client_changes'])\n    server_changes = data_store.get_changes_since(request.headers[\"previous_revision\"], head)\n\n    # Resolve conflicts\n    conflict_resolutions = json.loads(body_data['conflict_resolutions'])\n    if conflict_resolutions != []:\n        resolutions = {'server' : {},'client' : {}}\n        for r in conflict_resolutions:\n            if len(r['4_resolution']) != 1 or r['4_resolution'][0] not in ['client', 'server']: return fail(conflict_msg)\n            resolutions[r['4_resolution'][0]][r['1_path']] = None\n\n        client_changes = {k : v for k,v in client_changes.iteritems() if v['path'] not in resolutions['server']}\n        server_changes = {k : v for k,v in server_changes.iteritems() if v['path'] not in resolutions['client']}\n\n    sorted_changes = merge_client_and_server_changes(server_changes, client_changes)\n    return success({}, {'head' : head, 'sorted_changes': sorted_changes})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pull_file():\n\n    session_token = request.headers['session_token']\n    repository    = request.headers['repository']\n\n    #===\n    current_user = have_authenticated_user(request.environ['REMOTE_ADDR'], repository, session_token)\n    if current_user is False: return fail(user_auth_fail_msg)\n\n\n    #===\n    data_store = versioned_storage(config['repositories'][repository]['path'])\n    file_info = data_store.get_file_info_from_path(request.headers['path'])\n\n    return success({'file_info_json' : json.dumps(file_info)},\n                   send_from_directory(data_store.get_file_directory_path(file_info['hash']), file_info['hash'][2:]))", "response": "Get a file from the server"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef begin_commit():\n\n    session_token = request.headers['session_token']\n    repository    = request.headers['repository']\n\n    #===\n    current_user = have_authenticated_user(request.environ['REMOTE_ADDR'], repository, session_token)\n    if current_user is False: return fail(user_auth_fail_msg)\n\n    #===\n    repository_path = config['repositories'][repository]['path']\n\n    def with_exclusive_lock():\n        # The commit is locked for a given time period to a given session token,\n        # a client must hold this lock to use any of push_file(), delete_files() and commit().\n        # It does not matter if the user lock technically expires while a client is writing\n        # a large file, as the user lock is locked using flock for the duration of any\n        # operation and thus cannot be stolen by another client. It is updated to be in\n        # the future before returning to the client. The lock only needs to survive until\n        # the client owning the lock sends another request and re acquires the flock.\n        if not can_aquire_user_lock(repository_path, session_token): return fail(lock_fail_msg)\n\n        # Commits can only take place if the committing user has the latest revision,\n        # as committing from an outdated state could cause unexpected results, and may\n        # have conflicts. Conflicts are resolved during a client update so they are\n        # handled by the client, and a server interface for this is not needed.\n        data_store = versioned_storage(repository_path)\n        if data_store.get_head() != request.headers[\"previous_revision\"]: return fail(need_to_update_msg)\n\n\n        # Should the lock expire, the client which had the lock previously will be unable\n        # to continue the commit it had in progress. When this, or another client attempts\n        # to commit again it must do so by first obtaining the lock again by calling begin_commit().\n        # Any remaining commit data from failed prior commits is garbage collected here.\n        # While it would technically be possible to implement commit resume should the same\n        # client resume, I only see commits failing due to a network error and this is so\n        # rare I don't think it's worth the trouble.\n        if data_store.have_active_commit(): data_store.rollback()\n\n        #------------\n        data_store.begin()\n        update_user_lock(repository_path, session_token)\n\n        return success()\n    return lock_access(repository_path, with_exclusive_lock)", "response": "Allow a client to begin a commit and acquire the write lock"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npush a file to the server", "response": "def push_file():\n    \"\"\" Push a file to the server \"\"\" #NOTE beware that reading post data in flask causes hang until file upload is complete\n\n    session_token = request.headers['session_token']\n    repository    = request.headers['repository']\n\n    #===\n    current_user = have_authenticated_user(request.environ['REMOTE_ADDR'], repository, session_token)\n    if current_user is False: return fail(user_auth_fail_msg)\n\n    #===\n    repository_path = config['repositories'][repository]['path']\n\n    def with_exclusive_lock():\n        if not varify_user_lock(repository_path, session_token): return fail(lock_fail_msg)\n\n        #===\n        data_store = versioned_storage(repository_path)\n        if not data_store.have_active_commit(): return fail(no_active_commit_msg)\n\n        # There is no valid reason for path traversal characters to be in a file path within this system\n        file_path = request.headers['path']\n        if any(True for item in re.split(r'\\\\|/', file_path) if item in ['..', '.']): return fail()\n\n        #===\n        tmp_path = cpjoin(repository_path, 'tmp_file')\n        with open(tmp_path, 'wb') as f:\n            while True:\n                chunk = request.stream.read(1000 * 1000)\n                if chunk == b'': break\n                f.write(chunk)\n\n        #===\n        data_store.fs_put_from_file(tmp_path, {'path' : file_path})\n\n        # updates the user lock expiry\n        update_user_lock(repository_path, session_token)\n        return success()\n\n    return lock_access(repository_path, with_exclusive_lock)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_files():\n\n    session_token = request.headers['session_token']\n    repository    = request.headers['repository']\n\n    #===\n    current_user = have_authenticated_user(request.environ['REMOTE_ADDR'], repository, session_token)\n    if current_user is False: return fail(user_auth_fail_msg)\n\n    #===\n    repository_path = config['repositories'][repository]['path']\n    body_data = request.get_json()\n\n    def with_exclusive_lock():\n        if not varify_user_lock(repository_path, session_token): return fail(lock_fail_msg)\n\n        try:\n            data_store = versioned_storage(repository_path)\n            if not data_store.have_active_commit(): return fail(no_active_commit_msg)\n\n            #-------------\n            for fle in json.loads(body_data['files']):\n                data_store.fs_delete(fle)\n\n            # updates the user lock expiry\n            update_user_lock(repository_path, session_token)\n            return success()\n        except Exception: return fail() # pylint: disable=broad-except\n    return lock_access(repository_path, with_exclusive_lock)", "response": "Delete one or more files from the server"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncommit changes and releases the write lock", "response": "def commit():\n    \"\"\" Commit changes and release the write lock \"\"\"\n\n    session_token = request.headers['session_token']\n    repository    = request.headers['repository']\n\n    #===\n    current_user = have_authenticated_user(request.environ['REMOTE_ADDR'], repository, session_token)\n    if current_user is False: return fail(user_auth_fail_msg)\n\n    #===\n    repository_path = config['repositories'][repository]['path']\n\n    def with_exclusive_lock():\n        if not varify_user_lock(repository_path, session_token): return fail(lock_fail_msg)\n\n        #===\n        data_store = versioned_storage(repository_path)\n        if not data_store.have_active_commit(): return fail(no_active_commit_msg)\n\n        result = {}\n        if request.headers['mode'] == 'commit':\n            new_head = data_store.commit(request.headers['commit_message'], current_user['username'])\n            result = {'head' : new_head}\n        else:\n            data_store.rollback()\n\n        # Release the user lock\n        update_user_lock(repository_path, None)\n        return success(result)\n    return lock_access(repository_path, with_exclusive_lock)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serialize(self):\n\n        data = {}\n        for k, v in self.iteritems():\n            if k.startswith('_'):\n                continue\n\n            if isinstance(v, APIModel):\n                data[k] = v.serialize()\n            elif v and is_seq_not_string(v) and isinstance(v[0], APIModel):\n                data[k] = [x.serialize() for x in v]\n            else:\n                data[k] = v\n\n        return data", "response": "Converts a dict with the APIModel s attributes into a normal dict without references to the api\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_annotation(self, key, result_format='list'):\n        value = self.get('_annotations_by_key', {}).get(key)\n        if not value:\n            return value\n\n        if result_format == 'one':\n            return value[0]\n\n        return value", "response": "Get the annotation for the given key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the state of the current user", "response": "def update_user(self):\n        \"\"\"\n        Save the state of the current user\n        \"\"\"\n        # First create a copy of the current user\n        user_dict = self.serialize()\n        # Then delete the entities in the description field\n        del user_dict['description']['entities']\n        # Then upload user_dict\n        user, meta = self._api.update_user('me', data=user_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntest two dictionary is equal on values.", "response": "def is_same_dict(d1, d2):\n    \"\"\"Test two dictionary is equal on values. (ignore order)\n    \"\"\"\n    for k, v in d1.items():\n        if isinstance(v, dict):\n            is_same_dict(v, d2[k])\n        else:\n            assert d1[k] == d2[k]\n\n    for k, v in d2.items():\n        if isinstance(v, dict):\n            is_same_dict(v, d1[k])\n        else:\n            assert d1[k] == d2[k]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all nested Constant class and its name pair.", "response": "def Subclasses(cls, sort_by=None, reverse=False):\n        \"\"\"Get all nested Constant class and it's name pair.\n\n        :param sort_by: the attribute name used for sorting.\n        :param reverse: if True, return in descend order.\n        :returns: [(attr, value),...] pairs.\n\n        ::\n\n        >>> class MyClass(Constant):\n        ...     a = 1 # non-class attributre\n        ...     b = 2 # non-class attributre\n        ...\n        ...     class C(Constant):\n        ...         pass\n        ...\n        ...     class D(Constant):\n        ...         pass\n\n        >>> MyClass.Subclasses()\n        [(\"C\", MyClass.C), (\"D\", MyClass.D)]\n\n        .. versionadded:: 0.0.3\n        \"\"\"\n        l = list()\n        for attr, value in get_all_attributes(cls):\n            try:\n                if issubclass(value, Constant):\n                    l.append((attr, value))\n            except:\n                pass\n\n        if sort_by is None:\n            sort_by = \"__creation_index__\"\n\n        l = list(\n            sorted(l, key=lambda x: getattr(x[1], sort_by), reverse=reverse))\n\n        return l"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subclasses(self, sort_by=None, reverse=False):\n        l = list()\n        for attr, _ in self.Subclasses(sort_by, reverse):\n            value = getattr(self, attr)\n            l.append((attr, value))\n        return l", "response": "Get all nested Constant class instance and it s name pair."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the first nested Constant class that met attr == value.", "response": "def GetFirst(cls, attr, value, e=0.000001, sort_by=\"__name__\"):\n        \"\"\"Get the first nested Constant class that met ``klass.attr == value``.\n\n        :param attr: attribute name.\n        :param value: value.\n        :param e: used for float value comparison.\n        :param sort_by: nested class is ordered by <sort_by> attribute.\n\n        .. versionadded:: 0.0.5\n        \"\"\"\n        for _, klass in cls.Subclasses(sort_by=sort_by):\n            try:\n                if klass.__dict__[attr] == approx(value, e):\n                    return klass\n            except:\n                pass\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_first(self, attr, value, e=0.000001,\n                  sort_by=\"__name__\", reverse=False):\n        \"\"\"Get the first nested Constant class that met ``klass.attr == value``.\n\n        :param attr: attribute name.\n        :param value: value.\n        :param e: used for float value comparison.\n        :param sort_by: nested class is ordered by <sort_by> attribute.\n\n        .. versionchanged:: 0.0.5\n        \"\"\"\n        for _, klass in self.subclasses(sort_by, reverse):\n            try:\n                if getattr(klass, attr) == approx(value, e):\n                    return klass\n            except:\n                pass\n\n        return None", "response": "Get the first nested Constant class that met attr == value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetAll(cls, attr, value, e=0.000001, sort_by=\"__name__\"):\n        matched = list()\n        for _, klass in cls.Subclasses(sort_by=sort_by):\n            try:\n                if klass.__dict__[attr] == approx(value, e):\n                    matched.append(klass)\n            except:  # pragma: no cover\n                pass\n\n        return matched", "response": "Get all nested Constant classes that met attr == value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all nested Constant classes that met attr == value.", "response": "def get_all(self, attr, value, e=0.000001,\n                sort_by=\"__name__\", reverse=False):\n        \"\"\"Get all nested Constant class that met ``klass.attr == value``.\n\n        :param attr: attribute name.\n        :param value: value.\n        :param e: used for float value comparison.\n        :param sort_by: nested class is ordered by <sort_by> attribute.\n\n        .. versionchanged:: 0.0.5\n        \"\"\"\n        matched = list()\n        for _, klass in self.subclasses(sort_by, reverse):\n            try:\n                if getattr(klass, attr) == approx(value, e):\n                    matched.append(klass)\n            except:  # pragma: no cover\n                pass\n\n        return matched"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nassign defined one side mapping relationship to other side.", "response": "def BackAssign(cls,\n                   other_entity_klass,\n                   this_entity_backpopulate_field,\n                   other_entity_backpopulate_field,\n                   is_many_to_one=False):\n        \"\"\"\n        Assign defined one side mapping relationship to other side.\n\n        For example, each employee belongs to one department, then one department\n        includes many employees. If you defined each employee's department,\n        this method will assign employees to ``Department.employees`` field.\n        This is an one to many (department to employee) example.\n\n        Another example would be, each employee has multiple tags. If you defined\n        tags for each employee, this method will assign employees to\n        ``Tag.employees`` field. This is and many to many (employee to tag) example.\n\n        Support:\n\n        - many to many mapping\n        - one to many mapping\n\n        :param other_entity_klass: a :class:`Constant` class.\n        :param this_entity_backpopulate_field: str\n        :param other_entity_backpopulate_field: str\n        :param is_many_to_one: bool\n        :return:\n        \"\"\"\n        data = dict()\n        for _, other_klass in other_entity_klass.Subclasses():\n            other_field_value = getattr(\n                other_klass, this_entity_backpopulate_field)\n            if isinstance(other_field_value, (tuple, list)):\n                for self_klass in other_field_value:\n                    self_key = self_klass.__name__\n                    try:\n                        data[self_key].append(other_klass)\n                    except KeyError:\n                        data[self_key] = [other_klass, ]\n            else:\n                if other_field_value is not None:\n                    self_klass = other_field_value\n                    self_key = self_klass.__name__\n                    try:\n                        data[self_key].append(other_klass)\n                    except KeyError:\n                        data[self_key] = [other_klass, ]\n\n        if is_many_to_one:\n            new_data = dict()\n            for key, value in data.items():\n                try:\n                    new_data[key] = value[0]\n                except:  # pragma: no cover\n                    pass\n            data = new_data\n\n        for self_key, other_klass_list in data.items():\n            setattr(getattr(cls, self_key),\n                    other_entity_backpopulate_field, other_klass_list)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndumps data into a dict.", "response": "def dump(cls):\n        \"\"\"Dump data into a dict.\n\n        .. versionadded:: 0.0.2\n        \"\"\"\n        d = OrderedDict(cls.Items())\n        d[\"__classname__\"] = cls.__name__\n        for attr, klass in cls.Subclasses():\n            d[attr] = klass.dump()\n        return OrderedDict([(cls.__name__, d)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs a Constant class from it s dict data.", "response": "def load(cls, data):\n        \"\"\"Construct a Constant class from it's dict data.\n\n        .. versionadded:: 0.0.2\n        \"\"\"\n        if len(data) == 1:\n            for key, value in data.items():\n                if \"__classname__\" not in value:  # pragma: no cover\n                    raise ValueError\n                name = key\n                bases = (Constant,)\n                attrs = dict()\n                for k, v in value.items():\n                    if isinstance(v, dict):\n                        if \"__classname__\" in v:\n                            attrs[k] = cls.load({k: v})\n                        else:\n                            attrs[k] = v\n                    else:\n                        attrs[k] = v\n            return type(name, bases, attrs)\n        else:  # pragma: no cover\n            raise ValueError"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting detailed weather data for the requested days and location", "response": "def hourly(location='Fresno, CA', days=1, start=None, end=None, years=1, use_cache=True, verbosity=1):\n    \"\"\" Get detailed (hourly) weather data for the requested days and location\n\n    The Weather Underground URL for Fresno, CA on 1/1/2011 is:\n    http://www.wunderground.com/history/airport/KFAT/2011/1/1/DailyHistory.html?MR=1&format=1\n\n    This will fail periodically on Travis, b/c wunderground says \"No daily or hourly history data available\"\n    >> df = hourly('Fresno, CA', verbosity=-1)\n    >> 1 <= len(df) <= 24 * 2\n    True\n    The time zone of the client where this is used to compose the first column label, hence the ellipsis\n    >> df.columns  # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE\n    Index([u'Time...\n\n    >> df = hourly('Fresno, CA', days=5, verbosity=-1)\n    >> 24 * 4 <= len(df) <= 24 * (5 + 1) * 2\n    True\n    \"\"\"\n    airport_code = airport(location, default=location)\n\n    if isinstance(days, int):\n        start = start or None\n        end = end or datetime.datetime.today().date()\n        days = pd.date_range(start=start, end=end, periods=days)\n\n    # refresh the cache each calendar month or each change in the number of days in the dataset\n    cache_path = 'hourly-{}-{}-{:02d}-{:04d}.csv'.format(airport_code, days[-1].year, days[-1].month, len(days))\n    cache_path = os.path.join(CACHE_PATH, cache_path)\n    if use_cache:\n        try:\n            return pd.DataFrame.from_csv(cache_path)\n        except:\n            pass\n\n    df = pd.DataFrame()\n    for day in days:\n        url = ('http://www.wunderground.com/history/airport/{airport_code}/{year}/{month}/{day}/DailyHistory.html?MR=1&format=1'.format(\n               airport_code=airport_code,\n               year=day.year,\n               month=day.month,\n               day=day.day))\n        if verbosity > 1:\n            print('GETing *.CSV using \"{0}\"'.format(url))\n        buf = urllib.urlopen(url).read()\n        if verbosity > 0:\n            N = buf.count('\\n')\n            M = (buf.count(',') + N) / float(N)\n            print('Retrieved CSV for airport code \"{}\" with appox. {} lines and {} columns = {} cells.'.format(\n                  airport_code, N, int(round(M)), int(round(M)) * N))\n        if (buf.count('\\n') > 2) or ((buf.count('\\n') > 1) and buf.split('\\n')[1].count(',') > 0):\n            table = util.read_csv(buf, format='header+values-list', numbers=True)\n            columns = [s.strip() for s in table[0]]\n            table = table[1:]\n            tzs = [s[4:] for s in columns if (s[5:] in ['ST', 'DT'] and s[4] in 'PMCE' and s[:4].lower() == 'time')]\n            if tzs:\n                tz = tzs[0]\n            else:\n                tz = 'UTC'\n            for rownum, row in enumerate(table):\n                try:\n                    table[rownum] = [util.make_tz_aware(row[0], tz)] + row[1:]\n                except ValueError:\n                    pass\n            dates = [row[-1] for row in table]\n            if not all(isinstance(date, (datetime.datetime, pd.Timestamp)) for date in dates):\n                dates = [row[0] for row in table]\n            if len(columns) == len(table[0]):\n                df0 = pd.DataFrame(table, columns=columns, index=dates)\n                df = df.append(df0)\n            elif verbosity >= 0:\n                msg = \"The number of columns in the 1st row of the table:\\n    {}\\n    doesn't match the number of column labels:\\n    {}\\n\".format(\n                    table[0], columns)\n                msg += \"Wunderground.com probably can't find the airport: {} ({})\\n    or the date: {}\\n    in its database.\\n\".format(\n                    airport_code, location, day)\n                msg += \"Attempted a GET request using the URI:\\n    {0}\\n\".format(url)\n                warnings.warn(msg)\n    try:\n        df.to_csv(cache_path)\n    except:\n        if verbosity > 0 and use_cache:\n            from traceback import print_exc\n            print_exc()\n            warnings.warn('Unable to write weather data to cache file at {}'.format(cache_path))\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nuse the wunderground API to get current conditions instead of scraping", "response": "def api(feature='conditions', city='Portland', state='OR', key=None):\n    \"\"\"Use the wunderground API to get current conditions instead of scraping\n\n    Please be kind and use your own key (they're FREE!):\n    http://www.wunderground.com/weather/api/d/login.html\n\n    References:\n        http://www.wunderground.com/weather/api/d/terms.html\n\n    Examples:\n        >>> api('hurric', 'Boise', 'ID')  # doctest: +NORMALIZE_WHITESPACE, +ELLIPSIS\n        {u'currenthurricane': ...}}}\n\n        >>> features = ('alerts astronomy conditions currenthurricane forecast forecast10day geolookup history hourly hourly10day ' +\n        ...             'planner rawtide satellite tide webcams yesterday').split(' ')\n        >> everything = [api(f, 'Portland') for f in features]\n        >> js = api('alerts', 'Portland', 'OR')\n        >> js = api('condit', 'Sacramento', 'CA')\n        >> js = api('forecast', 'Mobile', 'AL')\n        >> js = api('10day', 'Fairhope', 'AL')\n        >> js = api('geo', 'Decatur', 'AL')\n        >> js = api('hist', 'history', 'AL')\n        >> js = api('astro')\n    \"\"\"\n    features = ('alerts astronomy conditions currenthurricane forecast forecast10day geolookup history hourly hourly10day ' +\n                'planner rawtide satellite tide webcams yesterday').split(' ')\n    feature = util.fuzzy_get(features, feature)\n    # Please be kind and use your own key (they're FREE!):\n    # http://www.wunderground.com/weather/api/d/login.html\n    key = key or env.get('WUNDERGROUND', None, verbosity=-1) or env.get('WUNDERGROUND_KEY', 'c45a86c2fc63f7d0', verbosity=-1)\n    url = 'http://api.wunderground.com/api/{key}/{feature}/q/{state}/{city}.json'.format(\n        key=key, feature=feature, state=state, city=city)\n    return json.load(urllib.urlopen(url))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve weather for the indicated airport code or city ST string.", "response": "def daily(location='Fresno, CA', years=1, use_cache=True, verbosity=1):\n    \"\"\"Retrieve weather for the indicated airport code or 'City, ST' string.\n\n    >>> df = daily('Camas, WA', verbosity=-1)\n    >>> 365 <= len(df) <= 365 * 2 + 1\n    True\n\n    Sacramento data has gaps (airport KMCC):\n        8/21/2013 is missing from 2013.\n        Whole months are missing from 2014.\n    >>> df = daily('Sacramento, CA', years=[2013], verbosity=-1)\n    >>> 364 <= len(df) <= 365\n    True\n    >>> df.columns\n    Index([u'PST', u'Max TemperatureF', u'Mean TemperatureF', u'Min TemperatureF', u'Max Dew PointF', u'MeanDew PointF', u'Min DewpointF', ...\n    \"\"\"\n    this_year = datetime.date.today().year\n    if isinstance(years, (int, float)):\n        # current (incomplete) year doesn't count in total number of years\n        # so 0 would return this calendar year's weather data\n        years = np.arange(0, int(years) + 1)\n    years = sorted(years)\n    if not all(1900 <= yr <= this_year for yr in years):\n        years = np.array([abs(yr) if (1900 <= abs(yr) <= this_year) else (this_year - abs(int(yr))) for yr in years])[::-1]\n\n    airport_code = airport(location, default=location)\n\n    # refresh the cache each time the start or end year changes\n    cache_path = 'daily-{}-{}-{}.csv'.format(airport_code, years[0], years[-1])\n    cache_path = os.path.join(CACHE_PATH, cache_path)\n    if use_cache:\n        try:\n            return pd.DataFrame.from_csv(cache_path)\n        except:\n            pass\n\n    df = pd.DataFrame()\n    for year in years:\n        url = ('http://www.wunderground.com/history/airport/{airport}/{yearstart}/1/1/' +\n               'CustomHistory.html?dayend=31&monthend=12&yearend={yearend}' +\n               '&req_city=&req_state=&req_statename=&reqdb.zip=&reqdb.magic=&reqdb.wmo=&MR=1&format=1').format(\n            airport=airport_code,\n            yearstart=year,\n            yearend=year\n            )\n        if verbosity > 1:\n            print('GETing *.CSV using \"{0}\"'.format(url))\n        buf = urllib.urlopen(url).read()\n        if verbosity > 0:\n            N = buf.count('\\n')\n            M = (buf.count(',') + N) / float(N)\n            print('Retrieved CSV for airport code \"{}\" with appox. {} lines and {} columns = {} cells.'.format(\n                  airport_code, N, int(round(M)), int(round(M)) * N))\n            if verbosity > 2:\n                print(buf)\n        table = util.read_csv(buf, format='header+values-list', numbers=True)\n        # # clean up the last column (if it contains <br> tags)\n        table = [util.strip_br(row) if len(row) > 1 else row for row in table]\n        # numcols = max(len(row) for row in table)\n        # table = [row for row in table if len(row) == numcols]\n        columns = table.pop(0)\n        tzs = [s for s in columns if (s[1:] in ['ST', 'DT'] and s[0] in 'PMCE')]\n        dates = [float('nan')] * len(table)\n        for i, row in enumerate(table):\n            for j, value in enumerate(row):\n                if not value and value is not None:\n                    value = 0\n                    continue\n                if columns[j] in tzs:\n                    table[i][j] = util.make_tz_aware(value, tz=columns[j])\n                    if isinstance(table[i][j], datetime.datetime):\n                        dates[i] = table[i][j]\n                        continue\n                try:\n                    table[i][j] = float(value)\n                    if not (table[i][j] % 1):\n                        table[i][j] = int(table[i][j])\n                except:\n                    pass\n        df0 = pd.DataFrame(table, columns=columns, index=dates)\n        df = df.append(df0)\n\n    if verbosity > 1:\n        print(df)\n\n    try:\n        df.to_csv(cache_path)\n    except:\n        if verbosity > 0 and use_cache:\n            from traceback import print_exc\n            print_exc()\n            warnings.warn('Unable to write weather data to cache file at {}'.format(cache_path))\n\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nensure that the gradle cache folder exists.", "response": "def ensure_cache_folder(self):\n    \"\"\"\n    Creates a gradle cache folder if it does not exist.\n    \"\"\"\n    if os.path.exists(self.cache_folder) is False:\n      os.makedirs(self.cache_folder)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_app_folder(self, folder):\n    with open('%s/%s/build.gradle' % (self.path, folder)) as f:\n      for line in f.readlines():\n        if config.gradle_plugin in line:\n          return True\n    return False", "response": "checks if a folder is a folder \n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_src_folder(self):\n    with open('%s/settings.gradle' % self.path) as f:\n      for line in f.readlines():\n        if line.startswith('include'):\n          matches = re.findall(r'\\'\\:?(.+?)\\'', line)\n        if len(matches) == 0:\n          continue\n        for folder in matches:\n          if self.is_app_folder(folder):\n            return folder\n    return 'app'", "response": "Gets the app source folder from settings. gradle file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the build tool version to be used by zipalign from build. gradle file.", "response": "def get_build_tool_version(self):\n    \"\"\"\n    Gets the build tool version to be used by zipalign from build.gradle file.\n\n    Returns:\n      A string containing the build tool version, default is 23.0.2.\n    \"\"\"\n    with open('%s/%s/build.gradle' % (self.path, self.src_folder)) as f:\n      for line in f.readlines():\n        if 'buildToolsVersion' in line:\n          matches = re.findall(r'buildToolsVersion \\\"(.+?)\\\"', line)\n          if len(matches) == 1:\n            return matches[0]\n    return config.build_tool_version"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sign(self, storepass=None, keypass=None, keystore=None, apk=None, alias=None, name='app'):\n    self.src_folder = self.get_src_folder()\n    if keystore is None:\n      (keystore, storepass, keypass, alias) = android_helper.get_default_keystore()\n    dist = '%s/%s.apk' % ('/'.join(apk.split('/')[:-1]), name)\n    android_helper.jarsign(storepass, keypass, keystore, apk, alias, path=self.path)\n    android_helper.zipalign(apk, dist, build_tool=self.get_build_tool_version(), path=self.path)", "response": "Signs a target apk file based on keystore information uses default debug keystore file by default."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate the app project before the build process.", "response": "def validate(self):\n    \"\"\"\n    Validates the app project before the build.\n\n    This is the first step in the build process.\n\n    Needs to be implemented by the subclass.\n    \"\"\"\n    if os.path.exists('%s/gradlew' % self.path) is False:\n      raise errors.InvalidProjectStructure(message='Missing gradlew project root folder')\n\n    self.touch_log('validate')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepare(self):\n    self.src_folder = self.get_src_folder()\n    st = os.stat('%s/gradlew' % self.path)\n    os.chmod('%s/gradlew' % self.path, st.st_mode | stat.S_IEXEC)", "response": "Prepares the android project to the build process."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build(self, mode='debug'):\n    self.ensure_cache_folder()\n    ref = {\n      'debug': 'assembleDebug',\n      'release': 'assembleRelease'\n    }\n    cmd = [\n      './gradlew',\n      ref.get(mode, mode),\n      '--gradle-user-home',\n      self.cache_folder \n    ]\n    self.run_cmd(cmd, 'build')", "response": "Builds the app project after the execution of validate and prepare."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a list of tables from an Excel file and convert them to SQL.", "response": "def excel_to_sql(excel_file_path, engine,\n                 read_excel_kwargs=None,\n                 to_generic_type_kwargs=None,\n                 to_sql_kwargs=None):\n    \"\"\"Create a database from excel.\n\n    :param read_excel_kwargs: dict, arguments for ``pandas.read_excel`` method.\n      example: ``{\"employee\": {\"skiprows\": 10}, \"department\": {}}``\n    :param to_sql_kwargs: dict, arguments for ``pandas.DataFrame.to_sql`` \n      method.\n\n    limitation:\n\n    1. If a integer column has None value, data type in database will be float.\n      Because pandas thinks that it is ``np.nan``.\n    2. If a string column looks like integer, ``pandas.read_excel()`` method\n      doesn't have options to convert it to string.\n    \"\"\"\n    if read_excel_kwargs is None:\n        read_excel_kwargs = dict()\n\n    if to_sql_kwargs is None:\n        to_sql_kwargs = dict()\n\n    if to_generic_type_kwargs is None:\n        to_generic_type_kwargs = dict()\n\n    xl = pd.ExcelFile(excel_file_path)\n    for sheet_name in xl.sheet_names:\n        df = pd.read_excel(\n            excel_file_path, sheet_name,\n            **read_excel_kwargs.get(sheet_name, dict())\n        )\n\n        kwargs = to_generic_type_kwargs.get(sheet_name)\n        if kwargs:\n            data = to_dict_list_generic_type(df, **kwargs)\n            smart_insert(data, sheet_name, engine)\n        else:\n            df.to_sql(\n                sheet_name, engine, index=False,\n                **to_sql_kwargs.get(sheet_name, dict(if_exists=\"replace\"))\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef database_to_excel(engine, excel_file_path):\n    from sqlalchemy import MetaData, select\n\n    metadata = MetaData()\n    metadata.reflect(engine)\n\n    writer = pd.ExcelWriter(excel_file_path)\n    for table in metadata.tables.values():\n        sql = select([table])\n        df = pd.read_sql(sql, engine)\n        df.to_excel(writer, table.name, index=False)\n\n    writer.save()", "response": "Export database to excel."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef requirements(requirements_file):\n    return [\n        str(pkg.req) for pkg in parse_requirements(\n            requirements_file, session=pip_download.PipSession()) if pkg.req is not None]", "response": "Returns a list of 3rd - party packages mentioned in the given requirements file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef createNewOoid(timestamp=None, depth=None):\n  if not timestamp:\n    timestamp = utc_now().date()\n  if not depth:\n    depth = defaultDepth\n  assert depth <= 4 and depth >=1\n  uuid = str(uu.uuid4())\n  return \"%s%d%02d%02d%02d\" %(uuid[:-7],depth,timestamp.year%100,timestamp.month,timestamp.day)", "response": "Create a new opaque id string for a given time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef uuidToOoid(uuid,timestamp=None, depth= None):\n  if not timestamp:\n    timestamp = utc_now().date()\n  if not depth:\n    depth = defaultDepth\n  assert depth <= 4 and depth >=1\n  return \"%s%d%02d%02d%02d\" %(uuid[:-7],depth,timestamp.year%100,timestamp.month,timestamp.day)", "response": "Create an opaque id string from a 32 - hex - digit uuid and timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dateAndDepthFromOoid(ooid):\n  year = month = day = None\n  try:\n    day = int(ooid[-2:])\n  except:\n    return None,None\n  try:\n    month = int(ooid[-4:-2])\n  except:\n    return None,None\n  try:\n    year = 2000 + int(ooid[-6:-4])\n    depth = int(ooid[-7])\n    if not depth: depth = oldHardDepth\n    return (dt.datetime(year,month,day,tzinfo=UTC),depth)\n  except:\n    return None,None\n  return None,None", "response": "Extract the encoded date and expected storage depth from an ooid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of all the currently loaded repo HEAD objects.", "response": "def HeadList(self):\n        \"\"\"Return a list of all the currently loaded repo HEAD objects.\"\"\"\n        return [(rname, repo.currenthead) for rname, repo in self.repos.items()\n                ]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the origin remote to the upstream url that we trust.", "response": "def setorigin(self):\n        \"\"\"Set the 'origin' remote to the upstream url that we trust.\"\"\"\n        try:\n            origin = self.repo.remotes.origin\n            if origin.url != self.origin_url:\n                log.debug('[%s] Changing origin url. Old: %s New: %s',\n                          self.name, origin.url, self.origin_url)\n                origin.config_writer.set('url', self.origin_url)\n        except AttributeError:\n            origin = self.repo.create_remote('origin', self.origin_url)\n            log.debug('[%s] Created remote \"origin\" with URL: %s',\n                      self.name, origin.url)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetchall(self):\n        try:\n            self.repo.remotes.origin.fetch()\n        except git.exc.GitCommandError as err:\n            raise GitError(err)", "response": "Fetch all refs from the upstream repo."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetchref(self, ref):\n        log.debug('[%s] Fetching ref: %s', self.name, ref)\n        fetch_info = self.repo.remotes.origin.fetch(ref).pop()\n        return fetch_info.ref", "response": "Fetch a particular git ref."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sethead(self, ref):\n        log.debug('[%s] Setting to ref %s', self.name, ref)\n        try:\n            ref = self.repo.rev_parse(ref)\n        except gitdb.exc.BadObject:\n            # Probably means we don't have it cached yet.\n            # So maybe we can fetch it.\n            ref = self.fetchref(ref)\n        log.debug('[%s] Setting head to %s', self.name, ref)\n        self.repo.head.reset(ref, working_tree=True)\n        log.debug('[%s] Head object: %s', self.name, self.currenthead)", "response": "Set the head object to a git ref."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_file(self, filename):\n        log.debug('[%s]: reading: //%s/%s', self.name, self.name, filename)\n        try:\n            blob = self.repo.head.commit.tree/filename\n            return blob.data_stream\n        except KeyError as err:\n            raise GitError(err)", "response": "Get a file from the repo."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshows the current log message in a progress scope.", "response": "def show_progress(self, message=None):\n        \"\"\"If we are in a progress scope, and no log messages have been\n        shown, write out another '.'\"\"\"\n        if self.in_progress_hanging:\n            if message is None:\n                sys.stdout.write('.')\n                sys.stdout.flush()\n            else:\n                if self.last_message:\n                    padding = ' ' * max(0, len(self.last_message)-len(message))\n                else:\n                    padding = ''\n                sys.stdout.write('\\r%s%s%s%s' % (' '*self.indent, self.in_progress, message, padding))\n                sys.stdout.flush()\n                self.last_message = message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(app_id: int = None,\n           login: str = None,\n           password: str = None,\n           service_token: str = None,\n           proxies: dict = None) -> API:\n    \"\"\"\n    Creates an API instance, requires app ID,\n    login and password or service token to create connection\n\n    :param app_id: int: specifies app ID\n    :param login: str: specifies login, can be phone number or email\n    :param password: str: specifies password\n    :param service_token: str: specifies password service token\n    :param proxies: dict: specifies proxies, require http and https proxy\n    \"\"\"\n    session_ = APISession(app_id,\n                          login,\n                          password,\n                          service_token,\n                          proxies)\n    return API(session_)", "response": "Creates an API instance for a node in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a user s homedir.", "response": "def user_homedir(username=None):\n    \"\"\"Returns a user's home directory.\n\n    If no username is specified, returns the current user's homedir.\n    \"\"\"\n    if username:\n        return os.path.expanduser('~%s/' % username)\n    elif 'HOME' in os.environ:\n        return os.environ['HOME']\n    elif os.name == 'posix':\n        return os.path.expanduser('~/')\n    else:\n        raise RuntimeError('This function has failed at life.')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading from fileobj stream return hash of its contents.", "response": "def hash_stream(fileobj, hasher=None, blocksize=65536):\n    \"\"\"Read from fileobj stream, return hash of its contents.\n\n    Args:\n      fileobj: File-like object with read()\n      hasher: Hash object such as hashlib.sha1(). Defaults to sha1.\n      blocksize: Read from fileobj this many bytes at a time.\n    \"\"\"\n    hasher = hasher or hashlib.sha1()\n    buf = fileobj.read(blocksize)\n    while buf:\n        hasher.update(buf)\n        buf = fileobj.read(blocksize)\n    return hasher"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef glob(*args):\n    if len(args) is 1 and isinstance(args[0], list):\n        args = args[0]\n    matches = []\n    for pattern in args:\n        for item in glob2.glob(pattern):\n            if not os.path.isdir(item):\n                matches.append(item)\n    return matches", "response": "Returns a list of paths matching one or more wildcard patterns."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nflattening an arbitrarily - nested list of strings and lists.", "response": "def flatten(listish):\n    \"\"\"Flatten an arbitrarily-nested list of strings and lists.\n\n    Works for any subclass of basestring and any type of iterable.\n    \"\"\"\n    for elem in listish:\n        if (isinstance(elem, collections.Iterable)\n                and not isinstance(elem, basestring)):\n            for subelem in flatten(elem):\n                yield subelem\n        else:\n            yield elem"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getcwd(cls):\n        if not hasattr(cls._tl, \"cwd\"):\n            cls._tl.cwd = os.getcwd()\n        return cls._tl.cwd", "response": "Return the current working directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the filename appropriate for an instance of this dataset.", "response": "def fname(self, version=None, tags=None, ext=None):\n        \"\"\"Returns the filename appropriate for an instance of this dataset.\n\n        Parameters\n        ----------\n        version: str, optional\n            The version of the instance of this dataset.\n        tags : list of str, optional\n            The tags associated with the instance of this dataset.\n        ext : str, optional\n            The file extension to use. If not given, the default extension is\n            used.\n\n        Returns\n        -------\n        str\n            The appropariate filename.\n        \"\"\"\n        if ext is None:\n            ext = self.default_ext\n        return '{}{}{}.{}'.format(\n            self.fname_base,\n            self._tags_to_str(tags=tags),\n            self._version_to_str(version=version),\n            ext,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fpath(self, version=None, tags=None, ext=None):\n        if self.singleton:\n            return dataset_filepath(\n                filename=self.fname(version=version, tags=tags, ext=ext),\n                task=self.task,\n                **self.kwargs,\n            )\n        return dataset_filepath(\n            filename=self.fname(version=version, tags=tags, ext=ext),\n            dataset_name=self.name,\n            task=self.task,\n            **self.kwargs,\n        )", "response": "Returns the filepath appropriate for an instance of this dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncopies a given file into local store as an instance of this dataset.", "response": "def add_local(self, source_fpath, version=None, tags=None):\n        \"\"\"Copies a given file into local store as an instance of this dataset.\n\n        Parameters\n        ----------\n        source_fpath : str\n            The full path for the source file to use.\n        version: str, optional\n            The version of the instance of this dataset.\n        tags : list of str, optional\n            The tags associated with the given instance of this dataset.\n\n        Returns\n        -------\n        ext : str\n            The extension of the file added.\n        \"\"\"\n        ext = os.path.splitext(source_fpath)[1]\n        ext = ext[1:]  # we dont need the dot\n        fpath = self.fpath(version=version, tags=tags, ext=ext)\n        shutil.copyfile(src=source_fpath, dst=fpath)\n        return ext"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupload the given instance of this dataset to dataset store.", "response": "def upload(self, version=None, tags=None, ext=None, source_fpath=None,\n               overwrite=False, **kwargs):\n        \"\"\"Uploads the given instance of this dataset to dataset store.\n\n        Parameters\n        ----------\n        version: str, optional\n            The version of the instance of this dataset.\n        tags : list of str, optional\n            The tags associated with the given instance of this dataset.\n        ext : str, optional\n            The file extension to use. If not given, the default extension is\n            used. If source_fpath is given, this is ignored, and the extension\n            of the source f\n        source_fpath : str, optional\n            The full path for the source file to use. If given, the file is\n            copied from the given path to the local storage path before\n            uploading.\n        **kwargs : extra keyword arguments\n            Extra keyword arguments are forwarded to\n            azure.storage.blob.BlockBlobService.create_blob_from_path.\n        \"\"\"\n        if source_fpath:\n            ext = self.add_local(\n                source_fpath=source_fpath, version=version, tags=tags)\n        if ext is None:\n            ext = self._find_extension(version=version, tags=tags)\n        if ext is None:\n            attribs = \"{}{}\".format(\n                \"version={} and \".format(version) if version else \"\",\n                \"tags={}\".format(tags) if tags else \"\",\n            )\n            raise MissingDatasetError(\n                \"No dataset with {} in local store!\".format(attribs))\n        fpath = self.fpath(version=version, tags=tags, ext=ext)\n        if not os.path.isfile(fpath):\n            attribs = \"{}{}ext={}\".format(\n                \"version={} and \".format(version) if version else \"\",\n                \"tags={} and \".format(tags) if tags else \"\",\n                ext,\n            )\n            raise MissingDatasetError(\n                \"No dataset with {} in local store! (path={})\".format(\n                    attribs, fpath))\n        upload_dataset(\n            dataset_name=self.name,\n            file_path=fpath,\n            task=self.task,\n            dataset_attributes=self.kwargs,\n            **kwargs,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads the given instance of this dataset from dataset store.", "response": "def download(self, version=None, tags=None, ext=None, overwrite=False,\n                 verbose=False, **kwargs):\n        \"\"\"Downloads the given instance of this dataset from dataset store.\n\n        Parameters\n        ----------\n        version: str, optional\n            The version of the instance of this dataset.\n        tags : list of str, optional\n            The tags associated with the given instance of this dataset.\n        ext : str, optional\n            The file extension to use. If not given, the default extension is\n            used.\n        overwrite : bool, default False\n            If set to True, the given instance of the dataset is downloaded\n            from dataset store even if it exists in the local data directory.\n            Otherwise, if a matching dataset is found localy, download is\n            skipped.\n        verbose : bool, default False\n            If set to True, informative messages are printed.\n        **kwargs : extra keyword arguments\n            Extra keyword arguments are forwarded to\n            azure.storage.blob.BlockBlobService.get_blob_to_path.\n        \"\"\"\n        fpath = self.fpath(version=version, tags=tags, ext=ext)\n        if os.path.isfile(fpath) and not overwrite:\n            if verbose:\n                print(\n                    \"File exists and overwrite set to False, so not \"\n                    \"downloading {} with version={} and tags={}\".format(\n                        self.name, version, tags))\n                return\n        download_dataset(\n            dataset_name=self.name,\n            file_path=fpath,\n            task=self.task,\n            dataset_attributes=self.kwargs,\n            **kwargs,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef df(self, version=None, tags=None, ext=None, **kwargs):\n        ext = self._find_extension(version=version, tags=tags)\n        if ext is None:\n            attribs = \"{}{}\".format(\n                \"version={} and \".format(version) if version else \"\",\n                \"tags={}\".format(tags) if tags else \"\",\n            )\n            raise MissingDatasetError(\n                \"No dataset with {} in local store!\".format(attribs))\n        fpath = self.fpath(version=version, tags=tags, ext=ext)\n        fmt = SerializationFormat.by_name(ext)\n        return fmt.deserialize(fpath, **kwargs)", "response": "Loads an instance of this dataset into a dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndump an instance of this dataset into a file.", "response": "def dump_df(self, df, version=None, tags=None, ext=None, **kwargs):\n        \"\"\"Dumps an instance of this dataset into a file.\n\n        Parameters\n        ----------\n        df : pandas.DataFrame\n            The dataframe to dump to file.\n        version: str, optional\n            The version of the instance of this dataset.\n        tags : list of str, optional\n            The tags associated with the given instance of this dataset.\n        ext : str, optional\n            The file extension to use. If not given, the default extension is\n            used.\n        **kwargs : extra keyword arguments, optional\n            Extra keyword arguments are forwarded to the serialization method\n            of the SerializationFormat object corresponding to the extension\n            used.\n        \"\"\"\n        if ext is None:\n            ext = self.default_ext\n        fpath = self.fpath(version=version, tags=tags, ext=ext)\n        fmt = SerializationFormat.by_name(ext)\n        fmt.serialize(df, fpath, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndumps an instance of this dataset into a file and uploads it to dataset store.", "response": "def upload_df(self, df, version=None, tags=None, ext=None, **kwargs):\n        \"\"\"Dumps an instance of this dataset into a file and then uploads it\n        to dataset store.\n\n        Parameters\n        ----------\n        df : pandas.DataFrame\n            The dataframe to dump and upload.\n        version: str, optional\n            The version of the instance of this dataset.\n        tags : list of str, optional\n            The tags associated with the given instance of this dataset.\n        ext : str, optional\n            The file extension to use. If not given, the default extension is\n            used.\n        **kwargs : extra keyword arguments, optional\n            Extra keyword arguments are forwarded to the serialization method\n            of the SerializationFormat object corresponding to the extension\n            used.\n        \"\"\"\n        self.dump_df(df=df, version=version, tags=tags, ext=ext, **kwargs)\n        self.upload(version=version, tags=tags, ext=ext)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_inline(cls: Type[IdentityType], version: int, currency: str, inline: str) -> IdentityType:\n        selfcert_data = Identity.re_inline.match(inline)\n        if selfcert_data is None:\n            raise MalformedDocumentError(\"Inline self certification\")\n        pubkey = selfcert_data.group(1)\n        signature = selfcert_data.group(2)\n        ts = BlockUID.from_str(selfcert_data.group(3))\n        uid = selfcert_data.group(4)\n\n        return cls(version, currency, pubkey, uid, ts, signature)", "response": "Return Identity instance from inline string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an Identity instance from a signed raw string", "response": "def from_signed_raw(cls: Type[IdentityType], signed_raw: str) -> IdentityType:\n        \"\"\"\n        Return Identity instance from a signed_raw string\n        :param signed_raw: Signed raw document\n        :return:\n        \"\"\"\n        n = 0\n        lines = signed_raw.splitlines(True)\n\n        version = int(Identity.parse_field(\"Version\", lines[n]))\n        n += 1\n\n        Identity.parse_field(\"Type\", lines[n])\n        n += 1\n\n        currency = Identity.parse_field(\"Currency\", lines[n])\n        n += 1\n\n        pubkey = Identity.parse_field(\"Issuer\", lines[n])\n        n += 1\n\n        uid = Identity.parse_field(\"UniqueID\", lines[n])\n        n += 1\n\n        ts = BlockUID.from_str(Identity.parse_field(\"Timestamp\", lines[n]))\n        n += 1\n\n        signature = Identity.parse_field(\"Signature\", lines[n])\n\n        return cls(version, currency, pubkey, uid, ts, signature)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef raw(self) -> str:\n        return \"\"\"Version: {version}\nType: Identity\nCurrency: {currency}\nIssuer: {pubkey}\nUniqueID: {uid}\nTimestamp: {timestamp}\n\"\"\".format(version=self.version,\n           currency=self.currency,\n           pubkey=self.pubkey,\n           uid=self.uid,\n           timestamp=self.timestamp)", "response": "Return a raw document of the Identity\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef inline(self) -> str:\n        return \"{pubkey}:{signature}:{timestamp}:{uid}\".format(\n            pubkey=self.pubkey,\n            signature=self.signatures[0],\n            timestamp=self.timestamp,\n            uid=self.uid)", "response": "Return an inline string of the Identity\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating that the source file extension is supported.", "response": "def _validate_extension(self):\n        \"\"\"Validates that source file extension is supported.\n\n        :raises: UnsupportedExtensionError\n\n        \"\"\"\n        extension = self.fpath.split('.')[-1]\n        if extension not in self.supported_extensions:\n            raise UnsupportedExtensionError"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_content(self) -> dict:\n        source_content = self.load_content()\n\n        converted = {}\n\n        tagged, content = self._get_tags_and_content(source_content)\n        if tagged:\n            converted.update(self._parse_tags(tagged))\n\n        if content:\n            converted['content'] = content.strip()\n        return converted", "response": "Convert content of source file into dict result."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_tags_and_content(self, content: str) -> typing.Tuple[str, str]:\n        content_lines = content.split('\\n')\n        tag_lines = []\n\n        if content_lines[0] != '---':\n            return '', content\n\n        content_lines.pop(0)\n        for line in content_lines:  # type: str\n            if line in ('---', '...'):\n                content_starts_at = content_lines.index(line) + 1\n                content_lines = content_lines[content_starts_at:]\n                break\n\n            tag_lines.append(line)\n\n        return '\\n'.join(tag_lines), '\\n'.join(content_lines)", "response": "Splits content into two string - tags part and another content."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(text):\n    found = re.findall(r'(?<=BEGIN_DEPENDENCIES_SCHEMA_OUTPUT>).*(?=<END_DEPENDENCIES_SCHEMA_OUTPUT)', text)\n\n    dependency_results = []\n\n    for match in found:\n        data = json.loads(match)\n\n        validate(data)  # will throw ValidationError if invalid\n\n        dependency_results += data['dependencies']\n\n    # we don't have any other fields yet, but in the future\n    # may have schema 'version' in which case we'd want to check\n    # the versions and compile all the results into 1 schema?\n\n    combined_results = {'dependencies': dependency_results}\n\n    return combined_results", "response": "Parses the dependency schema from a given string containing JSON data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute a Command Execute a command # noqa: E501 :param execute: The data needed to execute this command :type execute: dict | bytes :rtype: Response", "response": "def command(execute=None):  # noqa: E501\n    \"\"\"Execute a Command\n\n    Execute a command # noqa: E501\n\n    :param execute: The data needed to execute this command\n    :type execute: dict | bytes\n\n    :rtype: Response\n    \"\"\"\n    if connexion.request.is_json:\n        execute = Execute.from_dict(connexion.request.get_json())  # noqa: E501\n\n    if(not hasAccess()):\n        return redirectUnauthorized()\n\n    try:\n        connector = None\n\n        parameters = {}\n\n        if (execute.command.parameters):\n            parameters = execute.command.parameters\n\n        credentials = Credentials()\n        options = Options(debug=execute.command.options['debug'], sensitive=execute.command.options['sensitive'])\n\n        if (execute.auth):\n            credentials = mapUserAuthToCredentials(execute.auth, credentials)\n\n        if (not execute.auth.api_token):\n            options.sensitive = True\n\n        connector = Connector(options=options, credentials=credentials, command=execute.command.command,\n                              parameters=parameters)\n\n        commandHandler = connector.execute()\n\n        response = Response(status=commandHandler.getRequest().getResponseStatusCode(),\n                            body=json.loads(commandHandler.getRequest().getResponseBody()))\n\n        if (execute.command.options['debug']):\n            response.log = connector.logBuffer\n\n        return response\n    except:\n        State.log.error(traceback.format_exc())\n        if ('debug' in execute.command.options and execute.command.options['debug']):\n            return ErrorResponse(status=500,\n                                 message=\"Uncaught exception occured during processing. To get a larger stack trace, visit the logs.\",\n                                 state=traceback.format_exc(3))\n        else:\n            return ErrorResponse(status=500, message=\"\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the contents of a script.", "response": "def get_script(name=None):  # noqa: E501\n    \"\"\"Retrieve the contents of a script\n\n    Retrieve the contents of a script # noqa: E501\n\n    :param name: The script name.\n    :type name: str\n\n    :rtype: Response\n    \"\"\"\n\n    if(not hasAccess()):\n        return redirectUnauthorized()\n\n    driver = LoadedDrivers.getDefaultBaseDriver()\n    return Response(status=200, body=driver.readScript(name))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noutputting the list of HTML templates and subdirectories in the COMPS_DIR", "response": "def comp_listing(request, directory_slug=None):\n    \"\"\"\n    Output the list of HTML templates and subdirectories in the COMPS_DIR\n    \"\"\"\n    context = {}\n    working_dir = settings.COMPS_DIR\n    if directory_slug:\n        working_dir = os.path.join(working_dir, directory_slug)\n    dirnames = []\n    templates = []\n    items = os.listdir(working_dir)\n    templates = [x for x in items if os.path.splitext(x)[1] == '.html']\n    dirnames = [x for x in items if \\\n                    not os.path.isfile(os.path.join(working_dir, x))]\n    templates.sort()\n    dirnames.sort()\n    context['directories'] = dirnames\n    context['templates'] = templates\n    context['subdirectory'] = directory_slug\n    return render(request, \"comps/comp_listing.html\", context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef comp(request, slug, directory_slug=None):\n    context = {}\n    path = settings.COMPS_DIR\n    comp_dir = os.path.split(path)[1]\n    template = \"{0}/{1}\".format(comp_dir, slug)\n    if directory_slug:\n        template = \"{0}/{1}/{2}\".format(comp_dir, directory_slug, slug)\n    working_dir = os.path.join(path, slug)\n    if os.path.isdir(working_dir):\n        return redirect('comp-listing', directory_slug=slug)\n\n    try:\n        t = get_template(template)\n    except TemplateDoesNotExist:\n        return redirect('comp-listing')\n\n    c = RequestContext(request, context)\n    return HttpResponse(t.render(c))", "response": "View the requested comp\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef export_comps(request):\n    in_memory = BytesIO()\n    zip = ZipFile(in_memory, \"a\")\n\n    comps = settings.COMPS_DIR\n    static = settings.STATIC_ROOT or \"\"\n    context = RequestContext(request, {})\n    context['debug'] = False\n\n    # dump static resources\n    # TODO: inspect each template and only pull in resources that are used\n    for dirname, dirs, filenames in os.walk(static):\n        for filename in filenames:\n            full_path = os.path.join(dirname, filename)\n            rel_path = os.path.relpath(full_path, static)\n            content = open(full_path, 'rb').read()\n            try:\n                ext = os.path.splitext(filename)[1]\n            except IndexError:\n                pass\n            if ext == '.css':\n                # convert static refs to relative links\n                dotted_rel = os.path.relpath(static, full_path)\n                new_rel_path = '{0}{1}'.format(dotted_rel, '/static')\n                content = content.replace(b'/static', bytes(new_rel_path, 'utf8'))\n            path = os.path.join('static', rel_path)\n            zip.writestr(path, content)\n\n    for dirname, dirs, filenames in os.walk(comps):\n        for filename in filenames:\n            full_path = os.path.join(dirname, filename)\n            rel_path = os.path.relpath(full_path, comps)\n            template_path = os.path.join(comps.split('/')[-1], rel_path)\n            html = render_to_string(template_path, context)\n            # convert static refs to relative links\n            depth = len(rel_path.split(os.sep)) - 1\n            if depth == 0:\n                dotted_rel = '.'\n            else:\n                dotted_rel = ''\n                i = 0\n                while i < depth:\n                    dotted_rel += '../'\n                    i += 1\n            new_rel_path = '{0}{1}'.format(dotted_rel, '/static')\n            html = html.replace('/static', new_rel_path)\n            if PY2:\n                html = unicode(html)\n            zip.writestr(rel_path, html.encode('utf8'))\n\n    for item in zip.filelist:\n        item.create_system = 0\n    zip.close()\n\n    response = HttpResponse(content_type=\"application/zip\")\n    response[\"Content-Disposition\"] = \"attachment; filename=comps.zip\"\n    in_memory.seek(0)\n    response.write(in_memory.read())\n\n    return response", "response": "Exports the contents of the COMPS_DIR\n    to a zipfile."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_signed_raw(cls: Type[PeerType], raw: str) -> PeerType:\n        lines = raw.splitlines(True)\n        n = 0\n\n        version = int(Peer.parse_field(\"Version\", lines[n]))\n        n += 1\n\n        Peer.parse_field(\"Type\", lines[n])\n        n += 1\n\n        currency = Peer.parse_field(\"Currency\", lines[n])\n        n += 1\n\n        pubkey = Peer.parse_field(\"Pubkey\", lines[n])\n        n += 1\n\n        block_uid = BlockUID.from_str(Peer.parse_field(\"Block\", lines[n]))\n        n += 1\n\n        Peer.parse_field(\"Endpoints\", lines[n])\n        n += 1\n\n        endpoints = []\n        while not Peer.re_signature.match(lines[n]):\n            endpoints.append(endpoint(lines[n]))\n            n += 1\n\n        data = Peer.re_signature.match(lines[n])\n        if data is None:\n            raise MalformedDocumentError(\"Peer\")\n        signature = data.group(1)\n\n        return cls(version, currency, pubkey, block_uid, endpoints, signature)", "response": "Return a new instance of this class from a signed raw format string"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef raw(self) -> str:\n        doc = \"\"\"Version: {0}\nType: Peer\nCurrency: {1}\nPublicKey: {2}\nBlock: {3}\nEndpoints:\n\"\"\".format(self.version, self.currency, self.pubkey, self.blockUID)\n\n        for _endpoint in self.endpoints:\n            doc += \"{0}\\n\".format(_endpoint.inline())\n\n        return doc", "response": "Return a raw format string of the Peer document"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_image_from_url(url=None, timeout=30):\n\n    file_name = posixpath.basename(url)\n    img_tmp = NamedTemporaryFile(delete=True)\n\n    try:\n        response = requests.get(url, timeout=timeout)\n        response.raise_for_status()\n    except Exception as e:  # NOQA\n        return None, None\n\n    img_tmp.write(response.content)\n    img_tmp.flush()\n\n    image = File(img_tmp)\n    image.seek(0)\n\n    return file_name, image", "response": "Downloads and saves a image from url into a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_rhyme(d, w1, w2):\n    for p1 in d[w1]:\n        # extract only \"rhyming portion\"\n        p1 = p1.split(\"'\")[-1]\n        m = VOWELS_RE.search(p1)\n        if not m:\n            print(p1)\n        p1 = p1[m.start():]\n        for p2 in d[w2]:\n            p2 = p2.split(\"'\")[-1]\n            m = VOWELS_RE.search(p2)\n            if not m:\n                print(w2, p2)\n            p2 = p2[m.start():]\n            if p1 == p2:\n                return True\n    return False", "response": "check if words rhyme"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init_perfect_ttable(words):\n    d = read_celex()\n\n    not_in_dict = 0\n\n    n = len(words)\n    t_table = numpy.zeros((n, n + 1))\n\n    # initialize P(c|r) accordingly\n    for r, w in enumerate(words):\n        if w not in d:\n            not_in_dict += 1\n        for c, v in enumerate(words):\n            if c < r:\n                t_table[r, c] = t_table[c, r]\n            elif w in d and v in d:\n                t_table[r, c] = int(is_rhyme(d, w, v)) + 0.001  # for backoff\n            else:\n                t_table[r, c] = random.random()\n        t_table[r, n] = random.random()  # no estimate for P(r|no history)\n\n    print(not_in_dict, \"of\", n, \" words are not in CELEX\")\n\n    # normalize\n    for c in range(n + 1):\n        tot = sum(t_table[:, c])\n        for r in range(n):\n            t_table[r, c] = t_table[r, c] / tot\n\n    return t_table", "response": "initialize the t table according to whether words rhyme"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning all nested dictionaries that contain a key with a specific value. A sub-case of NestedLookup.", "response": "def get_nested_dicts_with_key_value(parent_dict: dict, key, value):\n    \"\"\"Return all nested dictionaries that contain a key with a specific value. A sub-case of NestedLookup.\"\"\"\n    references = []\n    NestedLookup(parent_dict, references, NestedLookup.key_value_equality_factory(key, value))\n    return (document for document, _ in references)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all nested dictionaries that contain a key with a specific value. A sub-case of NestedLookup.", "response": "def get_nested_dicts_with_key_containing_value(parent_dict: dict, key, value):\n    \"\"\"Return all nested dictionaries that contain a key with a specific value. A sub-case of NestedLookup.\"\"\"\n    references = []\n    NestedLookup(parent_dict, references, NestedLookup.key_value_containing_value_factory(key, value))\n    return (document for document, _ in references)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _nested_lookup(document, references, operation):\n        if isinstance(document, list):\n            for d in document:\n                for result in NestedLookup._nested_lookup(d, references, operation):\n                    yield result\n\n        if isinstance(document, dict):\n            for k, v in document.items():\n                if operation(k, v):\n                    references.append((document, k))\n                    yield v\n                elif isinstance(v, dict):\n                    for result in NestedLookup._nested_lookup(v, references, operation):\n                        yield result\n                elif isinstance(v, list):\n                    for d in v:\n                        for result in NestedLookup._nested_lookup(d, references, operation):\n                            yield result", "response": "Lookup a key in a nested document yield a value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_chunk(oscillators):\n    step_random_processes(oscillators)\n    subchunks = []\n    for osc in oscillators:\n        osc.amplitude.step_amp()\n        osc_chunk = osc.get_samples(config.CHUNK_SIZE)\n        if osc_chunk is not None:\n            subchunks.append(osc_chunk)\n    if len(subchunks):\n        new_chunk = sum(subchunks)\n    else:\n        new_chunk = numpy.zeros(config.CHUNK_SIZE)\n    # If we exceed the maximum amplitude, handle it gracefully\n    chunk_amplitude = amplitude.find_amplitude(new_chunk)\n    if chunk_amplitude > config.MAX_AMPLITUDE:\n        # Normalize the amplitude chunk to mitigate immediate clipping\n        new_chunk = amplitude.normalize_amplitude(new_chunk,\n                                                  config.MAX_AMPLITUDE)\n        # Pick some of the offending oscillators (and some random others)\n        # and lower their drift targets\n        avg_amp = (sum(osc.amplitude.value for osc in oscillators) /\n                   len(oscillators))\n        for osc in oscillators:\n            if (osc.amplitude.value > avg_amp and rand.prob_bool(0.1) or\n                    rand.prob_bool(0.01)):\n                osc.amplitude.drift_target = rand.weighted_rand(\n                    [(-5, 1), (0, 10)])\n                osc.amplitude.change_rate = rand.weighted_rand(\n                    osc.amplitude.change_rate_weights)\n    return new_chunk.astype(config.SAMPLE_DATA_TYPE).tostring()", "response": "Builds an audio chunk and progress the oscillator states."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun the command - line client for the specified database.", "response": "def shell(database='default'):\n    \"\"\"Runs the command-line client for the specified database.\n    \"\"\"\n\n    target = engine[database]\n    dialect = engine[database].dialect.name\n\n    if dialect == 'mysql':\n        args = ['mysql']\n\n        if target.url.username:\n            args += ['--user=%s' % target.url.username]\n\n        if target.url.password:\n            args += ['--password=%s' % target.url.password]\n\n        if 'unix_socket' in target.url.query:\n            args += [\"--socket=%s\" % target.url.query['unix_socket']]\n\n        elif target.url.host:\n            args += [\"--host=%s\" % target.url.host]\n\n            if target.url.port:\n                args += [\"--port=%s\" % target.url.port]\n\n        if target.url.database:\n            args += [target.url.database]\n\n    elif dialect == 'sqlite':\n        args = ['sqlite3', target.url.database]\n\n    else:  # pragma: nocoverage\n        raise RuntimeError(\n            'Database shell not available for the dialect %r' % dialect)\n\n    os.execvp(args[0], args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse some code and pretty - print it.", "response": "def parseprint(code, filename=\"<string>\", mode=\"exec\", **kwargs):\n    \"\"\"Parse some code from a string and pretty-print it.\"\"\"\n    node = parse(code, mode=mode)   # An ode to the code\n    print(dump(node, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of all time zones known to the system.", "response": "def list():\n        \"\"\"Return a list of all time zones known to the system.\"\"\"\n        handle = winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE)\n        tzkey = winreg.OpenKey(handle, TZKEYNAME)\n        result = [winreg.EnumKey(tzkey, i)\n                  for i in range(winreg.QueryInfoKey(tzkey)[0])]\n        tzkey.Close()\n        handle.Close()\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbegin a text style.", "response": "def colorstart(fgcolor, bgcolor, weight):\n    ''' Begin a text style. '''\n    if weight:\n        weight = bold\n    else:\n        weight = norm\n    if bgcolor:\n        out('\\x1b[%s;%s;%sm' % (weight, fgcolor, bgcolor))\n    else:\n        out('\\x1b[%s;%sm' % (weight, fgcolor))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cprint(text, fg=grey, bg=blackbg, w=norm, cr=False, encoding='utf8'):\n    ''' Print a string in a specified color style and then return to normal.\n        def cprint(text, fg=white, bg=blackbg, w=norm, cr=True):\n    '''\n    colorstart(fg, bg, w)\n    out(text)\n    colorend(cr)", "response": "Print a string in a specified color style and then return to normal."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bargraph(data, maxwidth, incolor=True, cbrackets=('\\u2595', '\\u258F')):\n    ''' Creates a monochrome or two-color bar graph. '''\n    threshold = 100.0 // (maxwidth * 2)  # if smaller than 1/2 of one char wide\n    position = 0\n    begpcnt = data[0][1] * 100\n    endpcnt = data[-1][1] * 100\n\n    if len(data) < 1: return        # Nada to do\n    maxwidth = maxwidth - 2         # because of brackets\n    datalen = len(data)\n\n    # Print left bracket in correct color:\n    if cbrackets and incolor:       # and not (begpcnt == 0 and endpcnt == 0):\n        if begpcnt < threshold: bkcolor = data[-1][2]  # greenbg\n        else:                   bkcolor = data[0][2]   # redbg\n        cprint(cbrackets[0], data[0][2], bkcolor, None, None)\n    else:\n        out(cbrackets[0])\n\n    for i, part in enumerate(data):\n        # unpack data\n        char, pcnt, fgcolor, bgcolor, bold = part\n        width = int(round(pcnt/100.0 * maxwidth, 0))\n        position = position + width\n\n        # and graph\n        if incolor and not (fgcolor is None):\n            cprint(char * width, fgcolor, bgcolor, bold, False)\n        else:\n            out((char * width))\n\n        if i == (datalen - 1):   # correct last one\n            if position < maxwidth:\n                if incolor:     # char\n                    cprint(char * (maxwidth-position), fgcolor, bgcolor,\n                           bold, False)\n                else:\n                    out(char * (maxwidth-position))\n            elif position > maxwidth:\n                out(chr(8) + ' ' + chr(8))  # backspace\n\n    # Print right bracket in correct color:\n    if cbrackets and incolor:\n        if endpcnt < threshold: bkcolor = data[0][3]    # redbg\n        else:                   bkcolor = data[1][3]    # greenbg\n        cprint(cbrackets[1], data[-1][2], bkcolor, None, None)\n    else:\n        out(cbrackets[1])", "response": "Creates a monochrome or two - color bar graph."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a rainbar style bar graph.", "response": "def rainbar(data, maxwidth, incolor=True, hicolor=True,\n            cbrackets=('\\u2595', '\\u258F')):\n    ''' Creates a \"rainbar\" style bar graph. '''\n    if not data: return             # Nada to do\n    datalen = len(data)\n    endpcnt = data[-1][1]\n    maxwidth = maxwidth - 2         # because of brackets\n\n    # setup\n    csi, csib, _, pal, rst, plen = get_palette(hicolor)\n\n    empty = data[-1][0]\n    bucket = float(maxwidth) / plen\n    position = 0\n\n    # Print left bracket in correct color:\n    if incolor:\n        out((csi % pal[0]) + cbrackets[0])  # start bracket\n    else:\n        out(cbrackets[0])\n\n    for i, part in enumerate(data):\n        char, pcnt, fgcolor, bgcolor, bold = part\n        if fgcolor and hicolor:\n            fgcolor = map8[fgcolor]\n        if not bold:\n            csib = csi\n\n        lastind = None\n        width = int(maxwidth * (pcnt / 100.0))\n        offset = position\n        position += width\n\n        if incolor:\n            for j in range(width):\n                # faster?\n                colorind = fgcolor or min(int((j+offset)/bucket), (plen-1))\n                #~ colorind=fgcolor or get_color_index(j, offset,maxwidth,plen)\n                if colorind == lastind:\n                    out(char)\n                else:\n                    color = fgcolor or pal[colorind]\n                    out((csib % color) + char)\n                lastind = colorind\n        else:\n            out((char * width))\n\n        if i == (datalen - 1):          # check if last one correct\n            if position < maxwidth:\n                rest = maxwidth - position\n                if incolor:\n                    out((csib % pal[-1]) + (empty * rest))\n                else:\n                    out(char * rest)\n            elif position > maxwidth:\n                out(chr(8) + ' ' + chr(8))  # backspace\n\n    # Print right bracket in correct color:\n    if incolor:\n        lastcolor = darkred if (hicolor and endpcnt > 1) else pal[-1]\n        out((csi % lastcolor) + cbrackets[1])    # end bracket\n        colorend()\n    else:\n        out(cbrackets[1])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse user linters or all available when not specified.", "response": "def _set_linters(self):\n        \"\"\"Use user linters or all available when not specified.\"\"\"\n        if 'linters' in self._config:\n            self.user_linters = list(self._parse_cfg_linters())\n            self.linters = {linter: self._all_linters[linter]\n                            for linter in self.user_linters}\n        else:\n            self.linters = self._all_linters"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef print_config(self):\n        linters = self.user_linters or list(self.linters)\n        print('linters:', ', '.join(linters))\n        for key, value in self._config.items():\n            if key != 'linters':\n                print('{}: {}'.format(key, value))", "response": "Print all yala configurations including default and user s."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_cfg_linters(self):\n        user_value = self._config.get('linters', '')\n        # For each line of \"linters\" value, use comma as separator\n        for line in user_value.splitlines():\n            yield from self._parse_linters_line(line)", "response": "Parse the linters config file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn linter options without linter name prefix.", "response": "def get_linter_config(self, name):\n        \"\"\"Return linter options without linter name prefix.\"\"\"\n        prefix = name + ' '\n        return {k[len(prefix):]: v\n                for k, v in self._config.items()\n                if k.startswith(prefix)}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _merge(cls, default, user):\n        section = cls._CFG_SECTION\n        merged = default[section]\n\n        if section not in user:\n            return merged\n\n        user = user[section]\n        for key, value in user.items():\n            if key in merged:\n                merged[key] += ' ' + value\n            else:\n                merged[key] = value\n        return merged", "response": "Append user options to default options. Return yala section."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning input string as a text string.", "response": "def as_text(str_or_bytes, encoding='utf-8', errors='strict'):\n    \"\"\"Return input string as a text string.\n\n    Should work for input string that's unicode or bytes,\n    given proper encoding.\n\n    >>> print(as_text(b'foo'))\n    foo\n    >>> b'foo'.decode('utf-8') == u'foo'\n    True\n    \"\"\"\n    if isinstance(str_or_bytes, text):\n        return str_or_bytes\n    return str_or_bytes.decode(encoding, errors)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_safe_path(in_str):\n    norm_str = _SAFE_PATH_RE.sub(\n        '_', unicodedata.normalize('NFKD', as_text(in_str)).strip())\n    if len(norm_str.strip('.')) == 0:\n        # making sure the normalized result is non-empty, and not just dots\n        raise ValueError(in_str)\n    return norm_str[:_MAX_PATH_NAME_LEN]", "response": "Return in_str converted to a string that can be safely used as a path in many\n             ."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nattempts to create a link to the system location of the given egg.", "response": "def attempt_dev_link_via_import(self, egg):\n        \"\"\"Create egg-link to FS location if an egg is found through importing.\n\n        Sometimes an egg *is* installed, but without a proper egg-info file.\n        So we attempt to import the egg in order to return a link anyway.\n\n        TODO: currently it only works with simple package names like\n        \"psycopg2\" and \"mapnik\".\n\n        \"\"\"\n        try:\n            imported = __import__(egg)\n        except ImportError:\n            self.logger.warn(\"Tried importing '%s', but that also didn't work.\", egg)\n            self.logger.debug(\"For reference, sys.path is %s\", sys.path)\n            return\n        self.logger.info(\"Importing %s works, however\", egg)\n        try:\n            probable_location = os.path.dirname(imported.__file__)\n        except:  # Bare except\n            self.logger.exception(\"Determining the location failed, however\")\n            return\n        filesystem_egg_link = os.path.join(\n            self.dev_egg_dir,\n            '%s.egg-link' % egg)\n        f = open(filesystem_egg_link, 'w')\n        f.write(probable_location)\n        f.close()\n        self.logger.info('Using sysegg %s for %s', probable_location, egg)\n        self.added.append(filesystem_egg_link)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _install_exception_handler(self):\n        def handler(t, value, traceback):\n            if self.args.verbose:\n                sys.__excepthook__(t, value, traceback)\n            else:\n                sys.stderr.write('%s\\n' % unicode(value).encode('utf-8'))\n\n        sys.excepthook = handler", "response": "Installs a replacement for sys. excepthook which handles pretty - printing uncaught exceptions."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef source_to_unicode(txt, errors='replace', skip_encoding_cookie=True):\n    if isinstance(txt, six.text_type):\n        return txt\n    if isinstance(txt, six.binary_type):\n        buffer = io.BytesIO(txt)\n    else:\n        buffer = txt\n    try:\n        encoding, _ = detect_encoding(buffer.readline)\n    except SyntaxError:\n        encoding = \"ascii\"\n    buffer.seek(0)\n\n    newline_decoder = io.IncrementalNewlineDecoder(None, True)\n\n    text = io.TextIOWrapper(buffer, encoding, errors=errors, line_buffering=True)\n    text.mode = 'r'\n    if skip_encoding_cookie:\n        return u\"\".join(strip_encoding_cookie(text))\n    else:\n        return text.read()", "response": "Converts a bytes string with python source code to unicode."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndecoding bytes representing source code and return the string.", "response": "def decode_source(source_bytes):\n    \"\"\"Decode bytes representing source code and return the string.\n    Universal newline support is used in the decoding.\n    \"\"\"\n    # source_bytes_readline = io.BytesIO(source_bytes).readline\n    # encoding, _ = detect_encoding(source_bytes_readline)\n    newline_decoder = io.IncrementalNewlineDecoder(None, True)\n    return newline_decoder.decode(source_to_unicode(source_bytes))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclone the given repository at the given location as a subrepo in the given directory.", "response": "def clone(location: str, directory: str, *, branch: str=None, tag: str=None, commit: str=None, author_name: str=None,\n          author_email: str=None) -> Commit:\n    \"\"\"\n    Clones the repository at the given location as a subrepo in the given directory.\n    :param location: the location of the repository to clone\n    :param directory: the directory that the subrepo will occupy (i.e. not the git repository root)\n    :param branch: the specific branch to clone\n    :param tag: the specific tag to clone\n    :param commit: the specific commit to clone (may also require tag/branch to be specified if not fetched)\n    :param author_name: the name of the author to assign to the clone commit (uses system specified if not set)\n    :param author_email: the email of the author to assign to the clone commit (uses system specified if not set)\n    :return: the commit reference of the checkout\n    \"\"\"\n    if os.path.exists(directory):\n        raise ValueError(f\"The directory \\\"{directory}\\\" already exists\")\n    if not os.path.isabs(directory):\n        raise ValueError(f\"Directory must be absolute: {directory}\")\n    if branch and tag:\n        raise ValueError(f\"Cannot specify both branch \\\"{branch}\\\" and tag \\\"{tag}\\\"\")\n    if not branch and not tag and not commit:\n        branch = _DEFAULT_BRANCH\n\n    existing_parent_directory = directory\n    while not os.path.exists(existing_parent_directory):\n        assert existing_parent_directory != \"\"\n        existing_parent_directory = os.path.dirname(existing_parent_directory)\n\n    git_root = get_git_root_directory(existing_parent_directory)\n    git_relative_directory = os.path.relpath(os.path.realpath(directory), git_root)\n\n    if (branch or tag) and commit:\n        run([GIT_COMMAND, \"fetch\", location, branch if branch else tag], execution_directory=git_root)\n        branch, tag = None, None\n    reference = branch if branch else (tag if tag else commit)\n\n    execution_environment = os.environ.copy()\n    if author_name is not None:\n        execution_environment[_GIT_AUTHOR_NAME_ENVIRONMENT_VARIABLE] = author_name\n    if author_email is not None:\n        execution_environment[_GIT_AUTHOR_EMAIL_ENVIRONMENT_VARIABLE] = author_email\n\n    try:\n        run([GIT_COMMAND, _GIT_SUBREPO_COMMAND, _GIT_SUBREPO_CLONE_COMMAND, _GIT_SUBREPO_VERBOSE_FLAG,\n             _GIT_SUBREPO_BRANCH_FLAG, reference, location, git_relative_directory], execution_directory=git_root,\n            execution_environment=execution_environment)\n    except RunException as e:\n        if re.search(\"Can't clone subrepo. (Unstaged|Index has) changes\", e.stderr) is not None:\n            raise UnstagedChangeException(git_root) from e\n        elif \"Command failed:\" in e.stderr:\n            try:\n                repo_info = run([GIT_COMMAND, _GIT_LS_REMOTE_COMMAND, location])\n                if not branch and not tag and commit:\n                    raise NotAGitReferenceException(\n                        f\"Commit \\\"{commit}\\\" not found (specify branch/tag to fetch that first if required)\")\n                else:\n                    references = re.findall(\"^.+\\srefs\\/.+\\/(.+)\", repo_info, flags=re.MULTILINE)\n                    if reference not in references:\n                        raise NotAGitReferenceException(f\"{reference} not found in {references}\") from e\n\n            except RunException as debug_e:\n                if re.match(\"fatal: repository .* not found\", debug_e.stderr):\n                    raise NotAGitRepositoryException(location) from e\n        raise e\n\n    assert os.path.exists(directory)\n    return status(directory)[2]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef status(directory: str) -> Tuple[RepositoryLocation, Branch, Commit]:\n    if not os.path.exists(directory):\n        raise ValueError(f\"No subrepo found in \\\"{directory}\\\"\")\n\n    try:\n        result = run([GIT_COMMAND, _GIT_SUBREPO_COMMAND, _GIT_SUBREPO_STATUS_COMMAND, _GIT_SUBREPO_VERBOSE_FLAG,\n                      get_directory_relative_to_git_root(directory)],\n                     execution_directory=get_git_root_directory(directory))\n    except RunException as e:\n        if \"Command failed: 'git rev-parse --verify HEAD'\" in e.stderr:\n            raise NotAGitSubrepoException(directory) from e\n        raise e\n\n    if re.search(\"is not a subrepo$\", result):\n        raise NotAGitSubrepoException(directory)\n\n    url = re.search(\"Remote URL:\\s*(.*)\", result).group(1)\n    branch = re.search(\"Tracking Branch:\\s*(.*)\", result).group(1)\n    commit = re.search(\"Pulled Commit:\\s*(.*)\", result).group(1)\n    return url, branch, commit", "response": "Gets the status of the subrepo that has been cloned into the given directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npulling the subrepo that has been cloned into the given directory.", "response": "def pull(directory: str) -> Commit:\n    \"\"\"\n    Pulls the subrepo that has been cloned into the given directory.\n    :param directory: the directory containing the subrepo\n    :return: the commit the subrepo is on\n    \"\"\"\n    if not os.path.exists(directory):\n        raise ValueError(f\"No subrepo found in \\\"{directory}\\\"\")\n    try:\n        result = run([GIT_COMMAND, _GIT_SUBREPO_COMMAND, _GIT_SUBREPO_PULL_COMMAND, _GIT_SUBREPO_VERBOSE_FLAG,\n                      get_directory_relative_to_git_root(directory)],\n                     execution_directory=get_git_root_directory(directory))\n    except RunException as e:\n        if \"Can't pull subrepo. Working tree has changes\" in e.stderr:\n            raise UnstagedChangeException() from e\n    return status(directory)[2]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cached(fn, size=32):\n    ''' this decorator creates a type safe lru_cache\n    around the decorated function. Unlike\n    functools.lru_cache, this will not crash when\n    unhashable arguments are passed to the function'''\n    assert callable(fn)\n    assert isinstance(size, int)\n    return overload(fn)(lru_cache(size, typed=True)(fn))", "response": "Decorator to create a type safe lru_cache\n    around the decorated function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef translate(client, event, channel, nick, rest):\n\ttry:\n\t\tset_key()\n\texcept Exception:\n\t\treturn (\n\t\t\t\"No API key configured. Google charges for translation. \"\n\t\t\t\"Please register for an API key at \"\n\t\t\t\"https://code.google.com/apis/console/?api=translate&promo=tr \"\n\t\t\t\"and set the 'Google API key' config variable to a valid key\")\n\trest = rest.strip()\n\tlangpair, _, rest = rest.partition(' ')\n\tsource_lang, _, target_lang = langpair.rpartition('|')\n\ttry:\n\t\treturn google.translate(rest.encode('utf-8'), target_lang, source_lang)\n\texcept Exception:\n\t\tlog.exception(\"Error occurred in translate\")\n\t\ttmpl = (\n\t\t\t\"An error occurred. \"\n\t\t\t\"Are you sure {langpair} is a valid language?\")\n\t\treturn tmpl.format(**vars())", "response": "Translate a phrase using Google Translate."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_model(app_dot_model):\n\n    try:\n        app, model = app_dot_model.split('.')\n    except ValueError:\n        msg = (f'Passed in value \\'{app_dot_model}\\' was not in the format '\n               '`<app_name>.<model_name>`.')\n        raise ValueError(msg)\n\n    return apps.get_app_config(app).get_model(model)", "response": "Returns the Django model class corresponding to passed - in app_dot_model string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a matcher that matches a list or set of allowed modules.", "response": "def match_modules(allowed_modules):\n    \"\"\"Creates a matcher that matches a list/set/tuple of allowed modules.\"\"\"\n    cleaned_allowed_modules = [\n        utils.mod_to_mod_name(tmp_mod)\n        for tmp_mod in allowed_modules\n    ]\n    cleaned_split_allowed_modules = [\n        tmp_mod.split(\".\")\n        for tmp_mod in cleaned_allowed_modules\n    ]\n    cleaned_allowed_modules = []\n    del cleaned_allowed_modules\n\n    def matcher(cause):\n        cause_cls = None\n        cause_type_name = cause.exception_type_names[0]\n        # Rip off the class name (usually at the end).\n        cause_type_name_pieces = cause_type_name.split(\".\")\n        cause_type_name_mod_pieces = cause_type_name_pieces[0:-1]\n        # Do any modules provided match the provided causes module?\n        mod_match = any(\n            utils.array_prefix_matches(mod_pieces,\n                                       cause_type_name_mod_pieces)\n            for mod_pieces in cleaned_split_allowed_modules)\n        if mod_match:\n            cause_cls = importutils.import_class(cause_type_name)\n            cause_cls = ensure_base_exception(cause_type_name, cause_cls)\n        return cause_cls\n\n    return matcher"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef match_classes(allowed_classes):\n    cleaned_allowed_classes = [\n        utils.cls_to_cls_name(tmp_cls)\n        for tmp_cls in allowed_classes\n    ]\n\n    def matcher(cause):\n        cause_cls = None\n        cause_type_name = cause.exception_type_names[0]\n        try:\n            cause_cls_idx = cleaned_allowed_classes.index(cause_type_name)\n        except ValueError:\n            pass\n        else:\n            cause_cls = allowed_classes[cause_cls_idx]\n            if not isinstance(cause_cls, type):\n                cause_cls = importutils.import_class(cause_cls)\n            cause_cls = ensure_base_exception(cause_type_name, cause_cls)\n        return cause_cls\n\n    return matcher", "response": "Creates a matcher that matches a list of allowed classes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef combine_or(matcher, *more_matchers):\n\n    def matcher(cause):\n        for sub_matcher in itertools.chain([matcher], more_matchers):\n            cause_cls = sub_matcher(cause)\n            if cause_cls is not None:\n                return cause_cls\n        return None\n\n    return matcher", "response": "Combines more than one matcher together."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getTWFiles(self):\n\n        ddir=\"../data/tw/\"\n        # get files in dir\n        # order by size, if size\n        # group them so that the total filesize is smaller then 1GB-1.4GB\n        files=os.path.listdir(ddir)\n        files=[i for i in files if os.path.getsize(i)]\n        files.sort(key=lambda i: os.path.getsize(i))\n        filegroups=self.groupTwitterFilesByEquivalents(files)\n        filegroups_grouped=self.groupTwitterFileGroupsForPublishing(filegroups)\n        return filegroups_grouped", "response": "Get data files with Twitter messages."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_cmd(cmd, log='log.log', cwd='.', stdout=sys.stdout, bufsize=1, encode='utf-8'):\n  logfile = '%s/%s' % (cwd, log)\n  \n  if os.path.exists(logfile):\n    os.remove(logfile)\n  proc_args = {\n    'stdout': subprocess.PIPE,\n    'stderr': subprocess.PIPE,\n    'cwd': cwd,\n    'universal_newlines': True\n  }\n\n  proc = subprocess.Popen(cmd, **proc_args)\n  \n  while True:\n    line = proc.stdout.readline()\n    if proc.poll() is None:\n      stdout.write(line)\n    else:\n      break\n  out, err = proc.communicate()\n\n  with open(logfile, 'w') as f:\n    if out:\n      f.write(out)\n    else:\n      f.write(err)", "response": "Runs a command in the backround by creating a new process and writing the output to a specified log file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef touch_log(log, cwd='.'):\n  logfile = '%s/%s' % (cwd, log)\n  with open(logfile, 'a'):\n    os.utime(logfile, None)", "response": "Touch the log file. Creates if not exists."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new collector or actor", "response": "def create(output_dir):\n    \"\"\"Create a new collector or actor\"\"\"\n    template_path = os.path.join(os.path.dirname(__file__), 'project_template')\n\n    click.secho('Let\\'s create a new component!', fg='green')\n    name = click.prompt('What is the name of this component (ex. python-pip)?')\n\n    click.secho('')\n    click.secho('We assume this will be pushed to GitHub and Docker Hub eventually, but these don\\'t have to exist yet.', fg='green')\n    repo_owner = click.prompt('GitHub repo owner (i.e. your username or organization name)')\n    repo_name = click.prompt('GitHub repo name', default=name)\n    dockerhub_owner = click.prompt('Docker Hub repo owner', default=repo_owner)\n    dockerhub_name = click.prompt('Docker Hub repo name', default=repo_name)\n\n    license_owner = click.prompt('Who should be the copyright owner on project?', default=repo_owner)\n\n    extra_context = {\n        'name': name,\n        'name_shields_io': name.replace('-', '--'),\n        'current_year': datetime.datetime.now().year,\n        'dependencies_cli_version': __version__,\n        'repo_owner': repo_owner,\n        'repo_name': repo_name,\n        'dockerhub_owner': dockerhub_owner,\n        'dockerhub_name': dockerhub_name,\n        'license_owner': license_owner,\n    }\n    project_dir = cookiecutter(template_path, no_input=True, extra_context=extra_context, output_dir=output_dir)\n\n    click.secho('')\n    click.secho('{name} is ready to go, `cd {project_dir}` and try running `dependencies test`!'.format(name=name, project_dir=project_dir), fg='green')\n    click.secho(\n        'We started you out with a fully functioning component based in python.\\n' +\n        'Once you\\'ve got a handle on how it works then you can change it to whatever language you want.'\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvalidate JSON input using dependencies - schema", "response": "def validate(text, file, schema_type):\n    \"\"\"Validate JSON input using dependencies-schema\"\"\"\n    content = None\n\n    if text:\n        print('Validating text input...')\n        content = text\n\n    if file:\n        print('Validating file input...')\n        content = file.read()\n\n    if content is None:\n        click.secho('Please give either text input or a file path. See help for more details.', fg='red')\n        exit(1)\n\n    try:\n        if schema_type == 'dependencies':\n            validator = DependenciesSchemaValidator()\n        elif schema_type == 'actions':\n            validator = ActionsSchemaValidator()\n        else:\n            raise Exception('Unknown type')\n\n        validator.validate_json(content)\n        click.secho('Valid JSON schema!', fg='green')\n    except Exception as e:\n        click.secho('Invalid JSON schema!', fg='red')\n        raise e"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self):\n        connectable = engine_from_config(\n            self._config.get_section(self._config.config_ini_section),\n            prefix='sqlalchemy.',\n            poolclass=pool.NullPool)\n\n        with connectable.connect() as connection:\n            ensureSchemaExists(connectable, self._schemaName)\n\n            context.configure(\n                connection=connection,\n                target_metadata=self._targetMetadata,\n                include_object=self._includeObjectFilter,\n                include_schemas=True,\n                version_table_schema=self._schemaName\n            )\n\n            with context.begin_transaction():\n                context.run_migrations()", "response": "Run migrations in online mode."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclean up build dir", "response": "def _clean():\n    \"\"\"\n    Cleans up build dir\n    \"\"\"\n    LOGGER.info('Cleaning project directory...')\n    folders_to_cleanup = [\n        '.eggs',\n        'build',\n        f'{config.PACKAGE_NAME()}.egg-info',\n    ]\n    for folder in folders_to_cleanup:\n        if os.path.exists(folder):\n            LOGGER.info('\\tremoving: %s', folder)\n            shutil.rmtree(folder)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef str_to_application_class(self, an_app_key):\n        try:\n            app_class = str_to_python_object(self.apps[an_app_key])\n        except KeyError:\n            app_class = str_to_python_object(an_app_key)\n        try:\n            self.application_defaults = DotDict(\n                app_class.get_application_defaults()\n            )\n        except AttributeError:\n            # no get_application_defaults, skip this step\n            pass\n        return app_class", "response": "a configman compatible str_to_* converter"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(table, session, conds):\n    with session.begin_nested():\n        archive_conds_list = _get_conditions_list(table, conds)\n        session.execute(\n            sa.delete(table.ArchiveTable, whereclause=_get_conditions(archive_conds_list))\n        )\n        conds_list = _get_conditions_list(table, conds, archive=False)\n        session.execute(\n            sa.delete(table, whereclause=_get_conditions(conds_list))\n        )", "response": "Performs a hard delete on a row in the Savage\n    table and archive table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _format_response(rows, fields, unique_col_names):\n    output = []\n    old_id = None\n    for row in rows:\n        id_ = {k: row[k] for k in unique_col_names}\n        formatted = {k: row[k] for k in row if k != 'data'}\n        if id_ != old_id:  # new unique versioned row\n            data = row['data']\n            formatted['data'] = {k: data.get(k) for k in fields}\n            output.append(formatted)\n        else:\n            data = row['data']\n            pruned_data = {k: data.get(k) for k in fields}\n            if (\n                pruned_data != output[-1]['data'] or\n                row['deleted'] != output[-1]['deleted']\n            ):\n                formatted['data'] = pruned_data\n                output.append(formatted)\n        old_id = id_\n    return output", "response": "This function will take a list of rows and extract the specified fields from the user table and return a list of dictionaries where each dictionary contains the key data and the value of the data column."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a sqlalchemy query that will be used to select the mysql conditions for the given primary key constraints.", "response": "def _get_conditions(pk_conds, and_conds=None):\n    \"\"\"If and_conds = [a1, a2, ..., an] and pk_conds = [[b11, b12, ..., b1m], ... [bk1, ..., bkm]],\n    this function will return the mysql condition clause:\n        a1 & a2 & ... an & ((b11 and ... b1m) or ... (b11 and ... b1m))\n\n    :param pk_conds: a list of list of primary key constraints returned by _get_conditions_list\n    :param and_conds: additional and conditions to be placed on the query\n    \"\"\"\n    if and_conds is None:\n        and_conds = []\n\n    if len(and_conds) == 0 and len(pk_conds) == 0:\n        return sa.and_()\n\n    condition1 = sa.and_(*and_conds)\n    condition2 = sa.or_(*[sa.and_(*cond) for cond in pk_conds])\n    return sa.and_(condition1, condition2)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_conditions_list(table, conds, archive=True):\n    if conds is None:\n        conds = []\n\n    all_conditions = []\n    for cond in conds:\n        if len(cond) != len(table.version_columns):\n            raise ValueError('Conditions must specify all unique constraints.')\n\n        conditions = []\n        t = table.ArchiveTable if archive else table\n\n        for col_name, value in cond.iteritems():\n            if col_name not in table.version_columns:\n                raise ValueError('{} is not one of the unique columns <{}>'.format(\n                    col_name, ','.join(table.version_columns)\n                ))\n            conditions.append(getattr(t, col_name) == value)\n        all_conditions.append(conditions)\n    return all_conditions", "response": "This function returns a list of lists of == conditions on sqlalchemy columns given conds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a 0 - indexed offset and limit based on page and page_size for a MySQL query.", "response": "def _get_limit_and_offset(page, page_size):\n    \"\"\"Returns a 0-indexed offset and limit based on page and page_size for a MySQL query.\n    \"\"\"\n    if page < 1:\n        raise ValueError('page must be >= 1')\n    limit = page_size\n    offset = (page - 1) * page_size\n    return limit, offset"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an ascending order clause on the versioned unique constraint as well as the version column.", "response": "def _get_order_clause(archive_table):\n    \"\"\"Returns an ascending order clause on the versioned unique constraint as well as the\n    version column.\n    \"\"\"\n    order_clause = [\n        sa.asc(getattr(archive_table, col_name)) for col_name in archive_table._version_col_names\n    ]\n    order_clause.append(sa.asc(archive_table.version_id))\n    return order_clause"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef areObservableElements(self, elementNames):\n        if not(hasattr(elementNames, \"__len__\")):\n            raise TypeError(\n                \"Element name should be a array of strings.\" +\n                \"I receive this {0}\"\n                .format(elementNames))\n\n        return self._evaluateArray(elementNames)", "response": "Evaluate the element names to see if they are observable elements."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nevaluating the element name and returns a boolean indicating if the element is an observable element.", "response": "def isObservableElement(self, elementName):\n        \"\"\"\n        Mention if an element is an observable element.\n\n        :param str ElementName: the element name to evaluate\n        :return: true if is an observable element, otherwise false.\n        :rtype: bool\n        \"\"\"\n        if not(isinstance(elementName, str)):\n            raise TypeError(\n                \"Element name should be a string .\" +\n                \"I receive this {0}\"\n                .format(elementName))\n\n        return (True if (elementName == \"*\")\n                else self._evaluateString(elementName))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add(self, observableElement):\n        if observableElement not in self._observables:\n            self._observables.append(observableElement)\n        else:\n            raise RuntimeError(\n                \"{0} is already an observable element\"\n                .format(observableElement))", "response": "add an observable element to the store"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove(self, observableElement):\n        if observableElement in self._observables:\n            self._observables.remove(observableElement)", "response": "remove an obsrvable element"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef install_config_kafka(self):\n        if self.prompt_check(\"Download and install kafka\"):\n            self.kafka_install()\n\n        if self.prompt_check(\"Configure and autostart kafka\"):\n            self.kafka_config()", "response": "Install and configure kafka"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninstalling and config elasticsearch", "response": "def install_config_elastic(self):\n        \"\"\"\n        install and config elasticsearch\n        :return:\n        \"\"\"\n        if self.prompt_check(\"Download and install elasticsearch\"):\n            self.elastic_install()\n\n        if self.prompt_check(\"Configure and autostart elasticsearch\"):\n            self.elastic_config()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninstalling and config logstash", "response": "def install_config_logstash(self):\n        \"\"\"\n        install and config logstash\n        :return:\n        \"\"\"\n        if self.prompt_check(\"Download and install logstash\"):\n            self.logstash_install()\n\n        if self.prompt_check(\"Configure and autostart logstash\"):\n            self.logstash_config()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef install_config_kibana(self):\n        if self.prompt_check(\"Download and install kibana\"):\n            self.kibana_install()\n\n        if self.prompt_check(\"Configure and autostart kibana\"):\n            self.kibana_config()", "response": "Install and configure kibana"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef install_config_spark(self):\n        if self.prompt_check(\"Download and install hadoop\"):\n            self.hadoop_install()\n\n        if self.prompt_check(\"Download and install spark\"):\n            self.spark_install()\n\n        if self.prompt_check(\"Configure spark\"):\n            self.spark_config()", "response": "Install and configure spark"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding master server to slave server", "response": "def add_slave_server(self):\n        \"\"\"\n        \u6dfb\u52a0slave\u670d\u52a1\u5668\n        :return:\n        \"\"\"\n        master = self.args.config[1]\n        slave = self.args.add_slave\n\n        # install java at slave server\n        self.reset_server_env(slave, self.configure)\n        if self.prompt_check(\"Update package at slave server\"):\n            self.update_source_list()\n            self.common_update_sys()\n\n        if self.prompt_check(\"Install java and python at slave server\"):\n            self.java_install()\n            sudo('apt-get install -y python python3 python-dev python3-dev')\n\n        # generate ssh key at master server\n        if not self.args.skip_master:\n            if self.prompt_check(\"Generate ssh key at Master Server\"):\n                self.generate_ssh(master, self.args, self.configure)\n\n        # generate ssh key at slave server and make slave connect with master\n        if self.prompt_check(\"Make ssh connection within master and slave\"):\n            self.generate_ssh(slave, self.args, self.configure)\n\n            # scp slave server ssh key to master server\n            run('scp ~/.ssh/id_rsa.pub {0}@{1}:~/.ssh/id_rsa.pub.{2}'.format(\n                self.configure[master]['user'],\n                self.configure[master]['host'],\n                slave\n            ))\n\n            # add slave ssh key to master authorized_keys\n            self.reset_server_env(master, self.configure)\n            run('cat ~/.ssh/id_rsa.pub* >> ~/.ssh/authorized_keys')\n\n            # scp master authorized_keys to slave authorized_keys\n            run('scp ~/.ssh/authorized_keys {0}@{1}:~/.ssh'.format(\n                self.configure[slave]['user'],\n                self.configure[slave]['host']\n            ))\n\n        # config slave and master\n        if self.prompt_check(\"Configure master and slave server\"):\n            master = self.args.config[1]\n            slave = self.args.add_slave\n\n            if self.args.bigdata_app == 'spark':\n                self.add_spark_slave(master, slave, self.configure)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_file_content(url, comes_from=None):\n    match = _scheme_re.search(url)\n    if match:\n        scheme = match.group(1).lower()\n        if (scheme == 'file' and comes_from\n            and comes_from.startswith('http')):\n            raise InstallationError(\n                'Requirements file %s references URL %s, which is local'\n                % (comes_from, url))\n        if scheme == 'file':\n            path = url.split(':', 1)[1]\n            path = path.replace('\\\\', '/')\n            match = _url_slash_drive_re.match(path)\n            if match:\n                path = match.group(1) + ':' + path.split('|', 1)[1]\n            path = urllib.unquote(path)\n            if path.startswith('/'):\n                path = '/' + path.lstrip('/')\n            url = path\n        else:\n            ## FIXME: catch some errors\n            resp = urlopen(url)\n            return geturl(resp), resp.read()\n    try:\n        f = open(url)\n        content = f.read()\n    except IOError:\n        e = sys.exc_info()[1]\n        raise InstallationError('Could not open requirements file: %s' % str(e))\n    else:\n        f.close()\n    return url, content", "response": "Gets the content of a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef url_to_path(url):\n    assert url.startswith('file:'), (\n        \"You can only turn file: urls into filenames (not %r)\" % url)\n    path = url[len('file:'):].lstrip('/')\n    path = urllib.unquote(path)\n    if _url_drive_re.match(path):\n        path = path[0] + ':' + path[2:]\n    else:\n        path = '/' + path\n    return path", "response": "Convert a file URL to a path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a path to a file URL.", "response": "def path_to_url(path):\n    \"\"\"\n    Convert a path to a file: URL.  The path will be made absolute.\n    \"\"\"\n    path = os.path.normcase(os.path.abspath(path))\n    if _drive_re.match(path):\n        path = path[0] + '|' + path[2:]\n    url = urllib.quote(path)\n    url = url.replace(os.path.sep, '/')\n    url = url.lstrip('/')\n    return 'file:///' + url"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef path_to_url2(path):\n    path = os.path.normpath(os.path.abspath(path))\n    drive, path = os.path.splitdrive(path)\n    filepath = path.split(os.path.sep)\n    url = '/'.join([urllib.quote(part) for part in filepath])\n    if not drive:\n        url = url.lstrip('/')\n    return 'file:///' + drive + url", "response": "Convert a path to a file URL."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the url of the urllib2_resp.", "response": "def geturl(urllib2_resp):\n    \"\"\"\n    Use instead of urllib.addinfourl.geturl(), which appears to have\n    some issues with dropping the double slash for certain schemes\n    (e.g. file://).  This implementation is probably over-eager, as it\n    always restores '://' if it is missing, and it appears some url\n    schemata aren't always followed by '//' after the colon, but as\n    far as I know pip doesn't need any of those.\n    The URI RFC can be found at: http://tools.ietf.org/html/rfc1630\n\n    This function assumes that\n        scheme:/foo/bar\n    is the same as\n        scheme:///foo/bar\n    \"\"\"\n    url = urllib2_resp.geturl()\n    scheme, rest = url.split(':', 1)\n    if rest.startswith('//'):\n        return url\n    else:\n        # FIXME: write a good test to cover it\n        return '%s://%s' % (scheme, rest)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap the URL to retrieve to protect against creative", "response": "def get_request(self, url):\n        \"\"\"\n        Wraps the URL to retrieve to protects against \"creative\"\n        interpretation of the RFC: http://bugs.python.org/issue8732\n        \"\"\"\n        if isinstance(url, string_types):\n            url = urllib2.Request(url, headers={'Accept-encoding': 'identity'})\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndo the dirty work of actually getting the rsponse object using urllib2 and its HTTP auth builtins.", "response": "def get_response(self, url, username=None, password=None):\n        \"\"\"\n        does the dirty work of actually getting the rsponse object using urllib2\n        and its HTTP auth builtins.\n        \"\"\"\n        scheme, netloc, path, query, frag = urlparse.urlsplit(url)\n        req = self.get_request(url)\n\n        stored_username, stored_password = self.passman.find_user_password(None, netloc)\n        # see if we have a password stored\n        if stored_username is None:\n            if username is None and self.prompting:\n                username = urllib.quote(raw_input('User for %s: ' % netloc))\n                password = urllib.quote(getpass.getpass('Password: '))\n            if username and password:\n                self.passman.add_password(None, netloc, username, password)\n            stored_username, stored_password = self.passman.find_user_password(None, netloc)\n        authhandler = urllib2.HTTPBasicAuthHandler(self.passman)\n        opener = urllib2.build_opener(authhandler)\n        # FIXME: should catch a 401 and offer to let the user reenter credentials\n        return opener.open(req)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset up urllib2 opener and urllib2.", "response": "def setup(self, proxystr='', prompting=True):\n        \"\"\"\n        Sets the proxy handler given the option passed on the command\n        line.  If an empty string is passed it looks at the HTTP_PROXY\n        environment variable.\n        \"\"\"\n        self.prompting = prompting\n        proxy = self.get_proxy(proxystr)\n        if proxy:\n            proxy_support = urllib2.ProxyHandler({\"http\": proxy, \"ftp\": proxy})\n            opener = urllib2.build_opener(proxy_support, urllib2.CacheFTPHandler)\n            urllib2.install_opener(opener)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts user and password from a url.", "response": "def extract_credentials(self, url):\n        \"\"\"\n        Extracts user/password from a url.\n\n        Returns a tuple:\n            (url-without-auth, username, password)\n        \"\"\"\n        if isinstance(url, urllib2.Request):\n            result = urlparse.urlsplit(url.get_full_url())\n        else:\n            result = urlparse.urlsplit(url)\n        scheme, netloc, path, query, frag = result\n\n        username, password = self.parse_credentials(netloc)\n        if username is None:\n            return url, None, None\n        elif password is None and self.prompting:\n            # remove the auth credentials from the url part\n            netloc = netloc.replace('%s@' % username, '', 1)\n            # prompt for the password\n            prompt = 'Password for %s@%s: ' % (username, netloc)\n            password = urllib.quote(getpass.getpass(prompt))\n        else:\n            # remove the auth credentials from the url part\n            netloc = netloc.replace('%s:%s@' % (username, password), '', 1)\n\n        target_url = urlparse.urlunsplit((scheme, netloc, path, query, frag))\n        return target_url, username, password"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the proxy string for the current user.", "response": "def get_proxy(self, proxystr=''):\n        \"\"\"\n        Get the proxy given the option passed on the command line.\n        If an empty string is passed it looks at the HTTP_PROXY\n        environment variable.\n        \"\"\"\n        if not proxystr:\n            proxystr = os.environ.get('HTTP_PROXY', '')\n        if proxystr:\n            if '@' in proxystr:\n                user_password, server_port = proxystr.split('@', 1)\n                if ':' in user_password:\n                    user, password = user_password.split(':', 1)\n                else:\n                    user = user_password\n                    prompt = 'Password for %s@%s: ' % (user, server_port)\n                    password = urllib.quote(getpass.getpass(prompt))\n                return '%s:%s@%s' % (user, password, server_port)\n            else:\n                return proxystr\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nenters a 6 - digit MFA token. Nephele will execute the appropriate AWS command line to authenticate that token.", "response": "def do_mfa(self, args):\n        \"\"\"\n        Enter a 6-digit MFA token. Nephele will execute the appropriate\n        `aws` command line to authenticate that token. \n\n        mfa -h for more details\n        \"\"\"\n        \n        parser = CommandArgumentParser(\"mfa\")\n        parser.add_argument(dest='token',help='MFA token value');\n        parser.add_argument(\"-p\",\"--profile\",dest='awsProfile',default=AwsConnectionFactory.instance.getProfile(),help='MFA token value');\n        args = vars(parser.parse_args(args))\n\n        token = args['token']\n        awsProfile = args['awsProfile']\n        arn = AwsConnectionFactory.instance.load_arn(awsProfile)\n\n        credentials_command = [\"aws\",\"--profile\",awsProfile,\"--output\",\"json\",\"sts\",\"get-session-token\",\"--serial-number\",arn,\"--token-code\",token]\n        output = run_cmd(credentials_command) # Throws on non-zero exit :yey:\n\n        credentials = json.loads(\"\\n\".join(output.stdout))['Credentials']\n        AwsConnectionFactory.instance.setMfaCredentials(credentials,awsProfile)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nnavigating up by one level.", "response": "def do_up(self,args):\n        \"\"\"\n        Navigate up by one level.\n\n        For example, if you are in `(aws)/stack:.../asg:.../`, executing `up` will place you in `(aws)/stack:.../`.\n\n        up -h for more details\n        \"\"\"\n        parser = CommandArgumentParser(\"up\")\n        args = vars(parser.parse_args(args))\n        if None == self.parent:\n            print \"You're at the root. Try 'quit' to quit\"\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_slash(self,args):\n        parser = CommandArgumentParser(\"slash\")\n        args = vars(parser.parse_args(args))\n        if None == self.parent:\n            print \"You're at the root. Try 'quit' to quit\"\n        else:\n            raise SlashException()", "response": "Navigate back to the root level."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nselects nephele profile profile -h for more details", "response": "def do_profile(self,args):\n        \"\"\"\n        Select nephele profile\n\n        profile -h for more details\n        \"\"\"\n        parser = CommandArgumentParser(\"profile\")\n        parser.add_argument(dest=\"profile\",help=\"Profile name\")\n        parser.add_argument('-v','--verbose',dest=\"verbose\",action='store_true',help='verbose')\n        args = vars(parser.parse_args(args))\n\n        profile = args['profile']\n        verbose = args['verbose']\n        if verbose:\n            print \"Selecting profile '{}'\".format(profile)\n\n        selectedProfile = {}\n        if profile in Config.config['profiles']:\n            selectedProfile = Config.config['profiles'][profile]\n\n        selectedProfile['name'] = profile\n        Config.config['selectedProfile'] = selectedProfile\n\n        awsProfile = profile\n        if 'awsProfile' in selectedProfile:\n            awsProfile = selectedProfile['awsProfile']\n        AwsConnectionFactory.resetInstance(profile=awsProfile)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeals with configuration. Available subcommands: * config print - print the current configuration * config reload - reload the current configuration from disk * config set - change a setting in the configuration * config save - save the configuration to disk config -h for more details", "response": "def do_config(self,args):\n        \"\"\"\n        Deal with configuration. Available subcommands:\n\n        * config print - print the current configuration\n        * config reload - reload the current configuration from disk\n        * config set - change a setting in the configuration\n        * config save - save the configuration to disk\n\n        config -h for more details\n        \"\"\"\n        parser = CommandArgumentParser(\"config\")\n        subparsers = parser.add_subparsers(help='sub-command help',dest='command')\n        # subparsers.required=\n        subparsers._parser_class = argparse.ArgumentParser # This is to work around `TypeError: __init__() got an unexpected keyword argument 'prog'`\n        \n        parserPrint = subparsers.add_parser('print',help='Print the current configuration')\n        parserPrint.add_argument(dest='keys',nargs='*',help='Key(s) to print')\n        \n        parserSet = subparsers.add_parser('set',help='Set a configuration value')\n        parserSave = subparsers.add_parser('save',help='Save the current configuration')\n        parserReload = subparsers.add_parser('reload',help='Reload the configuration from disk')\n        args = vars(parser.parse_args(args))\n\n        print(\"Command:{}\".format(args['command']))\n        {\n            'print' : AwsProcessor.sub_configPrint,\n            'set' : AwsProcessor.sub_configSet,\n            'save' : AwsProcessor.sub_configSave,\n            'reload' : AwsProcessor.sub_configReload\n        }[args['command']]( self, args )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(timestring):\n    for parser in _PARSERS:\n        match = parser['pattern'].match(timestring)\n        if match:\n            groups = match.groups()\n            ints = tuple(map(int, groups))\n            time = parser['factory'](ints)\n            return time\n\n    raise TimeError('Unsupported time format {}'.format(timestring))", "response": "Convert a statbank time string to a python datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef confirm(text, default=True):\n    if default:\n        legend = \"[y]/n\"\n    else:\n        legend = \"y/[n]\"\n    res = \"\"\n    while (res != \"y\") and (res != \"n\"):\n        res = raw_input(text + \" ({}): \".format(legend)).lower()\n        if not res and default:\n            res = \"y\"\n        elif not res and not default:\n            res = \"n\"\n    if res[0] == \"y\":\n        return True\n    else:\n        return False", "response": "Console confirmation dialog based on raw_input."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_file(fname):\n    res = []\n    try:\n        with open(fname, 'r') as f:\n            for line in f:\n                line = line.rstrip('\\n').rstrip('\\r')\n                if line and (line[0] != '#'):\n                    regexline = \".*\" + re.sub(\"\\*\", \".*\", line) + \".*\"\n                    res.append(regexline.lower())\n    except IOError:\n        pass\n    return res", "response": "Read file and convert wildcards into regular expressions skip empty lines\n            and comments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndropping a torrent from the list of filters and blacklist.", "response": "def drop_it(title, filters, blacklist):\n    \"\"\"\n    The found torrents should be in filters list and shouldn't be in blacklist.\n    \"\"\"\n    title = title.lower()\n    matched = False\n    for f in filters:\n        if re.match(f, title):\n            matched = True\n    if not matched:\n        return True\n    for b in blacklist:\n        if re.match(b, title):\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_create(config, config_dir):\n    if os.path.exists(config_dir):\n        print \"Configuration '{}' already exists.\".format(config)\n        exit(1)\n    os.makedirs(config_dir)\n    print \"Configuration directory created.\"\n\n    url = raw_input(\"RSS URL for processing []: \")\n    torrent_dir = raw_input(\"Output directory for found .torrent files [{}]: \"\\\n        .format(DEFAULT_TORRRENT_DIR)) or DEFAULT_TORRRENT_DIR\n    update_interval = raw_input(\"Update interval (mins) [{}]: \"\\\n        .format(DEFAULT_UPDATE_INTERVAL)) or DEFAULT_UPDATE_INTERVAL\n\n    editor = os.environ[\"EDITOR\"]\n\n    config_filter = os.path.join(config_dir, 'filter')\n    if confirm(\"Do you want to create filters list?\", False):\n        call([editor, config_filter])\n        print \"Filter configuration has been saved.\"\n\n    config_blacklist = os.path.join(config_dir, 'blacklist')\n    if confirm(\"Do you want to create blacklist?\", False):\n        call([editor, config_filter])\n        print \"Blacklist configuration has been saved.\"\n\n    config_file = os.path.join(config_dir, 'config')\n    config_data = json.dumps({\n        \"url\": url,\n        \"torrent_dir\": torrent_dir,\n        \"update_interval\": update_interval\n    }, sort_keys=True, indent=4, separators=(',', ': '))\n    with open(config_file, 'w') as f:\n        f.write(config_data)\n\n    ct = CronTab(user=True)\n    cmd = \"{} {} -e {}\".format(sys.executable,\n                               os.path.abspath(__file__),\n                               config)\n    job = ct.new(command=cmd)\n    job.minute.every(update_interval)\n    job.enable()\n    ct.write()\n    print \"Crontab updated.\"\n\n    print \"Config '{}' has been saved.\".format(config)", "response": "CLI action create new configuration."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_update(config, config_dir):\n    if not os.path.exists(config_dir):\n        print \"Configuration '{}' does not exist.\".format(config)\n        exit(1)\n\n    config_file = os.path.join(config_dir, 'config')\n    with open(config_file, 'r') as f:\n        old_config_data = json.load(f)\n\n    old_url = old_config_data['url']\n    old_torrent_dir = old_config_data['torrent_dir']\n    old_update_interval = old_config_data['update_interval']\n\n    url = raw_input(\"RSS URL for processing [{}]: \"\\\n        .format(old_url)) or old_url\n    torrent_dir = raw_input(\"Output directory for found .torrent files [{}]: \"\\\n        .format(old_torrent_dir)) or old_torrent_dir\n    update_interval = raw_input(\"Update interval (mins) [{}]: \"\\\n        .format(old_update_interval)) or old_update_interval\n\n    editor = os.environ[\"EDITOR\"]\n\n    config_filter = os.path.join(config_dir, 'filter')\n    if confirm(\"Do you want to edit filters list?\", False):\n        call([editor, config_filter])\n        print \"Filter configuration has been saved.\"\n\n    config_blacklist = os.path.join(config_dir, 'blacklist')\n    if confirm(\"Do you want to edit blacklist?\", False):\n        call([editor, config_filter])\n        print \"Blacklist configuration has been saved.\"\n\n    config_data = json.dumps({\n        \"url\": url,\n        \"torrent_dir\": torrent_dir,\n        \"update_interval\": update_interval\n    }, sort_keys=True, indent=4, separators=(',', ': '))\n    with open(config_file, 'w') as f:\n        f.write(config_data)\n\n    ct = CronTab(user=True)\n    for job in ct:\n        if re.match('.*ghetto.*\\-e\\s{}'.format(config), job.command):\n            ct.remove(job)\n\n    cmd = \"{} {} -e {}\".format(sys.executable,\n                               os.path.abspath(__file__),\n                               config)\n    new_job = ct.new(command=cmd)\n    new_job.minute.every(update_interval)\n    new_job.enable()\n    ct.write()\n    print \"Crontab updated.\"\n\n    print \"Configuration '{}' has been updated.\".format(config)", "response": "CLI action update new configuration."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_remove(config, config_dir):\n    if not os.path.exists(config_dir):\n        print \"Configuration '{}' does not exist.\".format(config)\n        exit(1)\n    if confirm(\"Confirm removal of the configuration '{}'\".format(config)):\n        shutil.rmtree(config_dir)\n        print \"Configuration '{}' has been removed.\".format(config)\n    else:\n        print \"Removal cancelled.\"", "response": "CLI action remove configuration."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_blacklist(config, config_dir):\n    if not os.path.exists(config_dir):\n        print \"Configuration '{}' does not exist.\".format(config)\n        exit(1)    \n\n    editor = os.environ[\"EDITOR\"]\n\n    config_blacklist = os.path.join(config_dir, 'blacklist')\n    call([editor, config_blacklist])\n    print \"Blacklist configuration has been updated.\"", "response": "CLI action run editor for blacklist."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_discrete(self):\n        for domain in self.domains.values():\n            if not domain.is_discrete():\n                return False\n        return True", "response": "Return whether this space is discrete."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks whether the labeling is consistent with all constraints", "response": "def consistent(self,lab):\n        \"\"\"\n        Check whether the labeling is consistent with all constraints\n        \"\"\"\n        for const in self.constraints:\n            if not const.consistent(lab):\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef satisfied(self,lab):\n        for const in self.constraints:\n            if not const.satisfied(lab):\n                return False\n        return True", "response": "Check whether the labeling satisfies all constraints"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new instance of this class from the inline string format", "response": "def from_inline(cls: Type[MembershipType], version: int, currency: str, membership_type: str,\n                    inline: str) -> MembershipType:\n        \"\"\"\n        Return Membership instance from inline format\n\n        :param version: Version of the document\n        :param currency: Name of the currency\n        :param membership_type: \"IN\" or \"OUT\" to enter or exit membership\n        :param inline: Inline string format\n        :return:\n        \"\"\"\n        data = Membership.re_inline.match(inline)\n        if data is None:\n            raise MalformedDocumentError(\"Inline membership ({0})\".format(inline))\n        issuer = data.group(1)\n        signature = data.group(2)\n        membership_ts = BlockUID.from_str(data.group(3))\n        identity_ts = BlockUID.from_str(data.group(4))\n        uid = data.group(5)\n        return cls(version, currency, issuer, membership_ts, membership_type, uid, identity_ts, signature)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new instance of this class from a signed raw format string.", "response": "def from_signed_raw(cls: Type[MembershipType], signed_raw: str) -> MembershipType:\n        \"\"\"\n        Return Membership instance from signed raw format\n\n        :param signed_raw: Signed raw format string\n        :return:\n        \"\"\"\n        lines = signed_raw.splitlines(True)\n        n = 0\n\n        version = int(Membership.parse_field(\"Version\", lines[n]))\n        n += 1\n\n        Membership.parse_field(\"Type\", lines[n])\n        n += 1\n\n        currency = Membership.parse_field(\"Currency\", lines[n])\n        n += 1\n\n        issuer = Membership.parse_field(\"Issuer\", lines[n])\n        n += 1\n\n        membership_ts = BlockUID.from_str(Membership.parse_field(\"Block\", lines[n]))\n        n += 1\n\n        membership_type = Membership.parse_field(\"Membership\", lines[n])\n        n += 1\n\n        uid = Membership.parse_field(\"UserID\", lines[n])\n        n += 1\n\n        identity_ts = BlockUID.from_str(Membership.parse_field(\"CertTS\", lines[n]))\n        n += 1\n\n        signature = Membership.parse_field(\"Signature\", lines[n])\n        n += 1\n\n        return cls(version, currency, issuer, membership_ts,\n                   membership_type, uid, identity_ts, signature)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef raw(self) -> str:\n        return \"\"\"Version: {0}\nType: Membership\nCurrency: {1}\nIssuer: {2}\nBlock: {3}\nMembership: {4}\nUserID: {5}\nCertTS: {6}\n\"\"\".format(self.version,\n           self.currency,\n           self.issuer,\n           self.membership_ts,\n           self.membership_type,\n           self.uid,\n           self.identity_ts)", "response": "Return a string that represents the Membership instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns inline string format of the Membership instance", "response": "def inline(self) -> str:\n        \"\"\"\n        Return inline string format of the Membership instance\n        :return:\n        \"\"\"\n        return \"{0}:{1}:{2}:{3}:{4}\".format(self.issuer,\n                                            self.signatures[0],\n                                            self.membership_ts,\n                                            self.identity_ts,\n                                            self.uid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_subsumed_by(x, y):\n    varsX = __split_expression(x)[1]\n    theta = unify(x, y)\n    if theta is problem.FAILURE:\n        return False\n    return all(__is_variable(theta[var]) for var in theta.keys()\n               if var in varsX)", "response": "Returns True if x subsumes y."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndoes a request to the specified url.", "response": "def _do_request(self, url, params=None, data=None, headers=None):\n        \"\"\"\n        Realiza as requisi\u00e7\u00f5es diversas utilizando a biblioteca requests,\n        tratando de forma gen\u00e9rica as exce\u00e7\u00f5es.\n        \"\"\"\n\n        if not headers:\n            headers = {'content-type': 'application/json'}\n\n        try:\n            response = requests.get(\n                url, params=params, data=data, headers=headers)\n        except:\n            return None\n\n        if response.status_code == 200:\n            return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the document s citations and accesses.", "response": "def update_document_indicators(self, doc_id, citations, accesses):\n        \"\"\"\n            Atualiza os indicadores de acessos e cita\u00e7\u00f5es de um determinado\n            doc_id.\n            exemplo de doc_id: S0021-25712009000400007-spa\n        \"\"\"\n\n        headers = {'content-type': 'application/json'}\n\n        data = {\n            \"add\": {\n                \"doc\": {\n                    \"id\": doc_id\n                }\n            }\n        }\n\n        if citations:\n            data['add']['doc']['total_received'] = {'set': str(citations)}\n\n        if accesses:\n            data['add']['doc']['total_access'] = {'set': str(accesses)}\n\n        params = {'wt': 'json'}\n\n        response = self._do_request(\n            self.UPDATE_ENDPOINT,\n            params=params,\n            data=json.dumps(data),\n            headers=headers\n        )\n\n        if not response:\n            logger.debug('Document (%s) could not be updated' % doc_id)\n\n        logger.debug('Document (%s) updated' % doc_id)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _commit(self):\n\n        params = {'commit': 'true'}\n\n        response = self._do_request(\n            self.UPDATE_ENDPOINT,\n            params=params\n        )\n\n        if response and response.status_code == 200:\n            logger.debug('Index commited')\n            return None\n\n        logger.warning('Fail to commite index')", "response": "Envia requisi\u00e7\u00e3o de commit do indice atrav\u00e9s da API."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending signal to process.", "response": "def process_kill(pid, sig=None):\n    \"\"\"Send signal to process.\n    \"\"\"\n    sig = sig or signal.SIGTERM\n    os.kill(pid, sig)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread pid from pidfile.", "response": "def load_pid(pidfile):\n    \"\"\"read pid from pidfile.\n    \"\"\"\n    if pidfile and os.path.isfile(pidfile):\n        with open(pidfile, \"r\", encoding=\"utf-8\") as fobj:\n            return int(fobj.readline().strip())\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_pidfile(pidfile):\n    pid = os.getpid()\n    if pidfile:\n        with open(pidfile, \"w\", encoding=\"utf-8\") as fobj:\n            fobj.write(six.u(str(pid)))\n    return pid", "response": "write current pid to pidfile."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the process with given pid is running", "response": "def is_running(pid):\n    \"\"\"check if the process with given pid still running\n    \"\"\"\n    process = get_process(pid)\n    if process and process.is_running() and process.status() != \"zombie\":\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef daemon_start(main, pidfile, daemon=True, workspace=None):\n    logger.debug(\"start daemon application pidfile={pidfile} daemon={daemon} workspace={workspace}.\".format(pidfile=pidfile, daemon=daemon, workspace=workspace))\n    new_pid = os.getpid()\n    workspace = workspace or os.getcwd()\n    os.chdir(workspace)\n    daemon_flag = False\n    if pidfile and daemon:\n        old_pid = load_pid(pidfile)\n        if old_pid:\n            logger.debug(\"pidfile {pidfile} already exists, pid={pid}.\".format(pidfile=pidfile, pid=old_pid))\n        # if old service is running, just exit.\n        if old_pid and is_running(old_pid):\n            error_message = \"Service is running in process: {pid}.\".format(pid=old_pid)\n            logger.error(error_message)\n            six.print_(error_message, file=os.sys.stderr)\n            os.sys.exit(95)\n        # clean old pid file.\n        clean_pid_file(pidfile)\n        # start as background mode if required and available.\n        if daemon and os.name == \"posix\":\n            make_basic_daemon()\n            daemon_flag = True\n    if daemon_flag:\n        logger.info(\"Start application in DAEMON mode, pidfile={pidfile} pid={pid}\".format(pidfile=pidfile, pid=new_pid))\n    else:\n        logger.info(\"Start application in FRONT mode, pid={pid}.\".format(pid=new_pid))\n    write_pidfile(pidfile)\n    atexit.register(clean_pid_file, pidfile)\n    main()\n    return", "response": "Start application in daemon mode if required and available."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_dicom(filename):\n    '''returns Boolean of whether the given file has the DICOM magic number'''\n    try:\n        with open(filename) as f:\n            d = f.read(132)\n            return d[128:132]==\"DICM\"\n    except:\n        return False", "response": "returns Boolean of whether the given file has the DICOM magic number"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a DicomInfo object containing the header information in filename", "response": "def info(filename):\n    '''returns a DicomInfo object containing the header information in ``filename``'''\n    try:\n        out = subprocess.check_output([_dicom_hdr,'-sexinfo',filename])\n    except subprocess.CalledProcessError:\n        return None\n    slice_timing_out = subprocess.check_output([_dicom_hdr,'-slice_times',filename])\n    slice_timing = [float(x) for x in slice_timing_out.strip().split()[5:]]\n    frames = []\n    for frame in re.findall(r'^(\\w{4}) (\\w{4})\\s+(\\d+) \\[(\\d+)\\s+\\] \\/\\/(.*?)\\/\\/(.*?)$',out,re.M):\n        new_frame = {}\n        new_frame['addr'] = (int(frame[0],16),int(frame[1],16))\n        new_frame['size'] = int(frame[2])\n        new_frame['offset'] = int(frame[3])\n        new_frame['label'] = frame[4].strip()\n        new_frame['value'] = frame[5].strip()\n        frames.append(new_frame)\n    sex_info = {}\n    for i in re.findall(r'^(.*?)\\s+= (.*)$',out,re.M):\n        sex_info[i[0]] = i[1]\n\n    return DicomInfo(frames,sex_info,slice_timing)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary for the given tags in the DICOM file filename", "response": "def info_for_tags(filename,tags):\n    '''return a dictionary for the given ``tags`` in the header of the DICOM file ``filename``\n\n    ``tags`` is expected to be a list of tuples that contains the DICOM address in hex values.\n\n    basically a rewrite of :meth:`info` because it's so slow. This is a lot faster and more reliable'''\n    if isinstance(tags,tuple):\n        tags = [tags]\n    d = pydicom.read_file(filename)\n    return_dict = {}\n    dicom_info = None\n    for k in tags:\n        if k in d:\n            return_dict[k] = d[k].value\n        else:\n            # Backup to the old method\n            if dicom_info==None:\n                dicom_info = info(filename)\n            i = dicom_info.addr(k)\n            if i:\n                return_dict[k] = nl.numberize(i['value'])\n    return return_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nscans a directory tree and returns a dictionary with files and key DICOM tags as keys and values of DICOM tags as values.", "response": "def scan_dir(dirname,tags=None,md5_hash=False):\n    '''scans a directory tree and returns a dictionary with files and key DICOM tags\n\n    return value is a dictionary absolute filenames as keys and with dictionaries of tags/values\n    as values\n\n    the param ``tags`` is the list of DICOM tags (given as tuples of hex numbers) that\n    will be obtained for each file. If not given,\n    the default list is:\n\n    :0008 0021:     Series date\n    :0008 0031:     Series time\n    :0008 103E:     Series description\n    :0008 0080:     Institution name\n    :0010 0020:     Patient ID\n    :0028 0010:     Image rows\n    :0028 0011:     Image columns\n\n    If the param ``md5_hash`` is ``True``, this will also return the MD5 hash of the file. This is useful\n    for detecting duplicate files\n    '''\n    if tags==None:\n        tags = [\n            (0x0008, 0x0021),\n            (0x0008, 0x0031),\n            (0x0008, 0x103E),\n            (0x0008, 0x0080),\n            (0x0010, 0x0020),\n            (0x0028, 0x0010),\n            (0x0028, 0x0011),\n        ]\n\n    return_dict = {}\n\n    for root,dirs,files in os.walk(dirname):\n        for filename in files:\n            fullname = os.path.join(root,filename)\n            if is_dicom(fullname):\n                return_dict[fullname] = info_for_tags(fullname,tags)\n                if md5_hash:\n                    return_dict[fullname]['md5'] = nl.hash(fullname)\n    return return_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_dups(file_dict):\n    '''takes output from :meth:`scan_dir` and returns list of duplicate files'''\n    found_hashes = {}\n    for f in file_dict:\n        if file_dict[f]['md5'] not in found_hashes:\n            found_hashes[file_dict[f]['md5']] = []\n        found_hashes[file_dict[f]['md5']].append(f)\n    final_hashes = dict(found_hashes)\n    for h in found_hashes:\n        if len(found_hashes[h])<2:\n            del(final_hashes[h])\n    return final_hashes.values()", "response": "takes output from scan_dir and returns list of duplicate files"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef max_diff(dset1,dset2):\n    '''calculates maximal voxel-wise difference in datasets (in %)\n\n    Useful for checking if datasets have the same data. For example, if the maximum difference is\n    < 1.0%, they're probably the same dataset'''\n    for dset in [dset1,dset2]:\n        if not os.path.exists(dset):\n            nl.notify('Error: Could not find file: %s' % dset,level=nl.level.error)\n            return float('inf')\n    try:\n        dset1_d = nib.load(dset1)\n        dset2_d = nib.load(dset2)\n        dset1_data = dset1_d.get_data()\n        dset2_data = dset2_d.get_data()\n    except IOError:\n        nl.notify('Error: Could not read files %s and %s' % (dset1,dset2),level=nl.level.error)\n        return float('inf')\n    try:\n        old_err = np.seterr(divide='ignore',invalid='ignore')\n        max_val = 100*np.max(np.ma.masked_invalid(np.double(dset1_data - dset2_data) / ((dset1_data+dset2_data)/2)))\n        np.seterr(**old_err)\n        return max_val\n    except ValueError:\n        return float('inf')", "response": "calculates maximal voxel - wise difference in datasets ( in % )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_dset(directory,slice_order='alt+z',sort_order='zt',force_slices=None):\n    '''tries to autocreate a dataset from images in the given directory'''\n    return _create_dset_dicom(directory,slice_order,sort_order,force_slices=force_slices)", "response": "tries to autocreate a dataset from images in the given directory"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef date_for_str(date_str):\n    '''tries to guess date from ambiguous date string'''\n    try:\n        for date_format in itertools.permutations(['%Y','%m','%d']):\n            try:\n                date = datetime.strptime(date_str,''.join(date_format))\n                raise StopIteration\n            except ValueError:\n                pass\n        return None\n    except StopIteration:\n        return date", "response": "tries to guess date from ambiguous date string"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef organize_dir(orig_dir):\n    '''scans through the given directory and organizes DICOMs that look similar into subdirectories\n\n    output directory is the ``orig_dir`` with ``-sorted`` appended to the end'''\n\n    tags = [\n        (0x10,0x20),    # Subj ID\n        (0x8,0x21),     # Date\n        (0x8,0x31),     # Time\n        (0x8,0x103e)    # Descr\n    ]\n    orig_dir = orig_dir.rstrip('/')\n    files = scan_dir(orig_dir,tags=tags,md5_hash=True)\n    dups = find_dups(files)\n    for dup in dups:\n        nl.notify('Found duplicates of %s...' % dup[0])\n        for each_dup in dup[1:]:\n            nl.notify('\\tdeleting %s' % each_dup)\n            try:\n                os.remove(each_dup)\n            except IOError:\n                nl.notify('\\t[failed]')\n            del(files[each_dup])\n\n    clustered = cluster_files(files)\n    output_dir = '%s-sorted' % orig_dir\n    for key in clustered:\n        if (0x8,0x31) in clustered[key]['info']:\n            clustered[key]['info'][(0x8,0x31)] = str(int(float(clustered[key]['info'][(0x8,0x31)])))\n        for t in tags:\n            if t not in clustered[key]['info']:\n                clustered[key]['info'][t] = '_'\n        run_name = '-'.join([scrub_fname(str(clustered[key]['info'][x])) for x in tags])+'-%d_images' %len(clustered[key]['files'])\n        run_dir = os.path.join(output_dir,run_name)\n        nl.notify('Moving files into %s' % run_dir)\n        try:\n            if not os.path.exists(run_dir):\n                os.makedirs(run_dir)\n        except IOError:\n            nl.notify('Error: failed to create directory %s' % run_dir)\n        else:\n            for f in clustered[key]['files']:\n                try:\n                    dset_fname = os.path.split(f)[1]\n                    if dset_fname[0]=='.':\n                        dset_fname = '_' + dset_fname[1:]\n                    os.rename(f,os.path.join(run_dir,dset_fname))\n                except (IOError, OSError):\n                    pass\n    for r,ds,fs in os.walk(output_dir,topdown=False):\n        for d in ds:\n            dname = os.path.join(r,d)\n            if len(os.listdir(dname))==0:\n                os.remove(dname)", "response": "scans through the given directory and organizes DICOMs that look similar into subdirectories\n    output directory is the original_dir with - sorted appended to the end"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef classify(label_dict,image_fname=None,image_label=None):\n    '''tries to classify a DICOM image based on known string patterns (with fuzzy matching)\n\n    Takes the label from the DICOM header and compares to the entries in ``label_dict``. If it finds something close\n    it will return the image type, otherwise it will return ``None``. Alternatively, you can supply your own string, ``image_label``,\n    and it will try to match that.\n\n    ``label_dict`` is a dictionary where the keys are dataset types and the values are lists of strings that match that type.\n    For example::\n\n        {\n            'anatomy': ['SPGR','MPRAGE','anat','anatomy'],\n            'dti': ['DTI'],\n            'field_map': ['fieldmap','TE7','B0']\n        }\n    '''\n    min_acceptable_match = 80\n    if image_fname:\n        label_info = info_for_tags(image_fname,[(0x8,0x103e)])\n        image_label = label_info[(0x8,0x103e)]\n    # creates a list of tuples: (type, keyword)\n    flat_dict = [i for j in [[(b,x) for x in label_dict[b]]  for b in label_dict] for i in j]\n    best_match = process.extractOne(image_label,[x[1] for x in flat_dict])\n    if best_match[1]<min_acceptable_match:\n        return None\n    else:\n        return [x[0] for x in flat_dict if x[1]==best_match[0]][0]", "response": "Tries to classify a DICOM image based on known string patterns and returns the image type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsort input_dir and tries to reconstruct the subdirectories found", "response": "def reconstruct_files(input_dir):\n    '''sorts ``input_dir`` and tries to reconstruct the subdirectories found'''\n    input_dir = input_dir.rstrip('/')\n    with nl.notify('Attempting to organize/reconstruct directory'):\n        # Some datasets start with a \".\", which confuses many programs\n        for r,ds,fs in os.walk(input_dir):\n            for f in fs:\n                if f[0]=='.':\n                    shutil.move(os.path.join(r,f),os.path.join(r,'i'+f))\n        nl.dicom.organize_dir(input_dir)\n        output_dir = '%s-sorted' % input_dir\n        if os.path.exists(output_dir):\n            with nl.run_in(output_dir):\n                for dset_dir in os.listdir('.'):\n                    with nl.notify('creating dataset from %s' % dset_dir):\n                        nl.dicom.create_dset(dset_dir)\n        else:\n            nl.notify('Warning: failed to auto-organize directory %s' % input_dir,level=nl.level.warning)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unpack_archive(fname,out_dir):\n    '''unpacks the archive file ``fname`` and reconstructs datasets into ``out_dir``\n\n    Datasets are reconstructed and auto-named using :meth:`create_dset`. The raw directories\n    that made the datasets are archive with the dataset name suffixed by ``tgz``, and any other\n    files found in the archive are put into ``other_files.tgz``'''\n    with nl.notify('Unpacking archive %s' % fname):\n        tmp_dir = tempfile.mkdtemp()\n        tmp_unpack = os.path.join(tmp_dir,'unpack')\n        os.makedirs(tmp_unpack)\n        nl.utils.unarchive(fname,tmp_unpack)\n        reconstruct_files(tmp_unpack)\n        out_dir = os.path.abspath(out_dir)\n        if not os.path.exists(out_dir):\n            os.makedirs(out_dir)\n        if not os.path.exists(tmp_unpack+'-sorted'):\n            return\n        with nl.run_in(tmp_unpack+'-sorted'):\n            for fname in glob.glob('*.nii'):\n                nl.run(['gzip',fname])\n            for fname in glob.glob('*.nii.gz'):\n                new_file = os.path.join(out_dir,fname)\n                if not os.path.exists(new_file):\n                    shutil.move(fname,new_file)\n            raw_out = os.path.join(out_dir,'raw')\n            if not os.path.exists(raw_out):\n                os.makedirs(raw_out)\n            for rawdir in os.listdir('.'):\n                rawdir_tgz = os.path.join(raw_out,rawdir+'.tgz')\n                if not os.path.exists(rawdir_tgz):\n                    with tarfile.open(rawdir_tgz,'w:gz') as tgz:\n                        tgz.add(rawdir)\n        if len(os.listdir(tmp_unpack))!=0:\n            # There are still raw files left\n            with tarfile.open(os.path.join(raw_out,'other_files.tgz'),'w:gz') as tgz:\n                tgz.add(tmp_unpack)\n    shutil.rmtree(tmp_dir)", "response": "unpacks the archive file fname and reconstructs datasets into out_dir"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addr(self,address):\n        '''returns dictionary with frame information for given address (a tuple of two hex numbers)'''\n        if isinstance(address,basestring):\n            # If you just gave me a single string, assume its \"XXXX XXXX\"\n            addr = address.split()\n        else:\n            addr = list(address)\n        # Convert to actual hex if you give me strings\n        for i in xrange(len(addr)):\n            if isinstance(addr[i],basestring):\n                addr[i] = int(addr[i],16)\n        for frame in self.raw_frames:\n            if frame['addr']==address:\n                return frame", "response": "returns dictionary with frame information for given address"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _generate_mark_code(rule_name):\n    code = ''.join([i for i in str(rule_name) if i.isdigit()])\n    code = code.zfill(2)\n    return code", "response": "Generates a two digit string based on a provided string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate a filename against a pattern.", "response": "def rule_n5xx(filename, rule_name, rule_conf, class_type):\n    \"\"\"Validate filename against a pattern if the filename passes the filter.\n\n    Args:\n        filename (str): The name of the file being parsed by flake8.\n        rule_name (str): The name of the rule.\n        rule_conf (dict): The dictionary containing the properties of the rule\n        class_type (class): The class that this rule was called from\n\n    Yields:\n        tuple: (int, int, str, type) the tuple used by flake8 to construct a violation\n    \"\"\"\n\n    line_num = 0\n    code = _generate_mark_code(rule_name)\n    message = \"N5{} filename failed regex validation '{}'\".format(code, rule_conf['filename_regex'])\n\n    sanitized_filename = splitext(basename(filename))[0]    # Strip path and extension\n\n    if re.match(rule_conf['filter_regex'], sanitized_filename):\n        if not re.match(rule_conf['filename_regex'], sanitized_filename):\n            yield (line_num, 0, message, class_type)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning wrapper that limits the amount of time it has to run optional args: seconds - how long it has until the function times out default_output - what will be returned instead of an error", "response": "def timeout(seconds=10, default_output='default_output'):\n    \"\"\" function wrapper that limits the amount of time it has to run\n    optional args:\n        seconds - how long it has until the function times out\n        default_output - what will be returned instead of an error\n    \"\"\"\n    def decorator(func):\n        def _handle_timeout(signum, frame):\n            \"\"\" throw the custom TimeoutError if called \"\"\"\n            raise TimeoutError(strerror(ETIME))\n\n        def wrapper(*args, **kwargs):\n            \"\"\" main wrapper for the error \"\"\"\n            # set up the propper error signal\n            signal(SIGALRM, _handle_timeout)\n            # set the time the function has to run\n            alarm(seconds)\n            try:\n                result = func(*args, **kwargs)\n            except TimeoutError:\n                if default_output == 'default_output':\n                    raise\n                else:\n                    result = default_output\n            finally:\n                # cancel the timer\n                alarm(0)\n            return result\n\n        return wraps(func)(wrapper)\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef triplifyGML(dpath=\"../data/fb/\",fname=\"foo.gdf\",fnamei=\"foo_interaction.gdf\",\n        fpath=\"./fb/\",scriptpath=None,uid=None,sid=None,fb_link=None,ego=True,umbrella_dir=None):\n    \"\"\"Produce a linked data publication tree from a standard GML file.\n\n    INPUTS:\n    ======\n    => the data directory path\n    => the file name (fname) of the friendship network\n    => the file name (fnamei) of the interaction network\n    => the final path (fpath) for the tree of files to be created\n    => a path to the script that is calling this function (scriptpath)\n    => the numeric id (uid) of the facebook user or group of the network(s)\n    => the numeric id (sid) of the facebook user or group of the network (s)\n    => the facebook link (fb_link) of the user or group\n    => the network is from a user (ego==True) or a group (ego==False)\n\n    OUTPUTS:\n    =======\n    the tree in the directory fpath.\"\"\"\n    c(\"iniciado tripgml\")\n    if sum(c.isdigit() for c in fname)==4:\n        year=re.findall(r\".*(\\d\\d\\d\\d).gml\",fname)[0][0]\n        B.datetime_snapshot=datetime.date(*[int(i) for i in (year)])\n    if sum(c.isdigit() for c in fname)==12:\n        day,month,year,hour,minute=re.findall(r\".*(\\d\\d)(\\d\\d)(\\d\\d\\d\\d)_(\\d\\d)(\\d\\d).gml\",fname)[0]\n        B.datetime_snapshot=datetime.datetime(*[int(i) for i in (year,month,day,hour,minute)])\n    if sum(c.isdigit() for c in fname)==14:\n        day,month,year,hour,minute,second=re.findall(r\".*(\\d\\d)(\\d\\d)(\\d\\d\\d\\d)_(\\d\\d)(\\d\\d)(\\d\\d).gml\",fname)[0]\n        B.datetime_snapshot=datetime.datetime(*[int(i) for i in (year,month,day,hour,minute,second)])\n    elif sum(c.isdigit() for c in fname)==8:\n        day,month,year=re.findall(r\".*(\\d\\d)(\\d\\d)(\\d\\d\\d\\d).gml\",fname)[0]\n        B.datetime_snapshot=datetime.date(*[int(i) for i in (year,month,day)])\n    B.datetime_snapshot_=datetime_snapshot.isoformat()\n    B.fname=fname\n    B.fnamei=fnamei\n    B.name=fname.replace(\".gml\",\"_gml\")\n    if fnamei:\n        B.namei=fnamei[:-4]\n    B.ego=ego\n    B.friendship=bool(fname)\n    B.interaction=bool(fnamei)\n    B.sid=sid\n    B.uid=uid\n    B.scriptpath=scriptpath\n    B.fb_link=fb_link\n    B.dpath=dpath\n    B.fpath=fpath\n    B.prefix=\"https://raw.githubusercontent.com/OpenLinkedSocialData/{}master/\".format(umbrella_dir)\n    B.umbrella_dir=umbrella_dir\n    c(\"antes de ler\")\n    #fnet=S.fb.readGML(dpath+fname)     # return networkx graph\n    fnet=S.fb.readGML2(dpath+fname)     # return networkx graph\n#    return fnet\n    c(\"depois de ler, antes de fazer rdf\")\n    fnet_=rdfFriendshipNetwork(fnet)   # return rdflib graph\n    if B.interaction:\n        inet=S.fb.readGML(dpath+fnamei)    # return networkx graph\n        inet_=rdfInteractionNetwork(inet)      # return rdflib graph\n    else:\n        inet_=0\n    meta=makeMetadata(fnet_,inet_)     # return rdflib graph with metadata about the structure\n    c(\"depois de rdf, escrita em disco\")\n    writeAllFB(fnet_,inet_,meta)  # write linked data tree\n    c(\"cabo\")", "response": "Produce a linked data publication tree from a standard GML file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register(self, *args, **kwargs):\n        '''\n        \u8c03\u7528\u65b9\u53ef\u6839\u636e\u4e3b\u952e\u5b57\u6bb5\u8fdb\u884c\u722c\u866b\u7684\u521b\u5efa\u6216\u66f4\u65b0\u64cd\u4f5c\n\n        :return: \u8fd4\u56de\u7b26\u5408\u63a5\u53e3\u5b9a\u4e49\u7684\u5b57\u5178\u6570\u636e\n        :rtype: dict\n        '''\n        return {\n            'name': zhihu.name,\n            'display_name': zhihu.display_name,\n            'author': zhihu.author,\n            'email': zhihu.email,\n            'description': zhihu.description,\n            'meta': {\n                # \u722c\u53d6\u8ba1\u5212\uff0c\u53c2\u8003 crontab \u914d\u7f6e\u65b9\u6cd5\n                'crawl_schedule': '0 23 * * *',\n\n                # \u6267\u884c\u722c\u53d6\u7684\u968f\u673a\u5ef6\u65f6\uff0c\u5355\u4f4d\u79d2\uff0c\u7528\u4e8e\u907f\u514d\u88ab Ban\n                'crawl_random_delay': str(60 * 60),\n\n                'package_module': 'mobi',\n                'language': 'zh-CN',\n                'book_mode': 'periodical',  # 'periodical' | 'book'\n                'img_cover': os.path.join(\n                    _images_path, 'cv_zhihudaily.jpg'),\n                'img_masthead': os.path.join(\n                    _images_path, 'mh_zhihudaily.gif'),\n                'image_filter': json.dumps(['zhihu.com/equation']),\n                'css_package': os.path.join(\n                    _css_path, 'package.css')\n            }\n        }", "response": "Register a new CMI - ZHihU."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncrawling a file and return a dict", "response": "def crawl(self, *args, **kwargs):\n        '''\n        \u6267\u884c\u722c\u53d6\u64cd\u4f5c\uff0c\u5e76\u963b\u585e\u76f4\u5230\u722c\u53d6\u5b8c\u6210\uff0c\u8fd4\u56de\u7ed3\u679c\u6570\u636e\u3002\n        \u6b64\u5904\u8003\u8651\u5230 Scrapy \u672c\u8eab\u7684\u5e76\u53d1\u7279\u6027\uff0c\u6545\u901a\u8fc7\u4e34\u65f6\u6587\u4ef6\u65b9\u5f0f\u505a\u6570\u636e\u4f20\u9012\uff0c\n        \u5c06\u4e34\u65f6\u8def\u5f84\u4f20\u9012\u5230\u722c\u866b\u4e1a\u52a1\u4e2d\uff0c\u5e76\u5728\u722c\u53d6\u7ed3\u675f\u540e\u5bf9\u6587\u4ef6\u8fdb\u884c\u8bfb\u53d6\u3001 JSON \u53cd\u5e8f\u5217\u5316\uff0c\u8fd4\u56de\n\n        :return: \u8fd4\u56de\u7b26\u5408\u63a5\u53e3\u5b9a\u4e49\u7684\u5b57\u5178\u5bf9\u8c61\n        :rtype: dict\n        '''\n        temp = tempfile.NamedTemporaryFile(mode='w+t')\n\n        try:\n            crawler = CrawlerScript()\n            # \u8c03\u8bd5\u65f6\u53ef\u6307\u5b9a\u660e\u786e\u65e5\u671f\u53c2\u6570\uff0c\u5982\uff1adate='20180423'\n            crawler.crawl(output_file=temp.name, *args, **kwargs)\n\n            temp.seek(0)\n            content = json.loads(temp.read(), encoding='UTF-8')\n        finally:\n            temp.close()\n\n        print('\u6293\u53d6\u5b8c\u6bd5\uff01')\n        return content"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nformatting a list of post data", "response": "def format(self, data, *args, **kwargs):\n        '''\n        \u5c06\u4f20\u5165\u7684Post\u5217\u8868\u6570\u636e\u8fdb\u884c\u683c\u5f0f\u5316\u5904\u7406\u3002\u6b64\u5904\u4f20\u5165\u7684 ``data`` \u683c\u5f0f\u5373\u4e3a\n        :meth:`.ZhihuDaily.crawl` \u8fd4\u56de\u7684\u683c\u5f0f\uff0c\u4f46\u5177\u4f53\u5185\u5bb9\u53ef\u4ee5\u4e0d\u540c\uff0c\u5373\u6b64\u5904\u4fdd\u7559\u4e86\u7075\u6d3b\u5ea6\uff0c\n        \u53ef\u4ee5\u5bf9\u975e\u5f53\u65e5\u6587\u7ae0\u5bf9\u8c61\u8fdb\u884c\u683c\u5f0f\u5316\uff0c\u5236\u4f5c\u76f8\u5173\u4e3b\u9898\u7684\u5408\u96c6\u4e66\u7c4d\n\n        :param data: \u5f85\u5904\u7406\u7684\u6587\u7ae0\u5217\u8868\n        :type data: list\n\n        :return: \u8fd4\u56de\u7b26\u5408mobi\u6253\u5305\u9700\u6c42\u7684\u5b9a\u5236\u5316\u6570\u636e\u7ed3\u6784\n        :rtype: dict\n        '''\n        sections = OrderedDict()\n        hot_list = []\n        normal_list = []\n        for item in data:\n            meta = item.get('meta', [])\n\n            # \u5982\u679c\u6807\u9898\u4e3a\u7a7a\uff0c\u5219\u8fed\u4ee3\u4e0b\u4e00\u6761\u76ee\n            if not item.get('title'):\n                continue\n\n            soup = BeautifulSoup(item.get('content'), \"lxml\")\n\n            # \u6e05\u6d17\u6587\u7ae0\u5185\u5bb9\uff0c\u53bb\u9664\u65e0\u7528\u5185\u5bb9\n            for view_more in soup.select('.view-more'):\n                view_more.extract()\n            item['content'] = str(soup.div)\n\n            # \u5904\u7406\u6587\u7ae0\u6458\u8981\uff0c\u82e5\u4e3a\u7a7a\u5219\u6839\u636e\u6b63\u6587\u81ea\u52a8\u751f\u6210\u5e76\u586b\u5145\n            if not item.get('excerpt') and item.get('content'):\n                word_limit = self.options.get(\n                    'toc_desc_word_limit', 500)\n                content_list = soup.select('div.content')\n                content_list = [content.get_text() for content in content_list]\n                excerpt = ' '.join(content_list)[:word_limit]\n                # \u6b64\u5904\u6458\u8981\u4fe1\u606f\u9700\u8fdb\u884cHTML\u8f6c\u4e49\uff0c\u5426\u5219\u4f1a\u9020\u6210toc.ncx\u4e2dtag\u5904\u7406\u9519\u8bef\n                item['excerpt'] = html.escape(excerpt)\n\n            # \u4eceitem\u4e2d\u63d0\u53d6\u51fasection\u5206\u7ec4\n            top = meta.pop('spider.zhihu_daily.top', '0')\n            item['meta'] = meta\n            if str(top) == '1':\n                hot_list.append(item)\n            else:\n                normal_list.append(item)\n\n        if hot_list:\n            sections.setdefault('\u70ed\u95fb', hot_list)\n        if normal_list:\n            sections.setdefault('\u65e5\u62a5', normal_list)\n        return sections"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef upsert_many(col, data):\n    ready_to_insert = list()\n    for doc in data:\n        res = col.update({\"_id\": doc[\"_id\"]}, {\"$set\": doc}, upsert=False)\n        # \u6ca1\u6709\u4efb\u4f55\u6570\u636e\u88ab\u4fee\u6539, \u4e14\u4e0d\u662f\u56e0\u4e3a\u6570\u636e\u5b58\u5728\u4f46\u503c\u76f8\u540c\n        if res[\"nModified\"] == 0 and res[\"updatedExisting\"] is False:\n            ready_to_insert.append(doc)\n    col.insert(ready_to_insert)", "response": "Insert many documents in a collection."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nproduce a linked data publication tree from a standard GML file.", "response": "def triplifyGML(fname=\"foo.gml\",fpath=\"./fb/\",scriptpath=None,uid=None,sid=None,extra_info=None):\n    \"\"\"Produce a linked data publication tree from a standard GML file.\n\n    INPUTS:\n    => the file name (fname, with path) where the gdf file\n    of the friendship network is.\n\n    => the final path (fpath) for the tree of files to be created.\n    \n    => a path to the script that is calling this function (scriptpath).\n\n    => the numeric id (uid) of the facebook user of which fname holds a friendship network \n    \n    => the numeric id (sid) of the facebook user of which fname holds a friendship network \n\n    OUTPUTS:\n    the tree in the directory fpath.\"\"\"\n\n#    aname=fname.split(\"/\")[-1].split(\".\")[0]\n    aname=fname.split(\"/\")[-1].split(\".\")[0]\n    if \"RonaldCosta\" in fname:\n        aname=fname.split(\"/\")[-1].split(\".\")[0]\n        name,day,month,year=re.findall(\".*/([a-zA-Z]*)(\\d\\d)(\\d\\d)(\\d\\d\\d\\d).gml\",fname)[0]\n        datetime_snapshot=datetime.datetime(*[int(i) for i in (year,month,day)]).isoformat().split(\"T\")[0]\n        name_=\"Ronald Scherolt Costa\"\n    elif \"AntonioAnzoategui\" in fname:\n        aname=re.findall(\".*/([a-zA-Z]*\\d*)\",fname)[0]\n        name,year,month,day,hour,minute=re.findall(r\".*/([a-zA-Z]*).*_(\\d+)_(\\d*)_(\\d*)_(\\d*)_(\\d*)_.*\",fname)[0]\n        datetime_snapshot=datetime.datetime(*[int(i) for i in (year,month,day,hour,minute)]).isoformat()[:-3]\n        name_=\"Ant\u00f4nio Anzoategui Fabbri\"\n    elif re.findall(\".*/[a-zA-Z]*(\\d)\",fname):\n        name,day,month,year=re.findall(\".*/([a-zA-Z]*)(\\d\\d)(\\d\\d)(\\d\\d\\d\\d).*.gml\",fname)[0]\n        datetime_snapshot=datetime.datetime(*[int(i) for i in (year,month,day)]).isoformat().split(\"T\")[0]\n        name_=\" \".join(re.findall(\"[A-Z][^A-Z]*\",name))\n    elif re.findall(\"[a-zA-Z]*_\",fname):\n        name,year,month,day,hour,minute=re.findall(\".*/([a-zA-Z]*).*(\\d\\d\\d\\d)_(\\d\\d)_(\\d\\d)_(\\d\\d)_(\\d\\d).*.gml\",fname)[0]\n        datetime_snapshot=datetime.datetime(*[int(i) for i in (year,month,day,hour,minute)]).isoformat().split(\"T\")[0]\n        name_=\" \".join(re.findall(\"[A-Z][^A-Z]*\",name))\n    else:\n        name_=\" \".join(re.findall(\"[A-Z][^A-Z]*\",name))\n    aname+=\"_fb\"\n    name+=\"_fb\"\n    c(\"started snapshot\",aname)\n    tg=P.rdf.makeBasicGraph([[\"po\",\"fb\"],[P.rdf.ns.per,P.rdf.ns.fb]],\"the {} facebook ego friendship network\")\n    tg2=P.rdf.makeBasicGraph([[\"po\",\"fb\"],[P.rdf.ns.per,P.rdf.ns.fb]],\"RDF metadata for the facebook friendship network of my son\")\n    snapshot=P.rdf.IC([tg2],P.rdf.ns.po.FacebookSnapshot,\n            aname,\"Snapshot {}\".format(aname))\n    extra_uri=extra_val=[]\n    if extra_info:\n        extra_uri=[NS.po.extraInfo]\n        extra_val=[extra_info]\n    P.rdf.link([tg2],snapshot,\"Snapshot {}\".format(aname),\n                          [P.rdf.ns.po.createdAt,\n                          P.rdf.ns.po.triplifiedIn,\n                          P.rdf.ns.po.donatedBy,\n                          P.rdf.ns.po.availableAt,\n                          P.rdf.ns.po.originalFile,\n                          P.rdf.ns.po.onlineTranslateXMLFile,\n                          P.rdf.ns.po.onlineTranslateTTLFile,\n                          P.rdf.ns.po.translateXMLFile,\n                          P.rdf.ns.po.translateTTLFile,\n                           P.rdf.ns.po.onlineMetaXMLFile,\n                           P.rdf.ns.po.onlineMetaTTLFile,\n                           P.rdf.ns.po.metaXMLFilename,\n                           P.rdf.ns.po.metaTTLFilename,\n                          P.rdf.ns.po.acquiredThrough,\n                          P.rdf.ns.rdfs.comment,\n                          P.rdf.ns.fb.uid,\n                          P.rdf.ns.fb.sid\n                          ]+extra_uri,\n                          [datetime_snapshot,\n                           datetime.datetime.now(),\n                           name,\n                           \"https://github.com/ttm/{}\".format(aname),\n                           \"https://raw.githubusercontent.com/ttm/{}/master/base/{}\".format(aname,fname.split(\"/\")[-1]),\n                           \"https://raw.githubusercontent.com/ttm/{}/master/rdf/{}Translate.rdf\".format(aname,aname),\n                           \"https://raw.githubusercontent.com/ttm/{}/master/rdf/{}Translate.ttl\".format(aname,aname),\n                           \"{}Translate.rdf\".format(aname),\n                           \"{}Translate.ttl\".format(aname),\n                            \"https://raw.githubusercontent.com/ttm/{}/master/rdf/{}Meta.rdf\".format(aname,aname),\n                                \"https://raw.githubusercontent.com/ttm/{}/master/rdf/{}Meta.ttl\".format(aname,aname),\n                                \"{}Meta.owl\".format(aname),\n                                \"{}Meta.ttl\".format(aname),\n                           \"Netvizz\",\n                                \"The facebook friendship network from {}\".format(name_),\n                                uid,\n                                sid\n                           ]+extra_val)\n    #for friend_attr in fg2[\"friends\"]:\n    c((aname,name_,datetime_snapshot))\n    fg2=x.read_gml(fname)\n    c(\"read gml\")\n    for uid in fg2:\n        c(uid)\n        ind=P.rdf.IC([tg],P.rdf.ns.fb.Participant,\"{}-{}\".format(aname,uid))\n        if \"locale\" in fg2.node[uid].keys():\n            data=[fg2.node[uid][attr] for attr in (\"id\",\"label\",\"locale\",\"sex\",\"agerank\",\"wallcount\")]\n            uris=[NS.fb.gid,    NS.fb.name,\n                  NS.fb.locale, NS.fb.sex,\n                  NS.fb.agerank,NS.fb.wallcount]\n        else:\n            data=[fg2.node[uid][attr] for attr in (\"id\",\"label\",\"sex\",\"agerank\",\"wallcount\")]\n            uris=[NS.fb.gid,    NS.fb.name,\n                  NS.fb.sex,\n                  NS.fb.agerank,NS.fb.wallcount]\n        P.rdf.link([tg],ind, None,uris,data,draw=False)\n        P.rdf.link_([tg],ind,None,[NS.po.snapshot],[snapshot],draw=False)\n\n\n    #friends_=[fg2[\"friends\"][i] for i in (\"name\",\"label\",\"locale\",\"sex\",\"agerank\")]\n    #for name,label,locale,sex,agerank in zip(*friends_):\n    #    ind=P.rdf.IC([tg],P.rdf.ns.fb.Participant,name,label)\n    #    P.rdf.link([tg],ind,label,[P.rdf.ns.fb.uid,P.rdf.ns.fb.name,\n    #                    P.rdf.ns.fb.locale,P.rdf.ns.fb.sex,\n    #                    P.rdf.ns.fb.agerank],\n    #                    [name,label,locale,sex,agerank])\n\n    c(\"escritos participantes\")\n    #friendships_=[fg2[\"friendships\"][i] for i in (\"node1\",\"node2\")]\n    i=1\n    for uid1,uid2 in fg2.edges():\n        flabel=\"{}-{}-{}\".format(aname,uid1,uid2)\n        ind=P.rdf.IC([tg],P.rdf.ns.fb.Friendship,flabel)\n        uids=[P.rdf.IC(None,P.rdf.ns.fb.Participant,\"{}-{}\".format(aname,i)) for i in (uid1,uid2)]\n        P.rdf.link_([tg],ind,flabel,[NS.po.snapshot]+[NS.fb.member]*2,\n                                    [snapshot]+uids,draw=False)\n        P.rdf.L_([tg],uids[0],P.rdf.ns.fb.friend,uids[1])\n        if (i%1000)==0:\n            c(i)\n        i+=1\n    c(\"escritas amizades\")\n    tg_=[tg[0]+tg2[0],tg[1]]\n    fpath_=\"{}/{}/\".format(fpath,aname)\n    P.rdf.writeAll(tg_,aname+\"Translate\",fpath_,False,1)\n    # copia o script que gera este codigo\n    if not os.path.isdir(fpath_+\"scripts\"):\n        os.mkdir(fpath_+\"scripts\")\n    #shutil.copy(this_dir+\"/../tests/rdfMyFNetwork2.py\",fpath+\"scripts/\")\n    shutil.copy(scriptpath,fpath_+\"scripts/\")\n    # copia do base data\n    if not os.path.isdir(fpath_+\"base\"):\n        os.mkdir(fpath_+\"base\")\n    shutil.copy(fname,fpath_+\"base/\")\n    P.rdf.writeAll(tg2,aname+\"Meta\",fpath_,False)\n    # faz um README\n    with open(fpath_+\"README\",\"w\") as f:\n        f.write(\"\"\"This repo delivers RDF data from the facebook\nfriendship network of {} ({}) collected at {}.\nIt has {} friends with metadata {};\nand {} friendships.\nThe linked data is available at rdf/ dir and was\ngenerated by the routine in the script/ directory.\nOriginal data from Netvizz in data/\\n\"\"\".format(\n            name_,aname,datetime_snapshot,\n            fg2.number_of_nodes(),\n                    \"name, locale (maybe), sex, agerank and wallcount\",\n                    fg2.number_of_edges()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nproducing a linked data publication tree from GDF files of a Facebook interaction network. INPUTS: => the file name (fname, with path) where the gdf file of the friendship network is. => the final path (fpath) for the tree of files to be created. => a path to the script that is calling this function (scriptpath). => the numeric id (uid) of the facebook group => the string id (sid) of the facebook group of which fname holds a friendship network OUTPUTS: the tree in the directory fpath.", "response": "def triplifyGDFInteraction(fname=\"foo.gdf\",fpath=\"./fb/\",scriptpath=None,uid=None,sid=None,dlink=None):\n    \"\"\"Produce a linked data publication tree from GDF files of a Facebook interaction network.\n\n    INPUTS:\n    => the file name (fname, with path) where the gdf file\n    of the friendship network is.\n\n    => the final path (fpath) for the tree of files to be created.\n    \n    => a path to the script that is calling this function (scriptpath).\n\n    => the numeric id (uid) of the facebook group\n    \n    => the string id (sid) of the facebook group of which fname holds a friendship network \n\n    OUTPUTS:\n    the tree in the directory fpath.\"\"\"\n    #aname=fname.split(\"/\")[-1].split(\".\")[0]+\"_fb\"\n    aname=fname.split(\"/\")[-1].split(\".\")[0]\n    if re.findall(\"[a-zA-Z]*_[0-9]\",fname):\n        name,year,month,day,hour,minute=re.findall(\".*/([a-zA-Z]*).*(\\d\\d\\d\\d)_(\\d\\d)_(\\d\\d)_(\\d\\d)_(\\d\\d).*.gdf\",fname)[0]\n        datetime_snapshot=datetime.datetime(*[int(i) for i in (year,month,day,hour,minute)]).isoformat().split(\"T\")[0]\n        name_=\" \".join(re.findall(\"[A-Z][^A-Z]*\",name))\n    elif re.findall(\"(\\d)\",fname):\n        name,day,month,year=re.findall(\".*/([a-zA-Z]*)(\\d\\d)(\\d\\d)(\\d\\d\\d\\d).*.gdf\",fname)[0]\n        datetime_snapshot=datetime.datetime(*[int(i) for i in (year,month,day)]).isoformat().split(\"T\")[0]\n        name_=\" \".join(re.findall(\"[A-Z][^A-Z]*\",name))\n    else:\n        datetime_snapshot=datetime.datetime(2013,3,15).isoformat().split(\"T\")[0]\n        name_=\" \".join(re.findall(\"[A-Z][^A-Z]*\",aname))\n    aname+=\"_fb\"\n    name=aname\n\n\n    tg=P.rdf.makeBasicGraph([[\"po\",\"fb\"],[P.rdf.ns.per,P.rdf.ns.fb]],\"The facebook interaction network from the {} file\".format(fname)) # drop de agraph\n    tg2=P.rdf.makeBasicGraph([[\"po\"],[P.rdf.ns.per]],\"Metadata for my facebook ego friendship network RDF files\") # drop de agraph\n    ind=P.rdf.IC([tg2],P.rdf.ns.po.Snapshot,\n            aname,\"Snapshot {}\".format(aname))\n\n    foo={\"uris\":[],\"vals\":[]}\n    if sid:\n        foo[\"uris\"].append(P.rdf.ns.fb.sid)\n        foo[\"vals\"].append(sid)\n    if uid:\n        foo[\"uris\"].append(P.rdf.ns.fb.uid)\n        foo[\"vals\"].append(uid)\n    if dlink:\n        foo[\"uris\"].append(P.rdf.ns.fb.link)\n        foo[\"vals\"].append(dlink)\n    P.rdf.link([tg2],ind,\"Snapshot {}\".format(aname),\n                        [P.rdf.ns.po.createdAt,\n                          P.rdf.ns.po.triplifiedIn,\n                          P.rdf.ns.po.donatedBy,\n                          P.rdf.ns.po.availableAt,\n                          P.rdf.ns.po.originalFile,\n                          P.rdf.ns.po.rdfFile,\n                          P.rdf.ns.po.ttlFile,\n                          P.rdf.ns.po.discorveryRDFFile,\n                          P.rdf.ns.po.discoveryTTLFile,\n                          P.rdf.ns.po.acquiredThrough,\n                          P.rdf.ns.rdfs.comment,\n                          ]+foo[\"uris\"],\n                          [datetime_snapshot,\n                           datetime.datetime.now(),\n                           name,\n                           \"https://github.com/ttm/{}\".format(aname),\n                           \"https://raw.githubusercontent.com/ttm/{}/master/base/{}\".format(aname,fname.split(\"/\")),\n                           \"https://raw.githubusercontent.com/ttm/{}/master/rdf/{}Translate.owl\".format(aname,aname),\n                           \"https://raw.githubusercontent.com/ttm/{}/master/rdf/{}Translate.ttl\".format(aname,aname),\n                                \"https://raw.githubusercontent.com/ttm/{}/master/rdf/{}Meta.owl\".format(aname,aname),\n                                \"https://raw.githubusercontent.com/ttm/{}/master/rdf/{}Meta.ttl\".format(aname,aname),\n                           \"Netvizz\",\n                                \"The facebook friendship network from {}\".format(name_),\n                           ]+foo[\"vals\"])\n    #for friend_attr in fg2[\"friends\"]:\n    fg2=readGDF(fname)\n    tkeys=list(fg2[\"friends\"].keys())\n    def trans(tkey):\n        if tkey==\"name\":\n            return \"uid\"\n        if tkey==\"label\":\n            return \"name\"\n        return tkey\n    foo={\"uris\":[],\"vals\":[]}\n    for tkey in tkeys:\n        if tkey==\"groupid\":\n            P.rdf.link([tg2],ind,\"Snapshot {}\".format(aname),\n                        [P.rdf.ns.po.uid,],\n                        [fg2[\"friends\"][tkey][0]])\n        if tkey:\n            foo[\"uris\"]+=[eval(\"P.rdf.ns.fb.\"+trans(tkey))]\n            foo[\"vals\"]+=[fg2[\"friends\"][tkey]]\n    print(tkeys)\n    iname=tkeys.index(\"name\")\n    ilabel=tkeys.index(\"label\")\n    icount=0\n    name_label={}\n    for vals_ in zip(*foo[\"vals\"]):\n        name,label=[foo[\"vals\"][i][icount] for i in (iname,ilabel)]\n        if not label:\n            label=\"po:noname\"\n            vals_=list(vals_)\n            vals_[ilabel]=label\n        name_label[name]=label\n        ind=P.rdf.IC([tg],P.rdf.ns.fb.Participant,name,label)\n        P.rdf.link([tg],ind,label,foo[\"uris\"],\n                        vals_,draw=False)\n        icount+=1\n\n    friendships_=[fg2[\"friendships\"][i] for i in (\"node1\",\"node2\")]\n    c(\"escritos participantes\")\n    i=1\n    for uid1,uid2 in zip(*friendships_):\n        flabel=\"{}-{}\".format(uid1,uid2)\n        labels=[name_label[uu] for uu in (uid1,uid2)]\n        ind=P.rdf.IC([tg],P.rdf.ns.fb.Friendship,\n                flabel)\n                #flabel,\"Friendship \"+flabel)\n        ind1=P.rdf.IC(None,P.rdf.ns.fb.Participant,uid1)\n        ind2=P.rdf.IC(None,P.rdf.ns.fb.Participant,uid2)\n        uids=[r.URIRef(P.rdf.ns.fb.Participant+\"#\"+str(i)) for i in (uid1,uid2)]\n        P.rdf.link_([tg],ind,\"Friendship \"+flabel,[P.rdf.ns.fb.member]*2,\n                            uids,labels,draw=False)\n        P.rdf.L_([tg],uids[0],P.rdf.ns.fb.friend,uids[1])\n        if (i%1000)==0:\n            c(i)\n        i+=1\n    P.rdf.G(tg[0],P.rdf.ns.fb.friend,\n            P.rdf.ns.rdf.type,\n            P.rdf.ns.owl.SymmetricProperty)\n    c(\"escritas amizades\")\n    tg_=[tg[0]+tg2[0],tg[1]]\n    fpath_=\"{}{}/\".format(fpath,aname)\n    P.rdf.writeAll(tg_,aname+\"Translate\",fpath_,False,1)\n    # copia o script que gera este codigo\n    if not os.path.isdir(fpath_+\"scripts\"):\n        os.mkdir(fpath_+\"scripts\")\n    shutil.copy(scriptpath,fpath_+\"scripts/\")\n    # copia do base data\n    if not os.path.isdir(fpath_+\"base\"):\n        os.mkdir(fpath_+\"base\")\n    shutil.copy(fname,fpath_+\"base/\")\n    P.rdf.writeAll(tg2,aname+\"Meta\",fpath_,1)\n    # faz um README\n    with open(fpath_+\"README\",\"w\") as f:\n        f.write(\"\"\"This repo delivers RDF data from the facebook\nfriendship network of {} collected at {}.\nIt has {} friends with metadata {};\nand {} friendships.\nThe linked data is available at rdf/ dir and was\ngenerated by the routine in the script/ directory.\nOriginal data from Netvizz in data/\\n\"\"\".format(\n            name_,datetime_snapshot,\n            len(fg2[\"friends\"][\"name\"]),\n                    \"facebook numeric id, name, locale, sex and agerank\",\n                    len(fg2[\"friendships\"][\"node1\"])\n                    ))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn user_ids that you have access to", "response": "def getFriends(self,user_id=\"astronauta.mecanico\",write=True):\n        \"\"\"Returns user_ids (that you have access) of the friends of your friend with user_ids\"\"\"\n        while user_id not in self.browser.url:\n            self.browser.visit(\"http://www.facebook.com/{}/friends\".format(user_id), wait_time=3)\n        #self.go(\"http://www.facebook.com/{}/friends\".format(user_id))\n        T=time.time()\n        while 1:\n            h1=self.browser.evaluate_script(\"document.body.scrollHeight\")\n            self.browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n            h2=self.browser.evaluate_script(\"document.body.scrollHeight\")\n            if h1 != h2:\n                T=time.time()\n            elif time.time()-T>10:\n                break\n        #links=self.browser.find_link_by_partial_href(\"hc_location=friends_tab\")\n        links=self.browser.find_by_css(\".fcb\")\n        friends=[]\n        for link in links:\n            name=link.value\n            user_id_=link.find_by_tag(\"a\")[\"href\"].split(\"/\")[-1].split(\"?\")[0]\n            friends.append((user_id_,name))\n        tdict={}\n        tdict[\"name\"]=self.browser.find_by_id(\"fb-timeline-cover-name\").value\n        tdict[\"user_id\"]=user_id\n        tdict[\"friends\"]=friends\n        infos=self.browser.find_by_css(\"._3c_\")\n        mutual=0\n        for info in infos:\n            if info.value==\"Mutual Friends\":\n                if info.find_by_css(\"._3d0\").value:\n                    tdict[\"n_mutual\"]=info.find_by_css(\"._3d0\").value\n                    mutual=1\n            if info.value==\"All Friends\":\n                    tdict[\"n_friends\"]=info.find_by_css(\"._3d0\").value\n        if mutual==0:\n            links=self.browser.find_by_css(\"._gs6\")\n            if \"Mutual\" in links.value:\n                tdict[\"n_mutual\"]=links.value.split(\" \")[0]\n        if write:\n            if not os.path.isdir(\"{}/fb_ids/\".format(self._BASE_DIR)):\n                os.mkdir(\"{}/fb_ids/\".format(self._BASE_DIR))\n            with open(\"{}fb_ids/{}.pickle\".format(self._BASE_DIR,user_id),\"wb\") as f:\n                pickle.dump(tdict,f)\n        self.tdict=tdict\n        return tdict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resolve(args):\n    if not args:\n        log.error('Exactly 1 argument is required.')\n        app.quit(1)\n    print(address.new(args[0]))", "response": "Just print the result of parsing a target string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build(args):\n\n    if len(args) != 1:\n        log.error('One target required.')\n        app.quit(1)\n\n    target = address.new(args[0])\n    log.info('Resolved target to: %s', target)\n\n    try:\n        bb = Butcher()\n        bb.clean()\n        bb.load_graph(target)\n        bb.build(target)\n    except (gitrepo.GitError,\n            error.BrokenGraph,\n            error.NoSuchTargetError) as err:\n        log.fatal(err)\n        app.quit(1)\n    except error.OverallBuildFailure as err:\n        log.fatal(err)\n        log.fatal('Error list:')\n        [log.fatal('  [%s]: %s', e.node, e) for e in bb.failure_log]\n        app.quit(1)", "response": "Build a target and its dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rebuild(args):\n    if len(args) != 1:\n        log.fatal('One target required.')\n        app.quit(1)\n\n    app.set_option('disable_cache_fetch', True)\n    Butcher.options['cache_fetch'] = False\n    build(args)", "response": "Rebuild a target and deps even if it has been built and cached."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload the build graph for a target and dump it to stdout.", "response": "def dump(args):\n    \"\"\"Load the build graph for a target and dump it to stdout.\"\"\"\n    if len(args) != 1:\n        log.error('One target required.')\n        app.quit(1)\n\n    try:\n        bb = Butcher()\n        bb.load_graph(args[0])\n    except error.BrokenGraph as lolno:\n        log.fatal(lolno)\n        app.quit(1)\n    print \"Nodes:\"\n    pprint.pprint(bb.graph.node)\n    print \"Edges:\"\n    pprint.pprint(bb.graph.edge)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the build graph for a target and render it to an image.", "response": "def draw(args):\n    \"\"\"Load the build graph for a target and render it to an image.\"\"\"\n    if len(args) != 2:\n        log.error('Two arguments required: [build target] [output file]')\n        app.quit(1)\n\n    target = args[0]\n    out = args[1]\n\n    try:\n        bb = Butcher()\n        bb.load_graph(target)\n    except error.BrokenGraph as lolno:\n        log.fatal(lolno)\n        app.quit(1)\n\n    # Filter down to the target and all of its transitive dependencies.\n    # TODO: make it possible to optionally draw the entire graph\n    filtered_graph = bb.graph.subgraph(\n        networkx.topological_sort(bb.graph, nbunch=[address.new(target)]))\n\n    a = networkx.to_agraph(filtered_graph)\n    a.draw(out, prog='dot')\n    log.info('Graph written to %s', out)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stub_main():\n    from google.apputils import run_script_module\n    import butcher.main\n    run_script_module.RunScriptModule(butcher.main)", "response": "stub main so that it can be run as a script entry_point"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun prior to the global main function.", "response": "def setup_function(self):\n        \"\"\"Runs prior to the global main function.\"\"\"\n        log.options.LogOptions.set_stderr_log_level('google:INFO')\n        if app.get_options().debug:\n            log.options.LogOptions.set_stderr_log_level('google:DEBUG')\n        if not app.get_options().build_root:\n            app.set_option('build_root', os.path.join(\n                app.get_options().butcher_basedir, 'build'))\n        self.buildroot = app.get_options().build_root\n        if not os.path.exists(self.buildroot):\n            os.makedirs(self.buildroot)\n        if app.get_options().disable_cache_fetch:\n            self.options['cache_fetch'] = False\n        if app.get_options().disable_hardlinks:\n            base.BaseBuilder.linkfiles = False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clean(self):\n        if os.path.exists(self.buildroot):\n            log.info('Clearing the build area.')\n            log.debug('Deleting: %s', self.buildroot)\n            shutil.rmtree(self.buildroot)\n            os.makedirs(self.buildroot)", "response": "Clear the contents of the build area."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npull a build file from git and return it.", "response": "def load_buildfile(self, target):\n        \"\"\"Pull a build file from git.\"\"\"\n        log.info('Loading: %s', target)\n        filepath = os.path.join(target.path, app.get_options().buildfile_name)\n        try:\n            repo = self.repo_state.GetRepo(target.repo)\n            return repo.get_file(filepath)\n        except gitrepo.GitError as err:\n            log.error('Failed loading %s: %s', target, err)\n            raise error.BrokenGraph('Sadface.')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef constructSpec(indentation, begin_block, end_block, begin_line, end_line, \n                  begin_action, end_action, \n                  begin_condition, end_condition, \n                  logical_and, logical_or):\n    \"\"\"Return a language specification based on parameters.\"\"\"\n    return {\n        INDENTATION   : indentation, \n        BEG_BLOCK     : begin_block,\n        END_BLOCK     : end_block,\n        BEG_LINE      : begin_line, \n        END_LINE      : end_line, \n        BEG_ACTION    : begin_action, \n        END_ACTION    : end_action, \n        BEG_CONDITION : begin_condition, \n        END_CONDITION : end_condition, \n        LOGICAL_AND   : logical_and, \n        LOGICAL_OR    : logical_or\n    }", "response": "Construct a language specification based on parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef translated(structure, values, lang_spec):\n    # LANGUAGE SPECS\n    indentation = '\\t'\n    endline = '\\n'\n\n\n    object_code = \"\"\n    stack = []\n    # define shortcuts to behavior\n    push = lambda x: stack.append(x)\n    pop  = lambda  : stack.pop()\n    last = lambda  : stack[-1] if len(stack) > 0 else ' '\n    def indented_code(s, level, end):\n        return lang_spec[INDENTATION]*level + s + end\n\n    # recreate python structure, and replace type by value\n    level = 0\n    CONDITIONS = [LEXEM_TYPE_PREDICAT, LEXEM_TYPE_CONDITION]\n    ACTION = LEXEM_TYPE_ACTION\n    DOWNLEVEL = LEXEM_TYPE_DOWNLEVEL\n    for lexem_type in structure:\n        if lexem_type is ACTION:\n            # place previous conditions if necessary\n            if last() in CONDITIONS:\n                # construct conditions lines\n                value, values = values[0:len(stack)], values[len(stack):]\n                object_code += (indented_code(lang_spec[BEG_CONDITION] \n                    + lang_spec[LOGICAL_AND].join(value) \n                    + lang_spec[END_CONDITION], \n                    level, \n                    lang_spec[END_LINE]\n                ))\n                # if provided, print the begin block token on a new line\n                if len(lang_spec[BEG_BLOCK]) > 0:\n                    object_code += indented_code( \n                        lang_spec[BEG_BLOCK],\n                        level, \n                        lang_spec[END_LINE]\n                    )\n                stack = []\n                level += 1\n            # and place the action\n            object_code += indented_code(\n                lang_spec[BEG_ACTION] + values[0], \n                level, \n                lang_spec[END_ACTION]+lang_spec[END_LINE]\n            )\n            values = values[1:]\n        elif lexem_type in CONDITIONS:\n            push(lexem_type)\n        elif lexem_type is DOWNLEVEL:\n            if last() not in CONDITIONS:\n                # down level, and add a END_BLOCK only if needed\n                level -= 1\n                if level >= 0:\n                    object_code += indented_code(\n                        lang_spec[END_BLOCK], level,\n                        lang_spec[END_LINE]\n                    )\n                else:\n                    level = 0\n\n    # add END_BLOCK while needed for reach level 0\n    while level > 0:\n        level -= 1\n        if level >= 0:\n            object_code += indented_code(\n                lang_spec[END_BLOCK], level,\n                lang_spec[END_LINE]\n            )\n        else:\n            level = 0\n    # Finished !\n    return object_code", "response": "Return code associated to given structure and values translate with given language specification."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cpp_spec():\n    return {\n        INDENTATION    : '\\t',\n        BEG_BLOCK      : '{',\n        END_BLOCK      : '}',\n        BEG_LINE       : '',\n        END_LINE       : '\\n',\n        BEG_ACTION     : '',\n        END_ACTION     : ';',\n        BEG_CONDITION  : 'if(',\n        END_CONDITION  : ')',\n        LOGICAL_AND    : ' && ',\n        LOGICAL_OR     : ' || '\n    }", "response": "C ++ specification provided for example and java compatible."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef driver_send(command,hostname=None,wait=0.2):\n    '''Send a command (or ``list`` of commands) to AFNI at ``hostname`` (defaults to local host)\n    Requires plugouts enabled (open afni with ``-yesplugouts`` or set ``AFNI_YESPLUGOUTS = YES`` in ``.afnirc``)\n    If ``wait`` is not ``None``, will automatically sleep ``wait`` seconds after sending the command (to make sure it took effect)'''\n    cmd = ['plugout_drive']\n    if hostname:\n        cmd += ['-host',hostname]\n    if isinstance(command,basestring):\n        command = [command]\n    cmd += [['-com',x] for x in command] + ['-quit']\n    o = nl.run(cmd,quiet=None,stderr=None)\n    if wait!=None:\n        time.sleep(wait)", "response": "Send a command to AFNI at hostname."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave currently open AFNI view to filename using type", "response": "def save_image(filename,view='axial',type='png',hostname=None):\n    '''Save currently open AFNI view ``view`` to ``filename`` using ``type`` (``png`` or ``jpeg``)'''\n    driver_send(\"SAVE_%s %simage %s\" % (type.upper(),view.lower(),filename),hostname=hostname)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the level of the threshold slider.", "response": "def set_thresh(thresh,p=False,hostname=None):\n    '''Sets the level of the threshold slider.\n    If ``p==True`` will be interpreted as a _p_-value'''\n    driver_send(\"SET_THRESHNEW %s *%s\" % (str(thresh),\"p\" if p else \"\"),hostname=hostname)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search(self, _):\n        queryset = super(AnnotationViewSet, self).filter_queryset(\n            self.get_queryset())\n        serializer = self.get_serializer(queryset, many=True)\n\n        return Response({\n            \"total\": len(serializer.data),\n            \"rows\": serializer.data\n        })", "response": "Implements the\n            search <http://docs. annotatorjs. org / en / v1. 2. x / storage. html#search > _\n            endpoint."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the HTTP headers that will be added to the HTTP response after the request has been completed.", "response": "def get_success_headers(self, data):\n        \"\"\"\n        As per the *Annotator* documentation regarding the\n        `create <http://docs.annotatorjs.org/en/v1.2.x/storage.html#create>`_\n        and\n        `update <http://docs.annotatorjs.org/en/v1.2.x/storage.html#update>`_\n        endpoints, we must return an absolute URL in the ``Location``\n        header.\n        :param data:\n            serialized object.\n        :return:\n            :class:`dict` of HTTP headers.\n        \"\"\"\n        headers = super(AnnotationViewSet, self).get_success_headers(data)\n\n        url = urlresolvers.reverse(\"annotations-detail\",\n                                   kwargs={\"pk\": data[\"id\"]})\n        headers.update({\"Location\": self.request.build_absolute_uri(url)})\n\n        return headers"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(self, request, *args, **kwargs):\n        response = super(AnnotationViewSet, self).create(request,\n                                                         *args,\n                                                         **kwargs)\n        response.data = None\n        response.status_code = status.HTTP_303_SEE_OTHER\n        return response", "response": "Create an annotation view set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, request, *args, **kwargs):\n        response = super(AnnotationViewSet, self).update(request,\n                                                         *args,\n                                                         **kwargs)\n        for h, v in self.get_success_headers(response.data).items():\n            response[h] = v\n        response.data = None\n        response.status_code = status.HTTP_303_SEE_OTHER\n        return response", "response": "Update the _get_next_page_url field of the _get_next_page_url field of the _get_next_page_url field of the _get_next_page_url field of the _get_next_page_url field of the _get_next_page_url field of the _get_next_page_url field of the _get_next_page_url field of the _get_next_page_url field."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_diskinfo(opts, show_all=False, local_only=False):\n    ''' Returns a list holding the current disk info,\n        stats divided by the ouptut unit.\n    '''\n    disks = []\n    outunit = opts.outunit\n\n    for drive in get_drives():\n        drive += ':\\\\'\n        disk = DiskInfo(dev=drive)\n        try:\n            usage = get_fs_usage(drive)\n        except WindowsError:  # disk not ready, request aborted, etc.\n            if show_all:\n                usage = _diskusage(0, 0, 0)\n            else:\n                continue\n        disk.ocap   = usage.total\n        disk.cap    = usage.total / outunit\n        disk.used   = usage.used / outunit\n        disk.free   = usage.free / outunit\n        disk.label  = get_vol_info(drive).name\n        if usage.total:\n            disk.pcnt = float(usage.used) / usage.total * 100\n        else:\n            disk.pcnt = 0\n        disk.mntp   = ''\n        disk.ismntd = True  # TODO needs work\n\n        # type is not working on Win7 under VirtualBox?\n        dtint, dtstr = get_drive_type(drive)\n        setattr(disk, *_drive_type_result[dtint])\n\n        disk.rw = os.access(drive, os.W_OK)  # doesn't work on optical\n        if usage.total:    # this not giving correct result on Win7 RTM either\n            disk.rw = stat.S_IMODE(os.stat(drive).st_mode) & stat.S_IWRITE\n        else:\n            disk.rw = False\n        disks.append(disk)\n\n    if opts.debug:\n        for disk in disks:\n            print(disk.dev, disk, '\\n')\n    return disks", "response": "Returns a list holding the current disk info and the ouptut unit."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary holding the current memory info and the total amount of memory used by the ouptut unit.", "response": "def get_meminfo(opts):\n    ''' Returns a dictionary holding the current memory info,\n        divided by the ouptut unit.\n    '''\n    meminfo = MemInfo()\n    outunit = opts.outunit\n    mstat = get_mem_info()  # from winstats\n    pinf = get_perf_info()\n    try:\n        pgpcnt = get_perf_data(r'\\Paging File(_Total)\\% Usage',\n                                'double')[0] / 100\n    except WindowsError:\n        pgpcnt = 0\n\n    totl = mstat.TotalPhys\n    meminfo.memtotal = totl / float(outunit)\n    used = totl * mstat.MemoryLoad / 100.0  # percent, more reliable\n    meminfo.used = used / float(outunit)\n    left = totl - used\n\n    # Cached\n    cache = pinf.SystemCacheBytes\n    if cache > left and version >= win7ver:\n        # Win7 RTM bug :/ this cache number is bogus\n        free = get_perf_data(r'\\Memory\\Free & Zero Page List Bytes', 'long')[0]\n        cache = left - free\n        meminfo.memfree = free / float(outunit)\n    else:\n        meminfo.memfree = (totl - used - cache) / float(outunit)\n    meminfo.buffers = 0\n\n    meminfo.cached = cache / float(outunit)\n\n    # SWAP  these numbers are actually commit charge, not swap; fix\n    #       should not contain RAM :/\n    swpt = abs(mstat.TotalPageFile - totl)\n    # these nums aren't quite right either, use perfmon instead :/\n    swpu = swpt * pgpcnt\n    swpf = swpt - swpu\n\n    meminfo.swaptotal = swpt / float(outunit)\n    meminfo.swapfree = swpf / float(outunit)\n    meminfo.swapused = swpu / float(outunit)\n    meminfo.swapcached = 0  # A linux stat for compat\n\n    if opts.debug:\n        import locale\n        fmt = lambda val: locale.format('%d', val, True)\n        print()\n        print('TotalPhys:', fmt(totl))\n        print('AvailPhys:', fmt(mstat.AvailPhys))\n        print('MemoryLoad:', fmt(mstat.MemoryLoad))\n        print()\n        print('used:', fmt(used))\n        print('left:', fmt(left))\n        if 'free' in locals():\n            print('PDH Free:', fmt(free))\n        print('SystemCacheBytes:', fmt(pinf.SystemCacheBytes))\n        print()\n        print('TotalPageFile:', fmt(mstat.TotalPageFile))\n        print('AvailPageFile:', fmt(mstat.AvailPageFile))\n        print('TotalPageFile fixed:', fmt(swpt))\n        print('AvailPageFile fixed:', fmt(swpf))\n\n    return meminfo"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef endpoint(value: Any) -> Any:\n    if issubclass(type(value), Endpoint):\n        return value\n    elif isinstance(value, str):\n        for api, cls in MANAGED_API.items():\n            if value.startswith(api + \" \"):\n                return cls.from_inline(value)\n        return UnknownEndpoint.from_inline(value)\n    else:\n        raise TypeError(\"Cannot convert {0} to endpoint\".format(value))", "response": "Converts a string to an Endpoint instance type"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns UnknownEndpoint instance from endpoint string", "response": "def from_inline(cls: Type[UnknownEndpointType], inline: str) -> UnknownEndpointType:\n        \"\"\"\n        Return UnknownEndpoint instance from endpoint string\n\n        :param inline: Endpoint string\n        :return:\n        \"\"\"\n        try:\n            api = inline.split()[0]\n            properties = inline.split()[1:]\n            return cls(api, properties)\n        except IndexError:\n            raise MalformedDocumentError(inline)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef inline(self) -> str:\n        doc = self.api\n        for p in self.properties:\n            doc += \" {0}\".format(p)\n        return doc", "response": "Return endpoint string for the resource set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_inline(cls: Type[BMAEndpointType], inline: str) -> BMAEndpointType:\n        m = BMAEndpoint.re_inline.match(inline)\n        if m is None:\n            raise MalformedDocumentError(BMAEndpoint.API)\n        server = m.group(1)\n        ipv4 = m.group(2)\n        ipv6 = m.group(3)\n        port = int(m.group(4))\n        return cls(server, ipv4, ipv6, port)", "response": "Return BMAEndpoint instance from endpoint string"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn endpoint string for inline BMA.", "response": "def inline(self) -> str:\n        \"\"\"\n        Return endpoint string\n\n        :return:\n        \"\"\"\n        return BMAEndpoint.API + \"{DNS}{IPv4}{IPv6}{PORT}\" \\\n            .format(DNS=(\" {0}\".format(self.server) if self.server else \"\"),\n                    IPv4=(\" {0}\".format(self.ipv4) if self.ipv4 else \"\"),\n                    IPv6=(\" {0}\".format(self.ipv6) if self.ipv6 else \"\"),\n                    PORT=(\" {0}\".format(self.port) if self.port else \"\"))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn SecuredBMAEndpoint instance from endpoint string", "response": "def from_inline(cls: Type[SecuredBMAEndpointType], inline: str) -> SecuredBMAEndpointType:\n        \"\"\"\n        Return SecuredBMAEndpoint instance from endpoint string\n\n        :param inline: Endpoint string\n        :return:\n        \"\"\"\n        m = SecuredBMAEndpoint.re_inline.match(inline)\n        if m is None:\n            raise MalformedDocumentError(SecuredBMAEndpoint.API)\n        server = m.group(1)\n        ipv4 = m.group(2)\n        ipv6 = m.group(3)\n        port = int(m.group(4))\n        path = m.group(5)\n        if not path:\n            path = \"\"\n        return cls(server, ipv4, ipv6, port, path)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inline(self) -> str:\n        inlined = [str(info) for info in (self.server, self.ipv4, self.ipv6, self.port, self.path) if info]\n        return SecuredBMAEndpoint.API + \" \" + \" \".join(inlined)", "response": "Return endpoint string that is inline with the server and ipv4 and ipv6."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef conn_handler(self, session: ClientSession, proxy: str = None) -> ConnectionHandler:\n        if self.server:\n            return ConnectionHandler(\"https\", \"wss\", self.server, self.port, self.path, session, proxy)\n        elif self.ipv6:\n            return ConnectionHandler(\"https\", \"wss\", \"[{0}]\".format(self.ipv6), self.port, self.path, session, proxy)\n\n        return ConnectionHandler(\"https\", \"wss\", self.ipv4, self.port, self.path, session, proxy)", "response": "Return the connection handler instance for the endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn WS2PEndpoint instance from endpoint string", "response": "def from_inline(cls: Type[WS2PEndpointType], inline: str) -> WS2PEndpointType:\n        \"\"\"\n        Return WS2PEndpoint instance from endpoint string\n\n        :param inline: Endpoint string\n        :return:\n        \"\"\"\n        m = WS2PEndpoint.re_inline.match(inline)\n        if m is None:\n            raise MalformedDocumentError(WS2PEndpoint.API)\n        ws2pid = m.group(1)\n        server = m.group(2)\n        port = int(m.group(3))\n        path = m.group(4)\n        if not path:\n            path = \"\"\n        return cls(ws2pid, server, port, path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning endpoint string that is inline", "response": "def inline(self) -> str:\n        \"\"\"\n        Return endpoint string\n\n        :return:\n        \"\"\"\n        inlined = [str(info) for info in (self.ws2pid, self.server, self.port, self.path) if info]\n        return WS2PEndpoint.API + \" \" + \" \".join(inlined)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_inline(cls: Type[ESCoreEndpointType], inline: str) -> ESCoreEndpointType:\n        m = ESCoreEndpoint.re_inline.match(inline)\n        if m is None:\n            raise MalformedDocumentError(ESCoreEndpoint.API)\n        server = m.group(1)\n        port = int(m.group(2))\n        return cls(server, port)", "response": "Return ESCoreEndpoint instance from endpoint string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a ConnectionHandler instance for the endpoint", "response": "def conn_handler(self, session: ClientSession, proxy: str = None) -> ConnectionHandler:\n        \"\"\"\n        Return connection handler instance for the endpoint\n\n        :param session: AIOHTTP client session instance\n        :param proxy: Proxy url\n        :return:\n        \"\"\"\n        return ConnectionHandler(\"https\", \"wss\", self.server, self.port, \"\", session, proxy)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns ESUserEndpoint instance from endpoint string", "response": "def from_inline(cls: Type[ESUserEndpointType], inline: str) -> ESUserEndpointType:\n        \"\"\"\n        Return ESUserEndpoint instance from endpoint string\n\n        :param inline: Endpoint string\n        :return:\n        \"\"\"\n        m = ESUserEndpoint.re_inline.match(inline)\n        if m is None:\n            raise MalformedDocumentError(ESUserEndpoint.API)\n        server = m.group(1)\n        port = int(m.group(2))\n        return cls(server, port)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_inline(cls: Type[ESSubscribtionEndpointType], inline: str) -> ESSubscribtionEndpointType:\n        m = ESSubscribtionEndpoint.re_inline.match(inline)\n        if m is None:\n            raise MalformedDocumentError(ESSubscribtionEndpoint.API)\n        server = m.group(1)\n        port = int(m.group(2))\n        return cls(server, port)", "response": "Return an ESSubscribtionEndpoint instance from an endpoint string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef inline(self) -> str:\n        inlined = [str(info) for info in (self.server, self.port) if info]\n        return ESSubscribtionEndpoint.API + \" \" + \" \".join(inlined)", "response": "Return endpoint string that contains inline information."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef continues(method):\n        '''Method decorator signifying that the visitor should not visit the\n        current node's children once this method has been invoked.\n        '''\n        @functools.wraps(method)\n        def wrapped(self, *args, **kwargs):\n            yield method(self, *args, **kwargs)\n            raise self.Continue()\n        return wrapped", "response": "Method decorator that marks the visitor to continue visiting the current node s children once this method has been invoked."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_methodnames(self, node):\n        '''Given a node, generate all names for matching visitor methods.\n        '''\n        nodekey = self.get_nodekey(node)\n        prefix = self._method_prefix\n        if isinstance(nodekey, self.GeneratorType):\n            for nodekey in nodekey:\n                yield self._method_prefix + nodekey\n        else:\n            yield self._method_prefix + nodekey", "response": "Given a node generate all names for matching visitor methods."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a particular node check the visitor instance for methods that are available at the class level.", "response": "def get_method(self, node):\n        '''Given a particular node, check the visitor instance for methods\n        mathing the computed methodnames (the function is a generator).\n\n        Note that methods are cached at the class level.\n        '''\n        methods = self._methods\n        for methodname in self.get_methodnames(node):\n            if methodname in methods:\n                return methods[methodname]\n            else:\n                cls = self.__class__\n                method = getattr(cls, methodname, None)\n                if method is not None:\n                    methods[methodname] = method\n                    return method"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit(self, node):\n        '''The main visit function. Visits the passed-in node and calls\n        finalize.\n        '''\n        for token in self.itervisit(node):\n            pass\n        result = self.finalize()\n        if result is not self:\n            return result", "response": "The main visit function."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a node find the matching visitor function and run it.", "response": "def itervisit_node(self, node):\n        '''Given a node, find the matching visitor function (if any) and\n        run it. If the result is a context manager, yield from all the nodes\n        children before allowing it to exit. Otherwise, return the result.\n        '''\n        # Get the corresponding method and run it.\n        func = self.get_method(node)\n        if func is None:\n            generic_visit = getattr(self, 'generic_visit', None)\n            if generic_visit is not None:\n                result = generic_visit(node)\n            else:\n                # There is no handler defined for this node.\n                return\n        else:\n            result = self.apply_visitor_method(func, node)\n\n        # If result is a generator, yield from it.\n        if isinstance(result, self.GeneratorType):\n            yield from result\n\n        # If result is a context manager, enter, visit children, then exit.\n        elif isinstance(result, self.GeneratorContextManager):\n            with result:\n                itervisit_nodes = self.itervisit_nodes\n                for child in self.get_children(node):\n                    try:\n                        yield from itervisit_nodes(child)\n                    except self.Continue:\n                        continue\n\n        # Otherwise just yield the result.\n        else:\n            yield result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading in a GDF file and return a dictionary of the data.", "response": "def readGDF(filename=\"../data/RenatoFabbri06022014.gdf\"):\n    \"\"\"Made to work with gdf files from my own network and friends and groups\"\"\"\n    with open(filename,\"r\") as f:\n        data=f.read()\n    lines=data.split(\"\\n\")\n    columns=lines[0].split(\">\")[1].split(\",\")\n    column_names=[i.split(\" \")[0] for i in columns]\n    data_friends={cn:[] for cn in column_names}\n    for line in lines[1:]:\n        if not line:\n            break\n        if \">\" in line:\n            columns=line.split(\">\")[1].split(\",\")\n            column_names2=[i.split(\" \")[0] for i in columns]\n            data_friendships={cn:[] for cn in column_names2}\n            continue\n        fields=line.split(\",\")\n        if \"column_names2\" not in locals():\n            for i, field in enumerate(fields):\n                if column_names[i] in (\"name\",\"groupid\"): pass\n                elif field.isdigit(): field=int(field)\n                data_friends[column_names[i]].append(field)\n        else:\n            for i, field in enumerate(fields):\n                if column_names2[i]==\"name\": pass\n                elif field.isdigit(): field=int(field)\n                data_friendships[column_names2[i]].append(field)\n    return {\"relations\":data_friendships,\n            \"individuals\":data_friends}"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an HttpResponse object containing JSON serialized data.", "response": "def json_response(data, status=200, serializer=None):\n    \"\"\"\n    Returns an HttpResponse object containing JSON serialized data.\n\n    The mime-type is set to application/json, and the charset to UTF-8.\n    \"\"\"\n    return HttpResponse(json.dumps(data, default=serializer),\n                        status=status,\n                        content_type='application/json; charset=UTF-8')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef jsonp_response(data, callback=\"f\", status=200, serializer=None):\n    val = json.dumps(data, default=serializer)\n    ret = \"{callback}('{val}');\".format(callback=callback, val=val)\n\n    return HttpResponse(ret,\n                        status=status,\n                        content_type='application/x-javascript; charset=UTF-8')", "response": "Returns a JSONP response object containing the given data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new instance of the specified class", "response": "def get_collection_instance(klass, api_client = None, request_api=True, **kwargs):\n    \"\"\"\n    instatiates the collection lookup of json type klass\n    :param klass: json file name\n    :param api_client: transportation api\n    :param request_api: if True uses the default APIClient\n    \"\"\"\n    _type = klass\n    if api_client is None and request_api:\n        api_client = api.APIClient()\n    if isinstance(klass, dict):\n        _type = klass['type']\n    obj = CollectionResource(_type, api_client, **kwargs)\n    return obj        \n \n#\n#    /**\n#     * magic method for mapping all kinds of method calls to addFilter\n#     * @param string $method method name\n#     * @param array $args array of arguments\n#     * @return SaleskingCollection\n#     * @throws BadMethodCallException\n#     * @since 1.0.0\n#     */\n#    public function __call($method, array $args) {\n#        try {\n#            $this->addFilter($method,$args[0]);\n#            return $this;\n#        }\n#        catch (SaleskingException $e)\n#        {\n#            if($e->getCode() == \"FILTER_NOTEXISTING\")\n#            {\n#                throw new BadMethodCallException('Call to undefined method :'.$method);\n#            }\n#\n#            throw $e;\n#        }\n#    }\n\n    def sort(self, direction = \"ASC\"):\n        \"\"\"\n        set the sort to the query\n        ['ASC','DESC']\n        \"\"\"\n        direction = directtion.upper()\n        if direction in ['ASC','DESC']:\n            self.sort = direction\n        else:\n            raise SaleskingException(\"SORT_INVALIDDIRECTION\",\"Invalid sorting direction - please choose either ASC or DESC\");\n    \n    def sort_by(self, property):\n        \"\"\"\n        set sort by property to the query\n        \"\"\"\n        seek =u\"sort_by\"\n        # make sure that the api supports sorting for this kind of object\n        if seek in self.schema['links']['instances']['properties']:\n            #  make sure that we have a valid property\n            if seek in self.schema['links']['instances']['properties']['sort_by']['enum']:\n                self.sort_by = property\n                return self\n            else:\n                raise SaleskingException(\"SORTBY_INVALIDPROPERTY\",\"Invalid property for sorting\");\n        else:\n            raise SaleskingException(\"SORTBY_CANNOTSORT\",\"object type doesnt support sorting\");"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_per_page(self, entries=100):\n        if isinstance(entries, int) and entries <= 200:\n            self.per_page = int(entries)\n            return self\n        else:\n            raise SalesKingException(\"PERPAGE_ONLYINT\", \"Please set an integer <200 for the per-page limit\");", "response": "set the per - page limit of the resource set"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_resource_type(self, klass):\n        self.resource_type = klass\n        self.schema = loaders.load_schema_raw(self.resource_type)", "response": "set type to load and load schema"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_filters(self, filters):\n        if not isinstance(filters, dict):\n            raise Exception(\"filters must be a dict\")\n        self.filters = {}\n        for key in filters.keys():\n            value = filters[key]\n            self.add_filter(key,value)", "response": "set and validate filters dict\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a filter with value filter_value returns True on success otherwise exception", "response": "def add_filter(self, key, filter_value):\n        \"\"\"\n        add and validate a filter with value\n        returns True on success otherwise exception\n        \"\"\"\n        seek = u\"filter[%s]\" % key\n        if self.validate_filter(key, filter_value):\n            self.filters[key] = filter_value\n            return True\n        else:\n            msg = u'Invalid filter value: filter:%s value:%s' % (key, filter_value)\n            print msg\n            raise SalesKingException(\"FILTER_INVALID\", msg )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _is_type(self, instance, type):\n        if type not in self._types:\n            raise UnknownType(type)\n        type = self._types[type]\n\n        # bool inherits from int, so ensure bools aren't reported as integers\n        if isinstance(instance, bool):\n            type = _flatten(type)\n            if int in type and bool not in type:\n                return False\n        return isinstance(instance, type)", "response": "Check if an instance is of the provided type."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_filter(self, key, filter_value):\n        ok = False\n        seek = u\"filter[%s]\" % key\n        value = None\n        for link in self.schema['links']:\n            if link['rel'] == 'instances':\n               for property in link['properties']:\n                   if seek == property:\n                       value = link['properties'][property]\n                       ok = True\n        if not ok:\n            return False\n        ok = self._is_type(filter_value, value['type'])\n        # if string with type add validation\n        if ok is True and value['type'] == 'string' and 'format' in value.keys():\n            ok = self._validate_json_format(filter_value, value)\n            \n        return ok", "response": "validate the filter key and value against the collection schema\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating the json format of the entry.", "response": "def _validate_json_format(self, filter_value, schema_validation_type):\n        \"\"\"\n        adds the type:string format:schema_validation_type\n        :param filter_value: value of the filter\n        :param schema_validation_type: format description of the json schema entry\n        \"\"\"\n        ok = False\n        try:\n            validators.json_schema_validation_format(filter_value, schema_validation_type)\n            ok = True\n        except ValueError as e:\n            pass\n        return ok"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds the url to call the list endpoint", "response": "def _build_query_url(self, page = None, verbose = False):\n        \"\"\"\n        builds the url to call\n        \"\"\"\n        query = []\n#        # build the filters\n#        for afilter in self.filters.keys():\n#            value = self.filters[afilter]\n#            print\"filter:%s value:%s\" % (afilter,value)\n#            value = urlencode(value)\n#            query_str = u\"%s=%s\" % (afilter, value)\n        if len(self.filters) > 0:\n            query.append(urlencode(self.filters))\n        if self.sort:\n            query_str = u\"%s=%s\" % (u\"sort\", self.sort)\n            query.append(query_str)\n        if self.sort_by:\n            query_str = u\"%s=%s\" % (u\"sort_by\", self.sort_by)\n            query.append(query_str)\n        if self.per_page:\n            query_str = u\"%s=%s\" % (u\"per_page\", self.per_page)\n            query.append(query_str)\n        if page:\n            query_str = u\"%s=%s\" % (u\"page\", page)\n            query.append(query_str)\n        query = u\"?%s\" % (u\"&\".join(query))\n        url = u\"%s%s\" % (self.get_list_endpoint()['href'],query)\n        url = u\"%s%s%s\" % (self.__api__.base_url, API_BASE_PATH, url)\n        msg = \"_build_query_url: url:%s\" % url\n        log.debug(msg)\n        if verbose:\n            print msg\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the configured list entpoint for the schema. type", "response": "def get_list_endpoint(self, rel=u\"instances\"):\n        \"\"\"\n        get the configured list entpoint for the schema.type\n        :param rel: lookup rel: value inside the links section\n        :returns the value\n        :raises APIException\n        \"\"\"\n        schema_loaded = not self.schema is None\n        links_present = \"links\" in self.schema.keys()\n        if (schema_loaded and links_present):\n             for row in self.schema['links']:\n                  if row['rel'] == rel:\n                      #print \"row %s\" % row\n                      return row\n        raise APIException(\"ENDPOINT_NOTFOUND\",\"invalid endpoint\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nposts load processing fills the self._items collection", "response": "def _post_load(self, response, verbose):\n        \"\"\"\n        post load processing\n        fills the self._items collection\n        \"\"\"\n        try:\n            if verbose:\n                print response.content\n            log.debug(response.content)\n        except Exception, e:\n            raise e\n            \n        if response is not None and response.status_code == 200:\n            types = helpers.pluralize(self.resource_type)\n            #print \"types %s\" % types\n            body = json.loads(response.content, encoding='utf-8')\n            self.total_entries = body['collection']['total_entries']\n            self.total_pages = body['collection']['total_pages']\n            self.current_page = body['collection']['current_page']\n            ## now get the items from the class factory\n            if self.total_entries != 0:\n                for response_item in body[types]:\n                    obj = self._response_item_to_object(response_item)\n                    ## add the items\n                    self._items.append(obj)\n            \n        else:\n            msg = u\"Fetching failed, an error happend\"\n            raise SalesKingException(\"LOAD_ERROR\", msg, response)\n        \n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntaking json and make a resource out of it", "response": "def _response_item_to_object(self, resp_item):\n        \"\"\"\n        take json and make a resource out of it\n        \"\"\"\n        item_cls = resources.get_model_class(self.resource_type)\n        properties_dict = resp_item[self.resource_type]\n        new_dict = helpers.remove_properties_containing_None(properties_dict)\n        # raises exception if something goes wrong\n        obj = item_cls(new_dict)\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(self, page = None, verbose=False):\n        url = self._build_query_url(page, verbose)\n        response = self._load(url, verbose)\n        response = self._post_load(response, verbose)\n        return response", "response": "execute the collection loading\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _load(self, url, verbose):\n        msg = u\"_load url: %s\" % url\n        self._last_query_str = url\n        log.debug(msg)\n        if verbose:\n            print msg\n        response = self.__api__.request(url)\n        return response", "response": "Execute a request against the Salesking API to fetch the items\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a cusotom implementation of a served http resource.", "response": "def addAdminResource(self, pluginSubPath: bytes, resource: BasicResource) -> None:\n        \"\"\" Add Site Resource\n\n        Add a cusotom implementation of a served http resource.\n\n        :param pluginSubPath: The resource path where you want to serve this resource.\n        :param resource: The resource to serve.\n        :return: None\n\n        \"\"\"\n        pluginSubPath = pluginSubPath.strip(b'/')\n        self.__rootAdminResource.putChild(pluginSubPath, resource)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cmd_part(self, connection, sender, target, payload):\n        if payload:\n            connection.part(payload)\n        else:\n            raise ValueError(\"No channel given\")", "response": "Called when a channel is left."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nask the bot to join a channel", "response": "def cmd_join(self, connection, sender, target, payload):\n        \"\"\"\n        Asks the bot to join a channel\n        \"\"\"\n        if payload:\n            connection.join(payload)\n        else:\n            raise ValueError(\"No channel given\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cmd_echo(self, connection, sender, target, payload):\n        connection.privmsg(target, payload or \"Hello, {0}\".format(sender))", "response": "Echo the given payload"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_refresh(self,args):\n        # prints all the groups: pprint(AwsConnectionFactory.getLogClient().describe_log_groups())\n\n        response = AwsConnectionFactory.getLogClient().describe_log_groups(logGroupNamePrefix=self.stackResource.physical_resource_id)\n        if not 'logGroups' in response:\n            raise Exception(\"Expected log group description to have logGroups entry. Got {}\".format(response))\n\n        # pprint(response)\n        descriptions = [x for x in response['logGroups'] if x['logGroupName'] == self.stackResource.physical_resource_id]\n        if not descriptions:\n            raise Exception(\"Could not find log group {} in list {}\".format(self.stackResource.physical_resource_id,response['logGroups']))\n\n        self.description = descriptions[0]\n\n        self.logStreams = self.loadLogStreams()\n        print \"== logStream\"\n        maxIndex = \"{}\".format(len(self.logStreams)+1)\n        print \"maxIndex:{}\".format(maxIndex)\n        frm = \"  {{0:{}d}}: {{1}}\".format(len(maxIndex))\n        print frm\n\n        index = 0\n        for logStream in self.logStreams:\n            print frm.format(index,logStream['logStreamName'])\n            index += 1", "response": "Refresh the view of the log group"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngoing to the specified log stream. logStream - h for detailed help", "response": "def do_logStream(self,args):\n        \"\"\"Go to the specified log stream. logStream -h for detailed help\"\"\"\n        parser = CommandArgumentParser(\"logStream\")\n        parser.add_argument(dest='logStream',help='logStream index.');\n        args = vars(parser.parse_args(args))\n\n        print \"loading log stream {}\".format(args['logStream'])\n        index = int(args['logStream'])\n        logStream = self.logStreams[index]\n\n        print \"logStream:{}\".format(logStream)\n        self.childLoop(AwsLogStream.AwsLogStream(logStream,self))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nselect and returns a build class based on project structure and config from a given path.", "response": "def from_path(path):\n  \"\"\"\n  Selects and returns a build class based on project structure/config from a given path.\n\n  :param path(str): required path argument to be used\n  \"\"\"\n  for item in ref:\n    build = ref[item]\n    valid_ = build['is_valid']\n    if valid_(path) is True:\n      return build['builder'](path)\n  raise errors.InvalidProjectStructure()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a particular token check the visitor instance for methods mathing the computed methodnames.", "response": "def get_nodekey(self, token, types=types, coll_abc=collections.abc):\n        '''Given a particular token, check the visitor instance for methods\n        mathing the computed methodnames (the function is a generator).\n        '''\n        # Check the mro.\n        for mro_type in type(token).__mro__:\n            yield mro_type.__name__\n\n        # Check for callability.\n        if callable(token):\n            yield 'callable'\n\n        # Check for the collections.abc types.\n        abc_types = (\n            'Hashable',\n            'Iterable',\n            'Iterator',\n            'Sized',\n            'Container',\n            'Callable',\n            'Set',\n            'MutableSet',\n            'Mapping',\n            'MutableMapping',\n            'MappingView',\n            'KeysView',\n            'ItemsView',\n            'ValuesView',\n            'Sequence',\n            'MutableSequence',\n            'ByteString')\n        for type_name in abc_types:\n            type_ = getattr(coll_abc, type_name, None)\n            if type_ is None:\n                continue\n            if isinstance(token, type_):\n                yield type_name\n\n        # Check for the standard interpreter types in the types module.\n        interp_types = (\n            'BuiltinFunctionType',\n            'BuiltinMethodType',\n            'CodeType',\n            'DynamicClassAttribute',\n            'FrameType',\n            'FunctionType',\n            'GeneratorType',\n            'GetSetDescriptorType',\n            'LambdaType',\n            'MappingProxyType',\n            'MemberDescriptorType',\n            'MethodType',\n            'ModuleType',\n            'SimpleNamespace',\n            'TracebackType')\n        for type_name in interp_types:\n            type_ = getattr(types, type_name, None)\n            if type_ is None:\n                continue\n            if isinstance(token, type_):\n                yield type_name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef itervisit(\n            self, iterable, gentype=types.GeneratorType,\n            exhaust_generators=True):\n        '''The main visit function. Visits the passed-in node and calls\n        finalize.\n        '''\n        self.iterable = iter(iterable)\n        for token in self.iterable:\n            result = self.itervisit_node(token)\n            if exhaust_generators and isinstance(result, gentype):\n                for output in result:\n                    yield output\n            elif result is not None:\n                yield result\n        result = self.finalize()\n        if result is self:\n            return\n        if isinstance(result, gentype):\n            for output in result:\n                yield output", "response": "The main visit function. Visits the passed - in node and calls finalize."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting current version then exits", "response": "def print_version(ctx: click.Context, _, value):\n    \"\"\"\n    Prints current version then exits\n    \"\"\"\n    if not value or ctx.resilient_parsing:\n        return\n\n    print(__version__)\n    sys.exit(0)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef base64url_decode(msg):\n    rem = len(msg) % 4\n    if rem:\n        msg += b'=' * (4 - rem)\n\n    return base64.urlsafe_b64decode(msg)", "response": "Decode a base64 message based on JWT spec Appendix B."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nproducing a base64 - encoded JWS header.", "response": "def _jws_header(keyid, algorithm):\n    \"\"\"Produce a base64-encoded JWS header.\"\"\"\n    data = {\n        'typ': 'JWT',\n        'alg': algorithm.name,\n        # 'kid' is used to indicate the public part of the key\n        # used during signing.\n        'kid': keyid\n    }\n\n    datajson = json.dumps(data, sort_keys=True).encode('utf8')\n    return base64url_encode(datajson)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nproducing a base64 - encoded JWS payload.", "response": "def _jws_payload(expire_at, requrl=None, **kwargs):\n    \"\"\"\n    Produce a base64-encoded JWS payload.\n\n    expire_at, if specified, must be a number that indicates\n    a timestamp after which the message must be rejected.\n\n    requrl, if specified, is used as the \"audience\" according\n    to the JWT spec.\n\n    Any other parameters are passed as is to the payload.\n    \"\"\"\n    data = {\n        'exp': expire_at,\n        'aud': requrl\n    }\n    data.update(kwargs)\n\n    datajson = json.dumps(data, sort_keys=True).encode('utf8')\n    return base64url_encode(datajson)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _jws_signature(signdata, privkey, algorithm):\n    signature = algorithm.sign(privkey, signdata)\n    return base64url_encode(signature)", "response": "Produce a base64 - encoded JWS signature based on the signdata passed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sign_serialize(privkey, expire_after=3600, requrl=None,\n                   algorithm_name=DEFAULT_ALGO, **kwargs):\n    \"\"\"\n    Produce a JWT compact serialization by generating a header, payload,\n    and signature using the privkey and algorithm specified.\n\n    The privkey object must contain at least a member named pubkey.\n\n    The parameter expire_after is used by the server to reject the payload\n    if received after current_time + expire_after. Set it to None to disable\n    its use.\n\n    The parameter requrl is optionally used by the server to reject the\n    payload if it is not delivered to the proper place, e.g. if requrl\n    is set to https://example.com/api/login but sent to a different server\n    or path then the receiving server should reject it.\n\n    Any other parameters are passed as is to the payload.\n    \"\"\"\n    assert algorithm_name in ALGORITHM_AVAILABLE\n\n    algo = ALGORITHM_AVAILABLE[algorithm_name]\n    addy = algo.pubkey_serialize(privkey.pubkey)\n\n    header = _jws_header(addy, algo).decode('utf8')\n    payload = _build_payload(expire_after, requrl, **kwargs)\n    signdata = \"{}.{}\".format(header, payload)\n    signature = _jws_signature(signdata, privkey, algo).decode('utf8')\n\n    return \"{}.{}\".format(signdata, signature)", "response": "Generates a compact JWT compact serialization using the privkey and algorithm specified."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef multisig_sign_serialize(privkeys, expire_after=3600, requrl=None,\n                            algorithm_name=DEFAULT_ALGO, **kwargs):\n    \"\"\"\n    Produce a general JSON serialization by generating a header, payload,\n    and multiple signatures using the list of private keys specified.\n    All the signatures will be performed using the same algorithm.\n\n    The parameter expire_after is used by the server to reject the payload\n    if received after current_time + expire_after. Set it to None to disable\n    its use.\n\n    The parameter requrl is optionally used by the server to reject the\n    payload if it is not delivered to the proper place, e.g. if requrl\n    is set to https://example.com/api/login but sent to a different server\n    or path then the receiving server should reject it.\n\n    Any other parameters are passed as is to the payload.\n    \"\"\"\n    assert algorithm_name in ALGORITHM_AVAILABLE\n\n    payload = _build_payload(expire_after, requrl, **kwargs)\n    result = {\"payload\": payload, \"signatures\": []}\n    algo = ALGORITHM_AVAILABLE[algorithm_name]\n\n    for pk in privkeys:\n        addy = algo.pubkey_serialize(pk.pubkey)\n        header = _jws_header(addy, algo).decode('utf8')\n        signdata = \"{}.{}\".format(header, payload)\n        signature = _jws_signature(signdata, pk, algo).decode('utf8')\n        result[\"signatures\"].append({\n            \"protected\": header,\n            \"signature\": signature})\n\n    return json.dumps(result)", "response": "Generates a JSON serialization of the private keys specified by the user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate a JSON serialization and return the headers and payload.", "response": "def multisig_validate_deserialize(rawmsg, requrl=None, check_expiration=True,\n                                  decode_payload=True,\n                                  algorithm_name=DEFAULT_ALGO):\n    \"\"\"\n    Validate a general JSON serialization and return the headers and\n    payload if all the signatures are good.\n\n    If check_expiration is False, the payload will be accepted even if\n    expired.\n\n    If decode_payload is True then this function will attempt to decode\n    it as JSON, otherwise the raw payload will be returned. Note that\n    it is always decoded from base64url.\n    \"\"\"\n    assert algorithm_name in ALGORITHM_AVAILABLE\n\n    algo = ALGORITHM_AVAILABLE[algorithm_name]\n\n    data = json.loads(rawmsg)\n    payload64 = data.get('payload', None)\n    signatures = data.get('signatures', None)\n    if payload64 is None or not isinstance(signatures, list):\n        raise InvalidMessage('must contain \"payload\" and \"signatures\"')\n    if not len(signatures):\n        raise InvalidMessage('no signatures')\n\n    try:\n        payload, sigs = _multisig_decode(payload64, signatures, decode_payload)\n    except Exception as err:\n        raise InvalidMessage(str(err))\n\n    all_valid = True\n    try:\n        for entry in sigs:\n            valid = _verify_signature(algorithm=algo, **entry)\n            all_valid = all_valid and valid\n    except Exception as err:\n        raise InvalidMessage('failed to verify signature: {}'.format(err))\n\n    if not all_valid:\n        return None, None\n\n    if decode_payload:\n        _verify_payload(payload, check_expiration, requrl)\n    return [entry['header'] for entry in sigs], payload"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_deserialize(rawmsg, requrl=None, check_expiration=True,\n                         decode_payload=True, algorithm_name=DEFAULT_ALGO):\n    \"\"\"\n    Validate a JWT compact serialization and return the header and\n    payload if the signature is good.\n\n    If check_expiration is False, the payload will be accepted even if\n    expired.\n\n    If decode_payload is True then this function will attempt to decode\n    it as JSON, otherwise the raw payload will be returned. Note that\n    it is always decoded from base64url.\n    \"\"\"\n    assert algorithm_name in ALGORITHM_AVAILABLE\n    algo = ALGORITHM_AVAILABLE[algorithm_name]\n\n    segments = rawmsg.split('.')\n    if len(segments) != 3 or not all(segments):\n        raise InvalidMessage('must contain 3 non-empty segments')\n\n    header64, payload64, cryptoseg64 = segments\n    try:\n        signature = base64url_decode(cryptoseg64.encode('utf8'))\n        payload_data = base64url_decode(payload64.encode('utf8'))\n        header_data = base64url_decode(header64.encode('utf8'))\n        header = json.loads(header_data.decode('utf8'))\n        if decode_payload:\n            payload = json.loads(payload_data.decode('utf8'))\n        else:\n            payload = payload_data\n    except Exception as err:\n        raise InvalidMessage(str(err))\n\n    try:\n        valid = _verify_signature(\n            '{}.{}'.format(header64, payload64),\n            header,\n            signature,\n            algo)\n    except Exception as err:\n        raise InvalidMessage('failed to verify signature: {}'.format(err))\n\n    if not valid:\n        return None, None\n\n    if decode_payload:\n        _verify_payload(payload, check_expiration, requrl)\n    return header, payload", "response": "Validate a JWT compact serialization and return the header and payload if the signature is good."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nraises type_ with value and traceback.", "response": "def raise_(type_, value=None, traceback=None):  # pylint: disable=W0613\n    \"\"\"\n    Does the same as ordinary ``raise`` with arguments do in Python 2.\n    But works in Python 3 (>= 3.3) also!\n\n    Please checkout README on https://github.com/9seconds/pep3134\n    to get an idea about possible pitfals. But short story is: please\n    be pretty carefull with tracebacks. If it is possible, use sys.exc_info\n    instead. But in most cases it will work as you expect.\n    \"\"\"\n\n    if type_.__traceback__ is not traceback:\n        raise type_.with_traceback(traceback)\n    raise type_"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef request(self, url, method = u\"get\", data = None, headers = None, **kwargs):\n\n        url, method, data, headers, kwargs = self._pre_request(url, \n                                                                 method=method,\n                                                                 data=data,\n                                                                 headers=headers,\n                                                                 **kwargs)\n        response = self._request(url, method=method, data=data, headers=headers, **kwargs)\n        response = self._post_request(response)\n        \n        # raises the appropriate exceptions\n        response = self._handle_response(response)\n        \n        return response", "response": "This method is used to make a request to the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhooking for manipulating the _pre request", "response": "def _pre_request(self, url, method = u\"get\", data = None, headers=None, **kwargs):\n        \"\"\"\n        hook for manipulating the _pre request data\n        \"\"\"\n        return (url, method, data, headers, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _pre_request(self, url, method = u\"get\", data = None, headers=None, **kwargs):\n        header = {\n            u\"Content-Type\": u\"application/json\",\n            u\"User-Agent\": u\"salesking_api_py_v1\",\n        }\n        if headers:\n            headers.update(header)\n        else:\n            headers = header\n        if url.find(self.base_url) !=0:\n            url = u\"%s%s\" %(self.base_url, url)\n        return (url, method, data, headers, kwargs)", "response": "hook for manipulating the _pre request data\n            u\"base_url u\" data \\ u2026 \\ u2027 \\ u2028 \\ u2029 \\ u2029 \\ u2029 \\ u2028 \\ u2029 \\ u2029 \\ u2029 \\ u2029 \\ u2028 \\ u2029 \\ u2029 \\ u2029 \\ u2028 \\ u2029 \\ u2029 \\ u2029 \\ u2028 \\ u"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _request(self, url, method = u\"get\", data = None, headers=None, **kwargs):\n        #        if self.access_token:\n        #            auth_header = {\n        #                u\"Authorization\": \"Bearer %s\" % (self.access_token)\n        #            }\n        #            headers.update(auth_header)\n        #basic auth\n        msg = \"method: %s url:%s\\nheaders:%s\\ndata:%s\" % (\n            method, url, headers, data)\n        #print msg\n        if not self.use_oauth:\n            auth = (self.sk_user, self.sk_pw)\n            if not self.client:\n                self.client = requests.session()\n            r = self.client.request(method, url, headers=headers, data=data, auth=auth,**kwargs)\n        else:\n            if not self.client:\n                self.client = requests.session(hooks={'pre_request': oauth_hook})\n            r = self.client.request(method, url, headers=headers, data=data,**kwargs)\n        return r", "response": "This function handles the request via requests. session."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _handle_response(self, response):\n        status = response.status_code\n        if status == 400:\n          msg = u\"bad request\"\n          raise exceptions.BadRequest(status, msg)\n        elif status == 401:\n          msg = u\"authorization failed user:%s\" % (self.sk_user)\n          raise exceptions.Unauthorized(status, msg)\n        elif status == 404:\n          raise exceptions.NotFound()\n        elif status == 422:\n          msg = u\"bad request\"\n          raise exceptions.BadRequest(status, msg)\n        elif status in range(400, 500):\n          msg = u\"unexpected bad request\"\n          raise exceptions.BadRequest(status, msg) \n        elif status in range(500, 600):\n          raise exceptions.ServerError()\n        return response", "response": "Handle the response from the API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef see_doc(obj_with_doc):\n    def decorator(fn):\n        fn.__doc__ = obj_with_doc.__doc__\n        return fn\n    return decorator", "response": "Copy docstring from existing object to the decorated callable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntrue if currently inside a class definition else False.", "response": "def class_in_progress(stack=None):\n    \"\"\"True if currently inside a class definition, else False.\"\"\"\n    if stack is None:\n        stack = inspect.stack()\n    for frame in stack:\n        statement_list = frame[4]\n        if statement_list is None:\n            continue\n        if statement_list[0].strip().startswith('class '):\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting initial yield value or result of send name.", "response": "def get(self, name=None):\n        \"\"\"Get initial yield value, or result of send(name) if name given.\"\"\"\n        if name is None:\n            return self.init_value\n        elif not self.support_name:\n            msg = \"generator does not support get-by-name: function {!r}\"\n            raise TypeError(msg.format(self.function))\n        try:\n            value = self.generator.send(name)\n        except StopIteration:\n            msg = \"generator didn't yield: function {!r}\"\n            raise RuntimeError(msg.format(self.function))\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the annotations of a given callable.", "response": "def get_annotations(cls, __fn):\n        \"\"\"Get the annotations of a given callable.\"\"\"\n        if hasattr(__fn, '__func__'):\n            __fn = __fn.__func__\n        if hasattr(__fn, '__notes__'):\n            return __fn.__notes__\n        raise AttributeError('{!r} does not have annotations'.format(__fn))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the annotations on the given callable.", "response": "def set_annotations(cls, __fn, *notes, **keyword_notes):\n        \"\"\"Set the annotations on the given callable.\"\"\"\n        if hasattr(__fn, '__func__'):\n            __fn = __fn.__func__\n        if hasattr(__fn, '__notes__'):\n            msg = 'callable already has notes: {!r}'\n            raise AttributeError(msg.format(__fn))\n        __fn.__notes__ = (notes, keyword_notes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wraps(__fn, **kw):\n        kw['assigned'] = kw.get('assigned', WRAPPER_ASSIGNMENTS)\n        return functools.wraps(__fn, **kw)", "response": "Like functools. wraps with support for annotations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwrapping a function for injection of a partially applied function.", "response": "def partial(__fn, *a, **kw):\n        \"\"\"Wrap a note for injection of a partially applied function.\n\n        This allows for annotated functions to be injected for composition::\n\n            from jeni import annotate\n\n            @annotate('foo', bar=annotate.maybe('bar'))\n            def foobar(foo, bar=None):\n                return\n\n            @annotate('foo', annotate.partial(foobar))\n            def bazquux(foo, fn):\n                # fn: injector.partial(foobar)\n                return\n\n        Keyword arguments are treated as `maybe` when using partial, in order\n        to allow partial application of only the notes which can be provided,\n        where the caller could then apply arguments known to be unavailable in\n        the injector. Note that with Python 3 function annotations, all\n        annotations are injected as keyword arguments.\n\n        Injections on the partial function are lazy and not applied until the\n        injected partial function is called. See `eager_partial` to inject\n        eagerly.\n        \"\"\"\n        return (PARTIAL, (__fn, a, tuple(kw.items())))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps a note for injection of a partially applied function or don t. may", "response": "def partial_regardless(__fn, *a, **kw):\n        \"\"\"Wrap a note for injection of a partially applied function, or don't.\n\n        Use this instead of `partial` when binding a callable that may or may\n        not have annotations.\n        \"\"\"\n        return (PARTIAL_REGARDLESS, (__fn, a, tuple(kw.items())))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping a note for injection of an eagerly partially applied function.", "response": "def eager_partial(__fn, *a, **kw):\n        \"\"\"Wrap a note for injection of an eagerly partially applied function.\n\n        Use this instead of `partial` when eager injection is needed in place\n        of lazy injection.\n        \"\"\"\n        return (EAGER_PARTIAL, (__fn, a, tuple(kw.items())))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap a note for injection of an eagerly partially applied function or don t. eager_partial_regardless", "response": "def eager_partial_regardless(__fn, *a, **kw):\n        \"\"\"Wrap a note for injection of an eagerly partially applied function, or don't.\n\n        Use this instead of `eager_partial partial` when binding a callable\n        that may or may not have annotations.\n        \"\"\"\n        return (EAGER_PARTIAL_REGARDLESS, (__fn, a, tuple(kw.items())))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister a provider class.", "response": "def provider(cls, note, provider=None, name=False):\n        \"\"\"Register a provider, either a Provider class or a generator.\n\n        Provider class::\n\n            from jeni import Injector as BaseInjector\n            from jeni import Provider\n\n            class Injector(BaseInjector):\n                pass\n\n            @Injector.provider('hello')\n            class HelloProvider(Provider):\n                def get(self, name=None):\n                    if name is None:\n                        name = 'world'\n                    return 'Hello, {}!'.format(name)\n\n        Simple generator::\n\n            @Injector.provider('answer')\n            def answer():\n                yield 42\n\n        If a generator supports get with a name argument::\n\n            @Injector.provider('spam', name=True)\n            def spam():\n                count_str = yield 'spam'\n                while True:\n                    count_str = yield 'spam' * int(count_str)\n\n        Registration can be a decorator or a direct method call::\n\n            Injector.provider('hello', HelloProvider)\n        \"\"\"\n        def decorator(provider):\n            if inspect.isgeneratorfunction(provider):\n                # Automatically adapt generator functions\n                provider = cls.generator_provider.bind(\n                        provider, support_name=name)\n                return decorator(provider)\n\n            cls.register(note, provider)\n            return provider\n\n        if provider is not None:\n            decorator(provider)\n        else:\n            return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a function as a provider.", "response": "def factory(cls, note, fn=None):\n        \"\"\"Register a function as a provider.\n\n        Function (name support is optional)::\n\n            from jeni import Injector as BaseInjector\n            from jeni import Provider\n\n            class Injector(BaseInjector):\n                pass\n\n            @Injector.factory('echo')\n            def echo(name=None):\n                return name\n\n        Registration can be a decorator or a direct method call::\n\n            Injector.factory('echo', echo)\n        \"\"\"\n        def decorator(f):\n            provider = cls.factory_provider.bind(f)\n            cls.register(note, provider)\n            return f\n\n        if fn is not None:\n            decorator(fn)\n        else:\n            return decorator"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a function with closure to lazily inject annotated callable.", "response": "def partial(self, fn, *user_args, **user_kwargs):\n        \"\"\"Return function with closure to lazily inject annotated callable.\n\n        Repeat calls to the resulting function will reuse injections from the\n        first call.\n\n        Positional arguments are provided in this order:\n\n        1. positional arguments provided by injector\n        2. positional arguments provided in `partial_fn = partial(fn, *args)`\n        3. positional arguments provided in `partial_fn(*args)`\n\n        Keyword arguments are resolved in this order (later override earlier):\n\n        1. keyword arguments provided by injector\n        2. keyword arguments provided in `partial_fn = partial(fn, **kwargs)`\n        3. keyword arguments provided in `partial_fn(**kargs)`\n\n        Note that Python function annotations (in Python 3) are injected as\n        keyword arguments, as documented in `annotate`, which affects the\n        argument order here.\n\n        `annotate.partial` accepts arguments in same manner as this `partial`.\n        \"\"\"\n        self.get_annotations(fn) # Assert has annotations.\n        def lazy_injection_fn(*run_args, **run_kwargs):\n            arg_pack = getattr(lazy_injection_fn, 'arg_pack', None)\n            if arg_pack is not None:\n                pack_args, pack_kwargs = arg_pack\n            else:\n                jeni_args, jeni_kwargs = self.prepare_callable(fn, partial=True)\n                pack_args = jeni_args + user_args\n                pack_kwargs = {}\n                pack_kwargs.update(jeni_kwargs)\n                pack_kwargs.update(user_kwargs)\n                lazy_injection_fn.arg_pack = (pack_args, pack_kwargs)\n            final_args = pack_args + run_args\n            final_kwargs = {}\n            final_kwargs.update(pack_kwargs)\n            final_kwargs.update(run_kwargs)\n            return fn(*final_args, **final_kwargs)\n        return lazy_injection_fn"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nliking apply but applies if callable is not annotated.", "response": "def apply_regardless(self, fn, *a, **kw):\n        \"\"\"Like `apply`, but applies if callable is not annotated.\"\"\"\n        if self.has_annotations(fn):\n            return self.apply(fn, *a, **kw)\n        return fn(*a, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlike partial but applies if callable is not annotated.", "response": "def partial_regardless(self, fn, *a, **kw):\n        \"\"\"Like `partial`, but applies if callable is not annotated.\"\"\"\n        if self.has_annotations(fn):\n            return self.partial(fn, *a, **kw)\n        else:\n            return functools.partial(fn, *a, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef eager_partial_regardless(self, fn, *a, **kw):\n        if self.has_annotations(fn):\n            return self.eager_partial(fn, *a, **kw)\n        return functools.partial(fn, *a, **kw)", "response": "Like eager_partial but applies if callable is not annotated."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresolves a single note into an object.", "response": "def get(self, note):\n        \"\"\"Resolve a single note into an object.\"\"\"\n        if self.closed:\n            raise RuntimeError('{!r} already closed'.format(self))\n\n        # Record request for note even if it fails to resolve.\n        self.stats[note] += 1\n\n        # Handle injection of partially applied annotated functions.\n        if isinstance(note, tuple) and len(note) == 2:\n            if note[0] == PARTIAL:\n                fn, a, kw_items = note[1]\n                return self.partial(fn, *a, **dict(kw_items))\n            elif note[0] == PARTIAL_REGARDLESS:\n                fn, a, kw_items = note[1]\n                return self.partial_regardless(fn, *a, **dict(kw_items))\n            elif note[0] == EAGER_PARTIAL:\n                fn, a, kw_items = note[1]\n                return self.eager_partial(fn, *a, **dict(kw_items))\n            elif note[0] == EAGER_PARTIAL_REGARDLESS:\n                fn, a, kw_items = note[1]\n                return self.eager_partial_regardless(fn, *a, **dict(kw_items))\n\n        basenote, name = self.parse_note(note)\n        if name is None and basenote in self.values:\n            return self.values[basenote]\n        try:\n            provider_factory = self.lookup(basenote)\n        except LookupError:\n            msg = \"Unable to resolve '{}'\"\n            raise LookupError(msg.format(note))\n\n        self.instantiating.append((basenote, name))\n        try:\n            if self.instantiating.count((basenote, name)) > 1:\n                stack = ' <- '.join(repr(note) for note in self.instantiating)\n                notes = tuple(self.instantiating)\n                raise DependencyCycleError(stack, notes=notes)\n\n            return self.handle_provider(provider_factory, note)\n        finally:\n            self.instantiating.pop()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclose the injector & injected Provider instances.", "response": "def close(self):\n        \"\"\"Close injector & injected Provider instances, including generators.\n\n        Providers are closed in the reverse order in which they were opened,\n        and each provider is only closed once. Providers are closed if accessed\n        by the injector, even if a dependency is not successfully provided. As\n        such, providers should determine whether or not anything needs to be\n        done in the close method.\n        \"\"\"\n        if self.closed:\n            raise RuntimeError('{!r} already closed'.format(self))\n        for finalizer in reversed(self.finalizers):\n            # Note: Unable to apply injector on close method.\n            finalizer()\n        self.closed = True\n        self.instances.clear()\n        self.values.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprepare arguments required to apply function fn.", "response": "def prepare_callable(self, fn, partial=False):\n        \"\"\"Prepare arguments required to apply function.\"\"\"\n        notes, keyword_notes = self.get_annotations(fn)\n        return self.prepare_notes(*notes, __partial=partial, **keyword_notes)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget injection values for all given notes.", "response": "def prepare_notes(self, *notes, **keyword_notes):\n        \"\"\"Get injection values for all given notes.\"\"\"\n        __partial = keyword_notes.pop('__partial', False)\n        args = tuple(self.get(note) for note in notes)\n        kwargs = {}\n        for arg in keyword_notes:\n            note = keyword_notes[arg]\n            if isinstance(note, tuple) and len(note) == 2 and note[0] == MAYBE:\n                try:\n                    kwargs[arg] = self.get(note[1])\n                except LookupError:\n                    continue\n            elif __partial:\n                try:\n                    kwargs[arg] = self.get(note)\n                except LookupError:\n                    continue\n            else:\n                kwargs[arg] = self.get(note)\n        return args, kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing string annotation into object reference with optional name.", "response": "def parse_note(cls, note):\n        \"\"\"Parse string annotation into object reference with optional name.\"\"\"\n        if isinstance(note, tuple):\n            if len(note) != 2:\n                raise ValueError('tuple annotations must be length 2')\n            return note\n        try:\n            match = cls.re_note.match(note)\n        except TypeError:\n            # Note is not a string. Support any Python object as a note.\n            return note, None\n        return match.groups()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle a provider call.", "response": "def handle_provider(self, provider_factory, note):\n        \"\"\"Get value from provider as requested by note.\"\"\"\n        # Implementation in separate method to support accurate book-keeping.\n        basenote, name = self.parse_note(note)\n\n        # _handle_provider could be even shorter if\n        # Injector.apply() worked with classes, issue #9.\n        if basenote not in self.instances:\n            if (isinstance(provider_factory, type) and\n                    self.has_annotations(provider_factory.__init__)):\n                args, kwargs = self.prepare_callable(provider_factory.__init__)\n                self.instances[basenote] = provider_factory(*args, **kwargs)\n\n            else:\n                self.instances[basenote] = self.apply_regardless(\n                        provider_factory)\n\n            provider = self.instances[basenote]\n            if hasattr(provider, 'close'):\n                self.finalizers.append(self.instances[basenote].close)\n\n        provider = self.instances[basenote]\n        get = self.partial_regardless(provider.get)\n\n        try:\n            if name is not None:\n                return get(name=name)\n            self.values[basenote] = get()\n            return self.values[basenote]\n\n        except UnsetError:\n            # Use sys.exc_info to support both Python 2 and Python 3.\n            exc_type, exc_value, tb = sys.exc_info()\n            exc_msg = str(exc_value)\n            if exc_msg:\n                msg = '{}: {!r}'.format(exc_msg, note)\n            else:\n                msg = repr(note)\n            six.reraise(exc_type, exc_type(msg, note=note), tb)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlooks up note in registered annotations walking class tree.", "response": "def lookup(cls, basenote):\n        \"\"\"Look up note in registered annotations, walking class tree.\"\"\"\n        # Walk method resolution order, which includes current class.\n        for c in cls.mro():\n            if 'provider_registry' not in vars(c):\n                # class is a mixin, super to base class, or never registered.\n                continue\n            if basenote in c.provider_registry:\n                # note is in the registry.\n                return c.provider_registry[basenote]\n        raise LookupError(repr(basenote))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating and instantiate a sub - injector.", "response": "def sub(cls, *mixins_and_dicts, **values):\n        \"\"\"Create and instantiate a sub-injector.\n\n        Mixins and local value dicts can be passed in as arguments.  Local\n        values can also be passed in as keyword arguments.\n        \"\"\"\n\n        class SubInjector(cls):\n            pass\n\n        mixins = [ x for x in mixins_and_dicts if isinstance(x, type) ]\n        if mixins:\n            SubInjector.__bases__ = tuple(mixins) + SubInjector.__bases__\n\n        dicts = [ x for x in mixins_and_dicts if not isinstance(x, type) ]\n        for d in reversed(dicts):\n            for k,v in d.items():\n                if k not in values:\n                    values[k] = v\n\n        for k,v in values.items():\n            SubInjector.value(k, v)\n\n        return SubInjector()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives the details on the args of the given function. r\"\"\" Gives the details on the args of the given function. r\"\"\" Returns the OrderedDict of the arguments that are passed to the function.", "response": "def _getFuncArgs(func):\n  r\"\"\"Gives the details on the args of the given func.\n\n  Args:\n    func (function): The function to get details on.\n  \"\"\"\n  code = func.func_code\n  Defaults = func.func_defaults\n\n  nargs = code.co_argcount\n  ArgNames = code.co_varnames[:nargs]\n\n  Args = OrderedDict()\n  argCount = len(ArgNames)\n  defCount = len(Defaults) if Defaults else 0\n  diff = argCount - defCount\n\n  for i in range(0, diff):\n    Args[ArgNames[i]] = {}\n\n  for i in range(diff, argCount):\n    Args[ArgNames[i]] = {'default': Defaults[i - diff]}\n\n  return Args"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a customized form label if condition is met otherwise returns the default form label.", "response": "def get_form_label(self, request=None, obj=None, model=None, form=None):\n        \"\"\"Returns a customized form label, if condition is met,\n        otherwise returns the default form label.\n\n        * condition is an instance of CustomLabelCondition.\n        \"\"\"\n        label = form.base_fields[self.field].label\n        condition = self.condition_cls(request=request, obj=obj, model=model)\n        if condition.check():\n            additional_opts = condition.get_additional_options(\n                request=request, obj=obj, model=model\n            )\n            visit_datetime = \"\"\n            if obj:\n                visit_datetime = getattr(\n                    obj, obj.visit_model_attr()\n                ).report_datetime.strftime(\"%B %Y\")\n            try:\n                label = self.custom_label.format(\n                    appointment=condition.appointment,\n                    previous_appointment=condition.previous_appointment,\n                    previous_obj=condition.previous_obj,\n                    previous_visit=condition.previous_visit,\n                    visit_datetime=visit_datetime,\n                    **additional_opts,\n                )\n            except KeyError as e:\n                raise CustomFormLabelError(\n                    f\"Custom label template has invalid keys. See {label}. Got {e}.\"\n                )\n        return label"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_stack(self,args):\n        parser = CommandArgumentParser(\"stack\")\n        parser.add_argument(dest='stack',help='stack index or name');\n        parser.add_argument('-a','--asg',dest='asg',help='descend into specified asg');\n        args = vars(parser.parse_args(args))\n\n        try:\n            index = int(args['stack'])\n            if self.stackList == None:\n                self.do_stacks('-s')\n            stack = AwsConnectionFactory.instance.getCfResource().Stack(self.stackList[index]['StackName'])\n        except ValueError:\n            stack = AwsConnectionFactory.instance.getCfResource().Stack(args['stack'])\n\n\n        if 'asg' in args:\n            AwsProcessor.processorFactory.Stack(stack,stack.name,self).onecmd('asg {}'.format(args['asg']))\n        AwsProcessor.processorFactory.Stack(stack,stack.name,self).cmdloop()", "response": "Go to the specified stack. stack - h for detailed help"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete specified stack. delete_stack - h for detailed help.", "response": "def do_delete_stack(self,args):\n        \"\"\"Delete specified stack. delete_stack -h for detailed help.\"\"\"\n        parser = CommandArgumentParser(\"delete_stack\")\n        parser.add_argument(dest='stack',help='stack index or name');\n        args = vars(parser.parse_args(args))\n\n        try:\n            index = int(args['stack'])\n            if self.stackList == None:\n                self.do_stacks('-s')\n            stack = AwsConnectionFactory.instance.getCfResource().Stack(self.stackList[index]['StackName'])\n        except ValueError:\n            stack = AwsConnectionFactory.instance.getCfResource().Stack(args['stack'])\n\n        print \"Here are the details of the stack you are about to delete:\"\n        print \"Stack.name: {}\".format(stack.name)\n        print \"Stack.stack_id: {}\".format(stack.stack_id)\n        print \"Stack.creation_time: {}\".format(stack.creation_time)\n        confirmation = raw_input(\"If you are sure, enter the Stack.name here: \")\n        if stack.name == confirmation:\n            stack.delete()\n            print \"Stack deletion in progress\"\n        else:\n            print \"Stack deletion canceled: '{}' != '{}'\".format(stack.name,confirmation)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists available stacks. stacks - h for detailed help.", "response": "def do_stacks(self,args):\n        \"\"\"List available stacks. stacks -h for detailed help.\"\"\"\n        parser = CommandArgumentParser()\n        parser.add_argument('-s','--silent',dest='silent',action='store_true',help='Run silently')\n        parser.add_argument('-i','--include',nargs='*',dest='includes',default=[],help='Add statuses')\n        parser.add_argument('-e','--exclude',nargs='*',dest='excludes',default=[],help='Remove statuses')\n        parser.add_argument('--summary',dest='summary',action='store_true',default=False,help='Show just a summary')\n        parser.add_argument(dest='filters',nargs='*',default=[\"*\"],help='Filter stacks')\n        args = vars(parser.parse_args(args))\n\n        nextToken = None\n\n        includes = args['includes']\n        excludes = args['excludes']\n        filters = args['filters']\n\n        global stackStatusFilter\n        for i in includes:            \n            if not i in stackStatusFilter:\n                stackStatusFilter.append(i)\n        for e in excludes:\n            stackStatusFilter.remove(e)\n\n        complete = False;\n        stackSummaries = []\n        while not complete:\n            if None == nextToken:\n                stacks = AwsConnectionFactory.getCfClient().list_stacks(StackStatusFilter=stackStatusFilter)\n            else:\n                stacks = AwsConnectionFactory.getCfClient().list_stacks(NextToken=nextToken,StackStatusFilter=stackStatusFilter)\n                #pprint(stacks)\n            if not 'NextToken' in stacks:\n                complete = True;\n            else:\n                nextToken = stacks['NextToken']\n\n            if 'StackSummaries' in stacks:\n                stackSummaries.extend(stacks['StackSummaries'])\n\n        stackSummaries = filter( lambda x: fnmatches(x['StackName'],filters),stackSummaries)\n        stackSummaries = sorted(stackSummaries, key= lambda entry: entry['StackName'])\n        index = 0;\n        stackSummariesByIndex = {}\n        for summary in stackSummaries:\n            summary['Index'] = index\n            stackSummariesByIndex[index] = summary\n            index += 1\n\n        self.stackList = stackSummariesByIndex\n        if not (args['silent'] or args['summary']):\n            for index,summary in stackSummariesByIndex.items():\n                print '{0:3d}: {2:20} {1:40} {3}'.format(summary['Index'],summary['StackName'],summary['StackStatus'],defaultifyDict(summary,'StackStatusReason',''))\n\n        if args['summary'] and not args['silent']:\n            print '{} stacks'.format(len(stackSummariesByIndex))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_stack_resource(self, args):\n        parser = CommandArgumentParser()\n        parser.add_argument('-s','--stack-name',dest='stack-name',help='name of the stack resource');\n        parser.add_argument('-i','--logical-id',dest='logical-id',help='logical id of the child resource');\n        args = vars(parser.parse_args(args))\n\n        stackName = args['stack-name']\n        logicalId = args['logical-id']\n\n        self.stackResource(stackName,logicalId)", "response": "Use specified stack resource. stack_resource - h for detailed help."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef searchTag(self,HTAG=\"#python\"):\n        self.t = Twython(app_key           =self.app_key           ,\n                        app_secret         =self.app_secret        ,\n                        oauth_token        =self.oauth_token       ,\n                        oauth_token_secret =self.oauth_token_secret)\n\n        search =self.t.search(q=HTAG,count=100,result_type=\"recent\")\n        ss=search[:]\n        search = self.t.search(q=HTAG,count=150,max_id=ss[-1]['id']-1,result_type=\"recent\")\n        #search = t.search(q=HTAG,count=150,since_id=ss[-1]['id'],result_type=\"recent\")\n        while seach:\n            ss+=search[:]\n            search = self.t.search(q=HTAG,count=150,max_id=ss[-1]['id']-1,result_type=\"recent\")\n        self.ss=ss", "response": "Search for a tag in the twitter database"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_upload_id(cls, tables: I2B2Tables, upload_id: int) -> int:\n        return cls._delete_upload_id(tables.crc_connection, tables.observation_fact, upload_id)", "response": "Delete all observation_fact records with the supplied upload_id."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete all records with the supplied sourcesystem_cd.", "response": "def delete_sourcesystem_cd(cls, tables: I2B2Tables, sourcesystem_cd: str) -> int:\n        \"\"\"\n        Delete all records with the supplied sourcesystem_cd\n        :param tables: i2b2 sql connection\n        :param sourcesystem_cd: sourcesystem_cd to remove\n        :return: number or records that were deleted\n        \"\"\"\n        return cls._delete_sourcesystem_cd(tables.crc_connection, tables.observation_fact, sourcesystem_cd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds or update the records to the observation_fact table as needed to reflect the contents of records .", "response": "def add_or_update_records(cls, tables: I2B2Tables, records: List[\"ObservationFact\"]) -> Tuple[int, int]:\n        \"\"\"\n        Add or update the observation_fact table as needed to reflect the contents of records\n        :param tables: i2b2 sql connection\n        :param records: records to apply\n        :return: number of records added / modified\n        \"\"\"\n        return cls._add_or_update_records(tables.crc_connection, tables.observation_fact, records)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _date_val(self, dt: datetime) -> None:\n        self._tval_char = dt.strftime('%Y-%m-%d %H:%M')\n        self._nval_num = (dt.year * 10000) + (dt.month * 100) + dt.day + \\\n                         (((dt.hour / 100.0) + (dt.minute / 10000.0)) if isinstance(dt, datetime) else 0)", "response": "Add a date value to the set of key - value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconfiguring the thread pool and monitor threads", "response": "def configure(self, config):\n        \"\"\"\n        Configure Monitor, pull list of what to monitor, initialize threads\n        \"\"\"\n        self.config = config\n        self.update_monitors()\n\n        # initialize thread pools\n        for profile in ('worker', 'result'):\n            for _ in range(config['threads'][profile]['number']):\n                worker = threading.Thread(target=config['threads'][profile]['function'])\n                worker.daemon = True\n                worker.start()\n\n        # send a heartbeat right away\n        self.heartbeat()\n\n        # setup interval jobs\n        self.refresh_stopper = set_interval(config['interval']['refresh']*1000,\n                                            self.update_monitors)\n        self.heartbeat_stopper = set_interval(config['interval']['heartbeat']*1000,\n                                              self.heartbeat)\n        self.reporting_stopper = set_interval(config['interval']['reporting']*1000,\n                                              self.reporting)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfeeds the monitors to the workers queue.", "response": "def feed_monitors(self):\n        \"\"\"\n        Pull from the cached monitors data and feed the workers queue.  Run\n        every interval (refresh:test).\n        \"\"\"\n        self.thread_debug(\"Filling worker queue...\", module='feed_monitors')\n        for mon in self.monitors:\n            self.thread_debug(\"    Adding \" + mon['title'])\n            self.workers_queue.put(mon)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start(self):\n        while True:\n            self.thread_debug(\"Interval starting\")\n            for thr in threading.enumerate():\n                self.thread_debug(\"    \" + str(thr))\n            self.feed_monitors()\n            start = time.time()\n            # wait fore queue to empty\n            self.workers_queue.join()\n            end = time.time()\n            diff = self.config['interval']['test'] - (end - start)\n            if diff <= 0:\n                # alarm\n                self.stats.procwin = -diff\n                self.thread_debug(\"Cannot keep up with tests! {} seconds late\"\n                                  .format(abs(diff)))\n            else:\n                self.thread_debug(\"waiting {} seconds...\".format(diff))\n                time.sleep(diff)", "response": "The main loop for the main loop."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the list of monitors and instances in the cache.", "response": "def update_monitors(self):\n        \"\"\"\n        Periodically check in with Reflex Engine and refresh the list of what to monitor\n        \"\"\"\n        self.thread_debug(\"Starting monitor refresh\", module=\"update_monitors\")\n\n        # need to make a more efficient way of doing this via Reflex Engine\n        monitors = []\n        self.rcs.cache_reset()\n\n        svcs = self.rcs.cache_list('service',\n                                   cols=['pipeline', 'name',\n                                         'active-instances'])\n        for svc in svcs:\n            try:\n                pipeline = self.rcs.cache_get('pipeline', svc['pipeline'])\n                for mon in pipeline.get('monitor', []):\n                    self.DEBUG(\"monitor {}\".format(mon))\n                    mon['service'] = svc['name']\n                    mon['pipeline'] = svc['pipeline']\n                    for inst_name in svc.get('active-instances', []):\n                        inst = self.rcs.cache_get('instance', inst_name)\n\n                        # todo: insert: macro flatten\n\n                        mymon = mon.copy()\n                        mymon['instance'] = inst_name\n                        mymon['target'] = inst['address']\n                        mymon['title'] = svc['name'] + \": \" + mon['name']\n                        monitors.append(mymon)\n            except KeyboardInterrupt:\n                raise\n            except: # pylint: disable=bare-except\n                self.NOTIFY(\"Error in processing monitor:\", err=traceback.format_exc())\n\n        self.NOTIFY(\"Refreshed monitors\", total_monitors=len(monitors))\n        self.DEBUG(\"Monitors\", monitors=monitors)\n\n        # mutex / threadsafe?\n        self.monitors = monitors\n        cache = self.rcs._cache # pylint: disable=protected-access\n        self.instances = cache['instance']\n        self.services = cache['service']\n        self.pipelines = cache['pipeline']\n        self.thread_debug(\"Refresh complete\", module=\"update_monitors\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef thread_debug(self, *args, **kwargs):\n        if 'module' not in kwargs:\n            kwargs['module'] = \"Monitor\"\n        if kwargs['module'] != 'Monitor' and self.do_DEBUG(module='Monitor'):\n            self.debug[kwargs['module']] = True\n        if not self.do_DEBUG(module=kwargs['module']):\n            return\n        thread_id = threading.current_thread().name\n        key = \"[\" + thread_id + \"] \" + kwargs['module']\n        if not self.debug.get(key):\n            self.debug[key] = True\n        kwargs['module'] = key\n        self.DEBUG(*args, **kwargs)", "response": "Wrap debug to include thread information"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef worker_thread(self):\n        self.thread_debug(\"Starting monitor thread\")\n        while not self.thread_stopper.is_set():\n            mon = self.workers_queue.get()\n            self.thread_debug(\"Processing {type} Monitor: {title}\".format(**mon))\n            result = getattr(self, \"_worker_\" + mon['type'])(mon)\n            self.workers_queue.task_done()\n            self.results_queue.put({'type':mon['type'], 'result':result})", "response": "The main worker thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _worker_http(self, monitor):\n        self.thread_debug(\"process_http\", data=monitor, module='handler')\n        query = monitor['query']\n        method = query['method'].lower()\n        self.stats.http_run += 1\n        try:\n            target = monitor['target']\n            url = 'http://{host}:{port}{path}'.format(path=query['path'], **target)\n            response = {\n                'url': url,\n                'status': 'failed',\n                'result': {},\n                'monitor': monitor,\n                'message': 'did not meet expected result or no expected result defined',\n                'elapsedms': monitor['timeout']*1000,\n                'code':0\n            }\n\n            # not sed_env_dict -- we do not want to xref headers\n            headers = query.get('headers', {})\n            for elem in headers:\n                headers[elem] = self.sed_env(headers[elem], {}, '')\n\n            res = response['result'] = getattr(requests, method)(url,\n                                                                 headers=headers,\n                                                                 timeout=monitor['timeout'])\n            response['code'] = res.status_code\n            response['elapsedms'] = res.elapsed.total_seconds() * 1000\n            if 'response-code' in monitor['expect']:\n                if int(monitor['expect']['response-code']) == res.status_code:\n                    response['message'] = ''\n                    response['status'] = 'ok'\n                else: # abort with failure, do not pass go\n                    return response\n\n            if 'content' in monitor['expect']:\n                if monitor['expect']['content'] in res.text:\n                    response['message'] = ''\n                    response['status'] = 'ok'\n                else: # abort with failure, do not pass go\n                    return response\n\n            if 'regex' in monitor['expect']:\n                if re.search(monitor['expect']['regex'], res.text):\n                    response['message'] = ''\n                    response['status'] = 'ok'\n                else: # abort with failure, do not pass go\n                    return response\n\n        except requests.exceptions.Timeout:\n            response['message'] = 'timeout'\n        except requests.exceptions.ConnectionError:\n            response['message'] = 'connect-failed'\n            response['elapsedms'] = -1\n        return response", "response": "Process an http monitor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handler_http(self, result):\n        monitor = result['monitor']\n        self.thread_debug(\"process_http\", data=monitor, module='handler')\n        self.stats.http_handled += 1\n\n        # splunk will pick this up\n        logargs = {\n            'type':\"metric\",\n            'endpoint': result['url'],\n            'pipeline': monitor['pipeline'],\n            'service': monitor['service'],\n            'instance': monitor['instance'],\n            'status': result['status'],\n            'elapsed-ms': round(result['elapsedms'], 5),\n            'code': result['code']\n        }\n        self.NOTIFY(result['message'], **logargs)\n\n        # if our status has changed, also update Reflex Engine\n        if result['status'] != self.instances[monitor['instance']]['status']:\n            # do some retry/counter steps on failure?\n            self.instances[monitor['instance']]['status'] = result['status']\n            self.rcs.patch('instance',\n                           monitor['instance'],\n                           {'status': result['status']})", "response": "Handle the result of an http monitor"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreports on consumption info", "response": "def reporting(self):\n        \"\"\"\n        report on consumption info\n        \"\"\"\n        self.thread_debug(\"reporting\")\n        res = resource.getrusage(resource.RUSAGE_SELF)\n        self.NOTIFY(\"\",\n                    type='internal-usage',\n                    maxrss=round(res.ru_maxrss/1024, 2),\n                    ixrss=round(res.ru_ixrss/1024, 2),\n                    idrss=round(res.ru_idrss/1024, 2),\n                    isrss=round(res.ru_isrss/1024, 2),\n                    threads=threading.active_count(),\n                    proctot=len(self.monitors),\n                    procwin=self.stats.procwin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npings heartbeat to statuscake sayin we are alive and okay.", "response": "def heartbeat(self):\n        \"\"\"\n        Watch our counters--as long as things are incrementing, send a ping to\n        statuscake sayin we are alive and okay.\n        \"\"\"\n\n        self.thread_debug(\"heartbeat\")\n\n        # check stats -- should be incrementing\n        if self.last_stats:\n            if self.stats.http_run <= self.last_stats.http_run:\n                self.NOTIFY(\"No monitors run since last heartbeat!\", service=\"heartbeat\")\n                return\n            elif self.stats.http_handled <= self.last_stats.http_handled:\n                self.NOTIFY(\"No monitor results handled since last heartbeat!\", service=\"heartbeat\")\n                return\n\n        # ping heartbeat as a webhook\n        if self.config.get('heartbeat-hook'):\n            result = requests.get(self.config.get('heartbeat-hook'))\n            if result.status_code != 200:\n                self.NOTIFY(\"Heartbeat ping to statuscake failed!\", level=\"ERROR\")\n\n        # keep a static copy of the last run stats\n        self.last_stats = self.stats.copy()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start_agent(self, cfgin=True):\n\n        default_conf = {\n            \"threads\": {\n                \"result\": {\n                    \"number\": 0,\n                    \"function\": None\n                },\n                \"worker\": {\n                    \"number\": 0,\n                    \"function\": None\n                },\n            },\n            \"interval\": {\n                \"refresh\": 900,\n                \"heartbeat\": 300,\n                \"reporting\": 300,\n                \"test\": 60\n            },\n            \"heartbeat-hook\": False\n        }\n        indata = {}\n        if cfgin:\n            indata = json.load(sys.stdin)\n        elif os.environ.get(\"REFLEX_MONITOR_CONFIG\"):\n            indata = os.environ.get(\"REFLEX_MONITOR_CONFIG\")\n            if indata[0] != \"{\":\n                indata = base64.b64decode(indata)\n        else:\n            self.NOTIFY(\"Using default configuration\")\n\n        conf = dictlib.union(default_conf, indata)\n\n        conf['threads']['result']['function'] = self.handler_thread\n        conf['threads']['worker']['function'] = self.worker_thread\n\n        self.NOTIFY(\"Starting monitor Agent\")\n        try:\n            self.configure(conf).start()\n        except KeyboardInterrupt:\n            self.thread_stopper.set()\n            if self.refresh_stopper:\n                self.refresh_stopper.set()\n            if self.heartbeat_stopper:\n                self.heartbeat_stopper.set()\n            if self.reporting_stopper:\n                self.reporting_stopper.set()", "response": "Start the monitor Agent."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setActiveModule(Module):\r\n  module_name = Module.__name__\r\n\r\n  if module_name not in ModuleMembers:\r\n    ModuleMembers[module_name] = []\r\n    ModulesQ.append(module_name)\r\n    Group(Module, {}) # brand the module with __ec_member__\r\n\r\n  state.ActiveModuleMemberQ = ModuleMembers[module_name]", "response": "r Helps with collecting the members of the imported modules."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef memoize(fn):\n    '''Cache the results of a function that only takes positional arguments.'''\n\n    cache = {}\n\n    @wraps(fn)\n    def wrapped_function(*args):\n        if args in cache:\n            return cache[args]\n\n        else:\n            result = fn(*args)\n            cache[args] = result\n            return result\n\n    return wrapped_function", "response": "Cache the results of a function that only takes positional arguments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup_config(epab_version: str):\n    logger = logging.getLogger('EPAB')\n    logger.debug('setting up config')\n    elib_config.ELIBConfig.setup(\n        app_name='EPAB',\n        app_version=epab_version,\n        config_file_path='pyproject.toml',\n        config_sep_str='__',\n        root_path=['tool', 'epab']\n    )\n    elib_config.write_example_config('pyproject.toml.example')\n    if not pathlib.Path('pyproject.toml').exists():\n        raise FileNotFoundError('pyproject.toml')\n    elib_config.validate_config()", "response": "Setup the elib_config package"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget amount of months between dates http://stackoverflow. com/a/4040338", "response": "def get_months_apart(d1, d2):\n    \"\"\"\n    Get amount of months between dates\n    http://stackoverflow.com/a/4040338\n    \"\"\"\n\n    return (d1.year - d2.year)*12 + d1.month - d2.month"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_month_list(to_date, from_date):\n\n    num_months = get_months_apart(to_date, from_date)\n    month_offset = from_date.month\n    month_list = []\n    for month in range(month_offset-1, month_offset+num_months):\n        year = from_date.year+(month/12)\n        real_month = (month % 12) + 1\n        month_list.append((year, real_month))\n\n    return month_list", "response": "Generate a list containing year + month between two dates."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_amplitude(chunk):\n    return (abs(int(chunk.max() - chunk.min())) / config.SAMPLE_RANGE)", "response": "Calculates the 0 - 1 amplitude of an audio chunk."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchanges the amplitude according to the change rate and drift target.", "response": "def step_amp(self):\n        \"\"\"\n        Change the amplitude according to the change rate and drift target.\n\n        Returns: None\n        \"\"\"\n        difference = self.drift_target - self._raw_value\n        if abs(difference) < self.change_rate:\n            self.value = self.drift_target\n        else:\n            delta = self.change_rate * numpy.sign(difference)\n            self.value = self._raw_value + delta"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of file - based module loaders.", "response": "def get_supported_file_loaders_2(force=False):\n    \"\"\"Returns a list of file-based module loaders.\n    Each item is a tuple (loader, suffixes).\n    \"\"\"\n\n    if force or (2, 7) <= sys.version_info < (3, 4):  # valid until which py3 version ?\n\n        import imp\n\n        loaders = []\n        for suffix, mode, type in imp.get_suffixes():\n            if type == imp.PY_SOURCE:\n                loaders.append((SourceFileLoader2, [suffix]))\n            else:\n                loaders.append((ImpFileLoader2, [suffix]))\n        return loaders\n\n    elif sys.version_info >= (3, 4):  # valid from which py3 version ?\n\n        from importlib.machinery import (\n            SOURCE_SUFFIXES, SourceFileLoader,\n            BYTECODE_SUFFIXES, SourcelessFileLoader,\n            EXTENSION_SUFFIXES, ExtensionFileLoader,\n        )\n\n        # This is already defined in importlib._bootstrap_external\n        # but is not exposed.\n        extensions = ExtensionFileLoader, EXTENSION_SUFFIXES\n        source = SourceFileLoader, SOURCE_SUFFIXES\n        bytecode = SourcelessFileLoader, BYTECODE_SUFFIXES\n        return [extensions, source, bytecode]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a tuple of parent - module - name parent - path - attr - name", "response": "def _find_parent_path_names(self):\n        \"\"\"Returns a tuple of (parent-module-name, parent-path-attr-name)\"\"\"\n        parent, dot, me = self._name.rpartition('.')\n        if dot == '':\n            # This is a top-level module. sys.path contains the parent path.\n            return 'sys', 'path'\n        # Not a top-level module. parent-module.__path__ contains the\n        #  parent path.\n        return parent, '__path__'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_package(self, fullname):\n        filename = os.path.split(self.get_filename(fullname))[1]\n        filename_base = filename.rsplit('.', 1)[0]\n        tail_name = fullname.rpartition('.')[2]\n        return filename_base == '__init__' and tail_name != '__init__'", "response": "Concrete implementation of InspectLoader. is_package by checking if\n        the path returned by get_filename has a filename of '__init__.py'."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the module and inserts it into sys. modules.", "response": "def create_module(self, spec):\n        \"\"\"Creates the module, and also insert it into sys.modules, adding this onto py2 import logic.\"\"\"\n        mod = sys.modules.setdefault(spec.name, types.ModuleType(spec.name))\n        # we are using setdefault to satisfy https://docs.python.org/3/reference/import.html#loaders\n        return mod"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_module(self, fullname):\n\n        if fullname in sys.modules:\n            mod = sys.modules[fullname]\n            self.exec_module(mod)\n            # In this case we do not want to remove the module in case of error\n            # Ref : https://docs.python.org/3/reference/import.html#loaders\n        else:\n            try:\n                # Retrieving the spec to help creating module properly\n                spec = spec_from_loader(fullname, self)\n\n                # this will call create_module and also initialize the module properly (like for py3)\n                mod = module_from_spec(spec)\n\n                # as per https://docs.python.org/3/reference/import.html#loaders\n                assert mod.__name__ in sys.modules\n\n                self.exec_module(mod)\n                # We don't ensure that the import-related module attributes get\n                # set in the sys.modules replacement case.  Such modules are on\n                # their own.\n            except Exception as exc:\n                # TODO : log exception !\n                # as per https://docs.python.org/3/reference/import.html#loaders\n                if fullname in sys.modules:\n                    del sys.modules[fullname]\n                raise\n\n        return sys.modules[fullname]", "response": "Load the specified module into sys. modules and return it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_module(self, spec):\n        mod = super(NamespaceLoader2, self).create_module(spec)\n        # Set a few properties required by PEP 302\n        # mod.__file__ = [p for p in self.path]\n        # this will set mod.__repr__ to not builtin... shouldnt break anything in py2...\n        # CAREFUL : get_filename present implies the module has ONE location, which is not true with namespaces\n        return mod", "response": "Improve python2 semantics for module creation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_module(self, name):\n        _verbose_message('namespace module loaded with path {!r}', self.path)\n\n        # Adjusting code from LoaderBasics\n        if name in sys.modules:\n            mod = sys.modules[name]\n            self.exec_module(mod)\n            # In this case we do not want to remove the module in case of error\n            # Ref : https://docs.python.org/3/reference/import.html#loaders\n        else:\n            try:\n                # Building custom spec and loading as in _LoaderBasics...\n                spec = ModuleSpec(name, self, origin='namespace', is_package=True)\n                spec.submodule_search_locations = self.path\n\n                # this will call create_module and also initialize the module properly (like for py3)\n                mod = module_from_spec(spec)\n\n                # as per https://docs.python.org/3/reference/import.html#loaders\n                assert mod.__name__ in sys.modules\n\n                self.exec_module(mod)\n                # We don't ensure that the import-related module attributes get\n                # set in the sys.modules replacement case.  Such modules are on\n                # their own.\n            except:\n                # as per https://docs.python.org/3/reference/import.html#loaders\n                if name in sys.modules:\n                    del sys.modules[name]\n                raise\n\n        return sys.modules[name]", "response": "Load a namespace module as if coming from an empty file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_source(self, name):\n        path = self.get_filename(name)\n        try:\n            source_bytes = self.get_data(path)\n        except OSError as exc:\n            e = _ImportError('source not available through get_data()',\n                             name=name)\n            e.__cause__ = exc\n            raise e\n        return decode_source(source_bytes)", "response": "Concrete implementation of InspectLoader. get_source."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute the module using the old imp.", "response": "def exec_module(self, module):\n        \"\"\"Execute the module using the old imp.\"\"\"\n        path = [os.path.dirname(module.__file__)]  # file should have been resolved before (module creation)\n        file = None\n        try:\n            file, pathname, description = imp.find_module(module.__name__.rpartition('.')[-1], path)\n            module = imp.load_module(module.__name__, file, pathname, description)\n        finally:\n            if file:\n                file.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_module(self, name):\n        # Implementation inspired from pytest.rewrite and importlib\n\n        # If there is an existing module object named 'name' in\n        # sys.modules, the loader must use that existing module. (Otherwise,\n        # the reload() builtin will not work correctly.)\n        if name in sys.modules:\n            return sys.modules[name]\n        try:\n            # we have already done the search, an gone through package layers\n            # so we directly feed the latest module and correct path\n            # to reuse the logic for choosing the proper loading behavior\n\n            # TODO : double check maybe we do not need the loop here, already handled by finders in dir hierarchy\n            # TODO : use exec_module (recent, more tested API) from here\n            for name_idx, name_part in enumerate(name.split('.')):\n                pkgname = \".\".join(name.split('.')[:name_idx+1])\n                if pkgname not in sys.modules:\n                    if '.' in pkgname:\n                        # parent has to be in sys.modules. make sure it is a package, else fails\n                        if '__path__' in vars(sys.modules[pkgname.rpartition('.')[0]]):\n                            path = sys.modules[pkgname.rpartition('.')[0]].__path__\n                        else:\n                            raise ImportError(\"{0} is not a package (no __path__ detected)\".format(pkgname.rpartition('.')[0]))\n                    else:  # using __file__ instead. should always be there.\n                        path = os.path.dirname(sys.modules[pkgname].__file__)if pkgname in sys.modules else None\n                    try:\n                        file, pathname, description = imp.find_module(pkgname.rpartition('.')[-1], path)\n                        sys.modules[pkgname] = imp.load_module(pkgname, file, pathname, description)\n                    finally:\n                        if file:\n                            file.close()\n        except:\n            # dont pollute the interpreter environment if we dont know what we are doing\n            if name in sys.modules:\n                del sys.modules[name]\n            raise\n        return sys.modules[name]", "response": "Load a module from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef analyze_xml(xml):\n\n    f = StringIO(xml)\n\n    try:\n        xml = packtools.XMLValidator.parse(f, sps_version='sps-1.4')\n    except packtools.exceptions.PacktoolsError as e:\n        logger.exception(e)\n        summary = {}\n        summary['dtd_is_valid'] = False\n        summary['sps_is_valid'] = False\n        summary['is_valid'] = False\n        summary['parsing_error'] = True\n        summary['dtd_errors'] = []\n        summary['sps_errors'] = []\n        return summary\n    except XMLSyntaxError as e:\n        logger.exception(e)\n        summary = {}\n        summary['dtd_is_valid'] = False\n        summary['sps_is_valid'] = False\n        summary['is_valid'] = False\n        summary['parsing_error'] = True\n        summary['dtd_errors'] = [e.message]\n        summary['sps_errors'] = []\n        return summary\n    else:\n        summary = summarize(xml)\n\n        return summary", "response": "Analyzes file against packtools XMLValidator."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init_host(self):\n        env.host_string = self.host_string\n        env.user = self.host_user\n        env.password = self.host_passwd\n        env.key_filename = self.host_keyfile", "response": "Initialize the environment variables for the host object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nyielding filehandles from openers list and returns them as Filehandle objects.", "response": "def filehandles(path, openers_list=openers, pattern='', verbose=False):\n    \"\"\"Main function that iterates over list of openers and decides which opener to use.\n\n    :param str path: Path.\n    :param list openers_list: List of openers.\n    :param str pattern: Regular expression pattern.\n    :param verbose: Print additional information.\n    :type verbose: :py:obj:`True` or :py:obj:`False`\n    :return: Filehandle(s).\n    \"\"\"\n    if not verbose:\n        logging.disable(logging.VERBOSE)\n\n    for opener in openers_list:\n        try:\n            for filehandle in opener(path=path, pattern=pattern, verbose=verbose):\n                with closing(filehandle):\n                    yield filehandle\n            break  # use the first successful opener function\n\n        except (zipfile.BadZipfile, tarfile.ReadError, GZValidationError,\n                BZ2ValidationError, IOError, NotADirectoryError):\n             continue\n\n        else:\n            logger.verbose('No opener found for path: \"{}\"'.format(path))\n            yield None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gzip_opener(path, pattern='', verbose=False):\n    source = path if is_url(path) else os.path.abspath(path)\n    filename = os.path.basename(path)\n\n    if pattern and not re.match(pattern, filename):\n        logger.verbose('Skipping file: {}, did not match regex pattern \"{}\"'.format(os.path.abspath(filename), pattern))\n        return\n\n    try:\n        filehandle = gzip.GzipFile(fileobj=io.BytesIO(urlopen(path).read())) if is_url(path) else gzip.open(path)\n        filehandle.read(1)\n        filehandle.seek(0)\n        logger.verbose('Processing file: {}'.format(source))\n        yield filehandle\n    except (OSError, IOError):\n        raise GZValidationError", "response": "Opener that opens a single gzip compressed file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bz2_opener(path, pattern='', verbose=False):\n    source = path if is_url(path) else os.path.abspath(path)\n    filename = os.path.basename(path)\n\n    if pattern and not re.match(pattern, filename):\n        logger.verbose('Skipping file: {}, did not match regex pattern \"{}\"'.format(os.path.abspath(path), pattern))\n        return\n\n    try:\n        filehandle = bz2.open(io.BytesIO(urlopen(path).read())) if is_url(path) else bz2.open(path)\n        filehandle.read(1)\n        filehandle.seek(0)\n        logger.verbose('Processing file: {}'.format(source))\n        yield filehandle\n    except (OSError, IOError):\n        raise BZ2ValidationError", "response": "Opener that opens a single bz2 compressed file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef text_opener(path, pattern='', verbose=False):\n    source = path if is_url(path) else os.path.abspath(path)\n    filename = os.path.basename(path)\n\n    if pattern and not re.match(pattern, filename):\n        logger.verbose('Skipping file: {}, did not match regex pattern \"{}\"'.format(os.path.abspath(path), pattern))\n        return\n\n    filehandle = urlopen(path) if is_url(path) else open(path)\n    logger.verbose('Processing file: {}'.format(source))\n    yield filehandle", "response": "Opener that opens single text file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a random string of the given length from the given character set.", "response": "def random_string(length, charset):\n    \"\"\"\n    Return a random string of the given length from the\n    given character set.\n\n    :param int length: The length of string to return\n    :param str charset: A string of characters to choose from\n    :returns: A random string\n    :rtype: str\n    \"\"\"\n    n = len(charset)\n    return ''.join(charset[random.randrange(n)] for _ in range(length))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef random_alphanum(length):\n    charset = string.ascii_letters + string.digits\n    return random_string(length, charset)", "response": "Returns a random string of ASCII letters and digits."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef random_hex(length):\n    charset = ''.join(set(string.hexdigits.lower()))\n    return random_string(length, charset)", "response": "Returns a random hex string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format_obj_keys(obj, formatter):\n    if type(obj) == list:\n        return [format_obj_keys(o, formatter) for o in obj]\n    elif type(obj) == dict:\n        return {formatter(k): format_obj_keys(v, formatter)\n                for k, v in obj.items()}\n    else:\n        return obj", "response": "Takes a dictionary with string keys and recursively converts all keys from one form to another using the formatting function formatter."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef merge_nodes(self, keep_node, kill_node):\n        # Merge links from kill_node to keep_node\n        for kill_link in kill_node.link_list:\n            if kill_link.target in self.node_list:\n                keep_node.add_link(kill_link.target, kill_link.weight)\n        # Merge any links in the graph pointing to kill_node into links\n        # pointing to keep_node\n        for node in self.node_list:\n            for link in node.link_list:\n                if link.target == kill_node:\n                    node.add_link(keep_node, link.weight)\n                    break\n        # Remove kill_node from the graph\n        self.remove_node(kill_node)", "response": "Merge two nodes into a single node."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a given node or list of nodes to the internal node list.", "response": "def add_nodes(self, nodes):\n        \"\"\"\n        Add a given node or list of nodes to self.node_list.\n\n        Args:\n            node (Node or list[Node]): the node or list of nodes to add\n                to the graph\n\n        Returns: None\n\n        Examples:\n\n        Adding one node: ::\n\n            >>> from blur.markov.node import Node\n            >>> graph = Graph()\n            >>> node_1 = Node('One')\n            >>> graph.add_nodes(node_1)\n            >>> print([node.value for node in graph.node_list])\n            ['One']\n\n        Adding multiple nodes at a time in a list: ::\n\n            >>> from blur.markov.node import Node\n            >>> graph = Graph()\n            >>> node_1 = Node('One')\n            >>> node_2 = Node('Two')\n            >>> graph.add_nodes([node_1, node_2])\n            >>> print([node.value for node in graph.node_list])\n            ['One', 'Two']\n        \"\"\"\n        # Generalize nodes to a list\n        if not isinstance(nodes, list):\n            add_list = [nodes]\n        else:\n            add_list = nodes\n        self.node_list.extend(add_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef feather_links(self, factor=0.01, include_self=False):\n        def feather_node(node):\n            node_weight_sum = sum(l.weight for l in node.link_list)\n            # Iterate over a copy of the original link list since we will\n            # need to refer to this while modifying node.link_list\n            for original_link in node.link_list[:]:\n                neighbor_node = original_link.target\n                neighbor_weight = original_link.weight\n                feather_weight = neighbor_weight / node_weight_sum\n                neighbor_node_weight_sum = sum(l.weight for\n                                               l in neighbor_node.link_list)\n                # Iterate over the links belonging to the neighbor_node,\n                # copying its links to ``node`` with proportional weights\n                for neighbor_link in neighbor_node.link_list:\n                    if (not include_self) and (neighbor_link.target == node):\n                        continue\n                    relative_link_weight = (neighbor_link.weight /\n                                            neighbor_node_weight_sum)\n                    feathered_link_weight = round((relative_link_weight *\n                                                   feather_weight * factor), 2)\n                    node.add_link(neighbor_link.target, feathered_link_weight)\n        for n in self.node_list:\n            feather_node(n)", "response": "Feather the links of connected nodes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd noise to every link in the network. Can use either a ``uniform_amount`` or a ``noise_weight`` weight profile. If ``noise_weight`` is set, ``uniform_amount`` will be ignored. Args: noise_weights (list): a list of weight tuples of form ``(float, float)`` corresponding to ``(amount, weight)`` describing the noise to be added to each link in the graph uniform_amount (float): the maximum amount of uniform noise to be applied if ``noise_weights`` is not set Returns: None Example: >>> from blur.markov.node import Node >>> node_1 = Node('One') >>> node_2 = Node('Two') >>> node_1.add_link(node_1, 3) >>> node_1.add_link(node_2, 5) >>> node_2.add_link(node_1, 1) >>> graph = Graph([node_1, node_2]) >>> for link in graph.node_list[0].link_list: ... print('{} {}'.format(link.target.value, link.weight)) One 3 Two 5 >>> graph.apply_noise() >>> for link in graph.node_list[0].link_list: ... print('{} {}'.format( ... link.target.value, link.weight)) # doctest: +SKIP One 3.154 Two 5.321", "response": "def apply_noise(self, noise_weights=None, uniform_amount=0.1):\n        \"\"\"\n        Add noise to every link in the network.\n\n        Can use either a ``uniform_amount`` or a ``noise_weight`` weight\n        profile. If ``noise_weight`` is set, ``uniform_amount`` will be\n        ignored.\n\n        Args:\n            noise_weights (list): a list of weight tuples\n                of form ``(float, float)`` corresponding to\n                ``(amount, weight)`` describing the noise to be\n                added to each link in the graph\n            uniform_amount (float): the maximum amount of uniform noise\n                to be applied if ``noise_weights`` is not set\n\n        Returns: None\n\n        Example:\n            >>> from blur.markov.node import Node\n            >>> node_1 = Node('One')\n            >>> node_2 = Node('Two')\n            >>> node_1.add_link(node_1, 3)\n            >>> node_1.add_link(node_2, 5)\n            >>> node_2.add_link(node_1, 1)\n            >>> graph = Graph([node_1, node_2])\n            >>> for link in graph.node_list[0].link_list:\n            ...     print('{} {}'.format(link.target.value, link.weight))\n            One 3\n            Two 5\n            >>> graph.apply_noise()\n            >>> for link in graph.node_list[0].link_list:\n            ...     print('{} {}'.format(\n            ...         link.target.value, link.weight))       # doctest: +SKIP\n            One 3.154\n            Two 5.321\n        \"\"\"\n        # Main node loop\n        for node in self.node_list:\n            for link in node.link_list:\n                if noise_weights is not None:\n                    noise_amount = round(weighted_rand(noise_weights), 3)\n                else:\n                    noise_amount = round(random.uniform(\n                        0, link.weight * uniform_amount), 3)\n                link.weight += noise_amount"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding and return a node in self. node_list with the value value.", "response": "def find_node_by_value(self, value):\n        \"\"\"\n        Find and return a node in self.node_list with the value ``value``.\n\n        If multiple nodes exist with the value ``value``,\n        return the first one found.\n\n        If no such node exists, this returns ``None``.\n\n        Args:\n            value (Any): The value of the node to find\n\n        Returns:\n            Node: A node with value ``value`` if it was found\n\n            None: If no node exists with value ``value``\n\n        Example:\n            >>> from blur.markov.node import Node\n            >>> node_1 = Node('One')\n            >>> graph = Graph([node_1])\n            >>> found_node = graph.find_node_by_value('One')\n            >>> found_node == node_1\n            True\n        \"\"\"\n        try:\n            return next(n for n in self.node_list if n.value == value)\n        except StopIteration:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves a node from the node list and links pointing to it.", "response": "def remove_node(self, node):\n        \"\"\"\n        Remove a node from ``self.node_list`` and links pointing to it.\n\n        If ``node`` is not in the graph, do nothing.\n\n        Args:\n            node (Node): The node to be removed\n\n        Returns: None\n\n        Example:\n            >>> from blur.markov.node import Node\n            >>> node_1 = Node('One')\n            >>> graph = Graph([node_1])\n            >>> graph.remove_node(node_1)\n            >>> len(graph.node_list)\n            0\n        \"\"\"\n        if node not in self.node_list:\n            return\n        self.node_list.remove(node)\n        # Remove links pointing to the deleted node\n        for n in self.node_list:\n            n.link_list = [link for link in n.link_list if\n                           link.target != node]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove all nodes in the node_list with the value value.", "response": "def remove_node_by_value(self, value):\n        \"\"\"\n        Delete all nodes in ``self.node_list`` with the value ``value``.\n\n        Args:\n            value (Any): The value to find and delete owners of.\n\n        Returns: None\n\n        Example:\n            >>> from blur.markov.node import Node\n            >>> node_1 = Node('One')\n            >>> graph = Graph([node_1])\n            >>> graph.remove_node_by_value('One')\n            >>> len(graph.node_list)\n            0\n        \"\"\"\n        self.node_list = [node for node in self.node_list\n                          if node.value != value]\n        # Remove links pointing to the deleted node\n        for node in self.node_list:\n            node.link_list = [link for link in node.link_list if\n                              link.target.value != value]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntesting if any node in self. node_list has the value value.", "response": "def has_node_with_value(self, value):\n        \"\"\"\n        Whether any node in ``self.node_list`` has the value ``value``.\n\n        Args:\n            value (Any): The value to find in ``self.node_list``\n\n        Returns: bool\n\n        Example:\n            >>> from blur.markov.node import Node\n            >>> node_1 = Node('One')\n            >>> graph = Graph([node_1])\n            >>> graph.has_node_with_value('One')\n            True\n            >>> graph.has_node_with_value('Foo')\n            False\n        \"\"\"\n        for node in self.node_list:\n            if node.value == value:\n                return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pick(self, starting_node=None):\n        if starting_node is None:\n            if self.current_node is None:\n                random_node = random.choice(self.node_list)\n                self.current_node = random_node\n                return random_node\n            else:\n                starting_node = self.current_node\n        # Use weighted_choice on start_node.link_list\n        self.current_node = weighted_choice(\n            [(link.target, link.weight) for link in starting_node.link_list])\n        return self.current_node", "response": "Pick a node from the graph based on the links in the starting node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_string(cls,\n                    source,\n                    distance_weights=None,\n                    merge_same_words=False,\n                    group_marker_opening='<<',\n                    group_marker_closing='>>'):\n        \"\"\"\n        Read a string and derive of ``Graph`` from it.\n\n        Words and punctuation marks are made into nodes.\n\n        Punctuation marks are split into separate nodes unless they fall\n        between other non-punctuation marks. ``'hello, world'`` is split\n        into ``'hello'``, ``','``, and ``'world'``, while ``'who's there?'``\n        is split into ``\"who's\"``, ``'there'``, and ``'?'``.\n\n        To group arbitrary characters together into a single node\n        (e.g. to make ``'hello, world!'``), surround the\n        text in question with ``group_marker_opening`` and\n        ``group_marker_closing``. With the default value, this\n        would look like ``'<<hello, world!>>'``. It is recommended that\n        the group markers not appear anywhere in the source text where they\n        aren't meant to act as such to prevent unexpected behavior.\n\n        The exact regex for extracting nodes is defined by: ::\n\n            expression = r'{0}(.+){1}|([^\\w\\s]+)\\B|([\\S]+\\b)'.format(\n                ''.join('\\\\' + c for c in group_marker_opening),\n                ''.join('\\\\' + c for c in group_marker_closing)\n            )\n\n        Args:\n            source (str): the string to derive the graph from\n            distance_weights (dict): dict of relative indices corresponding\n                with word weights. For example, if a dict entry is ``1: 1000``\n                this means that every word is linked to the word which follows\n                it with a weight of 1000. ``-4: 350`` would mean that every\n                word is linked to the 4th word behind it with a weight of 350.\n                A key of ``0`` refers to the weight words get\n                pointing to themselves. Keys pointing beyond the edge of the\n                word list will wrap around the list.\n\n                The default value for ``distance_weights`` is ``{1: 1}``.\n                This means that each word gets equal weight to whatever\n                word follows it. Consequently, if this default value is\n                used and ``merge_same_words`` is ``False``, the resulting\n                graph behavior will simply move linearly through the\n                source, wrapping at the end to the beginning.\n\n            merge_same_words (bool): if nodes which have the same value should\n                be merged or not.\n            group_marker_opening (str): The string used to mark the beginning\n                of word groups.\n            group_marker_closing (str): The string used to mark the end\n                of word groups. It is strongly recommended that this be\n                different than ``group_marker_opening`` to prevent unexpected\n                behavior with the regex pattern.\n\n        Returns: Graph\n\n        Example:\n            >>> graph = Graph.from_string('i have nothing to say and '\n            ...                           'i am saying it and that is poetry.')\n            >>> ' '.join(graph.pick().value for i in range(8)) # doctest: +SKIP\n            'using chance algorithmic in algorithmic art easier blur'\n        \"\"\"\n        if distance_weights is None:\n            distance_weights = {1: 1}\n        # Convert distance_weights to a sorted list of tuples\n        # To make output node list order more predictable\n        sorted_weights_list = sorted(distance_weights.items(),\n                                     key=lambda i: i[0])\n        # regex that matches:\n        #   * Anything surrounded by\n        #       group_marker_opening and group_marker_closing,\n        #   * Groups of punctuation marks followed by whitespace\n        #   * Any continuous group of non-whitespace characters\n        #       followed by whitespace\n        expression = r'{0}(.+){1}|([^\\w\\s]+)\\B|([\\S]+\\b)'.format(\n            ''.join('\\\\' + c for c in group_marker_opening),\n            ''.join('\\\\' + c for c in group_marker_closing)\n        )\n        matches = re.findall(expression, source)\n        # Un-tuple matches since we are only using groups to strip brackets\n        # Is there a better way to do this?\n        words = [next(t for t in match if t) for match in matches]\n\n        if merge_same_words:\n            # Ensure a 1:1 correspondence between words and nodes,\n            # and that all links point to these nodes as well\n\n            # Create nodes for every unique word\n            temp_node_list = []\n            for word in words:\n                if word not in (n.value for n in temp_node_list):\n                    temp_node_list.append(Node(word))\n            # Loop through words, attaching links to nodes which correspond\n            # to the current word. Ensure links also point to valid\n            # corresponding nodes in the node list.\n            for i, word in enumerate(words):\n                matching_node = next(\n                    (n for n in temp_node_list if n.value == word))\n                for key, weight in sorted_weights_list:\n                    # Wrap the index of edge items\n                    wrapped_index = (key + i) % len(words)\n                    target_word = words[wrapped_index]\n                    matching_target_node = next(\n                        (n for n in temp_node_list\n                         if n.value == target_word))\n                    matching_node.add_link(matching_target_node, weight)\n        else:\n            # Create one node for every (not necessarily unique) word.\n            temp_node_list = [Node(word) for word in words]\n            for i, node in enumerate(temp_node_list):\n                for key, weight in sorted_weights_list:\n                    # Wrap the index of edge items\n                    wrapped_index = (key + i) % len(temp_node_list)\n                    node.add_link(temp_node_list[wrapped_index], weight)\n\n        graph = cls()\n        graph.add_nodes(temp_node_list)\n        return graph", "response": "Read a string and derive a new Graph object from it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_file(cls,\n                  source,\n                  distance_weights=None,\n                  merge_same_words=False,\n                  group_marker_opening='<<',\n                  group_marker_closing='>>'):\n        \"\"\"\n        Read a string from a file and derive a ``Graph`` from it.\n\n        This is a convenience function for opening a file and passing its\n        contents to ``Graph.from_string()`` (see that for more detail)\n\n        Args:\n            source (str): the file to read and derive the graph from\n            distance_weights (dict): dict of relative indices corresponding\n                with word weights. See ``Graph.from_string`` for more detail.\n            merge_same_words (bool): whether nodes which have the same value\n                should be merged or not.\n            group_marker_opening (str): The string used to mark the beginning\n                of word groups.\n            group_marker_closing (str): The string used to mark the end\n                of word groups.\n\n        Returns: Graph\n\n        Example:\n            >>> graph = Graph.from_file('cage.txt')            # doctest: +SKIP\n            >>> ' '.join(graph.pick().value for i in range(8)) # doctest: +SKIP\n            'poetry i have nothing to say and i'\n        \"\"\"\n        source_string = open(source, 'r').read()\n        return cls.from_string(source_string,\n                               distance_weights,\n                               merge_same_words,\n                               group_marker_opening=group_marker_opening,\n                               group_marker_closing=group_marker_closing)", "response": "Read a string from a file and derive a Graph object from it."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\noverrides to only call notify if model matches.", "response": "def notify(self, force_notify=None, use_email=None, use_sms=None, **kwargs):\n        \"\"\"Overridden to only call `notify` if model matches.\n        \"\"\"\n        notified = False\n        instance = kwargs.get(\"instance\")\n        if instance._meta.label_lower == self.model:\n            notified = super().notify(\n                force_notify=force_notify,\n                use_email=use_email,\n                use_sms=use_sms,\n                **kwargs,\n            )\n        return notified"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute(prog_name, args=None):\n    args = _get_parser().parse_args(args or [])\n    locale, locale_dir = args.locale, args.locale_dir\n\n    program = 'msgfmt'\n    ensure_programs(program)\n\n    def has_bom(fn):\n        with open(fn, 'rb') as f:\n            sample = f.read(4)\n        return (sample[:3] == b'\\xef\\xbb\\xbf'\n                or sample.startswith(codecs.BOM_UTF16_LE)\n                or sample.startswith(codecs.BOM_UTF16_BE))\n\n    if locale:\n        dirs = [os.path.join(locale_dir, l, 'LC_MESSAGES') for l in locale]\n    else:\n        dirs = [locale_dir, ]\n    for ldir in dirs:\n        for dir_path, dir_names, file_names in os.walk(ldir):\n            for file_name in file_names:\n                if not file_name.endswith('.po'):\n                    continue\n                print_out(\"Processing file '{:}' in {:}\".format(file_name,\n                                                                dir_path))\n                file_path = os.path.join(dir_path, file_name)\n                if has_bom(file_path):\n                    raise RuntimeError(\n                        \"The '{:}' file has a BOM (Byte Order Mark). \"\n                        \"Verboselib supports only .po files encoded in UTF-8 \"\n                        \"and without any BOM.\".format(file_path))\n                prefix = os.path.splitext(file_path)[0]\n                args = [\n                    program,\n                    '--check-format',\n                    '-o',\n                    native_path(prefix + '.mo'),\n                    native_path(prefix + '.po'),\n                ]\n                output, errors, status = popen_wrapper(args)\n                if status:\n                    if errors:\n                        msg = \"Execution of %s failed: %s\" % (program, errors)\n                    else:\n                        msg = \"Execution of %s failed\" % program\n                    raise RuntimeError(msg)", "response": "Execute a verboselib program."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters the item in zookeeper / list", "response": "def register(self, itemtype, item_id, handler):\n        '''\n        register the item in zookeeper /list/\n        itemtype must be a Zooborg constant\n        item_id must be a string\n        handler: method to call on conf change\n        '''\n        # Create a node with data\n        #TODO: add system properties in data (ip, os)\n        #TODO: add uniq client id\n        if itemtype not in [ZooConst.CLIENT, ZooConst.WORKER, ZooConst.BROKER]:\n            raise Exception('Zooborg.register: invalid type')\n        self.initconn()\n        self.zk.ensure_path(\"/distark/\" + itemtype + \"/list\")\n        path=''.join(['/distark/' + itemtype + '/list/', item_id])\n        self.registred.append(path)\n        data=b'ip\u0302,os'\n        if not(self.zk.exists(path)):\n            self.zk.create(path, data, None, True)\n        else:\n            self.zk.delete(path, recursive=True)\n            self.zk.create(path, data, None, True)\n        #reload conf if change in zoo\n        self.zk.DataWatch('/distark/' + itemtype + '/conf/conf_reload_trigger',\n                          handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets list of objects", "response": "def getList(self, listtype):\n        '''\n        listtype must be a Zooborg constant\n        '''\n        if listtype not in [ZooConst.CLIENT, ZooConst.WORKER, ZooConst.BROKER]:\n            raise Exception('Zooborg.getList: invalid type')\n        self.initconn()\n        return self.zk.get_children('/distark/' + listtype + '/list')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getConf(self, conftype):\n        '''\n        conftype must be a Zooborg constant\n        '''\n        zooconf={}\n        if conftype not in [ZooConst.CLIENT, ZooConst.WORKER, ZooConst.BROKER]:\n            raise Exception('Zooborg.getConf: invalid type')\n\n        self.initconn()\n        if conftype in [ZooConst.CLIENT, ZooConst.WORKER]:\n            zooconf={'broker': {'connectionstr': None}}\n            zoopath='/distark/' + conftype + '/conf/broker/connectionstr'\n            zooconf['broker']['connectionstr'], stat = self.zk.get(zoopath)\n\n        if conftype in [ZooConst.BROKER]:\n            zooconf={'bindstr': None}\n            zoopath='/distark/' + conftype + '/conf/bindstr'\n            zooconf['bindstr'], stat = self.zk.get(zoopath)\n\n        return zooconf", "response": "get conf from zooborg"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets object from the object manager or None if it doesn t exist.", "response": "def get_object_or_none(model, *args, **kwargs):\n    \"\"\"\n    Like get_object_or_404, but doesn't throw an exception.\n\n    Allows querying for an object that might not exist without triggering\n    an exception.\n    \"\"\"\n    try:\n        return model._default_manager.get(*args, **kwargs)\n    except model.DoesNotExist:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating and parse the BMA answer from websocket", "response": "def parse_text(text: str, schema: dict) -> Any:\n    \"\"\"\n    Validate and parse the BMA answer from websocket\n\n    :param text: the bma answer\n    :param schema: dict for jsonschema\n    :return: the json data\n    \"\"\"\n    try:\n        data = json.loads(text)\n        jsonschema.validate(data, schema)\n    except (TypeError, json.decoder.JSONDecodeError):\n        raise jsonschema.ValidationError(\"Could not parse json\")\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate and parse the BMA answer from websocket", "response": "def parse_error(text: str) -> Any:\n    \"\"\"\n    Validate and parse the BMA answer from websocket\n\n    :param text: the bma error\n    :return: the json data\n    \"\"\"\n    try:\n        data = json.loads(text)\n        jsonschema.validate(data, ERROR_SCHEMA)\n    except (TypeError, json.decoder.JSONDecodeError) as e:\n        raise jsonschema.ValidationError(\"Could not parse json : {0}\".format(str(e)))\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def parse_response(response: ClientResponse, schema: dict) -> Any:\n    try:\n        data = await response.json()\n        response.close()\n        if schema is not None:\n            jsonschema.validate(data, schema)\n        return data\n    except (TypeError, json.decoder.JSONDecodeError) as e:\n        raise jsonschema.ValidationError(\"Could not parse json : {0}\".format(str(e)))", "response": "Validate and parse the BMA answer response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reverse_url(self, scheme: str, path: str) -> str:\n        # remove starting slash in path if present\n        path = path.lstrip('/')\n\n        server, port = self.connection_handler.server, self.connection_handler.port\n        if self.connection_handler.path:\n            url = '{scheme}://{server}:{port}/{path}'.format(scheme=scheme,\n                                                             server=server,\n                                                             port=port,\n                                                             path=path)\n        else:\n            url = '{scheme}://{server}:{port}/'.format(scheme=scheme,\n                                                       server=server,\n                                                       port=port)\n\n        return url + path", "response": "Reverses the url using scheme and path given in parameter."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrequest GET wrapper in order to use API parameters.", "response": "async def requests_get(self, path: str, **kwargs) -> ClientResponse:\n        \"\"\"\n        Requests GET wrapper in order to use API parameters.\n\n        :param path: the request path\n        :return:\n        \"\"\"\n        logging.debug(\"Request : {0}\".format(self.reverse_url(self.connection_handler.http_scheme, path)))\n        url = self.reverse_url(self.connection_handler.http_scheme, path)\n        response = await self.connection_handler.session.get(url, params=kwargs, headers=self.headers,\n                                                             proxy=self.connection_handler.proxy,\n                                                             timeout=15)\n        if response.status != 200:\n            try:\n                error_data = parse_error(await response.text())\n                raise DuniterError(error_data)\n            except (TypeError, jsonschema.ValidationError):\n                raise ValueError('status code != 200 => %d (%s)' % (response.status, (await response.text())))\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def requests_post(self, path: str, **kwargs) -> ClientResponse:\n        if 'self_' in kwargs:\n            kwargs['self'] = kwargs.pop('self_')\n\n        logging.debug(\"POST : {0}\".format(kwargs))\n        response = await self.connection_handler.session.post(\n            self.reverse_url(self.connection_handler.http_scheme, path),\n            data=kwargs,\n            headers=self.headers,\n            proxy=self.connection_handler.proxy,\n            timeout=15\n        )\n        return response", "response": "Requests POST wrapper in order to use API parameters.\n\n        :param path: the request path\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconnects to a websocket in order to use API parameters", "response": "def connect_ws(self, path: str) -> _WSRequestContextManager:\n        \"\"\"\n        Connect to a websocket in order to use API parameters\n\n        In reality, aiohttp.session.ws_connect returns a aiohttp.client._WSRequestContextManager instance.\n        It must be used in a with statement to get the ClientWebSocketResponse instance from it (__aenter__).\n        At the end of the with statement, aiohttp.client._WSRequestContextManager.__aexit__ is called\n        and close the ClientWebSocketResponse in it.\n\n        :param path: the url path\n        :return:\n        \"\"\"\n        url = self.reverse_url(self.connection_handler.ws_scheme, path)\n        return self.connection_handler.session.ws_connect(url, proxy=self.connection_handler.proxy)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def post(self, url_path: str, params: dict = None, rtype: str = RESPONSE_JSON, schema: dict = None) -> Any:\n        if params is None:\n            params = dict()\n\n        client = API(self.endpoint.conn_handler(self.session, self.proxy))\n\n        # get aiohttp response\n        response = await client.requests_post(url_path, **params)\n\n        # if schema supplied...\n        if schema is not None:\n            # validate response\n            await parse_response(response, schema)\n\n        # return the chosen type\n        if rtype == RESPONSE_AIOHTTP:\n            return response\n        elif rtype == RESPONSE_TEXT:\n            return await response.text()\n        elif rtype == RESPONSE_JSON:\n            return await response.json()", "response": "A POST request on the endpoint + url_path with params and return the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect_ws(self, path: str) -> _WSRequestContextManager:\n        client = API(self.endpoint.conn_handler(self.session, self.proxy))\n        return client.connect_ws(path)", "response": "Connect to a websocket in order to use API parameters\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract_version(filepath='jeni.py', name='__version__'):\n    context = {}\n    for line in open(filepath):\n        if name in line:\n            exec(line, context)\n            break\n    else:\n        raise RuntimeError('{} not found in {}'.format(name, filepath))\n    return context[name]", "response": "Parse __version__ out of given Python file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef quote_value(value):\n    adapted = adapt(value)\n    if hasattr(adapted, 'getquoted'):\n        adapted = adapted.getquoted()\n    return adapted", "response": "return the value ready to be used as a value in a SQL string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self,dset):\n        '''load a dataset from given filename into the object'''\n        self.dset_filename = dset\n        self.dset = nib.load(dset)\n        self.data = self.dset.get_data()\n        self.header = self.dset.get_header()", "response": "load a dataset from given filename into the object"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets an engine from string", "response": "def get_engine(name):\n    \"\"\"\n    get an engine from string (engine class without Engine)\n    \"\"\"\n\n    name = name.capitalize() + 'Engine'\n    if name in globals():\n        return globals()[name]\n\n    raise KeyError(\"engine '%s' does not exist\" % name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init(scope):\r\n    # define wrapper compatibility symbols\r\n    QtCore.THREADSAFE_NONE = XThreadNone()\r\n    QtGui.QDialog = QDialog\r\n    \r\n    # define the importable symbols\r\n    scope['QtCore'] = QtCore\r\n    scope['QtGui'] = QtGui\r\n    scope['QtWebKit'] = lazy_import('PySide.QtWebKit')\r\n    scope['QtNetwork'] = lazy_import('PySide.QtNetwork')\r\n    scope['QtXml'] = lazy_import('PySide.QtXml')\r\n    \r\n    scope['uic'] = Uic()\r\n    scope['rcc_exe'] = 'pyside-rcc'\r\n    \r\n    # map overrides\r\n    #QtCore.SIGNAL = SIGNAL\r\n    \r\n    # map shared core properties\r\n    QtCore.QDate.toPyDate = lambda x: x.toPython()\r\n    QtCore.QDateTime.toPyDateTime = lambda x: x.toPython()\r\n    QtCore.QTime.toPyTime = lambda x: x.toPython()\r\n    QtCore.QStringList = list\r\n    QtCore.QString = unicode", "response": "Initialize the xqt system with the PySide wrapper for the Qt system."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\noverloads teh create action method to handle proper base AttributeNames instance information.", "response": "def createAction(self, parent=None, name=''):\r\n        \"\"\"\r\n        Overloads teh create action method to handle the proper base\r\n        instance information, similar to the PyQt4 loading system.\r\n        \r\n        :param      parent | <QWidget> || None\r\n                    name   | <str>\r\n        \"\"\"\r\n        action = super(UiLoader, self).createAction(parent, name)\r\n        if not action.parent():\r\n            action.setParent(self._baseinstance)\r\n        setattr(self._baseinstance, name, action)\r\n        return action"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noverload teh create action group method to handle proper base instance information similar to the PyQt4 loading system.", "response": "def createActionGroup(self, parent=None, name=''):\r\n        \"\"\"\r\n        Overloads teh create action method to handle the proper base\r\n        instance information, similar to the PyQt4 loading system.\r\n        \r\n        :param      parent | <QWidget> || None\r\n                    name   | <str>\r\n        \"\"\"\r\n        actionGroup = super(UiLoader, self).createActionGroup(parent, name)\r\n        if not actionGroup.parent():\r\n            actionGroup.setParent(self._baseinstance)\r\n        setattr(self._baseinstance, name, actionGroup)\r\n        return actionGroup"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef createLayout(self, className, parent=None, name=''):\r\n        layout = super(UiLoader, self).createLayout(className, parent, name)\r\n        setattr(self._baseinstance, name, layout)\r\n        return layout", "response": "Overloads teh create action method to handle proper base\r\n        instance information similar to the PyQt4 loading system."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef createWidget(self, className, parent=None, name=''):\r\n        className = str(className)\r\n        \r\n        # create a widget off one of our dynamic classes\r\n        if className in self.dynamicWidgets:\r\n            widget = self.dynamicWidgets[className](parent)\r\n            if parent:\r\n                widget.setPalette(parent.palette())\r\n            widget.setObjectName(name)\r\n            \r\n            # hack fix on a QWebView (will crash app otherwise)\r\n            # forces a URL to the QWebView before it finishes\r\n            if className == 'QWebView':\r\n                widget.setUrl(QtCore.QUrl('http://www.google.com'))\r\n        \r\n        # create a widget from the default system\r\n        else:\r\n            widget = super(UiLoader, self).createWidget(className, parent, name)\r\n            if parent:\r\n                widget.setPalette(parent.palette())\r\n        \r\n        if parent is None:\r\n            return self._baseinstance\r\n        else:\r\n            setattr(self._baseinstance, name, widget)\r\n            return widget", "response": "Create a widget from a class name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef loadUi(self, filename, baseinstance=None):\r\n        try:\r\n            xui = ElementTree.parse(filename)\r\n        except xml.parsers.expat.ExpatError:\r\n            log.exception('Could not load file: %s' % filename)\r\n            return None\r\n        \r\n        loader = UiLoader(baseinstance)\r\n        \r\n        # pre-load custom widgets\r\n        xcustomwidgets = xui.find('customwidgets')\r\n        if xcustomwidgets is not None:\r\n            for xcustom in xcustomwidgets:\r\n                header = xcustom.find('header').text\r\n                clsname = xcustom.find('class').text\r\n                \r\n                if not header:\r\n                    continue\r\n                \r\n                if clsname in loader.dynamicWidgets:\r\n                    continue\r\n                \r\n                # modify the C++ headers to use the Python wrapping\r\n                if '/' in header:\r\n                    header = 'xqt.' + '.'.join(header.split('/')[:-1])\r\n                \r\n                # try to use the custom widgets\r\n                try:\r\n                    __import__(header)\r\n                    module = sys.modules[header]\r\n                    cls = getattr(module, clsname)\r\n                except (ImportError, KeyError, AttributeError):\r\n                    log.error('Could not load %s.%s' % (header, clsname))\r\n                    continue\r\n                \r\n                loader.dynamicWidgets[clsname] = cls\r\n                loader.registerCustomWidget(cls)\r\n        \r\n        # load the options\r\n        ui = loader.load(filename)\r\n        QtCore.QMetaObject.connectSlotsByName(ui)\r\n        return ui", "response": "Load a single UI from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisplays this dialog centering on its parent window.", "response": "def showEvent(self, event):\r\n        \"\"\"\r\n        Displays this dialog, centering on its parent.\r\n\r\n        :param      event | <QtCore.QShowEvent>\r\n        \"\"\"\r\n        super(QDialog, self).showEvent(event)\r\n\r\n        if not self._centered:\r\n            self._centered = True\r\n            try:\r\n                window = self.parent().window()\r\n                center = window.geometry().center()\r\n            except AttributeError:\r\n                return\r\n            else:\r\n                self.move(center.x() - self.width() / 2, center.y() - self.height() / 2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_uri_obj(uri, storage_args={}):\n\n    if isinstance(uri, BaseURI): return uri\n    uri_obj = None\n\n    o = urlparse(uri)\n    for storage in STORAGES:\n        uri_obj = storage.parse_uri(o, storage_args=storage_args)\n        if uri_obj is not None:\n            break\n    #end for\n    if uri_obj is None:\n        raise TypeError('<{}> is an unsupported URI.'.format(uri))\n\n    return uri_obj", "response": "Retrieve the underlying storage object based on the URI."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef uri_open(uri, mode='rb', auto_compress=True, in_memory=True, delete_tempfile=True, textio_args={}, storage_args={}):\n\n    if isinstance(uri, BaseURI): uri = str(uri)\n    uri_obj = get_uri_obj(uri, storage_args)\n\n    if mode == 'rb': read_mode, binary_mode = True, True\n    elif mode == 'r': read_mode, binary_mode = True, False\n    elif mode == 'w': read_mode, binary_mode = False, False\n    elif mode == 'wb': read_mode, binary_mode = False, True\n    else: raise TypeError('`mode` cannot be \"{}\".'.format(mode))\n\n    if read_mode:\n        if in_memory:\n            file_obj = BytesIO(uri_obj.get_content())\n            setattr(file_obj, 'name', str(uri_obj))\n        else:\n            file_obj = _TemporaryURIFileIO(uri_obj=uri_obj, input_mode=True, delete_tempfile=delete_tempfile)\n        #end if\n    else:\n        if in_memory: file_obj = URIBytesOutput(uri_obj)\n        else:\n            file_obj = _TemporaryURIFileIO(uri_obj=uri_obj, input_mode=False, pre_close_action=uri_obj.upload_file, delete_tempfile=delete_tempfile)\n            setattr(file_obj, 'name', str(uri_obj))\n        #end if\n    #end if\n\n    temp_name = getattr(file_obj, 'temp_name', None)\n\n    if auto_compress:\n        _, ext = os.path.splitext(uri)\n        ext = ext.lower()\n        if ext == '.gz': file_obj = gzip.GzipFile(fileobj=file_obj, mode='rb' if read_mode else 'wb')\n    #end if\n\n    if not binary_mode:\n        textio_args.setdefault('encoding', 'utf-8')\n        file_obj = TextIOWrapper(file_obj, **textio_args)\n    #end if\n\n    if not hasattr(file_obj, 'temp_name'): setattr(file_obj, 'temp_name', temp_name)\n\n    return file_obj", "response": "Opens a URI for reading or writing."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the contents of a URI into a string or bytestring.", "response": "def uri_read(*args, **kwargs):\n    \"\"\"\n    Reads the contents of a URI into a string or bytestring.\n    See :func:`uri_open` for complete description of keyword parameters.\n\n    :returns: Contents of URI\n    :rtype: str, bytes\n    \"\"\"\n\n    with uri_open(*args, **kwargs) as f:\n        content = f.read()\n    return content"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef uri_dump(uri, content, mode='wb', **kwargs):\n\n    if 'r' in mode: raise ValueError('Read mode is not allowed for `uri_dump`.')\n\n    with uri_open(uri, mode=mode, **kwargs) as f:\n        f.write(content)\n        f.flush()", "response": "Dumps the contents of a string or bytestring into a URI."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nblock / waits until URI exists.", "response": "def uri_exists_wait(uri, timeout=300, interval=5, storage_args={}):\n    \"\"\"\n    Block / waits until URI exists.\n\n    :param str uri: URI to check existence\n    :param float timeout: Number of seconds before timing out\n    :param float interval: Calls :func:`uri_exists` every ``interval`` seconds\n    :param dict storage_args: Keyword arguments to pass to the underlying storage object\n    :returns: ``True`` if URI exists\n    :rtype: bool\n    \"\"\"\n\n    uri_obj = get_uri_obj(uri, storage_args)\n    start_time = time.time()\n    while time.time() - start_time < timeout:\n        if uri_obj.exists(): return True\n        time.sleep(interval)\n    #end while\n\n    if uri_exists(uri): return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef payment(self, amount, **kwargs):\n        params = self.config.clone()\\\n            .update({ 'amount': amount })\\\n            .update(kwargs)\n\n        mandatory = ['abort_url', 'reasons', 'success_url']\n\n        for field in mandatory:\n            if not params.has(field):\n                raise ValueError('Mandatory field \"{}\" is not specified'.format(field))\n\n        params.reasons = [sofort.internals.strip_reason(reason)\n                                for reason\n                                in params.reasons]\n\n        return self._request(sofort.xml.multipay(params), params)", "response": "Get payment URL and new transaction ID"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_env(print_vars=False):\n    env_file = os.environ.get('ENV_FILE', '.env')\n    try:\n        variables = open(env_file).read().splitlines()\n        for v in variables:\n            if '=' in v:\n                key, value = v.split('=', 1)\n                if key.startswith('#'):\n                    continue\n                if key not in os.environ:\n                    if value.startswith('\"') and value.endswith('\"') or \\\n                                    value.startswith(\"'\") and value.endswith(\"'\"):\n                        os.environ[key] = ast.literal_eval(value)\n                    else:\n                        os.environ[key] = value\n                    if print_vars:\n                        print(key, os.environ[key])\n    except IOError:\n        pass", "response": "Load environment variables from a. env file if present."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npopulating a model with normalized properties.", "response": "def fill_model(self, model=None):\n        \"\"\"\n        Populates a model with normalized properties. If no model is provided (None) a new one will be created.\n        :param model: model to be populade\n        :return: populated model\n        \"\"\"\n        normalized_dct = self.normalize()\n        if model:\n            if not isinstance(model, self._model_class):\n                raise ModelFormSecurityError('%s should be %s instance' % (model, self._model_class.__name__))\n            model.populate(**normalized_dct)\n            return model\n        return self._model_class(**normalized_dct)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfilling this form with localized properties from a model.", "response": "def fill_with_model(self, model, *fields):\n        \"\"\"\n        Populates this form with localized properties from model.\n        :param fields: string list indicating the fields to include. If None, all fields defined on form will be used\n        :param model: model\n        :return: dict with localized properties\n        \"\"\"\n        model_dct = model.to_dict(include=self._fields.keys())\n        localized_dct = self.localize(*fields, **model_dct)\n        if model.key:\n            localized_dct['id'] = model.key.id()\n        return localized_dct"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_config(config_schema, env=None):\n    if env is None:\n        env = os.environ\n\n    return parser.parse_env(\n        config_schema,\n        env,\n    )", "response": "Parse the config from the environment against a given schema."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Log(self, messages):\n    self._seqid += 1\n    d = self._reqs[self._seqid] = defer.Deferred()\n    self.send_Log(messages)\n    return d", "response": "Logs the messages in a single message in a single message sequence. Returns a Deferred that fires when all messages have been sent."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insert_string_at_line(input_file: str,\n                          string_to_be_inserted: str,\n                          put_at_line_number: int,\n                          output_file: str,\n                          append: bool = True,\n                          newline_character: str = '\\n'):\n    r\"\"\"Write a string at the specified line.\n\n    :parameter input_file: the file that needs to be read.\n    :parameter string_to_be_inserted: the string that needs to be added.\n    :parameter put_at_line_number: the line number on which to append the\n         string.\n    :parameter output_file: the file that needs to be written with the new\n         content.\n    :parameter append: decides whether to append or prepend the string at the\n         selected line. Defaults to ``True``.\n    :parameter newline_character: set the character used to fill the file\n         in case line_number is greater than the number of lines of\n         input_file. Defaults to ``\\n``.\n    :type input_file: str\n    :type string_to_be_inserted: str\n    :type line_number: int\n    :type output_file: str\n    :type append: bool\n    :type newline_character: str\n    :returns: None\n    :raises: LineOutOfFileBoundsError or a built-in exception.\n\n    .. note::\n         Line numbers start from ``1``.\n    \"\"\"\n    assert put_at_line_number >= 1\n\n    with open(input_file, 'r') as f:\n        lines = f.readlines()\n\n    line_counter = 1\n    i = 0\n    loop = True\n    extra_lines_done = False\n    line_number_after_eof = len(lines) + 1\n    with atomic_write(output_file, overwrite=True) as f:\n        while loop:\n            if put_at_line_number > len(\n                    lines) and line_counter == line_number_after_eof:\n                # There are extra lines to write.\n                line = str()\n            else:\n                line = lines[i]\n            # It is ok if the position of line to be written is greater\n            # than the last line number of the input file. We just need to add\n            # the appropriate number of new line characters which will fill\n            # the non existing lines of the output file.\n            if put_at_line_number > len(\n                    lines) and line_counter == line_number_after_eof:\n                for additional_newlines in range(\n                        0, put_at_line_number - len(lines) - 1):\n                    # Skip the newline in the line where we need to insert\n                    # the new string.\n                    f.write(newline_character)\n                    line_counter += 1\n                    i += 1\n                extra_lines_done = True\n\n            if line_counter == put_at_line_number:\n                # A very simple append operation: if the original line ends\n                # with a '\\n' character, the string will be added on the next\n                # line...\n                if append:\n                    line = line + string_to_be_inserted\n                # ...otherwise the string is prepended.\n                else:\n                    line = string_to_be_inserted + line\n            f.write(line)\n            line_counter += 1\n            i += 1\n            # Quit the loop if there is nothing more to write.\n            if i >= len(lines):\n                loop = False\n            # Continue looping if there are still extra lines to write.\n            if put_at_line_number > len(lines) and not extra_lines_done:\n                loop = True", "response": "r Inserts a string at the specified line."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_line_interval(input_file: str, delete_line_from: int,\n                         delete_line_to: int, output_file: str):\n    r\"\"\"Remove a line interval.\n\n    :parameter input_file: the file that needs to be read.\n    :parameter delete_line_from: the line number from which start deleting.\n    :parameter delete_line_to: the line number to which stop deleting.\n    :parameter output_file: the file that needs to be written without the\n         selected lines.\n    :type input_file: str\n    :type delete_line_from: int\n    :type delete_line_to: int\n    :type output_file: str\n    :returns: None\n    :raises: LineOutOfFileBoundsError or a built-in exception.\n\n    .. note::\n         Line numbers start from ``1``.\n\n    .. note::\n         It is possible to remove a single line only. This happens when\n         the parameters delete_line_from and delete_line_to are equal.\n    \"\"\"\n    assert delete_line_from >= 1\n    assert delete_line_to >= 1\n\n    with open(input_file, 'r') as f:\n        lines = f.readlines()\n\n    # Invalid line ranges.\n    # Base case delete_line_to - delete_line_from == 0: single line.\n    if delete_line_to - delete_line_from < 0:\n        raise NegativeLineRangeError\n    if delete_line_from > len(lines) or delete_line_to > len(lines):\n        raise LineOutOfFileBoundsError\n\n    line_counter = 1\n    # Rewrite the file without the string.\n    with atomic_write(output_file, overwrite=True) as f:\n        for line in lines:\n            # Ignore the line interval where the content to be deleted lies.\n            if line_counter >= delete_line_from and line_counter <= delete_line_to:\n                pass\n            # Write the rest of the file.\n            else:\n                f.write(line)\n            line_counter += 1", "response": "r Removes a line interval from a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef upload_dataset(\n        dataset_name, file_path, task=None, dataset_attributes=None, **kwargs):\n    \"\"\"Uploads the given file to dataset store.\n\n    Parameters\n    ----------\n    dataset_name : str\n        The name of the dataset to upload.\n    file_path : str\n        The full path to the file to upload\n    task : str, optional\n        The task for which the given dataset is used for. If not given, a path\n        for the corresponding task-agnostic directory is used.\n    dataset_attributes : dict, optional\n        Additional attributes of the datasets. Used to generate additional\n        sub-folders on the blob \"path\". For example, providing 'lang=en' will\n        results in a path such as '/lang_en/mydataset.csv'. Hierarchy always\n        matches lexicographical order of keyword argument names, so 'lang=en'\n        and 'animal=dog' will result in a path such as\n        'task_name/animal_dof/lang_en/dset.csv'.\n    **kwargs : extra keyword arguments\n        Extra keyword arguments are forwarded to\n        azure.storage.blob.BlockBlobService.create_blob_from_path.\n    \"\"\"\n    fname = ntpath.basename(file_path)\n    blob_name = _blob_name(\n        dataset_name=dataset_name,\n        file_name=fname,\n        task=task,\n        dataset_attributes=dataset_attributes,\n    )\n    print(blob_name)\n    _blob_service().create_blob_from_path(\n        container_name=BARN_CFG['azure']['container_name'],\n        blob_name=blob_name,\n        file_path=file_path,\n        **kwargs,\n    )", "response": "Uploads the given file to dataset store."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads the given dataset from dataset store.", "response": "def download_dataset(\n        dataset_name, file_path, task=None, dataset_attributes=None, **kwargs):\n    \"\"\"Downloads the given dataset from dataset store.\n\n    Parameters\n    ----------\n    dataset_name : str\n        The name of the dataset to upload.\n    file_path : str\n        The full path to the file to upload\n    task : str, optional\n        The task for which the given dataset is used for. If not given, a path\n        for the corresponding task-agnostic directory is used.\n    dataset_attributes : dict, optional\n        Additional attributes of the datasets. Used to generate additional\n        sub-folders on the blob \"path\". For example, providing 'lang=en' will\n        results in a path such as '/lang_en/mydataset.csv'. Hierarchy always\n        matches lexicographical order of keyword argument names, so 'lang=en'\n        and 'animal=dog' will result in a path such as\n        'task_name/animal_dof/lang_en/dset.csv'.\n    **kwargs : extra keyword arguments\n        Extra keyword arguments are forwarded to\n        azure.storage.blob.BlockBlobService.get_blob_to_path.\n    \"\"\"\n    fname = ntpath.basename(file_path)\n    blob_name = _blob_name(\n        dataset_name=dataset_name,\n        file_name=fname,\n        task=task,\n        dataset_attributes=dataset_attributes,\n    )\n    # print(\"Downloading blob: {}\".format(blob_name))\n    try:\n        _blob_service().get_blob_to_path(\n            container_name=BARN_CFG['azure']['container_name'],\n            blob_name=blob_name,\n            file_path=file_path,\n            **kwargs,\n        )\n    except Exception as e:\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n        raise MissingDatasetError(\n            \"With blob {}.\".format(blob_name)) from e"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresolves a relative module name to an absolute one.", "response": "def _resolve_name(name, package, level):\n    \"\"\"Resolve a relative module name to an absolute one.\"\"\"\n    bits = package.rsplit('.', level - 1)\n    if len(bits) < level:\n        raise ValueError('attempted relative import beyond top-level package')\n    base = bits[0]\n    return '{}.{}'.format(base, name) if name else base"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresolving a relative module name to an absolute one.", "response": "def resolve_name(name, package):\n    \"\"\"Resolve a relative module name to an absolute one.\"\"\"\n    if not name.startswith('.'):\n        return name\n    elif not package:\n        raise ValueError('{!r} is not a relative name '\n                         '(no leading dot)'.format(name))\n    level = 0\n    for character in name:\n        if character != '.':\n            break\n        level += 1\n    return _resolve_name(name[level:], package, level)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _find_spec_from_path(name, path=None):\n    if name not in sys.modules:\n        return _find_spec(name, path)\n    else:\n        module = sys.modules[name]\n        if module is None:\n            return None\n        try:\n            spec = module.__spec__\n        except AttributeError:\n            six.raise_from(ValueError('{}.__spec__ is not set'.format(name)), None)\n        else:\n            if spec is None:\n                raise ValueError('{}.__spec__ is None'.format(name))\n            return spec", "response": "Find the spec for the specified module."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_spec(name, package=None):\n    fullname = resolve_name(name, package) if name.startswith('.') else name\n    if fullname not in sys.modules:\n        parent_name = fullname.rpartition('.')[0]\n        if parent_name:\n            # Use builtins.__import__() in case someone replaced it.\n            parent = __import__(parent_name, fromlist=['__path__'])\n            return _find_spec(fullname, parent.__path__)\n        else:\n            return _find_spec(fullname, None)\n    else:\n        module = sys.modules[fullname]\n        if module is None:\n            return None\n        try:\n            spec = module.__spec__\n        except AttributeError:\n            six.raise_from(ValueError('{}.__spec__ is not set'.format(name)), None)\n        else:\n            if spec is None:\n                raise ValueError('{}.__spec__ is None'.format(name))\n            return spec", "response": "Find the spec for the specified module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting __package__ on the returned module. This function is deprecated.", "response": "def set_package(fxn):\n    \"\"\"Set __package__ on the returned module.\n    This function is deprecated.\n    \"\"\"\n    @functools.wraps(fxn)\n    def set_package_wrapper(*args, **kwargs):\n        warnings.warn('The import system now takes care of this automatically.',\n                      DeprecationWarning, stacklevel=2)\n        module = fxn(*args, **kwargs)\n        if getattr(module, '__package__', None) is None:\n            module.__package__ = module.__name__\n            if not hasattr(module, '__path__'):\n                module.__package__ = module.__package__.rpartition('.')[0]\n        return module\n    return set_package_wrapper"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_loader(fxn):\n    @functools.wraps(fxn)\n    def set_loader_wrapper(self, *args, **kwargs):\n        warnings.warn('The import system now takes care of this automatically.',\n                      DeprecationWarning, stacklevel=2)\n        module = fxn(self, *args, **kwargs)\n        if getattr(module, '__loader__', None) is None:\n            module.__loader__ = self\n        return module\n    return set_loader_wrapper", "response": "Decorator to set the loader on the returned module. This function is deprecated."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_fields(fields, sort_by_date=False, sort_by_open_projects=False):\n    if (not sort_by_date) and (not sort_by_open_projects):\n        for (_, name, works) in fields:\n            print(name)\n            for work in works:\n                print('- '+str(work))\n    else:\n        works = all_works\n        # Sort works by due_date\n        if sort_by_date:\n            works.sort(key=lambda x: (not x.is_open, x.due_date), reverse=True)\n        for work in works:\n            if sort_by_open_projects:\n                if not work.is_open:\n                    continue\n            # This is ugly, but there is no way to know the field name of a work without searching for it, at the moment\n            field_name = [name for id, name, _ in fields if id == work.field][0]\n            print(field_name)\n            print('- '+str(work))", "response": "Print a list of available fields and works by date."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nask user for a file to send to a work", "response": "def send_work(baseurl, work_id=None, filename=None, command=\"make\"):\n    \"\"\"Ask user for a file to send to a work\"\"\"\n    while 1:\n        if not work_id:\n            try:\n                work_id = input(\"id? \")\n            except KeyboardInterrupt:\n                exit(0)\n        work = get_work(work_id)\n        if not work:\n            print(\"id '{0}' not found\".format(work_id))\n            work_id = None\n            continue\n        if not work.is_open:  # Verify it is open\n            print('\"It\\'s too late for {0} baby...\" (Arnold Schwarzenegger)'.format(work.title))\n            work_id = None\n            continue\n        if not filename:\n            try:\n                filename = input(\"filename? \")\n            except KeyboardInterrupt:\n                exit(0)\n        while 1:\n            try:\n                if command:\n                    if not archive_compile(filename, command):\n                        print(\"Compilation failed\")\n                        try:\n                            send = input(\"Send anyway [y/N] \")\n                        except KeyboardInterrupt:\n                            exit(0)\n                        if send != \"y\":\n                            exit(1)\n                            return\n                work.upload(baseurl, filename)\n                print(\"Uplodaed, but should verify it on the website\")\n                return\n            except FileNotFoundError:\n                print(\"{0} not found in current dir\".format(filename))\n                filename = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninstalling the path - based import components.", "response": "def activate():\n    \"\"\"Install the path-based import components.\"\"\"\n\n    global PathFinder, FileFinder, ff_path_hook\n\n    path_hook_index = len(sys.path_hooks)\n    sys.path_hooks.append(ff_path_hook)\n    # Resetting sys.path_importer_cache values,\n    # to support the case where we have an implicit package inside an already loaded package,\n    # since we need to replace the default importer.\n    sys.path_importer_cache.clear()\n\n    # Setting up the meta_path to change package finding logic\n    pathfinder_index = len(sys.meta_path)\n    sys.meta_path.append(PathFinder)\n\n    return path_hook_index, pathfinder_index"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send(self):\n        parse_links = self.parse_links or self.parse_markdown_links\n\n        message = {\n            'annotations': [],\n            'entities': {\n                'parse_links': parse_links,\n                'parse_markdown_links': self.parse_markdown_links,\n            }\n        }\n\n        if self.photo:\n            photo, photo_meta = _upload_file(self.api, self.photo)\n            message['annotations'].append({\n                'type': 'net.app.core.oembed',\n                'value': {\n                    '+net.app.core.file': {\n                        'file_id': photo.id,\n                        'file_token': photo.file_token,\n                        'format': 'oembed',\n                    }\n                }\n            })\n\n        if self.attachment:\n            attachment, attachment_meta = _upload_file(self.api, self.attachment)\n            message['annotations'].append({\n                'type': 'net.app.core.attachments',\n                'value': {\n                    '+net.app.core.file_list': [\n                        {\n                            'file_id': attachment.id,\n                            'file_token': attachment.file_token,\n                            'format': 'metadata',\n                        }\n                    ]\n                }\n            })\n\n        if self.text:\n            message['text'] = self.text\n        else:\n            message['machine_only'] = True\n\n        if self.headline:\n            message['annotations'].append({\n                'type': 'net.app.core.broadcast.message.metadata',\n                'value': {\n                    'subject': self.headline,\n                },\n            })\n\n        if self.read_more_link:\n            message['annotations'].append({\n                'type': 'net.app.core.crosspost',\n                'value': {\n                    'canonical_url': self.read_more_link,\n                }\n            })\n\n        return self.api.create_message(self.channel_id, data=message)", "response": "Sends the broadcast message."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_server(self,address,port=default_port,password=None,speed=None,valid_times=None,invalid_times=None):\n        '''\n        :address:           remote address of server, or special string ``local`` to\n                            run the command locally\n        :valid_times:       times when this server is available, given as a list\n                            of tuples of 2 strings of form \"HH:MM\" that define the\n                            start and end times. Alternatively, a list of 7 lists can\n                            be given to define times on a per-day-of-week basis\n        E.g.,::\n        \n            [('4:30','14:30'),('17:00','23:00')]\n            # or\n            [\n                [('4:30','14:30'),('17:00','23:00')],       # S\n                [('4:30','14:30'),('17:00','23:00')],       # M\n                [('4:30','14:30'),('17:00','23:00')],       # T\n                [('4:30','14:30'),('17:00','23:00')],       # W\n                [('4:30','14:30'),('17:00','23:00')],       # R\n                [('4:30','14:30'),('17:00','23:00')],       # F\n                [('4:30','14:30'),('17:00','23:00')]        # S\n            ]\n        \n        :invalid_times:     uses the same format as ``valid_times`` but defines times\n                            when the server should not be used\n        '''\n        for t in [valid_times,invalid_times]:\n            if t:\n                if not (self._is_list_of_tuples(t) or self._is_list_of_tuples(t,True)):\n                    raise ValueError('valid_times and invalid_times must either be lists of strings or lists')\n        self.servers.append({\n            'address':address,\n            'port':port,\n            'password':password,\n            'speed':speed,\n            'valid_times':valid_times,\n            'invalid_times':invalid_times\n        })", "response": "Add a server to the list of servers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn if the given archive properly compile.", "response": "def archive_compile(filename, command=\"make\"):\n    \"\"\"\n    Returns if the given archive properly compile.\n    Extract it in a temporary directory, run the given command, and return True it's result is 0\n    \"\"\"\n    if not tarfile.is_tarfile(filename):\n        print(\"Cannot extract archive\")\n        return False\n    if command == \"\":\n        return True\n    with tempfile.TemporaryDirectory(suffix=\"prof\") as tmpdir:\n        with tarfile.open(filename) as tararchive:\n            tararchive.extractall(tmpdir)\n            cwd = os.getcwd()  # get current directory\n            try:\n                os.chdir(tmpdir)\n                print(\"Running {} in {} for file {}\".format(command, tmpdir, filename))\n                make = os.system(command)\n                if make == 0:\n                    print(\"Successfully compiled\")\n                    return True\n            finally:\n                os.chdir(cwd)\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(arguments: List[str], execution_directory: str=None, execution_environment: Dict=None) -> str:\n    process = subprocess.Popen(\n        arguments, stdout=subprocess.PIPE, stdin=subprocess.PIPE, stderr=subprocess.PIPE, cwd=execution_directory,\n        env=execution_environment)\n    out, error = process.communicate()\n    stdout = out.decode(_DATA_ENCODING).rstrip()\n    if process.returncode == _SUCCESS_RETURN_CODE:\n        return stdout\n    else:\n        raise RunException(stdout, error.decode(_DATA_ENCODING).rstrip(), arguments, execution_directory)", "response": "Runs the given arguments from the given directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef raw(self):\n        try:\n            return urlopen(str(self.url))\n        except HTTPError as error:\n            try:\n                # parse error body as json and use message property as error message\n                parsed = self._parsejson(error)\n                exc = RequestError(parsed['message'])\n                exc.__cause__ = None\n                raise exc\n            except ValueError:\n                # when error body is not valid json, error might be caused by server\n                exc = StatbankError()\n                exc.__cause__ = None\n                raise exc", "response": "Make a request to the url and return the raw response object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef csv(self):\n        lines = self._parsecsv(self.raw)\n\n        # set keys from header line (first line)\n        keys = next(lines)\n\n        for line in lines:\n            yield dict(zip(keys, line))", "response": "Parse raw response as csv and return row object list."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct the class for the exception.", "response": "def construct_exc_class(cls):\n    \"\"\"Constructs proxy class for the exception.\"\"\"\n\n    class ProxyException(cls, BaseException):\n        __pep3134__ = True\n\n        @property\n        def __traceback__(self):\n            if self.__fixed_traceback__:\n                return self.__fixed_traceback__\n\n            current_exc, current_tb = sys.exc_info()[1:]\n            if current_exc is self:\n                return current_tb\n\n        def __init__(self, instance=None):  # pylint: disable=W0231\n            self.__original_exception__ = instance\n            self.__fixed_traceback__ = None\n\n        def __getattr__(self, item):\n            return getattr(self.__original_exception__, item)\n\n        def __repr__(self):\n            return repr(self.__original_exception__)\n\n        def __str__(self):\n            return str(self.__original_exception__)\n\n        def with_traceback(self, traceback):\n            instance = copy.copy(self)\n            instance.__fixed_traceback__ = traceback\n            return instance\n\n    ProxyException.__name__ = cls.__name__\n\n    return ProxyException"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prepare_raise(func):\n\n    @functools.wraps(func)\n    def decorator(type_, value=None, traceback=None):\n        if value is not None and isinstance(type_, Exception):\n            raise TypeError(\"instance exception may not have a separate value\")\n\n        if value is None:\n            if isinstance(type_, Exception):\n                error = type_\n            else:\n                error = type_()\n        else:\n            error = type_(value)\n        func(error, value, traceback)\n\n    return decorator", "response": "A short decorator which shrinks the full raise form into proper raise E."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_url(cls, url, **kwargs):\n    username = kwargs.get('username')\n    password = kwargs.get('password')\n    headers = kwargs.get('headers', {})\n    auth = None\n    path = kwargs.get('path', '/tmp/app.zip')\n    dest = kwargs.get('dest', '/app')\n    if username and password:\n      auth = base64.b64encode(b'%s:%s' % (username, password))\n    if auth:\n      headers['Authorization'] = 'Basic %s' % auth.decode('utf8')\n    r = request.get(url, headers=headers, stream=True)\n    if r.status_code != 200:\n      err_msg = 'Could not download resource from url (%s): %s'\n      err_args = (r.status_code, url)\n      raise errors.DownloadError(err_msg % err_args)\n    with open('/tmp/app.zip', 'wb+') as f:\n      chunks = r.iter_content(chunk_size=1024)\n      [f.write(chunk) for chunk in chunks if chunk]\n    return cls.from_zip(path, dest)", "response": "Download a zipped app source code from an url."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new app project from a zipped app file and instantiates it.", "response": "def from_zip(cls, src='/tmp/app.zip', dest='/app'):\n    \"\"\"\n    Unzips a zipped app project file and instantiates it.\n\n    :param src: zipfile path\n    :param dest: destination folder to extract the zipfile content\n\n    Returns\n      A project instance.\n    \"\"\"\n    try:\n      zf = zipfile.ZipFile(src, 'r')\n    except FileNotFoundError:\n      raise errors.InvalidPathError(src)\n    except zipfile.BadZipFile:\n      raise errors.InvalidZipFileError(src)\n    [zf.extract(file, dest) for file in zf.namelist()]\n    zf.close()\n    return cls.from_path(dest)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inspect(self, tab_width=2, ident_char='-'):\n    startpath = self.path\n    output = []\n    for (root, dirs, files) in os.walk(startpath):\n      level = root.replace(startpath, '').count(os.sep)\n      indent = ident_char * tab_width * (level)\n      if level == 0:\n        output.append('{}{}/'.format(indent, os.path.basename(root)))\n      else:\n        output.append('|{}{}/'.format(indent, os.path.basename(root)))\n      subindent = ident_char * tab_width * (level + 1)\n      [output.append('|{}{}'.format(subindent, f)) for f in files]\n    return '\\n'.join(output)", "response": "Inspects a project file structure based on the instance folder property."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef log(self, ctx='all'):\n    path = '%s/%s.log' % (self.path, ctx)\n    if os.path.exists(path) is True:\n      with open(path, 'r') as f:\n        print(f.read())\n      return\n    validate_path = '%s/validate.log' % self.path\n    build_path = '%s/build.log' % self.path\n    out = []\n    with open(validate_path) as validate_log, open(build_path) as build_log:\n      for line in validate_log.readlines():\n        out.append(line)\n      for line in build_log.readlines():\n        out.append(line)\n    print(''.join(out))", "response": "Gets the validate and build log output."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef second_order_diff(arr, x):\n    # Convert to array, so this will work with pandas Series\n    arr = np.array(arr)\n    # Calculate dx for forward diff point\n    dxf = (x[2] - x[0])/2\n    # Calculate dx for backward diff point\n    dxb = (x[-1] - x[-3])/2\n    # Calculate dx array for central difference\n    dx = (x[2:] - x[:-2])/2\n    # For first data point, use 2nd order forward difference\n    first = (-3*arr[0] + 4*arr[1] - arr[2])/(2*dxf)\n    # For last point, use 2nd order backward difference\n    last = (3*arr[-1] - 4*arr[-2] + arr[-3])/(2*dxb)\n    # For all interior points, use 2nd order central difference\n    interior = (arr[2:] - arr[:-2])/(2*dx)\n    # Create entire array\n    darr = np.concatenate(([first], interior, [last]))\n    return darr", "response": "Compute second order difference of an array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an OrderedDict of column names and values.", "response": "def _freeze(self) -> OrderedDict:\n        \"\"\"\n        Evaluate all of the column values and return the result\n        :return: column/value tuples\n        \"\"\"\n        return OrderedDict(**{k: getattr(self, k, None) for k in super().__getattribute__(\"_columns\")})"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nevaluate a method or function and return the value of the method or function invocation or value.", "response": "def _eval(self, m: EvalParam) -> object:\n        \"\"\"\n        Evaluate m returning the method / function invocation or value.  Kind of like a static method\n        :param m: object to evaluate\n        :return: return\n        \"\"\"\n        if inspect.ismethod(m) or inspect.isroutine(m):\n            return m()\n        elif inspect.isfunction(m):\n            return m(self) if len(inspect.signature(m)) > 0 else m()\n        else:\n            return m"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _process_json(response_body):\n    data = json.loads(response_body)\n    uwpassword = UwPassword(uwnetid=data[\"uwNetID\"],\n                            kerb_status=data[\"kerbStatus\"],\n                            interval=None,\n                            last_change=None,\n                            last_change_med=None,\n                            expires_med=None,\n                            interval_med=None,\n                            minimum_length=int(data[\"minimumLength\"]),\n                            time_stamp=parse(data[\"timeStamp\"]),)\n    if \"lastChange\" in data:\n        uwpassword.last_change = parse(data[\"lastChange\"])\n\n    if \"interval\" in data:\n        uwpassword.interval = timeparse(data[\"interval\"])\n\n    if \"lastChangeMed\" in data:\n        uwpassword.last_change_med = parse(data[\"lastChangeMed\"])\n\n    if \"expiresMed\" in data:\n        uwpassword.expires_med = parse(data[\"expiresMed\"])\n\n    if \"intervalMed\" in data:\n        uwpassword.interval_med = timeparse(data[\"intervalMed\"])\n\n    if \"netidStatus\" in data:\n        netid_status = []\n        for status in data[\"netidStatus\"]:\n            netid_status.append(status)\n        uwpassword.netid_status = netid_status\n    return uwpassword", "response": "Processes the response body of a UwPassword request and returns a UwPassword object"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_next_tag():\n    date = datetime.utcnow()\n    date_tag = '{}.{}.{}'.format(date.year, date.month, date.day)\n    if date_tag in latest_tag(): # if there was an update already today\n        latest = latest_tag().split('.') # split by spaces\n        if len(latest) == 4: # if it is not the first revision of the day\n            latest[-1]= str(int(latest[-1])+1)\n        else: # if it is the first revision of the day\n            latest+=['1']\n        date_tag = '.'.join(latest)\n    return date_tag", "response": "creates a tag based on the date and previous tags"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sync_readmes():\n    print(\"syncing README\")\n    with open(\"README.md\", 'r') as reader:\n        file_text = reader.read()\n    with open(\"README\", 'w') as writer:\n        writer.write(file_text)", "response": "syncs README. md into README for pypi documentation"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef similarity(self, other):\n        numerator, denominator = sorted((self.value, other.value))\n        try:\n            ratio = float(numerator) / denominator\n        except ZeroDivisionError:\n            ratio = 0.0 if numerator else 1.0\n        similarity = self.Similarity(ratio)\n        return similarity", "response": "Get similarity as a ratio of the two numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef similarity(self, other):\n        ratio = SequenceMatcher(a=self.value, b=other.value).ratio()\n        similarity = self.Similarity(ratio)\n        return similarity", "response": "Get similarity as a ratio of the two texts."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets similarity as a discrete ratio ( 1. 0 or 0. 0", "response": "def similarity(self, other):\n        \"\"\"Get similarity as a discrete ratio (1.0 or 0.0).\"\"\"\n        ratio = 1.0 if (str(self).lower() == str(other).lower()) else 0.0\n        similarity = self.Similarity(ratio)\n        return similarity"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstrip articles and whitespace and remove case.", "response": "def _strip(text):\n        \"\"\"Strip articles/whitespace and remove case.\"\"\"\n        text = text.strip()\n        text = text.replace('  ', ' ')  # remove duplicate spaces\n        text = text.lower()\n        for joiner in TextTitle.JOINERS:\n            text = text.replace(joiner, 'and')\n        for article in TextTitle.ARTICLES:\n            if text.startswith(article + ' '):\n                text = text[len(article) + 1:]\n                break\n        return text"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef similarity(self, other):\n        logging.debug(\"comparing %r and %r...\", self.stripped, other.stripped)\n        ratio = SequenceMatcher(a=self.stripped, b=other.stripped).ratio()\n        similarity = self.Similarity(ratio)\n        return similarity", "response": "Get similarity as a ratio of the stripped text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef skull_strip(dset,suffix='_ns',prefix=None,unifize=True):\n    ''' use bet to strip skull from given anatomy '''\n    # should add options to use betsurf and T1/T2 in the future\n    # Since BET fails on weirdly distributed datasets, I added 3dUnifize in... I realize this makes this dependent on AFNI. Sorry, :)\n    if prefix==None:\n        prefix = nl.suffix(dset,suffix)\n    unifize_dset = nl.suffix(dset,'_u')\n    cmd = bet2 if bet2 else 'bet2'\n    if unifize:\n        info = nl.dset_info(dset)\n        if info==None:\n            nl.notify('Error: could not read info for dset %s' % dset,level=nl.level.error)\n            return False\n        cmd = os.path.join(fsl_dir,cmd) if fsl_dir else cmd\n        cutoff_value = nl.max(dset) * 0.05\n        nl.run(['3dUnifize','-prefix',unifize_dset,nl.calc(dset,'step(a-%f)*a' % cutoff_value)],products=unifize_dset)\n    else:\n        unifize_dset = dset\n    nl.run([cmd,unifize_dset,prefix,'-w',0.5],products=prefix)", "response": "use bet to strip skull from given anatomy dataset"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a full url for a given URL.", "response": "def full_url(url='', domain=None, protocol='https'):\n    \"\"\"\n    Prepend protocol (default to https) and domain name (default from the Site framework) to an url\n    \"\"\"\n    if domain is None:\n        from django.contrib.sites.models import Site\n        domain = Site.objects.get_current().domain\n    return f'{protocol}://{domain}{url}'"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef query_sum(queryset, field):\n    return queryset.aggregate(s=models.functions.Coalesce(models.Sum(field), 0))['s']", "response": "Query the DBMS for a sum on a queryset"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets default environment variables from. env file", "response": "def get_env(env_file='.env'):\n    \"\"\"\n    Set default environment variables from .env file\n    \"\"\"\n    try:\n        with open(env_file) as f:\n            for line in f.readlines():\n                try:\n                    key, val = line.split('=', maxsplit=1)\n                    os.environ.setdefault(key.strip(), val.strip())\n                except ValueError:\n                    pass\n    except FileNotFoundError:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes a row and converts it into a dictionary.", "response": "def to_dict_formatter(row, cursor):\n    \"\"\" Take a row and use the column names from cursor to turn the row into a\n    dictionary.\n\n    Note: converts column names to lower-case!\n\n    :param row: one database row, sequence of column values\n    :type row: (value, ...)\n    :param cursor: the cursor which was used to make the query\n    :type cursor: DB-API cursor object\n    \"\"\"\n    # Empty row? Return.\n    if not row:\n        return row\n    # No cursor? Raise runtime error.\n    if cursor is None or cursor.description is None:\n        raise RuntimeError(\"No DB-API cursor or description available.\")\n\n    # Give each value the appropriate column name within in the resulting\n    # dictionary.\n    column_names = (d[0] for d in cursor.description)  # 0 is the name\n    return {name: value for value, name in zip(row, column_names)}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshow how the SQL looks like when executed by the DB.", "response": "def show(self, *args, **kwds):\n        \"\"\" Show how the SQL looks like when executed by the DB.\n\n        This might not be supported by all connection types.\n        For example: PostgreSQL does support it, SQLite does not.\n\n        :rtype: str\n        \"\"\"\n        # Same as in __call__, arguments win over keywords\n        arg = args\n        if not arg:\n            arg = kwds  # pylint: disable=redefined-variable-type\n        return self._db.show(self._sql, arg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the rows from the cursor and apply the row formatter.", "response": "def _produce_return(self, cursor):\n        \"\"\" Get the rows from the cursor and apply the row formatter.\n\n        :return: sequence of rows, or a generator if a row formatter has to be\n            applied\n        \"\"\"\n        results = cursor.fetchall()\n\n        # Format rows within a generator?\n        if self._row_formatter is not None:\n            return (self._row_formatter(r, cursor) for r in results)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _produce_return(self, cursor):\n        results = cursor.fetchmany(2)\n        if len(results) != 1:\n            return None\n\n        # Return the one row, or the one column.\n        row = results[0]\n        if self._row_formatter is not None:\n            row = self._row_formatter(row, cursor)\n        elif len(row) == 1:\n            row = row[0]\n\n        return row", "response": "Return the one result."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _row_generator(self, cursor):\n        rowset = cursor.fetchmany(self._arraysize)\n        while rowset:\n            if self._row_formatter is not None:\n                rowset = (self._row_formatter(r, cursor) for r in rowset)\n            for row in rowset:\n                yield row\n            rowset = cursor.fetchmany(self._arraysize)", "response": "Yields individual rows until no more rows\n            exist in query result. Applies row formatter if such exists."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _produce_return(self, cursor):\n        self.callback(self._row_generator(cursor), *self.cb_args)\n        return None", "response": "Calls callback once with generator.\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the rowcount property from the used cursor.", "response": "def _produce_return(self, cursor):\n        \"\"\" Return the rowcount property from the used cursor.\n\n        Checks the count first, if a count was given.\n\n        :raise ManipulationCheckError: if a row count was set but does not\n            match\n        \"\"\"\n        rowcount = cursor.rowcount\n\n        # Check the row count?\n        if self._rowcount is not None and self._rowcount != rowcount:\n            raise ManipulationCheckError(\n                \"Count was {}, expected {}.\".format(rowcount, self._rowcount))\n\n        return rowcount"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the linter parse and return result list.", "response": "def get_results(self):\n        \"\"\"Run the linter, parse, and return result list.\n\n        If a linter specified by the user is not found, return an error message\n        as result.\n        \"\"\"\n        try:\n            stdout, stderr = self._lint()\n            # Can't return a generator from a subprocess\n            return list(stdout), stderr or []\n        except FileNotFoundError as exception:\n            # Error if the linter was not found but was chosen by the user\n            if self._linter.name in self.config.user_linters:\n                error_msg = 'Could not find {}. Did you install it? ' \\\n                    'Got exception: {}'.format(self._linter.name, exception)\n                return [[], [error_msg]]\n            # If the linter was not chosen by the user, do nothing\n            return [[], []]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning command with options and targets ready for execution.", "response": "def _get_command(self):\n        \"\"\"Return command with options and targets, ready for execution.\"\"\"\n        targets = ' '.join(self.targets)\n        cmd_str = self._linter.command_with_options + ' ' + targets\n        cmd_shlex = shlex.split(cmd_str)\n        return list(cmd_shlex)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning the linter in a subprocess.", "response": "def _lint(self):\n        \"\"\"Run linter in a subprocess.\"\"\"\n        command = self._get_command()\n        process = subprocess.run(command, stdout=subprocess.PIPE,  # nosec\n                                 stderr=subprocess.PIPE)\n        LOG.info('Finished %s', ' '.join(command))\n        stdout, stderr = self._get_output_lines(process)\n        return self._linter.parse(stdout), self._parse_stderr(stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lint(self, targets):\n        LinterRunner.targets = targets\n        linters = self._config.get_linter_classes()\n        with Pool() as pool:\n            out_err_none = pool.map(LinterRunner.run, linters)\n        out_err = [item for item in out_err_none if item is not None]\n        stdout, stderr = zip(*out_err)\n        return sorted(chain.from_iterable(stdout)), chain.from_iterable(stderr)", "response": "Run linters in parallel and sort all results."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_from_cli(self, args):\n        if args['--dump-config']:\n            self._config.print_config()\n        else:\n            stdout, stderr = self.lint(args['<path>'])\n            self.print_results(stdout, stderr)", "response": "Read arguments run and print results."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef print_results(cls, stdout, stderr):\n        for line in stderr:\n            print(line, file=sys.stderr)\n        if stdout:\n            if stderr:  # blank line to separate stdout from stderr\n                print(file=sys.stderr)\n            cls._print_stdout(stdout)\n        else:\n            print(':) No issues found.')", "response": "Print linter results and exits with an error if there s any."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef download(self, *ids):\n        bundles = sublists_of(ids, 20)  # 20 files at once is an API restriction\n\n        for bundle in bundles:\n            download_response = self._rpc.DownloadSubtitles(self._token, bundle)\n\n            assert_status(download_response)\n\n            download_data = download_response.get('data')\n\n            for item in download_data:\n                subtitle_id = item['idsubtitlefile']\n                subtitle_data = item['data']\n\n                decompressed = decompress(subtitle_data)\n\n                yield Result(subtitle_id, decompressed)", "response": "Downloads the subtitles with the given ids."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef notification_on_post_create_historical_record(\n    instance, history_date, history_user, history_change_reason, **kwargs\n):\n    \"\"\"Checks and processes any notifications for this model.\n\n    Processes if `label_lower` is in site_notifications.models.\n\n    Note, this is the post_create of the historical model.\n    \"\"\"\n    if (\n        site_notifications.loaded\n        and instance._meta.label_lower in site_notifications.models\n    ):\n        opts = dict(\n            instance=instance,\n            user=instance.user_modified or instance.user_created,\n            history_date=history_date,\n            history_user=history_user,\n            history_change_reason=history_change_reason,\n            fail_silently=True,\n            **kwargs\n        )\n        site_notifications.notify(**opts)", "response": "Checks and processes any notifications for this model."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the mail server mailing lists based on the changes in the UserProfile model.", "response": "def manage_mailists_on_userprofile_m2m_changed(\n    action, instance, pk_set, sender, **kwargs\n):\n    \"\"\"Updates the mail server mailing lists based on the\n    selections in the UserProfile model.\n    \"\"\"\n    try:\n        instance.email_notifications\n    except AttributeError:\n        pass\n    else:\n        if action == \"post_remove\":\n            update_mailing_lists_in_m2m(\n                sender=sender,\n                userprofile=instance,\n                unsubscribe=True,\n                pk_set=pk_set,\n                verbose=True,\n            )\n        elif action == \"post_add\":\n            update_mailing_lists_in_m2m(\n                sender=sender,\n                userprofile=instance,\n                subscribe=True,\n                pk_set=pk_set,\n                verbose=True,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a cusotom implementation of a served http resource.", "response": "def addMobileResource(self, pluginSubPath: bytes, resource: BasicResource) -> None:\n        \"\"\" Add Site Resource\n\n        Add a cusotom implementation of a served http resource.\n\n        :param pluginSubPath: The resource path where you want to serve this resource.\n        :param resource: The resource to serve.\n        :return: None\n\n        \"\"\"\n        pluginSubPath = pluginSubPath.strip(b'/')\n        self.__rootMobileResource.putChild(pluginSubPath, resource)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(file_contents, file_name):\n    '''\n    Takes a list of files which are assumed to be jinja2 templates and tries to\n    parse the contents of the files\n\n    Args:\n        file_contents (str): File contents of a jinja file\n\n    Raises:\n        Exception: An exception is raised if the contents of the file cannot be\n                   parsed.\n    '''\n\n    env = Environment()\n    result = \"\"\n    try:\n        env.parse(file_contents)\n    except Exception:\n        _, exc_value, _ = sys.exc_info()\n        result += \"ERROR: Jinja2 Template File: {0}\".format(file_name)\n        result += repr(exc_value) + '\\n'\n\n    return result", "response": "Parses a list of files which are assumed to be jinja2 templates and returns a string containing the contents of the files that are parsed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite a response to the HTTP server.", "response": "def write_response(\n        self, status_code: Union[\n            int, constants.HttpStatusCode\n        ]=constants.HttpStatusCode.BAD_REQUEST, *,\n        headers: Optional[_HeaderType]=None\n            ) -> \"writers.HttpResponseWriter\":\n        \"\"\"\n        When this exception is raised on the server side, this method is used\n        to send a error response instead of\n        :method:`BaseHttpStreamReader.write_response()`.\n        \"\"\"\n        return self._delegate.write_response(\n            constants.HttpStatusCode(status_code),\n            headers=headers)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def read(self, n: int=-1, exactly: bool=False) -> bytes:\n        async with self._read_lock:\n            self._raise_exc_if_finished()\n\n            if n == 0:\n                return b\"\"\n\n            if exactly:\n                if n < 0:  # pragma: no cover\n                    raise ValueError(\n                        \"You MUST sepcify the length of the data \"\n                        \"if exactly is True.\")\n\n                if n > self.max_buf_len:  # pragma: no cover\n                    raise ValueError(\n                        \"The length provided cannot be larger \"\n                        \"than the max buffer length.\")\n\n                while len(self) < n:\n                    try:\n                        await self._wait_for_data()\n\n                    except asyncio.CancelledError:  # pragma: no cover\n                        raise\n\n                    except Exception as e:\n                        raise ReadUnsatisfiableError from e\n\n            elif n < 0:\n                while True:\n                    if len(self) > self.max_buf_len:\n                        raise MaxBufferLengthReachedError\n\n                    try:\n                        await self._wait_for_data()\n\n                    except asyncio.CancelledError:  # pragma: no cover\n                        raise\n\n                    except Exception:\n                        data = bytes(self._buf)\n                        self._buf.clear()\n\n                        return data\n\n            elif len(self) == 0:\n                await self._wait_for_data()\n\n            data = bytes(self._buf[0:n])\n            del self._buf[0:n]\n\n            return data", "response": "Read at most n bytes data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading until the separator is found in the buffer.", "response": "async def read_until(\n        self, separator: bytes=b\"\\n\",\n            *, keep_separator: bool=True) -> bytes:\n        \"\"\"\n        Read until the separator has been found.\n\n        When the max size of the buffer has been reached,\n        and the separator is not found, this method will raise\n        a :class:`MaxBufferLengthReachedError`.\n        Similarly, if the end has been reached before found the separator\n        it will raise a :class:`SeparatorNotFoundError`.\n\n        When :method:`.finished()` is `True`, this method will raise any errors\n        occurred during the read or a :class:`ReadFinishedError`.\n        \"\"\"\n        async with self._read_lock:\n            self._raise_exc_if_finished()\n\n            start_pos = 0\n\n            while True:\n                separator_pos = self._buf.find(separator, start_pos)\n\n                if separator_pos != -1:\n                    break\n\n                if len(self) > self.max_buf_len:\n                    raise MaxBufferLengthReachedError\n\n                try:\n                    await self._wait_for_data()\n\n                except asyncio.CancelledError:  # pragma: no cover\n                    raise\n\n                except Exception as e:\n                    if len(self) > 0:\n                        raise SeparatorNotFoundError from e\n\n                    else:\n                        raise\n\n                new_start_pos = len(self) - len(separator)\n\n                if new_start_pos > 0:\n                    start_pos = new_start_pos\n\n            full_pos = separator_pos + len(separator)\n\n            if keep_separator:\n                data_pos = full_pos\n\n            else:\n                data_pos = separator_pos\n\n            data = bytes(self._buf[0:data_pos])\n            del self._buf[0:full_pos]\n\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a response to the client.", "response": "def write_response(\n        self, status_code: Union[int, constants.HttpStatusCode], *,\n        headers: Optional[_HeaderType]=None\n            ) -> \"writers.HttpResponseWriter\":\n        \"\"\"\n        Write a response to the client.\n        \"\"\"\n        self._writer = self.__delegate.write_response(\n            constants.HttpStatusCode(status_code),\n            headers=headers)\n\n        return self._writer"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef createDbusProxyObject(bus_name, object_path, bus=None):\n    '''\n    Create dbus proxy object\n    '''\n    bus = bus or dbus.SessionBus.get_session()\n    return bus.get_object(bus_name, object_path)", "response": "Create dbus proxy object"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntranslates the given text to the specified language.", "response": "def translate(text, target_lang='en', source_lang=None):\n\t\"\"\"\n\tUse the Google v2 API to translate the text. You had better have set\n\tthe API key on this function before calling it.\n\t\"\"\"\n\turl_base = 'https://www.googleapis.com/language/translate/v2'\n\tparams = dict(\n\t\tkey=translate.API_key,\n\t\tq=text,\n\t\ttarget=target_lang,\n\t)\n\tif source_lang:\n\t\tparams['source'] = source_lang\n\tresp = requests.get(url_base, params=params)\n\tresp.raise_for_status()\n\treturn resp.json()['data']['translations'][0]['translatedText']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a SigningKey object from credentials.", "response": "def from_credentials(cls: Type[SigningKeyType], salt: Union[str, bytes], password: Union[str, bytes],\n                         scrypt_params: Optional[ScryptParams] = None) -> SigningKeyType:\n        \"\"\"\n        Create a SigningKey object from credentials\n\n        :param salt: Secret salt passphrase credential\n        :param password: Secret password credential\n        :param scrypt_params: ScryptParams instance\n        \"\"\"\n        if scrypt_params is None:\n            scrypt_params = ScryptParams()\n\n        salt = ensure_bytes(salt)\n        password = ensure_bytes(password)\n        seed = scrypt(password, salt, scrypt_params.N, scrypt_params.r, scrypt_params.p, scrypt_params.seed_length)\n\n        return cls(seed)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving hexadecimal seed file from seed to authentication file", "response": "def save_seedhex_file(self, path: str) -> None:\n        \"\"\"\n        Save hexadecimal seed file from seed\n\n        :param path: Authentication file path\n        \"\"\"\n        seedhex = convert_seed_to_seedhex(self.seed)\n        with open(path, 'w') as fh:\n            fh.write(seedhex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns SigningKey instance from Seedhex file", "response": "def from_seedhex_file(path: str) -> SigningKeyType:\n        \"\"\"\n        Return SigningKey instance from Seedhex file\n\n        :param str path: Hexadecimal seed file path\n        \"\"\"\n        with open(path, 'r') as fh:\n            seedhex = fh.read()\n        return SigningKey.from_seedhex(seedhex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_seedhex(cls: Type[SigningKeyType], seedhex: str) -> SigningKeyType:\n        regex_seedhex = compile(\"([0-9a-fA-F]{64})\")\n        match = search(regex_seedhex, seedhex)\n        if not match:\n            raise Exception('Error: Bad seed hexadecimal format')\n        seedhex = match.groups()[0]\n        seed = convert_seedhex_to_seed(seedhex)\n        return cls(seed)", "response": "Return SigningKey instance from seed hexadecimal format"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_private_key(path: str) -> SigningKeyType:\n        key = load_key(path)\n        key.pubkey = Base58Encoder.encode(key.vk)\n        return key", "response": "Read authentication file read public key add public key attribute"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decrypt_seal(self, data: bytes) -> bytes:\n        curve25519_public_key = libnacl.crypto_sign_ed25519_pk_to_curve25519(self.vk)\n        curve25519_secret_key = libnacl.crypto_sign_ed25519_sk_to_curve25519(self.sk)\n        return libnacl.crypto_box_seal_open(data, curve25519_public_key, curve25519_secret_key)", "response": "Decrypt bytes data with a curve25519 version of the ed25519 key pair."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_pubsec_file(cls: Type[SigningKeyType], path: str) -> SigningKeyType:\n        with open(path, 'r') as fh:\n            pubsec_content = fh.read()\n\n        # line patterns\n        regex_pubkey = compile(\"pub: ([1-9A-HJ-NP-Za-km-z]{43,44})\", MULTILINE)\n        regex_signkey = compile(\"sec: ([1-9A-HJ-NP-Za-km-z]{88,90})\", MULTILINE)\n\n        # check public key field\n        match = search(regex_pubkey, pubsec_content)\n        if not match:\n            raise Exception('Error: Bad format PubSec v1 file, missing public key')\n\n        # check signkey field\n        match = search(regex_signkey, pubsec_content)\n        if not match:\n            raise Exception('Error: Bad format PubSec v1 file, missing sec key')\n\n        # capture signkey\n        signkey_hex = match.groups()[0]\n\n        # extract seed from signkey\n        seed = bytes(Base58Encoder.decode(signkey_hex)[0:32])\n\n        return cls(seed)", "response": "Return SigningKey instance from PubSec v1 file"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves a Duniter PubSec file.", "response": "def save_pubsec_file(self, path: str) -> None:\n        \"\"\"\n        Save a Duniter PubSec file (PubSec) v1\n\n        :param path: Path to file\n        \"\"\"\n        # version\n        version = 1\n\n        # base58 encode keys\n        base58_signing_key = Base58Encoder.encode(self.sk)\n        base58_public_key = self.pubkey\n\n        # save file\n        with open(path, 'w') as fh:\n            fh.write(\n                \"\"\"Type: PubSec\nVersion: {version}\npub: {pubkey}\nsec: {signkey}\"\"\".format(version=version, pubkey=base58_public_key, signkey=base58_signing_key)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_wif_or_ewif_file(path: str, password: Optional[str] = None) -> SigningKeyType:\n        with open(path, 'r') as fh:\n            wif_content = fh.read()\n\n        # check data field\n        regex = compile('Data: ([1-9A-HJ-NP-Za-km-z]+)', MULTILINE)\n        match = search(regex, wif_content)\n        if not match:\n            raise Exception('Error: Bad format WIF or EWIF v1 file')\n\n        # capture hexa wif key\n        wif_hex = match.groups()[0]\n        return SigningKey.from_wif_or_ewif_hex(wif_hex, password)", "response": "Reads a WIF file and returns a SigningKey instance from it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn SigningKey instance from Duniter WIF or EWIF in hexadecimal format.", "response": "def from_wif_or_ewif_hex(wif_hex: str, password: Optional[str] = None) -> SigningKeyType:\n        \"\"\"\n        Return SigningKey instance from Duniter WIF or EWIF in hexadecimal format\n\n        :param wif_hex: WIF or EWIF string in hexadecimal format\n        :param password: Password of EWIF encrypted seed\n        \"\"\"\n        wif_bytes = Base58Encoder.decode(wif_hex)\n\n        fi = wif_bytes[0:1]\n\n        if fi == b\"\\x01\":\n            return SigningKey.from_wif_hex(wif_hex)\n        elif fi == b\"\\x02\" and password is not None:\n            return SigningKey.from_ewif_hex(wif_hex, password)\n        else:\n            raise Exception(\"Error: Bad format: not WIF nor EWIF\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_wif_file(path: str) -> SigningKeyType:\n        with open(path, 'r') as fh:\n            wif_content = fh.read()\n\n        # check data field\n        regex = compile('Data: ([1-9A-HJ-NP-Za-km-z]+)', MULTILINE)\n        match = search(regex, wif_content)\n        if not match:\n            raise Exception('Error: Bad format WIF v1 file')\n\n        # capture hexa wif key\n        wif_hex = match.groups()[0]\n        return SigningKey.from_wif_hex(wif_hex)", "response": "Return SigningKey instance from Duniter WIF file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn SigningKey instance from Duniter WIF in hexadecimal format.", "response": "def from_wif_hex(cls: Type[SigningKeyType], wif_hex: str) -> SigningKeyType:\n        \"\"\"\n        Return SigningKey instance from Duniter WIF in hexadecimal format\n\n        :param wif_hex: WIF string in hexadecimal format\n        \"\"\"\n        wif_bytes = Base58Encoder.decode(wif_hex)\n        if len(wif_bytes) != 35:\n            raise Exception(\"Error: the size of WIF is invalid\")\n\n        # extract data\n        checksum_from_wif = wif_bytes[-2:]\n        fi = wif_bytes[0:1]\n        seed = wif_bytes[1:-2]\n        seed_fi = wif_bytes[0:-2]\n\n        # check WIF format flag\n        if fi != b\"\\x01\":\n            raise Exception(\"Error: bad format version, not WIF\")\n\n        # checksum control\n        checksum = libnacl.crypto_hash_sha256(libnacl.crypto_hash_sha256(seed_fi))[0:2]\n        if checksum_from_wif != checksum:\n            raise Exception(\"Error: bad checksum of the WIF\")\n\n        return cls(seed)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave a Wallet Import Format file (WIF) v1 :param path: Path to file", "response": "def save_wif_file(self, path: str) -> None:\n        \"\"\"\n        Save a Wallet Import Format file (WIF) v1\n\n        :param path: Path to file\n        \"\"\"\n        # version\n        version = 1\n\n        # add format to seed (1=WIF,2=EWIF)\n        seed_fi = b\"\\x01\" + self.seed\n\n        # calculate checksum\n        sha256_v1 = libnacl.crypto_hash_sha256(seed_fi)\n        sha256_v2 = libnacl.crypto_hash_sha256(sha256_v1)\n        checksum = sha256_v2[0:2]\n\n        # base58 encode key and checksum\n        wif_key = Base58Encoder.encode(seed_fi + checksum)\n\n        with open(path, 'w') as fh:\n            fh.write(\n                \"\"\"Type: WIF\nVersion: {version}\nData: {data}\"\"\".format(version=version, data=wif_key)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the contents of an EWIF file and returns a SigningKey instance", "response": "def from_ewif_file(path: str, password: str) -> SigningKeyType:\n        \"\"\"\n        Return SigningKey instance from Duniter EWIF file\n\n        :param path: Path to EWIF file\n        :param password: Password of the encrypted seed\n        \"\"\"\n        with open(path, 'r') as fh:\n            wif_content = fh.read()\n\n        # check data field\n        regex = compile('Data: ([1-9A-HJ-NP-Za-km-z]+)', MULTILINE)\n        match = search(regex, wif_content)\n        if not match:\n            raise Exception('Error: Bad format EWIF v1 file')\n\n        # capture ewif key\n        ewif_hex = match.groups()[0]\n        return SigningKey.from_ewif_hex(ewif_hex, password)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_ewif_hex(cls: Type[SigningKeyType], ewif_hex: str, password: str) -> SigningKeyType:\n        ewif_bytes = Base58Encoder.decode(ewif_hex)\n        if len(ewif_bytes) != 39:\n            raise Exception(\"Error: the size of EWIF is invalid\")\n\n        # extract data\n        fi = ewif_bytes[0:1]\n        checksum_from_ewif = ewif_bytes[-2:]\n        ewif_no_checksum = ewif_bytes[0:-2]\n        salt = ewif_bytes[1:5]\n        encryptedhalf1 = ewif_bytes[5:21]\n        encryptedhalf2 = ewif_bytes[21:37]\n\n        # check format flag\n        if fi != b\"\\x02\":\n            raise Exception(\"Error: bad format version, not EWIF\")\n\n        # checksum control\n        checksum = libnacl.crypto_hash_sha256(libnacl.crypto_hash_sha256(ewif_no_checksum))[0:2]\n        if checksum_from_ewif != checksum:\n            raise Exception(\"Error: bad checksum of the EWIF\")\n\n        # SCRYPT\n        password_bytes = password.encode(\"utf-8\")\n        scrypt_seed = scrypt(password_bytes, salt, 16384, 8, 8, 64)\n        derivedhalf1 = scrypt_seed[0:32]\n        derivedhalf2 = scrypt_seed[32:64]\n\n        # AES\n        aes = pyaes.AESModeOfOperationECB(derivedhalf2)\n        decryptedhalf1 = aes.decrypt(encryptedhalf1)\n        decryptedhalf2 = aes.decrypt(encryptedhalf2)\n\n        # XOR\n        seed1 = xor_bytes(decryptedhalf1, derivedhalf1[0:16])\n        seed2 = xor_bytes(decryptedhalf2, derivedhalf1[16:32])\n        seed = bytes(seed1 + seed2)\n\n        # Password Control\n        signer = SigningKey(seed)\n        salt_from_seed = libnacl.crypto_hash_sha256(\n            libnacl.crypto_hash_sha256(\n                Base58Encoder.decode(signer.pubkey)))[0:4]\n        if salt_from_seed != salt:\n            raise Exception(\"Error: bad Password of EWIF address\")\n\n        return cls(seed)", "response": "Return SigningKey instance from Duniter EWIF string in hexadecimal format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave an Encrypted Wallet Import Format file.", "response": "def save_ewif_file(self, path: str, password: str) -> None:\n        \"\"\"\n        Save an Encrypted Wallet Import Format file (WIF v2)\n\n        :param path: Path to file\n        :param password:\n        \"\"\"\n        # version\n        version = 1\n\n        # add version to seed\n        salt = libnacl.crypto_hash_sha256(\n            libnacl.crypto_hash_sha256(\n                Base58Encoder.decode(self.pubkey)))[0:4]\n\n        # SCRYPT\n        password_bytes = password.encode(\"utf-8\")\n        scrypt_seed = scrypt(password_bytes, salt, 16384, 8, 8, 64)\n        derivedhalf1 = scrypt_seed[0:32]\n        derivedhalf2 = scrypt_seed[32:64]\n\n        # XOR\n        seed1_xor_derivedhalf1_1 = bytes(xor_bytes(self.seed[0:16], derivedhalf1[0:16]))\n        seed2_xor_derivedhalf1_2 = bytes(xor_bytes(self.seed[16:32], derivedhalf1[16:32]))\n\n        # AES\n        aes = pyaes.AESModeOfOperationECB(derivedhalf2)\n        encryptedhalf1 = aes.encrypt(seed1_xor_derivedhalf1_1)\n        encryptedhalf2 = aes.encrypt(seed2_xor_derivedhalf1_2)\n\n        # add format to final seed (1=WIF,2=EWIF)\n        seed_bytes = b'\\x02' + salt + encryptedhalf1 + encryptedhalf2\n\n        # calculate checksum\n        sha256_v1 = libnacl.crypto_hash_sha256(seed_bytes)\n        sha256_v2 = libnacl.crypto_hash_sha256(sha256_v1)\n        checksum = sha256_v2[0:2]\n\n        # B58 encode final key string\n        ewif_key = Base58Encoder.encode(seed_bytes + checksum)\n\n        # save file\n        with open(path, 'w') as fh:\n            fh.write(\n                \"\"\"Type: EWIF\nVersion: {version}\nData: {data}\"\"\".format(version=version, data=ewif_key)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(type=None, **ArgConfig):\n  ArgConfig.update(type=type)\n  return gatherInput(**reconfigArg(ArgConfig))", "response": "Helps to interactively get user input.\n    desc type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_product_version(path: typing.Union[str, Path]) -> VersionInfo:\n    path = Path(path).absolute()\n    pe_info = pefile.PE(str(path))\n\n    try:\n        for file_info in pe_info.FileInfo:  # pragma: no branch\n            if isinstance(file_info, list):\n                result = _parse_file_info(file_info)\n                if result:\n                    return result\n            else:\n                result = _parse_file_info(pe_info.FileInfo)\n                if result:\n                    return result\n\n        raise RuntimeError(f'unable to obtain version from {path}')\n    except (KeyError, AttributeError) as exc:\n        traceback.print_exc()\n        raise RuntimeError(f'unable to obtain version from {path}') from exc", "response": "Get version info from executable\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts the queing thread that executes the iterator and feeds jobs into the queue.", "response": "def start(self):\n        \"\"\"this function will start the queing thread that executes the\n        iterator and feeds jobs into the queue.  It also starts the worker\n        threads that just sit and wait for items to appear on the queue. This\n        is a non blocking call, so the executing thread is free to do other\n        things while the other threads work.\"\"\"\n        self.logger.debug('start')\n        # start each of the task threads.\n        for x in range(self.number_of_threads):\n            # each thread is given the config object as well as a reference to\n            # this manager class.  The manager class is where the queue lives\n            # and the task threads will refer to it to get their next jobs.\n            new_thread = TaskThread(self.config, self.task_queue)\n            self.thread_list.append(new_thread)\n            new_thread.start()\n        self.queuing_thread = threading.Thread(\n          name=\"QueuingThread\",\n          target=self._queuing_thread_func\n        )\n        self.queuing_thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef blocking_start(self, waiting_func=None):\n        try:\n            self.start()\n            self.wait_for_completion(waiting_func)\n            # it only ends if someone hits  ^C or sends SIGHUP or SIGTERM -\n            # any of which will get translated into a KeyboardInterrupt\n        except KeyboardInterrupt:\n            while True:\n                try:\n                    self.stop()\n                    break\n                except KeyboardInterrupt:\n                    self.logger.warning('We heard you the first time.  There '\n                                   'is no need for further keyboard or signal '\n                                   'interrupts.  We are waiting for the '\n                                   'worker threads to stop.  If this app '\n                                   'does not halt soon, you may have to send '\n                                   'SIGKILL (kill -9)')", "response": "start and then wait for completion"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsit around and wait for the queue to become empty.", "response": "def wait_for_empty_queue(self, wait_log_interval=0, wait_reason=''):\n        \"\"\"Sit around and wait for the queue to become empty\n\n        parameters:\n            wait_log_interval - while sleeping, it is helpful if the thread\n                                periodically announces itself so that we\n                                know that it is still alive.  This number is\n                                the time in seconds between log entries.\n            wait_reason - the is for the explaination of why the thread is\n                          sleeping.  This is likely to be a message like:\n                          'there is no work to do'.\"\"\"\n        seconds = 0\n        while True:\n            if self.task_queue.empty():\n                break\n            self.quit_check()\n            if wait_log_interval and not seconds % wait_log_interval:\n                self.logger.info('%s: %dsec so far',\n                                 wait_reason,\n                                 seconds)\n                self.quit_check()\n            seconds += 1\n            time.sleep(1.0)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _kill_worker_threads(self):\n        for x in range(self.number_of_threads):\n            self.task_queue.put((None, None))\n        self.logger.debug(\"waiting for standard worker threads to stop\")\n        for t in self.thread_list:\n            t.join()", "response": "This function coerces the consumer threads to kill them."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self):\n        try:\n            quit_request_detected = False\n            while True:\n                function, arguments = self.task_queue.get()\n                if function is None:\n                    # this allows us to watch the threads die and identify\n                    # threads that may be hanging or deadlocked\n                    self.config.logger.info('quits')\n                    break\n                if quit_request_detected:\n                    continue\n                try:\n                    try:\n                        args, kwargs = arguments\n                    except ValueError:\n                        args = arguments\n                        kwargs = {}\n                    function(*args, **kwargs)  # execute the task\n                except Exception:\n                    self.config.logger.error(\"Error in processing a job\",\n                                             exc_info=True)\n                except KeyboardInterrupt:  # TODO: can probably go away\n                    self.config.logger.info('quit request detected')\n                    quit_request_detected = True\n                    #thread.interrupt_main()  # only needed if signal handler\n                                             # not registered\n        except Exception:\n            self.config.logger.critical(\"Failure in task_queue\", exc_info=True)", "response": "The main routine for a thread s work."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef easter(year, method=EASTER_WESTERN):\n\n    if not (1 <= method <= 3):\n        raise ValueError(\"invalid method\")\n\n    # g - Golden year - 1\n    # c - Century\n    # h - (23 - Epact) mod 30\n    # i - Number of days from March 21 to Paschal Full Moon\n    # j - Weekday for PFM (0=Sunday, etc)\n    # p - Number of days from March 21 to Sunday on or before PFM\n    #     (-6 to 28 methods 1 & 3, to 56 for method 2)\n    # e - Extra days to add for method 2 (converting Julian\n    #     date to Gregorian date)\n\n    y = year\n    g = y % 19\n    e = 0\n    if method < 3:\n        # Old method\n        i = (19*g+15)%30\n        j = (y+y//4+i)%7\n        if method == 2:\n            # Extra dates to convert Julian to Gregorian date\n            e = 10\n            if y > 1600:\n                e = e+y//100-16-(y//100-16)//4\n    else:\n        # New method\n        c = y//100\n        h = (c-c//4-(8*c+13)//25+19*g+15)%30\n        i = h-(h//28)*(1-(h//28)*(29//(h+1))*((21-g)//11))\n        j = (y+y//4+i+2-c+c//4)%7\n\n    # p can be from -6 to 56 corresponding to dates 22 March to 23 May\n    # (later dates apply to method 2, although 23 May never actually occurs)\n    p = i-j+e\n    d = 1+(p+27+(p+6)//40)%31\n    m = 3+(p+26)//30\n    return datetime.date(int(y), int(m), int(d))", "response": "This method is used to create a new easter base for the given year."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef patch(module, external=(), internal=()):\n    external = tuple(external)\n    internal = tuple(internal)\n\n    def decorator(fn):\n        @wraps(fn)\n        def wrapper(*args, **kwargs):\n            # The master mock is used to contain all of the sub-mocks. It is a\n            # useful container and can also be used to determine the order of\n            # calls to all sub-mocks.\n            master_mock = mock.MagicMock()\n\n            def get_mock(name):\n                return getattr(master_mock, __patch_name(name))\n\n            def patch_external(name):\n                return mock.patch(name, get_mock(name))\n\n            def patch_internal(name):\n                return mock.patch(module.__name__ + '.' + name, get_mock(name))\n\n            try:\n                with __nested(patch_external(n) for n in external):\n                    if external:\n                        # Reload the module to ensure that patched external\n                        # dependencies are accounted for.\n                        reload_module(module)\n\n                    # Patch objects in the module itself.\n                    with __nested(patch_internal(n) for n in internal):\n                        return fn(master_mock, *args, **kwargs)\n            finally:\n                if external:\n                    # When all patches have been discarded, reload the module\n                    # to bring it back to its original state (except for all of\n                    # the references which have been reassigned).\n                    reload_module(module)\n        return wrapper\n    return decorator", "response": "Decorator to monkey - patch the dependencies of a module."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(cls, description=\"\", message=\"\"):\n        instance = cls()\n        instance.revision_id = make_hash_id()\n        instance.release_date = datetime.datetime.now()\n\n        if len(description) > 0:\n            instance.description = description\n\n        if len(message) > 0:\n            instance.message = message\n\n        return instance", "response": "Create a new object of type IKVM\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(self, rev_string):\n        elements = rev_string.split(MESSAGE_LINE_SEPARATOR)\n\n        heading = elements[0]\n\n        heading_elements = heading.split(\" \")\n\n        self.revision_id = heading_elements[2]\n        datetime_str = \"{} {}\".format(\n            heading_elements[0],\n            heading_elements[1]\n        )\n        self.release_date = datetime.datetime.strptime(\n            datetime_str,\n            DATETIME_FORMAT\n        )\n\n        self.description = elements[1]\n        self.message = elements[2]", "response": "Parse the revision string into the object properties."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a string representation of the object.", "response": "def to_markdown(self):\n        \"\"\"\n        :return:\n        :rtype: str\n        \"\"\"\n        return \"## {} {}\\n\\n{}\\n\\n{}\\n\\n\".format(\n            self.release_date.strftime(DATETIME_FORMAT),\n            self.revision_id,\n            self.description,\n            self.message\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking a series of points and interpolate between them at ``test_x``. Args: curve (list[tuple]): A list of ``(x, y)`` points sorted in nondecreasing ``x`` value. If multiple points have the same ``x`` value, all but the last will be ignored. test_x (float): The ``x`` value to find the ``y`` value of Returns: float: The ``y`` value of the curve at ``test_x`` if ``round_result is False`` int: if ``round_result is True`` or the result is a whole number, the ``y`` value of the curve at ``test_x`` rounded to the nearest whole number. Raises: ProbabilityUndefinedError: if ``test_x`` is out of the domain of ``curve`` Example: >>> curve = [(0, 0), (2, 1)] >>> _linear_interp(curve, 0.5) 0.25 >>> _linear_interp(curve, 0.5, round_result=True) 0", "response": "def _linear_interp(curve, test_x, round_result=False):\n    \"\"\"\n    Take a series of points and interpolate between them at ``test_x``.\n\n    Args:\n        curve (list[tuple]): A list of ``(x, y)`` points sorted in\n            nondecreasing ``x`` value. If multiple points have the same\n            ``x`` value, all but the last will be ignored.\n        test_x (float): The ``x`` value to find the ``y`` value of\n\n    Returns:\n        float: The ``y`` value of the curve at ``test_x``\n        if ``round_result is False``\n\n        int: if ``round_result is True`` or the result is a whole number,\n        the ``y`` value of the curve at ``test_x`` rounded to the\n        nearest whole number.\n\n    Raises:\n        ProbabilityUndefinedError: if ``test_x`` is out of the\n            domain of ``curve``\n\n    Example:\n        >>> curve = [(0, 0), (2, 1)]\n        >>> _linear_interp(curve, 0.5)\n        0.25\n        >>> _linear_interp(curve, 0.5, round_result=True)\n        0\n    \"\"\"\n    index = 0\n    for index in range(len(curve) - 1):\n        # Ignore points which share an x value with the following point\n        if curve[index][0] == curve[index + 1][0]:\n            continue\n        if curve[index][0] <= test_x <= curve[index + 1][0]:\n            slope = ((curve[index + 1][1] - curve[index][1]) /\n                     (curve[index + 1][0] - curve[index][0]))\n            y_intercept = curve[index][1] - (slope * curve[index][0])\n            result = (slope * test_x) + y_intercept\n            if round_result:\n                return int(round(result))\n            else:\n                if result.is_integer():\n                    return int(result)\n                else:\n                    return result\n    else:\n        raise ProbabilityUndefinedError"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _clamp_value(value, minimum, maximum):\n    if maximum < minimum:\n        raise ValueError\n    if value < minimum:\n        return minimum\n    elif value > maximum:\n        return maximum\n    else:\n        return value", "response": "Clamp a value to fit between a minimum and a maximum."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the cumulative distribution function of a normal curve.", "response": "def _normal_function(x, mean, variance):\n    \"\"\"\n    Find a value in the cumulative distribution function of a normal curve.\n\n    See https://en.wikipedia.org/wiki/Normal_distribution\n\n    Args:\n        x (float): Value to feed into the normal function\n        mean (float): Mean of the normal function\n        variance (float): Variance of the normal function\n\n    Returns: float\n\n    Example:\n        >>> round(_normal_function(0, 0, 5), 4)\n        0.1784\n    \"\"\"\n    e_power = -1 * (((x - mean) ** 2) / (2 * variance))\n    return (1 / math.sqrt(2 * variance * math.pi)) * (math.e ** e_power)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks whether values is a valid argument for weighted_choice.", "response": "def _is_valid_options_weights_list(value):\n    '''Check whether ``values`` is a valid argument for ``weighted_choice``.'''\n    return ((isinstance(value, list)) and\n            len(value) > 1 and\n            (all(isinstance(opt, tuple) and\n                 len(opt) == 2 and\n                 isinstance(opt[1], (int, float))\n                 for opt in value)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of tuples that are bound to all outcomes within the specified bounds.", "response": "def bound_weights(weights, minimum=None, maximum=None):\n    \"\"\"\n    Bound a weight list so that all outcomes fit within specified bounds.\n\n    The probability distribution within the ``minimum`` and ``maximum``\n    values remains the same. Weights in the list with outcomes outside of\n    ``minimum`` and ``maximum`` are removed.\n    If weights are removed from either end, attach weights at the modified\n    edges at the same weight (y-axis) position they had interpolated in the\n    original list.\n\n    If neither ``minimum`` nor ``maximum`` are set, ``weights`` will be\n    returned unmodified. If both are set, ``minimum`` must be less\n    than ``maximum``.\n\n    Args:\n        weights (list): the list of weights where each weight\n            is a ``tuple`` of form ``(float, float)`` corresponding to\n            ``(outcome, weight)``. Must be sorted in increasing order\n            of outcomes\n        minimum (float): Lowest allowed outcome for the weight list\n        maximum (float): Highest allowed outcome for the weight list\n\n    Returns:\n        list: A list of 2-tuples of form ``(float, float)``,\n        the bounded weight list.\n\n    Raises:\n        ValueError: if ``maximum < minimum``\n\n    Example:\n        >>> weights = [(0, 0), (2, 2), (4, 0)]\n        >>> bound_weights(weights, 1, 3)\n        [(1, 1), (2, 2), (3, 1)]\n    \"\"\"\n    # Copy weights to avoid side-effects\n    bounded_weights = weights[:]\n    # Remove weights outside of minimum and maximum\n    if minimum is not None and maximum is not None:\n        if maximum < minimum:\n            raise ValueError\n        bounded_weights = [bw for bw in bounded_weights\n                           if minimum <= bw[0] <= maximum]\n    elif minimum is not None:\n        bounded_weights = [bw for bw in bounded_weights\n                           if minimum <= bw[0]]\n    elif maximum is not None:\n        bounded_weights = [bw for bw in bounded_weights\n                           if bw[0] <= maximum]\n    else:\n        # Both minimum and maximum are None - the bound list is the same\n        # as the original\n        return bounded_weights\n    # If weights were removed, attach new endpoints where they would have\n    # appeared in the original curve\n    if (bounded_weights[0][0] > weights[0][0] and\n            bounded_weights[0][0] != minimum):\n        bounded_weights.insert(0, (minimum, _linear_interp(weights, minimum)))\n    if (bounded_weights[-1][0] < weights[-1][0] and\n            bounded_weights[-1][0] != maximum):\n        bounded_weights.append((maximum, _linear_interp(weights, maximum)))\n    return bounded_weights"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of weights approximating a normal distribution.", "response": "def normal_distribution(mean, variance,\n                        minimum=None, maximum=None, weight_count=23):\n    \"\"\"\n    Return a list of weights approximating a normal distribution.\n\n    Args:\n        mean (float): The mean of the distribution\n        variance (float): The variance of the distribution\n        minimum (float): The minimum outcome possible to\n            bound the output distribution to\n        maximum (float): The maximum outcome possible to\n            bound the output distribution to\n        weight_count (int): The number of weights that will\n            be used to approximate the distribution\n\n    Returns:\n        list: a list of ``(float, float)`` weight tuples\n        approximating a normal distribution.\n\n    Raises:\n        ValueError: ``if maximum < minimum``\n        TypeError: if both ``minimum`` and ``maximum`` are ``None``\n\n    Example:\n        >>> weights = normal_distribution(10, 3,\n        ...                               minimum=0, maximum=20,\n        ...                               weight_count=5)\n        >>> rounded_weights = [(round(value, 2), round(strength, 2))\n        ...                    for value, strength in weights]\n        >>> rounded_weights\n        [(1.34, 0.0), (4.8, 0.0), (8.27, 0.14), (11.73, 0.14), (15.2, 0.0)]\n    \"\"\"\n    # Pin 0 to +- 5 sigma as bounds, or minimum and maximum\n    # if they cross +/- sigma\n    standard_deviation = math.sqrt(variance)\n    min_x = (standard_deviation * -5) + mean\n    max_x = (standard_deviation * 5) + mean\n    step = (max_x - min_x) / weight_count\n    current_x = min_x\n    weights = []\n    while current_x < max_x:\n        weights.append(\n            (current_x, _normal_function(current_x, mean, variance))\n        )\n        current_x += step\n    if minimum is not None or maximum is not None:\n        return bound_weights(weights, minimum, maximum)\n    else:\n        return weights"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a non - uniform random value based on a list of weight tuples.", "response": "def weighted_rand(weights, round_result=False):\n    \"\"\"\n    Generate a non-uniform random value based on a list of weight tuples.\n\n    Treats weights as coordinates for a probability distribution curve and\n    rolls accordingly. Constructs a piece-wise linear curve according to\n    coordinates given in ``weights`` and rolls random values in the\n    curve's bounding box until a value is found under the curve\n\n    Weight tuples should be of the form: (outcome, strength).\n\n    Args:\n        weights: (list): the list of weights where each weight\n            is a tuple of form ``(float, float)`` corresponding to\n            ``(outcome, strength)``.\n            Weights with strength ``0`` or less will have no chance to be\n            rolled. The list must be sorted in increasing order of outcomes.\n        round_result (bool): Whether or not to round the resulting value\n            to the nearest integer.\n\n    Returns:\n        float: A weighted random number\n\n        int: A weighted random number rounded to the nearest ``int``\n\n    Example:\n        >>> weighted_rand([(-3, 4), (0, 10), (5, 1)])          # doctest: +SKIP\n        -0.650612268193731\n        >>> weighted_rand([(-3, 4), (0, 10), (5, 1)])          # doctest: +SKIP\n        -2\n    \"\"\"\n    # If just one weight is passed, simply return the weight's name\n    if len(weights) == 1:\n        return weights[0][0]\n\n    # Is there a way to do this more efficiently? Maybe even require that\n    # ``weights`` already be sorted?\n    weights = sorted(weights, key=lambda w: w[0])\n\n    x_min = weights[0][0]\n    x_max = weights[-1][0]\n    y_min = 0\n    y_max = max([point[1] for point in weights])\n\n    # Roll random numbers until a valid one is found\n    attempt_count = 0\n    while attempt_count < 500000:\n        # Get sample point\n        sample = (random.uniform(x_min, x_max), random.uniform(y_min, y_max))\n        if _point_under_curve(weights, sample):\n            # The sample point is under the curve\n            if round_result:\n                return int(round(sample[0]))\n            else:\n                return sample[0]\n        attempt_count += 1\n    else:\n        warnings.warn(\n             'Point not being found in weighted_rand() after 500000 '\n             'attempts, defaulting to a random weight point. '\n             'If this happens often, it is probably a bug.')\n        return random.choice(weights)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef weighted_choice(weights, as_index_and_value_tuple=False):\n    if not len(weights):\n        raise ValueError('List passed to weighted_choice() cannot be empty.')\n    # Construct a line segment where each weight outcome is\n    # allotted a length equal to the outcome's weight,\n    # pick a uniformally random point along the line, and take\n    # the outcome that point corresponds to\n    prob_sum = sum(w[1] for w in weights)\n    if prob_sum <= 0:\n        raise ProbabilityUndefinedError(\n            'No item weights in weighted_choice() are greater than 0. '\n            'Probability distribution is undefined.')\n    sample = random.uniform(0, prob_sum)\n    current_pos = 0\n    i = 0\n    while i < len(weights):\n        if current_pos <= sample <= (current_pos + weights[i][1]):\n            if as_index_and_value_tuple:\n                return (i, weights[i][0])\n            else:\n                return weights[i][0]\n        current_pos += weights[i][1]\n        i += 1\n    else:\n        raise AssertionError('Something went wrong in weighted_choice(). '\n                             'Please submit a bug report!')", "response": "Generates a non - uniform random choice based on a list of option tuples."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef weighted_order(weights):\n    if not len(weights):\n        return []\n    if any(w[1] <= 0 for w in weights):\n        raise ProbabilityUndefinedError(\n            'All weight values must be greater than 0.')\n    working_list = weights[:]\n    output_list = []\n    while working_list:\n        picked_item = weighted_choice(working_list,\n                                      as_index_and_value_tuple=True)\n        output_list.append(picked_item[1])\n        del working_list[picked_item[0]]\n    return output_list", "response": "Non - uniformally order a list according to weighted priorities."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tokenize(cls, text, mode='c'):\n        if mode == 'c':\n            return [ch for ch in text]\n        else:\n            return [w for w in text.split()]", "response": "Converts text into tokens\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef karbasa(self, result):\n        probs = result['all_probs']\n        probs.sort()\n        return float(probs[1] - probs[0]) / float(probs[-1] - probs[0])", "response": "Calculates the Karbasa ratio of the distance between 1st and 2nd class and last class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npredicting the Language of a given Unicode text.", "response": "def classify(self, text=u''):\n        \"\"\" Predicts the Language of a given text.\n\n            :param text: Unicode text to be classified.\n        \"\"\"\n        result = self.calculate(doc_terms=self.tokenize(text))\n        #return (result['calc_id'], result)\n        return (result['calc_id'], self.karbasa(result))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetecting links and mentions", "response": "def is_mention_line(cls, word):\n        \"\"\" Detects links and mentions\n\n            :param word: Token to be evaluated\n        \"\"\"\n        if word.startswith('@'):\n            return True\n        elif word.startswith('http://'):\n            return True\n        elif word.startswith('https://'):\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstripping Mentions and Links from a text.", "response": "def strip_mentions_links(self, text):\n        \"\"\" Strips Mentions and Links\n\n            :param text: Text to be stripped from.\n        \"\"\"\n        #print 'Before:', text\n        new_text = [word for word in text.split() if not self.is_mention_line(word)]\n        #print 'After:', u' '.join(new_text)\n        return u' '.join(new_text)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalize(self, text):\n        #print 'Normalize...\\n'\n        text = text.lower()\n        text = unicodedata.normalize('NFC', text)\n        text = self.strip_mentions_links(text)\n        return text", "response": "Normalizes text.\n            Converts to lowercase,\n            Unicode NFC normalization\n            and removes mentions and links\n\n            :param text: Text to be normalized."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_data(self, raw_data):\n        data = json.loads(raw_data)\n\n        message_type = data['meta'].get('type')\n        prepare_method = 'prepare_%s' % (message_type)\n        args = getattr(self, prepare_method, self.prepare_fallback)(data.get('data'))\n\n        method_name = 'on_%s' % (message_type,)\n        func = getattr(self, method_name, self.on_fallback)\n\n        func(*args, meta=StreamingMeta.from_response_data(data.get('meta'), self.api))", "response": "Called when raw data is received from the connection. Return False to stop stream and close connection."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all output files from all of the current module s rules.", "response": "def output_files(self):\n        \"\"\"Returns all output files from all of the current module's rules.\"\"\"\n        for dep in self.subgraph.successors(self.address):\n            dep_rule = self.subgraph.node[dep]['target_obj']\n            for out_file in dep_rule.output_files:\n                yield out_file"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend next request to the server.", "response": "async def write_request(\n        self, method: constants.HttpRequestMethod, *,\n        uri: str=\"/\", authority: Optional[str]=None,\n        scheme: Optional[str]=None,\n        headers: Optional[_HeaderType]=None) -> \\\n            \"writers.HttpRequestWriter\":\n        \"\"\"\n        Send next request to the server.\n        \"\"\"\n        return await self._delegate.write_request(\n            method, uri=uri, authority=authority,\n            scheme=scheme, headers=headers)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns solarzenithangle and sunobs for a given time.", "response": "def solarzenithangle(time: datetime, glat: float, glon: float, alt_m: float) -> tuple:\n    \"\"\"\n    Input:\n\n    t: scalar or array of datetime\n    \"\"\"\n    time = totime(time)\n\n    obs = EarthLocation(lat=glat*u.deg, lon=glon*u.deg, height=alt_m*u.m)\n    times = Time(time, scale='ut1')\n    sun = get_sun(times)\n    sunobs = sun.transform_to(AltAz(obstime=times, location=obs))\n\n    return 90 - sunobs.alt.degree, sun, sunobs"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks the order of the entries in the set of constraints.", "response": "def check_order(self):\n        \"\"\"\n        Performs the check and store the violations in self.violations.\n        :return: boolean indicating the error state\n        \"\"\"\n\n        for feature, info in self.constraints.items():\n            self._check_feature(feature, info, 'before')\n            self._check_feature(feature, info, 'after')\n            self._check_position(feature, info)\n\n        return not self.has_errors()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_feature(self, feature, info, mode):\n\n        op = dict(\n            before=operator.gt,\n            after=operator.lt\n        )[mode]\n\n        feature_pos = self.get_feature_position(feature)\n\n        if feature_pos is not None:\n            # only proceed if the the feature exists in the current feature list\n\n            for other in info.get(mode, []):\n                other_pos = self.get_feature_position(other)\n\n                if other_pos is not None:\n                    # only proceed if the the other feature exists in the current feature list\n                    if op(feature_pos, other_pos):\n                        message = '{feature} (pos {feature_pos}) must be {mode} feature {other} (pos {other_pos}) but isn\\'t.'.format(\n                            feature=feature,\n                            feature_pos=feature_pos,\n                            other=other,\n                            other_pos=other_pos,\n                            mode=mode.upper()\n                        )\n                        self.violations.append((feature, message))", "response": "Private method to check the feature in the current state."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_position(self, feature, info):\n        pos = info.get('position')\n        if pos is not None:\n            feature_pos = self.get_feature_position(feature)\n            if feature_pos is not None:\n                if feature_pos != pos:\n                    message = '{feature} has a forced position on ({pos}) but is on position {feature_pos}.'.format(\n                        feature=feature,\n                        pos=pos,\n                        feature_pos=feature_pos\n                    )\n                    self.violations.append((feature, message))", "response": "Checks if the current position of the given feature is correct."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the dictionary with the correct datums attribute names and data types for the top level of the report and return the nested levels separately.", "response": "def _report(self, action, key_mapper=mappers._report_key_mapper):\n        '''Return the dictionary of **kwargs with the correct datums attribute\n        names and data types for the top level of the report, and return the\n        nested levels separately.\n        '''\n        _top_level = [\n            k for k, v in self.report.items() if not isinstance(v, dict)]\n        _nested_level = [\n            k for k, v in self.report.items() if isinstance(v, dict)]\n        top_level_dict = {}\n        nested_levels_dict = {}\n        for key in _top_level:\n            try:\n                if key == 'date' or key == 'timestamp':\n                    item = mappers._key_type_mapper[key](\n                        str(self.report[key]), **{'ignoretz': True})\n                else:\n                    item = mappers._key_type_mapper[key](str(\n                        self.report[key]) if key != 'draft' else self.report[key])\n            except KeyError:\n                item = self.report[key]\n            finally:\n                try:\n                    top_level_dict[key_mapper[key]] = item\n                except KeyError:\n                    warnings.warn('''\n                        {0} is not currently supported by datums and will be ignored.\n                        Would you consider submitting an issue to add support?\n                        https://www.github.com/thejunglejane/datums/issues\n                        '''.format(key))\n        for key in _nested_level:\n            nested_levels_dict[key] = self.report[key]\n            # Add the parent report ID\n            nested_levels_dict[key][\n                'reportUniqueIdentifier'] = mappers._key_type_mapper[\n                    'uniqueIdentifier'](str(self.report['uniqueIdentifier']))\n            if key == 'placemark':\n                # Add the parent location report UUID\n                nested_levels_dict[key][\n                    'locationUniqueIdentifier'] = nested_levels_dict[key].pop(\n                        'reportUniqueIdentifier')\n            # Create UUID for altitude report if there is not one and the action\n            # is get_or_create, else delete the altitude report from the nested\n            # levels and warn that it will not be updated\n            if 'uniqueIdentifier' not in nested_levels_dict[key]:\n                if action.__func__.func_name == 'get_or_create':\n                    nested_levels_dict[key]['uniqueIdentifier'] = uuid.uuid4()\n                else:\n                    del nested_levels_dict[key]\n                    warnings.warn('''\n                        No uniqueIdentifier found for AltitudeReport in {0}.\n                        Existing altitude report will not be updated.\n                        '''.format(self.report['uniqueIdentifier']))\n        return top_level_dict, nested_levels_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_to_file(path_file, callback):\n        try:\n            with open(path_file, 'r+', encoding='utf-8') as f:\n                content = callback(f.read())\n                f.seek(0)\n                f.write(content)\n                f.truncate()\n        except Exception as e:\n            raise Exception(\n                'unable to minify file %(file)s, exception was %(exception)r' % {\n                    'file': path_file,\n                    'exception': e,\n                }\n            )", "response": "Writes the content of the given file into the callback and writes the result back to the file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck whether two Intervals are disjoint.", "response": "def is_disjoint(self,other):\n        \"\"\"\n        Check whether two Intervals are disjoint.\n\n        :param Interval other: The Interval to check disjointedness with.\n        \"\"\"\n        if self.is_empty() or other.is_empty():\n            return True\n\n        if self.bounds[0] < other.bounds[0]:\n            i1,i2 = self,other\n        elif self.bounds[0] > other.bounds[0]:\n            i2,i1 = self,other\n        else:\n            #coincident lower bounds\n            if self.is_discrete() and not other.included[0]:\n                return True\n            elif other.is_discrete() and not self.included[0]:\n                return True\n            else:\n                return False\n\n        return not i2.bounds[0] in i1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new Interval with the intersection of the two sets.", "response": "def intersection(self,other):\n        \"\"\"\n        Return a new Interval with the intersection of the two intervals,\n        i.e.  all elements that are in both self and other.\n\n        :param Interval other: Interval to intersect with\n        :rtype: Interval\n        \"\"\"\n        if self.bounds[0] < other.bounds[0]:\n            i1,i2 = self,other\n        else:\n            i2,i1 = self,other\n\n        if self.is_disjoint(other):\n            return Interval((1,0),(True,True))\n\n        bounds = [None,None]\n        included = [None,None]\n        #sets are not disjoint, so i2.bounds[0] in i1:\n        bounds[0] = i2.bounds[0]\n        included[0] = i2.included[0]\n\n        if i2.bounds[1] in i1:\n            bounds[1] = i2.bounds[1]\n            included[1] = i2.included[1]\n        else:\n            bounds[1] = i1.bounds[1]\n            included[1] = i1.included[1]\n\n        return Interval(bounds,included)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck whether this interval is empty.", "response": "def is_empty(self):\n        \"\"\"\n        Check whether this interval is empty.\n\n        :rtype: bool\n        \"\"\"\n        if self.bounds[1] < self.bounds[0]:\n            return True\n        if self.bounds[1] == self.bounds[0]:\n            return not (self.included[0] and self.included[1])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_discrete(self):\n        return self.bounds[1] == self.bounds[0] and\\\n               self.included == (True,True)", "response": "Check whether this interval contains exactly one number of entries."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates over all elements of the set.", "response": "def iter_members(self):\n        \"\"\"\n        Iterate over all elements of the set.\n\n        :raises ValueError: if self is a set of everything\n        \"\"\"\n        if not self.is_discrete():\n            raise ValueError(\"non-discrete IntervalSet can not be iterated\")\n        for i in self.ints:\n            yield i.get_point()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef intersection(self,other):\n        res = []\n        for i1 in self.ints:\n            for i2 in other.ints:\n                res.append(i1.intersection(i2))\n\n        return IntervalSet(res)", "response": "Return a new IntervalSet with the intersection of the two sets i. e. all elements that are both in self and other are in self and other."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new set with the difference of the two sets.", "response": "def difference(self,other):\n        \"\"\"\n        Return a new IntervalSet with the difference of the two sets, i.e.\n        all elements that are in self but not in other.\n\n        :param IntervalSet other: Set to subtract\n        :rtype: IntervalSet\n        \"\"\"\n        res = IntervalSet.everything()\n        for j in other.ints:\n            tmp = []\n            for i in self.ints:\n                tmp.extend(i._difference(j))\n            res = res.intersection(IntervalSet(tmp))\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef intersection(self,other):\n        if self.everything:\n            if other.everything:\n                return DiscreteSet()\n            else:\n                return DiscreteSet(other.elements)\n        else:\n            if other.everything:\n                return DiscreteSet(self.elements)\n            else:\n                return DiscreteSet(self.elements.intersection(other.elements))", "response": "Returns a new DiscreteSet with the intersection of the two sets."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new DiscreteSet with the difference of the two sets.", "response": "def difference(self,other):\n        \"\"\"\n        Return a new DiscreteSet with the difference of the two sets, i.e.\n        all elements that are in self but not in other.\n\n        :param DiscreteSet other: Set to subtract\n        :rtype: DiscreteSet\n        :raises ValueError: if self is a set of everything\n        \"\"\"\n        if self.everything:\n            raise ValueError(\"Can not remove from everything\")\n        elif other.everything:\n            return DiscreteSet([])\n        else:\n            return DiscreteSet(self.elements.difference(other.elements))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a new DiscreteSet with the union of the two sets.", "response": "def union(self,other):\n        \"\"\"\n        Return a new DiscreteSet with the union of the two sets, i.e.\n        all elements that are in self or in other.\n\n        :param DiscreteSet other: Set to unite with\n        :rtype: DiscreteSet\n        \"\"\"\n        if self.everything:\n            return self\n        elif other.everything:\n            return other\n        else:\n            return DiscreteSet(self.elements.union(other.elements))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iter_members(self):\n        if self.everything:\n            raise ValueError(\"Can not iterate everything\")\n        for coord in sorted(self.elements):\n            yield coord", "response": "Iterate over all elements of the set."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of tuples of names and values", "response": "def iter_points(self):\n        \"returns a list of tuples of names and values\"\n        if not self.is_discrete():\n            raise ValueError(\"Patch is not discrete\")\n        names = sorted(self.sets.keys())\n        icoords = [self.sets[name].iter_members() for name in names]\n        for coordinates in product(*icoords):\n            yield tuple(zip(names,coordinates))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_form_labels(self, request=None, obj=None, form=None):\n        for form_label in self.custom_form_labels:\n            if form_label.field in form.base_fields:\n                label = form_label.get_form_label(\n                    request=request, obj=obj, model=self.model, form=form\n                )\n                if label:\n                    form.base_fields[form_label.field].label = mark_safe(label)\n        return form", "response": "Updates the form labels of the given object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nopening the wrapped file.", "response": "def open_filezip(file_path, find_str):\n    \"\"\"\n    Open the wrapped file.\n    Read directly from the zip without extracting its content.\n    \"\"\"\n    if zipfile.is_zipfile(file_path):\n        zipf = zipfile.ZipFile(file_path)\n        interesting_files = [f for f in zipf.infolist() if find_str in f]\n\n        for inside_file in interesting_files:\n            yield zipf.open(inside_file)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_filezip(path_to_file, dest_path, target_zipfiles=None):\n\n    target_zipfiles = ['.*'] if target_zipfiles is None else target_zipfiles\n\n    files = []\n    _, ext = os.path.splitext(path_to_file)\n\n    if ext == '.zip':\n        file = open(path_to_file, 'rb')\n        with zipfile.ZipFile(file) as zip_file:\n            regexp = '|'.join(target_zipfiles) if target_zipfiles else '.*'\n            search_regex = re.compile(regexp)\n\n            lista = [m.group() for x in zip_file.namelist()\n                     for m in [search_regex.search(x)] if m]\n\n            for zp_file in lista:\n                try:\n                    zip_file.extract(zp_file, dest_path)\n                    files.append(os.path.join(dest_path, zp_file))\n                except Exception as ex:\n                    msg = 'Fail to extract {} in {} to {} - {}'.format(\n                        zp_file, path_to_file, dest_path, ex)\n                    logger.error(msg)\n        file.close()\n    else:\n        logger.warning('Not zipfile passed in args')\n    return files", "response": "Extract file zip to destiny path folder targeting only some kind of files."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download_file(url, destination, **kwargs):\n    web_file = open_remote_url(url, **kwargs)\n    file_size = 0\n\n    if not web_file:\n        logger.error(\n            \"Remote file not found. Attempted URLs: {}\".format(url))\n        return\n\n    modified = is_remote_file_modified(web_file, destination)\n    if modified:\n        logger.info(\"Downloading: \" + web_file.url)\n        file_size = copy_remote_file(web_file, destination)\n    else:\n        logger.info(\"File up-to-date: \" + destination)\n\n    web_file.close()\n    return file_size", "response": "Download a file from the remote server to the destination folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens the remote url and check that it stores a file.", "response": "def open_remote_url(urls, **kwargs):\n    \"\"\"Open the url and check that it stores a file.\n    Args:\n        :urls: Endpoint to take the file\n    \"\"\"\n    if isinstance(urls, str):\n        urls = [urls]\n    for url in urls:\n        try:\n            web_file = requests.get(url, stream=True, **kwargs)\n            if 'html' in web_file.headers['content-type']:\n                raise ValueError(\"HTML source file retrieved.\")\n            return web_file\n        except Exception as ex:\n            logger.error('Fail to open remote url - {}'.format(ex))\n            continue"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the online file has been modified in the destination path.", "response": "def is_remote_file_modified(web_file, destination):\n    \"\"\"\n    Check if online file has been modified.\n    Args:\n        :web_file: online file to check.\n        :destination: path of the offline file to compare.\n    \"\"\"\n    try:\n        # check datetime of last modified in file.\n        last_mod = web_file.headers.get('last-modified')\n        if last_mod:\n            web_file_time = time.strptime(\n                web_file.headers.get(\n                    'last-modified'), '%a, %d %b %Y %H:%M:%S %Z')\n        else:\n            web_file_time = time.gmtime()\n\n        web_file_size = int(web_file.headers.get('content-length', -1))\n        if os.path.exists(destination):\n            file_time = time.gmtime(os.path.getmtime(destination))\n            file_size = os.path.getsize(destination)\n            if file_time >= web_file_time and file_size == web_file_size:\n                return False\n\n    except Exception as ex:\n        msg = ('Fail checking if remote file is modified default returns TRUE'\n               ' - {}'.format(ex))\n        logger.debug(msg)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncopies online resource to local file.", "response": "def copy_remote_file(web_file, destination):\n    \"\"\"\n    Check if exist the destination path, and copy the online resource\n    file to local.\n\n    Args:\n        :web_file: reference to online file resource to take.\n        :destination: path to store the file.\n    \"\"\"\n    size = 0\n    dir_name = os.path.dirname(destination)\n    if not os.path.exists(dir_name):\n        os.makedirs(dir_name)\n\n    with open(destination, 'wb') as file_:\n        chunk_size = 8 * 1024\n        for chunk in web_file.iter_content(chunk_size=chunk_size):\n            if chunk:\n                file_.write(chunk)\n                size += len(chunk)\n    return size"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_file(paths):\n\n    for path in force_list(paths):\n        if os.path.exists(path):\n            os.remove(path)", "response": "Remove file from paths introduced."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndefining a new Ladder setting and save to disk file", "response": "def addLadder(settings):\n    \"\"\"define a new Ladder setting and save to disk file\"\"\"\n    ladder = Ladder(settings)\n    ladder.save()\n    getKnownLadders()[ladder.name] = ladder\n    return ladder"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nforgetting about a previously defined Ladder setting by deleting its disk file", "response": "def delLadder(name):\n    \"\"\"forget about a previously defined Ladder setting by deleting its disk file\"\"\"\n    ladders = getKnownLadders()\n    try:\n        ladder = ladders[name]\n        os.remove(ladder.filename) # delete from disk\n        del ladders[name] # deallocate object\n        return ladder\n    except KeyError:\n        raise ValueError(\"given ladder name '%s' is not a known ladder definition\"%(name))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getKnownLadders(reset=False):\n    if not ladderCache or reset:\n        jsonFiles = os.path.join(c.LADDER_FOLDER, \"*.json\")\n        for ladderFilepath in glob.glob(jsonFiles):\n            filename = os.path.basename(ladderFilepath)\n            name = re.search(\"^ladder_(.*?).json$\", filename).groups()[0]\n            ladder = Ladder(name)\n            ladderCache[ladder.name] = ladder\n    return ladderCache", "response": "identify all of the currently defined ladders"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the JSON file and validate it.", "response": "def load(cls, json_file_path, schema=None):\n        \"\"\"\n        :param str json_file_path: Path to the JSON file to be read.\n        :param voluptuous.Schema schema: JSON schema.\n        :return: Dictionary storing the parse results of JSON.\n        :rtype: dictionary\n\n        :raises ImportError:\n        :raises InvalidFilePathError:\n        :raises FileNotFoundError:\n        :raises RuntimeError:\n        :raises ValueError:\n        \"\"\"\n\n        gfile.check_file_existence(json_file_path)\n\n        try:\n            if not gfile.FileTypeChecker.is_text_file(json_file_path):\n                raise ValueError(\"not a JSON file\")\n        except ImportError:\n            # magic\u304c\u5fc5\u8981\u3068\u3059\u308b\u30e9\u30a4\u30d6\u30e9\u30ea\u304c\u898b\u3064\u304b\u3089\u306a\u3044 (e.g. Windows\u3067\u306f\u8ffd\u52a0DLL\u304c\u5fc5\u8981)\n            raise\n\n        with open(json_file_path, \"r\") as fp:\n            try:\n                dict_json = json.load(fp)\n            except ValueError:\n                _, e, _ = sys.exc_info()  # for python 2.5 compatibility\n                raise ValueError(os.linesep.join([\n                    str(e),\n                    \"decode error: check JSON format with http://jsonlint.com/\",\n                ]))\n\n        cls.__validate_json(schema, dict_json)\n\n        return dict_json"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a JSON string into a dictionary", "response": "def loads(cls, json_text, schema=None):\n        \"\"\"\n        :param str json_text: json text to be parse\n        :param voluptuous.Schema schema: JSON schema.\n        :return: Dictionary storing the parse results of JSON\n        :rtype: dictionary\n        :raises ImportError:\n        :raises RuntimeError:\n        :raises ValueError:\n        \"\"\"\n\n        try:\n            json_text = json_text.decode(\"ascii\")\n        except AttributeError:\n            pass\n\n        try:\n            dict_json = json.loads(json_text)\n        except ValueError:\n            _, e, _ = sys.exc_info()  # for python 2.5 compatibility\n            raise ValueError(os.linesep.join([\n                str(e),\n                \"decode error: check JSON format with http://jsonlint.com/\",\n            ]))\n\n        cls.__validate_json(schema, dict_json)\n\n        return dict_json"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_samples(self, sample_count):\n        if self.amplitude.value <= 0:\n            return None\n        # Build samples by rolling the period cache through the buffer\n        rolled_array = numpy.roll(self.wave_cache,\n                                  -1 * self.last_played_sample)\n        # Append remaining partial period\n        full_count, remainder = divmod(sample_count, self.cache_length)\n        final_subarray = rolled_array[:int(remainder)]\n        return_array = numpy.concatenate((numpy.tile(rolled_array, full_count),\n                                          final_subarray))\n        # Keep track of where we left off to prevent popping between chunks\n        self.last_played_sample = int(((self.last_played_sample + remainder) %\n                                       self.cache_length))\n        # Multiply output by amplitude\n        return return_array * (self.amplitude.value *\n                               self.amplitude_multiplier)", "response": "Fetch a number of samples from self. wave_cache and return them as ndarray."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _cmp_key(self, obj=None):\n        if not obj:\n            obj = self\n        line_nr = int(obj.line_nr) if obj.line_nr else 0\n        col = int(obj.col) if obj.col else 0\n        return (obj.path, line_nr, col, obj.msg)", "response": "Comparison key for sorting results from all linters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef command_with_options(self):\n        if 'args' in self.config:\n            return ' '.join((self.command, self.config['args']))\n        return self.command", "response": "Add arguments from config to self. command."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the relative path from current path.", "response": "def _get_relative_path(self, full_path):\n        \"\"\"Return the relative path from current path.\"\"\"\n        try:\n            rel_path = Path(full_path).relative_to(Path().absolute())\n        except ValueError:\n            LOG.error(\"%s: Couldn't find relative path of '%s' from '%s'.\",\n                      self.name, full_path, Path().absolute())\n            return full_path\n        return str(rel_path)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmatching pattern line by line and return Result instances.", "response": "def _parse_by_pattern(self, lines, pattern):\n        \"\"\"Match pattern line by line and return Results.\n\n        Use ``_create_output_from_match`` to convert pattern match groups to\n        Result instances.\n\n        Args:\n            lines (iterable): Output lines to be parsed.\n            pattern: Compiled pattern to match against lines.\n            result_fn (function): Receive results of one match and return a\n                Result.\n\n        Return:\n            generator: Result instances.\n        \"\"\"\n        for line in lines:\n            match = pattern.match(line)\n            if match:\n                params = match.groupdict()\n                if not params:\n                    params = match.groups()\n                yield self._create_output_from_match(params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_output_from_match(self, match_result):\n        if isinstance(match_result, dict):\n            return LinterOutput(self.name, **match_result)\n        return LinterOutput(self.name, *match_result)", "response": "Create Result instance from pattern match results."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_single_file_info(self, rel_path):\n\n        f_path = self.get_full_file_path(rel_path)\n        return get_single_file_info(f_path, rel_path)", "response": "Gets the last change time for a single file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the local manifest file or create a new one if there isn t one", "response": "def read_local_manifest(self):\n        \"\"\" Read the file manifest, or create a new one if there isn't one already \"\"\"\n\n        manifest = file_or_default(self.get_full_file_path(self.manifest_file), {\n            'format_version' : 2,\n            'root'           : '/',\n            'have_revision'  : 'root',\n            'files'          : {}}, json.loads)\n\n        if 'format_version' not in manifest or manifest['format_version'] < 2:\n            raise SystemExit('Please update the client manifest format')\n        return manifest"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a file to the FS", "response": "def fs_put(self, rpath, data):\n        \"\"\" Add a file to the FS \"\"\"\n        try:\n            self.begin()\n\n            # Add the file to the fs\n            self.file_put_contents(rpath, data)\n\n            # Add to the manifest\n            manifest = self.read_local_manifest()\n            manifest['files'][rpath] = self.get_single_file_info(rpath)\n            self.write_local_manifest(manifest)\n\n            self.commit()\n        except:\n            self.rollback(); raise"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef respond_to_SIGTERM(signal_number, frame, target=None):\n    if target:\n        target.config.logger.info('detected SIGTERM')\n        # by setting the quit flag to true, any calls to the 'quit_check'\n        # method that is so liberally passed around in this framework will\n        # result in raising the quit exception.  The current quit exception\n        # is KeyboardInterrupt\n        target.task_manager.quit = True\n    else:\n        raise KeyboardInterrupt", "response": "This function is used to instrument a KeyboardInterrupt by the Task Manager class. It is used to instrument a SIGTERM by the Task Manager class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_iterator(self):\n        try:\n            return self.job_param_source_iter(self.config)\n        except TypeError:\n            try:\n                return self.job_param_source_iter()\n            except TypeError:\n                return self.job_param_source_iter", "response": "The iterator passed in can take several forms of class that can be\n        instantiated and then iterated over ; a function that when called\n        returns an iterator or an iterable\n        collection"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _responsive_sleep(self, seconds, wait_log_interval=0, wait_reason=''):\n\n        for x in xrange(int(seconds)):\n            self.quit_check()\n            if wait_log_interval and not x % wait_log_interval:\n                self.logger.info('%s: %dsec of %dsec',\n                                 wait_reason,\n                                 x,\n                                 seconds)\n                self.quit_check()\n            time.sleep(1.0)", "response": "This function is used to sleep for a few seconds."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef blocking_start(self, waiting_func=None):\n        self.logger.debug('threadless start')\n        try:\n            for job_params in self._get_iterator():  # may never raise\n                                                     # StopIteration\n                self.config.logger.debug('received %r', job_params)\n                self.quit_check()\n                if job_params is None:\n                    if self.config.quit_on_empty_queue:\n                        raise KeyboardInterrupt\n                    self.logger.info(\"there is nothing to do.  Sleeping \"\n                                     \"for %d seconds\" %\n                                     self.config.idle_delay)\n                    self._responsive_sleep(self.config.idle_delay)\n                    continue\n                self.quit_check()\n                try:\n                    args, kwargs = job_params\n                except ValueError:\n                    args = job_params\n                    kwargs = {}\n                try:\n                    self.task_func(*args, **kwargs)\n                except Exception:\n                    self.config.logger.error(\"Error in processing a job\",\n                                             exc_info=True)\n        except KeyboardInterrupt:\n            self.logger.debug('queuingThread gets quit request')\n        finally:\n            self.quit = True\n            self.logger.debug(\"ThreadlessTaskManager dies quietly\")", "response": "This function starts the threadless task manager. It is called by the waiting_func function to do tasks while other threads are running."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes partitions with gmane help.", "response": "def makePartitions(self):\n        \"\"\"Make partitions with gmane help.\n        \"\"\"\n        class NetworkMeasures:\n            pass\n        self.nm=nm=NetworkMeasures()\n        nm.degrees=self.network.degree()\n        nm.nodes_= sorted(self.network.nodes(), key=lambda x : nm.degrees[x])\n        nm.degrees_=[nm.degrees[i] for i in nm.nodes_]\n        nm.edges=     self.network.edges(data=True)\n        nm.E=self.network.number_of_edges()\n        nm.N=self.network.number_of_nodes()\n        self.np=g.NetworkPartitioning(nm,10,metric=\"g\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking spiral images in sectors and steps.", "response": "def makeImages(self):\n        \"\"\"Make spiral images in sectors and steps.\n\n        Plain, reversed,\n        sectorialized, negative sectorialized\n        outline, outline reversed, lonely\n        only nodes, only edges, both\n        \"\"\"\n        # make layout\n        self.makeLayout()\n        self.setAgraph()\n        # make function that accepts a mode, a sector\n        # and nodes and edges True and False\n        self.plotGraph()\n        self.plotGraph(\"reversed\",filename=\"tgraphR.png\")\n        agents=n.concatenate(self.np.sectorialized_agents__)\n        for i, sector in enumerate(self.np.sectorialized_agents__):\n            self.plotGraph(\"plain\",   sector,\"sector{:02}.png\".format(i))\n            self.plotGraph(\"reversed\",sector,\"sector{:02}R.png\".format(i))\n            self.plotGraph(\"plain\", n.setdiff1d(agents,sector),\"sector{:02}N.png\".format(i))\n            self.plotGraph(\"reversed\",n.setdiff1d(agents,sector),\"sector{:02}RN.png\".format(i))\n        self.plotGraph(\"plain\",   [],\"BLANK.png\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot the graph with nodes and edges.", "response": "def plotGraph(self,mode=\"plain\",nodes=None,filename=\"tgraph.png\"):\n        \"\"\"Plot graph with nodes (iterable) into filename\n        \"\"\"\n        if nodes==None:\n            nodes=self.nodes\n        else:\n            nodes=[i for i in self.nodes if i in nodes]\n        for node in self.nodes:\n            n_=self.A.get_node(node)\n            if mode==\"plain\":\n                nmode=1\n            else:\n                nmode=-1\n            pos=\"{},{}\".format(self.xi[::nmode][self.nm.nodes_.index(node)],self.yi[::nmode][self.nm.nodes_.index(node)])\n            n_.attr[\"pos\"]=pos\n            n_.attr[\"pin\"]=True\n            color='#%02x%02x%02x' % tuple([255*i for i in self.cm[int(self.clustering[n_]*255)][:-1]])\n            n_.attr['fillcolor']= color\n            n_.attr['fixedsize']=True\n            n_.attr['width']=  abs(.1*(self.nm.degrees[n_]+  .5))\n            n_.attr['height']= abs(.1*(self.nm.degrees[n_]+.5))\n            n_.attr[\"label\"]=\"\"\n            if node not in nodes:\n                n_.attr[\"style\"]=\"invis\"\n            else:\n                n_.attr[\"style\"]=\"filled\"\n        for e in self.edges:\n            e.attr['penwidth']=3.4\n            e.attr[\"arrowsize\"]=1.5\n            e.attr[\"arrowhead\"]=\"lteeoldiamond\"\n            e.attr[\"style\"]=\"\"\n            if sum([i in nodes for i in (e[0],e[1])])==2:\n                e.attr[\"style\"]=\"\"\n            else:\n                e.attr[\"style\"]=\"invis\"\n        tname=\"{}{}\".format(self.basedir,filename)\n        print(tname)\n        self.A.draw(tname,prog=\"neato\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef makeVisualSong(self):\n        self.files=os.listdir(self.basedir)\n        self.stairs=[i for i in self.files if (\"stair\" in i) and (\"R\" in i)]\n        self.sectors=[i for i in self.files if \"sector\" in i]\n        self.stairs.sort()\n        self.sectors.sort()\n        filenames=[self.basedir+i for i in self.sectors[:4]]\n        self.iS0=mpy.ImageSequenceClip(filenames,durations=[1.5,2.5,.5,1.5])\n        self.iS1=mpy.ImageSequenceClip(\n                          [self.basedir+self.sectors[2],\n                           self.basedir+self.sectors[3],\n                           self.basedir+self.sectors[2],\n                           self.basedir+self.sectors[3],\n                           self.basedir+self.sectors[2],\n                           self.basedir+self.sectors[3],\n                           self.basedir+self.sectors[2],\n                           self.basedir+self.sectors[3]],\n                durations=[0.25]*8)\n        self.iS2=mpy.ImageSequenceClip(\n                          [self.basedir+self.sectors[2],\n                           self.basedir+self.sectors[3],\n                           self.basedir+self.sectors[2],\n                           self.basedir+self.sectors[3],\n                           self.basedir+self.sectors[0]],\n                durations=[0.75,0.25,0.75,0.25,2.]) # cai para sens\u00edvel\n\n        self.iS3=mpy.ImageSequenceClip(\n                          [self.basedir+\"BLANK.png\",\n                           self.basedir+self.sectors[0],\n                           self.basedir+self.sectors[1],\n                           self.basedir+self.sectors[1],\n                           self.basedir+self.sectors[1],\n                           self.basedir+self.sectors[0],\n                           self.basedir+self.sectors[0]],\n                durations=[1,0.5,2.,.25,.25,1.75, 0.25]) # [-1,8]\n\n        self.iS4=mpy.ImageSequenceClip(\n                          [self.basedir+self.sectors[2], # 1\n                           self.basedir+self.sectors[3], # .5\n                           self.basedir+self.sectors[5], # .5\n                           self.basedir+self.sectors[2], # .75\n                           self.basedir+self.sectors[0], #.25\n                           self.basedir+self.sectors[2], # 1\n                           self.basedir+self.sectors[0], # 2 8\n                           self.basedir+self.sectors[3], # 2 7\n                           self.basedir+self.sectors[0], # 2 -1\n                          self.basedir+\"BLANK.png\",# 2\n                           ],\n                durations=[1,0.5,0.5,.75,\n                              .25,1., 2.,2.,2.,2.]) # [0,7,11,0]\n\n        self.iS=mpy.concatenate_videoclips((\n            self.iS0,self.iS1,self.iS2,self.iS3,self.iS4))", "response": "Return a sequence of images and durations."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef makeAudibleSong(self):\n        sound0=n.hstack((sy.render(220,d=1.5),\n                        sy.render(220*(2**(7/12)),d=2.5),\n                        sy.render(220*(2**(-5/12)),d=.5),\n                        sy.render(220*(2**(0/12)),d=1.5),\n                        ))\n        sound1=n.hstack((sy.render(220*(2**(0/12)),d=.25),\n                         sy.render(220*(2**(7/12)),d=.25),\n                         sy.render(220*(2**(0/12)),d=.25),\n                         sy.render(220*(2**(7/12)),d=.25),\n                         sy.render(220*(2**(0/12)),d=.25),\n                         sy.render(220*(2**(7/12)),d=.25),\n                         sy.render(220*(2**(0/12)),d=.25),\n                         sy.render(220*(2**(7/12)),d=.25),\n                        ))\n        sound2=n.hstack((sy.render(220*(2**(0/12)),d=.75),\n                         sy.render(220*(2**(0/12)),d=.25),\n                         sy.render(220*(2**(7/12)),d=.75),\n                         sy.render(220*(2**(0/12)),d=.25),\n                         sy.render(220*(2**(-1/12)),d=2.0),\n                       ))\n        sound3=n.hstack((n.zeros(44100),\n                         sy.render(220*(2**(-1/12)),d=.5),\n                         sy.render(220*(2**(8/12)),d=2.),\n                         sy.render(220*(2**(8/12)),d=.25),\n                         sy.render(220*(2**(8/12)),d=.25),\n                         sy.render(220*(2**(-1/12)),d=1.75),\n                         sy.render(220*(2**(-1/12)),d=.25),\n                       ))\n        sound4=n.hstack((\n                         sy.render(220*(2**(0/12)),d=1.),\n                         sy.render(220*(2**(7/12)),d=.5),\n                         sy.render(220*(2**(11/12)),d=.5),\n                         sy.render(220*(2**(12/12)),d=.75),\n                         sy.render(220*(2**(11/12)),d=.25),\n                         sy.render(220*(2**(12/12)),d=1.),\n                         sy.render(220*(2**(8/12)),d=2.),\n                         sy.render(220*(2**(7/12)),d=2.),\n                         sy.render(220*(2**(-1/12)),d=2.),\n                         n.zeros(2*44100)\n                       ))\n\n        sound=n.hstack((sound0,sound1,sound2,sound3,sound4))\n        UT.write(sound,\"sound.wav\")", "response": "Use mass to render wav soundtrack."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef makeAnimation(self):\n        aclip=mpy.AudioFileClip(\"sound.wav\")\n        self.iS=self.iS.set_audio(aclip)\n        self.iS.write_videofile(\"mixedVideo.webm\",15,audio=True)\n        print(\"wrote \"+\"mixedVideo.webm\")", "response": "Use pymovie to render visual + audio + text overlays."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncut off the start and end of a string in the alphabetical order of the input_str.", "response": "def cutoff_filename(prefix, suffix, input_str):\n    \"\"\"\n    Cuts off the start and end of a string, as specified by 2 parameters\n\n    Parameters\n    ----------\n    prefix : string, if input_str starts with prefix, will cut off prefix\n    suffix : string, if input_str end with suffix, will cut off suffix\n    input_str : the string to be processed\n\n    Returns\n    -------\n    A string, from which the start and end have been cut\n    \"\"\"\n    if prefix is not '':\n        if input_str.startswith(prefix):\n            input_str = input_str[len(prefix):]\n    if suffix is not '':\n        if input_str.endswith(suffix):\n            input_str = input_str[:-len(suffix)]\n    return input_str"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a string with the following <src - path >:<src - line > -> <function - name >", "response": "def get_frame_src(f:Frame) -> str:\n    ''' inspects a frame and returns a string with the following\n\n        <src-path>:<src-line> -> <function-name>\n        <source-code>\n    '''\n    path, line, src, fn = _get_frame(\n        inspect.getframeinfo(f)\n    )\n    return '{}:{} -> {}\\n{}'.format(\n        path.split(os.sep)[-1],\n        line,\n        fn,\n        repr(src[0][:-1]) # shave off \\n\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a formatted view of the local variables in a frame", "response": "def get_locals(f:Frame) -> str:\n    ''' returns a formatted view of the local variables in a frame '''\n    return pformat({i:f.f_locals[i] for i in f.f_locals if not i.startswith('__')})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef default_profiler(f:Frame, _type:str, _value:Any):\n    ''' inspects an input frame and pretty prints the following:\n\n        <src-path>:<src-line> -> <function-name>\n        <source-code>\n        <local-variables>\n        ----------------------------------------\n    '''\n    try:\n        profile_print(\n            '\\n'.join([\n                get_frame_src(f),\n                get_locals(f),\n                '----------------------------------------'\n            ])\n        )\n    except:\n        pass", "response": "Prints the source code and local variables of the current module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmove this file to destination folder.", "response": "def on_close(self, filename):\n        \"\"\"Move this file to destination folder.\"\"\"\n        shutil.move(filename, self.destination_folder)\n        path, fn = os.path.split(filename)\n        return os.path.join(self.destination_folder, fn)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getAllRegexp():\n    ''' \n        Method that recovers ALL the list of <RegexpObject> classes to be processed....\n\n        :return:    Returns a list [] of <RegexpObject> classes.\n    '''\n    logger = logging.getLogger(\"entify\")\n\n    logger.debug(\"Recovering all the available <RegexpObject> classes.\")\n    listAll = []\n    # For demo only\n    #listAll.append(Demo())\n    listAll.append(BitcoinAddress())\n    listAll.append(DNI())\n    listAll.append(DogecoinAddress())         \n    listAll.append(Email())\n    listAll.append(IPv4())\n    listAll.append(LitecoinAddress())\n    listAll.append(MD5())\n    listAll.append(NamecoinAddress())\n    listAll.append(PeercoinAddress())\n    listAll.append(SHA1())\n    listAll.append(SHA256())\n    listAll.append(URL())\n    # Add any additional import here\n    #listAll.append(AnyNewRegexp)\n    # <ADD_NEW_REGEXP_TO_THE_LIST>\n    # Please, notify the authors if you have written a new regexp.\n\n    logger.debug(\"Returning a list of \" + str(len(listAll)) + \" <RegexpObject> classes.\")\n    return listAll", "response": "Method that recovers ALL the list of <RegexpObject > classes to be processed..."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getRegexpsByName(regexpNames = ['all']):\n    ''' \n        Method that recovers the names of the <RegexpObject> in a given list.\n\n        :param regexpNames:    list of strings containing the possible regexp.\n\n        :return:    Array of <RegexpObject> classes.\n    '''\n\n    allRegexpList = getAllRegexp()\n    if 'all' in regexpNames:\n        return allRegexpList\n\n    regexpList = []\n    # going through the regexpList \n    for name in regexpNames:\n        for r in allRegexpList:\n            if name == r.name:\n                regexpList.append(r)\n    return regexpList", "response": "Method that recovers the names of the regexp objects in a given list."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new instance of the class from a string containing the CRC public key.", "response": "def from_str(cls: Type[CRCPubkeyType], crc_pubkey: str) -> CRCPubkeyType:\n        \"\"\"\n        Return CRCPubkey instance from CRC public key string\n\n        :param crc_pubkey: CRC public key\n        :return:\n        \"\"\"\n        data = CRCPubkey.re_crc_pubkey.match(crc_pubkey)\n        if data is None:\n            raise Exception(\"Could not parse CRC public key {0}\".format(crc_pubkey))\n        pubkey = data.group(1)\n        crc = data.group(2)\n        return cls(pubkey, crc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns CRCPubkey instance from public key string", "response": "def from_pubkey(cls: Type[CRCPubkeyType], pubkey: str) -> CRCPubkeyType:\n        \"\"\"\n        Return CRCPubkey instance from public key string\n\n        :param pubkey: Public key\n        :return:\n        \"\"\"\n        hash_root = hashlib.sha256()\n        hash_root.update(base58.b58decode(pubkey))\n        hash_squared = hashlib.sha256()\n        hash_squared.update(hash_root.digest())\n        b58_checksum = ensure_str(base58.b58encode(hash_squared.digest()))\n\n        crc = b58_checksum[:3]\n        return cls(pubkey, crc)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if CRC is valid.", "response": "def is_valid(self) -> bool:\n        \"\"\"\n        Return True if CRC is valid\n        :return:\n        \"\"\"\n        return CRCPubkey.from_pubkey(self.pubkey).crc == self.crc"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove the statement from a ProcmailRC structure raise a RuntimeError", "response": "def delete(self):\n        \"\"\"Remove the statement from a ProcmailRC structure, raise a\n        RuntimeError if the statement is not inside a ProcmailRC structure\n        return the parent id\"\"\"\n        if self.parent is None:\n            raise RuntimeError(\n                \"Current statement has no parent, so it cannot \"\n                + \"be deleted form a procmailrc structure\"\n            )\n        elif self.id is None:\n            raise RuntimeError(\"id not set but have a parent, this should not be happening\")\n        else:\n            parent_id = self.parent.id\n            index = int(self.id.split('.')[-1])\n            self.parent.pop(index)\n            self.parent = None\n            self.id = None\n            return parent_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_office365edu_prod_subs(netid):\n    subs = get_netid_subscriptions(netid,\n                                   Subscription.SUBS_CODE_OFFICE_365)\n    if subs is not None:\n        for subscription in subs:\n            if (subscription.subscription_code ==\n                    Subscription.SUBS_CODE_OFFICE_365):\n                return subscription\n    return None", "response": "Returns a restclients. models. uwnetid. Subscription objects\n    on the given uwnetid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the metahash for this genrule cmd.", "response": "def _metahash(self):\n        \"\"\"Include genrule cmd in the metahash.\"\"\"\n        if self._cached_metahash:\n            return self._cached_metahash\n        mhash = base.BaseBuilder._metahash(self)\n        log.debug('[%s]: Metahash input: cmd=\"%s\"', self.address, self.cmd)\n        mhash.update(self.cmd)\n        self._cached_metahash = mhash\n        return mhash"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef expand_cmd_labels(self):\n        cmd = self.cmd\n\n        def _expand_onesrc():\n            \"\"\"Expand $@ or $(@) to one output file.\"\"\"\n            outs = self.rule.params['outs'] or []\n            if len(outs) != 1:\n                raise error.TargetBuildFailed(\n                    self.address,\n                    '$@ substitution requires exactly one output file, but '\n                    'this rule has %s of them: %s' % (len(outs), outs))\n            else:\n                return os.path.join(self.buildroot, self.path_to_this_rule,\n                                    outs[0])\n\n        # TODO: this function is dumb and way too long\n        def _expand_makevar(re_match):\n            \"\"\"Expands one substitution symbol.\"\"\"\n            # Expand $(location foo) and $(locations foo):\n            label = None\n            tagstr = re_match.groups()[0]\n            tag_location = re.match(\n                r'\\s*location\\s+([A-Za-z0-9/\\-_:\\.]+)\\s*', tagstr)\n            tag_locations = re.match(\n                r'\\s*locations\\s+([A-Za-z0-9/\\-_:\\.]+)\\s*', tagstr)\n            if tag_location:\n                label = tag_location.groups()[0]\n            elif tag_locations:\n                label = tag_locations.groups()[0]\n            if label:\n                # Is it a filename found in the outputs of this rule?\n                if label in self.rule.params['outs']:\n                    return os.path.join(self.buildroot, self.address.repo,\n                                        self.address.path, label)\n                # Is it an address found in the deps of this rule?\n                addr = self.rule.makeaddress(label)\n                if addr not in self.rule.composed_deps():\n                    raise error.TargetBuildFailed(\n                        self.address,\n                        '%s is referenced in cmd but is neither an output '\n                        'file from this rule nor a dependency of this rule.' %\n                        label)\n                else:\n                    paths = [x for x in self.rulefor(addr).output_files]\n                    if len(paths) is 0:\n                        raise error.TargetBuildFailed(\n                            self.address,\n                            'cmd refers to %s, but it has no output files.')\n                    elif len(paths) > 1 and tag_location:\n                        raise error.TargetBuildFailed(\n                            self.address,\n                            'Bad substitution in cmd: Expected exactly one '\n                            'file, but %s expands to %s files.' % (\n                                addr, len(paths)))\n                    else:\n                        return ' '.join(\n                            [os.path.join(self.buildroot, x) for x in paths])\n\n            # Expand $(OUTS):\n            elif re.match(r'OUTS', tagstr):\n                return ' '.join(\n                    [os.path.join(self.buildroot, x)\n                     for x in self.rule.output_files])\n\n            # Expand $(SRCS):\n            elif re.match(r'SRCS', tagstr):\n                return ' '.join(os.path.join(self.path_to_this_rule, x)\n                                for x in self.rule.params['srcs'] or [])\n\n            # Expand $(@D):\n            elif re.match(r'\\s*@D\\s*', tagstr):\n                ruledir = os.path.join(self.buildroot, self.path_to_this_rule)\n                return ruledir\n\n            # Expand $(@), $@:\n            elif re.match(r'\\s*@\\s*', tagstr):\n                return _expand_onesrc()\n\n            else:\n                raise error.TargetBuildFailed(\n                    self.address,\n                    '[%s] Unrecognized substitution in cmd: %s' % (\n                        self.address, re_match.group()))\n\n        cmd, _ = re.subn(self.paren_tag_re, _expand_makevar, cmd)\n\n        # Match tags starting with $ without parens. Will also catch parens, so\n        # this goes after the tag_re substitutions.\n        cmd, _ = re.subn(self.noparen_tag_re, _expand_makevar, cmd)\n\n        # Now that we're done looking for $(blabla) and $bla parameters, clean\n        # up any $$ escaping:\n        cmd, _ = re.subn(r'\\$\\$', '$', cmd)\n\n        # Maybe try heuristic label expansion?  Actually on second thought\n        # that's a terrible idea. Use the explicit syntax, you lazy slobs. ;-)\n\n        # TODO: Maybe consider other expansions from the gnu make manual?\n        # $^ might be useful.\n        # http://www.gnu.org/software/make/manual/html_node/Automatic-Variables.html#Automatic-Variables\n        self.cmd = cmd", "response": "Expand make - style variables in cmd parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn list of output files from this rule relative to buildroot.", "response": "def output_files(self):\n        \"\"\"Returns list of output files from this rule, relative to buildroot.\n\n        In this case it's simple (for now) - the output files are enumerated in\n        the rule definition.\n        \"\"\"\n        outs = [os.path.join(self.address.repo, self.address.path, x)\n                for x in self.params['outs']]\n        return outs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the response body and return a dict with the keys top_stories and stories.", "response": "def parse(self, response):\n        '''\n        \u6839\u636e\u5bf9 ``start_urls`` \u4e2d\u63d0\u4f9b\u94fe\u63a5\u7684\u8bf7\u6c42\u54cd\u5e94\u5305\u5185\u5bb9\uff0c\u89e3\u6790\u751f\u6210\u5177\u4f53\u6587\u7ae0\u94fe\u63a5\u8bf7\u6c42\n\n        :param Response response: \u7531 ``Scrapy`` \u8c03\u7528\u5e76\u4f20\u5165\u7684\u8bf7\u6c42\u54cd\u5e94\u5bf9\u8c61\n        '''\n        content_raw = response.body.decode()\n        self.logger.debug('\u54cd\u5e94body\u539f\u59cb\u6570\u636e\uff1a{}'.format(content_raw))\n        content = json.loads(content_raw, encoding='UTF-8')\n        self.logger.debug(content)\n\n        # \u6587\u7ae0\u53d1\u5e03\u65e5\u671f\n        date = datetime.datetime.strptime(content['date'], '%Y%m%d')\n\n        strftime = date.strftime(\"%Y-%m-%d\")\n        self.logger.info('\u65e5\u671f\uff1a{}'.format(strftime))\n\n        # \u5904\u7406\u5934\u6761\u6587\u7ae0\u5217\u8868\uff0c\u5c06\u5176 `top` \u6807\u8bb0\u5230\u76f8\u5e94 __story__ \u4e2d\n        if 'top_stories' in content:\n            self.logger.info('\u5904\u7406\u5934\u6761\u6587\u7ae0')\n            for item in content['top_stories']:\n                for story in content['stories']:\n                    if item['id'] == story['id']:\n                        story['top'] = 1\n                        break\n                self.logger.debug(item)\n\n        # \u5904\u7406\u4eca\u65e5\u6587\u7ae0\uff0c\u5e76\u629b\u51fa\u5177\u4f53\u6587\u7ae0\u8bf7\u6c42\n        post_num = len(content['stories'])\n        self.logger.info('\u5904\u7406\u4eca\u65e5\u6587\u7ae0\uff0c\u5171{:>2}\u7bc7'.format(post_num))\n        for item in content['stories']:\n            self.logger.info(item)\n            post_num = 0 if post_num < 0 else post_num\n            pub_time = date + datetime.timedelta(minutes=post_num)\n            post_num -= 1\n\n            url = 'http://news-at.zhihu.com/api/4/news/{}'.format(item['id'])\n            request = scrapy.Request(url, callback=self.parse_post)\n            post_dict = {\n                'spider': ZhihuDailySpider.name,\n                'date': pub_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n                'meta': {\n                    'spider.zhihu_daily.id': str(item.get('id', ''))\n                }\n            }\n            if item.get('top'):\n                post_dict['meta']['spider.zhihu_daily.top'] = \\\n                    str(item.get('top', 0))\n            request.meta['post'] = post_dict\n            self.item_list.append(post_dict)\n            yield request"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_post(self, response):\n        '''\n        \u6839\u636e :meth:`.ZhihuDailySpider.parse` \u4e2d\u751f\u6210\u7684\u5177\u4f53\u6587\u7ae0\u5730\u5740\uff0c\u83b7\u53d6\u5230\u6587\u7ae0\u5185\u5bb9\uff0c\n        \u5e76\u5bf9\u5176\u8fdb\u884c\u683c\u5f0f\u5316\u5904\u7406\uff0c\u7ed3\u679c\u586b\u5145\u5230\u5bf9\u8c61\u5c5e\u6027 ``item_list`` \u4e2d\n\n        :param Response response: \u7531 ``Scrapy`` \u8c03\u7528\u5e76\u4f20\u5165\u7684\u8bf7\u6c42\u54cd\u5e94\u5bf9\u8c61\n        '''\n        content = json.loads(response.body.decode(), encoding='UTF-8')\n        post = response.meta['post']\n\n        post['origin_url'] = content.get('share_url', '')\n        if not all([post['origin_url']]):\n            raise ValueError('\u539f\u6587\u5730\u5740\u4e3a\u7a7a')\n\n        post['title'] = html.escape(content.get('title', ''))\n        if not all([post['title']]):\n            raise ValueError('\u6587\u7ae0\u6807\u9898\u4e3a\u7a7a - {}'.format(post.get('origin_url')))\n\n        # \u5355\u72ec\u5904\u7406type\u5b57\u6bb5\u4e3a1\u7684\u60c5\u51b5\uff0c\u5373\u8be5\u6587\u7ae0\u4e3a\u7ad9\u5916\u8f6c\u53d1\u6587\u7ae0\n        if content.get('type') == 1:\n            self.logger.warn('\u9047\u5230\u7ad9\u5916\u6587\u7ae0\uff0c\u5355\u72ec\u5904\u7406 - {}'.format(post['title']))\n            return post\n\n        soup = BeautifulSoup(content.get('body', ''), 'lxml')\n        author_obj = soup.select('span.author')\n        self.logger.debug(author_obj)\n        if author_obj:\n            author_list = []\n            for author in author_obj:\n                author_list.append(\n                    author.string.rstrip('\uff0c, ').replace('\uff0c', ','))\n            author_list = list(set(author_list))\n            post['author'] = html.escape('\uff0c'.join(author_list))\n        post['content'] = str(soup.div)\n\n        # \u7ee7\u7eed\u586b\u5145post\u6570\u636e\n        image_back = content.get('images', [None])[0]\n        if image_back:\n            post['meta']['moear.cover_image_slug'] = \\\n                content.get('image', image_back)\n        self.logger.debug(post)", "response": "\u6839\u636e :meth:`.ZhihuDailySpider.parse` \u4e2d\u751f\u6210\u7684\u5177\u4f53\u6587\u7ae0\u5730\u5740\uff0c\u83b7\u53d6\u5230\u6587\u7ae0\u5185\u5bb9\uff0c\n        \u5e76\u5bf9\u5176\u8fdb\u884c\u683c\u5f0f\u5316\u5904\u7406\uff0c\u7ed3\u679c\u586b\u5145\u5230\u5bf9\u8c61\u5c5e\u6027 ``item_list`` \u4e2d\n\n        :param Response response: \u7531 ``Scrapy`` \u8c03\u7528\u5e76\u4f20\u5165\u7684\u8bf7\u6c42\u54cd\u5e94\u5bf9\u8c61"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall when the object is closed.", "response": "def closed(self, reason):\n        '''\n        \u5f02\u6b65\u722c\u53d6\u5168\u90e8\u7ed3\u675f\u540e\uff0c\u6267\u884c\u6b64\u5173\u95ed\u65b9\u6cd5\uff0c\u5bf9 ``item_list`` \u4e2d\u7684\u6570\u636e\u8fdb\u884c **JSON**\n        \u5e8f\u5217\u5316\uff0c\u5e76\u8f93\u51fa\u5230\u6307\u5b9a\u6587\u4ef6\u4e2d\uff0c\u4f20\u9012\u7ed9 :meth:`.ZhihuDaily.crawl`\n\n        :param obj reason: \u722c\u866b\u5173\u95ed\u539f\u56e0\n        '''\n        self.logger.debug('\u7ed3\u679c\u5217\u8868: {}'.format(self.item_list))\n\n        output_strings = json.dumps(self.item_list, ensure_ascii=False)\n        with open(self.output_file, 'w') as fh:\n            fh.write(output_strings)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the current branch name", "response": "def get_current_branch(self) -> str:\n        \"\"\"\n        :return: current branch\n        :rtype: str\n        \"\"\"\n        current_branch: str = self.repo.active_branch.name\n        LOGGER.debug('current branch: %s', current_branch)\n        return current_branch"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tag(self, tag: str, overwrite: bool = False) -> None:\n        LOGGER.info('tagging repo: %s', tag)\n        try:\n            self.repo.create_tag(tag)\n        except GitCommandError as exc:\n            if 'already exists' in exc.stderr and overwrite:\n                LOGGER.info('overwriting existing tag')\n                self.remove_tag(tag)\n                self.repo.create_tag(tag)\n            else:\n                LOGGER.exception('error while tagging repo')\n                raise", "response": "Tags the current commit with the given tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_tags(self, pattern: str = None) -> typing.List[str]:\n        tags: typing.List[str] = [str(tag) for tag in self.repo.tags]\n        if not pattern:\n            LOGGER.debug('tags found in repo: %s', tags)\n            return tags\n\n        LOGGER.debug('filtering tags with pattern: %s', pattern)\n        filtered_tags: typing.List[str] = [tag for tag in tags if pattern in tag]\n        LOGGER.debug('filtered tags: %s', filtered_tags)\n        return filtered_tags", "response": "Returns list of tags optionally matching pattern"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves the specified tag from the rpo repository.", "response": "def remove_tag(self, *tag: str):\n        \"\"\"\n        Removes tag(s) from the rpo\n\n        :param tag: tags to remove\n        :type tag: tuple\n        \"\"\"\n        LOGGER.info('removing tag(s) from repo: %s', tag)\n\n        self.repo.delete_tag(*tag)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_on_tag(self) -> bool:\n        if self.get_current_tag():\n            LOGGER.debug('latest commit is tagged')\n            return True\n\n        LOGGER.debug('latest commit is NOT tagged')\n        return False", "response": "Returns True if the latest commit is tagged False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_current_tag(self) -> typing.Optional[str]:\n        tags = list(self.repo.tags)\n        if not tags:\n            LOGGER.debug('no tag found')\n            return None\n        for tag in tags:\n            LOGGER.debug('tag found: %s; comparing with commit', tag)\n            if tag.commit == self.latest_commit():\n                tag_name: str = tag.name\n                LOGGER.debug('found tag on commit: %s', tag_name)\n                return tag_name\n\n        LOGGER.debug('no tag found on latest commit')\n        return None", "response": "Returns the name of the current tag on the latest commit."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstashes the current working tree changes with the given name.", "response": "def stash(self, stash_name: str):\n        \"\"\"\n        Stashes the current working tree changes\n\n        :param stash_name: name of the stash\n        :type stash_name: str\n        \"\"\"\n        if self.stashed:\n            LOGGER.error('already stashed')\n            sys.exit(-1)\n        else:\n            if not self.index_is_empty():\n                LOGGER.error('cannot stash; index is not empty')\n                sys.exit(-1)\n            if self.untracked_files():\n                LOGGER.error('cannot stash; there are untracked files')\n                sys.exit(-1)\n            if self.changed_files():\n                LOGGER.info('stashing changes')\n                self.repo.git.stash('push', '-u', '-k', '-m', f'\"{stash_name}\"')\n                self.stashed = True\n            else:\n                LOGGER.info('no changes to stash')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npop the last stash if EPAB made a stash before the current one", "response": "def unstash(self):\n        \"\"\"\n        Pops the last stash if EPAB made a stash before\n        \"\"\"\n        if not self.stashed:\n            LOGGER.error('no stash')\n        else:\n            LOGGER.info('popping stash')\n            self.repo.git.stash('pop')\n            self.stashed = False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ensure():\n        LOGGER.debug('checking repository')\n        if not os.path.exists('.git'):\n            LOGGER.error('This command is meant to be ran in a Git repository.')\n            sys.exit(-1)\n        LOGGER.debug('repository OK')", "response": "Ensures that the current working directory is a Git repository."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef last_commit_msg(self) -> str:\n        last_msg: str = self.latest_commit().message.rstrip()\n        LOGGER.debug('last msg: %s', last_msg)\n        return last_msg", "response": "Return the last commit message"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of untracked files.", "response": "def untracked_files(self) -> typing.List[str]:\n        \"\"\"\n        :return: of untracked files\n        :rtype: list\n        \"\"\"\n        untracked_files = list(self.repo.untracked_files)\n        LOGGER.debug('untracked files: %s', untracked_files)\n        return untracked_files"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef status(self) -> str:\n        status: str = self.repo.git.status()\n        LOGGER.debug('git status: %s', status)\n        return status", "response": "Return the current status of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_staged_files(self) -> typing.List[str]:\n        staged_files: typing.List[str] = [x.a_path for x in self.repo.index.diff('HEAD')]\n        LOGGER.debug('staged files: %s', staged_files)\n        return staged_files", "response": "Returns a list of all the staged files in the repository."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef index_is_empty(self) -> bool:\n        index_empty: bool = len(self.repo.index.diff(self.repo.head.commit)) == 0\n        LOGGER.debug('index is empty: %s', index_empty)\n        return index_empty", "response": "Return True if index is empty."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of changed files in the repository.", "response": "def changed_files(self) -> typing.List[str]:\n        \"\"\"\n        :return: changed files\n        :rtype: list of str\n        \"\"\"\n        changed_files: typing.List[str] = [x.a_path for x in self.repo.index.diff(None)]\n        LOGGER.debug('changed files: %s', changed_files)\n        return changed_files"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stage_all(self):\n        LOGGER.info('Staging all files')\n        self.repo.git.add(A=True)", "response": "Stage all files in the repository"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stage_modified(self):\n        LOGGER.info('Staging modified files')\n        self.repo.git.add(u=True)", "response": "Stages modified files only"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstaging a subset of files in the current repository.", "response": "def stage_subset(self, *files_to_add: str):\n        \"\"\"\n        Stages a subset of files\n\n        :param files_to_add: files to stage\n        :type files_to_add: str\n        \"\"\"\n        LOGGER.info('staging files: %s', files_to_add)\n        self.repo.git.add(*files_to_add, A=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_skip_ci_to_commit_msg(message: str) -> str:\n        first_line_index = message.find('\\n')\n        if first_line_index == -1:\n            edited_message = message + ' [skip ci]'\n        else:\n            edited_message = message[:first_line_index] + ' [skip ci]' + message[first_line_index:]\n        LOGGER.debug('edited commit message: %s', edited_message)\n        return edited_message", "response": "Adds a [ skip ci ] tag to the end of a commit message."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef commit(\n            self,\n            message: str,\n            files_to_add: typing.Optional[typing.Union[typing.List[str], str]] = None,\n            allow_empty: bool = False,\n    ):\n        \"\"\"\n        Commits changes to the repo\n\n        :param message: first line of the message\n        :type message: str\n        :param files_to_add: files to commit\n        :type files_to_add: optional list of str\n        :param allow_empty: allow dummy commit\n        :type allow_empty: bool\n        \"\"\"\n        message = str(message)\n        LOGGER.debug('message: %s', message)\n\n        files_to_add = self._sanitize_files_to_add(files_to_add)\n        LOGGER.debug('files to add: %s', files_to_add)\n\n        if not message:\n            LOGGER.error('empty commit message')\n            sys.exit(-1)\n\n        if os.getenv('APPVEYOR'):\n            LOGGER.info('committing on AV, adding skip_ci tag')\n            message = self.add_skip_ci_to_commit_msg(message)\n\n        if files_to_add is None:\n            self.stage_all()\n        else:\n            self.reset_index()\n            self.stage_subset(*files_to_add)\n\n        if self.index_is_empty() and not allow_empty:\n            LOGGER.error('empty commit')\n            sys.exit(-1)\n\n        self.repo.index.commit(message=message)", "response": "Commits changes to the repo."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef amend_commit(\n            self,\n            append_to_msg: typing.Optional[str] = None,\n            new_message: typing.Optional[str] = None,\n            files_to_add: typing.Optional[typing.Union[typing.List[str], str]] = None,\n    ):\n        \"\"\"\n        Amends last commit with either an entirely new commit message, or an edited version of the previous one\n\n        Note: it is an error to provide both \"append_to_msg\" and \"new_message\"\n\n        :param append_to_msg: message to append to previous commit message\n        :type append_to_msg: str\n        :param new_message: new commit message\n        :type new_message: str\n        :param files_to_add: optional list of files to add to this commit\n        :type files_to_add: str or list of str\n        \"\"\"\n\n        if new_message and append_to_msg:\n            LOGGER.error('Cannot use \"new_message\" and \"append_to_msg\" together')\n            sys.exit(-1)\n\n        files_to_add = self._sanitize_files_to_add(files_to_add)\n\n        message = self._sanitize_amend_commit_message(append_to_msg, new_message)\n\n        if os.getenv('APPVEYOR'):\n            message = f'{message} [skip ci]'\n\n        LOGGER.info('amending commit with new message: %s', message)\n        latest_tag = self.get_current_tag()\n\n        if latest_tag:\n            LOGGER.info('removing tag: %s', latest_tag)\n            self.remove_tag(latest_tag)\n\n        LOGGER.info('going back one commit')\n        branch = self.repo.head.reference\n        try:\n            branch.commit = self.repo.head.commit.parents[0]\n        except IndexError:\n            LOGGER.error('cannot amend the first commit')\n            sys.exit(-1)\n        if files_to_add:\n            self.stage_subset(*files_to_add)\n        else:\n            self.stage_all()\n        self.repo.index.commit(message, skip_hooks=True)\n        if latest_tag:\n            LOGGER.info('resetting tag: %s', latest_tag)\n            self.tag(latest_tag)", "response": "Amends the current branch with a new message."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge(self, ref_name: str):\n        if self.is_dirty():\n            LOGGER.error('repository is dirty; cannot merge: %s', ref_name)\n            sys.exit(-1)\n        LOGGER.info('merging ref: \"%s\" into branch: %s', ref_name, self.get_current_branch())\n        self.repo.git.merge(ref_name)", "response": "Merges two refs into the current branch"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef push(self, set_upstream: bool = True):\n        LOGGER.info('pushing repo to origin')\n\n        try:\n            self.repo.git.push()\n        except GitCommandError as error:\n            if 'has no upstream branch' in error.stderr and set_upstream:\n                self.repo.git.push(f'--set-upstream origin {self.get_current_branch()}')\n            else:\n                raise\n        self.push_tags()", "response": "Pushes all refs to origin"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_branches(self) -> typing.List[str]:\n        branches: typing.List[str] = [head.name for head in self.repo.heads]\n        LOGGER.debug('branches: %s', branches)\n        return branches", "response": "List the branches of the current repository."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the SHA of the latest commit", "response": "def get_sha(self) -> str:\n        \"\"\"\n        :return: SHA of the latest commit\n        :rtype: str\n        \"\"\"\n        current_sha: str = self.repo.head.commit.hexsha\n        LOGGER.debug('current commit SHA: %s', current_sha)\n        return current_sha"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_short_sha(self) -> str:\n        short_sha: str = self.get_sha()[:7]\n        LOGGER.debug('short SHA: %s', short_sha)\n        return short_sha", "response": "Returns the short SHA of the latest commit"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef checkout(self, reference: str):\n        LOGGER.info('checking out: %s', reference)\n        if not self.index_is_empty():\n            LOGGER.error('index contains change; cannot checkout. Status:\\n %s', self.status())\n            sys.exit(-1)\n        if self.is_dirty(untracked=True):\n            LOGGER.error('repository is dirty; cannot checkout \"%s\"', reference)\n            LOGGER.error('repository is dirty; cannot checkout. Status:\\n %s', self.status())\n            sys.exit(-1)\n\n        LOGGER.debug('going through all present references')\n        for head in self.repo.heads:\n            if head.name == reference:\n                LOGGER.debug('resetting repo index and working tree to: %s', reference)\n                self.repo.head.reference = head\n                self.repo.head.reset(index=True, working_tree=True)\n                break\n        else:\n            LOGGER.error('reference not found: %s', reference)\n            sys.exit(-1)", "response": "Checks out a reference."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new branch in the repository.", "response": "def create_branch(self, branch_name: str):\n        \"\"\"\n        Creates a new branch\n\n        Args:\n            branch_name: name of the branch\n\n        \"\"\"\n        LOGGER.info('creating branch: %s', branch_name)\n        self._validate_branch_name(branch_name)\n        if branch_name in self.list_branches():\n            LOGGER.error('branch already exists')\n            sys.exit(-1)\n        new_branch = self.repo.create_head(branch_name)\n        new_branch.commit = self.repo.head.commit"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new branch if it doesn t exist and checkouts it.", "response": "def create_branch_and_checkout(self, branch_name: str):\n        \"\"\"\n        Creates a new branch if it doesn't exist\n\n        Args:\n            branch_name: branch name\n        \"\"\"\n        self.create_branch(branch_name)\n        self.checkout(branch_name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the current repository contains uncommitted or untracked changes", "response": "def is_dirty(self, untracked=False) -> bool:\n        \"\"\"\n        Checks if the current repository contains uncommitted or untracked changes\n\n        Returns: true if the repository is clean\n        \"\"\"\n        result = False\n        if not self.index_is_empty():\n            LOGGER.error('index is not empty')\n            result = True\n        changed_files = self.changed_files()\n        if bool(changed_files):\n\n            LOGGER.error(f'Repo has %s modified files: %s', len(changed_files), changed_files)\n            result = True\n        if untracked:\n            result = result or bool(self.untracked_files())\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef startswith(text, ignore_case=True):\n        if ignore_case:\n            compiled = re.compile(\n                \"^%s\" % text.replace(\"\\\\\", \"\\\\\\\\\"), re.IGNORECASE)\n        else:  # pragma: no cover\n            compiled = re.compile(\"^%s\" % text.replace(\"\\\\\", \"\\\\\\\\\"))\n\n        return {\"$regex\": compiled}", "response": "Test if a string - field start with text."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fulltext(search, lang=Lang.English, ignore_case=True):\n        return {\n            \"$text\": {\n                \"$search\": search,\n                \"$language\": lang,\n                \"$caseSensitive\": not ignore_case,\n                \"$diacriticSensitive\": False,\n            }\n        }", "response": "Full text search.\n\n        Example::\n\n            filters = Text.fulltext(\"python pymongo_mate\")\n\n        .. note::\n\n            This field doesn't need to specify field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding all document near a point.", "response": "def near(lat, lng, max_dist=None, unit_miles=False):\n        \"\"\"Find document near a point.\n\n        For example:: find all document with in 25 miles radius from 32.0, -73.0.\n        \"\"\"\n        filters = {\n            \"$nearSphere\": {\n                \"$geometry\": {\n                    \"type\": \"Point\",\n                    \"coordinates\": [lng, lat],\n                }\n            }\n        }\n        if max_dist:\n            if unit_miles:  # pragma: no cover\n                max_dist = max_dist / 1609.344\n            filters[\"$nearSphere\"][\"$maxDistance\"] = max_dist\n        return filters"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_file(self,fName,content) :\n        if not self.isdir() : raise Exception(\"FSQuery tried to add a file in a node which is not a directory : %s\" % self.abs)\n        self.write_file(\"%s/%s\"%(self.abs,fName),content)", "response": "Add a file to the node"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nopening the file for reading and return the file handle", "response": "def open_file(self) :\n        \"\"\"If this FSNode is a file, open it for reading and return the file handle\"\"\"\n        if self.isdir() : raise Exception(\"FSQuery tried to open a directory as a file : %s\" % self.abs)\n        return open(self.abs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking a directory with this name.", "response": "def mk_dir(self) :\n        \"\"\"If this FSNode doesn't currently exist, then make a directory with this name.\"\"\"\n        if not os.path.exists(self.abs) :\n            os.makedirs(self.abs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nnoting this is a filtered walk", "response": "def walk(self,depth=0,fsNode=None) :\n        \"\"\"Note, this is a filtered walk\"\"\"\n        if not fsNode :\n            fsNode = FSNode(self.init_path,self.init_path,0)\n            \n        if fsNode.isdir() :\n            if self.check_dir(fsNode) :\n                if self.check_return(fsNode) :\n                    yield fsNode                \n                for n in fsNode.children() :\n                    if n.islink() :\n                        # currently we don't follow links\n                        continue\n                    for n2 in self.walk(depth+1,n) :\n                        if self.check_return(n2) :\n                            yield n2\n        else :\n            if self.check_file(fsNode) :\n                if self.check_return(fsNode) :\n                    yield fsNode\n        raise StopIteration"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef shadow(self,new_root,visitor) :\n        for n in self.walk() :\n            sn = n.clone(new_root)\n            if n.isdir() :\n                visitor.process_dir(n,sn)\n            else :\n                visitor.process_file(n,sn)", "response": "Runs through the query and applies process"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmatching dirs that have a child that matches filter f", "response": "def DirContains(self,f) :\n        \"\"\" Matches dirs that have a child that matches filter f\"\"\"\n        def match(fsNode) :\n            if not fsNode.isdir() : return False \n            for c in fsNode.children() :\n                if f(c) : return True\n            return False\n        return self.make_return(match)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister a peer according to its description", "response": "def register(self, peer):\n        \"\"\"\n        Registers a peer according to its description\n\n        :param peer: A Peer description bean\n        :raise KeyError:\n        \"\"\"\n        assert isinstance(peer, beans.Peer)\n\n        with self.__lock:\n            # Check presence\n            peer_id = peer.peer_id\n            if peer_id in self.peers:\n                raise KeyError(\"Already known peer: {0}\".format(peer))\n\n            # Store the description\n            self.peers[peer_id] = peer\n\n            # Store in the groups\n            for name in peer.groups:\n                self.groups.setdefault(name, set()).add(peer_id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reduce_contexts(parent, local):\n\n  \"\"\"Combine two test contexts into one.\n  For value types of dict and list, the new context will aggregate the parent\n  and local contexts. For other types, the value of the local context will\n  replace the value of the parent (if any).\"\"\"\n\n  context = {}\n\n  for k,v in parent.items():\n    if type(v) == dict:\n      d = v.copy()\n      d.update(local.get(k,{}))\n      context[k] = d\n    elif type(v) == list:\n      context[k] = v + ensure_list(local.get(k,[]))\n    else:\n      context[k] = local.get(k,v)\n\n  for k in set(local.keys()) - set(parent.keys()):\n    context[k] = local[k]\n\n  return context", "response": "Combine two test contexts into one."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresolves the contents of a module definition. The result is a list of program chunks.", "response": "def resolve_module(module, definitions):\n  \"\"\"Resolve (through indirections) the program contents of a module definition.\n  The result is a list of program chunks.\"\"\"\n\n  assert module in definitions, \"No definition for module '%s'\" % module\n  \n  d = definitions[module]\n  if type(d) == dict:\n    if 'filename' in d:\n      with open(d['filename']) as f:\n        return [f.read().strip()]\n    elif 'reference' in d:\n      return resolve_module(d['reference'], definitions)\n    elif 'group' in d:\n      return sum([resolve_module(m,definitions) for m in d['group']],[])\n    else:\n      assert False\n  else:\n    assert type(d) == str\n    return [d]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef canonicalize_spec(spec, parent_context):\n\n  test_specs = {k:v for (k,v) in spec.items() if k.startswith(\"Test\")}\n  local_context = {k:v for (k,v) in spec.items() if not k.startswith(\"Test\")}\n\n  context = reduce_contexts(parent_context, local_context)\n\n  if test_specs:\n    return {k: canonicalize_spec(v, context) for (k,v) in test_specs.items()}\n  else:\n    program_chunks = sum([resolve_module(m,context['Definitions']) for m in context['Modules']],[]) + [context['Program']]\n    test_spec = {\n      'Arguments': context['Arguments'],\n      'Program': \"\\n\".join(program_chunks),\n      'Expect': context['Expect'],\n    }\n    return test_spec", "response": "Push all context declarations to the leaves of a nested test specification."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef flatten_spec(spec, prefix,joiner=\" :: \"):\n\n  if any(filter(operator.methodcaller(\"startswith\",\"Test\"),spec.keys())):\n    flat_spec = {}\n    for (k,v) in spec.items():\n      flat_spec.update(flatten_spec(v,prefix + joiner + k[5:]))\n    return flat_spec \n  else:\n    return {\"Test \"+prefix: spec}", "response": "Flatten a canonical specification with nesting into one without nesting."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_stanzas(stanzas_file):\n    f = stanzas_file.readlines()\n    stanzas = []\n    for i, line in enumerate(f):\n        if i % 4 == 0:\n            stanza_words = line.strip().split()[1:]\n            stanzas.append(Stanza(stanza_words))\n    return stanzas", "response": "Load stanzas from gold standard file"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets an iterable of all final words in all stanzas", "response": "def get_wordlist(stanzas):\n    \"\"\"\n    Get an iterable of all final words in all stanzas\n    \"\"\"\n    return sorted(list(set().union(*[stanza.words for stanza in stanzas])))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_rhymelists(stanza, scheme):\n    rhymelists = defaultdict(list)\n    for rhyme_group, word_index in zip(scheme, stanza.word_indices):\n        rhymelists[rhyme_group].append(word_index)\n    return list(rhymelists.values())", "response": "Returns ordered lists of the stanza s word indices as defined by given scheme"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing pair - wise rhyme strenghts according to the given word distance function.", "response": "def init_distance_ttable(wordlist, distance_function):\n    \"\"\"\n    Initialize pair-wise rhyme strenghts according to the given word distance function\n    \"\"\"\n    n = len(wordlist)\n    t_table = numpy.zeros((n, n + 1))\n\n    # Initialize P(c|r) accordingly\n    for r, w in enumerate(wordlist):\n        for c, v in enumerate(wordlist):\n            if c < r:\n                t_table[r, c] = t_table[c, r]  # Similarity is symmetric\n            else:\n                t_table[r, c] = distance_function(w, v) + 0.001  # For backoff\n    t_table[:, n] = numpy.mean(t_table[:, :-1], axis=1)\n\n    # Normalize\n    t_totals = numpy.sum(t_table, axis=0)\n    for i, t_total in enumerate(t_totals.tolist()):\n        t_table[:, i] /= t_total\n    return t_table"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninitializes a uniformly - sized ttable from a list of words.", "response": "def init_uniform_ttable(wordlist):\n    \"\"\"\n    Initialize (normalized) theta uniformly\n    \"\"\"\n    n = len(wordlist)\n    return numpy.ones((n, n + 1)) * (1 / n)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing posterior probability of a scheme for a stanza", "response": "def post_prob_scheme(t_table, stanza, scheme):\n    \"\"\"\n    Compute posterior probability of a scheme for a stanza, with probability of every word in rhymelist\n    rhyming with all the ones before it\n    \"\"\"\n    myprob = 1\n    rhymelists = get_rhymelists(stanza, scheme)\n    for rhymelist in rhymelists:\n        for i, word_index in enumerate(rhymelist):\n            if i == 0:  # first word, use P(w|x)\n                myprob *= t_table[word_index, -1]\n            else:\n                for word_index2 in rhymelist[:i]:  # history\n                    myprob *= t_table[word_index, word_index2]\n    if myprob == 0 and len(stanza) > 30:  # probably underflow\n        myprob = 1e-300\n    return myprob"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef expectation_step(t_table, stanzas, schemes, rprobs):\n    probs = numpy.zeros((len(stanzas), schemes.num_schemes))\n    for i, stanza in enumerate(stanzas):\n        scheme_indices = schemes.get_schemes_for_len(len(stanza))\n        for scheme_index in scheme_indices:\n            scheme = schemes.scheme_list[scheme_index]\n            probs[i, scheme_index] = post_prob_scheme(t_table, stanza, scheme)\n    probs = numpy.dot(probs, numpy.diag(rprobs))\n\n    # Normalize\n    scheme_sums = numpy.sum(probs, axis=1)\n    for i, scheme_sum in enumerate(scheme_sums.tolist()):\n        if scheme_sum > 0:\n            probs[i, :] /= scheme_sum\n    return probs", "response": "Compute posterior probability of schemes for each stanza\nracket"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef maximization_step(num_words, stanzas, schemes, probs):\n    t_table = numpy.zeros((num_words, num_words + 1))\n    rprobs = numpy.ones(schemes.num_schemes)\n    for i, stanza in enumerate(stanzas):\n        scheme_indices = schemes.get_schemes_for_len(len(stanza))\n        for scheme_index in scheme_indices:\n            myprob = probs[i, scheme_index]\n            rprobs[scheme_index] += myprob\n            scheme = schemes.scheme_list[scheme_index]\n            rhymelists = get_rhymelists(stanza, scheme)\n            for rhymelist in rhymelists:\n                for j, word_index in enumerate(rhymelist):\n                    t_table[word_index, -1] += myprob\n                    for word_index2 in rhymelist[:j] + rhymelist[j + 1:]:\n                        t_table[word_index, word_index2] += myprob\n\n    # Normalize t_table\n    t_table_sums = numpy.sum(t_table, axis=0)\n    for i, t_table_sum in enumerate(t_table_sums.tolist()):\n        if t_table_sum != 0:\n            t_table[:, i] /= t_table_sum\n\n    # Normalize rprobs\n    totrprob = numpy.sum(rprobs)\n    rprobs /= totrprob\n\n    return t_table, rprobs", "response": "Maximization step for the model."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates EM and return final probabilities", "response": "def iterate(t_table, wordlist, stanzas, schemes, rprobs, maxsteps):\n    \"\"\"\n    Iterate EM and return final probabilities\n    \"\"\"\n    data_probs = numpy.zeros(len(stanzas))\n    old_data_probs = None\n    probs = None\n    num_words = len(wordlist)\n\n    ctr = 0\n    for ctr in range(maxsteps):\n        logging.info(\"Iteration {}\".format(ctr))\n        old_data_probs = data_probs\n\n        logging.info(\"Expectation step\")\n        probs = expectation_step(t_table, stanzas, schemes, rprobs)\n\n        logging.info(\"Maximization step\")\n        t_table, rprobs = maximization_step(num_words, stanzas, schemes, probs)\n\n    # Warn if it did not converge\n    data_probs = numpy.logaddexp.reduce(probs, axis=1)\n    if ctr == maxsteps - 1 and not numpy.allclose(data_probs, old_data_probs):\n        logging.warning(\"Warning: EM did not converge\")\n\n    logging.info(\"Stopped after {} interations\".format(ctr))\n    return probs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_results(probs, stanzas, schemes):\n    results = []\n    for i, stanza in enumerate(stanzas):\n        best_scheme = schemes.scheme_list[numpy.argmax(probs[i, :])]\n        results.append((stanza.words, best_scheme))\n    return results", "response": "Returns a list of tuples containing the final words and the best schemes for each stanza."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite results to outfile", "response": "def print_results(results, outfile):\n    \"\"\"\n    Write results to outfile\n    \"\"\"\n    for stanza_words, scheme in results:\n        outfile.write(str(' ').join(stanza_words) + str('\\n'))\n        outfile.write(str(' ').join(map(str, scheme)) + str('\\n\\n'))\n    outfile.close()\n    logging.info(\"Wrote result\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrap for find_schemes if called from command line", "response": "def main(args_list=None):\n    \"\"\"\n    Wrapper for find_schemes if called from command line\n    \"\"\"\n    args_list = args_list or sys.argv[1:]\n    parser = argparse.ArgumentParser(description='Discover schemes of given stanza file')\n    parser.add_argument(\n        'infile',\n        type=argparse.FileType('r'),\n    )\n    parser.add_argument(\n        'outfile',\n        help='Where the result is written to. Default: stdout',\n        nargs='?',\n        type=argparse.FileType('w'),\n        default=sys.stdout,\n    )\n    parser.add_argument(\n        '-t --init-type',\n        help='Whether to initialize theta uniformly (u), with the orthographic similarity '\n             'measure (o), or using CELEX pronunciations and definition of rhyme (p). '\n             'The last one requires you to have CELEX on your machine.',\n        dest='init_type',\n        choices=('u', 'o', 'p', 'd'),\n        default='o',\n    )\n    parser.add_argument(\n        '-i, --iterations',\n        help='Number of iterations (default: 10)',\n        dest='num_iterations',\n        type=int,\n        default=10,\n    )\n    parser.add_argument(\n        '-v', '--verbose',\n        help=\"Verbose output\",\n        action=\"store_const\",\n        dest=\"loglevel\",\n        const=logging.INFO,\n    )\n    args = parser.parse_args(args_list)\n    logging.basicConfig(level=args.loglevel)\n\n    stanzas = load_stanzas(args.infile)\n\n    init_function = None\n    if args.init_type == 'u':\n        init_function = init_uniform_ttable\n    elif args.init_type == 'o':\n        init_function = init_basicortho_ttable\n    elif args.init_type == 'p':\n        init_function = celex.init_perfect_ttable\n    elif args.init_type == 'd':\n        init_function = init_difflib_ttable\n\n    results = find_schemes(stanzas, init_function, args.num_iterations)\n\n    print_results(results, args.outfile)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_word_indices(self, wordlist):\n        self.word_indices = [wordlist.index(word) for word in self.words]", "response": "Populate the list of word indices mapping self. words to the given wordlist\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the scheme file and return a list of tuples.", "response": "def _parse_scheme_file(self):\n        \"\"\"\n        Initialize redundant data structures for lookup optimization\n        \"\"\"\n        schemes = json.loads(self.scheme_file.read(), object_pairs_hook=OrderedDict)\n        scheme_list = []\n        scheme_dict = defaultdict(list)\n        for scheme_len, scheme_group in schemes.items():\n            for scheme_str, _count in scheme_group:\n                scheme_code = tuple(int(c) for c in scheme_str.split(' '))\n                scheme_list.append(scheme_code)\n                scheme_dict[int(scheme_len)].append(len(scheme_list) - 1)\n        return scheme_list, scheme_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_output_from_match(self, match_result):\n        full_path = match_result['full_path']\n        path = self._get_relative_path(full_path)\n        return LinterOutput(self.name, path, match_result['msg'])", "response": "Create a LinterOutput object from a match result."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(self, lines):\n        patterns = [re.compile(r'^(.+?):(\\d+)'),\n                    re.compile(r'^\\s+(.+)$')]\n        for i, line in enumerate(lines):\n            if i % 2 == 0:\n                path, line_nr = patterns[0].match(line).groups()\n            else:\n                msg = patterns[1].match(line).group(1)\n                yield LinterOutput(self.name, path, msg, line_nr)", "response": "Parse the lines of a pydocstyle result file and yield a generator of LinterOutput objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(self, lines):\n        pattern = re.compile(r\"\"\"^(?P<path>.+?)\n                                 :(?P<msg>.+)\n                                 :(?P<line_nr>\\d+?)\n                                 :(?P<col>\\d+?)$\"\"\", re.VERBOSE)\n        return self._parse_by_pattern(lines, pattern)", "response": "Get : class. base. Result parameters using regex."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate one orbfit ephemeris", "response": "def _generate_one_ephemeris(\n        cmd):\n    \"\"\"generate one orbfit ephemeris\n\n    **Key Arguments:**\n        - ``cmd`` -- the command to execute [cmd, object]\n\n    **Return:**\n        - ``results`` -- the single ephemeris results\n    \"\"\"\n\n    global cmdList\n    cmd = cmdList[cmd]\n\n    results = []\n    for c in cmd:\n        p = Popen(c[0], stdout=PIPE, stderr=PIPE, shell=True)\n        stdout, stderr = p.communicate()\n\n        if len(stderr) and len(stderr.split()) != 15:\n            print stderr, len(stderr.split())\n            return None\n        elif \"!!WARNING! WARNING! WARNING! WARNING!!\" in stdout:\n            print \"%(stdout)s was not found in astorb.dat\" % locals()\n            return None\n\n        # SPLIT RESULTS INTO LIST OF DICTIONARIES\n        r = stdout.strip().split(\"\\n\")\n        keys = r[0].strip().split(',')\n        lines = r[1:]\n        for l in lines:\n            # CREATE DICTIONARY FROM KEYS AND VALUES\n            values = l.strip().split(',')\n            for k, v in zip(keys, values):\n                v = v.strip().replace(\"/\", \"\")\n                try:\n                    v = float(v)\n                except:\n                    pass\n            result = dict(zip(keys, values))\n            result[\"object_name\"] = c[1]\n            results.append(result)\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a known solar-system object ID (human-readable name or MPC number but *NOT* an MPC packed format) or list of names and one or more specific epochs, return the calculated ephemerides **Key Arguments:** - ``log`` -- logger - ``objectId`` -- human-readable name, MPC number or solar-system object name, or list of names - ``mjd`` -- a single MJD, or a list MJDs to generate an ephemeris for - ``settings`` -- the settings dictionary for rockfinder - ``obscode`` -- the observatory code for the ephemeris generation. Default **500** (geocentric) - ``verbose`` -- return extra information with each ephemeris - ``astorbPath`` -- override the default path to astorb.dat orbital elements file **Return:** - ``resultList`` -- a list of ordered dictionaries containing the returned ephemerides **Usage:** To generate a an ephemeris for a single epoch run,using ATLAS Haleakala as your observatory: .. code-block:: python from rockfinder import orbfit_ephemeris eph = orbfit_ephemeris( log=log, objectId=1, obscode=\"T05\" mjd=57916., ) or to generate an ephemeris for multiple epochs: .. code-block:: python from rockfinder import orbfit_ephemeris eph = orbfit_ephemeris( log=log, objectId=\"ceres\", mjd=[57916.1,57917.234,57956.34523] verbose=True ) Note by passing `verbose=True` the essential ephemeris data is supplimented with some extra data It's also possible to pass in an array of object IDs: .. code-block:: python from rockfinder import orbfit_ephemeris eph = orbfit_ephemeris( log=log, objectId=[1,5,03547,\"Shikoku\"], mjd=[57916.1,57917.234,57956.34523] ) And finally you override the default path to astorb.dat orbital elements file by passing in a custom path (useful for passing in a trimmed orbital elements database): .. code-block:: python from rockfinder import orbfit_ephemeris eph = orbfit_ephemeris( log=log, objectId=[1,5,03547,\"Shikoku\"], mjd=[57916.1,57917.234,57956.34523], astorbPath=\"/path/to/astorb.dat\" )", "response": "def orbfit_ephemeris(\n        log,\n        objectId,\n        mjd,\n        settings,\n        obscode=500,\n        verbose=False,\n        astorbPath=False):\n    \"\"\"Given a known solar-system object ID (human-readable name or MPC number but *NOT* an MPC packed format) or list of names and one or more specific epochs, return the calculated ephemerides\n\n    **Key Arguments:**\n        - ``log`` -- logger\n        - ``objectId`` -- human-readable name, MPC number or solar-system object name, or list of names\n        - ``mjd`` -- a single MJD, or a list MJDs to generate an ephemeris for\n        - ``settings`` -- the settings dictionary for rockfinder\n        - ``obscode`` -- the observatory code for the ephemeris generation. Default **500** (geocentric)\n        - ``verbose`` -- return extra information with each ephemeris\n        - ``astorbPath`` -- override the default path to astorb.dat orbital elements file\n\n    **Return:**\n        - ``resultList`` -- a list of ordered dictionaries containing the returned ephemerides\n\n    **Usage:**\n\n        To generate a an ephemeris for a single epoch run,using ATLAS Haleakala as your observatory:\n\n        .. code-block:: python\n\n            from rockfinder import orbfit_ephemeris\n            eph = orbfit_ephemeris(\n                log=log,\n                objectId=1,\n                obscode=\"T05\"\n                mjd=57916.,\n            )\n\n        or to generate an ephemeris for multiple epochs:\n\n        .. code-block:: python\n\n            from rockfinder import orbfit_ephemeris\n            eph = orbfit_ephemeris(\n                log=log,\n                objectId=\"ceres\",\n                mjd=[57916.1,57917.234,57956.34523]\n                verbose=True\n            )\n\n        Note by passing `verbose=True` the essential ephemeris data is supplimented with some extra data\n\n        It's also possible to pass in an array of object IDs:\n\n        .. code-block:: python\n\n            from rockfinder import orbfit_ephemeris\n            eph = orbfit_ephemeris(\n                log=log,\n                objectId=[1,5,03547,\"Shikoku\"],\n                mjd=[57916.1,57917.234,57956.34523]\n            )\n\n        And finally you override the default path to astorb.dat orbital elements file by passing in a custom path (useful for passing in a trimmed orbital elements database):\n\n        .. code-block:: python\n\n            from rockfinder import orbfit_ephemeris\n            eph = orbfit_ephemeris(\n                log=log,\n                objectId=[1,5,03547,\"Shikoku\"],\n                mjd=[57916.1,57917.234,57956.34523],\n                astorbPath=\"/path/to/astorb.dat\"\n            )\n\n    \"\"\"\n    log.debug('starting the ``orbfit_ephemeris`` function')\n\n    global cmdList\n\n    # MAKE SURE MJDs ARE IN A LIST\n    if not isinstance(mjd, list):\n        mjdList = [str(mjd)]\n    else:\n        mjdList = mjd\n\n    if not isinstance(objectId, list):\n        objectList = [objectId]\n    else:\n        objectList = objectId\n\n    ephem = settings[\"path to ephem binary\"]\n    home = expanduser(\"~\")\n\n    results = []\n    tmpCmdList = []\n\n    for o in objectList:\n        for m in mjdList:\n            if not isinstance(o, int) and \"'\" in o:\n                cmd = \"\"\"%(ephem)s %(obscode)s %(m)s \"%(o)s\" \"\"\" % locals()\n            else:\n                cmd = \"\"\"%(ephem)s %(obscode)s %(m)s '%(o)s'\"\"\" % locals()\n\n            if astorbPath:\n                cmd += \" '%(astorbPath)s'\" % locals()\n\n            tmpCmdList.append((cmd, o))\n\n    def chunks(l, n):\n        \"\"\"Yield successive n-sized chunks from l.\"\"\"\n        for i in range(0, len(l), n):\n            yield l[i:i + n]\n\n    # BATCH INTO 10s\n    cmdList = [c for c in chunks(tmpCmdList, 10)]\n\n    # DEFINE AN INPUT ARRAY\n    results = fmultiprocess(log=log, function=_generate_one_ephemeris,\n                            inputArray=range(len(cmdList)))\n\n    if verbose == True:\n        order = [\"object_name\", \"mjd\", \"ra_deg\", \"dec_deg\", \"apparent_mag\", \"observer_distance\", \"heliocentric_distance\",\n                 \"phase_angle\",  \"obscode\", \"sun_obs_target_angle\", \"galactic_latitude\", \"ra_arcsec_per_hour\", \"dec_arcsec_per_hour\"]\n    else:\n        order = [\"object_name\", \"mjd\", \"ra_deg\", \"dec_deg\", \"apparent_mag\", \"observer_distance\", \"heliocentric_distance\",\n                 \"phase_angle\"]\n\n    # ORDER THE RESULTS\n    resultList = []\n    for r2 in results:\n        if not r2:\n            continue\n        for r in r2:\n            if not r:\n                continue\n\n            orderDict = collections.OrderedDict({})\n            for i in order:\n                orderDict[i] = r[i]\n\n            resultList.append(orderDict)\n\n    log.debug('completed the ``orbfit_ephemeris`` function')\n    return resultList"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompile short markup text into an HTML string", "response": "def text(short):\n    \"\"\"Compiles short markup text into an HTML strings\"\"\"\n    return indent(short, branch_method=html_block_tag, leaf_method=convert_line, pass_syntax=PASS_SYNTAX,\n                  flush_left_syntax=FLUSH_LEFT_SYNTAX, flush_left_empty_line=FLUSH_LEFT_EMPTY_LINE,\n                  indentation_method=find_indentation)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an integer that is the number of lines that belong to a block begun on the first line.", "response": "def get_indented_block(prefix_lines):\n    \"\"\"Returns an integer.\n\n    The return value is the number of lines that belong to block begun\n    on the first line.\n\n    Parameters\n    ----------\n\n      prefix_lines : list of basestring pairs\n        Each pair corresponds to a line of SHPAML source code. The\n        first element of each pair is indentation. The second is the\n        remaining part of the line, except for trailing newline.\n    \"\"\"\n    prefix, line = prefix_lines[0]\n    len_prefix = len(prefix)\n\n    # Find the first nonempty line with len(prefix) <= len(prefix)\n    i = 1\n    while i < len(prefix_lines):\n        new_prefix, line = prefix_lines[i]\n        if line and len(new_prefix) <= len_prefix:\n            break\n        i += 1\n\n    # Rewind to exclude empty lines\n    while i - 1 > 0 and prefix_lines[i - 1][1] == '':\n        i -= 1\n\n    return i"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an HTML string with the given text indented.", "response": "def indent(text, branch_method, leaf_method, pass_syntax, flush_left_syntax, flush_left_empty_line, indentation_method,\n           get_block=get_indented_block):\n    \"\"\"Returns HTML as a basestring.\n\n    Parameters\n    ----------\n\n      text : basestring\n        Source code, typically SHPAML, but could be a different (but\n        related) language. The remaining parameters specify details\n        about the language used in the source code. To parse SHPAML,\n        pass the same values as convert_shpaml_tree.\n\n      branch_method : function\n        convert_shpaml_tree passes html_block_tag here.\n      leaf_method : function\n        convert_shpaml_tree passes convert_line here.\n\n      pass_syntax : basestring\n        convert_shpaml_tree passes PASS_SYNTAX here.\n      flush_left_syntax : basestring\n        convert_shpaml_tree passes FLUSH_LEFT_SYNTAX here.\n      flush_left_empty_line : basestring\n        convert_shpaml_tree passes FLUSH_LEFT_EMPTY_LINE here.\n\n      indentation_method : function\n        convert_shpaml_tree passes _indent here.\n\n      get_block : function\n        Defaults to get_indented_block.\n    \"\"\"\n    text = text.rstrip()\n    lines = text.split('\\n')\n    if lines and lines[0].startswith('!! '):\n        lines[0] = lines[0].replace('!! ', '<!DOCTYPE ') + '>'\n    output = []\n    indent_lines(lines, output, branch_method, leaf_method, pass_syntax, flush_left_syntax, flush_left_empty_line,\n                 indentation_method, get_block=get_indented_block)\n    return '\\n'.join(output) + '\\n'"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns None. The way this function produces output is by adding strings to the list that's passed in as the second parameter. Parameters ---------- lines : list of basestring's Each string is a line of a SHPAML source code (trailing newlines not included). output : empty list Explained earlier... The remaining parameters are exactly the same as in the indent function: * branch_method * leaf_method * pass_syntax * flush_left_syntax * flush_left_empty_line * indentation_method * get_block", "response": "def indent_lines(lines, output, branch_method, leaf_method, pass_syntax, flush_left_syntax, flush_left_empty_line,\n                 indentation_method, get_block):\n    \"\"\"Returns None.\n\n    The way this function produces output is by adding strings to the\n    list that's passed in as the second parameter.\n\n    Parameters\n    ----------\n\n      lines : list of basestring's\n        Each string is a line of a SHPAML source code\n        (trailing newlines not included).\n      output : empty list\n        Explained earlier...\n\n    The remaining parameters are exactly the same as in the indent\n    function:\n\n      * branch_method\n      * leaf_method\n      * pass_syntax\n      * flush_left_syntax\n      * flush_left_empty_line\n      * indentation_method\n      * get_block\n    \"\"\"\n    append = output.append\n\n    def recurse(prefix_lines):\n        while prefix_lines:\n            prefix, line = prefix_lines[0]\n            if line == '':\n                prefix_lines.pop(0)\n                append('')\n                continue\n\n            block_size = get_block(prefix_lines)\n            if block_size == 1:\n                prefix_lines.pop(0)\n                if line == pass_syntax:\n                    pass\n                elif line.startswith(flush_left_syntax):\n                    append(line[len(flush_left_syntax):])\n                elif line.startswith(flush_left_empty_line):\n                    append('')\n                else:\n                    append(prefix + leaf_method(line))\n            else:\n                block = prefix_lines[:block_size]\n                prefix_lines = prefix_lines[block_size:]\n                branch_method(output, block, recurse)\n        return\n    prefix_lines = list(map(indentation_method, lines))\n    recurse(prefix_lines)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites the requirements. txt file to the repository.", "response": "def _write_reqs(amend: bool = False, stage: bool = False):\n    \"\"\"\n    Writes the requirement files\n\n    Args:\n        amend: amend last commit with changes\n        stage: stage changes\n    \"\"\"\n    LOGGER.info('writing requirements')\n\n    base_cmd = 'pipenv lock -r'\n    _write_reqs_file(f'{base_cmd}', 'requirements.txt')\n    _write_reqs_file(f'{base_cmd} -d', 'requirements-dev.txt')\n    files_to_add = ['Pipfile', 'requirements.txt', 'requirements-dev.txt']\n\n    if amend:\n        CTX.repo.amend_commit(append_to_msg='update requirements [auto]', files_to_add=files_to_add)\n    elif stage:\n        CTX.repo.stage_subset(*files_to_add)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reqs(amend: bool = False, stage: bool = False):\n    changed_files = CTX.repo.changed_files()\n    if 'requirements.txt' in changed_files or 'requirements-dev.txt' in changed_files:\n        LOGGER.error('Requirements have changed; cannot update them')\n        sys.exit(-1)\n    _write_reqs(amend, stage)", "response": "Write requirements files\n\n    Args:\n        amend: amend last commit with changes\n        stage: stage changes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef chunks(data, size):\n    for i in range(0, len(data), size):\n        yield data[i:i + size]", "response": "Generator that splits the given data into size chunks"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    client_1 = MessageBot(\"verne\", \"Jules Verne\")\n    client_1.start()\n    client_1.connect(\"127.0.0.1\")\n\n    client_2 = MessageBot(\"adams\", \"Douglas Adams\")\n    client_2.start()\n    client_2.connect(\"127.0.0.1\")\n\n    herald_1 = Herald(client_1)\n    herald_1.start()\n\n    herald_2 = Herald(client_2)\n    herald_2.start()\n\n    handler = LogHandler()\n    herald_1.register('/toto/*', handler)\n    herald_2.register('/toto/*', handler)\n\n    cmd = HeraldBot(\"bot\", \"Robotnik\", herald_1)\n    cmd.connect(\"127.0.0.1\")\n\n    cmd.wait_stop()\n\n    for closable in (client_1, client_2, herald_1, herald_2):\n        closable.close()\n\n    logging.info(\"Bye !\")", "response": "Entry point for the main function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconnect to a server and starts the connection thread.", "response": "def connect(self, host, port=6667, password=None):\n        \"\"\"\n        Connects to a server\n        \"\"\"\n        # Prepare the callbacks\n        self._irc.add_global_handler('all_events', self.__handler)\n\n        # Prepare the connection\n        self._connection = self._irc.server().connect(\n            host, port, self._nickname, password,\n            self._username, self._realname)\n\n        # Start connection thread\n        self.__stopped.clear()\n        self.__thread = threading.Thread(target=self.__loop,\n                                         name=\"IRC-Bot-Loop\")\n        self.__thread.daemon = True\n        self.__thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle an IRC event", "response": "def __handler(self, connection, event):\n        \"\"\"\n        Handles an IRC event\n        \"\"\"\n        try:\n            # Find local handler\n            method = getattr(self, \"on_{0}\".format(event.type))\n        except AttributeError:\n            pass\n        else:\n            try:\n                # Call it\n                return method(connection, event)\n            except Exception as ex:\n                logging.exception(\"Error calling handler: %s\", ex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef close(self):\n        # Disconnect with a fancy message, then close connection\n        if self._connection is not None:\n            self._connection.disconnect(\"Bot is quitting\")\n            self._connection.close()\n            self._connection = None\n\n        # Stop the client loop\n        self.__stopped.set()\n\n        if self.__thread is not None:\n            try:\n                self.__thread.join(5)\n            except RuntimeError:\n                pass\n            self.__thread = None", "response": "Disconnects from the server and closes the connection."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wait(self, timeout=None):\n        self.__stopped.wait(timeout)\n        return self.__stopped.is_set()", "response": "Waits for the client to stop."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_welcome(self, connection, event):\n        # Start the pool\n        self.__pool.start()\n\n        logging.info(\"! Connected to server '%s': %s\",\n                     event.source, event.arguments[0])\n        connection.join(\"#cohorte\")", "response": "Called when we get a welcome message from the server"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles a PUBMSG event.", "response": "def on_pubmsg(self, connection, event):\n        \"\"\"\n        Got a message from a channel\n        \"\"\"\n        sender = self.get_nick(event.source)\n        channel = event.target\n        message = event.arguments[0]\n\n        self.handle_message(connection, sender, channel, message)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_privmsg(self, connection, event):\n        sender = self.get_nick(event.source)\n        message = event.arguments[0]\n        \n        if sender == 'NickServ':\n            logging.info(\"Got message from NickServ: %s\", message)\n            if \"password\" in message.lower():\n                connection.privmsg(\"NickServ\", \"pass\")\n            else:\n                connection.join('#cohorte')\n            \n            return\n\n        self.handle_message(connection, sender, sender, message)", "response": "Handle a private message from a user."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle a received message from the broker.", "response": "def handle_message(self, connection, sender, target, message):\n        \"\"\"\n        Handles a received message\n        \"\"\"\n        parts = message.strip().split(' ', 2)\n        if parts and parts[0].lower() == '!bot':\n            try:\n                command = parts[1].lower()\n            except IndexError:\n                self.safe_send(connection, target, \"No command given\")\n                return\n\n            try:\n                payload = parts[2]\n            except IndexError:\n                payload = \"\"\n\n            self.__pool.enqueue(self._handle_command,\n                                connection, sender, target, command, payload)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling when an invitation is received from a channel.", "response": "def on_invite(self, connection, event):\n        \"\"\"\n        Got an invitation to a channel\n        \"\"\"\n        sender = self.get_nick(event.source)\n        invited = self.get_nick(event.target)\n        channel = event.arguments[0]\n\n        if invited == self._nickname:\n            logging.info(\"! I am invited to %s by %s\", channel, sender)\n            connection.join(channel)\n\n        else:\n            logging.info(\">> %s invited %s to %s\", sender, invited, channel)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling a command from the broker.", "response": "def _handle_command(self, connection, sender, target, command, payload):\n        \"\"\"\n        Handles a command, if any\n        \"\"\"\n        try:\n            # Find the handler\n            handler = getattr(self, \"cmd_{0}\".format(command))\n        except AttributeError:\n            self.safe_send(connection, target, \"Unknown command: %s\",\n                            command)\n        else:\n            try:\n                logging.info(\"! Handling command: %s\", command)\n                handler(connection, sender, target, payload)\n            except Exception as ex:\n                logging.exception(\"Error calling command handler: %s\", ex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef safe_send(self, connection, target, message, *args, **kwargs):\n        # Compute maximum length of payload\n        prefix = \"PRIVMSG {0} :\".format(target)\n        max_len = 510 - len(prefix)\n\n        for chunk in chunks(message.format(*args, **kwargs), max_len):\n            connection.send_raw(\"{0}{1}\".format(prefix, chunk))", "response": "Send a message to the given target."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cmd_send(self, connection, sender, target, payload):\n        msg_target, topic, content = self.parse_payload(payload)\n        results = self.__herald.send(msg_target, topic, content)\n        self.safe_send(connection, target, \"GOT RESULT: {0}\".format(results))", "response": "Send a message to Herald"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cmd_fire(self, connection, sender, target, payload):\n        msg_target, topic, content = self.parse_payload(payload)\n\n        def callback(sender, payload):\n            logging.info(\"FIRE ACK from %s\", sender)\n\n        self.__herald.fire(msg_target, topic, content, callback)", "response": "Send a message to the Herald daemon"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a notice message to HAL.", "response": "def cmd_notice(self, connection, sender, target, payload):\n        \"\"\"\n        Sends a message\n        \"\"\"\n        msg_target, topic, content = self.parse_payload(payload)\n\n        def callback(sender, payload):\n            logging.info(\"NOTICE ACK from %s: %s\", sender, payload)\n\n        self.__herald.notice(msg_target, topic, content, callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cmd_post(self, connection, sender, target, payload):\n        msg_target, topic, content = self.parse_payload(payload)\n\n        def callback(sender, payload):\n            logging.info(\"POST RES from %s: %s\", sender, payload)\n\n        self.__herald.post(msg_target, topic, content, callback)", "response": "Send a message to Herald"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_privmsg(self, connection, event):\n        sender = self.get_nick(event.source)\n        message = event.arguments[0]\n        \n        if sender == 'NickServ':\n            logging.info(\"Got message from NickServ: %s\", message)\n            if \"password\" in message.lower():\n                connection.privmsg(\"NickServ\", \"pass\")\n            else:\n                connection.join('#cohorte')\n            \n            return\n        \n        self._pool.enqueue(self.__on_message, connection, sender, message)", "response": "Called when a private message is received from a channel."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall when a message is received from a channel.", "response": "def __on_message(self, connection, sender, message):\n        \"\"\"\n        Got a message from a channel\n        \"\"\"\n        if message.strip() == '!bot send':\n            cycle = itertools.cycle(string.digits)\n            content = ''.join(next(cycle) for _ in range(100))\n            self.send_message(sender, content)\n\n        else:\n            parts = message.split(':', 2)\n            if not parts or parts[0] != 'HRLD':\n                return\n\n            if parts[1] == 'BEGIN':\n                # Beginning of multi-line message\n                self._queue[parts[2]] = []\n\n            elif parts[1] == 'END':\n                # End of multi-line message\n                content = ''.join(self._queue.pop(parts[2]))\n                self.__notify(sender, content)\n\n            elif parts[1] == 'MSG':\n                # Single-line message\n                content = parts[2]\n                self.__notify(sender, content)\n\n            else:\n                # Multi-line message continuation\n                uid = parts[1]\n                self._queue[uid].append(parts[2])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nnotifying the user of a message received from the broker.", "response": "def __notify(self, sender, content):\n        \"\"\"\n        Calls back listener when a message is received\n        \"\"\"\n        if self.handle_message is not None:\n            try:\n                self.handle_message(sender, content)\n            except Exception as ex:\n                logging.exception(\"Error calling message listener: %s\", ex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a line in Herald s format", "response": "def _make_line(self, uid, command=None):\n        \"\"\"\n        Prepares an IRC line in Herald's format\n        \"\"\"\n        if command:\n            return \":\".join((\"HRLD\", command, uid))\n        else:\n            return \":\".join((\"HRLD\", uid))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_message(self, target, content, uid=None):\n        # Compute maximum length of payload\n        prefix = \"PRIVMSG {0} :\".format(target)\n        single_prefix = self._make_line(\"MSG:\")\n        single_prefix_len = len(single_prefix)\n        max_len = 510 - len(prefix)\n\n        content_len = len(content)\n        if (content_len + single_prefix_len) < max_len:\n            # One pass message\n            self._connection.send_raw(\"{0}{1}{2}\" \\\n                                       .format(prefix, single_prefix, content))\n\n        else:\n            # Multiple-passes message\n            uid = uid or str(uuid.uuid4()).replace('-', '').upper()\n            prefix = \"{0}{1}:\".format(prefix, self._make_line(uid))\n            max_len = 510 - len(prefix)\n\n            self._connection.privmsg(target, self._make_line(uid, \"BEGIN\"))\n\n            for chunk in chunks(content, max_len):\n                self._connection.send_raw(''.join((prefix, chunk)))\n\n            self._connection.privmsg(target, self._make_line(uid, \"END\"))", "response": "Sends a message through IRCMessages."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __make_message(self, topic, content):\n        return {\"uid\": str(uuid.uuid4()).replace('-', '').upper(),\n                \"topic\": topic,\n                \"content\": content}", "response": "Creates a message from topic and content"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfires a message from the broker", "response": "def fire(self, target, topic, content, callback=None):\n        \"\"\"\n        Fires a message\n        \"\"\"\n        message = self.__make_message(topic, content)\n        if callback is not None:\n            self.__callbacks[message['uid']] = ('fire', callback)\n\n        self.__client.send_message(target, json.dumps(message), message['uid'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a message to a topic.", "response": "def send(self, target, topic, content):\n        \"\"\"\n        Fires a message\n        \"\"\"\n        event = threading.Event()\n        results = []\n\n        def got_message(sender, content):\n            results.append(content)\n            event.set()\n\n        self.post(target, topic, content, got_message)\n        event.wait()\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _notify_listeners(self, sender, message):\n        uid = message['uid']\n        msg_topic = message['topic']\n\n\n        self._ack(sender, uid, 'fire')\n\n        all_listeners = set()\n        for lst_topic, listeners in self.__listeners.items():\n            if fnmatch.fnmatch(msg_topic, lst_topic):\n                all_listeners.update(listeners)\n\n        self._ack(sender, uid, 'notice', 'ok' if all_listeners else 'none')\n\n        try:\n            results = []\n            for listener in all_listeners:\n                result = listener.handle_message(sender,\n                                                 message['topic'],\n                                                 message['content'])\n                if result:\n                    results.append(result)\n\n            self._ack(sender, uid, 'send', json.dumps(results))\n        except:\n            self._ack(sender, uid, 'send', \"Error\")", "response": "Notify listeners of a new message"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nacknowledges a message from the broker", "response": "def _ack(self, sender, uid, level, payload=None):\n        \"\"\"\n        Replies to a message\n        \"\"\"\n        content = {'reply-to': uid,\n                   'reply-level': level,\n                   'payload': payload}\n        self.__client.send_message(sender, json.dumps(content))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls when a message is received from the client.", "response": "def on_message(self, sender, content):\n        \"\"\"\n        Got a message from the client\n        \"\"\"\n        try:\n            message = json.loads(content)\n\n        except (ValueError, TypeError) as ex:\n            logging.error(\"Not a valid JSON string: %s\", ex)\n            return\n\n        try:\n            # Check the replied message\n            reply_uid = message['reply-to']\n            reply_level = message['reply-level']\n\n        except KeyError:\n            # Got a new message\n            logging.info(\"Got message %s from %s\", message['content'], sender)\n\n            # Notify listeners\n            self.__pool.enqueue(self._notify_listeners, sender, message)\n\n        else:\n            # Got a reply\n            try:\n                level, callback = self.__callbacks[reply_uid]\n\n            except KeyError:\n                # Nobody to callback...\n                pass\n\n            else:\n                if level == reply_level:\n                    # Match\n                    try:\n                        callback(sender, message['payload'])\n                    except Exception as ex:\n                        logging.exception(\"Error notifying sender: %s\", ex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef t_php_STRING(t):\n    r'[A-Za-z_][\\w_]*'\n    t.type = reserved_map.get(t.value.upper(), 'STRING')\n    return t", "response": "r \\ w _"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef t_quotedvar_DOLLAR_OPEN_CURLY_BRACES(t):\n    r'\\$\\{'\n    if re.match(r'[A-Za-z_]', peek(t.lexer)):\n        t.lexer.begin('varname')\n    else:\n        t.lexer.begin('php')\n    return t", "response": "t_quotedvar_DOLLAR_OPEN_CURLY_BRACES - Handles quoted variable open braces."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef use(self, client_key):\n        if not self.clients.has_client(client_key):\n            raise ClientNotExist()\n\n        self.current_client = self.clients.get_client(client_key)\n\n        return self", "response": "Sets the current client to use the given client key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncommits the current revision to the current revision.", "response": "def commit(self, revision, is_amend=False):\n        \"\"\"\n        :param revision:\n        :type revision: :class:`revision.data.Revision`\n        :param is_amend:\n        :type is_amend: boolean\n        :return: The Orchestrator instance (for method chaining)\n        :rtype: :class:`revision.orchestrator.Orchestrator`\n        \"\"\"\n        if not isinstance(revision, Revision):\n            raise InvalidArgType()\n\n        if not self.current_client:\n            raise ClientNotSpecified()\n\n        if is_amend:\n            self.current_client.save(revision)\n        else:\n            self.current_client.write()\n            self.current_client.save(revision)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_commit(self, client_key=None):\n        if client_key is None and self.current_client is None:\n            raise ClientNotExist()\n\n        if client_key:\n            if not self.clients.has_client(client_key):\n                raise ClientNotExist()\n\n            client = self.clients.get_client(client_key)\n\n            return client.has_commit()\n\n        if self.current_client:\n            client = self.current_client\n\n            return client.has_commit()\n\n        return False", "response": "Return True if client has new commit."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init(ciprcfg, env, console):\n    ciprcfg.create()\n\n    templ_dir = path.join(env.skel_dir, 'default')\n\n    console.quiet('Copying files from %s' % templ_dir)\n    for src, dst in util.sync_dir_to(templ_dir, env.project_directory, ignore_existing=True):\n        console.quiet('  %s -> %s' % (src, dst))\n\n    src = path.join(env.code_dir, 'cipr.dev.lua')\n    dst = path.join(env.project_directory, 'cipr.lua')\n    console.quiet('  %s -> %s' % (src, dst))\n\n    shutil.copy(src, dst)", "response": "Initialize a Corona project directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate an existing cipr project to the latest installed version.", "response": "def update(env):\n    \"\"\"\n    Update an existing cipr project to the latest intalled version.\n    \"\"\"\n    files = [path.join(env.project_directory, 'cipr.lua')]\n    for filename in files:\n        if path.exists(filename):\n            os.remove(filename)\n    app.command.run(['init', env.project_directory])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef uninstall(args, env, console, ciprcfg):\n    for name in args:\n        package_dir = path.join(env.package_dir, name)\n        if path.exists(package_dir):\n            console.quiet('Removing %s...' % name)\n            if path.islink(package_dir):\n                os.remove(package_dir)\n            else:\n                shutil.rmtree(package_dir)\n\n        ciprcfg.remove_package(name)", "response": "Uninstall a package from the list of packages in the package_dir."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninstalls a package from github and make it available for use.", "response": "def install(args, console, env, ciprcfg, opts):\n    \"\"\"\n    Install a package from github and make it available for use.\n    \"\"\"\n    if len(args) == 0:\n        # Is this a cipr project?\n        if ciprcfg.exists:\n            # Install all the packages for this project\n            console.quiet('Installing current project packages...')\n            for name, source in ciprcfg.packages.items():\n                if opts.upgrade:\n                    app.command.run(['install', '--upgrade', source])\n                else:\n                    app.command.run(['install', source])\n        else:\n            console.error('No cipr project or package found.')\n        return\n    else:\n        for source in args:\n            package, name, version, type = _package_info(source)\n\n            if not path.exists(env.package_dir):\n                os.makedirs(env.package_dir)\n\n            package_dir = path.join(env.package_dir, name)\n\n            if path.exists(package_dir):\n                if opts.upgrade:\n                    app.command.run(['uninstall', name])\n                else:\n                    console.quiet('Package %s already exists. Use --upgrade to force a re-install.' % name)\n                    return\n\n            console.quiet('Installing %s...' % name)\n\n\n            if type == 'git':\n                tmpdir = tempfile.mkdtemp(prefix='cipr')\n                clom.git.clone(package, tmpdir).shell.execute()\n\n                if version:\n                    cmd = AND(clom.cd(tmpdir), clom.git.checkout(version))\n                    cmd.shell.execute()\n\n                package_json = path.join(tmpdir, 'package.json')\n                if path.exists(package_json):\n                    # Looks like a cipr package, copy directly\n                    shutil.move(tmpdir, package_dir)\n                else:\n                    # Not a cipr package, sandbox in sub-directory\n                    shutil.move(tmpdir, path.join(package_dir, name))\n\n                console.quiet('`%s` installed from git repo to `%s`' % (name, package_dir))\n\n            elif path.exists(package):\n                # Local\n                os.symlink(package, package_dir)\n            else:\n                console.error('Package `%s` type not recognized' % package)\n                return\n\n            pkg = Package(package_dir, source)\n            ciprcfg.add_package(pkg)\n\n            if pkg.dependencies:\n                console.quiet('Installing dependancies...')\n                for name, require in pkg.dependencies.items():\n                    if opts.upgrade:\n                        app.command.run(['install', '--upgrade', require])\n                    else:\n                        app.command.run(['install', require])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting installed packages for this project", "response": "def packages(ciprcfg, env, opts, console):\n    \"\"\"\n    List installed packages for this project\n    \"\"\"\n    for name, source in ciprcfg.packages.items():\n        console.normal('- %s' % name)\n\n        if opts.long_details:\n            console.normal('  - directory: %s' % path.join(env.package_dir, name))\n            console.normal('  - source: %s' % source)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(env):\n    os.putenv('CIPR_PACKAGES', env.package_dir)\n    os.putenv('CIPR_PROJECT', env.project_directory)\n\n    # `Corona Terminal` doesn't support spaces in filenames so we cd in and use '.'.\n\n    cmd = AND(\n        clom.cd(path.dirname(env.project_directory)),\n        clom[CORONA_SIMULATOR_PATH](path.basename(env.project_directory))\n    )\n\n    try:\n        cmd.shell.execute()\n    except KeyboardInterrupt:\n        pass", "response": "Run current project in Corona Simulator"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds the current project for distribution", "response": "def build(env, ciprcfg, console):\n    \"\"\"\n    Build the current project for distribution\n    \"\"\"\n    os.putenv('CIPR_PACKAGES', env.package_dir)\n    os.putenv('CIPR_PROJECT', env.project_directory)\n\n    build_settings = path.join(env.project_directory, 'build.settings')\n\n    with open(build_settings, 'r') as f:\n        data = f.read()\n\n    m = _build_re.search(data)\n    if m:\n        ver = int(m.group(2))\n        data = data.replace(m.group(0), 'CFBundleVersion = \"%d\"' % (ver + 1))\n\n        with open(build_settings, 'w') as f:\n            f.write(data)\n\n\n    if path.exists(env.build_dir):\n        shutil.rmtree(env.build_dir)\n\n    os.makedirs(env.build_dir)\n\n    if path.exists(env.dist_dir):\n        shutil.rmtree(env.dist_dir)\n\n    os.makedirs(env.dist_dir)\n\n    console.normal('Building in %s' % env.build_dir)\n\n    console.normal('Copy project files...')\n    for src, dst in util.sync_dir_to(env.project_directory, env.build_dir, exclude=['.cipr', '.git', 'build', 'dist', '.*']):\n        console.quiet('  %s -> %s' % (src, dst))\n        if src.endswith('.lua'):\n            _fix_lua_module_name(src, dst)\n\n\n    console.normal('Copy cipr packages...')\n    for package in ciprcfg.packages.keys():\n        for src, dst in util.sync_lua_dir_to(path.join(env.package_dir, package), env.build_dir, exclude=['.git'], include=['*.lua']):\n            console.quiet('  %s -> %s' % (src, dst))\n            if src.endswith('.lua'):\n                _fix_lua_module_name(src, dst)\n\n    src = path.join(env.code_dir, 'cipr.lua')\n    dst = path.join(env.build_dir, 'cipr.lua')\n    shutil.copy(src, dst)\n\n    cmd = AND(clom.cd(env.build_dir), clom[CORONA_SIMULATOR_PATH](env.build_dir))\n\n    console.normal('Be sure to output your app to %s' % env.dist_dir)\n\n    try:\n        cmd.shell.execute()\n    except KeyboardInterrupt:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef packageipa(env, console):\n    ipa_path, app_path = _get_ipa(env)\n    output_dir = path.dirname(ipa_path)\n\n    if path.exists(ipa_path):\n        console.quiet('Removing %s' % ipa_path)\n        os.remove(ipa_path)\n\n    zf = zipfile.ZipFile(ipa_path, mode='w')\n    payload_dir = 'Payload'\n\n    for (dirpath, dirnames, filenames) in os.walk(app_path):\n        for filename in filenames:\n            filepath = path.join(dirpath, filename)\n            prefix = path.commonprefix([filepath, path.dirname(app_path)])\n            write_path = path.join(payload_dir, filepath[len(prefix) + 1:])\n\n            console.quiet('Write %s' % write_path)\n\n            zf.write(filepath, write_path)\n\n    zf.close()\n\n    console.quiet('Packaged %s' % ipa_path)", "response": "Package the built app as an ipa for distribution in iOS App Store"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef expanddotpaths(env, console):\n    for filepath in os.listdir(path.join(env.dir)):\n        filename, ext = path.splitext(filepath)\n        if ext == '.lua' and '.' in filename:\n            paths, newfilename = filename.rsplit('.', 1)\n            newpath = paths.replace('.', '/')\n            newfilename = path.join(newpath, newfilename) + ext\n\n            console.quiet('Move %s to %s' % (filepath, newfilename))\n\n            fullpath = path.join(env.project_directory, newpath)\n            if not path.exists(fullpath):\n                os.makedirs(fullpath)\n\n            clom.git.mv(filepath, newfilename).shell.execute()", "response": "Move files with dots in them to sub - directories"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if a file exists and returns the file type.", "response": "def check_file_existence(path):\n    \"\"\"\n    :return: FileType\n    :rtype: int\n    :raises InvalidFilePathError:\n    :raises FileNotFoundError:\n    :raises RuntimeError:\n    \"\"\"\n\n    pathvalidate.validate_file_path(path)\n\n    if not os.path.lexists(path):\n        raise FileNotFoundError(path)\n\n    if os.path.isfile(path):\n        logger.debug(\"file found: \" + path)\n        return FileType.FILE\n\n    if os.path.isdir(path):\n        logger.debug(\"directory found: \" + path)\n        return FileType.DIRECTORY\n\n    if os.path.islink(path):\n        logger.debug(\"link found: \" + path)\n        return FileType.LINK\n\n    raise RuntimeError()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses permission 3 char", "response": "def parsePermission3Char(permission):\n    \"\"\"\n    'rwx' \u5f62\u5f0f\u306e\u30a2\u30af\u30bb\u30b9\u6a29\u9650\u6587\u5b57\u5217 permission \u30928\u9032\u6570\u5f62\u5f0f\u306b\u5909\u63db\u3059\u308b\n\n    :return:\n    :rtype: int\n    \"\"\"\n\n    if len(permission) != 3:\n        raise ValueError(permission)\n\n    permission_int = 0\n    if permission[0] == \"r\":\n        permission_int += 4\n    if permission[1] == \"w\":\n        permission_int += 2\n    if permission[2] == \"x\":\n        permission_int += 1\n\n    return permission_int"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parseLsPermissionText(permission_text):\n\n    from six.moves import range\n\n    match = re.search(\"[-drwx]+\", permission_text)\n    if match is None:\n        raise ValueError(\n            \"invalid permission character: \" + permission_text)\n\n    if len(permission_text) != 10:\n        raise ValueError(\n            \"invalid permission text length: \" + permission_text)\n\n    permission_text = permission_text[1:]\n\n    return int(\n        \"0\" + \"\".join([\n            str(parsePermission3Char(permission_text[i:i + 3]))\n            for i in range(0, 9, 3)\n        ]),\n        base=8)", "response": "parse ls - l style permission text"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef chmod(cls, path, permission_text):\n\n        try:\n            check_file_existence(path)\n        except FileNotFoundError:\n            _, e, _ = sys.exc_info()  # for python 2.5 compatibility\n            logger.debug(e)\n            return False\n\n        logger.debug(\"chmod %s %s\" % (path, permission_text))\n\n        os.chmod(path, parseLsPermissionText(permission_text))", "response": "Change the permissions of the named file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a known solar-system object ID (human-readable name, MPC number or MPC packed format) and one or more specific epochs, return the calculated ephemerides **Key Arguments:** - ``log`` -- logger - ``objectId`` -- human-readable name, MPC number or MPC packed format id of the solar-system object or list of names - ``mjd`` -- a single MJD, or a list of up to 10,000 MJDs to generate an ephemeris for - ``obscode`` -- the observatory code for the ephemeris generation. Default **500** (geocentric) - ``verbose`` -- return extra information with each ephemeris **Return:** - ``resultList`` -- a list of ordered dictionaries containing the returned ephemerides **Usage:** To generate a an ephemeris for a single epoch run, using ATLAS Haleakala as your observatory: .. code-block:: python from rockfinder import jpl_horizons_ephemeris eph = jpl_horizons_ephemeris( log=log, objectId=1, mjd=57916., obscode='T05' ) or to generate an ephemeris for multiple epochs: .. code-block:: python from rockfinder import jpl_horizons_ephemeris eph = jpl_horizons_ephemeris( log=log, objectId=\"ceres\", mjd=[57916.1,57917.234,57956.34523] verbose=True ) Note by passing `verbose=True` the essential ephemeris data is supplimented with some extra data It's also possible to pass in an array of object IDs: .. code-block:: python from rockfinder import jpl_horizons_ephemeris eph = jpl_horizons_ephemeris( log=log, objectId=[1,5,03547,\"Shikoku\",\"K10B11A\"], mjd=[57916.1,57917.234,57956.34523] )", "response": "def jpl_horizons_ephemeris(\n        log,\n        objectId,\n        mjd,\n        obscode=500,\n        verbose=False):\n    \"\"\"Given a known solar-system object ID (human-readable name, MPC number or MPC packed format) and one or more specific epochs, return the calculated ephemerides \n\n    **Key Arguments:**\n        - ``log`` -- logger\n        - ``objectId`` -- human-readable name, MPC number or MPC packed format id of the solar-system object or list of names\n        - ``mjd`` -- a single MJD, or a list of up to 10,000 MJDs to generate an ephemeris for\n        - ``obscode`` -- the observatory code for the ephemeris generation. Default **500** (geocentric)\n        - ``verbose`` -- return extra information with each ephemeris\n\n    **Return:**\n        - ``resultList`` -- a list of ordered dictionaries containing the returned ephemerides\n\n    **Usage:**\n\n        To generate a an ephemeris for a single epoch run, using ATLAS Haleakala as your observatory:\n\n        .. code-block:: python \n\n            from rockfinder import jpl_horizons_ephemeris\n            eph = jpl_horizons_ephemeris(\n                log=log,\n                objectId=1,\n                mjd=57916.,\n                obscode='T05'\n            )\n\n        or to generate an ephemeris for multiple epochs:\n\n        .. code-block:: python \n\n            from rockfinder import jpl_horizons_ephemeris\n            eph = jpl_horizons_ephemeris(\n                log=log,\n                objectId=\"ceres\",\n                mjd=[57916.1,57917.234,57956.34523]\n                verbose=True\n            )\n\n        Note by passing `verbose=True` the essential ephemeris data is supplimented with some extra data\n\n        It's also possible to pass in an array of object IDs:\n\n        .. code-block:: python \n\n            from rockfinder import jpl_horizons_ephemeris\n            eph = jpl_horizons_ephemeris(\n                log=log,\n                objectId=[1,5,03547,\"Shikoku\",\"K10B11A\"],\n                mjd=[57916.1,57917.234,57956.34523]\n            )\n    \"\"\"\n    log.debug('starting the ``jpl_horizons_ephemeris`` function')\n\n    # MAKE SURE MJDs ARE IN A LIST\n    if not isinstance(mjd, list):\n        mjd = [str(mjd)]\n\n    mjd = (\" \").join(map(str, mjd))\n\n    if not isinstance(objectId, list):\n        objectList = [objectId]\n    else:\n        objectList = objectId\n\n    keys = [\"jd\", \"solar_presence\", \"lunar_presence\",  \"ra_deg\", \"dec_deg\", \"ra_arcsec_per_hour\", \"dec_arcsec_per_hour\",  \"apparent_mag\", \"surface_brightness\", \"heliocentric_distance\", \"heliocentric_motion\", \"observer_distance\", \"observer_motion\",\n            \"sun_obs_target_angle\", \"apparent_motion_relative_to_sun\",  \"sun_target_obs_angle\", \"ra_3sig_error\", \"dec_3sig_error\", \"true_anomaly_angle\", \"phase_angle\", \"phase_angle_bisector_long\", \"phase_angle_bisector_lat\"]\n    if verbose == True:\n        order = [\"requestId\", \"objectId\", \"mjd\", \"ra_deg\", \"dec_deg\", \"ra_3sig_error\", \"dec_3sig_error\", \"ra_arcsec_per_hour\",  \"dec_arcsec_per_hour\", \"apparent_mag\",  \"heliocentric_distance\", \"heliocentric_motion\", \"observer_distance\", \"observer_motion\", \"phase_angle\", \"true_anomaly_angle\", \"surface_brightness\",\n                 \"sun_obs_target_angle\",  \"sun_target_obs_angle\", \"apparent_motion_relative_to_sun\", \"phase_angle_bisector_long\", \"phase_angle_bisector_lat\"]\n    else:\n        order = [\"requestId\", \"objectId\", \"mjd\", \"ra_deg\", \"dec_deg\", \"ra_3sig_error\", \"dec_3sig_error\", \"ra_arcsec_per_hour\",\n                 \"dec_arcsec_per_hour\", \"apparent_mag\",  \"heliocentric_distance\", \"observer_distance\", \"phase_angle\"]\n\n    params = {\n        \"COMMAND\": \"\",\n        \"OBJ_DATA\": \"'NO'\",\n        \"MAKE_EPHEM\": \"'YES'\",\n        \"TABLE_TYPE\": \"'OBS'\",\n        \"CENTER\": \"'%(obscode)s'\" % locals(),\n        \"TLIST\": mjd,\n        \"QUANTITIES\": \"'1,3,9,19,20,23,24,36,41,43'\",\n        \"REF_SYSTEM\": \"'J2000'\",\n        \"CAL_FORMAT\": \"'JD'\",\n        \"ANG_FORMAT\": \"'DEG'\",\n        \"APPARENT\": \"'REFRACTED'\",\n        \"TIME_DIGITS\": \"'FRACSEC'\",\n        \"TIME_ZONE\": \"'+00:00'\",\n        \"RANGE_UNITS\": \"'AU'\",\n        \"SUPPRESS_RANGE_RATE\": \"'NO'\",\n        \"SKIP_DAYLT\": \"'YES'\",\n        \"EXTRA_PREC\": \"'YES'\",\n        \"CSV_FORMAT\": \"'YES'\",\n        \"batch\": \"1\",\n    }\n\n    resultList = []\n    paramList = []\n    for objectId in objectList:\n\n        requestId = objectId\n        # FIX THE COMMAND FOR NUMBERED OBJECTS\n        try:\n            thisId = int(objectId)\n            objectId = \"%(thisId)s\" % locals()\n        except Exception as e:\n            pass\n\n        theseparams = copy.deepcopy(params)\n        theseparams[\"COMMAND\"] = '\"' + objectId + '\"'\n\n        paramList.append(theseparams)\n\n        # TEST THE URL\n        # try:\n        #     import requests\n        #     response = requests.get(\n        #         url=\"https://ssd.jpl.nasa.gov/horizons_batch.cgi\",\n        #         params=theseparams,\n        #     )\n        #     content = response.content\n        #     status_code = response.status_code\n        #     print response.url\n        # except requests.exceptions.RequestException:\n        #     print('HTTP Request failed')\n        #     sys.exit(0)\n\n    rs = [grequests.get(\"https://ssd.jpl.nasa.gov/horizons_batch.cgi\", params=p)\n          for p in paramList]\n\n    def exception_handler(request, exception):\n        print \"Request failed\"\n        print exception\n\n    returns = grequests.map(rs, size=1, exception_handler=exception_handler)\n\n    for result, requestId in zip(returns, objectList):\n        r = result.content\n\n        match = re.search(\n            r'Target body name:\\s(.*?)\\{',\n            r,\n            flags=re.S  # re.S\n        )\n\n        if not match:\n            log.warning(\n                \"Horizons could not find a match for `%(requestId)s`\" % locals())\n            try:\n                import requests\n                response = requests.get(\n                    url=\"https://ssd.jpl.nasa.gov/horizons_batch.cgi\",\n                    params=theseparams,\n                )\n                content = response.content\n                status_code = response.status_code\n                print response.url\n            except requests.exceptions.RequestException:\n                print('HTTP Request failed')\n                sys.exit(0)\n            objectDict = {}\n            for k in keys:\n                v = None\n                objectDict[k] = v\n\n            objectDict[\"objectId\"] = requestId + \" - NOT FOUND\"\n            objectDict[\"requestId\"] = requestId\n            objectDict[\"mjd\"] = None\n\n            orderDict = collections.OrderedDict({})\n            for i in order:\n                orderDict[i] = objectDict[i]\n\n            resultList.append(orderDict)\n            continue\n\n        horizonsId = match.group(1).replace(\"(\", \"\").replace(\")\", \"\").strip()\n\n        match = re.search(\n            r'\\$\\$SOE\\n(.*?)\\n\\$\\$EOE',\n            r,\n            flags=re.S  # re.S\n        )\n\n        keys2 = copy.deepcopy(keys)\n        order2 = copy.deepcopy(order)\n        if \"S-brt,\" not in r:\n            keys2.remove(\"surface_brightness\")\n            try:\n                order2.remove(\"surface_brightness\")\n            except:\n                pass\n\n        lines = match.group(1).split(\"\\n\")\n        for line in lines:\n\n            vals = line.split(\",\")\n            objectDict = {}\n            for k, v in zip(keys2, vals):\n                v = v.strip().replace(\"/\", \"\")\n                try:\n                    v = float(v)\n                except:\n                    pass\n                objectDict[k] = v\n\n            objectDict[\"mjd\"] = objectDict[\"jd\"] - 2400000.5\n            objectDict[\"objectId\"] = horizonsId\n            objectDict[\"requestId\"] = requestId\n\n            orderDict = collections.OrderedDict({})\n            for i in order2:\n                orderDict[i] = objectDict[i]\n\n            resultList.append(orderDict)\n\n    log.debug('completed the ``jpl_horizons_ephemeris`` function')\n    return resultList"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the status of a build", "response": "def status(self, key, value):\n        \"\"\"Update the status of a build\"\"\"\n        value = value.lower()\n        if value not in valid_statuses:\n            raise ValueError(\"Build Status must have a value from:\\n{}\".format(\", \".join(valid_statuses)))\n\n        self.obj['status'][key] = value\n        self.changes.append(\"Updating build:{}.status.{}={}\"\n                            .format(self.obj['name'], key, value))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef state(self, state):\n        state = state.lower()\n        if state not in valid_states:\n            raise ValueError(\"Build state must have a value from:\\n{}\".format(\", \".join(valid_state)))\n\n        self.obj['state'] = state\n        self.changes.append(\"Updating build:{}.state={}\"\n                            .format(self.obj['name'], state))\n        return self", "response": "Update the status of a build"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates any other attribute on the build object", "response": "def change(self, key, value):\n        \"\"\"Update any other attribute on the build object\"\"\"\n        self.obj[key] = value\n        self.changes.append(\"Updating build:{}.{}={}\"\n                            .format(self.obj['name'], key, value))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef release(self, lane, status, target=None, meta=None, svcs=None):\n\n        if target not in (None, 'current', 'future'):\n            raise ValueError(\"\\nError: Target must be None, 'current', or 'future'\\n\")\n\n        svcs, meta, lane = self._prep_for_release(lane, svcs=svcs, meta=meta)\n        when = time.time()\n\n        # loathe non-functional dictionaries in python\n        rel_data = meta.copy()\n        rel_data.update({\n            \"_time\": when,\n            \"status\": status,\n            \"services\": list(svcs.keys()),\n        })\n        rel_lane = self.obj.get('lanes', {}).get(lane, dict(log=[],status=status))\n        rel_lane['status'] = status\n        rel_lane['log'] = [rel_data] + rel_lane.get('log', [])\n\n        self.rcs.patch('build', self.name, {\n            \"lanes\": {\n                lane: rel_lane,\n            }\n        })\n\n        if target:\n            for svc in svcs:\n                rel_data = {target: self.name}\n\n            # if target is specified, then also update svc.release\n            #    {current/previous/future}\n            if target == \"current\":\n                mysvc = svcs[svc]\n                curver = mysvc.get('release', {}).get('current', '')\n                prev = []\n                if curver:\n                    prev = mysvc.get('release', {}).get('previous', [])\n                    if not prev or prev[0] != curver:\n                        prev = [curver] + prev\n                    while len(prev) > 5: # magic values FTW\n                        prev.pop() # only keep history of 5 previous\n                rel_data['previous'] = prev\n\n            self.rcs.patch('service', svc, {\n                \"release\": rel_data,\n                \"statuses\": {status: when},\n                \"status\": status\n            })", "response": "Set release information on a build"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npromoting a build so it is ready for an upper lane", "response": "def promote(self, lane, svcs=None, meta=None):\n        \"\"\"promote a build so it is ready for an upper lane\"\"\"\n\n        svcs, meta, lane = self._prep_for_release(lane, svcs=svcs, meta=meta)\n\n        # iterate and mark as future release\n        for svc in svcs:\n            self.changes.append(\"Promoting: {}.release.future={}\".format(svc, self.name))\n            self.rcs.patch('service', svc, {\n                \"release\": {\"future\": self.name}, # new way\n                \"statuses\": {\"future\": time.time()},\n            })\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_info(self, data):\n        for key in data:\n            # verboten\n            if key in ('status','state','name','id','application','services','release'):\n                raise ValueError(\"Sorry, cannot set build info with key of {}\".format(key))\n            self.obj[key] = data[key]\n        self.changes.append(\"Adding build info\")\n        return self", "response": "add info to a build"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate the value of the resource entry class attribute.", "response": "def validate_field(self, value):\n        '''\n        Method that must validate the value\n        It must return None if the value is valid and a error msg otherelse.\n        Ex: If expected input must be int, validate should a return a msg like\n        \"The filed must be a integer value\"\n        '''\n        if self.choices:\n            value = self.normalize_field(value)\n            if value in self.choices:\n                return None\n            return _('Must be one of: %(choices)s') % {'choices': '; '.join(self.choices)}\n        if self.default is not None:\n            if value is None or value == '':\n                value = self.default\n        if self.required and (value is None or value == ''):\n            return _('Required field')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nnormalize the value of a resource attribute.", "response": "def normalize_field(self, value):\n        \"\"\"\n        Method that must transform the value from string\n        Ex: if the expected type is int, it should return int(self._attr)\n\n        \"\"\"\n        if self.default is not None:\n            if value is None or value == '':\n                value = self.default\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef localize_field(self, value):\n        if self.default is not None:\n            if value is None or value == '':\n                value = self.default\n        return value or ''", "response": "Method that must transform the value from object to localized string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef collection_composition(collection, raw=False):\n\n    tc = ThriftClient()\n\n    body = {\"query\": {\"filtered\": {}}}\n\n    fltr = {}\n\n    query = {\n        \"query\": {\n            \"bool\": {\n                \"must\": [\n                    {\n                        \"match\": {\n                            \"collection\": collection\n                        }\n                    }\n                ]\n            }\n        }\n    }\n\n    body['query']['filtered'].update(fltr)\n    body['query']['filtered'].update(query)\n\n    query_parameters = [\n        ('size', '0'),\n        ('search_type', 'count')\n    ]\n\n    body['aggs'] = {\n        \"journals\": {\n            \"cardinality\": {\n                \"field\": \"issn\"\n            }\n        },\n        \"issues\": {\n            \"cardinality\": {\n                \"field\": \"issue\"\n            }\n        },\n        \"citations\": {\n            \"sum\": {\n                \"field\": \"citations\"\n            }\n        },\n        \"citable\": {\n            \"filter\": {\n                \"terms\": {\n                    \"document_type\": [i for i in utils.CITABLE_DOCUMENT_TYPES]\n                }\n            }\n        }\n    }\n\n    query_result = tc.search('article', json.dumps(body), query_parameters)\n\n    computed = _compute_collection_composition(query_result)\n\n    return query_result if raw else computed", "response": "This method returns the total of documents articles issues and bibliografic references of a given collection"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef journals_status(collection, raw=False):\n\n    tc = ThriftClient()\n\n    body = {\"query\": {\"filtered\": {}}}\n\n    fltr = {}\n\n    query = {\n        \"query\": {\n            \"bool\": {\n                \"must\": [\n                    {\n                        \"match\": {\n                            \"collection\": collection\n                        }\n                    }\n                ]\n            }\n        }\n    }\n\n    body['query']['filtered'].update(fltr)\n    body['query']['filtered'].update(query)\n\n    query_parameters = [\n        ('size', '0'),\n        ('search_type', 'count')\n    ]\n\n    body['aggs'] = {\n        \"status\": {\n            \"terms\": {\n                \"field\": \"status\"\n            }\n        }\n    }\n\n    query_result = tc.search('journal', json.dumps(body), query_parameters)\n\n    computed = _compute_journals_status(query_result)\n\n    return query_result if raw else computed", "response": "This method retrieve the total of documents articles issues and bibliografic references of a journal\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninputting ------ E: 1-D vector of energy bins [eV] E0: characteristic energy (scalar or vector) [eV] Q0: flux coefficient (scalar or vector) (to yield overall flux Q) output: ------- Phi: differential number flux Q: total flux Tanaka 2006 Eqn. 1 http://odin.gi.alaska.edu/lumm/Papers/Tanaka_2006JA011744.pdf", "response": "def maxwellian(E: np.ndarray, E0: np.ndarray, Q0: np.ndarray) -> Tuple[np.ndarray, float]:\n    \"\"\"\n    input:\n    ------\n    E: 1-D vector of energy bins [eV]\n    E0: characteristic energy (scalar or vector) [eV]\n    Q0: flux coefficient (scalar or vector) (to yield overall flux Q)\n\n    output:\n    -------\n    Phi: differential number flux\n    Q: total flux\n\n    Tanaka 2006 Eqn. 1\n    http://odin.gi.alaska.edu/lumm/Papers/Tanaka_2006JA011744.pdf\n    \"\"\"\n    E0 = np.atleast_1d(E0)\n    Q0 = np.atleast_1d(Q0)\n    assert E0.ndim == Q0.ndim == 1\n    assert (Q0.size == 1 or Q0.size == E0.size)\n\n    Phi = Q0/(2*pi*E0**3) * E[:, None] * np.exp(-E[:, None]/E0)\n\n    Q = np.trapz(Phi, E, axis=0)\n    logging.info('total maxwellian flux Q: ' + (' '.join('{:.1e}'.format(q) for q in Q)))\n    return Phi, Q"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hitail(E: np.ndarray, diffnumflux: np.ndarray, isimE0: np.ndarray, E0: np.ndarray,\n           Bhf: np.ndarray, bh: float, verbose: int = 0):\n    \"\"\"\n    strickland 1993 said 0.2, but 0.145 gives better match to peak flux at 2500 = E0\n    \"\"\"\n    Bh = np.empty_like(E0)\n    for iE0 in np.arange(E0.size):\n        Bh[iE0] = Bhf[iE0]*diffnumflux[isimE0[iE0], iE0]  # 4100.\n    # bh = 4                   #2.9\n    het = Bh*(E[:, None] / E0)**-bh\n    het[E[:, None] < E0] = 0.\n    if verbose > 0:\n        print('Bh: ' + (' '.join('{:0.1f}'.format(b) for b in Bh)))\n    return het", "response": "Compute the hitail of the given flux matrix E."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handler(self, path='/app'):\n    options = {\n      'path': path\n    }\n    project = builds.from_path(path)\n    print(project.get_export_path())", "response": "This is the main entry point for the apk file exporting process."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef handler(self, path='/app', ctx='all'):\n    options = {\n      'path': path\n    }\n    project = builds.from_path(path)\n    project.log(ctx=ctx)", "response": "This is the main entry point for the build log file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a JsonResponse. Make sure you have django installed first.", "response": "def json_response(data, status=200):\n    \"\"\"Return a JsonResponse. Make sure you have django installed first.\"\"\"\n    from django.http import JsonResponse\n    return JsonResponse(data=data, status=status, safe=isinstance(data, dict))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef error_response(message, status=400, code=None):\n    from django.http import JsonResponse\n    data = {'message': message}\n    if code:\n        data['code'] = code\n    LOG.error(\"Error response, status code is : {} | {}\".format(status, data))\n    return JsonResponse(data=data, status=status)", "response": "Return error message in dict"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_email_template(slug, base_url=None, context=None, user=None,\n                       to=None, cc=None, bcc=None, attachments=None, headers=None, connection=None, fail_silently=False):\n    \"\"\"\n    Shortcut to send an email template.\n    \"\"\"\n    email_template = EmailTemplate.objects.get_for_slug(slug)\n\n    email = email_template.get_email_message(\n        base_url, context, user,\n        to=to, cc=cc, bcc=bcc,\n        attachments=attachments, headers=headers, connection=connection\n    )\n\n    return email.send(fail_silently=fail_silently)", "response": "Shortcut to send an email template."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses an assignment line", "response": "def parse_assign(string):\n    \"\"\"Parse an assignment line:\n\n    >>> parse_assign(\"    scenario8.Actuator_MagazinVacuumOn = TRUE\")\n    (\"scenario8.Actuator_MagazinVacuumOn\", \"TRUE\")\n    \"\"\"\n    try:\n        a, b = string.split(\" = \")\n        return a.strip(), b.strip()\n    except:\n        print(\"Error with assignment: %s\" % string, file=sys.stderr)\n        return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads in a file and creates a trace object.", "response": "def from_file(filename):\n        \"\"\"Read in filename and creates a trace object.\n\n        :param filename: path to nu(x|s)mv output file\n        :type filename: str\n        :return:\n        \"\"\"\n        trace = Trace()\n        reached = False\n        with open(filename) as fp:\n            for line in fp.readlines():\n                if not reached and line.strip() == \"Trace Type: Counterexample\":\n                    reached = True\n                    continue\n                elif reached:\n                    trace.parse_line(line)\n            return trace"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetDate(text=None, selected=None, **kwargs):\n\n    args = ['--date-format=%d/%m/%Y']\n    if text:\n        args.append('--text=%s' % text)\n    if selected:\n        args.append('--day=%d' % selected.day)\n        args.append('--month=%d' % selected.month)\n        args.append('--year=%d' % selected.year)\n\n    for generic_args in kwargs_helper(kwargs):\n        args.append('--%s=%s' % generic_args)\n\n    p = run_zenity('--calendar', *args)\n\n    if p.wait() == 0:\n        retval = p.stdout.read().strip()\n        day, month, year = [int(x) for x in retval.split('/')]\n        return date(year, month, day)", "response": "Prompt the user for a date."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprompts the user for a filename.", "response": "def GetFilename(multiple=False, sep='|', **kwargs):\n    \"\"\"Prompt the user for a filename.\n    \n    This will raise a Zenity File Selection Dialog. It will return a list with \n    the selected files or None if the user hit cancel.\n    \n    multiple - True to allow the user to select multiple files.\n    sep - Token to use as the path separator when parsing Zenity's return \n          string.\n    kwargs - Optional command line parameters for Zenity such as height,\n             width, etc.\"\"\"\n\n    args = []\n    if multiple:\n        args.append('--multiple')\n    if sep != '|':\n        args.append('--separator=%s' % sep)\n    \n    for generic_args in kwargs_helper(kwargs):\n        args.append('--%s=%s' % generic_args)\n\n    p = run_zenity('--file-selection', *args)\n\n    if p.wait() == 0:\n        return p.stdout.read()[:-1].split('|')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetDirectory(multiple=False, selected=None, sep=None, **kwargs):\n\n    args = ['--directory']\n    if multiple:\n        args.append('--multiple')\n    if selected:\n        if not path.lexists(selected):\n            raise ValueError(\"File %s does not exist!\" % selected)\n        args.append('--filename=%s' % selected)\n    if sep:\n        args.append('--separator=%s' % sep)\n    \n    for generic_args in kwargs_helper(kwargs):\n        args.append('--%s=%s' % generic_args)\n\n    p = run_zenity('--file-selection', *args)\n\n    if p.wait() == 0:\n        return p.stdout.read().strip().split('|')", "response": "Prompt the user to select a directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprompts the user for a filename to save as.", "response": "def GetSavename(default=None, **kwargs):\n    \"\"\"Prompt the user for a filename to save as.\n    \n    This will raise a Zenity Save As Dialog.  It will return the name to save \n    a file as or None if the user hit cancel.\n    \n    default - The default name that should appear in the save as dialog.\n    kwargs - Optional command line parameters for Zenity such as height,\n             width, etc.\"\"\"\n\n    args = ['--save']\n    if default:\n        args.append('--filename=%s' % default)\n    \n    for generic_args in kwargs_helper(kwargs):\n        args.append('--%s=%s' % generic_args)\n\n    p = run_zenity('--file-selection', *args)\n\n    if p.wait() == 0:\n        return p.stdout.read().strip().split('|')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nputting an icon in the notification area. This will put an icon in the notification area and return when the user clicks on it. text - The tooltip that will show when the user hovers over it. window_icon - The stock icon (\"question\", \"info\", \"warning\", \"error\") or path to the icon to show. kwargs - Optional command line parameters for Zenity such as height, width, etc.", "response": "def Notification(text=None, window_icon=None, **kwargs):\n    \"\"\"Put an icon in the notification area.\n    \n    This will put an icon in the notification area and return when the user\n    clicks on it.\n    \n    text - The tooltip that will show when the user hovers over it.\n    window_icon - The stock icon (\"question\", \"info\", \"warning\", \"error\") or \n                  path to the icon to show.\n    kwargs - Optional command line parameters for Zenity such as height,\n             width, etc.\"\"\"\n\n    args = []\n    if text:\n        args.append('--text=%s' % text)\n    if window_icon:\n        args.append('--window-icon=%s' % window_icon)\n    \n    for generic_args in kwargs_helper(kwargs):\n        args.append('--%s=%s' % generic_args)\n\n    p = run_zenity('--notification', *args)\n    p.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef List(column_names, title=None, boolstyle=None, editable=False, \n         select_col=None, sep='|', data=[], **kwargs):\n    \"\"\"Present a list of items to select.\n    \n    This will raise a Zenity List Dialog populated with the colomns and rows \n    specified and return either the cell or row that was selected or None if \n    the user hit cancel.\n    \n    column_names - A tuple or list containing the names of the columns.\n    title - The title of the dialog box.\n    boolstyle - Whether the first columns should be a bool option (\"checklist\",\n                \"radiolist\") or None if it should be a text field.\n    editable - True if the user can edit the cells.\n    select_col - The column number of the selected cell to return or \"ALL\" to \n                 return the entire row.\n    sep - Token to use as the row separator when parsing Zenity's return. \n          Cells should not contain this token.\n    data - A list or tuple of tuples that contain the cells in the row.  The \n           size of the row's tuple must be equal to the number of columns.\n    kwargs - Optional command line parameters for Zenity such as height,\n             width, etc.\"\"\"\n\n    args = []\n    for column in column_names:\n        args.append('--column=%s' % column)\n    \n    if title:\n        args.append('--title=%s' % title)\n    if boolstyle:\n        if not (boolstyle == 'checklist' or boolstyle == 'radiolist'):\n            raise ValueError('\"%s\" is not a proper boolean column style.'\n                             % boolstyle)\n        args.append('--' + boolstyle)\n    if editable:\n        args.append('--editable')\n    if select_col:\n        args.append('--print-column=%s' % select_col)\n    if sep != '|':\n        args.append('--separator=%s' % sep)\n    \n    for generic_args in kwargs_helper(kwargs):\n        args.append('--%s=%s' % generic_args)\n\n    for datum in chain(*data):\n        args.append(str(datum))\n    \n    p = run_zenity('--list', *args)\n\n    if p.wait() == 0:\n        return p.stdout.read().strip().split(sep)", "response": "Presents a list of items to select from a list of columns."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nshowing an error message dialog to the user.", "response": "def ErrorMessage(text, **kwargs):\n    \"\"\"Show an error message dialog to the user.\n    \n    This will raise a Zenity Error Dialog with a description of the error.\n    \n    text - A description of the error.\n    kwargs - Optional command line parameters for Zenity such as height,\n             width, etc.\"\"\"\n\n    args = ['--text=%s' % text]\n    for generic_args in kwargs_helper(kwargs):\n        args.append('--%s=%s' % generic_args)\n\n    run_zenity('--error', *args).wait()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshowing a Zenity Progress dialog to the user.", "response": "def Progress(text='', percentage=0, auto_close=False, pulsate=False, **kwargs):\n    \"\"\"Show a progress dialog to the user.\n    \n    This will raise a Zenity Progress Dialog.  It returns a callback that \n    accepts two arguments.  The first is a numeric value of the percent \n    complete.  The second is a message about the progress.\n\n    NOTE: This function sends the SIGHUP signal if the user hits the cancel \n          button.  You must connect to this signal if you do not want your \n          application to exit.\n    \n    text - The initial message about the progress.\n    percentage - The initial percentage to set the progress bar to.\n    auto_close - True if the dialog should close automatically if it reaches \n                 100%.\n    pulsate - True is the status should pulsate instead of progress.\n    kwargs - Optional command line parameters for Zenity such as height,\n             width, etc.\"\"\"\n\n    args = []\n    if text:\n        args.append('--text=%s' % text)\n    if percentage:\n        args.append('--percentage=%s' % percentage)\n    if auto_close:\n        args.append('--auto-close=%s' % auto_close)\n    if pulsate:\n        args.append('--pulsate=%s' % pulsate)\n\n    for generic_args in kwargs_helper(kwargs):\n        args.append('--%s=%s' % generic_args)\n\n    p = Popen([zen_exec, '--progress'] + args, stdin=PIPE, stdout=PIPE)\n\n    def update(percent, message=''):\n        if type(percent) == float:\n            percent = int(percent * 100)\n        p.stdin.write(str(percent) + '\\n')\n        if message:\n            p.stdin.write('# %s\\n' % message)\n        return p.returncode\n\n    return update"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetText(text='', entry_text='', password=False, **kwargs):\n\n    args = []\n    if text:\n        args.append('--text=%s' % text)\n    if entry_text:\n        args.append('--entry-text=%s' % entry_text)\n    if password:\n        args.append('--hide-text')\n\n    for generic_args in kwargs_helper(kwargs):\n        args.append('--%s=%s' % generic_args)\n\n    p = run_zenity('--entry', *args)\n\n    if p.wait() == 0:\n        return p.stdout.read()[:-1]", "response": "This function will ask the user for some text from the user. It will raise a Zenity Text Entry Dialog."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef TextInfo(filename=None, editable=False, **kwargs):\n\n    args = []\n    if filename:\n        args.append('--filename=%s' % filename)\n    if editable:\n        args.append('--editable')\n\n    for generic_args in kwargs_helper(kwargs):\n        args.append('--%s=%s' % generic_args)\n\n    p = run_zenity('--text-info', *args)\n\n    if p.wait() == 0:\n        return p.stdout.read()", "response": "Show the contents of a file to the user with \n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the name of the version control backend at given location.", "response": "def get_backend_name(self, location):\n        \"\"\"\n        Return the name of the version control backend if found at given\n        location, e.g. vcs.get_backend_name('/path/to/vcs/checkout')\n        \"\"\"\n        for vc_type in self._registry.values():\n            path = os.path.join(location, vc_type.dirname)\n            if os.path.exists(path):\n                return vc_type.name\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if a destination location is ready for a checkout or clone.", "response": "def check_destination(self, dest, url, rev_options, rev_display):\n        \"\"\"\n        Prepare a location to receive a checkout/clone.\n\n        Return True if the location is ready for (and requires) a\n        checkout/clone, False otherwise.\n        \"\"\"\n        checkout = True\n        prompt = False\n        if os.path.exists(dest):\n            checkout = False\n            if os.path.exists(os.path.join(dest, self.dirname)):\n                existing_url = self.get_url(dest)\n                if self.compare_urls(existing_url, url):\n                    logger.info('%s in %s exists, and has correct URL (%s)'\n                                % (self.repo_name.title(), display_path(dest), url))\n                    logger.notify('Updating %s %s%s'\n                                  % (display_path(dest), self.repo_name, rev_display))\n                    self.update(dest, rev_options)\n                else:\n                    logger.warn('%s %s in %s exists with URL %s'\n                                % (self.name, self.repo_name, display_path(dest), existing_url))\n                    prompt = ('(s)witch, (i)gnore, (w)ipe, (b)ackup ', ('s', 'i', 'w', 'b'))\n            else:\n                logger.warn('Directory %s already exists, and is not a %s %s.'\n                            % (dest, self.name, self.repo_name))\n                prompt = ('(i)gnore, (w)ipe, (b)ackup ', ('i', 'w', 'b'))\n        if prompt:\n            logger.warn('The plan is to install the %s repository %s'\n                        % (self.name, url))\n            response = ask('What to do?  %s' % prompt[0], prompt[1])\n\n            if response == 's':\n                logger.notify('Switching %s %s to %s%s'\n                              % (self.repo_name, display_path(dest), url, rev_display))\n                self.switch(dest, url, rev_options)\n            elif response == 'i':\n                # do nothing\n                pass\n            elif response == 'w':\n                logger.warn('Deleting %s' % display_path(dest))\n                rmtree(dest)\n                checkout = True\n            elif response == 'b':\n                dest_dir = backup_dir(dest)\n                logger.warn('Backing up %s to %s'\n                            % (display_path(dest), dest_dir))\n                shutil.move(dest, dest_dir)\n                checkout = True\n        return checkout"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(file_contents, file_name):\n\n    try:\n        yaml.load(file_contents)\n    except Exception:\n\n        _, exc_value, _ = sys.exc_info()\n        return(\"Cannot Parse: {file_name}: \\n {exc_value}\"\n               .format(file_name=file_name, exc_value=exc_value))", "response": "Parses a list of filenames and their paths of expected yaml files and returns a dictionary of the names of the expected yaml files and the names of the expected yaml files."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets or create a record matching the instance.", "response": "def get_or_create(cls, **kwargs):\n        '''\n        If a record matching the instance already exists in the database, then\n        return it, otherwise create a new record.\n        '''\n        q = cls._get_instance(**kwargs)\n        if q:\n            return q\n        q = cls(**kwargs)\n        _action_and_commit(q, session.add)\n        return q"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the record with the given id.", "response": "def update(cls, **kwargs):\n        '''\n        If a record matching the instance id already exists in the database, \n        update it. If a record matching the instance id does not already exist,\n        create a new record.\n        '''\n        q = cls._get_instance(**{'id': kwargs['id']})\n        if q:\n            for k, v in kwargs.items():\n                setattr(q, k, v)\n            _action_and_commit(q, session.add)\n        else:\n            cls.get_or_create(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a record matching the instance id.", "response": "def delete(cls, **kwargs):\n        '''\n        If a record matching the instance id exists in the database, delete it.\n        '''\n        q = cls._get_instance(**kwargs)\n        if q:\n            _action_and_commit(q, session.delete)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_instance(self, **kwargs):\n        '''Return the first existing instance of the response record.\n        '''\n        return session.query(self.response_class).filter_by(**kwargs).first()", "response": "Return the first existing instance of the response record."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_or_create_from_legacy_response(self, response, **kwargs):\n        '''\n        If a record matching the instance already does not already exist in the\n        database, then create a new record.\n        '''\n        response_cls = self.response_class(**kwargs).get_or_create(**kwargs)\n        if not getattr(response_cls, self.column):\n            setattr(response_cls, self.column, self.accessor(response))\n            _action_and_commit(response_cls, session.add)", "response": "Get or create a record from a legacy response."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, response, **kwargs):\n        '''\n        If a record matching the instance already exists in the database, update\n        it, else create a new record.\n        '''\n        response_cls = self._get_instance(**kwargs)\n        if response_cls:\n            setattr(response_cls, self.column, self.accessor(response))\n            _action_and_commit(response_cls, session.add)\n        else:\n            self.get_or_create_from_legacy_response(response, **kwargs)", "response": "Update the record with the response."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self, response, **kwargs):\n        '''\n        If a record matching the instance id exists in the database, delete it.\n        '''\n        response_cls = self._get_instance(**kwargs)\n        if response_cls:\n            _action_and_commit(response_cls, session.delete)", "response": "Delete a record from the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_or_create_from_legacy_response(self, response, **kwargs):\n        '''\n        If a record matching the instance already does not already exist in the\n        database, then create a new record.\n        '''\n        response_cls = self.response_class(**kwargs).get_or_create(**kwargs)\n        if not getattr(response_cls, self.column):\n            setattr(response_cls, self.column, self.accessor(response))\n            _action_and_commit(response_cls, session.add)\n        if not getattr(response_cls, self.venue_column):\n            setattr(\n                response_cls, self.venue_column, self.venue_accessor(response))\n            _action_and_commit(response_cls, session.add)", "response": "Get or create a record from a legacy response."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update(self, response, **kwargs):\n        '''\n        If a record matching the instance already exists in the database, update\n        both the column and venue column attributes, else create a new record.\n        '''\n        response_cls = super(\n            LocationResponseClassLegacyAccessor, self)._get_instance(**kwargs)\n        if response_cls:\n            setattr(response_cls, self.column, self.accessor(response))\n            setattr(\n                response_cls, self.venue_column, self.venue_accessor(response))\n            _action_and_commit(response_cls, session.add)", "response": "Update the location record with the given response."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating ubuntu 16 source list", "response": "def update_source_list(self):\n        \"\"\"\n        update ubuntu 16 source list\n        :return: \n        \"\"\"\n        with cd('/etc/apt'):\n            sudo('mv sources.list sources.list.bak')\n            put(StringIO(bigdata_conf.ubuntu_source_list_16),\n                'sources.list', use_sudo=True)\n            sudo('apt-get update -y --fix-missing')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef common_install_nginx(self):\n        run('echo \"deb http://ppa.launchpad.net/nginx/stable/ubuntu $(lsb_release -sc) main\" | sudo tee /etc/apt/sources.list.d/nginx-stable.list')\n        sudo('apt-key adv --keyserver keyserver.ubuntu.com --recv-keys C300EE8C')\n        sudo('apt-get update -y')\n        sudo('apt-get install nginx -y')\n\n        print(green(' * Installed Nginx in the system.'))\n        print(green(' * Done'))\n        print()", "response": "Install Nginx in the system"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts nginx server from http to https", "response": "def common_config_nginx_ssl(self):\n        \"\"\"\n            Convert nginx server from http to https\n        \"\"\"\n        if prompt(red(' * Change url from http to https (y/n)?'), default='n') == 'y':\n            if not exists(self.nginx_ssl_dir):\n                sudo('mkdir -p {0}'.format(self.nginx_ssl_dir))\n\n            # generate ssh key\n            sudo('openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout {0}/cert.key -out {0}/cert.pem'.format(self.nginx_ssl_dir))\n\n            # do nginx config config\n            put(StringIO(self.nginx_web_ssl_config), '/etc/nginx/sites-available/default', use_sudo=True)\n\n            sudo('service nginx restart')\n\n            print(green(' * Make Nginx from http to https.'))\n            print(green(' * Done'))\n            print()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef common_install_apache2(self):\n        try:\n            sudo('apt-get install apache2 -y')\n        except Exception as e:\n            print(e)\n\n        print(green(' * Installed Apache2 in the system.'))\n        print(green(' * Done'))\n        print()", "response": "Install Apache2 web server"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef common_install_python_env(self):\n        sudo('apt-get install python3 python3-pip -y')\n        sudo('pip3 install virtualenv')\n\n        run('virtualenv {0}'.format(self.python_env_dir))\n\n        print(green(' * Installed Python3 virtual environment in the system.'))\n        print(green(' * Done'))\n        print()", "response": "Install Python virtual environment"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndownloading and install the Kafka archive", "response": "def kafka_install(self):\n        \"\"\"\n        kafka download and install\n        :return:\n        \"\"\"\n        with cd('/tmp'):\n            if not exists('kafka.tgz'):\n                sudo('wget {0} -O kafka.tgz'.format(\n                    bigdata_conf.kafka_download_url\n                ))\n\n            sudo('tar -zxf kafka.tgz')\n\n            sudo('rm -rf {0}'.format(bigdata_conf.kafka_home))\n            sudo('mv kafka_* {0}'.format(bigdata_conf.kafka_home))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninstalls logstash if logstash. deb is not present", "response": "def logstash_install(self):\n        \"\"\"\n        logstash install\n        :return:\n        \"\"\"\n        with cd('/tmp'):\n            if not exists('logstash.deb'):\n                sudo('wget {0} -O logstash.deb'.format(\n                    bigdata_conf.logstash_download_url\n                ))\n\n            sudo('dpkg -i logstash.deb')\n            sudo('apt-get install -y')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef kibana_install(self):\n        with cd('/tmp'):\n            if not exists('kibana.deb'):\n                sudo('wget {0} -O kibana.deb'.format(\n                    bigdata_conf.kibana_download_url\n                ))\n\n            sudo('dpkg -i kibana.deb')\n            sudo('apt-get install -y')", "response": "install kibana if it doesn t exist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconfiguring the kibana configuration file.", "response": "def kibana_config(self):\n        \"\"\"\n        config kibana\n        :return:\n        \"\"\"\n\n        uncomment(\"/etc/kibana/kibana.yml\", \"#server.host:\", use_sudo=True)\n        sed('/etc/kibana/kibana.yml', 'server.host:.*',\n            'server.host: \"{0}\"'.format(env.host_string), use_sudo=True)\n        sudo('systemctl stop kibana.service')\n        sudo('systemctl daemon-reload')\n        sudo('systemctl enable kibana.service')\n        sudo('systemctl start kibana.service')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef spark_install(self):\n        sudo('apt-get -y install build-essential python-dev python-six \\\n             python-virtualenv libcurl4-nss-dev libsasl2-dev libsasl2-modules \\\n             maven libapr1-dev libsvn-dev zlib1g-dev')\n\n        with cd('/tmp'):\n            if not exists('spark.tgz'):\n                sudo('wget {0} -O spark.tgz'.format(\n                    bigdata_conf.spark_download_url\n                ))\n\n            sudo('rm -rf spark-*')\n            sudo('tar -zxf spark.tgz')\n            sudo('rm -rf {0}'.format(bigdata_conf.spark_home))\n            sudo('mv spark-* {0}'.format(bigdata_conf.spark_home))", "response": "download and install spark"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reset_server_env(self, server_name, configure):\n        env.host_string = configure[server_name]['host']\n        env.user = configure[server_name]['user']\n        env.password = configure[server_name]['passwd']", "response": "reset server env to server - name\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd spark slave into spark - env. sh and spark - env. spark - env. spark - env. spark. hadoop. hadoop.", "response": "def add_spark_slave(self, master, slave, configure):\n        \"\"\"\n        add spark slave\n        :return:\n        \"\"\"\n        # go to master server, add config\n        self.reset_server_env(master, configure)\n        with cd(bigdata_conf.spark_home):\n            if not exists('conf/spark-env.sh'):\n                sudo('cp conf/spark-env.sh.template conf/spark-env.sh')\n\n            spark_env = bigdata_conf.spark_env.format(\n                spark_home=bigdata_conf.spark_home,\n                hadoop_home=bigdata_conf.hadoop_home,\n                host=env.host_string,\n                SPARK_WORKER_MEMORY=configure[master].get(\n                    'SPARK_WORKER_MEMORY', '512M'\n                )\n            )\n\n            put(StringIO(spark_env), 'conf/spark-env.sh', use_sudo=True)\n\n            if not exists('conf/slaves'):\n                sudo('cp conf/slaves.template conf/slaves')\n\n        # comment slaves localhost\n        comment('{0}/conf/slaves'.format(bigdata_conf.spark_home),\n                'localhost', use_sudo=True)\n\n        # add slave into config\n        append('{0}/conf/slaves'.format(bigdata_conf.spark_home),\n               '\\n{0}'.format(configure[slave]['host']), use_sudo=True)\n\n        run('scp -r {0} {1}@{2}:/opt'.format(\n            bigdata_conf.spark_home,\n            configure[slave]['user'],\n            configure[slave]['host']\n        ))\n\n        # go to slave server\n        self.reset_server_env(slave, configure)\n\n        append(bigdata_conf.global_env_home, 'export SPARK_LOCAL_IP={0}'.format(\n            configure[slave]['host']\n        ), use_sudo=True)\n        run('source {0}'.format(bigdata_conf.global_env_home))\n\n        # go to master server, restart server\n        self.reset_server_env(master, configure)\n        with cd(bigdata_conf.spark_home):\n            run('./sbin/stop-master.sh')\n            run('./sbin/stop-slaves.sh')\n            run('./sbin/start-master.sh')\n            run('./sbin/start-slaves.sh')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef new_tmp(self):\n\n        self.tmp_idx += 1\n        return p.join(self.tmp_dir, 'tmp_' + str(self.tmp_idx))", "response": "Create a new temporary file allocation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new backup file allocation", "response": "def new_backup(self, src):\n        \"\"\" Create a new backup file allocation \"\"\"\n\n        backup_id_file = p.join(self.backup_dir, '.bk_idx')\n        backup_num = file_or_default(backup_id_file, 1, int)\n        backup_name = str(backup_num) + \"_\" + os.path.basename(src)\n        backup_num += 1\n\n        file_put_contents(backup_id_file, str(backup_num))\n        return p.join(self.backup_dir, backup_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rollback(self):\n\n        # Close the journal for writing, if this is an automatic rollback following a crash,\n        # the file descriptor will not be open, so don't need to do anything.\n        if self.journal != None: self.journal.close()\n        self.journal = None\n\n        # Read the journal\n        journ_list = []\n        with open(self.j_file) as fle:\n            for l in fle: journ_list.append(json.loads(l))\n\n        journ_subtract = deque(reversed(journ_list))\n\n        for j_itm in reversed(journ_list):\n            try: self.do_action({'do' : j_itm}, False)\n            except IOError: pass\n\n            # As each item is completed remove it from the journal file, in case\n            # something fails during the rollback we can pick up where it stopped.\n            journ_subtract.popleft()\n            with open(self.j_file, 'w') as f:\n                for data in list(journ_subtract):\n                    f.write(json.dumps(data) + \"\\n\")\n                f.flush()\n\n        # Rollback is complete so delete the journal file\n        os.remove(self.j_file)", "response": "Do the rollback of the current journal."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the contents of the file located at path", "response": "def file_get_contents(self, path):\n        \"\"\" Returns contents of file located at 'path', not changing FS so does\n        not require journaling \"\"\"\n\n        with open(self.get_full_file_path(path), 'r') as f: return  f.read()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nput passed contents into file located at path.", "response": "def file_put_contents(self, path, data):\n        \"\"\" Put passed contents into file located at 'path' \"\"\"\n\n        path = self.get_full_file_path(path)\n\n        # if file exists, create a temp copy to allow rollback\n        if os.path.isfile(path):\n            tmp_path = self.new_tmp()\n            self.do_action({\n                'do'   : ['copy', path, tmp_path],\n                'undo' : ['move', tmp_path, path]})\n\n        self.do_action(\n            {'do'   : ['write', path, data],\n             'undo' : ['backup', path]})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef move_file(self, src, dst):\n\n        src = self.get_full_file_path(src); dst = self.get_full_file_path(dst)\n\n        # record where file moved\n        if os.path.isfile(src):\n            # if destination file exists, copy it to tmp first\n            if os.path.isfile(dst):\n                tmp_path = self.new_tmp()\n                self.do_action({\n                    'do'   : ['copy', dst, tmp_path],\n                    'undo' : ['move', tmp_path, dst]})\n\n        self.do_action(\n            {'do'   : ['move', src, dst],\n             'undo' : ['move', dst, src]})", "response": "Move file from src to dst"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds volume labels from filesystem and return in dict format.", "response": "def get_label_map(opts):\n    ''' Find volume labels from filesystem and return in dict format. '''\n    result = {}\n    try:  # get labels from filesystem\n        for entry in os.scandir(diskdir):\n            if entry.name.startswith('.'):\n                continue\n            if islink(entry.path):\n                target = os.readlink(entry.path)\n            else:\n                target = entry.path\n            result[target] = entry.name\n        if opts.debug:\n            print('\\n\\nlabel_map:', result)\n    except FileNotFoundError:\n        pass\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_diskinfo(opts, show_all=False, debug=False, local_only=False):\n    ''' Returns a list holding the current disk info,\n        stats divided by the ouptut unit.\n    '''\n    outunit = opts.outunit\n    disks = []\n    try:\n        label_map = get_label_map(opts)\n        lines = run(diskcmd).splitlines()[1:]   # dump header\n        for line in lines:\n            tokens  = line.split()\n            mntp = b' '.join(tokens[8:])\n            dev = basename(tokens[0])\n            disk = DiskInfo()\n            if (dev in devfilter) or (mntp in mntfilter):\n                if show_all:\n                    if dev == b'map':           # fix alignment :-/\n                        dev = tokens[0] = b'%b %b' % (dev, tokens[1])\n                        del tokens[1]\n                    disk.isram = True\n                else:\n                    continue\n\n            # convert to bytes as integer, then output units\n            disk.dev    = dev = dev.decode('ascii')\n            disk.ocap   = float(tokens[1]) * 1024\n            disk.cap    = disk.ocap / outunit\n            disk.free   = float(tokens[3]) * 1024 / outunit\n            disk.pcnt   = int(tokens[4][:-1])\n            disk.used   = float(tokens[2]) * 1024 / outunit\n\n            disk.mntp   = mntp.decode('utf8')\n            disk.label  = label_map.get(disk.mntp)\n            disk.ismntd = bool(disk.mntp)\n            disk.isnet  = ':' in dev  # cheesy but may work? (macos)\n            if local_only and disk.isnet:\n                continue\n            if disk.ismntd:\n                if disk.mntp == '/':\n                    disk.rw = True\n                else:\n                    disk.rw = os.access(disk.mntp, os.W_OK)\n\n            # ~ disk.isopt  = None  # TODO: not sure how to get these\n            # ~ disk.isrem  = None\n            disks.append(disk)\n    except IOError as err:\n        print(err)\n        return None\n\n    if opts.debug:\n        print()\n        for disk in disks:\n            print(disk.dev, disk)\n            print()\n    disks.sort()\n    return disks", "response": "Returns a list of the current disk info and the stats divided by the ouptut unit."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_meminfo(opts):\n    ''' Returns a dictionary holding the current memory info,\n        divided by the ouptut unit.  If mem info can't be read, returns None.\n        For Darwin / Mac OS X, interrogates the output of the sysctl and\n        vm_stat utilities rather than /proc/meminfo\n    '''\n    outunit = opts.outunit\n    meminfo = MemInfo()\n\n    sysinf = parse_sysctl(run(syscmd))\n    vmstat = parse_vmstat(run(vmscmd))\n    if opts.debug:\n        print('\\n')\n        print('sysinf', sysinf)\n        print('vmstat:', vmstat)\n        print()\n\n    # mem set\n    meminfo.memtotal = sysinf['hw.memsize'] / outunit\n    meminfo.memfree  = vmstat.free / outunit\n    meminfo.used     = (vmstat.wire + vmstat.active) / outunit\n    meminfo.cached   = (vmstat.inactive + vmstat.speculative) / outunit\n    meminfo.buffers  = 0  # TODO: investigate\n\n    # swap set\n    swaptotal, swapused, swapfree = sysinf['vm.swapusage']\n    meminfo.swaptotal = swaptotal / outunit\n    meminfo.swapused  = swapused  / outunit\n    meminfo.swapfree  = swapfree  / outunit\n    meminfo.swapcached = 0\n\n    # alternative to calculating used:\n    #~ meminfo.swapused = (meminfo.swaptotal - meminfo.swapcached -\n                        #~ meminfo.swapfree)\n    if opts.debug:\n        print('meminfo:', meminfo)\n    return meminfo", "response": "Returns a dictionary holding the current memory info and the current swap usage."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets base url from VK login page", "response": "def get_base_url(html: str) -> str:\n    \"\"\"\n    Search for login url from VK login page\n    \"\"\"\n    forms = BeautifulSoup(html, 'html.parser').find_all('form')\n    if not forms:\n        raise VVKBaseUrlException('Form for login not found')\n    elif len(forms) > 1:\n        raise VVKBaseUrlException('More than one login form found')\n    login_url = forms[0].get('action')\n    if not login_url:\n        raise VVKBaseUrlException('No action tag in form')\n    return login_url"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_page_for_warnings(html: str) -> None:\n    soup = BeautifulSoup(html, 'html.parser')\n    warnings = soup.find_all('div', {'class': 'service_msg_warning'})\n    if warnings:\n        exception_msg = '; '.join((warning.get_text() for warning in warnings))\n        raise VVKPageWarningException(exception_msg)", "response": "Checks if any warnings on page if so raises an exception otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef result_to_dict(res):\n    keys = res.keys()\n    return [dict(itertools.izip(keys, row)) for row in res]", "response": "Converts a sqlalchemy. engine. ResultProxy to a list of dicts where each dict represents a row in the query where the key \\\n    is the column name and the value \\\n    is the value of that column."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a bind processor for a given column type and dialect.", "response": "def get_bind_processor(column_type, dialect):\n    \"\"\"\n    Returns a bind processor for a column type and dialect, with special handling\n    for JSON/JSONB column types to return dictionaries instead of serialized JSON strings.\n\n    NOTE: This is a workaround for https://github.com/NerdWalletOSS/savage/issues/8\n\n    :param column_type: :py:class:`~sqlalchemy.sql.type_api.TypeEngine`\n    :param dialect: :py:class:`~sqlalchemy.engine.interfaces.Dialect`\n    :return: bind processor for given column type and dialect\n    \"\"\"\n    if column_type.compile(dialect) not in {'JSON', 'JSONB'}:\n        # For non-JSON/JSONB column types, return the column type's bind processor\n        return column_type.bind_processor(dialect)\n\n    if type(column_type) in {JSON, JSONB}:\n        # For bare JSON/JSONB types, we simply skip bind processing altogether\n        return None\n    elif isinstance(column_type, TypeDecorator) and column_type._has_bind_processor:\n        # For decorated JSON/JSONB types, we return the custom bind processor (if any)\n        return partial(column_type.process_bind_param, dialect=dialect)\n    else:\n        # For all other cases, we fall back to deserializing the result of the bind processor\n        def wrapped_bind_processor(value):\n            json_deserializer = dialect._json_deserializer or json.loads\n            return json_deserializer(column_type.bind_processor(dialect)(value))\n        return wrapped_bind_processor"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the value of the column attribute col_name on the row.", "response": "def get_column_attribute(row, col_name, use_dirty=True, dialect=None):\n    \"\"\"\n    :param row: the row object\n    :param col_name: the column name\n    :param use_dirty: whether to return the dirty value of the column\n    :param dialect: if not None, should be a :py:class:`~sqlalchemy.engine.interfaces.Dialect`. If \\\n    specified, this function will process the column attribute into the dialect type before \\\n    returning it; useful if one is using user defined column types in their mappers.\n\n    :return: if :any:`use_dirty`, this will return the value of col_name on the row before it was \\\n    changed; else this will return getattr(row, col_name)\n    \"\"\"\n    def identity(x):\n        return x\n\n    bind_processor = None\n    if dialect:\n        column_type = getattr(type(row), col_name).type\n        bind_processor = get_bind_processor(column_type, dialect)\n    bind_processor = bind_processor or identity\n    current_value = bind_processor(getattr(row, col_name))\n    if use_dirty:\n        return current_value\n\n    hist = getattr(inspect(row).attrs, col_name).history\n    if not hist.has_changes():\n        return current_value\n    elif hist.deleted:\n        return bind_processor(hist.deleted[0])\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a generator of tuples k c such that k is the name of the python attribute for the column and c is the name of the column in the sql table.", "response": "def get_column_keys_and_names(table):\n    \"\"\"\n    Return a generator of tuples k, c such that k is the name of the python attribute for\n    the column and c is the name of the column in the sql table.\n    \"\"\"\n    ins = inspect(table)\n    return ((k, c.name) for k, c in ins.mapper.c.items())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the given columns are part of a unique constraint on the given model.", "response": "def has_constraint(model, engine, *col_names):  # pragma: no cover\n    \"\"\"\n    :param model: model class to check\n    :param engine: SQLAlchemy engine\n    :param col_names: the name of columns which the unique constraint should contain\n\n    :rtype: bool\n    :return: True if the given columns are part of a unique constraint on model\n    \"\"\"\n    table_name = model.__tablename__\n    if engine.dialect.has_table(engine, table_name):\n        # Use SQLAlchemy reflection to determine unique constraints\n        insp = Inspector.from_engine(engine)\n        constraints = itertools.chain(\n            (sorted(x['column_names']) for x in insp.get_unique_constraints(table_name)),\n            sorted(insp.get_pk_constraint(table_name)['constrained_columns']),\n        )\n        return sorted(col_names) in constraints\n    else:\n        # Needed to validate test models pre-creation\n        constrained_cols = set()\n        for arg in getattr(model, '__table_args__', []):\n            if isinstance(arg, UniqueConstraint):\n                constrained_cols.update([c.name for c in arg.columns])\n        for c in model.__table__.columns:\n            if c.primary_key or c.unique:\n                constrained_cols.add(c.name)\n        return constrained_cols.issuperset(col_names)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if any of the columns in the row have been modified False otherwise.", "response": "def is_modified(row, dialect):\n    \"\"\"\n    Has the row data been modified?\n\n    This method inspects the row, and iterates over all columns looking for changes\n    to the (processed) data, skipping over unmodified columns.\n\n    :param row: SQLAlchemy model instance\n    :param dialect: :py:class:`~sqlalchemy.engine.interfaces.Dialect`\n    :return: True if any columns were modified, else False\n    \"\"\"\n    ins = inspect(row)\n    modified_cols = set(get_column_keys(ins.mapper)) - ins.unmodified\n    for col_name in modified_cols:\n        current_value = get_column_attribute(row, col_name, dialect=dialect)\n        previous_value = get_column_attribute(row, col_name, use_dirty=False, dialect=dialect)\n        if previous_value != current_value:\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering logging functions to this module.", "response": "def registerLoggers(info, error, debug):\n    \"\"\"\n    Add logging functions to this module.\n\n    Functions will be called on various severities (log, error, or debug\n    respectively).\n\n    Each function must have the signature:\n        fn(message, **kwargs)\n\n    If Python str.format()-style placeholders are in message, kwargs will be\n    interpolated.\n    \"\"\"\n    global log_info\n    global log_error\n    global log_debug\n\n    log_info = info\n    log_error = error\n    log_debug = debug"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing the reactor to run a process in the background.", "response": "def background(cl, proto=EchoProcess, **kw):\n    \"\"\"\n    Use the reactor to run a process in the background.\n\n    Keep the pid around.\n\n    ``proto'' may be any callable which returns an instance of ProcessProtocol\n    \"\"\"\n    if isinstance(cl, basestring):\n        cl = shlex.split(cl)\n\n    if not cl[0].startswith('/'):\n        path = which(cl[0])\n        assert path, '%s not found' % cl[0]\n        cl[0] = path[0]\n\n    d = Deferred()\n    proc = reactor.spawnProcess(\n            proto(name=basename(cl[0]), deferred=d),\n            cl[0],\n            cl,\n            env=os.environ,\n            **kw)\n\n    daycare.add(proc.pid)\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a standard run function that wraps an Options class", "response": "def runner(Options, buffering=True):\n    \"\"\"\n    Return a standard \"run\" function that wraps an Options class\n\n    If buffering=False, turn off stdout/stderr buffering for this process\n    \"\"\"\n    def run(argv=None):\n        if not buffering:\n            sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)\n            sys.stderr = os.fdopen(sys.stderr.fileno(), 'w', 0)\n\n        if argv is None:\n            argv = sys.argv\n        o = Options()\n        try:\n            o.parseOptions(argv[1:])\n        except usage.UsageError, e:\n            if hasattr(o, 'subOptions'):\n                print str(o.subOptions)\n            else:\n                print str(o)\n            print str(e)\n            return 1\n\n        return 0\n\n    return run"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef killall(self):\n        for pid in set(self):\n            try:\n                os.kill(pid, signal.SIGTERM)\n            except OSError, e: # pragma: nocover\n                if e.errno == errno.ESRCH:\n                    \"Process previously died on its own\"\n            self.remove(pid)", "response": "Kill all children of this process"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall when the process has ended.", "response": "def processEnded(self, reason):\n        \"\"\"\n        Connected process shut down\n        \"\"\"\n        log_debug(\"{name} process exited\", name=self.name)\n        if self.deferred:\n            if reason.type == ProcessDone:\n                self.deferred.callback(reason.value.exitCode)\n            elif reason.type == ProcessTerminated:\n                self.deferred.errback(reason)\n        return self.deferred"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall when an error is received from the system.", "response": "def errReceived(self, data):\n        \"\"\"\n        Connected process wrote to stderr\n        \"\"\"\n        lines = data.splitlines()\n        for line in lines:\n            log_error(\"*** {name} stderr *** {line}\", \n                    name=self.name,\n                    line=self.errFilter(line))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling data via stdout linewise.", "response": "def outLineReceived(self, line):\n        \"\"\"\n        Handle data via stdout linewise. This is useful if you turned off\n        buffering.\n\n        In your subclass, override this if you want to handle the line as a\n        protocol line in addition to logging it. (You may upcall this function\n        safely.)\n        \"\"\"\n        log_debug('<<< {name} stdout >>> {line}', \n                name=self.name,\n                line=self.outFilter(line))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites to both files .", "response": "def write(self, *a, **kw):\n        \"\"\"\n        Write to both files\n\n        If either one has an error, try writing the error to the other one.\n        \"\"\"\n        fl = None\n        try:\n            self.file1.write(*a, **kw)\n            self.file1.flush()\n        except IOError:\n            badFile, fl = 1, failure.Failure()\n\n        try:\n            self.file2.write(*a, **kw)\n            self.file2.flush()\n        except IOError:\n            badFile, fl = 2, failure.Failure()\n\n        if fl:\n            out = self.file2 if badFile == 1 else self.file1\n            out.write(str(fl) + '\\n')\n            out.flush()\n            fl.raiseException()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_item(self, item, spider):\n        '''\n        \u5c06\u4ece\u56fe\u7247\u5904\u7406\u7ba1\u9053\u6d41\u8fc7\u7684\u6570\u636e\u6a21\u578b\u4e2d\u7684\u7f29\u7565\u56fe\u94fe\u63a5\u66f4\u65b0\u5230\u6587\u7ae0\u4e2d\u7684\u76f8\u5e94\u56fe\u7247 URL \u4e0a\uff0c\n        \u5e76\u5bf9\u5176\u4e2d\u7684\uff0c\u5df2\u5220\u9664\u56fe\u7247 ``item['image_urls_removed']`` \u8fdb\u884c\u5904\u7406\uff0c\n        \u4f7f\u5176\u663e\u793a\u5185\u5efa\u7684\u5220\u9664\u56fe\u6807\u3002\n\n        \u6700\u7ec8\u4f7f\u7528\u6587\u7ae0\u6a21\u677f\uff0c\u5bf9\u6570\u636e\u6a21\u578b\u4e2d\u7684\u6570\u636e\u8fdb\u884c\u6e32\u67d3\u5e76\u8f93\u51fa\u5230\u6307\u5b9a\u8def\u5f84\u4e2d\uff0c\u5b8c\u6210\u672c\u5730\u5316\uff0c\n        \u7b49\u5f85\u6700\u7ec8 ``mobi`` \u6253\u5305\n\n        :param item: \u722c\u53d6\u5230\u7684\u6570\u636e\u6a21\u578b\n        :type item: :class:`.MoearPackageMobiItem` or dict\n        :param spider: \u5f53\u524d\u722c\u866b\u5bf9\u8c61\n        :type spider: :class:`.MobiSpider`\n        '''\n        soup = BeautifulSoup(item.get('content', ''), \"lxml\")\n        if item.get('images'):\n            # \u5c06content\u4e2d\u7684\u5168\u90e8img\u66ff\u6362\u4e3a\u672c\u5730\u5316\u540e\u7684url\n            img_list = soup.find_all('img')\n            for i in img_list:\n                img_src = i.get('src')\n\n                # \u5220\u9664image_urls_removed\u4e2d\u7684img\uff0c\u907f\u514d\u7531\u4e8e\u672a\u672c\u5730\u5316\u9020\u6210mobi\u751f\u6210\u5931\u8d25\n                if img_src in item.get('image_urls_removed', []):\n                    i['src'] = '../icons/delete.jpg'\n\n                for result in item.get('images', []):\n                    if img_src == result['url']:\n                        i['src'] = os.path.join('..', 'images', result['path'])\n                        spider._logger.debug(\n                            '\u6587\u7ae0({})\u7684\u6b63\u6587img\u4fdd\u5b58\u6210\u529f: {}'.format(\n                                item['title'], img_src))\n                        break\n\n            # \u586b\u5145toc_thumbnail\u8def\u5f84\u503c\n            for result in item['images']:\n                if item['cover_image'] == result['url']:\n                    item['toc_thumbnail'] = os.path.join(\n                        'images', result['path'])\n                    break\n\n        # \u8fc7\u6ee4\u6389\u4e0d\u652f\u6301\u7684\u6807\u7b7e\n        unsupport_tag = spider.options.get('kindlegen_unsupport_tag', [])\n        for tag in unsupport_tag:\n            for i in soup.find_all(tag):\n                delete_img = soup.new_tag('img')\n                delete_img['src'] = '../icons/delete.jpg'\n                i.replace_with(delete_img)\n\n        item['content'] = str(soup.div)\n\n        # \u5c06item['content']\u4fdd\u5b58\u5230\u672c\u5730\n        article_html_name = hashlib.md5(to_bytes(item['url'])).hexdigest()\n        html_name = '{}.html'.format(article_html_name)\n        item['url_local'] = os.path.join('html', html_name)\n        page_store = os.path.join(spider.build_source_dir, item['url_local'])\n\n        # \u5c06item\u4e2d\u7684\u751f\u6210\u5b57\u6bb5\u6dfb\u52a0\u5230post\u4e2d\n        idx = 0\n        post = None\n        for section in spider.data.items():\n            for p in section[1]:\n                idx += 1\n                if p.get('origin_url') == item.get('url'):\n                    post = p\n                    p['idx'] = 'post_{:0>3}'.format(idx)\n                    p['playOrder'] = idx\n                    p['content'] = item.get('content')\n                    p['url_local'] = item.get('url_local')\n                    p['toc_thumbnail'] = item.get('toc_thumbnail')\n\n                    # \u82e5\u4e3a\u6700\u540e\u4e00\u7bc7\u6587\u7ae0\uff0c\u5219\u6dfb\u52a0\u76f8\u5e94\u6807\u5fd7\n                    if idx == spider.post_num:\n                        spider._logger.info(\n                            '\u6807\u8bb0\u4e3a\u6700\u540e\u4e00\u7bc7\u6587\u7ae0: {}'.format(p.get('title')))\n                        p['last_one'] = True\n                    break\n\n        # \u521b\u5efa\u76ee\u6807dirname\n        dirname = os.path.dirname(page_store)\n        if not os.path.exists(dirname):\n            os.makedirs(dirname)\n\n        # \u57fa\u4e8e\u9884\u8bbe\u6a21\u677f\uff0c\u5c06\u6587\u7ae0\u6b63\u6587\u672c\u5730\u5316\n        with codecs.open(page_store, 'wb', 'utf-8') as fh:\n            fh.write(spider.template_post.render(\n                post=post,\n                options=spider.options))\n\n        # \u4e3a\u4f18\u5316log\u6253\u5370\u4fe1\u606f\uff0c\u6e05\u7a7a\u5df2\u5904\u7406\u8fc7\u7684\u5b57\u6bb5\n        item.pop('content', '')\n        item.pop('image_urls', [])\n        item.pop('images', [])\n\n        return item", "response": "Process a single item."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_etree(\n    el, node=None, node_cls=None,\n    tagsub=functools.partial(re.sub, r'\\{.+?\\}', ''),\n    Node=Node):\n    '''Convert the element tree to a tater tree.\n    '''\n    node_cls = node_cls or Node\n    if node is None:\n        node = node_cls()\n    tag = tagsub(el.tag)\n    attrib = dict((tagsub(k), v) for (k, v) in el.attrib.items())\n    node.update(attrib, tag=tag)\n\n    if el.text:\n        node['text'] = el.text\n    for child in el:\n        child = from_etree(child, node_cls=node_cls)\n        node.append(child)\n    if el.tail:\n        node['tail'] = el.tail\n    return node", "response": "Convert the element tree to a tater tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_dict(cls, raw_data, **kwargs):\n        instance = cls()\n        instance.populate(raw_data, **kwargs)\n        instance.validate(**kwargs)\n        return instance", "response": "This factory for Model objects creates a Model from a dict object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef secure(view):\n    auth_decorator = import_class(settings.AUTH_DECORATOR)\n    return (\n        view if project_settings.DEBUG\n        else method_decorator(auth_decorator, name='dispatch')(view)\n    )", "response": "This is a secure version of the Django view that is secure."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the name of the file that was opened and accepted.", "response": "def getOpenFileName(*args):\r\n        \"\"\"\r\n        Normalizes the getOpenFileName method between the different Qt\r\n        wrappers.\r\n        \r\n        :return     (<str> filename, <bool> accepted)\r\n        \"\"\"\r\n        result = QtGui.QFileDialog.getOpenFileName(*args)\r\n        \r\n        # PyQt4 returns just a string\r\n        if type(result) is not tuple:\r\n            return result, bool(result)\r\n        \r\n        # PySide returns a tuple of str, bool\r\n        else:\r\n            return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a tuple of the filename and accepted flags", "response": "def getDirectory(*args):\r\n        \"\"\"\r\n        Normalizes the getDirectory method between the different Qt\r\n        wrappers.\r\n        \r\n        :return     (<str> filename, <bool> accepted)\r\n        \"\"\"\r\n        result = QtGui.QFileDialog.getDirectory(*args)\r\n        \r\n        # PyQt4 returns just a string\r\n        if type(result) is not tuple:\r\n            return result, bool(result)\r\n        \r\n        # PySide returns a tuple of str, bool\r\n        else:\r\n            return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getSaveFileName(*args):\r\n        result = QtGui.QFileDialog.getSaveFileName(*args)\r\n        \r\n        # PyQt4 returns just a string\r\n        if type(result) is not tuple:\r\n            return result, bool(result)\r\n        \r\n        # PySide returns a tuple of str, bool\r\n        else:\r\n            return result", "response": "Returns the name of the file that was saved."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a list of uwnetid. models. Category objects corresponding to the netid and category code.", "response": "def get_netid_categories(netid, category_codes):\n    \"\"\"\n    Return a list of uwnetid.models Category objects\n    corresponding to the netid and category code or list provided\n    \"\"\"\n    url = _netid_category_url(netid, category_codes)\n    response = get_resource(url)\n    return _json_to_categories(response)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the category for the given netid and category_code", "response": "def update_catagory(netid, category_code, status):\n    \"\"\"\n    Post a subscriptionfor the given netid\n    and category_code\n    \"\"\"\n    url = \"{0}/category\".format(url_version())\n    body = {\n        \"categoryCode\": category_code,\n        \"status\": status,\n        \"categoryList\": [{\"netid\": netid}]\n    }\n\n    response = post_resource(url, json.dumps(body))\n    return json.loads(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _netid_category_url(netid, category_codes):\n    return \"{0}/{1}/category/{2}\".format(\n        url_base(), netid,\n        (','.join([str(n) for n in category_codes])\n         if isinstance(category_codes, (list, tuple))\n         else category_codes))", "response": "Return UWNetId resource for provided netid and category_codes or list of category_codes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of Category objects from a JSON response body.", "response": "def _json_to_categories(response_body):\n    \"\"\"\n    Returns a list of Category objects\n    \"\"\"\n    data = json.loads(response_body)\n    categories = []\n    for category_data in data.get(\"categoryList\", []):\n        categories.append(Category().from_json(\n            data.get('uwNetID'), category_data))\n\n    return categories"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute a python code object in the given environment.", "response": "def exec_function(ast, globals_map):\n    \"\"\"Execute a python code object in the given environment.\n\n    Args:\n      globals_map: Dictionary to use as the globals context.\n    Returns:\n      locals_map: Dictionary of locals from the environment after execution.\n    \"\"\"\n    locals_map = globals_map\n    exec ast in globals_map, locals_map\n    return locals_map"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nactivate the given ParseContext.", "response": "def activate(ctx):\n        \"\"\"Activate the given ParseContext.\"\"\"\n        if hasattr(ctx, '_on_context_exit'):\n            raise ContextError(\n                'Context actions registered outside this '\n                'parse context are active')\n\n        try:\n            ParseContext._active.append(ctx)\n            ctx._on_context_exit = []\n            yield\n        finally:\n            for func, args, kwargs in ctx._on_context_exit:\n                func(*args, **kwargs)\n            del ctx._on_context_exit\n            ParseContext._active.pop()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(self, **global_args):\n\n        if self.build_file not in ParseContext._parsed:\n            # http://en.wikipedia.org/wiki/Abstract_syntax_tree\n            # http://martinfowler.com/books/dsl.html\n            butcher_context = {}\n            for str_to_exec in self._strs_to_exec:\n                ast = compile(str_to_exec, '<string>', 'exec')\n                exec_function(ast, butcher_context)\n\n            with ParseContext.activate(self):\n                startdir = os.path.abspath(os.curdir)\n                try:\n                    os.chdir(self.build_file.path_on_disk)\n                    if self.build_file not in ParseContext._parsed:\n                        ParseContext._parsed.add(self.build_file)\n                        eval_globals = copy.copy(butcher_context)\n                        eval_globals.update(\n                            {'ROOT_DIR': self.build_file.path_on_disk,\n                             '__file__': 'bogus please fix this'})\n                        eval_globals.update(global_args)\n                        exec_function(self.build_file.code, eval_globals)\n                finally:\n                    os.chdir(startdir)", "response": "Entry point to parse a BUILD file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef instantiate_client(self, config):\n        modules = config.module.split('.')\n        class_name = modules.pop()\n        module_path = '.'.join(modules)\n\n        client_instance = getattr(\n            __import__(module_path, {}, {}, ['']),\n            class_name\n        )()\n\n        client_instance.add_config(config)\n\n        return client_instance", "response": "Instantiate the client class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_client(self, client):\n        if not isinstance(client, Client):\n            raise InvalidArgType()\n\n        if self.has_client(client.key):\n            return self\n\n        self[client.key] = client\n\n        return self", "response": "Adds the specified client to the manager."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_conf_file(argv: List[str]) -> bool:\n    parser = ArgumentParser(description=\"Generate SQL db_conf file template\")\n    parser.add_argument(\"-f\", \"--configfile\", help=\"File name to generate (Default: db_conf)\", metavar=\"Config File\",\n                        default=\"db_conf\")\n    opts = parser.parse_args(argv)\n    if os.path.exists(opts.configfile):\n        print(f\"{opts.configfile} already exists!\")\n        return False\n    with open(opts.configfile, 'w') as f:\n        f.write(conf_template)\n    print(f\"{opts.configfile} generated\")\n    return True", "response": "Generate a set of FHIR resources into their corresponding i2b2 counterparts."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute(self, *args, **kwargs)->[Any, None]:\n        return super().compute(\n            self.compose, *args, **kwargs\n        )", "response": "Compose and evaluate the function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new instance of the current chain.", "response": "def copy(self, klass=None):\n        \"\"\"Create a new instance of the current chain.\n        \"\"\"\n        chain = (\n            klass if klass else self.__class__\n        )(*self._args, **self._kwargs)\n        chain._tokens = self._tokens.copy()\n        return chain"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds args and kwargs to the tokens.", "response": "def call(self, tokens, *args, **kwargs):\n        \"\"\"Add args and kwargs to the tokens.\n        \"\"\"\n        tokens.append([evaluate, [args, kwargs], {}])\n        return tokens"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prefix(filename):\n    ''' strips common fMRI dataset suffixes from filenames '''\n    return os.path.split(re.sub(_afni_suffix_regex,\"\",str(filename)))[1]", "response": "strips common fMRI dataset suffixes from filenames"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a filenames with the given suffix inserted before the dataset suffix", "response": "def suffix(filename,suffix):\n    ''' returns a filenames with ``suffix`` inserted before the dataset suffix '''\n    return os.path.split(re.sub(_afni_suffix_regex,\"%s\\g<1>\" % suffix,str(filename)))[1]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef afni_copy(filename):\n    ''' creates a ``+orig`` copy of the given dataset and returns the filename as a string '''\n    if nl.pkg_available('afni',True):\n        afni_filename = \"%s+orig\" % nl.prefix(filename)\n        if not os.path.exists(afni_filename + \".HEAD\"):\n            nl.calc(filename,'a',prefix=nl.prefix(filename))\n        return afni_filename", "response": "creates a copy of the given dataset and returns the filename as a string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a. nii copy of the given dataset and returns the filename as a string", "response": "def nifti_copy(filename,prefix=None,gzip=True):\n    ''' creates a ``.nii`` copy of the given dataset and returns the filename as a string'''\n    # I know, my argument ``prefix`` clobbers the global method... but it makes my arguments look nice and clean\n    if prefix==None:\n        prefix = filename\n    nifti_filename = globals()['prefix'](prefix) + \".nii\"\n    if gzip:\n        nifti_filename += '.gz'\n    if not os.path.exists(nifti_filename):\n        try:\n            subprocess.check_call(['3dAFNItoNIFTI','-prefix',nifti_filename,str(filename)])\n        except subprocess.CalledProcessError:\n            nl.notify('Error: could not convert \"%s\" to NIFTI dset!' % filename,level=nl.level.error)\n            return None\n    return nifti_filename"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _dset_info_afni(dset):\n    ''' returns raw output from running ``3dinfo`` '''\n    info = DsetInfo()\n    try:\n        raw_info = subprocess.check_output(['3dinfo','-verb',str(dset)],stderr=subprocess.STDOUT)\n    except:\n        return None\n    if raw_info==None:\n        return None\n    # Subbrick info:\n    sub_pattern = r'At sub-brick #(\\d+) \\'([^\\']+)\\' datum type is (\\w+)(:\\s+(.*)\\s+to\\s+(.*))?\\n(.*statcode = (\\w+);  statpar = (.*)|)'\n    sub_info = re.findall(sub_pattern,raw_info)\n    for brick in sub_info:\n        brick_info = {\n            'index': int(brick[0]),\n            'label': brick[1],\n            'datum': brick[2]\n        }\n        if brick[3]!='':\n            brick_info.update({\n                'min': float(brick[4]),\n                'max': float(brick[5])\n            })\n        if brick[6]!='':\n            brick_info.update({\n                'stat': brick[7],\n                'params': brick[8].split()\n            })\n        info.subbricks.append(brick_info)\n    info.reps = len(info.subbricks)\n    # Dimensions:\n\n    orient = re.search('\\[-orient ([A-Z]+)\\]',raw_info)\n    if orient:\n        info.orient = orient.group(1)\n    for axis in ['RL','AP','IS']:\n        m = re.search(r'%s-to-%s extent:\\s+([0-9-.]+) \\[.\\] -to-\\s+([0-9-.]+) \\[.\\] -step-\\s+([0-9-.]+) mm \\[\\s*([0-9]+) voxels\\]' % (axis[0],axis[1]),raw_info)\n        if m:\n            info.spatial_from.append(float(m.group(1)))\n            info.spatial_to.append(float(m.group(2)))\n            info.voxel_size.append(float(m.group(3)))\n            info.voxel_dims.append(float(m.group(4)))\n    if len(info.voxel_size)==3:\n        info.voxel_volume = reduce(mul,info.voxel_size)\n\n    slice_timing = re.findall('-time:[tz][tz] \\d+ \\d+ [0-9.]+ (.*?) ',raw_info)\n    if len(slice_timing):\n        info.slice_timing = slice_timing[0]\n    TR = re.findall('Time step = ([0-9.]+)s',raw_info)\n    if len(TR):\n        info.TR = float(TR[0])\n\n    # Other info..\n    details_regex = {\n        'identifier': r'Identifier Code:\\s+(.*)',\n        'filetype': r'Storage Mode:\\s+(.*)',\n        'space': r'Template Space:\\s+(.*)'\n    }\n    for d in details_regex:\n        m = re.search(details_regex[d],raw_info)\n        if m:\n            setattr(info,d,m.group(1))\n\n    return info", "response": "returns raw output from running 3dinfo"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dset_info(dset):\n    '''returns a :class:`DsetInfo` object containing the meta-data from ``dset``'''\n    if nl.pkg_available('afni'):\n        return _dset_info_afni(dset)\n    nl.notify('Error: no packages available to get dset info',level=nl.level.error)\n    return None", "response": "returns a : class : DsetInfo object containing the meta - data from the given dset"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef subbrick(dset,label,coef=False,tstat=False,fstat=False,rstat=False,number_only=False):\n    ''' returns a string referencing the given subbrick within a dset\n\n    This method reads the header of the dataset ``dset``, finds the subbrick whose\n    label matches ``label`` and returns a string of type ``dataset[X]``, which can\n    be used by most AFNI programs to refer to a subbrick within a file\n\n    The options coef, tstat, fstat, and rstat will add the suffix that is\n    appended to the label by 3dDeconvolve\n\n    :coef:  \"#0_Coef\"\n    :tstat: \"#0_Tstat\"\n    :fstat: \"_Fstat\"\n    :rstat: \"_R^2\"\n\n    If ``coef`` or ``tstat`` are set to a number, it will use that parameter number\n    (instead of 0), for models that use multiple parameters (e.g., \"TENT\").\n\n    if ``number_only`` is set to ``True``, will only return the subbrick number instead of a string\n    '''\n\n    if coef is not False:\n        if coef is True:\n            coef = 0\n        label += \"#%d_Coef\" % coef\n    elif tstat != False:\n        if tstat==True:\n            tstat = 0\n        label += \"#%d_Tstat\" % tstat\n    elif fstat:\n        label += \"_Fstat\"\n    elif rstat:\n        label += \"_R^2\"\n\n    info = nl.dset_info(dset)\n    if info==None:\n        nl.notify('Error: Couldn\\'t get info from dset \"%s\"'%dset,level=nl.level.error)\n        return None\n    i = info.subbrick_labeled(label)\n    if number_only:\n        return i\n    return '%s[%d]' % (dset,i)", "response": "returns a string referencing the given subbrick within a file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dset_grids_equal(dsets):\n    '''Tests if each dataset in the ``list`` ``dsets`` has the same number of voxels and voxel-widths'''\n    infos = [dset_info(dset) for dset in dsets]\n    for i in xrange(3):\n        if len(set([x.voxel_size[i] for x in infos]))>1 or len(set([x.voxel_dims[i] for x in infos]))>1:\n            return False\n    return True", "response": "Tests if each dataset in the list dsets has the same number of voxels and voxel - widths"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ijk_to_xyz(dset,ijk):\n    '''convert the dset indices ``ijk`` to RAI coordinates ``xyz``'''\n    i = nl.dset_info(dset)\n    orient_codes = [int(x) for x in nl.run(['@AfniOrient2RAImap',i.orient]).output.split()]\n    orient_is = [abs(x)-1 for x in orient_codes]\n    rai = []\n    for rai_i in xrange(3):\n         ijk_i = orient_is[rai_i]\n         if orient_codes[rai_i] > 0:\n             rai.append(ijk[ijk_i]*i.voxel_size[rai_i] + i.spatial_from[rai_i])\n         else:\n             rai.append(i.spatial_to[rai_i] - ijk[ijk_i]*i.voxel_size[rai_i])\n    return rai", "response": "convert the dset indices ijk to RAI coordinates xyz"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bounding_box(dset):\n    '''return the coordinates (in RAI) of the corners of a box enclosing the data in ``dset``'''\n    o = nl.run([\"3dAutobox\",\"-input\",dset])\n    ijk_coords = re.findall(r'[xyz]=(\\d+)\\.\\.(\\d+)',o.output)\n    from_rai = ijk_to_xyz(dset,[float(x[0]) for x in ijk_coords])\n    to_rai = ijk_to_xyz(dset,[float(x[1]) for x in ijk_coords])\n    return (from_rai,to_rai)", "response": "return the coordinates of the corners of a box enclosing the data in dset"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef value_at_coord(dset,coords):\n    '''returns value at specified coordinate in ``dset``'''\n    return nl.numberize(nl.run(['3dmaskave','-q','-dbox'] + list(coords) + [dset],stderr=None).output)", "response": "returns value at specified coordinate in dset"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint the current set of activities for this Auto Scaling group.", "response": "def do_printActivities(self,args):\n        \"\"\"Print scaling activities\"\"\"\n        parser = CommandArgumentParser(\"printActivities\")\n        parser.add_argument('-r','--refresh',action='store_true',dest='refresh',help='refresh');\n        args = vars(parser.parse_args(args))\n        refresh = args['refresh'] or not self.activities\n\n        if refresh:\n            response = self.client.describe_scaling_activities(AutoScalingGroupName=self.scalingGroup)\n            self.activities = response['Activities']\n        \n        index = 0\n        for activity in self.activities:\n            print \"{}: {} -> {} {}: {}\".format(index,activity['StartTime'],stdplus.defaultifyDict(activity,'EndTime',''),activity['StatusCode'],activity['Description'])\n            index = index + 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_printActivity(self,args):\n        parser = CommandArgumentParser(\"printActivity\")\n        parser.add_argument(dest='index',type=int,help='refresh');\n        args = vars(parser.parse_args(args))\n        index = args['index']\n\n        activity = self.activities[index]\n        pprint(activity)", "response": "Print scaling activity details"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_printInstances(self,args):\n        parser = CommandArgumentParser(\"printInstances\")\n        parser.add_argument(dest='filters',nargs='*',default=[\"*\"],help='Filter instances');\n        parser.add_argument('-a','--addresses',action='store_true',dest='addresses',help='list all ip addresses');\n        parser.add_argument('-t','--tags',action='store_true',dest='tags',help='list all instance tags');\n        parser.add_argument('-d','--allDetails',action='store_true',dest='details',help='print all instance details');\n        parser.add_argument('-r','--refresh',action='store_true',dest='refresh',help='refresh');\n        parser.add_argument('-z','--zones',dest='availabilityZones',nargs='+',help='Only include specified availability zones');\n        args = vars(parser.parse_args(args))\n        \n        client = AwsConnectionFactory.getEc2Client()\n\n        filters = args['filters']\n        addresses = args['addresses']\n        tags = args['tags']\n        details = args['details']\n        availabilityZones = args['availabilityZones']\n        needDescription = addresses or tags or details\n\n        if args['refresh']:\n            self.scalingGroupDescription = self.client.describe_auto_scaling_groups(AutoScalingGroupNames=[self.scalingGroup])\n        \n        # print \"AutoScaling Group:{}\".format(self.scalingGroup)\n        print \"=== Instances ===\"\n        instances = self.scalingGroupDescription['AutoScalingGroups'][0]['Instances']\n\n        instances = filter( lambda x: fnmatches(x['InstanceId'],filters),instances)\n        if availabilityZones:\n            instances = filter( lambda x: fnmatches(x['AvailabilityZone'],availabilityZones),instances)\n        \n        index = 0\n        for instance in instances:\n            instance['index'] = index\n            print \"* {0:3d} {1} {2} {3}\".format(index,instance['HealthStatus'],instance['AvailabilityZone'],instance['InstanceId'])\n            description = None\n            if needDescription:\n                description = client.describe_instances(InstanceIds=[instance['InstanceId']])\n            if addresses:\n                networkInterfaces = description['Reservations'][0]['Instances'][0]['NetworkInterfaces']\n                number = 0\n                print \"      Network Interfaces:\"\n                for interface in networkInterfaces:\n                    print \"         * {0:3d} {1}\".format(number, interface['PrivateIpAddress'])\n                    number +=1\n            if tags:\n                tags = description['Reservations'][0]['Instances'][0]['Tags']\n                print \"      Tags:\"\n                for tag in tags:\n                    print \"        * {0} {1}\".format(tag['Key'],tag['Value'])\n            if details:\n                pprint(description)\n                \n            index += 1", "response": "Print the list of instances in this auto scaling group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting the autoscaling policy", "response": "def do_printPolicy(self,args):\n        \"\"\"Print the autoscaling policy\"\"\"\n        parser = CommandArgumentParser(\"printPolicy\")\n        args = vars(parser.parse_args(args))\n\n        policy = self.client.describe_policies(AutoScalingGroupName=self.scalingGroup)\n        pprint(policy)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the desired capacity of the Auto Scaling group", "response": "def do_setDesiredCapacity(self,args):\n        \"\"\"Set the desired capacity\"\"\"\n        parser = CommandArgumentParser(\"setDesiredCapacity\")\n        parser.add_argument(dest='value',type=int,help='new value');\n        args = vars(parser.parse_args(args))\n\n        value = int(args['value'])\n        print \"Setting desired capacity to {}\".format(value)\n        client = AwsConnectionFactory.getAsgClient()\n        client.set_desired_capacity(AutoScalingGroupName=self.scalingGroup,DesiredCapacity=value,HonorCooldown=True)\n        print \"Scaling activity in progress\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_run(self,args):\n        parser = CommandArgumentParser(\"run\")\n        parser.add_argument('-R','--replace-key',dest='replaceKey',default=False,action='store_true',help=\"Replace the host's key. This is useful when AWS recycles an IP address you've seen before.\")\n        parser.add_argument('-Y','--keyscan',dest='keyscan',default=False,action='store_true',help=\"Perform a keyscan to avoid having to say 'yes' for a new host. Implies -R.\")\n        parser.add_argument('-ii','--ignore-host-key',dest='ignore-host-key',default=False,action='store_true',help='Ignore host key')\n        parser.add_argument('-ne','--no-echo',dest='no-echo',default=False,action='store_true',help='Do not echo command')\n        parser.add_argument(dest='command',nargs='+',help=\"Command to run on all hosts.\") # consider adding a filter option later\n        parser.add_argument('-v',dest='verbosity',default=0,action=VAction,nargs='?',help='Verbosity. The more instances, the more verbose');        \n        parser.add_argument('-j',dest='jobs',type=int,default=1,help='Number of hosts to contact in parallel');\n        parser.add_argument('-s',dest='skip',type=int,default=0,help='Skip this many hosts');\n        parser.add_argument('-m',dest='macro',default=False,action='store_true',help='{command} is a series of macros to execute, not the actual command to run on the host');\n        args = vars(parser.parse_args(args))\n\n        replaceKey = args['replaceKey']\n        keyscan = args['keyscan']\n        verbosity = args['verbosity']\n        jobs = args['jobs']\n        skip = args['skip']\n        ignoreHostKey = args['ignore-host-key']\n        noEcho = args['no-echo']\n\n        instances = self.scalingGroupDescription['AutoScalingGroups'][0]['Instances']\n        instances = instances[skip:]\n        # if replaceKey or keyscan:\n        #     for instance in instances:\n        #         stdplus.resetKnownHost(instance)\n\n        if args['macro']:\n            if len(args['command']) > 1:\n                print(\"Only one macro may be specified with the -m switch.\")\n                return\n            else:\n                macro = args['command'][0]\n                print(\"Macro:{}\".format(macro))\n                command = Config.config['ssh-macros'][macro]\n        else:\n            command = ' '.join(args['command'])\n            \n        Parallel(n_jobs=jobs)(\n            delayed(ssh)(instance['InstanceId'],0,[],replaceKey,keyscan,False,verbosity,command,ignoreHostKey=ignoreHostKey,echoCommand=not noEcho,name=\"{}:{}: \".format(instance['index'],instance['InstanceId'])) for instance in instances\n        )", "response": "SSH to each instance in turn and run specified command"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_ssh(self,args):\n        parser = CommandArgumentParser(\"ssh\")\n        parser.add_argument(dest='instance',help='instance index or name');\n        parser.add_argument('-a','--address-number',default='0',dest='interface-number',help='instance id of the instance to ssh to');\n        parser.add_argument('-ii','--ignore-host-key',dest='ignore-host-key',default=False,action='store_true',help='Ignore host key')\n        parser.add_argument('-ne','--no-echo',dest='no-echo',default=False,action='store_true',help='Do not echo command')\n        parser.add_argument('-L',dest='forwarding',nargs='*',help=\"port forwarding string of the form: {localport}:{host-visible-to-instance}:{remoteport} or {port}\")\n        parser.add_argument('-R','--replace-key',dest='replaceKey',default=False,action='store_true',help=\"Replace the host's key. This is useful when AWS recycles an IP address you've seen before.\")\n        parser.add_argument('-Y','--keyscan',dest='keyscan',default=False,action='store_true',help=\"Perform a keyscan to avoid having to say 'yes' for a new host. Implies -R.\")\n        parser.add_argument('-B','--background',dest='background',default=False,action='store_true',help=\"Run in the background. (e.g., forward an ssh session and then do other stuff in aws-shell).\")\n        parser.add_argument('-v',dest='verbosity',default=0,action=VAction,nargs='?',help='Verbosity. The more instances, the more verbose');        \n        parser.add_argument('-m',dest='macro',default=False,action='store_true',help='{command} is a series of macros to execute, not the actual command to run on the host');\n        parser.add_argument(dest='command',nargs='*',help=\"Command to run on all hosts.\") # consider adding a filter option later\n        args = vars(parser.parse_args(args))\n\n        interfaceNumber = int(args['interface-number'])\n        forwarding = args['forwarding']\n        replaceKey = args['replaceKey']\n        keyscan = args['keyscan']\n        background = args['background']\n        verbosity = args['verbosity']\n        ignoreHostKey = args['ignore-host-key']\n        noEcho = args['no-echo']\n\n        # Figure out the host to connect to:\n        target = args['instance']\n        try:\n            index = int(args['instance'])\n            instances = self.scalingGroupDescription['AutoScalingGroups'][0]['Instances']\n            instance = instances[index]\n            target = instance['InstanceId']\n        except ValueError: # if args['instance'] is not an int, for example.\n            pass\n        \n        if args['macro']:\n            if len(args['command']) > 1:\n                print(\"Only one macro may be specified with the -m switch.\")\n                return\n            else:\n                macro = args['command'][0]\n                print(\"Macro:{}\".format(macro))\n                command = Config.config['ssh-macros'][macro]\n        else:\n            command = ' '.join(args['command'])\n            \n        ssh(target,interfaceNumber,forwarding,replaceKey,keyscan,background,verbosity,command,ignoreHostKey=ignoreHostKey,echoCommand = not noEcho)", "response": "SSH to an instance. ssh - h for detailed help"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nterminates an EC2 instance", "response": "def do_terminateInstance(self,args):\n        \"\"\"Terminate an EC2 instance\"\"\"\n        parser = CommandArgumentParser(\"terminateInstance\")\n        parser.add_argument(dest='instance',help='instance index or name');\n        args = vars(parser.parse_args(args))\n\n        instanceId = args['instance']\n        try:\n            index = int(instanceId)\n            instances = self.scalingGroupDescription['AutoScalingGroups'][0]['Instances']\n            instanceId = instances[index]\n        except ValueError:\n            pass\n\n        client = AwsConnectionFactory.getEc2Client()\n        client.terminate_instances(InstanceIds=[instanceId['InstanceId']])\n        self.do_printInstances(\"-r\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_updateCapacity(self,args):\n        parser = CommandArgumentParser(\"updateMinMax\")\n        parser.add_argument('-m','--min',dest='min',type=int,help='new values');\n        parser.add_argument('-M','--max',dest='max',type=int,help='new values');\n        parser.add_argument('-d','--desired',dest='desired',type=int,help='desired');\n        args = vars(parser.parse_args(args))\n\n        minSize = args['min']\n        maxSize = args['max']\n        desired = args['desired']\n        \n        print \"Setting desired capacity to {}-{}, {}\".format(minSize,maxSize,desired)\n        client = AwsConnectionFactory.getAsgClient()\n        client.update_auto_scaling_group(AutoScalingGroupName=self.scalingGroup,MinSize=minSize,MaxSize=maxSize,DesiredCapacity=desired)\n        #client.set_desired_capacity(AutoScalingGroupName=self.scalingGroup,DesiredCapacity=value,HonorCooldown=True)\n        print \"Scaling activity in progress\"", "response": "Update the desired capacity of the Auto Scaling group"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the appropriate functions in order :param sequencepath: path of folder containing FASTA genomes :param report: boolean to determine whether a report is to be created :param refseq_database: Path to reduced refseq database sketch :param num_threads: Number of threads to run mash/other stuff on :return: gc_dict, contig_dist_dict, longest_contig_dict, genome_length_dict, num_contigs_dict, n50_dict, n75_dict, \\ n90_dict, l50_dict, l75_dict, l90_dict, orf_dist_dict", "response": "def main(sequencepath, report, refseq_database, num_threads=12, start=time.time()):\n    \"\"\"\n    Run the appropriate functions in order\n    :param sequencepath: path of folder containing FASTA genomes\n    :param report: boolean to determine whether a report is to be created\n    :param refseq_database: Path to reduced refseq database sketch\n    :param num_threads: Number of threads to run mash/other stuff on\n    :return: gc_dict, contig_dist_dict, longest_contig_dict, genome_length_dict, num_contigs_dict, n50_dict, n75_dict, \\\n        n90_dict, l50_dict, l75_dict, l90_dict, orf_dist_dict\n    \"\"\"\n    files = find_files(sequencepath)\n    file_dict = filer(files)\n    printtime('Using MASH to determine genera of samples', start)\n    genus_dict = find_genus(file_dict, refseq_database, threads=num_threads)\n    file_records = fasta_records(file_dict)\n    printtime('Collecting basic quality metrics', start)\n    contig_len_dict, gc_dict = fasta_stats(file_dict, file_records)\n    contig_dist_dict = find_contig_distribution(contig_len_dict)\n    longest_contig_dict = find_largest_contig(contig_len_dict)\n    genome_length_dict = find_genome_length(contig_len_dict)\n    num_contigs_dict = find_num_contigs(contig_len_dict)\n    n50_dict = find_n50(contig_len_dict, genome_length_dict)\n    n75_dict = find_n75(contig_len_dict, genome_length_dict)\n    n90_dict = find_n90(contig_len_dict, genome_length_dict)\n    l50_dict = find_l50(contig_len_dict, genome_length_dict)\n    l75_dict = find_l75(contig_len_dict, genome_length_dict)\n    l90_dict = find_l90(contig_len_dict, genome_length_dict)\n    printtime('Using prodigal to calculate number of ORFs in each sample', start)\n    orf_file_dict = predict_orfs(file_dict, num_threads=num_threads)\n    orf_dist_dict = find_orf_distribution(orf_file_dict)\n    if report:\n        reporter(gc_dict, contig_dist_dict, longest_contig_dict, genome_length_dict, num_contigs_dict, n50_dict,\n                 n75_dict, n90_dict, l50_dict, l75_dict, l90_dict, orf_dist_dict, genus_dict, sequencepath)\n    printtime('Features extracted!', start)\n    return gc_dict, contig_dist_dict, longest_contig_dict, genome_length_dict, num_contigs_dict, n50_dict, n75_dict, \\\n        n90_dict, l50_dict, l75_dict, l90_dict, orf_dist_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_files(sequencepath):\n    # Create a sorted list of all the FASTA files in the sequence path\n    files = sorted(glob(os.path.join(sequencepath, '*.fa*')))\n    return files", "response": "Use glob to find all FASTA files in the provided sequence path"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a dictionary of all contig records for each FASTA file", "response": "def fasta_records(files):\n    \"\"\"\n    Use SeqIO to create dictionaries of all records for each FASTA file\n    :param files: dictionary of stain name: /sequencepath/strain_name.extension\n    :return: file_records: dictionary of all contig records for all strains\n    \"\"\"\n    # Initialise the dictionary\n    file_records = dict()\n    for file_name, fasta in files.items():\n        # Create a dictionary of records for each file\n        record_dict = SeqIO.to_dict(SeqIO.parse(fasta, \"fasta\"))\n        # Set the records dictionary as the value for file_records\n        file_records[file_name] = record_dict\n    return file_records"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nuse MASH to find the genus of each sample in a dictionary of fasta files.", "response": "def find_genus(files, database, threads=12):\n    \"\"\"\n    Uses MASH to find the genus of fasta files.\n    :param files: File dictionary returned by filer method.\n    :param database: Path to reduced refseq database sketch.\n    :param threads: Number of threads to run mash with.\n    :return: genus_dict: Dictionary of genus for each sample. Will return NA if genus could not be found.\n    \"\"\"\n    genus_dict = dict()\n    tmpdir = str(time.time()).split('.')[-1]\n    if not os.path.isdir(tmpdir):\n        os.makedirs(tmpdir)\n    for file_name, fasta in files.items():\n        mash.screen(database, fasta,\n                    threads=threads,\n                    w='',\n                    i=0.95,\n                    output_file=os.path.join(tmpdir, 'screen.tab'))\n        screen_output = mash.read_mash_screen(os.path.join(tmpdir, 'screen.tab'))\n        try:\n            os.remove(os.path.join(tmpdir, 'screen.tab'))\n        except IOError:\n            pass\n        try:\n            genus = screen_output[0].query_id.split('/')[-3]\n            if genus == 'Shigella':\n                genus = 'Escherichia'\n            genus_dict[file_name] = genus\n        except IndexError:\n            genus_dict[file_name] = 'NA'\n\n    shutil.rmtree(tmpdir)\n    return genus_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fasta_stats(files, records):\n    # Initialise dictionaries\n    contig_len_dict = dict()\n    gc_dict = dict()\n    for file_name in files:\n        # Initialise variables to store appropriate values parsed from contig records\n        contig_lengths = list()\n        fasta_sequence = str()\n        for contig, record in records[file_name].items():\n            # Append the length of the contig to the list\n            contig_lengths.append(len(record.seq))\n            # Add the contig sequence to the string\n            fasta_sequence += record.seq\n        # Set the reverse sorted (e.g. largest to smallest) list of contig sizes as the value\n        contig_len_dict[file_name] = sorted(contig_lengths, reverse=True)\n        # Calculate the GC% of the total genome sequence using GC - format to have two decimal places\n        gc_dict[file_name] = float('{:0.2f}'.format(GC(fasta_sequence)))\n    return contig_len_dict, gc_dict", "response": "Parse the lengths of all contigs for each sample and calculate the total GC% of all strains\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_contig_distribution(contig_lengths_dict):\n    # Initialise the dictionary\n    contig_len_dist_dict = dict()\n    for file_name, contig_lengths in contig_lengths_dict.items():\n        # Initialise integers to store the number of contigs that fall into the different bin sizes\n        over_1000000 = 0\n        over_500000 = 0\n        over_100000 = 0\n        over_50000 = 0\n        over_10000 = 0\n        over_5000 = 0\n        other = 0\n        for contig_length in contig_lengths:\n            # Depending on the size of the contig, increment the appropriate integer\n            if contig_length > 1000000:\n                over_1000000 += 1\n            elif contig_length > 500000:\n                over_500000 += 1\n            elif contig_length > 100000:\n                over_100000 += 1\n            elif contig_length > 50000:\n                over_50000 += 1\n            elif contig_length > 10000:\n                over_10000 += 1\n            elif contig_length > 5000:\n                over_5000 += 1\n            else:\n                other += 1\n        # Populate the dictionary with a tuple of each of the size range frequencies\n        contig_len_dist_dict[file_name] = (over_1000000,\n                                           over_500000,\n                                           over_100000,\n                                           over_50000,\n                                           over_10000,\n                                           over_5000,\n                                           other)\n    return contig_len_dist_dict", "response": "This function determines the frequency of different contig size ranges for each strain\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_largest_contig(contig_lengths_dict):\n    # Initialise the dictionary\n    longest_contig_dict = dict()\n    for file_name, contig_lengths in contig_lengths_dict.items():\n        # As the list is sorted in descending order, the largest contig is the first entry in the list\n        longest_contig_dict[file_name] = contig_lengths[0]\n    return longest_contig_dict", "response": "Determine the largest contig for each strain in the dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_genome_length(contig_lengths_dict):\n    # Initialise the dictionary\n    genome_length_dict = dict()\n    for file_name, contig_lengths in contig_lengths_dict.items():\n        # Use the sum() method to add all the contig lengths in the list\n        genome_length_dict[file_name] = sum(contig_lengths)\n    return genome_length_dict", "response": "This function calculates the total length of all the contigs for each strain in the dictionary"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_num_contigs(contig_lengths_dict):\n    # Initialise the dictionary\n    num_contigs_dict = dict()\n    for file_name, contig_lengths in contig_lengths_dict.items():\n        # Use the len() method to count the number of entries in the list\n        num_contigs_dict[file_name] = len(contig_lengths)\n    return num_contigs_dict", "response": "Count the total number of contigs for each strain\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the N50 for each strain in the dictionary", "response": "def find_n50(contig_lengths_dict, genome_length_dict):\n    \"\"\"\n    Calculate the N50 for each strain. N50 is defined as the largest contig such that at least half of the total\n    genome size is contained in contigs equal to or larger than this contig\n    :param contig_lengths_dict: dictionary of strain name: reverse-sorted list of all contig lengths\n    :param genome_length_dict: dictionary of strain name: total genome length\n    :return: n50_dict: dictionary of strain name: N50\n    \"\"\"\n    # Initialise the dictionary\n    n50_dict = dict()\n    for file_name, contig_lengths in contig_lengths_dict.items():\n        # Initialise a variable to store a running total of contig lengths\n        currentlength = 0\n        for contig_length in contig_lengths:\n            # Increment the current length with the length of the current contig\n            currentlength += contig_length\n            # If the current length is now greater than the total genome / 2, the current contig length is the N50\n            if currentlength >= genome_length_dict[file_name] * 0.5:\n                # Populate the dictionary, and break the loop\n                n50_dict[file_name] = contig_length\n                break\n    return n50_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the N75 for each strain in the dictionary", "response": "def find_n75(contig_lengths_dict, genome_length_dict):\n    \"\"\"\n    Calculate the N75 for each strain. N75 is defined as the largest contig such that at least 3/4 of the total\n    genome size is contained in contigs equal to or larger than this contig\n    :param contig_lengths_dict: dictionary of strain name: reverse-sorted list of all contig lengths\n    :param genome_length_dict: dictionary of strain name: total genome length\n    :return: n75_dict: dictionary of strain name: N75\n    \"\"\"\n    # Initialise the dictionary\n    n75_dict = dict()\n    for file_name, contig_lengths in contig_lengths_dict.items():\n        currentlength = 0\n        for contig_length in contig_lengths:\n            currentlength += contig_length\n            # If the current length is now greater than the 3/4 of the total genome length, the current contig length\n            # is the N75\n            if currentlength >= genome_length_dict[file_name] * 0.75:\n                n75_dict[file_name] = contig_length\n                break\n    return n75_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the N90 for each strain in the dictionary", "response": "def find_n90(contig_lengths_dict, genome_length_dict):\n    \"\"\"\n    Calculate the N90 for each strain. N90 is defined as the largest contig such that at least 9/10 of the total\n    genome size is contained in contigs equal to or larger than this contig\n    :param contig_lengths_dict: dictionary of strain name: reverse-sorted list of all contig lengths\n    :param genome_length_dict: dictionary of strain name: total genome length\n    :return: n75_dict: dictionary of strain name: N90\n    \"\"\"\n    # Initialise the dictionary\n    n90_dict = dict()\n    for file_name, contig_lengths in contig_lengths_dict.items():\n        currentlength = 0\n        for contig_length in contig_lengths:\n            currentlength += contig_length\n            # If the current length is now greater than the 3/4 of the total genome length, the current contig length\n            # is the N75\n            if currentlength >= genome_length_dict[file_name] * 0.95:\n                n90_dict[file_name] = contig_length\n                break\n    return n90_dict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_l50(contig_lengths_dict, genome_length_dict):\n    # Initialise the dictionary\n    l50_dict = dict()\n    for file_name, contig_lengths in contig_lengths_dict.items():\n        currentlength = 0\n        # Initialise a variable to count how many contigs have been added to the currentlength variable\n        currentcontig = 0\n        for contig_length in contig_lengths:\n            currentlength += contig_length\n            # Increment :currentcontig each time a contig is added to the current length\n            currentcontig += 1\n            # Same logic as with the N50, but the contig number is added instead of the length of the contig\n            if currentlength >= genome_length_dict[file_name] * 0.5:\n                l50_dict[file_name] = currentcontig\n                break\n    return l50_dict", "response": "Calculates the L50 for each strain in the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the L75 for each strain.", "response": "def find_l75(contig_lengths_dict, genome_length_dict):\n    \"\"\"\n    Calculate the L50 for each strain. L75 is defined as the number of contigs required to achieve the N75\n    :param contig_lengths_dict: dictionary of strain name: reverse-sorted list of all contig lengths\n    :param genome_length_dict: dictionary of strain name: total genome length\n    :return: l50_dict: dictionary of strain name: L75\n    \"\"\"\n    # Initialise the dictionary\n    l75_dict = dict()\n    for file_name, contig_lengths in contig_lengths_dict.items():\n        currentlength = 0\n        currentcontig = 0\n        for contig_length in contig_lengths:\n            currentlength += contig_length\n            currentcontig += 1\n            # Same logic as with the L75, but the contig number is added instead of the length of the contig\n            if currentlength >= genome_length_dict[file_name] * 0.75:\n                l75_dict[file_name] = currentcontig\n                break\n    return l75_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_l90(contig_lengths_dict, genome_length_dict):\n    # Initialise the dictionary\n    l90_dict = dict()\n    for file_name, contig_lengths in contig_lengths_dict.items():\n        currentlength = 0\n        # Initialise a variable to count how many contigs have been added to the currentlength variable\n        currentcontig = 0\n        for contig_length in contig_lengths:\n            currentlength += contig_length\n            # Increment :currentcontig each time a contig is added to the current length\n            currentcontig += 1\n            # Same logic as with the N50, but the contig number is added instead of the length of the contig\n            if currentlength >= genome_length_dict[file_name] * 0.9:\n                l90_dict[file_name] = currentcontig\n                break\n    return l90_dict", "response": "Calculates the L90 for each strain in the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nuse prodigal to predict the number of open reading frames in each strain", "response": "def predict_orfs(file_dict, num_threads=1):\n    \"\"\"\n    Use prodigal to predict the number of open reading frames (ORFs) in each strain\n    :param file_dict: dictionary of strain name: /sequencepath/strain_name.extension\n    :param num_threads: number of threads to use in the pool of prodigal processes\n    :return: orf_file_dict: dictionary of strain name: /sequencepath/prodigal results.sco\n    \"\"\"\n    # Initialise the dictionary\n    orf_file_dict = dict()\n    prodigallist = list()\n    for file_name, file_path in file_dict.items():\n        # Set the name of the output .sco results file\n        results = os.path.splitext(file_path)[0] + '.sco'\n        # Create the command for prodigal to execute - use sco output format\n        prodigal = ['prodigal', '-i', file_path, '-o', results,  '-f',  'sco']\n        # Only run prodigal if the output file doesn't already exist\n        if not os.path.isfile(results):\n            prodigallist.append(prodigal)\n        # Populate the dictionary with the name of the results file\n        orf_file_dict[file_name] = results\n    # Setup the multiprocessing pool.\n    pool = multiprocessing.Pool(processes=num_threads)\n    pool.map(run_prodigal, prodigallist)\n    pool.close()\n    pool.join()\n    return orf_file_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the prodigal outputs to determine the frequency of the ORF size ranges for each strain and return a dictionary of strain name to tuple of ORF size range distribution frequencies", "response": "def find_orf_distribution(orf_file_dict):\n    \"\"\"\n    Parse the prodigal outputs to determine the frequency of ORF size ranges for each strain\n    :param orf_file_dict: dictionary of strain name: /sequencepath/prodigal results.sco\n    :return: orf_dist_dict: dictionary of strain name: tuple of ORF size range distribution frequencies\n    \"\"\"\n    # Initialise the dictionary\n    orf_dist_dict = dict()\n    for file_name, orf_report in orf_file_dict.items():\n        # Initialise variable to store the frequency of the different ORF size ranges\n        total_orfs = 0\n        over_3000 = 0\n        over_1000 = 0\n        over_500 = 0\n        other = 0\n        # Open the strain-specific report\n        with open(orf_report, 'r') as orfreport:\n            for line in orfreport:\n                # The report has a header section that can be ignored - only parse lines beginning with '>'\n                if line.startswith('>'):\n                    # Split the line on '_' characters e.g. >1_345_920_- yields contig: >1, start: 345, stop: 920,\n                    # direction: -\n                    contig, start, stop, direction = line.split('_')\n                    # The size of the ORF is the end position minus the start position e.g. 920 - 345 = 575\n                    size = int(stop) - int(start)\n                    # Increment the total number of ORFs before binning based on ORF size\n                    total_orfs += 1\n                    # Increment the appropriate integer based on ORF size\n                    if size > 3000:\n                        over_3000 += 1\n                    elif size > 1000:\n                        over_1000 += 1\n                    elif size > 500:\n                        over_500 += 1\n                    else:\n                        other += 1\n        # Populate the dictionary with a tuple of the ORF size range frequencies\n        orf_dist_dict[file_name] = (total_orfs,\n                                    over_3000,\n                                    over_1000,\n                                    over_500,\n                                    other)\n        # Clean-up the prodigal reports\n        try:\n            os.remove(orf_report)\n        except IOError:\n            pass\n    return orf_dist_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a report of all the extracted features for a single strain.", "response": "def reporter(gc_dict, contig_dist_dict, longest_contig_dict, genome_length_dict, num_contigs_dict, n50_dict, n75_dict,\n             n90_dict, l50_dict, l75_dict, l90_dict, orf_dist_dict, genus_dict, sequencepath):\n    \"\"\"\n    Create a report of all the extracted features\n    :param gc_dict: dictionary of strain name: GC%\n    :param contig_dist_dict: dictionary of strain: tuple of contig distribution frequencies\n    :param longest_contig_dict: dictionary of strain name: longest contig\n    :param genome_length_dict: dictionary of strain name: total genome length\n    :param num_contigs_dict: dictionary of strain name: total number of contigs\n    :param n50_dict: dictionary of strain name: N50\n    :param n75_dict: dictionary of strain name: N75\n    :param n90_dict: dictionary of strain name: N90\n    :param l50_dict: dictionary of strain name: L50\n    :param l75_dict: dictionary of strain name: L75\n    :param l90_dict: dictionary of strain name: L90\n    :param orf_dist_dict: dictionary of strain name: tuple of ORF length frequencies\n    :param genus_dict: dictionary of strain name: genus\n    :param sequencepath: path of folder containing FASTA genomes\n    \"\"\"\n    # Initialise string with header information\n    data = 'SampleName,TotalLength,NumContigs,LongestContig,Contigs>1000000,Contigs>500000,Contigs>100000,' \\\n           'Contigs>50000,Contigs>10000,Contigs>5000,Contigs<5000,TotalORFs,ORFs>3000,ORFs>1000,ORFs>500,' \\\n           'ORFs<500,N50,N75,N90,L50,L75,L90,GC%,Genus\\n'\n    # Create and open the report for writign\n    with open(os.path.join(sequencepath, 'extracted_features.csv'), 'w') as feature_report:\n        for file_name in sorted(longest_contig_dict):\n            # Populate the data string with the appropriate values\n            data += '{name},{totlen},{numcontigs},{longestcontig},{over_106},{over_56},{over_105},{over_55},' \\\n                    '{over_104},{over_54},{under_54},{tORFS},{ORF33},{ORF13},{ORF52}, {ORF11},{n50},{n75},{n90},' \\\n                    '{l50},{l75},{l90},{gc},{genus}\\n'\\\n                .format(name=file_name,\n                        totlen=genome_length_dict[file_name],\n                        numcontigs=num_contigs_dict[file_name],\n                        longestcontig=longest_contig_dict[file_name],\n                        over_106=contig_dist_dict[file_name][0],\n                        over_56=contig_dist_dict[file_name][1],\n                        over_105=contig_dist_dict[file_name][2],\n                        over_55=contig_dist_dict[file_name][3],\n                        over_104=contig_dist_dict[file_name][4],\n                        over_54=contig_dist_dict[file_name][5],\n                        under_54=contig_dist_dict[file_name][6],\n                        tORFS=orf_dist_dict[file_name][0],\n                        ORF33=orf_dist_dict[file_name][1],\n                        ORF13=orf_dist_dict[file_name][2],\n                        ORF52=orf_dist_dict[file_name][3],\n                        ORF11=orf_dist_dict[file_name][4],\n                        n50=n50_dict[file_name],\n                        n75=n75_dict[file_name],\n                        n90=n90_dict[file_name],\n                        l50=l50_dict[file_name],\n                        l75=l75_dict[file_name],\n                        l90=l90_dict[file_name],\n                        gc=gc_dict[file_name],\n                        genus=genus_dict[file_name])\n        # Write the string to file\n        feature_report.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cli(sequencepath, report, refseq_database):\n    main(sequencepath, report, refseq_database, num_threads=multiprocessing.cpu_count())", "response": "This is the main function for the sequence extraction tool."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef grouplabelencode(data, mapping, nacode=None, nastate=False):\n    # What value is used for missing data?\n    if nastate:\n        if nacode is None:\n            nacode = len(mapping)\n\n    # Process depending on the data type of the data mapping variable\n    if isinstance(mapping, list):\n        m = mapping\n        e = range(len(mapping))\n    elif isinstance(mapping, dict):\n        m = list(mapping.values())\n        e = list(mapping.keys())\n    else:\n        raise Exception(\"'data' must be list-of-list or dict.\")\n\n    # Loop over 'data' array\n    return grouplabelencode_loop(data, m, e, nacode=nacode)", "response": "Encode data array with grouped labels."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_csv_col_headers(rows, row_headers_count_value=0):\n    count = 0\n\n    if rows:\n        for row in rows:\n            if exclude_empty_values(row[:row_headers_count_value]):\n                break\n            count += 1\n\n    if len(rows) == count:\n        count = 1  # by default\n\n    return [r[row_headers_count_value:] for r in rows[:count]]", "response": "Retrieve csv column headers"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npopulate csv rows headers when are empty extending the superior or upper headers.", "response": "def populate_csv_headers(rows,\n                         partial_headers,\n                         column_headers_count=1):\n    \"\"\"\n    Populate csv rows headers when are empty, extending the superior or\n    upper headers.\n    \"\"\"\n\n    result = [''] * (len(rows) - column_headers_count)\n\n    for i_index in range(0, len(partial_headers)):\n        for k_index in range(0, len(partial_headers[i_index])):\n\n            # missing field find for a value in upper rows\n            if not partial_headers[i_index][k_index] and i_index - 1 >= 0:\n\n                # TODO: It's necesary a for or only taking the\n                # inmediate latest row works well??\n                for t_index in range(i_index - 1, -1, -1):\n                    # TODO: could suposse that allways a value exists\n                    partial_value = partial_headers[t_index][k_index]\n                    if partial_value:\n                        partial_headers[i_index][k_index] = partial_value\n                        break\n\n        result[i_index] = \" \".join(map(str, partial_headers[i_index]))\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_row_headers(rows, row_headers_count_value=0, column_headers_count=1):\n    # TODO: REFACTOR ALGORITHM NEEDED\n    partial_headers = []\n\n    if row_headers_count_value:\n\n        # Take partial data\n        for k_index in range(0, len(rows) - column_headers_count):\n            header = rows[k_index + column_headers_count][\n                :row_headers_count_value]\n            partial_headers.append(remove_list_duplicates(force_list(header)))\n\n        # Populate headers\n        populated_headers = populate_csv_headers(\n            rows,\n            partial_headers,\n            column_headers_count)\n\n        return populated_headers", "response": "Return row headers.\n    Assume that by default it has one column header.\n    Assume that there is only one father row header."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef retrieve_csv_data(rows, row_header=0, column_header=0, limit_column=0):\n    return [row[row_header:limit_column] for row in rows[column_header:]]", "response": "Take the data from the rows."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the csv file to a list of rows.", "response": "def csv_tolist(path_to_file, **kwargs):\n    \"\"\"\n    Parse the csv file to a list of rows.\n    \"\"\"\n\n    result = []\n\n    encoding = kwargs.get('encoding', 'utf-8')\n    delimiter = kwargs.get('delimiter', ',')\n    dialect = kwargs.get('dialect', csv.excel)\n\n    _, _ext = path_to_file.split('.', 1)\n\n    try:\n\n        file = codecs.open(path_to_file, 'r', encoding)\n        items_file = io.TextIOWrapper(file, encoding=encoding)\n        result = list(\n            csv.reader(items_file, delimiter=delimiter, dialect=dialect))\n\n        items_file.close()\n        file.close()\n\n    except Exception as ex:\n        result = []\n        logger.error('Fail parsing csv to list of rows - {}'.format(ex))\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses an Excel file to a list of sheets and rows.", "response": "def excel_todictlist(path_to_file, **kwargs):\n    \"\"\"\n    Parse excel file to a dict list of sheets, rows.\n    \"\"\"\n    result = collections.OrderedDict()\n    encoding = kwargs.get('encoding', 'utf-8')\n    formatting_info = '.xlsx' not in path_to_file\n    count = 0\n\n    with xlrd.open_workbook(\n        path_to_file,\n        encoding_override=encoding, formatting_info=formatting_info) \\\n            as _excelfile:\n\n        for sheet_name_raw in _excelfile.sheet_names():\n\n            # if empty sheet name put sheet# as name\n            sheet_name = sheet_name_raw or \"sheet{}\".format(count)\n            result[sheet_name] = []\n\n            xl_sheet = _excelfile.sheet_by_name(sheet_name_raw)\n\n            for row_idx in range(0, xl_sheet.nrows):\n                col_data = []\n                for col_idx in range(0, xl_sheet.ncols):\n\n                    # Get cell object by row, col\n                    cell_obj = xl_sheet.cell(row_idx, col_idx)\n                    merged_info = is_merged(xl_sheet, row_idx, col_idx)\n\n                    # Search for value in merged_info\n                    if not cell_obj.value and merged_info:\n                        cell_obj = search_mergedcell_value(\n                            xl_sheet, merged_info[1])\n                        col_data.append(cell_obj.value if cell_obj else '')\n                    else:\n                        col_data.append(cell_obj.value)\n\n                result[sheet_name].append(col_data)\n\n            count += 1  # increase sheet counter\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches for a value in a merged cell.", "response": "def search_mergedcell_value(xl_sheet, merged_range):\n    \"\"\"\n    Search for a value in merged_range cells.\n    \"\"\"\n    for search_row_idx in range(merged_range[0], merged_range[1]):\n        for search_col_idx in range(merged_range[2], merged_range[3]):\n            if xl_sheet.cell(search_row_idx, search_col_idx).value:\n                return xl_sheet.cell(search_row_idx, search_col_idx)\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_merged(sheet, row, column):\n    for cell_range in sheet.merged_cells:\n        row_low, row_high, column_low, column_high = cell_range\n        if (row in range(row_low, row_high)) and \\\n                (column in range(column_low, column_high)):\n\n            # TODO: IS NECESARY THIS IF?\n            if ((column_high - column_low) < sheet.ncols - 1) and \\\n                    ((row_high - row_low) < sheet.nrows - 1):\n                return (True, cell_range)\n\n    return False", "response": "Check if a row column cell is a merged cell\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npopulating the list of headers with the values of the subheaders.", "response": "def populate_headers(headers):\n    \"\"\"\n    Concatenate headers with subheaders\n    \"\"\"\n    result = [''] * len(headers[0])\n    values = [''] * len(headers)\n    for k_index in range(0, len(headers)):\n        for i_index in range(0, len(headers[k_index])):\n            if headers[k_index][i_index]:\n                values[k_index] = normalizer(\n                    str(headers[k_index][i_index]))  # pass to str\n\n            if len(exclude_empty_values(result)) > i_index:\n                result[i_index] += \"-{}\".format(values[k_index])\n            else:\n                result[i_index] += str(values[k_index])\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlimits the rows to be a list of items.", "response": "def row_csv_limiter(rows, limits=None):\n    \"\"\"\n    Limit row passing a value or detect limits making the best effort.\n    \"\"\"\n\n    limits = [None, None] if limits is None else limits\n\n    if len(exclude_empty_values(limits)) == 2:\n        upper_limit = limits[0]\n        lower_limit = limits[1]\n    elif len(exclude_empty_values(limits)) == 1:\n        upper_limit = limits[0]\n        lower_limit = row_iter_limiter(rows, 1, -1, 1)\n    else:\n        upper_limit = row_iter_limiter(rows, 0, 1, 0)\n        lower_limit = row_iter_limiter(rows, 1, -1, 1)\n\n    return rows[upper_limit: lower_limit]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef csv_row_cleaner(rows):\n    result = []\n\n    for row in rows:\n\n        # check not empty row\n        check_empty = len(exclude_empty_values(row)) > 1\n\n        # check more or eq than 1 unique element in row\n        check_set = len(set(exclude_empty_values(row))) > 1\n        # check row not into result cleaned rows.\n        check_last_allready = (result and result[-1] == row)\n\n        if check_empty and check_set and not check_last_allready:\n            result.append(row)\n    return result", "response": "Clean a list of rows into a list of lists."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclean csv columns parsed omitting empty rows.", "response": "def csv_column_cleaner(rows):\n    \"\"\"\n    clean csv columns parsed omitting empty/dirty rows.\n    \"\"\"\n\n    # check columns if there was empty columns\n    result = [[] for x in range(0, len(rows))]\n    for i_index in range(0, len(rows[0])):\n\n        partial_values = []\n\n        for x_row in rows:\n            partial_values.append(\n                x_row[i_index] if len(x_row) > i_index else '')\n\n        colum_rows = exclude_empty_values(partial_values)\n\n        if len(colum_rows) > len(rows) / 5:  # adjust this value\n            for index in range(0, len(rows)):\n                result[index].append(\n                    rows[index][i_index] if len(rows[index]) > i_index else '')\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef csv_dict_format(csv_data, c_headers=None, r_headers=None):\n    # format dict if has row_headers\n    if r_headers:\n        result = {}\n        for k_index in range(0, len(csv_data)):\n            if r_headers[k_index]:\n                result[r_headers[k_index]] = collections.OrderedDict(\n                    zip(c_headers, csv_data[k_index]))\n\n    # format list if hasn't row_headers -- square csv\n    else:\n        result = []\n        for k_index in range(0, len(csv_data)):\n            result.append(\n                collections.OrderedDict(zip(c_headers, csv_data[k_index])))\n        result = [result]\n\n    return result", "response": "Format csv rows parsed to Dict.\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef csv_array_clean_format(csv_data, c_headers=None, r_headers=None):\n\n    result = []\n    real_num_header = len(force_list(r_headers[0])) if r_headers else 0\n    result.append([\"\"] * real_num_header + c_headers)\n\n    for k_index in range(0, len(csv_data)):\n\n        if r_headers:\n            result.append(\n                list(\n                    itertools.chain(\n                        [r_headers[k_index]],\n                        csv_data[k_index])))\n\n        else:\n            result.append(csv_data[k_index])\n\n    return result", "response": "Format csv rows parsed to Array clean format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting csv rows parsed to Dict or Array", "response": "def csv_format(csv_data, c_headers=None, r_headers=None, rows=None, **kwargs):\n    \"\"\"\n    Format csv rows parsed to Dict or Array\n    \"\"\"\n    result = None\n    c_headers = [] if c_headers is None else c_headers\n    r_headers = [] if r_headers is None else r_headers\n    rows = [] if rows is None else rows\n\n    result_format = kwargs.get('result_format', ARRAY_RAW_FORMAT)\n\n    # DICT FORMAT\n    if result_format == DICT_FORMAT:\n        result = csv_dict_format(csv_data, c_headers, r_headers)\n\n    # ARRAY_RAW_FORMAT\n    elif result_format == ARRAY_RAW_FORMAT:\n        result = rows\n\n    # ARRAY_CLEAN_FORMAT\n    elif result_format == ARRAY_CLEAN_FORMAT:\n        result = csv_array_clean_format(csv_data, c_headers, r_headers)\n\n    else:\n        result = None\n\n    # DEFAULT\n    if result and result_format < DICT_FORMAT:\n        result = [result]\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef csv_to_dict(csv_filepath, **kwargs):\n    callbacks = {'to_list': csv_tolist,\n                 'row_csv_limiter': row_csv_limiter,\n                 'csv_row_cleaner': csv_row_cleaner,\n                 'row_headers_count': row_headers_count,\n                 'get_col_header': get_csv_col_headers,\n                 'get_row_headers': get_row_headers,\n                 'populate_headers': populate_headers,\n                 'csv_column_header_cleaner': csv_column_header_cleaner,\n                 'csv_column_cleaner': csv_column_cleaner,\n                 'retrieve_csv_data': retrieve_csv_data}\n\n    callbacks.update(kwargs.get('alt_callbacks', {}))\n    rows = kwargs.get('rows', [])\n\n    if not rows:\n        # csv_tolist of rows\n        rows = callbacks.get('to_list')(csv_filepath, **kwargs)\n\n        if not rows:\n            msg = 'Empty rows obtained from {}'.format(csv_filepath)\n            logger.warning(msg)\n            raise ValueError(msg)\n\n    # apply limits\n    rows = callbacks.get('row_csv_limiter')(\n        rows, kwargs.get('limits', [None, None]))\n\n    # apply row cleaner\n    rows = callbacks.get('csv_row_cleaner')(rows)\n\n    # apply column cleaner\n    rows = callbacks.get('csv_column_cleaner')(rows)\n\n    # count raw headers\n    num_row_headers = callbacks.get('row_headers_count')(rows)\n\n    # take colum_headers\n    c_headers_raw = callbacks.get('get_col_header')(rows, num_row_headers)\n\n    # get row_headers\n    r_headers = callbacks.get('get_row_headers')(\n        rows, num_row_headers, len(c_headers_raw))\n\n    # format colum_headers\n    c_headers_dirty = callbacks.get('populate_headers')(\n        c_headers_raw) if len(c_headers_raw) > 1 else c_headers_raw[0]\n\n    # Clean csv column headers of empty values.\n    c_headers = callbacks.get('csv_column_header_cleaner')(c_headers_dirty)\n\n    # take data\n    csv_data = callbacks.get('retrieve_csv_data')(\n        rows,\n        column_header=len(c_headers_raw),\n        row_header=num_row_headers,\n        limit_column=len(c_headers) - len(c_headers_dirty) or None)\n\n    # Check column headers validation\n    if csv_data:\n        assert len(c_headers) == len(csv_data[0])\n\n    # Check row headers validation\n    if r_headers:\n        assert len(r_headers) == len(csv_data)\n\n    # Transform rows into dict zipping the headers.\n    kwargs.pop('rows', None)\n    result = csv_format(csv_data, c_headers, r_headers, rows, **kwargs)\n\n    return result", "response": "Turn csv into dict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef excel_to_dict(excel_filepath, encapsulate_filepath=False, **kwargs):\n    result = {}\n    try:\n        callbacks = {'to_dictlist': excel_todictlist}  # Default callback\n        callbacks.update(kwargs.get('alt_callbacks', {}))\n\n        # Retrieve excel data as dict of sheets lists\n        excel_data = callbacks.get('to_dictlist')(excel_filepath, **kwargs)\n        for sheet in excel_data.keys():\n            try:\n                kwargs['rows'] = excel_data.get(sheet, [])\n                result[sheet] = csv_to_dict(excel_filepath, **kwargs)\n            except Exception as ex:\n                logger.error('Fail to parse sheet {} - {}'.format(sheet, ex))\n                result[sheet] = []\n                continue\n\n        if encapsulate_filepath:\n            result = {excel_filepath: result}\n\n    except Exception as ex:\n        msg = 'Fail transform excel to dict - {}'.format(ex)\n        logger.error(msg, excel_filepath=excel_filepath)\n\n    return result", "response": "Turn excel file into dict."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef notify(\n        self,\n        force_notify=None,\n        use_email=None,\n        use_sms=None,\n        email_body_template=None,\n        **kwargs,\n    ):\n        \"\"\"Notify / send an email and/or SMS.\n\n        Main entry point.\n\n        This notification class (me) knows from whom and to whom the\n        notifications will be sent.\n\n        See signals and kwargs are:\n            * history_instance\n            * instance\n            * user\n        \"\"\"\n        email_sent = None\n        sms_sent = None\n        use_email = use_email or getattr(settings, \"EMAIL_ENABLED\", False)\n        use_sms = use_sms or getattr(settings, \"TWILIO_ENABLED\", False)\n        if force_notify or self._notify_on_condition(**kwargs):\n            if use_email:\n                email_body_template = (\n                    email_body_template or self.email_body_template\n                ) + self.email_footer_template\n                email_sent = self.send_email(\n                    email_body_template=email_body_template, **kwargs\n                )\n            if use_sms:\n                sms_sent = self.send_sms(**kwargs)\n            self.post_notification_actions(\n                email_sent=email_sent, sms_sent=sms_sent, **kwargs\n            )\n        return True if email_sent or sms_sent else False", "response": "Notify the user of a specific entry point."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _notify_on_condition(self, test_message=None, **kwargs):\n        if test_message:\n            return True\n        else:\n            return self.enabled and self.notify_on_condition(**kwargs)", "response": "Returns the value of notify_on_condition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if this notification is enabled based on the value of the Notification model instance.", "response": "def enabled(self):\n        \"\"\"Returns True if this notification is enabled based on the value\n        of Notification model instance.\n\n        Note: Notification names/display_names are persisted in the\n        \"Notification\" model where each mode instance can be flagged\n        as enabled or not, and are selected/subscribed to by\n        each user in their user profile.\n\n        See also: `site_notifications.update_notification_list`\n        \"\"\"\n        if not self._notification_enabled:\n            self._notification_enabled = self.notification_model.enabled\n        return self._notification_enabled"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the Notification model associated with this notification.", "response": "def notification_model(self):\n        \"\"\"Returns the Notification 'model' instance associated\n        with this notification.\n        \"\"\"\n        NotificationModel = django_apps.get_model(\"edc_notification.notification\")\n        # trigger exception if this class is not registered.\n        site_notifications.get(self.name)\n        try:\n            notification_model = NotificationModel.objects.get(name=self.name)\n        except ObjectDoesNotExist:\n            site_notifications.update_notification_list()\n            notification_model = NotificationModel.objects.get(name=self.name)\n        return notification_model"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary of message template options.", "response": "def get_template_options(self, instance=None, test_message=None, **kwargs):\n        \"\"\"Returns a dictionary of message template options.\n\n        Extend using `extra_template_options`.\n        \"\"\"\n        protocol_name = django_apps.get_app_config(\"edc_protocol\").protocol_name\n        test_message = test_message or self.test_message\n        template_options = dict(\n            name=self.name,\n            protocol_name=protocol_name,\n            display_name=self.display_name,\n            email_from=self.email_from,\n            test_subject_line=(\n                self.email_test_subject_line if test_message else \"\"\n            ).strip(),\n            test_body_line=self.email_test_body_line if test_message else \"\",\n            test_line=self.sms_test_line if test_message else \"\",\n            message_datetime=get_utcnow(),\n            message_reference=\"\",\n        )\n        if \"subject_identifier\" not in template_options:\n            try:\n                template_options.update(subject_identifier=instance.subject_identifier)\n            except AttributeError:\n                pass\n        if \"site_name\" not in template_options:\n            try:\n                template_options.update(site_name=instance.site.name.title())\n            except AttributeError:\n                pass\n        return template_options"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sms_recipients(self):\n        sms_recipients = []\n        UserProfile = django_apps.get_model(\"edc_auth.UserProfile\")\n        for user_profile in UserProfile.objects.filter(\n            user__is_active=True, user__is_staff=True\n        ):\n            try:\n                user_profile.sms_notifications.get(name=self.name)\n            except ObjectDoesNotExist:\n                pass\n            else:\n                if user_profile.mobile:\n                    sms_recipients.append(user_profile.mobile)\n        return sms_recipients", "response": "Returns a list of recipients subscribed to receive SMS s\n        for this notifications class."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsigns a list of permissions for a single resource.", "response": "def sign_filter_permissions(permissions):\n    \"\"\"\n    Return a compressed, signed dump of the json blob.\n\n    This function expects a json blob that is a dictionary containing model\n    dotted names as keys. Those keys each have a value that is a list of\n    dictionaries, each of which contains the keys 'filters' and 'actions':\n    The key 'filters' key is a dict that is a filter to be applied to a\n    django queryset. The key 'actions' is a list of DRF methods that can\n    be called for this model's viewset.\n\n    For example:\n        {\n            'accounts.Account':\n                [\n                    {\n                        'filters': {\n                            'email': 'marcel@chewse.com',\n                            'organizations__name': 'Chewse'\n                        },\n                        'actions': ['create', 'partial_update']\n                    }\n                ]\n        }\n    \"\"\"\n    permissions = {key.lower(): value for key, value in permissions.iteritems()}\n    return signing.dumps(permissions, compress=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unsign_filters_and_actions(sign, dotted_model_name):\n    permissions = signing.loads(sign)\n    return permissions.get(dotted_model_name, [])", "response": "Return the list of filters and actions for the given dotted_model_name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates equality between two objects.", "response": "def equal(obj1, obj2):\n    \"\"\"Calculate equality between two (Comparable) objects.\"\"\"\n    Comparable.log(obj1, obj2, '==')\n    equality = obj1.equality(obj2)\n    Comparable.log(obj1, obj2, '==', result=equality)\n    return equality"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating similarity between two objects.", "response": "def similar(obj1, obj2):\n    \"\"\"Calculate similarity between two (Comparable) objects.\"\"\"\n    Comparable.log(obj1, obj2, '%')\n    similarity = obj1.similarity(obj2)\n    Comparable.log(obj1, obj2, '%', result=similarity)\n    return similarity"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a __repr__ string from the arguments provided to __init__.", "response": "def _repr(self, *args, **kwargs):\n        \"\"\"Return a __repr__ string from the arguments provided to __init__.\n\n        @param args: list of arguments to __init__\n        @param kwargs: dictionary of keyword arguments to __init__\n        @return: __repr__ string\n\n        \"\"\"\n        # Remove unnecessary empty keywords arguments and sort the arguments\n        kwargs = {k: v for k, v in kwargs.items() if v is not None}\n        kwargs = OrderedDict(sorted(kwargs.items()))\n\n        # Build the __repr__ string pieces\n        args_repr = ', '.join(repr(arg) for arg in args)\n        kwargs_repr = ', '.join(k + '=' + repr(v) for k, v in kwargs.items())\n        if args_repr and kwargs_repr:\n            kwargs_repr = ', ' + kwargs_repr\n        name = self.__class__.__name__\n\n        return \"{}({}{})\".format(name, args_repr, kwargs_repr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomparing two objects for equality.", "response": "def equality(self, other):\n        \"\"\"Compare two objects for equality.\n\n        @param self: first object to compare\n        @param other: second object to compare\n\n        @return: boolean result of comparison\n\n        \"\"\"\n        # Compare specified attributes for equality\n        cname = self.__class__.__name__\n        for aname in self.attributes:\n            try:\n                attr1 = getattr(self, aname)\n                attr2 = getattr(other, aname)\n            except AttributeError as error:\n                logging.debug(\"%s.%s: %s\", cname, aname, error)\n                return False\n            self.log(attr1, attr2, '==', cname=cname, aname=aname)\n            eql = (attr1 == attr2)\n            self.log(attr1, attr2, '==', cname=cname, aname=aname, result=eql)\n            if not eql:\n                return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomparing two objects for similarity.", "response": "def similarity(self, other):\n        \"\"\"Compare two objects for similarity.\n\n        @param self: first object to compare\n        @param other: second object to compare\n\n        @return: L{Similarity} result of comparison\n\n        \"\"\"\n        sim = self.Similarity()\n        total = 0.0\n\n        # Calculate similarity ratio for each attribute\n        cname = self.__class__.__name__\n        for aname, weight in self.attributes.items():\n\n            attr1 = getattr(self, aname, None)\n            attr2 = getattr(other, aname, None)\n            self.log(attr1, attr2, '%', cname=cname, aname=aname)\n\n            # Similarity is ignored if None on both objects\n            if attr1 is None and attr2 is None:\n                self.log(attr1, attr2, '%', cname=cname, aname=aname,\n                         result=\"attributes are both None\")\n                continue\n\n            # Similarity is 0 if either attribute is non-Comparable\n            if not all((isinstance(attr1, Comparable),\n                        isinstance(attr2, Comparable))):\n                self.log(attr1, attr2, '%', cname=cname, aname=aname,\n                         result=\"attributes not Comparable\")\n                total += weight\n                continue\n\n            # Calculate similarity between the attributes\n            attr_sim = (attr1 % attr2)\n            self.log(attr1, attr2, '%', cname=cname, aname=aname,\n                     result=attr_sim)\n\n            # Add the similarity to the total\n            sim += attr_sim * weight\n            total += weight\n\n        # Scale the similarity so the total is 1.0\n        if total:\n            sim *= (1.0 / total)\n\n        return sim"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Similarity(self, value=None):  # pylint: disable=C0103\n        if value is None:\n            value = 0.0\n        return Similarity(value, threshold=self.threshold)", "response": "Constructor for new default Similarities."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef log(obj1, obj2, sym, cname=None, aname=None, result=None):  # pylint: disable=R0913\n        fmt = \"{o1} {sym} {o2} : {r}\"\n        if cname or aname:\n            assert cname and aname  # both must be specified\n            fmt = \"{c}.{a}: \" + fmt\n\n        if result is None:\n            result = '...'\n            fmt = _Indent.indent(fmt)\n            _Indent.more()\n        else:\n            _Indent.less()\n            fmt = _Indent.indent(fmt)\n\n        msg = fmt.format(o1=repr(obj1), o2=repr(obj2),\n                         c=cname, a=aname, sym=sym, r=result)\n        logging.info(msg)", "response": "Log the objects being compared and the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef translate_path(self, dep_file, dep_rule):\n        dst_base = dep_file.split(os.path.join(dep_rule.address.repo,\n                                               dep_rule.address.path), 1)[-1]\n        if self.params['strip_prefix']:\n            dst_base = dep_file.split(self.params['strip_prefix'], 1)[-1]\n        return os.path.join(self.address.repo, self.address.path,\n                            self.params['prefix'].lstrip('/'),\n                            dst_base.lstrip('/'))", "response": "Translate dep_file from dep_rule into this rule s output path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the list of output files from this rule.", "response": "def output_files(self):\n        \"\"\"Returns the list of output files from this rule.\n\n        Paths are generated from the outputs of this rule's dependencies, with\n        their paths translated based on prefix and strip_prefix.\n\n        Returned paths are relative to buildroot.\n        \"\"\"\n        for dep in self.subgraph.successors(self.address):\n            dep_rule = self.subgraph.node[dep]['target_obj']\n            for dep_file in dep_rule.output_files:\n                yield self.translate_path(dep_file, dep_rule).lstrip('/')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef human_to_boolean(human):\n    '''Convert a boolean string ('Yes' or 'No') to True or False.\n\n    PARAMETERS\n    ----------\n    human   : list\n              a list containing the \"human\" boolean string to be converted to\n              a Python boolean object. If a non-list is passed, or if the list\n              is empty, None will be returned. Only the first element of the\n              list will be used. Anything other than 'Yes' will be considered\n              False.\n    '''\n    if not isinstance(human, list) or len(human) == 0:\n        return None\n    if human[0].lower() == 'yes':\n        return True\n    return False", "response": "Convert a boolean string ('Yes' or 'No' or None to True or False."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate(self, data, *args, **kwargs):\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            self.options.setdefault('package_build_dir', tmpdirname)\n            crawler = CrawlerScript(self.options)\n            crawler.crawl(data, self.spider, *args, **kwargs)\n\n            output_file = os.path.join(\n                self.options['package_build_dir'], 'source', 'moear.mobi')\n            with open(output_file, 'rb') as fh:\n                content = fh.read()\n\n        return content", "response": "Generate a new Mobi file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwaiting seconds until countdown is done.", "response": "def _countdown(seconds):\n    \"\"\"\n    Wait `seconds` counting down.\n    \"\"\"\n    for i in range(seconds, 0, -1):\n        sys.stdout.write(\"%02d\" % i)\n        time.sleep(1)\n        sys.stdout.write(\"\\b\\b\")\n        sys.stdout.flush()\n    sys.stdout.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef export(self, location):\n        temp_dir = tempfile.mkdtemp('-export', 'pip-')\n        self.unpack(temp_dir)\n        if os.path.exists(location):\n            # Remove the location to make sure Bazaar can export it correctly\n            rmtree(location)\n        try:\n            call_subprocess([self.cmd, 'export', location], cwd=temp_dir,\n                            filter_stdout=self._filter, show_stdout=False)\n        finally:\n            rmtree(temp_dir)", "response": "Export the Bazaar repository at the url to the destination location"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verify(self, email):\n        resp = self._call(endpoint='single', data={'email': email})\n        return VerifiedEmail(email, resp['result'])", "response": "Verify a single email address."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new bulk verification job for the list of emails.", "response": "def create_job(self, emails):\n        \"\"\"\n        Create a new bulk verification job for the list of emails.\n        :param list emails: Email addresses to verify.\n        :return: A Job object.\n        \"\"\"\n        resp = self._call(endpoint='bulk', data={'input_location': '1', 'input': '\\n'.join(emails)})\n        return Job(resp['job_id'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking the status of a bulk verification job.", "response": "def check_job(self, job_id):\n        \"\"\"\n        Check the status of a bulk verification job.\n        :param int job_id: ID of a job to check the status of.\n        :return: A JobStatus object.\n        \"\"\"\n        resp = self._call(endpoint='status', data={'job_id': job_id})\n        map = {'id': 'job_id', 'status': 'status_code', 'type': 'type_code'}\n        job_status_args = {map.get(k, k): v for k, v in resp.items()}\n        return JobStatus(**job_status_args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef results(self, job_id):\n        resp = self._call(endpoint='download', data={'job_id': job_id})\n        Row = namedtuple('Row', ['email', 'result_text_code'])\n        for line in resp:\n            row = Row(*line.decode('utf-8').split(','))\n            yield VerifiedEmail.from_text_code(row.email, row.result_text_code)", "response": "Yields the result of a completed bulk verification job."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the results for a completed bulk verification job.", "response": "def retrieve_job(self, job_id):\n        \"\"\"\n        Result of a completed bulk verification job.\n        :param int job_id: ID of a job to retrieve the results for.\n        :return: A list of VerifiedEmail objects.\n        \"\"\"\n        warnings.warn('Use results generator method instead of retrieve_job which returns a list', UserWarning)\n        return list(self.results(job_id))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the account details like balance of credits and jobs completed.", "response": "def account(self):\n        \"\"\"\n        Get the API account details like balance of credits.\n        :return: An Account object.\n        \"\"\"\n        resp = self._call(endpoint='account')\n        return Account(resp['credits'], resp['jobs_completed'], resp['jobs_processing'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef access_token(self):\n        if self._cached_access_token is not None:\n            return self._cached_access_token\n        resp = self._request(endpoint='access_token', data={'grant_type': 'client_credentials', 'scope': 'basic user'},\n                             auth=(self.api_username, self.api_key))\n        self._cached_access_token = resp['access_token']\n        return self._cached_access_token", "response": "Retrieve and cache an access token to authenticate API calls."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking an authorized API call to specified endpoint.", "response": "def _call(self, endpoint, data=None):\n        \"\"\"\n        Make an authorized API call to specified endpoint.\n        :param str endpoint: API endpoint's relative URL, eg. `/account`.\n        :param dict data: POST request data.\n        :return: A dictionary or a string with response data.\n        \"\"\"\n        data = {} if data is None else data\n        try:\n            data['access_token'] = self.access_token()\n            return self._request(endpoint, data)\n        except AccessTokenExpired:\n            self._cached_access_token = None\n            data['access_token'] = self.access_token()\n            return self._request(endpoint, data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking an HTTP POST request to an API endpoint.", "response": "def _request(self, endpoint, data, auth=None):\n        \"\"\"\n        Make HTTP POST request to an API endpoint.\n        :param str endpoint: API endpoint's relative URL, eg. `/account`.\n        :param dict data: POST request data.\n        :param tuple auth: HTTP basic auth credentials.\n        :return: A dictionary or a string with response data.\n        \"\"\"\n        url = '{}/{}'.format(self.base_url, endpoint)\n        response = requests.post(url, data, auth=auth)\n        return self._handle_response(response)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _handle_response(response):\n        if not response.ok:\n            raise NeverBounceAPIError(response)\n        if response.headers.get('Content-Type') == 'application/octet-stream':\n            return response.iter_lines()\n\n        try:\n            resp = response.json()\n        except ValueError:\n             raise InvalidResponseError('Failed to handle the response content-type {}.'.format(\n                 response.headers.get('Content-Type'))\n             )\n        if 'success' in resp and not resp['success']:\n            if 'msg' in resp and resp['msg'] == 'Authentication failed':\n                raise AccessTokenExpired\n            else:\n                raise NeverBounceAPIError(response)\n        return resp", "response": "Handle the response and possible failures."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply the list of post processing methods to the table.", "response": "def post_process(table, post_processors):\n    \"\"\"Applies the list of post processing methods if any\"\"\"\n    table_result = table\n    for processor in post_processors:\n        table_result = processor(table_result)\n    return table_result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef describe(cls, full=False):\n    divider_double = \"=\" * 80\n    divider_single = \"-\" * 80\n    description = cls.__doc__\n    message = []\n    message.append(divider_double)\n    message.append(cls.__name__ + ':')\n    message.append(description)\n    if full and cls.post_processors(cls):\n        message.append(divider_single)\n        message.append(\"Post processors:\")\n        message.append(divider_single)\n        for processor in cls.post_processors(cls):\n            message.append(\">\" + \" \" * 3 + processor.__name__ + ':')\n            message.append(\" \" * 4 + processor.__doc__)\n            message.append('')\n    message.append(divider_double)\n    message.append('')\n    for line in message:\n        print(line)", "response": "Prints a description of the class"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting all postprocessors and their description", "response": "def describe_processors(cls):\n        \"\"\"List all postprocessors and their description\"\"\"\n        # TODO: Add dependencies to this dictionary\n        for processor in cls.post_processors(cls):\n            yield {'name': processor.__name__,\n                   'description': processor.__doc__,\n                   'processor': processor}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dependencies(cls):\n        dependencies = []\n        try:\n            dependencies += cls.source.dependencies\n        except AttributeError:\n            pass\n        for processor in cls.post_processors(cls):\n            try:\n                assert isinstance(processor.dependencies, list), \\\n                    \"{}.dependencies must be a list\".format(processor.__name__)\n                dependencies += processor.dependencies\n            except AttributeError:\n                pass\n        return dependencies", "response": "Returns a list of all dependent tables in the order they are defined."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_settings_list(self):\n        return [\n            self.source,\n            self.output,\n            self.kwargs,\n            self.post_processors,\n        ]", "response": "The settings list used for building the cache id."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_cached_filename(self, filename, extention, settings_list=None):\n        cached_name = \"_\".join([filename, self.get_hash()])\n        return \".\".join([cached_name, extention])", "response": "Returns a filename with md5 cache string based on settings list\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying the post processors and returns the table.", "response": "def _process_table(self, cache=True):\n        \"\"\"Applies the post processors\"\"\"\n        table = self.source()\n        assert not isinstance(table, None.__class__), \\\n            \"{}.source needs to return something, not None\".format(self.__class__.__name__)\n        table = post_process(table, self.post_processors())\n        if cache:\n            self.to_cache(table)\n        return table"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch the table and applies all post processors.", "response": "def fetch(self, rebuild=False, cache=True):\n        \"\"\"Fetches the table and applies all post processors.\n        Args:\n            rebuild (bool): Rebuild the table and ignore cache. Default: False\n            cache (bool): Cache the finished table for faster future loading.\n                Default: True\n        \"\"\"\n        if rebuild:\n            return self._process_table(cache)\n        try:\n            return self.read_cache()\n        except FileNotFoundError:\n            return self._process_table(cache)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the generation process.", "response": "def generate(self):\n        \"\"\"Runs generation process.\"\"\"\n        for root, _, files in os.walk(self.source_dir):\n            for fname in files:\n                source_fpath = os.path.join(root, fname)\n                self.generate_api_for_source(source_fpath)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate end json api file with directory structure for concrete source file.", "response": "def generate_api_for_source(self, source_fpath: str):\n        \"\"\"Generate end json api file with directory structure for concrete\n        source file.\"\"\"\n        content = self.convert_content(source_fpath)\n        if content is None:\n            return\n\n        dest_fpath = self.dest_fpath(source_fpath)\n        self.create_fpath_dir(dest_fpath)\n\n        with open(dest_fpath, 'w+') as dest_f:\n            json.dump(content, dest_f, cls=DateTimeJsonEncoder)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting content of source file with loader class provided with loader_cls self attribute. Returns None if no conversion is possible.", "response": "def convert_content(self, fpath: str) -> typing.Optional[dict]:\n        \"\"\"Convert content of source file with loader, provided with\n        `loader_cls` self attribute.\n\n        Returns dict with converted content if loader class support source file\n        extenstions, otherwise return nothing.\"\"\"\n        try:\n            loader = self.loader_cls(fpath)\n        except UnsupportedExtensionError:\n            return\n\n        return loader.convert_content()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dest_fpath(self, source_fpath: str) -> str:\n        relative_fpath = os.path.join(*source_fpath.split(os.sep)[1:])\n        relative_dirpath = os.path.dirname(relative_fpath)\n\n        source_fname = relative_fpath.split(os.sep)[-1]\n        base_fname = source_fname.split('.')[0]\n        dest_fname = f'{base_fname}.json'\n\n        return os.path.join(self.dest_dir, relative_dirpath, dest_fname)", "response": "Calculates full path for end json - api file from source file full\n        path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_fpath_dir(self, fpath: str):\n        os.makedirs(os.path.dirname(fpath), exist_ok=True)", "response": "Creates directory for fpath."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrequiring by flake8 add the possible options called first", "response": "def add_options(cls, parser):\n        \"\"\"Required by flake8\n        add the possible options, called first\n\n        Args:\n            parser (OptionsManager):\n        \"\"\"\n        kwargs = {'action': 'store', 'default': '', 'parse_from_config': True,\n                  'comma_separated_list': True}\n        for num in range(cls.min_check, cls.max_check):\n            parser.add_option(None, \"--filename_check{}\".format(num), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_options(cls, options):\n        d = {}\n        for filename_check, dictionary in cls.filename_checks.items():\n            # retrieve the marks from the passed options\n            filename_data = getattr(options, filename_check)\n            if len(filename_data) != 0:\n                parsed_params = {}\n                for single_line in filename_data:\n                    a = [s.strip() for s in single_line.split('=')]\n                    # whitelist the acceptable params\n                    if a[0] in ['filter_regex', 'filename_regex']:\n                        parsed_params[a[0]] = a[1]\n                d[filename_check] = parsed_params\n        cls.filename_checks.update(d)\n        # delete any empty rules\n        cls.filename_checks = {x: y for x, y in cls.filename_checks.items() if len(y) > 0}", "response": "Parse the options and add them to the options dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n\n        if len(self.filename_checks) == 0:\n            message = \"N401 no configuration found for {}, \" \\\n                      \"please provide filename configuration in a flake8 config\".format(self.name)\n            yield (0, 0, message, type(self))\n\n        rule_funcs = [rules.rule_n5xx]\n\n        for rule_func in rule_funcs:\n            for rule_name, configured_rule in self.filename_checks.items():\n                for err in rule_func(self.filename, rule_name, configured_rule, type(self)):\n                    yield err", "response": "Run the checks for the filename and return a list of violation items."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_my_ips():\n    ips = list()\n    if not os.path.exists(\"/sys/class/net\"): # not linux\n        return ['127.0.0.1']\n    for ifdev in os.listdir(\"/sys/class/net\"):\n        if ifdev == \"lo\":\n            continue\n        try:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n            ips.append(socket.inet_ntoa(fcntl.ioctl(\n                sock.fileno(),\n                0x8915,  # SIOCGIFADDR\n                struct.pack('256s', ifdev[:15].encode())\n            )[20:24]))\n        except OSError:\n            pass\n    return ips", "response": "highly os specific - works only in modern kernels"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_identity_document(current_block: dict, uid: str, salt: str, password: str) -> Identity:\n\n    # get current block BlockStamp\n    timestamp = BlockUID(current_block['number'], current_block['hash'])\n\n    # create keys from credentials\n    key = SigningKey.from_credentials(salt, password)\n\n    # create identity document\n    identity = Identity(\n        version=10,\n        currency=current_block['currency'],\n        pubkey=key.pubkey,\n        uid=uid,\n        ts=timestamp,\n        signature=None\n    )\n\n    # sign document\n    identity.sign([key])\n\n    return identity", "response": "Get an Identity document from the current block data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the datetime. now based SHA - 1 hash of a string.", "response": "def make_hash_id():\n    \"\"\"\n    Compute the `datetime.now` based SHA-1 hash of a string.\n\n    :return: Returns the sha1 hash as a string.\n    :rtype: str\n    \"\"\"\n    today = datetime.datetime.now().strftime(DATETIME_FORMAT)\n    return hashlib.sha1(today.encode('utf-8')).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_header(filename):\n    ''' returns a dictionary of values in the header of the given file '''\n    header = {}\n    in_header = False\n    data = nl.universal_read(filename)\n    lines = [x.strip() for x in data.split('\\n')]\n    for line in lines:\n        if line==\"*** Header Start ***\":\n            in_header=True\n            continue\n        if line==\"*** Header End ***\":\n            return header\n        fields = line.split(\": \")\n        if len(fields)==2:\n            header[fields[0]] = fields[1]", "response": "reads the header of the given file returns a dictionary of values in the header of the given file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef appointment(self):\n        return django_apps.get_model(self.appointment_model).objects.get(\n            pk=self.request.GET.get(\"appointment\")\n        )", "response": "Returns the appointment instance for this request or None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the previous visit for this request or None. Requires attr visit_model_cls.", "response": "def previous_visit(self):\n        \"\"\"Returns the previous visit for this request or None.\n\n        Requires attr `visit_model_cls`.\n        \"\"\"\n        previous_visit = None\n        if self.appointment:\n            appointment = self.appointment\n            while appointment.previous_by_timepoint:\n                try:\n                    previous_visit = self.model.visit_model_cls().objects.get(\n                        appointment=appointment.previous_by_timepoint\n                    )\n                except ObjectDoesNotExist:\n                    pass\n                else:\n                    break\n                appointment = appointment.previous_by_timepoint\n        return previous_visit"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a model obj that is the first occurrence of a previous obj relative to this object s appointment.", "response": "def previous_obj(self):\n        \"\"\"Returns a model obj that is the first occurrence of a previous\n        obj relative to this object's appointment.\n\n        Override this method if not am EDC subject model / CRF.\n        \"\"\"\n        previous_obj = None\n        if self.previous_visit:\n            try:\n                previous_obj = self.model.objects.get(\n                    **{f\"{self.model.visit_model_attr()}\": self.previous_visit}\n                )\n            except ObjectDoesNotExist:\n                pass\n        return previous_obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read(fname):\n    fpath = os.path.join(os.path.dirname(__file__), fname)\n    with codecs.open(fpath, 'r', 'utf8') as fhandle:\n        return fhandle.read().strip()", "response": "read and return file contents"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ensure_utf8(app_name_to_show_on_error: str):\n    encoding = locale.getpreferredencoding()\n    if encoding.lower() != 'utf-8':\n        raise OSError('{} works only in UTF-8, but yours is set at {}'.format(app_name_to_show_on_error, encoding))", "response": "Ensure that the application name is UTF - 8."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_file(self, filename, content):\n        with open(filename, 'w') as fp:\n            fp.write(content)", "response": "Create a new file with name filename and content content."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef insert_data_frame(col, df, int_col=None, binary_col=None, minimal_size=5):\n    data = transform.to_dict_list_generic_type(df,\n                                               int_col=int_col,\n                                               binary_col=binary_col)\n    smart_insert(col, data, minimal_size)", "response": "Insert a DataFrame into a new column in the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an ASCII Armor message.", "response": "def create(message: str, pubkey: Optional[str] = None, signing_keys: Optional[List[SigningKey]] = None,\n               message_comment: Optional[str] = None, signatures_comment: Optional[str] = None) -> str:\n        \"\"\"\n        Encrypt a message in ascii armor format, optionally signing it\n\n        :param message: Utf-8 message\n        :param pubkey: Public key of recipient for encryption\n        :param signing_keys: Optional list of SigningKey instances\n        :param message_comment: Optional message comment field\n        :param signatures_comment: Optional signatures comment field\n        :return:\n        \"\"\"\n        # if no public key and no signing key...\n        if not pubkey and not signing_keys:\n            # We can not create an Ascii Armor Message\n            raise MISSING_PUBLIC_KEY_AND_SIGNING_KEY_EXCEPTION\n\n        # keep only one newline at the end of the message\n        message = message.rstrip(\"\\n\\r\") + \"\\n\"\n\n        # create block with headers\n        ascii_armor_block = \"\"\"{begin_message_header}\n\"\"\".format(begin_message_header=BEGIN_MESSAGE_HEADER)\n\n        # if encrypted message...\n        if pubkey:\n            # add encrypted message fields\n            ascii_armor_block += \"\"\"{version_field}\n\"\"\".format(version_field=AsciiArmor._get_version_field())\n\n        # add message comment if specified\n        if message_comment:\n            ascii_armor_block += \"\"\"{comment_field}\n\"\"\".format(comment_field=AsciiArmor._get_comment_field(message_comment))\n\n        # blank line separator\n        ascii_armor_block += '\\n'\n\n        if pubkey:\n            # add encrypted message\n            pubkey_instance = PublicKey(pubkey)\n            base64_encrypted_message = base64.b64encode(pubkey_instance.encrypt_seal(message))  # type: bytes\n            ascii_armor_block += \"\"\"{base64_encrypted_message}\n\"\"\".format(base64_encrypted_message=base64_encrypted_message.decode('utf-8'))\n        else:\n            # remove trailing spaces\n            message = AsciiArmor._remove_trailing_spaces(message)\n\n            # add dash escaped message to ascii armor content\n            ascii_armor_block += AsciiArmor._dash_escape_text(message)\n\n        # if no signature...\n        if signing_keys is None:\n            # add message tail\n            ascii_armor_block += END_MESSAGE_HEADER\n        else:\n            # add signature blocks and close block on last signature\n            count = 1\n            for signing_key in signing_keys:\n                ascii_armor_block += AsciiArmor._get_signature_block(message, signing_key, count == len(signing_keys),\n                                                                     signatures_comment)\n                count += 1\n\n        return ascii_armor_block"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves trailing spaces and tabs from a text.", "response": "def _remove_trailing_spaces(text: str) -> str:\n        \"\"\"\n        Remove trailing spaces and tabs\n\n        :param text: Text to clean up\n        :return:\n        \"\"\"\n        clean_text = str()\n\n        for line in text.splitlines(True):\n            # remove trailing spaces (0x20) and tabs (0x09)\n            clean_text += line.rstrip(\"\\x09\\x20\")\n\n        return clean_text"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _dash_escape_text(text: str) -> str:\n        dash_escaped_text = str()\n\n        for line in text.splitlines(True):\n            # add dash '-' (0x2D) and space ' ' (0x20) as prefix\n            dash_escaped_text += DASH_ESCAPE_PREFIX + line\n\n        return dash_escaped_text", "response": "Add dash - escape prefix on each line of text."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a dash - escaped text line and return a string.", "response": "def _parse_dash_escaped_line(dash_escaped_line: str) -> str:\n        \"\"\"\n        Parse a dash-escaped text line\n\n        :param dash_escaped_line: Dash escaped text line\n        :return:\n        \"\"\"\n        text = str()\n        regex_dash_escape_prefix = compile('^' + DASH_ESCAPE_PREFIX)\n        # if prefixed by a dash escape prefix...\n        if regex_dash_escape_prefix.match(dash_escaped_line):\n            # remove dash '-' (0x2D) and space ' ' (0x20) prefix\n            text += dash_escaped_line[2:]\n\n        return text"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a signature block for the specified message.", "response": "def _get_signature_block(message: str, signing_key: SigningKey, close_block: bool = True,\n                             comment: Optional[str] = None) -> str:\n        \"\"\"\n        Return a signature block\n\n        :param message: Message (not encrypted!) to sign\n        :param signing_key: The libnacl SigningKey instance of the keypair\n        :param close_block: Optional flag to close the signature block with the signature tail header\n        :param comment: Optional comment field content\n        :return:\n        \"\"\"\n        base64_signature = base64.b64encode(signing_key.signature(message))\n\n        block = \"\"\"{begin_signature_header}\n{version_field}\n\"\"\".format(begin_signature_header=BEGIN_SIGNATURE_HEADER, version_field=AsciiArmor._get_version_field())\n\n        # add message comment if specified\n        if comment:\n            block += \"\"\"{comment_field}\n\"\"\".format(comment_field=AsciiArmor._get_comment_field(comment))\n\n        # blank line separator\n        block += '\\n'\n\n        block += \"\"\"{base64_signature}\n\"\"\".format(base64_signature=base64_signature.decode('utf-8'))\n\n        if close_block:\n            block += END_SIGNATURE_HEADER\n\n        return block"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing an ASCII Armor Message Block and return a dict with parsed content.", "response": "def parse(ascii_armor_message: str, signing_key: Optional[SigningKey] = None,\n              sender_pubkeys: Optional[List[str]] = None) -> dict:\n        \"\"\"\n        Return a dict with parsed content (decrypted message, signature validation) ::\n\n            {\n               'message':\n                   {\n                       'fields': {},\n                       'content': str,\n                    },\n               'signatures': [\n                   {'pubkey': str, 'valid': bool, fields: {}}\n               ]\n           }\n\n        :param ascii_armor_message: The Ascii Armor Message Block including BEGIN and END headers\n        :param signing_key: Optional Libnacl SigningKey instance to decrypt message\n        :param sender_pubkeys: Optional sender's public keys list to verify signatures\n        :exception libnacl.CryptError: Raise an exception if keypair fail to decrypt the message\n        :exception MissingSigningKeyException: Raise an exception if no keypair given for encrypted message\n\n        :return:\n        \"\"\"\n        # regex patterns\n        regex_begin_message = compile(BEGIN_MESSAGE_HEADER)\n        regex_end_message = compile(END_MESSAGE_HEADER)\n        regex_begin_signature = compile(BEGIN_SIGNATURE_HEADER)\n        regex_end_signature = compile(END_SIGNATURE_HEADER)\n        regex_fields = compile(\"^(Version|Comment): (.+)$\")\n\n        # trim message to get rid of empty lines\n        ascii_armor_message = ascii_armor_message.strip(\" \\t\\n\\r\")\n\n        # init vars\n        parsed_result = {\n            'message':\n                {\n                    'fields': {},\n                    'content': '',\n                },\n            'signatures': []\n        }  # type: Dict[str, Any]\n        cursor_status = 0\n        message = ''\n        signatures_index = 0\n\n        # parse each line...\n        for line in ascii_armor_message.splitlines(True):\n\n            # if begin message header detected...\n            if regex_begin_message.match(line):\n                cursor_status = ON_MESSAGE_FIELDS\n                continue\n\n            # if we are on the fields lines...\n            if cursor_status == ON_MESSAGE_FIELDS:\n                # parse field\n                m = regex_fields.match(line.strip())\n                if m:\n                    # capture field\n                    msg_field_name = m.groups()[0]\n                    msg_field_value = m.groups()[1]\n                    parsed_result['message']['fields'][msg_field_name] = msg_field_value\n                    continue\n\n                # if blank line...\n                if line.strip(\"\\n\\t\\r \") == '':\n                    cursor_status = ON_MESSAGE_CONTENT\n                    continue\n\n            # if we are on the message content lines...\n            if cursor_status == ON_MESSAGE_CONTENT:\n\n                # if a header is detected, end of message content...\n                if line.startswith(HEADER_PREFIX):\n\n                    # if field Version is present, the message is encrypted...\n                    if 'Version' in parsed_result['message']['fields']:\n\n                        # If keypair instance to decrypt not given...\n                        if signing_key is None:\n                            # SigningKey keypair is mandatory to decrypt the message...\n                            raise PARSER_MISSING_SIGNING_KEY_EXCEPTION\n\n                        # decrypt message with secret key from keypair\n                        message = AsciiArmor._decrypt(message, signing_key)\n\n                    # save message content in result\n                    parsed_result['message']['content'] = message\n\n                    # if message end header...\n                    if regex_end_message.match(line):\n                        # stop parsing\n                        break\n\n                    # if signature begin header...\n                    if regex_begin_signature.match(line):\n                        # add signature dict in list\n                        parsed_result['signatures'].append({\n                            'fields': {}\n                        })\n                        cursor_status = ON_SIGNATURE_FIELDS\n                        continue\n                else:\n                    # if field Version is present, the message is encrypted...\n                    if 'Version' in parsed_result['message']['fields']:\n                        # concatenate encrypted line to message content\n                        message += line\n                    else:\n                        # concatenate cleartext striped dash escaped line to message content\n                        message += AsciiArmor._parse_dash_escaped_line(line)\n\n            # if we are on a signature fields zone...\n            if cursor_status == ON_SIGNATURE_FIELDS:\n\n                # parse field\n                m = regex_fields.match(line.strip())\n                if m:\n                    # capture field\n                    sig_field_name = m.groups()[0]\n                    sig_field_value = m.groups()[1]\n                    parsed_result['signatures'][signatures_index]['fields'][sig_field_name] = sig_field_value\n                    continue\n\n                # if blank line...\n                if line.strip(\"\\n\\t\\r \") == '':\n                    cursor_status = ON_SIGNATURE_CONTENT\n                    continue\n\n            # if we are on the signature content...\n            if cursor_status == ON_SIGNATURE_CONTENT:\n\n                # if no public keys provided...\n                if sender_pubkeys is None:\n                    # raise exception\n                    raise PARSER_MISSING_PUBLIC_KEYS_EXCEPTION\n\n                # if end signature header detected...\n                if regex_end_signature.match(line):\n                    # end of parsing\n                    break\n\n                # if begin signature header detected...\n                if regex_begin_signature.match(line):\n                    signatures_index += 1\n                    cursor_status = ON_SIGNATURE_FIELDS\n                    continue\n\n                for pubkey in sender_pubkeys:\n                    verifier = VerifyingKey(pubkey)\n                    signature = base64.b64decode(line)\n                    parsed_result['signatures'][signatures_index]['pubkey'] = pubkey\n                    try:\n                        libnacl.crypto_sign_verify_detached(signature, message, verifier.vk)\n                        parsed_result['signatures'][signatures_index]['valid'] = True\n                    except ValueError:\n                        parsed_result['signatures'][signatures_index]['valid'] = False\n\n        return parsed_result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render(request, template_name, context=None, content_type=None, status=None, using=None, logs=None):\n    if logs:\n        obj_logger = ObjectLogger()\n        if not isinstance(logs, list):\n            logs = [logs, ]\n        for log in logs:\n            log = obj_logger.log_response(\n                log,\n                context,\n                status=str(status),\n                headers='',\n                content_type=str(content_type))\n            log.save()\n    return django_render(\n        request,\n        template_name,\n        context=context,\n        content_type=content_type,\n        status=status,\n        using=using)", "response": "Wrapper around django render method. Can take one or a list of logs and logs the response."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scanFolderForRegexp(folder = None, listRegexp = None, recursive = False, verbosity=1, logFolder= \"./logs\"):\n\t''' \n\t\t[Optionally] recursive method to scan the files in a given folder.\n\n\t\t:param folder:\tthe folder to be scanned.\n\t\t:param listRegexp:\tlistRegexp is an array of <RegexpObject>.\n\t\t:param recursive:\twhen True, it performs a recursive search on the subfolders.\n\t\n\t\t:return:\ta list of the available objects containing the expressions found in the provided data.\n\t\t[\n\t\t  {\n\t\t\t\"attributes\": [],\n\t\t\t\"type\": \"i3visio.email\",\n\t\t\t\"value\": \"foo@bar.com\"\n\t\t  },\n\t\t  {\n\t\t\t\"attributes\": [],\n\t\t\t\"type\": \"i3visio.email\",\n\t\t\t\"value\": \"bar@foo.com\"\n\t\t  }\n\t\t]\n\t'''\n\ti3visiotools.logger.setupLogger(loggerName=\"entify\", verbosity=verbosity, logFolder=logFolder)\n\tlogger = logging.getLogger(\"entify\")\n\n\tlogger.info(\"Scanning the folder: \" + folder)\t\n\tresults = {}\n\n\t#onlyfiles = []\n\t#for f in listdir(args.input_folder):\n\t#\tif isfile(join(args.input_folder, f)):\n\t#\t\tonlyfiles.append(f)\t\n\tonlyfiles = [ f for f in listdir(folder) if isfile(join(folder,f)) ]\n\t\n\tfor f in onlyfiles:\n\t\tfilePath = join(folder,f)\n\t\tlogger.debug(\"Looking for regular expressions in: \" + filePath)\t\n\n\t\twith open(filePath, \"r\") as tempF:\n\t\t\t# reading data\n\t\t\tfoundExpr = getEntitiesByRegexp(data = tempF.read(), listRegexp = listRegexp)\n\t\t\tlogger.debug(\"Updating the \" + str(len(foundExpr)) + \" results found on: \" + filePath)\t\n\t\t\tresults[filePath] = foundExpr\n\n\tif recursive:\n\t\tonlyfolders = [ f for f in listdir(folder) if isdir(join(folder,f)) ]\n\t\tfor f in onlyfolders:\n\t\t\tfolderPath = join(folder, f)\n\t\t\tlogger.debug(\"Looking for additional in the folder: \"+ folderPath)\n\t\t\tresults.update(scanFolderForRegexp(folder = folderPath,listRegexp = listRegexp, recursive = recursive))\n\treturn results", "response": "This method scans the folder for regular expressions and returns a list of the objects that match the regular expression."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef entify_main(args):\n\t''' \n\t\tMain function. This function is created in this way so as to let other applications make use of the full configuration capabilities of the application.\t\n\t'''\n\t# Recovering the logger\n\t# Calling the logger when being imported\n\ti3visiotools.logger.setupLogger(loggerName=\"entify\", verbosity=args.verbose, logFolder=args.logfolder)\t\n\t# From now on, the logger can be recovered like this:\n\tlogger = logging.getLogger(\"entify\")\n\n\tlogger.info(\"\"\"entify-launcher.py Copyright (C) F. Brezo and Y. Rubio (i3visio) 2014\nThis program comes with ABSOLUTELY NO WARRANTY.\nThis is free software, and you are welcome to redistribute it under certain conditions.\nFor details, run:\n\\tpython entify-launcher.py --license\"\"\")\n\n\tlogger.info(\"Selecting the regular expressions to be analysed...\")\n\n\tlistRegexp = []\n\tif args.regexp:\n\t\tlistRegexp = config.getRegexpsByName(args.regexp)\n\n\telif args.new_regexp:\n\t\tfor i, r in enumerate(args.new_regexp):\n\t\t\tlist.Regexp.append(RegexpObject(name = \"NewRegexp\"+str(i), reg_exp = args.new_regexp))\n\n\tif not args.web:\n\t\tresults = scanFolderForRegexp(folder = args.input_folder, listRegexp= listRegexp, recursive = args.recursive, verbosity=args.verbose, logFolder= args.logfolder)\n\telse:\n\t\tresults = scanResource(uri = args.web, listRegexp= listRegexp, verbosity=args.verbose, logFolder= args.logfolder)\n\tlogger.info(\"Printing the results:\\n\" + general.dictToJson(results))\n\n\tif args.output_folder:\n\t\tlogger.info(\"Preparing the output folder...\")\n\t\tif not os.path.exists(args.output_folder):\n\t\t\tlogger.warning(\"The output folder \\'\" + args.output_folder + \"\\' does not exist. The system will try to create it.\")\n\t\t\tos.makedirs(args.output_folder)\n\t\tlogger.info(\"Storing the results...\")\n\t\t\"\"\"if \"csv\" in args.extension:\n\t\t\twith open(os.path.join(args.output_folder, \"results.csv\"), \"w\") as oF:\n\t\t\t\toF.write(resultsToCSV(results))\"\"\"\n\t\tif \"json\" in args.extension:\n\t\t\twith open(os.path.join(args.output_folder, \"results.json\"), \"w\") as oF:\n\t\t\t\toF.write(general.dictToJson(results))", "response": "This function is called by the entify - launcher. py script. It is called by the entify - launcher. py script."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntransforming data frame to list of dict.", "response": "def to_index_row_dict(df, index_col=None, use_ordered_dict=True):\n    \"\"\"Transform data frame to list of dict.\n\n    :param index_col: None or str, the column that used as index.\n    :param use_ordered_dict: if True, row dict is has same order as df.columns. \n\n    **\u4e2d\u6587\u6587\u6863**\n\n    \u5c06dataframe\u4ee5\u6307\u5b9a\u5217\u4e3akey, \u8f6c\u5316\u6210\u4ee5\u884c\u4e3a\u89c6\u89d2\u7684dict\u7ed3\u6784, \u63d0\u5347\u6309\u884cindex\u8bbf\u95ee\n    \u7684\u901f\u5ea6\u3002\u82e5\u65e0\u6307\u5b9a\u5217, \u5219\u4f7f\u7528index\u3002\n    \"\"\"\n    if index_col:\n        index_list = df[index_col]\n    else:\n        index_list = df.index\n\n    columns = df.columns\n\n    if use_ordered_dict:\n        table = OrderedDict()\n    else:\n        table = dict()\n\n    for ind, tp in zip(index_list, itertuple(df)):\n        table[ind] = dict(zip(columns, tp))\n\n    return table"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_dict_list(df, use_ordered_dict=True):\n    if use_ordered_dict:\n        dict = OrderedDict\n\n    columns = df.columns\n    data = list()\n    for tp in itertuple(df):\n        data.append(dict(zip(columns, tp)))\n    return data", "response": "Transform each row to dict and put them into a list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_dict_list_generic_type(df, int_col=None, binary_col=None):\n    # Pre-process int_col, binary_col and datetime_col\n    if (int_col is not None) and (not isinstance(int_col, (list, tuple))):\n        int_col = [int_col, ]\n\n    if (binary_col is not None) and (not isinstance(binary_col, (list, tuple))):\n        binary_col = [binary_col, ]\n\n    datetime_col = list()\n    for col, dtype in dict(df.dtypes).items():\n        if \"datetime64\" in str(dtype):\n            datetime_col.append(col)\n    if len(datetime_col) == 0:\n        datetime_col = None\n\n    # Pre-process binary column dataframe\n    def b64_encode(b):\n        try:\n            return base64.b64encode(b)\n        except:\n            return b\n\n    if binary_col is not None:\n        for col in binary_col:\n            df[col] = df[col].apply(b64_encode)\n\n    data = json.loads(df.to_json(orient=\"records\", date_format=\"iso\"))\n\n    if int_col is not None:\n        for row in data:\n            for col in int_col:\n                try:\n                    row[col] = int(row[col])\n                except:\n                    pass\n\n    if binary_col is not None:\n        for row in data:\n            for col in binary_col:\n                try:\n                    row[col] = base64.b64decode(row[col].encode(\"ascii\"))\n                except:\n                    pass\n\n    if datetime_col is not None:\n        for row in data:\n            for col in datetime_col:\n                try:\n                    row[col] = rolex.str2datetime(row[col])\n                except:\n                    pass\n\n    return data", "response": "Transform each row to dict and put them into a list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_connection_args(parser: FileAwareParser, strong_config_file: bool=True) -> FileAwareParser:\n    # TODO: Decide what to do with this\n    parser.add_file_argument(\"--conf\", metavar=\"CONFIG FILE\", help=\"Configuration file\",\n                             action=ConfigFile if strong_config_file else None)\n\n    parser.add_argument(\"-db\", \"--dburl\", help=\"Default database URL\",\n                        default=Default_DB_Connection)\n    parser.add_argument(\"--user\", help=\"Default user name\",\n                        default=Default_User)\n    parser.add_argument(\"--password\", help=\"Default password\",\n                        default=Default_Password)\n    parser.add_argument(\"--crcdb\", help=\"CRC database URL. (default: dburl)\")\n    parser.add_argument(\"--crcuser\", help=\"User name for CRC database. (default: user)\")\n    parser.add_argument(\"--crcpassword\", help=\"Password for CRC database. (default: password)\")\n    parser.add_argument(\"--ontodb\", help=\"Ontology database URL.  (default: dburl)\")\n    parser.add_argument(\"--ontouser\", help=\"User name for ontology database. (default: user)\")\n    parser.add_argument(\"--ontopassword\", help=\"Password for ontology database. (default: password)\")\n    parser.add_argument(\"--onttable\", metavar=\"ONTOLOGY TABLE NAME\",\n                        help=\"Ontology table name (default: {})\".format(DEFAULT_ONTOLOGY_TABLE),\n                        default=DEFAULT_ONTOLOGY_TABLE)\n    return parser", "response": "Add the database connection arguments to the supplied parser."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_parsed_args(opts: Namespace, error_fun: Optional[Callable], connect: bool=True) -> Namespace:\n    def setdefault(vn: str, default: object) -> None:\n        assert vn in opts, \"Unknown option\"\n        if not getattr(opts, vn):\n            setattr(opts, vn, default)\n\n    if error_fun and \\\n            (getattr(opts, 'dburl') is None or getattr(opts, 'user') is None or getattr(opts, 'password') is None):\n        error_fun(\"db url, user id and password must be supplied\")\n    setdefault('crcdb', opts.dburl)\n    setdefault('crcuser', opts.user)\n    setdefault('crcpassword', opts.password)\n    setdefault('ontodb', opts.dburl)\n    setdefault('ontouser', opts.user)\n    setdefault('ontopassword', opts.password)\n    if connect:\n        opts.tables = I2B2Tables(opts)\n\n    # TODO: This approach needs to be re-thought.  As i2b2tablenames is a singleton, any changes here\n    # impact the entire testing harness\n    if opts.onttable:\n        i2b2tablenames.ontology_table = opts.onttable\n    return opts", "response": "Set the default values for the crc user id and password for the ontology tables."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a flat file dict into the tree format used for storage", "response": "def build_dir_tree(self, files):\n        \"\"\" Convert a flat file dict into the tree format used for storage \"\"\"\n\n        def helper(split_files):\n            this_dir = {'files' : {}, 'dirs' : {}}\n            dirs = defaultdict(list)\n\n            for fle in split_files:\n                index = fle[0]; fileinfo = fle[1]\n                if len(index)  == 1:\n                    fileinfo['path'] = index[0] # store only the file name instead of the whole path\n                    this_dir['files'][fileinfo['path']] = fileinfo\n                elif len(index) > 1:\n                    dirs[index[0]].append((index[1:], fileinfo))\n\n            for name,info in dirs.iteritems():\n                this_dir['dirs'][name] = helper(info)\n            return this_dir\n        return helper([(name.split('/')[1:], file_info) for name, file_info in files.iteritems()])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a directory tree back into a flat dict", "response": "def flatten_dir_tree(self, tree):\n        \"\"\" Convert a file tree back into a flat dict \"\"\"\n\n        result = {}\n\n        def helper(tree, leading_path = ''):\n            dirs  = tree['dirs']; files = tree['files']\n            for name, file_info in files.iteritems():\n                file_info['path'] = leading_path + '/'  + name\n                result[file_info['path']] = file_info\n\n            for name, contents in dirs.iteritems():\n                helper(contents, leading_path +'/'+ name)\n        helper(tree); return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_dir_tree(self, tree):\n\n        dirs  = tree['dirs']; files = tree['files']\n        child_dirs = {name : self.write_dir_tree(contents) for name, contents in dirs.iteritems()}\n        return self.write_index_object('tree', {'files' : files, 'dirs': child_dirs})", "response": "Recur through the dir tree and write it as a set of objects"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if there is an active commit owned by the specified user", "response": "def have_active_commit(self):\n        \"\"\" Checks if there is an active commit owned by the specified user \"\"\"\n\n        commit_state = sfs.file_or_default(sfs.cpjoin(self.base_path, 'active_commit'), None)\n        if commit_state != None: return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\namends last commit Args: append_to_msg: string to append to previous message new_message: new commit message files_to_add: optional list of files to commit", "response": "def amend_commit(\n            self,\n            append_to_msg: typing.Optional[str] = None,\n            new_message: typing.Optional[str] = None,\n            files_to_add: typing.Optional[typing.Union[typing.List[str], str]] = None,\n    ):\n        \"\"\"\n        Amends last commit\n\n        Args:\n            append_to_msg: string to append to previous message\n            new_message: new commit message\n            files_to_add: optional list of files to commit\n        \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_text_code(cls, email, result_text_code):\n        result_code = cls.result_text_codes[result_text_code]\n        return cls(email, result_code)", "response": "Alternative method to create an instance of VerifiedEmail object from a text code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compile(self, source_code, post_treatment=''.join, source='<string>', target='exec'): \n        self.last_python_code = super().compile(source_code, post_treatment)\n        return PyCompiler.executable(self.last_python_code, source, target)", "response": "Compile the code and return the executable object code."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_env_var(key: str, value: str):\n        elib_run.run(f'appveyor SetVariable -Name {key} -Value {value}')\n        AV.info('Env', f'set \"{key}\" -> \"{value}\"')", "response": "Sets environment variable on AV\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init(scope):\r\n    # update globals\r\n    scope['py2q'] = py2q\r\n    scope['q2py'] = q2py\r\n    \r\n    # define wrapper compatibility symbols\r\n    QtCore.THREADSAFE_NONE = None\r\n    \r\n    # define the importable symbols\r\n    scope['QtCore'] = QtCore\r\n    scope['QtGui'] = lazy_import('PyQt4.QtGui')\r\n    scope['QtWebKit'] = lazy_import('PyQt4.QtWebKit')\r\n    scope['QtNetwork'] = lazy_import('PyQt4.QtNetwork')\r\n    scope['QtXml'] = lazy_import('PyQt4.QtXml')\r\n    \r\n    # PyQt4 specific modules\r\n    scope['QtDesigner'] = lazy_import('PyQt4.QtDesigner')\r\n    scope['Qsci'] = lazy_import('PyQt4.Qsci')\r\n    \r\n    scope['uic'] = lazy_import('PyQt4.uic')\r\n    scope['rcc_exe'] = 'pyrcc4'\r\n    \r\n    # map shared core properties\r\n    QtCore.QDate.toPython = lambda x: x.toPyDate()\r\n    QtCore.QDateTime.toPython = lambda x: x.toPyDateTime()\r\n    QtCore.QTime.toPython = lambda x: x.toPyTime()\r\n    \r\n    QtCore.Signal = Signal\r\n    QtCore.Slot = Slot\r\n    QtCore.Property = QtCore.pyqtProperty\r\n    QtCore.SIGNAL = SIGNAL\r\n    QtCore.__version__ = QtCore.QT_VERSION_STR\r\n\r\n    if SIP_VERSION == '2':\r\n        QtCore.QStringList = list\r\n        QtCore.QString = unicode", "response": "Initialize the xqt system with the PyQt4 wrapper for the Qt system."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfreaking out if there are missing local references.", "response": "def validate_internal_deps(self):\n        \"\"\"Freak out if there are missing local references.\"\"\"\n        for node in self.node:\n            if ('target_obj' not in self.node[node]\n                    and node not in self.crossrefs):\n                raise error.BrokenGraph('Missing target: %s referenced from %s'\n                                        ' but not defined there.' %\n                                        (node, self.name))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef crossrefs(self):\n        # TODO: memoize this?\n        crefs = set()\n        for node in self.node:\n            if node.repo != self.target.repo or node.path != self.target.path:\n                crefs.add(node)\n        return crefs", "response": "Returns a set of non - local targets referenced by this build file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a set of paths that are crossrefs for this instance.", "response": "def crossref_paths(self):\n        \"\"\"Just like crossrefs, but all the targets are munged to :all.\"\"\"\n        return set(\n            [address.new(repo=x.repo, path=x.path) for x in self.crossrefs])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse(self, stream):\n        builddata = json.load(stream)\n        log.debug('This is a JSON build file.')\n\n        if 'targets' not in builddata:\n            log.warn('Warning: No targets defined here.')\n            return\n\n        for tdata in builddata['targets']:\n            # TODO: validate name\n            target = address.new(target=tdata.pop('name'),\n                                 repo=self.target.repo,\n                                 path=self.target.path)\n            # Duplicate target definition? Uh oh.\n            if target in self.node and 'target_obj' in self.node[target]:\n                raise error.ButcherError(\n                    'Target is defined more than once: %s', target)\n\n            rule_obj = targets.new(name=target,\n                                   ruletype=tdata.pop('type'),\n                                   **tdata)\n\n            log.debug('New target: %s', target)\n            self.add_node(target, {'target_obj': rule_obj})\n\n            # dep could be \":blabla\" or \"//foo:blabla\" or \"//foo/bar:blabla\"\n            for dep in rule_obj.composed_deps() or []:\n                d_target = address.new(dep)\n                if not d_target.repo:  # \":blabla\"\n                    d_target.repo = self.target.repo\n                if d_target.repo == self.target.repo and not d_target.path:\n                    d_target.path = self.target.path\n                if d_target not in self.nodes():\n                    self.add_node(d_target)\n                log.debug('New dep: %s -> %s', target, d_target)\n                self.add_edge(target, d_target)", "response": "Parse a JSON BUILD file and return a new object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if any of the exception classes caused the failure and return the corresponding argument that matched.", "response": "def check(self, *exc_classes):\n        \"\"\"Check if any of exception classes caused the failure/s.\n\n        :param exc_classes: exception types/exception type names to\n                            search for.\n\n        If any of the contained failures were caused by an exception of a\n        given type, the corresponding argument that matched is returned. If\n        not then ``None`` is returned.\n        \"\"\"\n        if not exc_classes:\n            return None\n        for cause in self:\n            result = cause.check(*exc_classes)\n            if result is not None:\n                return result\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_exc_info(cls, exc_info=None,\n                      retain_exc_info=True,\n                      cause=None, find_cause=True):\n        \"\"\"Creates a failure object from a ``sys.exc_info()`` tuple.\"\"\"\n        if exc_info is None:\n            exc_info = sys.exc_info()\n            if not any(exc_info):\n                raise NoActiveException(\"No exception currently\"\n                                        \" being handled\")\n        # This should always be the (type, value, traceback) tuple,\n        # either from a prior sys.exc_info() call or from some other\n        # creation...\n        if len(exc_info) != 3:\n            raise ValueError(\"Provided 'exc_info' must contain three\"\n                             \" elements\")\n        exc_type, exc_val, exc_tb = exc_info\n        try:\n            if exc_type is None or exc_val is None:\n                raise ValueError(\"Invalid exception tuple (exception\"\n                                 \" type and exception value must\"\n                                 \" be provided)\")\n            exc_args = tuple(getattr(exc_val, 'args', []))\n            exc_kwargs = dict(getattr(exc_val, 'kwargs', {}))\n            exc_type_names = utils.extract_roots(exc_type)\n            if not exc_type_names:\n                exc_type_name = reflection.get_class_name(\n                    exc_val, truncate_builtins=False)\n                # This should only be possible if the exception provided\n                # was not really an exception...\n                raise TypeError(\"Invalid exception type '%s' (not an\"\n                                \" exception)\" % (exc_type_name))\n            exception_str = utils.exception_message(exc_val)\n            if hasattr(exc_val, '__traceback_str__'):\n                traceback_str = exc_val.__traceback_str__\n            else:\n                if exc_tb is not None:\n                    traceback_str = '\\n'.join(\n                        traceback.format_exception(*exc_info))\n                else:\n                    traceback_str = ''\n            if not retain_exc_info:\n                exc_info = None\n            if find_cause and cause is None:\n                cause = cls._extract_cause(exc_val)\n            return cls(exc_info=exc_info, exc_args=exc_args,\n                       exc_kwargs=exc_kwargs, exception_str=exception_str,\n                       exc_type_names=exc_type_names, cause=cause,\n                       traceback_str=traceback_str,\n                       generated_on=sys.version_info[0:2])\n        finally:\n            del exc_type, exc_val, exc_tb", "response": "Creates a failure object from a sys. exc_info tuple."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a failure object from an exception instance.", "response": "def from_exception(cls, exception, retain_exc_info=True,\n                       cause=None, find_cause=True):\n        \"\"\"Creates a failure object from a exception instance.\"\"\"\n        exc_info = (\n            type(exception),\n            exception,\n            getattr(exception, '__traceback__', None)\n        )\n        return cls.from_exc_info(exc_info=exc_info,\n                                 retain_exc_info=retain_exc_info,\n                                 cause=cause, find_cause=find_cause)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating input data matches expected failure dict format.", "response": "def validate(cls, data):\n        \"\"\"Validate input data matches expected failure ``dict`` format.\"\"\"\n        try:\n            jsonschema.validate(\n                data, cls.SCHEMA,\n                # See: https://github.com/Julian/jsonschema/issues/148\n                types={'array': (list, tuple)})\n        except jsonschema.ValidationError as e:\n            raise InvalidFormat(\"Failure data not of the\"\n                                \" expected format: %s\" % (e.message))\n        else:\n            # Ensure that all 'exc_type_names' originate from one of\n            # base exceptions, because those are the root exceptions that\n            # python mandates/provides and anything else is invalid...\n            causes = collections.deque([data])\n            while causes:\n                cause = causes.popleft()\n                try:\n                    generated_on = cause['generated_on']\n                    ok_bases = cls.BASE_EXCEPTIONS[generated_on[0]]\n                except (KeyError, IndexError):\n                    ok_bases = []\n                root_exc_type = cause['exc_type_names'][-1]\n                if root_exc_type not in ok_bases:\n                    raise InvalidFormat(\n                        \"Failure data 'exc_type_names' must\"\n                        \" have an initial exception type that is one\"\n                        \" of %s types: '%s' is not one of those\"\n                        \" types\" % (ok_bases, root_exc_type))\n                sub_cause = cause.get('cause')\n                if sub_cause is not None:\n                    causes.append(sub_cause)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if another object is equivalent to this object.", "response": "def matches(self, other):\n        \"\"\"Checks if another object is equivalent to this object.\n\n        :returns: checks if another object is equivalent to this object\n        :rtype: boolean\n        \"\"\"\n        if not isinstance(other, Failure):\n            return False\n        if self.exc_info is None or other.exc_info is None:\n            return self._matches(other)\n        else:\n            return self == other"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reraise_if_any(failures, cause_cls_finder=None):\n        if not isinstance(failures, (list, tuple)):\n            # Convert generators/other into a list...\n            failures = list(failures)\n        if len(failures) == 1:\n            failures[0].reraise(cause_cls_finder=cause_cls_finder)\n        elif len(failures) > 1:\n            raise WrappedFailure(failures)", "response": "Re - raise exceptions if argument is not empty."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if any of the given exceptions caused the failure.", "response": "def check(self, *exc_classes):\n        \"\"\"Check if any of ``exc_classes`` caused the failure.\n\n        Arguments of this method can be exception types or type\n        names (strings **fully qualified**). If captured exception is\n        an instance of exception of given type, the corresponding argument\n        is returned, otherwise ``None`` is returned.\n        \"\"\"\n        for cls in exc_classes:\n            cls_name = utils.cls_to_cls_name(cls)\n            if cls_name in self._exc_type_names:\n                return cls\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\niterate over all causes.", "response": "def iter_causes(self):\n        \"\"\"Iterate over all causes.\"\"\"\n        curr = self._cause\n        while curr is not None:\n            yield curr\n            curr = curr._cause"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting this from a dictionary to a object.", "response": "def from_dict(cls, data):\n        \"\"\"Converts this from a dictionary to a object.\"\"\"\n        data = dict(data)\n        cause = data.get('cause')\n        if cause is not None:\n            data['cause'] = cls.from_dict(cause)\n        return cls(**data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting this object to a dictionary.", "response": "def to_dict(self, include_args=True, include_kwargs=True):\n        \"\"\"Converts this object to a dictionary.\n\n        :param include_args: boolean indicating whether to include the\n                             exception args in the output.\n        :param include_kwargs: boolean indicating whether to include the\n                               exception kwargs in the output.\n        \"\"\"\n        data = {\n            'exception_str': self.exception_str,\n            'traceback_str': self.traceback_str,\n            'exc_type_names': self.exception_type_names,\n            'exc_args': self.exception_args if include_args else tuple(),\n            'exc_kwargs': self.exception_kwargs if include_kwargs else {},\n            'generated_on': self.generated_on,\n        }\n        if self._cause is not None:\n            data['cause'] = self._cause.to_dict(include_args=include_args,\n                                                include_kwargs=include_kwargs)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy(self, deep=False):\n        cause = self._cause\n        if cause is not None:\n            cause = cause.copy(deep=deep)\n        exc_info = utils.copy_exc_info(self.exc_info, deep=deep)\n        exc_args = self.exception_args\n        exc_kwargs = self.exception_kwargs\n        if deep:\n            exc_args = copy.deepcopy(exc_args)\n            exc_kwargs = copy.deepcopy(exc_kwargs)\n        else:\n            exc_args = tuple(exc_args)\n            exc_kwargs = exc_kwargs.copy()\n        # These are just simple int/strings, so deep copy doesn't really\n        # matter/apply here (as they are immutable anyway).\n        exc_type_names = tuple(self._exc_type_names)\n        generated_on = self._generated_on\n        if generated_on:\n            generated_on = tuple(generated_on)\n        # NOTE(harlowja): use `self.__class__` here so that we can work\n        # with subclasses (assuming anyone makes one).\n        return self.__class__(exc_info=exc_info,\n                              exception_str=self.exception_str,\n                              traceback_str=self.traceback_str,\n                              exc_args=exc_args,\n                              exc_kwargs=exc_kwargs,\n                              exc_type_names=exc_type_names,\n                              cause=cause, generated_on=generated_on)", "response": "Copies this object (shallow or deep).\n\n        :param deep: boolean indicating whether to do a deep copy (or a\n                     shallow copy)."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting the location of a single feature and its version", "response": "def explain_feature(featurename):\n    '''print the location of single feature and its version\n\n    if the feature is located inside a git repository,\n    this will also print the git-rev and modified files\n    '''\n\n    import os\n    import featuremonkey\n    import importlib\n    import subprocess\n\n    def guess_version(feature_module):\n        if hasattr(feature_module, '__version__'):\n            return feature_module.__version__\n        if hasattr(feature_module, 'get_version'):\n            return feature_module.get_version()\n        return ('unable to determine version:'\n                ' please add __version__ or get_version()'\n                ' to this feature module!')\n\n    def git_rev(module):\n        stdout, stderr = subprocess.Popen(\n            [\"git\", \"rev-parse\", \"HEAD\"],\n            cwd=os.path.dirname(module.__file__),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE\n        ).communicate()\n        if 'Not a git repo' in stderr:\n            return '-'\n        else:\n            return stdout.strip()\n\n    def git_changes(module):\n        stdout = subprocess.Popen(\n            [\"git\", \"diff\", \"--name-only\"],\n            cwd=os.path.dirname(module.__file__),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE\n        ).communicate()[0]\n        return stdout.strip() or '-'\n\n    if featurename in featuremonkey.get_features_from_equation_file(os.environ['PRODUCT_EQUATION_FILENAME']):\n        print()\n        print(featurename)\n        print('-' * 60)\n        print()\n        is_subfeature = '.features.' in featurename\n        try:\n            feature_module = importlib.import_module(featurename)\n        except ImportError:\n            print('Error: unable to import feature \"%s\"' % featurename)\n\n        print('Location: %s' % os.path.dirname(feature_module.__file__))\n        print()\n        if is_subfeature:\n            print('Version: see parent feature')\n            print()\n        else:\n            print('Version: %s' % str(guess_version(feature_module)))\n            print()\n            print('git: %s' % git_rev(feature_module))\n            print()\n            print('git changed: %s' % '\\n\\t\\t'.join(git_changes(feature_module).split('\\n')))\n    else:\n        print('No feature named ' + featurename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef explain_features():\n    '''print the location of each feature and its version\n\n    if the feature is located inside a git repository, this will also print the git-rev and modified files\n    '''\n    from ape import tasks\n    import featuremonkey\n    import os\n\n    featurenames = featuremonkey.get_features_from_equation_file(os.environ['PRODUCT_EQUATION_FILENAME'])\n\n    for featurename in featurenames:\n        tasks.explain_feature(featurename)", "response": "print the location of each feature and its version"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef git_day():\n    vec = ['env', 'TZ=UTC', 'git', 'log', '--date=iso-local', '--pretty=%ad']\n    day = cmd(*(vec + ['-n', '1'])).split()[0]\n    commits = cmd(*(vec + ['--since', day + 'T00:00Z'])).strip()\n    n = len(commits.split('\\n'))\n    day = day.replace('-', '')\n    if n > 1:\n        day += '.%s' % n\n    # Branches that are not master are treated as local:\n    #   https://www.python.org/dev/peps/pep-0440/#local-version-identifiers\n    branch = get_git_branch()\n    if branch != 'master':\n        day += '+' + s(branch)\n    return day", "response": "Constructs a version string of the form git - day - branch - name - if - not - master - > + local - version - identifiers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef git_version():\n    tag = cmd('git', 'describe').strip()\n    pieces = s(tag).split('-')\n    dotted = pieces[0]\n    if len(pieces) < 2:\n        distance = None\n    else:\n        # Distance from the latest tag is treated as a patch level.\n        distance = pieces[1]\n        dotted += '.' + s(distance)\n    # Branches that are not master are treated as local:\n    #   https://www.python.org/dev/peps/pep-0440/#local-version-identifiers\n    if distance is not None:\n        branch = get_git_branch()\n        if branch != 'master':\n            dotted += '+' + s(branch)\n    return dotted", "response": "Constructs a version string of the form that can be used in PEP - 440."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef imprint(self, path=None):\n        if self.version is not None:\n            with open(path or self.version_file, 'w') as h:\n                h.write(self.version + '\\n')\n        else:\n            raise ValueError('Can not write null version to file.')\n        return self", "response": "Write the version of the current instance to the version file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_file(self, path=None):\n        if self._version is None:\n            self._version = file_version(path or self.version_file)\n        return self", "response": "Load the current version from the specified file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_git(self, path=None, prefer_daily=False):\n        if self._version is None:\n            frame = caller(1)\n            path = frame.f_globals.get('__file__') or '.'\n            providers = ([git_day, git_version] if prefer_daily\n                         else [git_version, git_day])\n            for provider in providers:\n                if self._version is not None:\n                    break\n                try:\n                    with cd(path):\n                        self._version = provider()\n                except CalledProcessError:\n                    pass\n                except OSError as e:\n                    if e.errno != errno.ENOENT:\n                        raise\n        return self", "response": "Use Git to determine the package version."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_pkg(self):\n        if self._version is None:\n            frame = caller(1)\n            pkg = frame.f_globals.get('__package__')\n            if pkg is not None:\n                self._version = pkg_version(pkg)\n        return self", "response": "Use pkg_resources to determine the installed package version."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the current state of the Herald message into the peer description.", "response": "def __load_dump(self, message):\n        \"\"\"\n        Calls the hook method to modify the loaded peer description before\n        giving it to the directory\n\n        :param message: The received Herald message\n        :return: The updated peer description\n        \"\"\"\n        dump = message.content\n        if self._hook is not None:\n            # Call the hook\n            try:\n                updated_dump = self._hook(message, dump)\n                if updated_dump is not None:\n                    # Use the new description\n                    dump = updated_dump\n            except (TypeError, ValueError) as ex:\n                self._logger(\"Invalid description hook: %s\", ex)\n        return dump"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle a message received by Herald.", "response": "def herald_message(self, herald_svc, message):\n        \"\"\"\n        Handles a message received by Herald\n\n        :param herald_svc: Herald service\n        :param message: Received message\n        \"\"\"\n        subject = message.subject\n        if subject == SUBJECT_DISCOVERY_STEP_1:\n            # Step 1: Register the remote peer and reply with our dump\n            try:\n                # Delayed registration\n                notification = self._directory.register_delayed(\n                    self.__load_dump(message))\n\n                peer = notification.peer\n                if peer is not None:\n                    # Registration succeeded\n                    self.__delayed_notifs[peer.uid] = notification\n\n                    # Reply with our dump\n                    herald_svc.reply(\n                        message, self._directory.get_local_peer().dump(),\n                        SUBJECT_DISCOVERY_STEP_2)\n            except ValueError:\n                self._logger.error(\"Error registering a discovered peer\")\n\n        elif subject == SUBJECT_DISCOVERY_STEP_2:\n            # Step 2: Register the dump, notify local listeners, then let\n            # the remote peer notify its listeners\n            try:\n                # Register the peer\n                notification = self._directory.register_delayed(\n                    self.__load_dump(message))\n\n                if notification.peer is not None:\n                    # Let the remote peer notify its listeners\n                    herald_svc.reply(message, None, SUBJECT_DISCOVERY_STEP_3)\n\n                    # Now we can notify listeners\n                    notification.notify()\n            except ValueError:\n                self._logger.error(\"Error registering a peer using the \"\n                                   \"description it sent\")\n\n        elif subject == SUBJECT_DISCOVERY_STEP_3:\n            # Step 3: notify local listeners about the remote peer\n            try:\n                self.__delayed_notifs.pop(message.sender).notify()\n            except KeyError:\n                # Unknown peer\n                pass\n        else:\n            # Unknown subject\n            self._logger.warning(\"Unknown discovery step: %s\", subject)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the API_URL of the current class.", "response": "def api_url(self):\n        \"\"\"Returns the api_url or None.\n        \"\"\"\n        if not self._api_url:\n            error_msg = (\n                f\"Email is enabled but API_URL is not set. \"\n                f\"See settings.{self.api_url_attr}\"\n            )\n            try:\n                self._api_url = getattr(settings, self.api_url_attr)\n            except AttributeError:\n                raise EmailNotEnabledError(error_msg, code=\"api_url_attribute_error\")\n            else:\n                if not self._api_url:\n                    raise EmailNotEnabledError(error_msg, code=\"api_url_is_none\")\n        return self._api_url"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef api_key(self):\n        if not self._api_key:\n            error_msg = (\n                f\"Email is enabled but API_KEY is not set. \"\n                f\"See settings.{self.api_key_attr}\"\n            )\n            try:\n                self._api_key = getattr(settings, self.api_key_attr)\n            except AttributeError:\n                raise EmailNotEnabledError(error_msg, code=\"api_key_attribute_error\")\n            else:\n                if not self._api_key:\n                    raise EmailNotEnabledError(error_msg, code=\"api_key_is_none\")\n        return self._api_key", "response": "Returns the API_KEY of the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subscribe(self, user, verbose=None):\n        if not self.email_enabled:\n            raise EmailNotEnabledError(\"See settings.EMAIL_ENABLED\")\n        if not user.email:\n            raise UserEmailError(f\"User {user}'s email address is not defined.\")\n        response = requests.post(\n            f\"{self.api_url}/{self.address}/members\",\n            auth=(\"api\", self.api_key),\n            data={\n                \"subscribed\": True,\n                \"address\": user.email,\n                \"name\": f\"{user.first_name} {user.last_name}\",\n                \"description\": f'{user.userprofile.job_title or \"\"}',\n                \"upsert\": \"yes\",\n            },\n        )\n        if verbose:\n            sys.stdout.write(\n                f\"Subscribing {user.email} to {self.address}. \"\n                f\"Got response={response.status_code}.\\n\"\n            )\n        return response", "response": "Subscribes a user to the list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a response after attempting to unsubscribe a member from the list.", "response": "def unsubscribe(self, user, verbose=None):\n        \"\"\"Returns a response after attempting to unsubscribe\n        a member from the list.\n        \"\"\"\n        if not self.email_enabled:\n            raise EmailNotEnabledError(\"See settings.EMAIL_ENABLED\")\n        response = requests.put(\n            f\"{self.api_url}/{self.address}/members/{user.email}\",\n            auth=(\"api\", self.api_key),\n            data={\"subscribed\": False},\n        )\n        if verbose:\n            sys.stdout.write(\n                f\"Unsubscribing {user.email} from {self.address}. \"\n                f\"Got response={response.status_code}.\\n\"\n            )\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self, verbose=None):\n        if not self.email_enabled:\n            raise EmailNotEnabledError(\"See settings.EMAIL_ENABLED\")\n        response = requests.post(\n            self.api_url,\n            auth=(\"api\", self.api_key),\n            data={\n                \"address\": self.address,\n                \"name\": self.name,\n                \"description\": self.display_name,\n            },\n        )\n        if verbose:\n            sys.stdout.write(\n                f\"Creating mailing list {self.address}. \"\n                f\"Got response={response.status_code}.\\n\"\n            )\n        return response", "response": "Creates a new mailing list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a response after attempting to delete the list.", "response": "def delete(self):\n        \"\"\"Returns a response after attempting to delete the list.\n        \"\"\"\n        if not self.email_enabled:\n            raise EmailNotEnabledError(\"See settings.EMAIL_ENABLED\")\n        return requests.delete(\n            f\"{self.api_url}/{self.address}\", auth=(\"api\", self.api_key)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_member(self, user):\n        if not self.email_enabled:\n            raise EmailNotEnabledError(\"See settings.EMAIL_ENABLED\")\n        return requests.delete(\n            f\"{self.api_url}/{self.address}/members/{user.email}\",\n            auth=(\"api\", self.api_key),\n        )", "response": "Removes a member from the list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning FBPE key for a sequence of FBPE code.", "response": "def fbpe_key(code):\n    \"\"\"\n    input:\n        'S0102-67202009000300001'\n    output:\n        'S0102-6720(09)000300001'\n    \"\"\"\n\n    begin = code[0:10]\n    year = code[12:14]\n    end = code[14:]\n\n    return '%s(%s)%s' % (begin, year, end)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef join_accesses(unique_id, accesses, from_date, until_date, dayly_granularity):\n    logger.debug('joining accesses for: %s' % unique_id)\n    joined_data = {}\n    listed_data = []\n    def joining_monthly(joined_data, atype, data):\n\n        if 'total' in data:\n            del(data['total'])\n\n        for year, months in data.items():\n            del(months['total'])\n            for month in months:\n\n                dt = '%s-%s' % (year[1:], month[1:])\n                if not dt >= from_date[:7] or not dt <= until_date[:7]:\n                    continue\n                joined_data.setdefault(dt, {})\n                joined_data[dt].setdefault(atype, 0)\n                joined_data[dt][atype] += data[year][month]['total']\n\n        return joined_data\n\n    def joining_dayly(joined_data, atype, data):\n\n        if 'total' in data:\n            del(data['total'])\n\n        for year, months in data.items():\n            del(months['total'])\n            for month, days in months.items():\n                del(days['total'])\n                for day in days:\n                    dt = '%s-%s-%s' % (year[1:], month[1:], day[1:])\n                    if not dt >= from_date or not dt <= until_date:\n                        continue\n                    joined_data.setdefault(dt, {})\n                    joined_data[dt].setdefault(atype, 0)\n                    joined_data[dt][atype] += data[year][month][day]\n\n        return joined_data\n\n    joining = joining_monthly\n    if dayly_granularity:\n        joining = joining_dayly\n\n    for data in accesses:\n        for key, value in data.items():\n            if not key in ['abstract', 'html', 'pdf', 'readcube']:\n                continue\n            joined_data = joining(joined_data, key, value)\n\n    return joined_data", "response": "Join the accesses of a unique_id with the given accesses."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a string into a date object.", "response": "def str2date(self, datestr):\n        \"\"\"Parse date from string. If no template matches this string,\n        raise Error. Please go\n        https://github.com/MacHu-GWU/rolex-project/issues\n        submit your date string. I 'll update templates asap.\n\n        This method is faster than :meth:`dateutil.parser.parse`.\n\n        :param datestr: a string represent a date\n        :type datestr: str\n        :return: a date object\n\n        **\u4e2d\u6587\u6587\u6863**\n\n        \u4ecestring\u89e3\u6790date\u3002\u9996\u5148\u5c1d\u8bd5\u9ed8\u8ba4\u6a21\u677f, \u5982\u679c\u5931\u8d25\u4e86, \u5219\u5c1d\u8bd5\u6240\u6709\u7684\u6a21\u677f\u3002\n        \u4e00\u65e6\u5c1d\u8bd5\u6210\u529f, \u5c31\u5c06\u5f53\u524d\u6210\u529f\u7684\u6a21\u677f\u4fdd\u5b58\u4e3a\u9ed8\u8ba4\u6a21\u677f\u3002\u8fd9\u6837\u505a\u5728\u5f53\u4f60\u5f85\u89e3\u6790\u7684\n        \u5b57\u7b26\u4e32\u975e\u5e38\u591a, \u4e14\u6a21\u5f0f\u5355\u4e00\u65f6, \u53ea\u6709\u7b2c\u4e00\u6b21\u5c1d\u8bd5\u8017\u65f6\u8f83\u591a, \u4e4b\u540e\u5c31\u975e\u5e38\u5feb\u4e86\u3002\n        \u8be5\u65b9\u6cd5\u8981\u5feb\u8fc7 :meth:`dateutil.parser.parse` \u65b9\u6cd5\u3002\n        \"\"\"\n        if datestr is None:\n            raise ValueError(\n                \"Parser must be a string or character stream, not NoneType\")\n\n        # try default date template\n        try:\n            return datetime.strptime(\n                datestr, self.default_date_template).date()\n        except:\n            pass\n\n        # try every datetime templates\n        for template in DateTemplates:\n            try:\n                dt = datetime.strptime(datestr, template)\n                self.default_date_template = template\n                return dt.date()\n            except:\n                pass\n\n        # raise error\n        raise Exception(\"Unable to parse date from: %r\" % datestr)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _str2datetime(self, datetimestr):\n        if datetimestr is None:\n            raise ValueError(\n                \"Parser must be a string or character stream, not NoneType\")\n\n        # try default datetime template\n        try:\n            return datetime.strptime(\n                datetimestr, self.default_datetime_template)\n        except:\n            pass\n\n        # try every datetime templates\n        for template in DatetimeTemplates:\n            try:\n                dt = datetime.strptime(datetimestr, template)\n                self.default_datetime_template = template\n                return dt\n            except:\n                pass\n\n        # raise error\n        dt = parser.parse(datetimestr)\n        self.str2datetime = parser.parse\n\n        return dt", "response": "Parse a string into a datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_date(self, value):\n        if value is None:\n            raise Exception(\"Unable to parse date from %r\" % value)\n        elif isinstance(value, string_types):\n            return self.str2date(value)\n        elif isinstance(value, int):\n            return date.fromordinal(value)\n        elif isinstance(value, datetime):\n            return value.date()\n        elif isinstance(value, date):\n            return value\n        else:\n            raise Exception(\"Unable to parse date from %r\" % value)", "response": "A lazy method to parse anything to date."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_datetime(self, value):\n        if value is None:\n            raise Exception(\"Unable to parse datetime from %r\" % value)\n        elif isinstance(value, string_types):\n            return self.str2datetime(value)\n        elif isinstance(value, integer_types):\n            return self.from_utctimestamp(value)\n        elif isinstance(value, float):\n            return self.from_utctimestamp(value)\n        elif isinstance(value, datetime):\n            return value\n        elif isinstance(value, date):\n            return datetime(value.year, value.month, value.day)\n        else:\n            raise Exception(\"Unable to parse datetime from %r\" % value)", "response": "A lazy method to parse anything to datetime."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating number of seconds from UTC 1970 - 01 - 01 00 : 00 : 00", "response": "def to_utctimestamp(self, dt):\n        \"\"\"Calculate number of seconds from UTC 1970-01-01 00:00:00.\n\n        When:\n\n        - dt doesn't have tzinfo: assume it's a utc time\n        - dt has tzinfo: use tzinfo\n\n        WARNING, if your datetime object doens't have ``tzinfo``, make sure\n        it's a UTC time, but **NOT a LOCAL TIME**.\n\n        **\u4e2d\u6587\u6587\u6863**\n\n        \u8ba1\u7b97\u65f6\u95f4\u6233\n\n        \u82e5:\n\n        - \u4e0d\u5e26tzinfo: \u5219\u9ed8\u8ba4\u4e3a\u662fUTC time\n        - \u5e26tzinfo: \u4f7f\u7528tzinfo\n        \"\"\"\n        if dt.tzinfo is None:\n            dt = dt.replace(tzinfo=utc)\n        delta = dt - datetime(1970, 1, 1, tzinfo=utc)\n        return delta.total_seconds()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a **UTC datetime** object that number of seconds after UTC 1970 - 01 - 01 00 : 00 : 00.", "response": "def from_utctimestamp(self, timestamp):\n        \"\"\"Create a **UTC datetime** object that number of seconds after\n        UTC 1970-01-01 00:00:00. If you want local time, use\n        :meth:`Rolex.from_timestamp`\n\n        Because python doesn't support negative timestamp to datetime\n        so we have to implement my own method.\n\n        **\u4e2d\u6587\u6587\u6863**\n\n        \u8fd4\u56de\u4e00\u4e2a\u5728UTC 1970-01-01 00:00:00 \u4e4b\u540e #timestamp \u79d2\u540e\u7684\u65f6\u95f4\u3002\u9ed8\u8ba4\u4e3a\n        UTC\u65f6\u95f4\u3002\u5373\u8fd4\u56de\u7684datetime\u4e0d\u5e26tzinfo\n        \"\"\"\n        if timestamp >= 0:\n            return datetime.utcfromtimestamp(timestamp)\n        else:\n            return datetime(1970, 1, 1) + timedelta(seconds=timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses frequency string into timedelta object.", "response": "def _freq_parser(self, freq):\n        \"\"\"Parse timedelta.\n\n        Valid keywords \"days\", \"day\", \"d\", \"hours\", \"hour\", \"h\",\n        \"minutes\", \"minute\", \"min\", \"m\", \"seconds\", \"second\", \"sec\", \"s\",\n        \"weeks\", \"week\", \"w\",\n        \"\"\"\n        freq = freq.lower().strip()\n\n        valid_keywords = [\n            \"days\", \"day\", \"d\",\n            \"hours\", \"hour\", \"h\",\n            \"minutes\", \"minute\", \"min\", \"m\",\n            \"seconds\", \"second\", \"sec\", \"s\",\n            \"weeks\", \"week\", \"w\",\n        ]\n        error_message = \"'%s' is invalid, use one of %s\" % (\n            freq, valid_keywords)\n\n        try:\n            # day\n            for surfix in [\"days\", \"day\", \"d\"]:\n                if freq.endswith(surfix):\n                    freq = freq.replace(surfix, \"\")\n                    return timedelta(days=int(freq))\n\n            # hour\n            for surfix in [\"hours\", \"hour\", \"h\"]:\n                if freq.endswith(surfix):\n                    freq = freq.replace(surfix, \"\")\n                    return timedelta(hours=int(freq))\n\n            # minute\n            for surfix in [\"minutes\", \"minute\", \"min\", \"m\"]:\n                if freq.endswith(surfix):\n                    freq = freq.replace(surfix, \"\")\n                    return timedelta(minutes=int(freq))\n\n            # second\n            for surfix in [\"seconds\", \"second\", \"sec\", \"s\"]:\n                if freq.endswith(surfix):\n                    freq = freq.replace(surfix, \"\")\n                    return timedelta(seconds=int(freq))\n\n            # week\n            for surfix in [\"weeks\", \"week\", \"w\"]:\n                if freq.endswith(surfix):\n                    freq = freq.replace(surfix, \"\")\n                    return timedelta(days=int(freq) * 7)\n        except:\n            pass\n\n        raise ValueError(error_message)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a datetime series with same weekday number.", "response": "def weekday_series(self, start, end, weekday, return_date=False):\n        \"\"\"Generate a datetime series with same weekday number.\n\n        ISO weekday number: Mon to Sun = 1 to 7\n\n        Usage::\n\n            >>> start, end = \"2014-01-01 06:30:25\", \"2014-02-01 06:30:25\"\n            >>> rolex.weekday_series(start, end, weekday=2) # All Tuesday\n            [\n                datetime(2014, 1, 7, 6, 30, 25),\n                datetime(2014, 1, 14, 6, 30, 25),\n                datetime(2014, 1, 21, 6, 30, 25),\n                datetime(2014, 1, 28, 6, 30, 25),\n            ]\n\n        :param weekday: int or list of int\n\n        **\u4e2d\u6587\u6587\u6863**\n\n        \u751f\u6210\u661f\u671f\u6570\u4e00\u81f4\u7684\u65f6\u95f4\u5e8f\u5217\u3002\n        \"\"\"\n        start = self.parse_datetime(start)\n        end = self.parse_datetime(end)\n\n        if isinstance(weekday, integer_types):\n            weekday = [weekday, ]\n\n        series = list()\n        for i in self.time_series(\n                start, end, freq=\"1day\", return_date=return_date):\n            if i.isoweekday() in weekday:\n                series.append(i)\n\n        return series"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rnd_date(self, start=date(1970, 1, 1), end=date.today()):\n        if isinstance(start, string_types):\n            start = self.str2date(start)\n        if isinstance(end, string_types):\n            end = self.str2date(end)\n        if start > end:\n            raise ValueError(\"start time has to be earlier than end time\")\n        return date.fromordinal(\n            random.randint(start.toordinal(), end.toordinal()))", "response": "Generate a random date between start and end time."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rnd_date_array(self, size, start=date(1970, 1, 1), end=date.today()):\n        if isinstance(start, string_types):\n            start = self.str2date(start)\n        if isinstance(end, string_types):\n            end = self.str2date(end)\n        if start > end:\n            raise ValueError(\"start time has to be earlier than end time\")\n\n        return self.randn(size, self._rnd_date, start, end)", "response": "Return random date array."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rnd_datetime(self, start=datetime(1970, 1, 1), end=datetime.now()):\n        if isinstance(start, string_types):\n            start = self.str2datetime(start)\n        if isinstance(end, str):\n            end = self.str2datetime(end)\n        if start > end:\n            raise ValueError(\"start time has to be earlier than end time\")\n        return self.from_utctimestamp(\n            random.randint(\n                int(self.to_utctimestamp(start)),\n                int(self.to_utctimestamp(end)),\n            )\n        )", "response": "Generate a random datetime between start and end time."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an array of random datetime objects.", "response": "def rnd_datetime_array(self,\n                           size, start=datetime(1970, 1, 1), end=datetime.now()):\n        \"\"\"Array or Matrix of random datetime generator.\n        \"\"\"\n        if isinstance(start, string_types):\n            start = self.str2datetime(start)\n        if isinstance(end, str):\n            end = self.str2datetime(end)\n        if start > end:\n            raise ValueError(\"start time has to be earlier than end time\")\n\n        return self.randn(size, self._rnd_datetime, start, end)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_seconds(self, datetimestr, n):\n        a_datetime = self.parse_datetime(datetimestr)\n        return a_datetime + timedelta(seconds=n)", "response": "Returns a time that n seconds after a time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a time that n minutes after a time.", "response": "def add_minutes(self, datetimestr, n):\n        \"\"\"Returns a time that n minutes after a time.\n\n        :param datetimestr: a datetime object or a datetime str\n        :param n: number of minutes, value can be negative\n\n        **\u4e2d\u6587\u6587\u6863**\n\n        \u8fd4\u56de\u7ed9\u5b9a\u65e5\u671fN\u5206\u949f\u4e4b\u540e\u7684\u65f6\u95f4\u3002\n        \"\"\"\n        a_datetime = self.parse_datetime(datetimestr)\n        return a_datetime + timedelta(seconds=60 * n)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a time that n hours after a time.", "response": "def add_hours(self, datetimestr, n):\n        \"\"\"Returns a time that n hours after a time.\n\n        :param datetimestr: a datetime object or a datetime str\n        :param n: number of hours, value can be negative\n\n        **\u4e2d\u6587\u6587\u6863**\n\n        \u8fd4\u56de\u7ed9\u5b9a\u65e5\u671fN\u5c0f\u65f6\u4e4b\u540e\u7684\u65f6\u95f4\u3002\n        \"\"\"\n        a_datetime = self.parse_datetime(datetimestr)\n        return a_datetime + timedelta(seconds=3600 * n)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_weeks(self, datetimestr, n, return_date=False):\n        a_datetime = self.parse_datetime(datetimestr)\n        a_datetime += timedelta(days=7 * n)\n        if return_date:\n            return a_datetime.date()\n        else:\n            return a_datetime", "response": "Returns a time that n weeks after a time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a time that n years after a time.", "response": "def add_years(self, datetimestr, n, return_date=False):\n        \"\"\"Returns a time that n years after a time.\n\n        :param datetimestr: a datetime object or a datetime str\n        :param n: number of years, value can be negative\n        :param return_date: returns a date object instead of datetime\n\n        **\u4e2d\u6587\u6587\u6863**\n\n        \u8fd4\u56de\u7ed9\u5b9a\u65e5\u671fN\u5e74\u4e4b\u540e\u7684\u65f6\u95f4\u3002\n        \"\"\"\n        a_datetime = self.parse_datetime(datetimestr)\n\n        try:\n            a_datetime = datetime(\n                a_datetime.year + n, a_datetime.month, a_datetime.day,\n                a_datetime.hour, a_datetime.minute,\n                a_datetime.second, a_datetime.microsecond)\n        except:\n            a_datetime = datetime(\n                a_datetime.year + n, 2, 28,\n                a_datetime.hour, a_datetime.minute,\n                a_datetime.second, a_datetime.microsecond)\n\n        if return_date:\n            return a_datetime.date()\n        else:\n            return a_datetime"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef round_to(self, dt, hour, minute, second, mode=\"floor\"):\n        mode = mode.lower()\n\n        new_dt = datetime(dt.year, dt.month, dt.day, hour, minute, second)\n        if mode == \"floor\":\n            if new_dt <= dt:\n                return new_dt\n            else:\n                return rolex.add_days(new_dt, -1)\n        elif mode == \"ceiling\":\n            if new_dt >= dt:\n                return new_dt\n            else:\n                return rolex.add_days(new_dt, 1)\n        else:\n            raise ValueError(\"'mode' has to be 'floor' or 'ceiling'!\")", "response": "Round the given datetime to specified hour minute and second."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun all linters in the base tree.", "response": "def lint(ctx: click.Context, amend: bool = False, stage: bool = False):\n    \"\"\"\n    Runs all linters\n\n    Args:\n        ctx: click context\n        amend: whether or not to commit results\n        stage: whether or not to stage changes\n    \"\"\"\n    _lint(ctx, amend, stage)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls the callback function of the post message.", "response": "def callback(self, herald_svc, message):\n        \"\"\"\n        Tries to call the callback of the post message.\n        Avoids errors to go outside this method.\n\n        :param herald_svc: Herald service instance\n        :param message: Received answer message\n        \"\"\"\n        if self.__callback is not None:\n            try:\n                # pylint: disable=W0703\n                self.__callback(herald_svc, message)\n            except Exception as ex:\n                _logger.exception(\"Error calling callback: %s\", ex)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef errback(self, herald_svc, exception):\n        if self.__errback is not None:\n            try:\n                # pylint: disable=W0703\n                self.__errback(herald_svc, exception)\n            except Exception as ex:\n                _logger.exception(\"Error calling errback: %s\", ex)", "response": "Calls the error callback of the post message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef socket_set_hwm(socket, hwm=-1):\n    try:\n        socket.sndhwm = socket.rcvhwm = hwm\n    except AttributeError:\n        socket.hwm = hwm", "response": "set hwm of socket"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef zpipe(ctx):\n    a = ctx.socket(zmq.PAIR)\n    a.linger = 0\n    b = ctx.socket(zmq.PAIR)\n    b.linger = 0\n    socket_set_hwm(a, 1)\n    socket_set_hwm(b, 1)\n    iface = \"inproc://%s\" % binascii.hexlify(os.urandom(8))\n    a.bind(iface)\n    b.connect(iface)\n    return a, b", "response": "build inproc pipe for talking to threads\n    mimic pipe used in czmq zthread_fork."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a country for a single resource.", "response": "def get_country(similar=False, **kwargs):\n    \"\"\"\n    Get a country for pycountry\n    \"\"\"\n    result_country = None\n    try:\n        if similar:\n            for country in countries:\n                if kwargs.get('name', '') in country.name:\n                    result_country = country\n                    break\n        else:\n            result_country = countries.get(**kwargs)\n    except Exception as ex:\n        msg = ('Country not found in pycountry with params introduced'\n               ' - {}'.format(ex))\n        logger.error(msg, params=kwargs)\n\n    return result_country"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving location coordinates from an address introduced.", "response": "def get_location(address=\"\"):\n    \"\"\"\n    Retrieve location coordinates from an address introduced.\n    \"\"\"\n    coordinates = None\n    try:\n        geolocator = Nominatim()\n        location = geolocator.geocode(address)\n        coordinates = (location.latitude, location.longitude)\n    except Exception as ex:\n        logger.error('Fail get location - {}'.format(ex))\n    return coordinates"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_address(coords=None, **kwargs):\n    address = None\n    try:\n        if (not coords) and \\\n            ('latitude' in kwargs and 'longitude' in kwargs) or \\\n                ('location' in kwargs):\n\n            coords = kwargs.get(\n                'location', (kwargs.get('latitude'), kwargs.get('longitude')))\n\n        # transform coords\n        if isinstance(coords, (list, tuple)) and len(coords) == 2:\n            coords = \"{}, {}\".join(map(str, coords))\n\n        geolocator = Nominatim()\n        location = geolocator.reverse(coords)\n        address = location.address\n    except Exception as ex:\n        logger.error('Fail get reverse address - {}'.format(ex))\n    return address", "response": "Retrieve a address from a location in coords format introduced."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_documents(self, documents, fully_formed=False):\n        def add_id(document, id):\n            def make_id_tag(root, rel_path, max_depth):\n                if max_depth < 0:\n                    raise ParameterError(\"document_id_xpath too deep!\")\n                if not rel_path:\n                    return root\n                else:\n                    child = root.find(rel_path[0])\n                    if child is None:\n                        child = ET.Element(rel_path[0])\n                        root.append(child)\n                    return make_id_tag(child, rel_path[1:], max_depth - 1)\n            make_id_tag(document, doc_id_xpath, 10).text = str(id)\n\n        if fully_formed: # documents is a list or single document that contians root tags and id fields.\n            if not isinstance(documents, list):\n                documents = [documents]\n        else: # documents is dict with ids as keys and documents as values.\n            doc_root_tag = self.connection.document_root_xpath  # Local scope is faster.\n            doc_id_xpath = self.connection.document_id_xpath.split('/')\n            # Convert to etrees.\n            documents = dict([(id, to_etree((document if document is not None else\n                                             query.term('', doc_root_tag)), doc_root_tag))\n                             for id, document in documents.items()])     # TODO: possibly ineficient\n            # If root not the same as given xpath, make new root and append to it.\n            for id, document in documents.items():\n                if document.tag != doc_root_tag:\n                    documents[id] = ET.Element(doc_root_tag)\n                    documents[id].append(document)  # documents is still the old reference\n            # Insert ids in documents and collapse to a list of documents.\n            for id, document in documents.items():\n                add_id(document, id)\n            documents = documents.values()\n        self._documents = map(to_raw_xml, documents)", "response": "Wrap documents in the correct root tags add id fields and convert them to etrees."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_doc_ids(self, doc_ids):\n        if isinstance(doc_ids, list):\n            self.set_documents(dict.fromkeys(doc_ids))\n        else:\n            self.set_documents({doc_ids: None})", "response": "Build xml documents from a list of document ids."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_property(self, set_property, name, starting_value, tag_name=None):\n        def del_property(self, tag_name):\n            try:\n                del self._content[tag_name]\n            except KeyError:\n                pass\n\n        def get_property(self, tag_name):\n            try:\n                return self._content[tag_name]\n            except KeyError:\n                return None\n\n        tag_name = (name if tag_name is None else tag_name)\n        fget = lambda self: get_property(self, tag_name)\n        fdel = lambda self: del_property(self, tag_name)\n        fset = lambda self, value: set_property(value)\n        setattr(self.__class__, name, property(fget, fset, fdel))\n        set_property(starting_value)", "response": "Add a property to the content dict using the given function that returns the value of the given property."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_query(self, value):\n        if isinstance(value, basestring) or value is None:\n            self._content['query'] = value\n        elif hasattr(value, 'keys'):\n            self._content['query'] = query.terms_from_dict(value)\n        else:\n            raise TypeError(\"Query must be a string or dict. Got: \" + type(value) + \" insted!\")", "response": "Convert a dict form of query in a string of needed and store the query string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake xml request string from stored request information.", "response": "def get_xml_request(self):\n        \"\"\" Make xml request string from stored request information.\n\n            Returns:\n                A properly formated XMl request string containing all set request fields and\n                wraped in connections envelope.\n        \"\"\"\n        def wrap_xml_content(xml_content):\n            \"\"\" Wrap XML content string in the correct CPS request envelope.\"\"\"\n            fields = ['<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n',\n                      '<cps:request xmlns:cps=\"www.clusterpoint.com\">\\n',\n                      '<cps:storage>', self.connection._storage, '</cps:storage>\\n']\n            if self.timestamp:\n                fields += []    # TODO: implement\n            if self.request_id:\n                fields += ['<cps:request_id>', str(self.request_id), '</cps:request_id>\\n']\n            if self.connection.reply_charset:\n                fields += []    # TODO: implement\n            if self.connection.application:\n                fields += ['<cps:application>', self.connection.application, '</cps:application>\\n']\n            fields += ['<cps:command>', self._command, '</cps:command>\\n',\n                       '<cps:user>', self.connection._user, '</cps:user>\\n',\n                       '<cps:password>', self.connection._password, '</cps:password>\\n',\n                       '<cps:account>', self.connection._account, '</cps:account>\\n']\n            if self.timeout:\n                fields += ['<cps:timeout>', str(self.timeout), '</cps:timeout>\\n']\n            if self.type:\n                fields += ['<cps:type>', self.type, '</cps:type>\\n']\n            if xml_content:\n                fields += ['<cps:content>\\n', xml_content, '\\n</cps:content>\\n']\n            else:\n                fields += '<cps:content/>\\n'\n            fields += '</cps:request>\\n'\n            # String concat from list faster than incremental concat.\n            xml_request = ''.join(fields)\n            return xml_request\n\n        xml_content = []\n        if self._documents:\n            xml_content += self._documents\n        for key, value in self._nested_content.items():\n            if value:\n                xml_content += ['<{0}>'.format(key)] +\\\n                    ['<{0}>{1}</{0}>'.format(sub_key, sub_value) for sub_key, sub_value in value if sub_value] +\\\n                    ['</{0}>'.format(key)]\n        for key, value in self._content.items():\n            if not isinstance(value, list):\n                value = [value]\n            xml_content += ['<{0}>{1}</{0}>'.format(key, item) for item in value if item]\n        xml_content = '\\n'.join(xml_content)\n        return wrap_xml_content(xml_content)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends an XML string version of content through the connection.", "response": "def send(self):\n        \"\"\" Send an XML string version of content through the connection.\n\n        Returns:\n            Response object.\n        \"\"\"\n        xml_request = self.get_xml_request()\n        if(self.connection._debug == 1):\n            print(xml_request)\n        Debug.warn('-' * 25)\n        Debug.warn(self._command)\n        Debug.dump(\"doc: \\n\", self._documents)\n        Debug.dump(\"cont: \\n\", self._content)\n        Debug.dump(\"nest cont \\n\", self._nested_content)\n        Debug.dump(\"Request: \\n\", xml_request)\n\n\n        response = _handle_response(self.connection._send_request(xml_request),\n                                         self._command, self.connection.document_id_xpath)\n        # TODO: j\u0101pabeidz debugs \n        # if(self.connection._debug == 1):\n        #     # print(response)\n        #     print(format(ET.tostring(response)))\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntimes zone offset ( minutes", "response": "def _min_timezone_offset():\n    \"time zone offset (minutes)\"\n    now = time.time()\n    return (datetime.datetime.fromtimestamp(now) - datetime.datetime.utcfromtimestamp(now)).seconds // 60"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format_duration(secs):\n    secs = int(secs)\n\n    if abs(secs) > 60:\n        mins = abs(secs) / 60\n        secs = abs(secs) - (mins * 60)\n\n        return '%s%im %02is' % ('-' if secs < 0 else '', mins, secs)\n\n    return '%is' % secs", "response": "Format a duration in seconds as minutes and seconds."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef learn(self, numEpochs, batchsize):\n        for epoch in range(numEpochs):\n            print('epoch %d' % epoch)\n            indexes = np.random.permutation(self.trainsize)\n            for i in range(0, self.trainsize, batchsize):\n                x = Variable(self.x_train[indexes[i: i + batchsize]])\n                t = Variable(self.y_train[indexes[i: i + batchsize]])\n                self.optimizer.update(self.model, x, t)", "response": "Train the classifier for a given number of epochs with a given batchsize"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef evaluate(self, batchsize):\n        sum_loss, sum_accuracy = 0, 0\n        for i in range(0, self.testsize, batchsize):\n            x = Variable(self.x_test[i: i + batchsize])\n            y = Variable(self.y_test[i: i + batchsize])\n            loss = self.model(x, y)\n            sum_loss += loss.data * batchsize\n            sum_accuracy += self.model.accuracy.data * batchsize\n        return sum_loss / self.testsize, sum_accuracy / self.testsize", "response": "Evaluate how well the classifier is doing. Return mean loss and mean accuracy"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self, model_filename, optimizer_filename):\n        serializers.save_hdf5(model_filename, self.model)\n        serializers.save_hdf5(optimizer_filename, self.optimizer)", "response": "Save the state of the model and optimizer to disk"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning this over an input vector and see the result", "response": "def classify(self, phrase_vector):\n        \"\"\" Run this over an input vector and see the result \"\"\"\n        x = Variable(np.asarray([phrase_vector]))\n        return self.model.predictor(x).data[0]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parent_site(self, site):\n        # Avoid auto filter if site is already set.\n        self._parent_site = site\n\n        if settings.FLUENTCMS_EMAILTEMPLATES_ENABLE_CROSS_SITE:\n            # Allow content to be shared between all sites:\n            return self.filter(Q(parent_site=site) | Q(is_cross_site=True))\n        else:\n            return self.filter(parent_site=site)", "response": "Filter to the given site only give content relevant for that site."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a single site if the queryset is filtered on a parent site.", "response": "def _single_site(self):\n        \"\"\"\n        Make sure the queryset is filtered on a parent site, if that didn't happen already.\n        \"\"\"\n        if settings.FLUENTCMS_EMAILTEMPLATES_FILTER_SITE_ID and self._parent_site is None:\n            return self.parent_site(settings.SITE_ID)\n        else:\n            return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisplaying help for the given route.", "response": "def help(route):\n  r\"\"\"Displays help for the given route.\n\n  Args:\n    route (str): A route that resolves a member.\n  \"\"\"\n  help_text = getRouteHelp(route.split('/') if route else [])\n\n  if help_text is None:\n    err('Can\\'t help :(')\n\n  else:\n    print '\\n%s' % help_text"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns Base58 string from data", "response": "def encode(data: Union[str, bytes]) -> str:\n        \"\"\"\n        Return Base58 string from data\n\n        :param data: Bytes or string data\n        \"\"\"\n        return ensure_str(base58.b58encode(ensure_bytes(data)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plotOptMod(verNObg3gray, VERgray):\n    if VERgray is None and verNObg3gray is None:\n        return\n\n    fg = figure()\n    ax2 = fg.gca()  # summed (as camera would see)\n\n    if VERgray is not None:\n        z = VERgray.alt_km\n        Ek = VERgray.energy_ev.values\n\n#        ax1.semilogx(VERgray, z, marker='',label='filt', color='b')\n        props = {'boxstyle': 'round', 'facecolor': 'wheat', 'alpha': 0.5}\n        fgs, axs = fg.subplots(6, 6, sharex=True, sharey='row')\n        axs = axs.ravel()  # for convenient iteration\n        fgs.subplots_adjust(hspace=0, wspace=0)\n        fgs.suptitle('filtered VER/flux')\n        fgs.text(0.04, 0.5, 'Altitude [km]', va='center', rotation='vertical')\n        fgs.text(0.5, 0.04, 'Beam energy [eV]', ha='center')\n        for i, e in enumerate(Ek):\n            axs[i].semilogx(VERgray.loc[:, e], z)\n            axs[i].set_xlim((1e-3, 1e4))\n\n# place a text box in upper left in axes coords\n            axs[i].text(0.95, 0.95, '{:0.0f}'.format(e)+'eV',\n                        transform=axs[i].transAxes, fontsize=12,\n                        va='top', ha='right', bbox=props)\n        for i in range(33, 36):\n            axs[i].axis('off')\n\n        ax2.semilogx(VERgray.sum(axis=1), z, label='filt', color='b')\n\n        # specific to energies\n        ax = figure().gca()\n        for e in Ek:\n            ax.semilogx(VERgray.loc[:, e], z, marker='', label='{:.0f} eV'.format(e))\n        ax.set_title('filtered VER/flux')\n        ax.set_xlabel('VER/flux')\n        ax.set_ylabel('altitude [km]')\n        ax.legend(loc='best', fontsize=8)\n        ax.set_xlim((1e-5, 1e5))\n        ax.grid(True)\n\n    if verNObg3gray is not None:\n        ax1 = figure().gca()  # overview\n        z = verNObg3gray.alt_km\n        Ek = verNObg3gray.energy_ev.values\n\n        ax1.semilogx(verNObg3gray, z, marker='', label='unfilt', color='r')\n        ax2.semilogx(verNObg3gray.sum(axis=1), z, label='unfilt', color='r')\n\n        ax = figure().gca()\n        for e in Ek:\n            ax.semilogx(verNObg3gray.loc[:, e], z, marker='', label='{:.0f} eV'.format(e))\n        ax.set_title('UNfiltered VER/flux')\n        ax.set_xlabel('VER/flux')\n        ax.set_ylabel('altitude [km]')\n        ax.legend(loc='best', fontsize=8)\n        ax.set_xlim((1e-5, 1e5))\n        ax.grid(True)\n\n        ax1.set_title('VER/flux, one profile per beam')\n        ax1.set_xlabel('VER/flux')\n        ax1.set_ylabel('altitude [km]')\n        ax1.grid(True)\n\n    ax2.set_xlabel('VER/flux')\n    ax2.set_ylabel('altitude [km]')\n    ax2.set_title('VER/flux summed over all energy beams \\n (as the camera would see)')\n    ax2.legend(loc='best')\n    ax2.grid(True)", "response": "plot the filtered VER - mod in a figure"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deriv(f,c,dx=0.0001):\n    return (f(c+dx)-f(c-dx))/(2*dx)", "response": "Returns f ( x ) computed as a symmetric difference quotient."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the x closest to a newton.", "response": "def newton(f,c,tol=0.0001,restrict=None):\n    \"\"\"\n    newton(f,c) --> float\n    \n    Returns the x closest to c such that f(x) = 0\n    \"\"\"\n    #print(c)\n    if restrict:\n        lo,hi = restrict\n        if c < lo or c > hi:\n            print(c)\n            c = random*(hi-lo)+lo\n\n    if fuzzyequals(f(c),0,tol):\n        return c\n    else:\n        try:\n            return newton(f,c-f(c)/deriv(f,c,tol),tol,restrict)\n        except:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef integrate_box(self,low,high,forcequad=False,**kwargs):\n        if not self.adaptive and not forcequad:\n            return self.gauss_kde.integrate_box_1d(low,high)*self.norm\n        return quad(self.evaluate,low,high,**kwargs)[0]", "response": "Integrates over a box. Optionally force quad integration even for non - adaptive."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_context(self):\n        if self.context and len(self.context) != len(set(self.context)):\n            LOGGER.error('Cannot have duplicated context objects')\n            raise Exception('Cannot have duplicated context objects.')", "response": "Validate that there are no duplicate context objects in the original tuple and that there are no duplicate context objects in the original tuple and that there are no duplicate context objects in the original tuple."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching the data to find an instance of a model class in the template.", "response": "def get_instance_of(self, model_cls):\n        \"\"\"\n        Search the data to find a instance\n        of a model specified in the template\n        \"\"\"\n        for obj in self.data.values():\n            if isinstance(obj, model_cls):\n                return obj\n        LOGGER.error('Context Not Found')\n        raise Exception('Context Not Found')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_context(self):\n        if not self.context:\n            return\n        else:\n            assert isinstance(self.context, tuple), 'Expected a Tuple not {0}'.format(type(self.context))\n        for model in self.context:\n            model_cls = utils.get_model_class(model)\n            key = utils.camel_to_snake(model_cls.__name__)\n            self.context_data[key] = self.get_instance_of(model_cls)", "response": "Create a dict with the context data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the context data for the current locale", "response": "def get_context_data(self):\n        \"\"\"\n        Context Data is equal to context + extra_context\n        Merge the dicts context_data and extra_context and\n        update state\n        \"\"\"\n        self.get_context()\n        self.context_data.update(self.get_extra_context())\n        return self.context_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends an email to the specified destination.", "response": "def send(self, to, language=None, **data):\n        \"\"\"\n        This is the method to be called\n        \"\"\"\n        self.data = data\n        self.get_context_data()\n        if app_settings['SEND_EMAILS']:\n            try:\n                if language:\n                    mail.send(to, template=self.template, context=self.context_data, language=language)\n                else:\n                    mail.send(to, template=self.template, context=self.context_data)\n            except EmailTemplate.DoesNotExist:\n                msg = 'Trying to use a non existent email template {0}'.format(self.template)\n                LOGGER.error('Trying to use a non existent email template {0}'.format(self.template))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the parameters used in the url of the API call and for authentication.", "response": "def params(self):\n        \"\"\"Parameters used in the url of the API call and for authentication.\n\n        :return: parameters used in the url.\n        :rtype: dict\n        \"\"\"\n        params = {}\n        params[\"access_token\"] = self.access_token\n        params[\"account_id\"] = self.account_id\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef data(self):\n        data = {}\n        data[\"name\"] = self.name\n        data[\"query\"] = self.queryd\n        data[\"languages\"] = self.languages\n        data[\"countries\"] = self.countries if self.countries else \"\"\n        data[\"sources\"] = self.sources if self.sources else \"\"\n        data[\"blocked_sites\"] = self.blocked_sites if self.blocked_sites else \"\"\n        data[\"noise_detection\"] = self.noise_detection if self.noise_detection else \"\"\n        data[\"reviews_pages\"] = self.reviews_pages if self.reviews_pages else \"\"\n\n        # Deletes parameter if it does not have a value\n        for key, value in list(data.items()):\n            if value == '':\n                del data[key]\n\n        data = json.dumps(data)\n        return data", "response": "Returns the details of the new\n         alert."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the parameters used in the API call and for authentication.", "response": "def params(self):\n        \"\"\"Parameters used in the url of the API call and for authentication.\n\n        :return: parameters used in the url.\n        :rtype: dict\n        \"\"\"\n        params = {}\n        params[\"access_token\"] = self.access_token\n        params[\"account_id\"] = self.account_id\n        params[\"alert_id\"] = self.alert_id\n\n        if self.since_id:\n            params[\"since_id\"] = self.since_id\n        else:\n            params[\"before_date\"] = self.before_date if self.before_date else \"\"\n            params[\"not_before_date\"] = self.not_before_date if self.before_date else \"\"\n            params[\"cursor\"] = self.cursor if self.cursor else \"\"\n\n        if self.unread:\n            params[\"unread\"] = self.unread\n        else:\n            if (self.favorite) and (\n                (self.folder == \"inbox\") or (self.folder == \"archive\")):\n                params[\"favorite\"] = self.favorite\n                params[\"folder\"] = self.folder\n            else:\n                 params[\"folder\"] = self.folder if self.folder else \"\"   \n            params[\"q\"] = self.q if self.q else \"\"\n            params[\"tone\"] = self.tone if self.tone else \"\"\n\n        if int(self.limit) > 1000:\n            params[\"limit\"] = \"1000\"\n        elif int(self.limit) < 1:\n            params[\"limit\"] = \"\"\n        else:\n            params[\"limit\"] = self.limit\n\n        params[\"source\"] = self.source if self.source else \"\"\n\n        params[\"countries\"] = self.countries if self.countries else \"\"\n        params[\"include_children\"] = self.include_children if self.include_children else \"\"\n        params[\"sort\"] = self.sort if self.sort else \"\"\n        params[\"languages\"] = self.languages if self.languages else \"\"\n        params[\"timezone\"] = self.timezone if self.timezone else \"\"\n\n        # Deletes parameter if it does not have a value\n        for key, value in list(params.items()):\n            if value == '':\n                del params[key]\n\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef params(self):\n        params = {}\n        params[\"access_token\"] = self.access_token\n        params[\"account_id\"] = self.account_id\n        params[\"alert_id\"] = self.alert_id\n        params[\"mention_id\"] = self.mention_id\n        params[\"before_date\"] = self.before_date if self.before_date else \"\"\n\n        if self.limit:\n            if int(self.limit) > 1000:\n                params[\"limit\"] = \"1000\"\n            elif int(self.limit) < 1:\n                params[\"limit\"] = \"\"\n            else:\n                params[\"limit\"] = self.limit\n\n        return params", "response": "Returns the parameters used in the url of the API call and for authentication."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the details of the alert as a dictionary.", "response": "def data(self):\n        \"\"\"Parameters passed to the API containing the details to update a\n         alert.\n\n        :return: parameters to create new alert.\n        :rtype: dict\n        \"\"\"\n        data = {}\n        data[\"favorite\"] = self.favorite if self.favorite else \"\"\n        data[\"trashed\"] = self.trashed if self.trashed else \"\"\n        data[\"read\"] = self.read if self.read else \"\"\n        data[\"tags\"] = self.tags if self.tags else \"\"\n        data[\"folder\"] = self.folder if self.folder else \"\"\n        data[\"tone\"] = self.tone if self.tone else \"\"\n\n        # Deletes parameter if it does not have a value\n        for key, value in list(data.items()):\n            if value == '':\n                del data[key]\n\n        data = json.dumps(data)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling a task as if it was called from the command line.", "response": "def call(command, collect_missing=False, silent=True):\n  r\"\"\"Calls a task, as if it were called from the command line.\n\n  Args:\n    command (str): A route followed by params (as if it were entered in the shell).\n    collect_missing (bool): Collects any missing argument for the command through the shell. Defaults to False.\n\n  Returns:\n    The return value of the called command.\n  \"\"\"\n  return (_execCommand if silent else execCommand)(shlex.split(command), collect_missing)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(TargetGroup, NewMember, Config=None, Args=None):\n  Member = Task(NewMember, Args or {}, Config or {}) if isfunction(NewMember) else Group(NewMember, Config or {})\n  ParentMembers = TargetGroup.__ec_member__.Members\n\n  ParentMembers[Member.Config['name']] = Member\n\n  alias = Member.Config.get('alias')\n\n  if alias:\n    ParentMembers[alias] = Member", "response": "r Adds members to an existing group."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_check_pep8(files, status):\n    for file_name in files:\n\n        args = ['flake8', '--max-line-length=120', '{0}'.format(file_name)]\n        output = run(*args)\n\n        if output:\n            status.append(\"Python PEP8/Flake8: {0}: {1}\".format(file_name,\n                                                                output))\n\n    return status", "response": "Run the python pep8 tool against the filst of the files and print any linting errors to the status list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_for_empty_defaults(status):\n\n    dirs_to_check = ('./vars', './handlers', './defaults', './tasks')\n\n    for dirpath, dirname, filename in os.walk('.'):\n\n        if dirpath == './files' or dirpath == \"./templates\":\n            if not any([dirname, filename]):\n                status.append(\"There are no files in the {0} directory. please\"\n                              \" remove directory\".format(dirpath))\n\n        if dirpath in dirs_to_check:\n            try:\n                joined_filename = os.path.join(dirpath, 'main.yml')\n                with open(joined_filename, 'r') as f:\n                    # try to match:\n                    # ---\n                    # (tasks|vars|defaults) file for myrole\n                    #\n                    if re.match(r'^---\\n# \\S+ file for \\S+\\n$', f.read()):\n                        status.append(\"Empty file, please remove file and \"\n                                      \"directory: {0}\".format(joined_filename))\n            except IOError:\n                # Can't find a main.yml - but this could be legitimate\n                pass\n\n    return status", "response": "Method to check for empty defaults for a user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_inline(cls: Type[RevocationType], version: int, currency: str, inline: str) -> RevocationType:\n        cert_data = Revocation.re_inline.match(inline)\n        if cert_data is None:\n            raise MalformedDocumentError(\"Revokation\")\n        pubkey = cert_data.group(1)\n        signature = cert_data.group(2)\n        return cls(version, currency, pubkey, signature)", "response": "Return a Revocation document instance from an inline string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_signed_raw(cls: Type[RevocationType], signed_raw: str) -> RevocationType:\n        lines = signed_raw.splitlines(True)\n        n = 0\n\n        version = int(Revocation.parse_field(\"Version\", lines[n]))\n        n += 1\n\n        Revocation.parse_field(\"Type\", lines[n])\n        n += 1\n\n        currency = Revocation.parse_field(\"Currency\", lines[n])\n        n += 1\n\n        issuer = Revocation.parse_field(\"Issuer\", lines[n])\n        n += 1\n\n        identity_uid = Revocation.parse_field(\"IdtyUniqueID\", lines[n])\n        n += 1\n\n        identity_timestamp = Revocation.parse_field(\"IdtyTimestamp\", lines[n])\n        n += 1\n\n        identity_signature = Revocation.parse_field(\"IdtySignature\", lines[n])\n        n += 1\n\n        signature = Revocation.parse_field(\"Signature\", lines[n])\n        n += 1\n\n        identity = Identity(version, currency, issuer, identity_uid, identity_timestamp, identity_signature)\n\n        return cls(version, currency, identity, signature)", "response": "Return a Revocation document instance from a signed raw string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_self_cert(signed_raw: str) -> Identity:\n        lines = signed_raw.splitlines(True)\n        n = 0\n\n        version = int(Revocation.parse_field(\"Version\", lines[n]))\n        n += 1\n\n        Revocation.parse_field(\"Type\", lines[n])\n        n += 1\n\n        currency = Revocation.parse_field(\"Currency\", lines[n])\n        n += 1\n\n        issuer = Revocation.parse_field(\"Issuer\", lines[n])\n        n += 1\n\n        unique_id = Revocation.parse_field(\"IdtyUniqueID\", lines[n])\n        n += 1\n\n        timestamp = Revocation.parse_field(\"IdtyTimestamp\", lines[n])\n        n += 1\n\n        signature = Revocation.parse_field(\"IdtySignature\", lines[n])\n        n += 1\n\n        return Identity(version, currency, issuer, unique_id, timestamp, signature)", "response": "Extract self - certified Identity instance from the signed raw document string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the raw document of the current version of the revocation.", "response": "def raw(self) -> str:\n        \"\"\"\n        Return Revocation raw document string\n\n        :return:\n        \"\"\"\n        if not isinstance(self.identity, Identity):\n            raise MalformedDocumentError(\"Can not return full revocation document created from inline\")\n\n        return \"\"\"Version: {version}\nType: Revocation\nCurrency: {currency}\nIssuer: {pubkey}\nIdtyUniqueID: {uid}\nIdtyTimestamp: {timestamp}\nIdtySignature: {signature}\n\"\"\".format(version=self.version,\n           currency=self.currency,\n           pubkey=self.identity.pubkey,\n           uid=self.identity.uid,\n           timestamp=self.identity.timestamp,\n           signature=self.identity.signatures[0])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsigning the current document.", "response": "def sign(self, keys: list) -> None:\n        \"\"\"\n        Sign the current document.\n        Warning : current signatures will be replaced with the new ones.\n\n        :param keys: List of libnacl key instances\n        :return:\n        \"\"\"\n        if not isinstance(self.identity, Identity):\n            raise MalformedDocumentError(\"Can not return full revocation document created from inline\")\n\n        self.signatures = []\n        for key in keys:\n            signing = base64.b64encode(key.signature(bytes(self.raw(), 'ascii')))\n            self.signatures.append(signing.decode(\"ascii\"))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef signed_raw(self) -> str:\n        if not isinstance(self.identity, Identity):\n            raise MalformedDocumentError(\"Can not return full revocation document created from inline\")\n\n        raw = self.raw()\n        signed = \"\\n\".join(self.signatures)\n        signed_raw = raw + signed + \"\\n\"\n        return signed_raw", "response": "Return Revocation signed raw document string"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clean_text(text):\n    if text:\n        text = html2text.html2text(clean_markdown(text))\n        return re.sub(r'\\s+', ' ', text).strip()", "response": "Clean text without markdown sintax or other things."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clean_markdown(text):\n    result = text\n\n    if isinstance(text, str):\n        result = ''.join(\n            BeautifulSoup(markdown(text), 'lxml').findAll(text=True))\n\n    return result", "response": "Parse markdown sintaxt to html.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef select_regexp_char(char):\n    regexp = '{}'.format(char)\n\n    if not isinstance(char, str) and not isinstance(char, int):\n        regexp = ''\n\n    if isinstance(char, str) and not char.isalpha() and not char.isdigit():\n        regexp = r\"\\{}\".format(char)\n\n    return regexp", "response": "Select correct regex depending the char"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving simbols from text.", "response": "def exclude_chars(text, exclusion=None):\n    \"\"\"\n    Clean text string of simbols in exclusion list.\n    \"\"\"\n    exclusion = [] if exclusion is None else exclusion\n    regexp = r\"|\".join([select_regexp_char(x) for x in exclusion]) or r''\n    return re.sub(regexp, '', text)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef strip_accents(text):\n\n    normalized_str = unicodedata.normalize('NFD', text)\n\n    return ''.join([\n        c for c in normalized_str if unicodedata.category(c) != 'Mn'])", "response": "Strip agents from a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalizer(text, exclusion=OPERATIONS_EXCLUSION, lower=True, separate_char='-', **kwargs):\n    clean_str = re.sub(r'[^\\w{}]'.format(\n        \"\".join(exclusion)), separate_char, text.strip()) or ''\n    clean_lowerbar = clean_str_without_accents = strip_accents(clean_str)\n\n    if '_' not in exclusion:\n        clean_lowerbar = re.sub(r'\\_', separate_char, clean_str_without_accents.strip())\n\n    limit_guion = re.sub(r'\\-+', separate_char, clean_lowerbar.strip())\n\n    # TODO: refactor with a regexp\n    if limit_guion and separate_char and separate_char in limit_guion[0]:\n        limit_guion = limit_guion[1:]\n\n    if limit_guion and separate_char and separate_char in limit_guion[-1]:\n        limit_guion = limit_guion[:-1]\n\n    if lower:\n        limit_guion = limit_guion.lower()\n\n    return limit_guion", "response": "Clean text string of simbols only alphanumeric chars."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a dictionary normalize all of their keys using normalize function.", "response": "def normalize_dict(dictionary, **kwargs):\n    \"\"\"\n    Given an dict, normalize all of their keys using normalize function.\n    \"\"\"\n    result = {}\n    if isinstance(dictionary, dict):\n        keys = list(dictionary.keys())\n        for key in keys:\n            result[normalizer(key, **kwargs)] = normalize_dict(dictionary.get(key), **kwargs)\n    else:\n        result = dictionary\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pluralize(data_type):\n    known = {\n             u\"address\": u\"addresses\", \n             u\"company\": u\"companies\"\n    }\n    if data_type in known.keys():\n        return known[data_type]\n    else:\n        return u\"%ss\" % data_type", "response": "Returns the plural form of the data type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_properties_containing_None(properties_dict):\n    # remove empty properties - as validations may fail\n    new_dict  = dict()\n    for key in properties_dict.keys():\n        value = properties_dict[key]\n        if value is not None:\n            new_dict[key] = value\n    return new_dict", "response": "Removes keys from a dict that contains None values"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the VEQ samples from a diff rotateral distribution.", "response": "def veq_samples(R_dist,Prot_dist,N=1e4,alpha=0.23,l0=20,sigl=20):\n    \"\"\"Source for diff rot\n    \"\"\"\n    ls = stats.norm(l0,sigl).rvs(N)\n    Prots = Prot_dist.rvs(N)\n    Prots *= diff_Prot_factor(ls,alpha)\n    return R_dist.rvs(N)*2*np.pi*RSUN/(Prots*DAY)/1e5"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fveq(z,R,dR,P,dP):\n\n    R *= 2*pi*RSUN\n    dR *= 2*pi*RSUN\n    P *= DAY\n    dP *= DAY\n\n    exp1 = -P**2/(2*dP**2) - R**2/(2*dR**2)\n    exp2 = (dR**2*P + dP**2*R*(z*1e5))**2/(2*dP**2*dR**2*(dR**2 + dP**2*(z*1e5)**2))\n\n    nonexp_term = 2*dP*dR*np.sqrt(dR**2 + dP**2*(z*1e5)**2)\n\n    return 1e5/(4*pi*(dR**2 + dP**2*(z*1e5)**2)**(3/2))*np.exp(exp1 + exp2) *\\\n        (dR**2 * P*np.sqrt(2*pi) + \n         dP**2 * np.sqrt(2*pi)*R*(z*1e5) + \n         nonexp_term * np.exp(-exp2) +\n         np.sqrt(2*pi)*(dR**2*P + dP**2*R*(z*1e5))*erf((dR**2*P + dP**2*R*(z*1e5)) *\n                                                       (np.sqrt(2)*dP*dR*\n                                                        np.sqrt(dR**2 + dP**2*(z*1e5)**2))))", "response": "fveq is the inverse of fveq in km"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cleanup():\n    lib_dir = os.path.join(os.environ['CONTAINER_DIR'], '_lib')\n    if os.path.exists(lib_dir):\n        shutil.rmtree(lib_dir)\n    os.mkdir(lib_dir)", "response": "Clean up the installation directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a project - level virtualenv.", "response": "def get_or_create_project_venv():\n    \"\"\"\n    Create a project-level virtualenv (if it does not already exist).\n\n    :return: ``VirtualEnv`` object\n    \"\"\"\n    venv_dir = get_project_venv_dir()\n\n    if os.path.exists(venv_dir):\n        return VirtualEnv(venv_dir)\n    else:\n        return create_project_venv()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a project - level virtualenv.", "response": "def create_project_venv():\n    \"\"\"\n    Create a project-level virtualenv.\n\n    :raises: if virtualenv exists already\n    :return: ``VirtualEnv`` object\n    \"\"\"\n    print('... creating project-level virtualenv')\n    venv_dir = get_project_venv_dir()\n\n    if os.path.exists(venv_dir):\n        raise Exception('ERROR: virtualenv already exists!')\n\n    use_venv_module = sys.version_info >= (3, 0) and 'APE_USE_VIRTUALENV' not in os.environ\n\n    VirtualEnv.create_virtualenv(venv_dir, use_venv_module=use_venv_module)\n\n    print('... virtualenv successfully created')\n    return VirtualEnv(venv_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches a git repository from repo_url and returns a FeaturePool object.", "response": "def fetch_pool(repo_url, branch='master', reuse_existing=False):\n    \"\"\"Fetch a git repository from ``repo_url`` and returns a ``FeaturePool`` object.\"\"\"\n    repo_name = get_repo_name(repo_url)\n    lib_dir = get_lib_dir()\n    pool_dir = get_pool_dir(repo_name)\n    print('... fetching %s ' % repo_name)\n\n    if os.path.exists(pool_dir):\n        if not reuse_existing:\n            raise Exception('ERROR: repository already exists')\n    else:\n        try:\n            a = call(['git', 'clone', repo_url], cwd=lib_dir)\n        except OSError:\n            raise Exception('ERROR: You probably dont have git installed: sudo apt-get install git')\n\n        if a != 0:\n            raise Exception('ERROR: check your repository url and credentials!')\n\n    try:\n        call(['git', 'checkout', branch], cwd=pool_dir)\n    except OSError:\n        raise Exception('ERROR: cannot switch branches')\n\n    print('... repository successfully cloned')\n    return FeaturePool(pool_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexclude values from list or dict elements", "response": "def exclude_values(values, args):\n    \"\"\"\n    Exclude data with specific value.\n    =============   =============   =======================================\n    Parameter       Type            Description\n    =============   =============   =======================================\n    values          list            values where exclude elements\n    args            list or dict    elements to exclude\n    =============   =============   =======================================\n    Returns: vakues without excluded elements\n    \"\"\"\n\n    if isinstance(args, dict):\n        return {\n            key: value\n            for key, value in (\n                (k, exclude_values(values, v)) for (k, v) in args.items())\n            if value not in values\n        }\n    elif isinstance(args, list):\n        return [\n            item\n            for item in [exclude_values(values, i) for i in args]\n            if item not in values\n        ]\n\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a dict and a path string to retrieve a single element from the set of nested objects in which the data is stored.", "response": "def get_element(source, path, separator=r'[/.]'):\n    \"\"\"\n    Given a dict and path '/' or '.' separated. Digs into de dict to retrieve\n    the specified element.\n\n    Args:\n        source (dict): set of nested objects in which the data will be searched\n        path (string): '/' or '.' string with attribute names\n    \"\"\"\n    return _get_element_by_names(source, re.split(separator, path))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_element_by_names(source, names):\n\n    if source is None:\n        return source\n\n    else:\n        if names:\n            head, *rest = names\n            if isinstance(source, dict) and head in source:\n                return _get_element_by_names(source[head], rest)\n            elif isinstance(source, list) and head.isdigit():\n                return _get_element_by_names(source[int(head)], rest)\n            elif not names[0]:\n                pass\n            else:\n                source = None\n        return source", "response": "Returns the element in the nested object set that matches the names in the names list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a value to a list or dict.", "response": "def add_element(source, path, value, separator=r'[/.]', **kwargs):\n    \"\"\"\n    Add element into a list or dict easily using a path.\n    =============   =============   =======================================\n    Parameter       Type            Description\n    =============   =============   =======================================\n    source          list or dict    element where add the value.\n    path            string          path to add the value in element.\n    value           \u00bfall?           value to add in source.\n    separator       regex string    Regexp to divide the path.\n    =============   =============   =======================================\n    Returns: source with added value\n    \"\"\"\n\n    return _add_element_by_names(\n        source,\n        exclude_empty_values(re.split(separator, path)),\n        value,\n        **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_element_by_names(src, names, value, override=False, digit=True):\n\n    if src is None:\n        return False\n\n    else:\n\n        if names and names[0]:\n            head, *rest = names\n\n            # list and digit head\n            if isinstance(src, list):\n                if force_list(digit)[0] and head.isdigit():\n                    head = int(head)\n\n                    # if src is a list and lenght <= head\n                    if len(src) <= head:\n                        src.extend([\"\"] * (head + 1 - len(src)))\n\n            # head not in src :(\n            elif isinstance(src, dict):\n                if head not in src:\n                    src[head] = [\"\"] * (int(rest[0]) + 1) if rest and force_list(digit)[0] and rest[0].isdigit() else {}\n\n            # more heads in rest\n            if rest:\n\n                # Head find but isn't a dict or list to navigate for it.\n                if not isinstance(src[head], (dict, list)):\n\n                    # only could be str for dict or int for list\n                    src[head] = [\"\"] * (int(rest[0]) + 1) if force_list(digit)[0] and rest[0].isdigit() else {}\n\n                    digit = digit if not digit or not isinstance(digit, list) else digit[1:]\n\n                    if not force_list(digit)[0] and rest and str(rest[0]).isdigit() and isinstance(src[head], list) and override:\n                        src[head] = {}\n\n                    _add_element_by_names(src[head], rest, value, override=override, digit=digit)\n\n                else:\n\n                    digit = digit if not digit or not isinstance(digit, list) else digit[1:]\n\n                    if not force_list(digit)[0] and rest and str(rest[0]).isdigit() and isinstance(src[head], list) and override:\n                        src[head] = {}\n\n                    _add_element_by_names(src[head], rest, value, override=override, digit=digit)\n\n            # it's final head\n            else:\n\n                if not override:\n\n                    if isinstance(src, list) and isinstance(head, int):\n\n                        if src[head] == '':\n                            src[head] = value\n                        else:\n                            src.append(value)\n\n                    elif isinstance(src[head], list):\n                        src[head].append(value)\n\n                    elif isinstance(src[head], dict) and isinstance(value, dict):\n                        src[head].update(value)\n\n                    else:\n                        src[head] = value\n\n                else:\n                    src[head] = value\n\n        return src", "response": "Internal method to add an element to a list or dict or list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_dict(dic, format_list, separator=',', default_value=str):\n\n    dic = collections.defaultdict(default_value, dic)\n\n    str_format = separator.join([\"{\" + \"{}\".format(head) + \"}\" for head in format_list])\n\n    return str_format.format(**dic)", "response": "Formats a dictionary to string passing a list of keys as order\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef force_list(element):\n    if element is None:\n        return []\n\n    if isinstance(element, (collections.Iterator, list)):\n        return element\n\n    return [element]", "response": "Given an element or a list returns a list of all elements"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef chunks(lista, size):\n    if not isinstance(lista, list):\n        logger.error('Erron in chunks, arg introduced is not a list.', lista=lista)\n        return lista\n\n    for i in range(0, len(lista), size):\n        yield lista[i:i + size]", "response": "Yield successive n - sized chunks from l."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntransform dictionary multilevel values to one level dict concatenating the keys with sep between them.", "response": "def flatten(data, parent_key='', sep='_'):\n    \"\"\"\n    Transform dictionary multilevel values to one level dict, concatenating\n    the keys with sep between them.\n    \"\"\"\n    items = []\n\n    if isinstance(data, list):\n        logger.debug('Flattening list {}'.format(data))\n        list_keys = [str(i) for i in range(0, len(data))]\n        items.extend(\n            flatten(dict(zip(list_keys, data)), parent_key, sep=sep).items())\n\n    elif isinstance(data, dict):\n        logger.debug('Flattening dict {}'.format(data))\n\n        for key, value in data.items():\n            new_key = parent_key + sep + key if parent_key else key\n            if isinstance(value, collections.MutableMapping):\n                items.extend(flatten(value, new_key, sep=sep).items())\n            else:\n                if isinstance(value, list):\n                    list_keys = [str(i) for i in range(0, len(value))]\n                    items.extend(\n                        flatten(\n                            dict(zip(list_keys, value)), new_key, sep=sep).items())\n                else:\n                    items.append((new_key, value))\n    else:\n        logger.debug('Nothing to flatten with {}'.format(data))\n        return data\n\n    return collections.OrderedDict(items)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransform nested dict to list", "response": "def nested_dict_to_list(path, dic, exclusion=None):\n    \"\"\"\n    Transform nested dict to list\n    \"\"\"\n    result = []\n    exclusion = ['__self'] if exclusion is None else exclusion\n\n    for key, value in dic.items():\n\n        if not any([exclude in key for exclude in exclusion]):\n            if isinstance(value, dict):\n                aux = path + key + \"/\"\n                result.extend(nested_dict_to_list(aux, value))\n            else:\n                if path.endswith(\"/\"):\n                    path = path[:-1]\n\n                result.append([path, key, value])\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_value_in_object(attr, obj):\n\n    # Carry on inspecting inside the list or tuple\n    if isinstance(obj, (collections.Iterator, list)):\n        for item in obj:\n            yield from find_value_in_object(attr, item)\n\n    # Final object (dict or entity) inspect inside\n    elif isinstance(obj, collections.Mapping):\n\n        # If result is found, inspect inside and return inner results\n        if attr in obj:\n\n            # If it is iterable, just return the inner elements (avoid nested\n            # lists)\n            if isinstance(obj[attr], (collections.Iterator, list)):\n                for item in obj[attr]:\n                    yield item\n\n            # If not, return just the objects\n            else:\n                yield obj[attr]\n\n        # Carry on inspecting inside the object\n        for item in obj.values():\n            if item:\n                yield from find_value_in_object(attr, item)", "response": "Return values for any key coincidence with attr in obj or any other nested dict."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving duplicated elements in a list.", "response": "def remove_list_duplicates(lista, unique=False):\n    \"\"\"\n    Remove duplicated elements in a list.\n    Args:\n        lista: List with elements to clean duplicates.\n    \"\"\"\n    result = []\n    allready = []\n\n    for elem in lista:\n        if elem not in result:\n            result.append(elem)\n        else:\n            allready.append(elem)\n\n    if unique:\n        for elem in allready:\n            result = list(filter((elem).__ne__, result))\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dict2orderedlist(dic, order_list, default='', **kwargs):\n    result = []\n    for key_order in order_list:\n        value = get_element(dic, key_order, **kwargs)\n        result.append(value if value is not None else default)\n    return result", "response": "Return a list with dict values ordered by a list of keys passed in args."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the dimension of the data passed by argument independently if it s an an arrays or dictionaries", "response": "def get_dimension(data):\n    \"\"\"\n    Get dimension of the data passed by argument independently if it's an\n    arrays or dictionaries\n    \"\"\"\n    result = [0, 0]\n\n    if isinstance(data, list):\n        result = get_dimension_array(data)\n\n    elif isinstance(data, dict):\n        result = get_dimension_dict(data)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting dimension of an array getting the number of rows and max num of columns.", "response": "def get_dimension_array(array):\n    \"\"\"\n    Get dimension of an array getting the number of rows and the max num of\n    columns.\n    \"\"\"\n    if all(isinstance(el, list) for el in array):\n        result = [len(array), len(max([x for x in array], key=len,))]\n\n    # elif array and isinstance(array, list):\n    else:\n        result = [len(array), 1]\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_ldict_keys(ldict, flatten_keys=False, **kwargs):\n    result = []\n    for ddict in ldict:\n        if isinstance(ddict, dict):\n\n            if flatten_keys:\n                ddict = flatten(ddict, **kwargs)\n\n            result.extend(ddict.keys())\n    return list(set(result))", "response": "Get first level keys from a list of dicts"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_alldictkeys(ddict, parent=None):\n    parent = [] if parent is None else parent\n\n    if not isinstance(ddict, dict):\n        return [tuple(parent)]\n    return reduce(\n        list.__add__,\n        [get_alldictkeys(v, parent + [k]) for k, v in ddict.items()],\n        [])", "response": "Get all keys in a dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves chars in dict keys and return a clean dictionary.", "response": "def clean_dictkeys(ddict, exclusions=None):\n    \"\"\"\n    Exclude chars in dict keys and return a clean dictionary.\n    \"\"\"\n    exclusions = [] if exclusions is None else exclusions\n\n    if not isinstance(ddict, dict):\n        return {}\n\n    for key in list(ddict.keys()):\n        if [incl for incl in exclusions if incl in key]:\n            data = ddict.pop(key)\n            clean_key = exclude_chars(key, exclusions)\n\n            if clean_key:\n                if clean_key in ddict:\n                    ddict[clean_key] = force_list(ddict[clean_key])\n                    add_element(ddict, clean_key, data)\n                else:\n                    ddict[clean_key] = data\n\n        # dict case\n        if isinstance(ddict.get(key), dict):\n            ddict[key] = clean_dictkeys(ddict[key], exclusions)\n\n        # list case\n        elif isinstance(ddict.get(key), list):\n            for row in ddict[key]:\n                if isinstance(row, dict):\n                    row = clean_dictkeys(row, exclusions)\n\n    return ddict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef authenticate(previous_token = None):\n\n    # if we already have a session token, try to authenticate with it\n    if previous_token != None:\n        headers = server_connection.request(\"authenticate\", {\n            'session_token' : previous_token,\n            'repository'    : config['repository']})[1] # Only care about headers\n\n        if headers['status'] == 'ok':\n            return previous_token\n\n    # If the session token has expired, or if we don't have one, re-authenticate\n\n    headers = server_connection.request(\"begin_auth\", {'repository' : config['repository']})[1] # Only care about headers\n\n    if headers['status'] == 'ok':\n        signature = base64.b64encode(pysodium.crypto_sign_detached(headers['auth_token'].decode('utf-8'), config['private_key']))\n        headers = server_connection.request(\"authenticate\", {\n            'auth_token' : headers['auth_token'],\n            'signature'  : signature,\n            'user'       : config['user'],\n            'repository' : config['repository']})[1] # Only care about headers\n\n        if headers['status'] == 'ok': return headers['session_token']\n    raise SystemExit('Authentication failed')", "response": "Authenticate the client to the server"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds things that have changed since the last run", "response": "def find_local_changes():\n    \"\"\" Find things that have changed since the last run, applying ignore filters \"\"\"\n\n    manifest = data_store.read_local_manifest()\n    old_state = manifest['files']\n    current_state = get_file_list(config['data_dir'])\n    current_state = [fle for fle in current_state if not\n                     next((True for flter in config['ignore_filters']\n                           if fnmatch.fnmatch(fle['path'], flter)), False)]\n    return manifest, find_manifest_changes(current_state, old_state)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(session_token, testing = False):\n\n    conflict_comparison_file_dest = cpjoin(config['data_dir'], '.shttpfs', 'conflict_files')\n    conflict_resolution_path = cpjoin(config['data_dir'], '.shttpfs', 'conflict_resolution.json')\n    conflict_resolutions = file_or_default(conflict_resolution_path, [], json.loads)\n\n    # Make sure that all conflicts have been resolved, reject if not\n    if not all(len(c['4_resolution']) == 1 for c in conflict_resolutions): conflict_resolutions = []\n\n    # Send the changes and the revision of the most recent update to the server to find changes\n    manifest, client_changes = find_local_changes()\n\n    req_result, headers = server_connection.request(\"find_changed\", {\n        \"session_token\"        : session_token,\n        'repository'           : config['repository'],\n        \"previous_revision\"    : manifest['have_revision'],\n        }, {\n            \"client_changes\"       : json.dumps(client_changes),\n            \"conflict_resolutions\" : json.dumps(conflict_resolutions)})\n\n    if headers['status'] != 'ok':\n        if headers['msg'] == 'Please resolve conflicts':\n            raise SystemExit('Server error: Please resolve conflicts in .shttpfs/conflict_resolution.json')\n        else:\n            raise SystemExit('Server error')\n\n    result = json.loads(req_result)\n    changes = result['sorted_changes']\n\n    # Are there any changes?\n    if all(v == [] for k,v in changes.iteritems()):\n        print 'Nothing to update'\n        return\n\n    # Pull and delete from remote to local\n    if changes['client_pull_files'] != []:\n        # Filter out pull ignore files\n        filtered_pull_files = []\n        for fle in changes['client_pull_files']:\n            if not next((True for flter in config['pull_ignore_filters'] if fnmatch.fnmatch(fle['path'], flter)), False):\n                filtered_pull_files.append(fle)\n            else: # log ignored items to give the opportunity to pull them in the future\n                with open(cpjoin(working_copy_base_path, '.shttpfs', 'pull_ignored_items'), 'a') as pull_ignore_log:\n                    pull_ignore_log.write(json.dumps((result['head'], fle)))\n                    pull_ignore_log.flush()\n\n        if filtered_pull_files != []:\n            print 'Pulling files from server...'\n\n        #----------\n        for fle in filtered_pull_files:\n            print 'Pulling file: ' + fle['path']\n\n            req_result, headers = server_connection.request(\"pull_file\", {\n                'session_token' : session_token,\n                'repository'    : config['repository'],\n                'path'          : fle['path']}, gen = True)\n\n            if headers['status'] != 'ok':\n                raise SystemExit('Failed to pull file')\n            else:\n                make_dirs_if_dont_exist(data_store.get_full_file_path(cpjoin(*fle['path'].split('/')[:-1]) + '/'))\n                data_store.fs_put(fle['path'], req_result)\n\n    # Files which have been deleted on server and need deleting on client\n    if changes['to_delete_on_client'] != []:\n        print 'Removing files deleted on the server...'\n\n        for fle in changes['to_delete_on_client']:\n            print 'Deleting file: ' + fle['path']\n\n            try: data_store.fs_delete(fle['path'])\n            except OSError: print 'Warning: remote deleted file does not exist locally.'\n\n            # Delete the folder if it is now empty\n            try: os.removedirs(os.path.dirname(data_store.get_full_file_path(fle['path'])))\n            except OSError as e:\n                if e.errno not in [errno.ENOTEMPTY, errno.ENOENT]: raise\n\n    # Files which are in conflict\n    if changes['conflict_files'] != []:\n        print \"There are conflicts!\\n\"\n\n        out = []; server_versions = []\n        for fle in changes['conflict_files']:\n            fle['resolution'] = ['local', 'remote']\n            print 'Path:          ' + fle['file_info']['path']\n            print 'Client status: ' + fle['client_status']\n            print 'Server status: ' + fle['server_status']\n            print\n            out.append({'1_path'          : fle['file_info']['path'],\n                        '2_client_status' : fle['client_status'],\n                        '3_server_status' : fle['server_status'],\n                        '4_resolution'    : ['client', 'server']})\n            if fle['server_status'] == 'Changed': server_versions.append(fle['file_info'])\n\n        #===============\n        if server_versions != []:\n            choice = None\n            if not testing:\n                while True:\n                    print 'Download server versions for comparison? (Y/N)'\n                    choice = raw_input()\n                    if choice.lower() in ['y', 'n']: break\n            else: choice = 'y'\n\n            errors = []\n            if choice == 'y':\n                for fle in server_versions:\n                    print 'Pulling file: ' + fle['path']\n\n                    result, headers = server_connection.request(\"pull_file\", {\n                        'session_token' : session_token,\n                        'repository'    : config['repository'],\n                        'path'          : fle['path']}, gen = True)\n\n                    if headers['status'] != 'ok':\n                        errors.append(fle['path'])\n\n                    else:\n                        make_dirs_if_dont_exist(cpjoin(conflict_comparison_file_dest, *fle['path'].split('/')[:-1]) + '/')\n                        result(cpjoin(conflict_comparison_file_dest, fle['path']))\n\n                print 'Server versions of conflicting files written to .shttpfs/conflict_files\\n'\n\n            pprint(errors)\n\n        # ====================\n\n        file_put_contents(conflict_resolution_path, json.dumps(out, indent=4, sort_keys=True))\n        raise SystemExit(\"Conflict resolution file written to .shttpfs/conflict_resolution.json\\n\" +\n                         \"Please edit this file removing 'client', or 'server' to choose which version to retain.\")\n\n    # Update the latest revision in the manifest only if there are no conflicts\n    else:\n        data_store.begin()\n        manifest = data_store.read_local_manifest()\n        manifest['have_revision'] = result['head']\n        data_store.write_local_manifest(manifest)\n        data_store.commit()\n\n        #delete the conflicts resolution file and recursively delete any conflict files downloaded for comparison\n        ignore(os.remove, conflict_resolution_path)\n        ignore(shutil.rmtree, conflict_comparison_file_dest)\n\n        if changes['to_delete_on_server'] != [] or changes['client_push_files'] != []:\n            print 'There are local changes to commit'\n        else:\n            print 'Update OK'", "response": "Update the local files of the current node with the latest changes on the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister an action to the parser cli.", "response": "def register_action(action):\n  \"\"\"\n  Adds an action to the parser cli.\n\n  :param action(BaseAction): a subclass of the BaseAction class\n  \"\"\"\n  sub = _subparsers.add_parser(action.meta('cmd'), help=action.meta('help'))\n  sub.set_defaults(cmd=action.meta('cmd'))\n  for (name, arg) in action.props().items():\n    sub.add_argument(arg.name, arg.flag, **arg.options)\n    _actions[action.meta('cmd')] = action"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(*args, **kwargs):\n  cmd = _parser.parse_args(*args, **kwargs)\n  if hasattr(cmd, 'cmd') is False:\n    return _parser.print_help()\n  Action = _actions.get(cmd.cmd)\n  action = Action()\n  try:\n    action(**{k:getattr(cmd, k) for k in action.props().keys()})\n  except errors.BaseError as e:\n    e.print_error()", "response": "Runs the parser and executes the action handler with the provided arguments from the CLI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a snapshot of a board", "response": "def snapshot(ctx, board, done):\n    \"\"\"\n        Recording mode - Daily snapshots of a board for ongoing reporting:\n         -> trellis report --board=87hiudhw\n                          --spend\n                          --revenue\n                          --done=Done\n\n    \"\"\"\n    ctx.obj['board_id'] = board\n    ts = TrelloStats(ctx.obj)\n    Snapshot.create_table(fail_silently=True)\n    done_id = ts.get_list_id_from_name(done)\n    ct = cycle_time(ts, board, done)\n    env = get_env()\n    print render_text(env, **dict(cycle_time=ct))\n\n    # Create snapshot\n    print Snapshot.create(board_id=board, done_id=done_id, cycle_time=ct)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef report(ctx, board, done, output):\n    ctx.obj['board_id'] = board\n    ts = TrelloStats(ctx.obj)\n    \"\"\"\n        Reporting mode - Daily snapshots of a board for ongoing reporting:\n         -> trellis report --board=87hiudhw\n                          --spend\n                          --revenue\n                          --done=Done\n\n    \"\"\"\n    ct = cycle_time(ts, board, done)\n    env = get_env()\n\n    #  Get all render functions from the module and filter out the ones we don't want.\n    render_functions = [target for target in\n                     dir(sys.modules['trellostats.reports'])\n                     if target.startswith(\"render_\") and\n                     target.endswith(output)]\n    \n    for render_func in render_functions:\n        print globals()[render_func](env, **dict(cycle_time=ct))", "response": "Report the current board state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a translation object in the default django domain.", "response": "def translation(language):\n    \"\"\"\n    Return a translation object in the default 'django' domain.\n    \"\"\"\n    global _translations\n    if language not in _translations:\n        _translations[language] = Translations(language)\n    return _translations[language]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gettext(message):\n    global _default\n    _default = _default or translation(DEFAULT_LANGUAGE)\n    translation_object = getattr(_active, 'value', _default)\n    result = translation_object.gettext(message)\n    return result", "response": "Translate the message string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _new_gnu_trans(self, localedir, use_null_fallback=True):\n        use_null_fallback = False\n        return gettext_module.translation(\n            domain=self.domain,\n            localedir=localedir,\n            languages=[self.language],\n            codeset='utf-8',\n            fallback=use_null_fallback)", "response": "Return a mergeable gettext.GNUTranslations instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_localedir_translations(self, localedir):\n        global _localedirs\n        if localedir in self.localedirs:\n            return\n        self.localedirs.append(localedir)\n        full_localedir = os.path.join(localedir, 'locale')\n        if os.path.exists(full_localedir):\n            translation = self._new_gnu_trans(full_localedir)\n            self.merge(translation)", "response": "Merge translations from localedir."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmerges another translation into this one.", "response": "def merge(self, other):\n        \"\"\"Merge another translation into this catalog.\"\"\"\n        if not getattr(other, '_catalog', None):\n            return  # NullTranslations() has no _catalog\n        if self._catalog is None:\n            # Take plural and _info from first catalog found\n            self.plural = other.plural\n            self._info = other._info.copy()\n            self._catalog = other._catalog.copy()\n        else:\n            self._catalog.update(other._catalog)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndecodes text_in into a list of strings.", "response": "def decode_input(text_in):\n    \"\"\" Decodes `text_in`\n        If text_in is is a string, \n        then decode it as utf-8 string.\n        If text_in is is a list of strings,\n        then decode each string of it, \n        then combine them into one outpust string.  \n    \"\"\"\n    \n    if type(text_in) == list:\n        text_out = u' '.join([t.decode('utf-8') for t in text_in])\n    else:\n        text_out = text_in.decode('utf-8')\n    return text_out"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates local file path if doesn t exist.", "response": "def _set_local_file_path(self):\n        \"\"\"\n        Take from environment variable, create dirs and\n        create file if doesn' exist.\n        \"\"\"\n\n        self.FILE_LOCAL = self._transfer.get_env('FILE_LOCAL')\n\n        if not self.FILE_LOCAL:\n            filename = '{}_{}.{}'.format(str(self._transfer.prefix),\n                                         str(self._transfer.namespace),\n                                         str(self.file_extension))\n            self.FILE_LOCAL = os.path.join(os.path.expanduser(\"~\"), filename)\n\n        dirs = os.path.dirname(self.FILE_LOCAL)\n        if not os.path.exists(dirs):\n            os.makedirs(dirs)\n\n        try:\n            open(self.FILE_LOCAL, \"rb+\").close()\n        except:\n            open(self.FILE_LOCAL, \"a\").close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gen_post_status():\n\n    if not app.config[\"DEBUG\"]:\n        post_status = and_(Post.status == PostStatus.PUBLISH)\n    else:\n        post_status = or_(Post.status == PostStatus.PUBLISH,\n                          Post.status == PostStatus.DRAFT)\n    return post_status", "response": "Generate a boolean flag indicating if the post is published or draft."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsubscribing an observer to this subject and return a subscription id", "response": "def subscribe(self, observer):\n        \"\"\"Subscribe an observer to this subject and return a subscription id\n\n        \"\"\"\n        sid = self._sn\n        self.observers[sid] = observer\n        self._sn += 1\n        return SubscribeID(self, sid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unsubscribe(self, sid):\n        if sid not in self.observers:\n            raise KeyError(\n                'Cannot disconnect a observer does not connected to subject'\n            )\n        del self.observers[sid]", "response": "Disconnect an observer from this subject"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_module_class(name):\n\n    source = sys.modules[name]\n\n    members = vars(source)\n    is_descriptor = lambda x: not isinstance(x, type) and hasattr(x, '__get__')\n    descriptors = {k: v for (k, v) in members.items() if is_descriptor(v)}\n    members = {k: v for (k, v) in members.items() if k not in descriptors}\n    descriptors['__source'] = source\n\n    target = type(name, (types.ModuleType,), descriptors)(name)\n    target.__dict__.update(members)\n\n    sys.modules[name] = target", "response": "Takes the module referenced by name and makes it a full class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_ann(N_input=None, N_hidden=2, N_output=1, hidden_layer_type='Linear', verbosity=1):\n    N_input = N_input or 1\n    N_output = N_output or 1\n    N_hidden = N_hidden or tuple()\n    if isinstance(N_hidden, (int, float, basestring)):\n        N_hidden = (int(N_hidden),)\n\n    hidden_layer_type = hidden_layer_type or tuple()\n    hidden_layer_type = tuplify(normalize_layer_type(hidden_layer_type))\n\n    if verbosity > 0:\n        print(N_hidden, ' layers of type ', hidden_layer_type)\n\n    assert(len(N_hidden) == len(hidden_layer_type))\n    nn = pb.structure.FeedForwardNetwork()\n\n    # layers\n    nn.addInputModule(pb.structure.BiasUnit(name='bias'))\n    nn.addInputModule(pb.structure.LinearLayer(N_input, name='input'))\n    for i, (Nhid, hidlaytype) in enumerate(zip(N_hidden, hidden_layer_type)):\n        Nhid = int(Nhid)\n        nn.addModule(hidlaytype(Nhid, name=('hidden-{}'.format(i) if i else 'hidden')))\n    nn.addOutputModule(pb.structure.LinearLayer(N_output, name='output'))\n\n    # connections\n    nn.addConnection(pb.structure.FullConnection(nn['bias'],  nn['hidden'] if N_hidden else nn['output']))\n    nn.addConnection(pb.structure.FullConnection(nn['input'], nn['hidden'] if N_hidden else nn['output']))\n    for i, (Nhid, hidlaytype) in enumerate(zip(N_hidden[:-1], hidden_layer_type[:-1])):\n        Nhid = int(Nhid)\n        nn.addConnection(pb.structure.FullConnection(nn[('hidden-{}'.format(i) if i else 'hidden')],\n                         nn['hidden-{}'.format(i + 1)]))\n    i = len(N_hidden) - 1\n    nn.addConnection(pb.structure.FullConnection(nn['hidden-{}'.format(i) if i else 'hidden'], nn['output']))\n\n    nn.sortModules()\n    if FAST:\n        try:\n            nn.convertToFastNetwork()\n        except:\n            if verbosity > 0:\n                print('Unable to convert slow PyBrain NN to a fast ARAC network...')\n    if verbosity > 0:\n        print(nn.connections)\n    return nn", "response": "Builds a neural network with the indicated input hidden and outout dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomposing a pybrain. dataset from a pandas DataFrame", "response": "def dataset_from_dataframe(df, delays=(1, 2, 3), inputs=(1, 2, -1), outputs=(-1,), normalize=False, verbosity=1):\n    \"\"\"Compose a pybrain.dataset from a pandas DataFrame\n\n    Arguments:\n      delays (list of int): sample delays to use for the input tapped delay line\n        Positive and negative values are treated the same as sample counts into the past.\n        default: [1, 2, 3], in z-transform notation: z^-1 + z^-2 + z^-3\n      inputs (list of int or list of str): column indices or labels for the inputs\n      outputs (list of int or list of str): column indices or labels for the outputs\n      normalize (bool): whether to divide each input to be normally distributed about 0 with std 1\n\n    Returns:\n      3-tuple: tuple(dataset, list of means, list of stds)\n        means and stds allow normalization of new inputs and denormalization of the outputs\n\n    TODO:\n\n        Detect categorical variables with low dimensionality and split into separate bits\n            Vowpel Wabbit hashes strings into an int?\n        Detect ordinal variables and convert to continuous int sequence\n        SEE: http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n    \"\"\"\n    if isinstance(delays, int):\n        if delays:\n            delays = range(1, delays + 1)\n        else:\n            delays = [0]\n    delays = np.abs(np.array([int(i) for i in delays]))\n    inputs = [df.columns[int(inp)] if isinstance(inp, (float, int)) else str(inp) for inp in inputs]\n    outputs = [df.columns[int(out)] if isinstance(out, (float, int)) else str(out) for out in (outputs or [])]\n\n    inputs = [fuzzy_get(df.columns, i) for i in inputs]\n    outputs = [fuzzy_get(df.columns, o) for o in outputs]\n\n    N_inp = len(inputs)\n    N_out = len(outputs)\n\n    inp_outs = inputs + outputs\n    if verbosity > 0:\n        print(\"inputs: {}\\noutputs: {}\\ndelays: {}\\n\".format(inputs, outputs, delays))\n    means, stds = np.zeros(len(inp_outs)), np.ones(len(inp_outs))\n    if normalize:\n        means, stds = df[inp_outs].mean(), df[inp_outs].std()\n\n    if normalize and verbosity > 0:\n        print(\"Input mean values (used to normalize input biases): {}\".format(means[:N_inp]))\n        print(\"Output mean values (used to normalize output biases): {}\".format(means[N_inp:]))\n    ds = pb.datasets.SupervisedDataSet(N_inp * len(delays), N_out)\n    if verbosity > 0:\n        print(\"Dataset dimensions are {}x{}x{} (records x indim x outdim) for {} delays, {} inputs, {} outputs\".format(\n              len(df), ds.indim, ds.outdim, len(delays), len(inputs), len(outputs)))\n    # FIXME: normalize the whole matrix at once and add it quickly rather than one sample at a time\n    if delays == np.array([0]) and not normalize:\n        if verbosity > 0:\n            print(\"No tapped delay lines (delays) were requested, so using undelayed features for the dataset.\")\n        assert(df[inputs].values.shape[0] == df[outputs].values.shape[0])\n        ds.setField('input', df[inputs].values)\n        ds.setField('target', df[outputs].values)\n        ds.linkFields(['input', 'target'])\n        # for inp, outp in zip(df[inputs].values, df[outputs].values):\n        #     ds.appendLinked(inp, outp)\n        assert(len(ds['input']) == len(ds['target']))\n    else:\n        for i, out_vec in enumerate(df[outputs].values):\n            if verbosity > 0 and i % 100 == 0:\n                print(\"{}%\".format(i / .01 / len(df)))\n            elif verbosity > 1:\n                print('sample[{i}].target={out_vec}'.format(i=i, out_vec=out_vec))\n            if i < max(delays):\n                continue\n            inp_vec = []\n            for delay in delays:\n                inp_vec += list((df[inputs].values[i - delay] - means[:N_inp]) / stds[:N_inp])\n            ds.addSample(inp_vec, (out_vec - means[N_inp:]) / stds[N_inp:])\n    if verbosity > 0:\n        print(\"Dataset now has {} samples\".format(len(ds)))\n    if normalize:\n        return ds, means, stds\n    else:\n        return ds"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a dataset with an empty output vector containing the input data.", "response": "def input_dataset_from_dataframe(df, delays=(1, 2, 3), inputs=(1, 2, -1), outputs=None, normalize=True, verbosity=1):\n    \"\"\" Build a dataset with an empty output/target vector\n\n    Identical to `dataset_from_dataframe`, except that default values for 2 arguments:\n        outputs: None\n    \"\"\"\n    return dataset_from_dataframe(df=df, delays=delays, inputs=inputs, outputs=outputs,\n                                  normalize=normalize, verbosity=verbosity)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inputs_from_dataframe(df, delays=(1, 2, 3), inputs=(1, 2, -1), outputs=None, normalize=True, verbosity=1):\n    ds = input_dataset_from_dataframe(df=df, delays=delays, inputs=inputs, outputs=outputs,\n                                      normalize=normalize, verbosity=verbosity)\n    return ds['input']", "response": "Builds a sequence of input vectors suitable for activation by a neural net."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconfigures neural net trainer from a pybrain dataset", "response": "def build_trainer(nn, ds, verbosity=1):\n    \"\"\"Configure neural net trainer from a pybrain dataset\"\"\"\n    return pb.supervised.trainers.rprop.RPropMinusTrainer(nn, dataset=ds, batchlearning=True, verbose=bool(verbosity))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef weight_matrices(nn):\n\n    if isinstance(nn, ndarray):\n        return nn\n\n    try:\n        return weight_matrices(nn.connections)\n    except:\n        pass\n\n    try:\n        return weight_matrices(nn.module)\n    except:\n        pass\n\n    # Network objects are ParameterContainer's too, but won't reshape into a single matrix,\n    # so this must come after try nn.connections\n    if isinstance(nn, (ParameterContainer, Connection)):\n        return reshape(nn.params, (nn.outdim, nn.indim))\n\n    if isinstance(nn, basestring):\n        try:\n            fn = nn\n            nn = NetworkReader(fn, newfile=False)\n            return weight_matrices(nn.readFrom(fn))\n        except:\n            pass\n    # FIXME: what does NetworkReader output? (Module? Layer?) need to handle it's type here\n\n    try:\n        return [weight_matrices(v) for (k, v) in nn.iteritems()]\n    except:\n        try:\n            connections = nn.module.connections.values()\n            nn = []\n            for conlist in connections:\n                nn += conlist\n            return weight_matrices(nn)\n        except:\n            return [weight_matrices(v) for v in nn]", "response": "Extract list of weight matrices from a Network object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the indices of the rows with nan values in a dataframe", "response": "def dataset_nan_locs(ds):\n    \"\"\"\n    from http://stackoverflow.com/a/14033137/623735\n    # gets the indices of the rows with nan values in a dataframe\n    pd.isnull(df).any(1).nonzero()[0]\n    \"\"\"\n    ans = []\n    for sampnum, sample in enumerate(ds):\n        if pd.isnull(sample).any():\n            ans += [{\n                'sample': sampnum,\n                'input':  pd.isnull(sample[0]).nonzero()[0],\n                'output': pd.isnull(sample[1]).nonzero()[0],\n                }]\n    return ans"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef table_nan_locs(table):\n    ans = []\n    for rownum, row in enumerate(table):\n        try:\n            if pd.isnull(row).any():\n                colnums = pd.isnull(row).nonzero()[0]\n                ans += [(rownum, colnum) for colnum in colnums]\n        except AttributeError:  # table is really just a sequence of scalars\n            if pd.isnull(row):\n                ans += [(rownum, 0)]\n    return ans", "response": "returns a list of tuples where each tuple is the row number and the column number of the nan values in the dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_network_results(network, ds=None, mean=0, std=1, title='', show=True, save=True):\n    df = sim_network(network=network, ds=ds, mean=mean, std=std)\n    df.plot()\n    plt.xlabel('Date')\n    plt.ylabel('Threshold (kW)')\n    plt.title(title)\n\n    if show:\n        try:\n            # ipython notebook overrides plt.show and doesn't have a block kwarg\n            plt.show(block=False)\n        except TypeError:\n            plt.show()\n    if save:\n        filename = 'ann_performance_for_{0}.png'.format(title).replace(' ', '_')\n        if isinstance(save, basestring) and os.path.isdir(save):\n            filename = os.path.join(save, filename)\n        plt.savefig(filename)\n    if not show:\n        plt.clf()\n\n    return network, mean, std", "response": "Identical to plot_trainer except network and ds must be provided separately"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nplotting the performance of the Network and SupervisedDataSet in a pybrain Trainer object.", "response": "def trainer_results(trainer, mean=0, std=1, title='', show=True, save=True):\n    \"\"\"Plot the performance of the Network and SupervisedDataSet in a pybrain Trainer\n\n    DataSet target and output values are denormalized before plotting with:\n\n        output * std + mean\n\n    Which inverses the normalization\n\n        (output - mean) / std\n\n    Args:\n        trainer (Trainer): a pybrain Trainer instance containing a valid Network and DataSet\n        ds (DataSet): a pybrain DataSet to override the one contained in `trainer`.\n          Required if trainer is a Network instance rather than a Trainer instance.\n        mean (float): mean of the denormalized dataset (default: 0)\n          Only affects the scale of the plot\n        std (float): std (standard deviation) of the denormalized dataset (default: 1)\n        title (str): title to display on the plot.\n\n    Returns:\n        3-tuple: (trainer, mean, std), A trainer/dataset along with denormalization info\n    \"\"\"\n    return plot_network_results(network=trainer.module, ds=trainer.ds, mean=mean, std=std, title=title,\n                                show=show, save=save)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sim_trainer(trainer, mean=0, std=1):\n    return sim_network(network=trainer.module, ds=trainer.ds, mean=mean, std=std)", "response": "Simulate a trainer by activating its DataSet and returning DataFrame"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsimulating a Network on a SupervisedDataSet and return a DataFrame with columns Output and Target.", "response": "def sim_network(network, ds=None, index=None, mean=0, std=1):\n    \"\"\"Simulate/activate a Network on a SupervisedDataSet and return DataFrame(columns=['Output','Target'])\n\n    The DataSet's target and output values are denormalized before populating the dataframe columns:\n\n        denormalized_output = normalized_output * std + mean\n\n    Which inverses the normalization that produced the normalized output in the first place: \\\n\n        normalized_output = (denormalzied_output - mean) / std\n\n    Args:\n        network (Network): a pybrain Network instance to activate with the provided DataSet, `ds`\n        ds (DataSet): a pybrain DataSet to activate the Network on to produce an output sequence\n        mean (float): mean of the denormalized dataset (default: 0)\n          Output is scaled\n        std (float): std (standard deviation) of the denormalized dataset (default: 1)\n        title (str): title to display on the plot.\n\n    Returns:\n        DataFrame: DataFrame with columns \"Output\" and \"Target\" suitable for df.plot-ting\n    \"\"\"\n    # just in case network is a trainer or has a Module-derived instance as one of it's attribute\n       # isinstance(network.module, (networks.Network, modules.Module))\n    if hasattr(network, 'module') and hasattr(network.module, 'activate'):\n        # may want to also check: isinstance(network.module, (networks.Network, modules.Module))\n        network = network.module\n    ds = ds or network.ds\n    if not ds:\n        raise RuntimeError(\"Unable to find a `pybrain.datasets.DataSet` instance to activate the Network with, \"\n                           \" to plot the outputs. A dataset can be provided as part of a network instance or \"\n                           \"as a separate kwarg if `network` is used to provide the `pybrain.Network`\"\n                           \" instance directly.\")\n    results_generator = ((network.activate(ds['input'][i])[0] * std + mean, ds['target'][i][0] * std + mean)\n                         for i in xrange(len(ds['input'])))\n\n    return pd.DataFrame(results_generator, columns=['Output', 'Target'], index=index or range(len(ds['input'])))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_svc_action(self, name, replace=None, svc=None):\n        actions = svc.get('actions')\n        if actions and actions.get(name):\n            return self.run(name, actions=actions, replace=replace)\n        if svc.get(name + \"-hook\"):\n            return self.run(name, actions={\n                name: {\n                    \"type\": \"hook\",\n                    \"url\": svc.get(name + \"-hook\")\n                }\n            }, replace=replace)\n        self.die(\"Unable to find action {name} on service {svc}\",\n                 name=name, svc=svc.get('name', ''))", "response": "Runs the action with the given name on the given service."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self, name, replace=None, actions=None):\n        self.actions = actions # incase we use group\n\n        action = actions.get(name)\n        if not action:\n            self.die(\"Action not found: {}\", name)\n        action['name'] = name\n        action_type = action.get('type', \"none\")\n        try:\n            func = getattr(self, '_run__' + action_type)\n        except AttributeError:\n            self.die(\"Unsupported action type \" + action_type)\n        try:\n            return func(action, replace)\n        except Exception as err: # pylint: disable=broad-except\n            if self._debug:\n                self.debug(traceback.format_exc())\n            self.die(\"Error running action name={} type={} error={}\",\n                     name, action_type, err)", "response": "Do an action.\n\n\n        If `replace` is provided as a dictionary, do a search/replace using\n        %{} templates on content of action (unique to action type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _run__group(self, action, replace):\n\n        for target in action.get('actions', []):\n            Action().run(target, actions=self.actions, replace=replace)", "response": "Run a group of actions in sequence."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _run__hook(self, action, replace):\n        url = action.get(\"url\")\n        expected = action.get(\"expect\", {}).get(\"response-codes\", (200, 201, 202, 204))\n        if replace and action.get(\"template\", True):\n            url = self.rfxcfg.macro_expand(url, replace)\n        self.logf(\"Action {} hook\\n\", action['name'])\n        self.logf(\"{}\\n\", url, level=common.log_msg)\n        result = requests.get(url)\n        self.debug(\"Result={}\\n\", result.status_code)\n        if result.status_code not in expected:\n            self.die(\"Hook failed name={} result={}\", action['name'], result.status_code)\n        self.logf(\"Success\\n\", level=common.log_good)", "response": "Simple webhook for the current action"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _run__exec(self, action, replace):\n\n        cmd = action.get('cmd')\n        shell = False\n        if isinstance(cmd, str):\n            shell = True\n\n        if replace and action.get(\"template\", True):\n            if shell:\n                cmd = self.rfxcfg.macro_expand(cmd, replace)\n            else:\n                cmd = [self.rfxcfg.macro_expand(x, replace) for x in cmd]\n\n        self.logf(\"Action {} exec\\n\", action['name'])\n        self.logf(\"{}\\n\", cmd, level=common.log_cmd)\n        if self.sys(cmd):\n            self.logf(\"Success\\n\", level=common.log_good)\n            return\n        self.die(\"Failure\\n\", level=common.log_err)", "response": "Run a system command"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def main():\n    # Create Client from endpoint string in Duniter format\n    client = Client(BMAS_ENDPOINT)\n\n    try:\n        # Create Web Socket connection on block path\n        ws_connection = client(bma.ws.block)\n\n        # From the documentation ws_connection should be a ClientWebSocketResponse object...\n        #\n        # https://docs.aiohttp.org/en/stable/client_quickstart.html#websockets\n        #\n        # In reality, aiohttp.session.ws_connect() returns a aiohttp.client._WSRequestContextManager instance.\n        # It must be used in a with statement to get the ClientWebSocketResponse instance from it (__aenter__).\n        # At the end of the with statement, aiohttp.client._WSRequestContextManager.__aexit__ is called\n        # and close the ClientWebSocketResponse in it.\n\n        # Mandatory to get the \"for msg in ws\" to work !\n        async with ws_connection as ws:\n            print(\"Connected successfully to web socket block path\")\n            # Iterate on each message received...\n            async for msg in ws:\n                # if message type is text...\n                if msg.type == aiohttp.WSMsgType.TEXT:\n                    print(\"Received a block\")\n                    # Validate jsonschema and return a the json dict\n                    block_data = parse_text(msg.data, bma.ws.WS_BLOCK_SCHEMA)\n                    print(block_data)\n                elif msg.type == aiohttp.WSMsgType.CLOSED:\n                    # Connection is closed\n                    print(\"Web socket connection closed !\")\n                elif msg.type == aiohttp.WSMsgType.ERROR:\n                    # Connection error\n                    print(\"Web socket connection error !\")\n\n                # Close session\n                await client.close()\n\n    except (aiohttp.WSServerHandshakeError, ValueError) as e:\n        print(\"Websocket block {0} : {1}\".format(type(e).__name__, str(e)))\n    except (aiohttp.ClientError, gaierror, TimeoutError) as e:\n        print(\"{0} : {1}\".format(str(e), BMAS_ENDPOINT))\n    except jsonschema.ValidationError as e:\n        print(\"{:}:{:}\".format(str(e.__class__.__name__), str(e)))", "response": "Main function for the main function of the main function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_default_args(func):\n    args, varargs, keywords, defaults = inspect.getargspec(func)\n    print(args)\n    return dict(zip(reversed(args), reversed(defaults)))", "response": "returns a dictionary of arg_name = > default_values for the input function\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_arg_names(func):\n    ''' this returns the arg names since dictionaries dont guarantee order '''\n    args, varargs, keywords, defaults = inspect.getargspec(func)\n    return(tuple(args))", "response": "this returns the arg names since dictionaries dont guarantee order"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nusing this decorator to enforce type checking on functions based on the function s default arguments", "response": "def strict_defaults(fn):\n    ''' use this decorator to enforce type checking on functions based on the function's defaults '''\n    @wraps(fn)\n    def wrapper(*args, **kwargs):\n        defaults = _get_default_args(fn)\n        # dictionary that holds each default type\n        needed_types={\n            key:type(defaults[key]) for key in defaults\n        }\n        # ordered tuple of the function's argument names\n        arg_names=_get_arg_names(fn)\n        assert not len(arg_names) - len(fn.__defaults__), '{} needs default variables on all arguments'.format(fn.__name__)\n        # merge args to kwargs for easy parsing\n        for i in range(len(args)):\n            if args[i] not in kwargs.keys():\n                kwargs[arg_names[i]]=args[i]\n        # assert that theyre all the correct type\n        for name in needed_types:\n            # do them all seperately so you can show what went wrong\n            assert  isinstance(kwargs[name],needed_types[name]), 'got {} and expected a {}'.format(kwargs[name],needed_types[name])\n        # return the refined results\n        return fn(**kwargs)\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the mailing lists in the M2M model.", "response": "def update_mailing_lists_in_m2m(\n    sender=None,\n    userprofile=None,\n    pk_set=None,\n    subscribe=None,\n    unsubscribe=None,\n    verbose=None,\n    email_enabled=None,\n):\n    \"\"\"\n    m2m_model = m2m model class for 'email_notifications' or\n    'sms_notifications'.\n    \"\"\"\n    response = None\n    email_enabled = email_enabled or settings.EMAIL_ENABLED\n    if email_enabled and site_notifications.loaded:\n        if userprofile.email_notifications.through == sender:\n            NotificationModel = django_apps.get_model(\"edc_notification.Notification\")\n            for notification_obj in NotificationModel.objects.filter(\n                pk__in=list(pk_set), enabled=True\n            ):\n                notification_cls = site_notifications.get(notification_obj.name)\n                notification = notification_cls()\n                manager = MailingListManager(\n                    address=notification.email_to[0],\n                    display_name=notification.display_name,\n                    name=notification.name,\n                )\n                response = manager.create(verbose=verbose)\n                if subscribe:\n                    response = manager.subscribe(userprofile.user, verbose=verbose)\n                elif unsubscribe:\n                    response = manager.unsubscribe(userprofile.user, verbose=verbose)\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef superdict(arg=()):\n    def update(obj, arg):\n        return obj.update(arg) or obj\n    return update(defaultdict(superdict), arg)", "response": "Recursive defaultdict which can init with other dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing pickle to do deep_copy", "response": "def deepcopy(data):\n    \"\"\"Use pickle to do deep_copy\"\"\"\n    try:\n        return pickle.loads(pickle.dumps(data))\n    except TypeError:\n        return copy.deepcopy(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuses ujson to do deep_copy", "response": "def deepcp(data):\n    \"\"\"Use ujson to do deep_copy\"\"\"\n    import ujson\n    try:\n        return ujson.loads(ujson.dumps(data))\n    except Exception:\n        return copy.deepcopy(data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nturning a string representing a version into a normalized version list.", "response": "def normalize(version_string, max_version_parts=4):\n    \"\"\"turn a string representing a version into a normalized version list.\n    Version lists are directly comparable using standard operators such as\n    >, <, ==, etc.\n\n    Parameters:\n      version_string - such as '3.5' or '3.6.3plugin3'\n      max_version_parts - version strings are comprised of a series of 4 tuples.\n                          This should be set to the maximum number of 4 tuples\n                          in a version string.\n    \"\"\"\n    version_list = []\n    for part_count, version_part in enumerate(version_string.split('.')):\n        try:\n            groups = _version_part_re.match(version_part).groups()\n        except Exception, x:\n            raise NotAVersionException(version_string)\n        version_list.extend(t(x) for x, t in zip(groups, _normalize_fn_list))\n    version_list.extend(_padding_list * (max_version_parts - part_count - 1))\n    return version_list"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _do_denormalize (version_tuple):\n    version_parts_list = []\n    for parts_tuple in itertools.imap(None,*([iter(version_tuple)]*4)):\n        version_part = ''.join(fn(x) for fn, x in\n                               zip(_denormalize_fn_list, parts_tuple))\n        if version_part:\n            version_parts_list.append(version_part)\n    return '.'.join(version_parts_list)", "response": "separate action function to allow for the memoize decorator."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef current_revision(self):\n        if self.current_index is None:\n            return None\n\n        if len(self.revisions) > self.current_index:\n            return self.revisions[self.current_index]\n\n        return None", "response": "Returns the current revision."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the revision file.", "response": "def load(self, revision_path):\n        \"\"\"\n        Load revision file.\n\n        :param revision_path:\n        :type revision_path: str\n        \"\"\"\n        if not os.path.exists(revision_path):\n            raise RuntimeError(\"revision file does not exist.\")\n\n        with open(revision_path, mode='r') as f:\n            text = f.read()\n            rev_strings = text.split(\"## \")\n\n            for rev_string in rev_strings:\n                if len(rev_string) == 0 or rev_string[:2] == \"# \":\n                    continue\n\n                try:\n                    revision = Revision()\n                    revision.parse(rev_string)\n                except RuntimeError:\n                    raise RuntimeError(\"\")\n\n                self.insert(revision, len(self.revisions))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninsert a revision at a given index.", "response": "def insert(self, revision, index):\n        \"\"\"\n        Insert a :class:`revision.data.Revision` at a given index.\n\n        :param revision:\n        :type revision: :class:`revision.data.Revision`\n        :param index:\n        :type index: int\n        \"\"\"\n        if not isinstance(revision, Revision):\n            raise InvalidArgType()\n\n        for rev in self.revisions:\n            if rev == revision:\n                return self\n\n        self.revisions.insert(index, revision)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the ast tree to a tater tree.", "response": "def from_ast(\n        pyast_node, node=None, node_cls=None, Node=Node,\n        iter_fields=ast.iter_fields, AST=ast.AST):\n    '''Convert the ast tree to a tater tree.\n    '''\n    node_cls = node_cls or Node\n    node = node or node_cls()\n    name = pyast_node.__class__.__name__\n\n    attrs = []\n    for field, value in iter_fields(pyast_node):\n        if name == 'Dict':\n            for key, value in zip(pyast_node.keys, pyast_node.values):\n                if isinstance(value, list):\n                    for item in value:\n                        if isinstance(item, AST):\n                            value = from_ast(item)\n                elif isinstance(value, AST):\n                    value = from_ast(value)\n                attrs.append((key.s, value))\n        else:\n            if isinstance(value, list):\n                for item in value:\n                    if isinstance(item, AST):\n                        value = from_ast(item)\n            elif isinstance(value, AST):\n                value = from_ast(value)\n            attrs.append((field, value))\n    node.update(attrs, type=name)\n    return node"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall if no explicit visitor function exists for a node.", "response": "def generic_visit(self, node, iter_fields=ast.iter_fields, AST=ast.AST):\n        \"\"\"Called if no explicit visitor function exists for a node.\n        \"\"\"\n        for field, value in iter_fields(node):\n            if isinstance(value, list):\n                for item in value:\n                    if isinstance(item, AST):\n                        self.visit(item)\n            elif isinstance(value, AST):\n                self.visit(value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _validateAttrs(self, keys):\n        badAttrsMsg = \"\"\n        for k in keys:\n            if k not in self.attrs:\n                badAttrsMsg += \"Attribute key '%s' is not a valid attribute\"%(k)\n        if badAttrsMsg:\n            raise ValueError(\"Encountered invalid attributes.  ALLOWED: %s%s%s\"\\\n                %(list(self.attrs), os.linesep, badAttrsMsg))", "response": "prove that all attributes are defined appropriately"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load(self, ladderName):\n        self.name = ladderName # preset value to load self.filename\n        with open(self.filename, \"rb\") as f:\n            data = f.read()\n            self.__dict__.update( json.loads(data) )", "response": "retrieve the ladder settings from saved disk file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, attrs):\n        self._validateAttrs(attrs)\n        for k,v in attrs.items():\n            typecast = type( getattr(self, k) )\n            if typecast==bool and v==\"False\":   newval = False # \"False\" evalued as boolean is True because its length > 0\n            else:                               newval = typecast(v.lower())\n            setattr(self, k, newval)", "response": "update attributes initialized with the proper type"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimports localities from a CSV file.", "response": "def import_localities(path, delimiter=';'):\n    \"\"\"\n    Import localities from a CSV file.\n\n    :param path: Path to the CSV file containing the localities.\n    \"\"\"\n\n    creates = []\n    updates = []\n\n    with open(path, mode=\"r\") as infile:\n        reader = csv.DictReader(infile, delimiter=str(delimiter))\n\n        with atomic():\n            for row in reader:\n                row['point'] = Point(float(row['longitude']),\n                                     float(row['latitude']))\n                locality, created = Locality.objects.update_or_create(\n                    id=row['id'],\n                    defaults=row\n                )\n                if created:\n                    creates.append(locality)\n                else:\n                    updates.append(locality)\n\n    return creates, updates"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of uwnetid. subscription objects corresponding to the netid and subscription code.", "response": "def get_netid_subscriptions(netid, subscription_codes):\n    \"\"\"\n    Returns a list of uwnetid.subscription objects\n    corresponding to the netid and subscription code or list provided\n    \"\"\"\n    url = _netid_subscription_url(netid, subscription_codes)\n    response = get_resource(url)\n    return _json_to_subscriptions(response)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select_subscription(subs_code, subscriptions):\n    if subs_code and subscriptions:\n        for subs in subscriptions:\n            if (subs.subscription_code == subs_code):\n                return subs\n    return None", "response": "Select the subscription object with the subs_code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef modify_subscription_status(netid, subscription_code, status):\n    url = _netid_subscription_url(netid, subscription_code)\n    body = {\n        'action': 'modify',\n        'value': str(status)\n    }\n\n    response = post_resource(url, json.dumps(body))\n    return _json_to_subscriptions(response)", "response": "Modify the status of a given netid and subscription_code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the subscription for the given netid and subscription_code.", "response": "def update_subscription(netid, action, subscription_code, data_field=None):\n    \"\"\"\n    Post a subscription action for the given netid and subscription_code\n    \"\"\"\n    url = '{0}/subscription.json'.format(url_version())\n    action_list = []\n\n    if isinstance(subscription_code, list):\n        for code in subscription_code:\n            action_list.append(_set_action(\n                netid, action, code, data_field))\n    else:\n        action_list.append(_set_action(\n            netid, action, subscription_code, data_field))\n\n    body = {'actionList': action_list}\n    response = post_resource(url, json.dumps(body))\n    return _json_to_subscription_post_response(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _netid_subscription_url(netid, subscription_codes):\n    return \"{0}/{1}/subscription/{2}\".format(\n        url_base(), netid,\n        (','.join([str(n) for n in subscription_codes])\n         if isinstance(subscription_codes, (list, tuple))\n         else subscription_codes))", "response": "Return UWNetId resource for provided netid and subscription_codes or list of subscription_codes"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _json_to_subscriptions(response_body):\n    data = json.loads(response_body)\n    subscriptions = []\n    for subscription_data in data.get(\"subscriptionList\", []):\n        subscriptions.append(Subscription().from_json(\n            data.get('uwNetID'), subscription_data))\n\n    return subscriptions", "response": "Returns a list of Subscription objects from a JSON response body."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _json_to_subscription_post_response(response_body):\n    data = json.loads(response_body)\n    response_list = []\n    for response_data in data.get(\"responseList\", []):\n        response_list.append(SubscriptionPostResponse().from_json(\n            data.get('uwNetID'), response_data))\n\n    return response_list", "response": "Returns a list of SubscriptionPostResponse objects from a JSON response body."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_permission(self, request, view):\n        if view.suffix == 'Instance':\n            return True\n\n        filter_and_actions = self._get_filter_and_actions(\n            request.query_params.get('sign'),\n            view.action,\n            '{}.{}'.format(\n                view.queryset.model._meta.app_label,\n                view.queryset.model._meta.model_name\n            )\n        )\n        if not filter_and_actions:\n            return False\n        if request.method == 'POST':\n            for key, value in request.data.iteritems():\n                # Do unicode conversion because value will always be a\n                # string\n                if (key in filter_and_actions['filters'] and not\n                        unicode(filter_and_actions['filters'][key]) == unicode(value)):\n                    return False\n        return True", "response": "Check list and create permissions based on sign and filters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the user has permission to view the object.", "response": "def has_object_permission(self, request, view, obj=None):\n        \"\"\"Check object permissions based on filters.\"\"\"\n        filter_and_actions = self._get_filter_and_actions(\n            request.query_params.get('sign'),\n            view.action,\n            '{}.{}'.format(obj._meta.app_label, obj._meta.model_name))\n        if not filter_and_actions:\n            return False\n        qs = view.queryset.filter(**filter_and_actions['filters'])\n        return qs.filter(id=obj.id).exists()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_file_argument(self, *args, **kwargs):\n        rval = self.add_argument(*args, **kwargs)\n        self.file_args.append(rval)\n        return rval", "response": "Adds an argument that represents the location of a file holding the cache entry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_argument(self, *args, **kwargs):\n        defhelp = kwargs.pop(\"help\", None)\n        defaults = kwargs.pop(\"default\", None)\n        default = defaults if self.use_defaults else None\n        if not defhelp or default is None or kwargs.get('action') == 'help':\n            return super().add_argument(*args, help=defhelp, default=default, **kwargs)\n        else:\n            return super().add_argument(*args, help=defhelp + \" (default: {})\".format(default),\n                                        default=default, **kwargs)", "response": "Add an argument incorporating the default value into the help string\n                                       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decode_file_args(self, argv: List[str]) -> List[str]:\n        for i in range(0, len(argv) - 1):\n            # TODO: take prefix into account\n            if argv[i] == '--conf':\n                del argv[i]\n                conf_file = argv[i]\n                del (argv[i])\n                with open(conf_file) as config_file:\n                    conf_args = shlex.split(config_file.read())\n                    # We take advantage of a poential bug in the parser where you can say \"foo -u 1 -u 2\" and get\n                    # 2 as a result\n                    argv = self.fix_rel_paths(conf_args, conf_file) + argv\n                return self.decode_file_args(argv)\n        return argv", "response": "Preprocess a configuration file and return the list of options with the file contents as a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse an Interface declaration", "response": "def p_Interface(p):\n  \"\"\"Interface : interface IDENTIFIER Inheritance \"{\" InterfaceMembers \"}\" \";\"\n  \"\"\"\n  p[0] = model.Interface(name=p[2], parent=p[3], members=p[5])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_Dictionary(p):\n  p[0] = model.Dictionary(name=p[2], parent=p[3], members=p[5])", "response": "A dictionary identifier is a literal identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntypes IDENTIFIER Default \";\" Member", "response": "def p_DictionaryMember(p):\n  \"\"\"DictionaryMember : Type IDENTIFIER Default \";\"\n  \"\"\"\n  p[0] = model.DictionaryMember(type=p[1], name=p[2], default=p[3])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_Exception(p):\n  p[0] = model.Exception(name=p[2], parent=p[3], members=p[5])", "response": "Exception : exception IDENTIFIER Inheritance \"{\" ExceptionMembers \"}\" \";\""}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_Const(p):\n  p[0] = model.Const(type=p[2], name=p[3], value=p[5])", "response": "Const : const ConstType IDENTIFIER \"=\" ConstValue \";\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nattributing | Attribute | |", "response": "def p_Attribute(p):\n  \"\"\"Attribute : Inherit ReadOnly attribute Type IDENTIFIER \";\"\n  \"\"\"\n  p[0] = model.Attribute(inherit=p[1], readonly=p[2], type=p[4], name=p[5])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_SingleType_any(p):\n  p[0] = helper.unwrapTypeSuffix(model.SimpleType(\n    model.SimpleType.ANY), p[2])", "response": "SingleType : any TypeSuffixStartingWithArray"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_UnionType(p):\n  t = [p[2]] + [p[4]] + p[5]\n  p[0] = model.UnionType(t=t)", "response": "UnionType | UnionMemberType | UnionMemberTypes | |"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_UnionMemberType_anyType(p):\n  p[0] = helper.unwrapTypeSuffix(model.Array(t=model.SimpleType(\n    type=model.SimpleType.ANY)), p[4])", "response": "UnionMemberType : any \"[\" TypeSuffix"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_NonAnyType_interface(p):\n  p[0] = helper.unwrapTypeSuffix(model.InterfaceType(name=p[1]), p[2])", "response": "NonAnyType : IDENTIFIER TypeSuffix"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nidentify ( ArgumentList )", "response": "def p_ExtendedAttributeArgList(p):\n  \"\"\"ExtendedAttributeArgList : IDENTIFIER \"(\" ArgumentList \")\"\n  \"\"\"\n  p[0] = model.ExtendedAttribute(\n    value=model.ExtendedAttributeValue(name=p[1], arguments=p[3]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef declare_selfvars(self):\n\n        #\n        # Object desc block\n        #\n        self.str_desc                   = ''\n        self.__name__                   = \"pfdicom\"\n        self.str_version                = '1.6.0'\n\n        # Directory and filenames\n        self.str_workingDir             = ''\n        self.str_inputDir               = ''\n        self.str_inputFile              = ''\n        self.str_extension              = ''\n        self.str_outputFileStem         = ''\n        self.str_ouptutDir              = ''\n        self.str_outputLeafDir          = ''\n        self.maxDepth                   = -1\n\n        # pftree dictionary\n        self.pf_tree                    = None\n        self.numThreads                 = 1\n\n        self.str_stdout                 = ''\n        self.str_stderr                 = ''\n        self.exitCode                   = 0\n\n        self.b_json                     = False\n        self.b_followLinks              = False\n\n        # The actual data volume and slice\n        # are numpy ndarrays\n        self.dcm                        = None\n        self.d_dcm                      = {}     # dict convert of raw dcm\n        self.strRaw                     = \"\"\n        self.l_tagRaw                   = []\n\n        # Simpler dictionary representations of DICOM tags\n        # NB -- the pixel data is not read into the dictionary\n        # by default\n        self.d_dicom                   = {}     # values directly from dcm ojbect\n        self.d_dicomSimple             = {}     # formatted dict convert\n\n        # Convenience vars\n        self.tic_start                  = None\n\n        self.dp                         = None\n        self.log                        = None\n        self.tic_start                  = 0.0\n        self.pp                         = pprint.PrettyPrinter(indent=4)\n        self.verbosityLevel             = 1", "response": "This function is used to declare the basic self - variables for the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef env_check(self, *args, **kwargs):\n        b_status    = True\n        str_error   = ''\n        if not len(self.str_outputDir): \n            b_status = False\n            str_error   = 'output directory not specified.'\n            self.dp.qprint(str_error, comms = 'error')\n            error.warn(self, 'outputDirFail', drawBox = True)\n        return {\n            'status':       b_status,\n            'str_error':    str_error\n        }", "response": "This method provides a common entry for all environment checks."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tagsInString_process(self, d_DICOM, astr, *args, **kwargs):\n        b_tagsFound         = False\n        str_replace         = ''        # The lookup/processed tag value\n        l_tags              = []        # The input string split by '%'\n        l_tagsToSub         = []        # Remove any noise etc from each tag\n        l_funcTag           = []        # a function/tag list\n        l_args              = []        # the 'args' of the function\n        func                = ''        # the function to apply\n        tag                 = ''        # the tag in the funcTag combo\n        chars               = ''        # the number of resultant chars from func\n                                        # result to use\n        if '%' in astr:\n            l_tags          = astr.split('%')[1:]\n            # Find which tags (mangled) in string match actual tags\n            l_tagsToSub     = [i for i in d_DICOM['l_tagRaw'] if any(i in b for b in l_tags)]\n            # Need to arrange l_tagsToSub in same order as l_tags\n            l_tagsToSubSort =  sorted(\n                l_tagsToSub, \n                key = lambda x: [i for i, s in enumerate(l_tags) if x in s][0]\n            )\n            for tag, func in zip(l_tagsToSubSort, l_tags):\n                b_tagsFound     = True\n                str_replace     = d_DICOM['d_dicomSimple'][tag]\n                if 'md5' in func:\n                    str_replace = hashlib.md5(str_replace.encode('utf-8')).hexdigest()\n                    l_funcTag   = func.split('_')[1:]\n                    func        = l_funcTag[0]\n                    l_args      = func.split('|')\n                    if len(l_args) > 1:\n                        chars   = l_args[1]\n                        str_replace     = str_replace[0:int(chars)]\n                    astr = astr.replace('_%s_' % func, '')\n                if 'strmsk' in func:\n                    l_funcTag   = func.split('_')[1:]\n                    func        = l_funcTag[0]\n                    str_msk     = func.split('|')[1]\n                    l_n = []\n                    for i, j in zip(list(str_replace), list(str_msk)):\n                        if j == '*':    l_n.append(i)\n                        else:           l_n.append(j)\n                    str_replace = ''.join(l_n)\n                    astr = astr.replace('_%s_' % func, '')\n                if 'nospc' in func:\n                    # pudb.set_trace()\n                    l_funcTag   = func.split('_')[1:]\n                    func        = l_funcTag[0]\n                    l_args      = func.split('|')\n                    str_char    = ''\n                    if len(l_args) > 1:\n                        str_char = l_args[1]\n                    # strip out all non-alphnumeric chars and \n                    # replace with space\n                    str_replace = re.sub(r'\\W+', ' ', str_replace)\n                    # replace all spaces with str_char\n                    str_replace = str_char.join(str_replace.split())\n                    astr = astr.replace('_%s_' % func, '')\n                astr  = astr.replace('%' + tag, str_replace)\n        \n        return {\n            'status':       True,\n            'b_tagsFound':  b_tagsFound,\n            'str_result':   astr\n        }", "response": "This method replaces DICOM tags that are '%' - tagged by the actual tag lookup and the actual tag lookup."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef DICOMfile_read(self, *args, **kwargs):\n        b_status        = False\n        l_tags          = []\n        l_tagsToUse     = []\n        d_tagsInString  = {}\n        str_file        = \"\"\n\n        d_DICOM           = {\n            'dcm':              None,\n            'd_dcm':            {},\n            'strRaw':           '',\n            'l_tagRaw':         [],\n            'd_json':           {},\n            'd_dicom':          {},\n            'd_dicomSimple':    {}\n        }\n\n        for k, v in kwargs.items():\n            if k == 'file':             str_file    = v\n            if k == 'l_tagsToUse':      l_tags      = v\n\n        if len(args):\n            l_file          = args[0]\n            str_file        = l_file[0]\n\n        str_localFile   = os.path.basename(str_file)\n        str_path        = os.path.dirname(str_file)\n        # self.dp.qprint(\"%s: In input base directory:      %s\" % (threading.currentThread().getName(), self.str_inputDir))\n        # self.dp.qprint(\"%s: Reading DICOM file in path:   %s\" % (threading.currentThread().getName(),str_path))\n        # self.dp.qprint(\"%s: Analysing tags on DICOM file: %s\" % (threading.currentThread().getName(),str_localFile))      \n        # self.dp.qprint(\"%s: Loading:                      %s\" % (threading.currentThread().getName(),str_file))\n\n        try:\n            # self.dcm    = dicom.read_file(str_file)\n            d_DICOM['dcm']  = dicom.read_file(str_file)\n            b_status    = True\n        except:\n            self.dp.qprint('In directory: %s' % os.getcwd(),    comms = 'error')\n            self.dp.qprint('Failed to read %s' % str_file,      comms = 'error')\n            b_status    = False\n        d_DICOM['d_dcm']    = dict(d_DICOM['dcm'])\n        d_DICOM['strRaw']   = str(d_DICOM['dcm'])\n        d_DICOM['l_tagRaw'] = d_DICOM['dcm'].dir()\n\n        if len(l_tags):\n            l_tagsToUse     = l_tags\n        else:\n            l_tagsToUse     = d_DICOM['l_tagRaw']\n\n        if 'PixelData' in l_tagsToUse:\n            l_tagsToUse.remove('PixelData')\n\n        for key in l_tagsToUse:\n            d_DICOM['d_dicom'][key]       = d_DICOM['dcm'].data_element(key)\n            try:\n                d_DICOM['d_dicomSimple'][key] = getattr(d_DICOM['dcm'], key)\n            except:\n                d_DICOM['d_dicomSimple'][key] = \"no attribute\"\n            d_DICOM['d_json'][key]        = str(d_DICOM['d_dicomSimple'][key])\n\n        # pudb.set_trace()\n        d_tagsInString  = self.tagsInString_process(d_DICOM, self.str_outputFileStem)\n        str_outputFile  = d_tagsInString['str_result']\n\n        return {\n            'status':           b_status,\n            'inputPath':        str_path,\n            'inputFilename':    str_localFile,\n            'outputFileStem':   str_outputFile,\n            'd_DICOM':          d_DICOM,\n            'l_tagsToUse':      l_tagsToUse\n        }", "response": "Read a DICOM file and perform some initial parsing of tags."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filelist_prune(self, at_data, *args, **kwargs):\n\n        b_status    = True\n        l_file      = []\n        str_path    = at_data[0]\n        al_file     = at_data[1]\n        if len(self.str_extension):\n            al_file = [x for x in al_file if self.str_extension in x]\n\n        if len(al_file):\n            al_file.sort()\n            l_file      = al_file\n            b_status    = True\n        else:\n            self.dp.qprint( \"No valid files to analyze found in path %s!\" % str_path, \n                            comms = 'error', level = 3)\n            l_file      = None\n            b_status    = False\n        return {\n            'status':   b_status,\n            'l_file':   l_file\n        }", "response": "Given a list of files possibly prune list by \n        extension."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndumping the result of a function call to the console or caller.", "response": "def ret_dump(self, d_ret, **kwargs):\n        \"\"\"\n        JSON print results to console (or caller)\n        \"\"\"\n        b_print     = True\n        for k, v in kwargs.items():\n            if k == 'JSONprint':    b_print     = bool(v)\n        if b_print:\n            print(\n                json.dumps(   \n                    d_ret, \n                    indent      = 4,\n                    sort_keys   = True\n                )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconnecting or reconnect to broker", "response": "def reconnect_to_broker(self):\n        \"\"\"Connect or reconnect to broker\"\"\"\n        #print \"CONNECT !\"\n        if self.client:\n            self.poller.unregister(self.client)\n            self.client.close()\n        self.client = self.ctx.socket(zmq.DEALER)\n        self.client.linger = 0\n        self.client.connect(self.broker)\n        self.poller.register(self.client, zmq.POLLIN)\n        if self.verbose:\n            logging.info(\"I: connecting to broker at %s...\", self.broker)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a request to broker with the specified service and the set of attributes.", "response": "def send(self, service, request):\n        \"\"\"Send request to broker\n        \"\"\"\n        if not isinstance(request, list):\n            request = [request]\n\n        # Prefix request with protocol frames\n        # Frame 0: empty (REQ emulation)\n        # Frame 1: \"MDPCxy\" (six bytes, MDP/Client x.y)\n        # Frame 2: Service name (printable string)\n\n        request = ['', MDP.C_CLIENT, service] + request\n        if self.verbose:\n            logging.warn(\"I: send request to '%s' service: \", service)\n            dump(request)\n        self.client.send_multipart(request)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreceive a reply from the server.", "response": "def recv(self):\n        \"\"\"Returns the reply message or None if there was no reply.\"\"\"\n        try:\n            items = self.poller.poll(self.timeout)\n        except KeyboardInterrupt:\n            return  # interrupted\n\n        if items:\n            # if we got a reply, process it\n            msg = self.client.recv_multipart()\n            self.close()\n            if self.verbose:\n                logging.info(\"I: received reply:\")\n                dump(msg)\n\n            # Don't try to handle errors, just assert noisily\n            assert len(msg) >= 4\n\n            #first drop will be drop (cause empty)\n            header = msg.pop(0)\n            header = msg.pop(0)\n            assert MDP.C_CLIENT == header\n\n            #this one contains servicename\n            #TODO: exploit this\n            header = msg.pop(0)\n\n            return msg\n        else:\n            logging.warn(\"W: permanent error, abandoning request\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def get_identity_document(client: Client, current_block: dict, pubkey: str) -> Identity:\n    # Here we request for the path wot/lookup/pubkey\n    lookup_data = await client(bma.wot.lookup, pubkey)\n\n    # init vars\n    uid = None\n    timestamp = BlockUID.empty()\n    signature = None\n\n    # parse results\n    for result in lookup_data['results']:\n        if result[\"pubkey\"] == pubkey:\n            uids = result['uids']\n            for uid_data in uids:\n                # capture data\n                timestamp = BlockUID.from_str(uid_data[\"meta\"][\"timestamp\"])\n                uid = uid_data[\"uid\"]\n                signature = uid_data[\"self\"]\n\n            # return self-certification document\n            return Identity(\n                version=10,\n                currency=current_block['currency'],\n                pubkey=pubkey,\n                uid=uid,\n                ts=timestamp,\n                signature=signature\n            )", "response": "Get the identity document of the pubkey"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_certification_document(current_block: dict, self_cert_document: Identity, from_pubkey: str) -> Certification:\n    # construct Certification Document\n    return Certification(version=10, currency=current_block['currency'], pubkey_from=from_pubkey,\n                                  identity=self_cert_document,\n                                  timestamp=BlockUID(current_block['number'], current_block['hash']), signature=\"\")", "response": "Create and return a Certification document based on the current block data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def main():\n    # Create Client from endpoint string in Duniter format\n    client = Client(BMAS_ENDPOINT)\n\n    # Get the node summary infos to test the connection\n    response = await client(bma.node.summary)\n    print(response)\n\n    # prompt hidden user entry\n    salt = getpass.getpass(\"Enter your passphrase (salt): \")\n\n    # prompt hidden user entry\n    password = getpass.getpass(\"Enter your password: \")\n\n    # create key from credentials\n    key = SigningKey.from_credentials(salt, password)\n    pubkey_from = key.pubkey\n\n    # prompt entry\n    pubkey_to = input(\"Enter certified pubkey: \")\n\n    # capture current block to get version and currency and blockstamp\n    current_block = await client(bma.blockchain.current)\n\n    # create our Identity document to sign the Certification document\n    identity = await get_identity_document(client, current_block, pubkey_to)\n\n    # send the Certification document to the node\n    certification = get_certification_document(current_block, identity, pubkey_from)\n\n    # sign document\n    certification.sign([key])\n\n    # Here we request for the path wot/certify\n    response = await client(bma.wot.certify, certification.signed_raw())\n\n    if response.status == 200:\n        print(await response.text())\n    else:\n        print(\"Error while publishing certification: {0}\".format(await response.text()))\n\n    # Close client aiohttp session\n    await client.close()", "response": "Main function for the node - get - summary - info command"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsigning the current document.", "response": "def sign(self, keys):\n        \"\"\"\n        Sign the current document.\n        Warning : current signatures will be replaced with the new ones.\n        \"\"\"\n        key = keys[0]\n        signed = self.raw()[-2:]\n        signing = base64.b64encode(key.signature(bytes(signed, 'ascii')))\n        self.signatures = [signing.decode(\"ascii\")]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _dfs_cycle_detect(graph, node, path, visited_nodes):\n    visited_nodes.add(node)\n    for target in graph[node]:\n        if target in path:\n            # cycle found => return current path\n            return path + [target]\n        else:\n            return _dfs_cycle_detect(graph, target, path + [target], visited_nodes)\n    return None", "response": "Search graph for cycle using DFS continuing from node\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch the given directed graph for cycles returns None if the given graph is cycle free otherwise it returns a path through the graph that contains a cycle :param graph: :return:", "response": "def detect_cycle(graph):\n    \"\"\"\n    search the given directed graph for cycles\n\n    returns None if the given graph is cycle free\n    otherwise it returns a path through the graph that contains a cycle\n    :param graph:\n    :return:\n    \"\"\"\n\n    visited_nodes = set()\n\n    for node in list(graph):\n        if node not in visited_nodes:\n            cycle = _dfs_cycle_detect(graph, node, [node], visited_nodes)\n            if cycle:\n                return cycle\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef topsort(graph):\n\n    count = defaultdict(int)\n    for feature, node in graph.items():\n        for target in node:\n            count[target] += 1\n    # convert for list is necessary for py3 as in py3 the filter\n    # function creates a filter object, in py2 it returns a list\n    free_nodes = list(filter(lambda x: count[x] == 0, graph))\n    result = []\n    while free_nodes:\n        node = free_nodes.pop()\n        result.append(node)\n        for target in graph[node]:\n            count[target] -= 1\n            if count[target] == 0:\n                free_nodes.append(target)\n    return result", "response": "Returns a list of nodes in topological order"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing arguments and make go", "response": "def main():\n    cmd = sys.argv\n    cmd.pop(0)\n    \"\"\"\n    parse arguments and make go\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '-s',\n        '--src',\n        help='source folder to watch',\n        default='.',\n        dest='src',\n        metavar='folder'\n    )\n    parser.add_argument(\n        '-d',\n        '--dest',\n        help='source folder to watch',\n        default=None,\n        dest='dest',\n        metavar='folder'\n    )\n    args = parser.parse_args()\n    print 'Initializing...'\n    config.source_dir = os.path.abspath(args.src)\n    if args.dest != None:\n        config.dest_dir = os.path.abspath(args.dest)\n    init_sources(config.source_dir)\n    if cmd:\n        c = cmd[0]\n        commands = globals()\n        if c in commands:\n            commands[c]()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init_sources(path):\n    for f in dir_list(path):\n        if(os.path.splitext(f)[1][1:] == config.source_ext):\n            print \"Source file discovered: %s\" % (f)\n            script = Script(f)\n            if (script.filename not in config.sources.keys()):\n                config.sources[script.path] = script\n                parse.parse_dependencies(script,script)", "response": "Initialize the sources array"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwatches for file events in the supplied path", "response": "def start_scanner(path):\n    \"\"\"\n    watch for file events in the supplied path\n    \"\"\"\n    try:\n        observer = Observer()\n        observer.start()\n        stream = Stream(file_modified, path, file_events=True)\n        observer.schedule(stream)\n        print \"Watching for changes. Press Ctrl-C to stop.\"\n        while 1:\n          pass\n    except (KeyboardInterrupt, OSError, IOError):\n        observer.unschedule(stream)\n        observer.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreacts to file events", "response": "def file_modified(event):\n    \"\"\"\n    react to file events\n    \"\"\"\n    if re.match(config.file_regex,event.name) or (event.name in config.sources.keys()):\n        print \"Change detected to: %s\" % (event.name)\n        config.stack = []\n        script = config.sources[event.name]\n        if script.extension == config.source_ext:\n            parse.parse_file(script)\n        else:\n            parse.parse_parents(script)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter_tuple_from_csv(path,\n                        iterator=False,\n                        chunksize=None,\n                        skiprows=None,\n                        nrows=None,\n                        **kwargs):\n    \"\"\"A high performance, low memory usage csv file row iterator function.\n\n    :param path: csv file path.\n    :param iterator:\n    :param chunksize:\n    :param skiprows:\n    :param nrows:\n\n    :yield tuple: \n\n    **\u4e2d\u6587\u6587\u6863**\n\n    \u5bf9dataframe\u8fdb\u884ctuple\u98ce\u683c\u7684\u9ad8\u6027\u80fd\u884c\u904d\u5386\u3002\n\n    \u5bf9\u7528pandas\u4ececsv\u6587\u4ef6\u8bfb\u53d6\u7684dataframe\u8fdb\u884c\u9010\u884c\u904d\u5386\u65f6, iterrows\u548citertuple\n    \u90fd\u4e0d\u662f\u6027\u80fd\u6700\u9ad8\u7684\u65b9\u6cd5\u3002\u8fd9\u662f\u56e0\u4e3aiterrows\u8981\u751f\u6210Series\u5bf9\u8c61, \u800citertuple\n    \u4e5f\u8981\u5bf9index\u8fdb\u884c\u8bbf\u95ee\u3002\u6240\u4ee5\u672c\u65b9\u6cd5\u662f\u4f7f\u7528\u5185\u5efazip\u65b9\u6cd5\u5bf9\u6240\u6709\u7684column\u8fdb\u884c\u6253\u5305\n    \u89e3\u538b, \u6240\u4ee5\u6027\u80fd\u4e0a\u662f\u6700\u4f73\u7684\u3002\n    \"\"\"\n    kwargs[\"iterator\"] = iterator\n    kwargs[\"chunksize\"] = chunksize\n    kwargs[\"skiprows\"] = skiprows\n    kwargs[\"nrows\"] = nrows\n\n    if iterator is True:\n        for df in pd.read_csv(path, **kwargs):\n            for tp in itertuple(df):\n                yield tp\n    else:\n        df = pd.read_csv(path, **kwargs)\n        for tp in itertuple(df):\n            yield tp", "response": "A high performance low memory usage csv file row iterator function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef index_row_dict_from_csv(path,\n                            index_col=None,\n                            iterator=False,\n                            chunksize=None,\n                            skiprows=None,\n                            nrows=None,\n                            use_ordered_dict=True,\n                            **kwargs):\n    \"\"\"Read the csv into a dictionary. The key is it's index, the value\n    is the dictionary form of the row.\n\n    :param path: csv file path.\n    :param index_col: None or str, the column that used as index.\n    :param iterator:\n    :param chunksize:\n    :param skiprows:\n    :param nrows:\n    :param use_ordered_dict:\n\n    :returns: {index_1: row1, index2: row2, ...} \n\n    **\u4e2d\u6587\u6587\u6863**\n\n    \u8bfb\u53d6csv, \u9009\u62e9\u4e00\u503c\u5b8c\u5168\u4e0d\u91cd\u590d, \u53ef\u4f5c\u4e3aindex\u7684\u5217\u4f5c\u4e3aindex, \u751f\u6210\u4e00\u4e2a\u5b57\u5178\n    \u6570\u636e\u7ed3\u6784, \u4f7f\u5f97\u53ef\u4ee5\u901a\u8fc7index\u76f4\u63a5\u8bbf\u95eerow\u3002\n    \"\"\"\n    _kwargs = dict(list(kwargs.items()))\n    _kwargs[\"iterator\"] = None\n    _kwargs[\"chunksize\"] = None\n    _kwargs[\"skiprows\"] = 0\n    _kwargs[\"nrows\"] = 1\n\n    df = pd.read_csv(path, index_col=index_col, **_kwargs)\n    columns = df.columns\n\n    if index_col is None:\n        raise Exception(\"please give index_col!\")\n\n    if use_ordered_dict:\n        table = OrderedDict()\n    else:\n        table = dict()\n\n    kwargs[\"iterator\"] = iterator\n    kwargs[\"chunksize\"] = chunksize\n    kwargs[\"skiprows\"] = skiprows\n    kwargs[\"nrows\"] = nrows\n\n    if iterator is True:\n        for df in pd.read_csv(path, index_col=index_col, **kwargs):\n            for ind, tp in zip(df.index, itertuple(df)):\n                table[ind] = dict(zip(columns, tp))\n    else:\n        df = pd.read_csv(path, index_col=index_col, **kwargs)\n        for ind, tp in zip(df.index, itertuple(df)):\n            table[ind] = dict(zip(columns, tp))\n\n    return table", "response": "Read the csv into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef native_path(path):  # pragma: no cover\n    if PY2 and not isinstance(path, bytes):\n        return path.encode(fs_encoding)\n    return path", "response": "Returns a native path that is unicode on Python 3 and bytestring on Python 2."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select_field(col, field_or_fields, filters=None):\n    fields = _preprocess_field_or_fields(field_or_fields)\n\n    if filters is None:\n        filters = dict()\n\n    wanted = {field: True for field in fields}\n\n    if len(fields) == 1:\n        header = fields[0]\n        data = [doc.get(header) for doc in col.find(filters, wanted)]\n        return header, data\n    else:\n        headers = list(fields)\n        data = [[doc.get(header) for header in headers]\n                for doc in col.find(filters, wanted)]\n        return headers, data", "response": "Select one or multiple fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef select_distinct_field(col, field_or_fields, filters=None):\n    fields = _preprocess_field_or_fields(field_or_fields)\n\n    if filters is None:\n        filters = dict()\n\n    if len(fields) == 1:\n        key = fields[0]\n        data = list(col.find(filters).distinct(key))\n        return data\n    else:\n        pipeline = [\n            {\n                \"$match\": filters\n            },\n            {\n                \"$group\": {\n                    \"_id\": {key: \"$\" + key for key in fields},\n                },\n            },\n        ]\n        data = list()\n        for doc in col.aggregate(pipeline):\n            # doc = {\"_id\": {\"a\": 0, \"b\": 0}} ...\n            data.append([doc[\"_id\"][key] for key in fields])\n        return data", "response": "Select distinct value or combination of values of all fields in a single or multiple fields."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating version ID for all dirty rows", "response": "def _before_flush_handler(session, _flush_context, _instances):\n    \"\"\"Update version ID for all dirty, modified rows\"\"\"\n    dialect = get_dialect(session)\n    for row in session.dirty:\n        if isinstance(row, SavageModelMixin) and is_modified(row, dialect):\n            # Update row version_id\n            row.update_version_id()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\narchive all new or updated data", "response": "def _after_flush_handler(session, _flush_context):\n    \"\"\"Archive all new/updated/deleted data\"\"\"\n    dialect = get_dialect(session)\n    handlers = [\n        (_versioned_delete, session.deleted),\n        (_versioned_insert, session.new),\n        (_versioned_update, session.dirty),\n    ]\n    for handler, rows in handlers:\n        # TODO: Bulk archive insert statements\n        for row in rows:\n            if not isinstance(row, SavageModelMixin):\n                continue\n            if not hasattr(row, 'ArchiveTable'):\n                raise LogTableCreationError('Need to register Savage tables!!')\n            user_id = getattr(row, '_updated_by', None)\n            handler(row, session, user_id, dialect)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting optical model from given version", "response": "def opticalModel(sim, ver: xarray.DataArray, obsAlt_km: float, zenithang: float):\n    \"\"\"\n    ver: Nalt x Nwavelength\n\n    \"\"\"\n    assert isinstance(ver, xarray.DataArray)\n# %% get system optical transmission T\n    optT = getSystemT(ver.wavelength_nm, sim.bg3fn, sim.windowfn, sim.qefn, obsAlt_km, zenithang)\n# %% first multiply VER by T, THEN sum overall wavelengths\n    if sim.opticalfilter == 'bg3':\n        VERgray = (ver*optT['sys'].values[None, :]).sum('wavelength_nm')\n    elif sim.opticalfilter == 'none':\n        VERgray = (ver*optT['sysNObg3'].values[None, :]).sum('wavelength_nm')\n    else:\n        logging.warning(f'unknown OpticalFilter type: {sim.opticalfilter}'\n                        '   falling back to using no filter at all')\n        VERgray = (ver*optT['sysNObg3'].values[None, :]).sum('wavelength_nm')\n\n    return VERgray"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_text_type(content_type, default_encoding, dumper, loader):\n    content_type = headers.parse_content_type(content_type)\n    content_type.parameters.clear()\n    key = str(content_type)\n    _content_types[key] = content_type\n\n    handler = _content_handlers.setdefault(key, _ContentHandler(key))\n    handler.dict_to_string = dumper\n    handler.string_to_dict = loader\n    handler.default_encoding = default_encoding or handler.default_encoding", "response": "Register handling for a text - based content type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_binary_type(content_type, dumper, loader):\n    content_type = headers.parse_content_type(content_type)\n    content_type.parameters.clear()\n    key = str(content_type)\n    _content_types[key] = content_type\n\n    handler = _content_handlers.setdefault(key, _ContentHandler(key))\n    handler.dict_to_bytes = dumper\n    handler.bytes_to_dict = loader", "response": "Register handling for a binary content type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unpack_bytes(self, obj_bytes, encoding=None):\n        assert self.bytes_to_dict or self.string_to_dict\n        encoding = encoding or self.default_encoding\n        LOGGER.debug('%r decoding %d bytes with encoding of %s',\n                     self, len(obj_bytes), encoding)\n        if self.bytes_to_dict:\n            return escape.recursive_unicode(self.bytes_to_dict(obj_bytes))\n        return self.string_to_dict(obj_bytes.decode(encoding))", "response": "Unpack a byte stream into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pack_bytes(self, obj_dict, encoding=None):\n        assert self.dict_to_bytes or self.dict_to_string\n        encoding = encoding or self.default_encoding or 'utf-8'\n        LOGGER.debug('%r encoding dict with encoding %s', self, encoding)\n        if self.dict_to_bytes:\n            return None, self.dict_to_bytes(obj_dict)\n        try:\n            return encoding, self.dict_to_string(obj_dict).encode(encoding)\n        except LookupError as error:\n            raise web.HTTPError(\n                406, 'failed to encode result %r', error,\n                reason='target charset {0} not found'.format(encoding))\n        except UnicodeEncodeError as error:\n            LOGGER.warning('failed to encode text as %s - %s, trying utf-8',\n                           encoding, str(error))\n            return 'utf-8', self.dict_to_string(obj_dict).encode('utf-8')", "response": "Pack a dictionary into a byte stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_request_body(self):\n        if self._request_body is None:\n            content_type_str = self.request.headers.get(\n                'Content-Type', 'application/octet-stream')\n            LOGGER.debug('decoding request body of type %s', content_type_str)\n            content_type = headers.parse_content_type(content_type_str)\n            try:\n                selected, requested = algorithms.select_content_type(\n                    [content_type], _content_types.values())\n            except errors.NoMatch:\n                raise web.HTTPError(\n                    415, 'cannot decoded content type %s', content_type_str,\n                    reason='Unexpected content type')\n            handler = _content_handlers[str(selected)]\n            try:\n                self._request_body = handler.unpack_bytes(\n                    self.request.body,\n                    encoding=content_type.parameters.get('charset'),\n                )\n            except ValueError as error:\n                raise web.HTTPError(\n                    400, 'failed to decode content body - %r', error,\n                    reason='Content body decode failure')\n        return self._request_body", "response": "Decodes the request body and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_response(self, response_dict):\n        accept = headers.parse_http_accept_header(\n            self.request.headers.get('Accept', '*/*'))\n        try:\n            selected, _ = algorithms.select_content_type(\n                accept, _content_types.values())\n        except errors.NoMatch:\n            raise web.HTTPError(406,\n                                'no acceptable content type for %s in %r',\n                                accept, _content_types.values(),\n                                reason='Content Type Not Acceptable')\n\n        LOGGER.debug('selected %s as outgoing content type', selected)\n        handler = _content_handlers[str(selected)]\n\n        accept = self.request.headers.get('Accept-Charset', '*')\n        charsets = headers.parse_accept_charset(accept)\n        charset = charsets[0] if charsets[0] != '*' else None\n        LOGGER.debug('encoding response body using %r with encoding %s',\n                     handler, charset)\n        encoding, response_bytes = handler.pack_bytes(response_dict,\n                                                      encoding=charset)\n\n        if encoding:  # don't overwrite the value in _content_types\n            copied = datastructures.ContentType(selected.content_type,\n                                                selected.content_subtype,\n                                                selected.parameters)\n            copied.parameters['charset'] = encoding\n            selected = copied\n        self.set_header('Content-Type', str(selected))\n        self.write(response_bytes)", "response": "Encode a response according to the request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef archive_query_interval(self, _from, to):\n        '''\n        :param _from: Start of interval (int) (inclusive)\n        :param to: End of interval (int) (exclusive)\n        :raises: IOError\n        '''\n        with self.session as session:\n            table = self.tables.archive\n\n            try:\n                results = session.query(table)\\\n                    .filter(table.dateTime >= _from)\\\n                    .filter(table.dateTime < to)\\\n                    .all()\n\n                return [self.archive_schema.dump(entry).data for entry in results]\n            except SQLAlchemyError as exc:\n                session.rollback()\n                print_exc()\n                raise IOError(exc)", "response": "Query archive for the set of archive entries in the archive."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninsert data into the archive table.", "response": "def archive_insert_data(self, data_dump):\n        '''\n        :param data: Archive table data\n        :type data: list[archive]\n        :raises: IOError\n        '''\n        with self.session as session:\n            try:\n                data = [self.tables.archive(**entry) for entry in data_dump]\n\n                session.add_all(data)\n                session.commit()\n            except SQLAlchemyError as exc:\n                session.rollback()\n                print_exc()\n                raise IOError(exc)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread a config file from the user s home directory.", "response": "def read_config():\n    \"\"\"\n    Read a config file from ``$HOME/.profrc``\n    We expect a file of the following form\n\n    [DEFAULT]\n    Baseurl = https://your-prof-instance\n    Login = username\n    \"\"\"\n    filename = path.join(path.expanduser('~'), '.profrc')\n    config = configparser.ConfigParser()\n    config.read(filename)\n    if 'baseurl' not in config['DEFAULT']:\n        print(\"\"\"FATAL : No baseurl found in {0}\nOpen {0} and add the following lines\n\n[DEFAULT]\nBaseurl = https://your-prof-instance\"\"\".format(filename))\n        sys.exit()\n    try:\n        requests.get(config['DEFAULT']['BASEURL'])\n    except:\n        print(\"{0} does not seems to be reachable. Verify the baseurl set at {1} matches ``https://your-prof-instance``\".format(config['DEFAULT']['BASEURL'], filename))\n        sys.exit()\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_sessid(sessid):\n    filename = path.join(path.expanduser('~'), '.profrc')\n    config = configparser.ConfigParser()\n    config.read(filename)\n    config.set('DEFAULT', 'Session', sessid)\n    with open(filename, 'w') as configfile:\n        print(\"write a new sessid\")\n        config.write(configfile)", "response": "Save this current sessid in the current config file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_command(command):\n    try:\n        check_ouput = getattr(\n            subprocess, 'check_output', subprocess.check_call)\n        result = check_ouput(command, stderr=subprocess.STDOUT, shell=True)\n        if check_ouput.__name__ == 'check_output':\n            return 0, result\n        else:\n            return result, None\n    except subprocess.CalledProcessError as e:\n        return e.returncode, getattr(e, 'output', None)", "response": "Utility function for run command with subprocess."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the values from a given environment against a given config schema.", "response": "def parse_env(config_schema, env):\n    \"\"\"Parse the values from a given environment against a given config schema\n\n    Args:\n        config_schema: A dict which maps the variable name to a Schema object\n            that describes the requested value.\n        env: A dict which represents the value of each variable in the\n            environment.\n    \"\"\"\n    try:\n        return {\n            key: item_schema.parse(key, env.get(key))\n            for key, item_schema in config_schema.items()\n        }\n    except KeyError as error:\n        raise MissingConfigError(\n            \"Required config not set: {}\".format(error.args[0])\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse(self, key, value):\n        if value is not None:\n            try:\n                return self._parser(value)\n            except Exception:\n                raise ParsingError(\"Error parsing {}\".format(key))\n        elif self._default is not SENTINAL:\n            return self._default\n        else:\n            raise KeyError(key)", "response": "Parse the environment variable value for a given key against the schema."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_json_to_temp_file(data):\n    fp = tempfile.NamedTemporaryFile(delete=False)\n    fp.write(json.dumps(data).encode('utf-8'))\n    fp.close()\n    return fp.name", "response": "Writes JSON data to a temporary file and returns the path to it"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mock_lockfile_update(path):\n    updated_lockfile_contents = {\n        'package1': '1.2.0'\n    }\n    with open(path, 'w+') as f:\n        f.write(json.dumps(updated_lockfile_contents, indent=4))\n    return updated_lockfile_contents", "response": "This is a mock update."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting the settings example.", "response": "def print_settings_example():\n    \"\"\"\n    You can use settings to get additional information from the user via their\n    dependencies.io configuration file. Settings will be automatically injected as\n    env variables with the \"SETTING_\" prefix.\n\n    All settings will be passed as strings. More complex types will be json\n    encoded. You should always provide defaults, if possible.\n    \"\"\"\n    SETTING_EXAMPLE_LIST = json.loads(os.getenv('SETTING_EXAMPLE_LIST', '[]'))\n    SETTING_EXAMPLE_STRING = os.getenv('SETTING_EXAMPLE_STRING', 'default')\n\n    print('List setting values: {}'.format(SETTING_EXAMPLE_LIST))\n    print('String setting value: {}'.format(SETTING_EXAMPLE_STRING))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef otsu(fpath):\n    img = imread(fpath, as_grey=True)\n    thresh = skimage.filter.threshold_otsu(img)\n\n    return thresh", "response": "Returns value of otsu threshold for an image\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmoves the file to the specified name", "response": "def move_to(name):\n    \"\"\"\n    Path to image folders\n    \"\"\"\n    datapath = path.join(path.dirname(path.realpath(__file__)), path.pardir)\n    datapath = path.join(datapath, '../gzoo_data', 'images', name)\n    print path.normpath(datapath)\n    return path.normpath(datapath)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the path to the train_solution. csv file", "response": "def labels():\n    \"\"\"\n    Path to labels file\n    \"\"\"\n    datapath = path.join(path.dirname(path.realpath(__file__)), path.pardir)\n    datapath = path.join(datapath, '../gzoo_data', 'train_solution.csv')\n    return path.normpath(datapath)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract important features and writes them in usable form Deletes features of little importance :param DataFrame: This is the file name of a csv file we wish to convert into a usable DataFrame. :param train: This is training set corresponding to our csv file. Should be of type pandas.DataFrame :returns: Returns csv file, after having been modified as a pandas.DataFrame type", "response": "def Feature_Engineering(DataFrame,train):\n    \"\"\"\n    Extracts important features and writes them in usable form\n    Deletes features of little importance\n    \n    :param DataFrame: This is the file name of a csv file we wish to convert into a usable DataFrame.\n    :param train: This is training set corresponding to our csv file. Should be of type pandas.DataFrame\n    :returns: Returns csv file, after having been modified as a pandas.DataFrame type\n    \"\"\"\n    \n    \n    DataFrame= pd.read_csv(DataFrame)\n    titles=DataFrame['Name'].apply(lambda x: x.split(',')[1].split(' ')[1])\n    title_mapping = {\"the\":5, \"Mr.\": 1, \"Miss.\": 2, \"Mrs.\": 3, \"Master.\": 4, \"Dr.\": 5, \"Rev.\": 6, \"Major.\": 7, \"Col.\": 7, \"Mlle.\": 2, \"Mme.\": 3, \"Don.\": 9, \"Lady.\": 10, \"Countess.\": 10, \"Jonkheer.\": 10, \"Sir.\": 9, \"Capt.\": 7, \"Ms.\": 2, \"Dona.\": 10}\n    for k,v in title_mapping.items():\n        titles[titles == k] = v\n    DataFrame[\"Title\"] = titles\n\n    DataFrame['NameLen']=DataFrame['Name'].apply(lambda x: len(x))\n    DataFrame['FamSize']=DataFrame['SibSp']+DataFrame['Parch']\n    DataFrame['Has_Cabin'] = DataFrame[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n    cabins=DataFrame['Cabin'].apply(lambda x:   str(x)[0])\n    cabin_mapping={'A':3,'B':5,'C':5,'D':4,'E':4,'F':3,'G':2,'T':1,'n':10}\n    for k,v in cabin_mapping.items():\n        cabins[cabins==k]=v\n    DataFrame['Cabin']=cabins  \n    del DataFrame['Parch']\n    del DataFrame['SibSp']\n    del DataFrame['PassengerId']\n\n    pclass = pd.get_dummies( DataFrame.Pclass , prefix='Pclass' )\n    sex = pd.get_dummies(DataFrame.Sex)\n    embarked = pd.get_dummies(DataFrame.Embarked, prefix='Embarked')\n    DataFrame=pd.concat([DataFrame,pclass,sex,embarked],axis=1)\n    del DataFrame['Pclass']\n    del DataFrame['Name']\n    del DataFrame['Ticket']\n    del DataFrame['Sex']\n    del DataFrame['Embarked']\n    \n    DataFrame['Fare'].fillna(train['Fare'].median(), inplace = True)\n        # Mapping Fare\n    DataFrame.loc[ DataFrame['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n    DataFrame.loc[(DataFrame['Fare'] > 7.91) & (DataFrame['Fare'] <= 14.454), 'Fare'] = 1\n    DataFrame.loc[(DataFrame['Fare'] > 14.454) & (DataFrame['Fare'] <= 31), 'Fare']   = 2\n    DataFrame.loc[ DataFrame['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n    DataFrame['Fare'] = DataFrame['Fare'].astype(int)\n    DataFrame['Age'].fillna(train['Age'].median(), inplace = True)\n\n    return DataFrame"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a Random Forest from a CSV file.", "response": "def Create_Random_Forest(train):\n    \"\"\"\n    Fits Random Forest to training set.\n    \n    :param train: This is the file name of a csv file we wish to have fitted to a Random Forest, does not need to have features already extracted.\n    :returns: Returns sklearn.ensemble.Random_Forest_Classifier fitted to training set.\n    \"\"\"\n    trainDF=pd.read_csv(train)\n    train=Feature_Engineering(train,trainDF)\n    RF = RFC(min_samples_split=10, n_estimators= 700, criterion= 'gini', max_depth=None)\n    RF.fit(train.iloc[:, 1:], train.iloc[:, 0])\n    return RF"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate predictions for a single test set.", "response": "def Produce_Predictions(FileName,train,test):\n    \"\"\"\n    Produces predictions for testing set, based off of training set.\n    \n    :param FileName: This is the csv file name we wish to have our predictions exported to.\n    :param train: This is the file name of a csv file that will be the training set.\n    :param test: This is the file name of the testing set that predictions will be made for.\n    :returns: Returns nothing, creates csv file containing predictions for testing set.\n    \"\"\"\n    TestFileName=test\n    TrainFileName=train\n    trainDF=pd.read_csv(train)\n    train=Feature_Engineering(train,trainDF)\n    test=Feature_Engineering(test,trainDF)\n    MLA=Create_Random_Forest(TrainFileName)\n    predictions = MLA.predict(test)\n    predictions = pd.DataFrame(predictions, columns=['Survived'])\n    test = pd.read_csv(TestFileName)\n    predictions = pd.concat((test.iloc[:, 0], predictions), axis = 1)\n    predictions.to_csv(FileName, sep=\",\", index = False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def memberships(client: Client, search: str) -> dict:\n    return await client.get(MODULE + '/memberships/%s' % search, schema=MEMBERSHIPS_SCHEMA)", "response": "Get list of Membership documents for UID / Public key"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npost a Membership document", "response": "async def membership(client: Client, membership_signed_raw: str) -> ClientResponse:\n    \"\"\"\n    POST a Membership document\n\n    :param client: Client to connect to the api\n    :param membership_signed_raw: Membership signed raw document\n    :return:\n    \"\"\"\n    return await client.post(MODULE + '/membership', {'membership': membership_signed_raw}, rtype=RESPONSE_AIOHTTP)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def block(client: Client, number: int = 0, block_raw: str = None, signature: str = None) -> Union[dict,\n                                                                                                        ClientResponse]:\n    \"\"\"\n    GET/POST a block from/to the blockchain\n\n    :param client: Client to connect to the api\n    :param number: Block number to get\n    :param block_raw: Block document to post\n    :param signature: Signature of the block document issuer\n    :return:\n    \"\"\"\n    # POST block\n    if block_raw is not None and signature is not None:\n        return await client.post(MODULE + '/block', {'block': block_raw, 'signature': signature},\n                                 rtype=RESPONSE_AIOHTTP)\n    # GET block\n    return await client.get(MODULE + '/block/%d' % number, schema=BLOCK_SCHEMA)", "response": "Get a block from the blockchain"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def blocks(client: Client, count: int, start: int) -> list:\n    assert type(count) is int\n    assert type(start) is int\n\n    return await client.get(MODULE + '/blocks/%d/%d' % (count, start), schema=BLOCKS_SCHEMA)", "response": "Get a list of blocks from the blockchain"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def hardship(client: Client, pubkey: str) -> dict:\n    return await client.get(MODULE + '/hardship/%s' % pubkey, schema=HARDSHIP_SCHEMA)", "response": "Get hardship level for given member s public key for writing next block\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting value to BlockUID instance", "response": "def block_uid(value: Union[str, BlockUID, None]) -> BlockUID:\n    \"\"\"\n    Convert value to BlockUID instance\n\n    :param value: Value to convert\n    :return:\n    \"\"\"\n    if isinstance(value, BlockUID):\n        return value\n    elif isinstance(value, str):\n        return BlockUID.from_str(value)\n    elif value is None:\n        return BlockUID.empty()\n    else:\n        raise TypeError(\"Cannot convert {0} to BlockUID\".format(type(value)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new instance of the class from the block id.", "response": "def from_str(cls: Type[BlockUIDType], blockid: str) -> BlockUIDType:\n        \"\"\"\n        :param blockid: The block id\n        \"\"\"\n        data = BlockUID.re_block_uid.match(blockid)\n        if data is None:\n            raise MalformedDocumentError(\"BlockUID\")\n        try:\n            number = int(data.group(1))\n        except AttributeError:\n            raise MalformedDocumentError(\"BlockUID\")\n\n        try:\n            sha_hash = data.group(2)\n        except AttributeError:\n            raise MalformedDocumentError(\"BlockHash\")\n\n        return cls(number, sha_hash)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_heartbeat(port, path, peer_uid, node_uid, app_id):\n    # Type and port...\n    packet = struct.pack(\"<BBH\", PACKET_FORMAT_VERSION, PACKET_TYPE_HEARTBEAT, port)\n    for string in (path, peer_uid, node_uid, app_id):\n        # Strings...\n        string_bytes = to_bytes(string)\n        packet += struct.pack(\"<H\", len(string_bytes))\n        packet += string_bytes\n\n    return packet", "response": "Builds a heartbeat packet."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_lastbeat(peer_uid, app_id):\n    packet = struct.pack(\"<BB\", PACKET_FORMAT_VERSION, PACKET_TYPE_LASTBEAT)\n    for string in (peer_uid, app_id):\n        string_bytes = to_bytes(string)\n        packet += struct.pack(\"<H\", len(string_bytes))\n        packet += string_bytes\n\n    return packet", "response": "Builds the last beat packet."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart listening to the socket", "response": "def start(self):\n        \"\"\"\n        Starts listening to the socket\n\n        :return: True if the socket has been created\n        \"\"\"\n        # Create the multicast socket (update the group)\n        self._socket, self._group = create_multicast_socket(self._group,\n                                                            self._port)\n\n        # Start the listening thread\n        self._stop_event.clear()\n        self._thread = threading.Thread(\n            target=self.__read,\n            name=\"MulticastReceiver-{0}\".format(self._port))\n        self._thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stop(self):\n        # Stop the loop\n        self._stop_event.set()\n\n        # Join the thread\n        self._thread.join()\n        self._thread = None\n\n        # Close the socket\n        close_multicast_socket(self._socket, self._group)", "response": "Stops listening to the socket\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _handle_heartbeat(self, sender, data):\n        # Format of packet\n        parsed, data = self._unpack(\"<B\", data)\n        format = parsed[0]\n        if format == PACKET_FORMAT_VERSION:\n            # Kind of beat\n            parsed, data = self._unpack(\"<B\", data)\n            kind = parsed[0]\n            if kind == PACKET_TYPE_HEARTBEAT:\n                # Extract content\n                parsed, data = self._unpack(\"<H\", data)\n                port = parsed[0]\n                path, data = self._unpack_string(data)\n                uid, data = self._unpack_string(data)\n                node_uid, data = self._unpack_string(data)\n                try:\n                    app_id, data = self._unpack_string(data)\n                except struct.error:\n                    # Compatibility with previous version\n                    app_id = herald.DEFAULT_APPLICATION_ID\n\n            elif kind == PACKET_TYPE_LASTBEAT:\n                # Peer is going away\n                uid, data = self._unpack_string(data)\n                app_id, data = self._unpack_string(data)\n                port = -1\n                path = None\n                node_uid = None\n\n            else:\n                _logger.warning(\"Unknown kind of packet: %d\", kind)\n                return\n\n            try:\n                self._callback(kind, uid, node_uid, app_id, sender[0], port, path)\n            except Exception as ex:\n                _logger.exception(\"Error handling heart beat: %s\", ex)", "response": "Handle a raw heart beat packet."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _unpack(self, fmt, data):\n        size = struct.calcsize(fmt)\n        read, unread = data[:size], data[size:]\n        return struct.unpack(fmt, read), unread", "response": "Calls struct.unpack().\n\n        Returns a tuple containing the result tuple and the subset of data\n        containing the unread content.\n\n        :param fmt: The format of data\n        :param data: Data to unpack\n        :return: A tuple (result tuple, unread_data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nunpack the next string from the given data", "response": "def _unpack_string(self, data):\n        \"\"\"\n        Unpacks the next string from the given data\n\n        :param data: A datagram, starting at a string size\n        :return: A (string, unread_data) tuple\n        \"\"\"\n        # Get the size of the string\n        result, data = self._unpack(\"<H\", data)\n        size = result[0]\n\n        # Read it\n        string_bytes = data[:size]\n\n        # Convert it\n        return to_unicode(string_bytes), data[size:]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread packets from the socket and handles them.", "response": "def __read(self):\n        \"\"\"\n        Reads packets from the socket\n        \"\"\"\n        # Set the socket as non-blocking\n        self._socket.setblocking(0)\n\n        while not self._stop_event.is_set():\n            # Watch for content\n            ready = select.select([self._socket], [], [], 1)\n            if ready[0]:\n                # Socket is ready\n                data, sender = self._socket.recvfrom(1024)\n                try:\n                    self._handle_heartbeat(sender, data)\n                except Exception as ex:\n                    _logger.exception(\"Error handling the heart beat: %s\", ex)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_log_config(component, handlers, level='DEBUG', path='/var/log/vfine/'):\n    config = {\n        'version': 1,\n        'disable_existing_loggers': False,\n        'formatters': {\n            'standard': {\n                'format': '%(asctime)s [%(levelname)s][%(threadName)s]' +\n                          '[%(name)s.%(funcName)s():%(lineno)d] %(message)s'\n            },\n            'color': {\n                '()': 'shaw.log.SplitColoredFormatter',\n                'format': \"%(asctime)s \" +\n                          \"%(log_color)s%(bold)s[%(levelname)s]%(reset)s\" +\n                          \"[%(threadName)s][%(name)s.%(funcName)s():%(lineno)d] \" +\n                          \"%(blue)s%(message)s\"\n            }\n        },\n        'handlers': {\n            'debug': {\n                'level': 'DEBUG',\n                'class': 'logging.handlers.RotatingFileHandler',\n                'filename': path + component + '.debug.log',\n                'maxBytes': 1024 * 1024 * 1024,\n                'backupCount': 5,\n                'formatter': 'standard',\n            },\n            'color': {\n                'level': 'DEBUG',\n                'class': 'logging.handlers.RotatingFileHandler',\n                'filename': path + component + '.color.log',\n                'maxBytes': 1024 * 1024 * 1024,\n                'backupCount': 5,\n                'formatter': 'color',\n            },\n            'info': {\n                'level': 'INFO',\n                'class': 'logging.handlers.RotatingFileHandler',\n                'filename': path + component + '.info.log',\n                'maxBytes': 1024 * 1024 * 1024,\n                'backupCount': 5,\n                'formatter': 'standard',\n            },\n            'error': {\n                'level': 'ERROR',\n                'class': 'logging.handlers.RotatingFileHandler',\n                'filename': path + component + '.error.log',\n                'maxBytes': 1024 * 1024 * 100,\n                'backupCount': 5,\n                'formatter': 'standard',\n            },\n            'console': {\n                'level': level,\n                'class': 'logging.StreamHandler',\n                'formatter': 'standard'\n            },\n        },\n        'loggers': {\n            'django': {\n                'handlers': handlers,\n                'level': 'INFO',\n                'propagate': False\n            },\n            'django.request': {\n                'handlers': handlers,\n                'level': 'INFO',\n                'propagate': False,\n            },\n            '': {\n                'handlers': handlers,\n                'level': level,\n                'propagate': False\n            },\n        }\n    }\n    return config", "response": "Return a log config for django project."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef doRollover(self):\n        # if self.stream:\n        #    self.stream.close()\n        # get the time that this sequence started at and make it a TimeTuple\n        t = self.rolloverAt - self.interval\n        if self.utc:\n            timeTuple = time.gmtime(t)\n        else:\n            timeTuple = time.localtime(t)\n        dfn = self.baseFilename + \".\" + time.strftime(self.suffix, timeTuple)\n        # if os.path.exists(dfn):\n        #    os.remove(dfn)\n        lockdata = struct.pack('hhllhh', fcntl.F_WRLCK, 0, 0, 0, 0, 0)\n        fcntl.fcntl(self.stream, fcntl.F_SETLKW, lockdata)\n        if not os.path.exists(dfn) and os.path.exists(self.baseFilename):\n            os.rename(self.baseFilename, dfn)\n            with open(self.baseFilename, 'a'):\n                pass\n        if self.backupCount > 0:\n            # find the oldest log file and delete it\n            # s = glob.glob(self.baseFilename + \".20*\")\n            # if len(s) > self.backupCount:\n            #    s.sort()\n            #    os.remove(s[0])\n            for s in self.getFilesToDelete():\n                os.remove(s)\n        # print \"%s -> %s\" % (self.baseFilename, dfn)\n        if self.stream:\n            self.stream.close()\n        self.mode = 'a'\n        self.stream = self._open()\n        currentTime = int(time.time())\n        newRolloverAt = self.computeRollover(currentTime)\n        while newRolloverAt <= currentTime:\n            newRolloverAt = newRolloverAt + self.interval\n        # If DST changes and midnight or weekly rollover, adjust for this.\n        if (self.when == 'MIDNIGHT' or self.when.startswith('W')) and not self.utc:\n            dstNow = time.localtime(currentTime)[-1]\n            dstAtRollover = time.localtime(newRolloverAt)[-1]\n            if dstNow != dstAtRollover:\n                if not dstNow:  # DST kicks in before next rollover, so we need to deduct an hour\n                    newRolloverAt = newRolloverAt - 3600\n                else:  # DST bows out before next rollover, so we need to add an hour\n                    newRolloverAt = newRolloverAt + 3600\n        self.rolloverAt = newRolloverAt", "response": "This method is called when the rollover is happening. It is called when the interval is reached."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef format(self, record):\n        record = ColoredRecord(record)\n        record.log_color = self.color(self.log_colors, record.levelname)\n\n        # Set secondary log colors\n        if self.secondary_log_colors:\n            for name, log_colors in self.secondary_log_colors.items():\n                color = self.color(log_colors, record.levelname)\n                setattr(record, name + '_log_color', color)\n\n        # Format the message\n        if sys.version_info > (2, 7):\n            message = super(ColoredFormatter, self).format(record)\n        else:\n            message = logging.Formatter.format(self, record)\n\n        # Add a reset code to the end of the message\n        # (if it wasn't explicitly added in format str)\n        if self.reset and not message.endswith(escape_codes['reset']):\n            message += escape_codes['reset']\n\n        if '|' in message:\n            desc, data = message.split(\"|\", 1)\n            desc = desc + escape_codes['reset']\n            data = escape_codes['green'] + data\n            message = desc + '|' + data\n\n        return message", "response": "Format a message from a record object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_console_logger():\n    global __console_logger\n    if __console_logger:\n        return __console_logger\n\n    logger = logging.getLogger(\"kkconst\")\n    logger.setLevel(logging.DEBUG)\n\n    ch = logging.StreamHandler(sys.stdout)\n    ch.setLevel(logging.DEBUG)\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    ch.setFormatter(formatter)\n    logger.addHandler(ch)\n\n    __console_logger = logger\n\n    return logger", "response": "just for kkconst demos"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _load_referenced_schemes_from_list(the_list, val, a_scheme, a_property):\n    scheme = copy.copy(a_scheme)\n    new_list = []\n    if isinstance(the_list, list):\n        for an_item in the_list:\n            if ((not isinstance(an_item, basestring)) and\n                    (u'$ref' in an_item.keys())):\n                sub_scheme_name = generate_schema_name_from_uri(an_item['$ref'])\n                content = load_schema(sub_scheme_name)\n                new_list.append(content)\n    else:\n        # somewhere the array is not an array - payment_reminder\n        sub_scheme_name = generate_schema_name_from_uri(the_list['$ref'])\n        new_list = load_schema(sub_scheme_name)\n    scheme['properties'][a_property]['items'] = new_list\n    return scheme", "response": "Load the referenced files and return the updated schema\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading referenced schema from a value.", "response": "def _load_referenced_schema_from_properties(val, a_scheme, a_property):\n    \"\"\"\n    :return: updated scheme\n    \"\"\"\n    scheme = copy.copy(a_scheme)\n    if _value_properties_are_referenced(val):\n        ref_schema_uri = val['properties']['$ref']\n        sub_schema = load_ref_schema(ref_schema_uri)\n        ## dereference the sub schema\n        sub_schema_copy_level_0 = copy.deepcopy(sub_schema)\n\n        # nesting level 1\n        # @TODO: NEEDS REFACTOR\n        for prop_0 in sub_schema_copy_level_0['properties']:\n            val_0 = sub_schema_copy_level_0['properties'][prop_0]\n            # arrays may contain the nesting\n            is_type_array_0 = (val_0['type'] == 'array')\n            is_type_object_0 = (val_0['type'] == 'object')\n            if ((is_type_array_0 or is_type_object_0)\n                and (_value_properties_are_referenced(val_0))):\n                # found a nested  thingy\n                sub_schema_copy_level_1 = _load_referenced_schema_from_properties(val_0, sub_schema_copy_level_0,\n                                                                                  prop_0)\n                ###\n                # one more loop level\n                ###\n                for prop_1 in sub_schema_copy_level_1['properties']:\n                    val_1 = sub_schema_copy_level_1['properties'][prop_1]\n                    is_type_array_1 = (val_1['type'] == 'array')\n                    is_type_object_1 = (val_1['type'] == 'object')\n                    if ((is_type_array_1 or is_type_object_1) and\n                            (_value_properties_are_referenced(val_1))):\n                        ### need to figure out a better way for loading\n                        # the referenced stuff\n                        # found a nested  thingy\n                        # sub_schema_copy_level_2 = _load_referenced_schema_from_properties(val_1, sub_schema_copy_level_1, prop_1)\n                        raise SalesKingException(\"too much nesting in the schemes\")\n\n            if _value_is_required(val_0):\n                # remove required\n                sub_schema_copy_level_0['properties'][prop_0]['required'] = False\n            # hack to bypass text format valitation to string\n            if _value_is_type_text(val_0):\n                log.debug(\"patched text to string\")\n                sub_schema_copy_level_0['properties'][prop_0]['type'] = u\"string\"\n\n\n        # outer scheme\n        scheme['properties'][a_property]['properties'] = sub_schema_copy_level_0['properties']\n\n    return scheme"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the given schema name from the local filesystem and puts it into a store if store_it is True", "response": "def import_schema_to_json(name, store_it=False):\n    \"\"\"\n    loads the given schema name\n    from the local filesystem\n    and puts it into a store if it\n    is not in there yet\n    :param name:\n    :param store_it: if set to True, stores the contents\n    :return:\n    \"\"\"\n\n    schema_file = u\"%s.json\" % name\n    file_path = os.path.join(SCHEMA_ROOT, schema_file)\n    log.debug(u\"trying to load %s \" % file_path)\n    schema = None\n    try:\n        schema_file = open(file_path, \"r\").read()\n    except IOError, e:\n        log.error(u\"file not found %s\" % e)\n        msg = \"Could not find schema file. %s\" % file_path\n        raise SalesKingException(\"SCHEMA_NOT_FOUND\", msg)\n    schema = json.loads(schema_file)\n\n    if schema is None:\n        msg = \"loading failed foo %s\" % name\n        raise SalesKingException(\"SCHEMA_NOT_FOUND\", msg)\n    return schema"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_schema(name):\n\n    schema = import_schema_to_json(name)\n\n    #salesking specific swap\n    #//set link relation as key name to make it easier to call these\n    for item in schema['links']:\n        #//set link relation as key name to make it easier to call these\n        #            foreach($schema->links as $key => $link)\n        #            {\n        #                $schema->links[$link->rel] = $link;\n        #                unset($schema->links[$key]);\n        #            }\n        # this here seems not to work as expected\n        # something is wrong\n        href_value = item['href']\n        rel_value = item['rel']\n        schema[rel_value] = href_value\n        del item\n\n    ## sk use nesting of schema\n    ## dynamically loading\n    for prop in schema['properties']:\n        value = schema['properties'][prop]\n        # arrays may contain the nesting\n        is_type_array = (value['type'] == 'array')\n        is_type_object = (value['type'] == 'object')\n        if ((is_type_array or is_type_object)\n            and (_value_properties_are_referenced(value))):\n            schema = _load_referenced_schema_from_properties(value, schema, prop)\n\n        if is_type_array and _value_is_default_any(value) and _value_has_items_key(value):\n            schema = _load_referenced_schemes_from_list(value['items'], value, schema, prop)\n\n        if _value_is_required(value):\n            # remove required\n            schema['properties'][prop]['required'] = False\n        \n        # hack to bypass text format valitation to string\n        if _value_is_type_text(value):\n            log.debug(\"patched text to string\")\n            schema['properties'][prop]['type'] = u\"string\"\n        \n        #ignore the readonly properties auto validation\n        #if 'readonly' in value.keys() and value['readonly'] == True:\n        #    log.debug(\"patched required validation to none required\")\n        #    schema['properties'][property]['readonly'] = False\n\n    # sk works on title and not name\n    schema['name'] = schema['title']\n    ## go one level deeper as we now have some replacements\n\n    # put it to storage when done\n    # if not JsonSchemaStore.is_stored(name) and (schema is not None):\n    #    JsonSchemaStore.copy_to_store(name, schema)\n    return schema", "response": "Loads the schema by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of plugged USB Flash drives.", "response": "def plugged_usbs(multiple=True) -> map or dict:\n    \"\"\"\n    Gets the plugged-in USB Flash drives (pen-drives).\n\n    If multiple is true, it returns a map, and a dict otherwise.\n\n    If multiple is false, this method will raise a :class:`.NoUSBFound` if no USB is found.\n    \"\"\"\n\n    class FindPenDrives(object):\n        # From https://github.com/pyusb/pyusb/blob/master/docs/tutorial.rst\n        def __init__(self, class_):\n            self._class = class_\n\n        def __call__(self, device):\n            # first, let's check the device\n            if device.bDeviceClass == self._class:\n                return True\n            # ok, transverse all devices to find an\n            # interface that matches our class\n            for cfg in device:\n                # find_descriptor: what's it?\n                intf = usb.util.find_descriptor(cfg, bInterfaceClass=self._class)\n                if intf is not None:\n                    try:\n                        product = intf.device.product.lower()\n                    except ValueError as e:\n                        if 'langid' in str(e):\n                            raise OSError('Cannot get \"langid\". Do you have permissions?')\n                        else:\n                            raise e\n                    if 'crw' not in product and 'reader' not in product:\n                        return True\n            return False\n\n    def get_pendrive(pen: usb.Device) -> dict:\n        manufacturer = pen.manufacturer.strip() or str(pen.idVendor)\n        model = pen.product.strip() or str(pen.idProduct)\n        serial_number = pen.serial_number.strip()\n        hid = Naming.hid(manufacturer, serial_number, model)\n        return {\n            '_id': hid,  # Make live easier to DeviceHubClient by using _id\n            'hid': hid,\n            '@type': 'USBFlashDrive',\n            'serialNumber': serial_number,\n            'model': model,\n            'manufacturer': manufacturer,\n            'vendorId': pen.idVendor,\n            'productId': pen.idProduct\n        }\n\n    result = usb.core.find(find_all=multiple, custom_match=FindPenDrives(CLASS_MASS_STORAGE))\n    if multiple:\n        return map(get_pendrive, result)\n    else:\n        if not result:\n            raise NoUSBFound()\n        return get_pendrive(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the reduced base of the given amount and base.", "response": "def reduce_base(amount: int, base: int) -> tuple:\n    \"\"\"\n    Compute the reduced base of the given parameters\n\n    :param amount: the amount value\n    :param base: current base value\n\n    :return: tuple containing computed (amount, base)\n    \"\"\"\n    if amount == 0:\n        return 0, 0\n\n    next_amount = amount\n    next_base = base\n    next_amount_is_integer = True\n    while next_amount_is_integer:\n        amount = next_amount\n        base = next_base\n        if next_amount % 10 == 0:\n            next_amount = int(next_amount / 10)\n            next_base += 1\n        else:\n            next_amount_is_integer = False\n\n    return int(amount), int(base)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a Transaction instance from an inline string format.", "response": "def from_inline(cls: Type[InputSourceType], tx_version: int, inline: str) -> InputSourceType:\n        \"\"\"\n        Return Transaction instance from inline string format\n\n        :param tx_version: Version number of the document\n        :param inline: Inline string format\n        :return:\n        \"\"\"\n        if tx_version == 2:\n            data = InputSource.re_inline.match(inline)\n            if data is None:\n                raise MalformedDocumentError(\"Inline input\")\n            source_offset = 0\n            amount = 0\n            base = 0\n        else:\n            data = InputSource.re_inline_v3.match(inline)\n            if data is None:\n                raise MalformedDocumentError(\"Inline input\")\n            source_offset = 2\n            amount = int(data.group(1))\n            base = int(data.group(2))\n        if data.group(1 + source_offset):\n            source = data.group(1 + source_offset)\n            origin_id = data.group(2 + source_offset)\n            index = int(data.group(3 + source_offset))\n        else:\n            source = data.group(4 + source_offset)\n            origin_id = data.group(5 + source_offset)\n            index = int(data.group(6 + source_offset))\n\n        return cls(amount, base, source, origin_id, index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an inline string format of the document Taxonomy", "response": "def inline(self, tx_version: int) -> str:\n        \"\"\"\n        Return an inline string format of the document\n\n        :param tx_version: Version number of the document\n        :return:\n        \"\"\"\n        if tx_version == 2:\n            return \"{0}:{1}:{2}\".format(self.source,\n                                        self.origin_id,\n                                        self.index)\n        else:\n            return \"{0}:{1}:{2}:{3}:{4}\".format(self.amount,\n                                                self.base,\n                                                self.source,\n                                                self.origin_id,\n                                                self.index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_inline(cls: Type[OutputSourceType], inline: str) -> OutputSourceType:\n        data = OutputSource.re_inline.match(inline)\n        if data is None:\n            raise MalformedDocumentError(\"Inline output\")\n        amount = int(data.group(1))\n        base = int(data.group(2))\n        condition_text = data.group(3)\n\n        return cls(amount, base, condition_text)", "response": "Return OutputSource instance from inline string format"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an inline string format of the document", "response": "def inline(self) -> str:\n        \"\"\"\n        Return an inline string format of the document\n\n        :return:\n        \"\"\"\n        return \"{0}:{1}:{2}\".format(self.amount, self.base,\n                                    pypeg2.compose(self.condition, output.Condition))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef condition_from_text(text) -> Condition:\n        try:\n            condition = pypeg2.parse(text, output.Condition)\n        except SyntaxError:\n            # Invalid conditions are possible, see https://github.com/duniter/duniter/issues/1156\n            # In such a case, they are store as empty PEG grammar object and considered unlockable\n            condition = Condition(text)\n        return condition", "response": "Parse a text string into a Condition instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_parameter(cls: Type[SIGParameterType], parameter: str) -> Optional[SIGParameterType]:\n        sig = SIGParameter.re_sig.match(parameter)\n        if sig:\n            return cls(int(sig.group(1)))\n\n        return None", "response": "Return a SIGParameter instance from an index parameter"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_parameter(cls: Type[XHXParameterType], parameter: str) -> Optional[XHXParameterType]:\n        xhx = XHXParameter.re_xhx.match(parameter)\n        if xhx:\n            return cls(int(xhx.group(1)))\n\n        return None", "response": "Return an XHXParameter instance from an index parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_parameter(cls: Type[UnlockParameterType], parameter: str) -> Optional[Union[SIGParameter, XHXParameter]]:\n\n        sig_param = SIGParameter.from_parameter(parameter)\n        if sig_param:\n            return sig_param\n        else:\n            xhx_param = XHXParameter.from_parameter(parameter)\n            if xhx_param:\n                return xhx_param\n\n        return None", "response": "Return UnlockParameter instance from parameter string"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an Unlock instance from an inline string format", "response": "def from_inline(cls: Type[UnlockType], inline: str) -> UnlockType:\n        \"\"\"\n        Return an Unlock instance from inline string format\n\n        :param inline: Inline string format\n\n        :return:\n        \"\"\"\n        data = Unlock.re_inline.match(inline)\n        if data is None:\n            raise MalformedDocumentError(\"Inline input\")\n        index = int(data.group(1))\n        parameters_str = data.group(2).split(' ')\n        parameters = []\n        for p in parameters_str:\n            param = UnlockParameter.from_parameter(p)\n            if param:\n                parameters.append(param)\n        return cls(index, parameters)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning inline string format of the instance", "response": "def inline(self) -> str:\n        \"\"\"\n        Return inline string format of the instance\n\n        :return:\n        \"\"\"\n        return \"{0}:{1}\".format(self.index, ' '.join([str(p) for p in self.parameters]))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_bma_history(cls: Type[TransactionType], currency: str, tx_data: Dict) -> TransactionType:\n        tx_data = tx_data.copy()\n        tx_data[\"currency\"] = currency\n        for data_list in ('issuers', 'outputs', 'inputs', 'unlocks', 'signatures'):\n            tx_data['multiline_{0}'.format(data_list)] = '\\n'.join(tx_data[data_list])\n        if tx_data[\"version\"] >= 3:\n            signed_raw = \"\"\"Version: {version}\nType: Transaction\nCurrency: {currency}\nBlockstamp: {blockstamp}\nLocktime: {locktime}\nIssuers:\n{multiline_issuers}\nInputs:\n{multiline_inputs}\nUnlocks:\n{multiline_unlocks}\nOutputs:\n{multiline_outputs}\nComment: {comment}\n{multiline_signatures}\n\"\"\".format(**tx_data)\n        else:\n            signed_raw = \"\"\"Version: {version}\nType: Transaction\nCurrency: {currency}\nLocktime: {locktime}\nIssuers:\n{multiline_issuers}\nInputs:\n{multiline_inputs}\nUnlocks:\n{multiline_unlocks}\nOutputs:\n{multiline_outputs}\nComment: {comment}\n{multiline_signatures}\n\"\"\".format(**tx_data)\n        return cls.from_signed_raw(signed_raw)", "response": "Get the transaction instance from a json transaction"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new Transaction instance from a compact format string", "response": "def from_compact(cls: Type[TransactionType], currency: str, compact: str) -> TransactionType:\n        \"\"\"\n        Return Transaction instance from compact string format\n\n        :param currency: Name of the currency\n        :param compact: Compact format string\n        :return:\n        \"\"\"\n        lines = compact.splitlines(True)\n        n = 0\n\n        header_data = Transaction.re_header.match(lines[n])\n        if header_data is None:\n            raise MalformedDocumentError(\"Compact TX header\")\n        version = int(header_data.group(1))\n        issuers_num = int(header_data.group(2))\n        inputs_num = int(header_data.group(3))\n        unlocks_num = int(header_data.group(4))\n        outputs_num = int(header_data.group(5))\n        has_comment = int(header_data.group(6))\n        locktime = int(header_data.group(7))\n        n += 1\n\n        blockstamp = None  # type: Optional[BlockUID]\n        if version >= 3:\n            blockstamp = BlockUID.from_str(Transaction.parse_field(\"CompactBlockstamp\", lines[n]))\n            n += 1\n\n        issuers = []\n        inputs = []\n        unlocks = []\n        outputs = []\n        signatures = []\n        for i in range(0, issuers_num):\n            issuer = Transaction.parse_field(\"Pubkey\", lines[n])\n            issuers.append(issuer)\n            n += 1\n\n        for i in range(0, inputs_num):\n            input_source = InputSource.from_inline(version, lines[n])\n            inputs.append(input_source)\n            n += 1\n\n        for i in range(0, unlocks_num):\n            unlock = Unlock.from_inline(lines[n])\n            unlocks.append(unlock)\n            n += 1\n\n        for i in range(0, outputs_num):\n            output_source = OutputSource.from_inline(lines[n])\n            outputs.append(output_source)\n            n += 1\n\n        comment = \"\"\n        if has_comment == 1:\n            data = Transaction.re_compact_comment.match(lines[n])\n            if data:\n                comment = data.group(1)\n                n += 1\n            else:\n                raise MalformedDocumentError(\"Compact TX Comment\")\n\n        while n < len(lines):\n            data = Transaction.re_signature.match(lines[n])\n            if data:\n                signatures.append(data.group(1))\n                n += 1\n            else:\n                raise MalformedDocumentError(\"Compact TX Signatures\")\n\n        return cls(version, currency, blockstamp, locktime, issuers, inputs, unlocks, outputs, comment, signatures)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a Transaction instance from a raw string format", "response": "def from_signed_raw(cls: Type[TransactionType], raw: str) -> TransactionType:\n        \"\"\"\n        Return a Transaction instance from a raw string format\n\n        :param raw: Raw string format\n\n        :return:\n        \"\"\"\n        lines = raw.splitlines(True)\n        n = 0\n\n        version = int(Transaction.parse_field(\"Version\", lines[n]))\n        n += 1\n\n        Transaction.parse_field(\"Type\", lines[n])\n        n += 1\n\n        currency = Transaction.parse_field(\"Currency\", lines[n])\n        n += 1\n\n        blockstamp = None  # type: Optional[BlockUID]\n        if version >= 3:\n            blockstamp = BlockUID.from_str(Transaction.parse_field(\"Blockstamp\", lines[n]))\n            n += 1\n\n        locktime = Transaction.parse_field(\"Locktime\", lines[n])\n        n += 1\n\n        issuers = []\n        inputs = []\n        unlocks = []\n        outputs = []\n        signatures = []\n\n        if Transaction.re_issuers.match(lines[n]):\n            n += 1\n            while Transaction.re_inputs.match(lines[n]) is None:\n                issuer = Transaction.parse_field(\"Pubkey\", lines[n])\n                issuers.append(issuer)\n                n += 1\n\n        if Transaction.re_inputs.match(lines[n]):\n            n += 1\n            while Transaction.re_unlocks.match(lines[n]) is None:\n                input_source = InputSource.from_inline(version, lines[n])\n                inputs.append(input_source)\n                n += 1\n\n        if Transaction.re_unlocks.match(lines[n]):\n            n += 1\n            while Transaction.re_outputs.match(lines[n]) is None:\n                unlock = Unlock.from_inline(lines[n])\n                unlocks.append(unlock)\n                n += 1\n\n        if Transaction.re_outputs.match(lines[n]) is not None:\n            n += 1\n            while not Transaction.re_comment.match(lines[n]):\n                _output = OutputSource.from_inline(lines[n])\n                outputs.append(_output)\n                n += 1\n\n        comment = Transaction.parse_field(\"Comment\", lines[n])\n        n += 1\n\n        if Transaction.re_signature.match(lines[n]) is not None:\n            while n < len(lines):\n                sign = Transaction.parse_field(\"Signature\", lines[n])\n                signatures.append(sign)\n                n += 1\n\n        return cls(version, currency, blockstamp, locktime, issuers, inputs, unlocks, outputs,\n                   comment, signatures)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef raw(self) -> str:\n        doc = \"\"\"Version: {0}\nType: Transaction\nCurrency: {1}\n\"\"\".format(self.version,\n           self.currency)\n\n        if self.version >= 3:\n            doc += \"Blockstamp: {0}\\n\".format(self.blockstamp)\n\n        doc += \"Locktime: {0}\\n\".format(self.locktime)\n\n        doc += \"Issuers:\\n\"\n        for p in self.issuers:\n            doc += \"{0}\\n\".format(p)\n\n        doc += \"Inputs:\\n\"\n        for i in self.inputs:\n            doc += \"{0}\\n\".format(i.inline(self.version))\n\n        doc += \"Unlocks:\\n\"\n        for u in self.unlocks:\n            doc += \"{0}\\n\".format(u.inline())\n\n        doc += \"Outputs:\\n\"\n        for o in self.outputs:\n            doc += \"{0}\\n\".format(o.inline())\n\n        doc += \"Comment: \"\n        doc += \"{0}\\n\".format(self.comment)\n\n        return doc", "response": "Return a string representation of the instance"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compact(self) -> str:\n        \"\"\"TX:VERSION:NB_ISSUERS:NB_INPUTS:NB_UNLOCKS:NB_OUTPUTS:HAS_COMMENT:LOCKTIME\nPUBLIC_KEY:INDEX\n...\nINDEX:SOURCE:FINGERPRINT:AMOUNT\n...\nPUBLIC_KEY:AMOUNT\n...\nCOMMENT\n\"\"\"\n        doc = \"TX:{0}:{1}:{2}:{3}:{4}:{5}:{6}\\n\".format(self.version,\n                                                        len(self.issuers),\n                                                        len(self.inputs),\n                                                        len(self.unlocks),\n                                                        len(self.outputs),\n                                                        '1' if self.comment != \"\" else '0',\n                                                        self.locktime)\n        if self.version >= 3:\n            doc += \"{0}\\n\".format(self.blockstamp)\n\n        for pubkey in self.issuers:\n            doc += \"{0}\\n\".format(pubkey)\n        for i in self.inputs:\n            doc += \"{0}\\n\".format(i.inline(self.version))\n        for u in self.unlocks:\n            doc += \"{0}\\n\".format(u.inline())\n        for o in self.outputs:\n            doc += \"{0}\\n\".format(o.inline())\n        if self.comment != \"\":\n            doc += \"{0}\\n\".format(self.comment)\n        for s in self.signatures:\n            doc += \"{0}\\n\".format(s)\n\n        return doc", "response": "Return a compact format from the instance"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfilter a transaction and checks if it is a simple one", "response": "def is_simple(tx: Transaction) -> bool:\n        \"\"\"\n        Filter a transaction and checks if it is a basic one\n        A simple transaction is a tx which has only one issuer\n        and two outputs maximum. The unlocks must be done with\n        simple \"SIG\" functions, and the outputs must be simple\n        SIG conditions.\n\n        :param tx: the transaction to check\n\n        :return: True if a simple transaction\n        \"\"\"\n        simple = True\n        if len(tx.issuers) != 1:\n            simple = False\n        for unlock in tx.unlocks:\n            if len(unlock.parameters) != 1:\n                simple = False\n            elif type(unlock.parameters[0]) is not SIGParameter:\n                simple = False\n        for o in tx.outputs:\n            # if right condition is not None...\n            if getattr(o.condition, 'right', None):\n                simple = False\n                # if left is not SIG...\n            elif type(o.condition.left) is not output.SIG:\n                simple = False\n\n        return simple"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef retry(self, retries, task_f, check_f=bool, wait_f=None):\n        for attempt in range(retries):\n            ret = task_f()\n            if check_f(ret):\n                return ret\n            if attempt < retries - 1 and wait_f is not None:\n                wait_f(attempt)\n        raise RetryException(\"Giving up after {} failed attempt(s)\".format(retries))", "response": "Try a function up to n times."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns a command and raise an exception if the command fails.", "response": "def check_assert(self, cmd, retries=1, pollrate=60, on_retry=None):\n        \"\"\"\n        Run a command, logging (using gather) and raise an exception if the\n        return code of the command indicates failure.\n        Try the command multiple times if requested.\n\n        :param cmd <string|list>: A shell command\n        :param retries int: The number of times to try before declaring failure\n        :param pollrate int: how long to sleep between tries\n        :param on_retry <string|list>: A shell command to run before retrying a failure\n        :return: (stdout,stderr) if exit code is zero\n        \"\"\"\n\n        for try_num in range(0, retries):\n            if try_num > 0:\n                self.logger.debug(\n                    \"assert: Failed {} times. Retrying in {} seconds: {}\".\n                    format(try_num, pollrate, cmd))\n                time.sleep(pollrate)\n                if on_retry is not None:\n                    self.gather(on_retry)  # no real use for the result though\n\n            result, stdout, stderr = self.gather(cmd)\n            if result == SUCCESS:\n                break\n\n        self.logger.debug(\"assert: Final result = {} in {} tries.\".format(result, try_num))\n\n        assertion.success(\n            result,\n            \"Error running [{}] {}.\\n{}\".\n            format(pushd.Dir.getcwd(), cmd, stderr))\n\n        return stdout, stderr"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gather(self, cmd):\n\n        if not isinstance(cmd, list):\n            cmd_list = shlex.split(cmd)\n        else:\n            cmd_list = cmd\n\n        cwd = pushd.Dir.getcwd()\n        cmd_info = '[cwd={}]: {}'.format(cwd, cmd_list)\n\n        self.logger.debug(\"Executing:gather {}\".format(cmd_info))\n        proc = subprocess.Popen(\n            cmd_list, cwd=cwd,\n            stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        out, err = proc.communicate()\n        rc = proc.returncode\n        self.logger.debug(\n            \"Process {}: exited with: {}\\nstdout>>{}<<\\nstderr>>{}<<\\n\".\n            format(cmd_info, rc, out, err))\n        return rc, out, err", "response": "Executes a command and returns the return code stdout and stderr as a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef json_serial(obj):\n\n        if isinstance(obj, (datetime.datetime, datetime.date)):\n            return obj.isoformat()\n\n        raise TypeError('Type {} not serializable.'.format(type(obj)))", "response": "Custom JSON serializer for objects not serializable by default."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint next version of Gitversion run then exits", "response": "def next_version(ctx: click.Context, _, value):\n    \"\"\"\n    Prints next version (according to Gitversion run) then exits\n    \"\"\"\n\n    if not value or ctx.resilient_parsing:\n        return\n\n    config.QUIET.default = True\n\n    CTX.repo = epab.utils.Repo()\n\n    print(epab.utils.get_next_version())\n    sys.exit(0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntrains a neural nerual net to predict the weather for tomorrow based on past weather.", "response": "def train_weather_predictor(\n        location='Portland, OR',\n        years=range(2013, 2016,),\n        delays=(1, 2, 3),\n        inputs=('Min Temperature', 'Max Temperature', 'Min Sea Level Pressure', u'Max Sea Level Pressure', 'WindDirDegrees',),\n        outputs=(u'Max TemperatureF',),\n        N_hidden=6,\n        epochs=30,\n        use_cache=False,\n        verbosity=2,\n        ):\n    \"\"\"Train a neural nerual net to predict the weather for tomorrow based on past weather.\n\n    Builds a linear single hidden layer neural net (multi-dimensional nonlinear regression).\n    The dataset is a basic SupervisedDataSet rather than a SequentialDataSet, so the training set\n    and the test set are sampled randomly. This means that historical data for one sample (the delayed\n    input vector) will likely be used as the target for other samples.\n\n    Uses CSVs scraped from wunderground (without an api key) to get daily weather for the years indicated.\n\n    Arguments:\n      location (str): City and state in standard US postal service format: \"City, ST\"\n          alternatively an airport code like \"PDX or LAX\"\n      delays (list of int): sample delays to use for the input tapped delay line.\n          Positive and negative values are treated the same as sample counts into the past.\n          default: [1, 2, 3], in z-transform notation: z^-1 + z^-2 + z^-3\n      years (int or list of int): list of 4-digit years to download weather from wunderground\n      inputs (list of int or list of str): column indices or labels for the inputs\n      outputs (list of int or list of str): column indices or labels for the outputs\n\n    Returns:\n      3-tuple: tuple(dataset, list of means, list of stds)\n          means and stds allow normalization of new inputs and denormalization of the outputs\n\n    \"\"\"\n    df = weather.daily(location, years=years, use_cache=use_cache, verbosity=verbosity).sort()\n    ds = util.dataset_from_dataframe(df, normalize=False, delays=delays, inputs=inputs, outputs=outputs, verbosity=verbosity)\n    nn = util.ann_from_ds(ds, N_hidden=N_hidden, verbosity=verbosity)\n    trainer = util.build_trainer(nn, ds=ds, verbosity=verbosity)\n    trainer.trainEpochs(epochs)\n\n    columns = []\n    for delay in delays:\n        columns += [inp + \"[-{}]\".format(delay) for inp in inputs]\n    columns += list(outputs)\n\n    columns += ['Predicted {}'.format(outp) for outp in outputs]\n    table = [list(i) + list(t) + list(trainer.module.activate(i)) for i, t in zip(trainer.ds['input'], trainer.ds['target'])]\n    df = pd.DataFrame(table, columns=columns, index=df.index[max(delays):])\n\n    #comparison = df[[] + list(outputs)]\n    return trainer, df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary that provides a forecast for tomorrow based on historical weather at that location.", "response": "def oneday_weather_forecast(\n        location='Portland, OR',\n        inputs=('Min Temperature', 'Mean Temperature', 'Max Temperature', 'Max Humidity', 'Mean Humidity', 'Min Humidity', 'Max Sea Level Pressure', 'Mean Sea Level Pressure', 'Min Sea Level Pressure', 'Wind Direction'),\n        outputs=('Min Temperature', 'Mean Temperature', 'Max Temperature', 'Max Humidity'),\n        date=None,\n        epochs=200,\n        delays=(1, 2, 3, 4),\n        num_years=4,\n        use_cache=False,\n        verbosity=1,\n        ):\n    \"\"\" Provide a weather forecast for tomorrow based on historical weather at that location \"\"\"\n    date = make_date(date or datetime.datetime.now().date())\n    num_years = int(num_years or 10)\n    years = range(date.year - num_years, date.year + 1)\n    df = weather.daily(location, years=years, use_cache=use_cache, verbosity=verbosity).sort()\n    # because up-to-date weather history was cached above, can use that cache, regardless of use_cache kwarg\n    trainer, df = train_weather_predictor(\n        location,\n        years=years,\n        delays=delays,\n        inputs=inputs,\n        outputs=outputs,\n        epochs=epochs,\n        verbosity=verbosity,\n        use_cache=True,\n        )\n    nn = trainer.module\n    forecast = {'trainer': trainer}\n\n    yesterday = dict(zip(outputs, nn.activate(trainer.ds['input'][-2])))\n    forecast['yesterday'] = update_dict(yesterday, {'date': df.index[-2].date()})\n\n    today = dict(zip(outputs, nn.activate(trainer.ds['input'][-1])))\n    forecast['today'] = update_dict(today, {'date': df.index[-1].date()})\n\n    ds = util.input_dataset_from_dataframe(df[-max(delays):], delays=delays, inputs=inputs, normalize=False, verbosity=0)\n    tomorrow = dict(zip(outputs, nn.activate(ds['input'][-1])))\n    forecast['tomorrow'] = update_dict(tomorrow, {'date': (df.index[-1] + datetime.timedelta(1)).date()})\n\n    return forecast"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef environ(context):\n  if 'BASEDIRSETSHELL' not in os.environ:\n    # It seems that we are in a hostile environment\n    # try to source the Idiap-wide shell\n    idiap_source = \"/idiap/resource/software/initfiles/shrc\"\n    if os.path.exists(idiap_source):\n      logger.debug(\"Sourcing: '%s'\"%idiap_source)\n      try:\n        command = ['bash', '-c', 'source %s && env' % idiap_source]\n        pi = subprocess.Popen(command, stdout = subprocess.PIPE)\n        # overwrite the default environment\n        for line in pi.stdout:\n          line = str_(line)\n          (key, _, value) = line.partition(\"=\")\n          os.environ[key.strip()] = value.strip()\n      except OSError as e:\n        # occurs when the file is not executable or not found\n        pass\n\n  # in case the BASEDIRSETSHELL environment variable is not set,\n  # we are not at Idiap,\n  # and so we don't have to set any additional variables.\n  if 'BASEDIRSETSHELL' not in os.environ:\n    return dict(os.environ)\n\n  BASEDIRSETSHELL = os.environ['BASEDIRSETSHELL']\n  dosetshell = '%s/setshell/bin/dosetshell' % BASEDIRSETSHELL\n\n  command = [dosetshell, '-s', 'sh', context]\n\n  # First things first, we get the path to the temp file created by dosetshell\n  try:\n    logger.debug(\"Executing: '%s'\", ' '.join(command))\n    p = subprocess.Popen(command, stdout = subprocess.PIPE)\n  except OSError as e:\n    # occurs when the file is not executable or not found\n    raise OSError(\"Error executing '%s': %s (%d)\" % (' '.join(command), e.strerror, e.errno))\n\n  try:\n    source = str_(p.communicate()[0]).strip()\n  except KeyboardInterrupt: # the user CTRL-C'ed\n    os.kill(p.pid, signal.SIGTERM)\n    sys.exit(signal.SIGTERM)\n\n  # We have now the name of the source file, source it and erase it\n  command2 = ['bash', '-c', 'source %s && env' % source]\n\n  try:\n    logger.debug(\"Executing: '%s'\", ' '.join(command2))\n    p2 = subprocess.Popen(command2, stdout = subprocess.PIPE)\n  except OSError as e:\n    # occurs when the file is not executable or not found\n    raise OSError(\"Error executing '%s': %s (%d)\" % (' '.join(command2), e.strerror, e.errno))\n\n  new_environ = dict(os.environ)\n  for line in p2.stdout:\n    line = str_(line)\n    (key, _, value) = line.partition(\"=\")\n    new_environ[key.strip()] = value.strip()\n\n  try:\n    p2.communicate()\n  except KeyboardInterrupt: # the user CTRL-C'ed\n    os.kill(p2.pid, signal.SIGTERM)\n    sys.exit(signal.SIGTERM)\n\n  if os.path.exists(source): os.unlink(source)\n\n  logger.debug(\"Discovered environment for context '%s':\", context)\n  for k in sorted(new_environ.keys()):\n    logger.debug(\"  %s = %s\", k, new_environ[k])\n\n  return new_environ", "response": "Retrieves the environment for a particular SETSHELL context"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting a command within a particular Idiap SETSHELL context", "response": "def sexec(context, command, error_on_nonzero=True):\n  \"\"\"Executes a command within a particular Idiap SETSHELL context\"\"\"\n\n  import six\n  if isinstance(context, six.string_types): E = environ(context)\n  else: E = context\n\n  try:\n    logger.debug(\"Executing: '%s'\", ' '.join(command))\n    p = subprocess.Popen(command, stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT, env=E)\n    (stdout, stderr) = p.communicate() #note: stderr will be 'None'\n    if p.returncode != 0:\n      if error_on_nonzero:\n        raise RuntimeError(\"Execution of '%s' exited with status != 0 (%d): %s\" % (' '.join(command), p.returncode, str_(stdout)))\n      else:\n        logger.debug(\"Execution of '%s' exited with status != 0 (%d): %s\" % \\\n            (' '.join(command), p.returncode, str_(stdout)))\n\n    return stdout.strip()\n\n  except KeyboardInterrupt: # the user CTRC-C'ed\n    os.kill(p.pid, signal.SIGTERM)\n    sys.exit(signal.SIGTERM)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of dates from the start to top.", "response": "def get_dates_in_period(start=None, top=None, step=1, step_dict={}):\n    \"\"\"Return a list of dates from the `start` to `top`.\"\"\"\n\n    delta = relativedelta(**step_dict) if step_dict else timedelta(days=step)\n\n    start = start or datetime.today()\n    top = top or start + delta\n    dates = []\n    current = start\n    while current <= top:\n        dates.append(current)\n        current += delta\n    return dates"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef localize_date(date, city):\n    local = pytz.timezone(city)\n    local_dt = local.localize(date, is_dst=None)\n    return local_dt", "response": "Localize date into city\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the month name for the given locale in the given string.", "response": "def get_month_from_date_str(date_str, lang=DEFAULT_DATE_LANG):\n    \"\"\"Find the month name for the given locale, in the given string.\n\n    Returns a tuple ``(number_of_month, abbr_name)``.\n    \"\"\"\n    date_str = date_str.lower()\n    with calendar.different_locale(LOCALES[lang]):\n        month_abbrs = list(calendar.month_abbr)\n        for seq, abbr in enumerate(month_abbrs):\n            if abbr and abbr.lower() in date_str:\n                return seq, abbr\n    return ()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_month_abbr_with_num(date_str, lang=DEFAULT_DATE_LANG):\n    num, abbr = get_month_from_date_str(date_str, lang)\n    return re.sub(abbr, str(num), date_str, flags=re.IGNORECASE)", "response": "Replace month strings occurrences with month number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef translate_month_abbr(\n        date_str,\n        source_lang=DEFAULT_DATE_LANG,\n        target_lang=DEFAULT_DATE_LANG):\n    \"\"\"Translate the month abbreviation from one locale to another.\"\"\"\n    month_num, month_abbr = get_month_from_date_str(date_str, source_lang)\n    with calendar.different_locale(LOCALES[target_lang]):\n        translated_abbr = calendar.month_abbr[month_num]\n        return re.sub(\n            month_abbr, translated_abbr, date_str, flags=re.IGNORECASE)", "response": "Translate the month abbreviation from one locale to another locale."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate datetime object from date and time strings.", "response": "def merge_datetime(date, time='', date_format='%d/%m/%Y', time_format='%H:%M'):\n    \"\"\"Create ``datetime`` object from date and time strings.\"\"\"\n    day = datetime.strptime(date, date_format)\n    if time:\n        time = datetime.strptime(time, time_format)\n        time = datetime.time(time)\n        day = datetime.date(day)\n        day = datetime.combine(day, time)\n    return day"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting a file list to terminal allows colouring output.", "response": "def display_list(prefix, l, color):\n    \"\"\" Prints a file list to terminal, allows colouring output. \"\"\"\n    for itm in l: print colored(prefix + itm['path'], color)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprefixing a path with the OS path separator if it is not already", "response": "def pfx_path(path):\n    \"\"\" Prefix a path with the OS path separator if it is not already \"\"\"\n    if path[0] != os.path.sep: return os.path.sep + path\n    else:                      return path"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nputting passed contents into file located at path.", "response": "def file_put_contents(path, data):\n    \"\"\" Put passed contents into file located at 'path' \"\"\"\n    with open(path, 'w') as f:\n        f.write(data); f.flush()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef file_or_default(path, default, function = None):\n    try:\n        result = file_get_contents(path)\n        if function != None: return function(result)\n        return result\n    except IOError as e:\n        if e.errno == errno.ENOENT: return default\n        raise", "response": "Return a file s contents or a default value if a file does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_dirs_if_dont_exist(path):\n    if path[-1] not in ['/']: path += '/'\n    path = os.path.dirname(path)\n    if path != '':\n        try: os.makedirs(path)\n        except OSError: pass", "response": "Create directories in path if they do not exist"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_single_file_info(f_path, int_path):\n    return { 'path'     : force_unicode(int_path),\n             'created'  : os.path.getctime(f_path),\n             'last_mod' : os.path.getmtime(f_path)}", "response": "Gets the creates and last change times for a single file in the internal\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhashes a file with sha256", "response": "def hash_file(file_path, block_size = 65536):\n    \"\"\" Hashes a file with sha256 \"\"\"\n    sha = hashlib.sha256()\n    with open(file_path, 'rb') as h_file:\n        file_buffer = h_file.read(block_size)\n        while len(file_buffer) > 0:\n            sha.update(file_buffer)\n            file_buffer = h_file.read(block_size)\n    return sha.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_file_list(path):\n    f_list = []\n    def recur_dir(path, newpath = os.path.sep):\n        files = os.listdir(path)\n        for fle in files:\n            f_path = cpjoin(path, fle)\n            if os.path.isdir(f_path): recur_dir(f_path, cpjoin(newpath, fle))\n            elif os.path.isfile(f_path): f_list.append(get_single_file_info(f_path, cpjoin(newpath, fle)))\n\n    recur_dir(path)\n    return f_list", "response": "Recursively lists all files in a file system below path."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds what has changed between two sets of files", "response": "def find_manifest_changes(new_file_state, old_file_state):\n    \"\"\" Find what has changed between two sets of files \"\"\"\n    prev_state_dict = copy.deepcopy(old_file_state)\n    changed_files = {}\n\n    # Find files which are new on the server\n    for itm in new_file_state:\n        if itm['path'] in prev_state_dict:\n            d_itm = prev_state_dict.pop(itm['path'])\n\n            # If the file has been modified\n            if itm['last_mod'] != d_itm['last_mod']:\n                n_itm = itm.copy()\n                n_itm['status'] = 'changed'\n                changed_files[itm['path']] = n_itm\n            else:\n                pass # The file has not changed\n\n        else:\n            n_itm = itm.copy()\n            n_itm['status'] = 'new'\n            changed_files[itm['path']] = n_itm\n\n    # any files remaining in the old file state have been deleted locally\n    for itm in prev_state_dict.itervalues():\n        n_itm = itm.copy()\n        n_itm['status'] = 'deleted'\n        changed_files[itm['path']] = n_itm\n\n    return changed_files"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shasha(msg):\n    res = hashlib.sha256(hashlib.sha256(msg).digest())\n    return res", "response": "SHA256 hash a message"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ripesha(msg):\n    ripe = hashlib.new('ripemd160')\n    ripe.update(hashlib.sha256(msg).digest())\n    return ripe", "response": "RIPEMD160 is a hash function that returns the SHA256 hash of the message."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef privkey_to_wif(rawkey, compressed=True, net=BC):\n    # See https://en.bitcoin.it/wiki/Wallet_import_format.\n    k = net.wifprefix + rawkey\n    if compressed:\n        k += b'\\x01'\n\n    chksum = shasha(k).digest()[:4]\n    key = k + chksum\n\n    b58key = b58encode(key)\n    return b58key", "response": "Convert a raw key to a Wallet Import Format WIF key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting Wallet Import Format ( WIF ) to privkey bytes.", "response": "def wif_to_privkey(wif, compressed=True, net=BC):\n    \"\"\"Convert Wallet Import Format (WIF) to privkey bytes.\"\"\"\n    key = b58decode(wif)\n\n    version, raw, check = key[0:1], key[1:-4], key[-4:]\n    assert version == net.wifprefix, \"unexpected version byte\"\n\n    check_compare = shasha(version + raw).digest()[:4]\n    assert check_compare == check\n\n    if compressed:\n        raw = raw[:-1]\n\n    return raw"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns boolean of whether this filename looks like an archive", "response": "def is_archive(filename):\n    '''returns boolean of whether this filename looks like an archive'''\n    for archive in archive_formats:\n        if filename.endswith(archive_formats[archive]['suffix']):\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the basename of a recognized archive file", "response": "def archive_basename(filename):\n    '''returns the basename (name without extension) of a recognized archive file'''\n    for archive in archive_formats:\n        if filename.endswith(archive_formats[archive]['suffix']):\n            return filename.rstrip('.' + archive_formats[archive]['suffix'])\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nunpack the given archive into output_dir", "response": "def unarchive(filename,output_dir='.'):\n    '''unpacks the given archive into ``output_dir``'''\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    for archive in archive_formats:\n        if filename.endswith(archive_formats[archive]['suffix']):\n            return subprocess.call(archive_formats[archive]['command'](output_dir,filename))==0\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef flatten(nested_list):\n    '''converts a list-of-lists to a single flat list'''\n    return_list = []\n    for i in nested_list:\n        if isinstance(i,list):\n            return_list += flatten(i)\n        else:\n            return_list.append(i)\n    return return_list", "response": "converts a list - of - lists to a single flat list"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps to run external programs in a directory", "response": "def run(command,products=None,working_directory='.',force_local=False,stderr=True,quiet=False):\n    '''wrapper to run external programs\n\n    :command:           list containing command and parameters\n                        (formatted the same as subprocess; must contain only strings)\n    :products:          string or list of files that are the products of this command\n                        if all products exist, the command will not be run, and False returned\n    :working_directory: will chdir to this directory\n    :force_local:       when used with `neural.scheduler`, setting to ``True`` will disable\n                        all job distribution functions\n    :stderr:            forward ``stderr`` into the output\n                        ``True`` will combine ``stderr`` and ``stdout``\n                        ``False`` will return ``stdout`` and let ``stderr`` print to the console\n                        ``None`` will return ``stdout`` and suppress ``stderr``\n    :quiet:             ``False`` (default) will print friendly messages\n                        ``True`` will suppress everything but errors\n                        ``None`` will suppress all output\n\n    Returns result in form of :class:`RunResult`\n    '''\n    with run_in(working_directory):\n        if products:\n            if isinstance(products,basestring):\n                products = [products]\n            if all([os.path.exists(x) for x in products]):\n                return False\n\n        command = flatten(command)\n        command = [str(x) for x in command]\n        quiet_option = False if quiet==False else True\n        with nl.notify('Running %s...' % command[0],level=nl.level.debug,quiet=quiet_option):\n            out = None\n            returncode = 0\n            try:\n                if stderr:\n                    # include STDERR in STDOUT output\n                    out = subprocess.check_output(command,stderr=subprocess.STDOUT)\n                elif stderr==None:\n                    # dump STDERR into nothing\n                    out = subprocess.check_output(command,stderr=subprocess.PIPE)\n                else:\n                    # let STDERR show through to the console\n                    out = subprocess.check_output(command)\n            except subprocess.CalledProcessError, e:\n                if quiet!=None:\n                    nl.notify('''ERROR: %s returned a non-zero status\n\n    ----COMMAND------------\n    %s\n    -----------------------\n\n\n    ----OUTPUT-------------\n    %s\n    -----------------------\n    Return code: %d\n    ''' % (command[0],' '.join(command),e.output,e.returncode),level=nl.level.error)\n                out = e.output\n                returncode = e.returncode\n            result = RunResult(out,returncode)\n            if products and returncode==0:\n                result.output_filename = products[0]\n            return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns string of MD5 hash of given filename", "response": "def hash(filename):\n    '''returns string of MD5 hash of given filename'''\n    buffer_size = 10*1024*1024\n    m = hashlib.md5()\n    with open(filename) as f:\n        buff = f.read(buffer_size)\n        while len(buff)>0:\n            m.update(buff)\n            buff = f.read(buffer_size)\n    dig = m.digest()\n    return ''.join(['%x' % ord(x) for x in dig])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef hash_str(string):\n    '''returns string of MD5 hash of given string'''\n    m = hashlib.md5()\n    m.update(string)\n    dig = m.digest()\n    return ''.join(['%x' % ord(x) for x in dig])", "response": "returns string of MD5 hash of given string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find(file):\n    '''tries to find ``file`` using OS-specific searches and some guessing'''\n    # Try MacOS Spotlight:\n    mdfind = which('mdfind')\n    if mdfind:\n        out = run([mdfind,'-name',file],stderr=None,quiet=None)\n        if out.return_code==0 and out.output:\n                for fname in out.output.split('\\n'):\n                    if os.path.basename(fname)==file:\n                        return fname\n\n    # Try UNIX locate:\n    locate = which('locate')\n    if locate:\n        out = run([locate,file],stderr=None,quiet=None)\n        if out.return_code==0 and out.output:\n            for fname in out.output.split('\\n'):\n                if os.path.basename(fname)==file:\n                    return fname\n\n    # Try to look through the PATH, and some guesses:\n    path_search = os.environ[\"PATH\"].split(os.pathsep)\n    path_search += ['/usr/local/afni','/usr/local/afni/atlases','/usr/local/share','/usr/local/share/afni','/usr/local/share/afni/atlases']\n    afni_path = which('afni')\n    if afni_path:\n        path_search.append(os.path.dirname(afni_path))\n    if nl.wrappers.fsl.bet2:\n        path_search.append(os.path.dirname(nl.wrappers.fsl.bet2))\n    for path in path_search:\n        path = path.strip('\"')\n        try:\n            if file in os.listdir(path):\n                return os.path.join(path,file)\n        except:\n            pass", "response": "tries to find file using OS - specific searches and some guessing"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef strip_rows(array,invalid=None):\n    '''takes a ``list`` of ``list``s and removes corresponding indices containing the\n    invalid value (default ``None``). '''\n    array = np.array(array)\n    none_indices = np.where(np.any(np.equal(array,invalid),axis=0))\n    return tuple(np.delete(array,none_indices,axis=1))", "response": "takes a list of lists and removes corresponding indices containing the\n    invalid value ( default None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nturning a string into a number if it s only a number otherwise returns the string.", "response": "def numberize(string):\n    '''Turns a string into a number (``int`` or ``float``) if it's only a number (ignoring spaces), otherwise returns the string.\n    For example, ``\"5 \"`` becomes ``5`` and ``\"2 ton\"`` remains ``\"2 ton\"``'''\n    if not isinstance(string,basestring):\n        return string\n    just_int = r'^\\s*[-+]?\\d+\\s*$'\n    just_float = r'^\\s*[-+]?\\d+\\.(\\d+)?\\s*$'\n    if re.match(just_int,string):\n        return int(string)\n    if re.match(just_float,string):\n        return float(string)\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if there is a valid packet for this app and instance?", "response": "def check_packet(self):\n        '''is there a valid packet (from another thread) for this app/instance?'''\n        if not os.path.exists(self.packet_file()):\n            # No packet file, we're good\n            return True\n        else:\n            # There's already a file, but is it still running?\n            try:\n                with open(self.packet_file()) as f:\n                    packet = json.loads(f.read())\n                if time.time() - packet['last_time'] > 3.0*packet['poll_time']:\n                    # We haven't heard a ping in too long. It's probably dead\n                    return True\n                else:\n                    # Still getting pings.. probably still a live process\n                    return False\n            except:\n                # Failed to read file... try again in a second\n                time.sleep(random.random()*2)\n                return self.check_packet()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn one or two hexagrams using a variety of divination methods.", "response": "def get_hexagram(method='THREE COIN'):\n    \"\"\"\n    Return one or two hexagrams using any of a variety of divination methods.\n\n    The ``NAIVE`` method simply returns a uniformally random ``int`` between\n    ``1`` and ``64``.\n\n    All other methods return a 2-tuple where the first value\n    represents the starting hexagram and the second represents the 'moving to'\n    hexagram.\n\n    To find the name and unicode glyph for a found hexagram, look it up in\n    the module-level `hexagrams` dict.\n\n    Args:\n        method (str): ``'THREE COIN'``, ``'YARROW'``, or ``'NAIVE'``,\n            the divination method model to use. Note that the three coin and\n            yarrow methods are not actually literally simulated,\n            but rather statistical models reflecting the methods are passed\n            to `blur.rand` functions to accurately approximate them.\n\n    Returns:\n        int: If ``method == 'NAIVE'``, the ``int`` key of the found hexagram.\n        Otherwise a `tuple` will be returned.\n\n        tuple: A 2-tuple of form ``(int, int)``  where the first value\n        is key of the starting hexagram and the second is that of the\n        'moving-to' hexagram.\n\n    Raises: ValueError if ``method`` is invalid\n\n    Examples:\n\n    The function being used alone: ::\n\n        >>> get_hexagram(method='THREE COIN')                  # doctest: +SKIP\n        # Might be...\n        (55, 2)\n        >>> get_hexagram(method='YARROW')                      # doctest: +SKIP\n        # Might be...\n        (41, 27)\n        >>> get_hexagram(method='NAIVE')                       # doctest: +SKIP\n        # Might be...\n        26\n\n    Usage in combination with hexagram lookup: ::\n\n        >>> grams = get_hexagram()\n        >>> grams                                              # doctest: +SKIP\n        (47, 42)\n        # unpack hexagrams for convenient reference\n        >>> initial, moving_to = grams\n        >>> hexagrams[initial]                                 # doctest: +SKIP\n        ('\u4dee', '\u56f0', 'Confining')\n        >>> hexagrams[moving_to]                               # doctest: +SKIP\n        ('\u4de9', '\u76ca', 'Augmenting')\n        >>> print('{} moving to {}'.format(\n        ...     hexagrams[initial][2],\n        ...     hexagrams[moving_to][2])\n        ...     )                                              # doctest: +SKIP\n        Confining moving to Augmenting\n    \"\"\"\n    if method == 'THREE COIN':\n        weights = [('MOVING YANG', 2),\n                   ('MOVING YIN',  2),\n                   ('STATIC YANG', 6),\n                   ('STATIC YIN',  6)]\n    elif method == 'YARROW':\n        weights = [('MOVING YANG', 8),\n                   ('MOVING YIN',  2),\n                   ('STATIC YANG', 11),\n                   ('STATIC YIN',  17)]\n    elif method == 'NAIVE':\n        return random.randint(1, 64)\n    else:\n        raise ValueError('`method` value of \"{}\" is invalid')\n\n    hexagram_1 = []\n    hexagram_2 = []\n\n    for i in range(6):\n        roll = weighted_choice(weights)\n        if roll == 'MOVING YANG':\n            hexagram_1.append(1)\n            hexagram_2.append(0)\n        elif roll == 'MOVING YIN':\n            hexagram_1.append(0)\n            hexagram_2.append(1)\n        elif roll == 'STATIC YANG':\n            hexagram_1.append(1)\n            hexagram_2.append(1)\n        else:  # if roll == 'STATIC YIN'\n            hexagram_1.append(0)\n            hexagram_2.append(0)\n    # Convert hexagrams lists into tuples\n    hexagram_1 = tuple(hexagram_1)\n    hexagram_2 = tuple(hexagram_2)\n    return (_hexagram_dict[hexagram_1], _hexagram_dict[hexagram_2])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_supported_resources(netid):\n    url = _netid_supported_url(netid)\n    response = get_resource(url)\n    return _json_to_supported(response)", "response": "Returns list of Supported resources for a given netid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _json_to_supported(response_body):\n    data = json.loads(response_body)\n    supported = []\n    for supported_data in data.get(\"supportedList\", []):\n        supported.append(Supported().from_json(\n            supported_data))\n\n    return supported", "response": "Returns a list of Supported objects from a JSON response body."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_arguments(parser):\n\n  default_log_path = os.path.realpath('logs')\n\n  parser.add_argument('--log-dir', metavar='LOG', type=str,\n      dest='logdir', default=default_log_path,\n      help='Base directory used for logging (defaults to \"%(default)s\")')\n\n  q_choices = (\n      'default', 'all.q',\n      'q_1day', 'q1d',\n      'q_1week', 'q1w',\n      'q_1month', 'q1m',\n      'q_1day_mth', 'q1dm',\n      'q_1week_mth', 'q1wm',\n      'q_gpu', 'gpu',\n      'q_long_gpu', 'lgpu',\n      'q_short_gpu', 'sgpu',\n      )\n\n  parser.add_argument('--queue-name', metavar='QUEUE', type=str,\n      dest='queue', default=q_choices[0], choices=q_choices,\n      help='Queue for submission - one of ' + \\\n          '|'.join(q_choices) + ' (defaults to \"%(default)s\")')\n\n  parser.add_argument('--hostname', metavar='HOSTNAME', type=str,\n      dest='hostname', default=None,\n      help='If set, it asks the queue to use only a subset of the available nodes')\n  parser.add_argument('--memfree', metavar='MEMFREE', type=str,\n      dest='memfree', default=None,\n      help='Adds the \\'-l mem_free\\' argument to qsub')\n  parser.add_argument('--hvmem', metavar='HVMEM', type=str,\n      dest='hvmem', default=None,\n      help='Adds the \\'-l h_vmem\\' argument to qsub')\n  parser.add_argument('--pe-opt', metavar='PE_OPT', type=str,\n      dest='pe_opt', default=None,\n      help='Adds the \\'--pe \\' argument to qsub')\n\n  parser.add_argument('--no-cwd', default=True, action='store_false',\n      dest='cwd', help='Do not change to the current directory when starting the grid job')\n\n  parser.add_argument('--dry-run', default=False, action='store_true',\n      dest='dryrun', help='Does not really submit anything, just print what would do instead')\n\n  parser.add_argument('--job-database', default=None,\n      dest='statefile', help='The path to the state file that will be created with the submissions (defaults to the parent directory of your logs directory)')\n\n  return parser", "response": "Adds stock arguments to argparse parsers from scripts that submit grid\n jobs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef submit(jman, command, arguments, deps=[], array=None):\n\n  logdir = os.path.join(os.path.realpath(arguments.logdir),\n      tools.random_logdir())\n\n  jobname = os.path.splitext(os.path.basename(command[0]))[0]\n  cmd = tools.make_shell(sys.executable, command)\n\n  if arguments.dryrun:\n    return DryRunJob(cmd, cwd=arguments.cwd, queue=arguments.queue,\n        hostname=arguments.hostname, memfree=arguments.memfree,\n        hvmem=arguments.hvmem, gpumem=arguments.gpumem, pe_opt=arguments.pe_opt,\n        stdout=logdir, stderr=logdir, name=jobname, deps=deps,\n        array=array)\n  \n  # really submit\n  return jman.submit(cmd, cwd=arguments.cwd, queue=arguments.queue,\n      hostname=arguments.hostname, memfree=arguments.memfree,\n      hvmem=arguments.hvmem, gpumem=arguments.gpumem, pe_opt=arguments.pe_opt,\n      stdout=logdir, stderr=logdir, name=jobname, deps=deps,\n      array=array)", "response": "A simple submission option for grid - enabled scripts. Create the log\n directories using random hash codes. Use the arguments as parsed by the main\n script."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_to_dict(self, text):\n        n = self.n\n\n        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|!)\\s', text)\n        # '' is a special symbol for the start of a sentence like pymarkovchain uses\n        for sentence in sentences:\n            sentence = sentence.replace('\"','') # remove quotes\n            words = sentence.strip().split()  # split each sentence into its constituent words\n            if len(words) == 0:\n                continue\n\n            # first word follows a sentence end\n            self.word_dict[(\"\",)][words[0]].count += 1\n\n            for j in range(1, n+1):\n                for i in range(len(words) - 1):\n                    if i + j >= len(words):\n                        continue\n                    word = tuple(words[i:i + j])\n                    self.word_dict[word][words[i + j]].count += 1\n\n                # last word precedes a sentence end\n                self.word_dict[tuple(words[len(words) - j:len(words)])][\"\"].count += 1\n\n        # We've now got the db filled with parametrized word counts\n        # We still need to normalize this to represent probabilities\n        for word in self.word_dict:\n            wordsum = 0\n            for nextword in self.word_dict[word]:\n                wordsum += self.word_dict[word][nextword].count\n            if wordsum != 0:\n                for nextword in self.word_dict[word]:\n                    self.word_dict[word][nextword].prob = self.word_dict[word][nextword].count / wordsum", "response": "Generate word n - tuple and next word probability dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the next word that is generated by the Markov Chain.", "response": "def next_word(self, previous_words):\n        \"\"\"The next word that is generated by the Markov Chain\n        depends on a tuple of the previous words from the Chain\"\"\"\n        # The previous words may never have appeared in order in the corpus used to\n        # generate the word_dict. Consequently, we want to try to find the previous \n        # words in orde, but if they are not there, then we remove the earliest word\n        # one by one and recheck. This means that next word depends on the current state\n        # but possible not on the entire state\n        previous_words = tuple(previous_words)\n        if previous_words != (\"\",): # the empty string 1-tuple (singleton tuple) is always there\n            while previous_words not in self.word_dict:\n                previous_words = tuple(previous_words[1:])\n                if not previous_words:\n                    return \"\"\n        frequencies = self.word_dict[previous_words]\n        inv = [(v.prob,k) for k, v in frequencies.items()]\n        p, w = zip(*inv)\n        return np.random.choice(w,1,p)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a Transaction document from the given source and from_pubkey", "response": "def get_transaction_document(current_block: dict, source: dict, from_pubkey: str, to_pubkey: str) -> Transaction:\n    \"\"\"\n    Return a Transaction document\n\n    :param current_block: Current block infos\n    :param source: Source to send\n    :param from_pubkey: Public key of the issuer\n    :param to_pubkey: Public key of the receiver\n\n    :return: Transaction\n    \"\"\"\n    # list of inputs (sources)\n    inputs = [\n        InputSource(\n            amount=source['amount'],\n            base=source['base'],\n            source=source['type'],\n            origin_id=source['identifier'],\n            index=source['noffset']\n        )\n    ]\n\n    # list of issuers of the inputs\n    issuers = [\n        from_pubkey\n    ]\n\n    # list of unlocks of the inputs\n    unlocks = [\n        Unlock(\n            # inputs[index]\n            index=0,\n            # unlock inputs[index] if signatures[0] is from public key of issuers[0]\n            parameters=[SIGParameter(0)]\n        )\n    ]\n\n    # lists of outputs\n    outputs = [\n        OutputSource(amount=source['amount'], base=source['base'], condition=\"SIG({0})\".format(to_pubkey))\n    ]\n\n    transaction = Transaction(\n        version=TRANSACTION_VERSION,\n        currency=current_block['currency'],\n        blockstamp=BlockUID(current_block['number'], current_block['hash']),\n        locktime=0,\n        issuers=issuers,\n        inputs=inputs,\n        unlocks=unlocks,\n        outputs=outputs,\n        comment='',\n        signatures=[]\n    )\n\n    return transaction"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def main():\n    # Create Client from endpoint string in Duniter format\n    client = Client(BMAS_ENDPOINT)\n\n    # Get the node summary infos to test the connection\n    response = await client(bma.node.summary)\n    print(response)\n\n    # prompt hidden user entry\n    salt = getpass.getpass(\"Enter your passphrase (salt): \")\n\n    # prompt hidden user entry\n    password = getpass.getpass(\"Enter your password: \")\n\n    # create keys from credentials\n    key = SigningKey.from_credentials(salt, password)\n    pubkey_from = key.pubkey\n\n    # prompt entry\n    pubkey_to = input(\"Enter recipient pubkey: \")\n\n    # capture current block to get version and currency and blockstamp\n    current_block = await client(bma.blockchain.current)\n\n    # capture sources of account\n    response = await client(bma.tx.sources, pubkey_from)\n\n    if len(response['sources']) == 0:\n        print(\"no sources found for account %s\" % pubkey_to)\n        exit(1)\n\n    # get the first source\n    source = response['sources'][0]\n\n    # create the transaction document\n    transaction = get_transaction_document(current_block, source, pubkey_from, pubkey_to)\n\n    # sign document\n    transaction.sign([key])\n\n    # send the Transaction document to the node\n    response = await client(bma.tx.process, transaction.signed_raw())\n\n    if response.status == 200:\n        print(await response.text())\n    else:\n        print(\"Error while publishing transaction: {0}\".format(await response.text()))\n\n    # Close client aiohttp session\n    await client.close()", "response": "Main function for the Duniter node"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_type(obj: Any,\n               candidate_type: Any,\n               reltype: str = 'invariant') -> bool:\n    \"\"\"Tell wether a value correspond to a type,\n    optionally specifying the type as contravariant or covariant.\n\n    Args:\n        obj (Any): The value to check.\n        candidate_type (Any): The type to check the object against.\n        reltype (:obj:`str`, optional): Variance of the type, can be contravariant,\n            covariant or invariant. By default is invariant.\n    Returns:\n        bool: True if the type is fine, False otherwise\n\n    Raises:\n        ValueError: When the variance or the type are not among the ones the function can manage.\n    \"\"\"\n    if reltype not in ['invariant', 'covariant', 'contravariant']:\n        raise ValueError(f' Variadic type {reltype} is unknown')\n\n    # builtin type like str, or a class\n    if type(candidate_type) == type and reltype in ['invariant']:\n        return isinstance(obj, candidate_type)\n\n    if type(candidate_type) == type and reltype in ['covariant']:\n        return issubclass(obj.__class__, candidate_type)\n\n    if type(candidate_type) == type and reltype in ['contravariant']:\n        return issubclass(candidate_type, obj.__class__)\n\n    # Any accepts everything\n    if type(candidate_type) == type(Any):\n        return True\n\n    # Union, at least one match in __args__\n    if type(candidate_type) == type(Union):\n        return any(check_type(obj, t, reltype) for t in candidate_type.__args__)\n\n    # Tuple, each element matches the corresponding type in __args__\n    if type(candidate_type) == type(Tuple) and tuple in candidate_type.__bases__:\n        if not hasattr(obj, '__len__'):\n            return False\n        if len(candidate_type.__args__) != len(obj):\n            return False\n        return all(check_type(o, t, reltype) for (o, t) in zip(obj, candidate_type.__args__))\n\n    # Dict, each (key, value) matches the type in __args__\n    if type(candidate_type) == type(Dict) and dict in candidate_type.__bases__:\n        if type(obj) != dict:\n            return False\n        return all(check_type(k, candidate_type.__args__[0], reltype)\n                   and check_type(v, candidate_type.__args__[1], reltype)\n                   for (k, v) in obj.items())\n\n    # List or Set, each element matches the type in __args__\n    if type(candidate_type) == type(List) and \\\n       (list in candidate_type.__bases__ or set in candidate_type.__bases__):\n        if not hasattr(obj, '__len__'):\n            return False\n        return all(check_type(o, candidate_type.__args__[0], reltype) for o in obj)\n\n    # TypeVar, this is tricky\n    if type(candidate_type) == TypeVar:\n        # TODO consider contravariant, variant and bound\n        # invariant with a list of constraints, acts like a Tuple\n        if not candidate_type.__constraints__:\n            return True\n        if not (candidate_type.__covariant__ or candidate_type.__contravariant__):\n            return any(check_type(obj, t) for t in candidate_type.__constraints__)\n\n    if type(candidate_type) == type(Type):\n        return check_type(obj, candidate_type.__args__[0], reltype='covariant')\n\n    if inspect.isclass(candidate_type) and reltype in ['invariant']:\n        return isinstance(obj, candidate_type)\n\n    raise ValueError(f'Cannot check against {reltype} type {candidate_type}')", "response": "Tells if a value correspond to a type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_argparser(self, root, parents):\n        parents.append(tools.argparser)\n\n        parser = root.add_parser('auth', parents=parents)\n        parser.set_defaults(func=self)\n\n        parser.add_argument(\n            '--secrets',\n            dest='secrets', action='store',\n            help='Path to the authorization secrets file (client_secrets.json).'\n        )\n\n        return parser", "response": "Add arguments for this command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a new configuration dictionary to the current configuration.", "response": "def add_config(self, config):\n        \"\"\"\n        :param config:\n        :type config: dict\n        \"\"\"\n        self.pre_configure()\n\n        self.config = config\n\n        if not self.has_revision_file():\n            #: Create new revision file.\n            touch_file(self.revfile_path)\n\n        self.history.load(self.revfile_path)\n\n        self.archiver.target_path = self.dest_path\n        self.archiver.zip_path = self.tmp_file_path\n\n        self.state.state_path = os.path.join(\n            REVISION_HOME,\n            \"clients\",\n            self.key\n        )\n        self.state.prepare()\n\n        self.post_configure()\n\n        self.prepared = True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the key - value - set file name", "response": "def filename(self):\n        \"\"\"\n        :return:\n        :rtype: str\n        \"\"\"\n        filename = self.key\n\n        if self.has_revision_file() and self.history.current_revision:\n            filename += \"-\"\n            filename += self.history.current_revision.revision_id\n\n        filename += \".zip\"\n\n        return filename"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_commit(self):\n        current_revision = self.history.current_revision\n        revision_id = self.state.revision_id\n\n        return current_revision.revision_id != revision_id", "response": "Returns True if the current revision is not the revision id of the revision"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef revfile_path(self):\n        return os.path.normpath(os.path.join(\n            os.getcwd(),\n            self.config.revision_file\n        ))", "response": "Returns the full path of the revision file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the path to the info file for the current locale.", "response": "def infofile_path(self):\n        \"\"\"\n        :return:\n        :rtype: str\n        \"\"\"\n        return os.path.normpath(os.path.join(\n            self.dest_path,\n            self.config.info_file\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the destination path.", "response": "def dest_path(self):\n        \"\"\"\n        :return: The destination path.\n        :rtype: str\n        \"\"\"\n        if os.path.isabs(self.config.local_path):\n            return self.config.local_path\n        else:\n            return os.path.normpath(os.path.join(\n                os.getcwd(),\n                self.config.local_path\n            ))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the path to the temporary file for the current locale.", "response": "def tmp_file_path(self):\n        \"\"\"\n        :return:\n        :rtype: str\n        \"\"\"\n        return os.path.normpath(os.path.join(\n            TMP_DIR,\n            self.filename\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self, revision):\n        if not isinstance(revision, Revision):\n            raise InvalidArgType()\n\n        self.state.update(revision)", "response": "Save the current state of the object to the given revision."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_new_revision(self):\n        if self.history.current_revision is None:\n            return self.state.revision_id is not None\n\n        current_revision_id = self.history.current_revision.revision_id\n        return self.state.revision_id != current_revision_id", "response": "Returns True if a new revision exists."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_source(self, key, name_spaces=None, default_prefix=''):\n        source = self.source or key\n        prefix = default_prefix\n        if name_spaces and self.name_space and self.name_space in name_spaces:\n            prefix = ''.join([name_spaces[self.name_space], ':'])\n        return ''.join([prefix, source])", "response": "Generates the dictionary key for the serialized representation\n        based on the instance variable source and a provided key."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the raw_data to an integer.", "response": "def validate(self, raw_data, **kwargs):\n        \"\"\"Convert the raw_data to an integer.\n\n        \"\"\"\n        try:\n            converted_data = int(raw_data)\n            return super(IntegerField, self).validate(converted_data)\n        except ValueError:\n            raise ValidationException(self.messages['invalid'], repr(raw_data))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert the raw_data to a float.", "response": "def validate(self, raw_data, **kwargs):\n        \"\"\"Convert the raw_data to a float.\n\n        \"\"\"\n        try:\n            converted_data = float(raw_data)\n            super(FloatField, self).validate(converted_data, **kwargs)\n            return raw_data\n        except ValueError:\n            raise ValidationException(self.messages['invalid'], repr(raw_data))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating the value of the tag.", "response": "def validate(self, raw_data, **kwargs):\n        \"\"\"The string ``'True'`` (case insensitive) will be converted\n        to ``True``, as will any positive integers.\n\n        \"\"\"\n        super(BooleanField, self).validate(raw_data, **kwargs)\n        if isinstance(raw_data, string_types):\n            valid_data = raw_data.strip().lower() == 'true'\n        elif isinstance(raw_data, bool):\n            valid_data = raw_data\n        else:\n            valid_data = raw_data > 0\n        return valid_data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deserialize(self, raw_data, **kwargs):\n        super(DateTimeField, self).deserialize(raw_data, **kwargs)\n        return self.converted", "response": "A : class : datetime. datetime object is returned."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncleaning the content of a post.", "response": "def _clean_post_content(blog_url, content):\n    \"\"\"\n    Replace import path with something relative to blog.\n    \"\"\"\n\n    content = re.sub(\n        \"<img.src=\\\"%s(.*)\\\"\" % blog_url,\n        lambda s: \"<img src=\\\"%s\\\"\" % _get_relative_upload(s.groups(1)[0]),\n        content)\n\n    return content"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, key, default=None):\n        segments = key.split('.')\n        result = reduce(\n            lambda dct, k: dct and dct.get(k) or None,\n            segments, self.data)\n\n        return result or default", "response": "u\"\"\"\n        \u0412\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0441 \u0443\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u043c \u043a\u043b\u044e\u0447\u0435\u043c\n\n        \u041f\u0440\u0438\u043c\u0435\u0440 \u0432\u044b\u0437\u043e\u0432\u0430:\n        value = self.get('system.database.name')\n\n        :param key: \u0418\u043c\u044f \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\n        :param default: \u0417\u043d\u0430\u0447\u0435\u043d\u0438\u0435, \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u043c\u043e\u0435 \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e\n        :return: mixed"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_converted(self, key, conversion_type, default=None):\n        # \u0412 \u0441\u043b\u0443\u0447\u0430\u0435 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0438\u044f \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430 \u0441\u0440\u0430\u0437\u0443 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e\n        if not self.has_param(key):\n            return default\n\n        value = self.get(key, default=default)\n        handler = self.conversion_handler(conversion_type)\n\n        try:\n            value = handler(value)\n        except Exception as exc:\n            raise ConversionTypeError((\n                u'\u041f\u0440\u043e\u0438\u0437\u043e\u0448\u043b\u0430 \u043e\u0448\u0438\u0431\u043a\u0430 \u043f\u0440\u0438 \u043f\u043e\u043f\u044b\u0442\u043a\u0435 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0442\u0438\u043f\u0430: {}'\n            ).format(exc))\n\n        return value", "response": "u Returns a mixed version of the key converted to the conversion_type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_by_type(self, key, conversion_func, default=None):\n        if not self.has_param(key):\n            return default\n\n        value = self.get(key, default=default)\n\n        try:\n            value = conversion_func(value)\n        except Exception as exc:\n            raise ConversionTypeError((\n                u'\u041f\u0440\u043e\u0438\u0437\u043e\u0448\u043b\u0430 \u043e\u0448\u0438\u0431\u043a\u0430 \u043f\u0440\u0438 \u043f\u043e\u043f\u044b\u0442\u043a\u0435 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0442\u0438\u043f\u0430: {}'\n            ).format(exc))\n\n        return value", "response": "u Returns a mixed object of type conversion_func."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_bool(self, key, default=None):\n        return self.get_converted(\n            key, ConversionTypeEnum.BOOL, default=default)", "response": "u Returns the bool value corresponding to the given key."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _queue(self, kwargs):\n    if not 'hard resource_list' in kwargs: return 'all.q'\n    d = dict([k.split('=') for k in kwargs['hard resource_list'].split(',')])\n    for k in d:\n      if k[0] == 'q' and d[k] == 'TRUE': return k\n    return 'all.q'", "response": "This function is used to extract the queue name from the hard resource_list keyword argument."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsubmit a job to the grid.", "response": "def submit(self, command_line, name = None, array = None, dependencies = [], exec_dir = None, log_dir = \"logs\", dry_run = False, verbosity = 0, stop_on_failure = False, **kwargs):\n    \"\"\"Submits a job that will be executed in the grid.\"\"\"\n    # add job to database\n    self.lock()\n    job = add_job(self.session, command_line, name, dependencies, array, exec_dir=exec_dir, log_dir=log_dir, stop_on_failure=stop_on_failure, context=self.context, **kwargs)\n    logger.info(\"Added job '%s' to the database.\" % job)\n    if dry_run:\n      print(\"Would have added the Job\")\n      print(job)\n      print(\"to the database to be executed in the grid with options:\", str(kwargs))\n      self.session.delete(job)\n      logger.info(\"Deleted job '%s' from the database due to dry-run option\" % job)\n      job_id = None\n\n    else:\n      job_id = self._submit_to_grid(job, name, array, dependencies, log_dir, verbosity, **kwargs)\n\n    self.session.commit()\n    self.unlock()\n\n    return job_id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncommunicating with the SGE grid using qstat to see if jobs are still running.", "response": "def communicate(self, job_ids = None):\n    \"\"\"Communicates with the SGE grid (using qstat) to see if jobs are still running.\"\"\"\n    self.lock()\n    # iterate over all jobs\n    jobs = self.get_jobs(job_ids)\n    for job in jobs:\n      job.refresh()\n      if job.status in ('queued', 'executing', 'waiting') and job.queue_name != 'local':\n        status = qstat(job.id, context=self.context)\n        if len(status) == 0:\n          job.status = 'failure'\n          job.result = 70 # ASCII: 'F'\n          logger.warn(\"The job '%s' was not executed successfully (maybe a time-out happened). Please check the log files.\" % job)\n          for array_job in job.array:\n            if array_job.status in ('queued', 'executing'):\n              array_job.status = 'failure'\n              array_job.result = 70 # ASCII: 'F'\n\n\n    self.session.commit()\n    self.unlock()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resubmit(self, job_ids = None, also_success = False, running_jobs = False, new_command=None, verbosity=0, keep_logs=False, **kwargs):\n    self.lock()\n    # iterate over all jobs\n    jobs = self.get_jobs(job_ids)\n    if new_command is not None:\n      if len(jobs) == 1:\n        jobs[0].set_command_line(new_command)\n      else:\n        logger.warn(\"Ignoring new command since no single job id was specified\")\n    accepted_old_status = ('submitted', 'success', 'failure') if also_success else ('submitted', 'failure',)\n    for job in jobs:\n      # check if this job needs re-submission\n      if running_jobs or job.status in accepted_old_status:\n        grid_status = qstat(job.id, context=self.context)\n        if len(grid_status) != 0:\n          logger.warn(\"Deleting job '%d' since it was still running in the grid.\" % job.unique)\n          qdel(job.id, context=self.context)\n        # re-submit job to the grid\n        arguments = job.get_arguments()\n        arguments.update(**kwargs)\n        if ('queue' not in arguments or arguments['queue'] == 'all.q'):\n          for arg in ('hvmem', 'pe_opt', 'io_big'):\n            if arg in arguments:\n              del arguments[arg]\n        job.set_arguments(kwargs=arguments)\n        # delete old status and result of the job\n        if not keep_logs:\n          self.delete_logs(job)\n        job.submit()\n        if job.queue_name == 'local' and 'queue' not in arguments:\n          logger.warn(\"Re-submitting job '%s' locally (since no queue name is specified).\" % job)\n        else:\n          deps = [dep.unique for dep in job.get_jobs_we_wait_for()]\n          logger.debug(\"Re-submitting job '%s' with dependencies '%s' to the grid.\" % (job, deps))\n          self._submit_to_grid(job, job.name, job.get_array(), deps, job.log_dir, verbosity, **arguments)\n\n        # commit after each job to avoid failures of not finding the job during execution in the grid\n        self.session.commit()\n    self.unlock()", "response": "Resubmit jobs to the grid."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_job(self, job_id, array_id = None):\n    # get the unique job id from the given grid id\n    self.lock()\n    jobs = list(self.session.query(Job).filter(Job.id == job_id))\n    if len(jobs) != 1:\n      self.unlock()\n      raise ValueError(\"Could not find job id '%d' in the database'\" % job_id)\n    job_id = jobs[0].unique\n    self.unlock()\n    # call base class implementation with the corrected job id\n    return JobManager.run_job(self, job_id, array_id)", "response": "Overwrites the run - job command from the manager to extract the correct job id before calling base class implementation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstops the jobs in the grid.", "response": "def stop_jobs(self, job_ids):\n    \"\"\"Stops the jobs in the grid.\"\"\"\n    self.lock()\n\n    jobs = self.get_jobs(job_ids)\n    for job in jobs:\n      if job.status in ('executing', 'queued', 'waiting'):\n        qdel(job.id, context=self.context)\n        logger.info(\"Stopped job '%s' in the SGE grid.\" % job)\n        job.submit()\n\n      self.session.commit()\n    self.unlock()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef encrypt(self, pubkey: str, nonce: Union[str, bytes], text: Union[str, bytes]) -> str:\n        text_bytes = ensure_bytes(text)\n        nonce_bytes = ensure_bytes(nonce)\n        recipient_pubkey = PublicKey(pubkey)\n        crypt_bytes = libnacl.public.Box(self, recipient_pubkey).encrypt(text_bytes, nonce_bytes)\n        return Base58Encoder.encode(crypt_bytes[24:])", "response": "Encrypt the message with the public key of the recipient and a nonce."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decrypt(self, pubkey: str, nonce: Union[str, bytes], text: str) -> str:\n        sender_pubkey = PublicKey(pubkey)\n        nonce_bytes = ensure_bytes(nonce)\n        encrypt_bytes = Base58Encoder.decode(text)\n        decrypt_bytes = libnacl.public.Box(self, sender_pubkey).decrypt(encrypt_bytes, nonce_bytes)\n        return decrypt_bytes.decode('utf-8')", "response": "Decrypt encrypted message text with recipient public key and the unique nonce used by the sender."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nencrypt data with a curve25519 version of the ed25519 public key", "response": "def encrypt_seal(self, data: Union[str, bytes]) -> bytes:\n        \"\"\"\n        Encrypt data with a curve25519 version of the ed25519 public key\n\n        :param data: Bytes data to encrypt\n        \"\"\"\n        curve25519_public_key = libnacl.crypto_sign_ed25519_pk_to_curve25519(self.pk)\n        return libnacl.crypto_box_seal(ensure_bytes(data), curve25519_public_key)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\noverride the default emails already defined by other apps", "response": "def override_default_templates(self):\n        \"\"\"\n        Override the default emails already defined by other apps\n        \"\"\"\n        if plugs_mail_settings['OVERRIDE_TEMPLATE_DIR']:\n            dir_ = plugs_mail_settings['OVERRIDE_TEMPLATE_DIR']\n            for file_ in os.listdir(dir_):\n                if file_.endswith(('.html', 'txt')):\n                    self.overrides[file_] = dir_"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the list of installed apps and return the list of emails that have", "response": "def get_apps(self):\n        \"\"\"\n        Get the list of installed apps\n        and return the apps that have\n        an emails module\n        \"\"\"\n        templates = []\n        for app in settings.INSTALLED_APPS:\n            try:\n                app = import_module(app + '.emails')\n                templates += self.get_plugs_mail_classes(app)\n            except ImportError:\n                pass\n        return templates"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_template_files(self, location, class_name):\n        template_name = utils.camel_to_snake(class_name)\n        dir_ = location[:-9] + 'templates/emails/'\n        files_ = []\n        for file_ in self.get_templates_files_in_dir(dir_):\n            if file_.startswith(template_name) and file_.endswith(('.html', '.txt')):\n                if file_ in self.overrides:\n                    files_.append(self.overrides[file_] + file_)\n                else:\n                    files_.append(dir_ + file_)\n        return files_", "response": "Returns a list of all the template files that match the class name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_plugs_mail_classes(self, app):\n        classes = []\n        members = self.get_members(app)\n        for member in members:\n            name, cls = member\n            if inspect.isclass(cls) and issubclass(cls, PlugsMail) and name != 'PlugsMail':\n                files_ = self.get_template_files(app.__file__, name)\n                for file_ in files_:\n                    try:\n                        description = cls.description\n                        location = file_\n                        language = self.get_template_language(location)\n                        classes.append((name, location, description, language))\n                    except AttributeError:\n                        raise AttributeError('Email class must specify email description.')\n        return classes", "response": "Returns a list of tuples but it should\n        return a list of dicts"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the language code of the template file.", "response": "def get_template_language(self, file_):\n        \"\"\"\n        Return the template language\n        Every template file must end in\n        with the language code, and the\n        code must match the ISO_6301 lang code\n        https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes\n        valid examples:\n\n        account_created_pt.html\n        payment_created_en.txt\n        \"\"\"\n        stem = Path(file_).stem\n        language_code = stem.split('_')[-1:][0]\n        if len(language_code) != 2:\n            # TODO naive and temp implementation\n            # check if the two chars correspond to one of the\n            # available languages\n            raise Exception('Template file `%s` must end in ISO_639-1 language code.' % file_)\n        return language_code.lower()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the subject from the first line of the email template.", "response": "def get_subject(self, text):\n        \"\"\"\n        Email template subject is the first\n        line of the email template, we can optionally\n        add SUBJECT: to make it clearer\n        \"\"\"\n        first_line = text.splitlines(True)[0]\n        # TODO second line should be empty\n        if first_line.startswith('SUBJECT:'):\n            subject = first_line[len('SUBJECT:'):]\n        else:\n            subject = first_line\n        return subject.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_templates(self, templates):\n        count = 0\n        for template in templates:\n            if not self.template_exists_db(template):\n                name, location, description, language = template\n                text = self.open_file(location)\n                html_content = self.get_html_content(text)\n                data = {\n                    'name': utils.camel_to_snake(name).upper(),\n                    'html_content': html_content,\n                    'content': self.text_version(html_content),\n                    'subject': self.get_subject(text),\n                    'description': description,\n                    'language': language\n                }\n                if models.EmailTemplate.objects.create(**data):\n                    count += 1\n        return count", "response": "Creates a list of templates in the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a file and returns the contents of the file", "response": "def open_file(self, file_):\n        \"\"\"\n        Receives a file path has input and returns a\n        string with the contents of the file\n        \"\"\"\n        with open(file_, 'r', encoding='utf-8') as file:\n            text = ''\n            for line in file:\n                text += line\n        return text"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef template_exists_db(self, template):\n        name = utils.camel_to_snake(template[0]).upper()\n        language = utils.camel_to_snake(template[3])\n        try:\n            models.EmailTemplate.objects.get(name=name, language=language)\n        except models.EmailTemplate.DoesNotExist:\n            return False\n        return True", "response": "Checks if a template exists in the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall the invalidate_caches method on all path entry finders stored in sys. path_importer_caches.", "response": "def invalidate_caches(cls):\n        \"\"\"Call the invalidate_caches() method on all path entry finders\n        stored in sys.path_importer_caches (where implemented).\"\"\"\n        for finder in sys.path_importer_cache.values():\n            if hasattr(finder, 'invalidate_caches'):\n                finder.invalidate_caches()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching sys. path_hooks for a finder for path.", "response": "def _path_hooks(cls, path):  # from importlib.PathFinder\n        \"\"\"Search sys.path_hooks for a finder for 'path'.\"\"\"\n        if sys.path_hooks is not None and not sys.path_hooks:\n            warnings.warn('sys.path_hooks is empty', ImportWarning)\n        for hook in sys.path_hooks:\n            try:\n                return hook(path)\n            except ImportError:\n                continue\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _path_importer_cache(cls, path):  # from importlib.PathFinder\n        if path == '':\n            try:\n                path = os.getcwd()\n            except FileNotFoundError:\n                # Don't cache the failure as the cwd can easily change to\n                # a valid directory later on.\n                return None\n        try:\n            finder = sys.path_importer_cache[path]\n        except KeyError:\n            finder = cls._path_hooks(path)\n            sys.path_importer_cache[path] = finder\n\n        return finder", "response": "Get the finder for the path entry from sys. path_importer_cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_spec(cls, fullname, path, target=None):\n        # If this ends up being a namespace package, namespace_path is\n        #  the list of paths that will become its __path__\n        namespace_path = []\n        for entry in path:\n            if not isinstance(entry, (str, bytes)):\n                continue\n            finder = cls._path_importer_cache(entry)\n            if finder is not None:\n                if hasattr(finder, 'find_spec'):\n                    spec = finder.find_spec(fullname, target)\n                else:\n                    spec = cls._legacy_get_spec(fullname, finder)\n                if spec is None:\n                    continue\n                if spec.loader is not None:\n                    return spec\n                portions = spec.submodule_search_locations\n                if portions is None:\n                    raise ImportError('spec missing loader')\n                # This is possibly part of a namespace package.\n                #  Remember these path entries (if any) for when we\n                #  create a namespace package, and continue iterating\n                #  on path.\n                namespace_path.extend(portions)\n        else:\n            spec = ModuleSpec(fullname, None)\n            spec.submodule_search_locations = namespace_path\n            return spec", "response": "Find the loader or namespace_path for this module name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_module(cls, fullname, path=None):\n        spec = cls.find_spec(fullname, path)\n        if spec is None:\n            return None\n        elif spec.loader is None and spec.submodule_search_locations:\n            # Here we need to create a namespace loader to handle namespaces since python2 doesn't...\n            return NamespaceLoader2(spec.name, spec.submodule_search_locations)\n        else:\n            return spec.loader", "response": "find the module on sys. path or path based on sys. path_hooks and\n        sys. path_importer_cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds the module on sys. path or sys. path_hooks and . path_importer_cache.", "response": "def find_spec(cls, fullname, path=None, target=None):\n        \"\"\"find the module on sys.path or 'path' based on sys.path_hooks and\n        sys.path_importer_cache.\"\"\"\n        if path is None:\n            path = sys.path\n        spec = cls._get_spec(fullname, path, target)\n        if spec is None:\n            return None\n        elif spec.loader is None:\n            namespace_path = spec.submodule_search_locations\n            if namespace_path:\n                # We found at least one namespace path.  Return a\n                #  spec which can create the namespace package.\n                spec.origin = 'namespace'\n                spec.submodule_search_locations = _NamespacePath(fullname, namespace_path, cls._get_spec)\n                return spec\n            else:\n                return None\n        else:\n            return spec"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntrying to find a spec for the specified module. Returns the matching spec or None if not found.", "response": "def find_spec(self, fullname, target=None):\n        \"\"\"Try to find a spec for the specified module.  Returns the\n        matching spec, or None if not found.\"\"\"\n        is_namespace = False\n        tail_module = fullname.rpartition('.')[2]\n\n        base_path = os.path.join(self.path, tail_module)\n        for suffix, loader_class in self._loaders:\n            init_filename = '__init__' + suffix\n            init_full_path = os.path.join(base_path, init_filename)\n            full_path = base_path + suffix\n            if os.path.isfile(init_full_path):\n                return self._get_spec(loader_class, fullname, init_full_path, [base_path], target)\n            if os.path.isfile(full_path):  # maybe we need more checks here (importlib filefinder checks its cache...)\n                return self._get_spec(loader_class, fullname, full_path, None, target)\n        else:\n            # If a namespace package, return the path if we don't\n            #  find a module in the next section.\n            is_namespace = os.path.isdir(base_path)\n\n        if is_namespace:\n            _verbose_message('possible namespace for {}'.format(base_path))\n            spec = ModuleSpec(fullname, None)\n            spec.submodule_search_locations = [base_path]\n            return spec\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to find a loader for the specified module or the namespace package portions. Returns None if no loader is found. Returns list - of - portions.", "response": "def find_loader(self, fullname):\n        \"\"\"Try to find a loader for the specified module, or the namespace\n        package portions. Returns (loader, list-of-portions).\n        This method is deprecated.  Use find_spec() instead.\n        \"\"\"\n        spec = self.find_spec(fullname)\n        if spec is None:\n            return None, []\n        return spec.loader, spec.submodule_search_locations or []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_module(self, fullname):\n\n        spec = self.find_spec(fullname)\n        if spec is None:\n            return None\n\n        # We need to handle the namespace case here for python2\n        if spec.loader is None and len(spec.submodule_search_locations):\n            spec.loader = NamespaceLoader2(spec.name, spec.submodule_search_locations)\n\n        return spec.loader", "response": "Try to find a loader for the specified module or the namespace\n        package portions. Returns None if no loader is found."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef t_IDENTIFIER(t):\n  r\"[A-Z_a-z][0-9A-Z_a-z]*\"\n  if t.value in keywords:\n    t.type = t.value\n  return t", "response": "r A identifier is a reserved word."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a unique ID for a specific type of object.", "response": "def getid(self, idtype):\n        '''\n        idtype in Uniq constants\n        '''\n        memorable_id = None\n        while memorable_id in self._ids:\n            l=[]\n            for _ in range(4):\n                l.append(str(randint(0, 19)))\n            memorable_id = ''.join(l)\n        self._ids.append(memorable_id)\n        return idtype + '-' + memorable_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dead(self):\n        if not self._weak:\n            return False\n        cb = self._callback()\n        if cb is None:\n            return True\n        return False", "response": "Whether the callback no longer exists."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_equivalent(self, callback, details_filter=None):\n        cb = self.callback\n        if cb is None and callback is not None:\n            return False\n        if cb is not None and callback is None:\n            return False\n        if cb is not None and callback is not None \\\n           and not reflection.is_same_callback(cb, callback):\n            return False\n        if details_filter is not None:\n            if self._details_filter is None:\n                return False\n            else:\n                return reflection.is_same_callback(self._details_filter,\n                                                   details_filter)\n        else:\n            return self._details_filter is None", "response": "Check if the callback used for comparison is the same as the internal one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if a callback was registered to", "response": "def is_registered(self, event_type, callback, details_filter=None):\n        \"\"\"Check if a callback is registered.\n\n        :param event_type: event type callback was registered to\n        :param callback: callback that was used during registration\n        :param details_filter: details filter that was used during\n                               registration\n\n        :returns: if the callback is registered\n        :rtype: boolean\n        \"\"\"\n        listeners = self._topics.get(event_type, [])\n        for listener in listeners:\n            if listener.is_equivalent(callback, details_filter=details_filter):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls into listeners handling failures and logging as needed.", "response": "def _do_dispatch(self, listeners, event_type, details):\n        \"\"\"Calls into listeners, handling failures and logging as needed.\"\"\"\n        possible_calls = len(listeners)\n        call_failures = 0\n        for listener in listeners:\n            try:\n                listener(event_type, details.copy())\n            except Exception:\n                self._logger.warn(\n                    \"Failure calling listener %s to notify about event\"\n                    \" %s, details: %s\", listener, event_type, details,\n                    exc_info=True)\n                call_failures += 1\n        return _Notified(possible_calls,\n                         possible_calls - call_failures,\n                         call_failures)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef notify(self, event_type, details):\n        if not self.can_trigger_notification(event_type):\n            raise ValueError(\"Event type '%s' is not allowed to trigger\"\n                             \" notifications\" % event_type)\n        listeners = list(self._topics.get(self.ANY, []))\n        listeners.extend(self._topics.get(event_type, []))\n        if not details:\n            details = {}\n        fut = self._executor.submit(self._do_dispatch, listeners,\n                                    event_type, details)\n        return fut", "response": "Notify about an event occurrence."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register(self, event_type, callback,\n                 args=None, kwargs=None, details_filter=None,\n                 weak=False):\n        \"\"\"Register a callback to be called when event of a given type occurs.\n\n        Callback will be called with provided ``args`` and ``kwargs`` and\n        when event type occurs (or on any event if ``event_type`` equals to\n        :attr:`.ANY`). It will also get additional keyword argument,\n        ``details``, that will hold event details provided to the\n        :meth:`.notify` method (if a details filter callback is provided then\n        the target callback will *only* be triggered if the details filter\n        callback returns a truthy value).\n\n        :param event_type: event type to get triggered on\n        :param callback: function callback to be registered.\n        :param args: non-keyworded arguments\n        :type args: list\n        :param kwargs: key-value pair arguments\n        :type kwargs: dictionary\n        :param weak: if the callback retained should be referenced via\n                     a weak reference or a strong reference (defaults to\n                     holding a strong reference)\n        :type weak: bool\n\n        :returns: the listener that was registered\n        :rtype: :py:class:`~.Listener`\n        \"\"\"\n        if not six.callable(callback):\n            raise ValueError(\"Event callback must be callable\")\n        if details_filter is not None:\n            if not six.callable(details_filter):\n                raise ValueError(\"Details filter must be callable\")\n        if not self.can_be_registered(event_type):\n            raise ValueError(\"Disallowed event type '%s' can not have a\"\n                             \" callback registered\" % event_type)\n        if kwargs:\n            for k in self.RESERVED_KEYS:\n                if k in kwargs:\n                    raise KeyError(\"Reserved key '%s' not allowed in \"\n                                   \"kwargs\" % k)\n        with self._lock:\n            if self.is_registered(event_type, callback,\n                                  details_filter=details_filter):\n                raise ValueError(\"Event callback already registered with\"\n                                 \" equivalent details filter\")\n            listener = Listener(_make_ref(callback, weak=weak),\n                                args=args, kwargs=kwargs,\n                                details_filter=details_filter,\n                                weak=weak)\n            listeners = self._topics.setdefault(event_type, [])\n            listeners.append(listener)\n            return listener", "response": "Register a callback to be called when an event occurs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove a single listener bound to event_type.", "response": "def deregister(self, event_type, callback, details_filter=None):\n        \"\"\"Remove a single listener bound to event ``event_type``.\n\n        :param event_type: deregister listener bound to event_type\n        :param callback: callback that was used during registration\n        :param details_filter: details filter that was used during\n                               registration\n\n        :returns: if a listener was deregistered\n        :rtype: boolean\n        \"\"\"\n        with self._lock:\n            listeners = self._topics.get(event_type, [])\n            for i, listener in enumerate(listeners):\n                if listener.is_equivalent(callback,\n                                          details_filter=details_filter):\n                    listeners.pop(i)\n                    return True\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving a single listener bound to event_type with uuid uuid.", "response": "def deregister_by_uuid(self, event_type, uuid):\n        \"\"\"Remove a single listener bound to event ``event_type``.\n\n        :param event_type: deregister listener bound to event_type\n        :param uuid: uuid of listener to remove\n\n        :returns: if the listener was deregistered\n        :rtype: boolean\n        \"\"\"\n        with self._lock:\n            listeners = self._topics.get(event_type, [])\n            for i, listener in enumerate(listeners):\n                if listener.uuid == uuid:\n                    listeners.pop(i)\n                    return True\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nclones this notifier and its bound listeners.", "response": "def copy(self):\n        \"\"\"Clones this notifier (and its bound listeners).\"\"\"\n        c = copy.copy(self)\n        c._topics = {}\n        c._lock = threading.Lock()\n        topics = set(six.iterkeys(self._topics))\n        while topics:\n            event_type = topics.pop()\n            try:\n                listeners = self._topics[event_type]\n                c._topics[event_type] = list(listeners)\n            except KeyError:\n                pass\n        return c"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef listeners_iter(self):\n        topics = set(six.iterkeys(self._topics))\n        while topics:\n            event_type = topics.pop()\n            try:\n                yield event_type, self._topics[event_type]\n            except KeyError:\n                pass", "response": "Return an iterator over the mapping of event => listeners bound."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef can_be_registered(self, event_type):\n        return (event_type in self._watchable_events or\n                (event_type == self.ANY and self._allow_any))", "response": "Checks if the event can be registered to.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread one or more text files and returns them joined together.", "response": "def read_local_files(*file_paths: str) -> str:\n    \"\"\"\n    Reads one or more text files and returns them joined together.\n    A title is automatically created based on the file name.\n\n    Args:\n        *file_paths: list of files to aggregate\n\n    Returns: content of files\n    \"\"\"\n\n    def _read_single_file(file_path):\n        with open(file_path) as f:\n            filename = os.path.splitext(file_path)[0]\n            title = f'{filename}\\n{\"=\" * len(filename)}'\n            return '\\n\\n'.join((title, f.read()))\n\n    return '\\n' + '\\n\\n'.join(map(_read_single_file, file_paths))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a file a utf - 8 file and returns a list of character tokens.", "response": "def _readfile(cls, filename):\n        \"\"\" Reads a file a utf-8 file,\n            and retuns character tokens.\n\n            :param filename: Name of file to be read.\n        \"\"\"\n        f = codecs.open(filename, encoding='utf-8')\n        filedata = f.read()\n        f.close()\n        tokenz = LM.tokenize(filedata, mode='c')\n        #print tokenz\n        return tokenz"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntraining our language model.", "response": "def train(self, root=''):\n        \"\"\" Trains our Language Model.\n\n            :param root: Path to training data.\n        \"\"\"\n\n        self.trainer = Train(root=root)\n        corpus = self.trainer.get_corpus()\n\n        # Show loaded Languages\n        #print 'Lang Set: ' + ' '.join(train.get_lang_set())\n\n        for item in corpus:\n            self.lm.add_doc(doc_id=item[0], doc_terms=self._readfile(item[1]))\n\n        # Save training timestamp\n        self.training_timestamp = self.trainer.get_last_modified()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if training data was modified since last training.", "response": "def is_training_modified(self):\n        \"\"\" Returns `True` if training data\n            was modified since last training.\n            Returns `False` otherwise,\n            or if using builtin training data.\n        \"\"\"\n\n        last_modified = self.trainer.get_last_modified()\n        if last_modified > self.training_timestamp:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_training_sample(self, text=u'', lang=''):\n        self.trainer.add(text=text, lang=lang)", "response": "Add a new sample to training data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave training samples in the specified domain.", "response": "def save_training_samples(self, domain='', filename=''):\n        \"\"\" Saves data previously added via add_training_sample().\n            Data saved in folder specified by Train.get_corpus_path().\n\n            :param domain: Name for domain folder.\n                           If not set, current timestamp will be used.\n            :param filename: Name for file to save data in.\n                             If not set, file.txt will be used.\n\n            Check the README file for more information about Domains.\n        \"\"\"\n        self.trainer.save(domain=domain, filename=filename)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef classify(self, text=u''):\n\n        text = self.lm.normalize(text)\n        tokenz = LM.tokenize(text, mode='c')\n        result = self.lm.calculate(doc_terms=tokenz)\n        #print 'Karbasa:', self.karbasa(result)\n        if self.unk and self.lm.karbasa(result) < self.min_karbasa:\n            lang = 'unk'\n        else:\n            lang = result['calc_id']\n        return lang", "response": "Predicts the Language of a given Unicode text."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exists(c_table_cd: str, tables: I2B2Tables) -> int:\n        conn = tables.ont_connection\n        table = tables.schemes\n        return bool(list(conn.execute(table.select().where(table.c.c_table_cd == c_table_cd))))", "response": "Return the number of records that exist with the table code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef del_records(c_table_cd: str, tables: I2B2Tables) -> int:\n        conn = tables.ont_connection\n        table = tables.schemes\n        return conn.execute(table.delete().where(table.c.c_table_cd == c_table_cd)).rowcount", "response": "Delete all records with c_table_code\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a config file into. ini format and return dict of shares.", "response": "def read_config(filename=None):\n    \"\"\"\n    Read a config filename into .ini format and return dict of shares.\n\n    Keyword arguments:\n    filename -- the path of config filename (default None)\n\n    Return dict.\n    \"\"\"\n    if not os.path.exists(filename):\n        raise IOError('Impossibile trovare il filename %s' % filename)\n    shares = []\n    config = ConfigParser()\n    config.read(filename)\n    for share_items in [config.items(share_title) for share_title in\n                        config.sections()]:\n        dict_share = {}\n        for key, value in share_items:\n            if key == 'hostname' and '@' in value:\n                hostname, credentials = (item[::-1] for item\n                                         in value[::-1].split('@', 1))\n                dict_share.update({key: hostname})\n                credentials = tuple(cred.lstrip('\"').rstrip('\"')\n                                    for cred in credentials.split(':', 1))\n                dict_share.update({'username': credentials[0]})\n                if len(credentials) > 1:\n                    dict_share.update({'password': credentials[1]})\n                continue\n            dict_share.update({key: value})\n        shares.append(dict_share)\n    return shares"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a blocking session object to the database.", "response": "def lock(self):\n    \"\"\"Generates (and returns) a blocking session object to the database.\"\"\"\n    if hasattr(self, 'session'):\n      raise RuntimeError('Dead lock detected. Please do not try to lock the session when it is already locked!')\n\n    if LooseVersion(sqlalchemy.__version__) < LooseVersion('0.7.8'):\n      # for old sqlalchemy versions, in some cases it is required to re-generate the engine for each session\n      self._engine = sqlalchemy.create_engine(\"sqlite:///\"+self._database)\n      self._session_maker = sqlalchemy.orm.sessionmaker(bind=self._engine)\n\n    # create the database if it does not exist yet\n    if not os.path.exists(self._database):\n      self._create()\n\n    # now, create a session\n    self.session = self._session_maker()\n    logger.debug(\"Created new database session to '%s'\" % self._database)\n    return self.session"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncloses the session to the database.", "response": "def unlock(self):\n    \"\"\"Closes the session to the database.\"\"\"\n    if not hasattr(self, 'session'):\n      raise RuntimeError('Error detected! The session that you want to close does not exist any more!')\n    logger.debug(\"Closed database session of '%s'\" % self._database)\n    self.session.close()\n    del self.session"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new and empty database.", "response": "def _create(self):\n    \"\"\"Creates a new and empty database.\"\"\"\n    from .tools import makedirs_safe\n\n    # create directory for sql database\n    makedirs_safe(os.path.dirname(self._database))\n\n    # create all the tables\n    Base.metadata.create_all(self._engine)\n    logger.debug(\"Created new empty database '%s'\" % self._database)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_jobs(self, job_ids = None):\n    if job_ids is not None and len(job_ids) == 0:\n      return []\n    q = self.session.query(Job)\n    if job_ids is not None:\n      q = q.filter(Job.unique.in_(job_ids))\n    return sorted(list(q), key=lambda job: job.unique)", "response": "Returns a list of jobs that are stored in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_job(self, job_id, array_id = None):\n    # set the job's status in the database\n    try:\n      # get the job from the database\n      self.lock()\n      jobs = self.get_jobs((job_id,))\n      if not len(jobs):\n        # it seems that the job has been deleted in the meanwhile\n        return\n      job = jobs[0]\n\n      # get the machine name we are executing on; this might only work at idiap\n      machine_name = socket.gethostname()\n\n      # set the 'executing' status to the job\n      job.execute(array_id, machine_name)\n\n      self.session.commit()\n    except Exception as e:\n      logger.error(\"Caught exception '%s'\", e)\n      pass\n    finally:\n      self.unlock()\n\n    # get the command line of the job from the database; does not need write access\n    self.lock()\n    job = self.get_jobs((job_id,))[0]\n    command_line = job.get_command_line()\n    exec_dir = job.get_exec_dir()\n    self.unlock()\n\n    logger.info(\"Starting job %d: %s\", job_id, \" \".join(command_line))\n\n    # execute the command line of the job, and wait until it has finished\n    try:\n      result = subprocess.call(command_line, cwd=exec_dir)\n      logger.info(\"Job %d finished with result %s\", job_id, str(result))\n    except Exception as e:\n      logger.error(\"The job with id '%d' could not be executed: %s\", job_id, e)\n      result = 69 # ASCII: 'E'\n\n    # set a new status and the results of the job\n    try:\n      self.lock()\n      jobs = self.get_jobs((job_id,))\n      if not len(jobs):\n        # it seems that the job has been deleted in the meanwhile\n        logger.error(\"The job with id '%d' could not be found in the database!\", job_id)\n        self.unlock()\n        return\n\n      job = jobs[0]\n      job.finish(result, array_id)\n\n      self.session.commit()\n\n      # This might not be working properly, so use with care!\n      if job.stop_on_failure and job.status == 'failure':\n        # the job has failed\n        # stop this and all dependent jobs from execution\n        dependent_jobs = job.get_jobs_waiting_for_us()\n        dependent_job_ids = set([dep.unique for dep in dependent_jobs] + [job.unique])\n        while len(dependent_jobs):\n          dep = dependent_jobs.pop(0)\n          new = dep.get_jobs_waiting_for_us()\n          dependent_jobs += new\n          dependent_job_ids.update([dep.unique for dep in new])\n\n        self.unlock()\n        deps = sorted(list(dependent_job_ids))\n        self.stop_jobs(deps)\n        logger.warn (\"Stopped dependent jobs '%s' since this job failed.\", str(deps))\n\n    except Exception as e:\n      logger.error(\"Caught exception '%s'\", e)\n      pass\n    finally:\n      if hasattr(self, 'session'):\n        self.unlock()", "response": "This function is called to run a job in the grid. It is called by the job manager to run the job with the given id and the given array index if applicable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list(self, job_ids, print_array_jobs = False, print_dependencies = False, long = False, print_times = False, status=Status, names=None, ids_only=False):\n    # configuration for jobs\n    fields = (\"job-id\", \"grid-id\", \"queue\", \"status\", \"job-name\")\n    lengths = (6, 17, 11, 12, 16)\n    dependency_length = 0\n\n    if print_dependencies:\n      fields += (\"dependencies\",)\n      lengths += (25,)\n      dependency_length = lengths[-1]\n\n    if long:\n      fields += (\"submitted command\",)\n      lengths += (43,)\n\n    format = \"{:^%d}  \" * len(lengths)\n    format = format % lengths\n\n    # if ids_only:\n    #   self.lock()\n    #   for job in self.get_jobs():\n    #     print(job.unique, end=\" \")\n    #   self.unlock()\n    #   return\n\n    array_format = \"{0:^%d}  {1:>%d}  {2:^%d}  {3:^%d}\" % lengths[:4]\n    delimiter = format.format(*['='*k for k in lengths])\n    array_delimiter = array_format.format(*[\"-\"*k for k in lengths[:4]])\n    header = [fields[k].center(lengths[k]) for k in range(len(lengths))]\n\n    # print header\n    if not ids_only:\n      print('  '.join(header))\n      print(delimiter)\n\n    self.lock()\n    for job in self.get_jobs(job_ids):\n      job.refresh()\n      if job.status in status and (names is None or job.name in names):\n        if ids_only:\n          print(job.unique, end=\" \")\n        else:\n          print(job.format(format, dependency_length))\n        if print_times:\n          print(times(job))\n\n        if (not ids_only) and print_array_jobs and job.array:\n          print(array_delimiter)\n          for array_job in job.array:\n            if array_job.status in status:\n              print(array_job.format(array_format))\n              if print_times:\n                print(times(array_job))\n          print(array_delimiter)\n\n    self.unlock()", "response": "Lists the jobs currently added to the database."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef report(self, job_ids=None, array_ids=None, output=True, error=True, status=Status, name=None):\n    def _write_contents(job):\n      # Writes the contents of the output and error files to command line\n      out_file, err_file = job.std_out_file(), job.std_err_file()\n      logger.info(\"Contents of output file: '%s'\" % out_file)\n      if output and out_file is not None and os.path.exists(out_file) and os.stat(out_file).st_size > 0:\n        print(open(out_file).read().rstrip())\n        print(\"-\"*20)\n      if error and err_file is not None and os.path.exists(err_file) and os.stat(err_file).st_size > 0:\n        logger.info(\"Contents of error file: '%s'\" % err_file)\n        print(open(err_file).read().rstrip())\n        print(\"-\"*40)\n\n    def _write_array_jobs(array_jobs):\n      for array_job in array_jobs:\n        print(\"Array Job\", str(array_job.id), (\"(%s) :\"%array_job.machine_name if array_job.machine_name is not None else \":\"))\n        _write_contents(array_job)\n\n    self.lock()\n\n    # check if an array job should be reported\n    if array_ids:\n      if len(job_ids) != 1: logger.error(\"If array ids are specified exactly one job id must be given.\")\n      array_jobs = list(self.session.query(ArrayJob).join(Job).filter(Job.unique.in_(job_ids)).filter(Job.unique == ArrayJob.job_id).filter(ArrayJob.id.in_(array_ids)))\n      if array_jobs: print(array_jobs[0].job)\n      _write_array_jobs(array_jobs)\n\n    else:\n      # iterate over all jobs\n      jobs = self.get_jobs(job_ids)\n      for job in jobs:\n        if name is not None and job.name != name:\n          continue\n        if job.status not in status:\n          continue\n        if job.array:\n          print(job)\n          _write_array_jobs(job.array)\n        else:\n          print(job)\n          _write_contents(job)\n        if job.log_dir is not None:\n          print(\"-\"*60)\n\n    self.unlock()", "response": "Report the results of the jobs in the job_ids array_ids."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, job_ids, array_ids = None, delete_logs = True, delete_log_dir = False, status = Status, delete_jobs = True):\n    def _delete_dir_if_empty(log_dir):\n      if log_dir and delete_log_dir and os.path.isdir(log_dir) and not os.listdir(log_dir):\n        os.rmdir(log_dir)\n        logger.info(\"Removed empty log directory '%s'\" % log_dir)\n\n    def _delete(job, try_to_delete_dir=False):\n      # delete the job from the database\n      if delete_logs:\n        self.delete_logs(job)\n        if try_to_delete_dir:\n          _delete_dir_if_empty(job.log_dir)\n      if delete_jobs:\n        self.session.delete(job)\n\n\n    self.lock()\n\n    # check if array ids are specified\n    if array_ids:\n      if len(job_ids) != 1: logger.error(\"If array ids are specified exactly one job id must be given.\")\n      array_jobs = list(self.session.query(ArrayJob).join(Job).filter(Job.unique.in_(job_ids)).filter(Job.unique == ArrayJob.job_id).filter(ArrayJob.id.in_(array_ids)))\n      if array_jobs:\n        job = array_jobs[0].job\n        for array_job in array_jobs:\n          if array_job.status in status:\n            if delete_jobs:\n              logger.debug(\"Deleting array job '%d' of job '%d' from the database.\" % (array_job.id, job.unique))\n            _delete(array_job)\n        if not job.array:\n          if job.status in status:\n            if delete_jobs:\n              logger.info(\"Deleting job '%d' from the database.\" % job.unique)\n            _delete(job, delete_jobs)\n\n    else:\n      # iterate over all jobs\n      jobs = self.get_jobs(job_ids)\n      for job in jobs:\n        # delete all array jobs\n        if job.array:\n          for array_job in job.array:\n            if array_job.status in status:\n              if delete_jobs:\n                logger.debug(\"Deleting array job '%d' of job '%d' from the database.\" % (array_job.id, job.unique))\n              _delete(array_job)\n        # delete this job\n        if job.status in status:\n          if delete_jobs:\n            logger.info(\"Deleting job '%d' from the database.\" % job.unique)\n          _delete(job, delete_jobs)\n\n    self.session.commit()\n    self.unlock()", "response": "Deletes the jobs with the given ids from the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n    p = ArgumentParser(description='Makes unit flux eV^-1 as input to GLOW or Transcar to create ionospheric eigenprofiles')\n    p.add_argument('-i', '--inputgridfn', help='original Zettergren input flux grid to base off of', default='zettflux.csv')\n    p.add_argument('-o', '--outfn', help='hdf5 file to write with ionospheric response (eigenprofiles)')\n    p.add_argument('-t', '--simtime', help='yyyy-mm-ddTHH:MM:SSZ time of sim', nargs='+', default=['1999-12-21T00:00:00Z'])\n    p.add_argument('-c', '--latlon', help='geodetic latitude/longitude (deg)', type=float, nargs=2, default=[65, -148.])\n#    p.add_argument('-m', '--makeplot', help='show to show plots, png to save pngs of plots', nargs='+', default=['show'])\n    p.add_argument('-M', '--model', help='specify auroral model (glow,rees,transcar)', default='glow')\n    p.add_argument('-z', '--zlim', help='minimum,maximum altitude [km] to plot', nargs=2, default=(None, None), type=float)\n    p.add_argument('--isotropic', help='(rees model only) isotropic or non-isotropic pitch angle', action='store_true')\n    p.add_argument('--vlim', help='plotting limits on energy dep and production plots', nargs=2, type=float, default=(1e-7, 1e1))\n\n    p = p.parse_args()\n\n    if not p.outfn:\n        print('you have not specified an output file with -o options, so I will only plot and not save result')\n\n#    makeplot = p.makeplot\n\n    if len(p.simtime) == 1:\n        T = [parse(p.simtime[0])]\n    elif len(p.simtime) == 2:\n        T = list(rrule.rrule(rrule.HOURLY,\n                             dtstart=parse(p.simtime[0]),\n                             until=parse(p.simtime[1])))\n# %% input unit flux\n    Egrid = loadregress(Path(p.inputgridfn).expanduser())\n    Ebins = makebin(Egrid)[:3]\n    EKpcolor, EK, diffnumflux = ekpcolor(Ebins)\n# %% ionospheric response\n    \"\"\" three output eigenprofiles\n    1) ver (optical emissions) 4-D array: time x energy x altitude x wavelength\n    2) prates (production) 4-D array:     time x energy x altitude x reaction\n    3) lrates (loss) 4-D array:           time x energy x altitude x reaction\n    \"\"\"\n    model = p.model.lower()\n    glat, glon = p.latlon\n\n    if model == 'glow':\n        ver, photIon, isr, phitop, zceta, sza, prates, lrates, tezs, sion = makeeigen(EK, diffnumflux, T, p.latlon,\n                                                                                      p.makeplot, p.outfn, p.zlim)\n\n        writeeigen(p.outfn, EKpcolor, T, ver.z_km, diffnumflux, ver, prates, lrates, tezs, p.latlon)\n        # %% plots\n        # input\n        doplot(p.inputgridfn, Ebins)\n\n        # output\n        sim = namedtuple('sim', ['reacreq', 'opticalfilter'])\n        sim.reacreq = sim.opticalfilter = ''\n\n        for t in ver:  # TODO for each time\n            # VER eigenprofiles, summed over wavelength\n            ploteigver(EKpcolor, ver.z_km, ver.sum('wavelength_nm'),\n                       (None,)*6, sim,\n                       '{} Vol. Emis. Rate '.format(t))\n            # volume production rate, summed over reaction\n            plotprodloss(prates.loc[:, 'final', ...].sum('reaction'),\n                         lrates.loc[:, 'final', ...].sum('reaction'),\n                         t, glat, glon, p.zlim)\n            # energy deposition\n            plotenerdep(tezs, t, glat, glon, p.zlim)\n\n    elif model == 'rees':\n        assert len(T) == 1, 'only one time with rees for now.'\n        z = glowalt()\n        q = reesiono(T, z, Ebins.loc[:, 'low'], glat, glon, p.isotropic)\n\n        writeeigen(p.outfn, Ebins, T, z, prates=q, tezs=None, latlon=(glat, glon))\n\n        plotA(q, 'Volume Production Rate {}  {} {}'.format(T, glat, glon), p.vlim)\n    elif model == 'transcar':\n        raise NotImplementedError('Transcar by request')\n    else:\n        raise NotImplementedError('I am not yet able to handle your model {}'.format(model))\n# %% plots\n\n    show()", "response": "This is the main function for the Zettergren command line interface. It will create an hdf5 file for the Zettergren input flux grid and plot the resulting EV^ - 1."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new revision file in a scripts directory", "response": "def revision(config, message):\n    \"\"\"Create new revision file in a scripts directory\"\"\"\n    with open(config, 'r'):\n        main.revision(yaml.load(open(config)), message)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupgrading or revert to a different revision.", "response": "def checkout(config, rev):\n    \"\"\"Upgrade/revert to a different revision.\n    \n    <rev> must be \"head\", integer or revision id. To pass negative\n    number you need to write \"--\" before it\"\"\"\n    with open(config, 'r'):\n        main.checkout(yaml.load(open(config)), rev)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef raise_(type_, value=None, traceback=None):  # pylint: disable=W0613\n\n    prev_exc, prev_tb = sys.exc_info()[1:]\n    proxy_class = construct_exc_class(type(type_))\n\n    err = proxy_class(type_)\n    err.__original_exception__.__cause__ = None\n    err.__original_exception__.__suppress_context__ = False\n\n    if getattr(prev_exc, \"__pep3134__\", False):\n        prev_exc = prev_exc.with_traceback(prev_tb)\n    err.__original_exception__.__context__ = prev_exc\n\n    if traceback:\n        raise err.with_traceback(traceback), None, traceback\n    else:\n        raise err", "response": "A wrapper around the Python 2. 7 raise function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef raise_from(exc, cause):\n\n    context_tb = sys.exc_info()[2]\n\n    incorrect_cause = not (\n        (isinstance(cause, type) and issubclass(cause, Exception)) or\n        isinstance(cause, BaseException) or\n        cause is None\n    )\n    if incorrect_cause:\n        raise TypeError(\"exception causes must derive from BaseException\")\n\n    if cause is not None:\n        if not getattr(cause, \"__pep3134__\", False):\n            # noinspection PyBroadException\n            try:\n                raise_(cause)\n            except:  # noqa pylint: disable=W0702\n                cause = sys.exc_info()[1]\n        cause.__fixed_traceback__ = context_tb\n\n    # noinspection PyBroadException\n    try:\n        raise_(exc)\n    except:  # noqa pylint: disable=W0702\n        exc = sys.exc_info()[1]\n\n    exc.__original_exception__.__suppress_context__ = True\n    exc.__original_exception__.__cause__ = cause\n    exc.__original_exception__.__context__ = None\n\n    raise exc", "response": "Raises an exception from the exception hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding all files in the given root.", "response": "def find_files(self, root):\n        \"\"\"\n        Helper method to get all files in the given root.\n        \"\"\"\n\n        def is_ignored(path, ignore_patterns):\n            \"\"\"\n            Check if the given path should be ignored or not.\n            \"\"\"\n            filename = os.path.basename(path)\n            ignore = lambda pattern: fnmatch.fnmatchcase(filename, pattern)\n            return any(ignore(pattern) for pattern in ignore_patterns)\n\n        dir_suffix = '%s*' % os.sep\n        normalized_patterns = [\n            p[:-len(dir_suffix)] if p.endswith(dir_suffix) else p\n            for p in self.ignore_patterns\n        ]\n\n        all_files = []\n        walker = os.walk(root, topdown=True, followlinks=self.follow_symlinks)\n        for dir_path, dir_names, file_names in walker:\n            for dir_name in dir_names[:]:\n                path = os.path.normpath(os.path.join(dir_path, dir_name))\n                if is_ignored(path, normalized_patterns):\n                    dir_names.remove(dir_name)\n                    if self.verbose:\n                        print_out(\"Ignoring directory '{:}'\".format(dir_name))\n            for file_name in file_names:\n                path = os.path.normpath(os.path.join(dir_path, file_name))\n                if is_ignored(path, self.ignore_patterns):\n                    if self.verbose:\n                        print_out(\"Ignoring file '{:}' in '{:}'\".format(\n                                  file_name, dir_path))\n                else:\n                    all_files.append((dir_path, file_name))\n        return sorted(all_files)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate or updates the PO file for the current locale.", "response": "def make_po_file(self, potfile, locale):\n        \"\"\"\n        Creates or updates the PO file for self.domain and :param locale:.\n        Uses contents of the existing :param potfile:.\n\n        Uses mguniq, msgmerge, and msgattrib GNU gettext utilities.\n        \"\"\"\n        pofile = self._get_po_path(potfile, locale)\n\n        msgs = self._get_unique_messages(potfile)\n        msgs = self._merge_messages(potfile, pofile, msgs)\n        msgs = self._strip_package_version(msgs)\n\n        with open(pofile, 'w') as fp:\n            fp.write(msgs)\n\n        self._remove_obsolete_messages(pofile)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreformats the input results into a dictionary with module names as keys and their respective results as values outputs to csv if outputPath is specified", "response": "def goodFormater(badFormat, outputPath, year, length):\n    '''[summary]\n\n    reformats the input results into a dictionary with module names as keys and their respective results as values\n\n    outputs to csv if outputPath is specified\n\n    Arguments:\n        badFormat {dict} -- candNumber : [results for candidate]\n        outputPath {str} -- the path to output to\n        year {int} -- the year candidateNumber is in\n        length {int} -- length of each row in badFormat divided by 2\n\n\n    Returns:\n        dictionary -- module : [results for module]\n        saves to file if output path is specified\n\n    '''\n\n    devcom = 'PHAS' + badFormat['Cand'][0]\n\n    goodFormat = {devcom: []}\n\n    # ignore first row cause it's just 'Mark' & 'ModuleN'\n    for row in list(badFormat.values())[1:]:\n        goodFormat[devcom].append(int(row[0]))  # add first val to devcom\n\n        for i in range(length-1):\n            # if a key for that module doesn't exist, initialize with empt array\n            goodFormat.setdefault(row[(2 * i) + 1], [])\n            # add value of module to module\n            goodFormat[row[(2*i)+1]].append(int(row[2*(i + 1)]))\n\n    goodFormat.pop('0')\n\n    goodFormat['Averages'] = everyonesAverage(year, badFormat, length)\n    if outputPath is not None:  # if requested to reformat and save to file\n\n        results = csv.writer(outputPath.open(mode='w'), delimiter=',')\n        # write the keys (module names) as first row\n        results.writerow(goodFormat.keys())\n        # zip module results together, fill modules with less people using empty values\n        # add row by row\n        results.writerows(itertools.zip_longest(\n            *goodFormat.values(), fillvalue=''))\n\n    return goodFormat"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes some plots of the number of candidates for each module in the order of the module.", "response": "def plotter(path, show, goodFormat):\n    '''makes some plots\n\n    creates binned histograms of the results of each module\n    (ie count of results in ranges [(0,40), (40, 50), (50,60), (60, 70), (70, 80), (80, 90), (90, 100)])\n\n    Arguments:\n        path {str} --  path to save plots to\n        show {boolean} -- whether to show plots using python\n        goodFormat {dict} -- module : [results for module]\n\n    output:\n        saves plots to files/shows plots depending on inputs\n    '''\n\n    for module in goodFormat.items():  # for each module\n        bins = [0, 40, 50, 60, 70, 80, 90, 100]\n        # cut the data into bins\n        out = pd.cut(module[1], bins=bins, include_lowest=True)\n        ax = out.value_counts().plot.bar(rot=0, color=\"b\", figsize=(10, 6), alpha=0.5,\n                                         title=module[0])  # plot counts of the cut data as a bar\n\n        ax.set_xticklabels(['0 to 40', '40 to 50', '50 to 60',\n                            '60 to 70', '70 to 80', '80 to 90', '90 to 100'])\n\n        ax.set_ylabel(\"# of candidates\")\n        ax.set_xlabel(\n            \"grade bins \\n total candidates: {}\".format(len(module[1])))\n\n        if path is not None and show is not False:\n\n            # if export path directory doesn't exist: create it\n            if not pathlib.Path.is_dir(path.as_posix()):\n                pathlib.Path.mkdir(path.as_posix())\n\n            plt.savefig(path / ''.join([module[0], '.png']))\n            plt.show()\n\n        elif path is not None:\n\n            # if export path directory doesn't exist: create it\n            if not pathlib.Path.is_dir(path):\n                pathlib.Path.mkdir(path)\n\n            plt.savefig(path / ''.join([module[0], '.png']))\n            plt.close()\n\n        elif show is not False:\n            plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef myGrades(year, candidateNumber, badFormat, length):\n    '''returns final result of candidateNumber in year\n\n    Arguments:\n        year {int} -- the year candidateNumber is in\n        candidateNumber {str} -- the candidateNumber of candidateNumber\n        badFormat {dict} -- candNumber : [results for candidate]\n        length {int} -- length of each row in badFormat divided by 2\n\n\n    Returns:\n        int -- a weighted average for a specific candidate number and year\n    '''\n\n    weights1 = [1, 1, 1, 1, 0.5, 0.5, 0.5, 0.5]\n    weights2 = [1, 1, 1, 1, 1, 1, 0.5, 0.5]\n    if year == 1:\n        myFinalResult = sum([int(badFormat[candidateNumber][2*(i + 1)])\n                             * weights1[i] for i in range(length-1)]) / 6\n    elif year == 2 or year == 3:\n        myFinalResult = sum([int(badFormat[candidateNumber][2*(i + 1)])\n                             * weights2[i] for i in range(length-1)]) / 7\n    elif year == 4:\n        myFinalResult = sum([int(badFormat[candidateNumber][2*(i + 1)])\n                             for i in range(length-1)]) / 8\n\n    return myFinalResult", "response": "returns final result of candidateNumber in year\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef myRank(grade, badFormat, year, length):\n    '''rank of candidateNumber in year\n\n    Arguments:\n        grade {int} -- a weighted average for a specific candidate number and year\n        badFormat {dict} -- candNumber : [results for candidate]\n        year {int} -- year you are in\n        length {int} -- length of each row in badFormat divided by 2\n\n\n\n    Returns:\n        int -- rank of candidateNumber in year\n    '''\n    return int(sorted(everyonesAverage(year, badFormat, length), reverse=True).index(grade) + 1)", "response": "Rank of a specific candidateNumber in a specific year"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef everyonesAverage(year, badFormat, length):\n    ''' creates list of weighted average results for everyone in year\n\n    Arguments:\n        year {int}\n        badFormat {dict} -- candNumber : [results for candidate]\n        length {int} -- length of each row in badFormat divided by 2\n\n\n    returns:\n        list -- weighted average results of everyone in year\n    '''\n    return [myGrades(year, cand, badFormat, length) for cand in list(badFormat.keys())[1:]]", "response": "creates a list of weighted average results for everyone in year\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef askInitial():\n    '''Asks the user for what it wants the script to do\n\n    Returns:\n        [dictionary] -- answers to the questions\n    '''\n    return inquirer.prompt([\n        inquirer.Text(\n            'inputPath', message=\"What's the path of your input file (eg input.csv)\"),\n        inquirer.List(\n            'year',\n            message=\"What year are you in\",\n                    choices=[1, 2, 3, 4]\n        ),\n        inquirer.Checkbox(\n            'whatToDo',\n            message=\"What can I do for you (select with your spacebar)\",\n            choices=[\n                \"Get your weighted average\",\n                \"Get your rank in the year\",\n                \"Reformat results by module and output to csv\",\n                \"Plot the results by module\"\n\n            ]),\n    ])", "response": "Asks the user for what it wants the script to do\n    Returns the questions to the questions\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef howPlotAsk(goodFormat):\n    '''plots using inquirer prompts\n\n    Arguments:\n        goodFormat {dict} -- module : [results for module]\n    '''\n    plotAnswer = askPlot()\n    if \"Save\" in plotAnswer['plotQ']:\n        exportPlotsPath = pathlib.Path(askSave())\n        if \"Show\" in plotAnswer['plotQ']:\n            plotter(exportPlotsPath, True, goodFormat)\n        else:\n            plotter(exportPlotsPath, False, goodFormat)\n    elif \"Show\" in plotAnswer['plotQ']:\n        plotter(None, True, goodFormat)", "response": "plots using inquirer prompts\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot using argparse if can", "response": "def howPlotArgs(goodFormat):\n    '''plots using argparse if can, if not uses howPlotask()\n\n    Arguments:\n        goodFormat {dict} -- module : [results for module]\n    '''\n    if args.exportplots is not None:\n        exportPlotsPath = pathlib.Path(args.exportplots)\n\n        if args.showplots:\n            plotter(exportPlotsPath, True, goodFormat)\n        else:\n            plotter(exportPlotsPath, False, goodFormat)\n    elif args.showplots:\n        plotter(None, True, goodFormat)\n    else:\n        howPlotAsk(goodFormat)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(args):\n    '''main entry point of app\n    \n    Arguments:\n        args {namespace} -- arguments provided in cli\n    '''\n    \n    print(\"\\nNote it's very possible that this doesn't work correctly so take what it gives with a bucketload of salt\\n\")\n\n    #########################\n    #                       #\n    #                       #\n    #         prompt        #\n    #                       #\n    #                       #\n    #########################\n\n    if not len(sys.argv) > 1:\n        initialAnswers = askInitial()\n\n        inputPath = pathlib.Path(initialAnswers['inputPath'])\n        year = int(initialAnswers['year'])\n        # create a list from every row\n        badFormat = badFormater(inputPath)  # create a list from every row\n        howManyCandidates = len(badFormat) - 1\n\n        length = int(len(badFormat['Cand'])/2)\n        finalReturn = []\n\n        if \"Get your rank in the year\" in initialAnswers['whatToDo']:\n            candidateNumber = askCandidateNumber()\n            weightedAverage = myGrades(year, candidateNumber, badFormat, length)\n            rank = myRank(weightedAverage, badFormat, year, length)\n\n            if \"Get your weighted average\" in initialAnswers['whatToDo']:\n                finalReturn.append('Your weighted average for the year is: {:.2f}%'.format(\n                    weightedAverage))\n\n            finalReturn.append('Your rank is {}th of {} ({:.2f} percentile)'.format(\n                rank, howManyCandidates, (rank * 100) / howManyCandidates))\n        elif \"Get your weighted average\" in initialAnswers['whatToDo']:\n            candidateNumber = askCandidateNumber()\n            weightedAverage = myGrades(year, candidateNumber, badFormat, length)\n            finalReturn.append('Your weighted average for the year is: {:.2f}%'.format(\n                weightedAverage))\n\n        if \"Reformat results by module and output to csv\" in initialAnswers['whatToDo']:\n\n            formatOutputPath = pathlib.Path(askFormat())\n\n            goodFormat = goodFormater(badFormat, formatOutputPath, year, length)\n\n            if \"Plot the results by module\" in initialAnswers['whatToDo']:\n                howPlotAsk(goodFormat)\n\n        elif \"Plot the results by module\" in initialAnswers['whatToDo']:\n            goodFormat = goodFormater(badFormat, None, year, length)\n            howPlotAsk(goodFormat)\n\n        [print('\\n', x) for x in finalReturn]\n\n    #########################\n    #                       #\n    #          end          #\n    #         prompt        #\n    #                       #\n    #                       #\n    #########################\n\n    #########################\n    #                       #\n    #                       #\n    #       run with        #\n    #       cli args        #\n    #                       #\n    #########################\n\n    if len(sys.argv) > 1:\n        if not args.input:\n            inputPath = pathlib.Path(askInput())\n        else:\n            inputPath = pathlib.Path(args.input)\n        if not args.year:\n            year = int(askYear())\n        else:\n            year = int(args.year)\n\n        # create a list from every row\n        badFormat = badFormater(inputPath)  # create a list from every row\n        howManyCandidates = len(badFormat) - 1\n\n        length = int(len(badFormat['Cand'])/2)\n        finalReturn = []\n\n        if args.rank:\n            if not args.candidate:\n                candidateNumber = askCandidateNumber()\n            else:\n                candidateNumber = args.candidate\n\n            weightedAverage = myGrades(year, candidateNumber, badFormat, length)\n            rank = myRank(weightedAverage, badFormat, year, length)\n\n            if args.my:\n                finalReturn.append('Your weighted average for the year is: {:.2f}%'.format(\n                    weightedAverage))\n\n            finalReturn.append('Your rank is {}th of {} ({:.2f} percentile)'.format(\n                rank, howManyCandidates, (rank * 100) / howManyCandidates))\n\n        elif args.my:\n            if not args.candidate:\n                candidateNumber = askCandidateNumber()\n            else:\n                candidateNumber = args.candidate\n\n            weightedAverage = myGrades(year, candidateNumber, badFormat, length)\n            finalReturn.append('Your weighted average for the year is: {:.2f}%'.format(\n                weightedAverage))\n\n        if args.format is not None:\n            formatOutputPath = pathlib.Path(args.format)\n            goodFormat = goodFormater(badFormat, formatOutputPath, year, length)\n\n            if args.plot:\n                howPlotArgs(goodFormat)\n        elif args.plot:\n            goodFormat = goodFormater(badFormat, None, year, length)\n            howPlotArgs(goodFormat)\n\n        [print('\\n', x) for x in finalReturn]\n\n    #########################\n    #                       #\n    #         end           #\n    #       run with        #\n    #       cli args        #\n    #                       #\n    #########################\n\n    print('')", "response": "This function is the main entry point of the app\n    \n            script. It will ask the user for the list of possible results and return a list of the results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread config from given path string or dict object.", "response": "def read_config(config_path_or_dict=None):\n    \"\"\"\n    Read config from given path string or dict object.\n\n    :param config_path_or_dict:\n    :type config_path_or_dict: str or dict\n    :return: Returns config object or None if not found.\n    :rtype: :class:`revision.config.Config`\n    \"\"\"\n    config = None\n\n    if isinstance(config_path_or_dict, dict):\n        config = Config(config_path_or_dict)\n\n    if isinstance(config_path_or_dict, string_types):\n        if os.path.isabs(config_path_or_dict):\n            config_path = config_path_or_dict\n        else:\n            config_path = os.path.join(\n                os.getcwd(),\n                os.path.normpath(config_path_or_dict)\n            )\n    else:\n        config_path = os.path.join(\n            os.getcwd(),\n            DEFAULT_CONFIG_PATH\n        )\n\n    if os.path.exists(config_path):\n        with open(config_path, 'r') as f:\n            data = json.load(f)\n            config = Config(data)\n\n    if config is None:\n        raise ConfigNotFound()\n    else:\n        config.validate()\n\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck the value of the config attributes.", "response": "def validate(self):\n        \"\"\"\n        Check the value of the config attributes.\n        \"\"\"\n        for client in self.clients:\n            for key in REQUIRED_KEYS:\n                if key not in client:\n                    raise MissingConfigValue(key)\n\n            if 'revision_file' not in client:\n                client.revision_file = DEFAULT_REVISION_FILEPATH.format(\n                    client.key\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wrap(func, with_func):\n  func.__name__ = with_func.__name__\n  func.__doc__ = with_func.__doc__\n  func.__dict__.update(with_func.__dict__)\n\n  return func", "response": "Copies the function signature from the wrapped function to the wrapping function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decorator(func):\n  def wrapper(__decorated__=None, *Args, **KwArgs):\n    if __decorated__ is None: # the decorator has some optional arguments.\n      return lambda _func: func(_func, *Args, **KwArgs)\n\n    else:\n      return func(__decorated__, *Args, **KwArgs)\n\n  return wrap(wrapper, func)", "response": "r Decorator to support optional args.\n"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef task(__decorated__=None, **Config):\n  if isinstance(__decorated__, tuple):  # the task has some args\n    _Task = Task(__decorated__[0], __decorated__[1], Config=Config)\n\n  else:\n    _Task = Task(__decorated__, [], Config)\n\n  state.ActiveModuleMemberQ.insert(0, _Task)\n\n  return _Task.Underlying", "response": "A decorator to make tasks out of functions.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _arg(__decorated__, **Config):\n  if isinstance(__decorated__, tuple):  # this decorator is followed by another arg decorator\n    __decorated__[1].insert(0, Config)\n    return __decorated__\n\n  else:\n    return __decorated__, [Config]", "response": "Decorator for the arg decorator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef exit_hook(callable, once=True):\n  if once and callable in ExitHooks:\n    return\n\n  ExitHooks.append(callable)", "response": "A decorator that makes the decorated function to run while ec exits."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef member(Imported, **Config):\n  __ec_member__ = Imported.__ec_member__\n  __ec_member__.Config.update(**Config)\n\n  state.ActiveModuleMemberQ.insert(0, __ec_member__)", "response": "Adds a new member to Scripts."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef configure_basic_logging(self, main_module_name, **kwargs):\n        '''Use common logging options to configure all logging.\n\n        Basic logging configuration is used to set levels for all logs from the main module and to\n        filter out logs from other modules unless they are of one level in priority higher.\n\n        :param main_module_name: name of the primary module for normal logging\n        '''\n        if not self._log_options_parent:\n            raise ValueError('Missing log_options_parent')\n\n        options = self[self._log_options_parent]\n        log_level_index = LOG_LEVELS.index(options.log_level)\n        log_kwargs = {\n            'level': getattr(logging, options.log_level.upper()),\n            'format': '[%(asctime)s #%(process)d] %(levelname)-8s %(name)-12s %(message)s',\n            'datefmt': '%Y-%m-%dT%H:%M:%S%z',\n        }\n\n        if options.log_file == 'STDERR':\n            log_kwargs['stream'] = sys.stderr\n        elif options.log_file == 'STDOUT':\n            log_kwargs['stream'] = sys.stdout\n        else:\n            log_kwargs['filename'] = options.log_file\n\n        log_kwargs.update(kwargs)  # allow overrides from caller\n        logging.basicConfig(**log_kwargs)\n\n        # now filter out any other module's logging unless it's one level above the main\n        other_log_level = getattr(logging, LOG_LEVELS[log_level_index + 1].upper())\n        other_filter = OtherLoggingFilter(main_module_name, other_log_level)\n        for handler in logging.root.handlers:\n            handler.addFilter(other_filter)", "response": "Configure all common logging options for the main module."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self, conflict_resolver=choose_mine):\n\n        '''Save all options in memory to the `config_file`.\n\n        Options are read once more from the file (to allow other writers to save configuration),\n        keys in conflict are resolved, and the final results are written back to the file.\n\n        :param conflict_resolver: a simple lambda or function to choose when an option key is\n               provided from an outside source (THEIRS, usually a file on disk) but is also already\n               set on this ConfigStruct (MINE)\n        '''\n        config = self._load(conflict_resolver)  # in case some other process has added items\n        with open(self._config_file, 'wb') as cf:\n            config.write(cf)", "response": "Save all options in memory to the config_file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef kw_str_parse(a_string):\n    try:\n        return dict((k, eval(v.rstrip(',')))\n                    for k, v in kw_list_re.findall(a_string))\n    except (AttributeError, TypeError):\n        if isinstance(a_string, collections.Mapping):\n            return a_string\n        return {}", "response": "convert a string in the form a = b c = d e = f to a dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_not_null_predicate(\n    raw_crash, dumps, processed_crash, processor, key=''\n):\n    \"\"\"a predicate that converts the key'd source to boolean.\n\n    parameters:\n        raw_crash - dict\n        dumps - placeholder in a fat interface - unused\n        processed_crash - placeholder in a fat interface - unused\n        processor - placeholder in a fat interface - unused\n    \"\"\"\n    try:\n        return bool(raw_crash[key])\n    except KeyError:\n        return False", "response": "a predicate that converts the key'd source to boolean."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef action(self, *args, **kwargs):\n        try:\n            return self._action(*args, **kwargs)\n        except KeyError, x:\n            self.config.logger.debug(\n                'Rule %s action failed because of missing key \"%s\"',\n                to_str(self.__class__),\n                x,\n            )\n        except Exception, x:\n            self.config.logger.debug(\n                'Rule %s action failed because of \"%s\"',\n                to_str(self.__class__),\n                x,\n                exc_info=True\n            )\n        return False", "response": "the default action for Support Classifiers invokes any derivied\n            _action function trapping any exceptions raised in the process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngathering a rules parameters together and run the predicate and the action functions.", "response": "def act(self, *args, **kwargs):\n        \"\"\"gather a rules parameters together and run the predicate. If that\n        returns True, then go on and run the action function\n\n        returns:\n            a tuple indicating the results of applying the predicate and the\n            action function:\n               (False, None) - the predicate failed, action function not run\n               (True, True) - the predicate and action functions succeeded\n               (True, False) - the predicate succeeded, but the action function\n                               failed\"\"\"\n        if self.predicate(*args, **kwargs):\n            bool_result = self.action(*args, **kwargs)\n            return (True, bool_result)\n        else:\n            return (False, None)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef function_invocation_proxy(fn, proxy_args, proxy_kwargs):\n        try:\n            return fn(*proxy_args, **proxy_kwargs)\n        except TypeError:\n            return bool(fn)", "response": "execute the fuction if it is one else evaluate the fuction as a boolean\n        and return that value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngather a rules parameters together and run the predicate and the action functions.", "response": "def act(self, *args, **kwargs):\n        \"\"\"gather a rules parameters together and run the predicate. If that\n        returns True, then go on and run the action function\n\n        returns:\n            a tuple indicating the results of applying the predicate and the\n            action function:\n               (False, None) - the predicate failed, action function not run\n               (True, True) - the predicate and action functions succeeded\n               (True, False) - the predicate succeeded, but the action function\n                               failed\"\"\"\n        pred_args = tuple(args) + tuple(self.predicate_args)\n        pred_kwargs = kwargs.copy()\n        pred_kwargs.update(self.predicate_kwargs)\n        if self.function_invocation_proxy(self.predicate,\n                                          pred_args,\n                                          pred_kwargs):\n            act_args = tuple(args) + tuple(self.action_args)\n            act_kwargs = kwargs.copy()\n            act_kwargs.update(self.action_kwargs)\n            bool_result = self.function_invocation_proxy(self.action, act_args,\n                                                         act_kwargs)\n            return (True, bool_result)\n        else:\n            return (False, None)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncycling through a collection of Transform rule tuples loading them into the TransformRuleSystem", "response": "def load_rules(self, an_iterable):\n        \"\"\"cycle through a collection of Transform rule tuples loading them\n        into the TransformRuleSystem\"\"\"\n        self.rules = [\n            TransformRule(*x, config=self.config) for x in an_iterable\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef append_rules(self, an_iterable):\n        self.rules.extend(\n            TransformRule(*x, config=self.config) for x in an_iterable\n        )", "response": "add rules to the TransformRuleSystem"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef apply_all_rules(self, *args, **kwargs):\n        for x in self.rules:\n            self._quit_check()\n            if self.config.chatty_rules:\n                self.config.logger.debug(\n                    'apply_all_rules: %s',\n                    to_str(x.__class__)\n                )\n            predicate_result, action_result = x.act(*args, **kwargs)\n            if self.config.chatty_rules:\n                self.config.logger.debug(\n                    '               : pred - %s; act - %s',\n                    predicate_result,\n                    action_result\n                )\n        return True", "response": "cycle through all rules and apply them all without regard to\n        success or failure\n        True - since success or failure is ignored"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compare(stanzas, gold_schemes, found_schemes):\n    result = SuccessMeasure()\n    total = float(len(gold_schemes))\n    correct = 0.0\n    for (g, f) in zip(gold_schemes, found_schemes):\n        if g == f:\n            correct += 1\n    result.accuracy = correct / total\n\n    # for each word, let rhymeset[word] = set of words in rest of stanza rhyming with the word\n    # precision = # correct words in rhymeset[word]/# words in proposed rhymeset[word]\n    # recall = # correct words in rhymeset[word]/# words in reference words in rhymeset[word]\n    # total precision and recall = avg over all words over all stanzas\n\n    tot_p = 0.0\n    tot_r = 0.0\n    tot_words = 0.0\n\n    for (s, g, f) in zip(stanzas, gold_schemes, found_schemes):\n        stanzasize = len(s)\n        for wi, word in enumerate(s):\n            grhymeset_word = set(\n                map(lambda x: x[0], filter(lambda x: x[1] == g[wi], zip(range(wi + 1, stanzasize), g[wi + 1:]))))\n            frhymeset_word = set(\n                map(lambda x: x[0], filter(lambda x: x[1] == f[wi], zip(range(wi + 1, stanzasize), f[wi + 1:]))))\n\n            if len(grhymeset_word) == 0:\n                continue\n\n            tot_words += 1\n\n            if len(frhymeset_word) == 0:\n                continue\n\n            # find intersection\n            correct = float(len(grhymeset_word.intersection(frhymeset_word)))\n            precision = correct / len(frhymeset_word)\n            recall = correct / len(grhymeset_word)\n            tot_p += precision\n            tot_r += recall\n\n    precision = tot_p / tot_words\n    recall = tot_r / tot_words\n    result.precision = precision\n    result.recall = recall\n    if precision + recall > 0:\n        result.f_score = 2 * precision * recall / (precision + recall)\n    return result", "response": "compare the givenstanza with the given gold schemes and the given found schemes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding naive baseline of gold_schemes", "response": "def naive(gold_schemes):\n    \"\"\"find naive baseline (most common scheme of a given length)?\"\"\"\n    scheme_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'data', 'schemes.json')\n    with open(scheme_path, 'r') as f:\n        dist = json.loads(f.read())\n    best_schemes = {}\n    for i in dist.keys():\n        if not dist[i]:\n            continue\n        best_schemes[int(i)] = tuple(int(j) for j in (max(dist[i], key=lambda x: x[1])[0]).split())\n\n    naive_schemes = []\n    for g in gold_schemes:\n        naive_schemes.append(best_schemes[len(g)])\n    return naive_schemes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind less naive baseline", "response": "def less_naive(gold_schemes):\n    \"\"\"find 'less naive' baseline (most common scheme of a given length in subcorpus)\"\"\"\n    best_schemes = defaultdict(lambda: defaultdict(int))\n    for g in gold_schemes:\n        best_schemes[len(g)][tuple(g)] += 1\n\n    for i in best_schemes:\n        best_schemes[i] = tuple(max(best_schemes[i].items(), key=lambda x: x[1])[0])\n\n    naive_schemes = []\n    for g in gold_schemes:\n        naive_schemes.append(best_schemes[len(g)])\n    return naive_schemes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_git_root_directory(directory: str):\n    try:\n        return run([GIT_COMMAND, \"rev-parse\", \"--show-toplevel\"], directory)\n    except RunException as e:\n        if \" Not a git repository\" in e.stderr:\n            raise NotAGitRepositoryException(directory) from e", "response": "Gets the path of the git project root directory from the given directory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_directory_relative_to_git_root(directory: str):\n    return os.path.relpath(os.path.realpath(directory), get_git_root_directory(directory))", "response": "Gets the path to the given directory relative to the git repository root."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_browse(self,args):\n        rawStack = self.wrappedStack['rawStack']\n        os.system(\"open -a \\\"Google Chrome\\\" https://us-west-2.console.aws.amazon.com/cloudformation/home?region=us-west-2#/stack/detail?stackId={}\".format(rawStack.stack_id))", "response": "Open the current stack in a browser."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_refresh(self,args):\n        self.wrappedStack = self.wrapStack(AwsConnectionFactory.instance.getCfResource().Stack(self.wrappedStack['rawStack'].name))", "response": "Refresh view of the current stack. refresh - h for detailed help"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the current stack. print - h for detailed help", "response": "def do_print(self,args):\n        \"\"\"Print the current stack. print -h for detailed help\"\"\"\n        parser = CommandArgumentParser(\"print\")\n        parser.add_argument('-r','--refresh',dest='refresh',action='store_true',help='refresh view of the current stack')\n        parser.add_argument('-i','--include',dest='include',default=None,nargs='+',help='resource types to include')\n        parser.add_argument(dest='filters',nargs='*',default=[\"*\"],help='Filter stacks');\n        args = vars(parser.parse_args(args))\n\n        if args['refresh']:\n            self.do_refresh('')\n\n        self.printStack(self.wrappedStack,args['include'],args['filters'])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_resource(self,args):\n        parser = CommandArgumentParser(\"resource\")\n        parser.add_argument('-i','--logical-id',dest='logical-id',help='logical id of the child resource');\n        args = vars(parser.parse_args(args))\n\n        stackName = self.wrappedStack['rawStack'].name\n        logicalId = args['logical-id']\n        self.stackResource(stackName,logicalId)", "response": "Go to the specified resource. resource - h for detailed help"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_asg(self,args):\n        parser = CommandArgumentParser(\"asg\")\n        parser.add_argument(dest='asg',help='asg index or name');\n        args = vars(parser.parse_args(args))\n\n        print \"loading auto scaling group {}\".format(args['asg'])\n        try:\n            index = int(args['asg'])\n            asgSummary = self.wrappedStack['resourcesByTypeIndex']['AWS::AutoScaling::AutoScalingGroup'][index]\n        except:\n            asgSummary = self.wrappedStack['resourcesByTypeName']['AWS::AutoScaling::AutoScalingGroup'][args['asg']]\n\n        self.stackResource(asgSummary.stack_name,asgSummary.logical_id)", "response": "Go to the specified auto scaling group. asg - h for detailed help"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngo to the specified eni. eni - h for detailed help.", "response": "def do_eni(self,args):\n        \"\"\"Go to the specified eni. eni -h for detailed help.\"\"\"\n        parser = CommandArgumentParser(\"eni\")\n        parser.add_argument(dest='eni',help='eni index or name');\n        args = vars(parser.parse_args(args))\n\n        print \"loading eni {}\".format(args['eni'])\n        try:\n            index = int(args['eni'])\n            eniSummary = self.wrappedStack['resourcesByTypeIndex']['AWS::EC2::NetworkInterface'][index]\n        except ValueError:\n            eniSummary = self.wrappedStack['resourcesByTypeName']['AWS::EC2::NetworkInterface'][args['eni']]\n\n        pprint(eniSummary)\n        self.stackResource(eniSummary.stack_name,eniSummary.logical_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngoing to the specified log group. logGroup - h for detailed help", "response": "def do_logGroup(self,args):\n        \"\"\"Go to the specified log group. logGroup -h for detailed help\"\"\"\n        parser = CommandArgumentParser(\"logGroup\")\n        parser.add_argument(dest='logGroup',help='logGroup index or name');\n        args = vars(parser.parse_args(args))\n\n        print \"loading log group {}\".format(args['logGroup'])\n        try:\n            index = int(args['logGroup'])\n            logGroup = self.wrappedStack['resourcesByTypeIndex']['AWS::Logs::LogGroup'][index]\n        except:\n            logGroup = self.wrappedStack['resourcesByTypeName']['AWS::Logs::LogGroup'][args['logGroup']]\n\n        print \"logGroup:{}\".format(logGroup)\n        self.stackResource(logGroup.stack_name,logGroup.logical_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngoing to the specified stack. stack - h for detailed help.", "response": "def do_stack(self,args):\n        \"\"\"Go to the specified stack. stack -h for detailed help.\"\"\"\n        parser = CommandArgumentParser(\"stack\")\n        parser.add_argument(dest='stack',help='stack index or name');\n        args = vars(parser.parse_args(args))\n\n        print \"loading stack {}\".format(args['stack'])\n        try:\n            index = int(args['stack'])            \n            stackSummary = self.wrappedStack['resourcesByTypeIndex']['AWS::CloudFormation::Stack'][index]\n        except ValueError:\n            stackSummary = self.wrappedStack['resourcesByTypeName']['AWS::CloudFormation::Stack'][args['stack']]\n\n        self.stackResource(stackSummary.stack_name,stackSummary.logical_id)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting the template for the current stack.", "response": "def do_template(self,args):\n        \"\"\"Print the template for the current stack. template -h for detailed help\"\"\"\n        parser = CommandArgumentParser(\"template\")\n        args = vars(parser.parse_args(args))\n\n        print \"reading template for stack.\"\n        rawStack = self.wrappedStack['rawStack']\n        template = AwsConnectionFactory.getCfClient().get_template(StackName=rawStack.name)\n        print template['TemplateBody']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncopying specified id to stack. copy - h for detailed help.", "response": "def do_copy(self,args):\n        \"\"\"Copy specified id to stack. copy -h for detailed help.\"\"\"\n        parser = CommandArgumentParser(\"copy\")\n        parser.add_argument('-a','--asg',dest='asg',nargs='+',required=False,default=[],help='Copy specified ASG info.')\n        parser.add_argument('-o','--output',dest='output',nargs='+',required=False,default=[],help='Copy specified output info.')        \n        args = vars(parser.parse_args(args))\n        values = []\n        if args['output']:\n            values.extend(self.getOutputs(args['output']))\n        if args['asg']:\n            for asg in args['asg']:\n                try:\n                    index = int(asg)\n                    asgSummary = self.wrappedStack['resourcesByTypeIndex']['AWS::AutoScaling::AutoScalingGroup'][index]\n                except:\n                    asgSummary = self.wrappedStack['resourcesByTypeName']['AWS::AutoScaling::AutoScalingGroup'][asg]\n                values.append(asgSummary.physical_resource_id)\n        print(\"values:{}\".format(values))\n        pyperclip.copy(\"\\n\".join(values))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclone data for given data_path", "response": "def clone_data(self, data_path):\n        \"\"\"\n        Clones data for given data_path:\n        :param str data_path: Git url (git/http/https) or local directory path\n        \"\"\"\n        self.data_path = data_path\n\n        data_url = urlparse.urlparse(self.data_path)\n        if data_url.scheme in SCHEMES or (data_url.scheme == '' and ':' in data_url.path):\n            data_name = os.path.splitext(os.path.basename(data_url.path))[0]\n            data_destination = os.path.join(self.clone_dir, data_name)\n            clone_data = True\n            if os.path.isdir(data_destination):\n                self.logger.info('Data clone directory already exists, checking commit sha')\n                with Dir(data_destination):\n                    # check the current status of what's local\n                    rc, out, err = self.cmd.gather(\"git status -sb\")\n                    if rc:\n                        raise GitDataException('Error getting data repo status: {}'.format(err))\n\n                    lines = out.strip().split('\\n')\n                    synced = ('ahead' not in lines[0] and 'behind' not in lines[0] and len(lines) == 1)\n\n                    # check if there are unpushed\n                    # verify local branch\n                    rc, out, err = self.cmd.gather(\"git rev-parse --abbrev-ref HEAD\")\n                    if rc:\n                        raise GitDataException('Error checking local branch name: {}'.format(err))\n                    branch = out.strip()\n                    if branch != self.branch:\n                        if not synced:\n                            msg = ('Local branch is `{}`, but requested `{}` and you have uncommitted/pushed changes\\n'\n                                   'You must either clear your local data or manually checkout the correct branch.'\n                                   ).format(branch, self.branch)\n                            raise GitDataBranchException(msg)\n                    else:\n                        # Check if local is synced with remote\n                        rc, out, err = self.cmd.gather([\"git\", \"ls-remote\", self.data_path, self.branch])\n                        if rc:\n                            raise GitDataException('Unable to check remote sha: {}'.format(err))\n                        remote = out.strip().split('\\t')[0]\n                        try:\n                            self.cmd.check_assert('git branch --contains {}'.format(remote))\n                            self.logger.info('{} is already cloned and latest'.format(self.data_path))\n                            clone_data = False\n                        except:\n                            if not synced:\n                                msg = ('Local data is out of sync with remote and you have unpushed commits: {}\\n'\n                                       'You must either clear your local data\\n'\n                                       'or manually rebase from latest remote to continue'\n                                       ).format(data_destination)\n                                raise GitDataException(msg)\n\n            if clone_data:\n                if os.path.isdir(data_destination):  # delete if already there\n                    shutil.rmtree(data_destination)\n                self.logger.info('Cloning config data from {}'.format(self.data_path))\n                if not os.path.isdir(data_destination):\n                    cmd = \"git clone -b {} --depth 1 {} {}\".format(self.branch, self.data_path, data_destination)\n                    rc, out, err = self.cmd.gather(cmd)\n                    if rc:\n                        raise GitDataException('Error while cloning data: {}'.format(err))\n\n            self.remote_path = self.data_path\n            self.data_path = data_destination\n        elif data_url.scheme in ['', 'file']:\n            self.remote_path = None\n            self.data_path = os.path.abspath(self.data_path)  # just in case relative path was given\n        else:\n            raise ValueError(\n                'Invalid data_path: {} - invalid scheme: {}'\n                .format(self.data_path, data_url.scheme)\n            )\n\n        if self.sub_dir:\n            self.data_dir = os.path.join(self.data_path, self.sub_dir)\n        else:\n            self.data_dir = self.data_path\n        if not os.path.isdir(self.data_dir):\n            raise GitDataPathException('{} is not a valid sub-directory in the data'.format(self.sub_dir))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncommits outstanding data changes", "response": "def commit(self, msg):\n        \"\"\"\n        Commit outstanding data changes\n        \"\"\"\n        self.logger.info('Commit config: {}'.format(msg))\n        with Dir(self.data_path):\n            self.cmd.check_assert('git add .')\n            self.cmd.check_assert('git commit --allow-empty -m \"{}\"'.format(msg))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npush changes back to data repo.", "response": "def push(self):\n        \"\"\"\n        Push changes back to data repo.\n        Will of course fail if user does not have write access.\n        \"\"\"\n        self.logger.info('Pushing config...')\n        with Dir(self.data_path):\n            self.cmd.check_assert('git push')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprompting the user to enter a new password", "response": "def prompt_for_new_password():\n    \"\"\" Prompt the user to enter a new password, with confirmation \"\"\"\n    while True:\n        passw = getpass.getpass()\n        passw2 = getpass.getpass()\n        if passw == passw2: return passw\n        print 'Passwords do not match'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unicode2Date(value, format=None):\n    # http://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior\n    if value == None:\n        return None\n\n    if format != None:\n        try:\n            if format.endswith(\"%S.%f\") and \".\" not in value:\n                value += \".000\"\n            return _unix2Date(datetime2unix(datetime.strptime(value, format)))\n        except Exception as e:\n            from mo_logs import Log\n\n            Log.error(\"Can not format {{value}} with {{format}}\", value=value, format=format, cause=e)\n\n    value = value.strip()\n    if value.lower() == \"now\":\n        return _unix2Date(datetime2unix(_utcnow()))\n    elif value.lower() == \"today\":\n        return _unix2Date(math.floor(datetime2unix(_utcnow()) / 86400) * 86400)\n    elif value.lower() in [\"eod\", \"tomorrow\"]:\n        return _unix2Date(math.floor(datetime2unix(_utcnow()) / 86400) * 86400 + 86400)\n\n    if any(value.lower().find(n) >= 0 for n in [\"now\", \"today\", \"eod\", \"tomorrow\"] + list(MILLI_VALUES.keys())):\n        return parse_time_expression(value)\n\n    try:  # 2.7 DOES NOT SUPPORT %z\n        local_value = parse_date(value)  #eg 2014-07-16 10:57 +0200\n        return _unix2Date(datetime2unix((local_value - local_value.utcoffset()).replace(tzinfo=None)))\n    except Exception as e:\n        e = Except.wrap(e)  # FOR DEBUGGING\n        pass\n\n    formats = [\n        \"%Y-%m-%dT%H:%M:%S\",\n        \"%Y-%m-%dT%H:%M:%S.%f\"\n    ]\n    for f in formats:\n        try:\n            return _unix2Date(datetime2unix(datetime.strptime(value, f)))\n        except Exception:\n            pass\n\n\n\n    deformats = [\n        \"%Y-%m\",# eg 2014-07-16 10:57 +0200\n        \"%Y%m%d\",\n        \"%d%m%Y\",\n        \"%d%m%y\",\n        \"%d%b%Y\",\n        \"%d%b%y\",\n        \"%d%B%Y\",\n        \"%d%B%y\",\n        \"%Y%m%d%H%M%S\",\n        \"%Y%m%dT%H%M%S\",\n        \"%d%m%Y%H%M%S\",\n        \"%d%m%y%H%M%S\",\n        \"%d%b%Y%H%M%S\",\n        \"%d%b%y%H%M%S\",\n        \"%d%B%Y%H%M%S\",\n        \"%d%B%y%H%M%S\"\n    ]\n    value = deformat(value)\n    for f in deformats:\n        try:\n            return unicode2Date(value, format=f)\n        except Exception:\n            pass\n\n    else:\n        from mo_logs import Log\n        Log.error(\"Can not interpret {{value}} as a datetime\", value=value)", "response": "Convert a unicode string to a UNIX date."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _mod(value, mod=1):\n    if value == None:\n        return None\n    elif mod <= 0:\n        return None\n    elif value < 0:\n        return (value % mod + mod) % mod\n    else:\n        return value % mod", "response": "Return value in mod mod."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef listIDs(basedir):\n    prefix = ''\n    # check for pairtree_prefix file\n    prefixfile = os.path.join(basedir, 'pairtree_prefix')\n    if os.path.isfile(prefixfile):\n        rff = open(prefixfile, 'r')\n        prefix = rff.readline().strip()\n        rff.close()\n    # check for pairtree_root dir\n    root = os.path.join(basedir, 'pairtree_root')\n    if os.path.isdir(root):\n        objects = pairtree.findObjects(root)\n        for obj in objects:\n            doi = os.path.split(obj)[1]\n            # print with prefix and original chars in place\n            print(prefix + pairtree.deSanitizeString(doi))\n    else:\n        print('pairtree_root directory not found')", "response": "Lists digital object identifiers of a Pairtree directory structure."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nestablishing connection to the server", "response": "def _set_conn(self):\n        \"\"\"Establish connection to the server\"\"\"\n        if self._tls:\n            ldap.set_option(ldap.OPT_X_TLS_REQUIRE_CERT, ldap.OPT_X_TLS_NEVER)\n        try:\n            conn = ldap.initialize(self._url)\n            conn.set_option(ldap.OPT_NETWORK_TIMEOUT, self._timeout)\n            conn.simple_bind_s(self._binddn, self._bindpw)\n        except Exception as e:\n            if hasattr(e, 'message') and 'desc' in e.message:\n                msg = e.message['desc']\n            else:\n                msg = e.args[0]['desc']\n            log.critical(msg)\n            raise\n        log.debug('%s connection established' % ('LDAPS' if self._tls else 'LDAP'))\n        self._conn = conn"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_ldap_msg(e):\n        msg = e\n        if hasattr(e, 'message'):\n            msg = e.message\n            if 'desc' in e.message:\n                msg = e.message['desc']\n            elif hasattr(e, 'args'):\n                msg = e.args[0]['desc']\n        return msg", "response": "Extract LDAP exception message from an exception object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_fqdn(self):\n        results = self._search(\n            'cn=config',\n            '(objectClass=*)',\n            ['nsslapd-localhost'],\n            scope=ldap.SCOPE_BASE\n        )\n        if not results and type(results) is not list:\n            r = None\n        else:\n            dn, attrs = results[0]\n            r = attrs['nsslapd-localhost'][0].decode('utf-8')\n        self._fqdn = r\n        log.debug('FQDN: %s' % self._fqdn)", "response": "Get the FQDN from LDAP"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_hostname_domain(self):\n        self._hostname, _, self._domain = str(self._fqdn).partition('.')\n        log.debug('Hostname: %s, Domain: %s' % (self._hostname, self._domain))", "response": "Extract hostname and domain from FQDN and set self. _hostname and self. _domain."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_ip(self):\n        self._ip = socket.gethostbyname(self._fqdn)\n        log.debug('IP: %s' % self._ip)", "response": "Resolve FQDN to IP address"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_base_dn(self):\n        results = self._search(\n            'cn=config',\n            '(objectClass=*)',\n            ['nsslapd-defaultnamingcontext'],\n            scope=ldap.SCOPE_BASE\n        )\n        if results and type(results) is list:\n            dn, attrs = results[0]\n            r = attrs['nsslapd-defaultnamingcontext'][0].decode('utf-8')\n        else:\n            raise Exception\n        self._base_dn = r\n        self._active_user_base = 'cn=users,cn=accounts,' + self._base_dn\n        self._stage_user_base = 'cn=staged users,cn=accounts,cn=provisioning,' + self._base_dn\n        self._preserved_user_base = 'cn=deleted users,cn=accounts,cn=provisioning,' + self._base_dn\n        self._groups_base = 'cn=groups,cn=accounts,' + self._base_dn\n        log.debug('Base DN: %s' % self._base_dn)", "response": "Get Base DN from LDAP"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn dict of users", "response": "def users(self, user_base='active'):\n        \"\"\"Return dict of users\"\"\"\n        if not getattr(self, '_%s_users' % user_base):\n            self._get_users(user_base)\n        return getattr(self, '_%s_users' % user_base)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_users(self, user_base):\n        results = self._search(\n            getattr(self, '_%s_user_base' % user_base),\n            '(objectClass=*)',\n            ['*'],\n            scope=ldap.SCOPE_ONELEVEL\n        )\n        for dn, attrs in results:\n            uid = attrs.get('uid')[0].decode('utf-8', 'ignore')\n            getattr(self, '_%s_users' % user_base)[uid] = FreeIPAUser(dn, attrs)\n            # print(attrs)\n        log.debug('%s users: %s' % (user_base.capitalize(), len(getattr(self, '_%s_users' % user_base))))", "response": "Get users from LDAP"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_users_by_email(self, email, user_base='active'):\n        users = []\n        for user in getattr(self, 'users')(user_base).values():\n            mail = user.mail\n            if mail and email in mail:\n                users.append(user)\n        log.debug('%s users with email address %s: %s' % (user_base.capitalize(), email, len(users)))\n        return users", "response": "Return list of users with given email address"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_anon_bind(self):\n        r = self._search(\n            'cn=config',\n            '(objectClass=*)',\n            ['nsslapd-allow-anonymous-access'],\n            scope=ldap.SCOPE_BASE\n        )\n        dn, attrs = r[0]\n        state = attrs.get('nsslapd-allow-anonymous-access')[0].decode('utf-8', 'ignore')\n        if state in ['on', 'off', 'rootdse']:\n            r = state\n        else:\n            r = None\n        self._anon_bind = r", "response": "Check anonymous bind and return anonymous bind state"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ordered_load(stream, Loader=yaml.Loader,\n    object_pairs_hook=dict):\n  '''Loads the contents of the YAML stream into :py:class:`collections.OrderedDict`'s\n\n  See: https://stackoverflow.com/questions/5121931/in-python-how-can-you-load-yaml-mappings-as-ordereddicts\n\n  '''\n\n  class OrderedLoader(Loader): pass\n\n  def construct_mapping(loader, node):\n    loader.flatten_mapping(node)\n    return object_pairs_hook(loader.construct_pairs(node))\n\n  OrderedLoader.add_constructor(yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG,\n      construct_mapping)\n\n  return yaml.load(stream, OrderedLoader)", "response": "Loads the contents of the YAML stream into a new ordered dict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef expand(data):\n  '''Generates configuration sets based on the YAML input contents\n\n  For an introduction to the YAML mark-up, just search the net. Here is one of\n  its references: https://en.wikipedia.org/wiki/YAML\n\n  A configuration set corresponds to settings for **all** variables in the\n  input template that needs replacing. For example, if your template mentions\n  the variables ``name`` and ``version``, then each configuration set should\n  yield values for both ``name`` and ``version``.\n\n  For example:\n\n  .. code-block:: yaml\n\n     name: [john, lisa]\n     version: [v1, v2]\n\n\n  This should yield to the following configuration sets:\n\n  .. code-block:: python\n\n     [\n       {'name': 'john', 'version': 'v1'},\n       {'name': 'john', 'version': 'v2'},\n       {'name': 'lisa', 'version': 'v1'},\n       {'name': 'lisa', 'version': 'v2'},\n     ]\n\n\n  Each key in the input file should correspond to either an object or a YAML\n  array. If the object is a list, then we'll iterate over it for every possible\n  combination of elements in the lists. If the element in question is not a\n  list, then it is considered unique and repeated for each yielded\n  configuration set. Example\n\n  .. code-block:: yaml\n\n     name: [john, lisa]\n     version: [v1, v2]\n     text: >\n        hello,\n        world!\n\n  Should yield to the following configuration sets:\n\n  .. code-block:: python\n\n     [\n       {'name': 'john', 'version': 'v1', 'text': 'hello, world!'},\n       {'name': 'john', 'version': 'v2', 'text': 'hello, world!'},\n       {'name': 'lisa', 'version': 'v1', 'text': 'hello, world!'},\n       {'name': 'lisa', 'version': 'v2', 'text': 'hello, world!'},\n     ]\n\n  Keys starting with one `_` (underscore) are treated as \"unique\" objects as\n  well. Example:\n\n  .. code-block:: yaml\n\n     name: [john, lisa]\n     version: [v1, v2]\n     _unique: [i1, i2]\n\n  Should yield to the following configuration sets:\n\n  .. code-block:: python\n\n     [\n       {'name': 'john', 'version': 'v1', '_unique': ['i1', 'i2']},\n       {'name': 'john', 'version': 'v2', '_unique': ['i1', 'i2']},\n       {'name': 'lisa', 'version': 'v1', '_unique': ['i1', 'i2']},\n       {'name': 'lisa', 'version': 'v2', '_unique': ['i1', 'i2']},\n     ]\n\n\n  Parameters:\n\n    data (str): YAML data to be parsed\n\n\n  Yields:\n\n    dict: A dictionary of key-value pairs for building the templates\n\n  '''\n\n  data = _ordered_load(data, yaml.SafeLoader)\n\n  # separates \"unique\" objects from the ones we have to iterate\n  # pre-assemble return dictionary\n  iterables = dict()\n  unique = dict()\n  for key, value in data.items():\n    if isinstance(value, list) and not key.startswith('_'):\n      iterables[key] = value\n    else:\n      unique[key] = value\n\n  # generates all possible combinations of iterables\n  for values in itertools.product(*iterables.values()):\n    retval = dict(unique)\n    keys = list(iterables.keys())\n    retval.update(dict(zip(keys, values)))\n    yield retval", "response": "Generates configuration sets based on the contents of the input file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate(variables, template):\n  '''Yields a resolved \"template\" for each config set and dumps on output\n\n  This function will extrapolate the ``template`` file using the contents of\n  ``variables`` and will output individual (extrapolated, expanded) files in\n  the output directory ``output``.\n\n\n  Parameters:\n\n    variables (str): A string stream containing the variables to parse, in YAML\n      format as explained on :py:func:`expand`.\n\n    template (str): A string stream containing the template to extrapolate\n\n\n  Yields:\n\n    str: A generated template you can save\n\n\n  Raises:\n\n    jinja2.UndefinedError: if a variable used in the template is undefined\n\n  '''\n\n  env = jinja2.Environment(undefined=jinja2.StrictUndefined)\n  for c in expand(variables):\n    c['rc'] = rc\n    yield env.from_string(template).render(c)", "response": "Yields a resolved template for each config set and dumps on output\n\n"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef aggregate(variables, template):\n  '''Generates a resolved \"template\" for **all** config sets and returns\n\n  This function will extrapolate the ``template`` file using the contents of\n  ``variables`` and will output a single (extrapolated, expanded) file.\n\n\n  Parameters:\n\n    variables (str): A string stream containing the variables to parse, in YAML\n      format as explained on :py:func:`expand`.\n\n    template (str): A string stream containing the template to extrapolate\n\n\n  Returns:\n\n    str: A generated template you can save\n\n\n  Raises:\n\n    jinja2.UndefinedError: if a variable used in the template is undefined\n\n  '''\n\n  env = jinja2.Environment(undefined=jinja2.StrictUndefined)\n  d = {'cfgset': list(expand(variables)), 'rc': rc}\n  return env.from_string(template).render(d)", "response": "Generates a resolved template for all config sets and returns\n\n"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove all records with the supplied sourcesystem code from the table.", "response": "def _delete_sourcesystem_cd(conn: Connection, table: Table, sourcesystem_cd: str) -> int:\n        \"\"\" Remove all table records with the supplied upload_id\n\n        :param conn: sql connection\n        :param table: table to modify\n        :param sourcesystem_cd: target sourcesystem code\n        :return: number of records removed\n        \"\"\"\n        return conn.execute(delete(table).where(table.c.sourcesystem_cd == sourcesystem_cd)).rowcount \\\n            if sourcesystem_cd else 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _delete_upload_id(conn: Connection, table: Table, upload_id: int) -> int:\n        return conn.execute(delete(table).where(table.c.upload_id == upload_id)).rowcount if upload_id else 0", "response": "Remove all records with the supplied upload_id from the table."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _nested_fcn(f: Callable, filters: List):\n        return None if len(filters) == 0 \\\n            else filters[0] if len(filters) == 1 \\\n            else f(filters[0], I2B2CoreWithUploadId._nested_fcn(f, filters[1:]))", "response": "Distribute binary function f across list L\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding or update the records in the supplied table as needed to reflect the contents of records .", "response": "def _add_or_update_records(cls, conn: Connection, table: Table,\n                               records: List[\"I2B2CoreWithUploadId\"]) -> Tuple[int, int]:\n        \"\"\"Add or update the supplied table as needed to reflect the contents of records\n\n        :param table: i2b2 sql connection\n        :param records: records to apply\n        :return: number of records added / modified\n        \"\"\"\n        num_updates = 0\n        num_inserts = 0\n        inserts = []\n        # Iterate over the records doing updates\n        # Note: This is slow as molasses - definitely not optimal for batch work, but hopefully we'll be dealing with\n        #    thousands to tens of thousands of records.  May want to move to ORM model if this gets to be an issue\n        for record in records:\n            keys = [(table.c[k] == getattr(record, k)) for k in cls.key_fields]\n            key_filter = I2B2CoreWithUploadId._nested_fcn(and_, keys)\n            rec_exists = conn.execute(select([table.c.upload_id]).where(key_filter)).rowcount\n            if rec_exists:\n                known_values = {k: v for k, v in as_dict(record).items()\n                                if v is not None and k not in cls._no_update_fields and\n                                k not in cls.key_fields}\n                vals = [table.c[k] != v for k, v in known_values.items()]\n                val_filter = I2B2CoreWithUploadId._nested_fcn(or_, vals)\n                known_values['update_date'] = record.update_date\n                upd = update(table).where(and_(key_filter, val_filter)).values(known_values)\n                num_updates += conn.execute(upd).rowcount\n            else:\n                inserts.append(as_dict(record))\n        if inserts:\n            if cls._check_dups:\n                dups = cls._check_for_dups(inserts)\n                nprints = 0\n                if dups:\n                    print(\"{} duplicate records encountered\".format(len(dups)))\n                    for k, vals in dups.items():\n                        if len(vals) == 2 and vals[0] == vals[1]:\n                            inserts.remove(vals[1])\n                        else:\n                            if nprints < 20:\n                                print(\"Key: {} has a non-identical dup\".format(k))\n                            elif nprints == 20:\n                                print(\".... more ...\")\n                            nprints += 1\n                            for v in vals[1:]:\n                                inserts.remove(v)\n            # TODO: refactor this to load on a per-resource basis.  Temporary fix\n            for insert in ListChunker(inserts, 500):\n                num_inserts += conn.execute(table.insert(), insert).rowcount\n        return num_inserts, num_updates"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating equality based on equality of all group items.", "response": "def equality(self, other):\n        \"\"\"Calculate equality based on equality of all group items.\"\"\"\n        if not len(self) == len(other):\n            return False\n        return super().equality(other)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef similarity(self, other):\n        # Select the longer list as the basis for comparison\n        if len(self.items) > len(other.items):\n            first, second = self, other\n        else:\n            first, second = other, self\n        items = list(first.items)  # backup items list\n        length = len(items)\n        sim = self.Similarity(0.0 if length else 1.0)\n\n        # Calculate the similarity for each permutation of items\n        cname = self.__class__.__name__\n\n        for num, perm in enumerate(permutations(items, length), start=1):\n            first.items = perm\n            aname = 'items-p{}'.format(num)\n            self.log(first, second, '%', cname=cname, aname=aname)\n            permutation_sim = super(Group, first).similarity(second)\n            self.log(first, second, '%', cname=cname, aname=aname,\n                     result=permutation_sim)\n\n            sim = max(sim, permutation_sim)\n            logging.debug(\"highest similarity: %s\", sim)\n\n        first.items = items  # restore original items list\n\n        return sim", "response": "Calculate similarity based on best matching permutation of items."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def peers(client: Client, leaves: bool = False, leaf: str = \"\") -> dict:\n    if leaves is True:\n        return await client.get(MODULE + '/peering/peers', {\"leaves\": \"true\"}, schema=PEERS_SCHEMA)\n    else:\n        return await client.get(MODULE + '/peering/peers', {\"leaf\": leaf}, schema=PEERS_SCHEMA)", "response": "GET peering entries of every node inside the currency network"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def peer(client: Client, peer_signed_raw: str) -> ClientResponse:\n    return await client.post(MODULE + '/peering/peers', {'peer': peer_signed_raw}, rtype=RESPONSE_AIOHTTP)", "response": "POST a Peer signed raw document"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to determine if a device is optical technology.", "response": "def check_optical(disk):\n    ''' Try to determine if a device is optical technology.\n        Needs improvement.\n    '''\n    dev = disk.dev\n    if dev.startswith('sr') or ('cd' in dev):\n        return True\n    elif disk.fmt in optical_fs:\n        return True\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_removable(dev, opts):\n    ''' Removable drives can be identified under /sys. '''\n    try:  # get parent device from sys filesystem, look from right.  :-/\n        parent = os.readlink(f'/sys/class/block/{dev}').rsplit(\"/\", 2)[1]\n        with open(f'/sys/block/{parent}/removable') as f:\n            return f.read() == '1\\n'\n\n    except IndexError as err:\n        if opts.debug:\n            print('ERROR: parent block device not found.', err)\n    except IOError as err:\n        if opts.debug:\n            print('ERROR:', err)", "response": "Check if a given device is removable under the current node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decode_mntp(mntp):\n    ''' Mount point strings have a unique encoding for whitespace. :-/\n        https://stackoverflow.com/a/13576641/450917\n        https://stackoverflow.com/a/6117124/450917\n    '''\n    import re\n    replacements = {\n        r'\\\\040': ' ',\n        r'\\\\011': '\\t',\n        r'\\\\012': '\\n',\n        r'\\\\134': '\\\\',\n    }\n    pattern = re.compile('|'.join(replacements.keys()))\n    return pattern.sub(lambda m: replacements[re.escape(m.group(0))], mntp)", "response": "Decode a mount point string into a sequence of unicode strings."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_label_map(opts):\n    ''' Find volume labels from filesystem and return in dict format. '''\n    results = {}\n    try:\n        for entry in os.scandir(diskdir):\n            target = normpath(join(diskdir, os.readlink(entry.path)))\n            decoded_name = entry.name.encode('utf8').decode('unicode_escape')\n            results[target] = decoded_name\n        if opts.debug:\n            print('\\n\\nlabel_map:', results)\n    except FileNotFoundError:\n        pass\n    return results", "response": "Find volume labels from filesystem and return in dict format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_diskinfo(opts, show_all=False, local_only=False):\n    ''' Returns a list holding the current disk info.\n        Stats are divided by the outputunit.\n    '''\n    disks = []\n    outunit = opts.outunit\n    label_map = get_label_map(opts)\n\n    # get mount info\n    try:\n        with open(mntfname) as infile:\n            lines = infile.readlines()\n            lines.sort()\n    except IOError:\n        return None\n\n    # build list of disks\n    for i, line in enumerate(lines):\n        device, mntp, fmt, mntops, *_ = line.split()\n\n        if device in ('cgroup',):       # never want these\n            continue\n\n        disk = DiskInfo()\n        dev = basename(device)          #\u00a0short name\n        disk.isnet  = ':' in device     # cheesy but works\n        if local_only and disk.isnet:\n            continue\n        disk.isimg = is_img = dev.startswith('loop')  # could be better\n        is_tmpfs = (device == 'tmpfs')\n\n        # lots of junk here, so we throw away most entries\n        for selector in selectors:\n            if selector in device:\n                if show_all:\n                    if is_tmpfs:\n                        disk.isram = True\n                else:  # skip these:\n                    if (is_img or\n                        is_tmpfs or\n                        mntp == '/boot/efi'):\n                            continue\n                break   # found a useful entry, stop here\n        else:           #\u00a0no-break, nothing was found\n            continue    # skip this one\n\n        disk.dev = dev\n        disk.fmt = fmt\n        disk.mntp = mntp = decode_mntp(mntp) if '\\\\' in mntp else mntp\n        disk.ismntd = bool(mntp)\n        disk.isopt = check_optical(disk)\n        if device[0] == '/':  # .startswith('/dev'):\n            disk.isrem = check_removable(dev, opts)\n        disk.label = label_map.get(device)\n\n        # get disk usage information\n        # http://pubs.opengroup.org/onlinepubs/009695399/basedefs/sys/statvfs.h.html\n        # convert to bytes, then output units\n        stat = os.statvfs(mntp)\n        disk.ocap  = stat.f_frsize * stat.f_blocks     # keep for later\n        disk.cap   = disk.ocap / outunit\n        disk.free  = stat.f_frsize * stat.f_bavail / outunit\n        disk.oused = stat.f_frsize * (stat.f_blocks - stat.f_bfree) # for later\n        disk.used  = disk.oused / outunit\n        disk.pcnt  = disk.oused / disk.ocap * 100\n        if mntops.startswith('rw'):             # read only\n            disk.rw = True\n        elif mntops.startswith('ro'):\n            disk.rw = False\n        else:\n            disk.rw = not bool(stat.f_flag & os.ST_RDONLY)\n\n        disks.append(disk)\n\n    if show_all:    # look at /dev/disks again for the unmounted\n        for devname in label_map:\n            dev = basename(devname)\n            exists = [ disk for disk in disks if disk.dev == dev ]\n            if not exists:\n                disk = DiskInfo(\n                    cap=0, free=0, ocap=0, pcnt=0, used=0,\n                    dev = dev,\n                    ismntd = False, mntp = '',\n                    isnet = False,\n                    isopt = check_optical(DiskInfo(dev=dev, fmt=None)),\n                    isram = False,   # no such thing?\n                    isrem = check_removable(dev, opts),\n                    label = label_map[devname],\n                    rw = None,\n                )\n                disks.append(disk)\n                disks.sort(key=lambda disk: disk.dev)  # sort again :-/\n\n    if opts.debug:\n        print()\n        for disk in disks:\n            print(disk.dev, disk)\n            print()\n    return disks", "response": "Returns a list holding the current disk info."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_meminfo(opts):\n    ''' Returns a dictionary holding the current memory info,\n        divided by the ouptut unit.  If mem info can't be read, returns None.\n    '''\n    meminfo = MemInfo()\n    outunit = opts.outunit\n    try:\n        with open(memfname) as infile:\n            lines = infile.readlines()\n    except IOError:\n        return None\n\n    for line in lines:                      # format: 'MemTotal:  511456 kB\\n'\n        tokens = line.split()\n        if tokens:\n            name, value = tokens[0][:-1].lower(), tokens[1]  # rm :\n            if len(tokens) == 2:\n                continue\n            unit = tokens[2].lower()\n\n            # parse_result to bytes  TODO\n            value = int(value)\n            if   unit == 'kb': value = value * 1024  # most likely\n            elif unit ==  'b': value = value\n            elif unit == 'mb': value = value * 1024 * 1024\n            elif unit == 'gb': value = value * 1024 * 1024 * 1024\n\n            setattr(meminfo, name, value / outunit)\n\n    cache = meminfo.cached + meminfo.buffers\n    meminfo.used = meminfo.memtotal - meminfo.memfree - cache\n    meminfo.swapused = (meminfo.swaptotal - meminfo.swapcached -\n                        meminfo.swapfree)\n    return meminfo", "response": "Returns a dictionary holding the current memory info and the ouptut unit."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset Conn String for Windiws Windows has a different way of forking processes which causes the daemon process to connect to the database.", "response": "def setConnStringForWindows():\n    \"\"\" Set Conn String for Windiws\n\n    Windows has a different way of forking processes, which causes the\n    @worker_process_init.connect signal not to work in \"CeleryDbConnInit\"\n\n\n    \"\"\"\n    global _dbConnectString\n    from peek_platform.file_config.PeekFileConfigABC import PeekFileConfigABC\n    from peek_platform.file_config.PeekFileConfigSqlAlchemyMixin import \\\n        PeekFileConfigSqlAlchemyMixin\n    from peek_platform import PeekPlatformConfig\n\n    class _WorkerTaskConfigMixin(PeekFileConfigABC,\n                           PeekFileConfigSqlAlchemyMixin):\n        pass\n\n    PeekPlatformConfig.componentName = peekWorkerName\n\n    _dbConnectString = _WorkerTaskConfigMixin().dbConnectString"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prefetchDeclarativeIds(Declarative, count) -> Optional[Iterable[int]]:\n    return _commonPrefetchDeclarativeIds(\n        getDbEngine(), _sequenceMutex, Declarative, count\n    )", "response": "Prefetches a number of IDs from a SQLAlchemy declarative object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef install_gem(gemname, version=None, conservative=True, ri=False, rdoc=False,\n                development=False, format_executable=False, force=False,\n                gem_source=None):\n    \"\"\"Install a ruby gem.\"\"\"\n    cmdline = ['gem', 'install']\n    if conservative:\n        cmdline.append('--conservative')\n    if ri:\n        cmdline.append('--ri')\n    else:\n        cmdline.append('--no-ri')\n    if rdoc:\n        cmdline.append('--rdoc')\n    else:\n        cmdline.append('--no-rdoc')\n    if development:\n        cmdline.append('--development')\n    if format_executable:\n        cmdline.append('--format-executable')\n    if force:\n        cmdline.append('--force')\n    if version:\n        cmdline.extend(['--version', version])\n    cmdline.extend(['--clear-sources',\n                    '--source', gem_source or RubyGems().gem_source])\n\n    cmdline.append(gemname)\n\n    msg = 'Installing ruby gem: %s' % gemname\n    if version:\n        msg += ' Version requested: %s' % version\n    log.debug(msg)\n\n    try:\n        subprocess.check_output(cmdline, shell=False)\n    except (OSError, subprocess.CalledProcessError) as err:\n        raise error.ButcherError(\n            'Gem install failed. Error was: %s. Output: %s' % (\n                err, err.output))", "response": "Install a ruby gem."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if a gem is installed.", "response": "def is_installed(gemname, version=None):\n    \"\"\"Check if a gem is installed.\"\"\"\n    cmdline = ['gem', 'list', '-i', gemname]\n    if version:\n        cmdline.extend(['-v', version])\n    try:\n        subprocess.check_output(cmdline, shell=False)\n        return True\n    except (OSError, subprocess.CalledProcessError) as err:\n        if err.returncode == 1:\n            return False\n        else:\n            raise error.ButcherError(\n                'Failure running gem. Error was: %s. Output: %s', err,\n                err.output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmerges links from another node with ``self.link_list``. Copy links from another node, merging when copied links point to a node which this already links to. Args: other_node (Node): The node to merge links from merge_same_value_targets (bool): Whether or not to merge links whose targets have the same value (but are not necessarily the same ``Node``). If False, links will only be merged when ``link_in_other.target == link_in_self.target``. If True, links will be merged when ``link_in_other.target.value == link_in_self.target.value`` Returns: None Example: >>> node_1 = Node('One') >>> node_2 = Node('Two') >>> node_1.add_link(node_1, 1) >>> node_1.add_link(node_2, 3) >>> node_2.add_link(node_1, 4) >>> node_1.merge_links_from(node_2) >>> print(node_1) node.Node instance with value One with 2 links: 0: 5 --> One 1: 3 --> Two", "response": "def merge_links_from(self, other_node, merge_same_value_targets=False):\n        \"\"\"\n        Merge links from another node with ``self.link_list``.\n\n        Copy links from another node, merging when copied links point to a\n        node which this already links to.\n\n        Args:\n            other_node (Node): The node to merge links from\n            merge_same_value_targets (bool): Whether or not to merge links\n                whose targets have the same value (but are not necessarily\n                the same ``Node``). If False, links will only be merged\n                when ``link_in_other.target == link_in_self.target``. If True,\n                links will be merged when\n                ``link_in_other.target.value == link_in_self.target.value``\n\n        Returns: None\n\n        Example:\n            >>> node_1 = Node('One')\n            >>> node_2 = Node('Two')\n            >>> node_1.add_link(node_1, 1)\n            >>> node_1.add_link(node_2, 3)\n            >>> node_2.add_link(node_1, 4)\n            >>> node_1.merge_links_from(node_2)\n            >>> print(node_1)\n            node.Node instance with value One with 2 links:\n                0: 5 --> One\n                1: 3 --> Two\n        \"\"\"\n        for other_link in other_node.link_list:\n            for existing_link in self.link_list:\n                if merge_same_value_targets:\n                    if other_link.target.value == existing_link.target.value:\n                        existing_link.weight += other_link.weight\n                        break\n                else:\n                    if other_link.target == existing_link.target:\n                        existing_link.weight += other_link.weight\n                        break\n            else:\n                self.add_link(other_link.target, other_link.weight)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the link that points to target_node.", "response": "def find_link(self, target_node):\n        \"\"\"\n        Find the link that points to ``target_node`` if it exists.\n\n        If no link in ``self`` points to ``target_node``, return None\n\n        Args:\n            target_node (Node): The node to look for in ``self.link_list``\n\n        Returns:\n            Link: An existing link pointing to ``target_node`` if found\n\n            None: If no such link exists\n\n        Example:\n            >>> node_1 = Node('One')\n            >>> node_2 = Node('Two')\n            >>> node_1.add_link(node_2, 1)\n            >>> link_1 = node_1.link_list[0]\n            >>> found_link = node_1.find_link(node_2)\n            >>> found_link == link_1\n            True\n        \"\"\"\n        try:\n            return next(l for l in self.link_list if l.target == target_node)\n        except StopIteration:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a link to the list of target nodes and add a weight to that link.", "response": "def add_link(self, targets, weight):\n        \"\"\"\n        Add link(s) pointing to ``targets``.\n\n        If a link already exists pointing to a target, just add ``weight``\n        to that link's weight\n\n        Args:\n            targets (Node or list[Node]): node or nodes to link to\n            weight (int or float): weight for the new link(s)\n\n        Returns: None\n\n        Example:\n            >>> node_1 = Node('One')\n            >>> node_2 = Node('Two')\n            >>> node_1.add_link(node_2, 1)\n            >>> new_link = node_1.link_list[0]\n            >>> print(new_link)\n            node.Link instance pointing to node with value \"Two\" with weight 1\n        \"\"\"\n        # Generalize targets to a list to simplify code\n        if not isinstance(targets, list):\n            target_list = [targets]\n        else:\n            target_list = targets\n\n        for target in target_list:\n            # Check to see if self already has a link to target\n            for existing_link in self.link_list:\n                if existing_link.target == target:\n                    existing_link.weight += weight\n                    break\n            else:\n                self.link_list.append(Link(target, weight))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_link_to_self(self, source, weight):\n        # Generalize source to a list to simplify code\n        if not isinstance(source, list):\n            source = [source]\n        for source_node in source:\n            source_node.add_link(self, weight=weight)", "response": "Create and add a Link instance pointing to self."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd links pointing in either direction between ``self`` and ``target``. This creates a ``Link`` from ``self`` to ``target`` and a ``Link`` from ``target`` to ``self`` of equal weight. If ``target`` is a list of ``Node`` 's, repeat this for each one. Args: target (Node or list[Node]): weight (int or float): Returns: None Example: >>> node_1 = Node('One') >>> node_2 = Node('Two') >>> node_1.add_reciprocal_link(node_2, 5) >>> new_link_1 = node_1.link_list[0] >>> new_link_2 = node_2.link_list[0] >>> print(new_link_1) node.Link instance pointing to node with value \"Two\" with weight 5 >>> print(new_link_2) node.Link instance pointing to node with value \"One\" with weight 5", "response": "def add_reciprocal_link(self, target, weight):\n        \"\"\"\n        Add links pointing in either direction between ``self`` and ``target``.\n\n        This creates a ``Link`` from ``self`` to ``target`` and a ``Link``\n        from ``target`` to ``self`` of equal weight. If ``target`` is a list\n        of ``Node`` 's, repeat this for each one.\n\n        Args:\n            target (Node or list[Node]):\n            weight (int or float):\n\n        Returns: None\n\n        Example:\n            >>> node_1 = Node('One')\n            >>> node_2 = Node('Two')\n            >>> node_1.add_reciprocal_link(node_2, 5)\n            >>> new_link_1 = node_1.link_list[0]\n            >>> new_link_2 = node_2.link_list[0]\n            >>> print(new_link_1)\n            node.Link instance pointing to node with value \"Two\" with weight 5\n            >>> print(new_link_2)\n            node.Link instance pointing to node with value \"One\" with weight 5\n        \"\"\"\n        # Generalize ``target`` to a list\n        if not isinstance(target, list):\n            target_list = [target]\n        else:\n            target_list = target\n        for t in target_list:\n            self.add_link(t, weight)\n            t.add_link(self, weight)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves any links from self.", "response": "def remove_links_to_self(self):\n        \"\"\"\n        Remove any link in ``self.link_list`` whose ``target`` is ``self``.\n\n        Returns: None\n\n        Example:\n            >>> node_1 = Node('One')\n            >>> node_1.add_link(node_1, 5)\n            >>> node_1.remove_links_to_self()\n            >>> len(node_1.link_list)\n            0\n        \"\"\"\n        self.link_list = [link for link in self.link_list if\n                          link.target != self]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncompiles given source code.", "response": "def compile(self, source_code, post_treatment=''.join):\n        \"\"\"Compile given source code.\n        Return object code, modified by given post treatment.\n        \"\"\"\n        # read structure\n        structure = self._structure(source_code)\n        values    = self._struct_to_values(structure, source_code)\n        # create object code, translated in targeted language\n        obj_code = langspec.translated(\n            structure, values, \n            self.target_lang_spec\n        )\n        # apply post treatment and return\n        return obj_code if post_treatment is None else post_treatment(obj_code)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate tables for structure and values word - > vocabulary", "response": "def _initialize_tables(self):\n        \"\"\"Create tables for structure and values, word->vocabulary\"\"\"\n        # structure table\n        self.table_struct, self.idnt_struct_size = self._create_struct_table()\n        # values table\n        self.table_values, self.idnt_values_size = self._create_values_table()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn structure in ACDP format.", "response": "def _structure(self, source_code):\n        \"\"\"return structure in ACDP format.\"\"\"\n        # define cutter as a per block reader\n        def cutter(seq, block_size):\n            for index in range(0, len(seq), block_size):\n                lexem = seq[index:index+block_size]\n                if len(lexem) == block_size:\n                    yield self.table_struct[seq[index:index+block_size]]\n        return tuple(cutter(source_code, self.idnt_struct_size))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning next readable lexem of given type in source_code.", "response": "def _next_lexem(self, lexem_type, source_code, source_code_size):\n        \"\"\"Return next readable lexem of given type in source_code.\n        If no value can be found, the neutral_value will be used\"\"\"\n        # define reader as a lexem extractor\n        def reader(seq, block_size):\n            identificator = ''\n            for char in source_code:\n                if len(identificator) == self.idnt_values_size[lexem_type]:\n                    yield self.table_values[lexem_type][identificator]\n                    identificator = ''\n                identificator += char\n        lexem_reader = reader(source_code, self.idnt_values_size)\n        lexem = None\n        time_out = 0\n        while lexem == None and time_out < 2*source_code_size: \n            lexem = next(lexem_reader)\n            time_out += 1\n        # here we have found a lexem\n        return lexem"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the next condition lexem readed in source_code", "response": "def _next_condition_lexems(self, source_code, source_code_size):\n        \"\"\"Return condition lexem readed in source_code\"\"\"\n        # find three lexems\n        lexems = tuple((\n            self._next_lexem(LEXEM_TYPE_COMPARISON, source_code, source_code_size),\n            self._next_lexem(LEXEM_TYPE_OPERATOR  , source_code, source_code_size),\n            self._next_lexem(LEXEM_TYPE_COMPARISON, source_code, source_code_size)\n        ))\n        # verify integrity\n        if None in lexems: # one of the condition lexem was not found in source code \n            return None\n        else: # all lexems are valid\n            return ' '.join(lexems)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread an integer in s in Little Indian.", "response": "def _string_to_int(self, s):\n        \"\"\"Read an integer in s, in Little Indian. \"\"\"\n        base = len(self.alphabet)\n        return sum((self._letter_to_int(l) * base**lsb \n                    for lsb, l in enumerate(s)\n                   ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns list of values readed in source_code according to given structure.", "response": "def _struct_to_values(self, structure, source_code):\n        \"\"\"Return list of values readed in source_code, \n        according to given structure.\n        \"\"\"\n        # iterate on source code until all values are finded\n        # if a value is not foundable, \n        #   (ie its identificator is not in source code)\n        #   it will be replaced by associated neutral value\n        iter_source_code = itertools.cycle(source_code)\n        values = []\n        for lexem_type in (l for l in structure if l is not 'D'):\n            if lexem_type is LEXEM_TYPE_CONDITION:\n                new_value = self._next_condition_lexems(\n                    iter_source_code, len(source_code)\n                )\n            else:\n                new_value = self._next_lexem(\n                    lexem_type, iter_source_code, len(source_code)\n                )\n            # if values is unvalid:\n            #   association with the right neutral value\n            if new_value is None:\n                if lexem_type in (LEXEM_TYPE_PREDICAT, LEXEM_TYPE_CONDITION):\n                    new_value = self.neutral_value_condition\n                else:\n                    new_value = self.neutral_value_action\n            values.append(new_value)\n\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_struct_table(self):\n        len_alph = len(self.alphabet)\n        len_vocb = len(self.voc_structure)\n        identificator_size = ceil(log(len_vocb, len_alph))\n        # create list of lexems \n        num2alph = lambda x, n: self.alphabet[(x // len_alph**n) % len_alph]\n        identificators = [[str(num2alph(x, n)) \n                           for n in range(identificator_size)\n                          ] \n                          for x in range(len_vocb)\n                         ]\n        # initialize table and iterable\n        identificators_table = {}\n        zip_id_voc = zip_longest(\n            identificators, self.voc_structure, \n            fillvalue=None\n        )\n        # create dict identificator:word\n        for idt, word in zip_id_voc:\n            identificators_table[''.join(idt)] = word\n        return identificators_table, identificator_size", "response": "Create table identificator - > vocabulary - > word - > word - > word - > word - > word - > word - > word - > word - > word - > word - > word - > word - > word - > word - > word - > word - > word - > word - > word - > word - > word - > word - > word - > word - > word"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a cusotom implementation of a served http resource.", "response": "def addDesktopResource(self, pluginSubPath: bytes, resource: BasicResource) -> None:\n        \"\"\" Add Site Resource\n\n        Add a cusotom implementation of a served http resource.\n\n        :param pluginSubPath: The resource path where you want to serve this resource.\n        :param resource: The resource to serve.\n        :return: None\n\n        \"\"\"\n        pluginSubPath = pluginSubPath.strip(b'/')\n        self.__rootDesktopResource.putChild(pluginSubPath, resource)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_arg_types(funcname, *args):\n    hasstr = hasbytes = False\n    for arg in args:\n        if isinstance(arg, str):\n            hasstr = True\n        elif isinstance(arg, bytes):\n            hasbytes = True\n        else:\n            raise TypeError('{0}() argument must be str or bytes, not {1}'\n                            .format(funcname, arg.__class__.__name__))\n    if hasstr and hasbytes:\n        raise TypeError(\"Can't mix strings and bytes in path components\")", "response": "Raise TypeError if not all items of args are same string type."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a sequence of POSIX path names return the longest common sub - path.", "response": "def posix_commonpath(paths):\n    \"\"\"Given a sequence of POSIX path names,\n       return the longest common sub-path.\"\"\"\n\n    if not paths:\n        raise ValueError('commonpath() arg is an empty sequence')\n\n    check_arg_types('commonpath', *paths)\n\n    if isinstance(paths[0], bytes):\n        sep = b'/'\n        curdir = b'.'\n    else:\n        sep = '/'\n        curdir = '.'\n\n    split_paths = [path.split(sep) for path in paths]\n\n    try:\n        isabs, = set(p[:1] == sep for p in paths)\n    except ValueError:\n        raise ValueError(\"Can't mix absolute and relative paths\")\n\n    split_paths = [[c for c in s if c and c != curdir] for s in split_paths]\n    s_min = min(split_paths)\n    s_max = max(split_paths)\n    common = s_min\n    for i, run_c in enumerate(s_min):\n        if run_c != s_max[i]:\n            common = s_min[:i]\n            break\n\n    prefix = sep if isabs else sep[:0]\n    return prefix + sep.join(common)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nt_commonpath(paths):  # pylint: disable=too-many-locals\n\n    from ntpath import splitdrive\n\n    if not paths:\n        raise ValueError('commonpath() arg is an empty sequence')\n\n    check_arg_types('commonpath', *paths)\n\n    if isinstance(paths[0], bytes):\n        sep = b'\\\\'\n        altsep = b'/'\n        curdir = b'.'\n    else:\n        sep = '\\\\'\n        altsep = '/'\n        curdir = '.'\n\n    drivesplits = [splitdrive(p.replace(altsep, sep).lower()) for p in paths]\n    split_paths = [p.split(sep) for d, p in drivesplits]\n\n    try:\n        isabs, = set(p[:1] == sep for d, p in drivesplits)\n    except ValueError:\n        raise ValueError(\"Can't mix absolute and relative paths\")\n\n    # Check that all drive letters or UNC paths match. The check is made\n    # only now otherwise type errors for mixing strings and bytes would not\n    # be caught.\n    if len(set(d for d, p in drivesplits)) != 1:\n        raise ValueError(\"Paths don't have the same drive\")\n\n    drive, path = splitdrive(paths[0].replace(altsep, sep))\n    common = path.split(sep)\n    common = [c for c in common if c and c != curdir]\n\n    split_paths = [[c for c in s if c and c != curdir] for s in split_paths]\n    s_min = min(split_paths)\n    s_max = max(split_paths)\n    for i, run_c in enumerate(s_min):\n        if run_c != s_max[i]:\n            common = common[:i]\n            break\n    else:\n        common = common[:len(s_min)]\n\n    prefix = drive + sep if isabs else drive\n    return prefix + sep.join(common)", "response": "Given a sequence of NT path names return the longest common sub - path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget comments to this thing. returns a list of the last limit comments", "response": "def comments(self, limit=None):\n        \"\"\"GETs comments to this thing.\n        \n        :param limit: max number of comments to return\n        \"\"\"\n        return self._reddit._limit_get(self.permalink, limit=limit)[1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndistinguish this thing (POST). Calls :meth:`narwal.Reddit.distinguish`. :param how: either True, False, or 'admin'", "response": "def distinguish(self, how=True):\n        \"\"\"Distinguishes this thing (POST).  Calls :meth:`narwal.Reddit.distinguish`.\n        \n        :param how: either True, False, or 'admin'\n        \"\"\"\n        return self._reddit.distinguish(self.name, how=how)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef next_listing(self, limit=None):\n        if self.after:\n            return self._reddit._limit_get(self._path, params={'after': self.after}, limit=limit or self._limit)\n        elif self._has_literally_more:\n            more = self[-1]\n            data = dict(\n                link_id=self[0].parent_id,\n                id=more.name,\n                children=','.join(more.children)\n            )\n            j = self._reddit.post('api', 'morechildren', data=data)\n            # since reddit is inconsistent here, we're hacking it to be\n            # consistent so it'll work with _thingify\n            d = j['json']\n            d['kind'] = 'Listing'\n            d['data']['children'] = d['data']['things']\n            del d['data']['things']\n            return self._reddit._thingify(d, path=self._path) \n        else:\n            raise NoMoreError('no more items')", "response": "GETs next listing directed to by this : class : Listing object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the previous listing of the current user.", "response": "def prev_listing(self, limit=None):\n        \"\"\"GETs previous :class:`Listing` directed to by this :class:`Listing`.  Returns :class:`Listing` object.\n        \n        :param limit: max number of entries to get\n        \"\"\"\n        if self.before:\n            return self._reddit._limit_get(self._path, eparams={'before': self.before}, limit=limit or self._limit)\n        else:\n            raise NoMoreError('no previous items')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget hot links from this subreddit.", "response": "def hot(self, limit=None):\n        \"\"\"GETs hot links from this subreddit.  Calls :meth:`narwal.Reddit.hot`.\n        \n        :param limit: max number of links to return\n        \"\"\"\n        return self._reddit.hot(self.display_name, limit=limit)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef new(self, limit=None):\n        return self._reddit.new(self.display_name, limit=limit)", "response": "GETs new links from this subreddit."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the top links from this subreddit.", "response": "def top(self, limit=None):\n        \"\"\"GETs top links from this subreddit.  Calls :meth:`narwal.Reddit.top`.\n        \n        :param limit: max number of links to return\n        \"\"\"\n        return self._reddit.top(self.display_name, limit=limit)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the controversial links from this subreddit.", "response": "def controversial(self, limit=None):\n        \"\"\"GETs controversial links from this subreddit.  Calls :meth:`narwal.Reddit.controversial`.\n        \n        :param limit: max number of links to return\n        \"\"\"\n        return self._reddit.controversial(self.display_name, limit=limit)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets newest comments from this subreddit.", "response": "def comments(self, limit=None):\n        \"\"\"GETs newest comments from this subreddit.  Calls :meth:`narwal.Reddit.comments`.\n        \n        :param limit: max number of links to return\n        \"\"\"\n        return self._reddit.comments(self.display_name, limit=limit)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef submit_link(self, title, url):\n        return self._reddit.submit_link(self.display_name, title, url)", "response": "Submit a link to this subreddit."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef submit_text(self, title, text):\n        return self._reddit.submit_text(self.display_name, title, text)", "response": "Submit text to this subreddit."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef moderators(self, limit=None):\n        return self._reddit.moderators(self.display_name, limit=limit)", "response": "GETs moderators for this subreddit."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef flair(self, name, text, css_class):\n        return self._reddit.flair(self.display_name, name, text, css_class)", "response": "Sets flair for the user in this subreddit."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the flairlist for this subreddit.", "response": "def flairlist(self, limit=1000, after=None, before=None):\n        \"\"\"GETs flairlist for this subreddit.  Calls :meth:`narwal.Reddit.flairlist`.\n        \n        :param limit: max number of items to return\n        :param after: full id of user to return entries after\n        :param before: full id of user to return entries *before*\n        \"\"\"\n        return self._reddit.flairlist(self.display_name, limit=limit, after=after, before=before)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget contributors for this subreddit.", "response": "def contributors(self, limit=None):\n        \"\"\"GETs contributors for this subreddit.  Calls :meth:`narwal.Reddit.contributors`.\n        \n        :param limit: max number of items to return\n        \"\"\"\n        return self._reddit.contributors(self.display_name, limit=limit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reply(self, text):\n        data = {\n            'thing_id': self.name,\n            'id': '#commentreply_{0}'.format(self.name),\n            'text': text,\n        }\n        j = self._reddit.post('api', 'comment', data=data)\n        try:\n            return self._reddit._thingify(j['json']['data']['things'][0], path=self._path)\n        except Exception:\n            raise UnexpectedResponse(j)", "response": "POSTs reply to message with own message. Returns posted message."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef overview(self, limit=None):\n        return self._reddit.user_overview(self.name, limit=limit)", "response": "GETs overview of user s activities."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the comments of the user.", "response": "def comments(self, limit=None):\n        \"\"\"GETs user's comments.  Calls :meth:`narwal.Reddit.user_comments`.\n        \n        :param limit: max number of comments to get\n        \"\"\"\n        return self._reddit.user_comments(self.name, limit=limit)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the user s submissions.", "response": "def submitted(self, limit=None):\n        \"\"\"GETs user's submissions.  Calls :meth:`narwal.Reddit.user_submitted`.\n        \n        :param limit: max number of submissions to get\n        \"\"\"\n        return self._reddit.user_submitted(self.name, limit=limit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomposes a message to this user.", "response": "def message(self, subject, text):\n        \"\"\"Compose a message to this user.  Calls :meth:`narwal.Reddit.compose`.\n        \n        :param subject: subject of message\n        :param text: body of message\n        \"\"\"\n        return self._reddit.compose(self.name, subject, text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning decorator. Used to decorate function that handles exception class exc. An optional exception handler can be passed as a second argument. This exception handler shall have the signature handler(exc, message, traceback).", "response": "def catches(exc, handler=re_raise):\n    '''\n    Function decorator. Used to decorate function that handles exception class exc.\n\n    An optional exception handler can be passed as a second argument. This exception\n    handler shall have the signature\n            handler(exc, message, traceback).\n    '''\n    if not __CHECKING__:\n        return lambda f: f\n\n    def wrap(f):\n        def call(*args, **kwd):\n            try:\n                ID = exc_checker.set_attention(exc)\n                res = f(*args, **kwd)\n                exc_checker.remove_attention(exc, ID)\n                return res\n            # handle checked exception\n            except exc, e:\n                exc_checker.remove_attention(exc, ID)\n                traceback = sys.exc_info()[2]\n                return handler(exc, str(e), traceback.tb_next.tb_next)\n            # re-raise unchecked exception but remove checked exeption info first\n            except Exception, e:\n                exc_checker.remove_attention(exc, ID)\n                traceback = sys.exc_info()[2]\n                raise e.__class__, e.args, traceback.tb_next.tb_next\n        call.__name__ = f.__name__\n        return call\n    return wrap"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef throws(exc):\n    '''\n    throws(exc)(func) -> func'\n\n    Function decorator. Used to decorate a function that raises exc.\n    '''\n    if not __CHECKING__:\n        return lambda f: f\n\n    def wrap(f):\n        def call(*args, **kwd):\n            res = f(*args, **kwd)\n            # raise UncheckedExceptionError if exc is not automatically\n            # registered by a function decorated with @catches(exc);\n            # otherwise do nothing\n            exc_checker.throwing(exc)\n            return res\n        call.__name__ = f.__name__\n        return call\n    return wrap", "response": "Function decorator. Used to decorate a function that raises exc.\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef locked(self):\n        conn = self._get_connection()\n        try:\n            self._lock(conn)\n            yield conn\n        finally:\n            self._unlock(conn)", "response": "Context generator for with statement yields thread - safe connection."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query(self, sql, *args, **kwargs):\n        with self.locked() as conn:\n            for row in conn.query(sql, *args, **kwargs):\n                yield row", "response": "Executes an SQL SELECT query and returns rows generator."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute(self, sql, *args, **kwargs):\n        with self.locked() as conn:\n            return conn.execute(sql, *args, **kwargs)", "response": "Executes an SQL INSERT UPDATE DELETE query with the given parameters and returns the number of affected rows."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fetch(self, sql, *args, **kwargs):\n        with self.locked() as conn:\n            return conn.query(sql, *args, **kwargs).fetch()", "response": "Executes an SQL SELECT query and returns the first row or None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting an SQL SELECT query and returns all selected rows.", "response": "def fetch_all(self, sql, *args, **kwargs):\n        \"\"\"Executes an SQL SELECT query and returns all selected rows.\n\n        :param sql: statement to execute\n        :param args: parameters iterable\n        :param kwargs: parameters iterable\n        :return: all selected rows\n        :rtype: list\n        \"\"\"\n        with self.locked() as conn:\n            return conn.query(sql, *args, **kwargs).fetch_all()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fetch_column(self, sql, *args, **kwargs):\n        with self.locked() as conn:\n            return conn.query(sql, *args, **kwargs).fetch_column()", "response": "Executes an SQL SELECT query and returns the first column of the first row or None."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert(self, table, values):\n        with self.locked() as conn:\n            return conn.insert(table, values)", "response": "Inserts a table row with specified data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, table, values, identifier):\n        with self.locked() as conn:\n            return conn.update(table, values, identifier)", "response": "Updates a table row with specified data by given identifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a table row by given identifier.", "response": "def delete(self, table, identifier):\n        \"\"\"Deletes a table row by given identifier.\n\n        :param table: the expression of the table to update quoted or unquoted\n        :param identifier: the delete criteria; a dictionary containing column-value pairs\n        :return: the number of affected rows\n        :rtype: int\n        \"\"\"\n        with self.locked() as conn:\n            return conn.delete(table, identifier)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts data in bytes if data is a string", "response": "def ensure_bytes(data: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Convert data in bytes if data is a string\n\n    :param data: Data\n    :rtype bytes:\n    \"\"\"\n    if isinstance(data, str):\n        return bytes(data, 'utf-8')\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ensure_str(data: Union[str, bytes]) -> str:\n    if isinstance(data, bytes):\n        return str(data, 'utf-8')\n\n    return data", "response": "Convert data in str if data is bytes"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef xor_bytes(b1: bytes, b2: bytes) -> bytearray:\n    result = bytearray()\n    for i1, i2 in zip(b1, b2):\n        result.append(i1 ^ i2)\n    return result", "response": "Apply XOR operation on two bytes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new Kompile class based on the supplied source code and returnsit.", "response": "def kompile(src, raw=False, filename='<compiler>', loader=None, **kwargs):\n    '''\n    Creates a new class based on the supplied template, and returnsit.\n\n    class Template(object):\n        def __call__(self, context):\n            return ''.join(self._iterator(context))\n\n        def _iterator(self, context):\n            return map(str, self._root(context)\n\n        def _root(self, context):\n            yield ''\n            yield ...\n            yield from self.head(context)\n\n    Blocks create new methods, and add a 'yield from self.{block}(context)' to\n    the current function\n\n    '''\n\n    parser = Parser(src, loader=loader)\n    parser.load_library('knights.tags')\n    parser.load_library('knights.helpers')\n\n    parser.build_method('_root')\n\n    if parser.parent:\n        # Remove _root from the method list\n        parser.methods = [\n            method for method in parser.methods if method.name != '_root'\n        ]\n\n    klass = parser.build_class()\n\n    # Wrap it in a module\n    inst = ast.Module(body=[klass])\n\n    ast.fix_missing_locations(inst)\n\n    if kwargs.get('astor', False):\n        import astor\n        print(astor.to_source(inst))\n\n    # Compile code to create class\n    code = compile(inst, filename=filename, mode='exec', optimize=2)\n\n    # Execute it and return the instance\n    g = {\n        '_': Helpers(parser.helpers),\n        'parent': parser.parent,\n        'ContextScope': ContextScope,\n    }\n    eval(code, g)\n\n    klass = g['Template']\n    if raw:\n        return klass\n    return klass()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calculate_checksum(source_string):\n    countTo = (int(len(source_string) / 2)) * 2\n    sum = 0\n    count = 0\n\n    # Handle bytes in pairs (decoding as short ints)\n    loByte = 0\n    hiByte = 0\n    while count < countTo:\n        if (sys.byteorder == \"little\"):\n            loByte = source_string[count]\n            hiByte = source_string[count + 1]\n        else:\n            loByte = source_string[count + 1]\n            hiByte = source_string[count]\n        sum = sum + (ord(hiByte) * 256 + ord(loByte))\n        count += 2\n\n    # Handle last byte if applicable (odd-number of bytes)\n    # Endianness should be irrelevant in this case\n    if countTo < len(source_string): # Check for odd length\n        loByte = source_string[len(source_string) - 1]\n        sum += ord(loByte)\n\n    sum &= 0xffffffff # Truncate sum to 32 bits (a variance from ping.c, which\n                      # uses signed ints, but overflow is unlikely in ping)\n\n    sum = (sum >> 16) + (sum & 0xffff)    # Add high 16 bits to low 16 bits\n    sum += (sum >> 16)                    # Add carry from above (if any)\n    answer = ~sum & 0xffff                # Invert and truncate to 16 bits\n    answer = socket.htons(answer)\n\n    return answer", "response": "Calculates the checksum of a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef signal_handler(self, signum, frame):\n        self.print_exit()\n        print(\"\\n(Terminated with signal %d)\\n\" % (signum))\n        sys.exit(0)", "response": "Handle print_exit via signals."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef header2dict(self, names, struct_format, data):\n        unpacked_data = struct.unpack(struct_format, data)\n        return dict(zip(names, unpacked_data))", "response": "Unpack the raw received IP and ICMP header information to a dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending one ICMP ECHO_REQUEST and receive one ICMP ECHO_REQUEST and return a PingResponse object.", "response": "def do(self):\n        \"\"\"\n        Send one ICMP ECHO_REQUEST and receive the response until self.timeout.\n        \"\"\"\n        try: # One could use UDP here, but it's obscure\n            current_socket = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.getprotobyname(\"icmp\"))\n        except socket.error as (errno, msg):\n            if errno == 1:\n                # Operation not permitted - Add more information to traceback\n                etype, evalue, etb = sys.exc_info()\n                evalue = etype(\n                    \"%s - Note that ICMP messages can only be send from processes running as root.\" % evalue\n                )\n                raise etype, evalue, etb\n            raise # raise the original error\n\n        send_time = self.send_one_ping(current_socket)\n        if send_time == None:\n            return\n        self.send_count += 1\n\n        receive_time, packet_size, ip, ip_header, icmp_header = self.receive_one_ping(current_socket)\n        current_socket.close()\n\n        if receive_time:\n            self.receive_count += 1\n            delay = (receive_time - send_time) * 1000.0\n            self.total_time += delay\n            if self.min_time > delay:\n                self.min_time = delay\n            if self.max_time < delay:\n                self.max_time = delay\n\n            return PingSuccess(delay, ip, packet_size, ip_header, icmp_header)\n        else:\n            return PingTimeout(self.destination)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending one ICMP ECHO_REQUEST.", "response": "def send_one_ping(self, current_socket):\n        \"\"\"\n        Send one ICMP ECHO_REQUEST.\n        \"\"\"\n        # Header is type (8), code (8), checksum (16), id (16), sequence (16)\n        checksum = 0\n\n        # Make a dummy header with a 0 checksum.\n        header = struct.pack(\n            \"!BBHHH\", ICMP_ECHO, 0, checksum, self.own_id, self.seq_number\n        )\n\n        padBytes = []\n        startVal = 0x42\n        for i in range(startVal, startVal + (self.packet_size)):\n            padBytes += [(i & 0xff)]  # Keep chars in the 0-255 range\n        data = bytes(padBytes)\n\n        # Calculate the checksum on the data and the dummy header.\n        checksum = calculate_checksum(header + data) # Checksum is in network order\n\n        # Now that we have the right checksum, we put that in. It's just easier\n        # to make up a new header than to stuff it into the dummy.\n        header = struct.pack(\n            \"!BBHHH\", ICMP_ECHO, 0, checksum, self.own_id, self.seq_number\n        )\n\n        packet = header + data\n\n        send_time = default_timer()\n\n        try:\n            current_socket.sendto(packet, (self.destination, 1)) # Port number is irrelevant for ICMP\n        except socket.error as e:\n            print(\"General failure (%s)\" % (e.args[1]))\n            current_socket.close()\n            return\n\n        return send_time"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef receive_one_ping(self, current_socket):\n        timeout = self.timeout / 1000.0\n\n        while True: # Loop while waiting for packet or timeout\n            select_start = default_timer()\n            inputready, outputready, exceptready = select.select([current_socket], [], [], timeout)\n            select_duration = (default_timer() - select_start)\n            if inputready == []: # timeout\n                return None, 0, 0, 0, 0\n\n            receive_time = default_timer()\n\n            packet_data, address = current_socket.recvfrom(ICMP_MAX_RECV)\n\n            icmp_header = self.header2dict(\n                names=[\n                    \"type\", \"code\", \"checksum\",\n                    \"packet_id\", \"seq_number\"\n                ],\n                struct_format=\"!BBHHH\",\n                data=packet_data[20:28]\n            )\n\n            if icmp_header[\"packet_id\"] == self.own_id: # Our packet\n                ip_header = self.header2dict(\n                    names=[\n                        \"version\", \"type\", \"length\",\n                        \"id\", \"flags\", \"ttl\", \"protocol\",\n                        \"checksum\", \"src_ip\", \"dest_ip\"\n                    ],\n                    struct_format=\"!BBHHHBBHII\",\n                    data=packet_data[:20]\n                )\n                packet_size = len(packet_data) - 28\n                ip = socket.inet_ntoa(struct.pack(\"!I\", ip_header[\"src_ip\"]))\n                # XXX: Why not ip = address[0] ???\n                return receive_time, packet_size, ip, ip_header, icmp_header\n\n            timeout = timeout - select_duration\n            if timeout <= 0:\n                return None, 0, 0, 0, 0", "response": "Receive one ping from the socket."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_link(self, peer):\n        for access in peer.accesses:\n            if access.type == 'mqtt':\n                break\n        else:\n            # No MQTT access found\n            return None\n\n        # Get server access tuple\n        server = (access.server.host, access.server.port)\n\n        with self.__lock:\n            try:\n                # Get existing link\n                return self._links[server]\n\n            except KeyError:\n                # Create a new link\n                link = self._links[server] = MQTTLink(access)\n                return link", "response": "Retrieves the link to the given peer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exit(exit_code=0):\n  core.processExitHooks()\n\n  if state.isExitHooked and not hasattr(sys, 'exitfunc'): # The function is called from the exit hook\n    sys.stderr.flush()\n    sys.stdout.flush()\n    os._exit(exit_code) #pylint: disable=W0212\n\n  sys.exit(exit_code)", "response": "Exit the current process."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef listMemberHelps(TargetGroup):\n  Members = []\n\n  for Member in TargetGroup.Members.values(): # get unique children (by discarding aliases)\n    if Member not in Members:\n      Members.append(Member)\n\n  Ret = []\n\n  for Member in Members:\n    Config = Member.Config\n    Ret.append(('%s%s' % (Config['name'], ', %s' % Config['alias'] if 'alias' in Config else ''), Config.get('desc', '')))\n\n  return Ret", "response": "r Gets help on a group s children."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getTypeStr(_type):\n  if isinstance(_type, CustomType):\n    return str(_type)\n\n  if hasattr(_type, '__name__'):\n    return _type.__name__\n\n  return ''", "response": "Gets the string representation of the given type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getTaskHelp(_Task):\n  Ret = []\n\n  for k in ['name', 'desc']:\n    v = _Task.Config.get(k)\n\n    if v is not None:\n      Ret.append('%s: %s' % (k, v))\n\n  Args = _Task.Args\n\n  if Args:\n    Ret.append('\\nArgs:')\n\n    for argName, Arg in Args.items():\n      Ret.append('  %s: %s' % (argName, Arg.get('desc', Arg['type_str'])))\n\n    Ret.append('')\n\n  return '\\n'.join(Ret).rstrip()", "response": "r Gets help on the given task member."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrestarts this script in a virtual environment", "response": "def restart_in_venv(venv, base, site_packages, args):\n    \"\"\"\n    Restart this script using the interpreter in the given virtual environment\n    \"\"\"\n    if base and not os.path.isabs(venv) and not venv.startswith('~'):\n        base = os.path.expanduser(base)\n        # ensure we have an abs basepath at this point:\n        #    a relative one makes no sense (or does it?)\n        if os.path.isabs(base):\n            venv = os.path.join(base, venv)\n\n    if venv.startswith('~'):\n        venv = os.path.expanduser(venv)\n\n    if not os.path.exists(venv):\n        try:\n            import virtualenv\n        except ImportError:\n            print('The virtual environment does not exist: %s' % venv)\n            print('and virtualenv is not installed, so a new environment cannot be created')\n            sys.exit(3)\n        print('Creating new virtualenv environment in %s' % venv)\n        virtualenv.logger = logger\n        logger.indent += 2\n        virtualenv.create_environment(venv, site_packages=site_packages)\n    if sys.platform == 'win32':\n        python = os.path.join(venv, 'Scripts', 'python.exe')\n        # check for bin directory which is used in buildouts\n        if not os.path.exists(python):\n            python = os.path.join(venv, 'bin', 'python.exe')\n    else:\n        python = os.path.join(venv, 'bin', 'python')\n    if not os.path.exists(python):\n        python = venv\n    if not os.path.exists(python):\n        raise BadCommand('Cannot find virtual environment interpreter at %s' % python)\n    base = os.path.dirname(os.path.dirname(python))\n    file = os.path.join(os.path.dirname(__file__), 'runner.py')\n    if file.endswith('.pyc'):\n        file = file[:-1]\n    proc = subprocess.Popen(\n        [python, file] + args + [base, '___VENV_RESTART___'])\n    proc.wait()\n    sys.exit(proc.returncode)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the public key sequence history of a public key", "response": "async def history(client: Client, pubkey: str) -> dict:\n    \"\"\"\n    Get transactions history of public key\n\n    :param client: Client to connect to the api\n    :param pubkey: Public key\n    :return:\n    \"\"\"\n    return await client.get(MODULE + '/history/%s' % pubkey, schema=HISTORY_SCHEMA)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def process(client: Client, transaction_signed_raw: str) -> ClientResponse:\n    return await client.post(MODULE + '/process', {'transaction': transaction_signed_raw}, rtype=RESPONSE_AIOHTTP)", "response": "POST a transaction raw document"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the sources for a public key", "response": "async def sources(client: Client, pubkey: str) -> dict:\n    \"\"\"\n    GET transaction sources\n\n    :param client: Client to connect to the api\n    :param pubkey: Public key\n    :return:\n    \"\"\"\n    return await client.get(MODULE + '/sources/%s' % pubkey, schema=SOURCES_SCHEMA)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def blocks(client: Client, pubkey: str, start: int, end: int) -> dict:\n    return await client.get(MODULE + '/history/%s/blocks/%s/%s' % (pubkey, start, end), schema=HISTORY_SCHEMA)", "response": "Get public key transactions history between start and end block number"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd arguments for this command to the argument parser.", "response": "def add_argparser(self, root, parents):\n        \"\"\"\n        Add arguments for this command.\n        \"\"\"\n        parser = root.add_parser('report', parents=parents)\n        parser.set_defaults(func=self)\n\n        parser.add_argument(\n            '--auth',\n            dest='auth', action='store',\n            help='Path to the authorized credentials file (analytics.dat).'\n        )\n\n        parser.add_argument(\n            '--title',\n            dest='title', action='store',\n            help='User-friendly title for your report.'\n        )\n\n        parser.add_argument(\n            '--property-id',\n            dest='property-id', action='store',\n            help='Google Analytics ID of the property to query.'\n        )\n\n        parser.add_argument(\n            '--start-date',\n            dest='start-date', action='store',\n            help='Start date for the query in YYYY-MM-DD format.'\n        )\n\n        parser.add_argument(\n            '--end-date',\n            dest='end-date', action='store',\n            help='End date for the query in YYYY-MM-DD format. Supersedes --ndays.'\n        )\n\n        parser.add_argument(\n            '--ndays',\n            dest='ndays', action='store', type=int,\n            help='The number of days from the start-date to query. Requires start-date. Superseded by end-date.'\n        )\n\n        parser.add_argument(\n            '--domain',\n            dest='domain', action='store',\n            help='Restrict results to only urls with this domain.'\n        )\n\n        parser.add_argument(\n            '--prefix',\n            dest='prefix', action='store',\n            help='Restrict results to only urls with this prefix.'\n        )\n\n        parser.add_argument(\n            'input_path',\n            action='store',\n            help='Path to either a YAML configuration file or pre-reported JSON data.'\n        )\n\n        parser.add_argument(\n            'output_path',\n            action='store',\n            help='Path to output either an HTML report or a JSON data file.'\n        )\n\n        return parser"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ndays(self, start_date, ndays):\n        if not getattr(self.args, 'start-date') and not self.config.get('start-date', None):\n            raise Exception('start-date must be provided when ndays is used.')\n\n        d = date(*map(int, start_date.split('-')))\n        d += timedelta(days=ndays)\n\n        return d.strftime('%Y-%m-%d')", "response": "Compute an end date given a start date and a number of days."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef report(self):\n        output = OrderedDict()\n\n        for arg in GLOBAL_ARGUMENTS:\n            output[arg] = getattr(self.args, arg) or self.config.get(arg, None)\n\n        output['title'] = getattr(self.args, 'title') or self.config.get('title', 'Untitled Report')\n        output['run_date'] = datetime.now().strftime('%Y-%m-%d')\n        output['queries'] = []\n\n        for analytic in self.config.get('queries', []):\n            print 'Querying \"%s\"' % analytic['name']\n\n            results = self.query(\n                metrics=analytic['metrics'],\n                dimensions=analytic.get('dimensions', []),\n                filters=analytic.get('filter', None),\n                segment=analytic.get('segment', None),\n                sort=analytic.get('sort', []),\n                start_index=analytic.get('start-index', 1),\n                max_results=analytic.get('max-results', 10)\n            )\n            \n            dimensions_len = len(analytic.get('dimensions', []))\n\n            data = OrderedDict([ \n                ('config', analytic),\n                ('sampled', results.get('containsSampledData', False)),\n                ('sampleSize', int(results.get('sampleSize', 0))),\n                ('sampleSpace', int(results.get('sampleSpace', 0))),\n                ('data_types', OrderedDict()),\n                ('data', OrderedDict())\n            ])\n                    \n            for column in results['columnHeaders'][dimensions_len:]:\n                data['data_types'][column['name']] = column['dataType']\n\n            def cast_data_type(d, dt):\n                if dt == 'INTEGER':\n                    return int(d)\n                elif data_type in ['TIME', 'FLOAT', 'CURRENCY', 'PERCENT']:  \n                    return float(d)\n                else:\n                    raise Exception('Unknown metric data type: %s' % data_type)\n\n            for i, metric in enumerate(analytic['metrics']):\n                data['data'][metric] = OrderedDict()\n                data_type = data['data_types'][metric]\n\n                if dimensions_len:\n                    for row in results.get('rows', []):\n                        column = i + dimensions_len\n                        label = ','.join(row[:dimensions_len]) \n                        value = cast_data_type(row[column], data_type)\n\n                        data['data'][metric][label] = value \n\n                data['data'][metric]['total'] = cast_data_type(results['totalsForAllResults'][metric], data_type)\n\n                # Prevent rate-limiting\n                sleep(1)\n\n            output['queries'].append(data)\n\n        return output", "response": "Query analytics and stash data suitable for serializing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting report data to an HTML file.", "response": "def html(self, report, f):\n        \"\"\"\n        Write report data to an HTML file.\n        \"\"\"\n        env = Environment(loader=PackageLoader('clan', 'templates'))\n\n        template = env.get_template('report.html')\n\n        context = {\n            'report': report,\n            'GLOBAL_ARGUMENTS': GLOBAL_ARGUMENTS,\n            'field_definitions': self.field_definitions,\n            'format_comma': format_comma,\n            'format_duration': format_duration,\n            'format_percent': format_percent\n        }\n\n        f.write(template.render(**context).encode('utf-8'))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ensure_exe(exe_name: str, *paths: str):  # pragma: no cover\n    if not elib_run.find_executable(exe_name, *paths):\n        LOGGER.error('could not find \"%s.exe\" on this system', exe_name)\n        sys.exit(-1)", "response": "Ensures that an executable exists on the system path."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles a captcha request", "response": "def handle_captcha(self, query_params: dict,\n                       html: str,\n                       login_data: dict) -> requests.Response:\n        \"\"\"\n        Handling CAPTCHA request\n        \"\"\"\n        check_url = get_base_url(html)\n        captcha_url = '{}?s={}&sid={}'.format(self.CAPTCHA_URI,\n                                              query_params['s'],\n                                              query_params['sid'])\n        login_data['captcha_sid'] = query_params['sid']\n        login_data['captcha_key'] = input(self.CAPTCHA_INPUT_PROMPT\n                                          .format(captcha_url))\n        return self.post(check_url, login_data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle two factor authorization request", "response": "def handle_two_factor_check(self, html: str) -> requests.Response:\n        \"\"\"\n        Handling two factor authorization request\n        \"\"\"\n        action_url = get_base_url(html)\n        code = input(self.TWO_FACTOR_PROMPT).strip()\n        data = {'code': code, '_ajax': '1', 'remember': '1'}\n        post_url = '/'.join((self.LOGIN_URL, action_url))\n        return self.post(post_url, data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle phone number check request", "response": "def handle_phone_number_check(self, html: str) -> requests.Response:\n        \"\"\"\n        Handling phone number request\n        \"\"\"\n        action_url = get_base_url(html)\n        phone_number = input(self.PHONE_PROMPT)\n        url_params = get_url_params(action_url)\n        data = {'code': phone_number,\n                'act': 'security_check',\n                'hash': url_params['hash']}\n        post_url = '/'.join((self.LOGIN_URL, action_url))\n        return self.post(post_url, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks the url for additional actions and calls the event handler", "response": "def check_for_additional_actions(self, url_params: dict,\n                                     html: str,\n                                     login_data: dict) -> None:\n        \"\"\"\n        Checks the url for a request for additional actions,\n        if so, calls the event handler\n        \"\"\"\n        action_response = ''\n        if 'sid' in url_params:\n            action_response = self.handle_captcha(url_params, html, login_data)\n        elif 'authcheck' in url_params:\n            action_response = self.handle_two_factor_check(html)\n        elif 'security_check' in url_params:\n            action_response = self.handle_phone_number_check(html)\n        if action_response:\n            check_page_for_warnings(action_response.text)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nauthorize a user and returns a bool value of the result", "response": "def login(self) -> bool:\n        \"\"\"\n        Authorizes a user and returns a bool value of the result\n        \"\"\"\n        response = self.get(self.LOGIN_URL)\n        login_url = get_base_url(response.text)\n        login_data = {'email': self._login, 'pass': self._password}\n        login_response = self.post(login_url, login_data)\n        url_params = get_url_params(login_response.url)\n        self.check_for_additional_actions(url_params,\n                                          login_response.text,\n                                          login_data)\n        if 'remixsid' in self.cookies or 'remixsid6' in self.cookies:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nauthenticates a user by OAuth2 to get access token", "response": "def auth_oauth2(self) -> dict:\n        \"\"\"\n        Authorizes a user by OAuth2 to get access token\n        \"\"\"\n        oauth_data = {\n            'client_id': self._app_id,\n            'display': 'mobile',\n            'response_type': 'token',\n            'scope': '+66560',\n            'v': self.API_VERSION\n        }\n        response = self.post(self.OAUTH_URL, oauth_data)\n        url_params = get_url_params(response.url, fragment=True)\n        if 'access_token' in url_params:\n            return url_params\n\n        action_url = get_base_url(response.text)\n        if action_url:\n            response = self.get(action_url)\n            return get_url_params(response.url)\n\n        response_json = response.json()\n        if 'error' in response_json['error']:\n            exception_msg = '{}: {}'.format(response_json['error'],\n                                            response_json['error_description'])\n            raise VVKAuthException(exception_msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_access_token(self) -> str:\n        if self._service_token:\n            return self._service_token\n        if self._app_id and self._login and self._password:\n            try:\n                if self.login():\n                    url_params = self.auth_oauth2()\n                    if 'access_token' in url_params:\n                        return url_params['access_token']\n            finally:\n                self.close()", "response": "Returns the access token in case of successful authorization"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_method_request(self, method: str, method_params: dict) -> dict:\n        url = '/'.join((self.METHOD_URL, method))\n        method_params['v'] = self.API_VERSION\n        if self._access_token:\n            method_params['access_token'] = self._access_token\n        response = self.post(url, method_params, timeout=10)\n        response.raise_for_status()\n        return json.loads(response.text)", "response": "Send a method request to the API."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef train(self, net_sizes, epochs, batchsize):\n        self.trainer = ClassificationTrainer(self.data, self.targets, net_sizes)\n        self.trainer.learn(epochs, batchsize)\n        return self.trainer.evaluate(batchsize)", "response": "Train the base trainer"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclassifying a phrase using the model.", "response": "def classify(self, phrase, cut_to_len=True):\n      \"\"\" Classify a phrase based on the model. (See corresponding function in PhraseClassifier).\n          Provided here mostly to help verify that a created model is worth saving. Technically, the\n          results of the training should be enough for that, but it is good to be able to run it on concrete\n          examples.\n      \"\"\"\n      if (len(phrase) > self.max_phrase_len):\n          if not cut_to_len:\n              raise Exception(\"Phrase too long.\")\n          phrase = phrase[0:self.max_phrase_len]\n      if (self.trainer == None):\n          raise Exception(\"Must train the classifier at least once before classifying\")\n \n      numbers = self.trainer.classify(stringToVector(phrase, self.vocab, self.max_vector_len))\n      return zip(self.targetTranslate, numbers)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef classify(self, phrase, cut_to_len=True):\n      if (len(phrase) > self.max_phrase_len):\n          if not cut_to_len:\n              raise Exception(\"Phrase too long.\")\n          phrase = phrase[0:self.max_phrase_len]\n\n      numbers = self.classifier.classify(stringToVector(phrase, self.vocab, self.max_vector_len))\n      return zip(self.targets, numbers)", "response": "Classify a phrase based on the loaded model."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_command(cmd, path=None, pathext=None):\n    if path is None:\n        path = os.environ.get('PATH', '').split(os.pathsep)\n    if isinstance(path, string_types):\n        path = [path]\n\n    # check if there are path extensions for Windows executables\n    if pathext is None:\n        pathext = os.environ.get('PATHEXT', '.COM;.EXE;.BAT;.CMD')\n        pathext = pathext.split(os.pathsep)\n\n    # don't use extensions if the command ends with one of them\n    for ext in pathext:\n        if cmd.endswith(ext):\n            pathext = ['']\n            break\n\n    # check if we find the command on PATH\n    for p in path:\n        f = os.path.join(p, cmd)\n        if os.path.isfile(f):\n            return f\n        for ext in pathext:\n            fext = f + ext\n            if os.path.isfile(fext):\n                return fext\n    return None", "response": "Find the command in the path and pathext."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a set of all extensions that are passed by extensions.", "response": "def handle_extensions(extensions=None, ignored=None):\n    \"\"\"\n    Organizes multiple extensions that are separated with commas or passed by\n    using --extension/-e multiple times. Note that the .py extension is ignored\n    here because of the way non-*.py files are handled in ``extract`` messages\n    (they are copied to file.ext.py files to trick xgettext to parse them as\n     Python files).\n\n    For example: running::\n\n        $ verboselib-manage extract -e js,txt -e xhtml -a\n\n    would result in an extension list ``['.js', '.txt', '.xhtml']``\n\n    .. code-block:: python\n\n        >>> handle_extensions(['.html', 'html,js,py,py,py,.py', 'py,.py'])\n        set(['.html', '.js'])\n        >>> handle_extensions(['.html, txt,.tpl'])\n        set(['.html', '.tpl', '.txt'])\n\n    Taken `from Django <http://bit.ly/1r7Eokw>`_ and changed a bit.\n    \"\"\"\n    extensions = extensions or ()\n    ignored = ignored or ('py', )\n\n    ext_list = []\n    for ext in extensions:\n        ext_list.extend(ext.replace(' ', '').split(','))\n    for i, ext in enumerate(ext_list):\n        if not ext.startswith('.'):\n            ext_list[i] = '.%s' % ext_list[i]\n    return set([x for x in ext_list if x.strip('.') not in ignored])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting a command and returns the output of the command.", "response": "def cmd(str, print_ret=False, usr_pwd=None, run=True):\n\t\"\"\"\n\tExecutes a command and throws an exception on error.\n\tin:\n\t\tstr - command\n\t\tprint_ret - print command return\n\t\tusr_pwd - execute command as another user (user_name, password)\n\t\trun - really execute command?\n\tout:\n\t\treturns the command output\n\t\"\"\"\n\tif usr_pwd:\n\t\tstr = 'echo {} | sudo -u {} {} '.format(usr_pwd[1], usr_pwd[0], str)\n\n\tprint('  [>] {}'.format(str))\n\n\tif run:\n\t\terr, ret = commands.getstatusoutput(str)\n\telse:\n\t\terr = None\n\t\tret = None\n\n\tif err:\n\t\tprint('  [x] {}'.format(ret))\n\t\traise Exception(ret)\n\tif ret and print_ret:\n\t\tlines = ret.split('\\n')\n\t\tfor line in lines:\n\t\t\tprint('  [<] {}'.format(line))\n\treturn ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getPackages(plist):\n\tnlist = plist.split('\\n')\n\tpkgs = []\n\tfor i in nlist:\n\t\tif i.find('===') > 0: continue\n\t\tpkg = i.split()[0]\n\t\tif pkg   == 'Warning:': continue\n\t\telif pkg == 'Could': continue\n\t\telif pkg == 'Some': continue\n\t\telif pkg == 'You': continue\n\t\telif not pkg: continue\n\t\tpkgs.append(pkg)\n\n\tprint('  >> Found', len(pkgs), 'packages')\n\n\treturn pkgs", "response": "Cleans up input from the command line tool and returns a list of package names"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pip(usr_pswd=None):\n\t# see if pip is installed\n\ttry: cmd('which pip')\n\texcept:\n\t\treturn\n\n\tprint('-[pip]----------')\n\tp = cmd('pip list --outdated')\n\tif not p: return\n\tpkgs = getPackages(p)\n\n\t# update pip and setuptools first\n\tfor i, p in enumerate(pkgs):\n\t\tif p in ['pip', 'setuptools']:\n\t\t\tcmd('pip install -U ' + p, usr_pwd=usr_pswd, run=global_run)\n\t\t\tpkgs.pop(i)\n\n\t# update the rest of them\n\tfor p in pkgs:\n\t\tcmd('pip install -U ' + p, usr_pwd=usr_pswd, run=global_run)", "response": "update pip packages at a time"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef brew(clean=False):\n\t# see if homebrew is installed\n\ttry: cmd('which brew')\n\texcept:\n\t\treturn\n\n\tprint('-[brew]----------')\n\tcmd('brew update')\n\tp = cmd('brew outdated')\n\tif not p: return\n\tpkgs = getPackages(p)\n\tfor p in pkgs:\n\t\tcmd('brew upgrade {}'.format(p), run=global_run)\n\n\tif clean:\n\t\tprint(' > brew prune old sym links and cleanup')\n\t\tcmd('brew prune')\n\t\tcmd('brew cleanup')", "response": "check if homebrew is installed and if so update brew packages and clean up old sym links and cleanup"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the linux kernel", "response": "def kernel():\n\t\"\"\"\n\tHandle linux kernel update\n\t\"\"\"\n\tprint('================================')\n\tprint('  WARNING: upgrading the kernel')\n\tprint('================================')\n\ttime.sleep(5)\n\n\tprint('-[kernel]----------')\n\tcmd('rpi-update', True)\n\tprint(' >> You MUST reboot to load the new kernel <<')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle npm for Node.js", "response": "def npm(usr_pwd=None, clean=False):\n\t\"\"\"\n\tHandle npm for Node.js\n\t\"\"\"\n\t# see if node is installed\n\ttry: cmd('which npm')\n\texcept:\n\t\treturn\n\n\tprint('-[npm]----------')\n\t# awk, ignore 1st line and grab 1st word\n\tp = cmd(\"npm outdated -g | awk 'NR>1 {print $1}'\")\n\tif not p: return\n\tpkgs = getPackages(p)\n\n\tfor p in pkgs:\n\t\tcmd('{} {}'.format('npm update -g ', p), usr_pwd=usr_pwd, run=global_run)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmarking the stop of the interval.", "response": "def stop(self):\n        \"\"\"Mark the stop of the interval.\n\n        Calling stop on an already stopped interval has no effect.\n        An interval can only be stopped once.\n\n        :returns: the duration if the interval is truely stopped otherwise ``False``.\n        \"\"\"\n        if self._start_instant is None:\n            raise IntervalException(\"Attempt to stop an interval that has not started.\")\n        if self._stop_instant is None:\n            self._stop_instant = instant()\n            self._duration = int((self._stop_instant - self._start_instant) * 1000)\n            return self._duration\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn how long the the interval was started.", "response": "def duration_so_far(self):\n        \"\"\"Return how the duration so far.\n\n        :returns: the duration from the time the Interval was started if the\n            interval is running, otherwise ``False``.\n        \"\"\"\n        if self._start_instant is None:\n            return False\n        if self._stop_instant is None:\n            return int((instant() - self._start_instant) * 1000)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the integer value of the interval", "response": "def duration(self):\n        \"\"\"Returns the integer value of the interval, the value is in milliseconds.\n\n        If the interval has not had stop called yet,\n        it will report the number of milliseconds in the interval up to the current point in time.\n        \"\"\"\n        if self._stop_instant is None:\n            return int((instant() - self._start_instant) * 1000)\n        if self._duration is None:\n            self._duration = int((self._stop_instant - self._start_instant) * 1000)\n        return self._duration"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __get_preferential_value(self, paths, index=0):\n\n        try:\n            value = paths[self.path_preference_order[index]]\n        except KeyError:\n            value = self.__get_preferential_value(paths, (index + 1))\n        except IndexError:\n            msg = ('Cannot fork to any of the provided path\\'s values. '\n                   'Perhaps add a fallback path (set to `True`) in your '\n                   'fork\\'s instantiation?')\n            raise self.PathNotAvailable(msg)\n\n        return value", "response": "Returns the preferential path s value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef import_module(self, name):\n        if name not in self._objects:\n            module = _import_module(name)\n            self._objects[name] = module\n            self._object_references[id(module)] = name\n        return self._objects[name]", "response": "Import a module into the bridge."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the root package or module of the passed module.", "response": "def _component_of(name):\n    \"\"\"Get the root package or module of the passed module.\n    \"\"\"\n\n    # Get the registered package this model belongs to.\n    segments = name.split('.')\n    while segments:\n        # Is this name a registered package?\n        test = '.'.join(segments)\n        if test in settings.get('COMPONENTS', []):\n            # This is the component we are in.\n            return test\n\n        # Remove the right-most segment.\n        segments.pop()\n\n    if not segments and '.models' in name:\n        # No package was found to be registered; attempt to guess the\n        # right package name; strip all occurrances of '.models' from the\n        # pacakge name.\n        return _component_of(name.replace('.models', ''))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self, commit=False):\n        if not has_identity(self):\n            # Object has not been persisted to the database.\n            session.add(self)\n\n        if commit:\n            # Commit the session as requested.\n            session.commit()\n\n        else:\n            # Just flush the session; do not commit.\n            session.flush()", "response": "Save the changes to the model."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef url(sport, league_id, team_id, start_date=None):\n    url = '%s/%s/%s/' % (SPORT_URLS[sport], league_id, team_id)\n    if start_date is not None:\n        url += 'team?&date=%s' % start_date\n    return url", "response": "Returns the url for the fantasy team page for a given sport name league_id and team_id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the team name of the current page", "response": "def team(page):\n    \"\"\"\n    Return the team name\n    \"\"\"\n    soup = BeautifulSoup(page)\n    try:\n        return soup.find('title').text.split(' | ')[0].split(' - ')[1]\n    except:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef league(page):\n    soup = BeautifulSoup(page)\n    try:\n        return soup.find('title').text.split(' | ')[0].split(' - ')[0]\n    except:\n        return None", "response": "Return the league name from a page"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef date(page):\n    soup = BeautifulSoup(page)\n    try:\n        page_date = soup.find('input', attrs={'name': 'date'})['value']\n        parsed_date = datetime.strptime(page_date, '%Y-%m-%d')\n        return parsed_date.strftime('%a, %b %d, %Y')\n    except:\n        return None", "response": "Return the date nicely - formatted\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns iterable containing players on bench who are available to play", "response": "def alternates(page):\n    \"\"\"\n    Return iterable containing players on bench who are available to play,\n    where each player is a dict containing:\n\n    - name\n    - details\n    - opponent\n    \"\"\"\n    soup = BeautifulSoup(page)\n    try:\n        bench = soup.find_all('tr', class_='bench')\n        bench_bios = [p.find('div', class_='ysf-player-name') for p in bench]\n        names = [p.find('a').text for p in bench_bios]\n        details = [p.find('span').text for p in bench_bios]\n        opponents = [p.find_all('td', recursive=False)[3].text for p in bench]\n        players = [{'name': n, 'details': d, 'opponent': o}\n                   for (n, d, o) in zip(names, details, opponents)]\n        return [p for p in players if len(p['opponent']) > 0]\n    except:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start_active_players_path(page):\n    soup = BeautifulSoup(page)\n    try:\n        return soup.find('a', href=True, text='Start Active Players')['href']\n    except:\n        return None", "response": "Return the path in the Start Active Players button"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _migrateStorageSchema(self, metadata: MetaData) -> None:\n\n        relDir = self._packageCfg.config.storage.alembicDir(require_string)\n        alembicDir = os.path.join(self.rootDir, relDir)\n        if not os.path.isdir(alembicDir): raise NotADirectoryError(alembicDir)\n\n        self._dbConn = DbConnection(\n            dbConnectString=self.platform.dbConnectString,\n            metadata=metadata,\n            alembicDir=alembicDir,\n            enableCreateAll=False\n        )\n\n        self._dbConn.migrate()", "response": "Initializes the DB connection and migrations the database schema."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prefetchDeclarativeIds(self, Declarative, count) -> Deferred:\n        return self._dbConn.prefetchDeclarativeIds(Declarative=Declarative, count=count)", "response": "Returns a generator that returns a chunk of IDs for the given declarative."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_once(func):\n\n    def _inner(*args, **kwargs):\n        if func.__name__ in CTX.run_once:\n            LOGGER.info('skipping %s', func.__name__)\n            return CTX.run_once[func.__name__]\n\n        LOGGER.info('running: %s', func.__name__)\n        result = func(*args, **kwargs)\n        CTX.run_once[func.__name__] = result\n        return result\n\n    return _inner", "response": "Decorator to ensure a function is ran only once"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self, commands=None, default_command=None, context=None):\n\n        if commands:\n            self._commands.update(commands)\n\n            # HACK: Overriding the old shell isn't cool.\n            # Should do it by default.\n        from alchemist.commands import Shell\n        self._commands['shell'] = Shell(context=context)\n\n        if default_command is not None and len(sys.argv) == 1:\n            sys.argv.append(default_command)\n\n        try:\n            result = self.handle(sys.argv[0], sys.argv[1:])\n        except SystemExit as e:\n            result = e.code\n\n        sys.exit(result or 0)", "response": "Run the command line"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the score of a list of dice that are at least min_same_faces or zero.", "response": "def score_x_of_a_kind_yahtzee(dice: List[int], min_same_faces: int) -> int:\n    \"\"\"Return sum of dice if there are a minimum of equal min_same_faces dice, otherwise\n    return zero. Only works for 3 or more min_same_faces.\n    \"\"\"\n    for die, count in Counter(dice).most_common(1):\n        if count >= min_same_faces:\n            return sum(dice)\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef score_small_straight_yahztee(dice: List[int]) -> int:\n    global CONSTANT_SCORES_YAHTZEE\n    dice_set = set(dice)\n    if _are_two_sets_equal({1, 2, 3, 4}, dice_set) or \\\n            _are_two_sets_equal({2, 3, 4, 5}, dice_set) or \\\n            _are_two_sets_equal({3, 4, 5, 6}, dice_set):\n        return CONSTANT_SCORES_YAHTZEE[Category.SMALL_STRAIGHT]\n    return 0", "response": "Small straight scoring according to regular yahtzee rules\n    Small straight scoring according to regular yahtzee rules\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef score_small_straight_yatzy(dice: List[int]) -> int:\n    dice_set = set(dice)\n    if _are_two_sets_equal({1, 2, 3, 4, 5}, dice_set):\n        return sum(dice)\n    return 0", "response": "Small straight scoring according to yatzy rules\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef score_large_straight_yatzy(dice: List[int]) -> int:\n    dice_set = set(dice)\n    if _are_two_sets_equal({2, 3, 4, 5, 6}, dice_set):\n        return sum(dice)\n    return 0", "response": "Large straight scoring according to yatzy rules\n    Large straight scoring according to yatzy rules\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives an iterable of dictionaries return the dictionaries where the values at a given key match the given value.", "response": "def select_dict(coll, key, value):\n    \"\"\"\n    Given an iterable of dictionaries, return the dictionaries\n    where the values at a given key match the given value.\n    If the value is an iterable of objects, the function will\n    consider any to be a match.\n\n    This is especially useful when calling REST APIs which\n    return arrays of JSON objects. When such a response is\n    converted to a Python list of dictionaries, it may be\n    easily filtered using this function.\n\n    :param iter coll: An iterable containing dictionaries\n    :param obj key: A key to search in each dictionary\n    :param value: A value or iterable of values to match\n    :type value: obj or iter\n    :returns: A list of dictionaries matching the query\n    :rtype: list\n\n    :Example:\n\n    ::\n\n      >>> dicts = [\n      ...    {'hi': 'bye'},\n      ...    {10: 2, 30: 4},\n      ...    {'hi': 'hello', 'bye': 'goodbye'},\n      ... ]\n      >>> select_dict(dicts, 'hi', 'bye')\n      [{'hi': 'bye'}]\n      >>> select_dict(dicts, 'hi', ('bye', 'hello'))\n      [{'hi': 'bye'}, {'hi': 'hello', 'bye': 'goodbye'}]\n    \"\"\"\n    if getattr(value, '__iter__', None):\n        iterable = value\n    else:\n        iterable = [value]\n    return [v for v in coll if key in v and v[key] in iterable]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the percentage of voxels above a statistical threshold inside a brain mask vs. outside it", "response": "def inside_brain(stat_dset,atlas=None,p=0.001):\n    '''calculates the percentage of voxels above a statistical threshold inside a brain mask vs. outside it\n    \n    if ``atlas`` is ``None``, it will try to find ``TT_N27``'''\n    atlas = find_atlas(atlas)\n    if atlas==None:\n        return None\n    mask_dset = nl.suffix(stat_dset,'_atlasfrac')\n    nl.run(['3dfractionize','-template',nl.strip_subbrick(stat_dset),'-input',nl.calc([atlas],'1+step(a-100)',datum='short'),'-preserve','-clip','0.2','-prefix',mask_dset],products=mask_dset,quiet=True,stderr=None)\n    s = nl.roi_stats(mask_dset,nl.thresh(stat_dset,p))\n    return 100.0 * s[2]['nzvoxels'] / (s[1]['nzvoxels'] + s[2]['nzvoxels'])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nalign dset to the TT_N27 atlas and returns cost and overlap", "response": "def atlas_overlap(dset,atlas=None):\n    '''aligns ``dset`` to the TT_N27 atlas and returns ``(cost,overlap)``'''\n    atlas = find_atlas(atlas)\n    if atlas==None:\n        return None\n    \n    cost_func = 'crM'\n    infile = os.path.abspath(dset)\n    tmpdir = tempfile.mkdtemp()\n    with nl.run_in(tmpdir):\n        o = nl.run(['3dAllineate','-verb','-base',atlas,'-source',infile + '[0]','-NN','-final','NN','-cost',cost_func,'-nmatch','20%','-onepass','-fineblur','2','-cmass','-prefix','test.nii.gz'])\n        m = re.search(r'Final\\s+cost = ([\\d.]+) ;',o.output)\n        if m:\n            cost = float(m.group(1))\n        o = nl.run(['3dmaskave','-mask',atlas,'-q','test.nii.gz'],stderr=None)\n        data_thresh = float(o.output) / 4\n        i = nl.dset_info('test.nii.gz')\n        o = nl.run(['3dmaskave','-q','-mask','SELF','-sum',nl.calc([atlas,'test.nii.gz'],'equals(step(a-10),step(b-%.2f))'%data_thresh)],stderr=None)\n        overlap = 100*float(o.output) / (i.voxel_dims[0]*i.voxel_dims[1]*i.voxel_dims[2])\n    try:\n        shutil.rmtree(tmpdir)\n    except:\n        pass\n    return (cost,overlap)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef outcount(dset,fraction=0.1):\n    '''gets outlier count and returns ``(list of proportion of outliers by timepoint,total percentage of outlier time points)'''\n    polort = nl.auto_polort(dset)\n    info = nl.dset_info(dset)\n    o = nl.run(['3dToutcount','-fraction','-automask','-polort',polort,dset],stderr=None,quiet=None)\n    if o.return_code==0 and o.output:\n        oc = [float(x) for x in o.output.split('\\n') if x.strip()!='']\n        binary_outcount = [x<fraction for x in oc]\n        perc_outliers = 1 - (sum(binary_outcount)/float(info.reps))\n        return (oc,perc_outliers)", "response": "gets outlier count and returns tuple of proportion of outliers by timepoint total percentage of outliers by timepoint"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef temporal_snr(signal_dset,noise_dset,mask=None,prefix='temporal_snr.nii.gz'):\n    '''Calculates temporal SNR by dividing average signal of ``signal_dset`` by SD of ``noise_dset``.\n    ``signal_dset`` should be a dataset that contains the average signal value (i.e., nothing that has\n    been detrended by removing the mean), and ``noise_dset`` should be a dataset that has all possible\n    known signal fluctuations (e.g., task-related effects) removed from it (the residual dataset from a \n    deconvolve works well)'''\n    for d in [('mean',signal_dset), ('stdev',noise_dset)]:\n        new_d = nl.suffix(d[1],'_%s' % d[0])\n        cmd = ['3dTstat','-%s' % d[0],'-prefix',new_d]\n        if mask:\n            cmd += ['-mask',mask]\n        cmd += [d[1]]\n        nl.run(cmd,products=new_d)\n    nl.calc([nl.suffix(signal_dset,'_mean'),nl.suffix(noise_dset,'_stdev')],'a/b',prefix=prefix)", "response": "Calculates temporal SNR by dividing average signal of signal_dset by SD of noise_dset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef auto_qc(dset,inside_perc=60,atlas=None,p=0.001):\n    '''returns ``False`` if ``dset`` fails minimum checks, or returns a float from ``0.0`` to ``100.0`` describing data quality'''\n    with nl.notify('Running quality check on %s:' % dset):\n        if not os.path.exists(dset):\n            nl.notify('Error: cannot find the file!',level=nl.level.error)\n            return False\n        \n        info = nl.dset_info(dset)\n        if not info:\n            nl.notify('Error: could not read the dataset!',level=nl.level.error)\n        \n        if any(['stat' in x for x in info.subbricks]):\n            with nl.notify('Statistical results detected...'):\n                inside = inside_brain(dset,atlas=atlas,p=p)\n                nl.notify('%.1f significant voxels inside brain')\n                if inside<inside_perc:\n                    nl.notify('Warning: below quality threshold!',level=nl.level.warning)\n#                    return False\n                nl.notify('Looks ok')\n                return inside\n        \n        if len(info.subbricks)>1:\n            with nl.notify('Time-series detected...'):\n                return_val = True\n                (cost,overlap) = atlas_overlap(dset)\n                if cost>0.15 or overlap<80:\n                    nl.notify('Warning: does not appear to conform to brain dimensions',level=nl.level.warning)\n                    return_val = False\n                if len(info.subbricks)>5:\n                    (oc,perc_outliers) = outcount(dset)\n                    if perc_outliers>0.1:\n                        nl.notify('Warning: large amount of outlier time points',level=nl.level.warning)\n                        return_val = False\n            if return_val:\n                nl.notify('Looks ok')\n                return min(100*(1-cost),overlap,100*perc_outliers)\n            return False\n        \n        with nl.notify('Single brain image detected...'):\n            (cost,overlap) = atlas_overlap(dset)\n            # Be more lenient if it's not an EPI, cuz who knows what else is in this image\n            if cost>0.45 or overlap<70:\n                nl.notify('Warning: does not appear to conform to brain dimensions',level=nl.level.warning)\n                return False\n            nl.notify('Looks ok')\n            return min(100*(1-cost),overlap)", "response": "returns a list of all the images in the dataset that are in the same brain as the passed in dataset"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nturns any callable into a lazy evaluated callable.", "response": "def lazy(func, *resultclasses):\n    \"\"\"\n    Turn any callable into a lazy evaluated callable. result classes or types\n    is required -- at least one is needed so that the automatic forcing of\n    the lazy evaluation code is triggered. Results are not memoized; the\n    function is evaluated on every access.\n    \"\"\"\n\n    @total_ordering\n    class __proxy__(Promise):\n        \"\"\"\n        Encapsulate a function call and act as a proxy for methods that are\n        called on the result of that function. The function is not evaluated\n        until one of the methods on the result is called.\n        \"\"\"\n        __prepared = False\n\n        def __init__(self, args, kw):\n            self.__args = args\n            self.__kw = kw\n            if not self.__prepared:\n                self.__prepare_class__()\n            self.__prepared = True\n\n        def __reduce__(self):\n            return (\n                _lazy_proxy_unpickle,\n                (func, self.__args, self.__kw) + resultclasses\n            )\n\n        def __repr__(self):\n            return repr(self.__cast())\n\n        @classmethod\n        def __prepare_class__(cls):\n            for resultclass in resultclasses:\n                for type_ in resultclass.mro():\n                    for method_name in type_.__dict__.keys():\n                        # All __promise__ return the same wrapper method, they\n                        # look up the correct implementation when called.\n                        if hasattr(cls, method_name):\n                            continue\n                        meth = cls.__promise__(method_name)\n                        setattr(cls, method_name, meth)\n            cls._delegate_bytes = bytes in resultclasses\n            cls._delegate_text = str in resultclasses\n            assert not (cls._delegate_bytes and cls._delegate_text), (\n                \"Cannot call lazy() with both bytes and text return types.\")\n            if cls._delegate_text:\n                cls.__str__ = cls.__text_cast\n            elif cls._delegate_bytes:\n                cls.__bytes__ = cls.__bytes_cast\n\n        @classmethod\n        def __promise__(cls, method_name):\n            # Builds a wrapper around some magic method\n            def __wrapper__(self, *args, **kw):\n                # Automatically triggers the evaluation of a lazy value and\n                # applies the given magic method of the result type.\n                res = func(*self.__args, **self.__kw)\n                return getattr(res, method_name)(*args, **kw)\n            return __wrapper__\n\n        def __text_cast(self):\n            return func(*self.__args, **self.__kw)\n\n        def __bytes_cast(self):\n            return bytes(func(*self.__args, **self.__kw))\n\n        def __bytes_cast_encoded(self):\n            return func(*self.__args, **self.__kw).encode()\n\n        def __cast(self):\n            if self._delegate_bytes:\n                return self.__bytes_cast()\n            elif self._delegate_text:\n                return self.__text_cast()\n            else:\n                return func(*self.__args, **self.__kw)\n\n        def __str__(self):\n            # object defines __str__(), so __prepare_class__() won't overload\n            # a __str__() method from the proxied class.\n            return str(self.__cast())\n\n        def __eq__(self, other):\n            if isinstance(other, Promise):\n                other = other.__cast()\n            return self.__cast() == other\n\n        def __lt__(self, other):\n            if isinstance(other, Promise):\n                other = other.__cast()\n            return self.__cast() < other\n\n        def __hash__(self):\n            return hash(self.__cast())\n\n        def __mod__(self, rhs):\n            if self._delegate_text:\n                return str(self) % rhs\n            return self.__cast() % rhs\n\n        def __deepcopy__(self, memo):\n            # Instances of this class are effectively immutable. It's just a\n            # collection of functions. So we don't need to do anything\n            # complicated for copying.\n            memo[id(self)] = self\n            return self\n\n    @wraps(func)\n    def __wrapper__(*args, **kw):\n        # Creates the proxy object, instead of the actual value.\n        return __proxy__(args, kw)\n\n    return __wrapper__"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reconnect(self, conn_retries=None):\r\n        ''' Connects to Redis with a exponential waiting (3**n) '''\r\n        if conn_retries is None:\r\n            conn_retries = self.conn_retries\r\n\r\n        count = 0\r\n        if self.logger:\r\n            self.logger.info('Connecting to Redis..')\r\n        while count < conn_retries:\r\n            super(redis.client.Redis, self).__init__(*self.args, **self.kwargs)\r\n\r\n            if self.ping():\r\n                if self.logger:\r\n                    self.logger.info('Connected to Redis!')\r\n                return True\r\n            else:\r\n                sl = min(3 ** count, self.max_sleep)\r\n                if self.logger:\r\n                    self.logger.info('Connecting failed, retrying in {0} seconds'.format(sl))\r\n                time.sleep(sl)\r\n                count += 1\r\n        raise ConnectionError", "response": "Connects to Redis with exponential waiting ( 3 ** n )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _multi_lpop_pipeline(self, pipe, queue, number):\r\n        ''' Pops multiple elements from a list in a given pipeline'''\r\n        pipe.lrange(queue, 0, number - 1)\r\n        pipe.ltrim(queue, number, -1)", "response": "Pops multiple elements from a list in a given pipeline"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef multi_lpop(self, queue, number, transaction=False):\r\n        ''' Pops multiple elements from a list\r\n            This operation will be atomic if transaction=True is passed\r\n        '''\r\n        try:\r\n            pipe = self.pipeline(transaction=transaction)\r\n            pipe.multi()\r\n            self._multi_lpop_pipeline(pipe, queue, number)\r\n            return pipe.execute()[0]\r\n        except IndexError:\r\n            return []\r\n        except:\r\n            raise", "response": "Pops multiple elements from a list\r\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npush multiple elements to a given pipeline", "response": "def _multi_rpush_pipeline(self, pipe, queue, values, bulk_size=0):\r\n        ''' Pushes multiple elements to a list in a given pipeline\r\n            If bulk_size is set it will execute the pipeline every bulk_size elements\r\n        '''\r\n        cont = 0\r\n        for value in values:\r\n            pipe.rpush(queue, value)\r\n            if bulk_size != 0 and cont % bulk_size == 0:\r\n                pipe.execute()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef multi_rpush(self, queue, values, bulk_size=0, transaction=False):\r\n        ''' Pushes multiple elements to a list\r\n            If bulk_size is set it will execute the pipeline every bulk_size elements\r\n            This operation will be atomic if transaction=True is passed\r\n        '''\r\n        # Check that what we receive is iterable\r\n        if hasattr(values, '__iter__'):\r\n            pipe = self.pipeline(transaction=transaction)\r\n            pipe.multi()\r\n            self._multi_rpush_pipeline(pipe, queue, values, bulk_size)\r\n            pipe.execute()\r\n        else:\r\n            raise ValueError('Expected an iterable')", "response": "Pushes multiple elements to a list\r\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npushes multiple elements to a list in an atomic way until it reaches certain size", "response": "def multi_rpush_limit(self, queue, values, limit=100000):\r\n        ''' Pushes multiple elements to a list in an atomic way until it reaches certain size\r\n            Once limit is reached, the function will lpop the oldest elements\r\n            This operation runs in LUA, so is always atomic\r\n        '''\r\n\r\n        lua = '''\r\n        local queue = KEYS[1]\r\n        local max_size = tonumber(KEYS[2])\r\n        local table_len = tonumber(table.getn(ARGV))\r\n        local redis_queue_len = tonumber(redis.call('LLEN', queue))\r\n        local total_size = redis_queue_len + table_len\r\n        local from = 0\r\n\r\n        if total_size >= max_size then\r\n            -- Delete the same amount of data we are inserting. Even better, limit the queue to the specified size\r\n            redis.call('PUBLISH', 'DEBUG', 'trim')\r\n            if redis_queue_len - max_size + table_len > 0 then\r\n                from = redis_queue_len - max_size + table_len\r\n            else\r\n                from = 0\r\n            end\r\n            redis.call('LTRIM', queue, from, redis_queue_len)\r\n        end\r\n        for _,key in ipairs(ARGV) do\r\n            redis.call('RPUSH', queue, key)\r\n        end\r\n        return 1\r\n\r\n        '''\r\n\r\n        # Check that what we receive is iterable\r\n        if hasattr(values, '__iter__'):\r\n            if len(values) > limit:\r\n                raise ValueError('The iterable size is bigger than the allowed limit ({1}): {0}'.format(len(values), limit))\r\n            try:\r\n                self.multi_rpush_limit_script([queue, limit], values)\r\n            except AttributeError:\r\n                if self.logger:\r\n                    self.logger.info('Script not registered... registering')\r\n                # If the script is not registered, register it\r\n                self.multi_rpush_limit_script = self.register_script(lua)\r\n                self.multi_rpush_limit_script([queue, limit], values)\r\n        else:\r\n            raise ValueError('Expected an iterable')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npushes an element to a list in an atomic way until it reaches certain size", "response": "def rpush_limit(self, queue, value, limit=100000):\r\n        ''' Pushes an element to a list in an atomic way until it reaches certain size\r\n            Once limit is reached, the function will lpop the oldest elements\r\n            This operation runs in LUA, so is always atomic\r\n        '''\r\n\r\n        lua = '''\r\n        local queue = KEYS[1]\r\n        local max_size = tonumber(KEYS[2])\r\n        local table_len = 1\r\n        local redis_queue_len = tonumber(redis.call('LLEN', queue))\r\n        local total_size = redis_queue_len + table_len\r\n        local from = 0\r\n\r\n        if total_size >= max_size then\r\n            -- Delete the same amount of data we are inserting. Even better, limit the queue to the specified size\r\n            redis.call('PUBLISH', 'DEBUG', 'trim')\r\n            if redis_queue_len - max_size + table_len > 0 then\r\n                from = redis_queue_len - max_size + table_len\r\n            else\r\n                from = 0\r\n            end\r\n            redis.call('LTRIM', queue, from, redis_queue_len)\r\n        end\r\n        redis.call('RPUSH', queue, ARGV[1])\r\n        return 1\r\n\r\n        '''\r\n\r\n        try:\r\n            self.rpush_limit_script([queue, limit], [value])\r\n        except AttributeError:\r\n            if self.logger:\r\n                self.logger.info('Script not registered... registering')\r\n            # If the script is not registered, register it\r\n            self.rpush_limit_script = self.register_script(lua)\r\n            self.rpush_limit_script([queue, limit], [value])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a lock and returns if it can be stablished. Returns false otherwise.", "response": "def get_lock(self, lockname, locktime=60, auto_renewal=False):\r\n        ''' Gets a lock and returns if it can be stablished. Returns false otherwise '''\r\n        pid = os.getpid()\r\n        caller = inspect.stack()[0][3]\r\n        try:\r\n            # rl = redlock.Redlock([{\"host\": settings.REDIS_SERVERS['std_redis']['host'], \"port\": settings.REDIS_SERVERS['std_redis']['port'], \"db\": settings.REDIS_SERVERS['std_redis']['db']}, ])\r\n            rl = redis_lock.Lock(self, lockname, expire=locktime, auto_renewal=auto_renewal)\r\n        except:\r\n            if self.logger:\r\n                self.logger.error('Process {0} ({1}) could not get lock {2}. Going ahead without locking!!! {3}'.format(pid, caller, lockname, traceback.format_exc()))\r\n            return False\r\n        try:\r\n            lock = rl.acquire(blocking=False)\r\n        except RedisError:\r\n            return False\r\n        if not lock:\r\n            return False\r\n        else:\r\n            return rl"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wait_for_lock(self, lockname, locktime=60, auto_renewal=False):\r\n        ''' Gets a lock or waits until it is able to get it '''\r\n        pid = os.getpid()\r\n        caller = inspect.stack()[0][3]\r\n        try:\r\n            # rl = redlock.Redlock([{\"host\": settings.REDIS_SERVERS['std_redis']['host'], \"port\": settings.REDIS_SERVERS['std_redis']['port'], \"db\": settings.REDIS_SERVERS['std_redis']['db']}, ])\r\n            rl = redis_lock.Lock(self, lockname, expire=locktime, auto_renewal=auto_renewal)\r\n        except AssertionError:\r\n            if self.logger:\r\n                self.logger.error('Process {0} ({1}) could not get lock {2}. Going ahead without locking!!! {3}'.format(pid, caller, lockname, traceback.format_exc()))\r\n            return False\r\n        cont = 1\r\n        t0 = time.time()\r\n        lock = None\r\n        while not lock:\r\n            time.sleep(.05)\r\n            cont += 1\r\n            if cont % 20 == 0:\r\n                if self.logger:\r\n                    self.logger.debug('Process {0} ({1}) waiting for lock {2}. {3} seconds elapsed.'.format(pid, caller, lockname, time.time() - t0))\r\n            # lock = rl.lock(lockname, locktime_ms)\r\n            try:\r\n                lock = rl.acquire()\r\n            except RedisError:\r\n                pass\r\n        if self.logger:\r\n            self.logger.debug('Process {0} ({1}) got lock {2} for {3} seconds'.format(pid, caller, lockname, locktime))\r\n        return rl", "response": "Gets a lock or waits until it is able to get it"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pipeline(self, transaction=True, shard_hint=None):\r\n        ''' Return a pipeline that support StoneRedis custom methods '''\r\n        args_dict = {\r\n            'connection_pool': self.connection_pool,\r\n            'response_callbacks': self.response_callbacks,\r\n            'transaction': transaction,\r\n            'shard_hint': shard_hint,\r\n            'logger': self.logger,\r\n        }\r\n\r\n        return StonePipeline(**args_dict)", "response": "Returns a pipeline that supports StoneRedis custom methods"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npopping multiple elements from a list", "response": "def multi_lpop(self, queue, number, transaction=False):\r\n        ''' Pops multiple elements from a list '''\r\n        try:\r\n            self._multi_lpop_pipeline(self, queue, number)\r\n        except:\r\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npushes multiple elements to a list", "response": "def multi_rpush(self, queue, values, bulk_size=0, transaction=False):\r\n        ''' Pushes multiple elements to a list '''\r\n        # Check that what we receive is iterable\r\n        if hasattr(values, '__iter__'):\r\n            self._multi_rpush_pipeline(self, queue, values, 0)\r\n        else:\r\n            raise ValueError('Expected an iterable')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _deserialize(data, klass):\n    if data is None:\n        return None\n\n    if klass in six.integer_types or klass in (float, str, bool):\n        return _deserialize_primitive(data, klass)\n    elif klass == object:\n        return _deserialize_object(data)\n    elif klass == datetime.date:\n        return deserialize_date(data)\n    elif klass == datetime.datetime:\n        return deserialize_datetime(data)\n    elif type(klass) == typing.GenericMeta:\n        if klass.__extra__ == list:\n            return _deserialize_list(data, klass.__args__[0])\n        if klass.__extra__ == dict:\n            return _deserialize_dict(data, klass.__args__[1])\n    else:\n        return deserialize_model(data, klass)", "response": "Deserializes dict list or str into an object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _deserialize_dict(data, boxed_type):\n    return {k: _deserialize(v, boxed_type)\n            for k, v in six.iteritems(data)}", "response": "Deserializes a dict and its elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves an observer from the cache", "response": "def remove(self, what, call):\n        \"\"\"\n        remove an observer\n\n        what: (string | array) state fields to observe\n        call: (function) when not given, decorator usage is assumed.\n            The call function should have 2 parameters:\n            - previousValue,\n            - actualValue\n\n        \"\"\"\n        type = observerTypeEnum.typeOf(what)\n        self._observers.remove({\n                                    \"observing\": what,\n                                    \"type\": type,\n                                    \"call\": call\n                                 })"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the list of observers to the instance of the class.", "response": "def getObservers(self):\n        \"\"\"\n        Get the list of observer to the instance of the class.\n\n        :return: Subscribed Obversers.\n        :rtype: Array\n        \"\"\"\n        result = []\n        for observer in self._observers:\n            result.append(\n                          {\n                              \"observing\": observer[\"observing\"],\n                              \"call\": observer[\"call\"]\n                          })\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef times(job):\n  timing = \"Submitted: %s\" % job.submit_time.ctime()\n  if job.start_time is not None:\n    timing += \"\\nStarted  : %s \\t Job waited  : %s\" % (job.start_time.ctime(), job.start_time - job.submit_time)\n  if job.finish_time is not None:\n    timing += \"\\nFinished : %s \\t Job executed: %s\" % (job.finish_time.ctime(), job.finish_time - job.start_time)\n  return timing", "response": "Returns a string containing the timing information for the given job."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nformatting the current job into a nicer string to fit into a table.", "response": "def format(self, format):\n    \"\"\"Formats the current job into a nicer string to fit into a table.\"\"\"\n\n    job_id = \"%d - %d\" % (self.job.id, self.id)\n    queue = self.job.queue_name if self.machine_name is None else self.machine_name\n    status = \"%s\" % self.status + (\" (%d)\" % self.result if self.result is not None else \"\" )\n\n    return format.format(\"\", job_id, queue, status)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef submit(self, new_queue = None):\n    self.status = 'submitted'\n    self.result = None\n    self.machine_name = None\n    if new_queue is not None:\n      self.queue_name = new_queue\n    for array_job in self.array:\n      array_job.status = 'submitted'\n      array_job.result = None\n      array_job.machine_name = None\n    self.submit_time = datetime.now()\n    self.start_time = None\n    self.finish_time = None", "response": "Sets the status of this job to submitted."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the status of this job to queued or waiting.", "response": "def queue(self, new_job_id = None, new_job_name = None, queue_name = None):\n    \"\"\"Sets the status of this job to 'queued' or 'waiting'.\"\"\"\n    # update the job id (i.e., when the job is executed in the grid)\n    if new_job_id is not None:\n      self.id = new_job_id\n\n    if new_job_name is not None:\n      self.name = new_job_name\n\n    if queue_name is not None:\n      self.queue_name = queue_name\n\n    new_status = 'queued'\n    self.result = None\n    # check if we have to wait for another job to finish\n    for job in self.get_jobs_we_wait_for():\n      if job.status not in ('success', 'failure'):\n        new_status = 'waiting'\n      elif self.stop_on_failure and job.status == 'failure':\n        new_status = 'failure'\n\n    # reset the queued jobs that depend on us to waiting status\n    for job in self.get_jobs_waiting_for_us():\n      if job.status == 'queued':\n        job.status = 'failure' if new_status == 'failure' else 'waiting'\n\n    self.status = new_status\n    for array_job in self.array:\n      if array_job.status not in ('success', 'failure'):\n        array_job.status = new_status"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute(self, array_id = None, machine_name = None):\n    self.status = 'executing'\n    if array_id is not None:\n      for array_job in self.array:\n        if array_job.id == array_id:\n          array_job.status = 'executing'\n          if machine_name is not None:\n            array_job.machine_name = machine_name\n            array_job.start_time = datetime.now()\n    elif machine_name is not None:\n      self.machine_name = machine_name\n    if self.start_time is None:\n      self.start_time = datetime.now()\n\n    # sometimes, the 'finish' command did not work for array jobs,\n    # so check if any old job still has the 'executing' flag set\n    for job in self.get_jobs_we_wait_for():\n      if job.array and job.status == 'executing':\n        job.finish(0, -1)", "response": "Sets the status of this job to executing."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef finish(self, result, array_id = None):\n    # check if there is any array job still running\n    new_status = 'success' if result == 0 else 'failure'\n    new_result = result\n    finished = True\n    if array_id is not None:\n      for array_job in self.array:\n        if array_job.id == array_id:\n          array_job.status = new_status\n          array_job.result = result\n          array_job.finish_time = datetime.now()\n        if array_job.status not in ('success', 'failure'):\n          finished = False\n        elif new_result == 0:\n          new_result = array_job.result\n\n    if finished:\n      # There was no array job, or all array jobs finished\n      self.status = 'success' if new_result == 0 else 'failure'\n      self.result = new_result\n      self.finish_time = datetime.now()\n\n      # update all waiting jobs\n      for job in self.get_jobs_waiting_for_us():\n        if job.status == 'waiting':\n          job.queue()", "response": "Sets the status of this job to success or failure."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrefresh the status information.", "response": "def refresh(self):\n    \"\"\"Refreshes the status information.\"\"\"\n    if self.status == 'executing' and self.array:\n      new_result = 0\n      for array_job in self.array:\n        if array_job.status == 'failure' and new_result is not None:\n          new_result = array_job.result\n        elif array_job.status not in ('success', 'failure'):\n          new_result = None\n      if new_result is not None:\n        self.status = 'success' if new_result == 0 else 'failure'\n        self.result = new_result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_command_line(self):\n    # In python 2, the command line is unicode, which needs to be converted to string before pickling;\n    # In python 3, the command line is bytes, which can be pickled directly\n    return loads(self.command_line) if isinstance(self.command_line, bytes) else loads(self.command_line.encode())", "response": "Returns the command line for the job."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the command line for the job.", "response": "def get_exec_dir(self):\n    \"\"\"Returns the command line for the job.\"\"\"\n    # In python 2, the command line is unicode, which needs to be converted to string before pickling;\n    # In python 3, the command line is bytes, which can be pickled directly\n    return str(os.path.realpath(self.exec_dir)) if self.exec_dir is not None else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the array arguments for the job ; usually a string.", "response": "def get_array(self):\n    \"\"\"Returns the array arguments for the job; usually a string.\"\"\"\n    # In python 2, the command line is unicode, which needs to be converted to string before pickling;\n    # In python 3, the command line is bytes, which can be pickled directly\n    return loads(self.array_string) if isinstance(self.array_string, bytes) else loads(self.array_string.encode())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_arguments(self):\n    # In python 2, the command line is unicode, which needs to be converted to string before pickling;\n    # In python 3, the command line is bytes, which can be pickled directly\n    args = loads(self.grid_arguments)['kwargs'] if isinstance(self.grid_arguments, bytes) else loads(self.grid_arguments.encode())['kwargs']\n    # in any case, the commands have to be converted to str\n    retval = {}\n    if 'pe_opt' in args:\n      retval['pe_opt'] = args['pe_opt']\n    if 'memfree' in args and args['memfree'] is not None:\n      retval['memfree'] = args['memfree']\n    if 'hvmem' in args and args['hvmem'] is not None:\n      retval['hvmem'] = args['hvmem']\n    if 'gpumem' in args and args['gpumem'] is not None:\n      retval['gpumem'] = args['gpumem']\n    if 'env' in args and len(args['env']) > 0:\n      retval['env'] = args['env']\n    if 'io_big' in args and args['io_big']:\n      retval['io_big'] = True\n\n    # also add the queue\n    if self.queue_name is not None:\n      retval['queue'] = str(self.queue_name)\n\n    return retval", "response": "Returns the additional options for the grid"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef format(self, format, dependencies = 0, limit_command_line = None):\n    command_line = self._cmdline()\n    if limit_command_line is not None and len(command_line) > limit_command_line:\n      command_line = command_line[:limit_command_line-3] + '...'\n\n    job_id = \"%d\" % self.id + (\" [%d-%d:%d]\" % self.get_array() if self.array else \"\")\n    status = \"%s\" % self.status + (\" (%d)\" % self.result if self.result is not None else \"\" )\n    queue = self.queue_name if self.machine_name is None else self.machine_name\n    if limit_command_line is None:\n      grid_opt = self.get_arguments()\n      if grid_opt:\n        # add additional information about the job at the end\n        command_line = \"<\" + \",\".join([\"%s=%s\" % (key,value) for key,value in grid_opt.items()]) + \">: \" + command_line\n      if self.exec_dir is not None:\n        command_line += \"; [Executed in directory: '%s']\" % self.exec_dir\n\n    if dependencies:\n      deps = str(sorted(list(set([dep.unique for dep in self.get_jobs_we_wait_for()]))))\n      if dependencies < len(deps):\n        deps = deps[:dependencies-3] + '...'\n      return format.format(self.unique, job_id, queue[:12], status, self.name, deps, command_line)\n    else:\n      return format.format(self.unique, job_id, queue[:12], status, self.name, command_line)", "response": "Formats the current job into a nicer string to fit into a table."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_repo_name(repo_dir):\n\n    repo = git.Repo(repo_dir)\n    url = repo.remotes.origin.url\n\n    return url.split('/')[-1].split('.git')[0]", "response": "Returns the name of the git repository in the directory repo_dir."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_feature_order_from_model_xml(file_path):\n\n    root = xml.etree.ElementTree.parse(file_path).getroot()\n    feature_order_node = root.find('featureOrder')\n\n    features = []\n    for child in feature_order_node:\n        features.append(child.attrib['name'])\n\n    return features", "response": "Takes the path to a FeatureIDE model. xml file and extracts the feature order."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_feature_order_constraints(container_dir):\n    import json\n\n    file_path = os.path.join(container_dir, '_lib/featuremodel/productline/feature_order.json')\n    with open(file_path, 'r') as f:\n        ordering_constraints = json.loads(f.read())\n\n    return ordering_constraints", "response": "Returns the feature order constraints dict defined in featuremodel / productline / feature_order. json\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_features_from_equation(container_dir, product_name):\n    import featuremonkey\n    file_path = os.path.join(container_dir, 'products', product_name, 'product.equation')\n    return featuremonkey.get_features_from_equation_file(file_path)", "response": "Takes the container dir and the product name and returns the list of features."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn all relevant paths from the container_dir and product_name and returns all relevant paths to the config_file_path.", "response": "def get_feature_ide_paths(container_dir, product_name):\n    \"\"\"\n    Takes the container_dir and the product name and returns all relevant paths from the\n    feature_order_json to the config_file_path.\n    :param container_dir: the full path of the container dir\n    :param product_name: the name of the product\n    :return: object with divert path attributes\n    \"\"\"\n    repo_name = get_repo_name(container_dir)\n\n    class Paths(object):\n        feature_order_json = os.path.join(container_dir, '_lib/featuremodel/productline/feature_order.json')\n        model_xml_path = os.path.join(container_dir, '_lib/featuremodel/productline/model.xml')\n        config_file_path = os.path.join(container_dir, '_lib/featuremodel/productline/products/', repo_name, product_name, 'product.equation.config')\n        equation_file_path = os.path.join(container_dir, 'products', product_name, 'product.equation')\n        product_spec_path = os.path.join(container_dir, '_lib/featuremodel/productline/products/', repo_name, 'product_spec.json')\n\n    return Paths"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a index is available in the array and returns it otherwise returns None", "response": "def index_get(array, *argv):\n    \"\"\"\n    checks if a index is available in the array and returns it\n    :param array: the data array\n    :param argv: index integers\n    :return: None if not available or the return value\n    \"\"\"\n\n    try:\n\n        for index in argv:\n            array = array[index]\n\n        return array\n\n    # there is either no info available or no popular times\n    # TypeError: rating/rating_n/populartimes wrong of not available\n    except (IndexError, TypeError):\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds optional parameters to the json", "response": "def add_optional_parameters(detail_json, detail, rating, rating_n, popularity, current_popularity, time_spent):\n    \"\"\"\n    check for optional return parameters and add them to the result json\n    :param detail_json:\n    :param detail:\n    :param rating:\n    :param rating_n:\n    :param popularity:\n    :param current_popularity:\n    :param time_spent:\n    :return:\n    \"\"\"\n\n    if rating is not None:\n        detail_json[\"rating\"] = rating\n    elif \"rating\" in detail:\n        detail_json[\"rating\"] = detail[\"rating\"]\n\n    if rating_n is not None:\n        detail_json[\"rating_n\"] = rating_n\n\n    if \"international_phone_number\" in detail:\n        detail_json[\"international_phone_number\"] = detail[\"international_phone_number\"]\n\n    if current_popularity is not None:\n        detail_json[\"current_popularity\"] = current_popularity\n\n    if popularity is not None:\n        popularity, wait_times = get_popularity_for_day(popularity)\n\n        detail_json[\"populartimes\"] = popularity\n        detail_json[\"time_wait\"] = wait_times\n\n    if time_spent is not None:\n        detail_json[\"time_spent\"] = time_spent\n\n    return detail_json"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget popularity for a given place identifier and parse current popularity.", "response": "def get_populartimes_from_search(place_identifier, user_agent=default_user_agent, **kwargs):\n    \"\"\"\n    request information for a place and parse current popularity\n    :param place_identifier: name and address string\n    :return:\n    \"\"\"\n    params_url = {\n        \"tbm\": \"map\",\n        \"tch\": 1,\n        \"q\": urllib.parse.quote_plus(place_identifier),\n        \"pb\": \"!4m12!1m3!1d4005.9771522653964!2d-122.42072974863942!3d37.8077459796541!2m3!1f0!2f0!3f0!3m2!1i1125!2i976\"\n              \"!4f13.1!7i20!10b1!12m6!2m3!5m1!6e2!20e3!10b1!16b1!19m3!2m2!1i392!2i106!20m61!2m2!1i203!2i100!3m2!2i4!5b1\"\n              \"!6m6!1m2!1i86!2i86!1m2!1i408!2i200!7m46!1m3!1e1!2b0!3e3!1m3!1e2!2b1!3e2!1m3!1e2!2b0!3e3!1m3!1e3!2b0!3e3!\"\n              \"1m3!1e4!2b0!3e3!1m3!1e8!2b0!3e3!1m3!1e3!2b1!3e2!1m3!1e9!2b1!3e2!1m3!1e10!2b0!3e3!1m3!1e10!2b1!3e2!1m3!1e\"\n              \"10!2b0!3e4!2b1!4b1!9b0!22m6!1sa9fVWea_MsX8adX8j8AE%3A1!2zMWk6Mix0OjExODg3LGU6MSxwOmE5ZlZXZWFfTXNYOGFkWDh\"\n              \"qOEFFOjE!7e81!12e3!17sa9fVWea_MsX8adX8j8AE%3A564!18e15!24m15!2b1!5m4!2b1!3b1!5b1!6b1!10m1!8e3!17b1!24b1!\"\n              \"25b1!26b1!30m1!2b1!36b1!26m3!2m2!1i80!2i92!30m28!1m6!1m2!1i0!2i0!2m2!1i458!2i976!1m6!1m2!1i1075!2i0!2m2!\"\n              \"1i1125!2i976!1m6!1m2!1i0!2i0!2m2!1i1125!2i20!1m6!1m2!1i0!2i956!2m2!1i1125!2i976!37m1!1e81!42b1!47m0!49m1\"\n              \"!3b1\"\n    }\n\n    search_url = \"https://www.google.es/search?\" + \"&\".join(k + \"=\" + str(v) for k, v in params_url.items())\n    logging.info(\"searchterm: \" + search_url)\n\n    # noinspection PyUnresolvedReferences\n    gcontext = ssl.SSLContext(ssl.PROTOCOL_TLSv1)\n\n    resp = urllib.request.urlopen(\n        urllib.request.Request(\n            url=search_url,\n            data=None,\n            headers=user_agent),\n        context=gcontext)\n\n    data = resp.read().decode('utf-8').split('/*\"\"*/')[0]\n\n    # find eof json\n    jend = data.rfind(\"}\")\n    if jend >= 0:\n        data = data[:jend + 1]\n\n    jdata = json.loads(data)[\"d\"]\n    jdata = json.loads(jdata[4:])\n\n    # get info from result array, has to be adapted if backend api changes\n    info = index_get(jdata, 0, 1, 0, 14)\n\n    rating = index_get(info, 4, 7)\n    rating_n = index_get(info, 4, 8)\n\n    popular_times = index_get(info, 84, 0)\n\n    # current_popularity is also not available if popular_times isn't\n    current_popularity = index_get(info, 84, 7, 1)\n\n    time_spent = index_get(info, 117, 0)\n\n    # extract numbers from time string\n    if time_spent is not None:\n        time_spent = time_spent.replace(\"\\xa0\", \" \")\n\n        time_spent = [[\n            float(s) for s in time_spent.replace(\"-\", \" \").replace(\",\", \".\").split(\" \")\n            if s.replace('.', '', 1).isdigit()\n        ], time_spent]\n\n    return rating, rating_n, popular_times, current_popularity, time_spent"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_response_code(resp):\n    if resp[\"status\"] == \"OK\" or resp[\"status\"] == \"ZERO_RESULTS\":\n        return\n\n    if resp[\"status\"] == \"REQUEST_DENIED\":\n        raise Exception(\"Google Places \" + resp[\"status\"],\n                        \"Request was denied, the API key is invalid.\")\n\n    if resp[\"status\"] == \"OVER_QUERY_LIMIT\":\n        raise Exception(\"Google Places \" + resp[\"status\"],\n                        \"You exceeded your Query Limit for Google Places API Web Service, \"\n                        \"check https://developers.google.com/places/web-service/usage \"\n                        \"to upgrade your quota.\")\n\n    if resp[\"status\"] == \"INVALID_REQUEST\":\n        raise Exception(\"Google Places \" + resp[\"status\"],\n                        \"The query string is malformed, \"\n                        \"check if your formatting for lat/lng and radius is correct.\")\n\n    raise Exception(\"Google Places \" + resp[\"status\"],\n                    \"Unidentified error with the Places API, please check the response code\")", "response": "check if the response code is OK"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_place_details(api_key, place_id, **kwargs):\n\n    params = {\n        'placeid': place_id,\n        'key': api_key,\n        }\n\n    resp = requests.get(url=DETAIL_GOOGLEMAPS_API_URL, params=params)\n\n    if resp.status_code >= 300:\n        raise Exception('Bad status code rerieved from google api')\n\n    data = json.loads(resp.text)\n\n    # check api response status codess\n    check_response_code(data)\n\n    detail = data.get(\"result\", {})\n\n    place_identifier = \"{} {}\".format(detail.get(\"name\"), detail.get(\"formatted_address\"))\n\n    detail_json = {\n        \"id\": detail.get(\"place_id\"),\n        \"name\": detail.get(\"name\"),\n        \"address\": detail.get(\"formatted_address\"),\n        \"types\": detail.get(\"types\"),\n        \"coordinates\": detail.get(\"geometry\", {}).get(\"location\")\n    }\n\n    detail_json = add_optional_parameters(\n        detail_json, detail,\n        *get_populartimes_from_search(place_identifier, **kwargs)\n    )\n\n    return detail_json", "response": "This function sends request to detail to get a search string and uses standard proto buffer to get additional information on the current status of popular times\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_hashed_filename(name, file, suffix=None):\n    basename, hash, ext = split_filename(name)\n    file.seek(0)\n    new_hash = '.%s' % md5(file.read()).hexdigest()[:12]\n    if suffix is not None:\n        basename = '%s_%s' % (basename, suffix)\n    return '%s%s%s' % (basename, new_hash, ext)", "response": "Returns a new filename for the provided file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsplitting a filename into three parts.", "response": "def split_filename(name):\n    \"\"\"\n    Splits the filename into three parts: the name part, the hash part, and the\n    extension. Like with the extension, the hash part starts with a dot.\n\n    \"\"\"\n    parts = hashed_filename_re.match(name).groupdict()\n    return (parts['name'] or '', parts['hash'] or '', parts['ext'] or '')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the 10 next departures for a given bus number stop code and date.", "response": "def next_departures(bus_number, stop_code, date, time, nb_departure, db_file):\n    \"\"\"\n    Getting the 10 next departures\n\n    How to check with tools database\n    sqlite3 stm.db\n\n    SELECT \"t2\".\"departure_time\" \n        FROM \"trips\" AS t1 INNER JOIN \"stop_times\" AS t2 ON (\"t1\".\"trip_id\" = \"t2\".\"trip_id\") \n        INNER JOIN \"stops\" AS t3 ON (\"t2\".\"stop_id\" = \"t3\".\"stop_id\") \n        WHERE (((\"t1\".\"route_id\" = '51') \n            AND (\"t3\".\"stop_code\" = '51176')) \n            AND (\"t1\".\"service_id\" IN (SELECT \"t4\".\"service_id\" \n                                        FROM \"calendar\" AS t4 \n                                        WHERE ('20190102' BETWEEN \"t4\".\"start_date\" AND \"t4\".\"end_date\" )\n                                            AND \"t4\".wednesday == 1\n                                            AND \"t4\".service_id NOT IN (select c2.service_id from calendar_dates as c2 WHERE 20190102 == c2.date)\n                                    )\n                )\n            ) \n        ORDER BY \"t2\".\"departure_time\" ;\n\n    Replace 20190102 with the expected date\n    Replace wednesday with corresponding day of week\n    make it also for bus number '51' and '51176'\n\n    Other guideline to get valid working schedule for the weekday\n    select * from calendar WHERE (20190102 BETWEEN start_date AND end_date) AND sunday == 1\n    select * from calendar_dates WHERE 20190102 == date\n\n    Select where cases of holiday for days that does not apply\n    SELECT t1.service_id\n    FROM calendar AS t1\n    WHERE (20190102 BETWEEN t1.start_date AND t1.end_date) \n        AND t1.wednesday == 1 \n        AND (t1.service_id NOT IN (select c2.service_id from calendar_dates as c2 WHERE 20190102 == c2.date))\n    \"\"\"\n\n    # Use table Calendar as update from december 2018\n    day_of_week = datetime.datetime.strptime(\n        date, \"%Y%m%d\").strftime(\"%A\").lower()\n\n    # Extract dates that the service is disabled\n    subquery_days_off = CalendarDate.select(CalendarDate.service_id)\\\n        .where(\n            date == CalendarDate.date\n    )\n\n    # Use calendar to get all services minus days off\n    subquery = Calendar.select(Calendar.service_id)\\\n        .where(\n            (date >= Calendar.start_date) &\n            (date <= Calendar.end_date) &\n            (getattr(Calendar, day_of_week) == 1) &\n            Calendar.service_id.not_in(subquery_days_off)\n    )\n\n    # Filter service_id as list of service_id available\n    query_result = Trip.select(StopTime.departure_time)\\\n        .join(StopTime, on=(Trip.trip_id == StopTime.trip_id))\\\n        .join(Stop, on=(StopTime.stop_id == Stop.stop_id))\\\n        .where(\n            (Trip.route_id == bus_number) &\n            (Stop.stop_code == stop_code) &\n            (Trip.service_id .in_(subquery)))\\\n        .order_by(StopTime.departure_time)\n\n    result = []\n    departures_listed = 0\n    for i in query_result.dicts():\n        dep_time = i['departure_time'].split(':')\n        if dep_time[0] == time[0] and dep_time[1] >= time[1]:\n            result.append(\"{0}:{1}\".format(dep_time[0], dep_time[1]))\n            departures_listed += 1\n        elif dep_time[0] > time[0]:\n            result.append(\"{0}:{1}\".format(dep_time[0], dep_time[1]))\n            departures_listed += 1\n\n        if departures_listed is nb_departure:\n            break\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a random IPv4 address from the given CIDR block.", "response": "def random_ipv4(cidr='10.0.0.0/8'):\n    \"\"\"\n    Return a random IPv4 address from the given CIDR block.\n\n    :key str cidr: CIDR block\n    :returns: An IPv4 address from the given CIDR block\n    :rtype: ipaddress.IPv4Address\n    \"\"\"\n    try:\n        u_cidr = unicode(cidr)\n    except NameError:\n        u_cidr = cidr\n    network = ipaddress.ip_network(u_cidr)\n    start = int(network.network_address) + 1\n    end = int(network.broadcast_address)\n    randint = random.randrange(start, end)\n    return ipaddress.ip_address(randint)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the list of output files from this rule.", "response": "def output_files(self):\n        \"\"\"Returns the list of output files from this rule.\n\n        Paths are relative to buildroot.\n        \"\"\"\n        for item in self.source_files:\n            yield os.path.join(self.address.repo, self.address.path, item)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _compile_qt_resources():\n    if config.QT_RES_SRC():\n        epab.utils.ensure_exe('pyrcc5')\n        LOGGER.info('compiling Qt resources')\n        elib_run.run(f'pyrcc5 {config.QT_RES_SRC()} -o {config.QT_RES_TGT()}')", "response": "Compile PyQT resources file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_json(msg):\n    result = {}\n    \n    # herald specification version\n    #result[herald.MESSAGE_HERALD_VERSION] = herald.HERALD_SPECIFICATION_VERSION\n    \n    # headers\n    result[herald.MESSAGE_HEADERS] = {}        \n    if msg.headers is not None:\n        for key in msg.headers:\n            result[herald.MESSAGE_HEADERS][key] = msg.headers.get(key) or None        \n    \n    # subject\n    result[herald.MESSAGE_SUBJECT] = msg.subject\n    # content\n    if msg.content is not None:\n        if isinstance(msg.content, str):\n            # string content\n            result[herald.MESSAGE_CONTENT] = msg.content\n        else:\n            # jaborb content\n            result[herald.MESSAGE_CONTENT] = jabsorb.to_jabsorb(msg.content)\n    \n    # metadata\n    result[herald.MESSAGE_METADATA] = {}        \n    if msg.metadata is not None:\n        for key in msg.metadata:\n            result[herald.MESSAGE_METADATA][key] = msg.metadata.get(key) or None\n            \n    return json.dumps(result, default=herald.utils.json_converter)", "response": "Returns a JSON string representation of this message"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_json(json_string):\n    # parse the provided json_message\n    try:            \n        parsed_msg = json.loads(json_string)            \n    except ValueError as ex:            \n        # if the provided json_message is not a valid JSON\n        return None\n    except TypeError as ex:\n        # if json_message not string or buffer\n        return None\n    herald_version = None\n    # check if it is a valid Herald JSON message\n    if herald.MESSAGE_HEADERS in parsed_msg:\n        if herald.MESSAGE_HERALD_VERSION in parsed_msg[herald.MESSAGE_HEADERS]:\n            herald_version = parsed_msg[herald.MESSAGE_HEADERS].get(herald.MESSAGE_HERALD_VERSION)                         \n    if herald_version is None or herald_version != herald.HERALD_SPECIFICATION_VERSION:\n        _logger.error(\"Herald specification of the received message is not supported!\")\n        return None   \n    # construct new Message object from the provided JSON object    \n    msg = herald.beans.MessageReceived(uid=(parsed_msg[herald.MESSAGE_HEADERS].get(herald.MESSAGE_HEADER_UID) or None), \n                          subject=parsed_msg[herald.MESSAGE_SUBJECT], \n                          content=None, \n                          sender_uid=(parsed_msg[herald.MESSAGE_HEADERS].get(herald.MESSAGE_HEADER_SENDER_UID) or None), \n                          reply_to=(parsed_msg[herald.MESSAGE_HEADERS].get(herald.MESSAGE_HEADER_REPLIES_TO) or None), \n                          access=None,\n                          timestamp=(parsed_msg[herald.MESSAGE_HEADERS].get(herald.MESSAGE_HEADER_TIMESTAMP) or None) \n                          )                           \n    # set content\n    try:\n        if herald.MESSAGE_CONTENT in parsed_msg:\n            parsed_content = parsed_msg[herald.MESSAGE_CONTENT]                              \n            if parsed_content is not None:\n                if isinstance(parsed_content, str):\n                    msg.set_content(parsed_content)\n                else:\n                    msg.set_content(jabsorb.from_jabsorb(parsed_content))\n    except KeyError as ex:\n        _logger.error(\"Error retrieving message content! \" + str(ex)) \n    # other headers\n    if herald.MESSAGE_HEADERS in parsed_msg:\n        for key in parsed_msg[herald.MESSAGE_HEADERS]:\n            if key not in msg._headers:\n                msg._headers[key] = parsed_msg[herald.MESSAGE_HEADERS][key]         \n    # metadata\n    if herald.MESSAGE_METADATA in parsed_msg:\n        for key in parsed_msg[herald.MESSAGE_METADATA]:\n            if key not in msg._metadata:\n                msg._metadata[key] = parsed_msg[herald.MESSAGE_METADATA][key] \n                       \n    return msg", "response": "Returns a new MessageReceived from the provided json_string string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self):\n        # The \"or\" part is for Python 2.6\n        while not (self.finished.wait(self.interval)\n                   or self.finished.is_set()):\n            self.function(*self.args, **self.kwargs)", "response": "Runs the given method until cancel is called."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resource(string: str):\n        try:\n            prefix, resulting_type = Naming.pop_prefix(string)\n            prefix += Naming.RESOURCE_PREFIX\n        except IndexError:\n            prefix = ''\n            resulting_type = string\n        resulting_type = dasherize(underscore(resulting_type))\n        return prefix + (pluralize(resulting_type) if Naming._pluralize(resulting_type) else resulting_type)", "response": "Converts a string to a resource name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a string to a python type", "response": "def python(string: str):\n        \"\"\"\n            :param string: String can be type, resource or python case\n        \"\"\"\n        return underscore(singularize(string) if Naming._pluralize(string) else string)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pop_prefix(string: str):\n        result = string.split(Naming.TYPE_PREFIX)\n        if len(result) == 1:\n            result = string.split(Naming.RESOURCE_PREFIX)\n            if len(result) == 1:\n                raise IndexError()\n        return result", "response": "Erases the prefix and returns it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new_type(type_name: str, prefix: str or None = None) -> str:\n        if Naming.TYPE_PREFIX in type_name:\n            raise TypeError('Cannot create new type: type {} is already prefixed.'.format(type_name))\n        prefix = (prefix + Naming.TYPE_PREFIX) if prefix is not None else ''\n        return prefix + type_name", "response": "Creates a new resource type with optional prefix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hid(manufacturer: str, serial_number: str, model: str) -> str:\n        return Naming.url_word(manufacturer) + '-' + Naming.url_word(serial_number) + '-' + Naming.url_word(model)", "response": "Computes the HID for the given properties of a device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a Membership document", "response": "def get_membership_document(membership_type: str, current_block: dict, identity: Identity, salt: str,\n                            password: str) -> Membership:\n    \"\"\"\n    Get a Membership document\n\n    :param membership_type: \"IN\" to ask for membership or \"OUT\" to cancel membership\n    :param current_block: Current block data\n    :param identity: Identity document\n    :param salt: Passphrase of the account\n    :param password: Password of the account\n\n    :rtype: Membership\n    \"\"\"\n\n    # get current block BlockStamp\n    timestamp = BlockUID(current_block['number'], current_block['hash'])\n\n    # create keys from credentials\n    key = SigningKey.from_credentials(salt, password)\n\n    # create identity document\n    membership = Membership(\n        version=10,\n        currency=current_block['currency'],\n        issuer=key.pubkey,\n        membership_ts=timestamp,\n        membership_type=membership_type,\n        uid=identity.uid,\n        identity_ts=identity.timestamp,\n        signature=None\n    )\n\n    # sign document\n    membership.sign([key])\n\n    return membership"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nscans an ast object for a given global variable and return its value.", "response": "def getvar(syntree, targetvar):\n    \"\"\"Scan an ast object for targetvar and return its value.\n\n    Only handles single direct assignment of python literal types. See docs on\n    ast.literal_eval for more info:\n    http://docs.python.org/2/library/ast.html#ast.literal_eval\n\n    Args:\n      syntree: ast.Module object\n      targetvar: name of global variable to return\n    Returns:\n      Value of targetvar if found in syntree, or None if not found.\n    \"\"\"\n    for node in syntree.body:\n        if isinstance(node, ast.Assign):\n            for var in node.targets:\n                if var.id == targetvar:\n                    return ast.literal_eval(node.value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning a command and return the output.", "response": "def run(cmd, shell=False, debug=False):\n    'Run a command and return the output.'\n    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=shell)\n    (out, _) = proc.communicate()  # no need for stderr\n    if debug:\n        print(cmd)\n        print(out)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind objects in pairtree.", "response": "def findObjects(path):\n    \"\"\"Finds objects in pairtree.\n\n    Given a path that corresponds to a pairtree, walk it and look for\n    non-shorty (it's ya birthday) directories.\n    \"\"\"\n    objects = []\n    if not os.path.isdir(path):\n        return []\n    contents = os.listdir(path)\n    for item in contents:\n        fullPath = os.path.join(path, item)\n        if not os.path.isdir(fullPath):\n            # deal with a split end at this point\n            # we might want to consider a normalize option\n            return [path]\n        else:\n            if isShorty(item):\n                objects = objects + findObjects(fullPath)\n            else:\n                objects.append(fullPath)\n    return objects"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetermining the pair path for the digital object meta - id.", "response": "def get_pair_path(meta_id):\n    \"\"\"Determines the pair path for the digital object meta-id.\"\"\"\n    pair_tree = pair_tree_creator(meta_id)\n    pair_path = os.path.join(pair_tree, meta_id)\n    return pair_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pair_tree_creator(meta_id):\n    chunks = []\n    for x in range(0, len(meta_id)):\n        if x % 2:\n            continue\n        if (len(meta_id) - 1) == x:\n            chunk = meta_id[x]\n        else:\n            chunk = meta_id[x: x + 2]\n        chunks.append(chunk)\n    return os.sep + os.sep.join(chunks) + os.sep", "response": "Splits string into a pairtree path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deSanitizeString(name):\n    oldString = name\n    # first pass\n    replaceTable2 = [\n        (\"/\", \"=\"),\n        (\":\", \"+\"),\n        (\".\", \",\"),\n    ]\n    for r in replaceTable2:\n        oldString = oldString.replace(r[1], r[0])\n    # reverse ascii 0-32 stuff\n    # must subtract number added at sanitization\n    for x in range(0, 33):\n        oldString = oldString.replace(\n            hex(x + sanitizerNum).replace('0x', '^'), chr(x))\n    # second pass\n    replaceTable = [\n        ('\"', '^22'),\n        ('<', '^3c'),\n        ('?', '^3f'),\n        ('*', '^2a'),\n        ('=', '^3d'),\n        ('+', '^2b'),\n        ('>', '^3e'),\n        ('|', '^7c'),\n        (',', '^2c'),\n        ('^', '^5e'),\n    ]\n\n    for r in replaceTable:\n        oldString = oldString.replace(r[1], r[0])\n    return oldString", "response": "Reverses sanitization process.\n\n    Reverses changes made to a string that has been sanitized for use\n    as a pairtree identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncleans a string in preparation for splitting for use as a pairtree identifier.", "response": "def sanitizeString(name):\n    \"\"\"Cleans string in preparation for splitting for use as a pairtree\n    identifier.\"\"\"\n    newString = name\n    # string cleaning, pass 1\n    replaceTable = [\n        ('^', '^5e'),  # we need to do this one first\n        ('\"', '^22'),\n        ('<', '^3c'),\n        ('?', '^3f'),\n        ('*', '^2a'),\n        ('=', '^3d'),\n        ('+', '^2b'),\n        ('>', '^3e'),\n        ('|', '^7c'),\n        (',', '^2c'),\n    ]\n\n    #   \"   hex 22           <   hex 3c           ?   hex 3f\n    #   *   hex 2a           =   hex 3d           ^   hex 5e\n    #   +   hex 2b           >   hex 3e           |   hex 7c\n    #   ,   hex 2c\n\n    for r in replaceTable:\n        newString = newString.replace(r[0], r[1])\n    # replace ascii 0-32\n    for x in range(0, 33):\n        # must add somewhat arbitrary num to avoid conflict at deSanitization\n        # conflict example: is ^x1e supposed to be ^x1 (ascii 1) followed by\n        # letter 'e' or really ^x1e (ascii 30)\n        newString = newString.replace(\n            chr(x), hex(x + sanitizerNum).replace('0x', '^'))\n\n    replaceTable2 = [\n        (\"/\", \"=\"),\n        (\":\", \"+\"),\n        (\".\", \",\"),\n    ]\n\n    # / -> =\n    # : -> +\n    # . -> ,\n\n    # string cleaning pass 2\n    for r in replaceTable2:\n        newString = newString.replace(r[0], r[1])\n    return newString"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef toPairTreePath(name):\n    sName = sanitizeString(name)\n    chunks = []\n    for x in range(0, len(sName)):\n        if x % 2:\n            continue\n        if (len(sName) - 1) == x:\n            chunk = sName[x]\n        else:\n            chunk = sName[x: x + 2]\n        chunks.append(chunk)\n    return os.sep.join(chunks) + os.sep", "response": "Cleans a string and then splits it into a pairtree path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_paired_dir(output_dir, meta_id, static=False, needwebdir=True):\n    # get the absolute root path\n    root_path = os.path.abspath(output_dir)\n    # if it's a static directory, add even and odd\n    if static:\n        # determine whether meta-id is odd or even\n        if meta_id[-1].isdigit():\n            last_character = int(meta_id[-1])\n        else:\n            last_character = ord(meta_id[-1])\n        if last_character % 2 == 0:\n            num_dir = 'even'\n        else:\n            num_dir = 'odd'\n        # add odd or even to the path, based on the meta-id\n        output_path = os.path.join(root_path, num_dir)\n    # if it's a meta directory, output as normal\n    else:\n        output_path = root_path\n    # if it doesn't already exist, create the output path (includes even/odd)\n    if not os.path.exists(output_path):\n        os.mkdir(output_path)\n    # add the pairtree to the output path\n    path_name = add_to_pairtree(output_path, meta_id)\n    # add the meta-id directory to the end of the pairpath\n    meta_dir = os.path.join(path_name, meta_id)\n    os.mkdir(meta_dir)\n    # if we are creating static output\n    if static and needwebdir:\n        # add the web path to the output directory\n        os.mkdir(os.path.join(meta_dir, 'web'))\n        static_dir = os.path.join(meta_dir, 'web')\n        return static_dir\n    # else we are creating meta output or don't need web directory\n    else:\n        return meta_dir", "response": "Creates the meta or static dirs based on the meta - id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate pairtree dir structure within pairtree for new element.", "response": "def add_to_pairtree(output_path, meta_id):\n    \"\"\"Creates pairtree dir structure within pairtree for new\n    element.\"\"\"\n    # create the pair path\n    paired_path = pair_tree_creator(meta_id)\n    path_append = ''\n    # for each directory in the pair path\n    for pair_dir in paired_path.split(os.sep):\n        # append the pair path together, one directory at a time\n        path_append = os.path.join(path_append, pair_dir)\n        # append the pair path to the output path\n        combined_path = os.path.join(output_path, path_append)\n        # if the path doesn't already exist, create it\n        if not os.path.exists(combined_path):\n            os.mkdir(combined_path)\n    return combined_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the prefix given in pairtree_prefix file.", "response": "def get_pairtree_prefix(pairtree_store):\n    \"\"\"Returns the prefix given in pairtree_prefix file.\"\"\"\n    prefix_path = os.path.join(pairtree_store, 'pairtree_prefix')\n    with open(prefix_path, 'r') as prefixf:\n        prefix = prefixf.read().strip()\n    return prefix"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a document field with regular expression and returns the value.", "response": "def parse_field(cls: Type[DocumentType], field_name: str, line: str) -> Any:\n        \"\"\"\n        Parse a document field with regular expression and return the value\n\n        :param field_name: Name of the field\n        :param line: Line string to parse\n        :return:\n        \"\"\"\n        try:\n            match = cls.fields_parsers[field_name].match(line)\n            if match is None:\n                raise AttributeError\n            value = match.group(1)\n        except AttributeError:\n            raise MalformedDocumentError(field_name)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the raw + current signatures", "response": "def signed_raw(self) -> str:\n        \"\"\"\n        If keys are None, returns the raw + current signatures\n        If keys are present, returns the raw signed by these keys\n        :return:\n        \"\"\"\n        raw = self.raw()\n        signed = \"\\n\".join(self.signatures)\n        signed_raw = raw + signed + \"\\n\"\n        return signed_raw"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns uppercase hex sha256 hash from signed raw document", "response": "def sha_hash(self) -> str:\n        \"\"\"\n        Return uppercase hex sha256 hash from signed raw document\n\n        :return:\n        \"\"\"\n        return hashlib.sha256(self.signed_raw().encode(\"ascii\")).hexdigest().upper()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a dictionary of archive table column names to values suitable for insert.", "response": "def build_row_dict(cls, row, dialect, deleted=False, user_id=None, use_dirty=True):\n        \"\"\"\n        Builds a dictionary of archive data from row which is suitable for insert.\n\n        NOTE: If `deleted` is False, version ID will be set to an AsIs SQL construct.\n\n        :param row: instance of :class:`~SavageModelMixin`\n        :param dialect: :py:class:`~sqlalchemy.engine.interfaces.Dialect`\n        :param deleted: whether or not the row is deleted (defaults to False)\n        :param user_id: ID of user that is performing the update on this row (defaults to None)\n        :param use_dirty: whether to use the dirty fields from row or not (defaults to True)\n        :return: a dictionary of archive table column names to values, suitable for insert\n        :rtype: dict\n        \"\"\"\n        data = {\n            'data': row.to_archivable_dict(dialect, use_dirty=use_dirty),\n            'deleted': deleted,\n            'updated_at': datetime.now(),\n            'version_id': current_version_sql(as_is=True) if deleted else row.version_id\n        }\n        for col_name in row.version_columns:\n            data[col_name] = utils.get_column_attribute(row, col_name, use_dirty=use_dirty)\n        if user_id is not None:\n            data['user_id'] = user_id\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbulks archives data previously written to DB.", "response": "def bulk_archive_rows(cls, rows, session, user_id=None, chunk_size=1000, commit=True):\n        \"\"\"\n        Bulk archives data previously written to DB.\n\n        :param rows: iterable of previously saved model instances to archive\n        :param session: DB session to use for inserts\n        :param user_id: ID of user responsible for row modifications\n        :return:\n        \"\"\"\n        dialect = utils.get_dialect(session)\n        to_insert_dicts = []\n        for row in rows:\n            row_dict = cls.build_row_dict(row, user_id=user_id, dialect=dialect)\n            to_insert_dicts.append(row_dict)\n            if len(to_insert_dicts) < chunk_size:\n                continue\n\n            # Insert a batch of rows\n            session.execute(insert(cls).values(to_insert_dicts))\n            to_insert_dicts = []\n\n        # Insert final batch of rows (if any)\n        if to_insert_dicts:\n            session.execute(insert(cls).values(to_insert_dicts))\n        if commit:\n            session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate the archive table.", "response": "def _validate(cls, engine, *version_cols):\n        \"\"\"\n        Validates the archive table.\n\n        Validates the following criteria:\n            - all version columns exist in the archive table\n            - the python types of the user table and archive table columns are the same\n            - a user_id column exists\n            - there is a unique constraint on version and the other versioned columns from the\n            user table\n\n        :param engine: instance of :class:`~sqlalchemy.engine.Engine`\n        :param *version_cols: instances of :class:`~InstrumentedAttribute` from\n        the user table corresponding to the columns that versioning pivots around\n        :raises: :class:`~LogTableCreationError`\n        \"\"\"\n        cls._version_col_names = set()\n        for version_column_ut in version_cols:\n            # Make sure all version columns exist on this table\n            version_col_name = version_column_ut.key\n            version_column_at = getattr(cls, version_col_name, None)\n            if not isinstance(version_column_at, InstrumentedAttribute):\n                raise LogTableCreationError(\"Log table needs {} column\".format(version_col_name))\n\n            # Make sure the type of the user table and log table columns are the same\n            version_col_at_t = version_column_at.property.columns[0].type.__class__\n            version_col_ut_t = version_column_ut.property.columns[0].type.__class__\n            if version_col_at_t != version_col_ut_t:\n                raise LogTableCreationError(\n                    \"Type of column {} must match in log and user table\".format(version_col_name)\n                )\n            cls._version_col_names.add(version_col_name)\n\n        # Ensure user added a user_id column\n        # TODO: should user_id column be optional?\n        user_id = getattr(cls, 'user_id', None)\n        if not isinstance(user_id, InstrumentedAttribute):\n            raise LogTableCreationError(\"Log table needs user_id column\")\n\n        # Check the unique constraint on the versioned columns\n        version_col_names = list(cls._version_col_names) + ['version_id']\n        if not utils.has_constraint(cls, engine, *version_col_names):\n            raise LogTableCreationError(\"There is no unique constraint on the version columns\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register(cls, archive_table, engine):\n        version_col_names = cls.version_columns\n        if not version_col_names:\n            raise LogTableCreationError('Need to specify version cols in cls.version_columns')\n        if cls.ignore_columns is None:\n            cls.ignore_columns = set()\n        cls.ignore_columns.add('version_id')\n        version_cols = [getattr(cls, col_name, None) for col_name in version_col_names]\n\n        cls._validate(engine, *version_cols)\n\n        archive_table._validate(engine, *version_cols)\n        cls.ArchiveTable = archive_table", "response": "Register the log entry with the archive table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert the current object to an archivable dictionary.", "response": "def to_archivable_dict(self, dialect, use_dirty=True):\n        \"\"\"\n        :param dialect: a :py:class:`~sqlalchemy.engine.interfaces.Dialect` corresponding to the \\\n            SQL dialect being used.\n        :param use_dirty: whether to make a dict of the fields as they stand, or the fields \\\n            before the row was updated\n\n        :return: a dictionary of key value pairs representing this row.\n        :rtype: dict\n        \"\"\"\n        return {\n            cn: utils.get_column_attribute(self, c, use_dirty=use_dirty, dialect=dialect)\n            for c, cn in utils.get_column_keys_and_names(self)\n            if c not in self.ignore_columns\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef self_aware(fn):\n    ''' decorating a function with this allows it to \n        refer to itself as 'self' inside the function\n        body.\n    '''\n    if isgeneratorfunction(fn):\n        @wraps(fn)\n        def wrapper(*a,**k):\n            generator = fn(*a,**k)\n            if hasattr(\n                generator, \n                'gi_frame'\n            ) and hasattr(\n                generator.gi_frame, \n                'f_builtins'\n            ) and hasattr(\n                generator.gi_frame.f_builtins, \n                '__setitem__'\n            ):\n                generator.gi_frame.f_builtins[\n                    'self'\n                ] = generator\n        return wrapper\n    else:\n        fn=strict_globals(**fn.__globals__)(fn)\n        fn.__globals__['self']=fn\n        return fn", "response": "decorator that allows it to \n        refer to itself as self inside the function\nAttributeNames body."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _basic_iterator(self):\n        for x in self._create_iter():\n            if x is None or isinstance(x, tuple):\n                yield x\n            else:\n                yield ((x,), {})\n            self._action_between_each_iteration()\n        else:\n            # when the iterator is exhausted, yield None as this is an\n            # indicator to some of the clients to take an action.\n            # This is a moribund action, but in this current refactoring\n            # we don't want to change old behavior\n            yield None\n        self._action_after_iteration_completes()", "response": "this iterator yields individual crash_ids and nones from the base iterator."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _infinite_iterator(self):\n        while True:\n            for crash_id in self._basic_iterator():\n                if self._filter_disallowed_values(crash_id):\n                    continue\n                yield crash_id", "response": "This iterator wraps the _basic_iterator and yields the crash_id s that are not allowed in any of the innermost configuration items."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _setup_source_and_destination(self):\n        try:\n            self.source = self.config.source.crashstorage_class(\n                self.config.source,\n                quit_check_callback=self.quit_check\n            )\n        except Exception:\n            self.config.logger.critical(\n                'Error in creating crash source',\n                exc_info=True\n            )\n            raise\n        try:\n            self.destination = self.config.destination.crashstorage_class(\n                self.config.destination,\n                quit_check_callback=self.quit_check\n            )\n        except Exception:\n            self.config.logger.critical(\n                'Error in creating crash destination',\n                exc_info=True\n            )\n            raise", "response": "instantiate the classes that implement the source and destination crash storage systems."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _setup_task_manager(self):\n        self.config.logger.info('installing signal handers')\n        # set up the signal handler for dealing with SIGTERM. the target should\n        # be this app instance so the signal handler can reach in and set the\n        # quit flag to be True.  See the 'respond_to_SIGTERM' method for the\n        # more information\n        respond_to_SIGTERM_with_logging = partial(\n            respond_to_SIGTERM,\n            target=self\n        )\n        signal.signal(signal.SIGTERM, respond_to_SIGTERM_with_logging)\n        self.task_manager = \\\n            self.config.producer_consumer.producer_consumer_class(\n                self.config.producer_consumer,\n                job_source_iterator=self.source_iterator,\n                task_func=self.transform\n            )\n        self.config.executor_identity = self.task_manager.executor_identity", "response": "instantiate the threaded task manager to run the producer and consumer\n            queue that is the heart of the processor."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main(self):\n\n        self._setup_task_manager()\n        self._setup_source_and_destination()\n        self.task_manager.blocking_start(waiting_func=self.waiting_func)\n        self.close()\n        self.config.logger.info('done.')", "response": "This is the main routine that is called by the daemon to start the crashstorage system. It is responsible for setting up the signal handlers the source and destination crashstorage systems at the task manager."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds to the source and destination for the new_crash_source app", "response": "def _setup_source_and_destination(self):\n        \"\"\"use the base class to setup the source and destinations but add to\n        that setup the instantiation of the \"new_crash_source\" \"\"\"\n        super(FetchTransformSaveWithSeparateNewCrashSourceApp, self) \\\n            ._setup_source_and_destination()\n        if self.config.new_crash_source.new_crash_source_class:\n            self.new_crash_source = \\\n                self.config.new_crash_source.new_crash_source_class(\n                    self.config.new_crash_source,\n                    name=self.app_instance_name,\n                    quit_check_callback=self.quit_check\n                )\n        else:\n            # the configuration failed to provide a \"new_crash_source\", fall\n            # back to tying the \"new_crash_source\" to the \"source\".\n            self.new_crash_source = self.source"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_config(options):\n    ''' Load options, platform, colors, and icons. '''\n    global opts, pform\n    opts = options\n    pform = options.pform\n    global_ns = globals()\n\n    # get colors\n    if pform.hicolor:\n        global_ns['dim_templ'] = ansi.dim8t\n        global_ns['swap_clr_templ'] = ansi.csi8_blk % ansi.blu8\n    else:\n        global_ns['dim_templ'] = ansi.dim4t\n        global_ns['swap_clr_templ'] = ansi.fbblue\n\n    # load icons into module namespace\n    for varname in dir(pform):\n        if varname.startswith('_') and varname.endswith('ico'):\n            global_ns[varname] = getattr(pform, varname)", "response": "Load options platform colors and icons into global namespace."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nformats justifies and returns a given string according to Taxonomy specifications.", "response": "def fmtstr(text='', colorstr=None, align='>', trunc=True, width=0, end=' '):\n    ''' Formats, justifies, and returns a given string according to\n        specifications.\n    '''\n    colwidth = width or opts.colwidth\n\n    if trunc:\n        if len(text) > colwidth:\n            text = truncstr(text, colwidth, align=trunc)  # truncate w/ellipsis\n\n    value = f'{text:{align}{colwidth}}'\n    if opts.incolor and colorstr:\n        return colorstr % value + end\n    else:\n        return value + end"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fmtval(value, colorstr=None, precision=None, spacing=True, trunc=True,\n           end=' '):\n    ''' Formats and returns a given number according to specifications. '''\n    colwidth = opts.colwidth\n    # get precision\n    if precision is None:\n        precision = opts.precision\n    fmt = '%%.%sf' % precision\n\n    # format with decimal mark, separators\n    result = locale.format(fmt, value, True)\n\n    if spacing:\n        result = '%%%ss' % colwidth % result\n\n    if trunc:\n        if len(result) > colwidth:   # truncate w/ellipsis\n            result = truncstr(result, colwidth)\n\n    # Add color if needed\n    if opts.incolor and colorstr:\n        return colorstr % result + end\n    else:\n        return result + end", "response": "Formats and returns a given number according to specifications."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the output unit and precision for future calculations and returns an integer and the string representation of it.", "response": "def get_units(unit, binary=False):\n    ''' Sets the output unit and precision for future calculations and returns\n        an integer and the string representation of it.\n    '''\n    result = None\n\n    if unit == 'b':\n        result = 1, 'Byte'\n\n    elif binary:    # 2^X\n        if   unit == 'k':\n            result = 1024, 'Kibibyte'\n        elif unit == 'm':\n            result = 1048576, 'Mebibyte'\n        elif unit == 'g':\n            if opts.precision == -1:\n                opts.precision = 3\n            result = 1073741824, 'Gibibyte'\n        elif unit == 't':\n            if opts.precision == -1:\n                opts.precision = 3\n            result = 1099511627776, 'Tebibyte'\n\n    else:           #  10^x\n        if   unit == 'k':\n            result = 1000, 'Kilobyte'\n        elif unit == 'm':\n            result = 1000000, 'Megabyte'\n        elif unit == 'g':\n            if opts.precision == -1:\n                opts.precision = 3      # new defaults\n            result = 1000000000, 'Gigabyte'\n        elif unit == 't':\n            if opts.precision == -1:\n                opts.precision = 3\n            result = 1000000000000, 'Terabyte'\n\n    if not result:\n        print(f'Warning: incorrect parameter: {unit}.')\n        result = _outunit\n\n    if opts.precision == -1:  # auto\n        opts.precision = 0\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_diskinfo(diskinfo, widelayout, incolor):\n    ''' Disk information output function. '''\n    sep = ' '\n    if opts.relative:\n        import math\n        base = max([ disk.ocap for disk in diskinfo ])\n\n    for disk in diskinfo:\n        if disk.ismntd:     ico = _diskico\n        else:               ico = _unmnico\n        if disk.isrem:      ico = _remvico\n        if disk.isopt:      ico = _discico\n        if disk.isnet:      ico = _netwico\n        if disk.isram:      ico = _ramico\n        if disk.isimg:      ico = _imgico\n        if disk.mntp == '/boot/efi':\n                            ico = _gearico\n\n        if opts.relative and disk.ocap and disk.ocap != base:\n            # increase log size reduction by raising to 4th power:\n            gwidth = int((math.log(disk.ocap, base)**4) * opts.width)\n        else:\n            gwidth = opts.width\n\n        # check color settings, ffg: free foreground, ufg: used forground\n        if disk.rw:\n            ffg = ufg = None        # auto colors\n        else:\n            # dim or dark grey\n            ffg = ufg = (ansi.dim8 if opts.hicolor else ansi.dim4)\n\n        cap = disk.cap\n        if cap and disk.rw:\n            lblcolor = ansi.get_label_tmpl(disk.pcnt, opts.width, opts.hicolor)\n        else:\n            lblcolor = None\n\n        # print stats\n        data = (\n            (_usedico, disk.pcnt,     ufg,  None,  pform.boldbar),  # Used\n            (_freeico, 100-disk.pcnt, ffg,  None,  False),          # free\n        )\n        mntp = fmtstr(disk.mntp, align='<', trunc='left',\n                      width=(opts.colwidth * 2) + 2)\n        mntp = mntp.rstrip()  # prevent wrap\n        if disk.label is None:\n            label = fmtstr(_emptico, dim_templ, align='<')\n        else:\n            label = fmtstr(disk.label, align='<')\n\n        if widelayout:\n            out(\n                fmtstr(ico + sep + disk.dev, align='<') + label\n            )\n            if cap:\n                out(fmtval(cap))\n                if disk.rw:\n                    out(\n                        fmtval(disk.used, lblcolor) +\n                        fmtval(disk.free, lblcolor)\n                    )\n                else:\n                    out(\n                        fmtstr() +\n                        fmtstr(_emptico, dim_templ)\n                    )\n            else:\n                out(fmtstr(_emptico, dim_templ))\n\n            if cap:\n                if disk.rw:  # factoring this caused colored brackets\n                    ansi.rainbar(data, gwidth, incolor,\n                                 hicolor=opts.hicolor,\n                                 cbrackets=_brckico)\n                else:\n                    ansi.bargraph(data, gwidth, incolor, cbrackets=_brckico)\n\n                if opts.relative and opts.width != gwidth:\n                    out(sep * (opts.width - gwidth))\n                out(sep + mntp)\n            print()\n        else:\n            out(\n                fmtstr(ico + sep + disk.dev, align=\"<\") + label\n            )\n            if cap:\n                out(\n                    fmtval(cap) +\n                    fmtval(disk.used, lblcolor) +\n                    fmtval(disk.free, lblcolor)\n                )\n            else:\n                out(fmtstr(_emptico, dim_templ) + fmtstr() + fmtstr())\n            print(sep, mntp)\n\n            if cap:\n                out(fmtstr())\n                if disk.rw:\n                    ansi.rainbar(data, gwidth, incolor, hicolor=opts.hicolor,\n                                 cbrackets=_brckico)\n                else:\n                    ansi.bargraph(data, gwidth, incolor, cbrackets=_brckico)\n            print()\n            print()\n    print()", "response": "Print the disk information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_meminfo(meminfo, widelayout, incolor):\n    ''' Memory information output function. '''\n    sep = ' '\n    # prep Mem numbers\n    totl = meminfo.memtotal\n    cach = meminfo.cached + meminfo.buffers\n    free = meminfo.memfree\n    used = meminfo.used\n\n    usep = float(used) / totl * 100           # % used of total ram\n    cacp = float(cach) / totl * 100           # % cache\n    frep = float(free) / totl * 100           # % free\n    rlblcolor = ansi.get_label_tmpl(usep, opts.width, opts.hicolor)\n\n    # Prepare Swap numbers\n    swpt = meminfo.swaptotal\n    if swpt:\n        swpf = meminfo.swapfree\n        swpc = meminfo.swapcached\n        swpu = meminfo.swapused\n        swfp = float(swpf) / swpt * 100       # % free of total sw\n        swcp = float(swpc) / swpt * 100       # % cache\n        swup = float(swpu) / swpt * 100       # % used\n        slblcolor = ansi.get_label_tmpl(swup, opts.width, opts.hicolor)\n    else:\n        swpf = swpc = swpu = swfp = swcp = swup = 0         # avoid /0 error\n        slblcolor = None\n    cacheico = _usedico if incolor else _cmonico\n\n    # print RAM info\n    data = (\n        (_usedico, usep, None,  None, pform.boldbar),       # used\n        (cacheico, cacp, ansi.blue,  None, pform.boldbar),  # cache\n        (_freeico, frep, None,  None, False),               # free\n    )\n    if widelayout:\n        out(\n            fmtstr(_ramico + ' RAM', align='<') +\n            fmtstr() +                                      # volume col\n            fmtval(totl) +\n            fmtval(used, rlblcolor) +\n            fmtval(free, rlblcolor)\n        )\n        # print graph\n        ansi.rainbar(data, opts.width, incolor, hicolor=opts.hicolor,\n                     cbrackets=_brckico)\n        print('', fmtval(cach, swap_clr_templ))\n    else:\n        out(\n            fmtstr(_ramico + ' RAM', align=\"<\") +\n            fmtstr() +                                      # volume col\n            fmtval(totl) +\n            fmtval(used, rlblcolor) +\n            fmtval(free, rlblcolor) +\n            sep + sep +\n            fmtval(cach, swap_clr_templ) + '\\n' +\n            fmtstr()                                        # blank space\n        )\n        # print graph\n        ansi.rainbar(data, opts.width, incolor, hicolor=opts.hicolor,\n                     cbrackets=_brckico)\n        print()                             # extra line in narrow layout\n\n    # Swap time:\n    data = (\n        (_usedico, swup, None, None, pform.boldbar),        # used\n        (_usedico, swcp, None, None, pform.boldbar),        # cache\n        (_freeico, swfp, None, None, False),                # free\n    )\n    if widelayout:\n        out(fmtstr(_diskico + ' SWAP', align='<') + fmtstr())   # label\n        if swpt:\n            out(\n                fmtval(swpt) +\n                fmtval(swpu, slblcolor) +\n                fmtval(swpf, slblcolor)\n            )\n        else:\n            print(fmtstr(_emptico, dim_templ))\n\n        # print graph\n        if swpt:\n            ansi.rainbar(data, opts.width, incolor, hicolor=opts.hicolor,\n                         cbrackets=_brckico)\n            if swpc:\n                out(' ' + fmtval(swpc, swap_clr_templ))\n            print()\n    else:\n        out(fmtstr(_diskico + ' SWAP', align='<'))\n        if swpt:\n            out(\n                fmtstr() +                                  # volume col\n                fmtval(swpt) +\n                fmtval(swpu, slblcolor) +\n                fmtval(swpf, slblcolor)\n            )\n            if swpc:\n                out('  ' + fmtval(swpc, swap_clr_templ))\n            print()\n            out(fmtstr())  # blank space\n\n            # print graph\n            ansi.rainbar(data, opts.width, incolor, hicolor=opts.hicolor,\n                         cbrackets=_brckico)\n            print()\n        else:\n            print(' ' + fmtstr(_emptico, dim_templ, align='<'))\n        print()\n\n    print()", "response": "Memory information output function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef truncstr(text, width, align='right'):\n    ''' Truncate a string, with trailing ellipsis. '''\n    before = after = ''\n    if align == 'left':\n        truncated = text[-width+1:]\n        before = _ellpico\n    elif align:\n        truncated = text[:width-1]\n        after = _ellpico\n\n    return f'{before}{truncated}{after}'", "response": "Truncates a string with trailing ellipsis."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the ZIP - encoded file to a directory.", "response": "def archive(self, target_path=None, zip_path=None):\n        \"\"\"\n        Writes the Zip-encoded file to a directory.\n\n        :param target_path: The directory path to add.\n        :type target_path: str\n        :param zip_path: The file path of the ZIP archive.\n        :type zip_path: str\n        \"\"\"\n        if target_path:\n            self.target_path = target_path\n\n        if zip_path:\n            self.zip_path = zip_path\n\n        if self.has_path is False or os.path.isdir(self.target_path) is False:\n            raise RuntimeError(\"\")\n\n        zip = zipfile.ZipFile(\n            self.zip_path,\n            'w',\n            zipfile.ZIP_DEFLATED\n        )\n\n        for root, _, files in os.walk(self.target_path):\n            for file in files:\n                if file in ARCHIVE_IGNORE_FILES:\n                    continue\n\n                current_dir = os.path.relpath(root, self.target_path)\n\n                if current_dir == \".\":\n                    file_path = file\n                else:\n                    file_path = os.path.join(current_dir, file)\n\n                print(\"Archive {}\".format(file))\n\n                zip.write(\n                    os.path.join(root, file),\n                    file_path\n                )\n\n        zip.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts the given files to the specified destination. :param src_path: The destination path where to extract the files. :type src_path: str :param zip_path: The file path of the ZIP archive. :type zip_path: str", "response": "def unarchive(self, target_path=None, zip_path=None):\n        \"\"\"\n        Extract the given files to the specified destination.\n\n        :param src_path: The destination path where to extract the files.\n        :type src_path: str\n        :param zip_path: The file path of the ZIP archive.\n        :type zip_path: str\n        \"\"\"\n        if target_path:\n            self.target_path = target_path\n\n        if zip_path:\n            self.zip_path = zip_path\n\n        if self.has_path is False:\n            raise RuntimeError(\"\")\n\n        if os.path.isdir(self.target_path) is False:\n            os.mkdir(self.target_path)\n\n        with zipfile.ZipFile(self.zip_path, 'r') as zip:\n            zip.extractall(self.target_path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_sns(style=\"white\", context=\"paper\", font_scale=1.5, color_codes=True,\n            rc={}):\n    \"\"\"Set default plot style using seaborn.\n\n    Font size is set to match the size of the tick labels, rather than the axes\n    labels.\n    \"\"\"\n    rcd = {\"lines.markersize\": 8, \"lines.markeredgewidth\": 1.25,\n           \"legend.fontsize\": \"small\", \"font.size\": 12/1.5*font_scale,\n           \"legend.frameon\": True, \"axes.formatter.limits\": (-5, 5),\n           \"axes.grid\": True}\n    rcd.update(rc)\n    import seaborn as sns\n    sns.set(style=style, context=context, font_scale=font_scale,\n            color_codes=color_codes, rc=rcd)", "response": "Set default plot style using seaborn. sns."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a subplot label.", "response": "def label_subplot(ax=None, x=0.5, y=-0.25, text=\"(a)\", **kwargs):\n    \"\"\"Create a subplot label.\"\"\"\n    if ax is None:\n        ax = plt.gca()\n    ax.text(x=x, y=y, s=text, transform=ax.transAxes,\n            horizontalalignment=\"center\", verticalalignment=\"top\", **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef coerce_file(fn):\n    import ast, os, re, tempfile, time, subprocess  # NOQA\n    text = open(os.path.join(os.path.dirname(__file__), fn)).read()\n    if fn.endswith('.py'):  # extract version, docstring etc out of python file\n        mock = type('mock', (object,), {})()\n        for attr in ('version', 'author', 'author_email', 'license', 'url'):\n            regex = r'^__%s__\\s*=\\s*[\\'\"]([^\\'\"]*)[\\'\"]$' % attr\n            m = re.search(regex, text, re.MULTILINE)\n            setattr(mock, attr, m.group(1) if m else None)\n        mock.docstring = ast.get_docstring(ast.parse(text))\n        if mock.version.endswith('dev'):\n            mock.version += str(int(time.time()))\n        return mock\n    if 'upload' in sys.argv and fn.endswith('md'):  # convert markdown to rest\n        text = '\\n'.join([l for l in text.split('\\n') if '[nopypi' not in l])\n        text = re.sub(r':\\S+:', '', text)  # no emojis\n        with tempfile.NamedTemporaryFile(mode='w+') as tmp:\n            tmp.write(text)\n            tmp.flush()\n            text, stderr = subprocess.Popen(['pandoc', '-t', 'rst', tmp.name],\n                stdout=subprocess.PIPE).communicate()\n    return text", "response": "Coerce file content to something useful for setuptools. setup"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a. changes file for this package.", "response": "def genchanges(self):\n        \"\"\"Generate a .changes file for this package.\"\"\"\n        chparams = self.params.copy()\n        debpath = os.path.join(self.buildroot, self.rule.output_files[0])\n        chparams.update({\n            'fullversion': '{epoch}:{version}-{release}'.format(**chparams),\n            'metahash': self._metahash().hexdigest(),\n            'deb_sha1': util.hash_file(debpath, hashlib.sha1()).hexdigest(),\n            'deb_sha256': util.hash_file(debpath, hashlib.sha256()\n                                         ).hexdigest(),\n            'deb_md5': util.hash_file(debpath, hashlib.md5()).hexdigest(),\n            'deb_bytes': os.stat(debpath).st_size,\n            # TODO: having to do this split('/')[-1] is absurd:\n            'deb_filename': debpath.split('/')[-1],\n            })\n\n        output = '\\n'.join([\n            'Format: 1.8',\n            # Static date string for repeatable builds:\n            'Date: Tue, 01 Jan 2013 00:00:00 -0700',\n            'Source: {package_name}',\n            'Binary: {package_name}',\n            'Architecture: {arch}',\n            'Version: {fullversion}',\n            'Distribution: {distro}',\n            'Urgency: {urgency}',\n            'Maintainer: {packager}',\n            'Description: ',\n            ' {package_name} - {short_description}',\n            'Changes: ',\n            ' {package_name} ({fullversion}) {distro}; urgency={urgency}',\n            ' .',\n            ' * Built by Butcher - metahash for this build is {metahash}',\n            'Checksums-Sha1: ',\n            ' {deb_sha1} {deb_bytes} {deb_filename}',\n            'Checksums-Sha256: ',\n            ' {deb_sha256} {deb_bytes} {deb_filename}',\n            'Files: ',\n            ' {deb_md5} {deb_bytes} {section} {priority} {deb_filename}',\n            ''  # Newline at end of file.\n            ]).format(**chparams)\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_args(self):\n        base.BaseTarget.validate_args(self)\n        params = self.params\n        if params['extra_control_fields'] is not None:\n            assert isinstance(params['extra_control_fields'], list), (\n                'extra_control_fields must be a list of tuples, not %s' % type(\n                    params['extra_control_fields']))\n            for elem in params['extra_control_fields']:\n                assert (isinstance(elem, tuple) and len(elem) == 1), (\n                    'extra_control_fields must be a list of 2-element tuples. '\n                    'Invalid contents: %s' % elem)\n        pkgname_re = '^[a-z][a-z0-9+-.]+'\n        assert re.match(pkgname_re, params['package_name']), (\n            'Invalid package name: %s. Must match %s' % (\n                params['package_name'], pkgname_re))", "response": "Input validators for this rule type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_next_version() -> str:\n    LOGGER.info('computing next version')\n    should_be_alpha = bool(CTX.repo.get_current_branch() != 'master')\n    LOGGER.info('alpha: %s', should_be_alpha)\n    calver = _get_calver()\n    LOGGER.info('current calver: %s', calver)\n    calver_tags = _get_current_calver_tags(calver)\n    LOGGER.info('found %s matching tags for this calver', len(calver_tags))\n    next_stable_version = _next_stable_version(calver, calver_tags)\n    LOGGER.info('next stable version: %s', next_stable_version)\n    if should_be_alpha:\n        return _next_alpha_version(next_stable_version, calver_tags)\n\n    return next_stable_version", "response": "Returns the next stable version for this Git repository"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef value(self):\n      originalPrice = self.lineItem.totalPrice\n      if self.flatRate == 0:\n        return originalPrice * self.percent\n      return self.flatRate", "response": "Returns the positive value to subtract from the total."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef voxel_count(dset,p=None,positive_only=False,mask=None,ROI=None):\n    ''' returns the number of non-zero voxels\n\n    :p:             threshold the dataset at the given *p*-value, then count\n    :positive_only: only count positive values\n    :mask:          count within the given mask\n    :ROI:           only use the ROI with the given value (or list of values) within the mask\n                    if ROI is 'all' then return the voxel count of each ROI\n                    as a dictionary\n    '''\n    if p:\n        dset = nl.thresh(dset,p,positive_only)\n    else:\n        if positive_only:\n            dset = nl.calc(dset,'step(a)')\n\n    count = 0\n    devnull = open(os.devnull,\"w\")\n    if mask:\n        cmd = ['3dROIstats','-1Dformat','-nomeanout','-nobriklab', '-nzvoxels']\n        cmd += ['-mask',str(mask),str(dset)]\n        out = subprocess.check_output(cmd,stderr=devnull).split('\\n')\n        if len(out)<4:\n            return 0\n        rois = [int(x.replace('NZcount_','')) for x in out[1].strip()[1:].split()]\n        counts = [int(x.replace('NZcount_','')) for x in out[3].strip().split()]\n        count_dict = None\n        if ROI==None:\n            ROI = rois\n        if ROI=='all':\n            count_dict = {}\n            ROI = rois\n        else:\n            if not isinstance(ROI,list):\n                ROI = [ROI]\n        for r in ROI:\n            if r in rois:\n                roi_count = counts[rois.index(r)]\n                if count_dict!=None:\n                    count_dict[r] = roi_count\n                else:\n                    count += roi_count\n    else:\n        cmd = ['3dBrickStat', '-slow', '-count', '-non-zero', str(dset)]\n        count = int(subprocess.check_output(cmd,stderr=devnull).strip())\n    if count_dict:\n        return count_dict\n    return count", "response": "returns the number of non - zero voxels in the given dataset"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the average of voxels in dset within non - zero voxels of mask", "response": "def mask_average(dset,mask):\n    '''Returns average of voxels in ``dset`` within non-zero voxels of ``mask``'''\n    o = nl.run(['3dmaskave','-q','-mask',mask,dset])\n    if o:\n        return float(o.output.split()[-1])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sphere_average(dset,x,y,z,radius=1):\n    '''returns a list of average values (one for each subbrick/time point) within the coordinate ``(x,y,z)`` (in RAI order) using a sphere of radius ``radius`` in ``dset``'''\n    return_list = []\n    if isinstance(dset,basestring):\n        dset = [dset]\n    for d in dset:\n        return_list += [float(a) for a in subprocess.check_output(['3dmaskave','-q','-dball',str(x),str(y),str(z),str(radius),d],stderr=subprocess.PIPE).split()]\n    return return_list", "response": "returns a list of average values within the coordinate x y z"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if LDAP group is member of LDAP group otherwise return False", "response": "def is_member_of(self, group_name):\n        \"\"\"Return True if member of LDAP group, otherwise return False\"\"\"\n        group_dn = 'cn=%s,cn=groups,cn=accounts,%s' % (group_name, self._base_dn)\n        if str(group_dn).lower() in [str(i).lower() for i in self.member_of]:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_attr_list(self, attr):\n        a = self._attrs.get(attr)\n        if not a:\n            return []\n        if type(a) is list:\n            r = [i.decode('utf-8', 'ignore') for i in a]\n        else:\n            r = [a.decode('utf-8', 'ignore')]\n        return r", "response": "Return user s attribute or attributes list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_locale(language, to_lower=False):\n    p = language.find('-')\n    if p >= 0:\n        if to_lower:\n            return language[:p].lower() + '_' + language[p + 1:].lower()\n        else:\n            # Get correct locale for sr-latn\n            if len(language[p + 1:]) > 2:\n                locale = language[:p].lower() + '_' + language[p + 1].upper()\n                return locale + language[p + 2:].lower()\n            return language[:p].lower() + '_' + language[p + 1:].upper()\n    else:\n        return language.lower()", "response": "Converts a language name into a locale name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_language(locale):\n    p = locale.find('_')\n    if p >= 0:\n        return locale[:p].lower() + '-' + locale[p + 1:].lower()\n    else:\n        return locale.lower()", "response": "Converts a locale name into a language name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _commonPrefetchDeclarativeIds(engine, mutex,\n                                  Declarative, count) -> Optional[Iterable[int]]:\n    \"\"\" Common Prefetch Declarative IDs\n\n    This function is used by the worker and server\n    \"\"\"\n    if not count:\n        logger.debug(\"Count was zero, no range returned\")\n        return\n\n    conn = engine.connect()\n    transaction = conn.begin()\n    mutex.acquire()\n    try:\n        sequence = Sequence('%s_id_seq' % Declarative.__tablename__,\n                            schema=Declarative.metadata.schema)\n\n        if isPostGreSQLDialect(engine):\n            sql = \"SELECT setval('%(seq)s', (select nextval('%(seq)s') + %(add)s), true)\"\n            sql %= {\n                'seq': '\"%s\".\"%s\"' % (sequence.schema, sequence.name),\n                'add': count\n            }\n            nextStartId = conn.execute(sql).fetchone()[0]\n            startId = nextStartId - count\n\n        elif isMssqlDialect(engine):\n            startId = conn.execute(\n                'SELECT NEXT VALUE FOR \"%s\".\"%s\"'\n                % (sequence.schema, sequence.name)\n            ).fetchone()[0] + 1\n\n            nextStartId = startId + count\n\n            conn.execute('alter sequence \"%s\".\"%s\" restart with %s'\n                         % (sequence.schema, sequence.name, nextStartId))\n\n        else:\n            raise NotImplementedError()\n\n        transaction.commit()\n\n        return iter(range(startId, nextStartId))\n\n    finally:\n        mutex.release()\n        conn.close()", "response": "Common Prefetch Declarative IDs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ormSessionCreator(self) -> DbSessionCreator:\n        assert self._dbConnectString\n\n        if self._ScopedSession:\n            return self._ScopedSession\n\n        self._dbEngine = create_engine(\n            self._dbConnectString,\n            **self._dbEngineArgs\n        )\n\n        self._ScopedSession = scoped_session(\n            sessionmaker(bind=self._dbEngine))\n\n        return self._ScopedSession", "response": "Get Orm Session\n\n        :return: A SQLAlchemy session scoped for the callers thread.."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms a database migration.", "response": "def migrate(self) -> None:\n        \"\"\" Migrate\n\n        Perform a database migration, upgrading to the latest schema level.\n        \"\"\"\n\n        assert self.ormSessionCreator, \"ormSessionCreator is not defined\"\n\n        connection = self._dbEngine.connect()\n        isDbInitialised = self._dbEngine.dialect.has_table(\n            connection, 'alembic_version',\n            schema=self._metadata.schema)\n        connection.close()\n\n        if isDbInitialised or not self._enableCreateAll:\n            self._doMigration(self._dbEngine)\n\n        else:\n            self._doCreateAll(self._dbEngine)\n\n        if self._enableForeignKeys:\n            self.checkForeignKeys(self._dbEngine)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef checkForeignKeys(self, engine: Engine) -> None:\n        missing = (sqlalchemy_utils.functions\n                   .non_indexed_foreign_keys(self._metadata, engine=engine))\n\n        for table, keys in missing.items():\n            for key in keys:\n                logger.warning(\"Missing index on ForeignKey %s\" % key.columns)", "response": "Check Foreign Keys\n\n        Log any foreign keys that don't have indexes assigned to them.\n        This is a performance issue."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prefetchDeclarativeIds(self, Declarative, count) -> DelcarativeIdGen:\n        return _commonPrefetchDeclarativeIds(\n            self.dbEngine, self._sequenceMutex, Declarative, count\n        )", "response": "Prefetches a number of declarative IDs from a database sequence."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting the changelog to the file.", "response": "def _chglog(amend: bool = False, stage: bool = False, next_version: str = None, auto_next_version: bool = False):\n    \"\"\"\n    Writes the changelog\n\n    Args:\n        amend: amend last commit with changes\n        stage: stage changes\n    \"\"\"\n    if config.CHANGELOG_DISABLE():\n        LOGGER.info('skipping changelog update as per config')\n    else:\n        epab.utils.ensure_exe('git')\n        epab.utils.ensure_exe('gitchangelog')\n        LOGGER.info('writing changelog')\n        if auto_next_version:\n            next_version = epab.utils.get_next_version()\n        with gitchangelog_config():\n            with temporary_tag(next_version):\n                changelog, _ = elib_run.run('gitchangelog', mute=True)\n        # changelog = changelog.encode('utf8').replace(b'\\r\\n', b'\\n').decode('utf8')\n        changelog = re.sub(BOGUS_LINE_PATTERN, '\\\\1\\n', changelog)\n        Path(config.CHANGELOG_FILE_PATH()).write_text(changelog, encoding='utf8')\n        if amend:\n            CTX.repo.amend_commit(\n                append_to_msg='update changelog [auto]', files_to_add=str(config.CHANGELOG_FILE_PATH())\n            )\n        elif stage:\n            CTX.repo.stage_subset(str(config.CHANGELOG_FILE_PATH()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the changelog file for the current version of the current version of the current version of the current version of the current version", "response": "def chglog(amend: bool = False, stage: bool = False, next_version: str = None, auto_next_version: bool = False):\n    \"\"\"\n    Writes the changelog\n\n    Args:\n        amend: amend last commit with changes\n        stage: stage changes\n        next_version: indicates next version\n        auto_next_version: infer next version from VCS\n    \"\"\"\n    changed_files = CTX.repo.changed_files()\n    changelog_file_path: Path = config.CHANGELOG_FILE_PATH()\n    changelog_file_name = changelog_file_path.name\n    if changelog_file_name in changed_files:\n        LOGGER.error('changelog has changed; cannot update it')\n        exit(-1)\n    _chglog(amend, stage, next_version, auto_next_version)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_rev_options(self, rev, dest, rev_options):\n        revisions = self.get_tag_revs(dest)\n        revisions.update(self.get_branch_revs(dest))\n\n        origin_rev = 'origin/%s' % rev\n        if origin_rev in revisions:\n            # remote branch\n            return [revisions[origin_rev]]\n        elif rev in revisions:\n            # a local tag or branch name\n            return [revisions[rev]]\n        else:\n            logger.warn(\"Could not find a tag or branch '%s', assuming commit.\" % rev)\n            return rev_options", "response": "Check the revision options before checkout to compensate that tags\n            and branches may need origin as a prefix."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves data from a dictionary in JSON format.", "response": "def savejson(filename, datadict):\n    \"\"\"Save data from a dictionary in JSON format. Note that this only\n    works to the second level of the dictionary with Numpy arrays.\n    \"\"\"\n    for key, value in datadict.items():\n        if type(value) == np.ndarray:\n            datadict[key] = value.tolist()\n        if type(value) == dict:\n            for key2, value2 in value.items():\n                if type(value2) == np.ndarray:\n                    datadict[key][key2] = value2.tolist()\n    with open(filename, \"w\") as f:\n        f.write(json.dumps(datadict, indent=4))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef loadjson(filename, asnparrays=False):\n    with open(filename) as f:\n        data = json.load(f)\n    if asnparrays:\n        for key, value in data.items():\n            if type(value) is list:\n                data[key] = np.asarray(value)\n            if type(value) is dict:\n                for key2, value2 in value.items():\n                    if type(value2) is list:\n                        data[key][key2] = np.asarray(value2)\n    return data", "response": "Load data from text file in JSON format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef savecsv(filename, datadict, mode=\"w\"):\n    if mode == \"a\" :\n        header = False\n    else:\n        header = True\n    with open(filename, mode) as f:\n        _pd.DataFrame(datadict).to_csv(f, index=False, header=header)", "response": "Save a dictionary of data to CSV."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload data from CSV file. Returns a single dict with column names as keys.", "response": "def loadcsv(filename):\n    \"\"\"Load data from CSV file.\n\n    Returns a single dict with column names as keys.\n    \"\"\"\n    dataframe = _pd.read_csv(filename)\n    data = {}\n    for key, value in dataframe.items():\n        data[key] = value.values\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef savehdf(filename, datadict, groupname=\"data\", mode=\"a\", metadata=None,\n            as_dataframe=False, append=False):\n    \"\"\"Save a dictionary of arrays to file--similar to how `scipy.io.savemat`\n    works. If `datadict` is a DataFrame, it will be converted automatically.\n    \"\"\"\n    if as_dataframe:\n        df = _pd.DataFrame(datadict)\n        df.to_hdf(filename, groupname)\n    else:\n        if isinstance(datadict, _pd.DataFrame):\n            datadict = datadict.to_dict(\"list\")\n        with _h5py.File(filename, mode) as f:\n            for key, value in datadict.items():\n                if append:\n                    try:\n                        f[groupname + \"/\" + key] = np.append(f[groupname + \"/\" + key], value)\n                    except KeyError:\n                        f[groupname + \"/\" + key] = value\n                else:\n                    f[groupname + \"/\" + key] = value\n            if metadata:\n                for key, value in metadata.items():\n                    f[groupname].attrs[key] = value", "response": "Save a dictionary of arrays to HDF5 file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads all data from top level of HDF5 file", "response": "def loadhdf(filename, groupname=\"data\", to_dataframe=False):\n    \"\"\"Load all data from top level of HDF5 file--similar to how\n    `scipy.io.loadmat` works.\n    \"\"\"\n    data = {}\n    with _h5py.File(filename, \"r\") as f:\n        for key, value in f[groupname].items():\n            data[key] = np.array(value)\n    if to_dataframe:\n        return _pd.DataFrame(data)\n    else:\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_hdf_metadata(filename, metadata, groupname=\"data\", mode=\"a\"):\n    with _h5py.File(filename, mode) as f:\n        for key, val in metadata.items():\n            f[groupname].attrs[key] = val", "response": "Save a dictionary of metadata to a group s attrs."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads attrs of the desired group into a dictionary.", "response": "def load_hdf_metadata(filename, groupname=\"data\"):\n    \"\"\"\"Load attrs of the desired group into a dictionary.\"\"\"\n    with _h5py.File(filename, \"r\") as f:\n        data = dict(f[groupname].attrs)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nauthenticating with the API", "response": "def authenticate(user=None):  # noqa: E501\n    \"\"\"Authenticate\n\n    Authenticate with the API # noqa: E501\n\n    :param user: The user authentication object.\n    :type user: dict | bytes\n\n    :rtype: AuthResponse\n    \"\"\"\n    if connexion.request.is_json:\n        user = UserAuth.from_dict(connexion.request.get_json())  # noqa: E501\n    return 'do some magic!'"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the documentation and datatype of a parameter for a specific acluster entry", "response": "def get_param_doc(doc, param):\n        \"\"\"Get the documentation and datatype for a parameter\n\n        This function returns the documentation and the argument for a\n        napoleon like structured docstring `doc`\n\n        Parameters\n        ----------\n        doc: str\n            The base docstring to use\n        param: str\n            The argument to use\n\n        Returns\n        -------\n        str\n            The documentation of the given `param`\n        str\n            The datatype of the given `param`\"\"\"\n        arg_doc = docstrings.keep_params_s(doc, [param]) or \\\n            docstrings.keep_types_s(doc, [param])\n        dtype = None\n        if arg_doc:\n            lines = arg_doc.splitlines()\n            arg_doc = dedents('\\n' + '\\n'.join(lines[1:]))\n            param_desc = lines[0].split(':', 1)\n            if len(param_desc) > 1:\n                dtype = param_desc[1].strip()\n        return arg_doc, dtype"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the parameters from the given `func` to the parameter settings Parameters ---------- func: function The function to use. If None, a function will be returned that can be used as a decorator setup_as: str The attribute that shall be assigned to the function in the resulting namespace. If specified, this function will be used when calling the :meth:`parse2func` method insert_at: int The position where the given `func` should be inserted. If None, it will be appended at the end and used when calling the :meth:`parse2func` method interprete: bool If True (default), the docstrings are interpreted and switches and lists are automatically inserted (see the [interpretation-docs]_ epilog_sections: list of str The headers of the sections to extract. If None, the :attr:`epilog_sections` attribute is used overwrite: bool If True, overwrite the existing epilog and the existing description of the parser append_epilog: bool If True, append to the existing epilog Returns ------- function Either the function that can be used as a decorator (if `func` is ``None``), or the given `func` itself. Examples -------- Use this method as a decorator:: >>> @parser.setup_args ... def do_something(a=1): ''' Just an example Parameters ---------- a: int A number to increment by one ''' return a + 1 >>> args = parser.parse_args('-a 2'.split()) Or by specifying the setup_as function:: >>> @parser.setup_args(setup_as='func') ... def do_something(a=1): ''' Just an example Parameters ---------- a: int A number to increment by one ''' return a + 1 >>> args = parser.parse_args('-a 2'.split()) >>> args.func is do_something >>> parser.parse2func('-a 2'.split()) 3 References ---------- .. [interpretation-docs] http://funcargparse.readthedocs.io/en/latest/docstring_interpretation.html)", "response": "def setup_args(self, func=None, setup_as=None, insert_at=None,\n                   interprete=True, epilog_sections=None,\n                   overwrite=False, append_epilog=True):\n        \"\"\"\n        Add the parameters from the given `func` to the parameter settings\n\n        Parameters\n        ----------\n        func: function\n            The function to use. If None, a function will be returned that can\n            be used as a decorator\n        setup_as: str\n            The attribute that shall be assigned to the function in the\n            resulting namespace. If specified, this function will be used when\n            calling the :meth:`parse2func` method\n        insert_at: int\n            The position where the given `func` should be inserted. If None,\n            it will be appended at the end and used when calling the\n            :meth:`parse2func` method\n        interprete: bool\n            If True (default), the docstrings are interpreted and switches and\n            lists are automatically inserted (see the\n            [interpretation-docs]_\n        epilog_sections: list of str\n            The headers of the sections to extract. If None, the\n            :attr:`epilog_sections` attribute is used\n        overwrite: bool\n            If True, overwrite the existing epilog and the existing description\n            of the parser\n        append_epilog: bool\n            If True, append to the existing epilog\n\n        Returns\n        -------\n        function\n            Either the function that can be used as a decorator (if `func` is\n            ``None``), or the given `func` itself.\n\n        Examples\n        --------\n        Use this method as a decorator::\n\n            >>> @parser.setup_args\n            ... def do_something(a=1):\n                '''\n                Just an example\n\n                Parameters\n                ----------\n                a: int\n                    A number to increment by one\n                '''\n                return a + 1\n            >>> args = parser.parse_args('-a 2'.split())\n\n        Or by specifying the setup_as function::\n\n            >>> @parser.setup_args(setup_as='func')\n            ... def do_something(a=1):\n                '''\n                Just an example\n\n                Parameters\n                ----------\n                a: int\n                    A number to increment by one\n                '''\n                return a + 1\n            >>> args = parser.parse_args('-a 2'.split())\n            >>> args.func is do_something\n            >>> parser.parse2func('-a 2'.split())\n            3\n\n        References\n        ----------\n        .. [interpretation-docs]\n           http://funcargparse.readthedocs.io/en/latest/docstring_interpretation.html)\n        \"\"\"\n        def setup(func):\n            # insert the function\n            if insert_at is None:\n                self._used_functions.append(func)\n            else:\n                self._used_functions.insert(insert_at, func)\n\n            args_dict = self.unfinished_arguments\n\n            # save the function to use in parse2funcs\n            if setup_as:\n                args_dict[setup_as] = dict(\n                    long=setup_as, default=func, help=argparse.SUPPRESS)\n                self._setup_as = setup_as\n\n            # create arguments\n            args, varargs, varkw, defaults = inspect.getargspec(func)\n            full_doc = docstrings.dedents(inspect.getdoc(func))\n\n            summary = docstrings.get_full_description(full_doc)\n            if summary:\n                if not self.description or overwrite:\n                    self.description = summary\n                full_doc = docstrings._remove_summary(full_doc)\n\n            self.extract_as_epilog(full_doc, epilog_sections, overwrite,\n                                   append_epilog)\n\n            doc = docstrings._get_section(full_doc, 'Parameters') + '\\n'\n            doc += docstrings._get_section(full_doc, 'Other Parameters')\n            doc = doc.rstrip()\n            default_min = len(args or []) - len(defaults or [])\n            for i, arg in enumerate(args):\n                if arg == 'self' or arg in args_dict:\n                    continue\n                arg_doc, dtype = self.get_param_doc(doc, arg)\n                args_dict[arg] = d = {'dest': arg, 'short': arg.replace('_',\n                                                                        '-'),\n                                      'long': arg.replace('_', '-')}\n                if arg_doc:\n                    d['help'] = arg_doc\n                    if i >= default_min:\n                        d['default'] = defaults[i - default_min]\n                    else:\n                        d['positional'] = True\n                    if interprete and dtype == 'bool' and 'default' in d:\n                        d['action'] = 'store_false' if d['default'] else \\\n                            'store_true'\n                    elif interprete and dtype:\n                        if dtype.startswith('list of'):\n                            d['nargs'] = '+'\n                            dtype = dtype[7:].strip()\n                        if dtype in ['str', 'string', 'strings']:\n                            d['type'] = six.text_type\n                            if dtype == 'strings':\n                                dtype = 'string'\n                        else:\n                            try:\n                                d['type'] = getattr(builtins, dtype)\n                            except AttributeError:\n                                try:    # maybe the dtype has a final 's'\n                                    d['type'] = getattr(builtins, dtype[:-1])\n                                    dtype = dtype[:-1]\n                                except AttributeError:\n                                    pass\n                        d['metavar'] = dtype\n            return func\n        if func is None:\n            return setup\n        else:\n            return setup(func)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_subparsers(self, *args, **kwargs):\n        chain = kwargs.pop('chain', None)\n        ret = super(FuncArgParser, self).add_subparsers(*args, **kwargs)\n        if chain:\n            self._chain_subparsers = True\n        self._subparsers_action = ret\n        return ret", "response": "Add subparsers to this parser."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setup_subparser(\n            self, func=None, setup_as=None, insert_at=None, interprete=True,\n            epilog_sections=None, overwrite=False, append_epilog=True,\n            return_parser=False, name=None, **kwargs):\n        \"\"\"\n        Create a subparser with the name of the given function\n\n        Parameters are the same as for the :meth:`setup_args` function, other\n        parameters are parsed to the :meth:`add_subparsers` method if (and only\n        if) this method has not already been called.\n\n        Parameters\n        ----------\n        %(FuncArgParser.setup_args.parameters)s\n        return_parser: bool\n            If True, the create parser is returned instead of the function\n        name: str\n            The name of the created parser. If None, the function name is used\n            and underscores (``'_'``) are replaced by minus (``'-'``)\n        ``**kwargs``\n            Any other parameter that is passed to the add_parser method that\n            creates the parser\n\n        Other Parameters\n        ----------------\n\n        Returns\n        -------\n        FuncArgParser or %(FuncArgParser.setup_args.returns)s\n            If return_parser is True, the created subparser is returned\n\n        Examples\n        --------\n        Use this method as a decorator::\n\n            >>> from funcargparser import FuncArgParser\n\n            >>> parser = FuncArgParser()\n\n            >>> @parser.setup_subparser\n            ... def my_func(my_argument=None):\n            ...     pass\n\n            >>> args = parser.parse_args('my-func -my-argument 1'.split())\n        \"\"\"\n        def setup(func):\n            if self._subparsers_action is None:\n                raise RuntimeError(\n                    \"No subparsers have yet been created! Run the \"\n                    \"add_subparsers method first!\")\n            # replace underscore by '-'\n            name2use = name\n            if name2use is None:\n                name2use = func.__name__.replace('_', '-')\n            kwargs.setdefault('help', docstrings.get_summary(\n                docstrings.dedents(inspect.getdoc(func))))\n            parser = self._subparsers_action.add_parser(name2use, **kwargs)\n            parser.setup_args(\n                func, setup_as=setup_as, insert_at=insert_at,\n                interprete=interprete, epilog_sections=epilog_sections,\n                overwrite=overwrite, append_epilog=append_epilog)\n            return func, parser\n        if func is None:\n            return lambda f: setup(f)[0]\n        else:\n            return setup(func)[int(return_parser)]", "response": "Create a subparser for the given function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_arg(self, arg, if_existent=None, **kwargs):\n        if if_existent or (if_existent is None and\n                           arg in self.unfinished_arguments):\n            self.unfinished_arguments[arg].update(kwargs)\n        elif not if_existent and if_existent is not None:\n            self.unfinished_arguments.setdefault(arg, kwargs)", "response": "Updates the add_argument data for the given argument."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_corresponding_parsers(self, func):\n        if func in self._used_functions:\n            yield self\n        if self._subparsers_action is not None:\n            for parser in self._subparsers_action.choices.values():\n                for sp in parser._get_corresponding_parsers(func):\n                    yield sp", "response": "Get the parsers that have been set up by the given function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pop_key(self, arg, key, *args, **kwargs):\n        return self.unfinished_arguments[arg].pop(key, *args, **kwargs)", "response": "Delete a previously defined key for the add_argument"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_arguments(self, subparsers=False):\n        ret = []\n        if not self._finalized:\n            for arg, d in self.unfinished_arguments.items():\n                try:\n                    not_positional = int(not d.pop('positional', False))\n                    short = d.pop('short', None)\n                    long_name = d.pop('long', None)\n                    if short is None and long_name is None:\n                        raise ValueError(\n                            \"Either a short (-) or a long (--) argument must \"\n                            \"be provided!\")\n                    if not not_positional:\n                        short = arg\n                        long_name = None\n                        d.pop('dest', None)\n                    if short == long_name:\n                        long_name = None\n                    args = []\n                    if short:\n                        args.append('-' * not_positional + short)\n                    if long_name:\n                        args.append('--' * not_positional + long_name)\n                    group = d.pop('group', self)\n                    if d.get('action') in ['store_true', 'store_false']:\n                        d.pop('metavar', None)\n                    ret.append(group.add_argument(*args, **d))\n                except Exception:\n                    print('Error while creating argument %s' % arg)\n                    raise\n        else:\n            raise ValueError('Parser has already been finalized!')\n        self._finalized = True\n        if subparsers and self._subparsers_action is not None:\n            for parser in self._subparsers_action.choices.values():\n                parser.create_arguments(True)\n        return ret", "response": "Create and add the arguments of the current parser."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nformats a section for the epilog by inserting a format", "response": "def format_epilog_section(self, section, text):\n        \"\"\"Format a section for the epilog by inserting a format\"\"\"\n        try:\n            func = self._epilog_formatters[self.epilog_formatter]\n        except KeyError:\n            if not callable(self.epilog_formatter):\n                raise\n            func = self.epilog_formatter\n        return func(section, text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract_as_epilog(self, text, sections=None, overwrite=False,\n                          append=True):\n        \"\"\"Extract epilog sections from the a docstring\n\n        Parameters\n        ----------\n        text\n            The docstring to use\n        sections: list of str\n            The headers of the sections to extract. If None, the\n            :attr:`epilog_sections` attribute is used\n        overwrite: bool\n            If True, overwrite the existing epilog\n        append: bool\n            If True, append to the existing epilog\"\"\"\n        if sections is None:\n            sections = self.epilog_sections\n        if ((not self.epilog or overwrite or append) and sections):\n            epilog_parts = []\n            for sec in sections:\n                text = docstrings._get_section(text, sec).strip()\n                if text:\n                    epilog_parts.append(\n                        self.format_epilog_section(sec, text))\n            if epilog_parts:\n                epilog = '\\n\\n'.join(epilog_parts)\n                if overwrite or not self.epilog:\n                    self.epilog = epilog\n                else:\n                    self.epilog += '\\n\\n' + epilog", "response": "Extract epilog sections from a docstring."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef grouparg(self, arg, my_arg=None, parent_cmds=[]):\n        if self._subparsers_action is None:\n            return None\n        commands = self._subparsers_action.choices\n        currentarg = self.__currentarg\n        # the default return value is the current argument we are in or the\n        # name of the subparser itself\n        ret = currentarg or my_arg\n        if currentarg is not None:\n            # if we are already in a sub command, we use the sub parser\n            sp_key = commands[currentarg].grouparg(arg, currentarg, chain(\n                commands, parent_cmds))\n            if sp_key is None and arg in commands:\n                # if the subparser did not recognize the command, we use the\n                # command the corresponds to this parser or (of this parser\n                # is the parent parser) the current subparser\n                self.__currentarg = currentarg = arg\n                ret = my_arg or currentarg\n            elif sp_key not in commands and arg in parent_cmds:\n                # otherwise, if the subparser recognizes the commmand but it is\n                # not in the known command of this parser, it must be another\n                # command of the subparser and this parser can ignore it\n                ret = None\n            else:\n                # otherwise the command belongs to this subparser (if this one\n                # is not the subparser) or the current subparser\n                ret = my_arg or currentarg\n        elif arg in commands:\n            # if the argument is a valid subparser, we return this one\n            self.__currentarg = arg\n            ret = arg\n        elif arg in parent_cmds:\n            # if the argument is not a valid subparser but in one of our\n            # parents, we return None to signalize that we cannot categorize\n            # it\n            ret = None\n        return ret", "response": "Group the current command line argument with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the main arguments only.", "response": "def __parse_main(self, args):\n        \"\"\"Parse the main arguments only. This is a work around for python 2.7\n        because argparse does not allow to parse arguments without subparsers\n        \"\"\"\n        if six.PY2:\n            self._subparsers_action.add_parser(\"__dummy\")\n            return super(FuncArgParser, self).parse_known_args(\n                list(args) + ['__dummy'])\n        return super(FuncArgParser, self).parse_known_args(args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_short(self, **kwargs):\n        for key, val in six.iteritems(kwargs):\n            self.update_arg(key, short=val)", "response": "Update the short argument names for the specified function\n            arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the long optional arguments for the specified function .", "response": "def update_long(self, **kwargs):\n        \"\"\"\n        Update the long optional arguments (those with two leading '-')\n\n        This method updates the short argument name for the specified function\n        arguments as stored in :attr:`unfinished_arguments`\n\n        Parameters\n        ----------\n        ``**kwargs``\n            Keywords must be keys in the :attr:`unfinished_arguments`\n            dictionary (i.e. keywords of the root functions), values the long\n            argument names\n\n        Examples\n        --------\n        Setting::\n\n            >>> parser.update_long(something='s', something_else='se')\n\n        is basically the same as::\n\n            >>> parser.update_arg('something', long='s')\n            >>> parser.update_arg('something_else', long='se')\n\n        which in turn is basically comparable to::\n\n            >>> parser.add_argument('--s', dest='something', ...)\n            >>> parser.add_argument('--se', dest='something_else', ...)\n\n        See Also\n        --------\n        update_short, update_longf\"\"\"\n        for key, val in six.iteritems(kwargs):\n            self.update_arg(key, long=val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the command line arguments to the setup function This method will parse the given list of command line arguments and call the function with the arguments and return the object.", "response": "def parse2func(self, args=None, func=None):\n        \"\"\"Parse the command line arguments to the setup function\n\n        This method parses the given command line arguments to the function\n        used in the :meth:`setup_args` method to setup up this parser\n\n        Parameters\n        ----------\n        args: list\n            The list of command line arguments\n        func: function\n            An alternative function to use. If None, the last function or the\n            one specified through the `setup_as` parameter in the\n            :meth:`setup_args` is used.\n\n        Returns\n        -------\n        object\n            What ever is returned by the called function\n\n        Note\n        ----\n        This method does not cover subparsers!\"\"\"\n        kws = vars(self.parse_args(args))\n        if func is None:\n            if self._setup_as:\n                func = kws.pop(self._setup_as)\n            else:\n                func = self._used_functions[-1]\n        return func(**kws)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_chained(self, args=None):\n        kws = vars(self.parse_args(args))\n        return self._parse2subparser_funcs(kws)", "response": "Parse the argument directly to the function that is used for setup\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_known_chained(self, args=None):\n        ns, remainder = self.parse_known_args(args)\n        kws = vars(ns)\n        return self._parse2subparser_funcs(kws), remainder", "response": "Parse the arguments passed to the function that can be used for setup\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a subparser corresponding to the given name.", "response": "def get_subparser(self, name):\n        \"\"\"\n        Convenience method to get a certain subparser\n\n        Parameters\n        ----------\n        name: str\n            The name of the subparser\n\n        Returns\n        -------\n        FuncArgParser\n            The subparsers corresponding to `name`\n        \"\"\"\n        if self._subparsers_action is None:\n            raise ValueError(\"%s has no subparsers defined!\" % self)\n        return self._subparsers_action.choices[name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_file(src):\n    #clear the stack between parses\n    if config.dest_dir == None:\n        dest = src.dir\n    else:\n        dest = config.dest_dir\n    output = get_output(src)\n    output_file = dest + '/' + src.basename + '.min.js'\n    f = open(output_file,'w')\n    f.write(jsmin.jsmin(output))\n    f.close()\n    print \"Wrote combined and minified file to: %s\" % (output_file)", "response": "parse a single file in config and output to dest dir\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_output(src):\n    output = ''\n    lines = open(src.path, 'rU').readlines()\n    for line in lines:\n        m = re.match(config.import_regex,line)\n        if m:\n            include_path = os.path.abspath(src.dir + '/' + m.group('script'));\n            if include_path not in config.sources:\n                script = Script(include_path)\n                script.parents.append(src)\n                config.sources[script.path] = script\n            include_file = config.sources[include_path]\n            #require statements dont include if the file has already been included\n            if include_file not in config.stack or m.group('command') == 'import':\n                config.stack.append(include_file)\n                output += get_output(include_file)\n        else:\n            output += line\n    return output", "response": "parse lines looking for commands\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_signed_raw_revocation_document(identity: Identity, salt: str, password: str) -> str:\n    revocation = Revocation(PROTOCOL_VERSION, identity.currency, identity, \"\")\n\n    key = SigningKey.from_credentials(salt, password)\n    revocation.sign([key])\n    return revocation.signed_raw()", "response": "Generate account revocation document for given identity"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def main():\n    # Create Client from endpoint string in Duniter format\n    client = Client(BMAS_ENDPOINT)\n\n    # Get the node summary infos to test the connection\n    response = await client(bma.node.summary)\n    print(response)\n\n    # prompt hidden user entry\n    salt = getpass.getpass(\"Enter your passphrase (salt): \")\n\n    # prompt hidden user entry\n    password = getpass.getpass(\"Enter your password: \")\n\n    # prompt public key\n    pubkey = input(\"Enter your public key: \")\n\n    # init signer instance\n    signer = SigningKey.from_credentials(salt, password)\n\n    # check public key\n    if signer.pubkey != pubkey:\n        print(\"Bad credentials!\")\n        exit(0)\n\n    # capture current block to get currency name\n    current_block = await client(bma.blockchain.current)\n\n    # create our Identity document to sign the revoke document\n    identity_document = await get_identity_document(client, current_block['currency'], pubkey)\n\n    # get the revoke document\n    revocation_signed_raw_document = get_signed_raw_revocation_document(identity_document, salt, password)\n\n    # save revoke document in a file\n    fp = open(REVOCATION_DOCUMENT_FILE_PATH, 'w')\n    fp.write(revocation_signed_raw_document)\n    fp.close()\n\n    # document saved\n    print(\"Revocation document saved in %s\" % REVOCATION_DOCUMENT_FILE_PATH)\n\n    # Close client aiohttp session\n    await client.close()", "response": "Main function for the node - get - revoking - document - save the revocation document to a file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef align_epi(anatomy,epis,suffix='_al',base=3,skull_strip=True):\n    '''[[currently in progress]]: a simple replacement for the ``align_epi_anat.py`` script, because I've found it to be unreliable, in my usage'''\n    for epi in epis:\n        nl.tshift(epi,suffix='_tshift')\n        nl.affine_align(nl.suffix(epi,'_tshift'),'%s[%d]'%(epis[0],base),skull_strip=False,epi=True,cost='crM',resample='wsinc5',grid_size=nl.dset_info(epi).voxel_size[0],suffix='_al')\n    ss = [anatomy] if skull_strip else False\n    nl.affine_align(anatomy,'%s[%d]'%(epis[0],base),skull_strip=ss,cost='lpa',grid_size=1,opts=['-interp','cubic'],suffix='_al-to-EPI')", "response": "aligns anatomy with an EPI"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates a motion regressor from the params file given by 3dAllineate ArcGIS", "response": "def motion_from_params(param_file,motion_file,individual=True,rms=True):\n    '''calculate a motion regressor from the params file given by 3dAllineate\n\n    Basically just calculates the rms change in the translation and rotation components. Returns the 6 motion vector (if ``individual`` is ``True``) and the RMS difference (if ``rms`` is ``True``).'''\n    with open(param_file) as inf:\n        translate_rotate = np.array([[float(y) for y in x.strip().split()[:6]] for x in inf.readlines() if x[0]!='#'])\n        motion = np.array([])\n        if individual:\n            motion = np.vstack((np.zeros(translate_rotate.shape[1]),np.diff(translate_rotate,axis=0)))\n        if rms:\n            translate = [sqrt(sum([x**2 for x in y[:3]])) for y in translate_rotate]\n            rotate = [sqrt(sum([x**2 for x in y[3:]])) for y in translate_rotate]\n            translate_rotate = np.array(map(add,translate,rotate))\n            translate_rotate_diff = np.hstack(([0],np.diff(translate_rotate,axis=0)))\n            if motion.shape==(0,):\n                motion = rms_motion\n            else:\n                motion = np.column_stack((motion,translate_rotate_diff))\n        with open(motion_file,'w') as outf:\n            outf.write('\\n'.join(['\\t'.join([str(y) for y in x]) for x in motion]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef volreg(dset,suffix='_volreg',base=3,tshift=3,dfile_suffix='_volreg.1D'):\n    '''simple interface to 3dvolreg\n\n        :suffix:        suffix to add to ``dset`` for volreg'ed file\n        :base:          either a number or ``dset[#]`` of the base image to register to\n        :tshift:        if a number, then tshift ignoring that many images, if ``None``\n                        then don't tshift\n        :dfile_suffix:  suffix to add to ``dset`` to save the motion parameters to\n    '''\n    cmd = ['3dvolreg','-prefix',nl.suffix(dset,suffix),'-base',base,'-dfile',nl.prefix(dset)+dfile_suffix]\n    if tshift:\n        cmd += ['-tshift',tshift]\n    cmd += [dset]\n    nl.run(cmd,products=nl.suffix(dset,suffix))", "response": "simple interface to 3dvolreg"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef affine_align(dset_from,dset_to,skull_strip=True,mask=None,suffix='_aff',prefix=None,cost=None,epi=False,resample='wsinc5',grid_size=None,opts=[]):\n    ''' interface to 3dAllineate to align anatomies and EPIs '''\n\n    dset_ss = lambda dset: os.path.split(nl.suffix(dset,'_ns'))[1]\n    def dset_source(dset):\n        if skull_strip==True or skull_strip==dset:\n            return dset_ss(dset)\n        else:\n            return dset\n\n    dset_affine = prefix\n    if dset_affine==None:\n        dset_affine = os.path.split(nl.suffix(dset_from,suffix))[1]\n    dset_affine_mat_1D = nl.prefix(dset_affine) + '_matrix.1D'\n    dset_affine_par_1D = nl.prefix(dset_affine) + '_params.1D'\n\n    if os.path.exists(dset_affine):\n        # final product already exists\n        return\n\n    for dset in [dset_from,dset_to]:\n        if skull_strip==True or skull_strip==dset:\n            nl.skull_strip(dset,'_ns')\n\n    mask_use = mask\n    if mask:\n        # the mask was probably made in the space of the original dset_to anatomy,\n        # which has now been cropped from the skull stripping. So the lesion mask\n        # needs to be resampled to match the corresponding mask\n        if skull_strip==True or skull_strip==dset_to:\n            nl.run(['3dresample','-master',dset_u(dset_ss(dset)),'-inset',mask,'-prefix',nl.suffix(mask,'_resam')],products=nl.suffix(mask,'_resam'))\n            mask_use = nl.suffix(mask,'_resam')\n\n    all_cmd = [\n        '3dAllineate',\n        '-prefix', dset_affine,\n        '-base', dset_source(dset_to),\n        '-source', dset_source(dset_from),\n        '-source_automask',\n        '-1Dmatrix_save', dset_affine_mat_1D,\n        '-1Dparam_save',dset_affine_par_1D,\n        '-autoweight',\n        '-final',resample,\n        '-cmass'\n    ] + opts\n    if grid_size:\n        all_cmd += ['-newgrid',grid_size]\n    if cost:\n        all_cmd += ['-cost',cost]\n    if epi:\n        all_cmd += ['-EPI']\n    if mask:\n        all_cmd += ['-emask', mask_use]\n\n    nl.run(all_cmd,products=dset_affine)", "response": "aligns two anatomies and EPIs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef affine_apply(dset_from,affine_1D,master,affine_suffix='_aff',interp='NN',inverse=False,prefix=None):\n    '''apply the 1D file from a previously aligned dataset\n    Applies the matrix in ``affine_1D`` to ``dset_from`` and makes the final grid look like the dataset ``master``\n    using the interpolation method ``interp``. If ``inverse`` is True, will apply the inverse of ``affine_1D`` instead'''\n    affine_1D_use = affine_1D\n    if inverse:\n        with tempfile.NamedTemporaryFile(delete=False) as temp:\n            temp.write(subprocess.check_output(['cat_matvec',affine_1D,'-I']))\n            affine_1D_use = temp.name\n    if prefix==None:\n        prefix = nl.suffix(dset_from,affine_suffix)\n    nl.run(['3dAllineate','-1Dmatrix_apply',affine_1D_use,'-input',dset_from,'-prefix',prefix,'-master',master,'-final',interp],products=prefix)", "response": "apply the 1D matrix from a previously aligned dataset\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_coord(coord_from,matrix_file,base_to_aligned=True):\n    '''Takes an XYZ array (in DICOM coordinates) and uses the matrix file produced by 3dAllineate to transform it. By default, the 3dAllineate\n    matrix transforms from base to aligned space; to get the inverse transform set ``base_to_aligned`` to ``False``'''\n    with open(matrix_file) as f:\n        try:\n            values = [float(y) for y in ' '.join([x for x in f.readlines() if x.strip()[0]!='#']).strip().split()]\n        except:\n            nl.notify('Error reading values from matrix file %s' % matrix_file, level=nl.level.error)\n            return False\n    if len(values)!=12:\n        nl.notify('Error: found %d values in matrix file %s (expecting 12)' % (len(values),matrix_file), level=nl.level.error)\n        return False\n    matrix = np.vstack((np.array(values).reshape((3,-1)),[0,0,0,1]))\n    if not base_to_aligned:\n        matrix = np.linalg.inv(matrix)\n    return np.dot(matrix,list(coord_from) + [1])[:3]", "response": "Takes an XYZ array and uses the matrix file produced by 3dAllineate to transform it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef qwarp_align(dset_from,dset_to,skull_strip=True,mask=None,affine_suffix='_aff',suffix='_qwarp',prefix=None):\n    '''aligns ``dset_from`` to ``dset_to`` using 3dQwarp\n\n    Will run ``3dSkullStrip`` (unless ``skull_strip`` is ``False``), ``3dUnifize``,\n    ``3dAllineate``, and then ``3dQwarp``. This method will add suffixes to the input\n    dataset for the intermediate files (e.g., ``_ss``, ``_u``). If those files already\n    exist, it will assume they were intelligently named, and use them as is\n\n    :skull_strip:       If True/False, turns skull-stripping of both datasets on/off.\n                        If a string matching ``dset_from`` or ``dset_to``, will only\n                        skull-strip the given dataset\n    :mask:              Applies the given mask to the alignment. Because of the nature\n                        of the alignment algorithms, the mask is **always** applied to\n                        the ``dset_to``. If this isn't what you want, you need to reverse\n                        the transform and re-apply it (e.g., using :meth:`qwarp_invert`\n                        and :meth:`qwarp_apply`). If the ``dset_to`` dataset is skull-stripped,\n                        the mask will also be resampled to match the ``dset_to`` grid.\n    :affine_suffix:     Suffix applied to ``dset_from`` to name the new dataset, as well as\n                        the ``.1D`` file.\n    :suffix:            Suffix applied to the final ``dset_from`` dataset. An additional file\n                        with the additional suffix ``_WARP`` will be created containing the parameters\n                        (e.g., with the default ``_qwarp`` suffix, the parameters will be in a file with\n                        the suffix ``_qwarp_WARP``)\n    :prefix:            Alternatively to ``suffix``, explicitly give the full output filename\n\n    The output affine dataset and 1D, as well as the output of qwarp are named by adding\n    the given suffixes (``affine_suffix`` and ``qwarp_suffix``) to the ``dset_from`` file\n\n    If ``skull_strip`` is a string instead of ``True``/``False``, it will only skull strip the given\n    dataset instead of both of them\n\n    # TODO: currently does not work with +tlrc datasets because the filenames get mangled\n    '''\n\n    dset_ss = lambda dset: os.path.split(nl.suffix(dset,'_ns'))[1]\n    dset_u = lambda dset: os.path.split(nl.suffix(dset,'_u'))[1]\n    def dset_source(dset):\n        if skull_strip==True or skull_strip==dset:\n            return dset_ss(dset)\n        else:\n            return dset\n\n    dset_affine = os.path.split(nl.suffix(dset_from,affine_suffix))[1]\n    dset_affine_1D = nl.prefix(dset_affine) + '.1D'\n    dset_qwarp = prefix\n    if dset_qwarp==None:\n        dset_qwarp = os.path.split(nl.suffix(dset_from,suffix))[1]\n\n    if os.path.exists(dset_qwarp):\n        # final product already exists\n        return\n\n    affine_align(dset_from,dset_to,skull_strip,mask,affine_suffix)\n\n    for dset in [dset_from,dset_to]:\n        nl.run([\n            '3dUnifize',\n            '-prefix', dset_u(dset_source(dset)),\n            '-input', dset_source(dset)\n        ],products=[dset_u(dset_source(dset))])\n\n    mask_use = mask\n    if mask:\n        # the mask was probably made in the space of the original dset_to anatomy,\n        # which has now been cropped from the skull stripping. So the lesion mask\n        # needs to be resampled to match the corresponding mask\n        if skull_strip==True or skull_strip==dset_to:\n            nl.run(['3dresample','-master',dset_u(dset_ss(dset)),'-inset',mask,'-prefix',nl.suffix(mask,'_resam')],products=nl.suffix(mask,'_resam'))\n            mask_use = nl.suffix(mask,'_resam')\n\n    warp_cmd = [\n        '3dQwarp',\n        '-prefix', dset_qwarp,\n        '-duplo', '-useweight', '-blur', '0', '3',\n        '-iwarp',\n        '-base', dset_u(dset_source(dset_to)),\n        '-source', dset_affine\n    ]\n\n    if mask:\n        warp_cmd += ['-emask', mask_use]\n\n    nl.run(warp_cmd,products=dset_qwarp)", "response": "Aligns dset_from to dset_to using 3dQwarp."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef qwarp_apply(dset_from,dset_warp,affine=None,warp_suffix='_warp',master='WARP',interp=None,prefix=None):\n    '''applies the transform from a previous qwarp\n\n    Uses the warp parameters from the dataset listed in\n    ``dset_warp`` (usually the dataset name ends in ``_WARP``)\n    to the dataset ``dset_from``. If a ``.1D`` file is given\n    in the ``affine`` parameter, it will be applied simultaneously\n    with the qwarp.\n\n    If the parameter ``interp`` is given, will use as interpolation method,\n    otherwise it will just use the default (currently wsinc5)\n\n    Output dataset with have the ``warp_suffix`` suffix added to its name\n    '''\n    out_dset = prefix\n    if out_dset==None:\n        out_dset = os.path.split(nl.suffix(dset_from,warp_suffix))[1]\n    dset_from_info = nl.dset_info(dset_from)\n    dset_warp_info = nl.dset_info(dset_warp)\n    if(dset_from_info.orient!=dset_warp_info.orient):\n        # If the datasets are different orientations, the transform won't be applied correctly\n        nl.run(['3dresample','-orient',dset_warp_info.orient,'-prefix',nl.suffix(dset_from,'_reorient'),'-inset',dset_from],products=nl.suffix(dset_from,'_reorient'))\n        dset_from = nl.suffix(dset_from,'_reorient')\n    warp_opt = str(dset_warp)\n    if affine:\n        warp_opt += ' ' + affine\n    cmd = [\n        '3dNwarpApply',\n        '-nwarp', warp_opt]\n    cmd += [\n        '-source', dset_from,\n        '-master',master,\n        '-prefix', out_dset\n    ]\n\n    if interp:\n        cmd += ['-interp',interp]\n\n    nl.run(cmd,products=out_dset)", "response": "applies the transform from a previous qwarp dataset to a new one"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef qwarp_invert(warp_param_dset,output_dset,affine_1Dfile=None):\n    '''inverts a qwarp (defined in ``warp_param_dset``) (and concatenates affine matrix ``affine_1Dfile`` if given)\n    outputs the inverted warp + affine to ``output_dset``'''\n\n    cmd = ['3dNwarpCat','-prefix',output_dset]\n\n    if affine_1Dfile:\n        cmd += ['-warp1','INV(%s)' % affine_1Dfile, '-warp2','INV(%s)' % warp_param_dset]\n    else:\n        cmd += ['-warp1','INV(%s)' % warp_param_dset]\n\n    nl.run(cmd,products=output_dset)", "response": "inverts a qwarp (defined in ``warp_param_dset``) (and concatenates affine matrix ``affine_1Dfile`` if given)\n    outputs the inverted warp + affine to ``output_dset``"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nalign an EPI time - series using 3dQwarp", "response": "def qwarp_epi(dset,align_subbrick=5,suffix='_qwal',prefix=None):\n    '''aligns an EPI time-series using 3dQwarp\n\n    Very expensive and not efficient at all, but it can produce pretty impressive alignment for EPI time-series with significant\n    distortions due to motion'''\n    info = nl.dset_info(dset)\n    if info==None:\n        nl.notify('Error reading dataset \"%s\"' % (dset),level=nl.level.error)\n        return False\n    if prefix==None:\n        prefix = nl.suffix(dset,suffix)\n    dset_sub = lambda x: '_tmp_qwarp_epi-%s_%d.nii.gz' % (nl.prefix(dset),x)\n    try:\n        align_dset = nl.suffix(dset_sub(align_subbrick),'_warp')\n        nl.calc('%s[%d]' % (dset,align_subbrick),expr='a',prefix=align_dset,datum='float')\n        for i in xrange(info.reps):\n            if i != align_subbrick:\n                nl.calc('%s[%d]' % (dset,i),expr='a',prefix=dset_sub(i),datum='float')\n                nl.run([\n                    '3dQwarp', '-nowarp',\n                    '-workhard', '-superhard', '-minpatch', '9', '-blur', '0',\n                    '-pear', '-nopenalty',\n                    '-base', align_dset,\n                    '-source', dset_sub(i),\n                    '-prefix', nl.suffix(dset_sub(i),'_warp')\n                ],quiet=True)\n        cmd = ['3dTcat','-prefix',prefix]\n        if info.TR:\n            cmd += ['-tr',info.TR]\n        if info.slice_timing:\n            cmd += ['-tpattern',info.slice_timing]\n        cmd += [nl.suffix(dset_sub(i),'_warp') for i in xrange(info.reps)]\n        nl.run(cmd,quiet=True)\n    except Exception as e:\n        raise e\n    finally:\n        for i in xrange(info.reps):\n            for suffix in ['','warp']:\n                try:\n                    os.remove(nl.suffix(dset_sub(i),suffix))\n                except:\n                    pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef align_epi_anat(anatomy,epi_dsets,skull_strip_anat=True):\n    ''' aligns epis to anatomy using ``align_epi_anat.py`` script\n\n    :epi_dsets:       can be either a string or list of strings of the epi child datasets\n    :skull_strip_anat:     if ``True``, ``anatomy`` will be skull-stripped using the default method\n\n    The default output suffix is \"_al\"\n    '''\n\n    if isinstance(epi_dsets,basestring):\n        epi_dsets = [epi_dsets]\n\n    if len(epi_dsets)==0:\n        nl.notify('Warning: no epi alignment datasets given for anatomy %s!' % anatomy,level=nl.level.warning)\n        return\n\n    if all(os.path.exists(nl.suffix(x,'_al')) for x in epi_dsets):\n        return\n\n    anatomy_use = anatomy\n\n    if skull_strip_anat:\n        nl.skull_strip(anatomy,'_ns')\n        anatomy_use = nl.suffix(anatomy,'_ns')\n\n    inputs = [anatomy_use] + epi_dsets\n    dset_products = lambda dset: [nl.suffix(dset,'_al'), nl.prefix(dset)+'_al_mat.aff12.1D', nl.prefix(dset)+'_tsh_vr_motion.1D']\n    products = nl.flatten([dset_products(dset) for dset in epi_dsets])\n    with nl.run_in_tmp(inputs,products):\n        if nl.is_nifti(anatomy_use):\n            anatomy_use = nl.afni_copy(anatomy_use)\n        epi_dsets_use = []\n        for dset in epi_dsets:\n            if nl.is_nifti(dset):\n                epi_dsets_use.append(nl.afni_copy(dset))\n            else:\n                epi_dsets_use.append(dset)\n        cmd = [\"align_epi_anat.py\", \"-epi2anat\", \"-anat_has_skull\", \"no\", \"-epi_strip\", \"3dAutomask\",\"-anat\", anatomy_use, \"-epi_base\", \"5\", \"-epi\", epi_dsets_use[0]]\n        if len(epi_dsets_use)>1:\n            cmd += ['-child_epi'] + epi_dsets_use[1:]\n            out = nl.run(cmd)\n\n        for dset in epi_dsets:\n            if nl.is_nifti(dset):\n                dset_nifti = nl.nifti_copy(nl.prefix(dset)+'_al+orig')\n                if dset_nifti and os.path.exists(dset_nifti) and dset_nifti.endswith('.nii') and dset.endswith('.gz'):\n                    nl.run(['gzip',dset_nifti])", "response": "aligns epis to anatomy using align_epi_anat. py script"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef skullstrip_template(dset,template,prefix=None,suffix=None,dilate=0):\n    '''Takes the raw anatomy ``dset``, aligns it to a template brain, and applies a templated skullstrip. Should produce fairly reliable skullstrips as long\n    as there is a decent amount of normal brain and the overall shape of the brain is normal-ish'''\n    if suffix==None:\n        suffix = '_sstemplate'\n    if prefix==None:\n        prefix = nl.suffix(dset,suffix)\n    if not os.path.exists(prefix):\n        with nl.notify('Running template-based skull-strip on %s' % dset):\n            dset = os.path.abspath(dset)\n            template = os.path.abspath(template)\n            tmp_dir = tempfile.mkdtemp()\n            cwd = os.getcwd()\n            with nl.run_in(tmp_dir):\n                nl.affine_align(template,dset,skull_strip=None,cost='mi',opts=['-nmatch','100%'])\n                nl.run(['3dQwarp','-minpatch','20','-penfac','10','-noweight','-source',nl.suffix(template,'_aff'),'-base',dset,'-prefix',nl.suffix(template,'_qwarp')],products=nl.suffix(template,'_qwarp'))\n                info = nl.dset_info(nl.suffix(template,'_qwarp'))\n                max_value = info.subbricks[0]['max']\n                nl.calc([dset,nl.suffix(template,'_qwarp')],'a*step(b-%f*0.05)'%max_value,prefix)\n                shutil.move(prefix,cwd)\n            shutil.rmtree(tmp_dir)", "response": "Takes the raw anatomy dset aligns it to a template brain and applies a templated skullstrip."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef printmp(msg):\n    filler = (80 - len(msg)) * ' '\n    print(msg + filler, end='\\r')\n    sys.stdout.flush()", "response": "Print temporarily until next print overrides it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting public contact info from users.", "response": "def contacts(github, logins):\n    \"\"\"Extract public contact info from users.\n    \"\"\"\n    printmp('Fetching contacts')\n    users = [github.user(login).as_dict() for login in logins]\n    mails = set()\n    blogs = set()\n    for user in users:\n        contact = user.get('name', 'login')\n        if user['email']:\n            contact += ' <%s>' % user['email']\n            mails.add(contact)\n        elif user['blog']:\n            contact += ' <%s>' % user['blog']\n            blogs.add(contact)\n        else:\n            continue\n    return mails, blogs"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts mails that sometimes leak from issue comments.", "response": "def extract_mail(issues):\n    \"\"\"Extract mails that sometimes leak from issue comments.\n    \"\"\"\n    contacts = set()\n    for idx, issue in enumerate(issues):\n        printmp('Fetching issue #%s' % idx)\n        for comment in issue.comments():\n            comm = comment.as_dict()\n            emails = list(email[0] for email in re.findall(MAIL_REGEX, comm['body'])\n                if not email[0].startswith('//') and not email[0].endswith('github.com') and\n                '@' in email[0])\n            contacts |= set(emails)\n    return contacts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch logins for users with given roles.", "response": "def fetch_logins(roles, repo):\n    \"\"\"Fetch logins for users with given roles.\n    \"\"\"\n    users = set()\n    if 'stargazer' in roles:\n        printmp('Fetching stargazers')\n        users |= set(repo.stargazers())\n    if 'collaborator' in roles:\n        printmp('Fetching collaborators')\n        users |= set(repo.collaborators())\n    if 'issue' in roles:\n        printmp('Fetching issues creators')\n        users |= set([i.user for i in repo.issues(state='all')])\n    return users"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts mails from stargazers, collaborators and people involved with issues of given repository.", "response": "def high_cli(repo_name, login, with_blog, as_list, role):\n    \"\"\"Extract mails from stargazers, collaborators and people involved with issues of given\n    repository.\n    \"\"\"\n    passw = getpass.getpass()\n    github = gh_login(login, passw)\n    repo = github.repository(login, repo_name)\n    role = [ROLES[k] for k in role]\n    users = fetch_logins(role, repo)\n    mails, blogs = contacts(github, users)\n\n    if 'issue' in role:\n        mails |= extract_mail(repo.issues(state='all'))\n\n    # Print results\n    sep = ', ' if as_list else '\\n'\n    print(sep.join(mails))\n    if with_blog:\n        print(sep.join(blogs))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __callback(self, data):\n        method = self.__cb_message\n        if method is not None:\n            try:\n                method(data)\n            except Exception as ex:\n                _logger.exception(\"Error calling method: %s\", ex)", "response": "Calls back a method in the object that was passed in to the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef freeze(ctx, version: str, clean: bool):\n    if clean:\n        _clean_spec()\n    ctx.invoke(epab.cmd.compile_qt_resources)\n    _freeze(version)", "response": "Freeze the current package into a single file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setupz(Np: int, zmin: float, gridmin: float, gridmax: float) -> np.ndarray:\n\n    dz = _ztanh(Np, gridmin, gridmax)\n\n    return np.insert(np.cumsum(dz)+zmin, 0, zmin)[:-1]", "response": "Setup the Z - axis of a sequence of points at a given minimum altitude and maximum altitude."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a Notification by name.", "response": "def get(self, name):\n        \"\"\"Returns a Notification by name.\n        \"\"\"\n        if not self.loaded:\n            raise RegistryNotLoaded(self)\n        if not self._registry.get(name):\n            raise NotificationNotRegistered(\n                f\"Notification not registered. Got '{name}'.\"\n            )\n        return self._registry.get(name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a Notification class unique by name.", "response": "def register(self, notification_cls=None):\n        \"\"\"Registers a Notification class unique by name.\n        \"\"\"\n        self.loaded = True\n        display_names = [n.display_name for n in self.registry.values()]\n        if (\n            notification_cls.name not in self.registry\n            and notification_cls.display_name not in display_names\n        ):\n            self.registry.update({notification_cls.name: notification_cls})\n\n            models = getattr(notification_cls, \"models\", [])\n            if not models and getattr(notification_cls, \"model\", None):\n                models = [getattr(notification_cls, \"model\")]\n            for model in models:\n                try:\n                    if notification_cls.name not in [\n                        n.name for n in self.models[model]\n                    ]:\n                        self.models[model].append(notification_cls)\n                except KeyError:\n                    self.models.update({model: [notification_cls]})\n        else:\n            raise AlreadyRegistered(\n                f\"Notification {notification_cls.name}: \"\n                f\"{notification_cls.display_name} is already registered.\"\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef notify(self, instance=None, **kwargs):\n        notified = {}\n        for notification_cls in self.registry.values():\n            notification = notification_cls()\n            if notification.notify(instance=instance, **kwargs):\n                notified.update({notification_cls.name: instance._meta.label_lower})\n        return notified", "response": "A wrapper to call notification. notify for each notification\n        class associated with the given model instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_notification_list(self, apps=None, schema_editor=None, verbose=False):\n        Notification = (apps or django_apps).get_model(\"edc_notification.notification\")\n\n        # flag all notifications as disabled and re-enable as required\n        Notification.objects.all().update(enabled=False)\n        if site_notifications.loaded:\n            if verbose:\n                sys.stdout.write(\n                    style.MIGRATE_HEADING(\"Populating Notification model:\\n\")\n                )\n            self.delete_unregistered_notifications(apps=apps)\n            for name, notification_cls in site_notifications.registry.items():\n                if verbose:\n                    sys.stdout.write(\n                        f\"  * Adding '{name}': '{notification_cls().display_name}'\\n\"\n                    )\n                try:\n                    obj = Notification.objects.get(name=name)\n                except ObjectDoesNotExist:\n                    Notification.objects.create(\n                        name=name,\n                        display_name=notification_cls().display_name,\n                        enabled=True,\n                    )\n                else:\n                    obj.display_name = notification_cls().display_name\n                    obj.enabled = True\n                    obj.save()", "response": "Updates the notification model to ensure all registered Notifications classes are listed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_unregistered_notifications(self, apps=None):\n        Notification = (apps or django_apps).get_model(\"edc_notification.notification\")\n        return Notification.objects.exclude(\n            name__in=[n.name for n in site_notifications.registry.values()]\n        ).delete()", "response": "Delete orphaned notification model instances."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate the mailing lists for each registered notification.", "response": "def create_mailing_lists(self, verbose=True):\n        \"\"\"Creates the mailing list for each registered notification.\n        \"\"\"\n        responses = {}\n        if (\n            settings.EMAIL_ENABLED\n            and self.loaded\n            and settings.EMAIL_BACKEND\n            != \"django.core.mail.backends.locmem.EmailBackend\"\n        ):\n            sys.stdout.write(style.MIGRATE_HEADING(f\"Creating mailing lists:\\n\"))\n            for name, notification_cls in self.registry.items():\n                message = None\n                notification = notification_cls()\n                manager = MailingListManager(\n                    address=notification.email_to,\n                    name=notification.name,\n                    display_name=notification.display_name,\n                )\n                try:\n                    response = manager.create()\n                except ConnectionError as e:\n                    sys.stdout.write(\n                        style.ERROR(\n                            f\"  * Failed to create mailing list {name}. \" f\"Got {e}\\n\"\n                        )\n                    )\n                else:\n                    if verbose:\n                        try:\n                            message = response.json().get(\"message\")\n                        except JSONDecodeError:\n                            message = response.text\n                        sys.stdout.write(\n                            f\"  * Creating mailing list {name}. \"\n                            f'Got {response.status_code}: \"{message}\"\\n'\n                        )\n                    responses.update({name: response})\n        return responses"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef autodiscover(self, module_name=None, verbose=False):\n        module_name = module_name or \"notifications\"\n        verbose = True if verbose is None else verbose\n        sys.stdout.write(f\" * checking for {module_name} ...\\n\")\n        for app in django_apps.app_configs:\n            try:\n                mod = import_module(app)\n                try:\n                    before_import_registry = copy.copy(site_notifications._registry)\n                    import_module(f\"{app}.{module_name}\")\n                    if verbose:\n                        sys.stdout.write(\n                            f\" * registered notifications from application '{app}'\\n\"\n                        )\n                except Exception as e:\n                    if f\"No module named '{app}.{module_name}'\" not in str(e):\n                        site_notifications._registry = before_import_registry\n                        if module_has_submodule(mod, module_name):\n                            raise\n            except ModuleNotFoundError:\n                pass", "response": "Autodiscovers classes in the notifications. py file of any ArcGIS application."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_package(self, package):\n        self._data.setdefault('packages', {})\n        \n        self._data['packages'][package.name] = package.source\n\n        for package in package.deploy_packages:\n            self.add_package(package)\n\n        self._save()", "response": "Add a package to this project"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncopies given string into system clipboard.", "response": "def copy(string, cmd=copy_cmd, stdin=PIPE):\n    \"\"\"Copy given string into system clipboard.\n    \"\"\"\n    Popen(cmd, stdin=stdin).communicate(string.encode('utf-8'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns system clipboard contents.", "response": "def paste(cmd=paste_cmd, stdout=PIPE):\n    \"\"\"Returns system clipboard contents.\n    \"\"\"\n    return Popen(cmd, stdout=stdout).communicate()[0].decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef umap(path, name=None, include=None, namespace=None, priority=None):\n    def url_wrapper(view):\n        # gets the module name\n        module = _find_urls_module(view)\n        # gets the view function (checking if it's a class-based view)\n        fn = view.as_view() if hasattr(view, 'as_view') else view\n\n        if namespace and include:\n            raise TypeError(\n                'You can\\'t use \\'namespace\\' and \\'include\\''\n                ' at the same time!'\n            )\n\n        if namespace:\n            # imports the urlpatterns object\n            base = import_string('{}.urls.urlpatterns'.format(module))\n            # searchs for the namespace\n            urlpatterns_list = [\n                x for x in base\n                if getattr(x, 'namespace', None) == namespace\n            ]\n            # if the list length is different than 1,\n            # then the namespace is either duplicated or doesn't exist\n            if len(urlpatterns_list) != 1:\n                raise ValueError(\n                    'Namespace \\'{}\\' not in list.'.format(namespace)\n                )\n            # if the namespace was found, get its object\n            urlpatterns = urlpatterns_list.pop(0).url_patterns\n        else:\n            # imports the urlpatterns object\n            urlpatterns = import_string('{}.urls.{}'.format(\n                module,\n                include or 'urlpatterns'\n            ))\n        # appends the url with its given name\n        call = (\n            urlpatterns.append if priority is None\n            else partial(urlpatterns.insert, priority)\n        )\n        call(url(path, fn, name=name))\n        return view\n    return url_wrapper", "response": "A function that maps a given URL path name and namespace to a view."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a. vacationrc file if none exists.", "response": "def touch():\n    \"\"\" Create a .vacationrc file if none exists. \"\"\"\n    if not os.path.isfile(get_rc_path()):\n        open(get_rc_path(), 'a').close()\n        print('Created file: {}'.format(get_rc_path()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting an entire. vacationrc file.", "response": "def write(entries):\n    \"\"\" Write an entire rc file. \"\"\"\n    try:\n        with open(get_rc_path(), 'w') as rc:\n            rc.writelines(entries)\n    except IOError:\n        print('Error writing your ~/.vacationrc file!')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef append(entry):\n    if not entry:\n        return\n    try:\n        with open(get_rc_path(), 'a') as f:\n            if isinstance(entry, list):\n                f.writelines(entry)\n            else:\n                f.write(entry + '\\n')\n    except IOError:\n        print('Error writing your ~/.vacationrc file!')", "response": "Append either a list of strings or a string to our file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(bad_entry):\n    entries = read()\n    kept_entries = [x for x in entries if x.rstrip() != bad_entry]\n    write(kept_entries)", "response": "Removes an entry from rc file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a normalized version of text.", "response": "def normalize(text, variant=VARIANT1, case_sensitive=False):\n    \"\"\"Create a normalized version of `text`.\n\n    With `variant` set to ``VARIANT1`` (default), german umlauts are\n    transformed to plain chars: ``\u00e4`` -> ``a``, ``\u00f6`` -> ``o``, ...::\n\n      >>> print(normalize(\"m\u00e4\u00dfig\"))\n      massig\n\n    With `variant` set to ``VARIANT2``, german umlauts are transformed\n    ``\u00e4`` -> ``ae``, etc.::\n\n      >>> print(normalize(\"m\u00e4\u00dfig\", variant=VARIANT2))\n      maessig\n\n    All words are turned to lower-case.::\n\n      >>> print(normalize(\"Ma\u00dfe\"))\n      masse\n\n    except if `case_sensitive` is set to `True`::\n\n      >>> print(normalize(\"Ma\u00dfe\", case_sensitive=True))\n      Masse\n\n    Other chars with diacritics will be returned with the diacritics\n    stripped off::\n\n      >>> print(normalize(\"\u010cesk\u00e1\"))\n      ceska\n\n\n    \"\"\"\n    text = text.replace(\"\u00df\", \"ss\")\n    if not case_sensitive:\n        text = text.lower()\n    if variant == VARIANT2:\n        for char, repl in (\n                ('\u00e4', 'ae'), ('\u00f6', 'oe'), ('\u00fc', 'ue'),\n                ('\u00c4', 'AE'), ('\u00d6', 'OE'), ('\u00dc', 'UE')):\n            text = text.replace(char, repl)\n    text = unicodedata.normalize(\"NFKD\", text).encode(\"ASCII\", \"ignore\")\n    return text.decode()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sort_func(variant=VARIANT1, case_sensitive=False):\n    return lambda x: normalize(\n        x, variant=variant, case_sensitive=case_sensitive)", "response": "A function generator that can be used for sorting the hierarchy of the hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching json data from n. pl", "response": "def fetcher(date=datetime.today(), url_pattern=URL_PATTERN):\n    \"\"\"\n    Fetch json data from n.pl\n\n    Args:\n        date (date) - default today\n        url_patter (string) - default URL_PATTERN\n\n    Returns:\n        dict - data from api\n    \"\"\"\n    api_url = url_pattern % date.strftime('%Y-%m-%d')\n\n    headers = {'Referer': 'http://n.pl/program-tv'}\n    raw_result = requests.get(api_url, headers=headers).json()\n    return raw_result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef result_to_dict(raw_result):\n\n    result = {}\n\n    for channel_index, channel in enumerate(raw_result):\n        channel_id, channel_name = channel[0], channel[1]\n        channel_result = {\n            'id': channel_id,\n            'name': channel_name,\n            'movies': []\n        }\n        for movie in channel[2]:\n            channel_result['movies'].append({\n                'title': movie[1],\n                'start_time': datetime.fromtimestamp(movie[2]),\n                'end_time': datetime.fromtimestamp(movie[2] + movie[3]),\n                'inf': True if movie[3] else False,\n            })\n        result[channel_id] = channel_result\n\n    return result", "response": "Parse raw result from fetcher into dictionary\nFormula"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef waitForCompletion (self):\n    for x in range(self.numberOfThreads):\n      self.taskQueue.put((None, None))\n    for t in self.threadList:\n      # print \"attempting to join %s\" % t.getName()\n      t.join()", "response": "Wait for all threads to complete their work\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self):\n    try:\n      while True:\n        aFunction, arguments = self.manager.taskQueue.get()\n        if aFunction is None:\n          break\n        aFunction(arguments)\n    except KeyboardInterrupt:\n      import thread\n      print >>sys.stderr, \"%s caught KeyboardInterrupt\" % threading.currentThread().getName()\n      thread.interrupt_main()\n    except Exception, x:\n      print >>sys.stderr, \"Something BAD happened in %s:\" % threading.currentThread().getName()\n      traceback.print_exc(file=sys.stderr)\n      print >>sys.stderr, x", "response": "The main routine for a thread s work."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint information about this productive environment", "response": "def info():\n    \"\"\"\n    List information about this productive environment\n    :return:\n    \"\"\"\n    print()\n    print('root directory         :', tasks.conf.APE_ROOT)\n    print()\n    print('active container       :', os.environ.get('CONTAINER_NAME', ''))\n    print()\n    print('active product         :', os.environ.get('PRODUCT_NAME', ''))\n    print()\n    print('ape feature selection  :', tasks.FEATURE_SELECTION)\n    print()\n    print('containers and products:')\n    print('-' * 30)\n    print()\n    for container_name in tasks.get_containers():\n        print(container_name)\n        for product_name in tasks.get_products(container_name):\n            print('    ' + product_name)\n    print()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef switch(poi):\n\n    parts = poi.split(':')\n    if len(parts) == 2:\n        container_name, product_name = parts\n    elif len(parts) == 1 and os.environ.get('CONTAINER_NAME'):\n        # interpret poi as product name if already zapped into a product in order\n        # to enable simply switching products by doing ape zap prod.\n        container_name = os.environ.get('CONTAINER_NAME')\n        product_name = parts[0]\n    else:\n        print('unable to find poi: ', poi)\n        sys.exit(1)\n\n    if container_name not in tasks.get_containers():\n        raise ContainerNotFound('No such container %s' % container_name)\n    elif product_name not in tasks.get_products(container_name):\n        raise ProductNotFound('No such product %s' % product_name)\n    else:\n        print(SWITCH_TEMPLATE.format(\n            source_header=tasks.conf.SOURCE_HEADER,\n            container_name=container_name,\n            product_name=product_name\n        ))", "response": "Switches the context of a specific product into a specific container."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef install_container(container_name):\n\n    container_dir = os.path.join(os.environ['APE_ROOT_DIR'], container_name)\n    if os.path.exists(container_dir):\n        os.environ['CONTAINER_DIR'] = container_dir\n    else:\n        raise ContainerNotFound('ERROR: container directory not found: %s' % container_dir)\n\n    install_script = os.path.join(container_dir, 'install.py')\n    if os.path.exists(install_script):\n        print('... running install.py for %s' % container_name)\n        subprocess.check_call(['python', install_script])\n    else:\n        raise ContainerError('ERROR: this container does not provide an install.py!')", "response": "Installs the container specified by container_name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_poi_tuple(poi=None):\n    if poi:\n        parts = poi.split(':')\n        if len(parts) == 2:\n            container_name, product_name = parts\n            if container_name not in tasks.get_containers():\n                print('No such container')\n                sys.exit(1)\n            elif product_name not in tasks.get_products(container_name):\n                print('No such product')\n                sys.exit(1)\n            else:\n                container_dir = tasks.get_container_dir(container_name)\n        else:\n            print('Please check your arguments: --poi <container>:<product>')\n            sys.exit(1)\n    else:\n        container_dir = os.environ.get('CONTAINER_DIR')\n        product_name = os.environ.get('PRODUCT_NAME')\n\n    return container_dir, product_name", "response": "Takes the poi or None and returns the container_dir and product_name of the poi or from os. environ - availabe"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_product_equation(poi=None):\n    from . import utils\n    from . import validators\n\n    container_dir, product_name = tasks.get_poi_tuple(poi=poi)\n    feature_list = utils.get_features_from_equation(container_dir, product_name)\n    ordering_constraints = utils.get_feature_order_constraints(container_dir)\n    spec_path = utils.get_feature_ide_paths(container_dir, product_name).product_spec_path\n\n    print('*** Starting product.equation validation')\n\n    # --------------------------------------------------------\n    # Validate the feature order\n    print('\\tChecking feature order')\n\n    feature_order_validator = validators.FeatureOrderValidator(feature_list, ordering_constraints)\n    feature_order_validator.check_order()\n\n    if feature_order_validator.has_errors():\n        print('\\t\\txxx ERROR in your product.equation feature order xxx')\n        for error in feature_order_validator.get_violations():\n            print('\\t\\t\\t', error[1])\n    else:\n        print('\\t\\tOK')\n\n    # --------------------------------------------------------\n    # Validate the functional product specification\n    print('\\tChecking functional product spec')\n\n    if not os.path.exists(spec_path):\n\n        print(\n            '\\t\\tSkipped - No product spec exists.\\n'\n            '\\t\\tYou may create a product spec if you want to ensure that\\n'\n            '\\t\\trequired functional features are represented in the product equation\\n'\n            '\\t\\t=> Create spec file featuremodel/productline/<container>/product_spec.json'\n        )\n        return\n\n    spec_validator = validators.ProductSpecValidator(spec_path, product_name, feature_list)\n    if not spec_validator.is_valid():\n        if spec_validator.get_errors_mandatory():\n            print('\\t\\tERROR: The following feature are missing', spec_validator.get_errors_mandatory())\n        if spec_validator.get_errors_never():\n            print('\\t\\tERROR: The following feature are not allowed', spec_validator.get_errors_never())\n    else:\n        print('\\t\\tOK')\n\n    if feature_order_validator.has_errors() or spec_validator.has_errors():\n        sys.exit(1)", "response": "Validates the product equation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn ordered feature list by feaquencer s topsort algorithm.", "response": "def get_ordered_feature_list(info_object, feature_list):\n    \"\"\"\n    Orders the passed feature list by the given, json-formatted feature\n    dependency file using feaquencer's topsort algorithm.\n    :param feature_list:\n    :param info_object:\n    :return:\n    \"\"\"\n    feature_dependencies = json.load(open(info_object.feature_order_json))\n    feature_selection = [feature for feature in [feature.strip().replace('\\n', '') for feature in feature_list]\n                         if len(feature) > 0 and not feature.startswith('_') and not feature.startswith('#')]\n    return [feature + '\\n' for feature in feaquencer.get_total_order(feature_selection, feature_dependencies)]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef config_to_equation(poi=None):\n    from . import utils\n\n    container_dir, product_name = tasks.get_poi_tuple(poi=poi)\n    info_object = utils.get_feature_ide_paths(container_dir, product_name)\n    feature_list = list()\n\n    try:\n        print('*** Processing ', info_object.config_file_path)\n        with open(info_object.config_file_path, 'r') as config_file:\n\n            config_file = config_file.readlines()\n            for line in config_file:\n                # in FeatureIDE we cant use '.' for the paths to sub-features so we used '__'\n                # e.g. django_productline__features__development\n                if len(line.split('__')) <= 2:\n                    line = line\n                else:\n                    line = line.replace('__', '.')\n\n                if line.startswith('abstract_'):\n                    # we skipp abstract features; this is a special case as featureIDE does not work with abstract\n                    # sub trees / leafs.\n                    line = ''\n\n                feature_list.append(line)\n    except IOError:\n        print('{} does not exist. Make sure your config file exists.'.format(info_object.config_file_path))\n\n    feature_list = tasks.get_ordered_feature_list(info_object, feature_list)\n\n    try:\n        with open(info_object.equation_file_path, 'w') as eq_file:\n            eq_file.writelines(feature_list)\n        print('*** Successfully generated product.equation')\n    except IOError:\n        print('product.equation file not found. Please make sure you have a valid product.equation in your chosen product')\n\n    # finally performing the validation of the product equation\n    tasks.validate_product_equation()", "response": "Generates a product. equation file for the given product name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new SIG instance from the given public key.", "response": "def token(cls: Type[SIGType], pubkey: str) -> SIGType:\n        \"\"\"\n        Return SIG instance from pubkey\n\n        :param pubkey: Public key of the signature issuer\n        :return:\n        \"\"\"\n        sig = cls()\n        sig.pubkey = pubkey\n        return sig"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn CSV instance from time", "response": "def token(cls: Type[CSVType], time: int) -> CSVType:\n        \"\"\"\n        Return CSV instance from time\n\n        :param time: Timestamp\n        :return:\n        \"\"\"\n        csv = cls()\n        csv.time = str(time)\n        return csv"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the CSV expression as string", "response": "def compose(self, parser: Any, grammar: Any = None, attr_of: str = None):\n        \"\"\"\n        Return the CSV(time) expression as string format\n\n        :param parser: Parser instance\n        :param grammar: Grammar\n        :param attr_of: Attribute of...\n        \"\"\"\n        return \"CSV({0})\".format(self.time)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef token(cls: Type[CLTVType], timestamp: int) -> CLTVType:\n        cltv = cls()\n        cltv.timestamp = str(timestamp)\n        return cltv", "response": "Return a CLTV instance from timestamp"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns XHX instance from sha_hash", "response": "def token(cls: Type[XHXType], sha_hash: str) -> XHXType:\n        \"\"\"\n        Return XHX instance from sha_hash\n\n        :param sha_hash: SHA256 hash\n        :return:\n        \"\"\"\n        xhx = cls()\n        xhx.sha_hash = sha_hash\n        return xhx"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an instance of cls from keyword in expression", "response": "def token(cls: Type[OperatorType], keyword: str) -> OperatorType:\n        \"\"\"\n        Return Operator instance from keyword\n\n        :param keyword: Operator keyword in expression\n        :return:\n        \"\"\"\n        op = cls(keyword)\n        return op"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef token(cls: Type[ConditionType], left: Any, op: Optional[Any] = None,\n              right: Optional[Any] = None) -> ConditionType:\n        \"\"\"\n        Return Condition instance from arguments and Operator\n\n        :param left: Left argument\n        :param op: Operator\n        :param right: Right argument\n        :return:\n        \"\"\"\n        condition = cls()\n        condition.left = left\n        if op:\n            condition.op = op\n        if right:\n            condition.right = right\n        return condition", "response": "Return a Condition instance from arguments and Operator\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compose(self, parser: Any, grammar: Any = None, attr_of: str = None) -> str:\n        if type(self.left) is Condition:\n            left = \"({0})\".format(parser.compose(self.left, grammar=grammar, attr_of=attr_of))\n        else:\n            left = parser.compose(self.left, grammar=grammar, attr_of=attr_of)\n\n        if getattr(self, 'op', None):\n\n            if type(self.right) is Condition:\n                right = \"({0})\".format(parser.compose(self.right, grammar=grammar, attr_of=attr_of))\n            else:\n                right = parser.compose(self.right, grammar=grammar, attr_of=attr_of)\n            op = parser.compose(self.op, grammar=grammar, attr_of=attr_of)\n            result = \"{0} {1} {2}\".format(left, op, right)\n        else:\n            result = left\n        return result", "response": "Return the Condition as string format\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a template library into the state.", "response": "def load_library(self, path):\n        '''\n        Load a template library into the state.\n        '''\n        module = import_module(path)\n        self.tags.update(module.register.tags)\n        self.helpers.update(module.register.helpers)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning default driver logger.", "response": "def get_default_logger():\n        \"\"\"Returns default driver logger.\n\n        :return: logger instance\n        :rtype: logging.Logger\n        \"\"\"\n        handler = logging.StreamHandler()\n        handler.setLevel(logging.DEBUG)\n        handler.setFormatter(logging.Formatter(\n            \"[%(levelname)1.1s %(asctime)s %(name)s] %(message)s\",\n            \"%y%m%d %H:%M:%S\"))\n\n        logger_name = \"pydbal\"\n        if Connection._instance_count > 1:\n            logger_name += \":\" + str(Connection._instance_count)\n        logger = logging.getLogger(logger_name)\n        logger.setLevel(logging.DEBUG)\n        logger.addHandler(handler)\n        return logger"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nensure database connection is still open.", "response": "def ensure_connected(self):\n        \"\"\"Ensures database connection is still open.\"\"\"\n        if not self.is_connected():\n            if not self._auto_connect:\n                raise DBALConnectionError.connection_closed()\n            self.connect()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef query(self, sql, *args, **kwargs):\n        self.ensure_connected()\n        stmt = Statement(self)\n        stmt.execute(sql, *args, **kwargs)\n        return stmt", "response": "Executes an SQL SELECT query returning a Statement object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute an SQL INSERT UPDATE DELETE query with the given parameters and returns the number of affected rows.", "response": "def execute(self, sql, *args, **kwargs):\n        \"\"\"Executes an SQL INSERT/UPDATE/DELETE query with the given parameters and returns the number of affected rows.\n\n        :param sql: statement to execute\n        :param args: parameters iterable\n        :param kwargs: parameters iterable\n        :return: number of affected rows\n        :rtype: int\n        \"\"\"\n        self.ensure_connected()\n        return Statement(self).execute(sql, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts a transaction by suspending auto - commit mode.", "response": "def begin_transaction(self):\n        \"\"\"Starts a transaction by suspending auto-commit mode.\"\"\"\n        self.ensure_connected()\n        self._transaction_nesting_level += 1\n        if self._transaction_nesting_level == 1:\n            self._driver.begin_transaction()\n        elif self._nest_transactions_with_savepoints:\n            self.create_savepoint(self._get_nested_transaction_savepoint_name())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef commit(self):\n        if self._transaction_nesting_level == 0:\n            raise DBALConnectionError.no_active_transaction()\n        if self._is_rollback_only:\n            raise DBALConnectionError.commit_failed_rollback_only()\n\n        self.ensure_connected()\n        if self._transaction_nesting_level == 1:\n            self._driver.commit()\n        elif self._nest_transactions_with_savepoints:\n            self.release_savepoint(self._get_nested_transaction_savepoint_name())\n\n        self._transaction_nesting_level -= 1\n\n        if not self._auto_commit and self._transaction_nesting_level == 0:\n            self.begin_transaction()", "response": "Commits the current transaction."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncommitting all current nesting transactions.", "response": "def commit_all(self):\n        \"\"\"Commits all current nesting transactions.\"\"\"\n        while self._transaction_nesting_level != 0:\n            if not self._auto_commit and self._transaction_nesting_level == 1:\n                return self.commit()\n            self.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rollback(self):\n        if self._transaction_nesting_level == 0:\n            raise DBALConnectionError.no_active_transaction()\n\n        self.ensure_connected()\n        if self._transaction_nesting_level == 1:\n            self._transaction_nesting_level = 0\n            self._driver.rollback()\n            self._is_rollback_only = False\n            if not self._auto_commit:\n                self.begin_transaction()\n        elif self._nest_transactions_with_savepoints:\n            self.rollback_savepoint(self._get_nested_transaction_savepoint_name())\n            self._transaction_nesting_level -= 1\n        else:\n            self._is_rollback_only = True\n            self._transaction_nesting_level -= 1", "response": "Cancels any database changes done during the current transaction."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute a function in a transaction.", "response": "def transaction(self, callback):\n        \"\"\"Executes a function in a transaction.\n\n        The function gets passed this Connection instance as an (optional) parameter.\n\n        If an exception occurs during execution of the function or transaction commit,\n        the transaction is rolled back and the exception re-thrown.\n\n        :param callback: the function to execute in a transaction\n        :return: the value returned by the `callback`\n        :raise: Exception\n        \"\"\"\n        self.begin_transaction()\n        try:\n            result = callback(self)\n            self.commit()\n            return result\n        except:\n            self.rollback()\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_auto_commit(self, auto_commit):\n        auto_commit = bool(auto_commit)\n        if auto_commit == self._auto_commit:\n            return\n\n        self._auto_commit = auto_commit\n\n        if self.is_connected() and self._transaction_nesting_level != 0:\n            self.commit_all()", "response": "Sets auto - commit mode for this connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_transaction_isolation(self, level):\n        self.ensure_connected()\n        self._transaction_isolation_level = level\n        self._platform.set_transaction_isolation(level)", "response": "Sets the transaction isolation level."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_transaction_isolation(self):\n        if self._transaction_isolation_level is None:\n            self._transaction_isolation_level = self._platform.get_default_transaction_isolation_level()\n        return self._transaction_isolation_level", "response": "Returns the currently active transaction isolation level."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_nest_transactions_with_savepoints(self, nest_transactions_with_savepoints):\n        if self._transaction_nesting_level > 0:\n            raise DBALConnectionError.may_not_alter_nested_transaction_with_savepoints_in_transaction()\n        if not self._platform.is_savepoints_supported():\n            raise DBALConnectionError.savepoints_not_supported()\n        self._nest_transactions_with_savepoints = bool(nest_transactions_with_savepoints)", "response": "Sets if nested transactions should use savepoints."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_savepoint(self, savepoint):\n        if not self._platform.is_savepoints_supported():\n            raise DBALConnectionError.savepoints_not_supported()\n        self.ensure_connected()\n        self._platform.create_savepoint(savepoint)", "response": "Creates a new savepoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreleases the given savepoint.", "response": "def release_savepoint(self, savepoint):\n        \"\"\"Releases the given savepoint.\n\n        :param savepoint: the name of the savepoint to release\n        :raise: pydbal.exception.DBALConnectionError\n        \"\"\"\n        if not self._platform.is_savepoints_supported():\n            raise DBALConnectionError.savepoints_not_supported()\n        if self._platform.is_release_savepoints_supported():\n            self.ensure_connected()\n            self._platform.release_savepoint(savepoint)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rollback_savepoint(self, savepoint):\n        if not self._platform.is_savepoints_supported():\n            raise DBALConnectionError.savepoints_not_supported()\n        self.ensure_connected()\n        self._platform.rollback_savepoint(savepoint)", "response": "Rolls back to the given savepoint."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert(self, table, values):\n        assert isinstance(values, dict)\n\n        sb = self.sql_builder().insert(table)\n        for column, value in values.iteritems():\n            values[column] = sb.create_positional_parameter(value)\n        return sb.values(values).execute()", "response": "Inserts a table row with specified data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates a table row with specified data by given identifier.", "response": "def update(self, table, values, identifier):\n        \"\"\"Updates a table row with specified data by given identifier.\n\n        :param table: the expression of the table to update quoted or unquoted\n        :param values: a dictionary containing column-value pairs\n        :param identifier: the update criteria; a dictionary containing column-value pairs\n        :return: the number of affected rows\n        :rtype: int\n        \"\"\"\n        assert isinstance(values, dict)\n        assert isinstance(identifier, dict)\n\n        sb = self.sql_builder().update(table)\n        for column, value in values.iteritems():\n            sb.set(column, sb.create_positional_parameter(value))\n        for column, value in identifier.iteritems():\n            func = self._expr.in_ if isinstance(value, (list, tuple)) else self._expr.eq\n            sb.and_where(func(column, sb.create_positional_parameter(value)))\n        return sb.execute()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(self, table, identifier):\n        assert isinstance(identifier, dict)\n\n        sb = self.sql_builder().delete(table)\n        for column, value in identifier.iteritems():\n            func = self._expr.in_ if isinstance(value, (list, tuple)) else self._expr.eq\n            sb.and_where(func(column, sb.create_positional_parameter(value)))\n        return sb.execute()", "response": "Deletes a table row by given identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute a statement with reconnecting by connection closed error codes.", "response": "def _execute(self, sql, params):\n        \"\"\"Execute statement with reconnecting by connection closed error codes.\n\n        2006 (CR_SERVER_GONE_ERROR): MySQL server has gone away\n        2013 (CR_SERVER_LOST): Lost connection to MySQL server during query\n        2055 (CR_SERVER_LOST_EXTENDED): Lost connection to MySQL server at '%s', system error: %d\n        \"\"\"\n        try:\n            return self._execute_unsafe(sql, params)\n        except MySQLdb.OperationalError as ex:\n            if ex.args[0] in (2006, 2013, 2055):\n                self._log(\"Connection with server is lost. Trying to reconnect.\")\n                self.connect()\n                return self._execute_unsafe(sql, params)\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef requirements(self):\n        cache = apt.cache.Cache()\n        for pkg in self.pkgs_required:\n            try:\n                pkg = cache[pkg]\n                if not pkg.is_installed:\n                    try:\n                        pkg.mark_install()\n                        cache.commit()\n                    except LockFailedException as lfe:\n                        logging.error(\n                            'Errore \"{}\" probabilmente l\\'utente {} non ha i '\n                            'diritti di amministratore'.format(lfe,\n                                                               self.username))\n                        raise lfe\n                    except Exception as e:\n                        logging.error('Errore non classificato \"{}\"'.format(e))\n                        raise e\n            except KeyError:\n                logging.error('Il pacchetto \"{}\" non e\\' presente in questa'\n                              ' distribuzione'.format(pkg))", "response": "Verifica che tutti i pacchetti apt necessari al funzionamento installati. Se cosi non fosse li installa. Se cosi non fosse li installa. Se cosi non fosse li installa. Se cosi non fosse li installa. Se cosi non fosse li installa. Se cosi non fosse li installa. Se cosi non fosse li installa."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_shares(self):\n        if self.filename is None:\n            self.filenamename = os.path.expanduser(\n                '~%s/%s' % (self.host_username, FILE_RC))\n        if not os.path.exists(self.filename):\n            error_msg = (u\"Impossibile trovare il file di configurazione \"\n                         u\"'%s'.\\nLe unit\u00e0 di rete non saranno collegate.\" % (\n                             FILE_RC.lstrip('.')))\n            if not self.shell_mode:\n                ErrorMessage(error_msg)\n            logging.error(error_msg)\n            sys.exit(5)\n        if self.verbose:\n            logging.warning(\"File RC utilizzato: %s\", self.filename)\n        self.samba_shares = read_config(self.filename)", "response": "Setta la variabile membro self. samba_shares il quale e un file ~. pygmount. rc e un file ~. pygmount. rc e un file ~. pygmount. rc e un file ~. pygmount. rc e un file ~. pygmount. rc e un file ~. pygmount. rc e un file ~. pygmount. rc e un file ~. pygmount. rc"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self):\n        logging.info('start run with \"{}\" at {}'.format(\n            self.username, datetime.datetime.now()))\n        progress = Progress(text=\"Controllo requisiti software...\",\n                            pulsate=True, auto_close=True)\n        progress(1)\n        try:\n            self.requirements()\n        except LockFailedException as lfe:\n            ErrorMessage('Errore \"{}\" probabilmente l\\'utente {} non ha i'\n                         ' diritti di amministratore'.format(lfe,\n                                                             self.username))\n            sys.exit(20)\n        except Exception as e:\n            ErrorMessage(\"Si e' verificato un errore generico: {}\".format(e))\n            sys.exit(21)\n        progress(100)\n\n        self.set_shares()\n        # richiesta username del dominio\n        insert_msg = \"Inserisci l'utente del Dominio/Posta Elettronica\"\n        default_username = (self.host_username if self.host_username\n                            else os.environ['USER'])\n        self.domain_username = GetText(text=insert_msg,\n                                       entry_text=self.username)\n\n        if self.domain_username is None or len(self.domain_username) == 0:\n            error_msg = \"Inserimento di un username di dominio vuoto\"\n            ErrorMessage(self.msg_error % error_msg)\n            sys.exit(2)\n\n        # richiesta della password di dominio\n        insert_msg = u\"Inserisci la password del Dominio/Posta Elettronica\"\n        self.domain_password = GetText(text=insert_msg,\n                                       entry_text='password',\n                                       password=True)\n\n        if self.domain_password is None or len(self.domain_password) == 0:\n            error_msg = u\"Inserimento di una password di dominio vuota\"\n            ErrorMessage(self.msg_error % error_msg)\n            sys.exit(3)\n\n        progress_msg = u\"Collegamento unit\u00e0 di rete in corso...\"\n        progress = Progress(text=progress_msg,\n                            pulsate=True,\n                            auto_close=True)\n        progress(1)\n        # ciclo per montare tutte le condivisioni\n        result = []\n        for share in self.samba_shares:\n            # print(\"#######\")\n            # print(share)\n            if 'mountpoint' not in share.keys():\n                # creazione stringa che rappresente il mount-point locale\n                mountpoint = os.path.expanduser(\n                    '~%s/%s/%s' % (self.host_username,\n                                   share['hostname'],\n                                   share['share']))\n                share.update({'mountpoint': mountpoint})\n            elif not share['mountpoint'].startswith('/'):\n                mountpoint = os.path.expanduser(\n                    '~%s/%s' % (self.host_username, share['mountpoint']))\n                share.update({'mountpoint': mountpoint})\n\n            share.update({\n                'host_username': self.host_username,\n                'domain_username': share.get(\n                    'username', self.domain_username),\n                'domain_password': share.get(\n                    'password', self.domain_password)})\n\n            # controllo che il mount-point locale esista altrimenti non\n            # viene creato\n            if not os.path.exists(share['mountpoint']):\n                if self.verbose:\n                    logging.warning('Mountpoint \"%s\" not exist.' %\n                                    share['mountpoint'])\n                if not self.dry_run:\n                    os.makedirs(share['mountpoint'])\n\n            # smonto la condivisione prima di rimontarla\n            umont_cmd = self.cmd_umount % share\n            if self.verbose:\n                logging.warning(\"Umount command: %s\" % umont_cmd)\n            if not self.dry_run:\n                umount_p = subprocess.Popen(umont_cmd,\n                                            shell=True)\n                returncode = umount_p.wait()\n                time.sleep(2)\n\n            mount_cmd = self.cmd_mount % share\n            if self.verbose:\n                placeholder = \",password=\"\n                logging.warning(\"Mount command: %s%s\" % (mount_cmd.split(\n                    placeholder)[0], placeholder + \"******\\\"\"))\n\n            # print(mount_cmd)\n            # print(\"#######\")\n            if not self.dry_run:\n                # montaggio della condivisione\n                p_mnt = subprocess.Popen(mount_cmd, shell=True,\n                                         stdout=subprocess.PIPE,\n                                         stderr=subprocess.PIPE)\n                returncode = p_mnt.wait()\n                result.append({'share': share['share'],\n                               'returncode': returncode,\n                               'stdout': p_mnt.stdout.read(),\n                               'stderr': p_mnt.stderr.read()})\n        progress(100)\n        if self.verbose:\n            logging.warning(\"Risultati: %s\" % result)", "response": "Run the controllo requisiti software."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndump database to dict data.", "response": "def _dump(db):\n    \"\"\"\n    Dump :class:`mongomock.database.Database` to dict data.\n    \"\"\"\n    db_data = {\"name\": db.name, \"_collections\": dict()}\n\n    for col_name, collection in iteritems(db._collections):\n        if col_name != \"system.indexes\":\n            col_data = {\n                \"_documents\": collection._documents,\n                \"_uniques\": collection._uniques,\n            }\n            db_data[\"_collections\"][col_name] = col_data\n\n    return db_data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _load(db_data, db):\n    if db.name != db_data[\"name\"]:\n        raise ValueError(\"dbname doesn't matches! Maybe wrong database data.\")\n\n    db.__init__(client=db._client, name=db.name)\n    for col_name, col_data in iteritems(db_data[\"_collections\"]):\n        collection = db.get_collection(col_name)\n        collection._documents = col_data[\"_documents\"]\n        collection._uniques = col_data[\"_uniques\"]\n        db._collections[col_name] = collection\n\n    return db", "response": "Load database from dict data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndumps a database to a local file.", "response": "def dump_db(db, file,\n            pretty=False,\n            overwrite=False,\n            verbose=True):\n    \"\"\"\n    Dump :class:`mongomock.database.Database` to a local file. Only support\n    ``*.json`` or ``*.gz`` (compressed json file)\n\n    :param db: instance of :class:`mongomock.database.Database`.\n    :param file: file path.\n    :param pretty: bool, toggle on jsonize into pretty format.\n    :param overwrite: bool, allow overwrite to existing file.\n    :param verbose: bool, toggle on log.\n    \"\"\"\n    db_data = _dump(db)\n    json.dump(\n        db_data, file,\n        pretty=pretty, overwrite=overwrite, verbose=verbose,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a database from a local file.", "response": "def load_db(file, db, verbose=True):\n    \"\"\"\n    Load :class:`mongomock.database.Database` from a local file.\n\n    :param file: file path.\n    :param db: instance of :class:`mongomock.database.Database`.\n    :param verbose: bool, toggle on log.\n    :return: loaded db.\n    \"\"\"\n    db_data = json.load(file, verbose=verbose)\n    return _load(db_data, db)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake Orm Values SubqueryCondition", "response": "def makeOrmValuesSubqueryCondition(ormSession, column, values: List[Union[int, str]]):\n    \"\"\" Make Orm Values Subquery\n\n    :param ormSession: The orm session instance\n    :param column: The column from the Declarative table, eg TableItem.colName\n    :param values: A list of string or int values\n    \"\"\"\n    if isPostGreSQLDialect(ormSession.bind):\n        return column.in_(values)\n\n    if not isMssqlDialect(ormSession.bind):\n        raise NotImplementedError()\n\n    sql = _createMssqlSqlText(values)\n\n    sub_qry = ormSession.query(column)  # Any column, it just assigns a name\n    sub_qry = sub_qry.from_statement(sql)\n\n    return column.in_(sub_qry)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef makeCoreValuesSubqueryCondition(engine, column, values: List[Union[int, str]]):\n\n    if isPostGreSQLDialect(engine):\n        return column.in_(values)\n\n    if not isMssqlDialect(engine):\n        raise NotImplementedError()\n\n    sql = _createMssqlSqlText(values)\n\n    return column.in_(sql)", "response": "Make a condition that returns True if the column is in the values list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resource_path(package_name: str, relative_path: typing.Union[str, Path]) -> Path:\n    relative_path = Path(relative_path)\n    methods = [\n        _get_from_dev,\n        _get_from_package,\n        _get_from_sys,\n    ]\n    for method in methods:\n        path = method(package_name, relative_path)\n        if path.exists():\n            return path\n\n    raise FileNotFoundError(relative_path)", "response": "Get absolute path to resource file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting the message to stderr if - v / PYTHONVERBOSE is turned on.", "response": "def _verbose_message(message, *args, **kwargs):\n    \"\"\"Print the message to stderr if -v/PYTHONVERBOSE is turned on.\"\"\"\n    verbosity = kwargs.pop('verbosity', 1)\n    if sys.flags.verbose >= verbosity:\n        if not message.startswith(('#', 'import ')):\n            message = '# ' + message\n        print(message.format(*args), file=sys.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _open_connection(self):\n        if self._scheme == 'unix':\n            self._connection = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM, 0)\n            self._connection.connect(self._path)\n        elif self._scheme == 'tcp':\n            self._connection = socket.socket(socket.AF_INET, socket.SOCK_STREAM, socket.SOL_TCP)\n            self._connection.connect((self._host, self._port))\n        elif self._scheme == 'http':\n            self._connection =  httplib.HTTPConnection(self._host, self._port, strict=False)\n        else:\n            raise ConnectionError(\"Connection scheme not recognized!\")", "response": "Open a new connection socket to the CPS."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _send_request(self, xml_request):\n        if self._scheme == 'http':\n            return self._send_http_request(xml_request)\n        else:\n            return self._send_socket_request(xml_request)", "response": "Send the XML request block to the CPS using the corect protocol."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _send_http_request(self, xml_request):\n        headers = {\"Host\": self._host, \"Content-Type\": \"text/xml\", \"Recipient\": self._storage}\n        try: # Retry once if failed in case the socket has just gone bad.\n            self._connection.request(\"POST\", self._selector_url, xml_request, headers)\n            response = self._connection.getresponse()\n        except (httplib.CannotSendRequest, httplib.BadStatusLine):\n            Debug.warn(\"\\nRestarting socket, resending message!\")\n            self._open_connection()\n            self._connection.request(\"POST\", self._selector_url, xml_request, headers)\n            response = self._connection.getresponse()\n        data = response.read()\n        return data", "response": "Send a request via HTTP protocol."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a request to the CPS socket.", "response": "def _send_socket_request(self, xml_request):\n        \"\"\" Send a request via protobuf.\n\n            Args:\n                xml_request -- A fully formed xml request string for the CPS.\n\n            Returns:\n                The raw xml response string.\n        \"\"\"\n        def to_variant(number):\n            buff = []\n            while number:\n                byte = number % 128\n                number = number // 128\n                if number > 0:\n                    byte |= 0x80\n                buff.append(chr(byte))\n            return ''.join(buff)\n\n        def from_variant(stream):\n            used = 0\n            number = 0\n            q = 1\n            while True:\n                byte = ord(stream[used])\n                used += 1\n                number += q * (byte & 0x7F)\n                q *= 128\n                if byte&0x80==0:\n                    break\n            return (number, used)\n\n        def encode_fields(fields):\n            chunks = []\n            for field_id, message in fields.items():\n                chunks.append(to_variant((field_id << 3) | 2)) # Hardcoded WireType=2\n                chunks.append(to_variant(len(message)))\n                chunks.append(message)\n            return ''.join(chunks)\n\n        def decode_fields(stream):\n            fields = {}\n            offset = 0\n            stream_lenght = len(stream)\n            while offset<stream_lenght:\n                field_header, used = from_variant(stream[offset:])\n                offset += used\n                wire_type = field_header & 0x07\n                field_id = field_header >> 3\n                if wire_type==2:\n                    message_lenght, used = from_variant(stream[offset:])\n                    offset += used\n                    fields[field_id] = stream[offset:offset+message_lenght]\n                    offset += message_lenght\n                elif wire_type==0:\n                    fields[field_id], used = from_variant(stream[offset:])\n                    offset += used\n                elif wire_type==1:\n                    fields[field_id] = stream[offset:offset+8]\n                    offset += 8\n                elif wire_type==3:\n                    raise ConnectionError()\n                elif wire_type==4:\n                    raise ConnectionError()\n                elif wire_type==5:\n                    fields[field_id] = stream[offse:offset+4]\n                    offset += 4\n                else:\n                    raise ConnectionError()\n            return fields\n\n\n        def make_header(lenght):\n            result = []\n            result.append(chr((lenght & 0x000000FF)))\n            result.append(chr((lenght & 0x0000FF00) >> 8))\n            result.append(chr((lenght & 0x00FF0000) >> 16))\n            result.append(chr((lenght & 0xFF000000) >> 24))\n            return '\\t\\t\\x00\\x00' + ''.join(result)\n\n        def parse_header(header):\n            if len(header) == 8 and header[0] == '\\t' and header[1] == '\\t' and\\\n                    header[2] == '\\00' and header[3] == '\\00':\n                return ord(header[4]) | (ord(header[5]) << 8) |\\\n                        (ord(header[6]) << 16) | (ord(header[7]) << 24)\n            else:\n                raise ConnectionError()\n\n        def socket_send(data):\n            sent_bytes = 0\n            failures = 0\n            total_bytes = len(data)\n            while sent_bytes < total_bytes:\n                sent = self._connection.send(data[sent_bytes:])\n                if sent == 0:\n                    failures += 1\n                    if failures > 5:\n                        raise ConnectionError()\n                    continue\n                sent_bytes += sent\n\n        def socket_recieve(lenght):\n            total_recieved = 0\n            failures = 5\n            recieved_chunks = []\n            while total_recieved<lenght:\n                chunk = self._connection.recv(lenght-total_recieved)\n                if not chunk:\n                    failures += 1\n                    if failures > 5:\n                        raise ConnectionError()\n                    continue\n                recieved_chunks.append(chunk)\n                total_recieved += len(chunk)\n            return ''.join(recieved_chunks)\n\n        encoded_message = encode_fields({1: xml_request,\n                                         2: self._storage if self._storage else \"special:detect-storage\"})\n        header = make_header(len(encoded_message))\n\n        try: # Retry once if failed in case the socket has just gone bad.\n            socket_send(header+encoded_message)\n        except (ConnectionError, socket.error):\n            self._connection.close()\n            self._open_connection()\n            socket_send(header+encoded_message)\n\n        # TODO: timeout\n        header = socket_recieve(8)\n        lenght = parse_header(header)\n        encoded_response = socket_recieve(lenght)\n        response = decode_fields(encoded_response)\n        # TODO: Test for id=3 error message\n        # TODO: check for and raise errors\n        return response[1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef similar_text(self, *args, **kwargs):\n        return SimilarRequest(self, *args, mode='text', **kwargs).send()", "response": "Search for documents that are similar to the textual content of the source document or to the existing document."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(arguments=None):\n\n    # setup the command-line util settings\n    su = tools(\n        arguments=arguments,\n        docString=__doc__,\n        logLevel=\"WARNING\",\n        options_first=False,\n        projectName=\"rockfinder\",\n        defaultSettingsFile=True\n    )\n    arguments, settings, log, dbConn = su.setup()\n\n    # unpack remaining cl arguments using `exec` to setup the variable names\n    # automatically\n    for arg, val in arguments.iteritems():\n        if arg[0] == \"-\":\n            varname = arg.replace(\"-\", \"\") + \"Flag\"\n        else:\n            varname = arg.replace(\"<\", \"\").replace(\">\", \"\")\n        if isinstance(val, str) or isinstance(val, unicode):\n            exec(varname + \" = '%s'\" % (val,))\n        else:\n            exec(varname + \" = %s\" % (val,))\n        if arg == \"--dbConn\":\n            dbConn = val\n        log.debug('%s = %s' % (varname, val,))\n\n    ## START LOGGING ##\n    startTime = times.get_now_sql_datetime()\n    log.info(\n        '--- STARTING TO RUN THE cl_utils.py AT %s' %\n        (startTime,))\n\n    # CALL FUNCTIONS/OBJECTS\n\n    if init:\n        from os.path import expanduser\n        home = expanduser(\"~\")\n        filepath = home + \"/.config/rockfinder/rockfinder.yaml\"\n        cmd = \"\"\"open %(filepath)s\"\"\" % locals()\n        p = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\n        try:\n            cmd = \"\"\"open %(filepath)s\"\"\" % locals()\n            p = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\n        except:\n            pass\n        try:\n            cmd = \"\"\"start %(filepath)s\"\"\" % locals()\n            p = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\n        except:\n            pass\n        return\n\n    if where and orbfitFlag:\n        from rockfinder import orbfit_ephemeris\n        eph = orbfit_ephemeris(\n            log=log,\n            objectId=objectId,\n            mjd=mjd,\n            obscode=obscode,\n            settings=settings,\n            verbose=extraFlag\n        )\n    else:\n        from rockfinder import jpl_horizons_ephemeris\n        eph = jpl_horizons_ephemeris(\n            log=log,\n            objectId=objectId,\n            mjd=mjd,\n            obscode=obscode,\n            verbose=extraFlag\n        )\n\n    dataSet = list_of_dictionaries(\n        log=log,\n        listOfDictionaries=eph\n    )\n    # xfundamentals-render-list-of-dictionaries\n\n    output = dataSet.table(filepath=None)\n    if csv:\n        output = dataSet.csv(filepath=None)\n    elif json:\n        output = dataSet.json(filepath=None)\n    elif yaml:\n        output = dataSet.yaml(filepath=None)\n    elif md:\n        output = dataSet.markdown(filepath=None)\n    elif rst:\n        output = dataSet.reST(filepath=None)\n\n    print output\n\n    if \"dbConn\" in locals() and dbConn:\n        dbConn.commit()\n        dbConn.close()\n    ## FINISH LOGGING ##\n    endTime = times.get_now_sql_datetime()\n    runningTime = times.calculate_time_difference(startTime, endTime)\n    log.info('-- FINISHED ATTEMPT TO RUN THE cl_utils.py AT %s (RUNTIME: %s) --' %\n             (endTime, runningTime, ))\n\n    return", "response": "This is the main function used by the cl_utils. py script."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsafes division of two items", "response": "def safe_division(dividend, divisor):\n    \"\"\"\n    :return:\n        nan: invalid arguments\n    :rtype: float\n    \"\"\"\n\n    try:\n        divisor = float(divisor)\n        dividend = float(dividend)\n    except (TypeError, ValueError, AssertionError):\n        return float(\"nan\")\n\n    try:\n        return dividend / divisor\n    except (ZeroDivisionError):\n        return float(\"nan\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compare_version(lhs_version, rhs_version):\n\n    lhs_major, lhs_minor, lhs_revision = [\n        int(v) for v in lhs_version.split(\".\")]\n    rhs_major, rhs_minor, rhs_revision = [\n        int(v) for v in rhs_version.split(\".\")]\n\n    if lhs_major < rhs_major:\n        return -1\n    elif lhs_major > rhs_major:\n        return 1\n\n    if lhs_minor < rhs_minor:\n        return -1\n    elif lhs_minor > rhs_minor:\n        return 1\n\n    if lhs_revision < rhs_revision:\n        return -1\n    elif lhs_revision > rhs_revision:\n        return 1\n\n    return 0", "response": "Compare two version strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dump_dict(dict_input, indent=4):\n\n    dict_work = dict(dict_input)\n    \"\"\"\n    for key, value in six.iteritems(dict_input):\n        if any([f(value) for f in (is_float, isDict, is_list_or_tuple)]):\n            dict_work[key] = value\n            continue\n\n        try:\n            dict_work[key] = str(value)\n        except:\n            dict_work[key] = str(type(value))\n\n        dict_work[key] = _convert_dump_dict(value)\n    \"\"\"\n\n    try:\n        import json\n        return json.dumps(dict_work, sort_keys=True, indent=indent)\n    except ImportError:\n        pass\n\n    try:\n        import simplejson as json\n        return json.dumps(dict_work, sort_keys=True, indent=indent)\n    except ImportError:\n        pass\n\n    try:\n        import pprint\n        return pprint.pformat(dict_work, indent=indent)\n    except ImportError:\n        pass\n\n    return str(dict_work)", "response": "Dump a dictionary to a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a directory if it does not exist. Takes into consideration concurrent access support. Works like the shell s mkdir - p.", "response": "def makedirs_safe(fulldir):\n  \"\"\"Creates a directory if it does not exists. Takes into consideration\n  concurrent access support. Works like the shell's 'mkdir -p'.\n  \"\"\"\n\n  try:\n    if not os.path.exists(fulldir): os.makedirs(fulldir)\n  except OSError as exc: # Python >2.5\n    import errno\n    if exc.errno == errno.EEXIST: pass\n    else: raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef str_(name):\n  if isinstance(name, bytes) and not isinstance(name, str):\n    return name.decode('utf8')\n  else:\n    return name", "response": "Return the string representation of the given name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef qsub(command, queue=None, cwd=True, name=None, deps=[], stdout='',\n    stderr='', env=[], array=None, context='grid', hostname=None,\n    memfree=None, hvmem=None, gpumem=None, pe_opt=None, io_big=False):\n  \"\"\"Submits a shell job to a given grid queue\n\n  Keyword parameters:\n\n  command\n    The command to be submitted to the grid\n\n  queue\n    A valid queue name or None, to use the default queue\n\n  cwd\n    If the job should change to the current working directory before starting\n\n  name\n    An optional name to set for the job. If not given, defaults to the script\n    name being launched.\n\n  deps\n    Job ids to which this job will be dependent on\n\n  stdout\n    The standard output directory. If not given, defaults to what qsub has as a\n    default.\n\n  stderr\n    The standard error directory (if not given, defaults to the stdout\n    directory).\n\n  env\n    This is a list of extra variables that will be set on the environment\n    running the command of your choice.\n\n  array\n    If set should be either:\n\n    1. a string in the form m[-n[:s]] which indicates the starting range 'm',\n       the closing range 'n' and the step 's'.\n    2. an integer value indicating the total number of jobs to be submitted.\n       This is equivalent ot set the parameter to a string \"1-k:1\" where \"k\" is\n       the passed integer value\n    3. a tuple that contains either 1, 2 or 3 elements indicating the start,\n       end and step arguments (\"m\", \"n\", \"s\").\n\n    The minimum value for \"m\" is 1. Giving \"0\" is an error.\n\n    If submitted with this option, the job to be created will be an SGE\n    parametric job. In this mode SGE does not allow individual control of each\n    job. The environment variable SGE_TASK_ID will be set on the executing\n    process automatically by SGE and indicates the unique identifier in the\n    range for which the current job instance is for.\n\n  context\n    The setshell context in which we should try a 'qsub'. Normally you don't\n    need to change the default. This variable can also be set to a context\n    dictionary in which case we just setup using that context instead of\n    probing for a new one, what can be fast.\n\n  memfree\n    If set, it asks the queue for a node with a minimum amount of memory\n    Used only if mem is not set\n    (cf. qsub -l mem_free=<...>)\n\n  hvmem\n    If set, it asks the queue for a node with a minimum amount of memory\n    Used only if mem is not set\n    (cf. qsub -l h_vmem=<...>)\n\n  gpumem\n    Applicable only for GPU-based queues. If set, it asks for the GPU queue\n    with a minimum amount of memory. The amount should not be more than 24.\n    (cf. qsub -l gpumem=<...>)\n\n  hostname\n    If set, it asks the queue to use only a subset of the available nodes\n    Symbols: | for OR, & for AND, ! for NOT, etc.\n    (cf. qsub -l hostname=<...>)\n\n  pe_opt\n    If set, add a -pe option when launching a job (for instance pe_exclusive* 1-)\n\n  io_big\n    If set to true, the io_big flag will be set.\n    Use this flag if your process will need a lot of Input/Output operations.\n\n  Returns the job id assigned to this job (integer)\n  \"\"\"\n\n  scmd = ['qsub']\n\n  import six\n  if isinstance(queue, six.string_types) and queue not in ('all.q', 'default'):\n    scmd += ['-l', queue]\n\n  if memfree: scmd += ['-l', 'mem_free=%s' % memfree]\n  if hvmem: scmd += ['-l', 'h_vmem=%s' % hvmem]\n\n  if gpumem: scmd += ['-l', 'gpumem=%s' % gpumem]\n\n  if io_big: scmd += ['-l', 'io_big']\n\n  if hostname: scmd += ['-l', 'hostname=%s' % hostname]\n\n  if pe_opt: scmd += ['-pe'] + pe_opt.split()\n\n  if cwd: scmd += ['-cwd']\n\n  if name: scmd += ['-N', name]\n\n  if deps: scmd += ['-hold_jid', ','.join(['%d' % k for k in deps])]\n\n  if stdout:\n\n    if not cwd:\n      # pivot, temporarily, to home directory\n      curdir = os.path.realpath(os.curdir)\n      os.chdir(os.environ['HOME'])\n\n    if not os.path.exists(stdout): makedirs_safe(stdout)\n\n    if not cwd:\n      # go back\n      os.chdir(os.path.realpath(curdir))\n\n    scmd += ['-o', stdout]\n\n  if stderr:\n    if not os.path.exists(stderr): makedirs_safe(stderr)\n    scmd += ['-e', stderr]\n  elif stdout: #just re-use the stdout settings\n    scmd += ['-e', stdout]\n\n  scmd += ['-terse'] # simplified job identifiers returned by the command line\n\n  for k in env: scmd += ['-v', k]\n\n  if array is not None:\n    scmd.append('-t')\n    if isinstance(array, six.string_types):\n      try:\n        i = int(array)\n        scmd.append('1-%d:1' % i)\n      except ValueError:\n        #must be complete...\n        scmd.append('%s' % array)\n    if isinstance(array, six.integer_types):\n      scmd.append('1-%d:1' % array)\n    if isinstance(array, (tuple, list)):\n      if len(array) < 1 or len(array) > 3:\n        raise RuntimeError(\"Array tuple should have length between 1 and 3\")\n      elif len(array) == 1:\n        scmd.append('%s' % array[0])\n      elif len(array) == 2:\n        scmd.append('%s-%s' % (array[0], array[1]))\n      elif len(array) == 3:\n        scmd.append('%s-%s:%s' % (array[0], array[1], array[2]))\n\n  if not isinstance(command, (list, tuple)): command = [command]\n  scmd += command\n\n  logger.debug(\"Qsub command '%s'\", ' '.join(scmd))\n\n  from .setshell import sexec\n  jobid = str_(sexec(context, scmd))\n  return int(jobid.split('.',1)[0])", "response": "Submits a command to a given queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef qstat(jobid, context='grid'):\n\n  scmd = ['qstat', '-j', '%d' % jobid, '-f']\n\n  logger.debug(\"Qstat command '%s'\", ' '.join(scmd))\n\n  from .setshell import sexec\n  data = str_(sexec(context, scmd, error_on_nonzero=False))\n\n  # some parsing:\n  retval = {}\n  for line in data.split('\\n'):\n    s = line.strip()\n    if s.lower().find('do not exist') != -1: return {}\n    if not s or s.find(10*'=') != -1: continue\n    kv = QSTAT_FIELD_SEPARATOR.split(s, 1)\n    if len(kv) == 2: retval[kv[0]] = kv[1]\n\n  return retval", "response": "Queries status of a given job."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhalt a given job.", "response": "def qdel(jobid, context='grid'):\n  \"\"\"Halts a given job.\n\n  Keyword parameters:\n\n  jobid\n    The job identifier as returned by qsub()\n\n  context\n    The setshell context in which we should try a 'qsub'. Normally you don't\n    need to change the default. This variable can also be set to a context\n    dictionary in which case we just setup using that context instead of\n    probing for a new one, what can be fast.\n  \"\"\"\n\n  scmd = ['qdel', '%d' % jobid]\n\n  logger.debug(\"Qdel command '%s'\", ' '.join(scmd))\n\n  from .setshell import sexec\n  sexec(context, scmd, error_on_nonzero=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the state of the node in the world.", "response": "def update_state(world):\n    \"\"\"\n    Increment the world state, determining which cells live, die, or appear.\n\n    Args:\n        world (list[list]): A square matrix of cells\n\n    Returns: None\n    \"\"\"\n\n    world_size = len(world)\n\n    def wrap(index):\n        \"\"\"Wrap an index around the other end of the array\"\"\"\n        return index % world_size\n\n    for x in range(world_size):\n        for y in range(world_size):\n            # Decide if this node cares about the rules right now\n            if not world[x][y].allow_change.get():\n                continue\n            live_neighbor_count = sum([\n                world[wrap(x)][wrap(y + 1)].value,\n                world[wrap(x + 1)][wrap(y + 1)].value,\n                world[wrap(x + 1)][wrap(y)].value,\n                world[wrap(x + 1)][wrap(y - 1)].value,\n                world[wrap(x)][wrap(y-1)].value,\n                world[wrap(x - 1)][wrap(y - 1)].value,\n                world[wrap(x - 1)][wrap(y)].value,\n                world[wrap(x - 1)][wrap(y + 1)].value\n            ])\n            if world[x][y].value:\n                # Any live cell with fewer than two live neighbours dies\n                # Any live cell with more than three live neighbours dies\n                # Any live cell with two or three live neighbours lives\n                if not (live_neighbor_count == 2 or live_neighbor_count == 3):\n                    world[x][y].value = False\n            else:\n                # Any dead cell with exactly three live neighbours comes alive\n                if live_neighbor_count == 3:\n                    world[x][y].value = True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef click_event(event):\n    grid_x_coord = int(divmod(event.x, cell_size)[0])\n    grid_y_coord = int(divmod(event.y, cell_size)[0])\n    world[grid_x_coord][grid_y_coord].value = True\n    color = world[x][y].color_alive.get_as_hex()\n    canvas.itemconfig(canvas_grid[grid_x_coord][grid_y_coord], fill=color)", "response": "On click bring the cell under the cursor to Life"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw_canvas():\n    for x in range(len(world)):\n        for y in range(len(world[x])):\n            if world[x][y].value:\n                color = world[x][y].color_alive.get_as_hex()\n            else:\n                color = world[x][y].color_dead.get_as_hex()\n            canvas.itemconfig(canvas_grid[x][y], fill=color)", "response": "Render the tkinter canvas based on the state of world"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef div(p, q):\n\n        from math import copysign\n\n        if q != 0.0:\n            # Normal case, no infinities.\n            return p / q\n        elif p == 0.0:\n            return p / q  # Doesn't return, raises an Exception.\n        elif copysign(1, q) > 0:\n            # q is +0.0, return inf with same sign as p.\n            return copysign(inf, p)\n        else:\n            # q is -0.0, return inf with flipped sign.\n            return copysign(inf, -p)", "response": "Returns the correct infinity instead of the correct infinity."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _make_context(context=None):\n    namespace = {'db': db, 'session': db.session}\n    namespace.update(_iter_context())\n\n    if context is not None:\n        namespace.update(context)\n\n    return namespace", "response": "Create the namespace of items already pre - imported when using shell."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize the specified names in the specified databases.", "response": "def init(**kwargs):\n    \"\"\"Initialize the specified names in the specified databases.\n\n    The general process is as follows:\n      - Ensure the database in question exists\n      - Ensure all tables exist in the database.\n    \"\"\"\n\n    # TODO: Iterate through all engines in name set.\n    database = kwargs.pop('database', False)\n    if database and not database_exists(engine['default'].url):\n        create_database(engine['default'].url, encoding='utf8')\n        clear_cache()\n\n    expression = lambda target, table: table.create(target)\n    test = lambda target, table: table.exists(target)\n    op(expression, test=test, primary='init', secondary='create', **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clear(**kwargs):\n\n    database = kwargs.pop('database', False)\n    expression = lambda target, table: table.drop(target)\n    test = lambda x, tab: not database_exists(x.url) or not tab.exists(x)\n\n    # TODO: Iterate through all engines in name set.\n    if database and database_exists(engine['default'].url):\n        drop_database(engine['default'].url)\n        clear_cache()\n\n    op(expression, reversed(metadata.sorted_tables), test=test,\n       primary='clear', secondary='drop', **kwargs)", "response": "Clear the specified names from the specified databases."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef flush(**kwargs):\n\n    expression = lambda target, table: target.execute(table.delete())\n    test = lambda target, table: not table.exists(target)\n    op(expression, reversed(metadata.sorted_tables), test=test,\n       primary='flush', secondary='flush', **kwargs)", "response": "Flush the specified names from the specified databases."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_table_included(table, names):\n\n    # No names indicates that every table is included.\n    if not names:\n        return True\n\n    # Introspect the table and pull out the model and component from it.\n    model, component = table.class_, table.class_._component\n\n    # Check for the component name.\n    if component in names:\n        return True\n\n    # Check for the full python name.\n    model_name = '%s.%s' % (model.__module__, model.__name__)\n    if model_name in names:\n        return True\n\n    # Check for the short name.\n    short_name = '%s:%s' % (component, model.__name__)\n    if short_name in names:\n        return True\n\n    return False", "response": "Determines if a table is included by reference in the names."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef autocomplete():\n    # Don't complete if user hasn't sourced bash_completion file.\n    if 'PIP_AUTO_COMPLETE' not in os.environ:\n        return\n    cwords = os.environ['COMP_WORDS'].split()[1:]\n    cword = int(os.environ['COMP_CWORD'])\n    try:\n        current = cwords[cword-1]\n    except IndexError:\n        current = ''\n    load_all_commands()\n    subcommands = [cmd for cmd, cls in command_dict.items() if not cls.hidden]\n    options = []\n    # subcommand\n    try:\n        subcommand_name = [w for w in cwords if w in subcommands][0]\n    except IndexError:\n        subcommand_name = None\n    # subcommand options\n    if subcommand_name:\n        # special case: 'help' subcommand has no options\n        if subcommand_name == 'help':\n            sys.exit(1)\n        # special case: list locally installed dists for uninstall command\n        if subcommand_name == 'uninstall' and not current.startswith('-'):\n            installed = []\n            lc = current.lower()\n            for dist in get_installed_distributions(local_only=True):\n                if dist.key.startswith(lc) and dist.key not in cwords[1:]:\n                    installed.append(dist.key)\n            # if there are no dists installed, fall back to option completion\n            if installed:\n                for dist in installed:\n                    print(dist)\n                sys.exit(1)\n        subcommand = command_dict.get(subcommand_name)\n        options += [(opt.get_opt_string(), opt.nargs)\n                    for opt in subcommand.parser.option_list\n                    if opt.help != optparse.SUPPRESS_HELP]\n        # filter out previously specified options from available options\n        prev_opts = [x.split('=')[0] for x in cwords[1:cword-1]]\n        options = [(x, v) for (x, v) in options if x not in prev_opts]\n        # filter options by current input\n        options = [(k, v) for k, v in options if k.startswith(current)]\n        for option in options:\n            opt_label = option[0]\n            # append '=' to options which require args\n            if option[1]:\n                opt_label += '='\n            print(opt_label)\n    else:\n        # show options of main parser only when necessary\n        if current.startswith('-') or current.startswith('--'):\n            subcommands += [opt.get_opt_string()\n                            for opt in parser.option_list\n                            if opt.help != optparse.SUPPRESS_HELP]\n        print(' '.join([x for x in subcommands if x.startswith(current)]))\n    sys.exit(1)", "response": "Autocomplete for the current command and its subcommands and options."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef secret_loader(self, callback):\n        if not callback or not callable(callback):\n            raise Exception(\"Please pass in a callable that loads secret keys\")\n        self.secret_loader_callback = callback\n        return callback", "response": "Decorate a method that receives a key id and returns a secret key"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecorating a method that receives a key id and returns an object or dict that will be available in the request context as g. cavage_context", "response": "def context_loader(self, callback):\n        \"\"\"\n        Decorate a method that receives a key id and returns an object or dict\n        that will be available in the request context as g.cavage_context\n        \"\"\"\n        if not callback or not callable(callback):\n            raise Exception(\"Please pass in a callable that loads your context.\")\n        self.context_loader_callback = callback\n        return callback"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef replay_checker(self, callback):\n        if not callback or not callable(callback):\n            raise Exception(\"Please pass in a callable that protects against replays\")\n        self.replay_checker_callback = callback\n        return callback", "response": "Decorate a method that receives the request headers and returns a bool\n        indicating whether we should proceed with the request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the response from the server and return a dict of the items.", "response": "def parse(self, response):\n        \"\"\"\n        \u4ece self.data \u4e2d\u5c06\u6587\u7ae0\u4fe1\u606f\u683c\u5f0f\u5316\u4e3a :class:`.MoearPackageMobiItem`\n        \"\"\"\n        # \u5de5\u4f5c&\u8f93\u51fa\u8def\u5f84\n        self.template_dir = self.settings.get('TEMPLATE_DIR')\n        shutil.rmtree(\n            self.settings.get('BUILD_SOURCE_DIR'), ignore_errors=True)\n        self.build_source_dir = utils.mkdirp(\n            self.settings.get('BUILD_SOURCE_DIR'))\n\n        # \u83b7\u53d6Post\u6a21\u677f\u5bf9\u8c61\n        template_post_path = os.path.join(self.template_dir, 'post.html')\n        with open(template_post_path, 'r') as f:\n            self.template_post = Template(f.read())\n\n        self._logger.info('\u6784\u5efa\u5904\u7406\u8def\u5f84 => {0}'.format(self.build_source_dir))\n\n        image_filter = self.options.get('image_filter', '')\n        common_image_filter = self.options.get('common_image_filter', [])\n        for sections in self.data.values():\n            for p in sections:\n                item = MoearPackageMobiItem()\n                pmeta = p.get('meta', {})\n                item['url'] = p.get('origin_url', '')\n                item['title'] = p.get('title', '')\n                item['cover_image'] = pmeta.get('moear.cover_image_slug')\n                item['content'] = p.get('content', '')\n\n                # \u4e3a\u56fe\u7247\u6301\u4e45\u5316pipeline\u6267\u884c\u505a\u6570\u636e\u51c6\u5907\n                item['image_urls'] = [item['cover_image']] \\\n                    if item['cover_image'] is not None else []\n                item['image_urls'] += \\\n                    self._populated_image_urls_with_content(item['content'])\n                self._logger.debug(\n                    '\u5f85\u5904\u7406\u7684\u56fe\u7247url(\u8fc7\u6ee4\u524d): {}'.format(item['image_urls']))\n                item['image_urls'], item['image_urls_removed'] = \\\n                    self.filter_images_urls(\n                        item['image_urls'], image_filter, common_image_filter)\n                self._logger.debug(\n                    '\u5f85\u5904\u7406\u7684\u56fe\u7247url: {}'.format(item['image_urls']))\n\n                yield item"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfilters images by their URL.", "response": "def filter_images_urls(image_urls, image_filter, common_image_filter=None):\n        '''\n        \u56fe\u7247\u94fe\u63a5\u8fc7\u6ee4\u5668\uff0c\u6839\u636e\u4f20\u5165\u7684\u8fc7\u6ee4\u5668\u89c4\u5219\uff0c\u5bf9\u56fe\u7247\u94fe\u63a5\u5217\u8868\u8fdb\u884c\u8fc7\u6ee4\u5e76\u8fd4\u56de\u7ed3\u679c\u5217\u8868\n\n        :param list(str) image_urls: \u56fe\u7247\u94fe\u63a5\u5b57\u4e32\u5217\u8868\n        :param list(str) image_filter: \u8fc7\u6ee4\u5668\u5b57\u4e32\u5217\u8868\n        :param list(str) common_image_filter: \u53ef\u9009\uff0c\u901a\u7528\u7684\u57fa\u7840\u8fc7\u6ee4\u5668\uff0c\n            \u4f1a\u5728\u5b9a\u5236\u8fc7\u6ee4\u5668\u524d\u5bf9\u4f20\u5165\u56fe\u7247\u5e94\u7528\n        :return: \u8fc7\u6ee4\u540e\u7684\u7ed3\u679c\u94fe\u63a5\u5217\u8868\uff0c\u4ee5\u53ca\u88ab\u8fc7\u6ee4\u6389\u7684\u94fe\u63a5\u5217\u8868\n        :rtype: list(str), list(str)\n        :raises TypeError: image_filter \u4e0d\u4e3a\u5b57\u4e32\u6216\u5217\u8868\n        :raises ValueError: image_filter \u4e2d\u5b58\u5728\u7a7a\u503c\n        '''\n        common_image_filter = common_image_filter or []\n\n        # \u5bf9\u56fe\u7247\u8fc7\u6ee4\u5668\u8fdb\u884c\u5b8c\u6574\u6027\u9a8c\u8bc1\n        image_filter = json.loads(image_filter, encoding='utf-8')\n        if not isinstance(image_filter, (str, list)):\n            raise TypeError('image_filter not str or list')\n        if isinstance(image_filter, str):\n            image_filter = [image_filter]\n        if not all(image_filter):\n            raise ValueError('image_filter \u4e2d\u5b58\u5728\u7a7a\u503c\uff1a{}'.format(image_filter))\n\n        rc = copy.deepcopy(image_urls)\n        rc_removed = []\n        for i in image_urls:\n            # \u6267\u884c\u5185\u7f6e\u8fc7\u6ee4\u5668\n            for f in common_image_filter:\n                if re.search(f, i):\n                    rc.remove(i)\n                    rc_removed.append(i)\n\n            # \u6267\u884c\u5177\u4f53\u6587\u7ae0\u6e90\u7684\u5b9a\u5236\u8fc7\u6ee4\u5668\n            for f in image_filter:\n                if re.search(f, i):\n                    rc.remove(i)\n                    rc_removed.append(i)\n        return rc, rc_removed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a mobi file from the Knockout.", "response": "def generate_mobi_file(self):\n        '''\n        \u4f7f\u7528 :mod:`subprocess` \u6a21\u5757\u8c03\u7528 ``KindleGen`` \u5de5\u5177\uff0c\n        \u5c06\u5df2\u51c6\u5907\u597d\u7684\u4e66\u7c4d\u6e90\u6587\u4ef6\u7f16\u8bd1\u751f\u6210 ``mobi`` \u6587\u4ef6\n        '''\n        opf_file = os.path.join(self.build_source_dir, 'moear.opf')\n        command_list = [self.kg, opf_file]\n        output = subprocess.Popen(\n            command_list, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n            shell=False).communicate()\n        self._logger.info('\u751f\u6210\u547d\u4ee4: {}'.format(' '.join(command_list)))\n        self._logger.info('\u751f\u6210 mobi : {}'.format(\n            output[0].decode()))\n        if output[1]:\n            self._logger.error(output[1].decode())\n            raise IOError('KindleGen\u8f6c\u6362\u5931\u8d25: {}'.format(output[1]))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall when the connection is closed.", "response": "def closed(self, reason):\n        '''\n        \u5f02\u6b65\u722c\u53d6\u672c\u5730\u5316\u5904\u7406\u5b8c\u6210\u540e\uff0c\u4f7f\u7528\u7ed3\u679c\u6570\u636e\uff0c\u8fdb\u884c\u8f93\u51fa\u6587\u4ef6\u7684\u6e32\u67d3\uff0c\u6e32\u67d3\u5b8c\u6bd5\uff0c\n        \u8c03\u7528 :meth:`.MobiSpider.generate_mobi_file` \u65b9\u6cd5\uff0c\u751f\u6210\u76ee\u6807 ``mobi`` \u6587\u4ef6\n        '''\n        # \u62f7\u8d1d\u5c01\u9762&\u62a5\u5934\u56fe\u7247\u6587\u4ef6\n        utils.mkdirp(os.path.join(self.build_source_dir, 'images'))\n        self._logger.info(self.options)\n        shutil.copy(\n            self.options.get('img_cover'),\n            os.path.join(self.build_source_dir, 'images', 'cover.jpg'))\n        shutil.copy(\n            self.options.get('img_masthead'),\n            os.path.join(self.build_source_dir, 'images', 'masthead.gif'))\n\n        # \u62f7\u8d1dcss\u6587\u4ef6\n        css_base_path = self.options.get('css_base')\n        css_package_path = self.options.get('css_package')\n        css_extra = self.options.get('extra_css', '')\n        css_output_dir = os.path.join(self.build_source_dir, 'css')\n        utils.mkdirp(css_output_dir)\n        if css_base_path:\n            shutil.copy(\n                css_base_path,\n                os.path.join(css_output_dir, 'base.css'))\n        if css_package_path:\n            shutil.copy(\n                css_package_path,\n                os.path.join(css_output_dir, 'package.css'))\n        if css_extra:\n            with codecs.open(\n                    os.path.join(css_output_dir, 'custom.css'),\n                    'wb', 'utf-8') as fh:\n                fh.write(css_extra)\n\n        # \u62f7\u8d1dicons\u8def\u5f84\u6587\u4ef6\n        icons_path = self.options.get('icons_path')\n        icons_output_dir = os.path.join(self.build_source_dir, 'icons')\n        shutil.rmtree(icons_output_dir, ignore_errors=True)\n        if icons_path:\n            shutil.copytree(icons_path, icons_output_dir)\n\n        # \u83b7\u53d6content\u6a21\u677f\u5bf9\u8c61\n        template_content_path = os.path.join(\n            self.template_dir, 'OEBPS', 'content.opf')\n        with open(template_content_path, 'r') as fh:\n            template_content = Template(fh.read())\n\n        # \u6e32\u67d3content\u76ee\u6807\u6587\u4ef6\n        content_path = os.path.join(self.build_source_dir, 'moear.opf')\n        with codecs.open(content_path, 'wb', 'utf-8') as fh:\n            fh.write(template_content.render(\n                data=self.data,\n                spider=self.spider,\n                options=self.options))\n\n        # \u83b7\u53d6toc.ncx\u6a21\u677f\u5bf9\u8c61\n        template_toc_path = os.path.join(\n            self.template_dir, 'OEBPS', 'toc.ncx')\n        with open(template_toc_path, 'r') as fh:\n            template_toc = Template(fh.read())\n\n        # \u6e32\u67d3toc.ncx\u76ee\u6807\u6587\u4ef6\n        toc_path = os.path.join(self.build_source_dir, 'misc', 'toc.ncx')\n        utils.mkdirp(os.path.dirname(toc_path))\n        with codecs.open(toc_path, 'wb', 'utf-8') as fh:\n            fh.write(template_toc.render(\n                data=self.data,\n                spider=self.spider,\n                options=self.options))\n\n        # \u83b7\u53d6toc.html\u6a21\u677f\u5bf9\u8c61\n        template_toc_path = os.path.join(\n            self.template_dir, 'OEBPS', 'toc.html')\n        with open(template_toc_path, 'r') as fh:\n            template_toc = Template(fh.read())\n\n        # \u6e32\u67d3toc.html\u76ee\u6807\u6587\u4ef6\n        toc_path = os.path.join(self.build_source_dir, 'html', 'toc.html')\n        utils.mkdirp(os.path.dirname(toc_path))\n        with codecs.open(toc_path, 'wb', 'utf-8') as fh:\n            fh.write(template_toc.render(\n                data=self.data,\n                options=self.options))\n\n        # \u751f\u6210mobi\u6587\u4ef6\u5230mobi_dir\n        self.generate_mobi_file()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating all the neccessary icons from source image", "response": "def makeicons(source):\n    \"\"\"\n    Create all the neccessary icons from source image\n    \"\"\"\n    im = Image.open(source)\n    for name, (_, w, h, func) in icon_sizes.iteritems():\n        print('Making icon %s...' % name)\n        tn = func(im, (w, h))\n        bg = Image.new('RGBA', (w, h), (255, 255, 255))\n        x = (w / 2) - (tn.size[0] / 2)\n        y = (h / 2) - (tn.size[1] / 2)\n        bg.paste(tn, (x, y))\n\n        bg.save(path.join(env.dir, name))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping the content of the given ElementBase object to a string", "response": "def dump_element(element):\n    \"\"\"\n    Dumps the content of the given ElementBase object to a string\n\n    :param element: An ElementBase object\n    :return: A full description of its content\n    :raise TypeError: Invalid object\n    \"\"\"\n    # Check type\n    try:\n        assert isinstance(element, sleekxmpp.ElementBase)\n    except AssertionError:\n        raise TypeError(\"Not an ElementBase: {0}\".format(type(element)))\n\n    # Prepare string\n    output = StringIO()\n    output.write(\"ElementBase : {0}\\n\".format(type(element)))\n    output.write(\"- name......: {0}\\n\".format(element.name))\n    output.write(\"- namespace.: {0}\\n\".format(element.namespace))\n\n    output.write(\"- interfaces:\\n\")\n    for itf in sorted(element.interfaces):\n        output.write(\"\\t- {0}: {1}\\n\".format(itf, element[itf]))\n\n    if element.sub_interfaces:\n        output.write(\"- sub-interfaces:\\n\")\n        for itf in sorted(element.sub_interfaces):\n            output.write(\"\\t- {0}: {1}\\n\".format(itf, element[itf]))\n\n    return output.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new room with the given parameters.", "response": "def create_room(self, room, service, nick, config=None,\n                    callback=None, errback=None, room_jid=None):\n        \"\"\"\n        Prepares the creation of a room.\n\n        The callback is a method with two arguments:\n          - room: Bare JID of the room\n          - nick: Nick used to create the room\n\n        The errback is a method with 4 arguments:\n          - room: Bare JID of the room\n          - nick: Nick used to create the room\n          - condition: error category (XMPP specification or \"not-owner\")\n          - text: description of the error\n\n\n        :param room: Name of the room\n        :param service: Name of the XMPP MUC service\n        :param config: Configuration of the room\n        :param callback: Method called back on success\n        :param errback: Method called on error\n        :param room_jid: Forced room JID\n        \"\"\"\n        self.__logger.debug(\"Creating room: %s\", room)\n\n        with self.__lock:\n            if not room_jid:\n                # Generate/Format the room JID if not given\n                room_jid = sleekxmpp.JID(local=room, domain=service).bare\n\n            self.__logger.debug(\"... Room JID: %s\", room_jid)\n\n            if not self.__rooms:\n                # First room to create: register to events\n                self.__xmpp.add_event_handler(\"presence\", self.__on_presence)\n\n            # Store information\n            self.__rooms[room_jid] = RoomData(room_jid, nick, config,\n                                              callback, errback)\n\n        # Send the presence, i.e. request creation of the room\n        self.__muc.joinMUC(room_jid, nick)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __safe_callback(self, room_data):\n        method = room_data.callback\n        if method is not None:\n            try:\n                method(room_data.room, room_data.nick)\n            except Exception as ex:\n                self.__logger.exception(\"Error calling back room creator: %s\",\n                                        ex)", "response": "Safe use of the callback method to avoid errors propagation\n                                       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsafe use of the callback method to avoid errors propagation", "response": "def __safe_errback(self, room_data, err_condition, err_text):\n        \"\"\"\n        Safe use of the callback method, to avoid errors propagation\n\n        :param room_data: A RoomData object\n        :param err_condition: Category of error\n        :param err_text: Description of the error\n        \"\"\"\n        method = room_data.errback\n        if method is not None:\n            try:\n                method(room_data.room, room_data.nick, err_condition, err_text)\n            except Exception as ex:\n                self.__logger.exception(\"Error calling back room creator: %s\",\n                                        ex)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a presence stanza", "response": "def __on_presence(self, data):\n        \"\"\"\n        Got a presence stanza\n        \"\"\"\n        room_jid = data['from'].bare\n        muc_presence = data['muc']\n        room = muc_presence['room']\n        nick = muc_presence['nick']\n\n        with self.__lock:\n            try:\n                # Get room state machine\n                room_data = self.__rooms[room]\n                if room_data.nick != nick:\n                    # Not about the room creator\n                    return\n            except KeyError:\n                # Unknown room (or not a room)\n                return\n            else:\n                # Clean up, as we got what we wanted\n                del self.__rooms[room]\n\n            if not self.__rooms:\n                # No more rooms: no need to listen to presence anymore\n                self.__xmpp.del_event_handler(\"presence\", self.__on_presence)\n\n        if data['type'] == 'error':\n            # Got an error: update the state machine and clean up\n            self.__safe_errback(room_data, data['error']['condition'],\n                                data['error']['text'])\n\n        elif muc_presence['affiliation'] != 'owner':\n            # We are not the owner the room: consider it an error\n            self.__safe_errback(room_data, 'not-owner',\n                                'We are not the owner of the room')\n\n        else:\n            # Success: we own the room\n            # Setup room configuration\n            try:\n                config = self.__muc.getRoomConfig(room_jid)\n            except ValueError:\n                # Can't differentiate IQ errors from a \"no configuration\"\n                # result: consider it OK\n                self.__logger.warning(\"Can't get the configuration form for \"\n                                      \"XMPP room %s\", room_jid)\n                self.__safe_callback(room_data)\n            else:\n                # Prepare our configuration\n                custom_values = room_data.configuration or {}\n\n                # Filter options that are not known from the server\n                known_fields = config['fields']\n                to_remove = [key for key in custom_values\n                             if key not in known_fields]\n                for key in to_remove:\n                    del custom_values[key]\n\n                # Send configuration (use a new form to avoid OpenFire to have\n                # an internal error)\n                form = self.__xmpp['xep_0004'].make_form(\"submit\")\n                form['values'] = custom_values\n                self.__muc.setRoomConfig(room_jid, form)\n\n                # Call back the creator\n                self.__safe_callback(room_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __call(self):\n        try:\n            if self.__callback is not None:\n                self.__callback(self.__successes, self.__errors)\n        except Exception as ex:\n            self.__logger.exception(\"Error calling back count down \"\n                                    \"handler: %s\", ex)\n        else:\n            self.__called = True", "response": "Calls the callback method that is called when the count down occurs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __mark(self, element, mark_set):\n        try:\n            # The given element can be of a different type than the original\n            # one (JID instead of str, ...), so we retrieve the original one\n            original = self.__elements.pop(element)\n            mark_set.add(original)\n        except KeyError:\n            return False\n        else:\n            if not self.__elements:\n                # No more elements to wait for\n                self.__call()\n            return True", "response": "Mark an element in the set"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_refresh(self,args):\n        pprint(AwsConnectionFactory.getEc2Client().describe_network_interfaces(NetworkInterfaceIds=[self.physicalId]));", "response": "Refresh the view of the eni"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\naccessing the parent templates block. {% super name %}", "response": "def do_super(parser, token):\n    '''\n    Access the parent templates block.\n\n    {% super name %}\n    '''\n    name = token.strip()\n    return ast.YieldFrom(\n        value=_a.Call(_a.Attribute(_a.Call(_a.Name('super')), name), [\n            # _a.Attribute(_a.Name('context'), 'parent'),\n            _a.Name('context'),\n        ])\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_with_scope(body, kwargs):\n    '''\n    Helper function to wrap a block in a scope stack:\n\n    with ContextScope(context, **kwargs) as context:\n        ... body ...\n    '''\n    return ast.With(\n        items=[\n            ast.withitem(\n                context_expr=_a.Call(\n                    _a.Name('ContextScope'),\n                    [_a.Name('context')],\n                    keywords=kwargs,\n                ),\n                optional_vars=_a.Name('context', ctx=ast.Store())\n            ),\n        ],\n        body=body,\n    )", "response": "Helper function to wrap a block in a scope stack"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_for(parser, token):\n    '''\n    {% for a, b, c in iterable %}\n\n    {% endfor %}\n\n    We create the structure:\n\n    with ContextWrapper(context) as context:\n        for a, b, c in iterable:\n            context.update(a=a, b=b, c=c)\n            ...\n\n    If there is a {% empty %} clause, we create:\n\n    if iterable:\n        { above code }\n    else:\n        { empty clause }\n    '''\n    code = ast.parse('for %s: pass' % token, mode='exec')\n\n    # Grab the ast.For node\n    loop = code.body[0]\n    # Wrap its source iterable\n    loop.iter = visitor.visit(loop.iter)\n\n    # Get the body of the loop\n    body, end = parser.parse_nodes_until('endfor', 'empty')\n\n    # Build a list of target variable names\n    if isinstance(loop.target, ast.Tuple):\n        targets = [elt.id for elt in loop.target.elts]\n    else:\n        targets = [loop.target.id]\n\n    kwargs = [\n        ast.keyword(arg=elt, value=_a.Name(elt))\n        for elt in targets\n    ]\n\n    # Insert our update call at the start of the loop body\n    body.insert(0, ast.Expr(value=_a.Call(\n        _a.Attribute(_a.Name('context'), 'update'),\n        keywords=kwargs\n    )))\n    loop.body = body\n\n    node = _create_with_scope([loop], [])\n\n    if end == 'empty':\n        # Now we wrap our for block in:\n        # if loop.iter:\n        # else:\n        empty, _ = parser.parse_nodes_until('endfor')\n\n        node = ast.If(\n            test=loop.iter,\n            body=[node],\n            orelse=empty\n        )\n\n    return node", "response": "{% for a, b, c in iterable %}\n\n    {% endfor %}\n\n    We create the structure:\n\n    with ContextWrapper(context) as context:\n        for a, b, c in iterable:\n            context.update(a=a, b=b, c=c)\n            ...\n\n    If there is a {% empty %} clause, we create:\n\n    if iterable:\n        { above code }\n    else:\n        { empty clause }"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef macro(parser, token):\n    '''\n    Works just like block, but does not render.\n    '''\n    name = token.strip()\n    parser.build_method(name, endnodes=['endmacro'])\n    return ast.Yield(value=ast.Str(s=''))", "response": "A macro that returns a sequence of tokens."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute the given method and stores its result in the object.", "response": "def execute(self, method, args, kwargs):\n        \"\"\"\n        Execute the given method and stores its result.\n        The result is considered \"done\" even if the method raises an exception\n\n        :param method: The method to execute\n        :param args: Method positional arguments\n        :param kwargs: Method keyword arguments\n        :raise Exception: The exception raised by the method\n        \"\"\"\n        # Normalize arguments\n        if args is None:\n            args = []\n\n        if kwargs is None:\n            kwargs = {}\n\n        try:\n            # Call the method\n            self._result = method(*args, **kwargs)\n\n        except Exception as ex:\n            self._exception = ex\n            raise\n\n        finally:\n            # Mark the action as executed\n            self._done_event.set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwaiting up to timeout for the result of the threaded job. Returns immediately the result if the job has already been done.", "response": "def result(self, timeout=None):\n        \"\"\"\n        Waits up to timeout for the result the threaded job.\n        Returns immediately the result if the job has already been done.\n\n        :param timeout: The maximum time to wait for a result (in seconds)\n        :raise OSError: The timeout raised before the job finished\n        :raise Exception: Raises the exception that occurred executing\n                          the method\n        \"\"\"\n        if self._done_event.wait(timeout) or self._done_event.is_set():\n            if self._exception is not None:\n                raise self._exception\n\n            return self._result\n\n        raise OSError(\"Timeout raised\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a link to the peer if it exists otherwise None.", "response": "def get_link(self, peer):\n        \"\"\"\n        Retrieves a link to the peer\n\n        :param peer: A Peer description\n        :return: A link to the peer, None if none available\n        \"\"\"\n        assert isinstance(peer, Peer)\n\n        for protocol in self._protocols:\n            try:\n                # Try to get a link\n                return protocol.get_link(peer)\n\n            except ValueError:\n                # Peer can't be handled by this protocol\n                pass\n\n        # No link found\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a message to the cache.", "response": "def send(self, message):\n        \"\"\"\n        Sends a message (synchronous)\n\n        :param message: Message to send\n        :return: Message response(s)\n        \"\"\"\n        future = self.post(message)\n        future.join()\n        return future.result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolve_composed_functions(data, recursive=True):\n\n    if isinstance(data, ComposedFunction):\n        data = data()\n\n    if recursive:\n        if isinstance(data, dict):\n            for key, value in data.items():\n                data[key] = resolve_composed_functions(\n                    value,\n                    recursive=recursive,\n                )\n        elif isinstance(data, (list, tuple, set)):\n            for index, value in enumerate(data):\n                data[index] = resolve_composed_functions(\n                    value,\n                    recursive=recursive,\n                )\n\n    return data", "response": "Resolves all ComposedFunction s and returns its return value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite metadata to the active archive.", "response": "def write(self, metadata, payload):\n        \"\"\"Write metadata\n\n        metadata is string:string dict.\n        payload must be encoded as string.\n        \"\"\"\n        a = self.get_active_archive()\n        a.write(metadata, payload)\n        if self._should_roll_archive():\n            self._roll_archive()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def main():\n    # Create Client from endpoint string in Duniter format\n    client = Client(BMAS_ENDPOINT)\n\n    # Get the node summary infos by dedicated method (with json schema validation)\n    print(\"\\nCall bma.node.summary:\")\n    response = await client(bma.node.summary)\n    print(response)\n\n    # Get the money parameters located in the first block\n    print(\"\\nCall bma.blockchain.parameters:\")\n    response = await client(bma.blockchain.parameters)\n    print(response)\n\n    # Get the current block\n    print(\"\\nCall bma.blockchain.current:\")\n    response = await client(bma.blockchain.current)\n    print(response)\n\n    # Get the block number 10\n    print(\"\\nCall bma.blockchain.block(10):\")\n    response = await client(bma.blockchain.block, 10)\n    print(response)\n\n    # jsonschema validator\n    summary_schema = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"duniter\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"software\": {\n                        \"type\": \"string\"\n                    },\n                    \"version\": {\n                        \"type\": \"string\",\n                    },\n                    \"forkWindowSize\": {\n                        \"type\": \"number\"\n                    }\n                },\n                \"required\": [\"software\", \"version\"]\n            },\n        },\n        \"required\": [\"duniter\"]\n    }\n\n    # Get the node summary infos (direct REST GET request)\n    print(\"\\nCall direct get on node/summary\")\n    response = await client.get('node/summary', rtype=RESPONSE_AIOHTTP, schema=summary_schema)\n    print(response)\n\n    # Close client aiohttp session\n    await client.close()", "response": "Main function for the Duniter blockchain API"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef might_prefer(self, **items):\n        '''Items to take precedence if their values are not None (never saved)'''\n        self._overrides = dict((k, v) for (k, v) in items.items() if v is not None)", "response": "Items to take precedence if their values are not None ( never saved )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsynchronizes current set of key values in this instance with those in the config.", "response": "def sync_with(self, config, conflict_resolver):\n        '''Synchronizes current set of key/values in this instance with those in the config.'''\n        if not config.has_section(self._name):\n            config.add_section(self._name)\n        resolved = self._sync_and_resolve(config, conflict_resolver)\n        self._add_new_items(config, resolved)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsynchronizing all items represented by the config according to the resolver and return a set of keys that have been resolved.", "response": "def _sync_and_resolve(self, config, resolver):\n        '''Synchronize all items represented by the config according to the resolver and return a\n        set of keys that have been resolved.'''\n        resolved = set()\n        for key, theirs in config.items(self._name):\n            theirs = self._real_value_of(theirs)\n            if key in self:\n                mine = self[key]\n                value = resolver(self._name, key, mine, theirs)\n            else:\n                value = theirs\n            self._set_value(config, key, value)\n            resolved.add(key)\n        return resolved"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _add_new_items(self, config, seen):\n        '''Add new (unseen) items to the config.'''\n        for (key, value) in self.items():\n            if key not in seen:\n                self._set_value(config, key, value)", "response": "Add new items to the config."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef upload(self, baseurl, filename):\n        # Prof is really dirty, we need to re-get the project page before upload\n        payload = {\n            'id_projet': self.field\n        }\n        prof_session.post(baseurl+\"/main.php\", params=payload)\n        # We also need to get the upload page...\n        payload = {\n            'id': int(self.work_id)\n        }\n        prof_session.get(baseurl+\"/upload.php\", params=payload)\n        # Finally we can actually send\n        payload = {\n            'MAX_FILE_SIZE': 1000000\n        }\n        prof_session.post(baseurl+'/upload2.php', files={'fichier1': open(filename, 'rb')}, params=payload)", "response": "Upload a file to this work"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads all non - abstract classes from package", "response": "def get_all_classes(module_name):\n    \"\"\"Load all non-abstract classes from package\"\"\"\n    module = importlib.import_module(module_name)\n    return getmembers(module, lambda m: isclass(m) and not isabstract(m))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, table_name):\n        assert table_name in self.tabs, \\\n            \"Table not avaiable. Avaiable tables: {}\".format(\n                \", \".join(self.tabs.keys())\n            )\n        return self.tabs[table_name]", "response": "Load table class by name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update_sys_path(self, package_path=None):\n        self.package_path = package_path\n        if not self.package_path in sys.path:\n            sys.path.append(self.package_path)", "response": "Updates and adds current directory to sys. path if not already present."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_tabs(self, custom_table_classes=None):\n        for module_name in get_all_modules(self.package_path):\n            for name, _type in get_all_classes(module_name):\n                # pylint: disable=W0640\n                subclasses = [Table] + (custom_table_classes or list())\n                iss_subclass = map(lambda c: issubclass(_type, c), subclasses)\n                if isclass(_type) and any(iss_subclass):\n                    self.tabs.update([[name, _type]])", "response": "Finds all classes that are subcalss of Table and loads them into\n         a dictionary named tables."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef describe_all(self, full=False):\n        for table in self.tabs:\n            yield self.tabs[table]().describe(full)", "response": "Prints description of all tables registered with the Ironic API."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _connect(self):\n        if self._connection is not None:\n            raise RuntimeError('Close connection first.')\n        self._connection = connect(self._database, **self._kwds)\n        self._connection.isolation_level = None", "response": "Connect to the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding arguments for this command.", "response": "def add_argparser(self, root, parents):\n        \"\"\"\n        Add arguments for this command.\n        \"\"\"\n        parser = root.add_parser('diff', parents=parents)\n        parser.set_defaults(func=self)\n\n        parser.add_argument(\n            '--secrets',\n            dest='secrets', action='store',\n            help='Path to the authorization secrets file (client_secrets.json).'\n        )\n\n        parser.add_argument(\n            '-d', '--data',\n            dest='data_path', action='store', default=None,\n            help='Path to a existing JSON diff file.'\n        )\n\n        parser.add_argument(\n           'report_a_path',\n            action='store',\n            help='Path to a JSON file containing the initial report data.'\n        )\n\n        parser.add_argument(\n           'report_b_path',\n            action='store',\n            help='Path to a JSON file containing the report data to compare.'\n        )\n\n        parser.add_argument(\n            'output_path',\n            action='store',\n            help='Path to output either an HTML report or a JSON data file.'\n        )\n\n        return parser"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef diff(self, report_a, report_b):\n        arguments = GLOBAL_ARGUMENTS + ['run_date']\n\n        output = OrderedDict([\n            ('a', OrderedDict([(arg, report_a[arg]) for arg in arguments])),\n            ('b', OrderedDict([(arg, report_b[arg]) for arg in arguments])),\n            ('queries', [])\n        ])\n\n        output['a']\n\n        for query_a in report_a['queries']:\n            for query_b in report_b['queries']:\n                if query_a['config'] == query_b['config']:\n                    diff = OrderedDict()\n\n                    diff['config'] = query_a['config']\n                    diff['data_types'] = query_a['data_types']\n                    diff['data'] = OrderedDict()\n\n                    for metric, values in query_a['data'].items():\n                        data_type = diff['data_types'][metric]\n                        diff['data'][metric] = OrderedDict()\n\n                        total_a = values['total']\n                        total_b = query_b['data'][metric]['total']\n\n                        for label, value in values.items():\n                            a = value\n                            \n                            try:\n                                b = query_b['data'][metric][label]\n                            # TODO: hack for when labels are different...\n                            except KeyError:\n                                continue\n\n                            change = b - a\n                            percent_change = float(change) / a if a > 0 else None\n                            \n                            percent_a = float(a) / total_a if total_a > 0 else None\n                            percent_b = float(b) / total_b if total_b > 0 else None\n\n                            if label == 'total' or data_type == 'TIME' or percent_a is None or percent_b is None:\n                                point_change = None\n                            else:\n                                point_change = percent_b - percent_a\n\n                            diff['data'][metric][label] = OrderedDict([\n                                ('change', change),\n                                ('percent_change', percent_change),\n                                ('point_change', point_change),\n                            ])\n\n                    output['queries'].append(diff)\n\n            query_b = report_b['queries']\n\n        return output", "response": "Generate a diff between two data reports."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef txt(self, diff, f):\n        env = Environment(\n            loader=PackageLoader('clan', 'templates'),\n            trim_blocks=True,\n            lstrip_blocks=True\n        )\n\n        template = env.get_template('diff.txt')\n\n        def format_row(label, values):\n            change = format_comma(values['change'])\n            percent_change = '{:.1%}'.format(values['percent_change']) if values['percent_change'] is not None else '-'\n            point_change = '{:.1f}'.format(values['point_change'] * 100) if values['point_change'] is not None else '-'\n\n            if values['change'] > 0:\n                change = '+%s' % change\n\n            if values['percent_change'] is not None and values['percent_change'] > 0:\n                percent_change = '+%s' % percent_change\n\n            if values['point_change'] is not None and values['point_change'] > 0:\n                point_change = '+%s' % point_change\n\n            return '{:>15s}    {:>8s}    {:>8s}    {:s}\\n'.format(change, percent_change, point_change, label)\n\n        context = {\n            'diff': diff,\n            'field_definitions': self.field_definitions,\n            'GLOBAL_ARGUMENTS': GLOBAL_ARGUMENTS,\n            'format_comma': format_comma,\n            'format_duration': format_duration,\n            'format_percent': format_percent,\n            'format_row': format_row\n        }\n\n        f.write(template.render(**context).encode('utf-8'))", "response": "Generate a text report for a diff."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a text report for a diff.", "response": "def html(self, diff, f):\n        \"\"\"\n        Generate a text report for a diff.\n        \"\"\"\n        env = Environment(loader=PackageLoader('clan', 'templates'))\n\n        template = env.get_template('diff.html')\n\n        def number_class(v):\n            if v is None:\n                return ''\n\n            if v > 0:\n                return 'positive'\n            elif v < 0:\n                return 'negative'\n\n            return ''\n\n        context = {\n            'diff': diff,\n            'GLOBAL_ARGUMENTS': GLOBAL_ARGUMENTS,\n            'format_comma': format_comma,\n            'format_duration': format_duration,\n            'number_class': number_class\n\n        }\n\n        f.write(template.render(**context).encode('utf-8'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering the HTML for the given instance.", "response": "def render_html(self, request, instance, context):\n        \"\"\"\n        Custom rendering function for HTML output\n        \"\"\"\n        render_template = self.get_render_template(request, instance, email_format='html')\n        if not render_template:\n            return str(u\"{No HTML rendering defined for class '%s'}\" % self.__class__.__name__)\n\n        instance_context = self.get_context(request, instance, email_format='html', parent_context=context)\n        instance_context['email_format'] = 'html'\n\n        html = self.render_to_string(request, render_template, instance_context)\n        if self.render_replace_context_fields:\n            html = replace_fields(html, instance_context)  # pass safe-string\n        return html"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_text(self, request, instance, context):\n        render_template = self.get_render_template(request, instance, email_format='text')\n        if not render_template:\n            # If there is no TEXT variation, create it by removing the HTML tags.\n            base_url = request.build_absolute_uri('/')\n            html = self.render_html(request, instance, context)\n            return html_to_text(html, base_url)\n\n        instance_context = self.get_context(request, instance, email_format='text', parent_context=context)\n        instance_context['email_format'] = 'text'\n\n        text = self.render_to_string(request, render_template, instance_context)\n        text = text + \"\"  # Avoid being a safestring\n        if self.render_replace_context_fields:\n            text = replace_fields(text, instance_context, autoescape=False)\n        return text", "response": "Render the text variation of the instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy_data(self):\n        HASH_FUNCTION = hashlib.sha256()\n\n        try:\n            raw_iterator = self.get_binary_iterator()\n        except AttributeError:\n            raw_iterator = self.get_non_binary_iterator()\n            self.copy_file = tempfile.NamedTemporaryFile(mode='w+')\n\n            for part in raw_iterator:\n                encoded_part = dbsafe_encode(part)\n                self.copy_file.write(encoded_part)\n                self.copy_file.write('\\n')\n                HASH_FUNCTION.update(encoded_part)\n\n            self.copy_file.seek(0)\n            self.data_iterator = (dbsafe_decode(line) for line in self.copy_file)\n\n        else:\n            self.copy_file = tempfile.NamedTemporaryFile(mode='w+b')\n\n            for part in raw_iterator:\n                self.copy_file.write(part)\n                HASH_FUNCTION.update(part)\n\n            self.copy_file.seek(0)\n            self.data_iterator = self.copy_file\n\n        self.new_hash = HASH_FUNCTION.hexdigest()", "response": "Copy the data from the it s point of origin serializing it storing it in raw form and calculate the hash of the serialized representation"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_binary_iterator(self):\n        CHUNK_SIZE = 1024\n        return (item for item in requests.get(self.url).iter_content(CHUNK_SIZE))", "response": "Generator to stream the remote file piece by piece."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef command_request(self, method, path):\n        op = self.client.swagger_spec.get_op_for_request(method, path)\n        if not op:\n            raise RuntimeError(\n                'no command found for (%s, %s)' % (method, path))\n\n        return Request(self.client, CallableOperation(op))", "response": "Returns a callable request for a given http method and API path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef path_requests(self, path):\n        path_spec = self.client.origin_spec['paths'].get(path)\n        if not path_spec:\n            raise RuntimeError(\"no path found for: %s\" % path)\n\n        get_for_meth = self.client.swagger_spec.get_op_for_request\n        rsrc = BravadoResource(name=path, ops={\n            method: get_for_meth(method, path)\n            for method in path_spec.keys()})\n\n        return RequestFactory.Resource(self.client, ResourceDecorator(rsrc))", "response": "Returns a Resource instance that has attributes for each of the http - methods\n            supported on that path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the url to add the related item to the add page.", "response": "def get_add_link(self):\n        \"\"\"\n        Appends the popup=1 query string to the url so the\n        destination url treats it as a popup.\n        \"\"\"\n\n        url = super(TaggedRelationWidget, self).get_add_link()\n        if url:\n            qs = self.get_add_qs()\n            if qs:\n                url = \"%s&%s\" % (url, urllib.urlencode(qs))\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_view(parser, token):\n    bits = token.split_contents()\n\n    n = len(bits)\n    if n < 2:\n        raise TemplateSyntaxError(\"'%s' takes at least one view as argument\")\n\n    viewname = bits[1]\n\n    kwargs = {}\n    if n > 2:\n        for bit in bits[2:]:\n            match = kwarg_re.match(bit)\n            if not match:\n                raise TemplateSyntaxError(\"Malformed arguments to render_view tag\")\n            name, value = match.groups()\n            if name:\n                kwargs[name] = parser.compile_filter(value)\n\n    return StringNode(viewname, kwargs)", "response": "Returns a string version of a view with as_string method."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bundle_view(parser, token):\n\n    bits = token.split_contents()\n    if len(bits) < 3:\n        raise TemplateSyntaxError(\"'%s' takes at least two arguments\"\n                                  \" bundle and view_name\" % bits[0])\n\n    bundle = parser.compile_filter(bits[1])\n    viewname = parser.compile_filter(bits[2])\n\n    asvar = None\n    bits = bits[2:]\n    if len(bits) >= 2 and bits[-2] == 'as':\n        asvar = bits[-1]\n        bits = bits[:-2]\n\n    return ViewNode(bundle, viewname, asvar)", "response": "This tag returns a string version of a bundle view."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bundle_url(parser, token):\n\n    bits = token.split_contents()\n    if len(bits) < 3:\n        raise TemplateSyntaxError(\"'%s' takes at least two arguments\"\n                                  \" bundle and view_name\" % bits[0])\n\n    bundle = parser.compile_filter(bits[1])\n    viewname = parser.compile_filter(bits[2])\n\n    kwargs = {}\n    asvar = None\n    bits = bits[2:]\n    if len(bits) >= 2 and bits[-2] == 'as':\n        asvar = bits[-1]\n        bits = bits[:-2]\n\n    if len(bits):\n        for bit in bits:\n            match = kwarg_re.match(bit)\n            if not match:\n                raise TemplateSyntaxError(\"Malformed arguments to url tag\")\n            name, value = match.groups()\n            if name:\n                kwargs[name] = parser.compile_filter(value)\n\n    return URLNode(bundle, viewname, kwargs, asvar)", "response": "Returns a url for given a bundle and view name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef user_url(user, bundle):\n    if not user:\n        return False\n\n    bundle = bundle.admin_site.get_bundle_for_model(User)\n    edit = None\n\n    if bundle:\n        edit = bundle.get_view_url('main', user)\n    return edit", "response": "Returns the URL for a user object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef groupby(data, keys=None, size=None, min_size=None, max_size=None, contiguous=False):\n    if isinstance(data, Container):\n        return data.groupby(keys)\n\n    if size != None or min_size != None or max_size != None:\n        if size != None:\n            max_size = size\n        return groupby_min_max_size(data, min_size=min_size, max_size=max_size)\n\n    try:\n        keys = listwrap(keys)\n        if not contiguous:\n            from jx_python import jx\n            data = jx.sort(data, keys)\n\n        if not data:\n            return Null\n\n        if any(is_expression(k) for k in keys):\n            Log.error(\"can not handle expressions\")\n        else:\n            accessor = jx_expression_to_function(jx_expression({\"tuple\": keys}))  # CAN RETURN Null, WHICH DOES NOT PLAY WELL WITH __cmp__\n\n        def _output():\n            start = 0\n            prev = accessor(data[0])\n            for i, d in enumerate(data):\n                curr = accessor(d)\n                if curr != prev:\n                    group = {}\n                    for k, gg in zip(keys, prev):\n                        group[k] = gg\n                    yield Data(group), data[start:i:]\n                    start = i\n                    prev = curr\n            group = {}\n            for k, gg in zip(keys, prev):\n                group[k] = gg\n            yield Data(group), data[start::]\n\n        return _output()\n    except Exception as e:\n        Log.error(\"Problem grouping\", cause=e)", "response": "Group by a list of keys and values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ranks(self) -> List[str]:\n        return list(OrderedDict.fromkeys((m.rank for m in self.members)))", "response": "Returns a list of ranks in the hierarchical order."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_content(cls, content):\n        if \"An internal error has occurred\" in content:\n            return None\n\n        parsed_content = parse_tibiacom_content(content)\n        try:\n            name_header = parsed_content.find('h1')\n            guild = Guild(name_header.text.strip())\n        except AttributeError:\n            raise InvalidContent(\"content does not belong to a Tibia.com guild page.\")\n\n        if not guild._parse_logo(parsed_content):\n            raise InvalidContent(\"content does not belong to a Tibia.com guild page.\")\n\n        info_container = parsed_content.find(\"div\", id=\"GuildInformationContainer\")\n        guild._parse_guild_info(info_container)\n        guild._parse_application_info(info_container)\n        guild._parse_guild_homepage(info_container)\n        guild._parse_guild_guildhall(info_container)\n        guild._parse_guild_disband_info(info_container)\n        guild._parse_guild_members(parsed_content)\n\n        if guild.guildhall and guild.members:\n            guild.guildhall.owner = guild.members[0].name\n\n        return guild", "response": "Creates an instance of the class from the HTML content of the guild s page."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a guild object from a TibiaData character response.", "response": "def from_tibiadata(cls, content):\n        \"\"\"Builds a guild object from a TibiaData character response.\n\n        Parameters\n        ----------\n        content: :class:`str`\n            The json string from the TibiaData response.\n\n        Returns\n        -------\n        :class:`Guild`\n            The guild contained in the description or ``None``.\n\n        Raises\n        ------\n        InvalidContent\n            If content is not a JSON response of a guild's page.\n        \"\"\"\n        json_content = parse_json(content)\n        guild = cls()\n        try:\n            guild_obj = json_content[\"guild\"]\n            if \"error\" in guild_obj:\n                return None\n            guild_data = guild_obj[\"data\"]\n            guild.name = guild_data[\"name\"]\n            guild.world = guild_data[\"world\"]\n            guild.logo_url = guild_data[\"guildlogo\"]\n            guild.description = guild_data[\"description\"]\n            guild.founded = parse_tibiadata_date(guild_data[\"founded\"])\n            guild.open_applications = guild_data[\"application\"]\n        except KeyError:\n            raise InvalidContent(\"content does not match a guild json from TibiaData.\")\n        guild.homepage = guild_data.get(\"homepage\")\n        guild.active = not guild_data.get(\"formation\", False)\n        if isinstance(guild_data[\"disbanded\"], dict):\n            guild.disband_date = parse_tibiadata_date(guild_data[\"disbanded\"][\"date\"])\n            guild.disband_condition = disband_tibadata_regex.search(guild_data[\"disbanded\"][\"notification\"]).group(1)\n        for rank in guild_obj[\"members\"]:\n            rank_name = rank[\"rank_title\"]\n            for member in rank[\"characters\"]:\n                guild.members.append(GuildMember(member[\"name\"], rank_name, member[\"nick\"] or None,\n                                                 member[\"level\"], member[\"vocation\"],\n                                                 joined=parse_tibiadata_date(member[\"joined\"]),\n                                                 online=member[\"status\"] == \"online\"))\n        for invited in guild_obj[\"invited\"]:\n            guild.invites.append(GuildInvite(invited[\"name\"], parse_tibiadata_date(invited[\"invited\"])))\n        if isinstance(guild_data[\"guildhall\"], dict):\n            gh = guild_data[\"guildhall\"]\n            guild.guildhall = GuildHouse(gh[\"name\"], gh[\"world\"], guild.members[0].name,\n                                         parse_tibiadata_date(gh[\"paid\"]))\n        return guild"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_current_member(self, previous_rank, values):\n        rank, name, vocation, level, joined, status = values\n        rank = previous_rank[1] if rank == \" \" else rank\n        title = None\n        previous_rank[1] = rank\n        m = title_regex.match(name)\n        if m:\n            name = m.group(1)\n            title = m.group(2)\n        self.members.append(GuildMember(name, rank, title, int(level), vocation, joined=joined,\n                                        online=status == \"online\"))", "response": "Parses the column texts of a member row into a member dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the guild s application info.", "response": "def _parse_application_info(self, info_container):\n        \"\"\"\n        Parses the guild's application info.\n\n        Parameters\n        ----------\n        info_container: :class:`bs4.Tag`\n            The parsed content of the information container.\n        \"\"\"\n        m = applications_regex.search(info_container.text)\n        if m:\n            self.open_applications = m.group(1) == \"opened\""}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the guild s disband info.", "response": "def _parse_guild_disband_info(self, info_container):\n        \"\"\"\n        Parses the guild's disband info, if available.\n\n        Parameters\n        ----------\n        info_container: :class:`bs4.Tag`\n            The parsed content of the information container.\n        \"\"\"\n        m = disband_regex.search(info_container.text)\n        if m:\n            self.disband_condition = m.group(2)\n            self.disband_date = parse_tibia_date(m.group(1).replace(\"\\xa0\", \" \"))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_guild_guildhall(self, info_container):\n        m = guildhall_regex.search(info_container.text)\n        if m:\n            paid_until = parse_tibia_date(m.group(\"date\").replace(\"\\xa0\", \" \"))\n            self.guildhall = GuildHouse(m.group(\"name\"), self.world, paid_until_date=paid_until)", "response": "Parses the guild s guildhall info."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the guild s homepage info.", "response": "def _parse_guild_homepage(self, info_container):\n        \"\"\"\n        Parses the guild's homepage info.\n\n        Parameters\n        ----------\n        info_container: :class:`bs4.Tag`\n            The parsed content of the information container.\n        \"\"\"\n        m = homepage_regex.search(info_container.text)\n        if m:\n            self.homepage = m.group(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the guild s general information and applies the found values.", "response": "def _parse_guild_info(self, info_container):\n        \"\"\"\n        Parses the guild's general information and applies the found values.\n\n        Parameters\n        ----------\n        info_container: :class:`bs4.Tag`\n            The parsed content of the information container.\n        \"\"\"\n        m = founded_regex.search(info_container.text)\n        if m:\n            description = m.group(\"desc\").strip()\n            self.description = description if description else None\n            self.world = m.group(\"world\")\n            self.founded = parse_tibia_date(m.group(\"date\").replace(\"\\xa0\", \" \"))\n            self.active = \"currently active\" in m.group(\"status\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the guild logo and saves it to the instance.", "response": "def _parse_logo(self, parsed_content):\n        \"\"\"\n        Parses the guild logo and saves it to the instance.\n\n        Parameters\n        ----------\n        parsed_content: :class:`bs4.Tag`\n            The parsed content of the page.\n\n        Returns\n        -------\n        :class:`bool`\n            Whether the logo was found or not.\n        \"\"\"\n        logo_img = parsed_content.find('img', {'height': '64'})\n        if logo_img is None:\n            return False\n\n        self.logo_url = logo_img[\"src\"]\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the guild s member and invited list.", "response": "def _parse_guild_members(self, parsed_content):\n        \"\"\"\n        Parses the guild's member and invited list.\n\n        Parameters\n        ----------\n        parsed_content: :class:`bs4.Tag`\n            The parsed content of the guild's page\n        \"\"\"\n        member_rows = parsed_content.find_all(\"tr\", {'bgcolor': [\"#D4C0A1\", \"#F1E0C6\"]})\n        previous_rank = {}\n        for row in member_rows:\n            columns = row.find_all('td')\n            values = tuple(c.text.replace(\"\\u00a0\", \" \") for c in columns)\n            if len(columns) == COLS_GUILD_MEMBER:\n                self._parse_current_member(previous_rank, values)\n            if len(columns) == COLS_INVITED_MEMBER:\n                self._parse_invited_member(values)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the column texts of an invited row into a invited dictionary.", "response": "def _parse_invited_member(self, values):\n        \"\"\"\n        Parses the column texts of an invited row into a invited dictionary.\n\n        Parameters\n        ----------\n        values: tuple[:class:`str`]\n            A list of row contents.\n        \"\"\"\n        name, date = values\n        if date != \"Invitation Date\":\n            self.invites.append(GuildInvite(name, date))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_world_list_url(cls, world):\n        return GUILD_LIST_URL + urllib.parse.quote(world.title().encode('iso-8859-1'))", "response": "Gets the Tibia. com URL for the guild section of a specific world."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_world_list_url_tibiadata(cls, world):\n        return GUILD_LIST_URL_TIBIADATA % urllib.parse.quote(world.title().encode('iso-8859-1'))", "response": "Gets the TibiaData. com URL for the guild list of a specific world."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_from_content(cls, content):\n        parsed_content = parse_tibiacom_content(content)\n        selected_world = parsed_content.find('option', selected=True)\n        try:\n            if \"choose world\" in selected_world.text:\n                # It belongs to a world that doesn't exist\n                return None\n            world = selected_world.text\n        except AttributeError:\n            raise InvalidContent(\"Content does not belong to world guild list.\")\n        # First TableContainer contains world selector.\n        _, *containers = parsed_content.find_all('div', class_=\"TableContainer\")\n        guilds = []\n        for container in containers:\n            header = container.find('div', class_=\"Text\")\n            active = \"Active\" in header.text\n            header, *rows = container.find_all(\"tr\", {'bgcolor': [\"#D4C0A1\", \"#F1E0C6\"]})\n            for row in rows:\n                columns = row.find_all('td')\n                logo_img = columns[0].find('img')[\"src\"]\n                description_lines = columns[1].get_text(\"\\n\").split(\"\\n\", 1)\n                name = description_lines[0]\n                description = None\n                if len(description_lines) > 1:\n                    description = description_lines[1].replace(\"\\r\", \"\").replace(\"\\n\", \" \")\n                guild = cls(name, world, logo_img, description, active)\n                guilds.append(guild)\n        return guilds", "response": "Gets a list of guilds from the HTML content of the world guilds page."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding a list of Character objects from a TibiaData character response.", "response": "def list_from_tibiadata(cls, content):\n        \"\"\"Builds a character object from a TibiaData character response.\n\n        Parameters\n        ----------\n        content: :class:`str`\n            A string containing the JSON response from TibiaData.\n\n        Returns\n        -------\n        :class:`list` of :class:`ListedGuild`\n            The list of guilds contained.\n\n        Raises\n        ------\n        InvalidContent\n            If content is not a JSON response of TibiaData's guild list.\n        \"\"\"\n        json_content = parse_json(content)\n        try:\n            guilds_obj = json_content[\"guilds\"]\n            guilds = []\n            for guild in guilds_obj[\"active\"]:\n                guilds.append(cls(guild[\"name\"], guilds_obj[\"world\"], logo_url=guild[\"guildlogo\"],\n                                  description=guild[\"desc\"], active=True))\n            for guild in guilds_obj[\"formation\"]:\n                guilds.append(cls(guild[\"name\"], guilds_obj[\"world\"], logo_url=guild[\"guildlogo\"],\n                                  description=guild[\"desc\"], active=False))\n        except KeyError:\n            raise InvalidContent(\"content doest not belong to a guilds response.\")\n        return guilds"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmerging all consecutive non - translatable text nodes into one", "response": "def merge_text_nodes_on(self, node):\n        \"\"\"Merges all consecutive non-translatable text nodes into one\"\"\"\n\n        if not isinstance(node, ContainerNode) or not node.children:\n            return\n\n        new_children = []\n        text_run = []\n        for i in node.children:\n            if isinstance(i, Text) and not i.translatable:\n                text_run.append(i.escaped())\n            else:\n                if text_run:\n                    new_children.append(EscapedText(''.join(text_run)))\n                    text_run = []\n\n                new_children.append(i)\n\n        if text_run:\n            new_children.append(EscapedText(''.join(text_run)))\n\n        node.children = new_children\n        for i in node.children:\n            self.merge_text_nodes_on(i)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef push_state(self):\n\n        new = dict(self.states[-1])\n        self.states.append(new)\n        return self.state", "response": "Push a copy of the topmost state on top of the state stack and return the new topmost state."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef enter_node(self, ir_node):\n        this_is_cdata = (isinstance(ir_node, Element)\n                         and ir_node.name in self.cdata_elements)\n        self.state['is_cdata'] = bool(self.state.get('is_cdata')) or this_is_cdata", "response": "Enter the given node ; keeps track of cdata ; subclasses may extend by overriding theCDATA element ; keeps track of cdata ; subclasses may extend by overriding theCDATA element ; keeps track of cdata ;"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef watch(static_root, watch_paths=None, on_reload=None, host='localhost', port=5555, server_base_path=\"/\",\n          watcher_interval=1.0, recursive=True, open_browser=True, open_browser_delay=1.0):\n    \"\"\"Initialises an HttpWatcherServer to watch the given path for changes. Watches until the IO loop\n    is terminated, or a keyboard interrupt is intercepted.\n\n    Args:\n        static_root: The path whose contents are to be served and watched.\n        watch_paths: The paths to be watched for changes. If not supplied, this defaults to the static root.\n        on_reload: An optional callback to pass to the watcher server that will be executed just before the\n            server triggers a reload in connected clients.\n        host: The host to which to bind our server.\n        port: The port to which to bind our server.\n        server_base_path: If the content is to be served from a non-standard base path, specify it here.\n        watcher_interval: The maximum refresh rate of the watcher server.\n        recursive: Whether to monitor the watch path recursively.\n        open_browser: Whether or not to automatically attempt to open the user's browser at the root URL of\n            the project (default: True).\n        open_browser_delay: The number of seconds to wait before attempting to open the user's browser.\n    \"\"\"\n    server = httpwatcher.HttpWatcherServer(\n        static_root,\n        watch_paths=watch_paths,\n        on_reload=on_reload,\n        host=host,\n        port=port,\n        server_base_path=server_base_path,\n        watcher_interval=watcher_interval,\n        recursive=recursive,\n        open_browser=open_browser,\n        open_browser_delay=open_browser_delay\n    )\n    server.listen()\n\n    try:\n        tornado.ioloop.IOLoop.current().start()\n    except KeyboardInterrupt:\n        server.shutdown()", "response": "Initialises a tornado. ioloop. IOLoop to watch the given path for changes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef query(self):\n        tree = pypeg2.parse(self._query, parser(), whitespace=\"\")\n        for walker in query_walkers():\n            tree = tree.accept(walker)\n        return tree", "response": "Parse the query string using given grammar."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalise_key(self, key):\n        key = key.replace('-', '_')\n        if key.startswith(\"noy_\"):\n            key = key[4:]\n        return key", "response": "Make sure key is a valid python attribute"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind a value and return it", "response": "def find_value(self, key):\n        \"\"\"Find a value and return it\"\"\"\n        values = self.values\n        if key not in values:\n            raise AttributeError(\"Config has no value for {}\".format(key))\n\n        val = values[key]\n        if isinstance(val, Default):\n            return val.val\n        else:\n            return val"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef use_options(self, options, extractor=None):\n        # Extract if necessary\n        if not extractor:\n            extracted = options\n        else:\n            extracted = extractor(self.template, options)\n\n        # Get values as [(key, val), ...]\n        if isinstance(extracted, dict):\n            extracted = extracted.items()\n\n        # Add our values if there are any\n        # Normalising the keys as we go along\n        if extracted is not None:\n            for key, val in extracted:\n                self.values[self.normalise_key(key)] = val", "response": "Update self. values with the options from self. template."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds where our config file is if there is one.", "response": "def find_config_file(self):\n        \"\"\"\n            Find where our config file is if there is any\n\n            If the value for the config file is a default and it doesn't exist\n            then it is silently ignored.\n\n            If however, the value isn't a default and it doesn't exist, an error is raised\n        \"\"\"\n        filename = self.values.get('config_file', Default('noy.json'))\n\n        ignore_missing = False\n        if isinstance(filename, Default):\n            filename = filename.val\n            ignore_missing = True\n\n        filename = os.path.abspath(filename)\n        if os.path.exists(filename):\n            return filename\n        elif not ignore_missing:\n            raise MissingConfigFile(\"Config file doesn't exist at {}\".format(filename))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying options from a config file to the internal dictionary self. values", "response": "def apply_config_file(self, filename):\n        \"\"\"\n            Add options from config file to self.values\n            Leave alone existing values that are not an instance of Default\n        \"\"\"\n        def extractor(template, options):\n            \"\"\"Ignore things that are existing non default values\"\"\"\n            for name, val in options:\n                normalised = self.normalise_key(name)\n                if normalised in self.values and not isinstance(self.values[normalised], Default):\n                    continue\n                else:\n                    yield name, val\n\n        items = json.load(open(filename)).items()\n        self.use_options(items, extractor)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef use_config_file(self):\n        self.config_file = self.find_config_file()\n        if self.config_file:\n            self.apply_config_file(self.config_file)", "response": "Find and apply the config file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setup(self, options=None, extractor=None):\n        # Get our programmatic options\n        self._util.use_options(options, extractor)\n\n        # Overwrite non defaults in self.values with values from config\n        self._util.use_config_file()", "response": "Set up the config object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef recursive_asdict(d):\n    out = {}\n    for k, v in asdict(d).iteritems():\n        if hasattr(v, '__keylist__'):\n            out[k] = recursive_asdict(v)\n        elif isinstance(v, list):\n            out[k] = []\n            for item in v:\n                if hasattr(item, '__keylist__'):\n                    out[k].append(recursive_asdict(item))\n                else:\n                    out[k].append(item)\n        else:\n            out[k] = v\n    return out", "response": "Convert Suds object into serializable format."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef index():\n    collection_names = request.values.getlist('collection')\n\n    # Validation of collection names.\n    collections = Collection.query\n    if collection_names:\n        collections = collections.filter(\n            Collection.name.in_(collection_names))\n    assert len(collection_names) == collections.count()\n\n    response = search.client.search(\n        body={\n            'query': {\n                'filtered': {\n                    'filter': {\n                        'terms': {\n                            '_collections': collection_names\n                        }\n                    }\n                }\n            }\n        }\n    )\n    return jsonify(**response)", "response": "Query Elasticsearch using collection param in query string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a Tibia. com response into a : class:`World.", "response": "def from_content(cls, content):\n        \"\"\"Parses a Tibia.com response into a :class:`World`.\n\n        Parameters\n        ----------\n        content: :class:`str`\n            The raw HTML from the server's information page.\n\n        Returns\n        -------\n        :class:`World`\n            The World described in the page, or ``None``.\n\n        Raises\n        ------\n        InvalidContent\n            If the provided content is not the html content of the world section in Tibia.com\n        \"\"\"\n        parsed_content = parse_tibiacom_content(content)\n        tables = cls._parse_tables(parsed_content)\n        try:\n            error = tables.get(\"Error\")\n            if error and error[0].text == \"World with this name doesn't exist!\":\n                return None\n            selected_world = parsed_content.find('option', selected=True)\n            world = cls(selected_world.text)\n            world._parse_world_info(tables.get(\"World Information\", []))\n\n            online_table = tables.get(\"Players Online\", [])\n            world.online_players = []\n            for row in online_table[1:]:\n                cols_raw = row.find_all('td')\n                name, level, vocation = (c.text.replace('\\xa0', ' ').strip() for c in cols_raw)\n                world.online_players.append(OnlineCharacter(name, world.name, int(level), vocation))\n        except AttributeError:\n            raise InvalidContent(\"content is not from the world section in Tibia.com\")\n\n        return world"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a TibiaData. com response into a : class : World object.", "response": "def from_tibiadata(cls, content):\n        \"\"\"Parses a TibiaData.com response into a :class:`World`\n\n        Parameters\n        ----------\n        content: :class:`str`\n            The raw JSON content from TibiaData\n\n        Returns\n        -------\n        :class:`World`\n            The World described in the page, or ``None``.\n\n        Raises\n        ------\n        InvalidContent\n            If the provided content is not a TibiaData world response.\n        \"\"\"\n        json_data = parse_json(content)\n        try:\n            world_data = json_data[\"world\"]\n            world_info = world_data[\"world_information\"]\n            world = cls(world_info[\"name\"])\n            if \"location\" not in world_info:\n                return None\n            world.online_count = world_info[\"players_online\"]\n            world.status = \"Online\" if world.online_count > 0 else \"Offline\"\n            world.record_count = world_info[\"online_record\"][\"players\"]\n            world.record_date = parse_tibiadata_datetime(world_info[\"online_record\"][\"date\"])\n            world.creation_date = world_info[\"creation_date\"]\n            world.location = try_enum(WorldLocation, world_info[\"location\"])\n            world.pvp_type = try_enum(PvpType, world_info[\"pvp_type\"])\n            world.transfer_type = try_enum(TransferType, world_info.get(\"transfer_type\"), TransferType.REGULAR)\n            world.premium_only = \"premium_type\" in world_info\n            world.world_quest_titles = world_info.get(\"world_quest_titles\", [])\n            world._parse_battleye_status(world_info.get(\"battleye_status\", \"\"))\n            world.experimental = world_info.get(\"Game World Type:\", \"Regular\") != \"Regular\"\n            for player in world_data.get(\"players_online\", []):\n                world.online_players.append(OnlineCharacter(player[\"name\"], world.name, player[\"level\"],\n                                                            player[\"vocation\"]))\n            return world\n        except KeyError:\n            raise InvalidContent(\"content is not a world json response from TibiaData\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the World Information table from Tibia. com and adds the found values to the object.", "response": "def _parse_world_info(self, world_info_table):\n        \"\"\"\n        Parses the World Information table from Tibia.com and adds the found values to the object.\n\n        Parameters\n        ----------\n        world_info_table: :class:`list`[:class:`bs4.Tag`]\n        \"\"\"\n        world_info = {}\n        for row in world_info_table:\n            cols_raw = row.find_all('td')\n            cols = [ele.text.strip() for ele in cols_raw]\n            field, value = cols\n            field = field.replace(\"\\xa0\", \"_\").replace(\" \", \"_\").replace(\":\", \"\").lower()\n            value = value.replace(\"\\xa0\", \" \")\n            world_info[field] = value\n        try:\n            self.online_count = int(world_info.pop(\"players_online\"))\n        except KeyError:\n            self.online_count = 0\n        self.location = try_enum(WorldLocation, world_info.pop(\"location\"))\n        self.pvp_type = try_enum(PvpType, world_info.pop(\"pvp_type\"))\n        self.transfer_type = try_enum(TransferType, world_info.pop(\"transfer_type\", None), TransferType.REGULAR)\n        m = record_regexp.match(world_info.pop(\"online_record\"))\n        if m:\n            self.record_count = int(m.group(\"count\"))\n            self.record_date = parse_tibia_datetime(m.group(\"date\"))\n        if \"world_quest_titles\" in world_info:\n            self.world_quest_titles = [q.strip() for q in world_info.pop(\"world_quest_titles\").split(\",\")]\n        self.experimental = world_info.pop(\"game_world_type\") != \"Regular\"\n        self._parse_battleye_status(world_info.pop(\"battleye_status\"))\n        self.premium_only = \"premium_type\" in world_info\n\n        month, year = world_info.pop(\"creation_date\").split(\"/\")\n        month = int(month)\n        year = int(year)\n        if year > 90:\n            year += 1900\n        else:\n            year += 2000\n        self.creation_date = \"%d-%02d\" % (year, month)\n\n        for k, v in world_info.items():\n            try:\n                setattr(self, k, v)\n            except AttributeError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_battleye_status(self, battleye_string):\n        m = battleye_regexp.search(battleye_string)\n        if m:\n            self.battleye_protected = True\n            self.battleye_date = parse_tibia_full_date(m.group(1))\n        else:\n            self.battleye_protected = False\n            self.battleye_date = None", "response": "Parses the BattlEye string and applies the results."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the information tables found in a world s information page.", "response": "def _parse_tables(cls, parsed_content):\n        \"\"\"\n        Parses the information tables found in a world's information page.\n\n        Parameters\n        ----------\n        parsed_content: :class:`bs4.BeautifulSoup`\n            A :class:`BeautifulSoup` object containing all the content.\n\n        Returns\n        -------\n        :class:`OrderedDict`[:class:`str`, :class:`list`[:class:`bs4.Tag`]]\n            A dictionary containing all the table rows, with the table headers as keys.\n        \"\"\"\n        tables = parsed_content.find_all('div', attrs={'class': 'TableContainer'})\n        output = OrderedDict()\n        for table in tables:\n            title = table.find(\"div\", attrs={'class': 'Text'}).text\n            title = title.split(\"[\")[0].strip()\n            inner_table = table.find(\"div\", attrs={'class': 'InnerTableContainer'})\n            output[title] = inner_table.find_all(\"tr\")\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the content of the World Overview section from Tibia. com into an object of this class.", "response": "def from_content(cls, content):\n        \"\"\"Parses the content of the World Overview section from Tibia.com into an object of this class.\n\n        Parameters\n        ----------\n        content: :class:`str`\n            The HTML content of the World Overview page in Tibia.com\n\n        Returns\n        -------\n        :class:`WorldOverview`\n            An instance of this class containing all the information.\n\n        Raises\n        ------\n        InvalidContent\n            If the provided content is not the HTML content of the worlds section in Tibia.com\n        \"\"\"\n        parsed_content = parse_tibiacom_content(content, html_class=\"TableContentAndRightShadow\")\n        world_overview = WorldOverview()\n        try:\n            record_row, titles_row, *rows = parsed_content.find_all(\"tr\")\n            m = record_regexp.search(record_row.text)\n            if not m:\n                raise InvalidContent(\"content does not belong to the World Overview section in Tibia.com\")\n            world_overview.record_count = int(m.group(\"count\"))\n            world_overview.record_date = parse_tibia_datetime(m.group(\"date\"))\n            world_rows = rows\n            world_overview._parse_worlds(world_rows)\n            return world_overview\n        except (AttributeError, KeyError, ValueError):\n            raise InvalidContent(\"content does not belong to the World Overview section in Tibia.com\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_tibiadata(cls, content):\n        json_data = parse_json(content)\n        try:\n            worlds_json = json_data[\"worlds\"][\"allworlds\"]\n            world_overview = cls()\n            for world_json in worlds_json:\n                world = ListedWorld(world_json[\"name\"], world_json[\"location\"], world_json[\"worldtype\"])\n                world._parse_additional_info(world_json[\"additional\"])\n                world.online_count = world_json[\"online\"]\n                world_overview.worlds.append(world)\n            return world_overview\n        except KeyError:\n            raise InvalidContent(\"content is not a worlds json response from TibiaData.com.\")", "response": "Parses the content of the World Overview section from TibiaData. com into an object of this class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the world columns and adds the results to self. worlds.", "response": "def _parse_worlds(self, world_rows):\n        \"\"\"Parses the world columns and adds the results to :py:attr:`worlds`.\n\n        Parameters\n        ----------\n        world_rows: :class:`list` of :class:`bs4.Tag`\n            A list containing the rows of each world.\n        \"\"\"\n        for world_row in world_rows:\n            cols = world_row.find_all(\"td\")\n            name = cols[0].text.strip()\n            status = \"Online\"\n            try:\n                online = int(cols[1].text.strip())\n            except ValueError:\n                online = 0\n                status = \"Offline\"\n            location = cols[2].text.replace(\"\\u00a0\", \" \").strip()\n            pvp = cols[3].text.strip()\n\n            world = ListedWorld(name, location, pvp, online_count=online, status=status)\n            # Check Battleye icon to get information\n            battleye_icon = cols[4].find(\"span\", attrs={\"class\": \"HelperDivIndicator\"})\n            if battleye_icon is not None:\n                world.battleye_protected = True\n                m = battleye_regexp.search(battleye_icon[\"onmouseover\"])\n                if m:\n                    world.battleye_date = parse_tibia_full_date(m.group(1))\n\n            additional_info = cols[5].text.strip()\n            world._parse_additional_info(additional_info)\n            self.worlds.append(world)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nresets all known crops to the default crop.", "response": "def reset_crops(self):\n        \"\"\"\n        Reset all known crops to the default crop.\n\n        If settings.ASSET_CELERY is specified then\n        the task will be run async\n        \"\"\"\n\n        if self._can_crop():\n            if settings.CELERY or settings.USE_CELERY_DECORATOR:\n                # this means that we are using celery\n                tasks.reset_crops.apply_async(args=[self.pk], countdown=5)\n            else:\n                tasks.reset_crops(None, asset=self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nensuring that a crop exists for each crop in required_crops.", "response": "def ensure_crops(self, *required_crops):\n        \"\"\"\n        Make sure a crop exists for each crop in required_crops.\n        Existing crops will not be changed.\n\n        If settings.ASSET_CELERY is specified then\n        the task will be run async\n        \"\"\"\n        if self._can_crop():\n            if settings.CELERY or settings.USE_CELERY_DECORATOR:\n                # this means that we are using celery\n                args = [self.pk]+list(required_crops)\n                tasks.ensure_crops.apply_async(args=args, countdown=5)\n            else:\n                tasks.ensure_crops(None, *required_crops, asset=self)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_crop(self, name, x, x2, y, y2):\n        if self._can_crop():\n            spec = get_image_cropper().create_crop(name, self.file, x=x,\n                                                   x2=x2, y=y, y2=y2)\n            ImageDetail.save_crop_spec(self, spec)", "response": "Create a crop for this asset."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete the actual file from storage after the object is deleted.", "response": "def delete(self, *args, **kwargs):\n        \"\"\"\n        Deletes the actual file from storage after the object is deleted.\n\n        Calls super to actually delete the object.\n        \"\"\"\n        file_obj = self.file\n        super(AssetBase, self).delete(*args, **kwargs)\n        self.delete_real_file(file_obj)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_not_annotated(func, annotations=None):\n    argspec = inspect.getfullargspec(func)\n    args = argspec.args\n    if argspec.defaults is not None:\n        args = args[:-len(argspec.defaults)]\n    if inspect.isclass(func) or inspect.ismethod(func):\n        args = args[1:]  # Strip off ``cls`` or ``self``.\n    kwonlyargs = argspec.kwonlyargs\n    if argspec.kwonlydefaults is not None:\n        kwonlyargs = kwonlyargs[:-len(argspec.kwonlydefaults)]\n    annotations = annotations or argspec.annotations\n    return [arg for arg in args + kwonlyargs if arg not in annotations]", "response": "Return non - optional parameters that are not annotated."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_args(func, variables, annotations=None):\n    arg_read_var = []\n    for arg_name, anno in (annotations or func.__annotations__).items():\n        if arg_name == 'return':\n            continue\n        var, read = _parse_arg(func, variables, arg_name, anno)\n        arg = Argument(name=arg_name, read=read)\n        arg_read_var.append((arg, var))\n    return arg_read_var", "response": "Return a list of arguments with the variable it reads."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_arg(func, variables, arg_name, anno):\n    if isinstance(anno, str):\n        var = variables[anno]\n        return var, var.read_latest\n    elif (isinstance(anno, list) and len(anno) == 1 and\n          isinstance(anno[0], str)):\n        var = variables[anno[0]]\n        return var, var.read_all\n    # For now, be very strict about annotation format (e.g.,\n    # allow list but not tuple) because we might want to use\n    # tuple for other meanings in the future.\n    raise StartupError(\n        'cannot parse annotation %r of parameter %r for %r' %\n        (anno, arg_name, func))", "response": "Parse an argument s annotation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_ret(func, variables, annotations=None):\n    anno = (annotations or func.__annotations__).get('return')\n    if anno is None:\n        return None\n    elif isinstance(anno, str):\n        writeto = variables[anno]\n        writeto.notify_will_write()\n        return writeto\n    elif (isinstance(anno, tuple) and\n          all(isinstance(name, str) for name in anno)):\n        writeto = tuple(variables[name] for name in anno)\n        for var in writeto:\n            var.notify_will_write()\n        return writeto\n    # Be very strict about annotation format for now.\n    raise StartupError(\n        'cannot parse return annotation %r for %r' % (anno, func))", "response": "Parse func s return annotation and return either None a variable or a tuple of variables."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _write_values(kwargs, variables):\n    writeto = []\n    for var_name, value in kwargs.items():\n        var = variables[var_name]\n        var.notify_will_write()\n        var.write(value)\n        writeto.append(var)\n    return _notify_reader_writes(writeto)", "response": "Write values of kwargs and return thus - satisfied closures."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nnotifying reader closures about these writes and return a sorted list of thus - satisfied closures.", "response": "def _notify_reader_writes(writeto):\n    \"\"\"Notify reader closures about these writes and return a sorted\n       list of thus-satisfied closures.\n    \"\"\"\n    satisfied = []\n    for var in writeto:\n        if var.readable:\n            for reader in var.readers:\n                reader.notify_read_ready()\n                if reader.satisfied:\n                    satisfied.append(reader)\n    return Closure.sort(satisfied)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _release(self):\n        del self.funcs\n        del self.variables\n        del self.variable_values\n        del self.satisfied", "response": "Destroy self since closures cannot be called again."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset a variable before call (", "response": "def set(self, name, value):\n        \"\"\"Set a variable before ``call()``.\"\"\"\n        if not hasattr(self, 'funcs'):\n            raise StartupError('startup cannot be called again')\n        self.variable_values[name] = value"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls all the functions that have previously been added to the internal dependency graph and return the variables in a dict.", "response": "def call(self, **kwargs):\n        \"\"\"Call all the functions that have previously been added to the\n        dependency graph in topological and lexicographical order, and\n        then return variables in a ``dict``.\n\n        You may provide variable values with keyword arguments.  These\n        values will be written and can satisfy dependencies.\n\n        NOTE: This object will be **destroyed** after ``call()`` returns\n        and should not be used any further.\n        \"\"\"\n        if not hasattr(self, 'funcs'):\n            raise StartupError('startup cannot be called again')\n        for name, var in self.variables.items():\n            var.name = name\n        self.variable_values.update(kwargs)\n        for name in self.variable_values:\n            self.variables[name].name = name\n        queue = Closure.sort(self.satisfied)\n        queue.extend(_write_values(self.variable_values, self.variables))\n        while queue:\n            closure = queue.pop(0)\n            writeto = closure.call()\n            self.funcs.remove(closure.func)\n            queue.extend(_notify_reader_writes(writeto))\n        if self.funcs:\n            raise StartupError('cannot satisfy dependency for %r' % self.funcs)\n        values = {\n            name: var.read_latest() for name, var in self.variables.items()\n        }\n        # Call _release() on normal exit only; otherwise keep the dead body for\n        # forensic analysis.\n        self._release()\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, value):\n        assert self.num_write_waits > 0, self\n        self.num_write_waits -= 1\n        self.values.append(value)\n        if self.readable:\n            LOG.debug('%s is now readable', self.name)", "response": "Write a new value to this variable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall the closure and return variable ( s ) that is written.", "response": "def call(self):\n        \"\"\"Call the closure and return variable(s) that is written.\"\"\"\n        assert self.satisfied, self\n        LOG.debug('call %s.%s', self.func.__module__, self.func.__qualname__)\n        kwargs = {arg.name: arg.read() for arg in self.args}\n        out_value = self.func(**kwargs)\n        if self.writeto is None:\n            writeto = set()\n        elif isinstance(self.writeto, Variable):\n            self.writeto.write(out_value)\n            writeto = {self.writeto}\n        else:\n            # A variable can be written multiple times, but we only\n            # return a unique set of variables.\n            for var, value in zip(self.writeto, out_value):\n                var.write(value)\n            writeto = set(self.writeto)\n        self._release()  # Only call _release() on normal exit.\n        return writeto"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the entry in the cluster.", "response": "def update(self, command):\n        \"\"\"\n        EXPECTING command == {\"set\":term, \"where\":where}\n        THE set CLAUSE IS A DICT MAPPING NAMES TO VALUES\n        THE where CLAUSE IS AN ES FILTER\n        \"\"\"\n        command = wrap(command)\n        table = self.get_table(command['update'])\n\n        es_index = self.es.cluster.get_index(read_only=False, alias=None, kwargs=self.es.settings)\n\n        schema = table.schema\n\n        # GET IDS OF DOCUMENTS\n        query = {\n            \"from\": command['update'],\n            \"select\": [{\"value\": \"_id\"}] + [\n                {\"name\": k, \"value\": v}\n                for k, v in command.set.items()\n            ],\n            \"where\": command.where,\n            \"format\": \"list\",\n            \"limit\": 10000\n        }\n\n        results = self.query(query)\n\n        if results.data:\n            content = \"\".join(\n                t\n                for r in results.data\n                for _id, row in [(r._id, r)]\n                for _ in [row.__setitem__('_id', None)]  # WARNING! DESTRUCTIVE TO row\n                for update in map(value2json, ({\"update\": {\"_id\": _id}}, {\"doc\": row}))\n                for t in (update, \"\\n\")\n            )\n            response = self.es.cluster.post(\n                es_index.path + \"/\" + \"_bulk\",\n                data=content,\n                headers={\"Content-Type\": \"application/json\"},\n                timeout=self.settings.timeout,\n                params={\"wait_for_active_shards\": self.settings.wait_for_active_shards}\n            )\n            if response.errors:\n                Log.error(\"could not update: {{error}}\", error=[e.error for i in response[\"items\"] for e in i.values() if e.status not in (200, 201)])\n\n        # DELETE BY QUERY, IF NEEDED\n        if \".\" in listwrap(command.clear):\n            es_filter = self.es.cluster.lang[jx_expression(command.where)].to_esfilter(schema)\n            self.es.delete_record(es_filter)\n            return\n\n        es_index.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_tonnikala(fileobj, keywords, comment_tags, options):\n    extractor = TonnikalaExtractor()\n    for msg in extractor(filename=None, fileobj=fileobj, options=Options()):\n        msgid = msg.msgid,\n\n        prefix = ''\n        if msg.msgid_plural:\n            msgid = (msg.msgid_plural,) + msgid\n            prefix = 'n'\n\n        if msg.msgctxt:\n            msgid = (msg.msgctxt,) + msgid\n            prefix += 'p'\n\n        yield (msg.location[1], prefix + 'gettext', msgid, msg.comment)", "response": "Extracts messages from Tonnikala files."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclears the current character and makes the machine ready to accept the next character.", "response": "def _clear_char(self):\n        '''\n        Clears the current character and makes the machine ready\n        to accept the next character.\n        '''\n        self.lvmarker_count = 0\n        self.geminate_count = 0\n        self.next_char_info = None\n        self.next_char_type = None\n        self.active_vowel = None\n        self.active_vowel_info = None\n        self.active_vowel_ro = None\n        self.active_xvowel = None\n        self.active_xvowel_info = None\n        self.active_char = None\n        self.active_char_info = None\n        self.active_char_type = None\n        self.active_dgr_a_info = None\n        self.active_dgr_b_info = None\n        self.has_xvowel = False\n        self.has_digraph_b = False\n        self.has_u_lvm = False\n        self.unknown_char = None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _append_unknown_char(self):\n        '''\n        Appends the unknown character, in case one was encountered.\n        '''\n        if self.unknown_strategy == UNKNOWN_INCLUDE and \\\n           self.unknown_char is not None:\n            self._append_to_stack(self.unknown_char)\n\n        self.unknown_char = None", "response": "Appends the unknown character to the stack if one was encountered."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nappend the r\u014dmaji characters that represent the current state of the machine. For example, if the state includes the character \u30c8, plus a geminate marker and a long vowel marker, this causes the characters \"tt\u014d\" to be added to the output.", "response": "def _flush_char(self):\n        '''\n        Appends the r\u014dmaji characters that represent the current state\n        of the machine. For example, if the state includes the character\n        \u30c8, plus a geminate marker and a long vowel marker, this causes\n        the characters \"tt\u014d\" to be added to the output.\n        '''\n        # Ignore in case there's no active character, only at the\n        # first iteration of the conversion process.\n        if self.active_char is None:\n            if self.unknown_char is not None:\n                self._append_unknown_char()\n\n            return\n\n        char_info = self.active_char_info\n        char_type = self.active_char_type\n        char_ro = char_info[0]\n        xv = self.active_xvowel_info\n        di_b = self.active_dgr_b_info\n        gem = self.geminate_count\n        lvm = self.lvmarker_count\n\n        # Check for special combinations. This is exceptional behavior\n        # for very specific character combinations, too unique to\n        # build into the data model for every kana.\n        # If a special combination is found, we'll replace the\n        # r\u014dmaji character we were planning on flushing.\n        if char_type == VOWEL and len(char_info) >= 3 and xv is not None:\n            try:\n                exc = char_info[2]['xv'][xv[0]]\n                # Found a special combination. Replace the r\u014dmaji character.\n                char_ro = exc\n            except (IndexError, KeyError):\n                # IndexError: no 'xv' exceptions list for this vowel.\n                # KeyError: no exception for the current small vowel.\n                pass\n\n        # Check whether we're dealing with a valid char type.\n        if char_type not in CHAR_TYPES:\n            raise InvalidCharacterTypeError\n\n        # If no modifiers are active (geminate marker, small vowel marker,\n        # etc.) then just the currently active character is flushed.\n        # We'll also continue if the character is 'n', which has a special\n        # case attached to it that we'll tackle down below.\n        if xv is di_b is None and gem == lvm == 0 and char_ro != 'n':\n            self._append_to_stack(char_ro)\n            self._append_unknown_char()\n            self._clear_char()\n            return\n\n        # At this point, we're considering two main factors: the currently\n        # active character, and possibly a small vowel character if one is set.\n        # For example, if the active character is \u30c6 and a small vowel \u30a3\n        # is set, the result is 'ti'. If no small vowel is set, just\n        # plain 'te' comes out.\n        #\n        # Aside from this choice, we're also considering the number of active\n        # long vowel markers, which repeats the vowel part. If there's\n        # at least one long vowel marker, we also use a macron vowel\n        # rather than the regular one, e.g. '\u012b' instead of 'i'.\n\n        if char_type == CV:\n            # Deconstruct the info object for clarity.\n            char_gem_cons = char_info[1]  # the extra geminate consonant\n            char_cons = char_info[2]      # the consonant part\n            char_lv = char_info[4]        # the long vowel part\n\n            # If this flushed character is an 'n', and precedes a vowel or\n            # a 'y' consonant, it must be followed by an apostrophe.\n            char_apostrophe = ''\n\n            if char_ro == 'n' and self.next_char_info is not None:\n                first_char = None\n\n                if self.next_char_type == CV:\n                    first_char = self._char_ro_cons(\n                        self.next_char_info,\n                        CV\n                    )\n\n                if self.next_char_type == VOWEL or \\\n                   self.next_char_type == XVOWEL:\n                    first_char = self._char_ro_vowel(\n                        self.next_char_info,\n                        VOWEL\n                    )\n\n                # If the following character is in the set of characters\n                # that should trigger an apostrophe, add it to the output.\n                if first_char in n_apostrophe:\n                    char_apostrophe = APOSTROPHE_CHAR\n\n            # Check to see if we've got a full digraph.\n            if self.active_dgr_a_info is not None and \\\n               self.active_dgr_b_info is not None:\n                char_cons = self.active_dgr_a_info[0]\n\n            # Determine the geminate consonant part (which can be\n            # arbitrarily long).\n            gem_cons = char_gem_cons * gem\n\n            if xv is not None:\n                # Combine the consonant of the character with the small vowel.\n                # Use a macron vowel if there's a long vowel marker,\n                # else use the regular vowel.\n                vowel = xv[1] * lvm if lvm > 0 else xv[0]\n            elif di_b is not None:\n                # Put together the digraph. Here we produce the latter half\n                # of the digraph.\n                vowel = di_b[1] * lvm if lvm > 0 else di_b[0]\n            else:\n                # Neither a small vowel marker, nor a digraph.\n                vowel = ''\n\n            if vowel != '':\n                # If we've got a special vowel part, combine it with the\n                # main consonant.\n                char_main = char_cons + char_apostrophe + vowel\n            else:\n                # If not, process the main character and add the long vowels\n                # if applicable.\n                if lvm > 0:\n                    char_main = char_cons + char_apostrophe + char_lv * lvm\n                else:\n                    char_main = char_ro + char_apostrophe\n\n            self._append_to_stack(gem_cons + char_main)\n\n        if char_type == VOWEL or char_type == XVOWEL:\n            char_lv = char_info[1]  # the long vowel part\n\n            if xv is not None:\n                xv_ro = xv[1] * lvm if lvm > 0 else xv[0]\n                self._append_to_stack(char_ro + xv_ro)\n            else:\n                vowel_ro = char_lv * lvm if lvm > 0 else char_ro\n                self._append_to_stack(vowel_ro)\n\n        # Append unknown the character as well.\n        self._append_unknown_char()\n        self._clear_char()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _promote_solitary_xvowel(self):\n        '''\n        \"Promotes\" the current xvowel to a regular vowel, in case\n        it is not otherwise connected to a character.\n        Used to print small vowels that would otherwise get lost;\n        normally small vowels always form a pair, but in case one is\n        by itself it should basically act like a regular vowel.\n        '''\n        char_type = self.active_char_type\n\n        # Only promote if we actually have an xvowel, and if the currently\n        # active character is not a consonant-vowel pair or vowel.\n        if char_type == VOWEL or char_type == CV or self.active_xvowel is None:\n            return\n\n        self._set_char(self.active_xvowel, XVOWEL)\n        self.active_xvowel = None\n        self.active_xvowel_info = None", "response": "Promotes the current xvowel to a regular vowel."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_unknown_char(self, string):\n        '''\n        Adds an unknown character to the stack.\n        '''\n        if self.has_xvowel:\n            # Ensure an xvowel gets printed if we've got an active\n            # one right now.\n            self._promote_solitary_xvowel()\n\n        self.unknown_char = string\n        self._flush_char()", "response": "Adds an unknown character to the stack."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the currently active character in case it is not already set.", "response": "def _set_digraph_a(self, char):\n        '''\n        Sets the currently active character, in case it is (potentially)\n        the first part of a digraph.\n        '''\n        self._set_char(char, CV)\n        self.active_dgr_a_info = di_a_lt[char]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_digraph_b(self, char):\n        '''\n        Sets the second part of a digraph.\n        '''\n        self.has_digraph_b = True\n        # Change the active vowel to the one provided by the second part\n        # of the digraph.\n        self.active_vowel_ro = di_b_lt[char][0]\n        self.active_dgr_b_info = di_b_lt[char]", "response": "Sets the second part of a digraph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the vowel part of a character in r\u014dmaji.", "response": "def _char_ro_vowel(self, char_info, type):\n        '''\n        Returns the vowel part of a character in r\u014dmaji.\n        '''\n        if type == CV:\n            return char_info[3]\n\n        if type == VOWEL or type == XVOWEL:\n            return char_info[0]\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the currently active character.", "response": "def _set_char(self, char, type):\n        '''\n        Sets the currently active character, e.g. \u30c8. We save some information\n        about the character as well. active_char_info contains the full\n        tuple of r\u014dmaji info, and active_ro_vowel contains e.g. 'o' for \u30c8.\n\n        We also set the character type: either a consonant-vowel pair\n        or a vowel. This affects the way the character is flushed later.\n        '''\n        self.next_char_info = self._char_lookup(char)\n        self.next_char_type = type\n        self._flush_char()\n\n        self.active_char = char\n        self.active_char_type = type\n\n        self.active_char_info = self._char_lookup(char)\n        self.active_vowel_ro = self._char_ro_vowel(self.active_char_info, type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the current vowel and sets the character to the given vowel.", "response": "def _set_vowel(self, vowel):\n        '''\n        Sets the currently active vowel, e.g. \u30a2.\n\n        Vowels act slightly differently from other characters. If one\n        succeeds the same vowel (or consonant-vowel pair with the same vowel)\n        then it acts like a long vowel marker. E.g. \u304a\u306d\u3048 becomes on\u0113.\n\n        Hence, either we increment the long vowel marker count, or we\n        flush the current character and set the active character to this.\n\n        In some cases, the \u30a6 becomes a consonant-vowel if it's\n        paired with a small vowel. We will not know this until we see\n        what comes after the \u30a6, so there's some backtracking\n        if that's the case.\n        '''\n        vowel_info = kana_lt[vowel]\n        vowel_ro = self.active_vowel_ro\n\n        if self._is_long_vowel(vowel_ro, vowel_info[0]):\n            # Check to see if the current vowel is \u30a6. If so,\n            # we might need to backtrack later on in case the 'u'\n            # turns into 'w' when \u30a6 is coupled with a small vowel.\n            if vowel_ro == 'u':\n                self.has_u_lvm = True\n\n            self._inc_lvmarker()\n        else:\n            # Not the same, so flush the active character and continue.\n            self._set_char(vowel, VOWEL)\n\n        self.active_vowel_info = vowel_info\n        self.active_vowel = vowel"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the current character to the given xvowel.", "response": "def _set_xvowel(self, xvowel):\n        '''\n        Sets the currently active small vowel, e.g. \u30a1.\n\n        If an active small vowel has already been set, the current character\n        must be flushed. (Double small vowels don't occur in dictionary\n        words.) After that, we'll set the current character to this small\n        vowel; in essence, it will act like a regular size vowel.\n\n        We'll check for digraphs too, just so e.g. \u3057\u3087 followed by \u3049 acts\n        like a long vowel marker. This doesn't occur in dictionary words,\n        but it's the most sensible behavior for unusual input.\n\n        If the currently active character ends with the same vowel as this\n        small vowel, a long vowel marker is added instead.\n        E.g. \u30c6\u30a7 becomes 't\u0113'.\n        '''\n        xvowel_info = kana_lt[xvowel]\n        vowel_info = self.active_vowel_info\n        dgr_b_info = None\n\n        # Special case: if the currently active character is 'n', we must\n        # flush the character and set this small vowel as the active character.\n        # This is because small vowels cannot affect 'n' like regular\n        # consonant-vowel pairs.\n        curr_is_n = self.active_vowel_ro == 'n'\n\n        # Special case: if we've got an active vowel with special cases\n        # attached to it (only \u30a6), and the small vowel that follows it\n        # activates that special case, we may need to backtrack a bit.\n        # This is because \u30a6 is normally 'u' but becomes 'w' if there's\n        # a small vowel right behind it (except the small 'u').\n        # The 'w' behaves totally different from a standard vowel.\n        if self.has_u_lvm and \\\n           xvowel_info is not None and \\\n           vowel_info is not None and \\\n           len(vowel_info) > 2 and \\\n           vowel_info[2].get('xv') is not None and \\\n           vowel_info[2]['xv'].get(xvowel_info[0]) is not None:\n            # Decrement the long vowel marker, which was added on the\n            # assumption that the 'u' is a vowel.\n            self._dec_lvmarker()\n            # Save the current vowel. We'll flush the current character,\n            # without this vowel, and then set it again from a clean slate.\n            former_vowel = self.active_vowel\n            self.active_vowel_info = None\n            self._flush_char()\n            self._set_char(former_vowel, VOWEL)\n\n        if self.active_vowel_ro == xvowel_info[0]:\n            # We have an active character whose vowel is the same.\n            self._inc_lvmarker()\n        elif self.has_xvowel is True:\n            # We have an active small vowel already. Flush the current\n            # character and act as though the current small vowel\n            # is a regular vowel.\n            self._flush_char()\n            self._set_char(xvowel, XVOWEL)\n            return\n        elif self.has_digraph_b is True:\n            # We have an active digraph (two parts).\n            dgr_b_info = self.active_dgr_b_info\n\n        if curr_is_n:\n            self._set_char(xvowel, XVOWEL)\n            return\n\n        if dgr_b_info is not None:\n            if self._is_long_vowel(self.active_vowel_ro, dgr_b_info[0]) or \\\n               self._is_long_vowel(self.active_dgr_b_info[0], dgr_b_info[0]):\n                # Same vowel as the one that's currently active.\n                self._inc_lvmarker()\n            else:\n                # Not the same, so flush the active character and continue.\n                self.active_vowel_ro = self.active_xvowel_info[0]\n                self._set_char(xvowel, XVOWEL)\n        else:\n            self.active_xvowel = xvowel\n            self.active_xvowel_info = xvowel_info\n\n        self.has_xvowel = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _postprocess_output(self, output):\n        '''\n        Performs the last modifications before the output is returned.\n        '''\n        # Replace long vowels with circumflex characters.\n        if self.vowel_style == CIRCUMFLEX_STYLE:\n            try:\n                output = output.translate(vowels_to_circumflexes)\n            except TypeError:\n                # Python 2 will error out here if there are no\n                # macron characters in the string to begin with.\n                pass\n\n        # Output the desired case.\n        if self.uppercase:\n            output = output.upper()\n\n        return output", "response": "Performs the last modifications before the output is returned."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _flush_stack(self):\n        '''\n        Returns the final output and resets the machine's state.\n        '''\n        output = self._postprocess_output(''.join(self.stack))\n        self._clear_char()\n        self._empty_stack()\n\n        if not PYTHON_2:\n            return output\n        else:\n            return unicode(output)", "response": "Returns the final output and resets the machine s state."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _preprocess_chars(self, chars):\n        '''\n        Performs string preprocessing before the main conversion algorithm\n        is used. Simple string replacements (for example, fullwidth r\u014dmaji\n        to regular r\u014dmaji) are performed at this point.\n        '''\n        chars = self._normalize_dakuten(chars)\n        chars = self._process_repeaters(chars)\n        chars = self._perform_replacements(chars)\n\n        return chars", "response": "Performs string preprocessing before the main conversion algorithm\n        is used."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding additional spacing to punctuation characters.", "response": "def _add_punctuation_spacing(self, input):\n        '''\n        Adds additional spacing to punctuation characters. For example,\n        this puts an extra space after a fullwidth full stop.\n        '''\n        for replacement in punct_spacing:\n            input = re.sub(replacement[0], replacement[1], input)\n\n        return input"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms simple key value string replacements that require no logic.", "response": "def _perform_replacements(self, chars):\n        '''\n        Performs simple key/value string replacements that require no logic.\n        This is used to convert the fullwidth r\u014dmaji, several ligatures,\n        and the punctuation characters.\n        '''\n        for n in range(len(chars)):\n            char = chars[n]\n            if char in repl:\n                chars[n] = repl[char]\n\n        # Some replacements might result in multi-character strings\n        # being inserted into the list. Ensure we still have a list\n        # of single characters for iteration.\n        return list(''.join(chars))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _normalize_dakuten(self, chars):\n        '''\n        Replaces the dakuten and handakuten modifier character combinations\n        with single characters. For example, \u304b\\u3099\u304b becomes \u304c\u3051,\n        or \u306f\u309c\u306f becomes \u3071\u306f.\n        '''\n        prev = None\n        prev_n = None\n\n        # Set all repeater characters to 0 initially,\n        # then go through the list and remove them all.\n        for n in range(len(chars)):\n            char = chars[n]\n\n            if char in dkt:\n                chars[n] = 0\n                if prev in dkt_cvs:\n                    chars[prev_n] = dkt_lt[prev]\n\n            if char in hdkt:\n                chars[n] = 0\n                if prev in hdkt_cvs:\n                    chars[prev_n] = hdkt_lt[prev]\n\n            prev = char\n            prev_n = n\n\n        # Remove all 0 values. There should not be any other than the ones we\n        # just added. (This could use (0).__ne__, but that's Python 3 only.)\n        return list(filter(lambda x: x is not 0, chars))", "response": "Normalizes the dakuten and handakuten modifier character combinations."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _process_repeaters(self, chars):\n        '''\n        Replace all repeater characters (e.g. turn \u30b5\u30fe\u30a8 into \u30b5\u30b6\u30a8).\n        '''\n        prev = None\n        for n in range(len(chars)):\n            char = chars[n]\n            if char in rpts:\n                # The character is a repeater.\n                chars[n] = prev\n\n            if char in drpts:\n                # The character is a repeater with dakuten.\n                # If the previous character can have a dakuten, add that\n                # to the stack; if not, just add whatever we had previously.\n                if prev in dkt_cvs:\n                    chars[n] = dkt_lt[prev]\n                else:\n                    chars[n] = prev\n\n            prev = char\n\n        return chars", "response": "Replace all repeater characters in chars with their respective system - specific ones."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_romaji(self, input):\n        '''\n        Converts kana input to r\u014dmaji and returns the result.\n        '''\n        input = self._preprocess_input(input)\n\n        # Preprocess the input, making string replacements where needed.\n        chars = list(input)\n        chars = self._preprocess_chars(chars)\n\n        chars.append(END_CHAR)\n        for char in chars:\n            if char in di_a:\n                self._set_digraph_a(char)\n                continue\n\n            if char in di_b:\n                self._set_digraph_b(char)\n                continue\n\n            if char in cvs:\n                self._set_char(char, CV)\n                continue\n\n            if char in vowels:\n                self._set_vowel(char)\n                continue\n\n            if char in xvowels:\n                self._set_xvowel(char)\n                continue\n\n            if char in geminates:\n                self._inc_geminate()\n                continue\n\n            if char == lvmarker:\n                self._inc_lvmarker()\n                continue\n\n            if char == WORD_BORDER:\n                # When stumbling upon a word border, e.g. in \u306c\u308c|\u3048\u3093,\n                # the current word has finished, meaning the character\n                # should be flushed.\n                self._flush_char()\n                continue\n\n            if char == END_CHAR:\n                self._promote_solitary_xvowel()\n                self._flush_char()\n                continue\n\n            # If we're still here, that means we've stumbled upon a character\n            # the machine can't deal with.\n            if self.unknown_strategy == UNKNOWN_DISCARD:\n                continue\n\n            if self.unknown_strategy == UNKNOWN_RAISE:\n                raise UnexpectedCharacterError\n\n            if self.unknown_strategy == UNKNOWN_INCLUDE:\n                # The default strategy.\n                self._add_unknown_char(char)\n\n        return self._flush_stack()", "response": "Converts a kana input to r\u014dmaji and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render(self, request, collect_render_data=True, **kwargs):\n        assert self.render_type in self.renders\n        render = self.renders[self.render_type]\n        if collect_render_data:\n            kwargs = self.get_render_data(**kwargs)\n\n        return render.render(request, **kwargs)", "response": "Render this view. This will call the render method\n        on the render class specified.\n\n        :param request: The request object\n        :param collect_render_data: If True we will call \\\n        the get_render_data method to pass a complete context \\\n        to the renderer.\n        :param kwargs: Any other keyword arguments that should \\\n        be passed to the renderer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_tags(self, view_object=None):\n        tags = [force_unicode(self.bundle.get_title())]\n        back_bundle = self.get_back_bundle()\n        if back_bundle and back_bundle != self.bundle:\n            tags.append(force_unicode(back_bundle.get_title()))\n        if view_object:\n            tags.append(force_unicode(view_object))\n\n        return tags", "response": "This method returns a list of tags to use in the template\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning all data that should be passed to the renderer.", "response": "def get_render_data(self, **kwargs):\n        \"\"\"\n        Returns all data that should be passed to the renderer.\n        By default adds the following arguments:\n\n        * **bundle** - The bundle that is attached to this view instance.\n        * **url_params** - The url keyword arguments. i.e.: self.kwargs.\n        * **user** - The user attached to this request.\n        * **base** - Unless base was already specified this gets set to \\\n        'self.base_template'.\n        * **navigation** - The navigation bar for the page\n        * **object_header_tmpl** - The template to use for the \\\n        object_header. Set to `self.object_header_tmpl`.\n        * **back_bundle** - The back_back bundle is bundle that is linked to \\\n        from the object header as part of navigation. If there is an 'obj' \\\n        argument in the context to render, this will be set to the bundle \\\n        pointed to by the `main_list` attribute of this view's bundle. \\\n        If this is not set, the template's back link will point to the \\\n        admin_site's home page.\n        \"\"\"\n\n        obj = getattr(self, 'object', None)\n        data = dict(self.extra_render_data)\n        data.update(kwargs)\n        data.update({\n            'bundle': self.bundle,\n            'navigation': self.get_navigation(),\n            'url_params': self.kwargs,\n            'user': self.request.user,\n            'object_header_tmpl': self.object_header_tmpl,\n            'view_tags': tag_handler.tags_to_string(self.get_tags(obj))\n        })\n\n        if not 'base' in data:\n            data['base'] = self.base_template\n\n        if not 'back_bundle' in data:\n            data['back_bundle'] = self.get_back_bundle()\n\n        return super(CMSView, self).get_render_data(**data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the user can view the entry in the cache.", "response": "def can_view(self, user):\n        \"\"\"\n        Returns True if user has permission to render this view.\n\n        At minimum this requires an active staff user. If the required_groups\n        attribute is not empty then the user must be a member of at least one\n        of those groups. If there are no required groups set for the view but\n        required groups are set for the bundle then the user must be a member\n        of at least one of those groups. If there are no groups to check this\n        will return True.\n        \"\"\"\n\n        if user.is_staff and user.is_active:\n            if user.is_superuser:\n                return True\n            elif self.required_groups:\n                return self._user_in_groups(user, self.required_groups)\n            elif self.bundle.required_groups:\n                return self._user_in_groups(user, self.bundle.required_groups)\n            else:\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_url_kwargs(self, request_kwargs=None, **kwargs):\n\n        if not request_kwargs:\n            request_kwargs = getattr(self, 'kwargs', {})\n\n        for k in self.bundle.url_params:\n            if k in request_kwargs and not k in kwargs:\n                kwargs[k] = request_kwargs[k]\n        return kwargs", "response": "Get the kwargs needed to reverse this url."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhook for customizing widgets for a form_class.", "response": "def customize_form_widgets(self, form_class, fields=None):\n        \"\"\"\n        Hook for customizing widgets for a form_class. This is needed\n        for forms that specify their own fields causing the\n        default db_field callback to not be run for that field.\n\n        Default implementation checks for APIModelChoiceWidgets\n        or APIManyChoiceWidgets and runs the update_links method\n        on them. Passing the admin_site and request being used.\n\n        Returns a new class that contains the field with the initialized\n        custom widget.\n        \"\"\"\n        attrs = {}\n        if fields:\n            fields = set(fields)\n\n        for k, f in form_class.base_fields.items():\n            if fields and not k in fields:\n                continue\n\n            if isinstance(f.widget, widgets.APIModelChoiceWidget) \\\n                    or isinstance(f.widget, widgets.APIManyChoiceWidget):\n                field = copy.deepcopy(f)\n                field.widget.update_links(self.request, self.bundle.admin_site)\n                attrs[k] = field\n\n        if attrs:\n            form_class = type(form_class.__name__, (form_class,), attrs)\n\n        return form_class"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\noverrides the default dispatch method to raise a Http404Exception if the current user does not have view permissions.", "response": "def dispatch(self, request, *args, **kwargs):\n        \"\"\"\n        Overrides the custom dispatch method to raise a Http404\n        if the current user does not have view permissions.\n        \"\"\"\n        self.request = request\n        self.args = args\n        self.kwargs = kwargs\n\n        if not self.can_view(request.user):\n            raise http.Http404\n\n        return super(CMSView, self).dispatch(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhook for specifying the form Field instance for a given database Field instance.", "response": "def formfield_for_dbfield(self, db_field, **kwargs):\n        \"\"\"\n        Hook for specifying the form Field instance for a given\n        database Field instance. If kwargs are given, they're\n        passed to the form Field's constructor.\n\n        Default implementation uses the overrides returned by\n        `get_formfield_overrides`. If a widget is an instance\n        of APIChoiceWidget this will do lookup on the current\n        admin site for the bundle that is registered for that\n        module as the primary bundle for that one model. If a\n        match is found then this will call update_links on that\n        widget to store the appropriate urls for the javascript\n        to call. Otherwise the widget is removed and the default\n        select widget will be used instead.\n        \"\"\"\n\n        overides = self.get_formfield_overrides()\n\n        # If we've got overrides for the formfield defined, use 'em. **kwargs\n        # passed to formfield_for_dbfield override the defaults.\n        for klass in db_field.__class__.mro():\n            if klass in overides:\n                kwargs = dict(overides[klass], **kwargs)\n                break\n\n        # Our custom widgets need special init\n        mbundle = None\n        extra = kwargs.pop('widget_kwargs', {})\n        widget = kwargs.get('widget')\n        if kwargs.get('widget'):\n            if widget and isinstance(widget, type) and \\\n                            issubclass(widget, widgets.APIChoiceWidget):\n                mbundle = self.bundle.admin_site.get_bundle_for_model(\n                                                db_field.rel.to)\n                if mbundle:\n                    widget = widget(db_field.rel, **extra)\n                else:\n                    widget = None\n\n        if getattr(self, 'prepopulated_fields', None) and \\\n                        not getattr(self, 'object', None) and \\\n                        db_field.name in self.prepopulated_fields:\n            extra = kwargs.pop('widget_kwargs', {})\n            attr = extra.pop('attrs', {})\n            attr['data-source-fields'] = self.prepopulated_fields[db_field.name]\n            extra['attrs'] = attr\n            if not widget:\n                from django.forms.widgets import TextInput\n                widget = TextInput(**extra)\n            elif widget and isinstance(widget, type):\n                widget = widget(**extra)\n\n        kwargs['widget'] = widget\n\n        field = db_field.formfield(**kwargs)\n        if mbundle:\n            field.widget.update_links(self.request, self.bundle.admin_site)\n        return field"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef log_action(self, instance, action, action_date=None, url=\"\",\n                   update_parent=True):\n        \"\"\"\n        Store an action in the database using the CMSLog model.\n        The following attributes are calculated and set on the log entry:\n\n         * **model_repr** - A unicode representation of the instance.\n         * **object_repr** - The verbose_name of the instance model class.\n         * **section** - The name of ancestor bundle that is directly \\\n         attached to the admin site.\n\n        :param instance: The instance that this action was performed \\\n        on.\n        :param action: The action type. Must be one of the options \\\n        in CMSLog.ACTIONS.\n        :param action_date: The datetime the action occurred.\n        :param url: The url that the log entry should point to, \\\n        Defaults to an empty string.\n        :param update_parent: If true this will update the last saved time \\\n        on the object pointed to by this bundle's object_view. \\\n        Defaults to True.\n        \"\"\"\n\n        section = None\n        if self.bundle:\n            bundle = self.bundle\n            while bundle.parent:\n                bundle = bundle.parent\n            section = bundle.name\n\n        # if we have a object view that comes from somewhere else\n        # save it too to update it.\n        changed_object = instance\n        bundle = self.bundle\n        while bundle.object_view == bundle.parent_attr:\n            bundle = bundle.parent\n\n        if update_parent and changed_object.__class__ != bundle._meta.model:\n            object_view, name = bundle.get_initialized_view_and_name(\n                                    bundle.object_view, kwargs=self.kwargs)\n\n            changed_object = object_view.get_object()\n            changed_object.save()\n\n        if not section:\n            section = \"\"\n\n        if url:\n            url = urlparse.urlparse(url).path\n\n        rep = unicode(instance)\n        if rep:\n            rep = rep[:255]\n\n        log = CMSLog(action=action, url=url, section=section,\n                     model_repr=instance._meta.verbose_name,\n                     object_repr=rep,\n                     user_name=self.request.user.username,\n                     action_date=action_date)\n        log.save()", "response": "Store an action in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_filter(self, **filter_kwargs):\n        filter_kwargs.update(self.base_filter_kwargs)\n        if filter_kwargs:\n            return [models.Q(**filter_kwargs)]\n        return []", "response": "Returns a list of Q objects that can be passed in keyword arguments to an queryset for filtering."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the list of items for this view.", "response": "def get_queryset(self, **filter_kwargs):\n        \"\"\"\n        Get the list of items for this view. This will\n        call the `get_parent_object` method before doing\n        anything else to ensure that a valid parent object\n        is present. If a parent_object is returned it gets\n        set to `self.parent_object`.\n\n        If a queryset has been set then that queryset will be used.\n        Otherwise the default manager for the provided\n        model will be used.\n\n        Once we have a queryset, the `get_filter` method\n        is called and added to the queryset which is then\n        returned.\n        \"\"\"\n        self.parent_object = self.get_parent_object()\n\n        if self.queryset is not None:\n            queryset = self.queryset\n            if hasattr(queryset, '_clone'):\n                queryset = queryset._clone()\n        elif self.model is not None:\n            queryset = self.model._default_manager.filter()\n        else:\n            raise ImproperlyConfigured(u\"'%s' must define 'queryset' or 'model'\"\n                                       % self.__class__.__name__)\n\n        q_objects = self.get_filter(**filter_kwargs)\n        queryset = queryset.filter()\n        for q in q_objects:\n            queryset = queryset.filter(q)\n\n        return queryset"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_parent_object(self):\n\n        if self.parent_field:\n            # Get the model we are querying on\n            if getattr(self.model._meta, 'init_name_map', None):\n                # pre-django-1.8\n                cache = self.model._meta.init_name_map()\n                field, mod, direct, m2m = cache[self.parent_field]\n            else:\n                # 1.10\n                if DJANGO_VERSION[1] >= 10:\n                    field = self.model._meta.get_field(self.parent_field)\n                    m2m = field.is_relation and field.many_to_many\n                    direct = not field.auto_created or field.concrete\n                else:\n                    # 1.8 and 1.9\n                    field, mod, direct, m2m = self.model._meta.get_field(self.parent_field)\n\n            to = None\n            field_name = None\n            if self.parent_lookups is None:\n                self.parent_lookups = ('pk',)\n\n            url_params = list(self.bundle.url_params)\n            if url_params and getattr(self.bundle, 'delegated', False):\n                url_params = url_params[:-1]\n\n            offset = len(url_params) - len(self.parent_lookups)\n            kwargs = {}\n            for i in range(len(self.parent_lookups) - 1):\n                k = url_params[offset + i]\n                value = self.kwargs[k]\n                kwargs[self.parent_lookups[i + 1]] = value\n\n            main_arg = self.kwargs[url_params[-1]]\n            main_key = self.parent_lookups[0]\n\n            if m2m:\n                rel = getattr(self.model, self.parent_field)\n                kwargs[main_key] = main_arg\n                if direct:\n                    to = rel.field.rel.to\n                    field_name = self.parent_field\n                else:\n                    try:\n                        from django.db.models.fields.related import (\n                            ForeignObjectRel)\n                        if isinstance(rel.rel, ForeignObjectRel):\n                            to = rel.rel.related_model\n                        else:\n                            to = rel.rel.model\n                    except ImportError:\n                        to = rel.rel.model\n                    field_name = rel.rel.field.name\n            else:\n                to = field.rel.to\n                if main_key == 'pk':\n                    to_field = field.rel.field_name\n                    if to_field == 'vid':\n                        to_field = 'object_id'\n                else:\n                    to_field = main_key\n                kwargs[to_field] = main_arg\n\n            # Build the list of arguments\n            try:\n                obj = to.objects.get(**kwargs)\n                if self.queryset is None:\n                    if m2m:\n                        self.queryset = getattr(obj, field_name)\n                    else:\n                        self.queryset = self.model.objects.filter(\n                                                    **{self.parent_field: obj})\n                return obj\n            except to.DoesNotExist:\n                raise http.Http404\n        return None", "response": "Lookup a parent object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_message(self, status=messages.INFO, message=None):\n        if not message:\n                message = u\"%s saved\" % self.object\n        messages.add_message(self.request, status, message)\n        return message", "response": "Writes a message to django s messaging framework and returns the message."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_url_kwargs(self, request_kwargs=None, **kwargs):\n\n        if not request_kwargs:\n            request_kwargs = getattr(self, 'kwargs', {})\n\n        kwargs = super(ModelCMSView, self).get_url_kwargs(request_kwargs,\n                                                          **kwargs)\n        obj = kwargs.pop('object', None)\n        if obj:\n            kwargs[self.slug_url_kwarg] = getattr(obj, self.slug_field, None)\n        elif self.slug_url_kwarg in request_kwargs:\n            kwargs[self.slug_url_kwarg] = request_kwargs[self.slug_url_kwarg]\n\n        return kwargs", "response": "Returns the kwargs that will be passed to the url_for method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the model_name to the context and then calls super. get_render_data", "response": "def get_render_data(self, **kwargs):\n        \"\"\"\n        Adds the model_name to the context, then calls super.\n        \"\"\"\n        kwargs['model_name'] = self.model_name\n        kwargs['model_name_plural'] = self.model_name_plural\n        return super(ModelCMSView, self).get_render_data(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_filter_form(self, **kwargs):\n\n        form = None\n        if self.filter_form:\n            form = self.filter_form(self.request.GET)\n        elif self.model and hasattr(self.model._meta, '_is_view'):\n            form = VersionFilterForm(self.request.GET)\n        return form", "response": "Returns the filter form for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of Q objects that can be passed to the queryset.", "response": "def get_filter(self, **filter_kwargs):\n        \"\"\"\n        Combines the Q objects returned by a valid\n        filter form with any other arguments and\n        returns a list of Q objects that can be passed\n        to a queryset.\n        \"\"\"\n\n        q_objects = super(ListView, self).get_filter(**filter_kwargs)\n        form = self.get_filter_form()\n        if form:\n            q_objects.extend(form.get_filter())\n\n        return q_objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_formset_form_class(self):\n        if self.form_class or self.change_fields:\n            params = {'formfield_callback': self.formfield_for_dbfield}\n            if self.form_class:\n                fc = self.customize_form_widgets(self.form_class)\n                params['form'] = fc\n            if self.change_fields:\n                params['fields'] = self.change_fields\n\n            return model_forms.modelform_factory(self.model, **params)", "response": "Returns the form class for use in the formset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_formset_class(self, **kwargs):\n        form_class = self.get_formset_form_class()\n        if form_class:\n            kwargs['formfield_callback'] = self.formfield_for_dbfield\n            return model_forms.modelformset_factory(self.model,\n                        form_class, fields=self.change_fields, extra=0,\n                        **kwargs)", "response": "Returns the formset class for the queryset if one is available."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_formset(self, data=None, queryset=None):\n        if not self.can_submit:\n            return None\n\n        FormSet = self.get_formset_class()\n        if queryset is None:\n            queryset = self.get_queryset()\n\n        if FormSet:\n            if data:\n                queryset = self._add_formset_id(data, queryset)\n            return FormSet(data, queryset=queryset)", "response": "Returns an instantiated FormSet if available."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_list_data(self, request, **kwargs):\n\n        self.object_list = self.get_queryset()\n        self._verify_list()\n\n        sort_field = None\n        order_type = None\n        if self.can_sort:\n            default = None\n            default_order = helpers.AdminList.ASC\n            if self.object_list.ordered:\n                if self.object_list.query.order_by:\n                    default = self.object_list.query.order_by[0]\n                else:\n                    default = self.object_list.model._meta.ordering[0]\n                if default.startswith('-'):\n                    default = default[1:]\n                    default_order = helpers.AdminList.DESC\n\n            sort_field = request.GET.get('sf', default)\n            order_type = request.GET.get('ot', default_order)\n\n        queryset = self._sort_queryset(self.object_list, sort_field,\n                                       order_type)\n\n        if self.request.method == 'POST' and self.can_submit:\n            formset = self.get_formset(data=self.request.POST, queryset=queryset)\n            is_paginated, page, paginator, queryset = self._paginate_queryset(queryset)\n        else:\n            is_paginated, page, paginator, queryset = self._paginate_queryset(queryset)\n            formset = self.get_formset(queryset=queryset)\n\n        visible_fields = self.get_visible_fields(formset)\n        adm_list = helpers.AdminList(formset, queryset, visible_fields,\n                                       sort_field, order_type,\n                                       self.model_name)\n\n        actions = self.get_action_context(request)\n        data = {\n            'list': adm_list,\n            'filter_form': self.get_filter_form(),\n            'page_obj': page,\n            'is_paginated': is_paginated,\n            'show_form': (self.can_submit and formset is not None),\n            'paginator': paginator,\n            'checkbox_name' : CHECKBOX_NAME,\n            'actions' : actions,\n        }\n\n        return data", "response": "Returns the data needed for displaying the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the context data for this view.", "response": "def get_context_data(self, **kwargs):\n        \"\"\"\n        Get the context for this view. Adds the following values:\n\n        * **query_string** - The querystring minus the current page.\n        * **action_links** - The results of the `get_actions` method.\n        \"\"\"\n\n        origin_qs = self._get_query_string(self.request, False)\n        context = {\n            'query_string': self._get_query_string(self.request),\n            'origin_qs': self.request.path + origin_qs,\n            'origin_var': self.ORIGIN_ARGUMENT,\n            'action_links': self.get_actions()\n        }\n        context.update(kwargs)\n\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, request, *args, **kwargs):\n\n        if request.GET.get('type') == 'choices':\n            self.render_type = 'choices'\n            self.can_submit = False\n\n        data = self.get_list_data(request, **kwargs)\n        return self.render(request, **data)", "response": "Method for handling GET requests."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post(self, request, *args, **kwargs):\n        msg = None\n        action = request.POST.get('actions', None)\n        selected = request.POST.getlist(CHECKBOX_NAME)\n        if not action == 'None' and action is not None:\n            if len(selected) > 0:\n                sel = {CHECKBOX_NAME : ','.join(selected)}\n                qs = '?' + urlencode(sel)\n                return self.render(request, redirect_url = action + qs)\n\n        data = self.get_list_data(request, **kwargs)\n\n        l = data.get('list')\n        formset = None\n        if l and l.formset:\n            formset = l.formset\n\n        url = self.request.build_absolute_uri()\n        if formset:\n            # Normally calling validate on a formset.\n            # will result in a db call for each pk in\n            # the formset regardless if the form has\n            # changed or not.\n            # To try to reduce queries only do a full\n            # validate on forms that changed.\n            # TODO: Find a way to not have to do\n            # a pk lookup for any since we already\n            # have the instance we want\n            for form in formset.forms:\n                if not form.has_changed():\n                    form.cleaned_data = {}\n                    form._errors = {}\n\n        if formset and formset.is_valid():\n            changecount = 0\n            with transaction.commit_on_success():\n                for form in formset.forms:\n                    if form.has_changed():\n                        obj = form.save()\n                        changecount += 1\n                        self.log_action(obj, CMSLog.SAVE, url=url,\n                                        update_parent=changecount == 1)\n\n            return self.render(request, redirect_url=url,\n                           message=\"%s items updated\" % changecount,\n                           collect_render_data=False)\n        else:\n            return self.render(request, message = msg, **data)", "response": "Method for handling POST requests.\n        If the formset is valid this will\n        loop through the formset and save each form.\n        A log is generated for each save. The user\n        is notified of the total number of changes\n        with a message. Returns a 'render redirect' to\n        the current url.\n\n        TODO: These formsets suffer from the same potential concurrency\n        issues that the django admin has. This is caused by some issues\n        with django formsets and concurrent users editing the same\n        objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the lines that have been modified by the user.", "response": "def get_user_modified_lines(self):\n        \"\"\"\n        Output: {file_path: [(line_a_start, line_a_end), (line_b_start, line_b_end)]}\n\n        Lines ranges are sorted and not overlapping\n        \"\"\"\n        # I assume that git diff:\n        # - doesn't mix diffs from different files,\n        # - diffs are not overlapping\n        # - diffs are sorted based on line numbers\n        output = {}\n\n        FILE_NAME_RE = r'^\\+\\+\\+ (.+)$'\n        CHANGED_LINES_RE = r'^@@ -[0-9,]+ \\+([0-9]+)(?:,([0-9]+))? @@'\n        current_file_name = None\n\n        for line in self.git_wrapper.get_min_diff(self.remote_sha1, self.local_sha1).split('\\n'):\n            file_name_match = re.match(FILE_NAME_RE, line)\n            if file_name_match:\n                current_file_name, = file_name_match.groups()\n                output[current_file_name] = []\n                continue\n\n            line_number_match = re.match(CHANGED_LINES_RE, line)\n            if line_number_match:\n                assert current_file_name\n                if current_file_name == '/dev/null':\n                    continue\n                line_start, diff_len = line_number_match.groups()\n                line_start, diff_len = int(line_start), int(diff_len or 0)\n                output[current_file_name].append(LinesRange(line_start, line_start + diff_len))\n                continue\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare_files(self, target_dir):\n        diff_names = self.git_wrapper.get_diff_names(self.remote_sha1, self.local_sha1)\n        files_modified = diff_names.split('\\n')\n        extensions = LINTERS.keys()\n\n        for file_path in files_modified:\n            extension = file_path.split('.')[-1]\n            if extension not in extensions:\n                continue\n\n            new_file_path = os.path.join(target_dir, file_path)\n            new_dirname = os.path.dirname(new_file_path)\n            if not os.path.isdir(new_dirname):\n                os.makedirs(new_dirname)\n\n            with open(new_file_path, \"wb\") as fh:\n                self.git_wrapper.save_content_to_file(file_path, self.local_ref, fh)\n            yield new_file_path", "response": "Prepare local files for the local branch."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a ping message to slack every 20 seconds", "response": "def schedule_ping_frequency(self):  # pragma: no cover\n        \"Send a ping message to slack every 20 seconds\"\n        ping = crontab('* * * * * */20', func=self.send_ping, start=False)\n        ping.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncleans OF ALL THREADS CREATED WITH THIS LIBRARY", "response": "def stop_main_thread(*args):\n    \"\"\"\n    CLEAN OF ALL THREADS CREATED WITH THIS LIBRARY\n    \"\"\"\n    try:\n        if len(args) and args[0] != _signal.SIGTERM:\n            Log.warning(\"exit with {{value}}\", value=_describe_exit_codes.get(args[0], args[0]))\n    except Exception as _:\n        pass\n    finally:\n        MAIN_THREAD.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwait for the user to exit.", "response": "def _wait_for_exit(please_stop):\n    \"\"\"\n    /dev/null PIPED TO sys.stdin SPEWS INFINITE LINES, DO NOT POLL AS OFTEN\n    \"\"\"\n    try:\n        import msvcrt\n        _wait_for_exit_on_windows(please_stop)\n    except:\n        pass\n\n    cr_count = 0  # COUNT NUMBER OF BLANK LINES\n\n    while not please_stop:\n        # DEBUG and Log.note(\"inside wait-for-shutdown loop\")\n        if cr_count > 30:\n            (Till(seconds=3) | please_stop).wait()\n        try:\n            line = sys.stdin.readline()\n        except Exception as e:\n            Except.wrap(e)\n            if \"Bad file descriptor\" in e:\n                _wait_for_interrupt(please_stop)\n                break\n\n        # DEBUG and Log.note(\"read line {{line|quote}}, count={{count}}\", line=line, count=cr_count)\n        if line == \"\":\n            cr_count += 1\n        else:\n            cr_count = -1000000  # NOT /dev/null\n\n        if line.strip() == \"exit\":\n            Log.alert(\"'exit' Detected!  Stopping...\")\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, target, *args, **kwargs):\n        t = Thread.run(target.__name__, target, *args, **kwargs)\n        self.threads.append(t)", "response": "Add a new thread to the list of threads."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstopping the thread and all its children.", "response": "def stop(self):\n        \"\"\"\n        BLOCKS UNTIL ALL THREADS HAVE STOPPED\n        THEN RUNS sys.exit(0)\n        \"\"\"\n        global DEBUG\n\n        self_thread = Thread.current()\n        if self_thread != MAIN_THREAD or self_thread != self:\n            Log.error(\"Only the main thread can call stop() on main thread\")\n\n        DEBUG = True\n        self.please_stop.go()\n\n        join_errors = []\n        with self.child_lock:\n            children = copy(self.children)\n        for c in reversed(children):\n            DEBUG and c.name and Log.note(\"Stopping thread {{name|quote}}\", name=c.name)\n            try:\n                c.stop()\n            except Exception as e:\n                join_errors.append(e)\n\n        for c in children:\n            DEBUG and c.name and Log.note(\"Joining on thread {{name|quote}}\", name=c.name)\n            try:\n                c.join()\n            except Exception as e:\n                join_errors.append(e)\n\n            DEBUG and c.name and Log.note(\"Done join on thread {{name|quote}}\", name=c.name)\n\n        if join_errors:\n            Log.error(\"Problem while stopping {{name|quote}}\", name=self.name, cause=unwraplist(join_errors))\n\n        self.stop_logging()\n        self.timers.stop()\n        self.timers.join()\n\n        write_profiles(self.cprofiler)\n        DEBUG and Log.note(\"Thread {{name|quote}} now stopped\", name=self.name)\n        sys.exit()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwait for shutdown of the current instance of the current instance.", "response": "def wait_for_shutdown_signal(\n        self,\n        please_stop=False,  # ASSIGN SIGNAL TO STOP EARLY\n        allow_exit=False,  # ALLOW \"exit\" COMMAND ON CONSOLE TO ALSO STOP THE APP\n        wait_forever=True  # IGNORE CHILD THREADS, NEVER EXIT.  False => IF NO CHILD THREADS LEFT, THEN EXIT\n    ):\n        \"\"\"\n        FOR USE BY PROCESSES THAT NEVER DIE UNLESS EXTERNAL SHUTDOWN IS REQUESTED\n\n        CALLING THREAD WILL SLEEP UNTIL keyboard interrupt, OR please_stop, OR \"exit\"\n\n        :param please_stop:\n        :param allow_exit:\n        :param wait_forever:: Assume all needed threads have been launched. When done\n        :return:\n        \"\"\"\n        self_thread = Thread.current()\n        if self_thread != MAIN_THREAD or self_thread != self:\n            Log.error(\"Only the main thread can sleep forever (waiting for KeyboardInterrupt)\")\n\n        if isinstance(please_stop, Signal):\n            # MUTUAL SIGNALING MAKES THESE TWO EFFECTIVELY THE SAME SIGNAL\n            self.please_stop.on_go(please_stop.go)\n            please_stop.on_go(self.please_stop.go)\n        else:\n            please_stop = self.please_stop\n\n        if not wait_forever:\n            # TRIGGER SIGNAL WHEN ALL CHILDREN THEADS ARE DONE\n            with self_thread.child_lock:\n                pending = copy(self_thread.children)\n            children_done = AndSignals(please_stop, len(pending))\n            children_done.signal.on_go(self.please_stop.go)\n            for p in pending:\n                p.stopped.on_go(children_done.done)\n\n        try:\n            if allow_exit:\n                _wait_for_exit(please_stop)\n            else:\n                _wait_for_interrupt(please_stop)\n        except KeyboardInterrupt as _:\n            Log.alert(\"SIGINT Detected!  Stopping...\")\n        except SystemExit as _:\n            Log.alert(\"SIGTERM Detected!  Stopping...\")\n        finally:\n            self.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstopping all the children of this thread.", "response": "def stop(self):\n        \"\"\"\n        SEND STOP SIGNAL, DO NOT BLOCK\n        \"\"\"\n        with self.child_lock:\n            children = copy(self.children)\n        for c in children:\n            DEBUG and c.name and Log.note(\"Stopping thread {{name|quote}}\", name=c.name)\n            c.stop()\n        self.please_stop.go()\n\n        DEBUG and Log.note(\"Thread {{name|quote}} got request to stop\", name=self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef join(self, till=None):\n        if self is Thread:\n            Log.error(\"Thread.join() is not a valid call, use t.join()\")\n\n        with self.child_lock:\n            children = copy(self.children)\n        for c in children:\n            c.join(till=till)\n\n        DEBUG and Log.note(\"{{parent|quote}} waiting on thread {{child|quote}}\", parent=Thread.current().name, child=self.name)\n        (self.stopped | till).wait()\n        if self.stopped:\n            self.parent.remove_child(self)\n            if not self.end_of_thread.exception:\n                return self.end_of_thread.response\n            else:\n                Log.error(\"Thread {{name|quote}} did not end well\", name=self.name, cause=self.end_of_thread.exception)\n        else:\n            raise Except(context=THREAD_TIMEOUT)", "response": "Joins the thread and all its children."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef inverse(d):\n    output = {}\n    for k, v in unwrap(d).items():\n        output[v] = output.get(v, [])\n        output[v].append(k)\n    return output", "response": "reverse the k : v pairs\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef zip(keys, values):\n    output = Data()\n    for i, k in enumerate(keys):\n        if i >= len(values):\n            break\n        output[k] = values[i]\n    return output", "response": "CONVERT LIST OF KEY - VALUE PAIRS TO Data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the tail of the given field.", "response": "def tail_field(field):\n    \"\"\"\n    RETURN THE FIRST STEP IN PATH, ALONG WITH THE REMAINING TAIL\n    \"\"\"\n    if field == \".\" or field==None:\n        return \".\", \".\"\n    elif \".\" in field:\n        if \"\\\\.\" in field:\n            return tuple(k.replace(\"\\a\", \".\") for k in field.replace(\"\\\\.\", \"\\a\").split(\".\", 1))\n        else:\n            return field.split(\".\", 1)\n    else:\n        return field, \".\""}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn field AS ARRAY OF DOT - SEPARATED FIELDS", "response": "def split_field(field):\n    \"\"\"\n    RETURN field AS ARRAY OF DOT-SEPARATED FIELDS\n    \"\"\"\n    if field == \".\" or field==None:\n        return []\n    elif is_text(field) and \".\" in field:\n        if field.startswith(\"..\"):\n            remainder = field.lstrip(\".\")\n            back = len(field) - len(remainder) - 1\n            return [-1]*back + [k.replace(\"\\a\", \".\") for k in remainder.replace(\"\\\\.\", \"\\a\").split(\".\")]\n        else:\n            return [k.replace(\"\\a\", \".\") for k in field.replace(\"\\\\.\", \"\\a\").split(\".\")]\n    else:\n        return [field]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef join_field(path):\n    output = \".\".join([f.replace(\".\", \"\\\\.\") for f in path if f != None])\n    return output if output else \".\"", "response": "Join a field with a list of field names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef startswith_field(field, prefix):\n    if prefix.startswith(\".\"):\n        return True\n        # f_back = len(field) - len(field.strip(\".\"))\n        # p_back = len(prefix) - len(prefix.strip(\".\"))\n        # if f_back > p_back:\n        #     return False\n        # else:\n        #     return True\n\n    if field.startswith(prefix):\n        if len(field) == len(prefix) or field[len(prefix)] == \".\":\n            return True\n    return False", "response": "Returns True if field starts with prefix"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef relative_field(field, parent):\n    if parent==\".\":\n        return field\n\n    field_path = split_field(field)\n    parent_path = split_field(parent)\n    common = 0\n    for f, p in _builtin_zip(field_path, parent_path):\n        if f != p:\n            break\n        common += 1\n\n    if len(parent_path) == common:\n        return join_field(field_path[common:])\n    else:\n        dots = \".\" * (len(parent_path) - common)\n        return dots + \".\" + join_field(field_path[common:])", "response": "RETURN field PATH WITH RESPECT TO parent\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the value of the key to value.", "response": "def _setdefault(obj, key, value):\n    \"\"\"\n    DO NOT USE __dict__.setdefault(obj, key, value), IT DOES NOT CHECK FOR obj[key] == None\n    \"\"\"\n    v = obj.get(key)\n    if v == None:\n        obj[key] = value\n        return value\n    return v"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_default(*params):\n    p0 = params[0]\n    agg = p0 if p0 or _get(p0, CLASS) in data_types else {}\n    for p in params[1:]:\n        p = unwrap(p)\n        if p is None:\n            continue\n        _all_default(agg, p, seen={})\n    return wrap(agg)", "response": "Set the default value of the base object for all the items in params."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _getdefault(obj, key):\n    try:\n        return obj[key]\n    except Exception as f:\n        pass\n\n    try:\n        return getattr(obj, key)\n    except Exception as f:\n        pass\n\n\n    try:\n        if float(key) == round(float(key), 0):\n            return obj[int(key)]\n    except Exception as f:\n        pass\n\n\n    # TODO: FIGURE OUT WHY THIS WAS EVER HERE (AND MAKE A TEST)\n    # try:\n    #     return eval(\"obj.\"+text_type(key))\n    # except Exception as f:\n    #     pass\n    return NullType(obj, key)", "response": "Get the default value of the object with the given key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the value of the attribute at the specified path.", "response": "def set_attr(obj, path, value):\n    \"\"\"\n    SAME AS object.__setattr__(), BUT USES DOT-DELIMITED path\n    RETURN OLD VALUE\n    \"\"\"\n    try:\n        return _set_attr(obj, split_field(path), value)\n    except Exception as e:\n        Log = get_logger()\n        if PATH_NOT_FOUND in e:\n            Log.warning(PATH_NOT_FOUND + \": {{path}}\", path=path, cause=e)\n        else:\n            Log.error(\"Problem setting value\", cause=e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the value of the attribute in the object at the specified path.", "response": "def get_attr(obj, path):\n    \"\"\"\n    SAME AS object.__getattr__(), BUT USES DOT-DELIMITED path\n    \"\"\"\n    try:\n        return _get_attr(obj, split_field(path))\n    except Exception as e:\n        Log = get_logger()\n        if PATH_NOT_FOUND in e:\n            Log.error(PATH_NOT_FOUND+\": {{path}}\",  path=path, cause=e)\n        else:\n            Log.error(\"Problem setting value\", e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wrap(v):\n\n    type_ = _get(v, CLASS)\n\n    if type_ is dict:\n        m = object.__new__(Data)\n        _set(m, SLOT, v)\n        return m\n    elif type_ is none_type:\n        return Null\n    elif type_ is list:\n        return FlatList(v)\n    elif type_ in generator_types:\n        return FlatList(list(unwrap(vv) for vv in v))\n    else:\n        return v", "response": "Returns the value v as a new object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform THE FOLLOWING TRANSLATION None -> [] value -> [value] [...] -> [...] (unchanged list) ##MOTIVATION## OFTEN IT IS NICE TO ALLOW FUNCTION PARAMETERS TO BE ASSIGNED A VALUE, OR A list-OF-VALUES, OR NULL. CHECKING FOR WHICH THE CALLER USED IS TEDIOUS. INSTEAD WE CAST FROM THOSE THREE CASES TO THE SINGLE CASE OF A LIST # BEFORE def do_it(a): if a is None: return if not isinstance(a, list): a=[a] for x in a: # do something # AFTER def do_it(a): for x in listwrap(a): # do something", "response": "def listwrap(value):\n    \"\"\"\n    PERFORMS THE FOLLOWING TRANSLATION\n    None -> []\n    value -> [value]\n    [...] -> [...]  (unchanged list)\n\n    ##MOTIVATION##\n    OFTEN IT IS NICE TO ALLOW FUNCTION PARAMETERS TO BE ASSIGNED A VALUE,\n    OR A list-OF-VALUES, OR NULL.  CHECKING FOR WHICH THE CALLER USED IS\n    TEDIOUS.  INSTEAD WE CAST FROM THOSE THREE CASES TO THE SINGLE CASE\n    OF A LIST\n\n    # BEFORE\n    def do_it(a):\n        if a is None:\n            return\n        if not isinstance(a, list):\n            a=[a]\n        for x in a:\n            # do something\n\n    # AFTER\n    def do_it(a):\n        for x in listwrap(a):\n            # do something\n\n    \"\"\"\n    if value == None:\n        return FlatList()\n    elif is_list(value):\n        return wrap(value)\n    elif isinstance(value, set):\n        return wrap(list(value))\n    else:\n        return wrap([unwrap(value)])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of the items in the passed in list.", "response": "def unwraplist(v):\n    \"\"\"\n    LISTS WITH ZERO AND ONE element MAP TO None AND element RESPECTIVELY\n    \"\"\"\n    if is_list(v):\n        if len(v) == 0:\n            return None\n        elif len(v) == 1:\n            return unwrap(v[0])\n        else:\n            return unwrap(v)\n    else:\n        return unwrap(v)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tuplewrap(value):\n    if isinstance(value, (list, set, tuple) + generator_types):\n        return tuple(tuplewrap(v) if is_sequence(v) else v for v in value)\n    return unwrap(value),", "response": "Wraps a value into a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of six adjacent coordinates on a standard keyboard where each row is slanted to the right from the first key.", "response": "def get_slanted_adjacent_coords(x, y):\n    '''\n    returns the six adjacent coordinates on a standard keyboard, where each row is slanted to the right from the last.\n    adjacencies are clockwise, starting with key to the left, then two keys above, then right key, then two keys below.\n    (that is, only near-diagonal keys are adjacent, so g's coordinate is adjacent to those of t,y,b,v, but not those of r,u,n,c.)\n    '''\n    return [(x-1, y), (x, y-1), (x+1, y-1), (x+1, y), (x, y+1), (x-1, y+1)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the nine clockwise adjacent coordinates on a keypad where each row is vertically aligned.", "response": "def get_aligned_adjacent_coords(x, y):\n    '''\n    returns the nine clockwise adjacent coordinates on a keypad, where each row is vertically aligned.\n    '''\n    return [(x-1, y), (x-1, y-1), (x, y-1), (x+1, y-1), (x+1, y), (x+1, y+1), (x, y+1), (x-1, y+1)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds an adjacency graph from a QWerty layout string.", "response": "def build_graph(layout_str, slanted):\n    '''\n    builds an adjacency graph as a dictionary: {character: [adjacent_characters]}.\n    adjacent characters occur in a clockwise order.\n    for example:\n    * on qwerty layout, 'g' maps to ['fF', 'tT', 'yY', 'hH', 'bB', 'vV']\n    * on keypad layout, '7' maps to [None, None, None, '=', '8', '5', '4', None]\n    '''\n    position_table = {} # maps from tuple (x,y) -> characters at that position.\n    tokens = layout_str.split()\n    token_size = len(tokens[0])\n    x_unit = token_size + 1 # x position unit length is token length plus 1 for the following whitespace.\n    adjacency_func = get_slanted_adjacent_coords if slanted else get_aligned_adjacent_coords\n    assert all(len(token) == token_size for token in tokens), 'token length mismatch:\\n ' + layout_str\n    for y, line in enumerate(layout_str.split('\\n')):\n        slant = y - 1 if slanted else 0 # the way i illustrated keys above, each qwerty row is indented one space in from the last\n        for token in line.split():\n            x, remainder = divmod(line.index(token) - slant, x_unit)\n            assert remainder == 0, 'unexpected x offset for %s in:\\n%s' % (token, layout_str)\n            position_table[(x,y)] = token\n\n    adjacency_graph = {}\n    for (x,y), chars in position_table.items():\n        for char in chars:\n            adjacency_graph[char] = []\n            for coord in adjacency_func(x, y):\n                # position in the list indicates direction (for qwerty, 0 is left, 1 is top, 2 is top right, ...)\n                # for edge chars like 1 or m, insert None as a placeholder when needed so that each character in the graph has a same-length adjacency list.\n                adjacency_graph[char].append(position_table.get(coord, None))\n    return adjacency_graph"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calcul_ratios_calage(year_data, year_calage, data_bdf, data_cn):\n    '''\n    Fonction qui calcule les ratios de calage (bdf sur cn pour ann\u00e9e de donn\u00e9es) et de vieillissement\n    \u00e0 partir des masses de comptabilit\u00e9 nationale et des masses de consommation de bdf.\n    '''\n    masses = data_cn.merge(\n        data_bdf, left_index = True, right_index = True\n        )\n    masses.rename(columns = {0: 'conso_bdf{}'.format(year_data)}, inplace = True)\n    if year_calage != year_data:\n        masses['ratio_cn{}_cn{}'.format(year_data, year_calage)] = (\n            masses['consoCN_COICOP_{}'.format(year_calage)] / masses['consoCN_COICOP_{}'.format(year_data)]\n            )\n    if year_calage == year_data:\n        masses['ratio_cn{}_cn{}'.format(year_data, year_calage)] = 1\n\n    masses['ratio_bdf{}_cn{}'.format(year_data, year_data)] = (\n        1e6 * masses['consoCN_COICOP_{}'.format(year_data)] / masses['conso_bdf{}'.format(year_data)]\n        )\n    return masses", "response": "Calculate the ratios de calage for a given year."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget pandas. DataFrame of all dataframes for a given set of depenses.", "response": "def get_bdf_data_frames(depenses, year_data = None):\n    assert year_data is not None\n    '''\n    R\u00e9cup\u00e8re les d\u00e9penses de budget des familles et les agr\u00e8ge par poste\n    (en tenant compte des poids respectifs des m\u00e9nages)\n    '''\n    depenses_by_grosposte = pandas.DataFrame()\n    for grosposte in range(1, 13):\n        if depenses_by_grosposte is None:\n            depenses_by_grosposte = depenses['coicop12_{}'.format(grosposte)]\n        else:\n            depenses_by_grosposte = concat([depenses_by_grosposte, depenses['coicop12_{}'.format(grosposte)]], axis = 1)\n    depenses_by_grosposte = concat([depenses_by_grosposte, depenses['pondmen']], axis = 1)\n    grospostes_list = set(depenses_by_grosposte.columns)\n    grospostes_list.remove('pondmen')\n\n    dict_bdf_weighted_sum_by_grosposte = {}\n    for grosposte in grospostes_list:\n        depenses_by_grosposte['{}pond'.format(grosposte)] = (\n            depenses_by_grosposte[grosposte] * depenses_by_grosposte['pondmen']\n            )\n        dict_bdf_weighted_sum_by_grosposte[grosposte] = depenses_by_grosposte['{}pond'.format(grosposte)].sum()\n    df_bdf_weighted_sum_by_grosposte = pandas.DataFrame(\n        pandas.Series(\n            data = dict_bdf_weighted_sum_by_grosposte,\n            index = dict_bdf_weighted_sum_by_grosposte.keys()\n            )\n        )\n    return df_bdf_weighted_sum_by_grosposte"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_rofr_rdf(app, api_home_dir, api_uri):\n    from time import sleep\n    from pyldapi import RegisterRenderer, RegisterOfRegistersRenderer\n    try:\n        os.remove(os.path.join(api_home_dir, 'rofr.ttl'))\n    except FileNotFoundError:\n        pass\n    sleep(1)  # to ensure that this occurs after the Flask boot\n    print('making RofR')\n    g = Graph()\n    # get the RDF for each Register, extract the bits we need, write them to graph g\n    for rule in app.url_map.iter_rules():\n        if '<' not in str(rule):  # no registers can have a Flask variable in their path\n            # make the register view URI for each possible register\n            try:\n                endpoint_func = app.view_functions[rule.endpoint]\n            except (AttributeError, KeyError):\n                continue\n            try:\n                candidate_register_uri = api_uri + str(\n                    rule) + '?_view=reg&_format=_internal'\n                test_context = app.test_request_context(candidate_register_uri)\n                with test_context:\n                    resp = endpoint_func()\n            except RegOfRegTtlError:  # usually an RofR renderer cannot find its rofr.ttl.\n                continue\n            except Exception as e:\n                raise e\n            if isinstance(resp, RegisterOfRegistersRenderer):\n                continue  # forbid adding a register of registers to a register of registers.\n            if isinstance(resp, RegisterRenderer):\n                with test_context:\n                    try:\n                        resp.format = 'text/html'\n                        html_resp = resp._render_reg_view_html()\n                    except TemplateNotFound:  # missing html template\n                        pass  # TODO: Fail on this error\n                    resp.format = 'application/json'\n                    json_resp = resp._render_reg_view_json()\n                    resp.format = 'text/turtle'\n                    rdf_resp = resp._render_reg_view_rdf()\n\n                _filter_register_graph(\n                    candidate_register_uri.replace('?_view=reg&_format=_internal', ''),\n                    rdf_resp, g)\n\n    # serialise g\n    with open(os.path.join(api_home_dir, 'rofr.ttl'), 'w') as f:\n        f.write(g.serialize(format='text/turtle').decode('utf-8'))\n\n    print('finished making RofR')", "response": "This function creates the ROFR RDF for each register of the API."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_filtered_register_graph(register_uri, g):\n    import requests\n    from pyldapi.exceptions import ViewsFormatsException\n    assert isinstance(g, Graph)\n    logging.debug('assessing register candidate ' + register_uri.replace('?_view=reg&_format=text/turtle', ''))\n    try:\n        r = requests.get(register_uri)\n        print('getting ' + register_uri)\n    except ViewsFormatsException as e:\n        return False  # ignore these exceptions as are just a result of requesting a view/format combo of something like a page\n    if r.status_code == 200:\n        return _filter_register_graph(register_uri.replace('?_view=reg&_format=text/turtle', ''), r, g)\n    logging.debug('{} returns no HTTP 200'.format(register_uri))\n    return False", "response": "Returns a filtered version of the given register graph"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef invalidate_cache(self, obj=None, queryset=None,\n                         extra=None, force_all=False):\n        \"\"\"\n        Method that should be called by all tiggers to invalidate the\n        cache for an item(s).\n\n        Should be overriden by inheriting classes to customize behavior.\n        \"\"\"\n\n        if self.cache_manager:\n            if queryset != None:\n                force_all = True\n\n            self.cache_manager.invalidate_cache(self.model, instance=obj,\n                                                   extra=extra,\n                                                   force_all=force_all)", "response": "Method to invalidate the cache for an item."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconnect to a given host on a given port.", "response": "def connect(self, host, port):\n        \"\"\"Connect to a host on a given port.\n        If the hostname ends with a colon (`:') followed by a number, and\n        there is no port specified, that suffix will be stripped off and the\n        number interpreted as the port number to use.\n        \"\"\"\n        if not port and (host.find(':') == host.rfind(':')):\n            i = host.rfind(':')\n            if i >= 0:\n                host, port = host[:i], host[i+1:]\n            try: port = int(port)\n            except ValueError:\n                raise socket.error, \"nonnumeric port\"\n        #if self.verbose > 0:\n        #    print 'connect:', (host, port)\n        msg = \"getaddrinfo returns an empty list\"\n        self.sock = None\n        for res in socket.getaddrinfo(host, port, 0, socket.SOCK_STREAM):\n            af, socktype, proto, canonname, sa = res\n            try:\n                self.sock = socket.socket(af, socktype, proto)\n                #if self.debuglevel > 0: print 'connect:', (host, port)\n                self.sock.connect(sa)\n            except socket.error, msg:\n                #if self.debuglevel > 0: print 'connect fail:', (host, port)\n                self.close()\n                continue\n            break\n        if not self.sock:\n            raise socket.error, msg"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef waiting(self, timeout=0):\n        \"Return True if data is ready for the client.\"\n        if self.linebuffer:\n            return True\n        (winput, woutput, wexceptions) = select.select((self.sock,), (), (), timeout)\n        return winput != []", "response": "Return True if data is ready for the client."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwait for and read data being streamed from the daemon.", "response": "def read(self):\n        \"Wait for and read data being streamed from the daemon.\"\n        if self.verbose > 1:\n            sys.stderr.write(\"poll: reading from daemon...\\n\")\n        eol = self.linebuffer.find('\\n')\n        if eol == -1:\n            frag = self.sock.recv(4096)\n            self.linebuffer += frag\n            if self.verbose > 1:\n                sys.stderr.write(\"poll: read complete.\\n\")\n            if not self.linebuffer:\n                if self.verbose > 1:\n                    sys.stderr.write(\"poll: returning -1.\\n\")\n                # Read failed\n                return -1\n            eol = self.linebuffer.find('\\n')\n            if eol == -1:\n                if self.verbose > 1:\n                    sys.stderr.write(\"poll: returning 0.\\n\")\n                # Read succeeded, but only got a fragment\n                return 0\n        else:\n            if self.verbose > 1:\n                sys.stderr.write(\"poll: fetching from buffer.\\n\")\n\n        # We got a line\n        eol += 1\n        self.response = self.linebuffer[:eol]\n        self.linebuffer = self.linebuffer[eol:]\n\n        # Can happen if daemon terminates while we're reading.\n        if not self.response:\n            return -1\n        if self.verbose:\n            sys.stderr.write(\"poll: data is %s\\n\" % repr(self.response))\n        self.received = time.time()\n        # We got a \\n-terminated line\n        return len(self.response)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nship commands to the daemon.", "response": "def send(self, commands):\n        \"Ship commands to the daemon.\"\n        if not commands.endswith(\"\\n\"):\n            commands += \"\\n\"\n        self.sock.send(commands)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncontrol streaming reports from the daemon", "response": "def stream(self, flags=0, devpath=None):\n        \"Control streaming reports from the daemon,\"\n        if flags & WATCH_DISABLE:\n            arg = '?WATCH={\"enable\":false'\n            if flags & WATCH_JSON:\n                arg += ',\"json\":false'\n            if flags & WATCH_NMEA:\n                arg += ',\"nmea\":false'\n            if flags & WATCH_RARE:\n                arg += ',\"raw\":1'\n            if flags & WATCH_RAW:\n                arg += ',\"raw\":2'\n            if flags & WATCH_SCALED:\n                arg += ',\"scaled\":false'\n            if flags & WATCH_TIMING:\n                arg += ',\"timing\":false'\n        else: # flags & WATCH_ENABLE:\n            arg = '?WATCH={\"enable\":true'\n            if flags & WATCH_JSON:\n                arg += ',\"json\":true'\n            if flags & WATCH_NMEA:\n                arg += ',\"nmea\":true'\n            if flags & WATCH_RAW:\n                arg += ',\"raw\":1'\n            if flags & WATCH_RARE:\n                arg += ',\"raw\":0'\n            if flags & WATCH_SCALED:\n                arg += ',\"scaled\":true'\n            if flags & WATCH_TIMING:\n                arg += ',\"timing\":true'\n            if flags & WATCH_DEVICE:\n                arg += ',\"device\":\"%s\"' % devpath\n        return self.send(arg + \"}\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new TurboGears 2 application with all the relevant settings.", "response": "def make_app(global_conf, full_stack=True, **app_conf):\n    \"\"\"\n    Set tg2-raptorized up with the settings found in the PasteDeploy configuration\n    file used.\n    \n    :param global_conf: The global settings for tg2-raptorized (those\n        defined under the ``[DEFAULT]`` section).\n    :type global_conf: dict\n    :param full_stack: Should the whole TG2 stack be set up?\n    :type full_stack: str or bool\n    :return: The tg2-raptorized application with all the relevant middleware\n        loaded.\n    \n    This is the PasteDeploy factory for the tg2-raptorized application.\n    \n    ``app_conf`` contains all the application-specific settings (those defined\n    under ``[app:main]``.\n    \n   \n    \"\"\"\n    app = make_base_app(global_conf, full_stack=True, **app_conf)\n    \n    # Wrap your base TurboGears 2 application with custom middleware here\n    app = raptorizemw.make_middleware(app)\n    \n    return app"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nradiusing of curvature in meters at specified latitude.", "response": "def CalcRad(lat):\n    \"Radius of curvature in meters at specified latitude.\"\n    a = 6378.137\n    e2 = 0.081082 * 0.081082\n    # the radius of curvature of an ellipsoidal Earth in the plane of a\n    # meridian of latitude is given by\n    #\n    # R' = a * (1 - e^2) / (1 - e^2 * (sin(lat))^2)^(3/2)\n    #\n    # where a is the equatorial radius,\n    # b is the polar radius, and\n    # e is the eccentricity of the ellipsoid = sqrt(1 - b^2/a^2)\n    #\n    # a = 6378 km (3963 mi) Equatorial radius (surface to center distance)\n    # b = 6356.752 km (3950 mi) Polar radius (surface to center distance)\n    # e = 0.081082 Eccentricity\n    sc = math.sin(Deg2Rad(lat))\n    x = a * (1.0 - e2)\n    z = 1.0 - e2 * sc * sc\n    y = pow(z, 1.5)\n    r = x / y\n\n    r = r * 1000.0      # Convert to meters\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef EarthDistance((lat1, lon1), (lat2, lon2)):\n    \"Distance in meters between two points specified in degrees.\"\n    x1 = CalcRad(lat1) * math.cos(Deg2Rad(lon1)) * math.sin(Deg2Rad(90-lat1))\n    x2 = CalcRad(lat2) * math.cos(Deg2Rad(lon2)) * math.sin(Deg2Rad(90-lat2))\n    y1 = CalcRad(lat1) * math.sin(Deg2Rad(lon1)) * math.sin(Deg2Rad(90-lat1))\n    y2 = CalcRad(lat2) * math.sin(Deg2Rad(lon2)) * math.sin(Deg2Rad(90-lat2))\n    z1 = CalcRad(lat1) * math.cos(Deg2Rad(90-lat1))\n    z2 = CalcRad(lat2) * math.cos(Deg2Rad(90-lat2))\n    a = (x1*x2 + y1*y2 + z1*z2)/pow(CalcRad((lat1+lat2)/2), 2)\n    # a should be in [1, -1] but can sometimes fall outside it by\n    # a very small amount due to rounding errors in the preceding\n    # calculations (this is prone to happen when the argument points\n    # are very close together).  Thus we constrain it here.\n    if abs(a) > 1: a = 1\n    elif a < -1: a = -1\n    return CalcRad((lat1+lat2) / 2) * math.acos(a)", "response": "Distance in meters between two points specified in degrees."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning offset in meters of second arg from first.", "response": "def MeterOffset((lat1, lon1), (lat2, lon2)):\n    \"Return offset in meters of second arg from first.\"\n    dx = EarthDistance((lat1, lon1), (lat1, lon2))\n    dy = EarthDistance((lat1, lon1), (lat2, lon1))\n    if lat1 < lat2: dy *= -1\n    if lon1 < lon2: dx *= -1\n    return (dx, dy)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert timestamps in ISO8661 format to and from Unix time.", "response": "def isotime(s):\n    \"Convert timestamps in ISO8661 format to and from Unix time.\"\n    if type(s) == type(1):\n        return time.strftime(\"%Y-%m-%dT%H:%M:%S\", time.gmtime(s))\n    elif type(s) == type(1.0):\n        date = int(s)\n        msec = s - date\n        date = time.strftime(\"%Y-%m-%dT%H:%M:%S\", time.gmtime(s))\n        return date + \".\" + repr(msec)[3:]\n    elif type(s) == type(\"\") or type(s) == type(u\"\"):\n        if s[-1] == \"Z\":\n            s = s[:-1]\n        if \".\" in s:\n            (date, msec) = s.split(\".\")\n        else:\n            date = s\n            msec = \"0\"\n        # Note: no leap-second correction! \n        return calendar.timegm(time.strptime(date, \"%Y-%m-%dT%H:%M:%S\")) + float(\"0.\" + msec)\n    else:\n        raise TypeError"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef not_found(entity_id=None, message='Entity not found'):\n        resp = jsonify({'message': message, 'entity_id': entity_id})\n        resp.status_code = 404\n        return resp", "response": "Build a response to indicate that the requested entity was not found."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef requires_auth(self, roles=None):\n\n        def requires_auth_inner(f):\n            @wraps(f)\n            def decorated(*args, **kwargs):\n                auth = request.authorization\n                if not auth:\n                    return MeteorApp.authentication_failure(message='No authorization header supplied')\n                user_id = auth.username\n                password = auth.password\n                try:\n                    db = self.get_db()\n                    user = db.get_user(user_id=user_id, password=password)\n                    if user is None:\n                        return MeteorApp.authentication_failure(message='Username and / or password incorrect')\n                    if roles is not None:\n                        for role in roles:\n                            if not user.has_role(role):\n                                return MeteorApp.authentication_failure(message='Missing role {0}'.format(role))\n                    g.user = user\n                    db.close_db()\n                except ValueError:\n                    return MeteorApp.authentication_failure(message='Unrecognized role encountered')\n                return f(*args, **kwargs)\n\n            return decorated\n\n        return requires_auth_inner", "response": "Decorator that wraps a function to impose auth constraints on requests which require a logged in user with the specified roles."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nswitches the character set to the given target character set.", "response": "def switch_charset(characters, target=''):\n    '''\n    Transforms an iterable of kana characters to its opposite script.\n    For example, it can turn [u'\u3042', u'\u3044'] into [u'\u30a2', u'\u30a4'],\n    or {u'\u30db': u'\u30dc} into {u'\u307b': u'\u307c'}.\n\n    There are no safety checks--keep in mind that the correct source and target\n    values must be set, otherwise the resulting characters will be garbled.\n    '''\n    if isinstance(characters, dict):\n        return _switch_charset_dict(characters, target)\n    else:\n        return _switch_charset_list(characters, target)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nswitches the character set of the key value pairs in a dictionary.", "response": "def _switch_charset_dict(characters, target=''):\n    '''\n    Switches the character set of the key/value pairs in a dictionary.\n    '''\n    offset_characters = {}\n    offset = block_offset * offsets[target]['direction']\n    for char in characters:\n        offset_key = chr(ord(char) + offset)\n        offset_value = chr(ord(characters[char]) + offset)\n        offset_characters[offset_key] = offset_value\n\n    return offset_characters"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _switch_charset_list(characters, target=''):\n    '''\n    Switches the character set of a list. If a character does not have\n    an equivalent in the target script (e.g. \u30f9 when converting to hiragana),\n    the original character is kept.\n    '''\n    # Copy the list to avoid modifying the existing one.\n    characters = characters[:]\n    offset = block_offset * offsets[target]['direction']\n    for n in range(len(characters)):\n        chars = list(characters[n])\n\n        for m in range(len(chars)):\n            char = chars[m]\n            char_offset = ord(char) + offset\n            # Verify that the offset character is within the valid range.\n            if in_range(char_offset, target):\n                chars[m] = chr(char_offset)\n            else:\n                chars[m] = char\n\n        characters[n] = ''.join(chars)\n\n    return characters", "response": "Switches the character set of a list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef kana_romaji_lt(romaji, *kana):\n    '''\n    Generates a lookup table with the kana characters on the left side\n    and their r\u014dmaji equivalents as the values.\n\n    For the consonant-vowel (cv) characters, we'll generate:\n\n       {u'\u304b': ('ka', 'k', 'k', '\u0101'),\n        u'\u304c': ('ga', 'g', 'g', '\u0101'),\n        [...]\n\n    Multiple kana character sets can be passed as rest arguments.\n    '''\n    lt = {}\n    for kana_set in kana:\n        for n in range(len(romaji)):\n            ro = romaji[n]\n            ka = kana_set[n]\n            lt[ka] = ro\n\n    return lt", "response": "Generates a lookup table with the kana characters on the left side\nATTRIBS and their r\u014dmaji equivalents as the values."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a lookup table with the fullwidth r\u014dmaji characters on the left side and the regular r\u014dmaji characters on the left side and the values of the fullwidth r\u014dmaji characters as the values.", "response": "def fw_romaji_lt(full, regular):\n    '''\n    Generates a lookup table with the fullwidth r\u014dmaji characters\n    on the left side, and the regular r\u014dmaji characters as the values.\n    '''\n    lt = {}\n    for n in range(len(full)):\n        fw = full[n]\n        reg = regular[n]\n        lt[fw] = reg\n\n    return lt"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the cache prefix for this request.", "response": "def get_cache_prefix(self, prefix=''):\n        \"\"\"\n        Hook for any extra data you would like\n        to prepend to your cache key.\n\n        The default implementation ensures that ajax not non\n        ajax requests are cached separately. This can easily\n        be extended to differentiate on other criteria\n        like mobile os' for example.\n        \"\"\"\n\n        if settings.CACHE_MIDDLEWARE_KEY_PREFIX:\n            prefix += settings.CACHE_MIDDLEWARE_KEY_PREFIX\n\n        if self.request.is_ajax():\n            prefix += 'ajax'\n\n        return prefix"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_vary_headers(self, request, response):\n\n        headers = []\n        accessed = False\n        try:\n            accessed = request.session.accessed\n        except AttributeError:\n            pass\n\n        if accessed:\n            headers.append(\"Cookie\")\n        return headers", "response": "Hook for patching the vary header"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the response as a string and caches it with a specific prefix", "response": "def get_as_string(self, request, *args, **kwargs):\n        \"\"\"\n        Should only be used when inheriting from cms View.\n\n        Gets the response as a string and caches it with a\n        separate prefix\n        \"\"\"\n\n        value = None\n        cache = None\n        prefix = None\n        if self.should_cache():\n            prefix = \"%s:%s:string\" % (self.get_cache_version(),\n                                self.get_cache_prefix())\n            cache = router.router.get_cache(prefix)\n            value = cache.get(prefix)\n\n        if not value:\n            value = super(CacheView, self).get_as_string(request, *args,\n                                                         **kwargs)\n            if self.should_cache() and value and \\\n                    getattr(self.request, '_cache_update_cache', False):\n                cache.set(prefix, value, self.cache_time)\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noverriding Django s default dispatch to provide caching.", "response": "def dispatch(self, request, *args, **kwargs):\n        \"\"\"\n        Overrides Django's default dispatch to provide caching.\n\n        If the should_cache method returns True, this will call\n        two functions get_cache_version and get_cache_prefix\n        the results of those two functions are combined and passed to\n        the standard django caching middleware.\n        \"\"\"\n\n        self.request = request\n        self.args = args\n        self.kwargs = kwargs\n        self.cache_middleware = None\n        response = None\n\n        if self.should_cache():\n            prefix = \"%s:%s\" % (self.get_cache_version(),\n                                self.get_cache_prefix())\n\n            # Using middleware here since that is what the decorator uses\n            # internally and it avoids making this code all complicated with\n            # all sorts of wrappers.\n            self.set_cache_middleware(self.cache_time, prefix)\n            response = self.cache_middleware.process_request(self.request)\n        else:\n            self.set_do_not_cache()\n\n        if not response:\n            response = super(CacheView, self).dispatch(self.request, *args,\n                                                       **kwargs)\n\n        return self._finalize_cached_response(request, response)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_crop_spec(self, im, x=None, x2=None, y=None, y2=None):\n        w, h = [float(v) for v in im.size]\n        upscale = self.upscale\n        if x is not None and x2 and y is not None and y2:\n            upscale = True\n            w = float(x2)-x\n            h = float(y2)-y\n        else:\n            x = 0\n            x2 = w\n            y = 0\n            y2 = h\n\n        if self.width and self.height:\n            ry = self.height / h\n            rx = self.width / w\n            if rx < ry:\n                ratio = ry\n                adjust = self._adjust_coordinates(ratio, w, self.width)\n                x = x + adjust\n                x2 = x2 - adjust\n            else:\n                ratio = rx\n                adjust = self._adjust_coordinates(ratio, h, self.height)\n                y = y + adjust\n                y2 = y2 - adjust\n\n            width = self.width\n            height = self.height\n        elif self.width:\n            ratio = self.width / w\n            width = self.width\n            height = int(h * ratio)\n        else:\n            ratio = self.height / h\n            width = int(w * ratio)\n            height = self.height\n\n        if ratio > 1 and not upscale:\n            return\n\n        x, x2, y, y2 = int(x), int(x2), int(y), int(y2)\n        return CropSpec(name=self.name,\n                        editable=self.editable,\n                        width=width, height=height,\n                        x=x, x2=x2, y=y, y2=y2)", "response": "Returns the default crop points for this image."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a crop for an image.", "response": "def create_crop(self, name, file_obj,\n                    x=None, x2=None, y=None, y2=None):\n        \"\"\"\n        Generate Version for an Image.\n        value has to be a serverpath relative to MEDIA_ROOT.\n\n        Returns the spec for the crop that was created.\n        \"\"\"\n\n        if name not in self._registry:\n            return\n\n        file_obj.seek(0)\n        im = Image.open(file_obj)\n        config = self._registry[name]\n\n        if x is not None and x2 and y is not None and y2 and not config.editable:\n            # You can't ask for something special\n            # for non editable images\n            return\n\n        im = config.rotate_by_exif(im)\n        crop_spec = config.get_crop_spec(im, x=x, x2=x2, y=y, y2=y2)\n        image = config.process_image(im, crop_spec=crop_spec)\n        if image:\n            crop_name = utils.get_size_filename(file_obj.name, name)\n            self._save_file(image, crop_name)\n            return crop_spec"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_imputation_loyers_proprietaires(temporary_store = None, year = None):\n\n    assert temporary_store is not None\n    assert year is not None\n\n    # Load data\n    bdf_survey_collection = SurveyCollection.load(collection = 'budget_des_familles',\n        config_files_directory = config_files_directory)\n    survey = bdf_survey_collection.get_survey('budget_des_familles_{}'.format(year))\n\n    if year == 1995:\n        imput00 = survey.get_values(table = \"socioscm\")\n        # cette \u00e9tape permet de ne garder que les donn\u00e9es dont on est s\u00fbr de la qualit\u00e9 et de la v\u00e9racit\u00e9\n        # exdep = 1 si les donn\u00e9es sont bien remplies pour les d\u00e9penses du m\u00e9nage\n        # exrev = 1 si les donn\u00e9es sont bien remplies pour les revenus du m\u00e9nage\n        imput00 = imput00[(imput00.exdep == 1) & (imput00.exrev == 1)]\n        imput00 = imput00[(imput00.exdep == 1) & (imput00.exrev == 1)]\n        kept_variables = ['mena', 'stalog', 'surfhab', 'confort1', 'confort2', 'confort3', 'confort4',\n                        'ancons', 'sitlog', 'nbphab', 'rg', 'cc']\n        imput00 = imput00[kept_variables]\n        imput00.rename(columns = {'mena': 'ident_men'}, inplace = True)\n\n        #TODO: continue variable cleaning\n        var_to_filnas = ['surfhab']\n        for var_to_filna in var_to_filnas:\n            imput00[var_to_filna] = imput00[var_to_filna].fillna(0)\n\n        var_to_ints = ['sitlog', 'confort1', 'stalog', 'surfhab', 'ident_men', 'ancons', 'nbphab']\n        for var_to_int in var_to_ints:\n            imput00[var_to_int] = imput00[var_to_int].astype(int)\n\n        depenses = temporary_store['depenses_{}'.format(year)]\n        depenses.reset_index(inplace = True)\n        depenses_small = depenses[['ident_men', '04110', 'pondmen']].copy()\n        depenses_small.ident_men = depenses_small.ident_men.astype('int')\n        imput00 = depenses_small.merge(imput00, on = 'ident_men').set_index('ident_men')\n        imput00.rename(columns = {'04110': 'loyer_reel'}, inplace = True)\n\n#       * une indicatrice pour savoir si le loyer est connu et l'occupant est locataire\n\n        imput00['observe'] = (imput00.loyer_reel > 0) & (imput00.stalog.isin([3, 4]))\n        imput00['maison_appart'] = imput00.sitlog == 1\n\n        imput00['catsurf'] = (\n            1 +\n            (imput00.surfhab > 15) +\n            (imput00.surfhab > 30) +\n            (imput00.surfhab > 40) +\n            (imput00.surfhab > 60) +\n            (imput00.surfhab > 80) +\n            (imput00.surfhab > 100) +\n            (imput00.surfhab > 150)\n            )\n        assert imput00.catsurf.isin(range(1, 9)).all()\n        # TODO: v\u00e9rifier ce qe l'on fait notamment regarder la vleur catsurf = 2 ommise dans le code stata\n        imput00.maison = 1 - ((imput00.cc == 5) & (imput00.catsurf == 1) & (imput00.maison_appart == 1))\n        imput00.maison = 1 - ((imput00.cc == 5) & (imput00.catsurf == 3) & (imput00.maison_appart == 1))\n        imput00.maison = 1 - ((imput00.cc == 5) & (imput00.catsurf == 8) & (imput00.maison_appart == 1))\n        imput00.maison = 1 - ((imput00.cc == 4) & (imput00.catsurf == 1) & (imput00.maison_appart == 1))\n\n        try:\n            parser = SafeConfigParser()\n            config_local_ini = os.path.join(config_files_directory, 'config_local.ini')\n            config_ini = os.path.join(config_files_directory, 'config.ini')\n            parser.read([config_ini, config_local_ini])\n            directory_path = os.path.normpath(\n                parser.get(\"openfisca_france_indirect_taxation\", \"assets\")\n                )\n            hotdeck = pandas.read_stata(os.path.join(directory_path, 'hotdeck_result.dta'))\n        except:\n            hotdeck = survey.get_values(table = 'hotdeck_result')\n\n\n        imput00.reset_index(inplace = True)\n        hotdeck.ident_men = hotdeck.ident_men.astype('int')\n        imput00 = imput00.merge(hotdeck, on = 'ident_men')\n        imput00.loyer_impute[imput00.observe] = 0\n        imput00.reset_index(inplace = True)\n        loyers_imputes = imput00[['ident_men', 'loyer_impute']].copy()\n        assert loyers_imputes.loyer_impute.notnull().all()\n        loyers_imputes.rename(columns = dict(loyer_impute = '0411'), inplace = True)\n\n    # POUR BdF 2000 ET 2005, ON UTILISE LES LOYERS IMPUTES CALCULES PAR L'INSEE\n    if year == 2000:\n        # Garder les loyers imput\u00e9s (disponibles dans la table sur les m\u00e9nages)\n        loyers_imputes = survey.get_values(table = \"menage\", variables = ['ident', 'rev81'])\n        loyers_imputes.rename(\n            columns = {\n                'ident': 'ident_men',\n                'rev81': 'poste_coicop_421',\n                },\n            inplace = True,\n            )\n\n    if year == 2005:\n        # Garder les loyers imput\u00e9s (disponibles dans la table sur les m\u00e9nages)\n        loyers_imputes = survey.get_values(table = \"menage\")\n        kept_variables = ['ident_men', 'rev801_d']\n        loyers_imputes = loyers_imputes[kept_variables]\n        loyers_imputes.rename(columns = {'rev801_d': 'poste_coicop_421'}, inplace = True)\n\n    if year == 2011:\n        try:\n            loyers_imputes = survey.get_values(table = \"MENAGE\")\n        except:\n            loyers_imputes = survey.get_values(table = \"menage\")\n\n        kept_variables = ['ident_me', 'rev801']\n        loyers_imputes = loyers_imputes[kept_variables]\n        loyers_imputes.rename(columns = {'rev801': 'poste_coicop_421', 'ident_me': 'ident_men'},\n                              inplace = True)\n\n    # Joindre \u00e0 la table des d\u00e9penses par COICOP\n    loyers_imputes.set_index('ident_men', inplace = True)\n    temporary_store['loyers_imputes_{}'.format(year)] = loyers_imputes\n    depenses = temporary_store['depenses_{}'.format(year)]\n    depenses.index = depenses.index.astype('int64')\n    loyers_imputes.index = loyers_imputes.index.astype('int64')\n    assert set(depenses.index) == set(loyers_imputes.index)\n    assert len(set(depenses.columns).intersection(set(loyers_imputes.columns))) == 0\n    depenses = depenses.merge(loyers_imputes, left_index = True, right_index = True)\n\n    # ****************************************************************************************************************\n    #  Etape n\u00b0 0-1-3 : SAUVER LES BASES DE DEPENSES HOMOGENEISEES DANS LE BON DOSSIER\n    # ****************************************************************************************************************\n\n    # Save in temporary store\n    temporary_store['depenses_bdf_{}'.format(year)] = depenses", "response": "Build menage consumption by categorie fiscale dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_functions_map(self):\n        return dict([(column, DATA_TYPE_FUNCTIONS[data_type]) for column, data_type in self.columns.values_list('name', 'data_type')])", "response": "Calculate the column name to data type conversion map"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _convert_value(self, item):\n        # Types:\n        # 0 = empty u''\n        # 1 = unicode text\n        # 2 = float (convert to int if possible, then convert to string)\n        # 3 = date (convert to unambiguous date/time string)\n        # 4 = boolean (convert to string \"0\" or \"1\")\n        # 5 = error (convert from code to error text)\n        # 6 = blank u''\n\n        # Thx to Augusto C Men to point fast solution for XLS/XLSX dates\n        if item.ctype == 3:  # XL_CELL_DATE:\n            try:\n                return datetime.datetime(*xlrd.xldate_as_tuple(item.value, self._book.datemode))\n            except ValueError:\n                # TODO: make toggable\n                # Invalid date\n                return item.value\n\n        if item.ctype == 2:  # XL_CELL_NUMBER:\n            if item.value % 1 == 0:  # integers\n                return int(item.value)\n            else:\n                return item.value\n\n        return item.value", "response": "Convert value to Python type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread and interpret data from the daemon.", "response": "def read(self):\n        \"Read and interpret data from the daemon.\"\n        status = gpscommon.read(self)\n        if status <= 0:\n            return status\n        if self.response.startswith(\"{\") and self.response.endswith(\"}\\r\\n\"):\n            self.unpack(self.response)\n            self.__oldstyle_shim()\n            self.newstyle = True\n            self.valid |= PACKET_SET\n        elif self.response.startswith(\"GPSD\"):\n            self.__oldstyle_unpack(self.response)\n            self.valid |= PACKET_SET\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nask gpsd to stream reports at your client.", "response": "def stream(self, flags=0, devpath=None):\n        \"Ask gpsd to stream reports at your client.\"\n        if (flags & (WATCH_JSON|WATCH_OLDSTYLE|WATCH_NMEA|WATCH_RAW)) == 0:\n            flags |= WATCH_JSON\n        if flags & WATCH_DISABLE:\n            if flags & WATCH_OLDSTYLE:\n                arg = \"w-\"\n                if flags & WATCH_NMEA:\n                    arg += 'r-'\n                    return self.send(arg)\n            else:\n                gpsjson.stream(self, ~flags, devpath)\n        else: # flags & WATCH_ENABLE:\n            if flags & WATCH_OLDSTYLE:\n                arg = 'w+'\n                if (flags & WATCH_NMEA):\n                    arg += 'r+'\n                    return self.send(arg)\n            else:\n                gpsjson.stream(self, flags, devpath)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main():\n\n    # if no arg, run secret miner\n    if (len(sys.argv) == 1):\n        (address, username, password, device, tstart, tend) = read_config()\n        r = Runner(device)\n\n        while True:\n            now = datetime.datetime.now()\n            start = get_time_by_cfgtime(now, tstart)\n            end = get_time_by_cfgtime(now, tend)\n\n            logger.info('start secret miner service')\n            logger.info('now: ' + now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n            logger.info('start: ' + start.strftime(\"%Y-%m-%d %H:%M:%S\"))\n            logger.info('end: ' + end.strftime(\"%Y-%m-%d %H:%M:%S\"))\n\n            logger.info('Check if the correct time to run miner ?')\n            if start > end:\n                if now > start or now < end:\n                    logger.info('Now is the correct time to run miner')\n                    r.run_miner_if_free()\n                else:\n                    logger.info('Now is the correct time to kill miner')\n                    r.kill_miner_if_exists()\n            else:\n                if now > start and now < end:\n                    logger.info('Now is the correct time to run miner')\n                    r.run_miner_if_free()\n                else:\n                    logger.info('Now is the correct time to kill miner')\n                    r.kill_miner_if_exists()\n\n            time.sleep(interval)\n    else:\n        save_and_test()", "response": "main function for the secret miner"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts miner if device is free", "response": "def run_miner_if_free(self):\n        \"\"\"TODO: docstring\"\"\"\n        (address, username, password, device, tstart, tend) = read_config()\n\n        if self.dtype == 0:\n            self.run_miner_cmd = [\n                cpu_miner_path, '-o', address, '-O', '{}:{}'.format(\n                    username, password)\n            ]\n        elif self.dtype == 1:\n            # parse address -> scheme + netloc\n            r = urlparse(address)\n\n            # scheme://user[:password]@hostname:port\n            url = '{}://{}:{}@{}'.format(r.scheme, username, password,\n                                         r.netloc)\n\n            # Cuda\n            self.run_miner_cmd = [gpu_miner_path, '-P', url, '-U']\n\n        if (len(self.run_miner_cmd) != 0):\n            logger.info(' '.join(self.run_miner_cmd))\n\n            # start if resource(cpu or gpu) is free\n            if (self.is_device_free()):\n                logger.info('start miner in another thread')\n                self.run_cmd(self.run_miner_cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef first_from_generator(generator):\n    try:\n        result = next(generator)\n    except StopIteration:\n        result = None\n    finally:\n        generator.close()\n    return result", "response": "Pull the first value from a generator and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef file_generator(self, sql, sql_args):\n\n        self.con.execute(sql, sql_args)\n        results = self.con.fetchall()\n        output = []\n        for result in results:\n            file_record = mp.FileRecord(obstory_id=result['obstory_id'], obstory_name=result['obstory_name'],\n                                        observation_id=result['observationId'],\n                                        repository_fname=result['repositoryFname'],\n                                        file_time=result['fileTime'], file_size=result['fileSize'],\n                                        file_name=result['fileName'], mime_type=result['mimeType'],\n                                        file_md5=result['fileMD5'],\n                                        semantic_type=result['semanticType'])\n\n            # Look up observation metadata\n            sql = \"\"\"SELECT f.metaKey, stringValue, floatValue\nFROM archive_metadata m\nINNER JOIN archive_metadataFields f ON m.fieldId=f.uid\nWHERE m.fileId=%s\n\"\"\"\n            self.con.execute(sql, (result['uid'],))\n            for item in self.con.fetchall():\n                value = first_non_null([item['stringValue'], item['floatValue']])\n                file_record.meta.append(mp.Meta(item['metaKey'], value))\n\n            output.append(file_record)\n        return output", "response": "Returns a generator which returns FileRecord instances from the supplied SQL statement."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a generator which generates observations from the supplied SQL statement and returns a list of Event instances.", "response": "def observation_generator(self, sql, sql_args):\n        \"\"\"Generator for Observation\n\n        :param sql:\n            A SQL statement which must return rows describing observations\n        :param sql_args:\n            Any variables required to populate the query provided in 'sql'\n        :return:\n            A generator which produces Event instances from the supplied SQL, closing any opened cursors on completion.\n        \"\"\"\n\n        self.con.execute(sql, sql_args)\n        results = self.con.fetchall()\n        output = []\n        for result in results:\n            observation = mp.Observation(obstory_id=result['obstory_id'], obstory_name=result['obstory_name'],\n                                         obs_time=result['obsTime'], obs_id=result['publicId'],\n                                         obs_type=result['obsType'])\n\n            # Look up observation metadata\n            sql = \"\"\"SELECT f.metaKey, stringValue, floatValue\nFROM archive_metadata m\nINNER JOIN archive_metadataFields f ON m.fieldId=f.uid\nWHERE m.observationId=%s\n\"\"\"\n            self.con.execute(sql, (result['uid'],))\n            for item in self.con.fetchall():\n                value = first_non_null([item['stringValue'], item['floatValue']])\n                observation.meta.append(mp.Meta(item['metaKey'], value))\n\n            # Fetch file objects\n            sql = \"SELECT f.repositoryFname FROM archive_files f WHERE f.observationId=%s\"\n            self.con.execute(sql, (result['uid'],))\n            for item in self.con.fetchall():\n                observation.file_records.append(self.db.get_file(item['repositoryFname']))\n\n            # Count votes for observation\n            self.con.execute(\"SELECT COUNT(*) FROM archive_obs_likes WHERE observationId=\"\n                             \"(SELECT uid FROM archive_observations WHERE publicId=%s);\", (result['publicId'],))\n            observation.likes = self.con.fetchone()['COUNT(*)']\n\n            output.append(observation)\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a generator which generates ObservationGroup objects from the supplied SQL statement and returns a list of Event instances.", "response": "def obsgroup_generator(self, sql, sql_args):\n        \"\"\"Generator for ObservationGroup\n\n        :param sql:\n            A SQL statement which must return rows describing observation groups\n        :param sql_args:\n            Any variables required to populate the query provided in 'sql'\n        :return:\n            A generator which produces Event instances from the supplied SQL, closing any opened cursors on completion.\n        \"\"\"\n\n        self.con.execute(sql, sql_args)\n        results = self.con.fetchall()\n        output = []\n        for result in results:\n            obs_group = mp.ObservationGroup(group_id=result['publicId'], title=result['title'],\n                                            obs_time=result['time'], set_time=result['setAtTime'],\n                                            semantic_type=result['semanticType'],\n                                            user_id=result['setByUser'])\n\n            # Look up observation group metadata\n            sql = \"\"\"SELECT f.metaKey, stringValue, floatValue\nFROM archive_metadata m\nINNER JOIN archive_metadataFields f ON m.fieldId=f.uid\nWHERE m.groupId=%s\n\"\"\"\n            self.con.execute(sql, (result['uid'],))\n            for item in self.con.fetchall():\n                value = first_non_null([item['stringValue'], item['floatValue']])\n                obs_group.meta.append(mp.Meta(item['metaKey'], value))\n\n            # Fetch observation objects\n            sql = \"\"\"SELECT o.publicId\nFROM archive_obs_group_members m\nINNER JOIN archive_observations o ON m.observationId=o.uid\nWHERE m.groupId=%s\n\"\"\"\n            self.con.execute(sql, (result['uid'],))\n            for item in self.con.fetchall():\n                obs_group.obs_records.append(self.db.get_observation(item['publicId']))\n\n            output.append(obs_group)\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a generator which returns a list of meteorpi_model. ObservatoryMetadata objects from the supplied SQL statement and returns a list of meteorpi_model. CameraStatus instances.", "response": "def obstory_metadata_generator(self, sql, sql_args):\n        \"\"\"\n        Generator for :class:`meteorpi_model.CameraStatus`\n\n        :param sql:\n            A SQL statement which must return rows describing obstory metadata\n        :param sql_args:\n            Any arguments required to populate the query provided in 'sql'\n        :return:\n            A generator which produces :class:`meteorpi_model.CameraStatus` instances from the supplied SQL, closing\n            any opened cursors on completion\n        \"\"\"\n\n        self.con.execute(sql, sql_args)\n        results = self.con.fetchall()\n        output = []\n        for result in results:\n            value = \"\"\n            if ('floatValue' in result) and (result['floatValue'] is not None):\n                value = result['floatValue']\n            if ('stringValue' in result) and (result['stringValue'] is not None):\n                value = result['stringValue']\n            obs_meta = mp.ObservatoryMetadata(metadata_id=result['metadata_id'], obstory_id=result['obstory_id'],\n                                              obstory_name=result['obstory_name'],\n                                              obstory_lat=result['obstory_lat'], obstory_lng=result['obstory_lng'],\n                                              key=result['metadata_key'], value=value,\n                                              metadata_time=result['time'], time_created=result['time_created'],\n                                              user_created=result['user_created'])\n            output.append(obs_meta)\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a generator which returns all the exported configuration instances.", "response": "def export_configuration_generator(self, sql, sql_args):\n        \"\"\"\n        Generator for :class:`meteorpi_model.ExportConfiguration`\n\n        :param sql:\n            A SQL statement which must return rows describing export configurations\n        :param sql_args:\n            Any variables required to populate the query provided in 'sql'\n        :return:\n            A generator which produces :class:`meteorpi_model.ExportConfiguration` instances from the supplied SQL,\n            closing any opened cursors on completion.\n        \"\"\"\n\n        self.con.execute(sql, sql_args)\n        results = self.con.fetchall()\n        output = []\n        for result in results:\n            if result['exportType'] == \"observation\":\n                search = mp.ObservationSearch.from_dict(json.loads(result['searchString']))\n            elif result['exportType'] == \"file\":\n                search = mp.FileRecordSearch.from_dict(json.loads(result['searchString']))\n            else:\n                search = mp.ObservatoryMetadataSearch.from_dict(json.loads(result['searchString']))\n            conf = mp.ExportConfiguration(target_url=result['targetURL'], user_id=result['targetUser'],\n                                          password=result['targetPassword'], search=search,\n                                          name=result['exportName'], description=result['description'],\n                                          enabled=result['active'], config_id=result['exportConfigId'])\n            output.append(conf)\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_to_redshift(\n        instance,\n        data,\n        replace=True,\n        batch_size=1000,\n        types=None,\n        primary_key=(),\n        create_boolean=False):\n    \"\"\"\n    data = {\n        \"table_name\" \t: 'name_of_the_redshift_schema' + '.' + 'name_of_the_redshift_table' #Must already exist,\n        \"columns_name\" \t: [first_column_name,second_column_name,...,last_column_name],\n        \"rows\"\t\t: [[first_raw_value,second_raw_value,...,last_raw_value],...]\n    }\n    \"\"\"\n\n    connection_kwargs = redshift_credentials.credential(instance)\n    print(\"Initiate send_to_redshift...\")\n\n    print(\"Test to know if the table exists...\")\n    if (not create.existing_test(instance, data[\"table_name\"])) or (types is not None) or (primary_key != ()):\n        create_boolean = True\n\n    print(\"Test to know if the table exists...OK\")\n\n    if create_boolean:\n        create.create_table(instance, data, primary_key, types)\n\n    # Create an SSH tunnel\n    ssh_host = os.environ.get(\"SSH_%s_HOST\" % instance)\n    ssh_user = os.environ.get(\"SSH_%s_USER\" % instance)\n    ssh_path_private_key = os.environ.get(\"SSH_%s_PATH_PRIVATE_KEY\" % instance)\n    if ssh_host:\n        tunnel = SSHTunnelForwarder(\n            (ssh_host, 22),\n            ssh_username=ssh_user,\n            ssh_private_key=ssh_path_private_key,\n            remote_bind_address=(\n                os.environ.get(\"RED_%s_HOST\" % instance), int(os.environ.get(\"RED_%s_PORT\" % instance))),\n            local_bind_address=('localhost', 6543),  # could be any available port\n        )\n        # Start the tunnel\n        try:\n            tunnel.start()\n            print(\"Tunnel opened!\")\n        except sshtunnel.HandlerSSHTunnelForwarderError:\n            pass\n\n        connection_kwargs[\"host\"] = \"localhost\"\n        connection_kwargs[\"port\"] = 6543\n\n    con = psycopg2.connect(**connection_kwargs)\n    cursor = con.cursor()\n\n    if replace:\n        cleaning_request = '''DELETE FROM ''' + data[\"table_name\"] + ''';'''\n        print(\"Cleaning\")\n        cursor.execute(cleaning_request)\n        print(\"Cleaning Done\")\n\n    boolean = True\n    index = 0\n    total_nb_batchs = len(data[\"rows\"]) // batch_size + 1\n    while boolean:\n        temp_row = []\n        for i in range(batch_size):\n            if not data[\"rows\"]:\n                boolean = False\n                continue\n            temp_row.append(data[\"rows\"].pop())\n\n        final_data = []\n        for x in temp_row:\n            for y in x:\n                final_data.append(y)\n\n        temp_string = ','.join(map(lambda a: '(' + ','.join(map(lambda b: '%s', a)) + ')', tuple(temp_row)))\n\n        inserting_request = '''INSERT INTO ''' + data[\"table_name\"] + ''' (''' + \", \".join(\n            data[\"columns_name\"]) + ''') VALUES ''' + temp_string + ''';'''\n        if final_data:\n            cursor.execute(inserting_request, final_data)\n        index = index + 1\n        percent = round(index * 100 / total_nb_batchs, 2)\n        if percent < 100:\n            print(\"\\r   %s / %s (%s %%)\" % (str(index), total_nb_batchs, str(percent)), end='\\r')\n        else:\n            print(\"\\r   %s / %s (%s %%)\" % (str(index), total_nb_batchs, str(percent)))\n    con.commit()\n\n    cursor.close()\n    con.close()\n\n    if ssh_host:\n        tunnel.close()\n        print(\"Tunnel closed!\")\n\n    print(\"data sent to redshift\")\n    return 0", "response": "Send data to the redshift instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a string into something that can be used as a valid python variable name.", "response": "def acceptable(value, capitalize=False):\n    \"\"\"Convert a string into something that can be used as a valid python variable name\"\"\"\n    name = regexes['punctuation'].sub(\"\", regexes['joins'].sub(\"_\", value))\n    # Clean up irregularities in underscores.\n    name = regexes['repeated_underscore'].sub(\"_\", name.strip('_'))\n    if capitalize:\n        # We don't use python's built in capitalize method here because it\n        # turns all upper chars into lower chars if not at the start of\n        # the string and we only want to change the first character.\n        name_parts = []\n        for word in name.split('_'):\n            name_parts.append(word[0].upper())\n            if len(word) > 1:\n                name_parts.append(word[1:])\n        name = ''.join(name_parts)\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef kls_name(self):\n        # Determine kls for group\n        if not self.parent or not self.parent.name:\n            return 'Test{0}'.format(self.name)\n        else:\n            use = self.parent.kls_name\n            if use.startswith('Test'):\n                use = use[4:]\n\n            return 'Test{0}_{1}'.format(use, self.name)", "response": "Determine python name for group"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines what kls this group inherits from from", "response": "def super_kls(self):\n        \"\"\"\n            Determine what kls this group inherits from\n            If default kls should be used, then None is returned\n        \"\"\"\n        if not self.kls and self.parent and self.parent.name:\n            return self.parent.kls_name\n        return self.kls"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting a new group", "response": "def start_group(self, scol, typ):\n        \"\"\"Start a new group\"\"\"\n        return Group(parent=self, level=scol, typ=typ)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts a new single", "response": "def start_single(self, typ, scol):\n        \"\"\"Start a new single\"\"\"\n        self.starting_single = True\n        single = self.single = Single(typ=typ, group=self, indent=(scol - self.level))\n        self.singles.append(single)\n        return single"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a part to what will end up being the kls superclass", "response": "def modify_kls(self, name):\n        \"\"\"Add a part to what will end up being the kls' superclass\"\"\"\n        if self.kls is None:\n            self.kls = name\n        else:\n            self.kls += name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve list of all fields currently configured", "response": "def get_field_list(self):\n        \"\"\"\n        Retrieve list of all fields currently configured\n        \"\"\"\n\n        list_out = []\n        for field in self.fields:\n            list_out.append(field)\n\n        return list_out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef data_regex_method(fields_list, mongo_db_obj, hist, record, lookup_type):\n\n        if hist is None:\n            hist = {}\n\n        for field in record:\n\n            if record[field] != '' and record[field] is not None:\n\n                if field in fields_list:\n\n                    if lookup_type in fields_list[field]['lookup']:\n\n                        field_val_new, hist = RegexLookup(\n                            fieldVal=record[field],\n                            db=mongo_db_obj,\n                            fieldName=field,\n                            lookupType=lookup_type,\n                            histObj=hist)\n\n                        record[field] = field_val_new\n\n        return record, hist", "response": "Method to lookup the replacement value based on regular expressions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _val_fs_regex(self, record, hist=None):\n\n        record, hist = self.data_regex_method(fields_list=self.fields,\n                                              mongo_db_obj=self.mongo,\n                                              hist=hist,\n                                              record=record,\n                                              lookup_type='fieldSpecificRegex')\n        return record, hist", "response": "Perform field - specific validation regex\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming generic validation of the record and return the record and hist", "response": "def _norm_lookup(self, record, hist=None):\n        \"\"\"\n        Perform generic validation lookup\n\n        :param dict record: dictionary of values to validate\n        :param dict hist: existing input of history values\n        \"\"\"\n\n        record, hist = self.data_lookup_method(fields_list=self.fields,\n                                               mongo_db_obj=self.mongo,\n                                               hist=hist,\n                                               record=record,\n                                               lookup_type='normLookup')\n        return record, hist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nnormalize includes and excludes fields in a record.", "response": "def _norm_include(self, record, hist=None):\n        \"\"\"\n        Normalization 'normIncludes' replace 'almost' values based on at least\n        one of the following: includes strings, excludes strings, starts with\n        string, ends with string\n\n        :param dict record: dictionary of values to validate\n        :param dict hist: existing input of history values\n        \"\"\"\n\n        if hist is None:\n            hist = {}\n\n        for field in record:\n\n            if record[field] != '' and record[field] is not None:\n\n                if field in self.fields:\n\n                    if 'normIncludes' in self.fields[field]['lookup']:\n\n                        field_val_new, hist, _ = IncludesLookup(\n                            fieldVal=record[field],\n                            lookupType='normIncludes',\n                            db=self.mongo,\n                            fieldName=field,\n                            histObj=hist)\n\n                        record[field] = field_val_new\n\n        return record, hist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nderive the value of the target field from given input values from one or more fields.", "response": "def _derive(self, record, hist=None):\n        \"\"\"\n        Derivation filters like 'deriveValue' to replace given input values\n        from one or more fields. In case 'copyValue' copy value to the target\n        field from given an input value from one field. 'deriveRegex' replace\n        given an input value from one field, derive target field value using\n        regular expressions. If 'deriveIncludes' applies then given an input\n        value from one field, derive target field based on at least one of the\n        following: includes strings, excludes strings, starts with string,\n        ends with string\n\n        :param dict record: dictionary of values to validate\n        :param dict hist: existing input of history values\n        \"\"\"\n\n        def check_derive_options(option, derive_set_config):\n            \"\"\"\n            Check derive option is exist into options list and return relevant\n            flag.\n            :param str option: drive options value\n            :param list derive_set_config: options list\n            :return boolean: True or False based on option exist into options\n            list\n            \"\"\"\n\n            return option in derive_set_config\n\n        hist_obj = {}\n\n        if hist is None:\n            hist = {}\n\n        for field in record:\n\n            field_val_new = field_val = record[field]\n\n            if field in self.fields:\n\n                for derive_set in self.fields[field]['derive']:\n\n                    check_match = False\n\n                    derive_set_config = derive_set\n\n                    if set.issubset(set(derive_set_config['fieldSet']),\n                                    record.keys()):\n\n                        # sorting here to ensure sub document match from\n                        # query\n\n                        derive_input = {val: record[val] for val in\n                                        derive_set_config['fieldSet']}\n\n                        if derive_set_config['type'] == 'deriveValue':\n\n                            overwrite_flag = check_derive_options(\n                                'overwrite',\n                                derive_set_config[\"options\"])\n\n                            blank_if_no_match_flag = check_derive_options(\n                                'blankIfNoMatch',\n                                derive_set_config[\"options\"])\n\n                            field_val_new, hist_obj, check_match = \\\n                                DeriveDataLookup(\n                                    fieldName=field,\n                                    db=self.mongo,\n                                    deriveInput=derive_input,\n                                    overwrite=overwrite_flag,\n                                    fieldVal=record[field],\n                                    histObj=hist,\n                                    blankIfNoMatch=blank_if_no_match_flag)\n\n                        elif derive_set_config['type'] == 'copyValue':\n\n                            overwrite_flag = check_derive_options(\n                                'overwrite',\n                                derive_set_config[\"options\"])\n\n                            field_val_new, hist_obj, check_match = \\\n                                DeriveDataCopyValue(\n                                    fieldName=field,\n                                    deriveInput=derive_input,\n                                    overwrite=overwrite_flag,\n                                    fieldVal=record[field],\n                                    histObj=hist)\n\n                        elif derive_set_config['type'] == 'deriveRegex':\n\n                            overwrite_flag = check_derive_options(\n                                'overwrite',\n                                derive_set_config[\"options\"])\n\n                            blank_if_no_match_flag = check_derive_options(\n                                'blankIfNoMatch',\n                                derive_set_config[\"options\"])\n\n                            field_val_new, hist_obj, check_match = \\\n                                DeriveDataRegex(\n                                    fieldName=field,\n                                    db=self.mongo,\n                                    deriveInput=derive_input,\n                                    overwrite=overwrite_flag,\n                                    fieldVal=record[field],\n                                    histObj=hist,\n                                    blankIfNoMatch=blank_if_no_match_flag)\n\n                        elif derive_set_config['type'] == 'deriveIncludes':\n\n                            overwrite_flag = check_derive_options(\n                                'overwrite',\n                                derive_set_config[\"options\"])\n\n                            blank_if_no_match_flag = check_derive_options(\n                                'blankIfNoMatch',\n                                derive_set_config[\"options\"])\n\n                            field_val_new, hist_obj, check_match = \\\n                                IncludesLookup(\n                                    fieldVal=record[field],\n                                    lookupType='deriveIncludes',\n                                    deriveFieldName= \\\n                                        derive_set_config['fieldSet'][0],\n                                    deriveInput=derive_input,\n                                    db=self.mongo,\n                                    fieldName=field,\n                                    histObj=hist,\n                                    overwrite=overwrite_flag,\n                                    blankIfNoMatch=blank_if_no_match_flag)\n\n                    if check_match or field_val_new != field_val:\n                        record[field] = field_val_new\n                        break\n\n        return record, hist_obj"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _apply_udfs(self, record, hist, udf_type):\n\n        def function_executor(func, *args):\n            \"\"\"\n            Execute user define function\n            :param python method func: Function obj\n            :param methods arguments args: Function arguments\n            \"\"\"\n\n            result, result_hist = func(*args)\n\n            return result, result_hist\n\n        if udf_type in self.udfs:\n\n            cust_function_od_obj = collections.OrderedDict(\n                sorted(\n                    self.udfs[udf_type].items()\n                )\n            )\n\n            for cust_function in cust_function_od_obj:\n\n                record, hist = function_executor(\n                    cust_function_od_obj[cust_function],\n                    record,\n                    hist\n                )\n\n        return record, hist", "response": "Function to apply user - defined functions to data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self, record, hist=None):\n\n        if hist is None:\n            hist = {}\n\n        if record:\n            # Run user-defined functions for beforeGenericValLookup\n            record, hist = self._apply_udfs(record=record,\n                                            hist=hist,\n                                            udf_type='beforeGenericValLookup')\n\n            # Run generic validation lookup\n            record, hist = self._val_g_lookup(record=record, hist=hist)\n\n            # Run user-defined functions for beforeGenericValRegex\n            record, hist = self._apply_udfs(record=record,\n                                            hist=hist,\n                                            udf_type='beforeGenericValRegex')\n\n            # Run generic validation regex\n            record, hist = self._val_g_regex(record=record, hist=hist)\n\n            # Run user-defined functions for beforeFieldSpecificLookup\n            record, hist = self._apply_udfs(record=record,\n                                            hist=hist,\n                                            udf_type='beforeFieldSpecificLookup')\n\n            # Run field-specific validation lookup\n            record, hist = self._val_fs_lookup(record=record, hist=hist)\n\n            # Run user-defined functions for beforeFieldSpecificLookup\n            record, hist = self._apply_udfs(record=record,\n                                            hist=hist,\n                                            udf_type='beforeFieldSpecificRegex')\n\n            # Run field-specific validation regex\n            record, hist = self._val_fs_regex(record=record, hist=hist)\n\n            # Run user-defined functions for beforeNormLookup\n            record, hist = self._apply_udfs(record=record,\n                                            hist=hist,\n                                            udf_type='beforeNormLookup')\n\n            # Run normalization lookup\n            record, hist = self._norm_lookup(record=record, hist=hist)\n\n            # Run user-defined functions for beforeNormRegex\n            record, hist = self._apply_udfs(record=record,\n                                            hist=hist,\n                                            udf_type='beforeNormRegex')\n\n            # Run normalization regex\n            record, hist = self._norm_regex(record=record, hist=hist)\n\n            # Run user-defined functions for beforeNormIncludes\n            record, hist = self._apply_udfs(record=record,\n                                            hist=hist,\n                                            udf_type='beforeNormIncludes')\n\n            # Run normalization includes\n            record, hist = self._norm_include(record=record, hist=hist)\n\n            # Run user-defined functions for beforeNormIncludes\n            record, hist = self._apply_udfs(record=record,\n                                            hist=hist,\n                                            udf_type='beforeDerive')\n\n            # Fill gaps / refresh derived data\n            record, hist = self._derive(record=record, hist=hist)\n\n            # Run user-defined functions for beforeNormIncludes\n            record, hist = self._apply_udfs(record=record,\n                                            hist=hist,\n                                            udf_type='afterAll')\n\n            return record, hist\n\n        return None, hist", "response": "Run the validation functions for the specified record and returns the input record after cleaning with history ( dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_field_error_dict(self, field):\n        '''Returns the dict containing the field errors information'''\n        return {\n            'name': field.html_name,\n            'id': 'id_{}'.format(field.html_name), # This may be a problem\n            'errors': field.errors,\n        }", "response": "Returns the dict containing the field errors information"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_hidden_fields_errors(self, form):\n        '''Returns a dict to add in response when something is wrong with hidden fields'''\n        if not self.include_hidden_fields or form.is_valid():\n            return {}\n\n        response = {self.hidden_field_error_key:{}}\n\n        for field in form.hidden_fields():\n            if field.errors:\n                response[self.hidden_field_error_key][field.html_name] = self._get_field_error_dict(field)\n        return response", "response": "Returns a dict to add in response when something is wrong with hidden fields"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding the JSON for the errors", "response": "def form_invalid(self, form):\n        '''Builds the JSON for the errors'''\n        response = {self.errors_key: {}}\n        response[self.non_field_errors_key] = form.non_field_errors()\n        response.update(self.get_hidden_fields_errors(form))\n\n        for field in form.visible_fields():\n            if field.errors:\n                response[self.errors_key][field.html_name] = self._get_field_error_dict(field)\n\n        if self.include_success:\n            response[self.sucess_key] = False\n\n        return self._render_json(response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset environment - name", "response": "def do_env(self, line):\n        \"\"\"\n        env {environment-name}\n        \"\"\"\n        if not line:\n            print \"use: env {environment-name}\"\n        else:\n            if not set_environment(line):\n                print \"no configuration for environment %s\" % line\n            else:\n                self.do_login('')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_login(self, line):\n        \"login aws-acces-key aws-secret\"\n        if line:\n            args = self.getargs(line)\n\n            self.conn = boto.connect_dynamodb(\n                aws_access_key_id=args[0],\n                aws_secret_access_key=args[1])\n        else:\n            self.conn = boto.connect_dynamodb()\n\n        self.do_tables('')", "response": "login aws - acces - key aws - secret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_describe(self, line):\n        \"describe [-c] {tablename}...\"\n        args = self.getargs(line)\n\n        if '-c' in args:\n            create_info = True\n            args.remove('-c')\n        else:\n            create_info = False\n\n        if not args:\n            if self.table:\n                args = [self.table.name]\n            else:\n                args = self.tables\n\n        for table in args:\n            desc = self.conn.describe_table(table)\n\n            if create_info:\n                info = desc['Table']\n                schema = info['KeySchema']\n                name = info['TableName']\n\n                hkey = schema['HashKeyElement']\n                hkey = \"%s:%s\" % (hkey['AttributeName'], hkey['AttributeType'])\n\n                if 'RangeKeyElement' in schema:\n                    rkey = schema['RangeKeyElement']\n                    rkey = \" %s:%s\" % (rkey['AttributeName'], rkey['AttributeType'])\n                else:\n                    rkey = ''\n\n                prov = info['ProvisionedThroughput']\n                prov = \"-c %d,%d\" % (prov['ReadCapacityUnits'], prov['WriteCapacityUnits'])\n                print \"create %s %s %s%s\" % (name, prov, hkey, rkey)\n            else:\n                self.pprint(desc, \"%s: \" % table)", "response": "describe [- c ] { tablename }..."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating - c rc wc", "response": "def do_create(self, line):\n        \"create {tablename} [-c rc,wc] {hkey}[:{type} {rkey}:{type}]\"\n        args = self.getargs(line)\n        rc = wc = 5\n\n        name = args.pop(0)  # tablename\n\n        if args[0] == \"-c\":  # capacity\n            args.pop(0)  # skyp -c\n\n            capacity = args.pop(0).strip()\n            rc, _, wc = capacity.partition(\",\")\n            rc = int(rc)\n            wc = int(wc) if wc != \"\" else rc\n\n        hkey, _, hkey_type = args.pop(0).partition(':')\n        hkey_type = self.get_type(hkey_type or 'S')\n\n        if args:\n            rkey, _, rkey_type = args.pop(0).partition(':')\n            rkey_type = self.get_type(rkey_type or 'S')\n        else:\n            rkey = rkey_type = None\n\n        t = self.conn.create_table(name,\n                                   self.conn.create_schema(hkey, hkey_type, rkey, rkey_type),\n                                   rc, wc)\n        self.pprint(self.conn.describe_table(t.name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_scan(self, line):\n\n        table, line = self.get_table_params(line)\n        args = self.getargs(line)\n\n        scan_filter = {}\n        count = False\n        as_array = False\n        max_size = None\n        batch_size = None\n        start = None\n\n        while args:\n            arg = args[0]\n\n            if arg.startswith('+'):\n                args.pop(0)\n                filter_name, filter_value = arg[1:].split(':', 1)\n\n                if filter_value.startswith(\"begin=\"):\n                    filter_cond = BEGINS_WITH(self.get_typed_value(filter_name, filter_value[6:]))\n                elif filter_value.startswith(\"eq=\"):\n                    filter_cond = EQ(self.get_typed_value(filter_name, filter_value[3:]))\n                elif filter_value.startswith(\"ne=\"):\n                    filter_cond = NE(self.get_typed_value(filter_name, filter_value[3:]))\n                elif filter_value.startswith(\"le=\"):\n                    filter_cond = LE(self.get_typed_value(filter_name, filter_value[3:]))\n                elif filter_value.startswith(\"lt=\"):\n                    filter_cond = LT(self.get_typed_value(filter_name, filter_value[3:]))\n                elif filter_value.startswith(\"ge=\"):\n                    filter_cond = GE(self.get_typed_value(filter_name, filter_value[3:]))\n                elif filter_value.startswith(\"gt=\"):\n                    filter_cond = GT(self.get_typed_value(filter_name, filter_value[3:]))\n                elif filter_value == \":exists\":\n                    filter_cond = NOT_NULL()\n                elif filter_value == \":nexists\":\n                    filter_cond = NULL()\n                elif filter_value.startswith(\"contains=\"):\n                    filter_cond = CONTAINS(self.get_typed_value(filter_name, filter_value[9:]))\n                elif filter_value.startswith(\"between=\"):\n                    parts = filter_value[8:].split(\",\", 1)\n                    filter_cond = BETWEEN(self.get_typed_value(parts[0]), self.get_typed_value(filter_name, parts[1]))\n                else:\n                    filter_cond = EQ(self.get_typed_value(filter_name, filter_value))\n\n                scan_filter[filter_name] = filter_cond\n\n            elif arg.startswith('--batch='):\n                args.pop(0)\n                batch_size = int(arg[8:])\n\n            elif arg.startswith('--max='):\n                args.pop(0)\n                max_size = int(arg[6:])\n\n            elif arg.startswith('--start='):\n                args.pop(0)\n                start = (arg[8:], )\n\n            elif arg == '--next':\n                args.pop(0)\n                if self.next_key:\n                    start = self.next_key\n                else:\n                    print \"no next\"\n                    return\n\n            elif arg in ['--array', '-a']:\n                args.pop(0)\n                as_array = True\n\n            elif arg in ['--count', '-c']:\n                args.pop(0)\n                count = True\n\n            elif arg[0] == '-' and arg[1:].isdigit():\n                args.pop(0)\n                max_size = int(arg[1:])\n\n            elif arg == '--':\n                args.pop(0)\n                break\n\n            elif arg.startswith('-'):\n                args.pop(0)\n                print \"invalid argument: %s\" % arg\n                break\n\n            else:\n                break\n\n        attr_keys = args[0].split(\",\") if args else None\n        attrs = list(set(attr_keys)) if attr_keys else None\n\n        #print \"scan filter:%s attributes:%s limit:%s max:%s count:%s\" % (scan_filter, attrs, batch_size, max, count)\n\n        result = table.scan(scan_filter=scan_filter, attributes_to_get=attrs, request_limit=batch_size, max_results=max_size, count=count, exclusive_start_key=start)\n\n        if count:\n            print \"count: %s/%s\" % (result.scanned_count, result.count)\n            self.next_key = None\n        else:\n            if as_array and attr_keys:\n                self.print_iterator_array(result, attr_keys)\n            else:\n                self.print_iterator(result)\n\n            self.next_key = result.last_evaluated_key\n\n        if self.consumed:\n            print \"consumed units:\", result.consumed_units", "response": "Scan the log file for the available entries."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nqueries the ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3166 - 1 ISO 3.", "response": "def do_query(self, line):\n        \"\"\"\n        query [:tablename] [-r] [--count|-c] [--array|-a] [-{max}] [{rkey-condition}] hkey [attributes,...]\n\n        where rkey-condition:\n            --eq={key} (equal key)\n            --ne={key} (not equal key)\n            --le={key} (less or equal than key)\n            --lt={key} (less than key)\n            --ge={key} (greater or equal than key)\n            --gt={key} (greater than key)\n            --exists   (key exists)\n            --nexists  (key does not exists)\n            --contains={key} (contains key)\n            --ncontains={key} (does not contains key)\n            --begin={startkey} (rkey begins with startkey)\n            --between={firstkey},{lastkey} (between firstkey and lastkey)\n        \"\"\"\n\n        table, line = self.get_table_params(line)\n        args = self.getargs(line)\n\n        condition = None\n        count = False\n        as_array = False\n        max_size = None\n        batch_size = None\n        start = None\n\n        if '-r' in args:\n            asc = False\n            args.remove('-r')\n        else:\n            asc = True\n\n        while args:\n            arg = args[0]\n\n            if arg[0] == '-' and arg[1:].isdigit():\n                max_size = int(arg[1:])\n                args.pop(0)\n\n            elif args[0].startswith('--max='):\n                arg = args.pop(0)\n                max_size = int(arg[6:])\n\n            elif arg in ['--count', '-c']:\n                count = True\n                args.pop(0)\n\n            elif arg in ['--array', '-a']:\n                as_array = True\n                args.pop(0)\n\n            elif args[0].startswith('--batch='):\n                arg = args.pop(0)\n                batch_size = int(arg[8:])\n\n            elif args[0].startswith('--start='):\n                arg = args.pop(0)\n                start = (arg[8:], )\n\n            elif args[0] == '--next':\n                arg = args.pop(0)\n                if self.next_key:\n                    start = self.next_key\n                else:\n                    print \"no next\"\n                    return\n\n            elif arg.startswith(\"--begin=\"):\n                condition = BEGINS_WITH(self.get_typed_key_value(table, arg[8:], False))\n                args.pop(0)\n            elif arg.startswith(\"--eq=\"):\n                condition = EQ(self.get_typed_key_value(table, arg[5:], False))\n                args.pop(0)\n            elif arg.startswith(\"--ne=\"):\n                condition = NE(self.get_typed_key_value(table, arg[5:], False))\n                args.pop(0)\n            elif arg.startswith(\"--le=\"):\n                condition = LE(self.get_typed_key_value(table, arg[5:], False))\n                args.pop(0)\n            elif arg.startswith(\"--lt=\"):\n                condition = LT(self.get_typed_key_value(table, arg[5:], False))\n                args.pop(0)\n            elif arg.startswith(\"--ge=\"):\n                condition = GE(self.get_typed_key_value(table, arg[5:], False))\n                args.pop(0)\n            elif arg.startswith(\"--gt=\"):\n                condition = GT(self.get_typed_key_value(table, arg[5:], False))\n                args.pop(0)\n            elif arg == \"--exists\":\n                condition = NOT_NULL()\n                args.pop(0)\n            elif arg == \"--nexists\":\n                condition = NULL()\n                args.pop(0)\n            elif arg.startswith(\"--contains=\"):\n                condition = CONTAINS(self.get_typed_key_value(table, arg[11:], False))\n                args.pop(0)\n            elif arg.startswith(\"--between=\"):\n                parts = arg[10:].split(\",\", 1)\n                condition = BETWEEN(self.get_typed_key_value(table, parts[0], True), self.get_typed_key_value(table, parts[1], False))\n                args.pop(0)\n\n            else:\n                break\n\n        hkey = self.get_typed_key_value(table, args.pop(0))\n        attr_keys = args[0].split(\",\") if args else None\n        attrs = list(set(attr_keys)) if attr_keys else None\n\n        result = table.query(hkey, range_key_condition=condition, attributes_to_get=attrs, scan_index_forward=asc, request_limit=batch_size, max_results=max_size, count=count, exclusive_start_key=start)\n\n        if count:\n            print \"count: %s/%s\" % (result.scanned_count, result.count)\n            self.next_key = None\n        else:\n            if as_array and attr_keys:\n                self.print_iterator_array(result, attr_keys)\n            else:\n                self.print_iterator(result)\n\n            self.next_key = result.last_evaluated_key\n\n        if self.consumed:\n            print \"consumed units:\", result.consumed_units"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves [ tablename... ] yes", "response": "def do_rmall(self, line):\n        \"remove [tablename...] yes\"\n        args = self.getargs(line)\n        if args and args[-1] == \"yes\":\n            args.pop()\n\n            if not args:\n                args = [self.table.name]\n\n            while args:\n                table = self.conn.get_table(args.pop(0))\n                print \"from table \" + table.name\n\n                for item in table.scan(attributes_to_get=[], request_limit=10):\n                    print \"  removing %s\" % item\n                    item.delete()\n        else:\n            print \"ok, never mind...\""}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dictionary with all variables", "response": "def getAll(self):\n        '''Return a dictionary with all variables'''\n\n        if not bool(len(self.ATTRIBUTES)):\n            self.load_attributes()\n        return eval(str(self.ATTRIBUTES))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndefines a variable in DB and in memory", "response": "def set(self, name, default=0, editable=True, description=\"\"):\n        '''Define a variable in DB and in memory'''\n\n        var, created = ConfigurationVariable.objects.get_or_create(name=name)\n\n        if created:\n            var.value = default\n\n        if not editable:\n            var.value = default\n\n        var.editable = editable\n        var.description = description\n        var.save(reload=False)\n\n        # ATTRIBUTES is accesible by any instance of VariablesManager\n        self.ATTRIBUTES[var.name] = var.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_attributes(self):\n        '''Read the variables from the VARS_MODULE_PATH'''\n\n        try:\n            vars_path = settings.VARS_MODULE_PATH\n        except Exception:\n            # logger.warning(\"*\" * 55)\n            logger.warning(\n                \" [WARNING] Using default VARS_MODULE_PATH = '{}'\".format(\n                    VARS_MODULE_PATH_DEFAULT))\n            vars_path = VARS_MODULE_PATH_DEFAULT\n\n        try:\n            __import__(vars_path)\n        except ImportError:\n            logger.warning(\" [WARNING] No module named '{}'\".format(\n                vars_path))\n            logger.warning(\" Please, read the docs: goo.gl/E82vkX\\n\".format(\n                vars_path))", "response": "Read the variables from the VARS_MODULE_PATH"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compile_expression(source):\n\n    # FORCE MODULES TO BE IN NAMESPACE\n    _ = coalesce\n    _ = listwrap\n    _ = Date\n    _ = convert\n    _ = Log\n    _ = Data\n    _ = EMPTY_DICT\n    _ = re\n    _ = wrap_leaves\n    _ = is_data\n\n    fake_locals = {}\n    try:\n        exec(\n\"\"\"\ndef output(row, rownum=None, rows=None):\n    _source = \"\"\" + convert.value2quote(source) + \"\"\"\n    try:\n        return \"\"\" + source + \"\"\"\n    except Exception as e:\n        Log.error(\"Problem with dynamic function {{func|quote}}\",  func=_source, cause=e)\n\"\"\",\n            globals(),\n            fake_locals\n        )\n    except Exception as e:\n        Log.error(\"Bad source: {{source}}\", source=source, cause=e)\n    return fake_locals['output']", "response": "Compiles a source code into a single function that returns a single object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clean(self, value, model_instance):\n        #: return constant's name instead of constant itself\n        value = self.to_python(value).name\n        self.validate(value, model_instance)\n        self.run_validators(value)\n        return value", "response": "Convert the value s type and run validation."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of all flatchoices in the admin s list_display attribute.", "response": "def _get_flatchoices(self):\n        \"\"\"\n        Redefine standard method.\n\n        Return constants themselves instead of their names for right rendering\n        in admin's 'change_list' view, if field is present in 'list_display'\n        attribute of model's admin.\n        \"\"\"\n        return [\n            (self.to_python(choice), value) for choice, value in self._choices\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a django. forms. Field instance for this database Field.", "response": "def formfield(self, form_class=None, choices_form_class=None, **kwargs):\n        \"\"\"\n        Returns a django.forms.Field instance for this database Field.\n        \"\"\"\n        defaults = {\n            'required': not self.blank,\n            'label': capfirst(self.verbose_name),\n            'help_text': self.help_text,\n        }\n        if self.has_default():\n            if callable(self.default):\n                defaults['initial'] = self.default\n                defaults['show_hidden_initial'] = True\n            else:\n                defaults['initial'] = self.get_default()\n\n        include_blank = (self.blank\n                         or not (self.has_default()\n                                 or 'initial' in kwargs))\n\n        choices = [BLANK_CHOICE_DASH, ] if include_blank else []\n        choices.extend([\n            (\n                x.name,\n                getattr(x, 'verbose_name', x.name) or x.name,\n                getattr(x, 'help_text', None) or None\n            )\n            for x in self.choices_class.constants()\n        ])\n\n        defaults['choices'] = choices\n        defaults['coerce'] = self.to_python\n\n        if self.null:\n            defaults['empty_value'] = None\n\n        # Many of the subclass-specific formfield arguments (min_value,\n        # max_value) don't apply for choice fields, so be sure to only pass\n        # the values that TypedChoiceField will understand.\n        for k in list(kwargs):\n            if k not in ('coerce', 'empty_value', 'choices', 'required',\n                         'widget', 'label', 'initial', 'help_text',\n                         'error_messages', 'show_hidden_initial'):\n                del kwargs[k]\n\n        defaults.update(kwargs)\n        form_class = choices_form_class or ChoicesFormField\n        return form_class(**defaults)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_bundle(self, current_bundle, url_kwargs, context_kwargs):\n        if self.bundle_attr:\n            if self.bundle_attr == PARENT:\n                return current_bundle.parent\n\n            view, name = current_bundle.get_view_and_name(self.bundle_attr)\n            return view\n\n        return current_bundle", "response": "Returns the bundle to get the alias view from."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the name of the view to lookup.", "response": "def get_view_name(self, requested):\n        \"\"\"\n        Returns the name of the view to lookup.\n        If `requested` is equal to 'self.bundle_attr' then\n        'main' will be returned. Otherwise if `self.alias_to`\n        is set the it's value will be returned. Otherwise\n        the `requested` itself will be returned.\n\n        \"\"\"\n        value = self.alias_to and self.alias_to or requested\n        if value == self.bundle_attr:\n            return 'main'\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a view instance and view name of the object header that is linked to in the header.", "response": "def get_object_header_view(self, request, url_kwargs, parent_only=False,\n                                render_type='object_header'):\n        \"\"\"\n        An object header is the title block of a CMS page. Actions\n        to linked to in the header are based on this views\n        bundle.\n\n        This returns a view instance and view name of the view that\n        should be rendered as an object header the view used is specified\n        in `self.object_view`. If not match is found None, None is returned\n\n        :param request: The request object\n        :param url_kwargs: Any url keyword arguments as a dictionary\n        :param parent_only: If `True` then the view will only \\\n        be rendered if object_view points to parent. This is usually \\\n        what you want to avoid extra lookups to get the object \\\n        you already have.\n        :param render_type: The render type to use for the header. \\\n        Defaults to 'object_header'.\n        \"\"\"\n\n        if parent_only and self.object_view != self.parent_attr:\n            return None, None\n\n        if self.object_view == self.parent_attr and self.parent:\n            return self.parent.get_object_header_view(request, url_kwargs,\n                                                    render_type=render_type)\n        elif self.object_view:\n            view, name = self.get_initialized_view_and_name(self.object_view,\n                                    can_submit=False,\n                                    base_template='cms/partial.html',\n                                    request=request, kwargs=url_kwargs,\n                                    render_type=render_type)\n            if view and view.can_view(request.user):\n                return view, name\n        return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_string_from_view(self, request, view_name, url_kwargs,\n                                                render_type='string'):\n\n        \"\"\"\n        Returns a string that is a rendering of the view given a\n        request, view_name, and the original url_kwargs. Makes the\n        following changes the view before rendering:\n\n        * Sets can_submit to False.\n        * Adds action_url to the context. This is the url where \\\n        this view actually lives.\n        * Sets the default base_template to be 'cms/partial.html'\n\n        This will always call GET and never POST as any actions\n        that modify data should take place on the original\n        url and not like this.\n\n        :param request: The request object.\n        :param view_name: The name of the view that you want.\n        :param url_kwargs: The url keyword arguments that came \\\n        with the request object. The view itself is responsible \\\n        to remove arguments that would not be part of a normal match \\\n        for that view. This is done by calling  the `get_url_kwargs` \\\n        method on the view.\n        :param render_type: The render type to use. Defaults to \\\n        'string'.\n        \"\"\"\n\n        response = \"\"\n        try:\n            view, name = self.get_initialized_view_and_name(view_name,\n                                    render_type=render_type,\n                                    can_submit=False,\n                                    base_template='cms/partial.html',\n                                    request=request, kwargs=url_kwargs)\n\n            if isinstance(view, URLAlias):\n                view_name = view.get_view_name(view_name)\n                bundle = view.get_bundle(self, url_kwargs, {})\n                if bundle and isinstance(bundle, Bundle):\n                    return bundle.get_string_from_view(request, view_name,\n                                                    url_kwargs,\n                                                    render_type=render_type)\n\n            elif view:\n                if view and name and view.can_view(request.user):\n                    response = self._render_view_as_string(view, name, request,\n                                                           url_kwargs)\n        except http.Http404:\n            pass\n        return response", "response": "Returns a string that is a rendering of the view given the request view_name and url_kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_view_url(self, view_name, user,\n                     url_kwargs=None, context_kwargs=None,\n                     follow_parent=True, check_permissions=True):\n        \"\"\"\n        Returns the url for a given view_name. If the view isn't\n        found or the user does not have permission None is returned.\n        A NoReverseMatch error may be raised if the view was unable\n        to find the correct keyword arguments for the reverse function\n        from the given url_kwargs and context_kwargs.\n\n        :param view_name: The name of the view that you want.\n        :param user: The user who is requesting the view\n        :param url_kwargs: The url keyword arguments that came \\\n        with the request object. The view itself is responsible \\\n        to remove arguments that would not be part of a normal match \\\n        for that view. This is done by calling  the `get_url_kwargs` \\\n        method on the view.\n        :param context_kwargs: Extra arguments that will be passed \\\n        to the view for consideration in the final keyword arguments \\\n        for reverse.\n        :param follow_parent: If we encounter a parent reference should \\\n        we follow it. Defaults to True.\n        :param check_permisions: Run permissions checks. Defaults to True.\n        \"\"\"\n\n        view, url_name = self.get_initialized_view_and_name(view_name,\n                                            follow_parent=follow_parent)\n\n        if isinstance(view, URLAlias):\n            view_name = view.get_view_name(view_name)\n            bundle = view.get_bundle(self, url_kwargs, context_kwargs)\n\n            if bundle and isinstance(bundle, Bundle):\n                return bundle.get_view_url(view_name, user,\n                                           url_kwargs=url_kwargs,\n                                           context_kwargs=context_kwargs,\n                                           follow_parent=follow_parent,\n                                           check_permissions=check_permissions)\n\n        elif view:\n\n            # Get kwargs from view\n            if not url_kwargs:\n                url_kwargs = {}\n\n            url_kwargs = view.get_url_kwargs(context_kwargs, **url_kwargs)\n            view.kwargs = url_kwargs\n\n            if check_permissions and not view.can_view(user):\n                return None\n\n            url = reverse(\"admin:%s\" % url_name, kwargs=url_kwargs)\n            return url", "response": "Returns the url for a given view_name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate and returns a new instance of a CMSView and its url_name.", "response": "def get_initialized_view_and_name(self, view_name,\n                                    follow_parent=True, **extra_kwargs):\n        \"\"\"\n        Creates and returns a new instance of a CMSView \\\n        and it's url_name.\n\n        :param view_name: The name of the view to return.\n        :param follow_parent: If we encounter a parent reference should \\\n        we follow it. Defaults to True.\n        :param extra_kwargs: Keyword arguments to pass to the view.\n        \"\"\"\n\n        view, name = self.get_view_and_name(view_name)\n\n        # Initialize the view with the right kwargs\n        if hasattr(view, 'as_view'):\n            e = dict(extra_kwargs)\n            e.update(**self._get_view_kwargs(view, view_name))\n            e['name'] = view_name\n            view = view(**e)\n\n        # It is a Bundle return the main\n        elif isinstance(view, Bundle):\n            view, name = view.get_initialized_view_and_name('main',\n                                                        **extra_kwargs)\n        elif view == self.parent_attr and self.parent:\n            if follow_parent:\n                return self.parent.get_initialized_view_and_name(view_name,\n                                                              **extra_kwargs)\n            else:\n                view = None\n                name = None\n        return view, name"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget s the title of the bundle.", "response": "def get_title(self, plural=True):\n        \"\"\"\n        Get's the title of the bundle. Titles can be singular\n        or plural.\n        \"\"\"\n        value = self.title\n        if value == self.parent_attr:\n            return self.parent.get_title(plural=plural)\n\n        if not value and self._meta.model:\n            value = helpers.model_name(self._meta.model,\n                                       self._meta.custom_model_name,\n                                       self._meta.custom_model_name_plural,\n                                       plural)\n        elif self.title and plural:\n            value = helpers.pluralize(self.title, self.title_plural)\n\n        return helpers.capfirst_if_needed(value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_view_and_name(self, attname):\n        view = getattr(self, attname, None)\n        if attname in self._children:\n            view = self._get_bundle_from_promise(attname)\n\n        if view:\n            if attname in self._children:\n                return view, view.name\n            elif isinstance(view, ViewAlias):\n                view_name = view.get_view_name(attname)\n                bundle = view.get_bundle(self, {}, {})\n                if bundle and isinstance(bundle, Bundle):\n                    view, name = bundle.get_view_and_name(view_name)\n\n            if hasattr(view, 'as_view'):\n                if attname != 'main':\n                    name = \"%s_%s\" % (self.name, attname)\n                else:\n                    name = self.name\n                return view, name\n            elif view == self.parent_attr and self.parent:\n                return self.parent_attr, None\n            elif isinstance(view, URLAlias):\n                return view, None\n\n        return None, None", "response": "Gets a view or bundle and returns it\n        and it s url_name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_urls(self):\n        parts = []\n        seen = set()\n\n        # Process item views in order\n        for v in list(self._meta.item_views)+list(self._meta.action_views):\n            if not v in seen:\n                view, name = self.get_view_and_name(v)\n                if view and name:\n                    parts.append(self.get_url(name, view, v))\n                seen.add(v)\n\n        # Process everything else that we have not seen\n        for v in set(self._views).difference(seen):\n            # Get the url name\n            view, name = self.get_view_and_name(v)\n            if view and name:\n                parts.append(self.get_url(name, view, v))\n\n        return parts", "response": "Returns urls handling bundles and views."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of tuples based on the values in self. navigation and self. parent_attr.", "response": "def get_navigation(self, request, **kwargs):\n        \"\"\"\n        Generates a list of tuples based on the values\n        in `self.navigation` that are the side navigation links\n        for this bundle. The tuple format is (url, title).\n        \"\"\"\n\n        if self.navigation == self.parent_attr:\n            if self.parent:\n                return self.parent.get_navigation(request, **kwargs)\n            return ()\n        else:\n            return self._nav_from_tuple(request, self.navigation,\n                                **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap the given bundle so that it can be lazily instantiated.", "response": "def as_subbundle(cls, name=None, title=None, title_plural=None):\n        \"\"\"\n        Wraps the given bundle so that it can be lazily\n        instantiated.\n\n        :param name: The slug for this bundle.\n        :param title: The verbose name for this bundle.\n        \"\"\"\n        return PromiseBundle(cls, name=name, title=title,\n                                title_plural=title_plural)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform the actual image cropping operation with PIL.", "response": "def _thumbnail_resize(self, image, thumb_size, crop=None, bg=None):\n        \"\"\"Performs the actual image cropping operation with PIL.\"\"\"\n\n        if crop == 'fit':\n            img = ImageOps.fit(image, thumb_size, Image.ANTIALIAS)\n        else:\n            img = image.copy()\n            img.thumbnail(thumb_size, Image.ANTIALIAS)\n\n        if bg:\n            img = self._bg_square(img, bg)\n\n        return img"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _thumbnail_local(self, original_filename, thumb_filename,\n                         thumb_size, thumb_url, crop=None, bg=None,\n                         quality=85):\n        \"\"\"Finds or creates a thumbnail for the specified image on the local filesystem.\"\"\"\n\n        # create folders\n        self._get_path(thumb_filename)\n\n        thumb_url_full = url_for('static', filename=thumb_url)\n\n        # Return the thumbnail URL now if it already exists locally\n        if os.path.exists(thumb_filename):\n            return thumb_url_full\n\n        try:\n            image = Image.open(original_filename)\n        except IOError:\n            return ''\n\n        img = self._thumbnail_resize(image, thumb_size, crop=crop, bg=bg)\n\n        img.save(thumb_filename, image.format, quality=quality)\n\n        return thumb_url_full", "response": "Finds or creates a thumbnail for the specified image on the local filesystem."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding or creates a thumbnail for the specified image on Amazon S3.", "response": "def _thumbnail_s3(self, original_filename, thumb_filename,\n                      thumb_size, thumb_url, bucket_name,\n                      crop=None, bg=None, quality=85):\n        \"\"\"Finds or creates a thumbnail for the specified image on Amazon S3.\"\"\"\n\n        scheme = self.app.config.get('THUMBNAIL_S3_USE_HTTPS') and 'https' or 'http'\n\n        thumb_url_full = url_for_s3(\n            'static',\n            bucket_name=self.app.config.get('THUMBNAIL_S3_BUCKET_NAME'),\n            filename=thumb_url,\n            scheme=scheme)\n        original_url_full = url_for_s3(\n            'static',\n            bucket_name=bucket_name,\n            filename=self._get_s3_path(original_filename).replace('static/', ''),\n            scheme=scheme)\n\n        # Return the thumbnail URL now if it already exists on S3.\n        # HTTP HEAD request saves us actually downloading the image\n        # for this check.\n        # Thanks to:\n        # http://stackoverflow.com/a/16778749/2066849\n        try:\n            resp = httplib2.Http().request(thumb_url_full, 'HEAD')\n            resp_status = int(resp[0]['status'])\n            assert(resp_status < 400)\n            return thumb_url_full\n        except Exception:\n            pass\n\n        # Thanks to:\n        # http://stackoverflow.com/a/12020860/2066849\n        try:\n            fd = urllib.urlopen(original_url_full)\n            temp_file = BytesIO(fd.read())\n            image = Image.open(temp_file)\n        except Exception:\n            return ''\n\n        img = self._thumbnail_resize(image, thumb_size, crop=crop, bg=bg)\n\n        temp_file = BytesIO()\n        img.save(temp_file, image.format, quality=quality)\n\n        conn = S3Connection(self.app.config.get('THUMBNAIL_S3_ACCESS_KEY_ID'), self.app.config.get('THUMBNAIL_S3_ACCESS_KEY_SECRET'))\n        bucket = conn.get_bucket(self.app.config.get('THUMBNAIL_S3_BUCKET_NAME'))\n\n        path = self._get_s3_path(thumb_filename)\n        k = bucket.new_key(path)\n\n        try:\n            k.set_contents_from_string(temp_file.getvalue())\n            k.set_acl(self.app.config.get('THUMBNAIL_S3_ACL', 'public-read'))\n        except S3ResponseError:\n            return ''\n\n        return thumb_url_full"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhooks for adding data to the context before rendering a template.", "response": "def update_kwargs(self, request, **kwargs):\n        \"\"\"\n        Hook for adding data to the context before\n        rendering a template.\n\n        :param kwargs: The current context keyword arguments.\n        :param request: The current request object.\n        \"\"\"\n        if not 'base' in kwargs:\n            kwargs['base'] = self.base\n            if request.is_ajax() or request.GET.get('json'):\n                kwargs['base'] = self.partial_base\n\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render(self, request, redirect_url=None, **kwargs):\n        if redirect_url:\n            # Redirection is used when we click on `Save` for ordering\n            # items on `ListView`. `kwargs` contains `message` but that\n            # one is not passing through redirection. That's the reason for using\n            # directly `messages` and get message on result template\n            if kwargs.get('obj') is None:\n                messages.success(request, kwargs.get('message'))\n            return self.redirect(request, redirect_url, **kwargs)\n\n        kwargs = self.update_kwargs(request, **kwargs)\n        return render(request, self.template, kwargs)", "response": "Uses self. template to render a response."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_kwargs(self, request, **kwargs):\n\n        kwargs = super(CMSRender, self).update_kwargs(request, **kwargs)\n\n        # Check if we need to to include a separate object\n        # bundle for the title\n        bundle = kwargs.get('bundle')\n        url_kwargs = kwargs.get('url_params')\n        view = None\n        if bundle:\n            view, name = bundle.get_object_header_view(request, url_kwargs, parent_only=True)\n\n        kwargs['dashboard'] = bundle.admin_site.get_dashboard_urls(request)\n\n        if view:\n            obj = view.get_object()\n            if not 'object_header' in kwargs:\n                kwargs['object_header'] = bundle._render_view_as_string(view, name, request, url_kwargs)\n            if obj and obj != kwargs.get('obj'):\n                kwargs['subitem'] = True\n        return kwargs", "response": "Updates the keyword arguments passed to the base cms templates."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a url that preserves the current querystring while changing the page requested to page.", "response": "def get_different_page(self, request, page):\n        \"\"\"\n        Returns a url that preserves the current querystring\n        while changing the page requested to `page`.\n        \"\"\"\n\n        if page:\n            qs = request.GET.copy()\n            qs['page'] = page\n            return \"%s?%s\" % (request.path_info, qs.urlencode())\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a JSON representation of the current object list page.", "response": "def render(self, request, **kwargs):\n        \"\"\"\n        Returns a JSON representation of a objects list page.\n        The json has the following attributes:\n\n        * **is_paginated** - Is the list paginated.\n        * **results** - A list of objects, where each object has an \\\n        attribute/value for each field in the list. An 'id' attribute \\\n        is always included.\n        * **fields** - An object who's properties are the fields \\\n        in the results list. Each property will have an object with \\\n        the the following attributes:\n            * **name** - The verbose name of the field.\n            * **sortable** - Can this column be sorted. True or False.\n            * **order_type** - What is the current order of this column.\n\n        The following attributes only appear if the list is paginated:\n\n        * **count** - If the list is paginated, how many objects \\\n        total are there.\n        * **page** - Current page number.\n        * **next** - The full link to the next page.\n        * **previous** - The full link to the previous page.\n\n        If the list can be filtered the following attribute is included:\n\n        * **params** - An object who's properties are the filter options. \\\n            Each property contains an object with the following attributes:\n            * **value** - If the current result list has been filtered by \\\n            this field then value will contain the filter value that was used.\n            * **choices** - If the field is a choice field this will contain \\\n            the options.\n\n        Example JSON:\n\n        ::\n\n            {\"count\": 1,\n            \"fields\": {\n                \"name\": {\"sortable\": true, \"name\": \"name\", \"order_type\": \"asc\"}\n            },\n            \"results\": [{\"id\": 12, \"name\": \"Test\"}],\n            \"next\": \"\",\n            \"params\": {\"name\": {\"value\": null}},\n            \"is_paginated\": true,\n            \"page\": 1,\n            \"previous\": \"\"}\n        \"\"\"\n        data = {\n            'is_paginated': kwargs.get('is_paginated')\n        }\n\n        if data.get('is_paginated'):\n            page = kwargs['page_obj']\n\n            next_p = ''\n            previous = ''\n            if page.has_next():\n                next_p = self.get_different_page(request, page.number + 1)\n\n            if page.has_previous():\n                previous = self.get_different_page(request, page.number - 1)\n\n            data.update({\n                'count': page.paginator.count,\n                'page': page.number,\n                'next': next_p,\n                'previous': previous,\n            })\n\n        if kwargs.get('filter_form'):\n            exclude = request.GET.getlist('exclude')\n            filter_form = {}\n            form = kwargs.get('filter_form')\n            for name in form.get_search_fields(exclude):\n                k = form[name]\n                obj = {}\n                obj['value'] = k.value()\n                obj['label'] = k.label\n                if hasattr(k.field, 'choices'):\n                    obj['choices'] = k.field.choices\n\n                filter_form[k.name] = obj\n\n            data['params'] = filter_form\n\n        adm_list = kwargs['list']\n        data['fields'] = self.get_fields(adm_list)\n        data['results'] = self.get_object_list(adm_list)\n        return http.HttpResponse(json.dumps(data, cls=DjangoJSONEncoder))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_kwargs_for_view(self, name):\n\n        data = dict(self.default_kwargs)\n        for k in self.view_attributes:\n            if hasattr(self, k):\n                data[k] = getattr(self, k)\n        data.update(getattr(self, '%s_kwargs' % name, {}))\n        return data", "response": "Returns the full list of keyword arguments for the given view name as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(url):\n    url = text_type(url)\n    if url.find(\"://\") == -1:\n        Log.error(\"{{url}} must have a prototcol (eg http://) declared\", url=url)\n\n    base = URL(\"\")\n    if url.startswith(\"file://\") and url[7] != \"/\":\n        if os.sep==\"\\\\\":\n            base = URL(\"file:///\" + os.getcwd().replace(os.sep, \"/\").rstrip(\"/\") + \"/.\")\n        else:\n            base = URL(\"file://\" + os.getcwd().rstrip(\"/\") + \"/.\")\n    elif url[url.find(\"://\") + 3] != \"/\":\n        Log.error(\"{{url}} must be absolute\", url=url)\n\n    phase1 = _replace_ref(wrap({\"$ref\": url}), base)  # BLANK URL ONLY WORKS IF url IS ABSOLUTE\n    try:\n        phase2 = _replace_locals(phase1, [phase1])\n        return wrap(phase2)\n    except Exception as e:\n        Log.error(\"problem replacing locals in\\n{{phase1}}\", phase1=phase1, cause=e)", "response": "Get a new object from a URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn THE EXPANDED JSON - SERIALIZABLE STRUCTURE FROM doc_url", "response": "def expand(doc, doc_url=\"param://\", params=None):\n    \"\"\"\n    ASSUMING YOU ALREADY PULED THE doc FROM doc_url, YOU CAN STILL USE THE\n    EXPANDING FEATURE\n\n    USE mo_json_config.expand({}) TO ASSUME CURRENT WORKING DIRECTORY\n\n    :param doc: THE DATA STRUCTURE FROM JSON SOURCE\n    :param doc_url: THE URL THIS doc CAME FROM (DEFAULT USES params AS A DOCUMENT SOURCE)\n    :param params: EXTRA PARAMETERS NOT FOUND IN THE doc_url PARAMETERS (WILL SUPERSEDE PARAMETERS FROM doc_url)\n    :return: EXPANDED JSON-SERIALIZABLE STRUCTURE\n    \"\"\"\n    if doc_url.find(\"://\") == -1:\n        Log.error(\"{{url}} must have a prototcol (eg http://) declared\", url=doc_url)\n\n    url = URL(doc_url)\n    url.query = set_default(url.query, params)\n    phase1 = _replace_ref(doc, url)  # BLANK URL ONLY WORKS IF url IS ABSOLUTE\n    phase2 = _replace_locals(phase1, [phase1])\n    return wrap(phase2)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the source file and returns a file - like object with the size of the file.", "response": "def safe_size(source):\n    \"\"\"\n    READ THE source UP TO SOME LIMIT, THEN COPY TO A FILE IF TOO BIG\n    RETURN A str() OR A FileString()\n    \"\"\"\n\n    if source is None:\n        return None\n\n    total_bytes = 0\n    bytes = []\n    b = source.read(MIN_READ_SIZE)\n    while b:\n        total_bytes += len(b)\n        bytes.append(b)\n        if total_bytes > MAX_STRING_SIZE:\n            try:\n                data = FileString(TemporaryFile())\n                for bb in bytes:\n                    data.write(bb)\n                del bytes\n                del bb\n                b = source.read(MIN_READ_SIZE)\n                while b:\n                    total_bytes += len(b)\n                    data.write(b)\n                    b = source.read(MIN_READ_SIZE)\n                data.seek(0)\n                Log.note(\"Using file of size {{length}} instead of str()\",  length= total_bytes)\n\n                return data\n            except Exception as e:\n                Log.error(\"Could not write file > {{num}} bytes\",  num= total_bytes, cause=e)\n        b = source.read(MIN_READ_SIZE)\n\n    data = b\"\".join(bytes)\n    del bytes\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nyield a sequence of bytes from a compressed byte - string.", "response": "def compressed_bytes2ibytes(compressed, size):\n    \"\"\"\n    CONVERT AN ARRAY OF BYTES TO A BYTE-BLOCK GENERATOR\n    USEFUL IN THE CASE WHEN WE WANT TO LIMIT HOW MUCH WE FEED ANOTHER\n    GENERATOR (LIKE A DECOMPRESSOR)\n    \"\"\"\n    decompressor = zlib.decompressobj(16 + zlib.MAX_WBITS)\n    for i in range(0, mo_math.ceiling(len(compressed), size), size):\n        try:\n            block = compressed[i: i + size]\n            yield decompressor.decompress(block)\n        except Exception as e:\n            Log.error(\"Not expected\", e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ibytes2ilines(generator, encoding=\"utf8\", flexible=False, closer=None):\n    decode = get_decoder(encoding=encoding, flexible=flexible)\n    _buffer = generator.next()\n    s = 0\n    e = _buffer.find(b\"\\n\")\n    while True:\n        while e == -1:\n            try:\n                next_block = generator.next()\n                _buffer = _buffer[s:] + next_block\n                s = 0\n                e = _buffer.find(b\"\\n\")\n            except StopIteration:\n                _buffer = _buffer[s:]\n                del generator\n                if closer:\n                    closer()\n                if _buffer:\n                    yield decode(_buffer)\n                return\n\n        yield decode(_buffer[s:e])\n        s = e + 1\n        e = _buffer.find(b\"\\n\", s)", "response": "A generator that yields a sequence of bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert A STREAM (with read() method) OF (ARBITRARY-SIZED) byte BLOCKS TO A LINE (CR-DELIMITED) GENERATOR", "response": "def sbytes2ilines(stream, encoding=\"utf8\", closer=None):\n    \"\"\"\n    CONVERT A STREAM (with read() method) OF (ARBITRARY-SIZED) byte BLOCKS\n    TO A LINE (CR-DELIMITED) GENERATOR\n    \"\"\"\n    def read():\n        try:\n            while True:\n                bytes_ = stream.read(4096)\n                if not bytes_:\n                    return\n                yield bytes_\n        except Exception as e:\n            Log.error(\"Problem iterating through stream\", cause=e)\n        finally:\n            try:\n                stream.close()\n            except Exception:\n                pass\n\n            if closer:\n                try:\n                    closer()\n                except Exception:\n                    pass\n\n    return ibytes2ilines(read(), encoding=encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a decoder function that returns a single object.", "response": "def get_decoder(encoding, flexible=False):\n    \"\"\"\n    RETURN FUNCTION TO PERFORM DECODE\n    :param encoding: STRING OF THE ENCODING\n    :param flexible: True IF YOU WISH TO TRY OUR BEST, AND KEEP GOING\n    :return: FUNCTION\n    \"\"\"\n    if encoding == None:\n        def no_decode(v):\n            return v\n        return no_decode\n    elif flexible:\n        def do_decode1(v):\n            return v.decode(encoding, 'ignore')\n        return do_decode1\n    else:\n        def do_decode2(v):\n            return v.decode(encoding)\n        return do_decode2"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup_app(command, conf, vars):\n    load_environment(conf.global_conf, conf.local_conf)\n    setup_schema(command, conf, vars)\n    bootstrap.bootstrap(command, conf, vars)", "response": "Place any commands to setup tg2raptorized here"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a vocation filter from a vocation s name.", "response": "def from_name(cls, name, all_fallback=True):\n        \"\"\"Gets a vocation filter from a vocation's name.\n\n        Parameters\n        ----------\n        name: :class:`str`\n            The name of the vocation.\n        all_fallback: :class:`bool`\n            Whether to return :py:attr:`ALL` if no match is found. Otherwise, ``None`` will be returned.\n\n        Returns\n        -------\n        VocationFilter, optional:\n            The matching vocation filter.\n        \"\"\"\n        name = name.upper()\n        for vocation in cls:  # type: VocationFilter\n            if vocation.name in name or vocation.name[:-1] in name and vocation != cls.ALL:\n                return vocation\n        if all_fallback or name.upper() == \"ALL\":\n            return cls.ALL\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef connect(*args, **kwargs):\n    global __connection, __connection_args\n    __connection_args = (args, dict(kwargs))\n    # inject our class_router\n    kwargs['class_router'] = class_router\n    __connection = Connection(*args, **kwargs)\n    return __connection", "response": "Connect to the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef new(cls, *args, **kwargs):\n        new = cls(make_default(getattr(cls, 'spec', {})))\n        new.update(args[0] if args and not kwargs else kwargs)\n        return new", "response": "Create a new instance of this model based on its spec either by either holding a map or the provided kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_one(cls, *args, **kwargs):\n        database, collection = cls._collection_key.split('.')\n        return current()[database][collection].find_one(*args, **kwargs)", "response": "Run a find_one on this model s collection."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave this object to the database.", "response": "def save(self):\n        \"\"\"Save this object to the database.  Behaves very similarly to\n        whatever collection.save(document) would, ie. does upserts on _id\n        presence.  If methods ``pre_save`` or ``post_save`` are defined, those\n        are called.  If there is a spec document, then the document is\n        validated against it after the ``pre_save`` hook but before the save.\"\"\"\n        if hasattr(self, 'pre_save'):\n            self.pre_save()\n        database, collection = self._collection_key.split('.')\n        self.validate()\n        _id = current()[database][collection].save(dict(self))\n        if _id: self._id = _id\n        if hasattr(self, 'post_save'):\n            self.post_save()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write(self, msg):\n\n        self.app.events.before_response(self, msg)\n        for bp in self.app.blueprints:\n            bp.events.before_app_response(self, msg)\n\n        try:\n            self.child_output.put_nowait(msg)\n            result = True\n        except:\n            logger.error('exc occur. msg: %r', msg, exc_info=True)\n            result = False\n\n        for bp in self.app.blueprints:\n            bp.events.after_app_response(self, msg, result)\n        self.app.events.after_response(self, msg, result)\n\n        return result", "response": "Write a message to the child_output queue."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nenhance the query restricting not permitted collections.", "response": "def apply(query, collection=None):\n    \"\"\"Enhance the query restricting not permitted collections.\n\n    Get the permitted restricted collection for the current user from the\n    user_info object and all the restriced collections from the\n    restricted_collection_cache.\n    \"\"\"\n    if not collection:\n        return query\n    result_tree = create_collection_query(collection)\n    return AndOp(query, result_tree)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving the first item of the args list", "response": "def __remove_args_first_item(self):\n        \"\"\"\n        # Todo: finding a better solution\n        This is a dirty solution\n        Because the first argument of inspectors' args will be itself\n        For current implementation, it should be ignore\n        \"\"\"\n        if len(self.args) > 0:\n            new_args_list = []\n            for item in self.args:\n                if len(item) > 0 and self.obj == item[0].__class__:\n                    new_args_list.append(item[1:])\n                else:\n                    new_args_list.append(item[:])\n            self.__set_args_list(new_args_list)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the SpyCall object for this Spy", "response": "def lastCall(self): #pylint: disable=invalid-name\n        \"\"\"\n        Return: SpyCall object for this spy's most recent call\n        \"\"\"\n        last_index = len(super(SinonSpy, self)._get_wrapper().call_list) - 1\n        return self.getCall(last_index)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if this spy was called before the given spy", "response": "def calledBefore(self, spy): #pylint: disable=invalid-name\n        \"\"\"\n        Compares the order in which two spies were called\n\n        E.g.\n            spy_a()\n            spy_b()\n            spy_a.calledBefore(spy_b) # True\n            spy_b.calledBefore(spy_a) # False\n            spy_a()\n            spy_b.calledBefore(spy_a) # True\n\n        Args: a Spy to compare with\n        Return: Boolean True if this spy's first call was called before the given spy's last call\n        \"\"\"\n        this_call = self.firstCall if self.firstCall is not None else False\n        given_call = spy.lastCall if spy.lastCall is not None else False\n        return (this_call and not given_call) or (this_call and given_call and this_call.callId < given_call.callId)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the current object was called with the given args and kwargs.", "response": "def calledWith(self, *args, **kwargs): #pylint: disable=invalid-name\n        \"\"\"\n        Determining whether args/kwargs are called previously\n        Eg.\n            f(1, 2, 3)\n            spy.calledWith(1, 2) will return True, because they are called partially\n            f(a=1, b=2, c=3)\n            spy.calledWith(a=1, b=3) will return True, because they are called partially\n        Return: Boolean\n        \"\"\"\n        self.__get_func = SinonSpy.__get_directly\n        return self.calledWithMatch(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef alwaysCalledWith(self, *args, **kwargs): #pylint: disable=invalid-name\n        self.__get_func = SinonSpy.__get_directly\n        return self.alwaysCalledWithMatch(*args, **kwargs)", "response": "Returns True if the caller has always called the previously called object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef calledWithExactly(self, *args, **kwargs): #pylint: disable=invalid-name\n        self.__remove_args_first_item()\n        if args and kwargs:\n            return True if (uch.tuple_in_list(self.args, args) and\n                            uch.dict_in_list(self.kwargs, kwargs)) else False\n        elif args:\n            return True if uch.tuple_in_list(self.args, args) else False\n        elif kwargs:\n            return True if uch.dict_in_list(self.kwargs, kwargs) else False\n        else:\n            ErrorHandler.called_with_empty_error()", "response": "Returns True if the function called with the same arguments and keyword arguments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef alwaysCalledWithExactly(self, *args, **kwargs): #pylint: disable=invalid-name\n        self.__remove_args_first_item()\n        if args and kwargs:\n            return True if (uch.tuple_in_list_always(self.args, args) and\n                            uch.dict_in_list_always(self.kwargs, kwargs)) else False\n        elif args:\n            return True if uch.tuple_in_list_always(self.args, args) else False\n        elif kwargs:\n            return True if uch.dict_in_list_always(self.kwargs, kwargs) else False\n        else:\n            ErrorHandler.called_with_empty_error()", "response": "Returns True if the user has called the method with the given args and kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calledWithMatch(self, *args, **kwargs): #pylint: disable=invalid-name\n        self.__remove_args_first_item()\n        if args and kwargs:\n            return (uch.tuple_partial_cmp(args, self.args, self.__get_func) and\n                    uch.dict_partial_cmp(kwargs, self.kwargs, self.__get_func))\n        elif args:\n            return uch.tuple_partial_cmp(args, self.args, self.__get_func)\n        elif kwargs:\n            return uch.dict_partial_cmp(kwargs, self.kwargs, self.__get_func)\n        else:\n            ErrorHandler.called_with_empty_error()\n        self.__get_func = SinonSpy.__get_by_matcher", "response": "Returns True if the passed in arguments and kwargs are matched in the order they were called."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the SinonMatcher was called with the given args and kwargs.", "response": "def alwaysCalledWithMatch(self, *args, **kwargs): #pylint: disable=invalid-name\n        \"\"\"\n        Determining whether args/kwargs are the ONLY matched args/kwargs called previously\n        Handle each arg/kwarg as a SinonMatcher\n        Return: Boolean\n        \"\"\"\n        self.__remove_args_first_item()\n        alist, klist, gfunc = self.args, self.kwargs, self.__get_func\n        if args and kwargs:\n            return (uch.tuple_partial_cmp_always(args, alist, gfunc) and\n                    uch.dict_partial_cmp_always(kwargs, klist, gfunc))\n        elif args:\n            return uch.tuple_partial_cmp_always(args, alist, gfunc)\n        elif kwargs:\n            return uch.dict_partial_cmp_always(kwargs, klist, gfunc)\n        else:\n            ErrorHandler.called_with_empty_error()\n        self.__get_func = SinonSpy.__get_by_matcher"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef threw(self, error_type=None):\n        if not error_type:\n            return True if len(self.exceptions) > 0 else False\n        else:\n            return uch.obj_in_list(self.exceptions, error_type)", "response": "Determines whether the exception is thrown by the user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef alwaysThrew(self, error_type=None): #pylint: disable=invalid-name\n        if self.callCount == 0:\n            return False\n        if not error_type:\n            return True if len(self.exceptions) == self.callCount else False\n        else:\n            return uch.obj_in_list_always(self.exceptions, error_type)", "response": "Determines whether the specified exception is the ONLY thrown exception."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreset the wrapped function to the original version of the current version.", "response": "def reset(self):\n        \"\"\"\n        Reseting wrapped function\n        \"\"\"\n        super(SinonSpy, self).unwrap()\n        super(SinonSpy, self).wrap2spy()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the SpyCall object for the n - th function call.", "response": "def getCall(self, n): #pylint: disable=invalid-name\n        \"\"\"\n        Args:\n            n: integer (index of function call)\n        Return:\n            SpyCall object (or None if the index is not valid)\n        \"\"\"\n        call_list = super(SinonSpy, self)._get_wrapper().call_list\n        if n >= 0 and n < len(call_list):\n            call = call_list[n]\n            call.proxy = weakref.proxy(self)\n            return call\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef b64decode(foo, *args):\n    'Only here for consistency with the above.'\n    if isinstance(foo, str):\n        foo = foo.encode('utf8')\n    return base64.b64decode(foo, *args)", "response": "Only here for consistency with the above."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assert_type_and_length(varname, var, T, L = None, minL = None, maxL = None):\n    'Facilitates simultaneous or one-line type/length checks.'\n    if not isinstance(var, T):\n        raise TypeError(\"Variable '{}' is supposed to be type '{}' but is '{}'\".format(varname, T, type(var)))\n    if isinstance(L, int):\n        if not L == len(var):\n            raise ValueError(\"Variable '{}' is supposed to be length {} but is {}\".format(varname, L, len(var)))\n    if isinstance(maxL, int):\n        if maxL < len(var):\n            raise ValueError(\"Variable '{}' is supposed to be smaller than {} but is length {}\".format(varname, maxL, len(var)))\n    if isinstance(minL, int):\n        if minL > len(var):\n            raise ValueError(\"Variable '{}' is supposed to be larger than {} but is length {}\".format(varname, minL, len(var)))", "response": "Facilitates simultaneous or one - line type / length checks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new ephemeral key constructed from a raw 32 - byte string from urandom.", "response": "def ephemeral(cls):\n        \"\"\"\n        Creates a new ephemeral key constructed using a raw 32-byte string from urandom.\n        Ephemeral keys are used once for each encryption task and are then discarded;\n        they are not intended for long-term or repeat use.\n        \"\"\"\n        private_key = nacl.public.PrivateKey(os.urandom(32))\n        return cls(private_key.public_key, private_key)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new key with a chosen prefix.", "response": "def fancy(cls, contains, max_tries, inner=False, keepcase=False):\n        \"\"\"\n        Try to create a key with a chosen prefix, by starting with a 26-bit\n        urandom number and appending with 8-byte integers until prefix matches.\n        This function is naive, but has a max_tries argument which will abort when\n        reached with a ValueError.\n        TODO: make this smarter, in general. Variable byte length according to\n        expected attempts, warnings of expected duration of iteration, etc. \n        TODO: Implement multiprocessing to use poly-core machines fully:\n            - Shared list, each process checks if empty every cycle, aborts if\n              contains a value.\n            - Successful values are pushed to list, cancelling all processes?\n            - Server waits on all child processes then expects a list?\n            - Ensure child processes start with different random base numbers,\n              to avoid duplication?\n            - Investigate server/manager aspect of multiprocessing; mini-clustering?\n        \"\"\"\n        contains = contains if keepcase else contains.lower()\n        if not set(contains).issubset(base58.alphabet):\n            raise ValueError(\"Cannot find contained phrase '{}' as it contains non-b58 characters\".format(contains))\n        basenum = os.urandom(26)\n        for i in range(max_tries):\n            k = nacl.public.PrivateKey(basenum + i.to_bytes(6, 'big'))\n            ukey = cls(k.public_key, k)\n            test_uid = ukey.userID if keepcase else ukey.userID.lower()\n            if test_uid.startswith(contains) or test_uid.endswith(contains) or (inner and contains in test_uid):\n                return ukey\n        else:\n            raise ValueError(\"Could not create key with desired prefix '{}' in {} attempts.\".format(prefix, max_tries))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding successive chunks from array.", "response": "def pieces(array, chunk_size):\n        \"\"\"Yield successive chunks from array/list/string.\n        Final chunk may be truncated if array is not evenly divisible by chunk_size.\"\"\"\n        for i in range(0, len(array), chunk_size): yield array[i:i+chunk_size]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprovide a streaming interface to file data in chunks of even size, which avoids memoryerrors from loading whole files into RAM to pass to `pieces`.", "response": "def piece_file(input_f, chunk_size):\n        \"\"\"\n        Provides a streaming interface to file data in chunks of even size, which\n        avoids memoryerrors from loading whole files into RAM to pass to `pieces`.\n        \"\"\"\n        chunk = input_f.read(chunk_size)\n        total_bytes = 0\n        while chunk:\n            yield chunk\n            chunk = input_f.read(chunk_size)\n            total_bytes += len(chunk)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconstruct a new MiniLockHeader object.", "response": "def new(cls, file_info, sender, recipients, version=1):\n        \"\"\"\n        Constructs (encrypts) a new MiniLockHeader object.\n        file_info: dict, with 'fileKey', 'fileNonce', 'fileHash' as bytes entries\n        sender: UserLock for sender\n        recipients: list of UserLock for recipients\n        \"\"\"\n        ephem_key = UserLock.ephemeral()\n        decryptInfo = {}\n        for recipient in recipients:\n            if isinstance(recipient, str):\n                recipient = UserLock.from_id(recipient)\n            if not isinstance(recipient, UserLock):\n                raise TypeError(\"Recipient must be either a UserLock object or a User ID as a string.\")\n            # This is the sender->recipient box for the inner fileinfo.\n            sending_box = nacl.public.Box(sender.private_key, recipient.public_key)\n            sending_nonce = os.urandom(24)\n            sending_nonce_b64 = b64encode(sending_nonce)\n            # Encrypt the fileinfo sender->recipient, then create an entry for this\n            # recipient with senderID/recipientID.\n            dumped_fileInfo = json.dumps(file_info, separators=(',',':')).encode('utf8')\n            crypted_fileInfo = sending_box.encrypt(dumped_fileInfo, sending_nonce)[24:]\n            di_entry = json.dumps({\n                'fileInfo'    : b64encode(crypted_fileInfo),\n                'senderID'    : sender.userID,\n                'recipientID' : recipient.userID\n            }).encode('utf8')\n            # This is the ephem->recipient box, which obfuscates the sender.\n            ephem_sending_box = nacl.public.Box(ephem_key.private_key, recipient.public_key)\n            crypted_di_entry = ephem_sending_box.encrypt(di_entry, sending_nonce)[24:]\n            decryptInfo[sending_nonce_b64] = b64encode(crypted_di_entry)\n        # Now have a decryptInfo dictionary full of entries for each recipient.\n        return cls({\n            'version': version,\n            'ephemeral': ephem_key.b64str,  # Should be ephem_key.userID, for consistency! Support both?\n            'decryptInfo': decryptInfo\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nattempts to decrypt a header with a private key ; returns decryptInfo.", "response": "def decrypt(self, recipient_key):\n        \"\"\"\n        Attempt decryption of header with a private key; returns decryptInfo.\n        Returns a dictionary, not a new MiniLockHeader!\n        \"\"\"\n        ephem = UserLock.from_b64(self.dict['ephemeral'])\n        ephem_box = nacl.public.Box(recipient_key.private_key, ephem.public_key)\n        # Scan available entries in decryptInfo and try to decrypt each; break when\n        # successful with any.\n        for nonce, crypted_decryptInfo in self.dict['decryptInfo'].items():\n            raw_nonce = b64decode(nonce)\n            crypted_decryptInfo = b64decode(crypted_decryptInfo)\n            try:\n                decryptInfo_raw = ephem_box.decrypt(crypted_decryptInfo, raw_nonce)\n                decryptInfo = json.loads(decryptInfo_raw.decode('utf8'))\n                success_nonce = raw_nonce\n                break\n            except Exception as E:\n                #print(\"Decoding exception: '{}' - with ciphertext '{}'\".format(E, crypted_decryptInfo))\n                pass\n        else:\n            raise ValueError(\"No decryptInfo block found for this recipient Key.\")\n        if not recipient_key.userID == decryptInfo['recipientID']:\n            raise ValueError(\"Decrypted a meta block but stated recipient is not this private key!\")\n        # Now work with decryptInfo and success_nonce to extract file data.\n        senderKey = UserLock.from_id(decryptInfo['senderID'])\n        senderBox = nacl.public.Box(recipient_key.private_key, senderKey.public_key)\n        fileInfo_raw = b64decode(decryptInfo['fileInfo'])\n        fileInfo_decrypted = senderBox.decrypt(fileInfo_raw, success_nonce).decode('utf8')\n        fileInfo = json.loads(fileInfo_decrypted)\n        # Overwrite decryptInfo's fileInfo key\n        decryptInfo['fileInfo'] = fileInfo\n        return decryptInfo"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new(cls, file_name, file_or_contents, sender, recipients):\n        assert_type_and_length('recipients', recipients, list, minL=1)\n        assert_type_and_length('sender', sender, UserLock)\n        for R in recipients:\n            assert_type_and_length('recipient', R, (str, UserLock))   \n        recipients = list(set(recipients))\n        # Encrypt file with secret key using file_contents and file_name\n        file_key   = os.urandom(32)\n        file_nonce = os.urandom(16)\n        file_cipher = SymmetricMiniLock.from_key(file_key)\n        ciphertext = b''.join(file_cipher.encrypt(file_or_contents, file_name, file_nonce))\n        file_info = {\n            'fileKey'   : b64encode(file_key),\n            'fileNonce' : b64encode(file_nonce),\n            'fileHash'  : b64encode(pyblake2.blake2s(ciphertext).digest())\n        }\n        header = MiniLockHeader.new(file_info, sender, recipients)\n        b_header = header.to_bytes()\n        encrypted_file = b'miniLock' + len(b_header).to_bytes(4, 'little') + b_header + ciphertext\n        return cls(encrypted_file)", "response": "Constructs a new miniLock file from file_name file_contents sender and list of recipients."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\niterates over the chunks of the file according to their length prefixes.", "response": "def iter_chunks(self, start_count=0):\n        \"\"\"\n        Iterate over the chunks of the file according to their length prefixes.\n        yields: index <int>, encrypted chunks without length prefixes <bytes>, lastchunk <bool>\n        \"\"\"\n        ciphertext = self.chunks_block\n        chunknum = start_count\n        idx = 0\n        lastchunk = False\n        while idx < len(ciphertext):\n            plainlen = int.from_bytes(ciphertext[idx: idx+4], 'little')\n            chunklen = plainlen + 16\n            if idx + 4 + chunklen == len(ciphertext):\n                lastchunk = True\n            elif idx + chunklen > len(ciphertext):\n                raise ValueError(\"Bad ciphertext; when reading chunks, hit EOF early\")\n            yield chunknum, ciphertext[idx + 4 : idx + 4 + chunklen], lastchunk\n            idx += chunklen + 4\n            chunknum += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a JSON representation of the object.", "response": "def to_json(self):\n        \"\"\"\n        Returns:\n            str:\n        \"\"\"\n        data = dict()\n\n        for key, value in self.__dict__.items():\n            if value:\n                if hasattr(value, 'to_dict'):\n                    data[key] = value.to_dict()\n                elif isinstance(value, datetime):\n                    data[key] = value.strftime('%Y-%m-%d %H:%M:%S')\n                else:\n                    data[key] = value\n\n        return json.dumps(data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_dict(self):\n        data = dict()\n\n        for key, value in self.__dict__.items():\n            if value:\n                if hasattr(value, 'to_dict'):\n                    data[key] = value.to_dict()\n                else:\n                    data[key] = value\n\n        return data", "response": "Returns a dictionary representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(query, container=Null):\n    if container == None:\n        container = wrap(query)[\"from\"]\n        query_op = QueryOp.wrap(query, container=container, namespace=container.schema)\n    else:\n        query_op = QueryOp.wrap(query, container, container.namespace)\n\n    if container == None:\n        from jx_python.containers.list_usingPythonList import DUAL\n\n        return DUAL.query(query_op)\n    elif isinstance(container, Container):\n        return container.query(query_op)\n    elif is_many(container):\n        container = wrap(list(container))\n    elif isinstance(container, Cube):\n        if is_aggs(query_op):\n            return cube_aggs(container, query_op)\n    elif is_op(container, QueryOp):\n        container = run(container)\n    elif is_data(container):\n        query = container\n        container = query[\"from\"]\n        container = run(QueryOp.wrap(query, container, container.namespace), container)\n    else:\n        Log.error(\n            \"Do not know how to handle {{type}}\", type=container.__class__.__name__\n        )\n\n    if is_aggs(query_op):\n        container = list_aggs(container, query_op)\n    else:  # SETOP\n        if query_op.where is not TRUE:\n            container = filter(container, query_op.where)\n\n        if query_op.sort:\n            container = sort(container, query_op.sort, already_normalized=True)\n\n        if query_op.select:\n            container = select(container, query_op.select)\n\n    if query_op.window:\n        if isinstance(container, Cube):\n            container = list(container.values())\n\n        for param in query_op.window:\n            window(container, param)\n\n    # AT THIS POINT frum IS IN LIST FORMAT, NOW PACKAGE RESULT\n    if query_op.format == \"cube\":\n        container = convert.list2cube(container)\n    elif query_op.format == \"table\":\n        container = convert.list2table(container)\n        container.meta.format = \"table\"\n    else:\n        container = wrap({\"meta\": {\"format\": \"list\"}, \"data\": container})\n\n    return container", "response": "This function runs a query on a list container."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dict that represents unique items in the data.", "response": "def unique_index(data, keys=None, fail_on_dup=True):\n    \"\"\"\n    RETURN dict THAT USES KEYS TO INDEX DATA\n    ONLY ONE VALUE ALLOWED PER UNIQUE KEY\n    \"\"\"\n    o = UniqueIndex(listwrap(keys), fail_on_dup=fail_on_dup)\n\n    for d in data:\n        try:\n            o.add(d)\n        except Exception as e:\n            o.add(d)\n            Log.error(\n                \"index {{index}} is not unique {{key}} maps to both {{value1}} and {{value2}}\",\n                index=keys,\n                key=select([d], keys)[0],\n                value1=o[d],\n                value2=d,\n                cause=e,\n            )\n    return o"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef map2set(data, relation):\n    if data == None:\n        return Null\n    if isinstance(relation, Data):\n        Log.error(\"Does not accept a Data\")\n\n    if is_data(relation):\n        try:\n            # relation[d] is expected to be a list\n            # return set(cod for d in data for cod in relation[d])\n            output = set()\n            for d in data:\n                for cod in relation.get(d, []):\n                    output.add(cod)\n            return output\n        except Exception as e:\n            Log.error(\"Expecting a dict with lists in codomain\", e)\n    else:\n        try:\n            # relation[d] is expected to be a list\n            # return set(cod for d in data for cod in relation[d])\n            output = set()\n            for d in data:\n                cod = relation(d)\n                if cod == None:\n                    continue\n                output.add(cod)\n            return output\n        except Exception as e:\n            Log.error(\"Expecting a dict with lists in codomain\", e)\n    return Null", "response": "This function takes a dict of data and a relation and returns a set of all the items in the list that are in the relation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tuple(data, field_name):\n    if isinstance(data, Cube):\n        Log.error(\"not supported yet\")\n\n    if isinstance(data, FlatList):\n        Log.error(\"not supported yet\")\n\n    if is_data(field_name) and \"value\" in field_name:\n        # SIMPLIFY {\"value\":value} AS STRING\n        field_name = field_name[\"value\"]\n\n    # SIMPLE PYTHON ITERABLE ASSUMED\n    if is_text(field_name):\n        if len(split_field(field_name)) == 1:\n            return [(d[field_name],) for d in data]\n        else:\n            path = split_field(field_name)\n            output = []\n            flat_list._tuple1(data, path, 0, output)\n            return output\n    elif is_list(field_name):\n        paths = [_select_a_field(f) for f in field_name]\n        output = FlatList()\n        _tuple((), unwrap(data), paths, 0, output)\n        return output\n    else:\n        paths = [_select_a_field(field_name)]\n        output = FlatList()\n        _tuple((), data, paths, 0, output)\n        return output", "response": "RETURN LIST OF TUPLES"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfield = {\"name\":name, \"value\":[\"attribute\", \"path\"]} r[field.name]=v[field.value], BUT WE MUST DEAL WITH POSSIBLE LIST IN field.value PATH", "response": "def _tuple_deep(v, field, depth, record):\n    \"\"\"\n    field = {\"name\":name, \"value\":[\"attribute\", \"path\"]}\n    r[field.name]=v[field.value], BUT WE MUST DEAL WITH POSSIBLE LIST IN field.value PATH\n    \"\"\"\n    if hasattr(field.value, \"__call__\"):\n        return 0, None, record + (field.value(v),)\n\n    for i, f in enumerate(field.value[depth : len(field.value) - 1 :]):\n        v = v.get(f)\n        if is_list(v):\n            return depth + i + 1, v, record\n\n    f = field.value.last()\n    return 0, None, record + (v.get(f),)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select(data, field_name):\n    if isinstance(data, Cube):\n        return data._select(_normalize_selects(field_name))\n\n    if isinstance(data, PartFlatList):\n        return data.select(field_name)\n\n    if isinstance(data, UniqueIndex):\n        data = (\n            data._data.values()\n        )  # THE SELECT ROUTINE REQUIRES dicts, NOT Data WHILE ITERATING\n\n    if is_data(data):\n        return select_one(data, field_name)\n\n    if is_data(field_name):\n        field_name = wrap(field_name)\n        if field_name.value in [\"*\", \".\"]:\n            return data\n\n        if field_name.value:\n            # SIMPLIFY {\"value\":value} AS STRING\n            field_name = field_name.value\n\n    # SIMPLE PYTHON ITERABLE ASSUMED\n    if is_text(field_name):\n        path = split_field(field_name)\n        if len(path) == 1:\n            return FlatList([d[field_name] for d in data])\n        else:\n            output = FlatList()\n            flat_list._select1(data, path, 0, output)\n            return output\n    elif is_list(field_name):\n        keys = [_select_a_field(wrap(f)) for f in field_name]\n        return _select(Data(), unwrap(data), keys, 0)\n    else:\n        keys = [_select_a_field(field_name)]\n        return _select(Data(), unwrap(data), keys, 0)", "response": "Select the value of a field in a nested list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _select_deep(v, field, depth, record):\n    if hasattr(field.value, \"__call__\"):\n        try:\n            record[field.name] = field.value(wrap(v))\n        except Exception as e:\n            record[field.name] = None\n        return 0, None\n\n    for i, f in enumerate(field.value[depth : len(field.value) - 1 :]):\n        v = v.get(f)\n        if v is None:\n            return 0, None\n        if is_list(v):\n            return depth + i + 1, v\n\n    f = field.value.last()\n    try:\n        if not f:  # NO NAME FIELD INDICATES SELECT VALUE\n            record[field.name] = v\n        else:\n            record[field.name] = v.get(f)\n    except Exception as e:\n        Log.error(\n            \"{{value}} does not have {{field}} property\", value=v, field=f, cause=e\n        )\n    return 0, None", "response": "Select the next deep list of entries in the record."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _select_deep_meta(field, depth):\n    name = field.name\n    if hasattr(field.value, \"__call__\"):\n        try:\n\n            def assign(source, destination):\n                destination[name] = field.value(wrap(source))\n                return 0, None\n\n            return assign\n        except Exception as e:\n\n            def assign(source, destination):\n                destination[name] = None\n                return 0, None\n\n            return assign\n\n    prefix = field.value[depth : len(field.value) - 1 :]\n    if prefix:\n\n        def assign(source, destination):\n            for i, f in enumerate(prefix):\n                source = source.get(f)\n                if source is None:\n                    return 0, None\n                if is_list(source):\n                    return depth + i + 1, source\n\n            f = field.value.last()\n            try:\n                if not f:  # NO NAME FIELD INDICATES SELECT VALUE\n                    destination[name] = source\n                else:\n                    destination[name] = source.get(f)\n            except Exception as e:\n                Log.error(\n                    \"{{value}} does not have {{field}} property\",\n                    value=source,\n                    field=f,\n                    cause=e,\n                )\n            return 0, None\n\n        return assign\n    else:\n        f = field.value[0]\n        if not f:  # NO NAME FIELD INDICATES SELECT VALUE\n\n            def assign(source, destination):\n                destination[name] = source\n                return 0, None\n\n            return assign\n        else:\n\n            def assign(source, destination):\n                try:\n                    destination[name] = source.get(f)\n                except Exception as e:\n                    Log.error(\n                        \"{{value}} does not have {{field}} property\",\n                        value=source,\n                        field=f,\n                        cause=e,\n                    )\n                return 0, None\n\n            return assign", "response": "Select the deep meta data for a single field."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsorting the data list by the given fieldnames.", "response": "def sort(data, fieldnames=None, already_normalized=False):\n    \"\"\"\n    PASS A FIELD NAME, OR LIST OF FIELD NAMES, OR LIST OF STRUCTS WITH {\"field\":field_name, \"sort\":direction}\n    \"\"\"\n    try:\n        if data == None:\n            return Null\n\n        if not fieldnames:\n            return wrap(sort_using_cmp(data, value_compare))\n\n        if already_normalized:\n            formal = fieldnames\n        else:\n            formal = query._normalize_sort(fieldnames)\n\n        funcs = [(jx_expression_to_function(f.value), f.sort) for f in formal]\n\n        def comparer(left, right):\n            for func, sort_ in funcs:\n                try:\n                    result = value_compare(func(left), func(right), sort_)\n                    if result != 0:\n                        return result\n                except Exception as e:\n                    Log.error(\"problem with compare\", e)\n            return 0\n\n        if is_list(data):\n            output = FlatList([unwrap(d) for d in sort_using_cmp(data, cmp=comparer)])\n        elif hasattr(data, \"__iter__\"):\n            output = FlatList(\n                [unwrap(d) for d in sort_using_cmp(list(data), cmp=comparer)]\n            )\n        else:\n            Log.error(\"Do not know how to handle\")\n            output = None\n\n        return output\n    except Exception as e:\n        Log.error(\"Problem sorting\\n{{data}}\", data=data, cause=e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfilters the data by a function that accepts record rownum rows and returns boolean", "response": "def filter(data, where):\n    \"\"\"\n    where  - a function that accepts (record, rownum, rows) and returns boolean\n    \"\"\"\n    if len(data) == 0 or where == None or where == TRUE:\n        return data\n\n    if isinstance(data, Container):\n        return data.filter(where)\n\n    if is_container(data):\n        temp = jx_expression_to_function(where)\n        dd = wrap(data)\n        return wrap([unwrap(d) for i, d in enumerate(data) if temp(wrap(d), i, dd)])\n    else:\n        Log.error(\n            \"Do not know how to handle type {{type}}\", type=data.__class__.__name__\n        )\n\n    try:\n        return drill_filter(where, data)\n    except Exception as _:\n        # WOW!  THIS IS INEFFICIENT!\n        return wrap(\n            [unwrap(d) for d in drill_filter(where, [DataObject(d) for d in data])]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wrap_function(func):\n    if is_text(func):\n        return compile_expression(func)\n\n    numarg = func.__code__.co_argcount\n    if numarg == 0:\n\n        def temp(row, rownum, rows):\n            return func()\n\n        return temp\n    elif numarg == 1:\n\n        def temp(row, rownum, rows):\n            return func(row)\n\n        return temp\n    elif numarg == 2:\n\n        def temp(row, rownum, rows):\n            return func(row, rownum)\n\n        return temp\n    elif numarg == 3:\n        return func", "response": "A function that wraps a single function in a single one."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef intervals(_min, _max=None, size=1):\n    if _max == None:\n        _max = _min\n        _min = 0\n    _max = int(mo_math.ceiling(_max))\n    _min = int(mo_math.floor(_min))\n\n    output = ((x, min(x + size, _max)) for x in _range(_min, _max, size))\n    return output", "response": "RETURN a list of intervals"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_context_hints_per_source(context_renderers):\n    # Merge the context render hints for each source as there can be multiple context hints for\n    # sources depending on the render target. Merging them together involves combining select\n    # and prefetch related hints for each context renderer\n    context_hints_per_source = defaultdict(lambda: defaultdict(lambda: {\n        'app_name': None,\n        'model_name': None,\n        'select_related': set(),\n        'prefetch_related': set(),\n    }))\n    for cr in context_renderers:\n        for key, hints in cr.context_hints.items() if cr.context_hints else []:\n            for source in cr.get_sources():\n                context_hints_per_source[source][key]['app_name'] = hints['app_name']\n                context_hints_per_source[source][key]['model_name'] = hints['model_name']\n                context_hints_per_source[source][key]['select_related'].update(hints.get('select_related', []))\n                context_hints_per_source[source][key]['prefetch_related'].update(hints.get('prefetch_related', []))\n\n    return context_hints_per_source", "response": "Given a list of context renderers return a dictionary of context hints per source."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a list of context hints dictionaries return a dictionary that contains a list of querysets for efficient context loading.", "response": "def get_querysets_for_context_hints(context_hints_per_source):\n    \"\"\"\n    Given a list of context hint dictionaries, return a dictionary\n    of querysets for efficient context loading. The return value\n    is structured as follows:\n\n    {\n        model: queryset,\n        ...\n    }\n    \"\"\"\n    model_select_relateds = defaultdict(set)\n    model_prefetch_relateds = defaultdict(set)\n    model_querysets = {}\n    for context_hints in context_hints_per_source.values():\n        for hints in context_hints.values():\n            model = get_model(hints['app_name'], hints['model_name'])\n            model_querysets[model] = model.objects\n            model_select_relateds[model].update(hints.get('select_related', []))\n            model_prefetch_relateds[model].update(hints.get('prefetch_related', []))\n\n    # Attach select and prefetch related parameters to the querysets if needed\n    for model, queryset in model_querysets.items():\n        if model_select_relateds[model]:\n            queryset = queryset.select_related(*model_select_relateds[model])\n        if model_prefetch_relateds[model]:\n            queryset = queryset.prefetch_related(*model_prefetch_relateds[model])\n        model_querysets[model] = queryset\n\n    return model_querysets"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dict_find(d, which_key):\n    # If the starting point is a list, iterate recursively over all values\n    if isinstance(d, (list, tuple)):\n        for i in d:\n            for result in dict_find(i, which_key):\n                yield result\n\n    # Else, iterate over all key values of the dictionary\n    elif isinstance(d, dict):\n        for k, v in d.items():\n            if k == which_key:\n                yield d, v\n            for result in dict_find(v, which_key):\n                yield result", "response": "Finds key values in a nested dictionary. Returns a tuple of the dictionary in which\n    the key was found along with the value\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_model_ids_to_fetch(events, context_hints_per_source):\n    number_types = (complex, float) + six.integer_types\n    model_ids_to_fetch = defaultdict(set)\n\n    for event in events:\n        context_hints = context_hints_per_source.get(event.source, {})\n        for context_key, hints in context_hints.items():\n            for d, value in dict_find(event.context, context_key):\n                values = value if isinstance(value, list) else [value]\n                model_ids_to_fetch[get_model(hints['app_name'], hints['model_name'])].update(\n                    v for v in values if isinstance(v, number_types)\n                )\n\n    return model_ids_to_fetch", "response": "Gets the ids of all models that need to be fetched from the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a dictionary of models to querysets and model IDs to models fetch the IDs for every model and return the objects in the following structure.", "response": "def fetch_model_data(model_querysets, model_ids_to_fetch):\n    \"\"\"\n    Given a dictionary of models to querysets and model IDs to models, fetch the IDs\n    for every model and return the objects in the following structure.\n\n    {\n        model: {\n            id: obj,\n            ...\n        },\n        ...\n    }\n    \"\"\"\n    return {\n        model: id_dict(model_querysets[model].filter(id__in=ids_to_fetch))\n        for model, ids_to_fetch in model_ids_to_fetch.items()\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_fetched_objects_into_contexts(events, model_data, context_hints_per_source):\n    for event in events:\n        context_hints = context_hints_per_source.get(event.source, {})\n        for context_key, hints in context_hints.items():\n            model = get_model(hints['app_name'], hints['model_name'])\n            for d, value in dict_find(event.context, context_key):\n                if isinstance(value, list):\n                    for i, model_id in enumerate(d[context_key]):\n                        d[context_key][i] = model_data[model].get(model_id)\n                else:\n                    d[context_key] = model_data[model].get(value)", "response": "Given the fetched model data and the context hints for each source go through each event and populate the contexts with the loaded information."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive the events and mediums and context renderers load the renderers into the event objects", "response": "def load_renderers_into_events(events, mediums, context_renderers, default_rendering_style):\n    \"\"\"\n    Given the events and the context renderers, load the renderers into the event objects\n    so that they may be able to call the 'render' method later on.\n    \"\"\"\n    # Make a mapping of source groups and rendering styles to context renderers. Do\n    # the same for sources and rendering styles to context renderers\n    source_group_style_to_renderer = {\n        (cr.source_group_id, cr.rendering_style_id): cr\n        for cr in context_renderers if cr.source_group_id\n    }\n    source_style_to_renderer = {\n        (cr.source_id, cr.rendering_style_id): cr\n        for cr in context_renderers if cr.source_id\n    }\n\n    for e in events:\n        for m in mediums:\n            # Try the following when loading a context renderer for a medium in an event.\n            # 1. Try to look up the renderer based on the source group and medium rendering style\n            # 2. If step 1 doesn't work, look up based on the source and medium rendering style\n            # 3. If step 2 doesn't work, look up based on the source group and default rendering style\n            # 4. if step 3 doesn't work, look up based on the source and default rendering style\n            # If none of those steps work, this event will not be able to be rendered for the mediun\n            cr = source_group_style_to_renderer.get((e.source.group_id, m.rendering_style_id))\n            if not cr:\n                cr = source_style_to_renderer.get((e.source_id, m.rendering_style_id))\n            if not cr and default_rendering_style:\n                cr = source_group_style_to_renderer.get((e.source.group_id, default_rendering_style.id))\n            if not cr and default_rendering_style:\n                cr = source_style_to_renderer.get((e.source_id, default_rendering_style.id))\n\n            if cr:\n                e._context_renderers[m] = cr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a list of events and mediums load the context model data into the contexts of the events.", "response": "def load_contexts_and_renderers(events, mediums):\n    \"\"\"\n    Given a list of events and mediums, load the context model data into the contexts of the events.\n    \"\"\"\n    sources = {event.source for event in events}\n    rendering_styles = {medium.rendering_style for medium in mediums if medium.rendering_style}\n\n    # Fetch the default rendering style and add it to the set of rendering styles\n    default_rendering_style = get_default_rendering_style()\n    if default_rendering_style:\n        rendering_styles.add(default_rendering_style)\n\n    context_renderers = ContextRenderer.objects.filter(\n        Q(source__in=sources, rendering_style__in=rendering_styles) |\n        Q(source_group_id__in=[s.group_id for s in sources], rendering_style__in=rendering_styles)).select_related(\n            'source', 'rendering_style').prefetch_related('source_group__source_set')\n\n    context_hints_per_source = get_context_hints_per_source(context_renderers)\n    model_querysets = get_querysets_for_context_hints(context_hints_per_source)\n    model_ids_to_fetch = get_model_ids_to_fetch(events, context_hints_per_source)\n    model_data = fetch_model_data(model_querysets, model_ids_to_fetch)\n    load_fetched_objects_into_contexts(events, model_data, context_hints_per_source)\n    load_renderers_into_events(events, mediums, context_renderers, default_rendering_style)\n\n    return events"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_printer(colors: bool = True, width_limit: bool = True, disabled: bool = False) -> Printer:\n    global _printer\n    global _colors\n    # Make sure we can print colors if needed.\n    colors = colors and _colors\n    # If the printer was never defined before, or the settings have changed.\n    if not _printer or (colors != _printer._colors) or (width_limit != _printer._width_limit):\n        _printer = Printer(DefaultWriter(disabled=disabled), colors=colors, width_limit=width_limit)\n    return _printer", "response": "Returns an already initialized instance of the printer."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_windows_console_width() -> int:\n    from ctypes import byref, windll\n    import pyreadline\n\n    out = windll.kernel32.GetStdHandle(-11)\n    info = pyreadline.console.CONSOLE_SCREEN_BUFFER_INFO()\n    windll.kernel32.GetConsoleScreenBufferInfo(out, byref(info))\n    return info.dwSize.X", "response": "A small utility function for getting the current console window s width in Windows."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a context manager which adds an indentation before each line.", "response": "def group(self, indent: int = DEFAULT_INDENT, add_line: bool = True) -> _TextGroup:\n        \"\"\"\n        Returns a context manager which adds an indentation before each line.\n\n        :param indent: Number of spaces to print.\n        :param add_line: If True, a new line will be printed after the group.\n        :return: A TextGroup context manager.\n        \"\"\"\n        return _TextGroup(self, indent, add_line)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _split_lines(self, original_lines: List[str]) -> List[str]:\n        console_width = get_console_width()\n        # We take indent into account only in the inner group lines.\n        max_line_length = console_width - len(self.LINE_SEP) - self._last_position - \\\n            (self.indents_sum if not self._is_first_line else self.indents_sum - self._indents[-1])\n\n        lines = []\n        for i, line in enumerate(original_lines):\n            fixed_line = []\n            colors_counter = 0\n            line_index = 0\n            while line_index < len(line):\n                c = line[line_index]\n\n                # Check if we're in a color block.\n                if self._colors and c == self._ANSI_COLOR_PREFIX and \\\n                        len(line) >= (line_index + self._ANSI_COLOR_LENGTH):\n                    current_color = line[line_index:line_index + self._ANSI_COLOR_LENGTH]\n                    # If it really is a color, skip it.\n                    if self._ANSI_REGEXP.match(current_color):\n                        line_index += self._ANSI_COLOR_LENGTH\n                        fixed_line.extend(list(current_color))\n                        colors_counter += 1\n                        continue\n                fixed_line.append(line[line_index])\n                line_index += 1\n\n                # Create a new line, if max line is reached.\n                if len(fixed_line) >= max_line_length + (colors_counter * self._ANSI_COLOR_LENGTH):\n                    # Special case in which we want to split right before the line break.\n                    if len(line) > line_index and line[line_index] == self.LINE_SEP:\n                        continue\n                    line_string = ''.join(fixed_line)\n                    if not line_string.endswith(self.LINE_SEP):\n                        line_string += self.LINE_SEP\n                    lines.append(line_string)\n                    fixed_line = []\n                    colors_counter = 0\n                    self._last_position = 0\n                    # Max line length has changed since the last position is now 0.\n                    max_line_length = console_width - len(self.LINE_SEP) - self.indents_sum\n                    self._is_first_line = False\n\n            if len(fixed_line) > 0:\n                fixed_line = ''.join(fixed_line)\n                # If this line contains only color codes, attach it to the last line instead of creating a new one.\n                if len(fixed_line) == self._ANSI_COLOR_LENGTH and self._ANSI_REGEXP.match(fixed_line) is not None and \\\n                        len(lines) > 0:\n                    lines[-1] = lines[-1][:-1] + fixed_line\n                else:\n                    lines.append(fixed_line)\n        return lines", "response": "Splits the original lines list according to the current console width and group indentations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting the text to the screen.", "response": "def write(self, text: str):\n        \"\"\"\n        Prints text to the screen.\n        Supports colors by using the color constants.\n        To use colors, add the color before the text you want to print.\n\n        :param text: The text to print.\n        \"\"\"\n        # Default color is NORMAL.\n        last_color = (self._DARK_CODE, 0)\n        # We use splitlines with keepends in order to keep the line breaks.\n        # Then we split by using the console width.\n        original_lines = text.splitlines(True)\n        lines = self._split_lines(original_lines) if self._width_limit else original_lines\n\n        # Print the new width-formatted lines.\n        for line in lines:\n            # Print indents only at line beginnings.\n            if not self._in_line:\n                self._writer.write(' ' * self.indents_sum)\n            # Remove colors if needed.\n            if not self._colors:\n                for color_code in self._ANSI_REGEXP.findall(line):\n                    line = line.replace(self._ANSI_COLOR_CODE % (color_code[0], int(color_code[1])), '')\n            elif not self._ANSI_REGEXP.match(line):\n                # Check if the line starts with a color. If not, we apply the color from the last line.\n                line = self._ANSI_COLOR_CODE % (last_color[0], int(last_color[1])) + line\n            # Print the final line.\n            self._writer.write(line)\n            # Update the in_line status.\n            self._in_line = not line.endswith(self.LINE_SEP)\n            # Update the last color used.\n            if self._colors:\n                last_color = self._ANSI_REGEXP.findall(line)[-1]\n\n        # Update last position (if there was no line break in the end).\n        if len(lines) > 0:\n            last_line = lines[-1]\n            if not last_line.endswith(self.LINE_SEP):\n                # Strip the colors to figure out the real number of characters in the line.\n                if self._colors:\n                    for color_code in self._ANSI_REGEXP.findall(last_line):\n                        last_line = last_line.replace(self._ANSI_COLOR_CODE % (color_code[0], int(color_code[1])), '')\n                self._last_position += len(last_line)\n            else:\n                self._last_position = 0\n                self._is_first_line = False\n        else:\n            self._last_position = 0\n\n        # Reset colors for the next print.\n        if self._colors and not text.endswith(self.NORMAL):\n            self._writer.write(self.NORMAL)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting the key and value pairs aligned to align_size.", "response": "def write_aligned(self, key: str, value: str, not_important_keys: Optional[List[str]] = None,\n                      is_list: bool = False, align_size: Optional[int] = None, key_color: str = PURPLE,\n                      value_color: str = GREEN, dark_key_color: str = DARK_PURPLE, dark_value_color: str = DARK_GREEN,\n                      separator: str = SEPARATOR):\n        \"\"\"\n        Prints keys and values aligned to align_size.\n\n        :param key: The name of the property to print.\n        :param value: The value of the property to print.\n        :param not_important_keys: Properties that will be printed in a darker color.\n        :param is_list: True if the value is a list of items.\n        :param align_size: The alignment size to use.\n        :param key_color: The key text color (default is purple).\n        :param value_color: The value text color (default is green).\n        :param dark_key_color: The key text color for unimportant keys (default is dark purple).\n        :param dark_value_color: The values text color for unimportant values (default is dark green).\n        :param separator: The separator to use (default is ':').\n        \"\"\"\n        align_size = align_size or min(32, get_console_width() // 2)\n        not_important_keys = not_important_keys or []\n        if value is None:\n            return\n        if isinstance(value, bool):\n            value = str(value)\n        if key in not_important_keys:\n            key_color = dark_key_color\n            value_color = dark_value_color\n\n        self.write(key_color + key + separator)\n        self.write(' ' * (align_size - len(key) - 1))\n        with self.group(indent=align_size):\n            if is_list and len(value) > 0:\n                self.write_line(value_color + value[0])\n                if len(value) > 1:\n                    for v in value[1:]:\n                        self.write_line(value_color + v)\n            elif not is_list:\n                self.write_line(value_color + str(value))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint a title with a hyphen line underneath it.", "response": "def write_title(self, title: str, title_color: str = YELLOW, hyphen_line_color: str = WHITE):\n        \"\"\"\n        Prints title with hyphen line underneath it.\n\n        :param title: The title to print.\n        :param title_color: The title text color (default is yellow).\n        :param hyphen_line_color: The hyphen line color (default is white).\n        \"\"\"\n        self.write_line(title_color + title)\n        self.write_line(hyphen_line_color + '=' * (len(title) + 3))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a new POS tagger for the current language.", "response": "def generate_pos_tagger(check_accuracy=False):\n    \"\"\"Accuracy is about 0.94 with 90% training data.\"\"\"\n    global tagger\n    logging.debug(\"Reading TIGER corpus\")\n    corp = nltk.corpus.ConllCorpusReader(DIR_PATH, TIGER_FILE_NAME,\n                                         ['ignore', 'words', 'ignore', 'ignore', 'pos'],\n                                         encoding='utf-8')\n    tagged_sents = list(corp.tagged_sents())\n    logging.debug(\"Shuffling sentences\")\n    random.shuffle(tagged_sents)\n    if check_accuracy:\n        # set a split size: use 90% for training, 10% for testing\n        split_perc = 0.1\n        split_size = int(len(tagged_sents) * split_perc)\n        train_sents, test_sents = tagged_sents[split_size:], tagged_sents[:split_size]\n    else:\n        train_sents = tagged_sents\n    logging.debug(\"Training Tagger\")\n    tagger = ClassifierBasedGermanTagger(train=train_sents)\n    logging.debug(\"Training finished\")\n    if check_accuracy:\n        accuracy = tagger.evaluate(test_sents)\n        logging.debug(\"Accurracy is {}.\".format(accuracy))\n    logging.debug(\"Serializing the Tagger\")\n    with open(os.path.join(DIR_PATH, TAGGER_FILE_NAME), 'wb') as f:\n        pickle.dump(tagger, f, protocol=3)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_holes(db_module, db, table_name, column_name, _range, filter=None):\n    if not filter:\n        filter = {\"match_all\": {}}\n\n    _range = wrap(_range)\n    params = {\n        \"min\": _range.min,\n        \"max\": _range.max - 1,\n        \"column_name\": db_module.quote_column(column_name),\n        \"table_name\": db_module.quote_column(table_name),\n        \"filter\": esfilter2sqlwhere(filter)\n    }\n\n    min_max = db.query(\"\"\"\n        SELECT\n            min({{column_name}}) `min`,\n            max({{column_name}})+1 `max`\n        FROM\n            {{table_name}} a\n        WHERE\n            a.{{column_name}} BETWEEN {{min}} AND {{max}} AND\n            {{filter}}\n    \"\"\", params)[0]\n\n    db.execute(\"SET @last={{min}}-1\", {\"min\": _range.min})\n    ranges = db.query(\"\"\"\n        SELECT\n            prev_rev+1 `min`,\n            curr_rev `max`\n        FROM (\n            SELECT\n                a.{{column_name}}-@last diff,\n                @last prev_rev,\n                @last:=a.{{column_name}} curr_rev\n            FROM\n                {{table_name}} a\n            WHERE\n                a.{{column_name}} BETWEEN {{min}} AND {{max}} AND\n                {{filter}}\n            ORDER BY\n                a.{{column_name}}\n        ) a\n        WHERE\n            diff>1\n    \"\"\", params)\n\n    if ranges:\n        ranges.append({\"min\": min_max.max, \"max\": _range.max})\n    else:\n        if min_max.min:\n            ranges.append({\"min\": _range.min, \"max\": min_max.min})\n            ranges.append({\"min\": min_max.max, \"max\": _range.max})\n        else:\n            ranges.append(_range)\n\n    return ranges", "response": "FIND HOLES IN A DENSE COLUMN OF INTEGERS\n    RETURNS A LIST OF {\"min\": min max : max"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef values2rows(values, column_names):\n    values = wrap(values)\n    lookup = {name: i for i, name in enumerate(column_names)}\n    output = []\n    for value in values:\n        row = [None] * len(column_names)\n        for k, v in value.leaves():\n            index = lookup.get(k, -1)\n            if index != -1:\n                row[index] = v\n        output.append(row)\n    return output", "response": "Convert a list of values into a list of rows."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns encrypted binary file content if successful", "response": "def encrypt_file(file_path, sender, recipients):\n    \"Returns encrypted binary file content if successful\"\n    for recipient_key in recipients:\n        crypto.assert_type_and_length('recipient_key', recipient_key, (str, crypto.UserLock))\n    crypto.assert_type_and_length(\"sender_key\", sender, crypto.UserLock)\n    if (not os.path.exists(file_path)) or (not os.path.isfile(file_path)):\n        raise OSError(\"Specified path does not point to a valid file: {}\".format(file_path))\n    _, filename = os.path.split(file_path)\n    with open(file_path, \"rb\") as I:\n        crypted = crypto.MiniLockFile.new(filename, I.read(), sender, recipients)\n    return crypted.contents"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decrypt_file(file_path, recipient_key, *, base64=False):\n    \"Returns (filename, file_contents) if successful\"\n    crypto.assert_type_and_length('recipient_key', recipient_key, crypto.UserLock)\n    with open(file_path, \"rb\") as I:\n        contents = I.read()\n        if base64:\n            contents = crypto.b64decode(contents)\n        crypted = crypto.MiniLockFile(contents)\n    return crypted.decrypt(recipient_key)", "response": "Returns ( filename file_contents ) if successful"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encrypt_folder(path, sender, recipients):\n    for recipient_key in recipients:\n        crypto.assert_type_and_length('recipient_key', recipient_key, (str, crypto.UserLock))\n    crypto.assert_type_and_length(\"sender_key\", sender, crypto.UserLock)\n    if (not os.path.exists(path)) or (not os.path.isdir(path)):\n        raise OSError(\"Specified path is not a valid directory: {}\".format(path))\n    buf = io.BytesIO()\n    zipf = zipfile.ZipFile(buf, mode=\"w\", compression=zipfile.ZIP_DEFLATED)\n    for root, folders, files in os.walk(path):\n        for fn in files:\n            fp = os.path.join(root, fn)\n            zipf.write(fp)\n    zipf.close()\n    zip_contents = buf.getvalue()\n    _, filename = os.path.split(path)\n    filename += \".zip\"\n    crypted = crypto.MiniLockFile.new(filename, zip_contents, sender, recipients)\n    return crypted.contents", "response": "This helper function should zip the contents of a folder and encrypt it as a zip - file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_profile(A):\n    \"Fail-soft profile getter; if no profile is present assume none and quietly ignore.\"\n    try:\n        with open(os.path.expanduser(A.profile)) as I:\n            profile = json.load(I)\n        return profile\n    except:\n        return {}", "response": "Fail - soft profile getter ; if no profile is present assume none and quietly ignore."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nencrypt to recipient list using primary key OR prompted key. Recipients may be IDs or petnames.", "response": "def main_encrypt(A):\n    \"Encrypt to recipient list using primary key OR prompted key. Recipients may be IDs or petnames.\"\n    profile = get_profile(A)\n    localKeys = profile.get('local keys', [])\n    if not localKeys:\n        localKeys = [make_lock_securely(warn_only = A.ignore_entropy)]\n    else:\n        localKeys = [crypto.UserLock.private_from_b64(k['private_key']) for k in localKeys]\n    # First key is considered \"main\"\n    userKey = localKeys[0]\n    print(\"User ID:\", userKey.userID)\n    if not os.path.exists(A.path):\n        error_out(\"File or directory '{}' does not exist.\".format(A.path))\n    # Create, fetch or error out for recipient list:\n    recipients = resolve_recipients(profile, A.recipient)\n    recipients.append(userKey)\n    print(\"Recipients:\", *set(k.userID if isinstance(k, crypto.UserLock) else k for k in recipients))\n    # Do files OR folders\n    if os.path.isfile(A.path):\n        crypted = encrypt_file(A.path, userKey, recipients)\n    elif os.path.isdir(A.path):\n        crypted = encrypt_folder(A.path, userKey, recipients)\n    else:\n        error_out(\"Specified path '{}' is neither a file nor a folder.\".format(A.path))\n    if A.base64:\n        crypted = crypto.b64encode(crypted)\n    if not A.output:\n        A.output = hex(int.from_bytes(os.urandom(6),'big'))[2:] + \".minilock\"\n    print(\"Saving output to\", A.output)\n    with open(A.output, \"wb\") as O:\n        O.write(crypted)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main_decrypt(A):\n    \"Get all local keys OR prompt user for key, then attempt to decrypt with each.\"\n    profile = get_profile(A)\n    localKeys = profile.get('local keys', [])\n    if not localKeys:\n        localKeys = [make_lock_securely(warn_only = A.ignore_entropy)]\n    else:\n        localKeys = [crypto.UserLock.private_from_b64(k['private_key']) for k in localKeys]\n    if not os.path.exists(A.path):\n        error_out(\"File or directory '{}' does not exist.\".format(A.path))\n    if os.path.isfile(A.path):\n        for k in localKeys:\n            print(\"Attempting decryption with:\", k.userID)\n            try:\n                filename, senderID, decrypted = decrypt_file(A.path, k, base64 = A.base64)\n                break\n            except ValueError as E:\n                pass\n        else:\n            error_out(\"Failed to decrypt with all available keys.\")\n    else:\n        error_out(\"Specified path '{}' is not a file.\".format(A.path))\n    print(\"Decrypted file from\", senderID)\n    print(\"Saving output to\", filename)\n    with open(filename, \"wb\") as O:\n        O.write(decrypted)", "response": "Get all local keys OR prompt user for key then attempt to decrypt with each."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a dataframe of all homogeneisation revenus menages.", "response": "def build_homogeneisation_revenus_menages(temporary_store = None, year = None):\n    assert temporary_store is not None\n    \"\"\"Build menage consumption by categorie fiscale dataframe \"\"\"\n\n    assert year is not None\n    # Load data\n    bdf_survey_collection = SurveyCollection.load(\n        collection = 'budget_des_familles', config_files_directory = config_files_directory)\n    survey = bdf_survey_collection.get_survey('budget_des_familles_{}'.format(year))\n\n# **********************************************************************************************************************\n# ********************************* HOMOGENEISATION DES DONNEES SUR LES REVENUS DES MENAGES ****************************\n# ************************************ CALCUL D'UN PROXI DU REVENU DISPONIBLE DES MENAGES ******************************\n# **********************************************************************************************************************\n#\n# ********************HOMOGENEISATION DES BASES DE RESSOURCES***************************\n\n# La base 95 permet de distinguer taxe d'habitation et imp\u00f4ts fonciers.\n# On calcule leur montant relatif pour l'appliquer \u00e0 00 et 05\n\n    if year == 1995:\n        menrev = survey.get_values(\n            table = \"menrev\",\n            variables = [\n                'revtot', 'ir', 'irbis', 'imphab', 'impfon', 'revaid', 'revsal', 'revind', 'revsec', 'revret',\n                'revcho', 'revfam', 'revlog', 'revinv', 'revrmi', 'revpat', 'mena', 'ponderr'\n                ],\n            )\n        menage = survey.get_values(\n            table = \"socioscm\",\n            variables = ['exdep', 'exrev', 'mena']\n            )\n\n        menage.set_index('mena')\n        menrev = menrev.merge(menage, left_index = True, right_index = True)\n        # cette \u00e9tape de ne garder que les donn\u00e9es dont on est s\u00fbr de la qualit\u00e9 et de la v\u00e9racit\u00e9\n        # exdep = 1 si les donn\u00e9es sont bien remplies pour les d\u00e9penses du m\u00e9nage\n        # exrev = 1 si les donn\u00e9es sont bien remplies pour les revenus du m\u00e9nage\n\n        menrev = menrev[(menrev.exdep == 1) & (menrev.exrev == 1)]\n\n        menrev['foncier_hab'] = menrev.imphab + menrev.impfon\n        menrev['part_IMPHAB'] = menrev.imphab / menrev.foncier_hab\n        menrev['part_IMPFON'] = menrev.impfon / menrev.foncier_hab\n\n        menrev['revsoc'] = (\n            menrev.revret + menrev.revcho + menrev.revfam + menrev.revlog + menrev.revinv + menrev.revrmi\n            )\n        for variable in ['revcho', 'revfam', 'revinv', 'revlog', 'revret', 'revrmi']:\n            del menrev[variable]\n\n        menrev['revact'] = menrev['revsal'] + menrev['revind'] + menrev['revsec']\n        menrev.rename(\n            columns = dict(\n                revpat = \"revpat\",\n                impfon = \"impfon\",\n                imphab = \"imphab\",\n                revaid = \"somme_obl_recue\",\n                ),\n            inplace = True\n            )\n        menrev['impot_revenu'] = menrev['ir'] + menrev['irbis']\n\n        rev_disp = survey.get_values(\n            table = \"menrev\",\n            variables = ['revtot', 'revret', 'revcho', 'revfam', 'revlog', 'revinv', 'revrmi', 'imphab', 'impfon',\n                'revaid', 'revsal', 'revind', 'revsec', 'revpat', 'mena', 'ponderr', 'ir', 'irbis'],\n            )\n        rev_disp.set_index('mena', inplace=True)\n\n        menage2 = survey.get_values(\n            table = \"socioscm\",\n            variables = ['exdep', 'exrev', 'mena']\n            )\n\n        menage2.set_index('mena', inplace = True)\n        rev_disp = menage2.merge(rev_disp, left_index = True, right_index = True)\n\n        rev_disp = rev_disp[(rev_disp.exrev == 1) & (rev_disp.exdep == 1)]\n\n        rev_disp['revsoc'] = (\n            rev_disp['revret'] + rev_disp['revcho'] + rev_disp['revfam'] + rev_disp['revlog'] + rev_disp['revinv'] +\n            rev_disp['revrmi']\n            )\n        rev_disp['impot_revenu'] = rev_disp['ir'] + rev_disp['irbis']\n\n        rev_disp.rename(\n            columns = dict(\n                revaid = 'somme_obl_recue',\n                ),\n            inplace = True\n            )\n        rev_disp.somme_obl_recue = rev_disp.somme_obl_recue.fillna(0)\n\n        rev_disp['revact'] = rev_disp['revsal'] + rev_disp['revind'] + rev_disp['revsec']\n\n        rev_disp['revtot'] = rev_disp['revact'] + rev_disp['revpat'] + rev_disp['revsoc'] + rev_disp['somme_obl_recue']\n\n        rev_disp['revact'] = rev_disp['revsal'] + rev_disp['revind'] + rev_disp['revsec']\n\n        rev_disp.rename(\n            columns = dict(\n                ponderr = \"pondmen\",\n                mena = \"ident_men\",\n                revind = \"act_indpt\",\n                revsal = \"salaires\",\n                revsec = \"autres_rev\",\n                ),\n            inplace = True\n            )\n\n        rev_disp['autoverses'] = '0'\n        rev_disp['somme_libre_recue'] = '0'\n        rev_disp['autres_ress'] = '0'\n\n\n#\n# /* Le revenu disponible se calcule \u00e0 partir de revtot \u00e0 laquelle on retrancher la taxe d'habitation\n# et l'imp\u00f4t sur le revenu, plus \u00e9ventuellement les CSG et CRDS.\n# La variable revtot est la somme des revenus d'activit\u00e9, sociaux, du patrimoine et d'aide. */\n#\n        rev_disp['rev_disponible'] = rev_disp.revtot - rev_disp.impot_revenu - rev_disp.imphab\n        loyers_imputes = temporary_store['depenses_bdf_{}'.format(year)]\n        loyers_imputes.rename(\n            columns = {\"0411\": \"loyer_impute\"},\n            inplace = True,\n            )\n\n        rev_dispbis = loyers_imputes.merge(rev_disp, left_index = True, right_index = True)\n        rev_disp['rev_disp_loyerimput'] = rev_disp['rev_disponible'] - rev_dispbis['loyer_impute']\n\n        for var in ['somme_obl_recue', 'act_indpt', 'revpat', 'salaires', 'autres_rev', 'rev_disponible', 'impfon',\n            'imphab', 'revsoc', 'revact', 'impot_revenu', 'revtot', 'rev_disp_loyerimput']:\n            rev_disp[var] = rev_disp[var] / 6.55957  # CONVERSION EN EUROS\n\n        temporary_store[\"revenus_{}\".format(year)] = rev_disp\n\n    elif year == 2000:\n        # TODO: r\u00e9cup\u00e9rer plut\u00f4t les variables qui viennent de la table d\u00e9penses (dans temporary_store)\n        rev_disp = survey.get_values(\n            table = \"consomen\",\n            variables = ['c13141', 'c13111', 'c13121', 'c13131', 'pondmen', 'ident'],\n            )\n        menage = survey.get_values(\n            table = \"menage\",\n            variables = ['ident', 'revtot', 'revact', 'revsoc', 'revpat', 'rev70', 'rev71', 'revt_d', 'pondmen',\n                'rev10', 'rev11', 'rev20', 'rev21'],\n            ).sort_values(by = ['ident'])\n        menage.index = menage.index.astype(ident_men_dtype)\n        rev_disp.index = rev_disp.index.astype(ident_men_dtype)\n        revenus = menage.join(rev_disp, how = \"outer\", rsuffix = \"rev_disp\")\n        revenus.fillna(0, inplace = True)\n        revenus.rename(\n            columns = dict(\n                c13111 = \"impot_res_ppal\",\n                c13141 = \"impot_revenu\",\n                c13121 = \"impot_autres_res\",\n                rev70 = \"somme_obl_recue\",\n                rev71 = \"somme_libre_recue\",\n                revt_d = \"autres_ress\",\n                ident = \"ident_men\",\n                rev10 = \"act_indpt\",\n                rev11 = \"autoverses\",\n                rev20 = \"salaires\",\n                rev21 = \"autres_rev\",\n                ),\n            inplace = True\n            )\n\n        var_to_ints = ['pondmen', 'impot_autres_res', 'impot_res_ppal', 'pondmenrev_disp', 'c13131']\n        for var_to_int in var_to_ints:\n            revenus.loc[revenus[var_to_int].isnull(), var_to_int] = 0\n            revenus[var_to_int] = revenus[var_to_int].astype(int)\n\n        revenus['imphab'] = 0.65 * (revenus.impot_res_ppal + revenus.impot_autres_res)\n        revenus['impfon'] = 0.35 * (revenus.impot_res_ppal + revenus.impot_autres_res)\n\n        loyers_imputes = temporary_store[\"depenses_bdf_{}\".format(year)]\n        variables = [\"poste_coicop_421\"]\n        loyers_imputes = loyers_imputes[variables]\n\n        loyers_imputes.rename(\n            columns = {\"poste_coicop_421\": \"loyer_impute\"},\n            inplace = True,\n            )\n\n        temporary_store[\"loyers_imputes_{}\".format(year)] = loyers_imputes\n        loyers_imputes.index = loyers_imputes.index.astype(ident_men_dtype)\n\n        revenus.set_index('ident_men', inplace = True)\n        revenus.index = revenus.index.astype(ident_men_dtype)\n        assert set(revenus.index) == set(loyers_imputes.index), 'revenus and loyers_imputes indexes are not equal'\n        revenus = revenus.merge(loyers_imputes, left_index = True, right_index = True)\n        revenus['rev_disponible'] = revenus.revtot - revenus.impot_revenu - revenus.imphab\n        revenus['rev_disponible'] = revenus['rev_disponible'] * (revenus['rev_disponible'] >= 0)\n        revenus['rev_disp_loyerimput'] = revenus.rev_disponible + revenus.loyer_impute\n\n        var_to_ints = ['loyer_impute']\n        for var_to_int in var_to_ints:\n            revenus[var_to_int] = revenus[var_to_int].astype(int)\n\n        temporary_store[\"revenus_{}\".format(year)] = revenus\n\n    elif year == 2005:\n        c05d = survey.get_values(\n            table = \"c05d\",\n            variables = ['c13111', 'c13121', 'c13141', 'pondmen', 'ident_men'],\n            )\n        rev_disp = c05d.sort_values(by = ['ident_men'])\n        del c05d\n        menage = survey.get_values(\n            table = \"menage\",\n            variables = ['ident_men', 'revtot', 'revact', 'revsoc', 'revpat', 'rev700_d', 'rev701_d',\n                'rev999_d', 'rev100_d', 'rev101_d', 'rev200_d', 'rev201_d'],\n            ).sort_values(by = ['ident_men'])\n        rev_disp.set_index('ident_men', inplace = True)\n        menage.set_index('ident_men', inplace = True)\n        menage.index = menage.index.astype('str')\n        rev_disp.index = rev_disp.index.astype('str')\n        assert menage.index.dtype == rev_disp.index.dtype, 'menage ({}) and revdisp ({}) dtypes differs'.format(\n            menage.index.dtype, rev_disp.index.dtype)\n        revenus = pandas.concat([menage, rev_disp], axis = 1)\n        assert len(menage.index) == len(revenus.index)\n        revenus.rename(\n            columns = dict(\n                rev100_d = \"act_indpt\",\n                rev101_d = \"autoverses\",\n                rev200_d = \"salaires\",\n                rev201_d = \"autres_rev\",\n                rev700_d = \"somme_obl_recue\",\n                rev701_d = \"somme_libre_recue\",\n                rev999_d = \"autres_ress\",\n                c13111 = \"impot_res_ppal\",\n                c13141 = \"impot_revenu\",\n                c13121 = \"impot_autres_res\",\n                ),\n            inplace = True\n            )\n        # * Ces pond\u00e9rations (0.65 0.35) viennent de l'enqu\u00eate BdF 1995 qui distingue taxe d'habitation et imp\u00f4ts\n        #   fonciers. A partir de BdF 1995,\n        # * on a calcul\u00e9 que la taxe d'habitation repr\u00e9sente en moyenne 65% des imp\u00f4ts locaux, et que les imp\u00f4ts\n        #   fonciers en repr\u00e9sentenr 35%.\n        # * On applique ces taux aux enqu\u00eates 2000 et 2005.\n\n        revenus['imphab'] = 0.65 * (revenus.impot_res_ppal + revenus.impot_autres_res)\n        revenus['impfon'] = 0.35 * (revenus.impot_res_ppal + revenus.impot_autres_res)\n        del revenus['impot_autres_res']\n        del revenus['impot_res_ppal']\n\n        #    * Calculer le revenu disponible avec et sans le loyer imput\u00e9\n\n        loyers_imputes = temporary_store[\"depenses_bdf_{}\".format(year)]\n        variables = [\"poste_coicop_421\"]\n        loyers_imputes = loyers_imputes[variables]\n        loyers_imputes.rename(\n            columns = {\"poste_coicop_421\": \"loyer_impute\"},\n            inplace = True,\n            )\n        temporary_store[\"loyers_imputes_{}\".format(year)] = loyers_imputes\n        loyers_imputes.index = loyers_imputes.index.astype('str')\n        assert revenus.index.dtype == loyers_imputes.index.dtype\n        assert set(revenus.index) == set(loyers_imputes.index), '''revenus and loyers_imputes indexes are not equal.\nIn revenus and not in loyers_imputes:\n{}\nIn loyers_imputes and not in revenus:\n{}\n'''.format(set(revenus.index) - set(loyers_imputes.index), set(loyers_imputes.index) - set(revenus.index))\n        revenus = revenus.merge(loyers_imputes, left_index = True, right_index = True)\n        revenus['rev_disponible'] = revenus.revtot - revenus.impot_revenu - revenus.imphab\n        revenus['rev_disponible'] = revenus['rev_disponible'] * (revenus['rev_disponible'] >= 0)\n        revenus['rev_disp_loyerimput'] = revenus.rev_disponible + revenus.loyer_impute\n\n        temporary_store[\"revenus_{}\".format(year)] = revenus\n\n    elif year == 2011:\n        try:\n            c05 = survey.get_values(\n                table = \"C05\",\n                variables = ['c13111', 'c13121', 'c13141', 'pondmen', 'ident_me'],\n                )\n            rev_disp = c05.sort_values(by = ['ident_me'])\n        except:\n            c05 = survey.get_values(\n                table = \"c05\",\n                variables = ['c13111', 'c13121', 'c13141', 'pondmen', 'ident_me'],\n                )\n            rev_disp = c05.sort_values(by = ['ident_me'])\n        del c05\n        try:\n            menage = survey.get_values(\n                table = \"MENAGE\",\n                variables = ['ident_me', 'revtot', 'revact', 'revsoc', 'revpat', 'rev700', 'rev701', 'rev999',\n                             'revindep', 'salaires'],\n                ).sort_values(by = ['ident_me'])\n        except:\n            menage = survey.get_values(\n                table = \"menage\",\n                variables = ['ident_me', 'revtot', 'revact', 'revsoc', 'revpat', 'rev700', 'rev701', 'rev999',\n                             'revindep', 'salaires'],\n                ).sort_values(by = ['ident_me'])\n\n        rev_disp.index = rev_disp.index.astype(ident_men_dtype)\n        menage.index = menage.index.astype(ident_men_dtype)\n        rev_disp.set_index('ident_me', inplace = True)\n        menage.set_index('ident_me', inplace = True)\n        revenus = pandas.concat([menage, rev_disp], axis = 1)\n        menage.index.name = 'ident_men'\n        revenus.index.name = 'ident_men'\n        revenus.rename(\n            columns = dict(\n                revindep = \"act_indpt\",\n                # TODO: trouver ces revenus comment\u00e9s dans bdf 2011\n                # rev101_d = \"autoverses\",\n                salaires = \"salaires\",\n                # rev201_d = \"autres_rev\",\n                rev700 = \"somme_obl_recue\",\n                rev701 = \"somme_libre_recue\",\n                rev999 = \"autres_ress\",\n                c13111 = \"impot_res_ppal\",\n                c13141 = \"impot_revenu\",\n                c13121 = \"impot_autres_res\",\n                ),\n            inplace = True\n            )\n        revenus['imphab'] = 0.65 * (revenus.impot_res_ppal + revenus.impot_autres_res)\n        revenus['impfon'] = 0.35 * (revenus.impot_res_ppal + revenus.impot_autres_res)\n        del revenus['impot_autres_res']\n        del revenus['impot_res_ppal']\n\n        loyers_imputes = temporary_store[\"depenses_bdf_{}\".format(year)]\n        variables = [\"poste_coicop_421\"]\n        loyers_imputes = loyers_imputes[variables]\n        loyers_imputes.rename(\n            columns = {\"poste_coicop_421\": \"loyer_impute\"},\n            inplace = True,\n            )\n        temporary_store[\"loyers_imputes_{}\".format(year)] = loyers_imputes\n        revenus = revenus.merge(loyers_imputes, left_index = True, right_index = True)\n        revenus['rev_disponible'] = revenus.revtot - revenus.impot_revenu - revenus.imphab\n        revenus['rev_disponible'] = revenus['rev_disponible'] * (revenus['rev_disponible'] >= 0)\n        revenus['rev_disp_loyerimput'] = revenus.rev_disponible + revenus.loyer_impute\n        temporary_store[\"revenus_{}\".format(year)] = revenus"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrendering the collection page.", "response": "def collection(name=None):\n    \"\"\"Render the collection page.\n\n    It renders it either with a collection specific template (aka\n    collection_{collection_name}.html) or with the default collection\n    template (collection.html).\n    \"\"\"\n    if name is None:\n        collection = Collection.query.get_or_404(1)\n    else:\n        collection = Collection.query.filter(\n            Collection.name == name).first_or_404()\n\n    # TODO add breadcrumbs\n    # breadcrumbs = current_breadcrumbs + collection.breadcrumbs(ln=g.ln)[1:]\n    return render_template([\n        'invenio_collections/collection_{0}.html'.format(collection.id),\n        'invenio_collections/collection_{0}.html'.format(slugify(name, '_')),\n        current_app.config['COLLECTIONS_DEFAULT_TEMPLATE']\n    ], collection=collection)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef url(self):\n        return self.get_url(self.world, self.category, self.vocation, self.page)", "response": "Returns the URL to the highscores page containing the results."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef url_tibiadata(self):\n        return self.get_url_tibiadata(self.world, self.category, self.vocation)", "response": "Returns the URL to the highscores page on TibiaData. com containing the results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an instance of the class from the HTML content of a highscore page.", "response": "def from_content(cls, content):\n        \"\"\"Creates an instance of the class from the html content of a highscores page.\n\n        Notes\n        -----\n        Tibia.com only shows up to 25 entries per page, so in order to obtain the full highscores, all 12 pages must\n        be parsed and merged into one.\n\n        Parameters\n        ----------\n        content: :class:`str`\n            The HTML content of the page.\n\n        Returns\n        -------\n        :class:`Highscores`\n            The highscores results contained in the page.\n\n        Raises\n        ------\n        InvalidContent\n            If content is not the HTML of a highscore's page.\"\"\"\n        parsed_content = parse_tibiacom_content(content)\n        tables = cls._parse_tables(parsed_content)\n        filters = tables.get(\"Highscores Filter\")\n        if filters is None:\n            raise InvalidContent(\"content does is not from the highscores section of Tibia.com\")\n        world_filter, vocation_filter, category_filter = filters\n        world = world_filter.find(\"option\", {\"selected\": True})[\"value\"]\n        if world == \"\":\n            return None\n        category = category_filter.find(\"option\", {\"selected\": True})[\"value\"]\n        vocation_selected = vocation_filter.find(\"option\", {\"selected\": True})\n        vocation = int(vocation_selected[\"value\"]) if vocation_selected else 0\n        highscores = cls(world, category, vocation=vocation)\n        entries = tables.get(\"Highscores\")\n        if entries is None:\n            return None\n        _, header, *rows = entries\n        info_row = rows.pop()\n        highscores.results_count = int(results_pattern.search(info_row.text).group(1))\n        for row in rows:\n            cols_raw = row.find_all('td')\n            highscores._parse_entry(cols_raw)\n        return highscores"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_tibiadata(cls, content, vocation=None):\n        json_content = parse_json(content)\n        try:\n            highscores_json = json_content[\"highscores\"]\n            if \"error\" in highscores_json[\"data\"]:\n                return None\n            world = highscores_json[\"world\"]\n            category = highscores_json[\"type\"]\n            highscores = cls(world, category)\n            for entry in highscores_json[\"data\"]:\n                value_key = \"level\"\n                if highscores.category in [Category.ACHIEVEMENTS, Category.LOYALTY_POINTS, Category.EXPERIENCE]:\n                    value_key = \"points\"\n                if highscores.category == Category.EXPERIENCE:\n                    highscores.entries.append(ExpHighscoresEntry(entry[\"name\"], entry[\"rank\"], entry[\"voc\"],\n                                                                 entry[value_key], entry[\"level\"]))\n                elif highscores.category == Category.LOYALTY_POINTS:\n                    highscores.entries.append(LoyaltyHighscoresEntry(entry[\"name\"], entry[\"rank\"], entry[\"voc\"],\n                                                                     entry[value_key], entry[\"title\"]))\n                else:\n                    highscores.entries.append(HighscoresEntry(entry[\"name\"], entry[\"rank\"], entry[\"voc\"],\n                                                              entry[value_key]))\n            highscores.results_count = len(highscores.entries)\n        except KeyError:\n            raise InvalidContent(\"content is not a TibiaData highscores response.\")\n        if isinstance(vocation, VocationFilter):\n            highscores.vocation = vocation\n        return highscores", "response": "Builds a highscores object from a TibiaData highscores response."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_url(cls, world, category=Category.EXPERIENCE, vocation=VocationFilter.ALL, page=1):\n        return HIGHSCORES_URL % (world, category.value, vocation.value, page)", "response": "Gets the Tibia. com URL of the desired highscores for the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the TibiaData. com URL of the desired highscores for the given parameters.", "response": "def get_url_tibiadata(cls, world, category=Category.EXPERIENCE, vocation=VocationFilter.ALL):\n        \"\"\"Gets the TibiaData.com URL of the highscores for the given parameters.\n\n        Parameters\n        ----------\n        world: :class:`str`\n            The game world of the desired highscores.\n        category: :class:`Category`\n            The desired highscores category.\n        vocation: :class:`VocationFiler`\n            The vocation filter to apply. By default all vocations will be shown.\n\n        Returns\n        -------\n        The URL to the TibiaData.com highscores.\n        \"\"\"\n        return HIGHSCORES_URL_TIBIADATA % (world, category.value.lower(), vocation.name.lower())"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses an entry s row and adds the result to self. entries.", "response": "def _parse_entry(self, cols):\n        \"\"\"Parses an entry's row and adds the result to py:attr:`entries`.\n\n        Parameters\n        ----------\n        cols: :class:`bs4.ResultSet`\n            The list of columns for that entry.\n        \"\"\"\n        rank, name, vocation, *values = [c.text.replace('\\xa0', ' ').strip() for c in cols]\n        rank = int(rank)\n        if self.category == Category.EXPERIENCE or self.category == Category.LOYALTY_POINTS:\n            extra, value = values\n        else:\n            value, *extra = values\n        value = int(value.replace(',', ''))\n        if self.category == Category.EXPERIENCE:\n            entry = ExpHighscoresEntry(name, rank, vocation, value, int(extra))\n        elif self.category == Category.LOYALTY_POINTS:\n            entry = LoyaltyHighscoresEntry(name, rank, vocation, value, extra)\n        else:\n            entry = HighscoresEntry(name, rank, vocation, value)\n        self.entries.append(entry)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntransform the string to upside - down writing.", "response": "def transform(string, transliterations=None):\n    \"\"\"\n    Transform the string to \"upside-down\" writing.\n\n    Example:\n\n        >>> import upsidedown\n        >>> print(upsidedown.transform('Hello World!'))\n        \u00a1p\ua781\u0279oM o\ua781\ua781\u01ddH\n\n    For languages with diacritics you might want to supply a transliteration to\n    work around missing (rendering of) upside-down forms:\n        >>> import upsidedown\n        >>> print(upsidedown.transform('k\u00f6ln', transliterations={'\u00f6': 'oe'}))\n        u\ua781\u01ddo\u029e\n    \"\"\"\n    transliterations = transliterations or TRANSLITERATIONS\n\n    for character in transliterations:\n        string = string.replace(character, transliterations[character])\n\n    inputChars = list(string)\n    inputChars.reverse()\n\n    output = []\n    for character in inputChars:\n        if character in _CHARLOOKUP:\n            output.append(_CHARLOOKUP[character])\n        else:\n            charNormalised = unicodedata.normalize(\"NFD\", character)\n\n            for c in charNormalised[:]:\n                if c in _CHARLOOKUP:\n                    charNormalised = charNormalised.replace(c, _CHARLOOKUP[c])\n                elif c in _DIACRITICSLOOKUP:\n                    charNormalised = charNormalised.replace(c,\n                        _DIACRITICSLOOKUP[c])\n\n            output.append(unicodedata.normalize(\"NFC\", charNormalised))\n\n    return ''.join(output)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npopping a message from the queue.", "response": "def pop_message(self, wait=SECOND, till=None):\n        \"\"\"\n        RETURN TUPLE (message, payload) CALLER IS RESPONSIBLE FOR CALLING message.delete() WHEN DONE\n        \"\"\"\n        if till is not None and not isinstance(till, Signal):\n            Log.error(\"Expecting a signal\")\n\n        message = self.queue.read(wait_time_seconds=mo_math.floor(wait.seconds))\n        if not message:\n            return None\n        message.delete = lambda: self.queue.delete_message(message)\n\n        payload = mo_json.json2value(message.get_body())\n        return message, payload"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef never(self):\n        def check(): #pylint: disable=missing-docstring\n            return not super(SinonExpectation, self).called\n        self.valid_list.append(check)\n        return self", "response": "Inspected function should never be called\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef once(self):\n        def check(): #pylint: disable=missing-docstring\n            return super(SinonExpectation, self).calledOnce\n        self.valid_list.append(check)\n        return self", "response": "Inspected function should be called one time\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninspect function should be called two times", "response": "def twice(self):\n        \"\"\"\n        Inspected function should be called two times\n        Return: self\n        \"\"\"\n        def check(): #pylint: disable=missing-docstring\n            return super(SinonExpectation, self).calledTwice\n        self.valid_list.append(check)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninspects function should be called three times Return self", "response": "def thrice(self):\n        \"\"\"\n        Inspected function should be called three times\n        Return: self\n        \"\"\"\n\n        def check(): #pylint: disable=missing-docstring\n            return super(SinonExpectation, self).calledThrice\n        self.valid_list.append(check)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef exactly(self, number):\n        def check(): #pylint: disable=missing-docstring\n            return True if number == super(SinonExpectation, self).callCount else False\n        self.valid_list.append(check)\n        return self", "response": "Inspected function should be called exactly number times\n        Return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninspecting function should be called with some of specified arguments.", "response": "def withArgs(self, *args, **kwargs): #pylint: disable=invalid-name\n        \"\"\"\n        Inspected function should be called with some of specified arguments\n        Args: any\n        Return: self\n        \"\"\"\n        def check(): #pylint: disable=missing-docstring\n            return super(SinonExpectation, self).calledWith(*args, **kwargs)\n        self.valid_list.append(check)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef withExactArgs(self, *args, **kwargs): #pylint: disable=invalid-name\n        def check(): #pylint: disable=missing-docstring\n            return super(SinonExpectation, self).calledWithExactly(*args, **kwargs)\n        self.valid_list.append(check)\n        return self", "response": "Inspected function should be called with full of specified arguments"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies that the current instance is in the valid_list", "response": "def verify(self):\n        \"\"\"\n        Running all conditions in the instance variable valid_list\n        Return:\n            True: pass all conditions\n            False: fail at more than one condition\n        \"\"\"\n        if self not in self._queue:\n            return False\n        valid = True\n        for check in self.valid_list:\n            valid = valid & check()\n        return valid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd new property of object as inspector into exp_list", "response": "def expects(self, prop):\n        \"\"\"\n        Adding new property of object as inspector into exp_list\n        Args: string (property of object)\n        Return: SinonExpectation\n        \"\"\"\n        expectation = SinonExpectation(self.obj, prop)\n        self.exp_list.append(expectation)\n        return expectation"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef verify(self):\n        for expectation in self.exp_list:\n            if hasattr(expectation, \"verify\") and not expectation.verify():\n                return False\n        return True", "response": "Verify all inspectors in exp_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrestores all inspectors and SinonMocks from the local state.", "response": "def restore(self):\n        \"\"\"\n        Destroy all inspectors in exp_list and SinonMock itself\n        \"\"\"\n        for expectation in self.exp_list:\n            try:\n                expectation.restore()\n            except ReferenceError:\n                pass #ignore removed expectation\n        self._queue.remove(self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef google_app_engine_ndb_delete_expired_sessions(dormant_for=86400, limit=500):\n    from vishnu.backend.client.google_app_engine_ndb import VishnuSession\n    from google.appengine.ext import ndb\n    from datetime import datetime\n    from datetime import timedelta\n\n    now = datetime.utcnow()\n    last_accessed = now - timedelta(seconds=dormant_for)\n\n    query = VishnuSession.query(ndb.OR(\n        ndb.AND(VishnuSession.expires <= now, VishnuSession.expires != None),\n        VishnuSession.last_accessed <= last_accessed\n    ))\n    results = query.fetch(keys_only=True, limit=limit)\n\n    ndb.delete_multi(results)\n\n    return len(results) < limit", "response": "Delete expired sessions in a Google App Engine NDB database."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete expired sessions in the NDB.", "response": "def google_cloud_datastore_delete_expired_sessions(dormant_for=86400, limit=500):\n    \"\"\"\n    Deletes expired sessions\n    A session is expired if it expires date is set and has passed or\n    if it has not been accessed for a given period of time.\n\n    :param dormant_for: seconds since last access to delete sessions, defaults to 24 hours.\n    :type dormant_for: int\n    :param limit: amount to delete in one call of the method, the maximum and default for this is the NDB fetch limit of 500\n    :type limit: int\n    \"\"\"\n    from vishnu.backend.client.google_cloud_datastore import TABLE_NAME\n    from google.cloud import datastore\n    from datetime import datetime\n    from datetime import timedelta\n\n    now = datetime.utcnow()\n    last_accessed = now - timedelta(seconds=dormant_for)\n\n    client = datastore.Client()\n    accessed_query = client.query(kind=TABLE_NAME)\n    accessed_query.add_filter(\"last_accessed\", \"<=\", last_accessed)\n    accessed_results = accessed_query.fetch(limit=limit)\n\n    expires_query = client.query(kind=TABLE_NAME)\n    expires_query.add_filter(\"expires\", \"<=\", now)\n    expires_results = expires_query.fetch(limit=limit)\n\n    keys = list()\n    for result in accessed_results:\n        keys.append(result.key)\n    for result in expires_results:\n        if result.key not in keys:\n            keys.append(result.key)\n\n    client.delete_multi(keys)\n\n    return len(keys) < limit"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning VALUES FOR THE GIVEN PATH NAME", "response": "def values(self, name):\n        \"\"\"\n        RETURN VALUES FOR THE GIVEN PATH NAME\n        :param name:\n        :return:\n        \"\"\"\n        return list(self.lookup_variables.get(unnest_path(name), Null))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of leaves of the given name considering query_path and namespace.", "response": "def leaves(self, name):\n        \"\"\"\n        RETURN LEAVES OF GIVEN PATH NAME\n        pull leaves, considering query_path and namespace\n        pull all first-level properties\n        pull leaves, including parent leaves\n        pull the head of any tree by name\n        :param name:\n        :return:\n        \"\"\"\n\n        return list(self.lookup_leaves.get(unnest_path(name), Null))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef map_to_es(self):\n        full_name = self.query_path\n        return set_default(\n            {\n                relative_field(c.name, full_name): c.es_column\n                for k, cs in self.lookup.items()\n                # if startswith_field(k, full_name)\n                for c in cs if c.jx_type not in STRUCT\n            },\n            {\n                c.name: c.es_column\n                for k, cs in self.lookup.items()\n                # if startswith_field(k, full_name)\n                for c in cs if c.jx_type not in STRUCT\n            }\n        )", "response": "Returns a new es_column with the names of the entries in the base record that are not in the lookup table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting sdist from parent.", "response": "def get_version_from_dirname(name, parent):\n    \"\"\"Extracted sdist\"\"\"\n    parent = parent.resolve()\n    logger.info(f\"dirname: Trying to get version of {name} from dirname {parent}\")\n\n    name_re = name.replace(\"_\", \"[_-]\")\n    re_dirname = re.compile(f\"{name_re}-{RE_VERSION}$\")\n    if not re_dirname.match(parent.name):\n        logger.info(f\"dirname: Failed; Does not match {re_dirname!r}\")\n        return None\n\n    logger.info(\"dirname: Succeeded\")\n    return Version.parse(parent.name[len(name) + 1 :])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute by command line arguments", "response": "def execute_by_options(args):\n    \"\"\"execute by argument dictionary\n\n    Args:\n        args (dict): command line argument dictionary\n\n    \"\"\"\n    if args['subcommand'] == 'sphinx':\n        s = Sphinx(proj_info)\n        if args['quickstart']:\n            s.quickstart()\n        elif args['gen_code_api']:\n            s.gen_code_api()\n        elif args['rst2html']:\n            s.rst2html()\n        pass\n    elif args['subcommand'] == 'offline_dist':\n        pod = PyOfflineDist()\n        if args['freeze_deps']:\n            pod.freeze_deps()\n        elif args['download_deps']:\n            pod.download_deps()\n        elif args['install_deps']:\n            pod.install_deps()\n        elif args['clean_deps']:\n            pod.clean_deps()\n        elif args['mkbinary']:\n            pod.pyinstaller_mkbinary(args['mkbinary'])\n        elif args['clean_binary']:\n            pod.clean_binary()\n\n    pass"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef editline_with_regex(self, regex_tgtline, to_replace):\n        for idx, line in enumerate(self._swp_lines):\n            mobj = re.match(regex_tgtline, line)\n\n            if mobj:\n                self._swp_lines[idx] = to_replace\n\n                return", "response": "replace the first matched line with the given regular expression"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gen_code_api(self):\n\n        # edit config file\n\n        conf_editor = Editor(self.conf_fpath)\n\n        # insert code path for searching\n        conf_editor.editline_with_regex(r'^# import os', 'import os')\n        conf_editor.editline_with_regex(r'^# import sys', 'import sys')\n        conf_editor.editline_with_regex(\n            r'^# sys\\.path\\.insert',\n            'sys.path.insert(0, \"{}\")'.format(self.code_fdpath))\n        conf_editor.editline_with_regex(\n            r\"\"\"html_theme = 'alabaster'\"\"\",\n            'html_theme = \\'default\\''.format(self.code_fdpath))\n\n        conf_editor.finish_writing()\n\n        # sphinx-apidoc to generate rst from source code\n\n        # force regenerate\n        subprocess.call(self._sphinx_apidoc_cmd)\n\n        pass", "response": "Generate code api for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsurround the given 'function' with a spy wrapper that tracks usage data, such as: * call count * arguments it was called with * keyword argument it was called with * return values * etc. Parameters: function: function, could be one of 3 things: 1. the original function the user wants to spy on 2. the custom function the user specified to replace the original 3. a default function configurable via returns/throws owner: object, the owner of the original function. It is necessary in certain cases to specify this, such as when the user stubs a class. Otherwise, the SpyCall arguments will erroneously include the 'owner' as the first parameter of every call. Returns: function, the spy wrapper that is replacing the inputted function", "response": "def wrap_spy(function, owner=None):\n    \"\"\"\n    Surrounds the given 'function' with a spy wrapper that tracks usage data, such as:\n      * call count\n      * arguments it was called with\n      * keyword argument it was called with\n      * return values\n      * etc.\n\n    Parameters:\n        function: function, could be one of 3 things:\n                    1. the original function the user wants to spy on\n                    2. the custom function the user specified to replace the original\n                    3. a default function configurable via returns/throws\n        owner: object, the owner of the original function. It is necessary in certain cases\n               to specify this, such as when the user stubs a class. Otherwise, the SpyCall\n               arguments will erroneously include the 'owner' as the first parameter of every call.\n    Returns:\n        function, the spy wrapper that is replacing the inputted function\n    \"\"\"\n    def __set__(value, new_list):\n        \"\"\"\n        For python 2.x compatibility\n        \"\"\"\n        setattr(wrapped, value, new_list)\n\n    def wrapped(*args, **kwargs):\n        \"\"\"\n        Fully manipulatable inspector function\n        \"\"\"\n        if owner:\n            if len(args) > 0:\n                if owner == args[0].__class__:\n                    args = args[1:]\n        \n        wrapped.callCount += 1\n        wrapped.args_list.append(args)\n        wrapped.kwargs_list.append(kwargs)\n\n        call = SpyCall()\n        call.args = args\n        call.kwargs = kwargs\n        call.stack = traceback.format_stack()\n        wrapped.call_list.append(call)\n\n        try:\n            ret = function(*args, **kwargs)\n            wrapped.ret_list.append(ret)\n            call.returnValue = ret\n            return ret\n        except BaseException as excpt:\n            # Todo: make sure e.__class__ is enough for all purpose or not\n            wrapped.error_list.append(excpt.__class__)\n            call.exception = excpt\n            raise excpt\n\n    wrapped.__set__ = __set__\n    wrapped.callCount = 0\n    wrapped.args_list = []\n    wrapped.call_list = []\n    wrapped.kwargs_list = []\n    wrapped.error_list = []\n    wrapped.ret_list = []\n    wrapped.LOCK = True\n    return wrapped"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves the current object to datastore.", "response": "def save(self, sync_only=False):\n        \"\"\"\n        :param sync_only:\n        :type: bool\n        \"\"\"\n\n        entity = datastore.Entity(key=self._key)\n        entity[\"last_accessed\"] = self.last_accessed\n\n        # todo: restore sync only\n        entity[\"data\"] = self._data\n        if self.expires:\n            entity[\"expires\"] = self.expires\n\n        self._client.put(entity)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __default_custom_function(self, *args, **kwargs):\n        index_list = self.__get_matching_withargs_indices(*args, **kwargs)\n        # if there are 'withArgs' conditions that might be applicable\n        if index_list:\n            return self.__get_return_value_withargs(index_list, *args, **kwargs)\n        # else no 'withArgs' conditions are applicable\n        else:\n            return self.__get_return_value_no_withargs(*args, **kwargs)", "response": "Default custom function for the catalythm of the user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of indices in args_list that are not in kwargs_list", "response": "def __get_matching_indices(self, args, kwargs, args_list, kwargs_list):\n        \"\"\"\n        Args:\n            args: tuple, the arguments inputed by the user\n            kwargs: dictionary, the keyword arguments inputed by the user\n            args_list: list, a list of argument tuples\n            kwargs_list: list, a list of keyword argument dictionaries\n        Returns:\n            list, the list of indices in args_list/kwargs_list for which the user args/kwargs match\n        \"\"\"\n        if args and kwargs:\n            if args in args_list and kwargs in kwargs_list:\n                args_indices = [i for i, x in enumerate(args_list) if x == args]\n                kwargs_indices = [i for i, x in enumerate(kwargs_list) if x == kwargs]\n                return list(set(args_indices).intersection(kwargs_indices))\n        # args only\n        elif args:\n            if args in args_list:\n                return [i for i, x in enumerate(args_list) if x == args and not kwargs_list[i]]\n        #kwargs only\n        elif kwargs:\n            if kwargs in kwargs_list:\n                return [i for i, x in enumerate(kwargs_list) if x == kwargs and not args_list[i]]\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __get_matching_withargs_indices(self, *args, **kwargs):\n        return self.__get_matching_indices(args, kwargs, self._conditions[\"args\"], self._conditions[\"kwargs\"])", "response": "Returns a list of indices in the conditions that match the given args and kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __get_call_count(self, args, kwargs, args_list, kwargs_list):\n        return len(self.__get_matching_indices(args, kwargs, args_list, kwargs_list))", "response": "Returns the number of times this combination of args and kwargs has been called by the user"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __get_return_value_withargs(self, index_list, *args, **kwargs):\n        c = self._conditions\n        args_list = self._wrapper.args_list\n        kwargs_list = self._wrapper.kwargs_list\n\n        # indices with an arg and oncall have higher priority and should be checked first\n        indices_with_oncall = [i for i in reversed(index_list) if c[\"oncall\"][i]]\n\n        # if there are any combined withArgs+onCall conditions\n        if indices_with_oncall:\n            call_count = self.__get_call_count(args, kwargs, args_list, kwargs_list)\n            for i in indices_with_oncall:\n                if c[\"oncall\"][i] == call_count:\n                    return c[\"action\"][i](*args, **kwargs)\n\n        # else if there are simple withArgs conditions\n        indices_without_oncall = [i for i in reversed(index_list) if not c[\"oncall\"][i]]\n        if indices_without_oncall:\n            max_index = max(indices_without_oncall)\n            return c[\"action\"][max_index](*args, **kwargs)\n\n        # else all conditions did not match\n        return c[\"default\"](*args, **kwargs)", "response": "This method is called by the user to get the return value of the user with the specified args and kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the value of the action that was not specified by the user.", "response": "def __get_return_value_no_withargs(self, *args, **kwargs):\n        \"\"\"    \n        Pre-conditions:\n           (1) The user has created a stub and specified the stub behaviour\n           (2) The user has called the stub function with the specified \"args\" and \"kwargs\"\n           (3) No 'withArgs' conditions were applicable in this case\n        Args:\n            args: tuple, the arguments inputed by the user\n            kwargs: dictionary, the keyword arguments inputed by the user\n        Returns:\n            any type, the appropriate return value, based on the stub's behaviour setup and the user input\n        \"\"\"\n        c = self._conditions\n        call_count = self._wrapper.callCount\n\n        # if there might be applicable onCall conditions\n        if call_count in c[\"oncall\"]:\n            index_list = [i for i, x in enumerate(c[\"oncall\"]) if x and not c[\"args\"][i] and not c[\"kwargs\"][i]]\n            for i in reversed(index_list):\n                # if the onCall condition applies\n                if call_count == c[\"oncall\"][i]:\n                    return c[\"action\"][i](*args, **kwargs)\n\n        # else all conditions did not match\n        return c[\"default\"](*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _append_condition(self, sinon_stub_condition, func):\n        '''\n        Permanently saves the current (volatile) conditions, which would be otherwise lost\n\n        In the _conditions dictionary, the keys \"args\", \"kwargs\", \"oncall\" and \"action\"\n        each refer to a list. All 4 lists have a value appended each time the user calls\n        returns or throws to add a condition to the stub. Hence, all 4 lists are in sync,\n        so a single index refers to the same condition in all 4 lists.\n\n        e.g.\n            stub.withArgs(5).returns(7)\n              # conditions: args [(5,)] kwargs [()] oncall [None] action [7]\n            stub.withArgs(10).onFirstCall().returns(14)\n              # conditions: args [(5,),(10,)] kwargs [(),()] oncall [None,1] action [7,14]\n\n        Args:\n            sinon_stub_condition: the _SinonStubCondition object that holds the current conditions\n            func: returns a value or raises an exception (i.e. the action to take, as specified by the user)\n        '''\n        self._conditions[\"args\"].append(sinon_stub_condition._cond_args)\n        self._conditions[\"kwargs\"].append(sinon_stub_condition._cond_kwargs)\n        self._conditions[\"oncall\"].append(sinon_stub_condition._oncall)\n        self._conditions[\"action\"].append(func)", "response": "Adds a condition to the internal _conditions dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef withArgs(self, *args, **kwargs): #pylint: disable=invalid-name\n        cond_args = args if len(args) > 0 else None\n        cond_kwargs = kwargs if len(kwargs) > 0 else None\n        return _SinonStubCondition(copy=self._copy, cond_args=cond_args, cond_kwargs=cond_kwargs, oncall=self._oncall)", "response": "Returns a copy of this object with the specified arguments added to the condition list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef onCall(self, n): #pylint: disable=invalid-name\n        cond_oncall = n + 1\n        return _SinonStubCondition(copy=self._copy, oncall=cond_oncall, cond_args=self._cond_args, cond_kwargs=self._cond_kwargs)", "response": "Adds a condition for when the stub is called."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef throws(self, exception=Exception):\n        def exception_function(*args, **kwargs):\n            raise exception\n        self._conditions[\"default\"] = exception_function\n        return self", "response": "Customizes the stub function to raise an exception."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncustomizing the return values of the stub function.", "response": "def returns(self, obj):\n        \"\"\"\n        Customizes the return values of the stub function. If conditions like withArgs or onCall\n        were specified, then the return value will only be returned when the conditions are met.\n\n        Args: obj (anything)\n        Return: a SinonStub object (able to be chained)\n        \"\"\"\n        self._copy._append_condition(self, lambda *args, **kwargs: obj)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncustomizing the stub function to raise an exception.", "response": "def throws(self, exception=Exception):\n        \"\"\"\n        Customizes the stub function to raise an exception. If conditions like withArgs or onCall\n        were specified, then the return value will only be returned when the conditions are met.\n\n        Args: exception (by default=Exception, it could be any customized exception)\n        Return: a SinonStub object (able to be chained)\n        \"\"\"\n        def exception_function(*args, **kwargs):\n            raise exception\n        self._copy._append_condition(self, exception_function)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef humanize_api_path(api_path):\n    return reduce(lambda val, func: func(val),\n                  [parameterize, underscore, camelize],\n                  unicode(api_path))", "response": "Converts an API path to a humaized string for example."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assign_operation_ids(spec, operids):\n\n    empty_dict = {}\n\n    for path_name, path_data in six.iteritems(spec['paths']):\n        for method, method_data in six.iteritems(path_data):\n            oper_id = operids.get(path_name, empty_dict).get(method)\n            if oper_id:\n                method_data['operationId'] = oper_id", "response": "assigns caller provided operationId values into a spec"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pretty_print(self, printer: Optional[Printer] = None, align: int = ALIGN_CENTER, border: bool = False):\n        if printer is None:\n            printer = get_printer()\n        table_string = self._get_pretty_table(indent=printer.indents_sum, align=align, border=border).get_string()\n        if table_string != '':\n            first_line = table_string.splitlines()[0]\n            first_line_length = len(first_line) - len(re.findall(Printer._ANSI_REGEXP, first_line)) * \\\n                Printer._ANSI_COLOR_LENGTH\n            if self.title_align == self.ALIGN_CENTER:\n                title = '{}{}'.format(' ' * (first_line_length // 2 - len(self.title) // 2), self.title)\n            elif self.title_align == self.ALIGN_LEFT:\n                title = self.title\n            else:\n                title = '{}{}'.format(' ' * (first_line_length - len(self.title)), self.title)\n            printer.write_line(printer.YELLOW + title)\n            # We split the table to lines in order to keep the indentation.\n            printer.write_line(table_string)", "response": "Pretty prints the table with the specified printer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the table rows.", "response": "def rows(self) -> List[List[str]]:\n        \"\"\"\n        Returns the table rows.\n        \"\"\"\n        return [list(d.values()) for d in self.data]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the size limit of a specific column.", "response": "def set_column_size_limit(self, column_name: str, size_limit: int):\n        \"\"\"\n        Sets the size limit of a specific column.\n\n        :param column_name: The name of the column to change.\n        :param size_limit: The max size of the column width.\n        \"\"\"\n        if self._column_size_map.get(column_name):\n            self._column_size_map[column_name] = size_limit\n        else:\n            raise ValueError(f'There is no column named {column_name}!')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_pretty_table(self, indent: int = 0, align: int = ALIGN_CENTER, border: bool = False) -> PrettyTable:\n        rows = self.rows\n        columns = self.columns\n        # Add the column color.\n        if self._headers_color != Printer.NORMAL and len(rows) > 0 and len(columns) > 0:\n            # We need to copy the lists so that we wont insert colors in the original ones.\n            rows[0] = rows[0][:]\n            columns = columns[:]\n            columns[0] = self._headers_color + columns[0]\n            # Write the table itself in NORMAL color.\n            rows[0][0] = Printer.NORMAL + str(rows[0][0])\n\n        table = PrettyTable(columns, border=border, max_width=get_console_width() - indent)\n        table.align = self._ALIGN_DICTIONARY[align]\n\n        for row in rows:\n            table.add_row(row)\n\n        # Set the max width according to the columns size dict, or by default size limit when columns were not provided.\n        for column, max_width in self._column_size_map.items():\n            table.max_width[column] = max_width\n\n        return table", "response": "Returns a PrettyTable object with the format of the scheme i. e. the table header and column headers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_as_html(self) -> str:\n        table_string = self._get_pretty_table().get_html_string()\n        title = ('{:^' + str(len(table_string.splitlines()[0])) + '}').format(self.title)\n        return f'<center><h1>{title}</h1></center>{table_string}'", "response": "Returns the table object as an HTML string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the table object as a CSV string.", "response": "def get_as_csv(self, output_file_path: Optional[str] = None) -> str:\n        \"\"\"\n        Returns the table object as a CSV string.\n\n        :param output_file_path: The output file to save the CSV to, or None.\n        :return: CSV representation of the table.\n        \"\"\"\n        output = StringIO() if not output_file_path else open(output_file_path, 'w')\n        try:\n            csv_writer = csv.writer(output)\n\n            csv_writer.writerow(self.columns)\n            for row in self.rows:\n                csv_writer.writerow(row)\n            output.seek(0)\n            return output.read()\n        finally:\n            output.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nscheduling an update of this object.", "response": "def schedule(self, when=None, action=None, **kwargs):\n        \"\"\"\n        Schedule an update of this object.\n\n        when: The date for the update.\n\n        action: if provided it will be looked up\n        on the implementing class and called with\n        **kwargs. If action is not provided each k/v pair\n        in kwargs will be set on self and then self\n        is saved.\n\n        kwargs: any other arguments you would like passed\n        for this change. Saved as a json object so must cleanly\n        serialize.\n        \"\"\"\n\n        # when is empty or passed, just save it now.\n        if not when or when <= timezone.now():\n            self.do_scheduled_update(action, **kwargs)\n        else:\n            ctype = ContentType.objects.get_for_model(self.__class__)\n            Schedule(\n                content_type=ctype,\n                object_args=self.get_scheduled_filter_args(),\n                when=when,\n                action=action,\n                json_args=kwargs\n            ).save()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_scheduled_update(self, action, **kwargs):\n\n        action = getattr(self, action, None)\n        if callable(action):\n            return action(**kwargs)\n        else:\n            for k, v in kwargs.items():\n                setattr(self, k, v)\n            self.save()", "response": "This method is called by the update_scheduled_action method of the class that performs the actual update."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_md5_hash(file_path):\n    checksum = hashlib.md5()\n    with open(file_path, 'rb') as f:\n        for chunk in iter(lambda: f.read(128 * checksum.block_size), b''):\n            checksum.update(chunk)\n    return checksum.hexdigest()", "response": "Calculate the MD5 hash for a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting this FileRecordSearch instance to a dict ready for serialization to JSON for use in the API.", "response": "def as_dict(self):\n        \"\"\"\n        Convert this FileRecordSearch to a dict, ready for serialization to JSON for use in the API.\n\n        :return:\n            Dict representation of this FileRecordSearch instance\n        \"\"\"\n        d = {}\n        _add_value(d, 'obstory_ids', self.obstory_ids)\n        _add_value(d, 'lat_min', self.lat_min)\n        _add_value(d, 'lat_max', self.lat_max)\n        _add_value(d, 'long_min', self.long_min)\n        _add_value(d, 'long_max', self.long_max)\n        _add_value(d, 'time_min', self.time_min)\n        _add_value(d, 'time_max', self.time_max)\n        _add_value(d, 'mime_type', self.mime_type)\n        _add_value(d, 'skip', self.skip)\n        _add_value(d, 'limit', self.limit)\n        _add_string(d, 'semantic_type', self.semantic_type)\n        _add_string(d, 'observation_type', self.observation_type)\n        _add_value(d, 'observation_id', self.observation_id)\n        _add_string(d, 'repository_fname', self.repository_fname)\n        _add_boolean(d, 'exclude_imported', self.exclude_imported)\n        _add_string(d, 'exclude_export_to', self.exclude_export_to)\n        d['meta'] = list((x.as_dict() for x in self.meta_constraints))\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_dict(d):\n        obstory_ids = _value_from_dict(d, 'obstory_ids')\n        lat_min = _value_from_dict(d, 'lat_min')\n        lat_max = _value_from_dict(d, 'lat_max')\n        long_min = _value_from_dict(d, 'long_min')\n        long_max = _value_from_dict(d, 'long_max')\n        time_min = _value_from_dict(d, 'time_min')\n        time_max = _value_from_dict(d, 'time_max')\n        mime_type = _string_from_dict(d, 'mime_type')\n        skip = _value_from_dict(d, 'skip', 0)\n        limit = _value_from_dict(d, 'limit', 100)\n        semantic_type = _string_from_dict(d, 'semantic_type')\n        observation_type = _string_from_dict(d, 'observation_type')\n        observation_id = _value_from_dict(d, 'observation_id')\n        repository_fname = _string_from_dict(d, 'repository_fname')\n        exclude_imported = _boolean_from_dict(d, 'exclude_imported')\n        exclude_export_to = _string_from_dict(d, 'exclude_export_to')\n        if 'meta' in d:\n            meta_constraints = list((MetaConstraint.from_dict(x) for x in d['meta']))\n        else:\n            meta_constraints = []\n        return FileRecordSearch(obstory_ids=obstory_ids, lat_min=lat_min, lat_max=lat_max, long_min=long_min,\n                                long_max=long_max, time_min=time_min, time_max=time_max, mime_type=mime_type,\n                                semantic_type=semantic_type,\n                                observation_type=observation_type,\n                                observation_id=observation_id, repository_fname=repository_fname,\n                                meta_constraints=meta_constraints, limit=limit, skip=skip,\n                                exclude_imported=exclude_imported,\n                                exclude_export_to=exclude_export_to)", "response": "Builds a new FileRecordSearch object from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef as_dict(self):\n        d = {}\n        _add_string(d, 'obstory_name', self.obstory_name)\n        _add_string(d, 'semantic_type', self.semantic_type)\n        _add_value(d, 'time_min', self.time_min)\n        _add_value(d, 'time_max', self.time_max)\n        _add_string(d, 'group_id', self.group_id)\n        _add_string(d, 'observation_id', self.observation_id)\n        _add_value(d, 'skip', self.skip)\n        _add_value(d, 'limit', self.limit)\n        d['meta'] = list((x.as_dict() for x in self.meta_constraints))\n        return d", "response": "Convert this ObservationGroupSearch instance to a dict ready for serialization to JSON for use in the API."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts this ObservatoryMetadataSearch instance to a dict ready for serialization to JSON for use in the API.", "response": "def as_dict(self):\n        \"\"\"\n        Convert this ObservatoryMetadataSearch to a dict, ready for serialization to JSON for use in the API.\n\n        :return:\n            Dict representation of this ObservatoryMetadataSearch instance\n        \"\"\"\n        d = {}\n        _add_value(d, 'obstory_ids', self.obstory_ids)\n        _add_string(d, 'field_name', self.field_name)\n        _add_value(d, 'lat_min', self.lat_min)\n        _add_value(d, 'lat_max', self.lat_max)\n        _add_value(d, 'long_min', self.long_min)\n        _add_value(d, 'long_max', self.long_max)\n        _add_value(d, 'time_min', self.time_min)\n        _add_value(d, 'time_max', self.time_max)\n        _add_string(d, 'item_id', self.item_id)\n        _add_value(d, 'skip', self.skip)\n        _add_value(d, 'limit', self.limit)\n        _add_boolean(d, 'exclude_imported', self.exclude_imported)\n        _add_string(d, 'exclude_export_to', self.exclude_export_to)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning number string date or unknown depending on the type of the value", "response": "def type(self):\n        \"\"\"Returns 'number', 'string', 'date' or 'unknown' based on the type of the value\"\"\"\n        if isinstance(self.value, numbers.Number):\n            return \"number\"\n        if isinstance(self.value, basestring):\n            return \"string\"\n        return \"unknown\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _data(self):\n        current_position = self.file.tell()\n        self.file.seek(self.position)\n        data = self.file.read(self.length)\n        self.file.seek(current_position)\n        if self.length % 2:\n            data += '\\x00' # Padding byte\n        return data", "response": "Read data from the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the first chunk with specified header and optional list type.", "response": "def find(self, header, list_type=None):\n        \"\"\"Find the first chunk with specified header and optional list type.\"\"\"\n        for chunk in self:\n            if chunk.header == header and (list_type is None or (header in\n                    list_headers and chunk.type == list_type)):\n                return chunk\n            elif chunk.header in list_headers:\n                try:\n                    result = chunk.find(header, list_type)\n                    return result\n                except chunk.NotFound:\n                    pass\n        if list_type is None:\n            raise self.NotFound('Chunk \\'{0}\\' not found.'.format(header))\n        else:\n            raise self.NotFound('List \\'{0} {1}\\' not found.'.format(header,\n                list_type))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_all(self, header, list_type=None):\n        found = []\n        for chunk in self:\n            if chunk.header == header and (not list_type or (header in\n                list_headers and chunk.type == list_type)):\n                found.append(chunk)\n        return found", "response": "Find all direct children with header and optional list type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing a child chunk with something else.", "response": "def replace(self, child, replacement):\n        \"\"\"Replace a child chunk with something else.\"\"\"\n        for i in range(len(self.chunks)):\n            if self.chunks[i] == child:\n                self.chunks[i] = replacement"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove a child element from the list.", "response": "def remove(self, child):\n        \"\"\"Remove a child element.\"\"\"\n        for i in range(len(self)):\n            if self[i] == child:\n                del self[i]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_data(data):\n        header, length = struct.unpack('4s<I', data[:8])\n        data = data[8:]\n        return RiffDataChunk(header, data)", "response": "Create a chunk from data including header and length bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_urls(self):\n        from django.conf.urls import patterns, url\n        from views import DashboardWelcomeView\n\n        urls = super(AdminMixin, self).get_urls()\n        del urls[0]\n        custom_url = patterns(\n            '',\n            url(r'^$', self.admin_view(DashboardWelcomeView.as_view()), name=\"index\")\n        )\n\n        return custom_url + urls", "response": "Add our dashboard view to the admin urlconf. Deleted the default index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef index_to_coordinate(dims):\n    _ = divmod  # SO WE KEEP THE IMPORT\n\n    num_dims = len(dims)\n    if num_dims == 0:\n        return _zero_dim\n\n    prod = [1] * num_dims\n    acc = 1\n    domain = range(0, num_dims)\n    for i in reversed(domain):\n        prod[i] = acc\n        acc *= dims[i]\n\n    commands = []\n    coords = []\n    for i in domain:\n        if i == num_dims - 1:\n            commands.append(\"\\tc\" + text_type(i) + \" = index\")\n        else:\n            commands.append(\"\\tc\" + text_type(i) + \", index = divmod(index, \" + text_type(prod[i]) + \")\")\n        coords.append(\"c\" + text_type(i))\n    output = None\n    if num_dims == 1:\n        code = (\n            \"def output(index):\\n\" +\n            \"\\n\".join(commands) + \"\\n\" +\n            \"\\treturn \" + coords[0] + \",\"\n        )\n    else:\n        code = (\n            \"def output(index):\\n\" +\n            \"\\n\".join(commands) + \"\\n\" +\n            \"\\treturn \" + \", \".join(coords)\n        )\n\n    exec(code)\n    return output", "response": "A function that maps an index to a coordinate."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngrouping the elements of the matrix into a list of tuples.", "response": "def groupby(self, io_select):\n        \"\"\"\n        SLICE THIS MATRIX INTO ONES WITH LESS DIMENSIONALITY\n        io_select - 1 IF GROUPING BY THIS DIMENSION, 0 IF FLATTENING\n        return -\n        \"\"\"\n\n        # offsets WILL SERVE TO MASK DIMS WE ARE NOT GROUPING BY, AND SERVE AS RELATIVE INDEX FOR EACH COORDINATE\n        offsets = []\n        new_dim = []\n        acc = 1\n        for i, d in reversed(enumerate(self.dims)):\n            if not io_select[i]:\n                new_dim.insert(0, d)\n            offsets.insert(0, acc * io_select[i])\n            acc *= d\n\n        if not new_dim:\n            # WHEN groupby ALL DIMENSIONS, ONLY THE VALUES REMAIN\n            # RETURN AN ITERATOR OF PAIRS (c, v), WHERE\n            # c - COORDINATES INTO THE CUBE\n            # v - VALUE AT GIVEN COORDINATES\n            return ((c, self[c]) for c in self._all_combos())\n        else:\n            output = [[None, Matrix(dims=new_dim)] for i in range(acc)]\n            _groupby(self.cube, 0, offsets, 0, output, tuple(), [])\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef forall(self, method):\n        for c in self._all_combos():\n            method(self[c], c, self.cube)", "response": "A method that accepts all the keys and values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef items(self):\n        for c in self._all_combos():\n            _, value = _getitem(self.cube, c)\n            yield c, value", "response": "Iterate over all the keys and values of the current instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nyielding all the possible combinations of the keys in the current object.", "response": "def _all_combos(self):\n        \"\"\"\n        RETURN AN ITERATOR OF ALL COORDINATES\n        \"\"\"\n        combos = _product(self.dims)\n        if not combos:\n            return\n\n        calc = [(coalesce(_product(self.dims[i+1:]), 1), mm) for i, mm in enumerate(self.dims)]\n\n        for c in xrange(combos):\n            yield tuple(int(c / dd) % mm for dd, mm in calc)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npublish a pulse message to the proper exchange.", "response": "def send(self, topic, message):\n        \"\"\"Publishes a pulse message to the proper exchange.\"\"\"\n\n        if not message:\n            Log.error(\"Expecting a message\")\n\n        message._prepare()\n\n        if not self.connection:\n            self.connect()\n\n        producer = Producer(\n            channel=self.connection,\n            exchange=Exchange(self.settings.exchange, type='topic'),\n            routing_key=topic\n        )\n\n        # The message is actually a simple envelope format with a payload and\n        # some metadata.\n        final_data = Data(\n            payload=message.data,\n            _meta=set_default({\n                'exchange': self.settings.exchange,\n                'routing_key': message.routing_key,\n                'serializer': self.settings.serializer,\n                'sent': time_to_string(datetime.datetime.now(timezone(self.settings.broker_timezone))),\n                'count': self.count\n            }, message.metadata)\n        )\n\n        producer.publish(jsons.scrub(final_data), serializer=self.settings.serializer)\n        self.count += 1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a child to the tree.", "response": "def add_child(self, child):\n        \"\"\"\n        Add a child to the tree. Extends discards all comments\n        and whitespace Text. On non-whitespace Text, and any\n        other nodes, raise a syntax error.\n        \"\"\"\n\n        if isinstance(child, Comment):\n            return\n\n        # ignore Text nodes with whitespace-only content\n        if isinstance(child, Text) and not child.text.strip():\n            return\n\n        super(Extends, self).add_child(child)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nquery the database for the given command.", "response": "def query(self, command):\n        \"\"\"\n        WILL BLOCK CALLING THREAD UNTIL THE command IS COMPLETED\n        :param command: COMMAND FOR SQLITE\n        :return: list OF RESULTS\n        \"\"\"\n        if self.closed:\n            Log.error(\"database is closed\")\n\n        signal = _allocate_lock()\n        signal.acquire()\n        result = Data()\n        trace = extract_stack(1) if self.get_trace else None\n\n        if self.get_trace:\n            current_thread = Thread.current()\n            with self.locker:\n                for t in self.available_transactions:\n                    if t.thread is current_thread:\n                        Log.error(DOUBLE_TRANSACTION_ERROR)\n\n        self.queue.add(CommandItem(command, result, signal, trace, None))\n        signal.acquire()\n\n        if result.exception:\n            Log.error(\"Problem with Sqlite call\", cause=result.exception)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef close(self):\n        self.closed = True\n        signal = _allocate_lock()\n        signal.acquire()\n        self.queue.add(CommandItem(COMMIT, None, signal, None, None))\n        signal.acquire()\n        self.worker.please_stop.go()\n        return", "response": "Closes the current session."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving and fully evaluate the next export task.", "response": "def handle_next_export(self):\n        \"\"\"\n        Retrieve and fully evaluate the next export task, including resolution of any sub-tasks requested by the\n        import client such as requests for binary data, observation, etc.\n\n        :return:\n            An instance of ExportStateCache, the 'state' field contains the state of the export after running as many\n            sub-tasks as required until completion or failure. If there were no jobs to run this returns None.\n\n                :complete:\n                    A job was processed and completed. The job has been marked as complete in the database\n                :continue:\n                    A job was processed, more information was requested and sent, but the job is still active\n                :failed:\n                    A job was processed but an error occurred during processing\n                :confused:\n                    A job was processed, but the importer returned a response which we couldn't recognise\n        \"\"\"\n        state = None\n        while True:\n            state = self._handle_next_export_subtask(export_state=state)\n            if state is None:\n                return None\n            elif state.export_task is None:\n                return state"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprocess the next export sub - task.", "response": "def _handle_next_export_subtask(self, export_state=None):\n        \"\"\"\n        Process the next export sub-task, if there is one.\n\n        :param ExportState export_state:\n            If provided, this is used instead of the database queue, in effect directing the exporter to process the\n            previous export again. This is used to avoid having to query the database when we know already what needs\n            to be done. It also maintains a cache of the entity so we don't have to re-acquire it on multiple exports.\n        :return:\n            A :class:`meteorpi_db.exporter.MeteorExporter.ExportStateCache` representing the state of the export, or\n            None if there was nothing to do.\n        \"\"\"\n        # Use a cached state, or generate a new one if required\n        if export_state is None or export_state.export_task is None:\n            export = self.db.get_next_entity_to_export()\n            if export is not None:\n                export_state = self.ExportState(export_task=export)\n            else:\n                return None\n        try:\n            auth = (export_state.export_task.target_user,\n                    export_state.export_task.target_password)\n            target_url = export_state.export_task.target_url\n            response = post(url=target_url, verify=False,\n                            json=export_state.entity_dict,\n                            auth=auth)\n            response.raise_for_status()\n            json = response.json()\n            state = json['state']\n            if state == 'complete':\n                return export_state.fully_processed()\n            elif state == 'need_file_data':\n                file_id = json['file_id']\n                file_record = self.db.get_file(repository_fname=file_id)\n                if file_record is None:\n                    return export_state.failed()\n                with open(self.db.file_path_for_id(file_id), 'rb') as file_content:\n                    multi = MultipartEncoder(fields={'file': ('file', file_content, file_record.mime_type)})\n                    post(url=\"{0}/data/{1}/{2}\".format(target_url, file_id, file_record.file_md5),\n                         data=multi, verify=False,\n                         headers={'Content-Type': multi.content_type},\n                         auth=auth)\n                return export_state.partially_processed()\n            elif state == 'continue':\n                return export_state.partially_processed()\n            else:\n                return export_state.confused()\n        except HTTPError:\n            traceback.print_exc()\n            return export_state.failed()\n        except ConnectionError:\n            traceback.print_exc()\n            return export_state.failed()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract options from a dictionary against the template", "response": "def extract_options_dict(template, options):\n    \"\"\"Extract options from a dictionary against the template\"\"\"\n    for option, val in template.items():\n        if options and option in options:\n            yield option, options[option]\n        else:\n            yield option, Default(template[option]['default'](os.environ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmodifies the headers of a Mach - O file at the given path by calling the modificator function on each header.", "response": "def modify_macho_file_headers(macho_file_path, modificator_func):\n\t\"\"\" Modifies headers of a Mach-O file at the given path by calling\n\tthe modificator function on each header.\n\t\n\tReturns True on success, otherwise rises an exeption (e.g. from macholib)\n\t\"\"\"\n\tif not os.path.isfile(macho_file_path):\n\t\traise Exception(\"You must specify a real executable path as a target\")\n\t\treturn False\n\t\t\n\tm = MachO(macho_file_path)\n\tapply_to_headers(m, modificator_func)\n\tsave_macho(m, macho_file_path)\n\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef backup(self, backup_name, folder_key=None, folder_name=None):\r\n\r\n        folder = self._find_or_create_folder(folder_key, folder_name)\r\n        drive_service = self.drive_service\r\n        try:\r\n            source_rsrc = drive_service.files().get(fileId=self.document_key).execute()\r\n        except Exception, e:\r\n            logger.exception(\"Google API error. %s\", e)\r\n            raise e\r\n\r\n        backup = self._create_new_or_copy(source_doc=source_rsrc, \r\n                                        target_name=backup_name, \r\n                                        folder=folder,\r\n                                        sheet_description=\"backup\")\r\n\r\n        backup_key = backup['id']\r\n        return backup_key", "response": "Copies the google spreadsheet to the backup_name and folder specified."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the worksheet and returns a dictionary of the most recent related key - tuple objects.", "response": "def data(self, as_cells=False):\r\n        \"\"\" Reads the worksheet and returns an indexed dictionary of the\r\n        row objects.\r\n        \r\n        For example:\r\n\r\n        >>>print sheet.data()\r\n\r\n        {'Miss Piggy': {'Color': 'Pink', 'Performer': 'Frank Oz'}, 'Kermit': {'Color': 'Green', 'Performer': 'Jim Henson'}} \r\n        \r\n        \"\"\"\r\n        sheet_data = {}\r\n        self.max_row = max(self.header_row_ix, self.formula_ref_row_ix)\r\n        all_cells = self._cell_feed(row=self.max_row+1,\r\n                                    further_rows=True,\r\n                                    col=self.header.first_column,\r\n                                    max_col=self.header.last_column,\r\n                                    return_empty=True)\r\n\r\n        for wks_row in self._yield_rows(all_cells):\r\n            if wks_row.row_num not in sheet_data and not wks_row.is_empty():\r\n                sheet_data[wks_row.row_num] = wks_row\r\n\r\n        all_rows = sheet_data.keys()\r\n        if all_rows:\r\n            self.max_row = max(all_rows)\r\n\r\n        # Now index by key_tuple\r\n        indexed_sheet_data = {}\r\n        for row, wks_row in sheet_data.iteritems():\r\n            # Make the key tuple\r\n            if len(self.key_column_headers) == 0:\r\n                # Are there any default key column headers?\r\n                if \"Key\" in wks_row:\r\n                    logger.info(\"Assumed key column's header is 'Key'\")\r\n                    self.key_column_headers = ['Key']\r\n                elif \"Key-1\" in wks_row:\r\n                    self.key_column_headers = [h for h in wks_row.keys() \r\n                        if h.startswith(\"Key-\") and h.split(\"-\")[1].isdigit()]\r\n                    logger.info(\"Assumed key column headers were: %s\",\r\n                                self.key_column_headers)\r\n                else:\r\n                    raise Exception(\"Unable to read spreadsheet. Specify\"\r\n                        \"key_column_headers when initializing Sheet object.\")\r\n\r\n            key_list = []\r\n            for key_hdr in self.key_column_headers:\r\n                key_val = wks_row.db.get(key_hdr,\"\")\r\n                if key_val.startswith(\"'\"):\r\n                    key_val = key_val[1:]\r\n                key_list.append(key_val)\r\n            key_tuple = tuple(key_list)\r\n            if all(k == \"\" for k in key_tuple):\r\n                continue\r\n\r\n            if as_cells:\r\n                indexed_sheet_data[key_tuple] = wks_row\r\n            else:\r\n                if len(key_tuple) == 1:\r\n                    key_tuple = key_tuple[0]\r\n                indexed_sheet_data[key_tuple] = wks_row.db\r\n\r\n        return indexed_sheet_data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inject(self, raw_data, row_change_callback=None):\r\n        return self._update(raw_data, row_change_callback, delete_rows=False)", "response": "Adds or updates rows in the same spreadsheet."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_module_function(obj, prop):\n    python_version = sys.version_info[0]\n    if python_version == 3:\n        unicode = str\n\n    if prop and (isinstance(prop, str) or isinstance(prop, unicode)): #property\n        if prop in dir(obj):\n            if (\n                    isinstance(getattr(obj, prop), FunctionType)\n                    or isinstance(getattr(obj, prop), BuiltinFunctionType)\n                    or inspect.ismethod(getattr(obj, prop))\n            ):\n            #inspect.ismethod for python2.7\n            #isinstance(...) for python3.x\n                return True\n            else:\n                ErrorHandler.prop_is_func_error(obj, prop)\n        else:\n            ErrorHandler.prop_in_obj_error(obj, prop)\n    elif prop:\n        ErrorHandler.prop_type_error(prop)\n    return False", "response": "Checks if the property is a module function"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks and setting type to MODULE", "response": "def is_module(obj):\n    \"\"\"\n    Checking and setting type to MODULE\n    Args:\n        obj: ModuleType / class\n        Note: An instance will be treated as a Class\n    Return:\n        Boolean\n    \"\"\"\n    return True if obj and isinstance(obj, ModuleType) or inspect.isclass(obj) else False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_apps(cls, apps):\n        \"Takes in an Apps and returns a VersionedProjectState matching it\"\n        app_models = {}\n        for model in apps.get_models(include_swapped=True):\n            model_state = VersionedModelState.from_model(model)\n            app_models[(model_state.app_label, model_state.name.lower())] = model_state\n        return cls(app_models)", "response": "Takes in an Apps and returns a VersionedProjectState matching it"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrenders the data to HTML using Django s standard template rendering.", "response": "def render(self, data, accepted_media_type=None, renderer_context=None):\n        \"\"\"\n        Renders data to HTML, using Django's standard template rendering.\n\n        The template name is determined by (in order of preference):\n\n        1. An explicit .template_name set on the response.\n        2. An explicit .template_name set on this class.\n        3. The return result of calling view.get_template_names().\n        \"\"\"\n        renderer_context = renderer_context or {}\n        view = renderer_context['view']\n        request = renderer_context['request']\n        response = renderer_context['response']\n        extra_context = renderer_context['extra_context']\n        obj = view.get_object()\n\n        if response.exception:\n            template = self.get_exception_template(response)\n        else:\n            template_names = self.get_template_names(response, view)\n            template = self.resolve_template(template_names)\n\n        context = self.resolve_context(data, request, response)\n\n        if response.exception:\n            # If there is an exception don't bother calculating data or geometries\n            context.update({'template_extra_context': extra_context})\n            return template.render(context)\n\n        new_data = {\n            \"type\": \"FeatureCollection\",\n        }\n\n        features = []\n\n        self.setup_icons_dict()\n\n        try:\n            popup_template = Template(getattr(obj, 'popup_template', None))\n        except TemplateSyntaxError as exception:\n            popup_template = Template(exception)\n\n        try:\n            marker_template = Template(getattr(obj, 'marker_template', None))\n        except TemplateSyntaxError as exception:\n            marker_template = Template(exception)\n\n        if isinstance(data, dict):\n            features.append(self.process_feature(data, popup_template, marker_template))\n        else:\n            for feature in data:\n                features.append(self.process_feature(feature, popup_template, marker_template))\n\n        new_data['features'] = features\n        if 'latitude' and 'longitude' not in extra_context:\n            # User didn't specified which latitude and longitude to move the map,\n            # determine where to move the map ourselves\n            try:\n                extra_context['extents'] = self.determine_extents(features)\n            except (StopIteration, BoundsError):\n                pass\n\n        ret = json.dumps(new_data, cls=self.encoder_class, ensure_ascii=True)\n\n        # On python 2.x json.dumps() returns bytestrings if ensure_ascii=True,\n        # but if ensure_ascii=False, the return type is underspecified,\n        # and may (or may not) be unicode.\n        # On python 3.x json.dumps() returns unicode strings.\n        if isinstance(ret, six.text_type):\n            ret = bytes(ret.encode(self.charset))\n\n        context.update({'data': ret, 'markers': obj.markers, 'header': obj.template_header})\n\n        if 'geometry' in extra_context:\n            extra_context['geometry'] = json.dumps(extra_context['geometry'].__geo_interface__)\n\n        context.update({'template_extra_context': extra_context})\n\n        return template.render(context)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching assets by passing a list of one or more tags.", "response": "def search_tags(self, tags):\n        \"\"\"\n        Search assets by passing a list of one or more tags.\n        \"\"\"\n        qs = self.filter(tags__name__in=tags).order_by('file').distinct()\n        return qs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the m2m relationships of the current object to the new ones.", "response": "def _set_m2ms(self, old_m2ms):\n        \"\"\"\n        Creates the same m2m relationships that the old\n        object had.\n        \"\"\"\n\n        for k, v in old_m2ms.items():\n            if v:\n                setattr(self, k, v)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclone all the objects that were previously gathered.", "response": "def _clone_reverses(self, old_reverses):\n        \"\"\"\n        Clones all the objects that were previously gathered.\n        \"\"\"\n\n        for ctype, reverses in old_reverses.items():\n            for parts in reverses.values():\n                sub_objs = parts[1]\n                field_name = parts[0]\n\n                attrs = {}\n                for sub_obj in sub_objs:\n                    if ctype != 'm2m' and not attrs:\n                        field = sub_obj._meta.get_field(field_name)\n                        attrs = {\n                            field.column: getattr(self, field.rel.field_name)\n                        }\n                    sub_obj._clone(**attrs)\n\n                if ctype == 'm2m':\n                    setattr(self, field_name, sub_objs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking a copy of an instance of the current object.", "response": "def _clone(self, **attrs):\n        \"\"\"\n        Makes a copy of an model instance.\n\n        for every key in **attrs value will\n        be set on the new instance.\n        \"\"\"\n\n        with xact():\n            # Gather objs we'll need save after\n            old_m2ms = self._gather_m2ms()\n            old_reverses = self._gather_reverses()\n\n            for k, v in attrs.items():\n                setattr(self, k, v)\n\n            # Do the clone\n            self.prep_for_clone()\n            self.validate_unique()\n            # Prevent last save from changing\n            self.save(last_save=self.last_save)\n\n            # save m2ms\n            self._set_m2ms(old_m2ms)\n            # Prevent last save from changing\n            self.save(last_save=self.last_save)\n\n            # save reverses\n            self._clone_reverses(old_reverses)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _delete_reverses(self):\n\n        for reverse in self.clone_related:\n            self._delete_reverse(reverse)\n\n        for field in self._meta.local_many_to_many:\n            if field.rel.through and \\\n                    field.rel.through._meta.auto_created and not \\\n                    field.name in self.clone_related:\n                man = getattr(self, field.name)\n                man.clear()", "response": "Delete all objects that would have been cloned by another command."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes clonable relations first, since they may be objects that wouldn't otherwise be deleted. Calls super to actually delete the object.", "response": "def delete(self, *args, **kwargs):\n        \"\"\"\n        Delete clonable relations first, since they may be\n        objects that wouldn't otherwise be deleted.\n\n        Calls super to actually delete the object.\n        \"\"\"\n        skip_reverses = kwargs.pop('skip_reverses', False)\n        if not skip_reverses:\n            self._delete_reverses()\n\n        return super(Cloneable, self).delete(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving the object to the database.", "response": "def save(self, *args, **kwargs):\n        \"\"\"\n        Takes an optional last_save keyword argument\n        other wise last_save will be set to timezone.now()\n\n        Calls super to actually save the object.\n        \"\"\"\n        self.last_save = kwargs.pop('last_save', timezone.now())\n        super(Cloneable, self).save(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_related(cls, related_name):\n\n        if not hasattr(cls, '_clone_related'):\n            cls._clone_related = []\n\n        if type(cls._clone_related) != type([]):\n            cls._clone_related = list(cls._clone_related)\n\n        if not related_name in cls._clone_related:\n            cls._clone_related.append(related_name)", "response": "Register a related item that should be cloned\n            when this model is set."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_to_class(cls, name, value):\n        if name == '_base_manager':\n            if not value.name:\n                value.name = name\n            value.model = cls\n            setattr(cls._meta, 'base_manager_name', 'normal')\n        else:\n            super(VersionModelMeta, cls).add_to_class(name, value)", "response": "Add a new version to the class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_version(self, state=None, date=None):\n\n        version_model = self._meta._version_model\n        q = version_model.objects.filter(object_id=self.pk)\n        if state:\n            q = version_model.normal.filter(object_id=self.pk, state=state)\n\n        if date:\n            q = q.filter(date_published__lte=date)\n\n        q = q.order_by('-date_published')\n\n        results = q[:1]\n        if results:\n            return results[0]\n        return None", "response": "Get a particular version of an item."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npublish a item and any sub items.", "response": "def publish(self, user=None, when=None):\n        \"\"\"\n        Publishes a item and any sub items.\n        A new transaction will be started if\n        we aren't already in a transaction.\n\n        Should only be run on draft items\n        \"\"\"\n\n        assert self.state == self.DRAFT\n\n        user_published = 'code'\n        if user:\n            user_published = user.username\n\n        now = timezone.now()\n\n        with xact():\n            # If this item hasn't got live yet and no new date was specified\n            # delete the old scheduled items and schedule this one on that date\n            published = False\n            if getattr(self._meta, '_is_view', False):\n                published = self.is_published\n            else:\n                published = self.object.is_published\n\n            if not when and not published and self.last_scheduled:\n                klass = self.get_version_class()\n                for obj in klass.normal.filter(object_id=self.object_id,\n                                               last_scheduled=self.last_scheduled,\n                                               state=self.SCHEDULED):\n                    when = self.date_published\n                    obj.delete()\n\n            when = when or now\n\n            # Drafts get preserved so save the\n            # time we last cloned this\n            if self.state == self.DRAFT:\n                self.last_scheduled = now\n                self.date_published = when\n                self.save(last_save=now)\n\n            self._clone()\n\n            self.user_published = user_published\n            self.state = self.SCHEDULED\n            self.save()\n\n            self.schedule(when=when)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes this version the draft", "response": "def make_draft(self):\n        \"\"\"\n        Make this version the draft\n        \"\"\"\n        assert self.__class__ == self.get_version_class()\n\n        # If this is draft do nothing\n        if self.state == self.DRAFT:\n            return\n\n        with xact():\n            # Delete whatever is currently this draft\n            try:\n                klass = self.get_version_class()\n                old_draft = klass.normal.get(object_id=self.object_id,\n                                             state=self.DRAFT)\n                old_draft.delete()\n            except klass.DoesNotExist:\n                pass\n\n            # Set this to draft and save\n            self.state = self.DRAFT\n            # Make last_scheduled and last save match on draft\n            self.last_save = self.last_scheduled\n            self._clone()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes older archived items.", "response": "def purge_archives(self):\n        \"\"\"\n        Delete older archived items.\n\n        Use the class attribute NUM_KEEP_ARCHIVED to control\n        how many items are kept.\n        \"\"\"\n\n        klass = self.get_version_class()\n        qs = klass.normal.filter(object_id=self.object_id,\n                                 state=self.ARCHIVED).order_by('-last_save')[self.NUM_KEEP_ARCHIVED:]\n\n        for obj in qs:\n            obj._delete_reverses()\n            klass.normal.filter(vid=obj.vid).delete()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef status_line(self):\n\n        date = self.date_published\n        status = self.state.title()\n        if self.state == self.DRAFT:\n            # Check if this item has changed since\n            # our last publish\n            status = \"Draft saved\"\n            date = self.last_save\n            if date and self.last_save == self.last_scheduled:\n                # We need to figure out if the item it is based on\n                # is either live now or will be live at some point.\n\n                # If last_scheduled is less than or equal to\n                # v_last_save this item is or will go live\n                # at some point. Otherwise it won't\n                # so we'll leave state as draft.\n                if self.v_last_save:\n                    if self.last_scheduled >= self.v_last_save:\n                        status = self.PUBLISHED.title()\n\n                    # The date this was scheduled is greater than\n                    # what is currently live, this will go live at\n                    # some point\n                    if self.last_scheduled > self.v_last_save:\n                        status = \"Publish Scheduled\"\n                else:\n                    status = \"Publish Scheduled\"\n\n                date = self.date_published\n\n        if date:\n            status = \"%s: %s\" % (status, formats.date_format(date, \"SHORT_DATE_FORMAT\"))\n        return status", "response": "Returns a status line for an item."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef schedule(self, when=None, action=None, **kwargs):\n        action = '_publish'\n        super(BaseVersionedModel, self).schedule(when=when, action=action,\n                                                 **kwargs)", "response": "Schedule this item to be published."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_unique(self, *args, **kwargs):\n\n        super(BaseVersionedModel, self).validate_unique(*args, **kwargs)\n        if hasattr(self, 'versioned_unique'):\n            unique_checks = []\n            for field in self.versioned_unique:\n                unique_checks.append((self.__class__, (field,)))\n            errors = self._perform_unique_checks(unique_checks)\n\n            if errors:\n                raise ValidationError(errors)", "response": "Validate that the item with the given name is unique."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_unique(self, *args, **kwargs):\n\n        super(BaseVersionedModel, self).validate_unique(*args, **kwargs)\n        if hasattr(self, 'versioned_unique'):\n            errors = {}\n\n            for field in self.versioned_unique:\n                lookup_kwargs = {field: getattr(self, field)}\n                qs = self.__class__._default_manager.filter(**lookup_kwargs)\n\n                # Exclude the current object from the query if we are editing\n                # an instance (as opposed to creating a new one)\n                if self.object_id:\n                    qs = qs.exclude(object_id=self.object_id)\n\n                if qs.exists():\n                    msg = self.unique_error_message(self.__class__, (field,))\n                    errors[field] = msg\n\n            if errors:\n                raise ValidationError(errors)", "response": "Checks that the item with the given name is unique."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave this item. Creates a default base if there isn't one already.", "response": "def save(self, *args, **kwargs):\n        \"\"\"\n        Saves this item.\n\n        Creates a default base if there isn't\n        one already.\n        \"\"\"\n        with xact():\n            if not self.vid:\n                self.state = self.DRAFT\n\n                if not self.object_id:\n                    base = self._meta._base_model(is_published=False)\n                    base.save(*args, **kwargs)\n                    self.object = base\n\n            super(VersionModel, self).save(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef slugify(text, delim='-'):\n    result = []\n    for word in _punct_re.split((text or '').lower()):\n        result.extend(codecs.encode(word, 'ascii', 'replace').split())\n    return delim.join([str(r) for r in result])", "response": "Generate an ASCII - only slug."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn search query parser.", "response": "def parser():\n    \"\"\"Return search query parser.\"\"\"\n    query_parser = current_app.config['COLLECTIONS_QUERY_PARSER']\n    if isinstance(query_parser, six.string_types):\n        query_parser = import_string(query_parser)\n        return query_parser"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn query walker instances.", "response": "def query_walkers():\n    \"\"\"Return query walker instances.\"\"\"\n    return [\n        import_string(walker)() if isinstance(walker, six.string_types)\n        else walker() for walker in current_app.config[\n            'COLLECTIONS_QUERY_WALKERS']\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pad(cls, data):\n        if sys.version_info > (3, 0):\n            try:\n                data = data.encode(\"utf-8\")\n            except AttributeError:\n                pass\n\n            length = AES.block_size - (len(data) % AES.block_size)\n            data += bytes([length]) * length\n            return data\n        else:\n            return data + (AES.block_size - len(data) % AES.block_size) * chr(AES.block_size - len(data) % AES.block_size)", "response": "Pads data to match AES block size"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nencrypt raw data using AES and then base64 encodes it.", "response": "def encrypt(self, raw):\n        \"\"\"\n        Encrypts raw data using AES and then base64 encodes it.\n        :param raw:\n        :return:\n        \"\"\"\n        padded = AESCipher.pad(raw)\n        init_vec = Random.new().read(AES.block_size)\n        cipher = AES.new(self._key, AES.MODE_CBC, init_vec)\n        return b64encode(init_vec + cipher.encrypt(padded))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef simple_locking(lock_id, expiration=None):\n    def inner_decorator(function):\n        def wrapper(*args, **kwargs):\n            try:\n                # Trying to acquire lock\n                lock = Lock.acquire_lock(lock_id, expiration)\n            except LockError:\n                # Unable to acquire lock - non fatal\n                pass\n            else:\n                # Lock acquired, proceed normally, release lock afterwards\n                logger.debug('acquired lock: %s' % lock_id)\n                try:\n                    return function(*args, **kwargs)\n                except:\n                    # Re raise any exception that occured when calling wrapped\n                    # function\n                    raise\n                finally:\n                    lock.release()\n        return wraps(function)(wrapper)\n    return inner_decorator", "response": "A decorator that makes a function in a single lock getting algorithm\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fix(source_key, rownum, line, source, sample_only_filter, sample_size):\n    value = json2value(line)\n\n    if rownum == 0:\n        if len(line) > MAX_RECORD_LENGTH:\n            _shorten(source_key, value, source)\n        value = _fix(value)\n        if sample_only_filter and Random.int(int(1.0/coalesce(sample_size, 0.01))) != 0 and jx.filter([value], sample_only_filter):\n            # INDEX etl.id==0, BUT NO MORE\n            if value.etl.id != 0:\n                Log.error(\"Expecting etl.id==0\")\n            row = {\"value\": value}\n            return row, True\n    elif len(line) > MAX_RECORD_LENGTH:\n        _shorten(source_key, value, source)\n        value = _fix(value)\n    elif '\"resource_usage\":' in line:\n        value = _fix(value)\n\n    row = {\"value\": value}\n    return row, False", "response": "Fixes the data structure of a single resource in a single resource in a single resource in a single resource in a single resource in a single resource in a single resource."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy(self, keys, source, sample_only_filter=None, sample_size=None, done_copy=None):\n        num_keys = 0\n        queue = None\n        pending = []  # FOR WHEN WE DO NOT HAVE QUEUE YET\n        for key in keys:\n            timer = Timer(\"Process {{key}}\", param={\"key\": key}, silent=not DEBUG)\n            try:\n                with timer:\n                    for rownum, line in enumerate(source.read_lines(strip_extension(key))):\n                        if not line:\n                            continue\n\n                        if rownum > 0 and rownum % 1000 == 0:\n                            Log.note(\"Ingested {{num}} records from {{key}} in bucket {{bucket}}\", num=rownum, key=key, bucket=source.name)\n\n                        insert_me, please_stop = fix(key, rownum, line, source, sample_only_filter, sample_size)\n                        if insert_me == None:\n                            continue\n                        value = insert_me['value']\n\n                        if '_id' not in value:\n                            Log.warning(\"expecting an _id in all S3 records. If missing, there can be duplicates\")\n\n                        if queue == None:\n                            queue = self._get_queue(insert_me)\n                            if queue == None:\n                                pending.append(insert_me)\n                                if len(pending) > 1000:\n                                    if done_copy:\n                                        done_copy()\n                                    Log.error(\"first 1000 (key={{key}}) records for {{alias}} have no indication what index to put data\", key=tuple(keys)[0], alias=self.settings.index)\n                                continue\n                            elif queue is DATA_TOO_OLD:\n                                break\n                            if pending:\n                                queue.extend(pending)\n                                pending = []\n\n                        num_keys += 1\n                        queue.add(insert_me)\n\n                        if please_stop:\n                            break\n            except Exception as e:\n                if KEY_IS_WRONG_FORMAT in e:\n                    Log.warning(\"Could not process {{key}} because bad format. Never trying again.\", key=key, cause=e)\n                    pass\n                elif CAN_NOT_DECODE_JSON in e:\n                    Log.warning(\"Could not process {{key}} because of bad JSON. Never trying again.\", key=key, cause=e)\n                    pass\n                else:\n                    Log.warning(\"Could not process {{key}} after {{duration|round(places=2)}}seconds\", key=key, duration=timer.duration.seconds, cause=e)\n                    done_copy = None\n\n        if done_copy:\n            if queue == None:\n                done_copy()\n            elif queue is DATA_TOO_OLD:\n                done_copy()\n            else:\n                queue.add(done_copy)\n\n        if [p for p in pending if wrap(p).value.task.state not in ('failed', 'exception')]:\n            Log.error(\"Did not find an index for {{alias}} to place the data for key={{key}}\", key=tuple(keys)[0], alias=self.settings.index)\n\n        Log.note(\"{{num}} keys from {{key|json}} added\", num=num_keys, key=keys)\n        return num_keys", "response": "Copy the data from one bucket to another."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets host and port settings from the environment.", "response": "def from_env():\n    \"\"\"Get host/port settings from the environment.\"\"\"\n    if 'MICROMONGO_URI' in os.environ:\n        return (os.environ['MICROMONGO_URI'],)\n    host = os.environ.get('MICROMONGO_HOST', 'localhost')\n    port = int(os.environ.get('MICROMONGO_PORT', 27017))\n    return (host, port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef order_by(self, *fields):\n        doc = []\n        for field in fields:\n            if field.startswith('-'):\n                doc.append((field.strip('-'), pymongo.DESCENDING))\n            else:\n                doc.append((field, pymongo.ASCENDING))\n        return self.sort(doc)", "response": "An alternate to sort which allows you to specify a list\n of fields and use a leading - minus ASCENDING."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef next(self):\n        if self.__tailable:\n            return PymongoCursor.next(self)\n        try:\n            ret = PymongoCursor.next(self)\n        except StopIteration:\n            self.__fullcache = True\n            raise\n        self.__itercache.append(ret)\n        return ret", "response": "A next that caches the returned results."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef adjust_locations(ast_node, first_lineno, first_offset):\n\n    line_delta = first_lineno - 1\n\n    def _fix(node):\n        if 'lineno' in node._attributes:\n            lineno = node.lineno\n            col = node.col_offset\n\n            # adjust the offset on the first line\n            if lineno == 1:\n                col += first_offset\n\n            lineno += line_delta\n\n            node.lineno = lineno\n            node.col_offset = col\n\n        for child in iter_child_nodes(node):\n            _fix(child)\n\n    _fix(ast_node)", "response": "Adjust the locations of the nodes in the tree to the new lineno and column offset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncoalesce the constant output expressions into the output of the tree.", "response": "def coalesce_outputs(tree):\n    \"\"\"\n    Coalesce the constant output expressions\n\n        __output__('foo')\n        __output__('bar')\n        __output__(baz)\n        __output__('xyzzy')\n\n    into\n\n        __output__('foobar', baz, 'xyzzy')\n    \"\"\"\n\n    coalesce_all_outputs = True\n    if coalesce_all_outputs:\n        should_coalesce = lambda n: True\n    else:\n        should_coalesce = lambda n: n.output_args[0].__class__ is Str\n\n    class OutputCoalescer(NodeVisitor):\n        def visit(self, node):\n            # if - else expression also has a body! it is not we want, though.\n            if hasattr(node, 'body') and isinstance(node.body, Iterable):\n                # coalesce continuous string output nodes\n                new_body = []\n                output_node = None\n\n                def coalesce_strs():\n                    if output_node:\n                        output_node.value.args[:] = \\\n                            coalesce_strings(output_node.value.args)\n\n                for i in node.body:\n                    if hasattr(i, 'output_args') and should_coalesce(i):\n                        if output_node:\n                            if len(output_node.value.args) + len(i.output_args) > 250:\n                                coalesce_strs()\n                                output_node = i\n                            else:\n                                output_node.value.args.extend(i.output_args)\n                                continue\n\n                        output_node = i\n\n                    else:\n                        coalesce_strs()\n                        output_node = None\n\n                    new_body.append(i)\n\n                coalesce_strs()\n                node.body[:] = new_body\n\n            NodeVisitor.visit(self, node)\n\n        def check(self, node):\n            \"\"\"\n            Coalesce __TK__output(__TK__escape(literal(x))) into\n            __TK__output(x).\n            \"\"\"\n            if not ast_equals(node.func, NameX('__TK__output')):\n                return\n\n            for i in range(len(node.args)):\n                arg1 = node.args[i]\n                if not arg1.__class__.__name__ == 'Call':\n                    continue\n\n                if not ast_equals(arg1.func, NameX('__TK__escape')):\n                    continue\n\n                if len(arg1.args) != 1:\n                    continue\n\n                arg2 = arg1.args[0]\n                if not arg2.__class__.__name__ == 'Call':\n                    continue\n\n                if not ast_equals(arg2.func, NameX('literal')):\n                    continue\n\n                if len(arg2.args) != 1:\n                    continue\n\n                node.args[i] = arg2.args[0]\n\n        def visit_Call(self, node):\n            self.check(node)\n            self.generic_visit(node)\n\n    OutputCoalescer().visit(tree)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving locations from the given AST tree completely", "response": "def remove_locations(node):\n    \"\"\"\n    Removes locations from the given AST tree completely\n    \"\"\"\n\n    def fix(node):\n        if 'lineno' in node._attributes and hasattr(node, 'lineno'):\n            del node.lineno\n\n        if 'col_offset' in node._attributes and hasattr(node, 'col_offset'):\n            del node.col_offset\n\n        for child in iter_child_nodes(node):\n            fix(child)\n\n    fix(node)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall when a read is complete.", "response": "def _on_read_complete(self, data, box):\n        \"\"\"\n        \u5b8c\u6574\u6570\u636e\u63a5\u6536\u5b8c\u6210\n        :param data: \u539f\u59cb\u6570\u636e\n        :param box: \u89e3\u6790\u4e4b\u540e\u7684box\n        :return:\n        \"\"\"\n        msg = dict(\n            conn_id=id(self),\n            address=self.address,\n            data=data,\n        )\n\n        # \u83b7\u53d6\u6620\u5c04\u7684group_id\n        group_id = self.factory.app.group_router(box)\n\n        try:\n            self.factory.app.parent_output_dict[group_id].put_nowait(msg)\n        except:\n            logger.error('exc occur. msg: %r', msg, exc_info=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pop(self, timeout=None):\n        with self.lock:\n            while not self.please_stop:\n                if self.db.status.end > self.start:\n                    value = self.db[str(self.start)]\n                    self.start += 1\n                    return value\n\n                if timeout is not None:\n                    with suppress_exception:\n                        self.lock.wait(timeout=timeout)\n                        if self.db.status.end <= self.start:\n                            return None\n                else:\n                    self.lock.wait()\n\n            DEBUG and Log.note(\"persistent queue already stopped\")\n            return THREAD_STOP", "response": "PASSES\n            is the last entry in the persistent queue. If timeout is None then the persistent queue is stopped."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pop_all(self):\n        with self.lock:\n            if self.please_stop:\n                return [THREAD_STOP]\n            if self.db.status.end == self.start:\n                return []\n\n            output = []\n            for i in range(self.start, self.db.status.end):\n                output.append(self.db[str(i)])\n\n            self.start = self.db.status.end\n            return output", "response": "POP ALL IN QUEUE IF ANY"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rows_to_columns(data, schema=None):\n    if not schema:\n        schema = SchemaTree()\n    all_schema = schema\n    all_leaves = schema.leaves\n    values = {full_name: [] for full_name in all_leaves}\n    reps = {full_name: [] for full_name in all_leaves}\n    defs = {full_name: [] for full_name in all_leaves}\n\n    def _none_to_column(schema, path, rep_level, def_level):\n        for full_path in all_schema.leaves:\n            if startswith_field(full_path, path):\n                reps[full_path].append(rep_level)\n                defs[full_path].append(def_level)\n\n    def _value_to_column(value, schema, path, counters, def_level):\n        ptype = type(value)\n        ntype, dtype, ltype, jtype, itype, byte_width = python_type_to_all_types[ptype]\n\n        if jtype is NESTED:\n            if schema.element.repetition_type != REPEATED:\n                Log.error(\"Expecting {{path|quote}} to be repeated\", path=path)\n\n            new_path = path\n            if not value:\n                _none_to_column(schema, new_path, get_rep_level(counters), def_level)\n            else:\n                try:\n                    new_schema = schema.more.get('.')\n\n                    if not new_schema:\n                        if schema.locked:\n                            # DEFAULT TO REQUIRED ENTRIES\n                            new_schema = schema\n                            schema.element.repetition_type = REQUIRED\n                        else:\n                            new_path = path\n                            new_value = value[0]\n                            ptype = type(new_value)\n                            new_schema = schema.add(\n                                new_path,\n                                OPTIONAL,\n                                ptype\n                            )\n                            if new_value is None or python_type_to_json_type[ptype] in PRIMITIVE:\n                                values[new_path] = []\n                                reps[new_path] = [0] * counters[0]\n                                defs[new_path] = [0] * counters[0]\n                    for k, new_value in enumerate(value):\n                        new_counters = counters + (k,)\n                        _value_to_column(new_value, new_schema, new_path, new_counters, def_level+1)\n                finally:\n                    schema.element.repetition_type = REPEATED\n        elif jtype is OBJECT:\n            if value is None:\n                if schema.element.repetition_type == REQUIRED:\n                    Log.error(\"{{path|quote}} is required\", path=path)\n                _none_to_column(schema, path, get_rep_level(counters), def_level)\n            else:\n                if schema.element.repetition_type == REPEATED:\n                    Log.error(\"Expecting {{path|quote}} to be repeated\", path=path)\n\n                if schema.element.repetition_type == REQUIRED:\n                    new_def_level = def_level\n                else:\n                    counters = counters + (0,)\n                    new_def_level = def_level+1\n\n                for name, sub_schema in schema.more.items():\n                    new_path = concat_field(path, name)\n                    new_value = value.get(name, None)\n                    _value_to_column(new_value, sub_schema, new_path, counters, new_def_level)\n\n                for name in set(value.keys()) - set(schema.more.keys()):\n                    if schema.locked:\n                        Log.error(\"{{path}} is not allowed in the schema\", path=path)\n                    new_path = concat_field(path, name)\n                    new_value = value.get(name, None)\n                    ptype = type(new_value)\n                    sub_schema = schema.add(\n                        new_path,\n                        REPEATED if isinstance(new_value, list) else OPTIONAL,\n                        ptype\n                    )\n                    if python_type_to_json_type[ptype] in PRIMITIVE:\n                        values[new_path] = []\n                        reps[new_path] = [0] * counters[0]\n                        defs[new_path] = [0] * counters[0]\n                    _value_to_column(new_value, sub_schema, new_path, counters, new_def_level)\n        else:\n            if jtype is STRING:\n                value = value.encode('utf8')\n            merge_schema(schema, path, value)\n            values[path].append(value)\n            if schema.element.repetition_type == REQUIRED:\n                reps[path].append(get_rep_level(counters))\n                defs[path].append(def_level)\n            else:\n                reps[path].append(get_rep_level(counters))\n                defs[path].append(def_level + 1)\n\n    for rownum, new_value in enumerate(data):\n        try:\n            _value_to_column(new_value, schema, '.', (rownum,), 0)\n        except Exception as e:\n            Log.error(\"can not encode {{row|json}}\", row=new_value, cause=e)\n\n    return Table(values, reps, defs, len(data), schema)", "response": "Convert a list of objects to a list of Table objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_content(cls, content):\n        parsed_content = parse_tibiacom_content(content)\n        tables = cls._parse_tables(parsed_content)\n        char = Character()\n        if \"Could not find character\" in tables.keys():\n            return None\n        if \"Character Information\" in tables.keys():\n            char._parse_character_information(tables[\"Character Information\"])\n        else:\n            raise InvalidContent(\"content does not contain a tibia.com character information page.\")\n        char._parse_achievements(tables.get(\"Account Achievements\", []))\n        char._parse_deaths(tables.get(\"Character Deaths\", []))\n        char._parse_account_information(tables.get(\"Account Information\", []))\n        char._parse_other_characters(tables.get(\"Characters\", []))\n        return char", "response": "Creates an instance of the class from the HTML content of the character s page."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a Character object from a TibiaData character response.", "response": "def from_tibiadata(cls, content):\n        \"\"\"Builds a character object from a TibiaData character response.\n\n        Parameters\n        ----------\n        content: :class:`str`\n            The JSON content of the response.\n\n        Returns\n        -------\n        :class:`Character`\n            The character contained in the page, or None if the character doesn't exist\n\n        Raises\n        ------\n        InvalidContent\n            If content is not a JSON string of the Character response.\"\"\"\n        json_content = parse_json(content)\n        char = cls()\n        try:\n            character = json_content[\"characters\"]\n            if \"error\" in character:\n                return None\n            character_data = character[\"data\"]\n            char.name = character_data[\"name\"]\n            char.world = character_data[\"world\"]\n            char.level = character_data[\"level\"]\n            char.achievement_points = character_data[\"achievement_points\"]\n            char.sex = try_enum(Sex, character_data[\"sex\"])\n            char.vocation = try_enum(Vocation, character_data[\"vocation\"])\n            char.residence = character_data[\"residence\"]\n            char.account_status = try_enum(AccountStatus, character_data[\"account_status\"])\n        except KeyError:\n            raise InvalidContent(\"content does not match a character json from TibiaData.\")\n        char.former_names = character_data.get(\"former_names\", [])\n        if \"deleted\" in character_data:\n            char.deletion_date = parse_tibiadata_datetime(character_data[\"deleted\"])\n        char.married_to = character_data.get(\"married_to\")\n        char.former_world = character_data.get(\"former_world\")\n        char.position = character_data.get(\"Position:\")\n        if \"guild\" in character_data:\n            char.guild_membership = GuildMembership(character_data[\"guild\"][\"name\"], character_data[\"guild\"][\"rank\"])\n        if \"house\" in character_data:\n            house = character_data[\"house\"]\n            paid_until_date = parse_tibiadata_date(house[\"paid\"])\n            char.house = CharacterHouse(house[\"houseid\"], house[\"name\"], char.world, house[\"town\"], char.name,\n                                        paid_until_date)\n        char.comment = character_data.get(\"comment\")\n        if len(character_data[\"last_login\"]) > 0:\n            char.last_login = parse_tibiadata_datetime(character_data[\"last_login\"][0])\n        for achievement in character[\"achievements\"]:\n            char.achievements.append(Achievement(achievement[\"name\"], achievement[\"stars\"]))\n\n        char._parse_deaths_tibiadata(character.get(\"deaths\", []))\n\n        for other_char in character[\"other_characters\"]:\n            char.other_characters.append(OtherCharacter(other_char[\"name\"], other_char[\"world\"],\n                                                        other_char[\"status\"] == \"online\",\n                                                        other_char[\"status\"] == \"deleted\"))\n\n        if character[\"account_information\"]:\n            acc_info = character[\"account_information\"]\n            created = parse_tibiadata_datetime(acc_info.get(\"created\"))\n            loyalty_title = None if acc_info[\"loyalty_title\"] == \"(no title)\" else acc_info[\"loyalty_title\"]\n            position = acc_info.get(\"position\")\n\n            char.account_information = AccountInformation(created, loyalty_title, position)\n\n        return char"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_account_information(self, rows):\n        acc_info = {}\n        if not rows:\n            return\n        for row in rows:\n            cols_raw = row.find_all('td')\n            cols = [ele.text.strip() for ele in cols_raw]\n            field, value = cols\n            field = field.replace(\"\\xa0\", \"_\").replace(\" \", \"_\").replace(\":\", \"\").lower()\n            value = value.replace(\"\\xa0\", \" \")\n            acc_info[field] = value\n        created = parse_tibia_datetime(acc_info[\"created\"])\n        loyalty_title = None if acc_info[\"loyalty_title\"] == \"(no title)\" else acc_info[\"loyalty_title\"]\n        position = acc_info.get(\"position\")\n        self.account_information = AccountInformation(created, loyalty_title, position)", "response": "Parses the character s account information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_achievements(self, rows):\n        for row in rows:\n            cols = row.find_all('td')\n            if len(cols) != 2:\n                continue\n            field, value = cols\n            grade = str(field).count(\"achievement-grade-symbol\")\n            name = value.text.strip()\n            self.achievements.append(Achievement(name, grade))", "response": "Parses the character s displayed achievements and adds them to the achievements attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the character s basic information and applies the found values.", "response": "def _parse_character_information(self, rows):\n        \"\"\"\n        Parses the character's basic information and applies the found values.\n\n        Parameters\n        ----------\n        rows: :class:`list` of :class:`bs4.Tag`\n            A list of all rows contained in the table.\n        \"\"\"\n        int_rows = [\"level\", \"achievement_points\"]\n        char = {}\n        house = {}\n        for row in rows:\n            cols_raw = row.find_all('td')\n            cols = [ele.text.strip() for ele in cols_raw]\n            field, value = cols\n            field = field.replace(\"\\xa0\", \"_\").replace(\" \", \"_\").replace(\":\", \"\").lower()\n            value = value.replace(\"\\xa0\", \" \")\n            # This is a special case cause we need to see the link\n            if field == \"house\":\n                house_text = value\n                paid_until = house_regexp.search(house_text).group(1)\n                paid_until_date = parse_tibia_date(paid_until)\n                house_link = cols_raw[1].find('a')\n                url = urllib.parse.urlparse(house_link[\"href\"])\n                query = urllib.parse.parse_qs(url.query)\n                house = {\"id\": int(query[\"houseid\"][0]), \"name\": house_link.text.strip(),\n                         \"town\": query[\"town\"][0], \"paid_until\": paid_until_date}\n                continue\n            if field in int_rows:\n                value = int(value)\n            char[field] = value\n\n        # If the character is deleted, the information is fouund with the name, so we must clean it\n        m = deleted_regexp.match(char[\"name\"])\n        if m:\n            char[\"name\"] = m.group(1)\n            char[\"deletion_date\"] = parse_tibia_datetime(m.group(2))\n        if \"guild_membership\" in char:\n            m = guild_regexp.match(char[\"guild_membership\"])\n            char[\"guild_membership\"] = GuildMembership(m.group(2), m.group(1))\n\n        if \"former_names\" in char:\n            former_names = [fn.strip() for fn in char[\"former_names\"].split(\",\")]\n            char[\"former_names\"] = former_names\n\n        if \"never\" in char[\"last_login\"]:\n            char[\"last_login\"] = None\n        else:\n            char[\"last_login\"] = parse_tibia_datetime(char[\"last_login\"])\n\n        char[\"vocation\"] = try_enum(Vocation, char[\"vocation\"])\n        char[\"sex\"] = try_enum(Sex, char[\"sex\"])\n        char[\"account_status\"] = try_enum(AccountStatus, char[\"account_status\"])\n\n        for k, v in char.items():\n            try:\n                setattr(self, k, v)\n            except AttributeError:\n                pass\n        if house:\n            self.house = CharacterHouse(house[\"id\"], house[\"name\"], self.world, house[\"town\"], self.name,\n                                        house[\"paid_until\"])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_deaths(self, rows):\n        for row in rows:\n            cols = row.find_all('td')\n            death_time_str = cols[0].text.replace(\"\\xa0\", \" \").strip()\n            death_time = parse_tibia_datetime(death_time_str)\n            death = str(cols[1]).replace(\"\\xa0\", \" \")\n            death_info = death_regexp.search(death)\n            if death_info:\n                level = int(death_info.group(\"level\"))\n                killers_desc = death_info.group(\"killers\")\n            else:\n                continue\n            death = Death(self.name, level, time=death_time)\n            assists_name_list = []\n            # Check if the killers list contains assists\n            assist_match = death_assisted.search(killers_desc)\n            if assist_match:\n                # Filter out assists\n                killers_desc = assist_match.group(\"killers\")\n                # Split assists into a list.\n                assists_name_list = self._split_list(assist_match.group(\"assists\"))\n            killers_name_list = self._split_list(killers_desc)\n            for killer in killers_name_list:\n                killer_dict = self._parse_killer(killer)\n                death.killers.append(Killer(**killer_dict))\n            for assist in assists_name_list:\n                # Extract names from character links in assists list.\n                assist_dict = {\"name\": link_content.search(assist).group(1), \"player\": True}\n                death.assists.append(Killer(**assist_dict))\n            try:\n                self.deaths.append(death)\n            except ValueError:\n                # Some pvp deaths have no level, so they are raising a ValueError, they will be ignored for now.\n                continue", "response": "Parses the character s recent deaths and adds them to the internal list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a killer into a dictionary.", "response": "def _parse_killer(cls, killer):\n        \"\"\"Parses a killer into a dictionary.\n\n        Parameters\n        ----------\n        killer: :class:`str`\n            The killer's raw HTML string.\n\n        Returns\n        -------\n        :class:`dict`: A dictionary containing the killer's info.\n        \"\"\"\n        # If the killer contains a link, it is a player.\n        if \"href\" in killer:\n            killer_dict = {\"name\": link_content.search(killer).group(1), \"player\": True}\n        else:\n            killer_dict = {\"name\": killer, \"player\": False}\n        # Check if it contains a summon.\n        m = death_summon.search(killer)\n        if m:\n            killer_dict[\"summon\"] = m.group(\"summon\")\n        return killer_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_other_characters(self, rows):\n        for row in rows:\n            cols_raw = row.find_all('td')\n            cols = [ele.text.strip() for ele in cols_raw]\n            if len(cols) != 5:\n                continue\n            name, world, status, __, __ = cols\n            name = name.replace(\"\\xa0\", \" \").split(\". \")[1]\n            self.other_characters.append(OtherCharacter(name, world, status == \"online\", status == \"deleted\"))", "response": "Parses the character s other visible characters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the information tables contained in a character s page.", "response": "def _parse_tables(cls, parsed_content):\n        \"\"\"\n        Parses the information tables contained in a character's page.\n\n        Parameters\n        ----------\n        parsed_content: :class:`bs4.BeautifulSoup`\n            A :class:`BeautifulSoup` object containing all the content.\n\n        Returns\n        -------\n        :class:`OrderedDict`[str, :class:`list`of :class:`bs4.Tag`]\n            A dictionary containing all the table rows, with the table headers as keys.\n        \"\"\"\n        tables = parsed_content.find_all('table', attrs={\"width\": \"100%\"})\n        output = OrderedDict()\n        for table in tables:\n            title = table.find(\"td\").text\n            output[title] = table.find_all(\"tr\")[1:]\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit a string listing elements into a list of strings.", "response": "def _split_list(cls, items, separator=\",\", last_separator=\" and \"):\n        \"\"\"\n        Splits a string listing elements into an actual list.\n\n        Parameters\n        ----------\n        items: :class:`str`\n            A string listing elements.\n        separator: :class:`str`\n            The separator between each item. A comma by default.\n        last_separator: :class:`str`\n            The separator used for the last item. ' and ' by default.\n\n        Returns\n        -------\n        :class:`list` of :class:`str`\n            A list containing each one of the items.\n        \"\"\"\n        if items is None:\n            return None\n        items = items.split(separator)\n        last_item = items[-1]\n        last_split = last_item.split(last_separator)\n        if len(last_split) > 1:\n            items[-1] = last_split[0]\n            items.append(last_split[1])\n        return [e.strip() for e in items]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new many - to - many intermediary model for the given field.", "response": "def create_many_to_many_intermediary_model(field, klass):\n    \"\"\"\n    Copied from django, but uses FKToVersion for the\n    'from' field. Fields are also always called 'from' and 'to'\n    to avoid problems between version combined models.\n    \"\"\"\n    managed = True\n    if (isinstance(field.remote_field.to, basestring) and\n            field.remote_field.to != related.RECURSIVE_RELATIONSHIP_CONSTANT):\n        to_model = field.remote_field.to\n        to = to_model.split('.')[-1]\n\n        def set_managed(field, model, cls):\n            managed = model._meta.managed or cls._meta.managed\n            if issubclass(cls, VersionView):\n                managed = False\n            field.remote_field.through._meta.managed = managed\n        related.add_lazy_relation(klass, field, to_model, set_managed)\n    elif isinstance(field.remote_field.to, basestring):\n        to = klass._meta.object_name\n        to_model = klass\n        managed = klass._meta.managed\n    else:\n        to = field.remote_field.to._meta.object_name\n        to_model = field.remote_field.to\n        managed = klass._meta.managed or to_model._meta.managed\n        if issubclass(klass, VersionView):\n            managed = False\n\n    name = '%s_%s' % (klass._meta.object_name, field.name)\n    if (field.remote_field.to == related.RECURSIVE_RELATIONSHIP_CONSTANT or\n            to == klass._meta.object_name):\n        from_ = 'from_%s' % to.lower()\n        to = 'to_%s' % to.lower()\n    else:\n        from_ = klass._meta.object_name.lower()\n        to = to.lower()\n    meta = type('Meta', (object,), {\n        'db_table': field._get_m2m_db_table(klass._meta),\n        'managed': managed,\n        'auto_created': klass,\n        'app_label': klass._meta.app_label,\n        'db_tablespace': klass._meta.db_tablespace,\n        'unique_together': ('from', 'to'),\n        'verbose_name': '%(from)s-%(to)s relationship' % {\n            'from': from_, 'to': to},\n        'verbose_name_plural': '%(from)s-%(to)s relationships' % {\n            'from': from_, 'to': to},\n        'apps': field.model._meta.apps,\n    })\n\n    # Construct and return the new class.\n    return type(str(name), (models.Model,), {\n        'Meta': meta,\n        '__module__': klass.__module__,\n        'from': FKToVersion(klass, related_name='%s+' % name,\n                            db_tablespace=field.db_tablespace,\n                            db_constraint=field.remote_field.db_constraint),\n        'to': models.ForeignKey(to_model, related_name='%s+' % name,\n                                db_tablespace=field.db_tablespace,\n                                db_constraint=field.remote_field.db_constraint)\n    })"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the remote_field. model attribute of the related class.", "response": "def update_rel_to(self, klass):\n        \"\"\"\n        If we have a string for a model, see if we know about it yet,\n        if so use it directly otherwise take the lazy approach.\n        This check is needed because this is called before\n        the main M2M field contribute to class is called.\n        \"\"\"\n\n        if isinstance(self.remote_field.to, basestring):\n            relation = self.remote_field.to\n            try:\n                app_label, model_name = relation.split(\".\")\n            except ValueError:\n                # If we can't split, assume a model in current app\n                app_label = klass._meta.app_label\n                model_name = relation\n\n            model = None\n            try:\n                model = klass._meta.apps.get_registered_model(app_label, model_name)\n            # For django < 1.6\n            except AttributeError:\n                model = models.get_model(\n                    app_label, model_name,\n                    seed_cache=False, only_installed=False)\n            except LookupError:\n                pass\n\n            if model:\n                self.remote_field.model = model"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking the inspector is not called.", "response": "def notCalled(cls, spy): #pylint: disable=invalid-name\n        \"\"\"\n        Checking the inspector is not called\n        Args: SinonSpy\n        \"\"\"\n        cls.__is_spy(spy)\n        if not (not spy.called):\n            raise cls.failException(cls.message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calledOnce(cls, spy): #pylint: disable=invalid-name\n        cls.__is_spy(spy)\n        if not (spy.calledOnce):\n            raise cls.failException(cls.message)", "response": "Check the inspector is called once."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calledTwice(cls, spy): #pylint: disable=invalid-name\n        cls.__is_spy(spy)\n        if not (spy.calledTwice):\n            raise cls.failException(cls.message)", "response": "Check the inspector is called twice\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck the inspector is called thrice", "response": "def calledThrice(cls, spy): #pylint: disable=invalid-name\n        \"\"\"\n        Checking the inspector is called thrice\n        Args: SinonSpy\n        \"\"\"\n        cls.__is_spy(spy)\n        if not (spy.calledThrice):\n            raise cls.failException(cls.message)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking the inspector is called number times", "response": "def callCount(cls, spy, number): #pylint: disable=invalid-name\n        \"\"\"\n        Checking the inspector is called number times\n        Args: SinonSpy, number\n        \"\"\"\n        cls.__is_spy(spy)\n        if not (spy.callCount == number):\n            raise cls.failException(cls.message)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks the inspector is called with given priority", "response": "def callOrder(cls, *args): #pylint: disable=invalid-name\n        \"\"\"\n        Checking the inspector is called with given priority\n        Args: SinonSpy, list of inspectors\n        eg.\n            [spy1, spy2, spy3] => spy1 is called before spy2, spy2 is called before spy3\n            [spy1, spy2, spy1] => spy1 is called before and after spy2\n        \"\"\"\n        for spy in args:\n            cls.__is_spy(spy)\n        for idx, val in enumerate(args):\n            if val != args[0]:\n                if not (val.calledAfter(args[idx-1])):\n                    raise cls.failException(cls.message)\n            if val != args[-1]:\n                if not (val.calledBefore(args[idx+1])):\n                    raise cls.failException(cls.message)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking the inspector is called with partial args and kwargs", "response": "def calledWith(cls, spy, *args, **kwargs): #pylint: disable=invalid-name\n        \"\"\"\n        Checking the inspector is called with partial args/kwargs\n        Args: SinonSpy, args/kwargs\n        \"\"\"\n        cls.__is_spy(spy)\n        if not (spy.calledWith(*args, **kwargs)):\n            raise cls.failException(cls.message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef alwaysCalledWith(cls, spy, *args, **kwargs): #pylint: disable=invalid-name\n        cls.__is_spy(spy)\n        if not (spy.alwaysCalledWith(*args, **kwargs)):\n            raise cls.failException(cls.message)", "response": "Check the inspector is always called with partial args and kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks the inspector is never called with partial args and kwargs", "response": "def neverCalledWith(cls, spy, *args, **kwargs): #pylint: disable=invalid-name\n        \"\"\"\n        Checking the inspector is never called with partial args/kwargs\n        Args: SinonSpy, args/kwargs\n        \"\"\"\n        cls.__is_spy(spy)\n        if not (spy.neverCalledWith(*args, **kwargs)):\n            raise cls.failException(cls.message)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck the inspector is called with exactly args and kwargs", "response": "def calledWithExactly(cls, spy, *args, **kwargs): #pylint: disable=invalid-name\n        \"\"\"\n        Checking the inspector is called with exactly args/kwargs\n        Args: SinonSpy, args/kwargs\n        \"\"\"\n        cls.__is_spy(spy)\n        if not (spy.calledWithExactly(*args, **kwargs)):\n            raise cls.failException(cls.message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef alwaysCalledWithExactly(cls, spy, *args, **kwargs): #pylint: disable=invalid-name\n        cls.__is_spy(spy)\n        if not (spy.alwaysCalledWithExactly(*args, **kwargs)):\n            raise cls.failException(cls.message)", "response": "Check the inspector is always called with exactly args and kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calledWithMatch(cls, spy, *args, **kwargs): #pylint: disable=invalid-name\n        cls.__is_spy(spy)\n        if not (spy.calledWithMatch(*args, **kwargs)):\n            raise cls.failException(cls.message)", "response": "Check the inspector is called with partial SinonMatcher"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef alwaysCalledWithMatch(cls, spy, *args, **kwargs): #pylint: disable=invalid-name\n        cls.__is_spy(spy)\n        if not (spy.alwaysCalledWithMatch(*args, **kwargs)):\n            raise cls.failException(cls.message)", "response": "Check the inspector is always called with partial SinonMatcher"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef neverCalledWithMatch(cls, spy, *args, **kwargs): #pylint: disable=invalid-name\n        cls.__is_spy(spy)\n        if not (spy.neverCalledWithMatch(*args, **kwargs)):\n            raise cls.failException(cls.message)", "response": "Check the inspector is never called with partial SinonMatcher"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck the inspector is raised error_type", "response": "def threw(cls, spy, error_type=None):\n        \"\"\"\n        Checking the inspector is raised error_type\n        Args: SinonSpy, Exception (defaut: None)\n        \"\"\"\n        cls.__is_spy(spy)\n        if not (spy.threw(error_type)):\n            raise cls.failException(cls.message)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking the inspector is always raised error_type", "response": "def alwaysThrew(cls, spy, error_type=None): #pylint: disable=invalid-name\n        \"\"\"\n        Checking the inspector is always raised error_type\n        Args: SinonSpy, Exception (defaut: None)\n        \"\"\"\n        cls.__is_spy(spy)\n        if not (spy.alwaysThrew(error_type)):\n            raise cls.failException(cls.message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _scrub_key(key):\n    if key == None:\n        return None\n\n    output = []\n    for c in key:\n        if c in [\":\", \".\"]:\n            output.append(c)\n    return \"\".join(output)", "response": "Scrubs a key into a single string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_meta(self, key, conforming=True):\n        try:\n            metas = list(self.bucket.list(prefix=key))\n            metas = wrap([m for m in metas if m.name.find(\".json\") != -1])\n\n            perfect = Null\n            favorite = Null\n            too_many = False\n            error = None\n            for m in metas:\n                try:\n                    simple = strip_extension(m.key)\n                    if conforming:\n                        self._verify_key_format(simple)\n                    if simple == key:\n                        perfect = m\n                        too_many = False\n                    if simple.startswith(key + \".\") or simple.startswith(key + \":\"):\n                        if favorite and not perfect:\n                            too_many = True\n                        favorite = m\n                except Exception as e:\n                    error = e\n\n            if too_many:\n                Log.error(\n                    \"multiple keys in {{bucket}} with prefix={{prefix|quote}}: {{list}}\",\n                    bucket=self.name,\n                    prefix=key,\n                    list=[k.name for k in metas]\n                )\n            if not perfect and error:\n                Log.error(\"Problem with key request\", error)\n            return coalesce(perfect, favorite)\n        except Exception as e:\n            Log.error(READ_ERROR+\" can not read {{key}} from {{bucket}}\", key=key, bucket=self.bucket.name, cause=e)", "response": "Get the metadata for a key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef keys(self, prefix=None, delimiter=None):\n        if delimiter:\n            # WE REALLY DO NOT GET KEYS, BUT RATHER Prefix OBJECTS\n            # AT LEAST THEY ARE UNIQUE\n            candidates = [k.name.rstrip(delimiter) for k in self.bucket.list(prefix=prefix, delimiter=delimiter)]\n        else:\n            candidates = [strip_extension(k.key) for k in self.bucket.list(prefix=prefix)]\n\n        if prefix == None:\n            return set(c for c in candidates if c != \"0.json\")\n        else:\n            return set(k for k in candidates if k == prefix or k.startswith(prefix + \".\") or k.startswith(prefix + \":\"))", "response": "Returns a set of keys in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef metas(self, prefix=None, limit=None, delimiter=None):\n        limit = coalesce(limit, TOO_MANY_KEYS)\n        keys = self.bucket.list(prefix=prefix, delimiter=delimiter)\n        prefix_len = len(prefix)\n        output = []\n        for i, k in enumerate(k for k in keys if len(k.key) == prefix_len or k.key[prefix_len] in [\".\", \":\"]):\n            output.append({\n                \"key\": strip_extension(k.key),\n                \"etag\": convert.quote2string(k.etag),\n                \"expiry_date\": Date(k.expiry_date),\n                \"last_modified\": Date(k.last_modified)\n            })\n            if i >= limit:\n                break\n        return wrap(output)", "response": "Return a list of all the metadata for this object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_middleware(app=None, *args, **kw):\n    app = RaptorizeMiddleware(app, *args, **kw)\n    return app", "response": "Given an app return that app wrapped in RaptorizeMiddleware"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef should_raptorize(self, req, resp):\n\n        if resp.status != \"200 OK\":\n            return False\n\n        content_type = resp.headers.get('Content-Type', 'text/plain').lower()\n        if not 'html' in content_type:\n            return False\n\n        if random.random() > self.random_chance:\n            return False\n\n        if self.only_on_april_1st:\n            now = datetime.datetime.now()\n            if now.month != 20 and now.day != 1:\n                return False\n\n        return True", "response": "Determines if the request should be raptorized."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef raptorize(self, resp):\n\n        soup = BeautifulSoup.BeautifulSoup(resp.body)\n\n        if not soup.html:\n            return resp\n\n        if not soup.html.head:\n            soup.html.insert(0, BeautifulSoup.Tag(soup, \"head\"))\n\n        prefix = self.resources_app.prefix\n        js_helper = BeautifulSoup.Tag(\n            soup, \"script\", attrs=[\n                ('type', 'text/javascript'),\n                ('src', prefix + '/js_helper.js'),\n            ])\n        soup.html.head.insert(len(soup.html.head), js_helper)\n\n        payload_js = BeautifulSoup.Tag(\n            soup, \"script\", attrs=[\n                ('type', 'text/javascript'),\n            ])\n        payload_js.setString(\n            \"\"\"\n            run_with_jquery(function() {\n                include_js(\"%s\", function() {\n                    $(window).load(function() {\n                        $('body').raptorize({\n                            enterOn: \"%s\",\n                            delayTime: %i,\n                        });\n                    });\n                })\n            });\n            \"\"\" % (\n                prefix + '/jquery.raptorize.1.0.js',\n                self.enterOn,\n                self.delayTime\n            )\n        )\n        soup.html.head.insert(len(soup.html.head), payload_js)\n\n        resp.body = str(soup.prettify())\n        return resp", "response": "Raptorize this response!\n\n        Insert javascript into the <head> tag.\n\n        If jquery is already included, make sure not to stomp on it by\n        re-including it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bind(context, block=False):\n\n    if block:\n        def decorate(func):\n            name = func.__name__.replace('__TK__block__', '')\n            if name not in context:\n                context[name] = func\n            return context[name]\n\n        return decorate\n\n    def decorate(func):\n        name = func.__name__\n        if name not in context:\n            context[name] = func\n        return context[name]\n\n    return decorate", "response": "Returns a decorator that binds the decorated function to the context."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_homogeneisation_vehicules(temporary_store = None, year = None):\n    assert temporary_store is not None\n    \"\"\"Compute vehicule numbers by type\"\"\"\n\n    assert year is not None\n    # Load data\n    bdf_survey_collection = SurveyCollection.load(\n        collection = 'budget_des_familles', config_files_directory = config_files_directory)\n    survey = bdf_survey_collection.get_survey('budget_des_familles_{}'.format(year))\n\n    if year == 1995:\n        vehicule = None\n\n    # L'enqu\u00eate BdF 1995 ne contient pas d'information sur le type de carburant utilis\u00e9 par les v\u00e9hicules.\n\n    if year == 2000:\n        vehicule = survey.get_values(table = \"depmen\")\n        kept_variables = ['ident', 'carbu01', 'carbu02']\n        vehicule = vehicule[kept_variables]\n        vehicule.rename(columns = {'ident': 'ident_men'}, inplace = True)\n        vehicule.rename(columns = {'carbu01': 'carbu1'}, inplace = True)\n        vehicule.rename(columns = {'carbu02': 'carbu2'}, inplace = True)\n        vehicule[\"veh_tot\"] = 1\n        vehicule[\"veh_essence\"] = 1 * (vehicule['carbu1'] == 1) + 1 * (vehicule['carbu2'] == 1)\n        vehicule[\"veh_diesel\"] = 1 * (vehicule['carbu1'] == 2) + 1 * (vehicule['carbu2'] == 2)\n        vehicule.index = vehicule.index.astype(ident_men_dtype)\n\n\n    if year == 2005:\n        vehicule = survey.get_values(table = \"automobile\")\n        kept_variables = ['ident_men', 'carbu']\n        vehicule = vehicule[kept_variables]\n        vehicule[\"veh_tot\"] = 1\n        vehicule[\"veh_essence\"] = (vehicule['carbu'] == 1)\n        vehicule[\"veh_diesel\"] = (vehicule['carbu'] == 2)\n\n    if year == 2011:\n        try:\n            vehicule = survey.get_values(table = \"AUTOMOBILE\")\n        except:\n            vehicule = survey.get_values(table = \"automobile\")\n        kept_variables = ['ident_me', 'carbu']\n        vehicule = vehicule[kept_variables]\n        vehicule.rename(columns = {'ident_me': 'ident_men'}, inplace = True)\n        vehicule[\"veh_tot\"] = 1\n        vehicule[\"veh_essence\"] = (vehicule['carbu'] == 1)\n        vehicule[\"veh_diesel\"] = (vehicule['carbu'] == 2)\n\n    # Compute the number of cars by category and save\n    if year != 1995:\n        vehicule = vehicule.groupby(by = 'ident_men')[\"veh_tot\", \"veh_essence\", \"veh_diesel\"].sum()\n        vehicule[\"pourcentage_vehicule_essence\"] = 0\n        vehicule.pourcentage_vehicule_essence.loc[vehicule.veh_tot != 0] = vehicule.veh_essence / vehicule.veh_tot\n        # Save in temporary store\n        temporary_store['automobile_{}'.format(year)] = vehicule", "response": "Build homogeneisation vehicules for a given year."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_json(url, **kwargs):\n    response = get(url, **kwargs)\n    try:\n        c = response.all_content\n        return json2value(utf82unicode(c))\n    except Exception as e:\n        if mo_math.round(response.status_code, decimal=-2) in [400, 500]:\n            Log.error(u\"Bad GET response: {{code}}\", code=response.status_code)\n        else:\n            Log.error(u\"Good GET requests, but bad JSON\", cause=e)", "response": "GET URL IN JSON"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef post_json(url, **kwargs):\n    if 'json' in kwargs:\n        kwargs['data'] = unicode2utf8(value2json(kwargs['json']))\n        del kwargs['json']\n    elif 'data' in kwargs:\n        kwargs['data'] = unicode2utf8(value2json(kwargs['data']))\n    else:\n        Log.error(u\"Expecting `json` parameter\")\n    response = post(url, **kwargs)\n    details = json2value(utf82unicode(response.content))\n    if response.status_code not in [200, 201, 202]:\n\n        if \"template\" in details:\n            Log.error(u\"Bad response code {{code}}\", code=response.status_code, cause=Except.wrap(details))\n        else:\n            Log.error(u\"Bad response code {{code}}\\n{{details}}\", code=response.status_code, details=details)\n    else:\n        return details", "response": "POST URL with JSON data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_project_export(self, project_id):\n        try:\n            result = self._request('/getprojectexport/',\n                                   {'projectid': project_id})\n            return TildaProject(**result)\n        except NetworkError:\n            return []", "response": "Get project info for export"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting short page info and body html code", "response": "def get_page(self, page_id):\n        \"\"\" Get short page info and body html code \"\"\"\n        try:\n            result = self._request('/getpage/',\n                                   {'pageid': page_id})\n            return TildaPage(**result)\n        except NetworkError:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_page_full(self, page_id):\n        try:\n            result = self._request('/getpagefull/',\n                                   {'pageid': page_id})\n            return TildaPage(**result)\n        except NetworkError:\n            return []", "response": "Get full page info and full html code"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_page_export(self, page_id):\n        try:\n            result = self._request('/getpageexport/',\n                                   {'pageid': page_id})\n            return TildaPage(**result)\n        except NetworkError:\n            return []", "response": "Get short page info for export and body html code"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting full page info for export and body html code", "response": "def get_page_full_export(self, page_id):\n        \"\"\" Get full page info for export and body html code \"\"\"\n        try:\n            result = self._request('/getpagefullexport/',\n                                   {'pageid': page_id})\n            return TildaPage(**result)\n        except NetworkError:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsplitting a pathname into components in a platform - neutral way.", "response": "def fullsplit(path, result=None, base_path=None):\n    \"\"\"\n    Split a pathname into components (the opposite of os.path.join) in a\n    platform-neutral way.\n    \"\"\"\n\n    if base_path:\n        path = path.replace(base_path, '')\n\n    if result is None:\n        result = []\n    head, tail = os.path.split(path)\n    if head == '':\n        return [tail] + result\n    if head == path:\n        return result\n    return fullsplit(head, [tail] + result)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _flatten(l):\n    res = []\n    for sublist in l:\n        if isinstance(sublist, whaaaaat.Separator):\n            res.append(sublist)\n        else:\n            for item in sublist:\n                res.append(item)\n    return res", "response": "helper to flatten a list of lists"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle(app):\n    # TODO:  for this to work properly we need a generator registry\n    # generator, lifecycle etc.\n    # list of tuples (label, value)\n    # TODO customize & use own style\n\n    default_choices = [\n        {\n            'name': 'Install a generator',\n            'value': 'install'\n        },\n        {\n            'name': 'Find some help',\n            'value': 'help'\n        },\n        {\n            'name': 'Get me out of here!',\n            'value': 'exit'\n        }\n    ]\n\n    '''\n    if (globalConfigHasContent()) {\n    defaultChoices.splice(defaultChoices.length - 1, 0, {\n      name: 'Clear global config',\n      value: 'clearConfig'\n    });\n    }\n\n    var generatorList = _.chain(app.generators).map(function (generator) {\n    if (!generator.appGenerator) {\n      return null;\n    }\n\n    var updateInfo = generator.updateAvailable ? chalk.dim.yellow(' \u2665 Update Available!') : '';\n\n    return {\n      name: generator.prettyName + updateInfo,\n      value: {\n        method: 'run',\n        generator: generator.namespace\n      }\n    };\n    }).compact().sortBy(function (el) {\n    var generatorName = namespaceToName(el.value.generator);\n    return -app.conf.get('generatorRunCount')[generatorName] || 0;\n    }).value();\n\n    if (generatorList.length) {\n    defaultChoices.unshift({\n      name: 'Update your generators',\n      value: 'update'\n    });\n    }\n    '''\n\n    # app.insight.track('yoyo', 'home');\n    generator_list = [{'name': g.title(), 'value': {'name': g, 'method': 'run'}}\n                      for g in app.generators]\n\n    choices = _flatten([\n        whaaaaat.Separator('Run a generator'),\n        generator_list,\n        whaaaaat.Separator(),\n        default_choices,\n        whaaaaat.Separator(),\n    ])\n\n    # var allo = name ? '\\'Allo ' + name.split(' ')[0] + '! ' : '\\'Allo! ';\n    allo = 'MoinMoin! '\n\n    questions = [\n        {\n            'type': 'list',\n            'name': 'what_next',\n            'message': allo + 'What would you like to do?',\n            'choices': choices,\n        }\n    ]\n\n    answer = whaaaaat.prompt(questions)\n\n    if isinstance(answer['what_next'], dict) and \\\n            answer['what_next']['method'] == 'run':\n        app.navigate('run', answer['what_next']['name'])\n        return\n    elif answer['what_next'] == 'exit':\n        return\n\n    app.navigate(answer['what_next'])", "response": "Handle the action of the main application."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_thrift(file_obj, ttype):\n    from thrift.transport.TTransport import TFileObjectTransport, TBufferedTransport\n    starting_pos = file_obj.tell()\n\n    # set up the protocol chain\n    ft = TFileObjectTransport(file_obj)\n    bufsize = 2 ** 16\n    # for accelerated reading ensure that we wrap this so that the CReadable transport can be used.\n    bt = TBufferedTransport(ft, bufsize)\n    pin = TCompactProtocol(bt)\n\n    # read out type\n    obj = ttype()\n    obj.read(pin)\n\n    # The read will actually overshoot due to the buffering that thrift does. Seek backwards to the correct spot,.\n    buffer_pos = bt.cstringio_buf.tell()\n    ending_pos = file_obj.tell()\n    blocks = ((ending_pos - starting_pos) // bufsize) - 1\n    if blocks < 0:\n        blocks = 0\n    file_obj.seek(starting_pos + blocks * bufsize + buffer_pos)\n    return obj", "response": "Read a thrift structure from the given fo."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_thrift(fobj, thrift):\n    t0 = fobj.tell()\n    pout = TCompactProtocol(fobj)\n    try:\n        thrift.write(pout)\n        fail = False\n    except TProtocolException as e:\n        typ, val, tb = sys.exc_info()\n        frames = []\n        while tb is not None:\n            frames.append(tb)\n            tb = tb.tb_next\n        frame = [tb for tb in frames if 'write_struct' in str(tb.tb_frame.f_code)]\n        variables = frame[0].tb_frame.f_locals\n        obj = variables['obj']\n        name = variables['fname']\n        fail = True\n    if fail:\n        raise ParquetException('Thrift parameter validation failure %s'\n                               ' when writing: %s-> Field: %s' % (\n            val.args[0], obj, name\n        ))\n    return fobj.tell() - t0", "response": "Writes a binary compact representation of thiftpy structured object to a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef thrift_print(structure, offset=0):\n    if not is_thrift_item(structure):\n        return str(structure)\n    s = str(structure.__class__) + '\\n'\n    for key in dir(structure):\n        if key.startswith('_') or key in ['thrift_spec', 'read', 'write',\n                                          'default_spec', 'validate']:\n            continue\n        s = s + ' ' * offset + key + ': ' + thrift_print(getattr(structure, key)\n                                                         , offset+2) + '\\n'\n    return s", "response": "Return a string representation of the given structure."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert_load_command(target_path, library_install_name):\n\tdef patchHeader(t):\n\t\tload_command = generate_dylib_load_command(t, library_install_name)\n\t\treturn insert_load_command_into_header(t, load_command)\n\t\t\n\treturn modify_macho_file_headers(target_path, patchHeader)", "response": "Inserts a new LC_LOAD_DYLIB load command into the Mach - O header."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a list of libraries that depend on a given Mach - O file.", "response": "def macho_dependencies_list(target_path, header_magic=None):\n\t\"\"\" Generates a list of libraries the given Mach-O file depends on.\n\n\tIn that list a single library is represented by its \"install path\": for some\n\tlibraries it would be a full file path, and for others it would be a relative\n\tpath (sometimes with dyld templates like @executable_path or @rpath in it).\n\n\tNote: I don't know any reason why would some architectures of a fat Mach-O depend\n\ton certain libraries while others don't, but *it's technically possible*.\n\tSo that's why you may want to specify the `header_magic` value for a particular header.\n\n\tReturns an object with two properties: `weak` and `strong` that hold lists of weak\n\tand strong dependencies respectively.\n\t\"\"\"\n\tMachODeprendencies = namedtuple(\"MachODeprendecies\", \"weak strong\")\n\n\t# Convert the magic value into macholib representation if needed\n\tif isinstance(header_magic, basestring):\n\t\theader_magic = _MH_MAGIC_from_string(header_magic)\n\n\tmacho = MachO(target_path)\n\t# Obtain a list of headers for the required magic value (if any)\n\tsuggestions = filter(lambda t: t.header.magic == header_magic\n\t                                 or # just add all headers if user didn't specifiy the magic\n\t                                 header_magic == None, macho.headers)\n\theader = None if len(suggestions) <= 0 else suggestions[0]\n\t# filter() above *always* returns a list, so we have to check if it's empty\n\tif header is None:\n\t\traise Exception(\"Unable to find a header for the given MAGIC value in that Mach-O file\")\n\t\treturn None\n\n\tdef decodeLoadCommandData(data):\n\t\t# Also ignore trailing zeros\n\t\treturn data[:data.find(b\"\\x00\")].decode(sys.getfilesystemencoding())\n\n\tdef strongReferencesFromHeader(h):\n\t\t# List of LC_LOAD_DYLIB commands\n\t\tlist = filter(lambda (lc,cmd,data): lc.cmd == LC_LOAD_DYLIB, h.commands)\n\t\t# Their contents (aka data) as a file path\n\t\treturn map(lambda (lc,cmd,data): decodeLoadCommandData(data), list)\n\n\tdef weakReferencesFromHeader(h):\n\t\tlist = filter(lambda (lc,cmd,data): lc.cmd == LC_LOAD_WEAK_DYLIB, h.commands)\n\t\treturn map(lambda (lc,cmd,data): decodeLoadCommandData(data), list)\n\n\tstrongRefs = strongReferencesFromHeader(header)\n\tweakRefs   = weakReferencesFromHeader(header)\n\n\treturn MachODeprendencies(weak = weakRefs, strong = strongRefs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts the given load command into the header and adjusts its size by the command size.", "response": "def insert_load_command_into_header(header, load_command):\n\t\"\"\" Inserts the given load command into the header and adjust its size. \"\"\"\n\tlc, cmd, path = load_command\n\theader.commands.append((lc, cmd, path))\n\theader.header.ncmds += 1\n\theader.changedHeaderSizeBy(lc.cmdsize)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_dylib_load_command(header, libary_install_name):\n\t\n\t# One can not simply create instances of `dylib_command` and `load_command` classes,\n\t# because that's just not the way macholib works. If we try then all we'll get is a bunch\n\t# of endian (big/little) issues when these objects are serialized into a file.\n\t# BUT THAT'S PROGRAMMING RIGHT?\n\t# So instead I'll iterate *existing* load commands, find a dyld_command, copy it\n\t# and modify this copy. This existing command is said to be fully initialized.\n\tlc = None\n\tcmd = None\n\tfor (command, internal_cmd, data) in header.commands:\n\t\tif (command.cmd == LC_LOAD_DYLIB) and isinstance(internal_cmd, dylib_command):\n\t\t\tlc = deepcopy(command)\n\t\t\tcmd = deepcopy(internal_cmd)\n\t\t\tbreak\n\tif not lc or not cmd:\n\t\traise Exception(\"Invalid Mach-O file. I mean, there must be at least one LC_LOAD_DYLIB load command.\")\n\t\treturn None\n\t\n\t# Well, now we just replace everything with our own stuff\n\tcmd.timestamp = 0\n\tcmd.current_version = cmd.compatibility_version = 0x1000\n\t# Since we store the library's path just after the load command itself, we need to find out it's offset.\n\tbase = sizeof(load_command) + sizeof(dylib_command)\n\t# `name` is rather bad name for this property: actually it means a path string offset\n\tcmd.name = base\n\t# Also the whole thing must be aligned by 4 bytes on 32-bit arches and by 8 bytes on 64-bit arches\n\talign = 4 if header.header.magic == MH_MAGIC else 8\n\taligned_name = libary_install_name + (b'\\x00' * (align - (len(libary_install_name) % align)))\n\t# So now we finally can say what size this load_command is\n\tlc.cmdsize = base + len(aligned_name)\n\t\n\treturn (lc, cmd, aligned_name)", "response": "Generates a LC_LOAD_DYLIB load command for the given header and a library install path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate that the username is alphanumeric and is not already in use.", "response": "def clean_username(self):\n        \"\"\"\n        Validate that the username is alphanumeric and is not already in use.\n        Also validates that the username is not listed in\n        ACCOUNTS_FORBIDDEN_USERNAMES list.\n        \"\"\"\n        try:\n            get_user_model().objects.get(\n                username__iexact=self.cleaned_data['username'])\n        except get_user_model().DoesNotExist:\n            pass\n        else:\n            raise forms.ValidationError(_('This username is already taken.'))\n        if self.cleaned_data['username'].lower() in accounts_settings.ACCOUNTS_FORBIDDEN_USERNAMES:\n            raise forms.ValidationError(_('This username is not allowed.'))\n        return self.cleaned_data['username']"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate that the e - mail address is unique.", "response": "def clean_email(self):\n        \"\"\"\n        Validate that the e-mail address is unique.\n        \"\"\"\n        if get_user_model().objects.filter(\n            email__iexact=self.cleaned_data['email']):\n            raise forms.ValidationError(_('This email is already in use. Please supply a different email.'))\n        return self.cleaned_data['email']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self):\n        username, email, password, first_name, last_name = (self.cleaned_data['username'],\n                                     self.cleaned_data['email'],\n                                     self.cleaned_data['password1'],\n                                     self.cleaned_data['first_name'],\n                                     self.cleaned_data['last_name'],)\n\n        new_user = get_user_model()(username=username,\n                                 email=email,\n                                 first_name=first_name,\n                                 last_name=last_name)\n        new_user.set_password(password)\n        new_user.save()\n        return new_user", "response": "Creates a new user and account. Returns the newly created user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines the WWW - Authenticate header to use for 401 responses.", "response": "def get_authenticate_header(self, request):\n        \"\"\"\n        If a request is unauthenticated, determine the WWW-Authenticate\n        header to use for 401 responses, if any.\n        \"\"\"\n        authenticators = self.get_authenticators()\n        if authenticators:\n            return authenticators[0].authenticate_header(request)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_dir(dst):\n    directory = os.path.dirname(dst)\n    if directory and not os.path.exists(directory):\n        os.makedirs(directory)", "response": "create directory if necessary"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncopies all the files that match the glob", "response": "def copy_wildcard(src_folder, dst_folder, glob):\n    \"\"\"copy\n    \"\"\"\n    create_dir(dst_folder)\n    for sname in iglob(os.path.join(src_folder, glob)):\n        rname = os.path.relpath(sname, src_folder)\n        dname = os.path.join(dst_folder, rname)\n        create_dir(dname)\n        shutil.copy(sname, dname)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy_tpl(template_file, dst, template_vars):\n    create_dir(dst)\n\n    # load template\n    template_loader = jinja2.FileSystemLoader(searchpath='/')\n    template_env = jinja2.Environment(loader=template_loader,\n                                      keep_trailing_newline=True)\n    template = template_env.get_template(template_file)\n\n    # render and write to file\n    template.stream(template_vars).dump(dst)", "response": "Copy a template file to a new location."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_for_maintenance(self):\n        '''\n        Returns True if the maintenance worker should be run now,\n        and False otherwise.\n        :return:\n        '''\n        numrevs = self.conn.get_one(\"SELECT count(revnum) FROM csetLog\")[0]\n        if numrevs >= SIGNAL_MAINTENACE_CSETS:\n            return True\n        return False", "response": "Returns True if the maintenance worker should be run now and False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a list of revisions to the table.", "response": "def add_cset_entries(self, ordered_rev_list, timestamp=False, number_forward=True):\n        '''\n        Adds a list of revisions to the table. Assumes ordered_rev_list is an ordered\n        based on how changesets are found in the changelog. Going forwards or backwards is dealt\n        with by flipping the list\n        :param ordered_cset_list: Order given from changeset log searching.\n        :param timestamp: If false, records are kept indefinitely\n                          but if holes exist: (delete, None, delete, None)\n                          those delete's with None's around them\n                          will not be deleted.\n        :param numbered: If True, this function will number the revision list\n                         by going forward from max(revNum), else it'll go backwards\n                         from revNum, then add X to all revnums and self.next_revnum\n                         where X is the length of ordered_rev_list\n        :return:\n        '''\n        with self.conn.transaction() as t:\n            current_min = t.get_one(\"SELECT min(revnum) FROM csetlog\")[0]\n            current_max = t.get_one(\"SELECT max(revnum) FROM csetlog\")[0]\n            if not current_min or not current_max:\n                current_min = 0\n                current_max = 0\n\n            direction = -1\n            start = current_min - 1\n            if number_forward:\n                direction = 1\n                start = current_max + 1\n                ordered_rev_list = ordered_rev_list[::-1]\n\n            insert_list = [\n                (\n                    start + direction * count,\n                    rev,\n                    int(time.time()) if timestamp else -1\n                )\n                for count, rev in enumerate(ordered_rev_list)\n            ]\n\n            # In case of overlapping requests\n            fmt_insert_list = []\n            for cset_entry in insert_list:\n                tmp = self._get_one_revision(t, cset_entry)\n                if not tmp:\n                    fmt_insert_list.append(cset_entry)\n\n            for _, tmp_insert_list in jx.groupby(fmt_insert_list, size=SQL_CSET_BATCH_SIZE):\n                t.execute(\n                    \"INSERT INTO csetLog (revnum, revision, timestamp)\" +\n                    \" VALUES \" +\n                    sql_list(\n                        quote_set((revnum, revision, timestamp))\n                        for revnum, revision, timestamp in tmp_insert_list\n                    )\n                )\n\n            # Move the revision numbers forward if needed\n            self.recompute_table_revnums()\n\n        # Start a maintenance run if needed\n        if self.check_for_maintenance():\n            self.maintenance_signal.go()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _fill_in_range(self, parent_cset, child_cset, timestamp=False, number_forward=True):\n        '''\n        Fills cset logs in a certain range. 'parent_cset' can be an int and in that case,\n        we get that many changesets instead. If parent_cset is an int, then we consider\n        that we are going backwards (number_forward is False) and we ignore the first\n        changeset of the first log, and we ignore the setting for number_forward.\n        Otherwise, we continue until we find the given 'parent_cset'.\n        :param parent_cset:\n        :param child_cset:\n        :param timestamp:\n        :param number_forward:\n        :return:\n        '''\n        csets_to_add = []\n        found_parent = False\n        find_parent = False\n        if type(parent_cset) != int:\n            find_parent = True\n        elif parent_cset >= MAX_BACKFILL_CLOGS * CHANGESETS_PER_CLOG:\n            Log.warning(\n                \"Requested number of new changesets {{num}} is too high. \"\n                \"Max number that can be requested is {{maxnum}}.\",\n                num=parent_cset,\n                maxnum=MAX_BACKFILL_CLOGS * CHANGESETS_PER_CLOG\n            )\n            return None\n\n        csets_found = 0\n        clogs_seen = 0\n        final_rev = child_cset\n        while not found_parent and clogs_seen < MAX_BACKFILL_CLOGS:\n            clog_url = self.tuid_service.hg_url / self.config.hg.branch / 'json-log' / final_rev\n            clog_obj = self._get_clog(clog_url)\n            clog_csets_list = list(clog_obj['changesets'])\n            for clog_cset in clog_csets_list[:-1]:\n                if not number_forward and csets_found <= 0:\n                    # Skip this entry it already exists\n                    csets_found += 1\n                    continue\n\n                nodes_cset = clog_cset['node'][:12]\n                if find_parent:\n                    if nodes_cset == parent_cset:\n                        found_parent = True\n                        if not number_forward:\n                            # When going forward this entry is\n                            # the given parent\n                            csets_to_add.append(nodes_cset)\n                        break\n                else:\n                    if csets_found + 1 > parent_cset:\n                        found_parent = True\n                        if not number_forward:\n                            # When going forward this entry is\n                            # the given parent (which is supposed\n                            # to already exist)\n                            csets_to_add.append(nodes_cset)\n                        break\n                    csets_found += 1\n                csets_to_add.append(nodes_cset)\n            if found_parent == True:\n                break\n\n            clogs_seen += 1\n            final_rev = clog_csets_list[-1]['node'][:12]\n\n        if found_parent:\n            self.add_cset_entries(csets_to_add, timestamp=timestamp, number_forward=number_forward)\n        else:\n            Log.warning(\n                \"Couldn't find the end of the request for {{request}}. \"\n                \"Max number that can be requested through _fill_in_range is {{maxnum}}.\",\n                request={\n                    'parent_cset': parent_cset,\n                    'child_cset':child_cset,\n                    'number_forward': number_forward\n                },\n                maxnum=MAX_BACKFILL_CLOGS * CHANGESETS_PER_CLOG\n            )\n            return None\n        return csets_to_add", "response": "Fill in the given parent_cset and child_cset."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexpect requests of the tuple form: (parent_cset, timestamp) parent_cset can be an int X to go back by X changesets, or a string to search for going backwards in time. If timestamp is false, no timestamps will be added to the entries. :param please_stop: :return:", "response": "def fill_backward_with_list(self, please_stop=None):\n        '''\n        Expects requests of the tuple form: (parent_cset, timestamp)\n        parent_cset can be an int X to go back by X changesets, or\n        a string to search for going backwards in time. If timestamp\n        is false, no timestamps will be added to the entries.\n        :param please_stop:\n        :return:\n        '''\n        while not please_stop:\n            try:\n                request = self.csets_todo_backwards.pop(till=please_stop)\n                if please_stop:\n                    break\n\n                # If backfilling is disabled, all requests\n                # are ignored.\n                if self.disable_backfilling:\n                    Till(till=CSET_BACKFILL_WAIT_TIME).wait()\n                    continue\n\n                if request:\n                    parent_cset, timestamp = request\n                else:\n                    continue\n\n                with self.working_locker:\n                    with self.conn.transaction() as t:\n                        parent_revnum = self._get_one_revnum(t, parent_cset)\n                    if parent_revnum:\n                        continue\n\n                    with self.conn.transaction() as t:\n                        _, oldest_revision = self.get_tail(t)\n\n                    self._fill_in_range(\n                        parent_cset,\n                        oldest_revision,\n                        timestamp=timestamp,\n                        number_forward=False\n                    )\n                Log.note(\"Finished {{cset}}\", cset=parent_cset)\n            except Exception as e:\n                Log.warning(\"Unknown error occurred during backfill: \", cause=e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the current tip in DB. Returns False if the tip is already at the newest or True if the update has taken place.", "response": "def update_tip(self):\n        '''\n        Returns False if the tip is already at the newest, or True\n        if an update has taken place.\n        :return:\n        '''\n        clog_obj = self._get_clog(self.tuid_service.hg_url / self.config.hg.branch / 'json-log' / 'tip')\n\n        # Get current tip in DB\n        with self.conn.transaction() as t:\n            _, newest_known_rev = self.get_tip(t)\n\n        # If we are still at the newest, wait for CSET_TIP_WAIT_TIME seconds\n        # before checking again.\n        first_clog_entry = clog_obj['changesets'][0]['node'][:12]\n        if newest_known_rev == first_clog_entry:\n            return False\n\n        csets_to_gather = None\n        if not newest_known_rev:\n            Log.note(\n                \"No revisions found in table, adding {{minim}} entries...\",\n                minim=MINIMUM_PERMANENT_CSETS\n            )\n            csets_to_gather = MINIMUM_PERMANENT_CSETS\n\n        found_newest_known = False\n        csets_to_add = []\n        csets_found = 0\n        clogs_seen = 0\n        Log.note(\"Found new revisions. Updating csetLog tip to {{rev}}...\", rev=first_clog_entry)\n        while not found_newest_known and clogs_seen < MAX_TIPFILL_CLOGS:\n            clog_csets_list = list(clog_obj['changesets'])\n            for clog_cset in clog_csets_list[:-1]:\n                nodes_cset = clog_cset['node'][:12]\n                if not csets_to_gather:\n                    if nodes_cset == newest_known_rev:\n                        found_newest_known = True\n                        break\n                else:\n                    if csets_found >= csets_to_gather:\n                        found_newest_known = True\n                        break\n                csets_found += 1\n                csets_to_add.append(nodes_cset)\n            if not found_newest_known:\n                # Get the next page\n                clogs_seen += 1\n                final_rev = clog_csets_list[-1]['node'][:12]\n                clog_url = self.tuid_service.hg_url / self.config.hg.branch / 'json-log' / final_rev\n                clog_obj = self._get_clog(clog_url)\n\n        if clogs_seen >= MAX_TIPFILL_CLOGS:\n            Log.error(\n                \"Too many changesets, can't find last tip or the number is too high: {{rev}}. \"\n                \"Maximum possible to request is {{maxnum}}\",\n                rev=coalesce(newest_known_rev, csets_to_gather),\n                maxnum=MAX_TIPFILL_CLOGS * CHANGESETS_PER_CLOG\n            )\n            return False\n\n        with self.working_locker:\n            Log.note(\"Adding {{csets}}\", csets=csets_to_add)\n            self.add_cset_entries(csets_to_add, timestamp=False)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle deleting old csetLog entries and timestamping revisions.", "response": "def csetLog_maintenance(self, please_stop=None):\n        '''\n        Handles deleting old csetLog entries and timestamping\n        revisions once they pass the length for permanent\n        storage for deletion later.\n        :param please_stop:\n        :return:\n        '''\n        while not please_stop:\n            try:\n                # Wait until something signals the maintenance cycle\n                # to begin (or end).\n                (self.maintenance_signal | please_stop).wait()\n\n                if please_stop:\n                    break\n                if self.disable_maintenance:\n                    continue\n\n                # Reset signal so we don't request\n                # maintenance infinitely.\n                with self.maintenance_signal.lock:\n                    self.maintenance_signal._go = False\n\n                with self.working_locker:\n                    all_data = None\n                    with self.conn.transaction() as t:\n                        all_data = sorted(\n                            t.get(\"SELECT revnum, revision, timestamp FROM csetLog\"),\n                            key=lambda x: int(x[0])\n                        )\n\n                    # Restore maximum permanents (if overflowing)\n                    new_data = []\n                    modified = False\n                    for count, (revnum, revision, timestamp) in enumerate(all_data[::-1]):\n                        if count < MINIMUM_PERMANENT_CSETS:\n                            if timestamp != -1:\n                                modified = True\n                                new_data.append((revnum, revision, -1))\n                            else:\n                                new_data.append((revnum, revision, timestamp))\n                        elif type(timestamp) != int or timestamp == -1:\n                            modified = True\n                            new_data.append((revnum, revision, int(time.time())))\n                        else:\n                            new_data.append((revnum, revision, timestamp))\n\n                    # Delete annotations at revisions with timestamps\n                    # that are too old. The csetLog entries will have\n                    # their timestamps reset here.\n                    new_data1 = []\n                    annrevs_to_del = []\n                    current_time = time.time()\n                    for count, (revnum, revision, timestamp) in enumerate(new_data[::-1]):\n                        new_timestamp = timestamp\n                        if timestamp != -1:\n                            if current_time >= timestamp + TIME_TO_KEEP_ANNOTATIONS.seconds:\n                                modified = True\n                                new_timestamp = current_time\n                                annrevs_to_del.append(revision)\n                        new_data1.append((revnum, revision, new_timestamp))\n\n                    if len(annrevs_to_del) > 0:\n                        # Delete any latestFileMod and annotation entries\n                        # that are too old.\n                        Log.note(\n                            \"Deleting annotations and latestFileMod for revisions for being \"\n                            \"older than {{oldest}}: {{revisions}}\",\n                            oldest=TIME_TO_KEEP_ANNOTATIONS,\n                            revisions=annrevs_to_del\n                        )\n                        with self.conn.transaction() as t:\n                            t.execute(\n                                \"DELETE FROM latestFileMod WHERE revision IN \" +\n                                quote_set(annrevs_to_del)\n                            )\n                            t.execute(\n                                \"DELETE FROM annotations WHERE revision IN \" +\n                                quote_set(annrevs_to_del)\n                            )\n\n                    # Delete any overflowing entries\n                    new_data2 = new_data1\n                    reved_all_data = all_data[::-1]\n                    deleted_data = reved_all_data[MAXIMUM_NONPERMANENT_CSETS:]\n                    delete_overflowing_revstart = None\n                    if len(deleted_data) > 0:\n                        _, delete_overflowing_revstart, _ = deleted_data[0]\n                        new_data2 = set(all_data) - set(deleted_data)\n\n                        # Update old frontiers if requested, otherwise\n                        # they will all get deleted by the csetLog_deleter\n                        # worker\n                        if UPDATE_VERY_OLD_FRONTIERS:\n                            _, max_revision, _ = all_data[-1]\n                            for _, revision, _ in deleted_data:\n                                with self.conn.transaction() as t:\n                                    old_files = t.get(\n                                        \"SELECT file FROM latestFileMod WHERE revision=?\",\n                                        (revision,)\n                                    )\n                                if old_files is None or len(old_files) <= 0:\n                                    continue\n\n                                self.tuid_service.get_tuids_from_files(\n                                    old_files,\n                                    max_revision,\n                                    going_forward=True,\n                                )\n\n                                still_exist = True\n                                while still_exist and not please_stop:\n                                    Till(seconds=TUID_EXISTENCE_WAIT_TIME).wait()\n                                    with self.conn.transaction() as t:\n                                        old_files = t.get(\n                                            \"SELECT file FROM latestFileMod WHERE revision=?\",\n                                            (revision,)\n                                        )\n                                    if old_files is None or len(old_files) <= 0:\n                                        still_exist = False\n\n                    # Update table and schedule a deletion\n                    if modified:\n                        with self.conn.transaction() as t:\n                            t.execute(\n                                \"INSERT OR REPLACE INTO csetLog (revnum, revision, timestamp) VALUES \" +\n                                sql_list(\n                                    quote_set(cset_entry)\n                                    for cset_entry in new_data2\n                                )\n                            )\n                    if not deleted_data:\n                        continue\n\n                    Log.note(\"Scheduling {{num_csets}} for deletion\", num_csets=len(deleted_data))\n                    self.deletions_todo.add(delete_overflowing_revstart)\n            except Exception as e:\n                Log.warning(\"Unexpected error occured while maintaining csetLog, continuing to try: \", cause=e)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef csetLog_deleter(self, please_stop=None):\n        '''\n        Deletes changesets from the csetLog table\n        and also changesets from the annotation table\n        that have revisions matching the given changesets.\n        Accepts lists of csets from self.deletions_todo.\n        :param please_stop:\n        :return:\n        '''\n        while not please_stop:\n            try:\n                request = self.deletions_todo.pop(till=please_stop)\n                if please_stop:\n                    break\n\n                # If deletion is disabled, ignore the current\n                # request - it will need to be re-requested.\n                if self.disable_deletion:\n                    Till(till=CSET_DELETION_WAIT_TIME).wait()\n                    continue\n\n                with self.working_locker:\n                    first_cset = request\n\n                    # Since we are deleting and moving stuff around in the\n                    # TUID tables, we need everything to be contained in\n                    # one transaction with no interruptions.\n                    with self.conn.transaction() as t:\n                        revnum = self._get_one_revnum(t, first_cset)[0]\n                        csets_to_del = t.get(\n                            \"SELECT revnum, revision FROM csetLog WHERE revnum <= ?\", (revnum,)\n                        )\n                        csets_to_del = [cset for _, cset in csets_to_del]\n                        existing_frontiers = t.query(\n                            \"SELECT revision FROM latestFileMod WHERE revision IN \" +\n                            quote_set(csets_to_del)\n                        ).data\n\n                        existing_frontiers = [existing_frontiers[i][0] for i, _ in enumerate(existing_frontiers)]\n                        Log.note(\n                            \"Deleting all annotations and changeset log entries with revisions in the list: {{csets}}\",\n                            csets=csets_to_del\n                        )\n\n                        if len(existing_frontiers) > 0:\n                            # This handles files which no longer exist anymore in\n                            # the main branch.\n                            Log.note(\n                                \"Deleting existing frontiers for revisions: {{revisions}}\",\n                                revisions=existing_frontiers\n                            )\n                            t.execute(\n                                \"DELETE FROM latestFileMod WHERE revision IN \" +\n                                quote_set(existing_frontiers)\n                            )\n\n                        Log.note(\"Deleting annotations...\")\n                        t.execute(\n                            \"DELETE FROM annotations WHERE revision IN \" +\n                            quote_set(csets_to_del)\n                        )\n\n                        Log.note(\n                            \"Deleting {{num_entries}} csetLog entries...\",\n                            num_entries=len(csets_to_del)\n                        )\n                        t.execute(\n                            \"DELETE FROM csetLog WHERE revision IN \" +\n                            quote_set(csets_to_del)\n                        )\n\n                    # Recalculate the revnums\n                    self.recompute_table_revnums()\n            except Exception as e:\n                Log.warning(\"Unexpected error occured while deleting from csetLog:\", cause=e)\n                Till(seconds=CSET_DELETION_WAIT_TIME).wait()\n        return", "response": "Delete all changesets from the annotation table and also the changeset log entries that have revisions matching the given changesets."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new class in the order that the properties of the given columns are defined.", "response": "def DataClass(name, columns, constraint=None):\n    \"\"\"\n    Use the DataClass to define a class, but with some extra features:\n    1. restrict the datatype of property\n    2. restrict if `required`, or if `nulls` are allowed\n    3. generic constraints on object properties\n\n    It is expected that this class become a real class (or be removed) in the\n    long term because it is expensive to use and should only be good for\n    verifying program correctness, not user input.\n\n    :param name: Name of the class we are creating\n    :param columns: Each columns[i] has properties {\n            \"name\",     - (required) name of the property\n            \"required\", - False if it must be defined (even if None)\n            \"nulls\",    - True if property can be None, or missing\n            \"default\",  - A default value, if none is provided\n            \"type\"      - a Python datatype\n        }\n    :param constraint: a JSON query Expression for extra constraints (return true if all constraints are met)\n    :return: The class that has been created\n    \"\"\"\n\n    columns = wrap(\n        [\n            {\"name\": c, \"required\": True, \"nulls\": False, \"type\": object}\n            if is_text(c)\n            else c\n            for c in columns\n        ]\n    )\n    slots = columns.name\n    required = wrap(\n        filter(lambda c: c.required and not c.nulls and not c.default, columns)\n    ).name\n    nulls = wrap(filter(lambda c: c.nulls, columns)).name\n    defaults = {c.name: coalesce(c.default, None) for c in columns}\n    types = {c.name: coalesce(c.jx_type, object) for c in columns}\n\n    code = expand_template(\n        \"\"\"\nfrom __future__ import unicode_literals\nfrom mo_future import is_text, is_binary\nfrom collections import Mapping\n\nmeta = None\ntypes_ = {{types}}\ndefaults_ = {{defaults}}\n\nclass {{class_name}}(Mapping):\n    __slots__ = {{slots}}\n\n\n    def _constraint(row, rownum, rows):\n        try:\n            return {{constraint_expr}}\n        except Exception as e:\n            return False\n\n    def __init__(self, **kwargs):\n        if not kwargs:\n            return\n\n        for s in {{slots}}:\n            object.__setattr__(self, s, kwargs.get(s, {{defaults}}.get(s, None)))\n\n        missed = {{required}}-set(kwargs.keys())\n        if missed:\n            Log.error(\"Expecting properties {\"+\"{missed}}\", missed=missed)\n\n        illegal = set(kwargs.keys())-set({{slots}})\n        if illegal:\n            Log.error(\"{\"+\"{names}} are not a valid properties\", names=illegal)\n\n        if not self._constraint(0, [self]):\n            Log.error(\"constraint not satisfied {\"+\"{expect}}\\\\n{\"+\"{value|indent}}\", expect={{constraint}}, value=self)\n\n    def __getitem__(self, item):\n        return getattr(self, item)\n\n    def __setitem__(self, item, value):\n        setattr(self, item, value)\n        return self\n\n    def __setattr__(self, item, value):\n        if item not in {{slots}}:\n            Log.error(\"{\"+\"{item|quote}} not valid attribute\", item=item)\n        object.__setattr__(self, item, value)\n        if not self._constraint(0, [self]):\n            Log.error(\"constraint not satisfied {\"+\"{expect}}\\\\n{\"+\"{value|indent}}\", expect={{constraint}}, value=self)\n\n    def __getattr__(self, item):\n        Log.error(\"{\"+\"{item|quote}} not valid attribute\", item=item)\n\n    def __hash__(self):\n        return object.__hash__(self)\n\n    def __eq__(self, other):\n        if isinstance(other, {{class_name}}) and dict(self)==dict(other) and self is not other:\n            Log.error(\"expecting to be same object\")\n        return self is other\n\n    def __dict__(self):\n        return {k: getattr(self, k) for k in {{slots}}}\n\n    def items(self):\n        return ((k, getattr(self, k)) for k in {{slots}})\n\n    def __copy__(self):\n        _set = object.__setattr__\n        output = object.__new__({{class_name}})\n        {{assign}}\n        return output\n\n    def __iter__(self):\n        return {{slots}}.__iter__()\n\n    def __len__(self):\n        return {{len_slots}}\n\n    def __str__(self):\n        return str({{dict}})\n\n\"\"\",\n        {\n            \"class_name\": name,\n            \"slots\": \"(\" + (\", \".join(quote(s) for s in slots)) + \")\",\n            \"required\": \"{\" + (\", \".join(quote(s) for s in required)) + \"}\",\n            \"nulls\": \"{\" + (\", \".join(quote(s) for s in nulls)) + \"}\",\n            \"defaults\": Literal(defaults).to_python(),\n            \"len_slots\": len(slots),\n            \"dict\": \"{\" + (\", \".join(quote(s) + \": self.\" + s for s in slots)) + \"}\",\n            \"assign\": \"; \".join(\n                \"_set(output, \" + quote(s) + \", self.\" + s + \")\" for s in slots\n            ),\n            \"types\": \"{\"\n            + (\",\".join(quote(k) + \": \" + v.__name__ for k, v in types.items()))\n            + \"}\",\n            \"constraint_expr\": Python[jx_expression(constraint)].to_python(),\n            \"constraint\": value2json(constraint),\n        },\n    )\n\n    output = _exec(code, name)\n    register_data(output)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates signature with the SIG_METHOD ( HMAC - SHA1", "response": "def sign(self, method, params):\n        \"\"\"Calculate signature with the SIG_METHOD(HMAC-SHA1)\n        Returns a base64 encoeded string of the hex signature\n\n        :param method: the http verb\n        :param params: the params needs calculate\n        \"\"\"\n        query_str = utils.percent_encode(params.items(), True)\n\n        str_to_sign = \"{0}&%2F&{1}\".format(\n            method, utils.percent_quote(query_str)\n        )\n\n        sig = hmac.new(\n            utils.to_bytes(self._secret_key + \"&\"),\n            utils.to_bytes(str_to_sign),\n            hashlib.sha1\n        )\n        return base64.b64encode(sig.digest())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the full path of the executable.", "response": "def getPathOfExecutable(executable):\n    \"\"\"\n    Returns the full path of the executable, or None if the executable\n    can not be found.\n    \"\"\"\n    exe_paths = os.environ['PATH'].split(':')\n    for exe_path in exe_paths:\n        exe_file = os.path.join(exe_path, executable)\n        if os.path.isfile(exe_file) and os.access(exe_file, os.X_OK):\n            return exe_file\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck that all of the given executables are on the path.", "response": "def requireExecutables(executables):\n    \"\"\"\n    Check that all of the given executables are on the path.\n    If at least one of them is not, exit the script and inform\n    the user of the missing requirement(s).\n    \"\"\"\n    missingExecutables = []\n    for executable in executables:\n        if getPathOfExecutable(executable) is None:\n            missingExecutables.append(executable)\n    if len(missingExecutables) > 0:\n        log(\"In order to run this script, the following \"\n            \"executables need to be on the path:\")\n        for missingExecutable in missingExecutables:\n            log(missingExecutable)\n        exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun a shell command and returns the stdout and stderr", "response": "def runCommandReturnOutput(cmd):\n    \"\"\"\n    Runs a shell command and return the stdout and stderr\n    \"\"\"\n    splits = shlex.split(cmd)\n    proc = subprocess.Popen(\n        splits, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout, stderr = proc.communicate()\n    if proc.returncode != 0:\n        raise subprocess.CalledProcessError(stdout, stderr)\n    return stdout, stderr"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a yaml file s contents as a dictionary", "response": "def getYamlDocument(filePath):\n    \"\"\"\n    Return a yaml file's contents as a dictionary\n    \"\"\"\n    with open(filePath) as stream:\n        doc = yaml.load(stream)\n        return doc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef captureOutput(func, *args, **kwargs):\n    stdout = sys.stdout\n    sys.stdout = StringIO.StringIO()\n    stderr = sys.stderr\n    sys.stderr = StringIO.StringIO()\n    try:\n        func(*args, **kwargs)\n        stdoutOutput = sys.stdout.getvalue()\n        stderrOutput = sys.stderr.getvalue()\n    finally:\n        sys.stdout.close()\n        sys.stdout = stdout\n        sys.stderr.close()\n        sys.stderr = stderr\n    return stdoutOutput, stderrOutput", "response": "Runs the specified function and arguments and returns the stdout and stderr as strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of lists that are all of the same length.", "response": "def zipLists(*lists):\n    \"\"\"\n    Checks to see if all of the lists are the same length, and throws\n    an AssertionError otherwise.  Returns the zipped lists.\n    \"\"\"\n    length = len(lists[0])\n    for i, list_ in enumerate(lists[1:]):\n        if len(list_) != length:\n            msg = \"List at index {} has length {} != {}\".format(\n                i + 1, len(list_), length)\n            raise AssertionError(msg)\n    return zip(*lists)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getLinesFromLogFile(stream):\n    stream.flush()\n    stream.seek(0)\n    lines = stream.readlines()\n    return lines", "response": "Returns all lines written to the passed in stream"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getFilePathsWithExtensionsInDirectory(dirTree, patterns, sort=True):\n    filePaths = []\n    for root, dirs, files in os.walk(dirTree):\n        for filePath in files:\n            for pattern in patterns:\n                if fnmatch.fnmatch(filePath, pattern):\n                    fullPath = os.path.join(root, filePath)\n                    filePaths.append(fullPath)\n                    break\n    if sort:\n        filePaths.sort()\n    return filePaths", "response": "Returns all file paths that match any one of patterns in dirTree."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nchange the current working directory to dirPath before performing an operation, then restore the original working directory after", "response": "def performInDirectory(dirPath):\n    \"\"\"\n    Change the current working directory to dirPath before performing\n    an operation, then restore the original working directory after\n    \"\"\"\n    originalDirectoryPath = os.getcwd()\n    try:\n        os.chdir(dirPath)\n        yield\n    finally:\n        os.chdir(originalDirectoryPath)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the filenames that this par2 file repairs.", "response": "def filenames(self):\n        \"\"\"Returns the filenames that this par2 file repairs.\"\"\"\n        return [p.name for p in self.packets if isinstance(p, FileDescriptionPacket)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef related_pars(self):\n        if not self.path:\n            return []\n        names = [self.path]\n        basename = self.path.replace('.par2', '').replace('.PAR2', '')\n        names += fileutil.cibaseglob('*.vol*.PAR2', basename)\n        return names", "response": "Returns a list of related par2 files."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the slot names to Null.", "response": "def _set_slots_to_null(self, cls):\n        \"\"\"\n        WHY ARE SLOTS NOT ACCESIBLE UNTIL WE ASSIGN TO THEM?\n        \"\"\"\n        if hasattr(cls, \"__slots__\"):\n            for s in cls.__slots__:\n                self.__setattr__(s, Null)\n        for b in cls.__bases__:\n            self._set_slots_to_null(b)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main():\n    def die((x, y)):\n        \"\"\"Pretend any out-of-bounds cell is dead.\"\"\"\n        if 0 <= x < width and 0 <= y < height:\n            return x, y\n\n    LOAD_FACTOR = 9  # Smaller means more crowded.\n    NUDGING_LOAD_FACTOR = LOAD_FACTOR * 3  # Smaller means a bigger nudge.\n\n    term = Terminal()\n    width = term.width\n    height = term.height\n    board = random_board(width - 1, height - 1, LOAD_FACTOR)\n    detector = BoredomDetector()\n    cells = cell_strings(term)\n\n    with nested(term.fullscreen(), term.hidden_cursor()):\n        try:\n            while True:\n                frame_end = time() + 0.05\n                board = next_board(board, die)\n                draw(board, term, cells)\n\n                # If the pattern is stuck in a loop, give it a nudge:\n                if detector.is_bored_of(board):\n                    board.update(random_board(width - 1,\n                                              height - 1,\n                                              NUDGING_LOAD_FACTOR))\n\n                stdout.flush()\n                sleep_until(frame_end)\n                clear(board, term, height)\n        except KeyboardInterrupt:\n            pass", "response": "Play Conway s Game of Life on the terminal."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cell_strings(term):\n    num_colors = term.number_of_colors\n    if num_colors >= 16:\n        funcs = term.on_bright_red, term.on_bright_green, term.on_bright_cyan\n    elif num_colors >= 8:\n        funcs = term.on_red, term.on_green, term.on_blue\n    else:\n        # For black and white, use the checkerboard cursor from the vt100\n        # alternate charset:\n        return (term.reverse(' '),\n                term.smacs + term.reverse('a') + term.rmacs,\n                term.smacs + 'a' + term.rmacs)\n    # Wrap spaces in whatever pretty colors we chose:\n    return [f(' ') for f in funcs]", "response": "Return the strings that represent each possible living cell state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a random board with given max x and y coords.", "response": "def random_board(max_x, max_y, load_factor):\n    \"\"\"Return a random board with given max x and y coords.\"\"\"\n    return dict(((randint(0, max_x), randint(0, max_y)), 0) for _ in\n                xrange(int(max_x * max_y / load_factor)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear(board, term, height):\n    for y in xrange(height):\n        print term.move(y, 0) + term.clear_eol,", "response": "Clear the droppings of the given board."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef draw(board, term, cells):\n    for (x, y), state in board.iteritems():\n        with term.location(x, y):\n            print cells[state],", "response": "Draw a board to the terminal."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef next_board(board, wrap):\n    new_board = {}\n\n    # We need consider only the points that are alive and their neighbors:\n    points_to_recalc = set(board.iterkeys()) | set(chain(*map(neighbors, board)))\n\n    for point in points_to_recalc:\n        count = sum((neigh in board) for neigh in\n                    (wrap(n) for n in neighbors(point) if n))\n        if count == 3:\n            state = 0 if point in board else 1\n        elif count == 2 and point in board:\n            state = 2\n        else:\n            state = None\n\n        if state is not None:\n            wrapped = wrap(point)\n            if wrapped:\n                new_board[wrapped] = state\n\n    return new_board", "response": "Given a board return the next board that is not already in the board."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef neighbors((x, y)):\n    yield x + 1, y\n    yield x - 1, y\n    yield x, y + 1\n    yield x, y - 1\n    yield x + 1, y + 1\n    yield x + 1, y - 1\n    yield x - 1, y + 1\n    yield x - 1, y - 1", "response": "Return the neighbors of a point."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_bored_of(self, board):\n        self.iteration += 1\n        if len(board) == self.num:\n            self.times += 1\n        is_bored = self.times > self.REPETITIONS\n        if self.iteration > self.REPETITIONS * self.PATTERN_LENGTH or is_bored:\n            # A little randomness in case things divide evenly into each other:\n            self.iteration = randint(-2, 0)\n            self.num = len(board)\n            self.times = 0\n        return is_bored", "response": "Return whether the simulation is probably in a loop."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef droit_d_accise(depense, droit_cn, consommation_cn, taux_plein_tva):\n    return depense * ((1 + taux_plein_tva) * droit_cn) / (consommation_cn - (1 + taux_plein_tva) * droit_cn)", "response": "Calcule le montant de droit d accise sur un volume de depense pay\u00e9 pour le poste ad\u00e9quat."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a value to the queue.", "response": "def add(self, value, timeout=None, force=False):\n        \"\"\"\n        :param value:  ADDED THE THE QUEUE\n        :param timeout:  HOW LONG TO WAIT FOR QUEUE TO NOT BE FULL\n        :param force:  ADD TO QUEUE, EVEN IF FULL (USE ONLY WHEN CONSUMER IS RETURNING WORK TO THE QUEUE)\n        :return: self\n        \"\"\"\n        with self.lock:\n            if value is THREAD_STOP:\n                # INSIDE THE lock SO THAT EXITING WILL RELEASE wait()\n                self.queue.append(value)\n                self.closed.go()\n                return\n\n            if not force:\n                self._wait_for_queue_space(timeout=timeout)\n            if self.closed and not self.allow_add_after_close:\n                Log.error(\"Do not add to closed queue\")\n            else:\n                if self.unique:\n                    if value not in self.queue:\n                        self.queue.append(value)\n                else:\n                    self.queue.append(value)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npushes a value to the end of the queue.", "response": "def push(self, value):\n        \"\"\"\n        SNEAK value TO FRONT OF THE QUEUE\n        \"\"\"\n        if self.closed and not self.allow_add_after_close:\n            Log.error(\"Do not push to closed queue\")\n\n        with self.lock:\n            self._wait_for_queue_space()\n            if not self.closed:\n                self.queue.appendleft(value)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pop_message(self, till=None):\n\n        if till is not None and not isinstance(till, Signal):\n            Log.error(\"Expecting a signal\")\n        return Null, self.pop(till=till)", "response": "Pops a message from the queue."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _wait_for_queue_space(self, timeout=DEFAULT_WAIT_TIME):\n        wait_time = 5\n\n        (DEBUG and len(self.queue) > 1 * 1000 * 1000) and Log.warning(\"Queue {{name}} has over a million items\")\n\n        now = time()\n        if timeout != None:\n            time_to_stop_waiting = now + timeout\n        else:\n            time_to_stop_waiting = now + DEFAULT_WAIT_TIME\n\n        if self.next_warning < now:\n            self.next_warning = now + wait_time\n\n        while not self.closed and len(self.queue) >= self.max:\n            if now > time_to_stop_waiting:\n                Log.error(THREAD_TIMEOUT)\n\n            if self.silent:\n                self.lock.wait(Till(till=time_to_stop_waiting))\n            else:\n                self.lock.wait(Till(seconds=wait_time))\n                if len(self.queue) >= self.max:\n                    now = time()\n                    if self.next_warning < now:\n                        self.next_warning = now + wait_time\n                        Log.alert(\n                            \"Queue by name of {{name|quote}} is full with ({{num}} items), thread(s) have been waiting {{wait_time}} sec\",\n                            name=self.name,\n                            num=len(self.queue),\n                            wait_time=wait_time\n                        )", "response": "Waits for the queue to have at least self. max items and adds a new lock to the queue until self. max is reached."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pop_all(self):\n        with self.lock:\n            output = list(self.queue)\n            self.queue.clear()\n\n        return output", "response": "POP ALL IN QUEUE"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pop_one(self):\n        with self.lock:\n            if self.closed:\n                return [THREAD_STOP]\n            elif not self.queue:\n                return None\n            else:\n                v =self.queue.pop()\n                if v is THREAD_STOP:  # SENDING A STOP INTO THE QUEUE IS ALSO AN OPTION\n                    self.closed.go()\n                return v", "response": "Pops one item from the queue."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npop a value from the queue.", "response": "def pop(self, till=None, priority=None):\n        \"\"\"\n        WAIT FOR NEXT ITEM ON THE QUEUE\n        RETURN THREAD_STOP IF QUEUE IS CLOSED\n        RETURN None IF till IS REACHED AND QUEUE IS STILL EMPTY\n\n        :param till:  A `Signal` to stop waiting and return None\n        :return:  A value, or a THREAD_STOP or None\n        \"\"\"\n        if till is not None and not isinstance(till, Signal):\n            Log.error(\"expecting a signal\")\n\n        with self.lock:\n            while True:\n                if not priority:\n                    priority = self.highest_entry()\n                if priority:\n                    value = self.queue[priority].queue.popleft()\n                    return value\n                if self.closed:\n                    break\n                if not self.lock.wait(till=till | self.closed):\n                    if self.closed:\n                        break\n                    return None\n        (DEBUG or not self.silent) and Log.note(self.name + \" queue stopped\")\n        return THREAD_STOP"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pop_all(self, priority=None):\n        output = []\n        with self.lock:\n            if not priority:\n                priority = self.highest_entry()\n            if priority:\n                output = list(self.queue[priority].queue)\n                self.queue[priority].queue.clear()\n        return output", "response": "POP ALL IN QUEUE IF ANY"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npop ALL IN QUEUE IF ANY", "response": "def pop_all_queues(self):\n        \"\"\"\n        NON-BLOCKING POP ALL IN QUEUE, IF ANY\n        \"\"\"\n        output = []\n        with self.lock:\n            for q in self.queue:\n                output.extend(list(q.queue))\n                q.queue.clear()\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npops one item from the queue.", "response": "def pop_one(self, priority=None):\n        \"\"\"\n        NON-BLOCKING POP IN QUEUE, IF ANY\n        \"\"\"\n        with self.lock:\n            if not priority:\n                priority = self.highest_entry()\n            if self.closed:\n                return [THREAD_STOP]\n            elif not self.queue:\n                return None\n            else:\n                v =self.pop(priority=priority)\n                if v is THREAD_STOP:  # SENDING A STOP INTO THE QUEUE IS ALSO AN OPTION\n                    self.closed.go()\n                return v"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef typed_encode(self, r):\n        try:\n            value = r.get('value')\n            if \"json\" in r:\n                value = json2value(r[\"json\"])\n            elif is_data(value) or value != None:\n                pass\n            else:\n                from mo_logs import Log\n                raise Log.error(\"Expecting every record given to have \\\"value\\\" or \\\"json\\\" property\")\n\n            _buffer = UnicodeBuilder(1024)\n            net_new_properties = []\n            path = []\n            if is_data(value):\n                given_id = self.get_id(value)\n                value['_id'] = None\n                version = self.get_version(value)\n            else:\n                given_id = None\n                version = None\n\n            if given_id:\n                record_id = r.get('id')\n                if record_id and record_id != given_id:\n                    from mo_logs import Log\n\n                    raise Log.error(\n                        \"expecting {{property}} of record ({{record_id|quote}}) to match one given ({{given|quote}})\",\n                        property=self.id_info,\n                        record_id=record_id,\n                        given=given_id\n                    )\n            else:\n                record_id = r.get('id')\n                if record_id:\n                    given_id = record_id\n                else:\n                    given_id = random_id()\n\n            typed_encode(value, self.schema, path, net_new_properties, _buffer)\n            json = _buffer.build()\n\n            return given_id, version, json\n        except Exception as e:\n            # THE PRETTY JSON WILL PROVIDE MORE DETAIL ABOUT THE SERIALIZATION CONCERNS\n            from mo_logs import Log\n\n            Log.error(\"Serialization of JSON problems\", cause=e)", "response": "This function encodes a single record into a dict with id and json properties."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn RANDOM INDEX INTO WEIGHTS GIVEN WEIGHTS", "response": "def weight(weights):\n        \"\"\"\n        RETURN RANDOM INDEX INTO WEIGHT ARRAY, GIVEN WEIGHTS\n        \"\"\"\n        total = sum(weights)\n\n        p = SEED.random()\n        acc = 0\n        for i, w in enumerate(weights):\n            acc += w / total\n            if p < acc:\n                return i\n        return len(weights) - 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms AES block cipher on input", "response": "def cipher_block (self, state):\n        \"\"\"Perform AES block cipher on input\"\"\"\n        # PKCS7 Padding\n        state=state+[16-len(state)]*(16-len(state))# Fails test if it changes the input with +=\n\n        self._add_round_key(state, 0)\n\n        for i in range(1, self._Nr):\n            self._sub_bytes(state)\n            self._shift_rows(state)\n            self._mix_columns(state, False)\n            self._add_round_key(state, i)\n\n        self._sub_bytes(state)\n        self._shift_rows(state)\n        self._add_round_key(state, self._Nr)\n        return state"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decipher_block (self, state):\n        if len(state) != 16:\n            Log.error(u\"Expecting block of 16\")\n\n        self._add_round_key(state, self._Nr)\n\n        for i in range(self._Nr - 1, 0, -1):\n            self._i_shift_rows(state)\n            self._i_sub_bytes(state)\n            self._add_round_key(state, i)\n            self._mix_columns(state, True)\n\n        self._i_shift_rows(state)\n        self._i_sub_bytes(state)\n        self._add_round_key(state, 0)\n        return state", "response": "Perform AES block decipher on input"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndry run : simulate sql execution.", "response": "def dry_run(func):\n    \"\"\"Dry run: simulate sql execution.\"\"\"\n    @wraps(func)\n    def inner(dry_run, *args, **kwargs):\n        ret = func(dry_run=dry_run, *args, **kwargs)\n        if not dry_run:\n            db.session.commit()\n        else:\n            db.session.rollback()\n        return ret\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nshowing the tree of the collection ( s ) specified.", "response": "def tree(names):\n    \"\"\"Show the tree of the collection(s) specified.\"\"\"\n    # query\n    query = Collection.query\n    if names:\n        query = query.filter(Collection.name.in_(names))\n    else:\n        query = query.filter(Collection.level == 1)\n    # print tree\n    tr = LeftAligned(traverse=AttributeTraversal())\n    for coll in query.all():\n        click.secho(tr(coll))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef path(name):\n    try:\n        coll = Collection.query.filter(Collection.name == name).one()\n        tr = LeftAligned(\n            traverse=CollTraversalPathToRoot(coll.path_to_root().all()))\n        click.echo(tr(coll))\n    except NoResultFound:\n        raise click.UsageError('Collection {0} not found'.format(name))", "response": "Print path to root."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint the collection query.", "response": "def query(name):\n    \"\"\"Print the collection query.\"\"\"\n    collection = Collection.query.filter_by(name=name).one()\n    click.echo(collection.dbquery)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef attach(names, parent, dry_run, verbose):\n    parent = Collection.query.filter_by(name=parent).one()\n    collections = Collection.query.filter(Collection.name.in_(names)).all()\n    for collection in collections:\n        collection.move_inside(parent.id)\n        if verbose:\n            click.secho(\n                'Collection \"{0}\" is being attached to \"{1}\".'.format(\n                    collection.name, parent\n                ), fg='green')", "response": "Attach collection s to a parent."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_text(self, node):\n        return click.style(\n            repr(node), fg='green' if node.level > 1 else 'red'\n        )", "response": "Get node text representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisplaying information about a Tibia character.", "response": "def cli_char(name, tibiadata, json):\n    \"\"\"Displays information about a Tibia character.\"\"\"\n    name = \" \".join(name)\n    char = _fetch_and_parse(Character.get_url, Character.from_content,\n                            Character.get_url_tibiadata, Character.from_tibiadata,\n                            tibiadata, name)\n    if json and char:\n        print(char.to_json(indent=2))\n        return\n    print(get_character_string(char))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndisplay information about a Tibia guild.", "response": "def cli_guild(name, tibiadata, json):\n    \"\"\"Displays information about a Tibia guild.\"\"\"\n    name = \" \".join(name)\n    guild = _fetch_and_parse(Guild.get_url, Guild.from_content,\n                             Guild.get_url_tibiadata, Guild.from_tibiadata,\n                             tibiadata, name)\n    if json and guild:\n        print(guild.to_json(indent=2))\n        return\n    print(get_guild_string(guild))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cli_guilds(world, tibiadata, json):\n    world = \" \".join(world)\n    guilds = _fetch_and_parse(ListedGuild.get_world_list_url, ListedGuild.list_from_content,\n                              ListedGuild.get_world_list_url_tibiadata, ListedGuild.list_from_tibiadata,\n                              tibiadata, world)\n    if json and guilds:\n        import json as _json\n        print(_json.dumps(guilds, default=dict, indent=2))\n        return\n    print(get_guilds_string(guilds))", "response": "Displays the list of guilds for a specific world"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all unseen events that have not been seen on this medium.", "response": "def _unseen_event_ids(medium):\n    \"\"\"\n    Return all events that have not been seen on this medium.\n    \"\"\"\n    query = '''\n    SELECT event.id\n    FROM entity_event_event AS event\n        LEFT OUTER JOIN (SELECT *\n                         FROM entity_event_eventseen AS seen\n                         WHERE seen.medium_id=%s) AS eventseen\n            ON event.id = eventseen.event_id\n    WHERE eventseen.medium_id IS NULL\n    '''\n    unseen_events = Event.objects.raw(query, params=[medium.id])\n    ids = [e.id for e in unseen_events]\n    return ids"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate EventSeen objects for every event in the queryset that have been seen for the given medium.", "response": "def mark_seen(self, medium):\n        \"\"\"\n        Creates EventSeen objects for the provided medium for every event\n        in the queryset.\n\n        Creating these EventSeen objects ensures they will not be\n        returned when passing ``seen=False`` to any of the medium\n        event retrieval functions, ``events``, ``entity_events``, or\n        ``events_targets``.\n        \"\"\"\n        EventSeen.objects.bulk_create([\n            EventSeen(event=event, medium=medium) for event in self\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_event(self, actors=None, ignore_duplicates=False, **kwargs):\n        kwargs['actors'] = actors\n        kwargs['ignore_duplicates'] = ignore_duplicates\n\n        events = self.create_events([kwargs])\n\n        if events:\n            return events[0]\n\n        return None", "response": "Creates an event with the given actors and context."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_events(self, kwargs_list):\n        # Build map of uuid to event info\n        uuid_map = {\n            kwargs.get('uuid', ''): {\n                'actors': kwargs.pop('actors', []),\n                'ignore_duplicates': kwargs.pop('ignore_duplicates', False),\n                'event_kwargs': kwargs\n\n            }\n            for kwargs in kwargs_list\n        }\n\n        # Check for uuids\n        uuid_set = set(Event.objects.filter(uuid__in=uuid_map.keys()).values_list('uuid', flat=True))\n\n        # Set a flag for whether each uuid exists\n        for uuid, event_dict in uuid_map.items():\n            event_dict['exists'] = uuid in uuid_set\n\n        # Build list of events to bulk create\n        events_to_create = []\n        for uuid, event_dict in uuid_map.items():\n            # If the event doesn't already exist or the event does exist but we are allowing duplicates\n            if not event_dict['exists'] or not event_dict['ignore_duplicates']:\n                events_to_create.append(Event(**event_dict['event_kwargs']))\n\n        # Bulk create the events\n        created_events = Event.objects.bulk_create(events_to_create)\n\n        # Build list of EventActor objects to bulk create\n        event_actors_to_create = []\n        for created_event in created_events:\n            event_dict = uuid_map[created_event.uuid]\n            if event_dict['actors'] is not None:\n                for actor in event_dict['actors']:\n                    actor_id = actor.id if hasattr(actor, 'id') else actor\n                    event_actors_to_create.append(EventActor(entity_id=actor_id, event=created_event))\n\n        EventActor.objects.bulk_create(event_actors_to_create)\n\n        return created_events", "response": "Create events in bulk to save on queries."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the list of the right node.", "response": "def right(self, num=None):\n        \"\"\"\n        WITH SLICES BEING FLAT, WE NEED A SIMPLE WAY TO SLICE FROM THE RIGHT [-num:]\n        \"\"\"\n        if num == None:\n            return self.last.node\n        if num <= 0:\n            return []\n\n        if not self.list:\n            self._build_list()\n        return self.list[-num:]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the list of the items that are not on the right.", "response": "def not_right(self, num):\n        \"\"\"\n        WITH SLICES BEING FLAT, WE NEED A SIMPLE WAY TO SLICE FROM THE LEFT [:-num:]\n        \"\"\"\n        if not self.list:\n            self._build_list()\n\n        if num == None:\n            return self.list[:-1:]\n        if num <= 0:\n            return []\n\n        return self.list[:-num:]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_object_url(self):\n\n        if self.kwargs.get(self.slug_url_kwarg, False) == \\\n                    unicode(getattr(self.object, self.slug_field, \"\")) \\\n                    and not self.force_add:\n            url = self.request.build_absolute_uri()\n        else:\n            url = self.bundle.get_view_url('edit', self.request.user,\n                                           {'object': self.object},\n                                           self.kwargs)\n        return url", "response": "Returns the url where this object can be edited."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the cancel url for this view.", "response": "def get_cancel_url(self):\n        \"\"\"\n        Returns the cancel url for this view.\n\n        if `self.cancel_view` is None the current url will\n        be used. Otherwise the get_view_url will be called with\n        the current bundle using `self.cancel_view` as the\n        view name.\n        \"\"\"\n        if self.cancel_view:\n            url = self.bundle.get_view_url(self.cancel_view,\n                                            self.request.user, {},\n                                            self.kwargs)\n        else:\n            url = self.request.build_absolute_uri()\n\n        return self.customized_return_url(url)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_success_url(self):\n\n        if self.redirect_to_view:\n            kwargs = {}\n            if self.redirect_to_view != 'main' and \\\n                        self.redirect_to_view != 'main_list':\n                kwargs['object'] = self.object\n            return self.bundle.get_view_url(self.redirect_to_view,\n                                            self.request.user, kwargs,\n                                            self.kwargs)\n        else:\n            return self.request.build_absolute_uri()", "response": "Returns the url to redirect to after a successful update."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the object we are working with. Makes sure that the queryset is called even when in add mode.", "response": "def get_object(self):\n        \"\"\"\n        Get the object we are working with. Makes sure\n        get_queryset is called even when in add mode.\n        \"\"\"\n\n        if not self.force_add and self.kwargs.get(self.slug_url_kwarg, None):\n            return super(FormView, self).get_object()\n        else:\n            self.queryset = self.get_queryset()\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_fieldsets(self):\n\n        if self.fieldsets:\n            return self.fieldsets\n        form_class = self.get_form_class()\n        form = self.get_form(form_class)\n        fields = form.base_fields.keys()\n\n        readonly_fields = self.get_readonly_fields()\n        if readonly_fields:\n            fields.extend(readonly_fields)\n\n        return [(None, {'fields': fields})]", "response": "Hook for specifying fieldsets."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the form class to use in this view.", "response": "def get_form_class(self):\n        \"\"\"\n        Returns the form class to use in this view. Makes\n        sure that the form_field_callback is set to use\n        the `formfield_for_dbfield` method and that any\n        custom form classes are prepared by the\n        `customize_form_widgets` method.\n        \"\"\"\n        if self.fieldsets:\n            fields = flatten_fieldsets(self.get_fieldsets())\n        else:\n            if (self.form_class and\n                    getattr(self.form_class, 'Meta', None) and\n                    getattr(self.form_class.Meta, 'fields', None)):\n                fields = self.form_class.Meta.fields\n            else:\n                fields = []\n\n        exclude = None\n        if self.parent_field:\n            exclude = (self.parent_field,)\n\n        readonly_fields = self.get_readonly_fields()\n        if readonly_fields:\n            if exclude:\n                exclude = list(exclude)\n            else:\n                exclude = []\n\n            for field in readonly_fields:\n                try:\n                    try:\n                        f = self.model._meta.get_field(field)\n                        if fields:\n                            fields.remove(field)\n                        else:\n                            exclude.append(field)\n                    except models.FieldDoesNotExist:\n                        if fields:\n                            fields.remove(field)\n                except ValueError:\n                    pass\n\n        params = {'fields': fields or '__all__',\n                  'exclude': exclude,\n                  'formfield_callback': self.formfield_for_dbfield}\n\n        if self.form_class:\n            if issubclass(self.form_class, forms.ModelForm) and \\\n                    getattr(self.form_class._meta, 'model', None):\n                model = self.form_class.Meta.model\n            else:\n                model = self.model\n            fc = self.customize_form_widgets(self.form_class, fields=fields)\n            params['form'] = fc\n        else:\n            if self.model is not None:\n                # If a model has been explicitly provided, use it\n                model = self.model\n            elif hasattr(self, 'object') and self.object is not None:\n                # If this view is operating on a single object, use\n                # the class of that object\n                model = self.object.__class__\n            else:\n                # Try to get a queryset and extract the model class\n                # from that\n                model = self.get_queryset().model\n\n        return model_forms.modelform_factory(model, **params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the keyword arguments for instantiating the form.", "response": "def get_form_kwargs(self):\n        \"\"\"\n        Returns the keyword arguments for instantiating the form.\n        \"\"\"\n        kwargs = {'initial': self.get_initial(),\n                  'instance': self.object}\n\n        if self.request.method in ('POST', 'PUT') and self.can_submit:\n            kwargs.update({\n                'data': self.request.POST,\n                'files': self.request.FILES\n            })\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_form(self, form):\n\n        # Add any force_instance_values\n        force = self.get_force_instance_values()\n        if force:\n            for k, v in force.items():\n                setattr(form.instance, k, v)\n\n        # Are we adding to an attr or manager\n        should_add = False\n        if self.parent_object:\n            m2ms = [f.name for f in form.instance._meta.many_to_many]\n            m2ms.extend(\n                [f.field.rel.related_name for f in\n                    [\n                        f for f in form.instance._meta.get_fields(include_hidden=True)\n                        if f.many_to_many and f.auto_created\n                    ]\n                ]\n            )\n\n            if self.parent_field in m2ms:\n                should_add = True\n            else:\n                try:\n                    form.instance._meta.get_field(self.parent_field)\n                    setattr(form.instance, self.parent_field,\n                            self.parent_object)\n                except FieldDoesNotExist:\n                    pass\n\n        obj = form.save()\n        # Do we need to add this to a m2m\n        if should_add:\n            getattr(obj, self.parent_field).add(self.parent_object)\n\n        return obj", "response": "Save a valid form."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the given formsets.", "response": "def save_formsets(self, form, formsets, auto_tags=None):\n        \"\"\"\n        Hook for saving formsets. Loops through\n        all the given formsets and calls their\n        save method.\n        \"\"\"\n        for formset in formsets.values():\n            tag_handler.set_auto_tags_for_formset(formset, auto_tags)\n            formset.save()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef success_response(self, message=None):\n\n        return self.render(self.request,\n                           redirect_url=self.get_success_url(),\n                           obj=self.object,\n                           message=message,\n                           collect_render_data=False)", "response": "Returns a render redirect to the result of the get_success_url method."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render(self, request, **kwargs):\n        if request.GET.get('popup'):\n            self.render_type = 'popup'\n            kwargs['popup'] = 1\n\n        kwargs['cancel_url'] = self.get_cancel_url()\n        if not self.object:\n            kwargs['single_title'] = True\n        return super(FormView, self).render(request, **kwargs)", "response": "Renders this view. Adds cancel_url to the context.\n        If the request get parameters contains 'popup' then\n        the `render_type` is set to 'popup'."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, request, *args, **kwargs):\n\n        self.object = self.get_object()\n        form_class = self.get_form_class()\n        form = self.get_form(form_class)\n        formsets = self.get_formsets(form)\n\n        adminForm = self.get_admin_form(form)\n        adminFormSets = self.get_admin_formsets(formsets)\n        context = {\n            'adminForm': adminForm,\n            'obj': self.object,\n            'formsets': adminFormSets,\n        }\n        return self.render(request, **context)", "response": "Method for handling GET requests."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_object(self):\n        obj = super(PreviewWrapper, self).get_object()\n\n        if not obj:\n            raise http.Http404\n\n        return obj", "response": "Get the object for previewing."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_preview_kwargs(self, **kwargs):\n        if not self.pass_through_kwarg:\n            return {}\n\n        obj = self.get_object()\n        return {\n            self.pass_through_kwarg: getattr(obj, self.pass_through_attr)\n        }", "response": "Returns the keyword arguments to pass to the preview_view callable."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreverts the given version to the active draft.", "response": "def revert(self, version, url):\n        \"\"\"\n        Set the given version to be the active draft.\n        This is done by calling the object's `make_draft` method.\n        Logs the revert as a 'save' and messages the user.\n        \"\"\"\n        message = \"Draft replaced with %s version. This revert has not been published.\" % version.date_published\n        version.make_draft()\n\n        # Log action as a save\n        self.log_action(self.object, CMSLog.SAVE, url=url)\n        return self.write_message(message=message)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting the given version.", "response": "def delete(self, version):\n        \"\"\"\n        Deletes the given version, not the object itself.\n        No log entry is generated but the user is notified\n        with a message.\n        \"\"\"\n        # Shouldn't be able to delete live or draft version\n        if version.state != version.DRAFT and \\\n                      version.state != version.PUBLISHED:\n            version.delete()\n            message = \"%s version deleted.\" % version.date_published\n            return self.write_message(message=message)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef post(self, request, *args, **kwargs):\n\n        versions = self._get_versions()\n        url = self.get_done_url()\n        msg = None\n\n        try:\n            vid = int(request.POST.get('version', ''))\n            version = versions.get(vid=vid)\n            if request.POST.get('revert'):\n                object_url = self.get_object_url()\n                msg = self.revert(version, object_url)\n            elif request.POST.get('delete'):\n                msg = self.delete(version)\n                # Delete should redirect back to itself\n                url = self.request.build_absolute_uri()\n\n        # If the give version isn't valid we'll just silently redirect\n        except (ValueError, versions.model.DoesNotExist):\n            pass\n\n        return self.render(request, redirect_url=url,\n                   message=msg,\n                   obj=self.object,\n                   collect_render_data=False)", "response": "Method for handling POST requests."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild an encoded string suitable for use as a URL component.", "response": "def _to_encoded_string(o):\n    \"\"\"\n    Build an encoded string suitable for use as a URL component. This includes double-escaping the string to\n    avoid issues with escaped backslash characters being automatically converted by WSGI or, in some cases\n    such as default Apache servers, blocked entirely.\n\n    :param o: an object of any kind, if it has an as_dict() method this will be used, otherwise uses __dict__\n    :return: an encoded string suitable for use as a URL component\n    :internal:\n    \"\"\"\n    _dict = o.__dict__\n    if o.as_dict:\n        _dict = o.as_dict()\n    return urllib.quote_plus(urllib.quote_plus(json.dumps(obj=_dict, separators=(',', ':'))))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_observatories(self):\n        response = requests.get(self.base_url + '/obstories').text\n        return safe_load(response)", "response": "Get the IDs of all observatories with have stored observations on this server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the status of an observatory.", "response": "def get_observatory_status(self, observatory_id, status_time=None):\n        \"\"\"\n        Get details of the specified camera's status\n\n        :param string observatory_id:\n            a observatory ID, as returned by list_observatories()\n        :param float status_time:\n            optional, if specified attempts to get the status for the given camera at a particular point in time\n            specified as a datetime instance. This is useful if you want to retrieve the status of the camera at the\n            time a given event or file was produced. If this is None or not specified the time is 'now'.\n        :return:\n            a dictionary, or None if there was either no observatory found.\n        \"\"\"\n        if status_time is None:\n            response = requests.get(\n                self.base_url + '/obstory/{0}/statusdict'.format(observatory_id))\n        else:\n            response = requests.get(\n                self.base_url + '/obstory/{0}/statusdict/{1}'.format(observatory_id, str(status_time)))\n        if response.status_code == 200:\n            d = safe_load(response.text)\n            if 'status' in d:\n                return d['status']\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch for observations returning an Observation object for each result.", "response": "def search_observations(self, search=None):\n        \"\"\"\n        Search for observations, returning an Observation object for each result. FileRecords within result Observations\n        have two additional methods patched into them, get_url() and download_to(file_name), which will retrieve the\n        URL for the file content and download that content to a named file on disk, respectively.\n\n        :param search:\n            an instance of ObservationSearch - see the model docs for details on how to construct this\n        :return:\n            a dictionary containing 'count' and 'events'. 'events' is a sequence of Event objects containing the\n            results of the search, and 'count' is the total number of results which would be returned if no result\n            limit was in place (i.e. if the number of Events in the 'events' part is less than 'count' you have more\n            records which weren't returned because of a query limit. Note that the default query limit is 100).\n        \"\"\"\n        if search is None:\n            search = model.ObservationSearch()\n        search_string = _to_encoded_string(search)\n        url = self.base_url + '/obs/{0}'.format(search_string)\n        # print url\n        response = requests.get(url)\n        response_object = safe_load(response.text)\n        obs_dicts = response_object['obs']\n        obs_count = response_object['count']\n        return {'count': obs_count,\n                'events': [self._augment_observation_files(e)\n                           for e in (model.Observation.from_dict(d)\n                                     for d in obs_dicts)\n                           ]\n                }"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search_files(self, search=None):\n        if search is None:\n            search = model.FileRecordSearch()\n        search_string = _to_encoded_string(search)\n        url = self.base_url + '/files/{0}'.format(search_string)\n        # print url\n        response = requests.get(url)\n        response_object = safe_load(response.text)\n        file_dicts = response_object['files']\n        file_count = response_object['count']\n        return {'count': file_count,\n                'files': list((self._augment_file(f) for f in (model.FileRecord.from_dict(d) for d in file_dicts)))}", "response": "Search for files returning a FileRecord for each result."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _augment_file(self, f):\n\n        def get_url(target):\n            if target.file_size is None:\n                return None\n            if target.file_name is not None:\n                return self.base_url + '/files/content/{0}/{1}'.format(target.file_id.hex, target.file_name)\n            else:\n                return self.base_url + '/files/content/{0}'.format(target.file_id.hex, )\n\n        f.get_url = types.MethodType(get_url, f)\n\n        def download_to(target, file_name):\n            url = target.get_url()\n            r = requests.get(url, stream=True)\n            with open(file_name, 'wb') as file_to_write:\n                for chunk in r.iter_content(chunk_size=1024):\n                    if chunk:  # filter out keep-alive new chunks\n                        file_to_write.write(chunk)\n                        file_to_write.flush()\n            return file_name\n\n        f.download_to = types.MethodType(download_to, f)\n        return f", "response": "Augment a FileRecord with methods to get the data URL and download the file for use by generator functions\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\naugmenting all the file records in an event by adding them to the event s file_records attribute.", "response": "def _augment_observation_files(self, e):\n        \"\"\"\n        Augment all the file records in an event\n        :internal:\n        \"\"\"\n        e.file_records = [self._augment_file(f) for f in e.file_records]\n        return e"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_defaults(self):\n        defaults = {}\n        for arg in self.args:\n            if not isinstance(arg, _BaseOpt):\n                raise errors.InvalidSchemeError('Unable to build default for non-Option type')\n\n            # if there is a default set, add it to the defaults dict\n            if not isinstance(arg.default, NoDefault):\n                defaults[arg.name] = arg.default\n\n            # if we have a dict option, build the defaults for its scheme.\n            # if any defaults exist, use them.\n            if isinstance(arg, DictOption):\n                if arg.scheme:\n                    b = arg.scheme.build_defaults()\n                    if b:\n                        defaults[arg.name] = b\n        return defaults", "response": "Build a dictionary of default values from the Scheme."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nflattens the scheme into a dictionary where the keys are compound. dot notation keys and the values are the corresponding options.", "response": "def flatten(self):\n        \"\"\"Flatten the scheme into a dictionary where the keys are\n        compound 'dot' notation keys, and the values are the corresponding\n        options.\n\n        Returns:\n            dict: The flattened `Scheme`.\n        \"\"\"\n        if self._flat is None:\n            flat = {}\n            for arg in self.args:\n                if isinstance(arg, Option):\n                    flat[arg.name] = arg\n\n                elif isinstance(arg, ListOption):\n                    flat[arg.name] = arg\n\n                elif isinstance(arg, DictOption):\n                    flat[arg.name] = arg\n                    if arg.scheme:\n                        for k, v in arg.scheme.flatten().items():\n                            flat[arg.name + '.' + k] = v\n\n            self._flat = flat\n        return self._flat"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate(self, config):\n        if not isinstance(config, dict):\n            raise errors.SchemeValidationError(\n                'Scheme can only validate a dictionary config, but was given '\n                '{} (type: {})'.format(config, type(config))\n            )\n\n        for arg in self.args:\n            # the option exists in the config\n            if arg.name in config:\n                arg.validate(config[arg.name])\n\n            # the option does not exist in the config\n            else:\n                # if the option is not required, then it is fine to omit.\n                # otherwise, its omission constitutes a validation error.\n                if arg.required:\n                    raise errors.SchemeValidationError(\n                        'Option \"{}\" is required, but not found.'.format(arg.name)\n                    )", "response": "Validate the given config against the schema."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cast(self, value):\n        # if there is no type set for the option, return the given\n        # value unchanged.\n        if self.type is None:\n            return value\n\n        # cast directly\n        if self.type in (str, int, float):\n            try:\n                return self.type(value)\n            except Exception as e:\n                raise errors.BisonError(\n                    'Failed to cast {} to {}'.format(value, self.type)\n                ) from e\n\n        # for bool, can't cast a string, since a string is truthy,\n        # so we need to check the value.\n        elif self.type == bool:\n            return value.lower() == 'true'\n\n        # the option type is currently not supported\n        else:\n            raise errors.BisonError('Unsupported type for casting: {}'.format(self.type))", "response": "Cast a value to the type required by the option."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the geometric mean of the values in the passed list.", "response": "def geometricmean(inlist):\n    \"\"\"\nCalculates the geometric mean of the values in the passed list.\nThat is:  n-th root of (x1 * x2 * ... * xn).  Assumes a '1D' list.\n\nUsage:   lgeometricmean(inlist)\n\"\"\"\n    mult = 1.0\n    one_over_n = 1.0 / len(inlist)\n    for item in inlist:\n        mult = mult * pow(item, one_over_n)\n    return mult"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the harmonic mean of the values in the passed list.", "response": "def harmonicmean(inlist):\n    \"\"\"\nCalculates the harmonic mean of the values in the passed list.\nThat is:  n / (1/x1 + 1/x2 + ... + 1/xn).  Assumes a '1D' list.\n\nUsage:   lharmonicmean(inlist)\n\"\"\"\n    sum = 0\n    for item in inlist:\n        sum = sum + 1.0 / item\n    return len(inlist) / sum"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mean(inlist):\n    sum = 0\n    for item in inlist:\n        sum = sum + item\n    return sum / float(len(inlist))", "response": "Returns the arithematic mean of the values in the passed list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the median score of the passed list.", "response": "def medianscore(inlist):\n    \"\"\"\nReturns the 'middle' score of the passed list.  If there is an even\nnumber of scores, the mean of the 2 middle scores is returned.\n\nUsage:   lmedianscore(inlist)\n\"\"\"\n\n    newlist = copy.deepcopy(inlist)\n    newlist.sort()\n    if len(newlist) % 2 == 0:   # if even number of scores, average middle 2\n        index = len(newlist) / 2  # integer division correct\n        median = float(newlist[index] + newlist[index - 1]) / 2\n    else:\n        index = len(newlist) / 2  # int divsion gives mid value when count from 0\n        median = newlist[index]\n    return median"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mode(inlist):\n\n    scores = pstat.unique(inlist)\n    scores.sort()\n    freq = []\n    for item in scores:\n        freq.append(inlist.count(item))\n    maxfreq = max(freq)\n    mode = []\n    stillmore = 1\n    while stillmore:\n        try:\n            indx = freq.index(maxfreq)\n            mode.append(scores[indx])\n            del freq[indx]\n            del scores[indx]\n        except ValueError:\n            stillmore = 0\n    return maxfreq, mode", "response": "Returns a list of the most common mode value for the passed in list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the nth moment about the mean for a sample.", "response": "def moment(inlist, moment=1):\n    \"\"\"\nCalculates the nth moment about the mean for a sample (defaults to\nthe 1st moment).  Used to calculate coefficients of skewness and kurtosis.\n\nUsage:   lmoment(inlist,moment=1)\nReturns: appropriate moment (r) from pyLibrary. 1/n * SUM((inlist(i)-mean)**r)\n\"\"\"\n    if moment == 1:\n        return 0.0\n    else:\n        mn = mean(inlist)\n        n = len(inlist)\n        s = 0\n        for x in inlist:\n            s = s + (x - mn) ** moment\n        return s / float(n)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns some descriptive statistics of the passed list.", "response": "def describe(inlist):\n    \"\"\"\nReturns some descriptive statistics of the passed list (assumed to be 1D).\n\nUsage:   ldescribe(inlist)\nReturns: n, mean, standard deviation, skew, kurtosis\n\"\"\"\n    n = len(inlist)\n    mm = (min(inlist), max(inlist))\n    m = mean(inlist)\n    sd = stdev(inlist)\n    sk = skew(inlist)\n    kurt = kurtosis(inlist)\n    return n, mm, m, sd, sk, kurt"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of pairs. Each pair consists of one of the scores in inlist and it s frequency count.", "response": "def itemfreq(inlist):\n    \"\"\"\nReturns a list of pairs.  Each pair consists of one of the scores in inlist\nand it's frequency count.  Assumes a 1D list is passed.\n\nUsage:   litemfreq(inlist)\nReturns: a 2D frequency table (col [0:n-1]=scores, col n=frequencies)\n\"\"\"\n    scores = pstat.unique(inlist)\n    scores.sort()\n    freq = []\n    for item in scores:\n        freq.append(inlist.count(item))\n    return zip(scores, freq)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scoreatpercentile(inlist, percent):\n    if percent > 1:\n        print(\"\\nDividing percent>1 by 100 in lscoreatpercentile().\\n\")\n        percent = percent / 100.0\n    targetcf = percent * len(inlist)\n    h, lrl, binsize, extras = histogram(inlist)\n    cumhist = cumsum(copy.deepcopy(h))\n    for i in range(len(cumhist)):\n        if cumhist[i] >= targetcf:\n            break\n    score = binsize * ((targetcf - cumhist[i - 1]) / float(h[i])) + (lrl + binsize * i)\n    return score", "response": "Returns the score at a given percentile relative to the distribution\n given by inlist."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the percentile value of a score relative to the distribution given by inlist.", "response": "def percentileofscore(inlist, score, histbins=10, defaultlimits=None):\n    \"\"\"\nReturns the percentile value of a score relative to the distribution\ngiven by inlist.  Formula depends on the values used to histogram the data(!).\n\nUsage:   lpercentileofscore(inlist,score,histbins=10,defaultlimits=None)\n\"\"\"\n\n    h, lrl, binsize, extras = histogram(inlist, histbins, defaultlimits)\n    cumhist = cumsum(copy.deepcopy(h))\n    i = int((score - lrl) / float(binsize))\n    pct = (cumhist[i - 1] + ((score - (lrl + binsize * i)) / float(binsize)) * h[i]) / float(len(inlist)) * 100\n    return pct"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef histogram(inlist, numbins=10, defaultreallimits=None, printextras=0):\n    if (defaultreallimits != None):\n        if type(defaultreallimits) not in [list, tuple] or len(defaultreallimits) == 1: # only one limit given, assumed to be lower one & upper is calc'd\n            lowerreallimit = defaultreallimits\n            upperreallimit = 1.000001 * max(inlist)\n        else: # assume both limits given\n            lowerreallimit = defaultreallimits[0]\n            upperreallimit = defaultreallimits[1]\n        binsize = (upperreallimit - lowerreallimit) / float(numbins)\n    else:     # no limits given for histogram, both must be calc'd\n        estbinwidth = (max(inlist) - min(inlist)) / float(numbins) + 1e-6 # 1=>cover all\n        binsize = ((max(inlist) - min(inlist) + estbinwidth)) / float(numbins)\n        lowerreallimit = min(inlist) - binsize / 2 # lower real limit,1st bin\n    bins = [0] * (numbins)\n    extrapoints = 0\n    for num in inlist:\n        try:\n            if (num - lowerreallimit) < 0:\n                extrapoints = extrapoints + 1\n            else:\n                bintoincrement = int((num - lowerreallimit) / float(binsize))\n                bins[bintoincrement] = bins[bintoincrement] + 1\n        except:\n            extrapoints = extrapoints + 1\n    if (extrapoints > 0 and printextras == 1):\n        print('\\nPoints outside given histogram range =', extrapoints)\n    return (bins, lowerreallimit, binsize, extrapoints)", "response": "This routine calculates the binning of the sequence objects in the object in the object tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a cumulative frequency histogram using the histogram function.", "response": "def cumfreq(inlist, numbins=10, defaultreallimits=None):\n    \"\"\"\nReturns a cumulative frequency histogram, using the histogram function.\n\nUsage:   lcumfreq(inlist,numbins=10,defaultreallimits=None)\nReturns: list of cumfreq bin values, lowerreallimit, binsize, extrapoints\n\"\"\"\n    h, l, b, e = histogram(inlist, numbins, defaultreallimits)\n    cumhist = cumsum(copy.deepcopy(h))\n    return cumhist, l, b, e"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a relative frequency histogram using the histogram function.", "response": "def relfreq(inlist, numbins=10, defaultreallimits=None):\n    \"\"\"\nReturns a relative frequency histogram, using the histogram function.\n\nUsage:   lrelfreq(inlist,numbins=10,defaultreallimits=None)\nReturns: list of cumfreq bin values, lowerreallimit, binsize, extrapoints\n\"\"\"\n    h, l, b, e = histogram(inlist, numbins, defaultreallimits)\n    for i in range(len(h)):\n        h[i] = h[i] / float(len(inlist))\n    return h, l, b, e"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing a transform on input data (any number of columns). Used to test for homogeneity of variance prior to running one-way stats. From Maxwell and Delaney, p.112. Usage: lobrientransform(*args) Returns: transformed data for use in an ANOVA", "response": "def obrientransform(*args):\n    \"\"\"\nComputes a transform on input data (any number of columns).  Used to\ntest for homogeneity of variance prior to running one-way stats.  From\nMaxwell and Delaney, p.112.\n\nUsage:   lobrientransform(*args)\nReturns: transformed data for use in an ANOVA\n\"\"\"\n    TINY = 1e-10\n    k = len(args)\n    n = [0.0] * k\n    v = [0.0] * k\n    m = [0.0] * k\n    nargs = []\n    for i in range(k):\n        nargs.append(copy.deepcopy(args[i]))\n        n[i] = float(len(nargs[i]))\n        v[i] = var(nargs[i])\n        m[i] = mean(nargs[i])\n    for j in range(k):\n        for i in range(n[j]):\n            t1 = (n[j] - 1.5) * n[j] * (nargs[j][i] - m[j]) ** 2\n            t2 = 0.5 * v[j] * (n[j] - 1.0)\n            t3 = (n[j] - 1.0) * (n[j] - 2.0)\n            nargs[j][i] = (t1 - t2) / float(t3)\n    check = 1\n    for j in range(k):\n        if v[j] - mean(nargs[j]) > TINY:\n            check = 0\n    if check != 1:\n        raise ValueError('Problem in obrientransform.')\n    else:\n        return nargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef samplevar(inlist):\n    n = len(inlist)\n    mn = mean(inlist)\n    deviations = []\n    for item in inlist:\n        deviations.append(item - mn)\n    return ss(deviations) / float(n)", "response": "Returns the sample variance of the values in the passed list using\nN for the denominator."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the estimated covariance of the values in the passed array (i.e., N-1). Dimension can equal None (ravel array first), an integer (the dimension over which to operate), or a sequence (operate over multiple dimensions). Set keepdims=1 to return an array with the same number of dimensions as inarray. Usage: lcov(x,y,keepdims=0)", "response": "def cov(x, y, keepdims=0):\n    \"\"\"\nReturns the estimated covariance of the values in the passed\narray (i.e., N-1).  Dimension can equal None (ravel array first), an\ninteger (the dimension over which to operate), or a sequence (operate\nover multiple dimensions).  Set keepdims=1 to return an array with the\nsame number of dimensions as inarray.\n\nUsage:   lcov(x,y,keepdims=0)\n\"\"\"\n\n    n = len(x)\n    xmn = mean(x)\n    ymn = mean(y)\n    xdeviations = [0] * len(x)\n    ydeviations = [0] * len(y)\n    for i in range(len(x)):\n        xdeviations[i] = x[i] - xmn\n        ydeviations[i] = y[i] - ymn\n    ss = 0.0\n    for i in range(len(xdeviations)):\n        ss = ss + xdeviations[i] * ydeviations[i]\n    return ss / float(n - 1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the variance of the values in the passed list using N - 1 for the denominator.", "response": "def var(inlist):\n    \"\"\"\nReturns the variance of the values in the passed list using N-1\nfor the denominator (i.e., for estimating population variance).\n\nUsage:   lvar(inlist)\n\"\"\"\n    n = len(inlist)\n    mn = mean(inlist)\n    deviations = [0] * len(inlist)\n    for i in range(len(inlist)):\n        deviations[i] = inlist[i] - mn\n    return ss(deviations) / float(n - 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the estimated standard error of the mean of the the values in the passed list.", "response": "def sem(inlist):\n    \"\"\"\nReturns the estimated standard error of the mean (sx-bar) of the\nvalues in the passed list.  sem = stdev / sqrt(n)\n\nUsage:   lsem(inlist)\n\"\"\"\n    sd = stdev(inlist)\n    n = len(inlist)\n    return sd / math.sqrt(n)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of z - scores one for each score in the passed list.", "response": "def zs(inlist):\n    \"\"\"\nReturns a list of z-scores, one for each score in the passed list.\n\nUsage:   lzs(inlist)\n\"\"\"\n    zscores = []\n    for item in inlist:\n        zscores.append(z(inlist, item))\n    return zscores"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef trimboth(l, proportiontocut):\n    lowercut = int(proportiontocut * len(l))\n    uppercut = len(l) - lowercut\n    return l[lowercut:uppercut]", "response": "Returns a list of items from BOTH ends of a passed sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef trim1(l, proportiontocut, tail='right'):\n    if tail == 'right':\n        lowercut = 0\n        uppercut = len(l) - int(proportiontocut * len(l))\n    elif tail == 'left':\n        lowercut = int(proportiontocut * len(l))\n        uppercut = len(l)\n    return l[lowercut:uppercut]", "response": "Returns a list of items from ONE end of the passed n - item list l."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef paired(x, y):\n    samples = ''\n    while samples not in ['i', 'r', 'I', 'R', 'c', 'C']:\n        print('\\nIndependent or related samples, or correlation (i,r,c): ',)\n        samples = raw_input()\n\n    if samples in ['i', 'I', 'r', 'R']:\n        print('\\nComparing variances ...',)\n        # USE O'BRIEN'S TEST FOR HOMOGENEITY OF VARIANCE, Maxwell & delaney, p.112\n        r = obrientransform(x, y)\n        f, p = F_oneway(pstat.colex(r, 0), pstat.colex(r, 1))\n        if p < 0.05:\n            vartype = 'unequal, p=' + str(round(p, 4))\n        else:\n            vartype = 'equal'\n        print(vartype)\n        if samples in ['i', 'I']:\n            if vartype[0] == 'e':\n                t, p = ttest_ind(x, y, 0)\n                print('\\nIndependent samples t-test:  ', round(t, 4), round(p, 4))\n            else:\n                if len(x) > 20 or len(y) > 20:\n                    z, p = ranksums(x, y)\n                    print('\\nRank Sums test (NONparametric, n>20):  ', round(z, 4), round(p, 4))\n                else:\n                    u, p = mannwhitneyu(x, y)\n                    print('\\nMann-Whitney U-test (NONparametric, ns<20):  ', round(u, 4), round(p, 4))\n        else:  # RELATED SAMPLES\n            if vartype[0] == 'e':\n                t, p = ttest_rel(x, y, 0)\n                print('\\nRelated samples t-test:  ', round(t, 4), round(p, 4))\n            else:\n                t, p = ranksums(x, y)\n                print('\\nWilcoxon T-test (NONparametric):  ', round(t, 4), round(p, 4))\n    else:  # CORRELATION ANALYSIS\n        corrtype = ''\n        while corrtype not in ['c', 'C', 'r', 'R', 'd', 'D']:\n            print('\\nIs the data Continuous, Ranked, or Dichotomous (c,r,d): ',)\n            corrtype = raw_input()\n        if corrtype in ['c', 'C']:\n            m, b, r, p, see = linregress(x, y)\n            print('\\nLinear regression for continuous variables ...')\n            lol = [['Slope', 'Intercept', 'r', 'Prob', 'SEestimate'], [round(m, 4), round(b, 4), round(r, 4), round(p, 4), round(see, 4)]]\n            pstat.printcc(lol)\n        elif corrtype in ['r', 'R']:\n            r, p = spearmanr(x, y)\n            print('\\nCorrelation for ranked variables ...')\n            print(\"Spearman's r: \", round(r, 4), round(p, 4))\n        else: # DICHOTOMOUS\n            r, p = pointbiserialr(x, y)\n            print('\\nAssuming x contains a dichotomous variable ...')\n            print('Point Biserial r: ', round(r, 4), round(p, 4))\n    print('\\n\\n')\n    return None", "response": "This function determines the type of data and runs the appropriate statistic for the paired group data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the concordance correlation coefficient of a set of x and y.", "response": "def lincc(x, y):\n    \"\"\"\nCalculates Lin's concordance correlation coefficient.\n\nUsage:   alincc(x,y)    where x, y are equal-length arrays\nReturns: Lin's CC\n\"\"\"\n    covar = cov(x, y) * (len(x) - 1) / float(len(x))  # correct denom to n\n    xvar = var(x) * (len(x) - 1) / float(len(x))  # correct denom to n\n    yvar = var(y) * (len(y) - 1) / float(len(y))  # correct denom to n\n    lincc = (2 * covar) / ((xvar + yvar) + ((mean(x) - mean(y)) ** 2))\n    return lincc"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npointing - biserial r calculation.", "response": "def pointbiserialr(cats, vals):\n    \"\"\"\nCalculates a point-biserial correlation coefficient and the associated\nprobability value.  Taken from Heiman's Basic Statistics for the Behav.\nSci (1st), p.194.\n\nUsage:   pointbiserialr(x,y)      where x,y are equal-length lists\nReturns: Point-biserial r, two-tailed p-value\n\"\"\"\n    TINY = 1e-30\n    if len(cats) != len(vals):\n        raise ValueError('INPUT VALUES NOT PAIRED IN pointbiserialr.  ABORTING.')\n    data = zip(cats, vals)\n    categories = pstat.unique(cats)\n    if len(categories) != 2:\n        raise ValueError(\"Exactly 2 categories required for pointbiserialr().\")\n    else:   # there are 2 categories, continue\n        c1 = [v for i, v in enumerate(vals) if cats[i] == categories[0]]\n        c2 = [v for i, v in enumerate(vals) if cats[i] == categories[1]]\n        xmean = mean(c1)\n        ymean = mean(c2)\n        n = len(vals)\n        adjust = math.sqrt((len(c1) / float(n)) * (len(c2) / float(n)))\n        rpb = (ymean - xmean) / samplestdev(vals) * adjust\n        df = n - 2\n        t = rpb * math.sqrt(df / ((1.0 - rpb + TINY) * (1.0 + rpb + TINY)))\n        prob = betai(0.5 * df, 0.5, df / (df + t * t))  # t already a float\n        return rpb, prob"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef chisquare(f_obs, f_exp=None):\n    k = len(f_obs)                 # number of groups\n    if f_exp == None:\n        f_exp = [sum(f_obs) / float(k)] * len(f_obs) # create k bins with = freq.\n    chisq = 0\n    for i in range(len(f_obs)):\n        o = f_obs[i]\n        e = f_exp[i]\n        chisq = chisq + (o - e) ** 2 / float(e)\n    return chisq, chisqprob(chisq, k - 1)", "response": "Calculates a one - way chi square for list of observed frequencies and returns\nthe result."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wilcoxont(x, y):\n    if len(x) != len(y):\n        raise ValueError('Unequal N in wilcoxont.  Aborting.')\n    d = []\n    for i in range(len(x)):\n        diff = x[i] - y[i]\n        if diff != 0:\n            d.append(diff)\n    count = len(d)\n    absd = map(abs, d)\n    absranked = rankdata(absd)\n    r_plus = 0.0\n    r_minus = 0.0\n    for i in range(len(absd)):\n        if d[i] < 0:\n            r_minus = r_minus + absranked[i]\n        else:\n            r_plus = r_plus + absranked[i]\n    wt = min(r_plus, r_minus)\n    mn = count * (count + 1) * 0.25\n    se = math.sqrt(count * (count + 1) * (2.0 * count + 1.0) / 24.0)\n    z = math.fabs(wt - mn) / se\n    prob = 2 * (1.0 - zprob(abs(z)))\n    return wt, prob", "response": "A non - parametric Wilcoxon T - test."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef erfcc(x):\n    z = abs(x)\n    t = 1.0 / (1.0 + 0.5 * z)\n    ans = t * math.exp(\n        -z * z - 1.26551223 + t * (1.00002368 + t * (0.37409196 + t * (0.09678418 + t * (-0.18628806 + t * (0.27886807 + t * (-1.13520398 + t * (1.48851587 + t * (-0.82215223 + t * 0.17087277)))))))))\n    if x >= 0:\n        return ans\n    else:\n        return 2.0 - ans", "response": "Returns the complementary error function erfc with fractional\nerror everywhere less than 1. 2e - 7."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fprob(dfnum, dfden, F):\n    p = betai(0.5 * dfden, 0.5 * dfnum, dfden / float(dfden + dfnum * F))\n    return p", "response": "Function that returns the 1 - tailed significance level p - value of a F\nstatistic given the degrees of freedom dfnum and dfden."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef betacf(a, b, x):\n    ITMAX = 200\n    EPS = 3.0e-7\n\n    bm = az = am = 1.0\n    qab = a + b\n    qap = a + 1.0\n    qam = a - 1.0\n    bz = 1.0 - qab * x / qap\n    for i in range(ITMAX + 1):\n        em = float(i + 1)\n        tem = em + em\n        d = em * (b - em) * x / ((qam + tem) * (a + tem))\n        ap = az + d * am\n        bp = bz + d * bm\n        d = -(a + em) * (qab + em) * x / ((qap + tem) * (a + tem))\n        app = ap + d * az\n        bpp = bp + d * bz\n        aold = az\n        am = ap / bpp\n        bm = bp / bpp\n        az = app / bpp\n        bz = 1.0\n        if (abs(az - aold) < (EPS * abs(az))):\n            return az\n    print('a or b too big, or ITMAX too small in Betacf.')", "response": "This function evaluates the continued fraction form of the incomplete betacf function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming a 1-way ANOVA, returning an F-value and probability given any number of groups. From Heiman, pp.394-7. Usage: F_oneway(*lists) where *lists is any number of lists, one per treatment group Returns: F value, one-tailed p-value", "response": "def F_oneway(*lists):\n    \"\"\"\nPerforms a 1-way ANOVA, returning an F-value and probability given\nany number of groups.  From Heiman, pp.394-7.\n\nUsage:   F_oneway(*lists)    where *lists is any number of lists, one per\n                                  treatment group\nReturns: F value, one-tailed p-value\n\"\"\"\n    a = len(lists)           # ANOVA on 'a' groups, each in it's own list\n    means = [0] * a\n    vars = [0] * a\n    ns = [0] * a\n    alldata = []\n    tmp = lists\n    means = map(mean, tmp)\n    vars = map(var, tmp)\n    ns = map(len, lists)\n    for i in range(len(lists)):\n        alldata = alldata + lists[i]\n    bign = len(alldata)\n    sstot = ss(alldata) - (square_of_sums(alldata) / float(bign))\n    ssbn = 0\n    for list in lists:\n        ssbn = ssbn + square_of_sums(list) / float(len(list))\n    ssbn = ssbn - (square_of_sums(alldata) / float(bign))\n    sswn = sstot - ssbn\n    dfbn = a - 1\n    dfwn = bign - a\n    msb = ssbn / float(dfbn)\n    msw = sswn / float(dfwn)\n    f = msb / msw\n    prob = fprob(dfbn, dfwn, f)\n    return f, prob"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the F - statistic value given the following conditions ER EF dfnum and dfden", "response": "def F_value(ER, EF, dfnum, dfden):\n    \"\"\"\nReturns an F-statistic given the following:\n        ER  = error associated with the null hypothesis (the Restricted model)\n        EF  = error associated with the alternate hypothesis (the Full model)\n        dfR-dfF = degrees of freedom of the numerator\n        dfF = degrees of freedom associated with the denominator/Full model\n\nUsage:   lF_value(ER,EF,dfnum,dfden)\n\"\"\"\n    return ((ER - EF) / float(dfnum) / (EF / float(dfden)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef incr(l, cap):        # to increment a list up to a max-list of 'cap'\n    l[0] = l[0] + 1     # e.g., [0,0,0] --> [2,4,3] (=cap)\n    for i in range(len(l)):\n        if l[i] > cap[i] and i < len(l) - 1: # if carryover AND not done\n            l[i] = 0\n            l[i + 1] = l[i + 1] + 1\n        elif l[i] > cap[i] and i == len(l) - 1: # overflow past last column, must be finished\n            l = -1\n    return l", "response": "incr - simulate a counting system from an n - dimensional list l - list to increment"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cumsum(inlist):\n    newlist = copy.deepcopy(inlist)\n    for i in range(1, len(newlist)):\n        newlist[i] = newlist[i] + newlist[i - 1]\n    return newlist", "response": "Returns a list consisting of the cumulative sum of the items in the passed list."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the sum of all the squares in each value in the passed list and the result.", "response": "def ss(inlist):\n    \"\"\"\nSquares each value in the passed list, adds up these squares and\nreturns the result.\n\nUsage:   lss(inlist)\n\"\"\"\n    ss = 0\n    for item in inlist:\n        ss = ss + item * item\n    return ss"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the sum of all resulting multiplications of elements in list1 and list2.", "response": "def summult(list1, list2):\n    \"\"\"\nMultiplies elements in list1 and list2, element by element, and\nreturns the sum of all resulting multiplications.  Must provide equal\nlength lists.\n\nUsage:   lsummult(list1,list2)\n\"\"\"\n    if len(list1) != len(list2):\n        raise ValueError(\"Lists not equal length in summult.\")\n    s = 0\n    for item1, item2 in zip(list1, list2):\n        s = s + item1 * item2\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sumdiffsquared(x, y):\n    sds = 0\n    for i in range(len(x)):\n        sds = sds + (x[i] - y[i]) ** 2\n    return sds", "response": "Takes pairwise differences of the values in lists x and y and returns the sum of these squares."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef shellsort(inlist):\n    n = len(inlist)\n    svec = copy.deepcopy(inlist)\n    ivec = range(n)\n    gap = n / 2   # integer division needed\n    while gap > 0:\n        for i in range(gap, n):\n            for j in range(i - gap, -1, -gap):\n                while j >= 0 and svec[j] > svec[j + gap]:\n                    temp = svec[j]\n                    svec[j] = svec[j + gap]\n                    svec[j + gap] = temp\n                    itemp = ivec[j]\n                    ivec[j] = ivec[j + gap]\n                    ivec[j + gap] = itemp\n        gap = gap / 2  # integer division needed\n    # svec is now sorted inlist, and ivec has the order svec[i] = vec[ivec[i]]\n    return svec, ivec", "response": "Sort a 1D - list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rankdata(inlist):\n    n = len(inlist)\n    svec, ivec = shellsort(inlist)\n    sumranks = 0\n    dupcount = 0\n    newlist = [0] * n\n    for i in range(n):\n        sumranks = sumranks + i\n        dupcount = dupcount + 1\n        if i == n - 1 or svec[i] != svec[i + 1]:\n            averank = sumranks / float(dupcount) + 1\n            for j in range(i - dupcount + 1, i + 1):\n                newlist[ivec[j]] = averank\n            sumranks = 0\n            dupcount = 0\n    return newlist", "response": "Ranks the data in inlist dealing with ties appropritely."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef findwithin(data):\n\n    numfact = len(data[0]) - 1\n    withinvec = 0\n    for col in range(1, numfact):\n        examplelevel = pstat.unique(pstat.colex(data, col))[0]\n        rows = pstat.linexand(data, col, examplelevel)  # get 1 level of this factor\n        factsubjs = pstat.unique(pstat.colex(rows, 0))\n        allsubjs = pstat.unique(pstat.colex(data, 0))\n        if len(factsubjs) == len(allsubjs):  # fewer Ss than scores on this factor?\n            withinvec = withinvec + (1 << col)\n    return withinvec", "response": "findwithin -\nsubject factor - > level where 1 = within -\nsubject factor 0 = between."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_model(self, model, bundle):\n        if model in self._model_registry:\n            raise AlreadyRegistered('The model %s is already registered' \\\n                                     % model)\n\n        if bundle.url_params:\n            raise Exception(\"A primary model bundle cannot have dynamic \\\n                            url_parameters\")\n\n        self._model_registry[model] = bundle", "response": "Registers a model with the given bundle."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unregister_model(self, model):\n        if model not in self._model_registry:\n            raise NotRegistered('The model %s is not registered' % model)\n\n        del self._model_registry[model]", "response": "Unregisters the given model."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register(self, slug, bundle, order=1, title=None):\n\n        if slug in self._registry:\n            raise AlreadyRegistered('The url %s is already registered' % slug)\n\n        # Instantiate the admin class to save in the registry.\n        self._registry[slug] = bundle\n        self._order[slug] = order\n        if title:\n            self._titles[slug] = title\n        bundle.set_admin_site(self)", "response": "Registers a bundle for a certain slug."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef password_change(self, request):\n        from django.contrib.auth.views import password_change\n        url = reverse('admin:cms_password_change_done')\n        defaults = {\n            'post_change_redirect': url,\n            'template_name': 'cms/password_change_form.html',\n        }\n        if self.password_change_template is not None:\n            defaults['template_name'] = self.password_change_template\n        return password_change(request, **defaults)", "response": "Handles the password change task."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef password_change_done(self, request, extra_context=None):\n        from django.contrib.auth.views import password_change_done\n        defaults = {\n            'extra_context': extra_context or {},\n            'template_name': 'cms/password_change_done.html',\n        }\n        if self.password_change_done_template is not None:\n            defaults['template_name'] = self.password_change_done_template\n        return password_change_done(request, **defaults)", "response": "Displays the success page after a password change."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlogs out the user for the given HttpRequest.", "response": "def logout(self, request, extra_context=None):\n        \"\"\"\n        Logs out the user for the given HttpRequest.\n\n        This should *not* assume the user is already logged in.\n        \"\"\"\n        from django.contrib.auth.views import logout\n        defaults = {\n            'extra_context': extra_context or {},\n            'template_name': 'cms/logged_out.html',\n        }\n        if self.logout_template is not None:\n            defaults['template_name'] = self.logout_template\n        return logout(request, **defaults)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef login(self, request, extra_context=None):\n        from django.contrib.auth.views import login\n        context = {\n            'title': _('Log in'),\n            'app_path': request.get_full_path(),\n            REDIRECT_FIELD_NAME: request.get_full_path(),\n        }\n        context.update(extra_context or {})\n        defaults = {\n            'extra_context': context,\n            'authentication_form': self.login_form or AdminAuthenticationForm,\n            'template_name': self.login_template or 'cms/login.html',\n        }\n        return login(request, **defaults)", "response": "Displays the login form for the given HttpRequest."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_allowed_sections(self, dashboard):\n\n        allowed_titles = [x[0] for x in dashboard]\n        allowed_sections = [x[2] for x in dashboard]\n        return tuple(allowed_sections), tuple(allowed_titles)", "response": "Get the sections to display based on dashboard\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef index(self, request, extra_context=None):\n\n        dashboard = self.get_dashboard_urls(request)\n        dash_blocks = self.get_dashboard_blocks(request)\n\n        sections, titles = self._get_allowed_sections(dashboard)\n        choices = zip(sections, titles)\n        choices.sort(key=lambda tup: tup[1])\n        choices.insert(0, ('', 'All'))\n\n        class SectionFilterForm(BaseFilterForm):\n            section = forms.ChoiceField(required=False, choices=choices)\n\n        form = SectionFilterForm(request.GET)\n        filter_kwargs = form.get_filter_kwargs()\n\n        if not filter_kwargs and not request.user.is_superuser:\n            filter_kwargs['section__in'] = sections\n        cms_logs = models.CMSLog.objects.filter(**filter_kwargs\n                                                ).order_by('-when')\n\n        template = self.dashboard_template or 'cms/dashboard.html'\n\n        paginator = Paginator(cms_logs[:20 * 100], 20,\n                              allow_empty_first_page=True)\n        page_number = request.GET.get('page') or 1\n        try:\n            page_number = int(page_number)\n        except ValueError:\n            page_number = 1\n\n        page = paginator.page(page_number)\n\n        return TemplateResponse(request, [template], {\n            'dashboard': dashboard, 'blocks': dash_blocks,\n            'page': page, 'bundle': self._registry.values()[0],\n            'form': form},)", "response": "Displays the main log list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_models(self, *models, **kwargs):\n\n        for model in models:\n            self.register(model, **kwargs)", "response": "Register multiple models with the same\n        arguments."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a model with this group.", "response": "def register(self, model, values=None, instance_values=None):\n        \"\"\"\n        Registers a model with this group.\n\n        :param values: A list of values that should be incremented \\\n        whenever invalidate_cache is called for a instance or class \\\n        of this type.\n\n        :param instance_values: A list of attribute names that will \\\n        be looked up on the instance of this model that is passed to \\\n        invalidate_cache. The value resulting from that lookup \\\n        will then be incremented.\n        \"\"\"\n\n        if model in self._models:\n            raise Exception(\"%s is already registered\" % model)\n\n        self._models[model] = CacheConfig(values, instance_values)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef invalidate_cache(self, klass, instance=None, extra=None,\n                         force_all=False):\n        \"\"\"\n        Use this method to invalidate keys related to a particular\n        model or instance. Invalidating a cache is really just\n        incrementing the version for the right key(s).\n\n        :param klass: The model class you are invalidating. If the given \\\n        class was not registered with this group no action will be taken.\n\n        :param instance: The instance you want to use with the registered\\\n        instance_values. Usually the instance that was just saved. \\\n        Defaults to None.\n\n        :param extra: A list of extra values that you would like incremented \\\n        in addition to what was registered for this model.\n\n        :param force_all: Ignore all registered values and provided \\\n        arguments and increment the major version for this group.\n        \"\"\"\n\n        values = self._get_cache_extras(klass, instance=instance,\n                                        extra=extra, force_all=force_all)\n\n        if values == CacheConfig.ALL:\n            self._increment_version()\n        elif values:\n            for value in values:\n                self._increment_version(extra=value)", "response": "This method is used to invalidate a specific cache entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_routes(meteor_app, url_path=''):\n    from meteorpi_server import MeteorApp\n\n    app = meteor_app.app\n\n    @app.after_request\n    def after_request(response):\n        response.headers.add('Accept-Ranges', 'bytes')\n        return response\n\n    # Return a list of all of the observatories which are registered in this repository\n    # A dictionary of basic information is returned for each\n    @app.route('{0}/obstories'.format(url_path), methods=['GET'])\n    def get_obstories():\n        db = meteor_app.get_db()\n        obstories = db.get_obstory_ids()\n        output = {}\n        for o in obstories:\n            output[o] = db.get_obstory_from_id(o)\n            db.con.execute(\"SELECT m.time FROM archive_metadata m \"\n                           \"INNER JOIN archive_observatories l ON m.observatory = l.uid \"\n                           \"AND l.publicId = %s AND m.time>0 \"\n                           \"ORDER BY m.time ASC LIMIT 1\",\n                           (o,))\n            first_seen = 0\n            results = db.con.fetchall()\n            if results:\n                first_seen = results[0]['time']\n            db.con.execute(\"SELECT m.time FROM archive_metadata m \"\n                           \"INNER JOIN archive_observatories l ON m.observatory = l.uid \"\n                           \"AND l.publicId = %s AND m.time>0 \"\n                           \"ORDER BY m.time DESC LIMIT 1\",\n                           (o,))\n            last_seen = 0\n            results = db.con.fetchall()\n            if results:\n                last_seen = results[0]['time']\n            output[o]['firstSeen'] = first_seen\n            output[o]['lastSeen'] = last_seen\n        db.close_db()\n        return jsonify(output)\n\n    # Return a list of all of the metadata tags which ever been set on a particular observatory, with time stamp\n    @app.route('{0}/obstory/<obstory_id>/metadata'.format(url_path), methods=['GET'])\n    def get_obstory_status_all(obstory_id):\n        db = meteor_app.get_db()\n        search = mp.ObservatoryMetadataSearch(obstory_ids=[obstory_id], time_min=0, time_max=time.time())\n        data = db.search_obstory_metadata(search)['items']\n        data.sort(key=lambda x: x.time)\n        output = [[i.time, i.key, i.value] for i in data]\n        db.close_db()\n        return jsonify({'status': output})\n\n    # Return a list of all of the metadata which was valid for a particular observatory at a particular time\n    @app.route('{0}/obstory/<obstory_id>/statusdict'.format(url_path), methods=['GET'])\n    @app.route('{0}/obstory/<obstory_id>/statusdict/<unix_time>'.format(url_path), methods=['GET'])\n    def get_obstory_status_by_time(obstory_id, unix_time=None):\n        db = meteor_app.get_db()\n        if unix_time is None:\n            unix_time = time.time()\n        status = {}\n        try:\n            obstory_info = db.get_obstory_from_id(obstory_id)\n            if obstory_info:\n                obstory_name = obstory_info['name']\n                status = db.get_obstory_status(obstory_name=obstory_name, time=float(unix_time))\n        except ValueError:\n            return jsonify({'error': 'No such observatory \"%s\".' % obstory_id})\n        db.close_db()\n        return jsonify({'status': status})\n\n    # Search for observations using a YAML search string\n    @app.route('{0}/obs/<search_string>'.format(url_path), methods=['GET'], strict_slashes=True)\n    def search_events(search_string):\n        db = meteor_app.get_db()\n        try:\n            search = mp.ObservationSearch.from_dict(safe_load(unquote(search_string)))\n        except ValueError:\n            return jsonify({'error': str(sys.exc_info()[1])})\n        observations = db.search_observations(search)\n        db.close_db()\n        return jsonify({'obs': list(x.as_dict() for x in observations['obs']), 'count': observations['count']})\n\n    # Search for files using a YAML search string\n    @app.route('{0}/files/<search_string>'.format(url_path), methods=['GET'])\n    def search_files(search_string):\n        db = meteor_app.get_db()\n        try:\n            search = mp.FileRecordSearch.from_dict(safe_load(unquote(search_string)))\n        except ValueError:\n            return jsonify({'error': str(sys.exc_info()[1])})\n        files = db.search_files(search)\n        db.close_db()\n        return jsonify({'files': list(x.as_dict() for x in files['files']), 'count': files['count']})\n\n    # Return a list of sky clarity measurements for a particular observatory (scale 0-100)\n    @app.route('{0}/skyclarity/<obstory_id>/<utc_min>/<utc_max>/<period>'.format(url_path), methods=['GET'])\n    def get_skyclarity(obstory_id, utc_min, utc_max, period):\n        db = meteor_app.get_db()\n        utc_min = float(utc_min)\n        utc_max = float(utc_max)\n        period = float(period)\n        count = 0\n        output = []\n        while count < 250:\n            a = utc_min + period * count\n            b = a + period\n            count += 1\n            db.con.execute(\"SELECT m.floatValue FROM archive_metadata m \"\n                           \"INNER JOIN archive_files f ON m.fileId = f.uid \"\n                           \"INNER JOIN archive_semanticTypes fs ON f.semanticType = fs.uid \"\n                           \"INNER JOIN archive_metadataFields mf ON m.fieldId = mf.uid \"\n                           \"INNER JOIN archive_observations o ON f.observationId = o.uid \"\n                           \"INNER JOIN archive_observatories l ON o.observatory = l.uid \"\n                           \"WHERE mf.metaKey='meteorpi:skyClarity' \"\n                           \"AND l.publicId = %s \"\n                           \"AND fs.name='meteorpi:timelapse/frame/bgrdSub/lensCorr' \"\n                           \"AND f.fileTime>%s AND f.fileTime<%s \"\n                           \"LIMIT 250\",\n                           (obstory_id, a, b))\n            results = db.con.fetchall()\n            if len(results) > 0:\n                output.append(sum([i['floatValue'] for i in results]) / len(results))\n            else:\n                output.append(0)\n            if b >= utc_max:\n                break\n        db.close_db()\n        return jsonify(output)\n\n    # Return a list of the number of observations of a particular type in a sequence\n    # of time intervals between utc_min and utc_max, with step size period\n    @app.route('{0}/activity/<obstory_id>/<semantic_type>/<utc_min>/<utc_max>/<period>'.format(url_path),\n               methods=['GET'])\n    def get_activity(obstory_id, semantic_type, utc_min, utc_max, period):\n        db = meteor_app.get_db()\n        utc_min = float(utc_min)\n        utc_max = float(utc_max)\n        period = float(period)\n        count = 0\n        output = []\n        while count < 250:\n            a = utc_min + period * count\n            b = a + period\n            count += 1\n            db.con.execute(\"SELECT COUNT(*) FROM archive_observations o \"\n                           \"INNER JOIN archive_observatories l ON o.observatory = l.uid \"\n                           \"INNER JOIN archive_semanticTypes s ON o.obsType = s.uid \"\n                           \"WHERE l.publicId=%s AND s.name=%s AND o.obsTime>=%s AND o.obsTime<%s LIMIT 1\",\n                           (obstory_id, semantic_type, a, b))\n            output.append(db.con.fetchone()['COUNT(*)'])\n            if b >= utc_max:\n                break\n        db.close_db()\n        return jsonify({\"activity\": output})\n\n    # Return a thumbnail version of an image\n    @app.route('{0}/thumbnail/<file_id>/<file_name>'.format(url_path), methods=['GET'])\n    def get_thumbnail(file_id, file_name):\n        db = meteor_app.get_db()\n        record = db.get_file(repository_fname=file_id)\n        if record is None:\n            db.close_db()\n            return MeteorApp.not_found(entity_id=file_id)\n        if record.mime_type != \"image/png\":\n            db.close_db()\n            return MeteorApp.not_found(entity_id=file_id)\n        file_path = db.file_path_for_id(record.id)\n        thumb_path = os.path.join(db.file_store_path, \"../thumbnails\", record.id)\n        if not os.path.exists(thumb_path):\n            resize_tool = os.path.join(meteor_app.binary_path, \"resize\")\n            os.system(\"%s %s 220 %s\" % (resize_tool, file_path, thumb_path))\n        db.close_db()\n        return send_file(filename_or_fp=thumb_path, mimetype=record.mime_type)\n\n    # Return a file from the repository\n    @app.route('{0}/files/content/<file_id>/<file_name>'.format(url_path), methods=['GET'])\n    @app.route('{0}/files/content/<file_id>'.format(url_path), methods=['GET'])\n    def get_file_content(file_id, file_name=None):\n\n        # http://blog.asgaard.co.uk/2012/08/03/http-206-partial-content-for-flask-python\n        def send_file_partial(filename_or_fp, mimetype):\n            range_header = request.headers.get('Range', None)\n            if not range_header:\n                return send_file(filename_or_fp, mimetype=record.mime_type)\n\n            size = os.path.getsize(filename_or_fp)\n            byte1, byte2 = 0, None\n\n            m = re.search('(\\d+)-(\\d*)', range_header)\n            g = m.groups()\n\n            if g[0]:\n                byte1 = int(g[0])\n            if g[1]:\n                byte2 = int(g[1])\n\n            length = size - byte1\n            if byte2 is not None:\n                length = byte2 - byte1 + 1\n\n            with open(filename_or_fp, 'rb') as f:\n                f.seek(byte1)\n                data = f.read(length)\n\n            rv = Response(data,\n                          206,\n                          mimetype=mimetype,\n                          direct_passthrough=True)\n            rv.headers.add('Content-Range', 'bytes {0}-{1}/{2}'.format(byte1, byte1 + length - 1, size))\n\n            return rv\n\n        db = meteor_app.get_db()\n        record = db.get_file(repository_fname=file_id)\n        if record is None:\n            db.close_db()\n            return MeteorApp.not_found(entity_id=file_id)\n        file_path = db.file_path_for_id(record.id)\n        db.close_db()\n        return send_file_partial(filename_or_fp=file_path, mimetype=record.mime_type)", "response": "Adds the routes to a MeteorApp instance to which routes should be added to a MeteorServer instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a ES query template that returns a list of the navigable items that match the given path.", "response": "def es_query_template(path):\n    \"\"\"\n    RETURN TEMPLATE AND PATH-TO-FILTER AS A 2-TUPLE\n    :param path: THE NESTED PATH (NOT INCLUDING TABLE NAME)\n    :return: (es_query, es_filters) TUPLE\n    \"\"\"\n\n    if not is_text(path):\n        Log.error(\"expecting path to be a string\")\n\n    if path != \".\":\n        f0 = {}\n        f1 = {}\n        output = wrap({\n            \"query\": es_and([\n                f0,\n                {\"nested\": {\n                    \"path\": path,\n                    \"query\": f1,\n                    \"inner_hits\": {\"size\": 100000}\n                }}\n            ]),\n            \"from\": 0,\n            \"size\": 0,\n            \"sort\": []\n        })\n        return output, wrap([f0, f1])\n    else:\n        f0 = {}\n        output = wrap({\n            \"query\": es_and([f0]),\n            \"from\": 0,\n            \"size\": 0,\n            \"sort\": []\n        })\n        return output, wrap([f0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _ancestors(collection):\n    for index, c in enumerate(collection.path_to_root()):\n        if index > 0 and c.dbquery is not None:\n            raise StopIteration\n        yield c.name\n    raise StopIteration", "response": "Get the ancestors of the collection."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _build_cache():\n    query = current_app.config['COLLECTIONS_DELETED_RECORDS']\n    for collection in Collection.query.filter(\n            Collection.dbquery.isnot(None)).all():\n        yield collection.name, dict(\n            query=query.format(dbquery=collection.dbquery),\n            ancestors=set(_ancestors(collection)),\n        )\n    raise StopIteration", "response": "Build a cache of all the deleted resources."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind matching collections with internal engine.", "response": "def _find_matching_collections_internally(collections, record):\n    \"\"\"Find matching collections with internal engine.\n\n    :param collections: set of collections where search\n    :param record: record to match\n    \"\"\"\n    for name, data in iteritems(collections):\n        if _build_query(data['query']).match(record):\n            yield data['ancestors']\n    raise StopIteration"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns list of collections to which record belongs to.", "response": "def get_record_collections(record, matcher):\n    \"\"\"Return list of collections to which record belongs to.\n\n    :param record: Record instance.\n    :param matcher: Function used to check if a record belongs to a collection.\n    :return: list of collection names.\n    \"\"\"\n    collections = current_collections.collections\n    if collections is None:\n        # build collections cache\n        collections = current_collections.collections = dict(_build_cache())\n\n    output = set()\n\n    for collections in matcher(collections, record):\n        output |= collections\n\n    return list(output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dfs(graph, func, head, reverse=None):\n    todo = deque()\n    todo.append(head)\n    path = deque()\n    done = set()\n    while todo:\n        node = todo.popleft()\n        if node in done:\n            path.pop()\n            continue\n\n        done.add(node)\n        path.append(node)\n        result = func(node, path, graph)\n        if result:\n            if reverse:\n                children = graph.get_parents(node)\n            else:\n                children = graph.get_children(node)\n            todo.extend(children)", "response": "DEPTH FIRST SEARCH\n\n    IF func RETURNS FALSE, THEN PATH IS NO LONGER TAKEN\n\n    IT'S EXPECTED func TAKES 3 ARGUMENTS\n    node - THE CURRENT NODE IN THE\n    path - PATH FROM head TO node\n    graph - THE WHOLE GRAPH"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bfs(graph, func, head, reverse=None):\n\n    todo = deque()  # LIST OF PATHS\n    todo.append(Step(None, head))\n\n    while todo:\n        path = todo.popleft()\n        keep_going = func(path.node, Path(path), graph, todo)\n        if keep_going:\n            todo.extend(Step(path, c) for c in graph.get_children(path.node))", "response": "BFS - BFS implementation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a tree of DOMINATORS for the given graph.", "response": "def dominator_tree(graph):\n    \"\"\"\n    RETURN DOMINATOR FOREST\n    THERE ARE TWO TREES, \"ROOTS\" and \"LOOPS\"\n    ROOTS HAVE NO PARENTS\n    LOOPS ARE NODES THAT ARE A MEMBER OF A CYCLE THAT HAS NO EXTRNAL PARENT\n\n    roots = dominator_tree(graph).get_children(ROOTS)\n    \"\"\"\n    todo = Queue()\n    done = set()\n    dominator = Tree(None)\n    nodes = list(graph.nodes)\n\n    while True:\n        # FIGURE OUT NET ITEM TO WORK ON\n        if todo:\n            node = todo.pop()\n        elif nodes:\n            node = nodes.pop()\n            if len(nodes) % 1000 == 0:\n                Log.note(\"{{num}} nodes remaining\", num=len(nodes))\n        else:\n            break\n        if node in done:\n            continue\n\n        parents = graph.get_parents(node) - {node}\n        if not parents:\n            # node WITHOUT parents IS A ROOT\n            done.add(node)\n            dominator.add_edge(Edge(ROOTS, node))\n            continue\n\n        not_done = parents - done\n        if not_done:\n            # THERE ARE MORE parents TO DO FIRST\n            more_todo = not_done - todo\n            if not more_todo:\n                # ALL PARENTS ARE PART OF A CYCLE, MAKE node A ROOT\n                done.add(node)\n                dominator.add_edge(Edge(LOOPS, node))\n            else:\n                # DO THE PARENTS BEFORE node\n                todo.push(node)\n                for p in more_todo:\n                    todo.push(p)\n            continue\n\n        # WE CAN GET THE DOMINATORS FOR ALL parents\n        if len(parents) == 1:\n            # SHORTCUT\n            dominator.add_edge(Edge(list(parents)[0], node))\n            done.add(node)\n            continue\n\n        paths_from_roots = [\n            list(reversed(dominator.get_path_to_root(p)))\n            for p in parents\n        ]\n\n        if any(p[0] is ROOTS for p in paths_from_roots):\n            # THIS OBJECT CAN BE REACHED FROM A ROOT, IGNORE PATHS FROM LOOPS\n            paths_from_roots = [p for p in paths_from_roots if p[0] is ROOTS]\n            if len(paths_from_roots) == 1:\n                # SHORTCUT\n                dom = paths_from_roots[0][-1]\n                dominator.add_edge(Edge(dom, node))\n                done.add(node)\n                continue\n\n        # FIND COMMON PATH FROM root\n        num_paths = len(paths_from_roots)\n        for i, x in enumerate(zip_longest(*paths_from_roots)):\n            if x.count(x[0]) != num_paths:\n                dom = paths_from_roots[0][i-1]\n                if dom is LOOPS:\n                    # CAN BE REACHED FROM MORE THAN ONE LOOP, PICK ONE TO BLAME\n                    dom = paths_from_roots[0][-1]\n                break\n        else:\n            # ALL PATHS IDENTICAL\n            dom = paths_from_roots[0][-1]\n\n        dominator.add_edge(Edge(dom, node))\n        done.add(node)\n\n    return dominator"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_schema_from_list(table_name, frum):\n    columns = UniqueIndex(keys=(\"name\",))\n    _get_schema_from_list(frum, \".\", parent=\".\", nested_path=ROOT_PATH, columns=columns)\n    return Schema(table_name=table_name, columns=list(columns))", "response": "Get a schema from a list of table names."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_schema_from_list(frum, table_name, parent, nested_path, columns):\n\n    for d in frum:\n        row_type = python_type_to_json_type[d.__class__]\n\n        if row_type != \"object\":\n            # EXPECTING PRIMITIVE VALUE\n            full_name = parent\n            column = columns[full_name]\n            if not column:\n                column = Column(\n                    name=concat_field(table_name, full_name),\n                    es_column=full_name,\n                    es_index=\".\",\n                    es_type=d.__class__.__name__,\n                    jx_type=None,  # WILL BE SET BELOW\n                    last_updated=Date.now(),\n                    nested_path=nested_path,\n                )\n                columns.add(column)\n            column.es_type = _merge_python_type(column.es_type, d.__class__)\n            column.jx_type = python_type_to_json_type[column.es_type]\n        else:\n            for name, value in d.items():\n                full_name = concat_field(parent, name)\n                column = columns[full_name]\n                if not column:\n                    column = Column(\n                        name=concat_field(table_name, full_name),\n                        es_column=full_name,\n                        es_index=\".\",\n                        es_type=value.__class__.__name__,\n                        jx_type=None,  # WILL BE SET BELOW\n                        last_updated=Date.now(),\n                        nested_path=nested_path,\n                    )\n                    columns.add(column)\n                if is_container(value):  # GET TYPE OF MULTIVALUE\n                    v = list(value)\n                    if len(v) == 0:\n                        this_type = none_type.__name__\n                    elif len(v) == 1:\n                        this_type = v[0].__class__.__name__\n                    else:\n                        this_type = reduce(\n                            _merge_python_type, (vi.__class__.__name__ for vi in value)\n                        )\n                else:\n                    this_type = value.__class__.__name__\n                column.es_type = _merge_python_type(column.es_type, this_type)\n                column.jx_type = python_type_to_json_type[column.es_type]\n\n                if this_type in {\"object\", \"dict\", \"Mapping\", \"Data\"}:\n                    _get_schema_from_list(\n                        [value], table_name, full_name, nested_path, columns\n                    )\n                elif this_type in {\"list\", \"FlatList\"}:\n                    np = listwrap(nested_path)\n                    newpath = unwraplist([join_field(split_field(np[0]) + [name])] + np)\n                    _get_schema_from_list(\n                        value, table_name, full_name, newpath, columns\n                    )", "response": "Returns the schema of the list of items in the specified table."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a new entry to the table.", "response": "def _add(self, column):\n        \"\"\"\n        :param column: ANY COLUMN OBJECT\n        :return:  None IF column IS canonical ALREADY (NET-ZERO EFFECT)\n        \"\"\"\n        columns_for_table = self.data.setdefault(column.es_index, {})\n        existing_columns = columns_for_table.setdefault(column.name, [])\n\n        for canonical in existing_columns:\n            if canonical is column:\n                return None\n            if canonical.es_type == column.es_type:\n                if column.last_updated > canonical.last_updated:\n                    for key in Column.__slots__:\n                        old_value = canonical[key]\n                        new_value = column[key]\n                        if new_value == None:\n                            pass  # DO NOT BOTHER CLEARING OLD VALUES (LIKE cardinality AND paritiions)\n                        elif new_value == old_value:\n                            pass  # NO NEED TO UPDATE WHEN NO CHANGE MADE (COMMON CASE)\n                        else:\n                            canonical[key] = new_value\n                return canonical\n        existing_columns.append(column)\n        return column"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of all the columns that are not in the structure of the class.", "response": "def denormalized(self):\n        \"\"\"\n        THE INTERNAL STRUCTURE FOR THE COLUMN METADATA IS VERY DIFFERENT FROM\n        THE DENORMALIZED PERSPECITVE. THIS PROVIDES THAT PERSPECTIVE FOR QUERIES\n        \"\"\"\n        with self.locker:\n            self._update_meta()\n            output = [\n                {\n                    \"table\": c.es_index,\n                    \"name\": untype_path(c.name),\n                    \"cardinality\": c.cardinality,\n                    \"es_column\": c.es_column,\n                    \"es_index\": c.es_index,\n                    \"last_updated\": c.last_updated,\n                    \"count\": c.count,\n                    \"nested_path\": [unnest_path(n) for n in c.nested_path],\n                    \"es_type\": c.es_type,\n                    \"type\": c.jx_type,\n                }\n                for tname, css in self.data.items()\n                for cname, cs in css.items()\n                for c in cs\n                if c.jx_type not in STRUCT  # and c.es_column != \"_id\"\n            ]\n\n        from jx_python.containers.list_usingPythonList import ListContainer\n\n        return ListContainer(\n            self.name,\n            data=output,\n            schema=jx_base.Schema(\"meta.columns\", SIMPLE_METADATA_COLUMNS),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert SORT PARAMETERS TO A NORMAL FORM SO EASIER TO USE", "response": "def normalize_sort(sort=None):\n    \"\"\"\n    CONVERT SORT PARAMETERS TO A NORMAL FORM SO EASIER TO USE\n    \"\"\"\n\n    if not sort:\n        return Null\n\n    output = FlatList()\n    for s in listwrap(sort):\n        if is_text(s) or mo_math.is_integer(s):\n            output.append({\"value\": s, \"sort\": 1})\n        elif not s.field and not s.value and s.sort==None:\n            #ASSUME {name: sort} FORM\n            for n, v in s.items():\n                output.append({\"value\": n, \"sort\": sort_direction[v]})\n        else:\n            output.append({\"value\": coalesce(s.field, s.value), \"sort\": coalesce(sort_direction[s.sort], 1)})\n    return wrap(output)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_tibia_datetime(datetime_str) -> Optional[datetime.datetime]:\n    try:\n        datetime_str = datetime_str.replace(\",\", \"\").replace(\"&#160;\", \" \")\n        # Extracting timezone\n        tz = datetime_str[-4:].strip()\n\n        # Convert time string to time object\n        # Removing timezone cause CEST and CET are not supported\n        t = datetime.datetime.strptime(datetime_str[:-4].strip(), \"%b %d %Y %H:%M:%S\")\n\n        # Getting the offset\n        if tz == \"CET\":\n            utc_offset = 1\n        elif tz == \"CEST\":\n            utc_offset = 2\n        else:\n            return None\n        # Add/subtract hours to get the real time\n        t = t - datetime.timedelta(hours=utc_offset)\n        return t.replace(tzinfo=datetime.timezone.utc)\n    except (ValueError, AttributeError):\n        return None", "response": "Parses a string in the format used in Tibia. com\n    and returns a datetime. datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a date from the format used in Tibia. com Accepted format : YYYYMMDD YYYY Returns optional date", "response": "def parse_tibia_date(date_str) -> Optional[datetime.date]:\n    \"\"\"Parses a date from the format used in Tibia.com\n\n    Accepted format:\n\n    - ``MMM DD YYYY``, e.g. ``Jul 23 2015``\n\n    Parameters\n    -----------\n    date_str: :class:`str`\n        The date as represented in Tibia.com\n\n    Returns\n    -----------\n    :class:`datetime.date`, optional\n        The represented date.\"\"\"\n    try:\n        t = datetime.datetime.strptime(date_str.strip(), \"%b %d %Y\")\n        return t.date()\n    except (ValueError, AttributeError):\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_tibiadata_datetime(date_dict) -> Optional[datetime.datetime]:\n    try:\n        t = datetime.datetime.strptime(date_dict[\"date\"], \"%Y-%m-%d %H:%M:%S.%f\")\n    except (KeyError, ValueError, TypeError):\n        return None\n\n    if date_dict[\"timezone\"] == \"CET\":\n        timezone_offset = 1\n    elif date_dict[\"timezone\"] == \"CEST\":\n        timezone_offset = 2\n    else:\n        return None\n    # We subtract the offset to convert the time to UTC\n    t = t - datetime.timedelta(hours=timezone_offset)\n    return t.replace(tzinfo=datetime.timezone.utc)", "response": "Parses the TibiaData API s time object into a datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef try_datetime(obj) -> Optional[datetime.datetime]:\n    if obj is None:\n        return None\n    if isinstance(obj, datetime.datetime):\n        return obj\n    res = parse_tibia_datetime(obj)\n    if res is not None:\n        return res\n    res = parse_tibiadata_datetime(obj)\n    return res", "response": "Attempts to convert an object into a datetime. datetime object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef try_date(obj) -> Optional[datetime.date]:\n    if obj is None:\n        return None\n    if isinstance(obj, datetime.datetime):\n        return obj.date()\n    if isinstance(obj, datetime.date):\n        return obj\n    res = parse_tibia_date(obj)\n    if res is not None:\n        return res\n    res = parse_tibia_full_date(obj)\n    if res is not None:\n        return res\n    res = parse_tibiadata_date(obj)\n    return res", "response": "Attempts to convert an object into a date."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_tibiacom_content(content, *, html_class=\"BoxContent\", tag=\"div\", builder=\"lxml\"):\n    return bs4.BeautifulSoup(content.replace('ISO-8859-1', 'utf-8'), builder,\n                             parse_only=bs4.SoupStrainer(tag, class_=html_class))", "response": "Parses the raw HTML content from Tibia. com into a BeautifulSoup object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef try_enum(cls: Type[T], val, default: D = None) -> Union[T, D]:\n    if isinstance(val, cls):\n        return val\n    try:\n        return cls(val)\n    except ValueError:\n        return default", "response": "Attempts to convert a value into their enum value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_json(content):\n    try:\n        json_content = json.loads(content)\n        return _recursive_strip(json_content)\n    except json.JSONDecodeError:\n        raise InvalidContent(\"content is not a json string.\")", "response": "Tries to parse a string into a json object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_social_share_link(context, share_link, object_url, object_title):\n\n    \"\"\"\n    Construct the social share link for the request object.\n\n    \"\"\"\n    request = context['request']\n    url = unicode(object_url)\n    if 'http' not in object_url.lower():\n        full_path = ''.join(('http', ('', 's')[request.is_secure()], '://', request.META['HTTP_HOST'], url))\n    else:\n        full_path = url\n\n    return share_link.get_share_url(full_path, object_title)", "response": "Construct the social share link for the request object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a set of all nodes that are connected to the given node.", "response": "def get_family(self, node):\n        \"\"\"\n        RETURN ALL ADJACENT NODES\n        \"\"\"\n        return set(p if c == node else c for p, c in self.get_edges(node))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef choices(self, cl):\n        #: Just tidy up standard implementation for the sake of DRY principle.\n        def _choice_item(is_selected, query_string, title):\n            return {\n                'selected': is_selected,\n                'query_string': query_string,\n                'display': force_text(title),\n            }\n\n        yield _choice_item(\n            self.lookup_val is None,\n            cl.get_query_string({}, [self.lookup_kwarg]),\n            _('All'))\n\n        container = (self.field.choices\n                     if isinstance(self.field, ChoicesField) else\n                     self.field.flatchoices)\n\n        for lookup, title in container:\n            yield _choice_item(\n                smart_text(lookup) == self.lookup_val,\n                cl.get_query_string({self.lookup_kwarg: lookup}),\n                title)", "response": "Yields the choices from ChoicesField and flatchoices"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef page_factory(request):\n    prefix = request.matchdict['prefix']  # /{prefix}/page1/page2/page3...\n    settings = request.registry.settings\n    dbsession = settings[CONFIG_DBSESSION]\n    config = settings[CONFIG_MODELS]\n\n    if prefix not in config:\n        # prepend {prefix} to *traverse\n        request.matchdict['traverse'] =\\\n            tuple([prefix] + list(request.matchdict['traverse']))\n        prefix = None\n\n    # Get all resources and models from config with the same prefix.\n    resources = config.get(\n        prefix, config.get(   # 1. get resources with prefix same as URL prefix\n            '', config.get(   # 2. if not, then try to get empty prefix\n                '/', None)))  # 3. else try to get prefix '/' otherwise None\n\n    if not hasattr(resources, '__iter__'):\n        resources = (resources, )\n\n    tree = {}\n\n    if not resources:\n        return tree\n\n    # Add top level nodes of resources in the tree\n    for resource in resources:\n        table = None\n        if not hasattr(resource, '__table__')\\\n                and hasattr(resource, 'model'):\n            table = resource.model\n        else:\n            table = resource\n\n        if not hasattr(table, 'slug'):\n            continue\n\n        nodes = dbsession.query(table)\n        if hasattr(table, 'parent_id'):\n            nodes = nodes.filter(or_(\n                table.parent_id == None,  # noqa\n                table.parent.has(table.slug == '/')\n            ))\n        for node in nodes:\n            if not node.slug:\n                continue\n            resource = resource_of_node(resources, node)\n            tree[node.slug] = resource(node, prefix=prefix)\n    return tree", "response": "Page factory.\n\n    Config models example:\n\n    .. code-block:: python\n\n        models = {\n            '': [WebPage, CatalogResource],\n            'catalogue': CatalogResource,\n            'news': NewsResource,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister views for each resource in the pages_config.", "response": "def register_views(*args):\n    \"\"\" Registration view for each resource from config.\n    \"\"\"\n    config = args[0]\n    settings = config.get_settings()\n    pages_config = settings[CONFIG_MODELS]\n    resources = resources_of_config(pages_config)\n    for resource in resources:\n        if hasattr(resource, '__table__')\\\n                and not hasattr(resource, 'model'):\n            continue\n        resource.model.pyramid_pages_template = resource.template\n        config.add_view(resource.view,\n                        attr=resource.attr,\n                        route_name=PREFIX_PAGE,\n                        renderer=resource.template,\n                        context=resource,\n                        permission=PREFIX_PAGE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef accumulate_nested_doc(nested_path, expr=IDENTITY):\n    name = literal_field(nested_path)\n    def output(doc):\n        acc = []\n        for h in doc.inner_hits[name].hits.hits:\n            i = h._nested.offset\n            obj = Data()\n            for f, v in h.fields.items():\n                local_path = untype_path(relative_field(f, nested_path))\n                obj[local_path] = unwraplist(v)\n            # EXTEND THE LIST TO THE LENGTH WE REQUIRE\n            for _ in range(len(acc), i+1):\n                acc.append(None)\n            acc[i] = expr(obj)\n        return acc\n    return output", "response": "A function that accumulates the nested_doc for each entry in the nested_path and returns a function that returns a list of the results."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef es_query_proto(path, selects, wheres, schema):\n    output = None\n    last_where = MATCH_ALL\n    for p in reversed(sorted( wheres.keys() | set(selects.keys()))):\n        where = wheres.get(p)\n        select = selects.get(p)\n\n        if where:\n            where = AndOp(where).partial_eval().to_esfilter(schema)\n            if output:\n                where = es_or([es_and([output, where]), where])\n        else:\n            if output:\n                if last_where is MATCH_ALL:\n                    where = es_or([output, MATCH_ALL])\n                else:\n                    where = output\n            else:\n                where = MATCH_ALL\n\n        if p == \".\":\n            output = set_default(\n                {\n                    \"from\": 0,\n                    \"size\": 0,\n                    \"sort\": [],\n                    \"query\": where\n                },\n                select.to_es()\n            )\n        else:\n            output = {\"nested\": {\n                \"path\": p,\n                \"inner_hits\": set_default({\"size\": 100000}, select.to_es()) if select else None,\n                \"query\": where\n            }}\n\n        last_where = where\n    return output", "response": "Returns a 2 - TUPLE that is a query that returns a nested dict with the keys nested and the values of the nested table as a nested dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine what to do with the next token in the tree.", "response": "def next_token(self, tokenum, value, scol):\n        \"\"\"Determine what to do with the next token\"\"\"\n\n        # Make self.current reflect these values\n        self.current.set(tokenum, value, scol)\n\n        # Determine indent_type based on this token\n        if self.current.tokenum == INDENT and self.current.value:\n            self.indent_type = self.current.value[0]\n\n        # Only proceed if we shouldn't ignore this token\n        if not self.ignore_token():\n            # Determining if this token is whitespace\n            self.determine_if_whitespace()\n\n            # Determine if inside a container\n            self.determine_inside_container()\n\n            # Change indentation as necessary\n            self.determine_indentation()\n\n            # See if we are force inserting this token\n            if self.forced_insert():\n                return\n\n            # If we have a newline after an inserted line, then we don't need to worry about semicolons\n            if self.inserted_line and self.current.tokenum == NEWLINE:\n                self.inserted_line = False\n\n            # If we have a non space, non comment after an inserted line, then insert a semicolon\n            if self.result and not self.is_space and self.inserted_line:\n                if self.current.tokenum != COMMENT:\n                    self.result.append((OP, ';'))\n                self.inserted_line = False\n\n            # Progress the tracker\n            self.progress()\n\n            # Add a newline if we just skipped a single\n            if self.single and self.single.skipped:\n                self.single.skipped = False\n                self.result.append((NEWLINE, '\\n'))\n\n            # Set after_space so next line knows if it is after space\n            self.after_space = self.is_space"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeals with next token Used to create fillout and end groups and singles.", "response": "def progress(self):\n        \"\"\"\n            Deal with next token\n            Used to create, fillout and end groups and singles\n            As well as just append everything else\n        \"\"\"\n        tokenum, value, scol = self.current.values()\n\n        # Default to not appending anything\n        just_append = False\n\n        # Prevent from group having automatic pass given to it\n        # If it already has a pass\n        if tokenum == NAME and value == 'pass':\n            self.groups.empty = False\n\n        # Set variables to be used later on to determine if this will likely make group not empty\n        created_group = False\n        found_content = False\n        if not self.groups.starting_group and not self.is_space:\n            found_content = True\n\n        if self.groups.starting_group:\n            # Inside a group signature, add to it\n            if tokenum == STRING:\n                self.groups.name = value\n\n            elif tokenum == NAME or (tokenum == OP and value == '.'):\n                # Modify super class for group\n                self.groups.modify_kls(value)\n\n            elif tokenum == NEWLINE:\n                # Premature end of group\n                self.add_tokens_for_group(with_pass=True)\n\n            elif tokenum == OP and value == \":\":\n                # Proper end of group\n                self.add_tokens_for_group()\n\n        elif self.groups.starting_single:\n            # Inside single signature, add to it\n            if tokenum == STRING:\n                self.single.name = value\n\n            elif tokenum == NEWLINE and not self.in_container:\n                # Premature end of single\n                self.add_tokens_for_single(ignore=True)\n\n            elif tokenum == OP and value == \":\":\n                # Proper end of single\n                self.add_tokens_for_single()\n\n            elif value and self.single.name:\n                # Only want to add args after the name for the single has been specified\n                self.single.add_to_arg(tokenum, value)\n\n        elif self.after_space or self.after_an_async or scol == 0 and tokenum == NAME:\n            # set after_an_async if we found an async by itself\n            # So that we can just have that prepended and still be able to interpret our special blocks\n            with_async = self.after_an_async\n            if not self.after_an_async and value == \"async\":\n                self.after_an_async = True\n            else:\n                self.after_an_async = False\n\n            if value in ('describe', 'context'):\n                created_group = True\n\n                # add pass to previous group if nothing added between then and now\n                if self.groups.empty and not self.groups.root:\n                    self.add_tokens_for_pass()\n\n                # Start new group\n                self.groups = self.groups.start_group(scol, value)\n                self.all_groups.append(self.groups)\n\n            elif value in ('it', 'ignore'):\n                self.single = self.groups.start_single(value, scol)\n\n            elif value in ('before_each', 'after_each'):\n                setattr(self.groups, \"has_%s\" % value, True)\n                if with_async:\n                    setattr(self.groups, \"async_%s\" % value, True)\n                self.add_tokens_for_test_helpers(value, with_async=with_async)\n\n            else:\n                just_append = True\n        else:\n            # Don't care about it, append!\n            just_append = True\n\n        # Found something that isn't whitespace or a new group\n        # Hence current group isn't empty !\n        if found_content and not created_group:\n            self.groups.empty = False\n\n        # Just append if token should be\n        if just_append:\n            self.result.append([tokenum, value])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reset_indentation(self, amount):\n        while self.result and self.result[-1][0] == INDENT:\n            self.result.pop()\n        self.result.append((INDENT, amount))", "response": "Replace previous indentation with desired amount"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ignore_token(self):\n        def get_next_ignore(remove=False):\n            \"\"\"Get next ignore from ignore_next and remove from ignore_next\"\"\"\n            next_ignore = self.ignore_next\n\n            # Just want to return it, don't want to remove yet\n            if not remove:\n                if type(self.ignore_next) in (list, tuple):\n                    next_ignore = self.ignore_next[0]\n                return next_ignore\n\n            # Want to remove it from ignore_next\n            if type(next_ignore) in (list, tuple) and next_ignore:\n                next_ignore = self.ignore_next.pop(0)\n            elif not next_ignore:\n                self.next_ignore = None\n                next_ignore = None\n            else:\n                self.next_ignore = None\n\n            return next_ignore\n\n        # If we have tokens to be ignored and we're not just inserting till some token\n        if not self.insert_till and self.ignore_next:\n            # Determine what the next ignore is\n            next_ignore = get_next_ignore()\n            if next_ignore == (self.current.tokenum, self.current.value):\n                # Found the next ignore token, remove it from the stack\n                # So that the next ignorable token can be considered\n                get_next_ignore(remove=True)\n                return True\n            else:\n                # If not a wildcard, then return now\n                if type(next_ignore) is not WildCard:\n                    return False\n\n                # Go through tokens untill we find one that isn't a wildcard\n                while type(next_ignore) == WildCard:\n                    next_ignore = get_next_ignore(remove=True)\n\n                # If the next token is next ignore then we're done here!\n                if next_ignore == (self.current.tokenum, self.current.value):\n                    get_next_ignore(remove=True)\n                    return True\n                else:\n                    # If there is another token to ignore, then consider the wildcard\n                    # And keep inserting till we reach this next ignorable token\n                    if next_ignore:\n                        self.insert_till = next_ignore\n                    return False", "response": "Determine if we should ignore current token"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wrapped_setups(self):\n        lst = []\n        for group in self.all_groups:\n            if not group.root:\n                if group.has_after_each:\n                    lst.extend(self.tokens.wrap_after_each(group.kls_name, group.async_after_each))\n\n                if group.has_before_each:\n                    lst.extend(self.tokens.wrap_before_each(group.kls_name, group.async_before_each))\n\n        if lst:\n            indentation_reset = [\n                  (NEWLINE, '\\n')\n                , (INDENT, '')\n                ]\n            lst = indentation_reset + lst\n\n        return lst", "response": "Create tokens for Described. setup for setup and teardown."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate tokens for setting __testname__ on functions", "response": "def make_method_names(self):\n        \"\"\"Create tokens for setting __testname__ on functions\"\"\"\n        lst = []\n        for group in self.all_groups:\n            for single in group.singles:\n                name, english = single.name, single.english\n                if english[1:-1] != name.replace('_', ' '):\n                    lst.extend(self.tokens.make_name_modifier(not group.root, single.identifier, english))\n        return lst"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates tokens for setting is_noy_spec on describes", "response": "def make_describe_attrs(self):\n        \"\"\"Create tokens for setting is_noy_spec on describes\"\"\"\n        lst = []\n        if self.all_groups:\n            lst.append((NEWLINE, '\\n'))\n            lst.append((INDENT, ''))\n\n            for group in self.all_groups:\n                if group.name:\n                    lst.extend(self.tokens.make_describe_attr(group.kls_name))\n\n        return lst"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef forced_insert(self):\n        # If we have any tokens we are waiting for\n        if self.insert_till:\n            # Determine where to append this token\n            append_at = -1\n            if self.inserted_line:\n                append_at = -self.inserted_line+1\n\n            # Reset insert_till if we found it\n            if self.current.tokenum == self.insert_till[0] and self.current.value == self.insert_till[1]:\n                self.insert_till = None\n            else:\n                # Adjust self.adjust_indent_at to take into account the new token\n                for index, value in enumerate(self.adjust_indent_at):\n                    if value < len(self.result) - append_at:\n                        self.adjust_indent_at[index] = value + 1\n\n                # Insert the new token\n                self.result.insert(append_at, (self.current.tokenum, self.current.value))\n\n            # We appended the token\n            return True", "response": "Returns True if the current token is inserted before it False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_tokens_for_pass(self):\n        # Make sure pass not added to group again\n        self.groups.empty = False\n\n        # Remove existing newline/indentation\n        while self.result[-1][0] in (INDENT, NEWLINE):\n            self.result.pop()\n\n        # Add pass and indentation\n        self.add_tokens(\n            [ (NAME, 'pass')\n            , (NEWLINE, '\\n')\n            , (INDENT, self.indent_type * self.current.scol)\n            ]\n        )", "response": "Add tokens for a pass to result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_tokens_for_group(self, with_pass=False):\n        kls = self.groups.super_kls\n        name = self.groups.kls_name\n\n        # Reset indentation to beginning and add signature\n        self.reset_indentation('')\n        self.result.extend(self.tokens.make_describe(kls, name))\n\n        # Add pass if necessary\n        if with_pass:\n            self.add_tokens_for_pass()\n\n        self.groups.finish_signature()", "response": "Add the tokens for the group signature"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_tokens_for_single(self, ignore=False):\n        args = self.single.args\n        name = self.single.python_name\n\n        # Reset indentation to proper amount and add signature\n        self.reset_indentation(self.indent_type * self.single.indent)\n        self.result.extend(self.tokens.make_single(name, args))\n\n        # Add skip if necessary\n        if ignore:\n            self.single.skipped = True\n            self.result.extend(self.tokens.test_skip)\n\n        self.groups.finish_signature()", "response": "Add the tokens for the single signature"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef finish_hanging(self):\n        if self.groups.starting_signature:\n            if self.groups.starting_group:\n                self.add_tokens_for_group(with_pass=True)\n\n            elif self.groups.starting_single:\n                self.add_tokens_for_single(ignore=True)", "response": "Add tokens for hanging singature if any"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef determine_if_whitespace(self):\n        value = self.current.value\n\n        if value == '\\n':\n            self.is_space = True\n        else:\n            self.is_space = False\n            if (value == '' or regexes['whitespace'].match(value)):\n                self.is_space = True", "response": "Determine if the current token is whitespace."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef determine_inside_container(self):\n        tokenum, value = self.current.tokenum, self.current.value\n        ending_container = False\n        starting_container = False\n\n        if tokenum == OP:\n            # Record when we're inside a container of some sort (tuple, list, dictionary)\n            # So that we can care about that when determining what to do with whitespace\n            if value in ['(', '[', '{']:\n                # add to the stack because we started a list\n                self.containers.append(value)\n                starting_container = True\n\n            elif value in [')', ']', '}']:\n                # not necessary to check for correctness\n                self.containers.pop()\n                ending_container = True\n\n        self.just_ended_container = not len(self.containers) and ending_container\n        self.just_started_container = len(self.containers) == 1 and starting_container\n        self.in_container = len(self.containers) or self.just_ended_container or self.just_started_container", "response": "Determine if we re inside a container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetermine indentation for current token and in self. result.", "response": "def determine_indentation(self):\n        \"\"\"Reset indentation for current token and in self.result to be consistent and normalized\"\"\"\n        # Ensuring NEWLINE tokens are actually specified as such\n        if self.current.tokenum != NEWLINE and self.current.value == '\\n':\n            self.current.tokenum = NEWLINE\n\n        # I want to change dedents into indents, because they seem to screw nesting up\n        if self.current.tokenum == DEDENT:\n            self.current.tokenum, self.current.value = self.convert_dedent()\n\n        if self.after_space and not self.is_space and (not self.in_container or self.just_started_container):\n            # Record current indentation level\n            if not self.indent_amounts or self.current.scol > self.indent_amounts[-1]:\n                self.indent_amounts.append(self.current.scol)\n\n            # Adjust indent as necessary\n            while self.adjust_indent_at:\n                self.result[self.adjust_indent_at.pop()] = (INDENT, self.indent_type * (self.current.scol - self.groups.level))\n\n        # Roll back groups as necessary\n        if not self.is_space and not self.in_container:\n            while not self.groups.root and self.groups.level >= self.current.scol:\n                self.finish_hanging()\n                self.groups = self.groups.parent\n\n        # Reset indentation to deal with nesting\n        if self.current.tokenum == INDENT and not self.groups.root:\n           self.current.value = self.current.value[self.groups.level:]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a dedent into an indent", "response": "def convert_dedent(self):\n        \"\"\"Convert a dedent into an indent\"\"\"\n        # Dedent means go back to last indentation\n        if self.indent_amounts:\n            self.indent_amounts.pop()\n\n        # Change the token\n        tokenum = INDENT\n\n        # Get last indent amount\n        last_indent = 0\n        if self.indent_amounts:\n            last_indent = self.indent_amounts[-1]\n\n        # Make sure we don't have multiple indents in a row\n        while self.result[-1][0] == INDENT:\n            self.result.pop()\n\n        value = self.indent_type * last_indent\n        return tokenum, value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lookupAll(data, configFields, lookupType, db, histObj={}):\n\n    for field in data.keys():\n\n        if field in configFields.keys() and data[field]!='':\n\n            if lookupType in configFields[field][\"lookup\"]:\n\n                if lookupType in ['genericLookup', 'fieldSpecificLookup', 'normLookup']:\n\n                    fieldValNew, histObj = DataLookup(fieldVal=data[field], db=db, lookupType=lookupType, fieldName=field, histObj=histObj)\n\n                elif lookupType in ['genericRegex', 'fieldSpecificRegex', 'normRegex']:\n\n                    fieldValNew, histObj = RegexLookup(fieldVal=data[field], db=db, fieldName=field, lookupType=lookupType, histObj=histObj)\n\n                elif lookupType=='normIncludes':\n\n                    fieldValNew, histObj, checkMatch = IncludesLookup(fieldVal=data[field], lookupType='normIncludes', db=db, fieldName=field, histObj=histObj)\n\n                data[field] = fieldValNew\n\n    return data, histObj", "response": "This function will perform a single lookup on all fields in the configFields and returns a single record after having cleaning rules applied to all fields in the configFields."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef DeriveDataLookupAll(data, configFields, db, histObj={}):\n\n    def checkDeriveOptions(option, derive_set_config):\n        \"\"\"\n        Check derive option is exist into options list and return relevant flag.\n        :param option: drive options value\n        :param derive_set_config: options list\n        :return: boolean True or False based on option exist into options list\n        \"\"\"\n\n        return option in derive_set_config\n\n    for field in configFields.keys():\n\n        if field in data.keys():\n\n            fieldVal = data[field]\n\n            fieldValNew = fieldVal\n\n            for deriveSet in configFields[field]['derive'].keys():\n\n                deriveSetConfig = configFields[field]['derive'][deriveSet]\n\n                checkMatch = False\n\n                if set.issubset(set(deriveSetConfig['fieldSet']), data.keys()):\n\n                    deriveInput = {}\n\n                    # sorting here to ensure subdocument match from query\n                    for val in deriveSetConfig['fieldSet']:\n                        deriveInput[val] = data[val]\n\n                    if deriveSetConfig['type']=='deriveValue':\n\n                        fieldValNew, histObj, checkMatch = DeriveDataLookup(fieldName=field, db=db, deriveInput=deriveInput, overwrite=checkDeriveOptions('overwrite', deriveSetConfig[\"options\"]), fieldVal=fieldVal, histObj=histObj, blankIfNoMatch=checkDeriveOptions('blankIfNoMatch', deriveSetConfig[\"options\"]))\n\n                    elif deriveSetConfig['type']=='copyValue':\n\n                        fieldValNew, histObj, checkMatch = DeriveDataCopyValue(fieldName=field, deriveInput=deriveInput, overwrite=checkDeriveOptions('overwrite', deriveSetConfig[\"options\"]), fieldVal=fieldVal, histObj=histObj)\n\n                    elif deriveSetConfig['type']=='deriveRegex':\n\n                        fieldValNew, histObj, checkMatch = DeriveDataRegex(fieldName=field, db=db, deriveInput=deriveInput, overwrite=checkDeriveOptions('overwrite', deriveSetConfig[\"options\"]), fieldVal=fieldVal, histObj=histObj, blankIfNoMatch=checkDeriveOptions('blankIfNoMatch', deriveSetConfig[\"options\"]))\n\n                    elif deriveSetConfig['type']=='deriveIncludes':\n\n                        fieldValNew, histObj, checkMatch = IncludesLookup(fieldVal=data[field], lookupType='deriveIncludes', deriveFieldName=deriveSetConfig['fieldSet'][0], deriveInput=deriveInput,  db=db, fieldName=field, histObj=histObj, overwrite=checkDeriveOptions('overwrite', deriveSetConfig[\"options\"]), blankIfNoMatch=checkDeriveOptions('blankIfNoMatch', deriveSetConfig[\"options\"]))\n\n                if checkMatch or fieldValNew!=fieldVal:\n                    data[field] = fieldValNew\n\n                    break\n\n    return data, histObj", "response": "This function takes a dictionary of data and returns a single record after performing derive rules for all fields in the order they appear in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_generators(self):\n        # on using entrypoints:\n        # http://stackoverflow.com/questions/774824/explain-python-entry-points\n        # TODO: make sure we do not have conflicting generators installed!\n        generators = [ep.name for ep in\n                      pkg_resources.iter_entry_points(self.group)]\n        return generators", "response": "Get installed banana plugins.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_generator(self, name):\n        for ep in pkg_resources.iter_entry_points(self.group, name=None):\n            if ep.name == name:\n                generator = ep.load()\n                return generator", "response": "Load the generator plugin and execute its lifecycle."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute(self, name):\n        generator = self._get_generator(name)\n        generator.initializing()\n        answers = generator.prompting(create_store_prompt(name))\n        # TODO\n        # app.insight.track('yoyo', 'help', answers)\n        generator.configuring(answers)\n        generator.writing(answers)", "response": "Orchestrate the work of the generator plugin."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse ba arguments and return them as a dict", "response": "def parse_args(self, doc, argv):\n        \"\"\"Parse ba arguments\n\n        :param args: sys.argv[1:]\n        :return: arguments\n        \"\"\"\n        # first a little sneak peak if we have a generator\n        arguments = docopt(doc, argv=argv, help=False)\n        if arguments.get('<generator>'):\n            name = arguments['<generator>']\n            generator = self._get_generator(name)\n\n            if hasattr(generator, 'DOC'):\n                # register help for generator!\n                # this runs after the generator was loaded so we have to\n                # prepend the cmd!\n                def _banana_help(args, router):\n                    print(doc)\n\n                cmd.register(lambda args: args.get('--help'), name,\n                             _banana_help)\n                doc = generator.DOC\n                arguments = docopt(doc, argv=argv, help=False)\n\n            # register generator '--version' cmd\n            version = 'not provided by %s generator' % name\n            if hasattr(generator, '__version__'):\n                version = generator.__version__\n\n            def _banana_version(args, router):\n                print(version)\n\n            cmd.register(lambda args: args.get('--version'), name,\n                         _banana_version)\n\n            # register generator interactive mode (last cmd for this generator)\n            def _banana_run(args, router):\n                router.navigate('run', name)\n                router.navigate('exit')\n            cmd.register(lambda args: True, name, _banana_run)\n\n        return arguments"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef navigate(self, name, *args):\n        if name not in self.routes:\n            raise Exception('invalid route name \\'%s\\'' % name)\n        elif callable(self.routes[name]):\n            return self.routes[name](self, *args)\n        raise Exception('route %s not callable', name)", "response": "Navigate to a route in the cache"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering a route handler for a specific name", "response": "def register_route(self, name, route):\n        \"\"\"Register a route handler\n\n        :param name: Name of the route\n        :param route: Route handler\n        \"\"\"\n        try:\n            self.routes[name] = route.handle\n        except Exception as e:\n            print('could not import handle, maybe something wrong ',\n                  'with your code?')\n            print(e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef box(script):\n    if script.type is BOOLEAN:\n        return \"Boolean.valueOf(\" + text_type(script.expr) + \")\"\n    elif script.type is INTEGER:\n        return \"Integer.valueOf(\" + text_type(script.expr) + \")\"\n    elif script.type is NUMBER:\n        return \"Double.valueOf(\" + text_type(script.expr) + \")\"\n    else:\n        return script.expr", "response": "returns the expression of the script with non - objects BOXED"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, full_name, repetition_type, type):\n        base_name = self.element.name\n        simple_name = relative_field(full_name, base_name)\n        path = split_field(simple_name)\n        output = self\n\n        if len(path) == 0:\n            return output._add_one('.', full_name, repetition_type, type)\n        else:\n            fname = base_name\n            for p in path[:-1]:\n                fname = concat_field(fname, p)\n                n = output.more.get(p)\n                output = n or output._add_one(p, fname, OPTIONAL, object)\n\n            return output._add_one(path[-1], full_name, repetition_type, type)", "response": "Adds a new entry to the internal list of the object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of schema elements that are part of the tree.", "response": "def get_parquet_metadata(\n        self,\n        path='.'\n    ):\n        \"\"\"\n        OUTPUT PARQUET METADATA COLUMNS\n        :param path: FOR INTERNAL USE\n        :return: LIST OF SchemaElement\n        \"\"\"\n        children = []\n        for name, child_schema in sort_using_key(self.more.items(), lambda p: p[0]):\n            children.extend(child_schema.get_parquet_metadata(concat_field(path, name)))\n\n        if path == '.':\n            return children\n        else:\n            self.element.num_children = len(children)\n            return [self.element] + children"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_json(self, *, indent=None, sort_keys = False):\n        return json.dumps({k: v for k, v in dict(self).items() if v is not None}, indent=indent, sort_keys=sort_keys,\n                          default=self._try_dict)", "response": "Returns the object s JSON representation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef url(self):\n        return self.get_url(self.id, self.world) if self.id and self.world else None", "response": "Returns the URL to the Tibia. com page of the house."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef url_tibiadata(self):\n        return self.get_url_tibiadata(self.id, self.world) if self.id and self.world else None", "response": "Returns the URL to the TibiaData. com page of the house."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the TUIDS of a single file", "response": "def get_tuid(self, branch, revision, file):\n        \"\"\"\n        :param branch: BRANCH TO FIND THE REVISION/FILE\n        :param revision: THE REVISION NUNMBER\n        :param file: THE FULL PATH TO A SINGLE FILE\n        :return: A LIST OF TUIDS\n        \"\"\"\n        service_response = wrap(self.get_tuids(branch, revision, [file]))\n        for f, t in service_response.items():\n            return t"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_tuids(self, branch, revision, files):\n\n        # SCRUB INPUTS\n        revision = revision[:12]\n        files = [file.lstrip('/') for file in files]\n\n        with Timer(\n            \"ask tuid service for {{num}} files at {{revision|left(12)}}\",\n            {\"num\": len(files), \"revision\": revision},\n            silent=not DEBUG or not self.enabled\n        ):\n            response = self.db.query(\n                \"SELECT file, tuids FROM tuid WHERE revision=\" + quote_value(revision) +\n                \" AND file IN \" + quote_list(files)\n            )\n            found = {file: json2value(tuids) for file, tuids in response.data}\n\n            try:\n                remaining = set(files) - set(found.keys())\n                new_response = None\n                if remaining:\n                    request = wrap({\n                        \"from\": \"files\",\n                        \"where\": {\"and\": [\n                            {\"eq\": {\"revision\": revision}},\n                            {\"in\": {\"path\": remaining}},\n                            {\"eq\": {\"branch\": branch}}\n                        ]},\n                        \"branch\": branch,\n                        \"meta\": {\n                            \"format\": \"list\",\n                            \"request_time\": Date.now()\n                        }\n                    })\n                    if self.push_queue is not None:\n                        if DEBUG:\n                            Log.note(\"record tuid request to SQS: {{timestamp}}\", timestamp=request.meta.request_time)\n                        self.push_queue.add(request)\n                    else:\n                        if DEBUG:\n                            Log.note(\"no recorded tuid request\")\n\n                    if not self.enabled:\n                        return found\n\n                    new_response = http.post_json(\n                        self.endpoint,\n                        json=request,\n                        timeout=self.timeout\n                    )\n\n                    if new_response.data and any(r.tuids for r in new_response.data):\n                        try:\n                            with self.db.transaction() as transaction:\n\n\n                                command = \"INSERT INTO tuid (revision, file, tuids) VALUES \" + sql_list(\n                                    quote_list((revision, r.path, value2json(r.tuids)))\n                                    for r in new_response.data\n                                    if r.tuids != None\n                                )\n                                if not command.endswith(\" VALUES \"):\n                                    transaction.execute(command)\n                        except Exception as e:\n                            Log.error(\"can not insert {{data|json}}\", data=new_response.data, cause=e)\n                self.num_bad_requests = 0\n\n                found.update({r.path: r.tuids for r in new_response.data} if new_response else {})\n                return found\n\n            except Exception as e:\n                self.num_bad_requests += 1\n                if self.enabled:\n                    if \"502 Bad Gateway\" in e:\n                        self.enabled = False\n                        Log.error(\"TUID service has problems.\", cause=e)\n                    elif self.num_bad_requests >= MAX_BAD_REQUESTS:\n                        self.enabled = False\n                        Log.error(\"TUID service has problems.\", cause=e)\n                    else:\n                        Log.warning(\"TUID service has problems.\", cause=e)\n                        Till(seconds=SLEEP_ON_ERROR).wait()\n                return found", "response": "GET TUIDS FROM ENDPOINT AND STORE IN DB\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds two routes to the specified instance of meteor_server. MeteorApp and allow the import API to be used for replication of data to this server.", "response": "def add_routes(meteor_app, url_path='/importv2'):\n    \"\"\"\n    Add two routes to the specified instance of :class:`meteorpi_server.MeteorApp` to implement the import API and allow\n    for replication of data to this server.\n\n    :param meteorpi_server.MeteorApp meteor_app:\n        The :class:`meteorpi_server.MeteorApp` to which import routes should be added\n    :param meteorpi_server.importer_api.BaseImportReceiver handler:\n        A subclass of :class:`meteorpi_server.importer_api.BaseImportReceiver` which is used to handle the import. If\n        not specified this defaults to an instance of :class:`meteorpi_server.importer_api.MeteorDatabaseImportReceiver`\n        which will replicate any missing information from the import into the database attached to the meteor_app.\n    :param string url_path:\n        The base of the import routes for this application. Defaults to '/import' - routes will be created at this path\n        and as import_path/data/<id> for binary data reception. Both paths only respond to POST requests and require\n        that the requests are authenticated and that the authenticated user has the 'import' role.\n    \"\"\"\n    app = meteor_app.app\n\n    @app.route(url_path, methods=['POST'])\n    @meteor_app.requires_auth(roles=['import'])\n    def import_entities():\n        \"\"\"\n        Receive an entity import request, using :class:`meteorpi_server.import_api.ImportRequest` to parse it, then\n        passing the parsed request on to an instance of :class:`meteorpi_server.import_api.BaseImportReceiver` to deal\n        with the possible import types.\n\n        :return:\n            A response, generally using one of the response_xxx methods in ImportRequest\n        \"\"\"\n        db = meteor_app.get_db()\n        handler = MeteorDatabaseImportReceiver(db=db)\n        import_request = ImportRequest.process_request()\n        if import_request.entity is None:\n            return import_request.response_continue()\n        if import_request.entity_type == 'file':\n            response = handler.receive_file_record(import_request)\n            handler.db.commit()\n            db.close_db()\n            if response is not None:\n                return response\n            else:\n                return import_request.response_complete()\n        elif import_request.entity_type == 'observation':\n            response = handler.receive_observation(import_request)\n            handler.db.commit()\n            db.close_db()\n            if response is not None:\n                return response\n            else:\n                return import_request.response_complete()\n        elif import_request.entity_type == 'metadata':\n            response = handler.receive_metadata(import_request)\n            handler.db.commit()\n            db.close_db()\n            if response is not None:\n                return response\n            else:\n                return import_request.response_continue()\n        else:\n            db.close_db()\n            return import_request.response_failed(\"Unknown import request\")\n\n    @app.route('{0}/data/<file_id_hex>/<md5_hex>'.format(url_path), methods=['POST'])\n    @meteor_app.requires_auth(roles=['import'])\n    def import_file_data(file_id_hex, md5_hex):\n        \"\"\"\n        Receive a file upload, passing it to the handler if it contains the appropriate information\n\n        :param string file_id_hex:\n            The hex representation of the :class:`meteorpi_model.FileRecord` to which this data belongs.\n        \"\"\"\n        db = meteor_app.get_db()\n        handler = MeteorDatabaseImportReceiver(db=db)\n        file_id = file_id_hex\n        file_data = request.files['file']\n        if file_data:\n            handler.receive_file_data(file_id=file_id, file_data=file_data, md5_hex=md5_hex)\n        db.close_db()\n        return ImportRequest.response_continue_after_file()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef response_complete(self):\n        ImportRequest.logger.info(\"Completed import for {0} with id {1}\".format(self.entity_type, self.entity_id))\n        ImportRequest.logger.debug(\"Sending: complete\")\n        return jsonify({'state': 'complete'})", "response": "This method is called when the export request has completed."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsignals that a partial reception of data has occurred and that the exporter should continue to send data for this entity. This should also be used if import-side caching has missed, in which case the response will direct the exporter to re-send the full data for the entity (otherwise it will send back the entity ID and rely on the import party's caching to resolve it). Use this for generic cases where we need to be messaged again about this entity - currently used after requesting and receiving a status block, and in its cache-refresh form if we have a cache miss during import. :return: A response that can be returned from a Flask service method", "response": "def response_continue(self):\n        \"\"\"\n        Signals that a partial reception of data has occurred and that the exporter should continue to send data for\n        this entity. This should also be used if import-side caching has missed, in which case the response will direct\n        the exporter to re-send the full data for the entity (otherwise it will send back the entity ID and rely on the\n        import party's caching to resolve it). Use this for generic cases where we need to be messaged again about this\n        entity - currently used after requesting and receiving a status block, and in its cache-refresh form if we have\n        a cache miss during import.\n\n        :return:\n            A response that can be returned from a Flask service method\n        \"\"\"\n        if self.entity is not None:\n            ImportRequest.logger.debug(\"Sending: continue\")\n            return jsonify({'state': 'continue'})\n        else:\n            ImportRequest.logger.debug(\"Sending: continue-nocache\")\n            return jsonify({'state': 'continue-nocache'})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess a request from the server and return a new ImportRequest object.", "response": "def process_request():\n        \"\"\"\n        Retrieve a CameraStatus, Event or FileRecord from the request, based on the supplied type and ID. If the type is\n        'cached_request' then the ID must be specified in 'cached_request_id' - if this ID is not for an entity in the\n        cache this method will return None and clear the cache (this should only happen under conditions where we've\n        failed to correctly handle caching, such as a server restart or under extreme load, but will result in the\n        server having to re-request a previous value from the exporting party).\n\n        :return:\n            A dict containing 'entity' - the entity for this request or None if there was an issue causing an unexpected\n            cache miss, and 'entity-id' which will be the UUID of the entity requested.\n            The entity corresponding to this request, or None if we had an issue and there was an unexpected cache miss.\n        \"\"\"\n        g.request_dict = safe_load(request.get_data())\n        entity_type = g.request_dict['type']\n        entity_id = g.request_dict[entity_type]['id']\n        ImportRequest.logger.debug(\"Received request, type={0}, id={1}\".format(entity_type, entity_id))\n        entity = ImportRequest._get_entity(entity_id)\n        ImportRequest.logger.debug(\"Entity with id={0} was {1}\".format(entity_id, entity))\n        return ImportRequest(entity=entity, entity_id=entity_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_entity(entity_id):\n        entity_type = g.request_dict['type']\n        if entity_type == 'file':\n            return model.FileRecord.from_dict(g.request_dict['file'])\n        elif entity_type == 'metadata':\n            return model.ObservatoryMetadata.from_dict(g.request_dict['metadata'])\n        elif entity_type == 'observation':\n            return model.Observation.from_dict(g.request_dict['observation'])\n        else:\n            return None", "response": "Retrieves a specific entity from the request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_game(site, description=\"\", create=False):\n\n    game = None\n    games = Game.objects.filter(site=site).order_by(\"-created\")\n    try:\n        game = games[0]\n    except IndexError:\n        game = None\n\n    # no game, yet, or game expired\n    if game is None or game.is_expired() or is_after_endtime():\n        if create:\n            if is_starttime():\n                game = Game(site=site, description=description)\n                game.save()\n            else:\n                raise TimeRangeError(\n                    _(u\"game start outside of the valid timerange\"))\n        else:\n            game = None\n\n    # game exists and its not after the GAME_END_TIME\n    elif not is_after_endtime():\n        game = games[0]\n\n    return game", "response": "get the current game if it is still active else creates a new game"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef words_with_votes(self, only_topics=True):\n        result = Word.objects.filter(\n            bingofield__board__game__id=self.id).exclude(\n            type=WORD_TYPE_MIDDLE)\n\n        if only_topics:\n            result = result.exclude(bingofield__word__type=WORD_TYPE_META)\n\n        result = result.annotate(\n            votes=Sum(\"bingofield__vote\")).order_by(\"-votes\").values()\n\n        for item in result:\n            item['votes'] = max(0, item['votes'])\n            if result[0]['votes'] != 0:\n                item['percent'] = float(item['votes']) / result[0]['votes'] * 100\n            else:\n                item['percent'] = 0\n        return result", "response": "Returns a list with words ordered by the number of votes in the votes property."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _assign_to_null(obj, path, value, force=True):\n    try:\n        if obj is Null:\n            return\n        if _get(obj, CLASS) is NullType:\n            d = _get(obj, \"__dict__\")\n            o = d[OBJ]\n            p = d[\"__key__\"]\n            s = [p]+path\n            return _assign_to_null(o, s, value)\n\n        path0 = path[0]\n\n        if len(path) == 1:\n            if force:\n                obj[path0] = value\n            else:\n                _setdefault(obj, path0, value)\n            return\n\n        old_value = obj.get(path0)\n        if old_value == None:\n            if value == None:\n                return\n            else:\n                obj[path0] = old_value = {}\n\n        _assign_to_null(old_value, path[1:], value)\n    except Exception as e:\n        raise e", "response": "Assign value to obj if obj is Null or if obj is a dict and path is an array of properties names."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a regex from a space - separated list of literal choices.", "response": "def literals(choices, prefix=\"\", suffix=\"\"):\n    \"\"\"Create a regex from a space-separated list of literal `choices`.\n\n    If provided, `prefix` and `suffix` will be attached to each choice\n    individually.\n\n    \"\"\"\n    return \"|\".join(prefix + re.escape(c) + suffix for c in choices.split())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef new_instance(settings):\n    settings = set_default({}, settings)\n    if not settings[\"class\"]:\n        Log.error(\"Expecting 'class' attribute with fully qualified class name\")\n\n    # IMPORT MODULE FOR HANDLER\n    path = settings[\"class\"].split(\".\")\n    class_name = path[-1]\n    path = \".\".join(path[:-1])\n    constructor = None\n    try:\n        temp = __import__(path, globals(), locals(), [class_name], 0)\n        constructor = object.__getattribute__(temp, class_name)\n    except Exception as e:\n        Log.error(\"Can not find class {{class}}\", {\"class\": path}, cause=e)\n\n    settings['class'] = None\n    try:\n        return constructor(kwargs=settings)  # MAYBE IT TAKES A KWARGS OBJECT\n    except Exception as e:\n        pass\n\n    try:\n        return constructor(**settings)\n    except Exception as e:\n        Log.error(\"Can not create instance of {{name}}\", name=\".\".join(path), cause=e)", "response": "Creates a new object of the same class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a function by its full name.", "response": "def get_function_by_name(full_name):\n    \"\"\"\n    RETURN FUNCTION\n    \"\"\"\n\n    # IMPORT MODULE FOR HANDLER\n    path = full_name.split(\".\")\n    function_name = path[-1]\n    path = \".\".join(path[:-1])\n    constructor = None\n    try:\n        temp = __import__(path, globals(), locals(), [function_name], -1)\n        output = object.__getattribute__(temp, function_name)\n        return output\n    except Exception as e:\n        Log.error(\"Can not find function {{name}}\",  name= full_name, cause=e)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extend(cls):\n    def extender(func):\n        setattr(cls, get_function_name(func), func)\n        return func\n    return extender", "response": "A decorator that adds a function to the class s hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalize_fieldsets(fieldsets):\n    result = []\n    for name, options in fieldsets:\n        result.append((name, normalize_dictionary(options)))\n    return result", "response": "Normalizes the keys in fieldset dictionaries are strings. Returns the resulting list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nnormalize the dictionary so that all keys in data_dict are strings.", "response": "def normalize_dictionary(data_dict):\n    \"\"\"\n    Converts all the keys in \"data_dict\" to strings. The keys must be\n    convertible using str().\n    \"\"\"\n    for key, value in data_dict.items():\n        if not isinstance(key, str):\n            del data_dict[key]\n            data_dict[str(key)] = value\n    return data_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_sort_field(attr, model):\n\n    try:\n        if model._meta.get_field(attr):\n            return attr\n    except FieldDoesNotExist:\n        if isinstance(attr, basestring):\n            val = getattr(model, attr, None)\n            if val and hasattr(val, 'sort_field'):\n                return getattr(model, attr).sort_field\n        return None", "response": "Get s the field to sort on for the given attr."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef labels(self):\n\n        if type(self.object_list) == type([]):\n            model = self.formset.model\n        else:\n            model = self.object_list.model\n\n        for field in self.visible_fields:\n            name = None\n            if self.formset:\n                f = self.formset.empty_form.fields.get(field, None)\n                if f:\n                    name = f.label\n\n            if name is None:\n                name = label_for_field(field, model)\n\n            if name == model._meta.verbose_name:\n                name = self.model_name and self.model_name or \\\n                            model._meta.verbose_name\n\n            stype = None\n            cur_sorted = False\n\n            sortable = False\n\n            if self.order_type:\n                sortable = get_sort_field(field, model)\n                stype = self.ASC\n\n                # change order_type so that next sorting on the same\n                # field will give reversed results\n                if sortable and field == self.sort_field:\n                    cur_sorted = True\n                    if self.order_type == self.ASC:\n                        stype = self.DESC\n                    elif self.order_type == self.DESC:\n                        stype = self.ASC\n                    else:\n                        stype = self.ASC\n\n\n            yield AdminListLabel(name, field, stype, cur_sorted, bool(sortable))", "response": "Yields a list of AdminListLabel objects for the object list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef use_setuptools(\n    version=DEFAULT_VERSION, download_base=DEFAULT_URL, to_dir=os.curdir,\n    download_delay=15\n):\n    \"\"\"Automatically find/download setuptools and make it available on sys.path\n\n    `version` should be a valid setuptools version number that is available\n    as an egg for download under the `download_base` URL (which should end with\n    a '/').  `to_dir` is the directory where setuptools will be downloaded, if\n    it is not already available.  If `download_delay` is specified, it should\n    be the number of seconds that will be paused before initiating a download,\n    should one be required.  If an older version of setuptools is installed,\n    this routine will print a message to ``sys.stderr`` and raise SystemExit in\n    an attempt to abort the calling script.\n    \"\"\"\n    try:\n        import setuptools\n        if setuptools.__version__ == '0.0.1':\n            print >>sys.stderr, (\n            \"You have an obsolete version of setuptools installed.  Please\\n\"\n            \"remove it from your system entirely before rerunning this script.\"\n            )\n            sys.exit(2)\n    except ImportError:\n        egg = download_setuptools(version, download_base, to_dir, download_delay)\n        sys.path.insert(0, egg)\n        import setuptools; setuptools.bootstrap_install_from = egg\n\n    import pkg_resources\n    try:\n        pkg_resources.require(\"setuptools>=\"+version)\n\n    except pkg_resources.VersionConflict, e:\n        # XXX could we install in a subprocess here?\n        print >>sys.stderr, (\n            \"The required version of setuptools (>=%s) is not available, and\\n\"\n            \"can't be installed while this script is running. Please install\\n\"\n            \" a more recent version first.\\n\\n(Currently using %r)\"\n        ) % (version, e.args[0])\n        sys.exit(2)", "response": "Automatically download setuptools and make it available on sys. path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nactivating a user with an activation key.", "response": "def activate(request, activation_key,\n             template_name='accounts/activate_fail.html',\n             success_url=None, extra_context=None):\n    \"\"\"\n    Activate a user with an activation key.\n\n    The key is a SHA1 string. When the SHA1 is found with an\n    :class:`AccountsSignup`, the :class:`User` of that account will be\n    activated.  After a successful activation the view will redirect to\n    ``success_url``.  If the SHA1 is not found, the user will be shown the\n    ``template_name`` template displaying a fail message.\n\n    :param activation_key:\n        String of a SHA1 string of 40 characters long. A SHA1 is always 160bit\n        long, with 4 bits per character this makes it --160/4-- 40 characters\n        long.\n\n    :param template_name:\n        String containing the template name that is used when the\n        ``activation_key`` is invalid and the activation fails. Defaults to\n        ``accounts/activation_fail.html``.\n\n    :param success_url:\n        String containing the URL where the user should be redirected to after\n        a successful activation. Will replace ``%(username)s`` with string\n        formatting if supplied. If ``success_url`` is left empty, will direct\n        to ``accounts_profile_detail`` view.\n\n    :param extra_context:\n        Dictionary containing variables which could be added to the template\n        context. Default to an empty dictionary.\n\n    \"\"\"\n    user = AccountsSignup.objects.activate_user(activation_key)\n    if user:\n        # Sign the user in.\n        auth_user = authenticate(identification=user.email,\n                                 check_password=False)\n        login(request, auth_user)\n\n        if accounts_settings.ACCOUNTS_USE_MESSAGES:\n            messages.success(request,\n                             _('Your account has been activated and you have been signed in.'),\n                             fail_silently=True)\n\n        if success_url:\n            redirect_to = success_url % {'username': user.username}\n        else:\n            redirect_to = reverse('accounts_profile_detail',\n                                    kwargs={'username': user.username})\n        return redirect(redirect_to)\n    else:\n        if not extra_context:\n            extra_context = dict()\n        return ExtraContextTemplateView.as_view(template_name=template_name,\n                                        extra_context=extra_context)(request)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef email_confirm(request, confirmation_key,\n                  template_name='accounts/email_confirm_fail.html',\n                  success_url=None, extra_context=None):\n    \"\"\"\n    Confirms an email address with a confirmation key.\n\n    Confirms a new email address by running :func:`User.objects.confirm_email`\n    method. If the method returns an :class:`User` the user will have his new\n    e-mail address set and redirected to ``success_url``. If no ``User`` is\n    returned the user will be represented with a fail message from\n    ``template_name``.\n\n    :param confirmation_key:\n        String with a SHA1 representing the confirmation key used to verify a\n        new email address.\n\n    :param template_name:\n        String containing the template name which should be rendered when\n        confirmation fails. When confirmation is successful, no template is\n        needed because the user will be redirected to ``success_url``.\n\n    :param success_url:\n        String containing the URL which is redirected to after a successful\n        confirmation.  Supplied argument must be able to be rendered by\n        ``reverse`` function.\n\n    :param extra_context:\n        Dictionary of variables that are passed on to the template supplied by\n        ``template_name``.\n\n    \"\"\"\n    user = AccountsSignup.objects.confirm_email(confirmation_key)\n    if user:\n        if accounts_settings.ACCOUNTS_USE_MESSAGES:\n            messages.success(request,\n                             _('Your email address has been changed.'),\n                             fail_silently=True)\n\n        if success_url:\n            redirect_to = success_url\n        else:\n            redirect_to = reverse('accounts_email_confirm_complete',\n                                    kwargs={'username': user.username})\n        return redirect(redirect_to)\n    else:\n        if not extra_context:\n            extra_context = dict()\n        return ExtraContextTemplateView.as_view(template_name=template_name,\n                                        extra_context=extra_context)(request)", "response": "This function is used to confirm an email address."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndirecting to user template.", "response": "def direct_to_user_template(request, username, template_name,\n                            extra_context=None):\n    \"\"\"\n    Simple wrapper for Django's :func:`direct_to_template` view.\n\n    This view is used when you want to show a template to a specific user. A\n    wrapper for :func:`direct_to_template` where the template also has access\n    to the user that is found with ``username``. For ex. used after signup,\n    activation and confirmation of a new e-mail.\n\n    :param username:\n        String defining the username of the user that made the action.\n\n    :param template_name:\n        String defining the name of the template to use. Defaults to\n        ``accounts/signup_complete.html``.\n\n    **Keyword arguments**\n\n    ``extra_context``\n        A dictionary containing extra variables that should be passed to the\n        rendered template. The ``account`` key is always the ``User``\n        that completed the action.\n\n    **Extra context**\n\n    ``viewed_user``\n        The currently :class:`User` that is viewed.\n\n    \"\"\"\n    user = get_object_or_404(get_user_model(), username__iexact=username)\n\n    if not extra_context:\n        extra_context = dict()\n    extra_context['viewed_user'] = user\n    extra_context['profile'] = user.get_profile()\n    return ExtraContextTemplateView.as_view(template_name=template_name,\n                                        extra_context=extra_context)(request)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsigning out the user and adds a success message ``You have been signed out.`` If next_page is defined you will be redirected to the URI. If not the template in template_name is used. :param next_page: A string which specifies the URI to redirect to. :param template_name: String defining the name of the template to use. Defaults to ``accounts/signout.html``.", "response": "def signout(request, next_page=accounts_settings.ACCOUNTS_REDIRECT_ON_SIGNOUT,\n            template_name='accounts/signout.html', *args, **kwargs):\n    \"\"\"\n    Signs out the user and adds a success message ``You have been signed\n    out.`` If next_page is defined you will be redirected to the URI. If\n    not the template in template_name is used.\n\n    :param next_page:\n        A string which specifies the URI to redirect to.\n\n    :param template_name:\n        String defining the name of the template to use. Defaults to\n        ``accounts/signout.html``.\n\n    \"\"\"\n    if request.user.is_authenticated() and \\\n            accounts_settings.ACCOUNTS_USE_MESSAGES:  # pragma: no cover\n        messages.success(request, _('You have been signed out.'),\n                         fail_silently=True)\n    return Signout(request, next_page, template_name, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchanging the email address of a user.", "response": "def email_change(request, username, email_form=ChangeEmailForm,\n                 template_name='accounts/email_form.html', success_url=None,\n                 extra_context=None):\n    \"\"\"\n    Change email address\n\n    :param username:\n        String of the username which specifies the current account.\n\n    :param email_form:\n        Form that will be used to change the email address. Defaults to\n        :class:`ChangeEmailForm` supplied by accounts.\n\n    :param template_name:\n        String containing the template to be used to display the email form.\n        Defaults to ``accounts/email_form.html``.\n\n    :param success_url:\n        Named URL where the user will get redirected to when successfully\n        changing their email address.  When not supplied will redirect to\n        ``accounts_email_complete`` URL.\n\n    :param extra_context:\n        Dictionary containing extra variables that can be used to render the\n        template. The ``form`` key is always the form supplied by the keyword\n        argument ``form`` and the ``user`` key by the user whose email address\n        is being changed.\n\n    **Context**\n\n    ``form``\n        Form that is used to change the email address supplied by ``form``.\n\n    ``account``\n        Instance of the ``Account`` whose email address is about to be changed.\n\n    **Todo**\n\n    Need to have per-object permissions, which enables users with the correct\n    permissions to alter the email address of others.\n\n    \"\"\"\n    user = get_object_or_404(get_user_model(), username__iexact=username)\n\n    form = email_form(user)\n\n    if request.method == 'POST':\n        form = email_form(user,\n                               request.POST,\n                               request.FILES)\n\n        if form.is_valid():\n            form.save()\n\n            if success_url:\n                redirect_to = success_url\n            else:\n                redirect_to = reverse('accounts_email_change_complete',\n                                        kwargs={'username': user.username})\n            return redirect(redirect_to)\n\n    if not extra_context:\n        extra_context = dict()\n    extra_context['form'] = form\n    extra_context['profile'] = user.get_profile()\n    return ExtraContextTemplateView.as_view(template_name=template_name,\n                                        extra_context=extra_context)(request)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nchange the password of a user.", "response": "def password_change(request, username,\n                    template_name='accounts/password_form.html',\n                    pass_form=PasswordChangeForm, success_url=None,\n                    extra_context=None):\n    \"\"\" Change password of user.\n\n    This view is almost a mirror of the view supplied in\n    :func:`contrib.auth.views.password_change`, with the minor change that in\n    this view we also use the username to change the password. This was needed\n    to keep our URLs logical (and REST) across the entire application. And\n    that in a later stadium administrators can also change the users password\n    through the web application itself.\n\n    :param username:\n        String supplying the username of the user who's password is about to be\n        changed.\n\n    :param template_name:\n        String of the name of the template that is used to display the password\n        change form. Defaults to ``accounts/password_form.html``.\n\n    :param pass_form:\n        Form used to change password. Default is the form supplied by Django\n        itself named ``PasswordChangeForm``.\n\n    :param success_url:\n        Named URL that is passed onto a :func:`reverse` function with\n        ``username`` of the active user. Defaults to the\n        ``accounts_password_complete`` URL.\n\n    :param extra_context:\n        Dictionary of extra variables that are passed on to the template. The\n        ``form`` key is always used by the form supplied by ``pass_form``.\n\n    **Context**\n\n    ``form``\n        Form used to change the password.\n\n    \"\"\"\n    user = get_object_or_404(get_user_model(),\n                             username__iexact=username)\n\n    form = pass_form(user=user)\n\n    if request.method == \"POST\":\n        form = pass_form(user=user, data=request.POST)\n        if form.is_valid():\n            form.save()\n\n            # Send a signal that the password has changed\n            accounts_signals.password_complete.send(sender=None,\n                                                   user=user)\n\n            if success_url:\n                redirect_to = success_url\n            else:\n                redirect_to = reverse('accounts_password_change_complete',\n                                        kwargs={'username': user.username})\n            return redirect(redirect_to)\n\n    if not extra_context:\n        extra_context = dict()\n    extra_context['form'] = form\n    extra_context['profile'] = user.get_profile()\n    return ExtraContextTemplateView.as_view(template_name=template_name,\n                                        extra_context=extra_context)(request)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nedit profile. Edits a profile selected by the supplied username. First checks permissions if the user is allowed to edit this profile, if denied will show a 404. When the profile is successfully edited will redirect to ``success_url``. :param username: Username of the user which profile should be edited. :param edit_profile_form: Form that is used to edit the profile. The :func:`EditProfileForm.save` method of this form will be called when the form :func:`EditProfileForm.is_valid`. Defaults to :class:`EditProfileForm` from accounts. :param template_name: String of the template that is used to render this view. Defaults to ``accounts/edit_profile_form.html``. :param success_url: Named URL which will be passed on to a django ``reverse`` function after the form is successfully saved. Defaults to the ``accounts_detail`` url. :param extra_context: Dictionary containing variables that are passed on to the ``template_name`` template. ``form`` key will always be the form used to edit the profile, and the ``profile`` key is always the edited profile. **Context** ``form`` Form that is used to alter the profile. ``profile`` Instance of the ``Profile`` that is edited.", "response": "def profile_edit(request, username, edit_profile_form=EditProfileForm,\n                 template_name='accounts/profile_form.html', success_url=None,\n                 extra_context=None, **kwargs):\n    \"\"\"\n    Edit profile.\n\n    Edits a profile selected by the supplied username. First checks\n    permissions if the user is allowed to edit this profile, if denied will\n    show a 404. When the profile is successfully edited will redirect to\n    ``success_url``.\n\n    :param username:\n        Username of the user which profile should be edited.\n\n    :param edit_profile_form:\n\n        Form that is used to edit the profile. The :func:`EditProfileForm.save`\n        method of this form will be called when the form\n        :func:`EditProfileForm.is_valid`.  Defaults to :class:`EditProfileForm`\n        from accounts.\n\n    :param template_name:\n        String of the template that is used to render this view. Defaults to\n        ``accounts/edit_profile_form.html``.\n\n    :param success_url:\n        Named URL which will be passed on to a django ``reverse`` function\n        after the form is successfully saved. Defaults to the\n        ``accounts_detail`` url.\n\n    :param extra_context:\n        Dictionary containing variables that are passed on to the\n        ``template_name`` template.  ``form`` key will always be the form used\n        to edit the profile, and the ``profile`` key is always the edited\n        profile.\n\n    **Context**\n\n    ``form``\n        Form that is used to alter the profile.\n\n    ``profile``\n        Instance of the ``Profile`` that is edited.\n\n    \"\"\"\n    user = get_object_or_404(get_user_model(),\n                             username__iexact=username)\n\n    profile = user.get_profile()\n\n    user_initial = {'first_name': user.first_name,\n                    'last_name': user.last_name}\n\n    form = edit_profile_form(instance=profile, initial=user_initial)\n\n    if request.method == 'POST':\n        form = edit_profile_form(request.POST, request.FILES, instance=profile,\n                                 initial=user_initial)\n\n        if form.is_valid():\n            profile = form.save()\n\n            if accounts_settings.ACCOUNTS_USE_MESSAGES:\n                messages.success(request, _('Your profile has been updated.'),\n                                 fail_silently=True)\n\n            if success_url:\n                redirect_to = success_url\n            else:\n                redirect_to = reverse('accounts_profile_detail',\n                                      kwargs={'username': username})\n            return redirect(redirect_to)\n\n    if not extra_context:\n        extra_context = dict()\n    extra_context['form'] = form\n    extra_context['profile'] = profile\n    return ExtraContextTemplateView.as_view(template_name=template_name,\n                                        extra_context=extra_context)(request)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetail view of an user. :param username: String of the username of which the profile should be viewed. :param template_name: String representing the template name that should be used to display the profile. :param extra_context: Dictionary of variables which should be supplied to the template. The ``profile`` key is always the current profile. **Context** ``profile`` Instance of the currently viewed ``Profile``.", "response": "def profile_detail(\n    request, username,\n    template_name=accounts_settings.ACCOUNTS_PROFILE_DETAIL_TEMPLATE,\n    extra_context=None, **kwargs):\n    \"\"\"\n    Detailed view of an user.\n\n    :param username:\n        String of the username of which the profile should be viewed.\n\n    :param template_name:\n        String representing the template name that should be used to display\n        the profile.\n\n    :param extra_context:\n        Dictionary of variables which should be supplied to the template. The\n        ``profile`` key is always the current profile.\n\n    **Context**\n\n    ``profile``\n        Instance of the currently viewed ``Profile``.\n\n    \"\"\"\n    user = get_object_or_404(get_user_model(),\n                             username__iexact=username)\n    profile_model = get_profile_model()\n    try:\n        profile = user.get_profile()\n    except profile_model.DoesNotExist:\n        profile = profile_model(user=user)\n        profile.save()\n    if not profile.can_view_profile(request.user):\n        return HttpResponseForbidden(_(\"You don't have permission to view this profile.\"))\n    if not extra_context:\n        extra_context = dict()\n    extra_context['profile'] = user.get_profile()\n    return ExtraContextTemplateView.as_view(template_name=template_name,\n                                       extra_context=extra_context)(request)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_properties(parent_index_name, parent_name, nested_path, esProperties):\n    columns = FlatList()\n    for name, property in esProperties.items():\n        index_name = parent_index_name\n        column_name = concat_field(parent_name, name)\n        jx_name = column_name\n\n        if property.type == \"nested\" and property.properties:\n            # NESTED TYPE IS A NEW TYPE DEFINITION\n            # MARKUP CHILD COLUMNS WITH THE EXTRA DEPTH\n            self_columns = parse_properties(index_name, column_name, [column_name] + nested_path, property.properties)\n            columns.extend(self_columns)\n            columns.append(Column(\n                name=jx_name,\n                es_index=index_name,\n                es_column=column_name,\n                es_type=\"nested\",\n                jx_type=NESTED,\n                last_updated=Date.now(),\n                nested_path=nested_path\n            ))\n\n            continue\n\n        if property.properties:\n            child_columns = parse_properties(index_name, column_name, nested_path, property.properties)\n            columns.extend(child_columns)\n            columns.append(Column(\n                name=jx_name,\n                es_index=index_name,\n                es_column=column_name,\n                es_type=\"source\" if property.enabled == False else \"object\",\n                jx_type=OBJECT,\n                last_updated=Date.now(),\n                nested_path=nested_path\n            ))\n\n        if property.dynamic:\n            continue\n        if not property.type:\n            continue\n\n        cardinality = 0 if not (property.store or property.enabled) and name != '_id' else None\n\n        if property.fields:\n            child_columns = parse_properties(index_name, column_name, nested_path, property.fields)\n            if cardinality is None:\n                for cc in child_columns:\n                    cc.cardinality = None\n            columns.extend(child_columns)\n\n        if property.type in es_type_to_json_type.keys():\n            columns.append(Column(\n                name=jx_name,\n                es_index=index_name,\n                es_column=column_name,\n                es_type=property.type,\n                jx_type=es_type_to_json_type[property.type],\n                cardinality=cardinality,\n                last_updated=Date.now(),\n                nested_path=nested_path\n            ))\n            if property.index_name and name != property.index_name:\n                columns.append(Column(\n                    name=jx_name,\n                    es_index=index_name,\n                    es_column=column_name,\n                    es_type=property.type,\n                    jx_type=es_type_to_json_type[property.type],\n                    cardinality=0 if property.store else None,\n                    last_updated=Date.now(),\n                    nested_path=nested_path\n                ))\n        elif property.enabled == None or property.enabled == False:\n            columns.append(Column(\n                name=jx_name,\n                es_index=index_name,\n                es_column=column_name,\n                es_type=\"source\" if property.enabled == False else \"object\",\n                jx_type=OBJECT,\n                cardinality=0 if property.store else None,\n                last_updated=Date.now(),\n                nested_path=nested_path\n            ))\n        else:\n            Log.warning(\"unknown type {{type}} for property {{path}}\", type=property.type, path=parent_name)\n\n    return columns", "response": "Parses the properties of the object and returns a list of Column objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the best type name and mapping from a mapping.", "response": "def _get_best_type_from_mapping(mapping):\n    \"\"\"\n    THERE ARE MULTIPLE TYPES IN AN INDEX, PICK THE BEST\n    :param mapping: THE ES MAPPING DOCUMENT\n    :return: (type_name, mapping) PAIR (mapping.properties WILL HAVE PROPERTIES\n    \"\"\"\n    best_type_name = None\n    best_mapping = None\n    for k, m in mapping.items():\n        if k == \"_default_\":\n            continue\n        if best_type_name is None or len(m.properties) > len(best_mapping.properties):\n            best_type_name = k\n            best_mapping = m\n    if best_type_name == None:\n        return \"_default_\", mapping[\"_default_\"]\n    return best_type_name, best_mapping"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _merge_mapping(a, b):\n    for name, b_details in b.items():\n        a_details = a[literal_field(name)]\n        if a_details.properties and not a_details.type:\n            a_details.type = \"object\"\n        if b_details.properties and not b_details.type:\n            b_details.type = \"object\"\n\n        if a_details:\n            a_details.type = _merge_type[a_details.type][b_details.type]\n\n            if b_details.type in ES_STRUCT:\n                _merge_mapping(a_details.properties, b_details.properties)\n        else:\n            a[literal_field(name)] = deepcopy(b_details)\n\n    return a", "response": "Merge two mappings a and b."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting SCHEMA FROM 5. x to 1. x", "response": "def retro_schema(schema):\n    \"\"\"\n    CONVERT SCHEMA FROM 5.x to 1.x\n    :param schema:\n    :return:\n    \"\"\"\n    output = wrap({\n        \"mappings\":{\n            typename: {\n                \"dynamic_templates\": [\n                    retro_dynamic_template(*(t.items()[0]))\n                    for t in details.dynamic_templates\n                ],\n                \"properties\": retro_properties(details.properties)\n            }\n            for typename, details in schema.mappings.items()\n        },\n        \"settings\": schema.settings\n    })\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the differences between two elasticsearch properties A and B.", "response": "def diff_schema(A, B):\n    \"\"\"\n    RETURN PROPERTIES IN A, BUT NOT IN B\n    :param A: elasticsearch properties\n    :param B: elasticsearch properties\n    :return: (name, properties) PAIRS WHERE name IS DOT-DELIMITED PATH\n    \"\"\"\n    output =[]\n    def _diff_schema(path, A, B):\n        for k, av in A.items():\n            if k == \"_id\" and path == \".\":\n                continue  # DO NOT ADD _id TO ANY SCHEMA DIFF\n            bv = B[k]\n            if bv == None:\n                output.append((concat_field(path, k), av))\n            elif av.type == bv.type:\n                pass  # OK\n            elif (av.type == None and bv.type == 'object') or (av.type == 'object' and bv.type == None):\n                pass  # OK\n            else:\n                Log.warning(\"inconsistent types: {{typeA}} vs {{typeB}}\", typeA=av.type, typeB=bv.type)\n            _diff_schema(concat_field(path, k), av.properties, bv.properties)\n\n    # what to do with conflicts?\n    _diff_schema(\".\", A, B)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_all_but_self(self):\n        prefix = self.settings.alias\n        name = self.settings.index\n\n        if prefix == name:\n            Log.note(\"{{index_name}} will not be deleted\",  index_name= prefix)\n        for a in self.cluster.get_aliases():\n            # MATCH <prefix>YYMMDD_HHMMSS FORMAT\n            if re.match(re.escape(prefix) + \"\\\\d{8}_\\\\d{6}\", a.index) and a.index != name:\n                self.cluster.delete_index(a.index)", "response": "Delete ALL INDEXES WITH GIVEN PREFIX EXCEPT name\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if the given index is a proto.", "response": "def is_proto(self, index):\n        \"\"\"\n        RETURN True IF THIS INDEX HAS NOT BEEN ASSIGNED ITS ALIAS\n        \"\"\"\n        for a in self.cluster.get_aliases():\n            if a.index == index and a.alias:\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextend the index with the given records.", "response": "def extend(self, records):\n        \"\"\"\n        records - MUST HAVE FORM OF\n            [{\"value\":value}, ... {\"value\":value}] OR\n            [{\"json\":json}, ... {\"json\":json}]\n            OPTIONAL \"id\" PROPERTY IS ALSO ACCEPTED\n        \"\"\"\n        if self.settings.read_only:\n            Log.error(\"Index opened in read only mode, no changes allowed\")\n        lines = []\n        try:\n            for r in records:\n                if '_id' in r or 'value' not in r:  # I MAKE THIS MISTAKE SO OFTEN, I NEED A CHECK\n                    Log.error('Expecting {\"id\":id, \"value\":document} form.  Not expecting _id')\n                id, version, json_bytes = self.encode(r)\n                if '\"_id\":' in json_bytes:\n                    id, version, json_bytes = self.encode(r)\n\n                if version:\n                    lines.append(value2json({\"index\": {\"_id\": id, \"version\": int(version), \"version_type\": \"external_gte\"}}))\n                else:\n                    lines.append('{\"index\":{\"_id\": ' + value2json(id) + '}}')\n                lines.append(json_bytes)\n\n            del records\n\n            if not lines:\n                return\n\n            with Timer(\"Add {{num}} documents to {{index}}\", {\"num\": int(len(lines) / 2), \"index\": self.settings.index}, silent=not self.debug):\n                try:\n                    data_string = \"\\n\".join(l for l in lines) + \"\\n\"\n                except Exception as e:\n                    raise Log.error(\"can not make request body from\\n{{lines|indent}}\", lines=lines, cause=e)\n\n                wait_for_active_shards = coalesce(\n                    self.settings.wait_for_active_shards,\n                    {\"one\": 1, None: None}[self.settings.consistency]\n                )\n\n                response = self.cluster.post(\n                    self.path + \"/_bulk\",\n                    data=data_string,\n                    headers={\"Content-Type\": \"application/x-ndjson\"},\n                    timeout=self.settings.timeout,\n                    retry=self.settings.retry,\n                    params={\"wait_for_active_shards\": wait_for_active_shards}\n                )\n                items = response[\"items\"]\n\n                fails = []\n                if self.cluster.version.startswith(\"0.90.\"):\n                    for i, item in enumerate(items):\n                        if not item.index.ok:\n                            fails.append(i)\n                elif self.cluster.version.startswith((\"1.4.\", \"1.5.\", \"1.6.\", \"1.7.\", \"5.\", \"6.\")):\n                    for i, item in enumerate(items):\n                        if item.index.status == 409:  # 409 ARE VERSION CONFLICTS\n                            if \"version conflict\" not in item.index.error.reason:\n                                fails.append(i)  # IF NOT A VERSION CONFLICT, REPORT AS FAILURE\n                        elif item.index.status not in [200, 201]:\n                            fails.append(i)\n                else:\n                    Log.error(\"version not supported {{version}}\", version=self.cluster.version)\n\n                if fails:\n                    if len(fails) <= 3:\n                        cause = [\n                            Except(\n                                template=\"{{status}} {{error}} (and {{some}} others) while loading line id={{id}} into index {{index|quote}} (typed={{typed}}):\\n{{line}}\",\n                                params={\n                                    \"status\":items[i].index.status,\n                                    \"error\":items[i].index.error,\n                                    \"some\":len(fails) - 1,\n                                    \"line\":strings.limit(lines[i * 2 + 1], 500 if not self.debug else 100000),\n                                    \"index\":self.settings.index,\n                                    \"typed\":self.settings.typed,\n                                    \"id\":items[i].index._id\n                                }\n                            )\n                            for i in fails\n                        ]\n                    else:\n                        i=fails[0]\n                        cause = Except(\n                            template=\"{{status}} {{error}} (and {{some}} others) while loading line id={{id}} into index {{index|quote}} (typed={{typed}}):\\n{{line}}\",\n                            params={\n                                \"status\":items[i].index.status,\n                                \"error\":items[i].index.error,\n                                \"some\":len(fails) - 1,\n                                \"line\":strings.limit(lines[i * 2 + 1], 500 if not self.debug else 100000),\n                                \"index\":self.settings.index,\n                                \"typed\":self.settings.typed,\n                                \"id\":items[i].index._id\n                            }\n                        )\n                    Log.error(\"Problems with insert\", cause=cause)\n            pass\n        except Exception as e:\n            e = Except.wrap(e)\n            if e.message.startswith(\"sequence item \"):\n                Log.error(\"problem with {{data}}\", data=text_type(repr(lines[int(e.message[14:16].strip())])), cause=e)\n            Log.error(\"problem sending to ES\", cause=e)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_refresh_interval(self, seconds, **kwargs):\n        if seconds <= 0:\n            interval = -1\n        else:\n            interval = text_type(seconds) + \"s\"\n\n        if self.cluster.version.startswith(\"0.90.\"):\n            response = self.cluster.put(\n                \"/\" + self.settings.index + \"/_settings\",\n                data='{\"index\":{\"refresh_interval\":' + value2json(interval) + '}}',\n                **kwargs\n            )\n\n            result = json2value(utf82unicode(response.all_content))\n            if not result.ok:\n                Log.error(\"Can not set refresh interval ({{error}})\", {\n                    \"error\": utf82unicode(response.all_content)\n                })\n        elif self.cluster.version.startswith((\"1.4.\", \"1.5.\", \"1.6.\", \"1.7.\", \"5.\", \"6.\")):\n            result = self.cluster.put(\n                \"/\" + self.settings.index + \"/_settings\",\n                data={\"index\": {\"refresh_interval\": interval}},\n                **kwargs\n            )\n\n            if not result.acknowledged:\n                Log.error(\"Can not set refresh interval ({{error}})\", {\n                    \"error\": result\n                })\n        else:\n            Log.error(\"Do not know how to handle ES version {{version}}\", version=self.cluster.version)", "response": "Set the refresh interval for the current node."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an index object for the given index name.", "response": "def get_index(self, index, type, alias=None, typed=None, read_only=True, kwargs=None):\n        \"\"\"\n        TESTS THAT THE INDEX EXISTS BEFORE RETURNING A HANDLE\n        \"\"\"\n        if kwargs.tjson != None:\n            Log.error(\"used `typed` parameter, not `tjson`\")\n        if read_only:\n            # GET EXACT MATCH, OR ALIAS\n            aliases = wrap(self.get_aliases())\n            if index in aliases.index:\n                pass\n            elif index in aliases.alias:\n                match = [a for a in aliases if a.alias == index][0]\n                kwargs.alias = match.alias\n                kwargs.index = match.index\n            else:\n                Log.error(\"Can not find index {{index_name}}\", index_name=kwargs.index)\n            return Index(kwargs=kwargs, cluster=self)\n        else:\n            # GET BEST MATCH, INCLUDING PROTOTYPE\n            best = self.get_best_matching_index(index, alias)\n            if not best:\n                Log.error(\"Can not find index {{index_name}}\", index_name=kwargs.index)\n\n            if best.alias != None:\n                kwargs.alias = best.alias\n                kwargs.index = best.index\n            elif kwargs.alias == None:\n                kwargs.alias = kwargs.index\n                kwargs.index = best.index\n\n            return Index(kwargs=kwargs, cluster=self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an index for the given alias", "response": "def get_alias(self, alias):\n        \"\"\"\n        RETURN REFERENCE TO ALIAS (MANY INDEXES)\n        USER MUST BE SURE NOT TO SEND UPDATES\n        \"\"\"\n        aliases = self.get_aliases()\n        if alias in aliases.alias:\n            settings = self.settings.copy()\n            settings.alias = alias\n            settings.index = alias\n            return Index(read_only=True, kwargs=settings, cluster=self)\n        Log.error(\"Can not find any index with alias {{alias_name}}\",  alias_name= alias)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_canonical_index(self, alias):\n        output = jx.sort(set(\n            i\n            for ai in self.get_aliases()\n            for a, i in [(ai.alias, ai.index)]\n            if a == alias or i == alias or (re.match(re.escape(alias) + \"\\\\d{8}_\\\\d{6}\", i) and i != alias)\n        ))\n\n        if len(output) > 1:\n            Log.error(\"only one index with given alias==\\\"{{alias}}\\\" expected\", alias=alias)\n\n        if not output:\n            return Null\n\n        return output.last()", "response": "Returns the canonical index of the entry with the given alias."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_prototype(self, alias):\n        output = sort([\n            a.index\n            for a in self.get_aliases()\n            if re.match(re.escape(alias) + \"\\\\d{8}_\\\\d{6}\", a.index) and not a.alias\n        ])\n        return output", "response": "Returns a list of prototype entries for this entry."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_all_but(self, prefix, name):\n        if prefix == name:\n            Log.note(\"{{index_name}} will not be deleted\", {\"index_name\": prefix})\n        for a in self.get_aliases():\n            # MATCH <prefix>YYMMDD_HHMMSS FORMAT\n            if re.match(re.escape(prefix) + \"\\\\d{8}_\\\\d{6}\", a.index) and a.index != name:\n                self.delete_index(a.index)", "response": "Delete all entries with the given prefix but with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_aliases(self):\n        for index, desc in self.get_metadata().indices.items():\n            if not desc[\"aliases\"]:\n                yield wrap({\"index\": index})\n            elif desc['aliases'][0] == index:\n                Log.error(\"should not happen\")\n            else:\n                for a in desc[\"aliases\"]:\n                    yield wrap({\"index\": index, \"alias\": a})", "response": "Yields all aliases in the current instance"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_homogeneisation_caracteristiques_sociales(temporary_store = None, year = None):\n\n    assert temporary_store is not None\n    assert year is not None\n    # Load data\n    bdf_survey_collection = SurveyCollection.load(\n        collection = 'budget_des_familles', config_files_directory = config_files_directory)\n    survey = bdf_survey_collection.get_survey('budget_des_familles_{}'.format(year))\n    # ******************************************************************************************************************\n    # * Etape n\u00b0 0-3 : HOMOGENEISATION DES CARACTERISTIQUES SOCIALES DES MENAGES\n    # ******************************************************************************************************************\n    # ******************************************************************************************************************\n\n    if year == 1995:\n        kept_variables = ['exdep', 'exrev', 'mena', 'v', 'ponderrd', 'nbpers', 'nbenf', 'typmen1', 'cohabpr', 'sexepr',\n            'agepr', 'agecj', 'matripr', 'occuppr', 'occupcj', 'nbact', 'sitlog', 'stalog', 'mena', 'nm14a', 'typmen1']\n        menage = survey.get_values(\n            table = \"socioscm\",\n            variables = kept_variables,\n            )\n        # cette \u00e9tape permet de ne garder que les donn\u00e9es dont on est s\u00fbr de la qualit\u00e9 et de la v\u00e9racit\u00e9\n        # exdep = 1 si les donn\u00e9es sont bien remplies pour les d\u00e9penses du m\u00e9nage\n        # exrev = 1 si les donn\u00e9es sont bien remplies pour les revenus du m\u00e9nage\n        menage = menage[(menage.exdep == 1) & (menage.exrev == 1)]\n        menage.rename(\n            columns = {\n                'v': 'vag',\n                'mena': 'ident_men',\n                'ponderrd': 'pondmen',\n                'nbpers': 'npers',\n                'nm14a': 'nenfants',\n                'nbenf': 'nenfhors',\n                'nbact': 'nactifs',\n                'cohabpr': 'couplepr',\n                'matripr': 'etamatri',\n                'typmen1': 'typmen'\n                },\n            inplace = True,\n            )\n        # la variable vag est utilis\u00e9e dans les mod\u00e8les QAIDS et AIDS comme variable temporelle afin d'attibuer\n        # le bon prix mensuel\n        menage.agecj = menage.agecj.fillna(0)\n        menage.nenfhors = menage.nenfhors.fillna(0)\n        menage.vag = menage.vag.astype('int')\n\n        menage['nadultes'] = menage['npers'] - menage['nenfants']\n        menage['ocde10'] = 1 + 0.5 * numpy.maximum(0, menage['nadultes'] - 1) + 0.3 * menage['nenfants']\n\n        # harmonisation des types de m\u00e9nage sur la nomenclature 2010\n        menage['typmen_'] = menage['typmen']\n        menage.typmen[menage.typmen_ == 1] = 1\n        menage.typmen[menage.typmen_ == 2] = 3\n        menage.typmen[menage.typmen_ == 3] = 4\n        menage.typmen[menage.typmen_ == 4] = 4\n        menage.typmen[menage.typmen_ == 5] = 4\n        menage.typmen[menage.typmen_ == 6] = 2\n        menage.typmen[menage.typmen_ == 7] = 5\n        del menage['typmen_']\n\n        var_to_ints = ['couplepr', 'etamatri']\n        for var_to_int in var_to_ints:\n            menage[var_to_int] = menage[var_to_int].astype(int)\n\n        #  Methode :\n        #  1. on nettoite les variables (i.e. changement de nom de format)\n        #  2. Reformatage des variables (r\u00e9attribution des cat\u00e9gories pour quelles soient identiques\n        #     pour les diff\u00e9rentes ann\u00e9es)\n\n        menage[\"situacj\"] = 0\n        menage.situacj[menage.occupcj == 1] = 1\n        menage.situacj[menage.occupcj == 3] = 3\n        menage.situacj[menage.occupcj == 2] = 4\n        menage.situacj[menage.occupcj == 5] = 5\n        menage.situacj[menage.occupcj == 6] = 5\n        menage.situacj[menage.occupcj == 7] = 6\n        menage.situacj[menage.occupcj == 8] = 7\n        menage.situacj[menage.occupcj == 4] = 8\n\n        menage[\"situapr\"] = 0\n        menage.situapr[menage.occuppr == 1] = 1\n        menage.situapr[menage.occuppr == 3] = 3\n        menage.situapr[menage.occuppr == 2] = 4\n        menage.situapr[menage.occuppr == 5] = 5\n        menage.situapr[menage.occuppr == 6] = 5\n        menage.situapr[menage.occuppr == 7] = 6\n        menage.situapr[menage.occuppr == 8] = 7\n        menage.situapr[menage.occuppr == 4] = 8\n\n        menage[\"typlog\"] = 0\n        menage.typlog[menage.sitlog == 1] = 1\n        menage.typlog[menage.sitlog != 1] = 2\n\n        menage['stalog'] = menage['stalog'].astype(int)\n\n        individus = survey.get_values(\n            table = \"individu\",\n            )\n        variables = ['mena', 'v']\n        individus.rename(\n            columns = {'mena': 'identmen'},\n            inplace = True,\n            )\n        menage.set_index('ident_men', inplace = True)\n\n    if year == 2000:\n        menage = survey.get_values(\n            table = \"menage\",\n            variables = [\n                'ident', 'pondmen', 'nbact', 'nbenf1', 'nbpers', 'ocde10', 'sitlog', 'stalog', 'strate',\n                'typmen1', 'zeat', 'stalog', 'vag', 'sexepr', 'sexecj', 'agecj', 'napr', 'nacj', 'cs2pr',\n                'cs2cj', 'diegpr', 'dieppr', 'diespr', 'diegcj', 'diepcj', 'diescj', 'hod_nb', 'cohabpr',\n                'occupapr', 'occupacj', 'occupbpr', 'occupbcj', 'occupcpr', 'occupccj', 'typmen1'\n                ]\n            )\n        menage.rename(\n            columns = {\n                'cohabpr': 'couplepr',\n                'hod_nb': 'nenfhors',\n                'ident': 'ident_men',\n                'nbact': 'nactifs',\n                'nbenf1': 'nenfants',\n                'nbpers': 'npers',\n                'rev81': 'poste_coicop_421',\n                'typmen1': 'typmen'\n                },\n            inplace = True,\n            )\n        menage.ocde10 = menage.ocde10 / 10\n        # on met un num\u00e9ro \u00e0 chaque vague pour pouvoir faire un meilleur suivi des \u00e9volutions temporelles\n        # pour le mod\u00e8le de demande\n        menage.agecj = menage.agecj.fillna(0)\n\n        assert menage.notnull().all().all(), 'The following variables contains NaN values: {}'.format(\n            list(menage.isnull().any()[menage.isnull().any()].index))\n\n        menage['vag_'] = menage['vag']\n        menage.vag.loc[menage.vag_ == 1] = 9\n        menage.vag.loc[menage.vag_ == 2] = 10\n        menage.vag.loc[menage.vag_ == 3] = 11\n        menage.vag.loc[menage.vag_ == 4] = 12\n        menage.vag.loc[menage.vag_ == 5] = 13\n        menage.vag.loc[menage.vag_ == 6] = 14\n        menage.vag.loc[menage.vag_ == 7] = 15\n        menage.vag.loc[menage.vag_ == 8] = 16\n        del menage['vag_']\n        # harmonisation des types de m\u00e9nage sur la nomenclature 2010\n        menage['typmen_'] = menage['typmen']\n        menage.typmen.loc[menage.typmen_ == 1] = 1\n        menage.typmen.loc[menage.typmen_ == 2] = 3\n        menage.typmen.loc[menage.typmen_ == 3] = 4\n        menage.typmen.loc[menage.typmen_ == 4] = 4\n        menage.typmen.loc[menage.typmen_ == 5] = 4\n        menage.typmen.loc[menage.typmen_ == 6] = 2\n        menage.typmen.loc[menage.typmen_ == 7] = 5\n        del menage['typmen_']\n\n        menage.couplepr = menage.couplepr.astype('int')\n        menage[\"nadultes\"] = menage['npers'] - menage['nenfants']\n\n        menage.typmen = menage.typmen.astype('int')\n\n        # occupa : 1 si la personne travaille, 2 sinon. occupb : 1 si elle travaille effectivement, 2 si cong\u00e9 de\n        # longue dur\u00e9e (n\u00e9glig\u00e9 ici). occupc : de 2 \u00e0 8 selon le statut si ne travaille pas (\u00e9tudiant, retrait\u00e9, etc.)\n        menage[\"situacj\"] = 0\n        menage.situacj.loc[menage.occupacj == 1] = 1\n        menage.situacj.loc[menage.occupccj == 3] = 3\n        menage.situacj.loc[menage.occupccj == 2] = 4\n        menage.situacj.loc[menage.occupccj == 5] = 5\n        menage.situacj.loc[menage.occupccj == 6] = 5\n        menage.situacj.loc[menage.occupccj == 7] = 6\n        menage.situacj.loc[menage.occupccj == 8] = 7\n        menage.situacj.loc[menage.occupccj == 4] = 8\n\n        menage[\"situapr\"] = 0\n        menage.situapr.loc[menage.occupapr == 1] = 1\n        menage.situapr.loc[menage.occupcpr == 3] = 3\n        menage.situapr.loc[menage.occupcpr == 2] = 4\n        menage.situapr.loc[menage.occupcpr == 5] = 5\n        menage.situapr.loc[menage.occupcpr == 6] = 5\n        menage.situapr.loc[menage.occupcpr == 7] = 6\n        menage.situapr.loc[menage.occupcpr == 8] = 7\n        menage.situapr.loc[menage.occupcpr == 4] = 8\n\n        menage[\"natiocj\"] = 0\n        menage[\"natiopr\"] = 0\n        menage.natiocj.loc[menage.nacj == 1] = 1\n        menage.natiocj.loc[menage.nacj == 2] = 1\n        menage.natiocj.loc[menage.nacj == 3] = 2\n        menage.natiopr.loc[menage.napr == 1] = 1\n        menage.natiopr.loc[menage.napr == 2] = 1\n        menage.natiopr.loc[menage.napr == 3] = 2\n\n        menage[\"typlog\"] = 0\n        menage.typlog.loc[menage.sitlog == 1] = 1\n        menage.typlog.loc[menage.sitlog != 1] = 2\n\n        # Homog\u00e9n\u00e9isation des dipl\u00f4mes, choix d'\u00e9quivalence entre les dipl\u00f4mes\n        menage[\"dip14pr\"] = 999999\n        menage.dip14pr.loc[menage.diegpr == 0] = 71\n        menage.dip14pr.loc[menage.diegpr == 2] = 70\n        menage.dip14pr.loc[menage.diegpr == 15] = 60\n        menage.dip14pr.loc[menage.diegpr == 18] = 60\n        menage.dip14pr.loc[menage.diegpr == 16] = 41\n        menage.dip14pr.loc[menage.diegpr == 17] = 41\n        menage.dip14pr.loc[menage.diegpr == 19] = 41\n\n        menage.dip14pr.loc[menage.dieppr == 23] = 50\n        menage.dip14pr.loc[menage.dieppr == 25] = 50\n        menage.dip14pr.loc[menage.dieppr == 27] = 50\n        menage.dip14pr.loc[menage.dieppr == 29] = 50\n        menage.dip14pr.loc[menage.dieppr == 34] = 43\n        menage.dip14pr.loc[menage.dieppr == 32] = 42\n        menage.dip14pr.loc[menage.dieppr == 36] = 42\n\n        menage.dip14pr.loc[menage.diespr == 41] = 30\n        menage.dip14pr.loc[menage.diespr == 42] = 31\n        menage.dip14pr.loc[menage.diespr == 43] = 31\n        menage.dip14pr.loc[menage.diespr == 44] = 33\n        menage.dip14pr.loc[menage.diespr == 46] = 20\n        menage.dip14pr.loc[menage.diespr == 48] = 12\n        menage.dip14pr.loc[menage.diespr == 47] = 10\n\n        menage.set_index('ident_men', inplace = True)\n\n        # Recodage des cat\u00e9gories zeat\n        menage.zeat.loc[menage.zeat == 7] = 6\n        menage.zeat.loc[menage.zeat == 8] = 7\n        menage.zeat.loc[menage.zeat == 9] = 8\n\n        assert menage.zeat.isin(range(1, 9)).all()\n\n        individus = survey.get_values(\n            table = \"individus\",\n            variables = ['ident', 'matri', 'lien', 'anais']\n            )\n\n        individus = individus.loc[individus.lien == 1].copy()\n        individus.rename(\n            columns = {'ident': 'ident_men', 'matri': 'etamatri'},\n            inplace = True,\n            )\n        variables_to_destring = ['anais']\n        for variable_to_destring in variables_to_destring:\n            individus[variable_to_destring] = individus[variable_to_destring].astype('int').copy()\n        individus['agepr'] = year - individus.anais\n        individus.set_index('ident_men', inplace = True)\n\n        assert menage.notnull().all().all(), 'The following variables contains NaN values: {}'.format(\n            list(menage.isnull().any()[menage.isnull().any()].index))\n\n        menage = menage.merge(individus, left_index = True, right_index = True)\n\n    if year == 2005:\n        menage = survey.get_values(table = \"menage\")\n        # donn\u00e9es socio-d\u00e9mographiques\n        socio_demo_variables = ['agpr', 'agcj', 'couplepr', 'decuc', 'ident_men', 'nactifs', 'nenfants', 'nenfhors',\n            'npers', 'ocde10', 'pondmen', 'sexecj', 'sexepr', 'typmen5', 'vag', 'zeat', 'cs24pr']\n        socio_demo_variables += [column for column in menage.columns if column.startswith('dip14')]\n        socio_demo_variables += [column for column in menage.columns if column.startswith('natio7')]\n        # activit\u00e9 professionnelle\n        activite_prof_variables = ['situacj', 'situapr']\n        activite_prof_variables += [column for column in menage.columns if column.startswith('cs42')]\n        # logement\n        logement_variables = ['htl', 'strate']\n        menage = menage[socio_demo_variables + activite_prof_variables + logement_variables]\n        menage.rename(\n            columns = {\n                # \"agpr\": \"agepr\",\n                \"agcj\": \"agecj\",\n                \"typmen5\": \"typmen\",\n                \"cs24pr\": \"cs_pr\"\n                },\n            inplace = True,\n            )\n        del menage['agpr']\n        menage['nadultes'] = menage.npers - menage.nenfants\n        for person in ['pr', 'cj']:\n            menage['natio' + person] = (menage['natio7' + person] > 2)  # TODO: changer de convention ?\n            del menage['natio7' + person]\n\n        menage.agecj = menage.agecj.fillna(0)\n        menage.nenfhors = menage.nenfhors.fillna(0)\n        var_to_ints = ['ocde10', 'decuc', 'nactifs', 'nenfants', 'npers', 'pondmen', 'nadultes']\n        assert menage.notnull().all().all(), 'The following variables contains NaN values: {}'.format(\n            list(menage.isnull().any()[menage.isnull().any()].index))\n\n        menage.couplepr = menage.couplepr > 2  # TODO: changer de convention ?\n        menage.ocde10 = menage.ocde10 / 10\n        menage.set_index('ident_men', inplace = True)\n        # on met un num\u00e9ro \u00e0 chaque vague pour pouvoir faire un meilleur suivi des \u00e9volutions temporelles\n        # pour le mod\u00e8le de demande\n        menage['vag_'] = menage['vag']\n        menage.vag.loc[menage.vag_ == 1] = 17\n        menage.vag.loc[menage.vag_ == 2] = 18\n        menage.vag.loc[menage.vag_ == 3] = 19\n        menage.vag.loc[menage.vag_ == 4] = 20\n        menage.vag.loc[menage.vag_ == 5] = 21\n        menage.vag.loc[menage.vag_ == 6] = 22\n        del menage['vag_']\n\n        # Recodage des cat\u00e9gories zeat\n        menage.zeat.loc[menage.zeat == 7] = 6\n        menage.zeat.loc[menage.zeat == 8] = 7\n        menage.zeat.loc[menage.zeat == 9] = 8\n\n        assert menage.zeat.isin(range(1, 9)).all()\n\n        stalog = survey.get_values(table = \"depmen\", variables = ['ident_men', 'stalog'])\n        stalog['stalog'] = stalog.stalog.astype('int').copy()\n        stalog['new_stalog'] = 0\n        stalog.loc[stalog.stalog == 2, 'new_stalog'] = 1\n        stalog.loc[stalog.stalog == 1, 'new_stalog'] = 2\n        stalog.loc[stalog.stalog == 4, 'new_stalog'] = 3\n        stalog.loc[stalog.stalog == 5, 'new_stalog'] = 4\n        stalog.loc[stalog.stalog.isin([3, 6]), 'new_stalog'] = 5\n        stalog.stalog = stalog.new_stalog.copy()\n        del stalog['new_stalog']\n\n        assert stalog.stalog.isin(range(1, 6)).all()\n        stalog.set_index('ident_men', inplace = True)\n        menage = menage.merge(stalog, left_index = True, right_index = True)\n        menage['typlog'] = 2\n        menage.loc[menage.htl.isin(['1', '5']), 'typlog'] = 1\n        assert menage.typlog.isin([1, 2]).all()\n        del menage['htl']\n\n        individus = survey.get_values(table = 'individu')\n        # Il y a un probl\u00e8me sur l'ann\u00e9e de naissance,\n        # donc on le recalcule avec l'ann\u00e9e de naissance et la vague d'enqu\u00eate\n        individus['agepr'] = year - individus.anais\n        individus.loc[individus.vag == 6, ['agepr']] = year + 1 - individus.anais\n        individus = individus[individus.lienpref == 00].copy()\n        kept_variables = ['ident_men', 'etamatri', 'agepr']\n        individus = individus[kept_variables].copy()\n        individus.etamatri.loc[individus.etamatri == 0] = 1\n        individus['etamatri'] = individus['etamatri'].astype('int')  # MBJ TODO: define as a catagory ?\n        individus.set_index('ident_men', inplace = True)\n        menage = menage.merge(individus, left_index = True, right_index = True)\n\n        individus = survey.get_values(\n            table = 'individu',\n            variables = ['ident_men', 'ident_ind', 'age', 'anais', 'vag', 'lienpref'],\n            )\n        # Il y a un probl\u00e8me sur l'ann\u00e9e de naissance,\n        # donc on le recalcule avec l'ann\u00e9e de naissance et la vague d'enqu\u00eate\n        individus['age'] = year - individus.anais\n        individus.loc[individus.vag == 6, ['age']] = year + 1 - individus.anais\n        # Garder toutes les personnes du m\u00e9nage qui ne sont pas la personne de r\u00e9f\u00e9rence et le conjoint\n        individus = individus[(individus.lienpref != 00) & (individus.lienpref != 01)].copy()\n        individus.sort_values(by = ['ident_men', 'ident_ind'], inplace = True)\n\n        # Inspired by http://stackoverflow.com/questions/17228215/enumerate-each-row-for-each-group-in-a-dataframe\n        def add_col_numero(data_frame):\n            data_frame['numero'] = numpy.arange(len(data_frame)) + 3\n            return data_frame\n\n        individus = individus.groupby(by = 'ident_men').apply(add_col_numero)\n        pivoted = individus.pivot(index = 'ident_men', columns = \"numero\", values = 'age')\n        pivoted.columns = [\"age{}\".format(column) for column in pivoted.columns]\n        menage = menage.merge(pivoted, left_index = True, right_index = True, how = 'outer')\n\n        individus = survey.get_values(\n            table = 'individu',\n            variables = ['ident_men', 'ident_ind', 'agfinetu', 'lienpref'],\n            )\n        individus.set_index('ident_men', inplace = True)\n        pr = individus.loc[individus.lienpref == 00, 'agfinetu'].copy()\n        conjoint = individus.loc[individus.lienpref == 01, 'agfinetu'].copy()\n        conjoint.name = 'agfinetu_cj'\n        agfinetu_merged = pandas.concat([pr, conjoint], axis = 1)\n        menage = menage.merge(agfinetu_merged, left_index = True, right_index = True)\n        temporary_store['donnes_socio_demog_{}'.format(year)] = menage\n\n        # label var agepr \"Age de la personne de r\u00e9f\u00e9rence au 31/12/${yearrawdata}\"\n        # label var agecj \"Age du conjoint de la PR au 31/12/${yearrawdata}\"\n        # label var sexepr \"Sexe de la personne de r\u00e9f\u00e9rence\"\n        # label var sexecj \"Sexe du conjoint de la PR\"\n        # label var cs42pr \"Cat\u00e9gorie socio-professionnelle de la PR\"\n        # label var cs42cj \"Cat\u00e9gorie socio-professionnelle du conjoint de la PR\"\n        # label var ocde10 \"Nombre d'unit\u00e9s de consommation (\u00e9chelle OCDE)\"\n        # label var ident_men \"Identifiant du m\u00e9nage\"\n        # label var pondmen \"Ponderation du m\u00e9nage\"\n        # label var npers \"Nombre total de personnes dans le m\u00e9nage\"\n        # label var nadultes \"Nombre d'adultes dans le m\u00e9nage\"\n        # label var nenfants \"Nombre d'enfants dans le m\u00e9nage\"\n        # label var nenfhors \"Nombre d'enfants vivant hors domicile\"\n        # label var nactifs  \"Nombre d'actifs dans le m\u00e9nage\"\n        # label var couplepr \"Vie en couple de la personne de r\u00e9f\u00e9rence\"\n        # label define typmen5 1 \"Personne seule\" 2 \"Famille monoparentale\" 3 \"Couple sans enfant\"\n        #                      4 \"Couple avec enfants\" 5 \"Autre type de m\u00e9nage (complexe)\"\n        # label values typmen5 typmen5\n        # label var typmen5 \"Type de m\u00e9nage (5 modalit\u00e9s)\"\n        # label var etamatri \"Situation matrimoniale de la personne de r\u00e9f\u00e9rence\"\n        # label define matripr 1 \"C\u00e9libataire\" 2 \"Mari\u00e9(e)\" 3 \"Veuf(ve)\" 4 \"Divorc\u00e9(e)\"\n        # label values etamatri matripr\n        # label define occupation 1 \"Occupe un emploi\" ///\n        # 2 \"Apprenti\" ///\n        # 3 \"Etudiant, \u00e9l\u00e8ve, en formation\"  ///\n        # 4 \"Ch\u00f4meur (inscrit ou non \u00e0 l'ANPE)\" ///\n        # 5 \"Retrait\u00e9, pr\u00e9retrait\u00e9 ou retir\u00e9 des affaires\" ///\n        # 6 \"Au foyer\"  ///\n        # 7 \"Autre situation (handicap\u00e9)\"  ///\n        # 8 \"Militaire du contingent\"\n        # label values situapr occupation\n        # label values situacj occupation\n        # label var situapr \"Situation d'activit\u00e9 de la personne de r\u00e9f\u00e9rence\"\n        # label var situacj \"Situation d'activit\u00e9 du conjoint de la PR\"\n        # label define diplome 10 \"Dipl\u00f4me de 3\u00e8me cycle universitaire, doctorat\" ///\n        # 12 \"Dipl\u00f4me d'ing\u00e9nieur, grande \u00e9cole\" ///\n        # 20 \"Dipl\u00f4me de 2nd cycle universitaire\" ///\n        # 30 \"Dipl\u00f4me de 1er cycle universitaire\" ///\n        # 31 \"BTS, DUT ou \u00e9quivalent\" ///\n        # 33 \"Dipl\u00f4me des professions sociales et de la sant\u00e9 niveau Bac +2\" ///\n        # 41 \"Baccalaur\u00e9at g\u00e9n\u00e9ral, brevet sup\u00e9rieur, capacit\u00e9 en droit\" ///\n        # 42 \"Baccalaur\u00e9at technologique\" ///\n        # 43 \"Baccalaur\u00e9at professionnel\" ///\n        # 44 \"Brevet professionnel ou de technicien\" ///\n        # 50 \"CAP, BEP ou dipl\u00f4me de m\u00eame niveau\" ///\n        # 60 \"Brevet des coll\u00e8ges, BEPC\" ///\n        # 70 \"Certificat d'\u00e9tudes primaires\" ///\n        # 71 \"Aucun dipl\u00f4me\"\n        # label values dip14pr diplome\n        # label values dip14cj diplome\n        # label var dip14pr \"Dipl\u00f4me le plus \u00e9lev\u00e9 de la PR\"\n        # label var dip14cj \"Dipl\u00f4me le plus \u00e9lev\u00e9 du conjoint de la PR\"\n        # label define nationalite 1 \"Fran\u00e7ais, par naissance ou naturalisation\" 2 \"Etranger\"\n        # label values natiopr nationalite\n        # label values natiocj nationalite\n        # label var natiopr \"Nationalit\u00e9 de la personne de r\u00e9f\u00e9rence\"\n        # label var natiocj \"Nationalit\u00e9 du conjoint de la PR\"\n        # label define logement 1 \"Maison\" 2 \"Appartement\"\n        # label values typlog logement\n        # label var typlog \"Type de logement\"\n        # label define statutlogement 1 \"Propri\u00e9taire ou copropri\u00e9taire\" ///\n        # 2 \"Acc\u00e9dant \u00e0 la propri\u00e9t\u00e9 (rembourse un pr\u00eat)\" ///\n        # 3 \"Locataire\" ///\n        # 4 \"Sous-locataire\" ///\n        # 5 \"Log\u00e9 gratuitement\"\n        # label values stalog statutlogement\n        # label var stalog \"Statut d'occupation du logement\"\n        # label define viecouple 1 \"Vit en couple\" 2 \"Ne vit pas en couple\"\n        # label values couplepr viecouple\n        #\n        # /* Recodage des CSP en 12 et 8 postes \u00e0 partir de classification de l'INSEE (2003, PCS niveaux 1 et 2) */\n        # gen cs24pr=00\n        # replace cs24pr=10 if cs42pr==\"11\"\n        # replace cs24pr=10 if cs42pr==\"12\"\n        # replace cs24pr=10 if cs42pr==\"13\"\n        # replace cs24pr=21 if cs42pr==\"21\"\n        # replace cs24pr=22 if cs42pr==\"22\"\n        # replace cs24pr=23 if cs42pr==\"23\"\n        # replace cs24pr=31 if cs42pr==\"31\"\n        # replace cs24pr=32 if cs42pr==\"33\"\n        # replace cs24pr=32 if cs42pr==\"34\"\n        # replace cs24pr=32 if cs42pr==\"35\"\n        # replace cs24pr=36 if cs42pr==\"37\"\n        # replace cs24pr=36 if cs42pr==\"38\"\n        # replace cs24pr=41 if cs42pr==\"42\"\n        # replace cs24pr=41 if cs42pr==\"43\"\n        # replace cs24pr=41 if cs42pr==\"44\"\n        # replace cs24pr=41 if cs42pr==\"45\"\n        # replace cs24pr=46 if cs42pr==\"46\"\n        # replace cs24pr=47 if cs42pr==\"47\"\n        # replace cs24pr=48 if cs42pr==\"48\"\n        # replace cs24pr=51 if cs42pr==\"52\"\n        # replace cs24pr=51 if cs42pr==\"53\"\n        # replace cs24pr=54 if cs42pr==\"54\"\n        # replace cs24pr=55 if cs42pr==\"55\"\n        # replace cs24pr=56 if cs42pr==\"56\"\n        # replace cs24pr=61 if cs42pr==\"62\"\n        # replace cs24pr=61 if cs42pr==\"63\"\n        # replace cs24pr=61 if cs42pr==\"64\"\n        # replace cs24pr=61 if cs42pr==\"65\"\n        # replace cs24pr=66 if cs42pr==\"67\"\n        # replace cs24pr=66 if cs42pr==\"68\"\n        # replace cs24pr=69 if cs42pr==\"69\"\n        # replace cs24pr=71 if cs42pr==\"71\"\n        # replace cs24pr=72 if cs42pr==\"72\"\n        # replace cs24pr=73 if cs42pr==\"74\"\n        # replace cs24pr=73 if cs42pr==\"75\"\n        # replace cs24pr=76 if cs42pr==\"77\"\n        # replace cs24pr=76 if cs42pr==\"78\"\n        # replace cs24pr=81 if cs42pr==\"81\"\n        # replace cs24pr=82 if cs42pr==\"83\"\n        # replace cs24pr=82 if cs42pr==\"84\"\n        # replace cs24pr=82 if cs42pr==\"85\"\n        # replace cs24pr=82 if cs42pr==\"86\"\n        # replace cs24pr=82 if cs42pr==\"**\"\n        # replace cs24pr=82 if cs42pr==\"00\"\n        #\n\n        menage['cs24pr'] = 0\n        csp42s_by_csp24 = {\n            10: [\"11\", \"12\", \"13\"],\n            21: [\"21\"],\n            22: [\"22\"],\n            23: [\"23\"],\n            31: [\"31\"],\n            32: [\"32\", \"33\", \"34\", \"35\"],\n            36: [\"37\", \"38\"],\n            41: [\"42\", \"43\", \"44\", \"45\"],\n            46: [\"46\"],\n            47: [\"47\"],\n            48: [\"48\"],\n            51: [\"52\", \"53\"],\n            54: [\"54\"],\n            55: [\"55\"],\n            56: [\"56\"],\n            61: [\"62\", \"63\", \"64\", \"65\"],\n            66: [\"67\", \"68\"],\n            69: [\"69\"],\n            71: [\"71\"],\n            72: [\"72\"],\n            73: [\"74\", \"75\"],\n            76: [\"77\", \"78\"],\n            81: [\"81\"],\n            82: [\"83\", \"84\", \"85\", \"86\", \"**\", \"00\"],\n            }\n        for csp24, csp42s in csp42s_by_csp24.items():\n            menage.loc[menage.cs42pr.isin(csp42s), 'cs24pr'] = csp24\n        assert menage.cs24pr.isin(csp42s_by_csp24.keys()).all()\n\n        menage['cs8pr'] = numpy.floor(menage.cs24pr / 10)\n        assert menage.cs8pr.isin(range(1, 9)).all()\n\n        variables = [\n            'pondmen', 'npers', 'nenfants', 'nenfhors', 'nadultes', 'nactifs', 'ocde10', 'typmen',\n            'sexepr', 'agepr', 'etamatri', 'couplepr', 'situapr', 'dip14pr', 'cs42pr', 'cs24pr', 'cs8pr', 'natiopr',\n            'sexecj', 'agecj', 'situacj', 'dip14cj', 'cs42cj', 'natiocj', 'typlog', 'stalog'\n            ] + [\"age{}\".format(age) for age in range(3, 14)]\n\n        for variable in variables:\n            assert variable in menage.columns, \"{} is not a column of menage data frame\".format(variable)\n\n    if year == 2011:\n        variables = [\n            'agecj',\n            'agepr',\n            'coeffuc',\n            'decuc1',\n            'ident_me',\n            'pondmen',\n            'npers',\n            'nenfants',\n            'nactifs',\n            'sexepr',\n            'sexecj',\n            'dip14cj',\n            'dip14pr',\n            'typmen5',\n            'cataeu',\n            'situapr',\n            'situacj',\n            'zeat',\n            ]\n\n        try:\n            menage = survey.get_values(table = \"MENAGE\", variables = variables)\n        except:\n            menage = survey.get_values(table = \"menage\", variables = variables)\n\n        menage.rename(\n            columns = {\n                'ident_me': 'ident_men',\n                'coeffuc': 'ocde10',\n                'typmen5': 'typmen',\n                'decuc1': 'decuc',\n                'cataeu': 'strate'\n                },\n            inplace = True,\n            )\n        del variables\n        menage.agecj = menage.agecj.fillna(0)\n        # Ajout de la variable vag\n        try:\n            depmen = survey.get_values(table = \"DEPMEN\")\n        except:\n            depmen = survey.get_values(table = \"depmen\")\n        depmen.rename(columns = {'ident_me': 'ident_men'}, inplace = True)\n        vague = depmen[['vag', 'ident_men']].copy()\n        stalog = depmen[['stalog', 'ident_men']].copy()\n        del depmen\n\n        menage.set_index('ident_men', inplace = True)\n        vague.set_index('ident_men', inplace = True)\n        menage = menage.merge(vague, left_index = True, right_index = True)\n        # On met un num\u00e9ro \u00e0 chaque vague pour pouvoir faire un meilleur suivi des \u00e9volutions temporelles pour\n        # le mod\u00e8le de demande\n        menage['vag_'] = menage['vag'].copy()\n        menage.vag.loc[menage.vag_ == 1] = 23\n        menage.vag.loc[menage.vag_ == 2] = 24\n        menage.vag.loc[menage.vag_ == 3] = 25\n        menage.vag.loc[menage.vag_ == 4] = 26\n        menage.vag.loc[menage.vag_ == 5] = 27\n        menage.vag.loc[menage.vag_ == 6] = 28\n        del menage['vag_']\n\n        # Homog\u00e9n\u00e9isation de la variable statut du logement qui prend des valeurs diff\u00e9rentes pour 2011\n        stalog['stalog'] = stalog.stalog.astype('int').copy()\n        stalog['new_stalog'] = 0\n        stalog.loc[stalog.stalog == 2, 'new_stalog'] = 1\n        stalog.loc[stalog.stalog == 1, 'new_stalog'] = 2\n        stalog.loc[stalog.stalog == 4, 'new_stalog'] = 3\n        stalog.loc[stalog.stalog == 5, 'new_stalog'] = 4\n        stalog.loc[stalog.stalog.isin([3, 6]), 'new_stalog'] = 5\n        stalog.stalog = stalog.new_stalog.copy()\n        del stalog['new_stalog']\n        assert stalog.stalog.isin(range(1, 6)).all()\n        stalog.set_index('ident_men', inplace = True)\n        menage = menage.merge(stalog, left_index = True, right_index = True)\n\n        # Recodage des cat\u00e9gories zeat\n        menage.loc[menage.zeat == 7, 'zeat'] = 6\n        menage.zeat.loc[menage.zeat == 8] = 7\n        menage.zeat.loc[menage.zeat == 9] = 8\n        assert menage.zeat.isin(range(0, 9)).all()\n        menage.index.name = 'ident_men'\n\n    #\n    assert menage.index.name == 'ident_men'\n    menage['role_menage'] = 0\n    temporary_store['donnes_socio_demog_{}'.format(year)] = menage", "response": "u. B. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. B. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. C. A. B. A. B. B."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate and populate an instance of meteorpi_db. SQLBuilder for a given search object.", "response": "def search_obsgroups_sql_builder(search):\n    \"\"\"\n    Create and populate an instance of :class:`meteorpi_db.SQLBuilder` for a given\n    :class:`meteorpi_model.ObservationGroupSearch`. This can then be used to retrieve the results of the search,\n    materialise them into :class:`meteorpi_model.ObservationGroup` instances etc.\n\n    :param ObservationGroupSearch search:\n        The search to realise\n    :return:\n        A :class:`meteorpi_db.SQLBuilder` configured from the supplied search\n    \"\"\"\n    b = SQLBuilder(tables=\"\"\"archive_obs_groups g\nINNER JOIN archive_semanticTypes s ON g.semanticType=s.uid\"\"\", where_clauses=[])\n    b.add_sql(search.obstory_name, \"\"\"\nEXISTS (SELECT 1 FROM archive_obs_group_members x1\nINNER JOIN archive_observations x2 ON x2.uid=x1.observationId\nINNER JOIN archive_observatories x3 ON x3.uid=x2.observatory\nWHERE x1.groupId=g.uid AND x3.publicId=%s)\"\"\")\n    b.add_sql(search.semantic_type, 's.name = %s')\n    b.add_sql(search.observation_id, \"\"\"\nEXISTS (SELECT 1 FROM archive_obs_group_members y1\nINNER JOIN archive_observations y2 ON y2.uid=y1.observationId\nWHERE y1.groupId=g.uid AND y2.publicId=%s)\"\"\")\n    b.add_sql(search.group_id, 'g.publicId = %s')\n    b.add_sql(search.time_min, 'g.time > %s')\n    b.add_sql(search.time_max, 'g.time < %s')\n    b.add_metadata_query_properties(meta_constraints=search.meta_constraints, id_column=\"groupId\", id_table=\"g\")\n    return b"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search_files_sql_builder(search):\n    b = SQLBuilder(tables=\"\"\"archive_files f\nINNER JOIN archive_semanticTypes s2 ON f.semanticType=s2.uid\nINNER JOIN archive_observations o ON f.observationId=o.uid\nINNER JOIN archive_semanticTypes s ON o.obsType=s.uid\nINNER JOIN archive_observatories l ON o.observatory=l.uid\"\"\", where_clauses=[])\n    b.add_set_membership(search.obstory_ids, 'l.publicId')\n    b.add_sql(search.repository_fname, 'f.repositoryFname = %s')\n    b.add_sql(search.observation_type, 's.name = %s')\n    b.add_sql(search.observation_id, 'o.uid = %s')\n    b.add_sql(search.time_min, 'f.fileTime > %s')\n    b.add_sql(search.time_max, 'f.fileTime < %s')\n    b.add_sql(search.lat_min, 'l.latitude >= %s')\n    b.add_sql(search.lat_max, 'l.latitude <= %s')\n    b.add_sql(search.long_min, 'l.longitude >= %s')\n    b.add_sql(search.long_max, 'l.longitude <= %s')\n    b.add_sql(search.mime_type, 'f.mimeType = %s')\n    b.add_sql(search.semantic_type, 's2.name = %s')\n    b.add_metadata_query_properties(meta_constraints=search.meta_constraints, id_column=\"fileId\", id_table=\"f\")\n\n    # Check for import / export filters\n    if search.exclude_imported:\n        b.where_clauses.append('NOT EXISTS (SELECT * FROM archive_observationImport i WHERE i.observationId = o.uid')\n    if search.exclude_export_to is not None:\n        b.where_clauses.append(\"\"\"\n        NOT EXISTS (SELECT * FROM archive_fileExport ex\n        INNER JOIN archive_exportConfig c ON ex.exportConfig = c.uid\n        WHERE ex.fileId = f.uid  AND c.exportConfigID = %s)\n        \"\"\")\n        b.sql_args.append(SQLBuilder.map_value(search.exclude_export_to))\n\n    return b", "response": "Create and populate an instance of meteorpi_db. SQLBuilder for a given search."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating and populate an instance of meteorpi_db. SQLBuilder for a given search object.", "response": "def search_metadata_sql_builder(search):\n    \"\"\"\n    Create and populate an instance of :class:`meteorpi_db.SQLBuilder` for a given\n    :class:`meteorpi_model.ObservatoryMetadataSearch`. This can then be used to retrieve the results of the search,\n    materialise them into :class:`meteorpi_model.ObservatoryMetadata` instances etc.\n\n    :param ObservatoryMetadataSearch search:\n        The search to realise\n    :return:\n        A :class:`meteorpi_db.SQLBuilder` configured from the supplied search\n    \"\"\"\n    b = SQLBuilder(tables=\"\"\"archive_metadata m\nINNER JOIN archive_metadataFields f ON m.fieldId=f.uid\nINNER JOIN archive_observatories l ON m.observatory=l.uid\"\"\", where_clauses=[\"m.observatory IS NOT NULL\"])\n    b.add_set_membership(search.obstory_ids, 'l.publicId')\n    b.add_sql(search.field_name, 'f.metaKey = %s')\n    b.add_sql(search.time_min, 'm.time > %s')\n    b.add_sql(search.time_max, 'm.time < %s')\n    b.add_sql(search.lat_min, 'l.latitude >= %s')\n    b.add_sql(search.lat_max, 'l.latitude <= %s')\n    b.add_sql(search.long_min, 'l.longitude >= %s')\n    b.add_sql(search.long_max, 'l.longitude <= %s')\n    b.add_sql(search.item_id, 'm.publicId = %s')\n\n    # Check for import / export filters\n    if search.exclude_imported:\n        b.where_clauses.append('NOT EXISTS (SELECT * FROM archive_metadataImport i WHERE i.metadataId = m.uid')\n    if search.exclude_export_to is not None:\n        b.where_clauses.append(\"\"\"\n        NOT EXISTS (SELECT * FROM archive_metadataExport ex\n        INNER JOIN archive_exportConfig c ON ex.exportConfig = c.uid\n        WHERE ex.metadataId = m.uid AND c.exportConfigID = %s)\n        \"\"\")\n        b.sql_args.append(SQLBuilder.map_value(search.exclude_export_to))\n\n    return b"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_sql(self, value, clause):\n        if value is not None:\n            self.sql_args.append(SQLBuilder.map_value(value))\n            self.where_clauses.append(clause)", "response": "Adds a WHERE clause to the state."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nappends a set membership test to the state.", "response": "def add_set_membership(self, values, column_name):\n        \"\"\"\n        Append a set membership test, creating a query of the form 'WHERE name IN (?,?...?)'.\n\n        :param values:\n            A list of values, or a subclass of basestring. If this is non-None and non-empty this will add a set\n            membership test to the state. If the supplied value is a basestring it will be wrapped in a single element\n            list. Values are mapped by SQLBuilder._map_value before being added, so e.g. NSString instances will work\n            here.\n        :param column_name:\n            The name of the column to use when checking the 'IN' condition.\n        \"\"\"\n        if values is not None and len(values) > 0:\n            if isinstance(values, basestring):\n                values = [values]\n            question_marks = ', '.join([\"%s\"] * len(values))\n            self.where_clauses.append('{0} IN ({1})'.format(column_name, question_marks))\n            for value in values:\n                self.sql_args.append(SQLBuilder.map_value(value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_metadata_query_properties(self, meta_constraints, id_table, id_column):\n        for mc in meta_constraints:\n            meta_key = str(mc.key)\n            ct = mc.constraint_type\n            sql_template = \"\"\"\n{0}.uid IN (\nSELECT m.{1} FROM archive_metadata m\nINNER JOIN archive_metadataFields k ON m.fieldId=k.uid\nWHERE m.{2} {3} %s AND k.metaKey = %s\n)\"\"\"\n            # Add metadata value to list of SQL arguments\n            self.sql_args.append(SQLBuilder.map_value(mc.value))\n            # Add metadata key to list of SQL arguments\n            self.sql_args.append(meta_key)\n            # Put an appropriate WHERE clause\n            if ct == 'less':\n                self.where_clauses.append(sql_template.format(id_table, id_column, 'floatValue', '<='))\n            elif ct == 'greater':\n                self.where_clauses.append(sql_template.format(id_table, id_column, 'floatValue', '>='))\n            elif ct == 'number_equals':\n                self.where_clauses.append(sql_template.format(id_table, id_column, 'floatValue', '='))\n            elif ct == 'string_equals':\n                self.where_clauses.append(sql_template.format(id_table, id_column, 'stringValue', '='))\n            else:\n                raise ValueError(\"Unknown meta constraint type!\")", "response": "Constructs the WHERE clauses from a list of MetaConstraint objects adding them to the query state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_select_sql(self, columns, order=None, limit=0, skip=0):\n        sql = 'SELECT '\n        sql += '{0} FROM {1} '.format(columns, self.tables)\n        if len(self.where_clauses) > 0:\n            sql += ' WHERE '\n            sql += ' AND '.join(self.where_clauses)\n        if order is not None:\n            sql += ' ORDER BY {0}'.format(order)\n        if limit > 0:\n            sql += ' LIMIT {0} '.format(limit)\n        if skip > 0:\n            sql += ' OFFSET {0} '.format(skip)\n        return sql", "response": "Builds a SELECT query based on the current state of the builder."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_count_sql(self):\n        sql = 'SELECT COUNT(*) FROM ' + self.tables\n        if len(self.where_clauses) > 0:\n            sql += ' WHERE '\n            sql += ' AND '.join(self.where_clauses)\n        return sql", "response": "Build a SELECT query which returns the count of items for a specific resource."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwrapping the class_name and typ in a list of lines.", "response": "def wrap_setup(self, class_name, typ, with_async=False):\n        \"\"\"Described.typ = noy_wrap_typ(Described, Described.typ)\"\"\"\n        equivalence = self.equivalence[typ]\n        return [\n              (NEWLINE, '\\n')\n            , (NAME, class_name)\n            , (OP, '.')\n            , (NAME, equivalence)\n            , (OP, '=')\n            , (NAME, \"%snoy_wrap_%s\" % ('async_' if with_async else '', equivalence))\n            , (OP, \"(\")\n            , (NAME, class_name)\n            , (OP, ',')\n            , (NAME, class_name)\n            , (OP, '.')\n            , (NAME, equivalence)\n            , (OP, \")\")\n            ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize the SinonGlobals class", "response": "def init(scope):\n    \"\"\"\n    Copy all values of scope into the class SinonGlobals\n    Args:\n        scope (eg. locals() or globals())\n    Return:\n        SinonGlobals instance\n    \"\"\"\n    class SinonGlobals(object): #pylint: disable=too-few-public-methods\n        \"\"\"\n        A fully empty class\n        External can push the whole `scope` into this class through global function init()\n        \"\"\"\n        pass\n\n    global CPSCOPE #pylint: disable=global-statement\n    CPSCOPE = SinonGlobals()\n    funcs = [obj for obj in scope.values() if isinstance(obj, FunctionType)]\n    for func in funcs:\n        setattr(CPSCOPE, func.__name__, func)\n    return CPSCOPE"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the object that is wrapped by the object.", "response": "def _get_wrapper(self):\n        \"\"\"\n        Return:\n            Wrapper object\n        Raise:\n            Exception if wrapper object cannot be found\n        \"\"\"\n        if self.args_type == \"MODULE_FUNCTION\":\n            return getattr(self.obj, self.prop)\n        elif self.args_type == \"FUNCTION\":\n            return getattr(self.g, self.obj.__name__)\n        elif self.args_type == \"PURE\":\n            return getattr(self.pure, \"func\")\n        else:\n            ErrorHandler.wrapper_object_not_found_error()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __set_type(self, obj, prop):\n        if TypeHandler.is_pure(obj, prop):\n            self.args_type = \"PURE\"\n            self.pure = SinonBase.Pure()\n            setattr(self.pure, \"func\", Wrapper.empty_function)\n            self.orig_func = None\n        elif TypeHandler.is_module_function(obj, prop):\n            self.args_type = \"MODULE_FUNCTION\"\n            self.orig_func = None\n        elif TypeHandler.is_function(obj):\n            self.args_type = \"FUNCTION\"\n            self.orig_func = None\n        elif TypeHandler.is_module(obj):\n            self.args_type = \"MODULE\"\n        elif TypeHandler.is_instance(obj):\n            obj = obj.__class__\n            self.args_type = \"MODULE\"", "response": "Sets the type of the object based on arguments"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __check_lock(self):\n        if self.args_type == \"MODULE_FUNCTION\":\n            if hasattr(getattr(self.obj, self.prop), \"LOCK\"):\n                ErrorHandler.lock_error(self.prop)\n        elif self.args_type == \"MODULE\":\n            if hasattr(self.obj, \"__SINONLOCK__\"):\n                ErrorHandler.lock_error(self.obj)\n        elif self.args_type == \"FUNCTION\":\n            if hasattr(getattr(CPSCOPE, self.obj.__name__), \"LOCK\"):\n                ErrorHandler.lock_error(self.obj)", "response": "Checks whether the inspector is wrapped or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wrap2spy(self):\n        if self.args_type == \"MODULE_FUNCTION\":\n            self.orig_func = deepcopy(getattr(self.obj, self.prop))\n            setattr(self.obj, self.prop, Wrapper.wrap_spy(getattr(self.obj, self.prop)))\n        elif self.args_type == \"MODULE\":\n            setattr(self.obj, \"__SINONLOCK__\", True)\n        elif self.args_type == \"FUNCTION\":\n            self.orig_func = deepcopy(getattr(CPSCOPE, self.obj.__name__))\n            setattr(CPSCOPE, self.obj.__name__,\n                    Wrapper.wrap_spy(getattr(CPSCOPE, self.obj.__name__)))\n        elif self.args_type == \"PURE\":\n            self.orig_func = deepcopy(getattr(self.pure, \"func\"))\n            setattr(self.pure, \"func\", Wrapper.wrap_spy(getattr(self.pure, \"func\")))", "response": "Wraps the inspector as a spy based on the type of the inspector."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nunwrapping the inspector based on the type of the inspector.", "response": "def unwrap(self):\n        \"\"\"\n        Unwrapping the inspector based on the type\n        \"\"\"\n        if self.args_type == \"MODULE_FUNCTION\":\n            setattr(self.obj, self.prop, self.orig_func)\n        elif self.args_type == \"MODULE\":\n            delattr(self.obj, \"__SINONLOCK__\")\n        elif self.args_type == \"FUNCTION\":\n            setattr(CPSCOPE, self.obj.__name__, self.orig_func)\n        elif self.args_type == \"PURE\":\n            setattr(self.pure, \"func\", self.orig_func)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps the inspector as a stub based on the type of the object.", "response": "def wrap2stub(self, customfunc):\n        \"\"\"\n        Wrapping the inspector as a stub based on the type\n        Args:\n            customfunc: function that replaces the original\n        Returns:\n            function, the spy wrapper around the customfunc\n        \"\"\"\n        if self.args_type == \"MODULE_FUNCTION\":\n            wrapper = Wrapper.wrap_spy(customfunc, self.obj)\n            setattr(self.obj, self.prop, wrapper)\n        elif self.args_type == \"MODULE\":\n            wrapper = Wrapper.EmptyClass\n            setattr(CPSCOPE, self.obj.__name__, wrapper)\n        elif self.args_type == \"FUNCTION\":\n            wrapper = Wrapper.wrap_spy(customfunc)\n            setattr(CPSCOPE, self.obj.__name__, wrapper)\n        elif self.args_type == \"PURE\":\n            wrapper = Wrapper.wrap_spy(customfunc)\n            setattr(self.pure, \"func\", wrapper)\n        return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if a specific operator instance is a specific operator instance.", "response": "def is_op(call, op):\n    \"\"\"\n    :param call: The specific operator instance (a method call)\n    :param op: The the operator we are testing against\n    :return: isinstance(call, op), but faster\n    \"\"\"\n    try:\n        return call.id == op.id\n    except Exception as e:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsorting VALUES, NULL IS THE LEAST VALUE :param left: LHS :param right: RHS :param ordering: (-1, 0, 1) TO AFFECT SORT ORDER :return: The return value is negative if x < y, zero if x == y and strictly positive if x > y.", "response": "def value_compare(left, right, ordering=1):\n    \"\"\"\n    SORT VALUES, NULL IS THE LEAST VALUE\n    :param left: LHS\n    :param right: RHS\n    :param ordering: (-1, 0, 1) TO AFFECT SORT ORDER\n    :return: The return value is negative if x < y, zero if x == y and strictly positive if x > y.\n    \"\"\"\n\n    try:\n        ltype = left.__class__\n        rtype = right.__class__\n\n        if ltype in list_types or rtype in list_types:\n            if left == None:\n                return ordering\n            elif right == None:\n                return - ordering\n\n            left = listwrap(left)\n            right = listwrap(right)\n            for a, b in zip(left, right):\n                c = value_compare(a, b) * ordering\n                if c != 0:\n                    return c\n\n            if len(left) < len(right):\n                return - ordering\n            elif len(left) > len(right):\n                return ordering\n            else:\n                return 0\n\n        if ltype is float and isnan(left):\n            left = None\n            ltype = none_type\n        if rtype is float and isnan(right):\n            right = None\n            rtype = none_type\n\n        null_order = ordering*10\n        ltype_num = TYPE_ORDER.get(ltype, null_order)\n        rtype_num = TYPE_ORDER.get(rtype, null_order)\n\n        type_diff = ltype_num - rtype_num\n        if type_diff != 0:\n            return ordering if type_diff > 0 else -ordering\n\n        if ltype_num == null_order:\n            return 0\n        elif ltype is builtin_tuple:\n            for a, b in zip(left, right):\n                c = value_compare(a, b)\n                if c != 0:\n                    return c * ordering\n            return 0\n        elif ltype in data_types:\n            for k in sorted(set(left.keys()) | set(right.keys())):\n                c = value_compare(left.get(k), right.get(k)) * ordering\n                if c != 0:\n                    return c\n            return 0\n        elif left > right:\n            return ordering\n        elif left < right:\n            return -ordering\n        else:\n            return 0\n    except Exception as e:\n        Log.error(\"Can not compare values {{left}} to {{right}}\", left=left, right=right, cause=e)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the jx_type for given column", "response": "def jx_type(column):\n    \"\"\"\n    return the jx_type for given column\n    \"\"\"\n    if column.es_column.endswith(EXISTS_TYPE):\n        return EXISTS\n    return es_type_to_json_type[column.es_type]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreload the columns of the metadata for the given table.", "response": "def _reload_columns(self, table_desc):\n        \"\"\"\n        :param alias: A REAL ALIAS (OR NAME OF INDEX THAT HAS NO ALIAS)\n        :return:\n        \"\"\"\n        # FIND ALL INDEXES OF ALIAS\n        es_last_updated = self.es_cluster.metatdata_last_updated\n\n        alias = table_desc.name\n        canonical_index = self.es_cluster.get_best_matching_index(alias).index\n        es_metadata_update_required = not (table_desc.timestamp < es_last_updated)\n        metadata = self.es_cluster.get_metadata(force=es_metadata_update_required)\n\n        props = [\n            (self.es_cluster.get_index(index=i, type=t, debug=DEBUG), t, m.properties)\n            for i, d in metadata.indices.items()\n            if alias in d.aliases\n            for t, m in [_get_best_type_from_mapping(d.mappings)]\n        ]\n\n        # CONFIRM ALL COLUMNS ARE SAME, FIX IF NOT\n        dirty = False\n        all_comparisions = list(jx.pairwise(props)) + list(jx.pairwise(jx.reverse(props)))\n        # NOTICE THE SAME (index, type, properties) TRIPLE FROM ABOVE\n        for (i1, t1, p1), (i2, t2, p2) in all_comparisions:\n            diff = elasticsearch.diff_schema(p2, p1)\n            if not self.settings.read_only:\n                for d in diff:\n                    dirty = True\n                    i1.add_property(*d)\n        meta = self.es_cluster.get_metadata(force=dirty).indices[canonical_index]\n\n        data_type, mapping = _get_best_type_from_mapping(meta.mappings)\n        mapping.properties[\"_id\"] = {\"type\": \"string\", \"index\": \"not_analyzed\"}\n        columns = self._parse_properties(alias, mapping)\n        table_desc.timestamp = es_last_updated\n        return columns"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_columns(self, table_name, column_name=None, after=None, timeout=None):\n        DEBUG and after and Log.note(\"getting columns for after {{time}}\", time=after)\n        table_path = split_field(table_name)\n        root_table_name = table_path[0]\n\n        alias = self._find_alias(root_table_name)\n        if not alias:\n            self.es_cluster.get_metadata(force=True)\n            alias = self._find_alias(root_table_name)\n            if not alias:\n                Log.error(\"{{table|quote}} does not exist\", table=table_name)\n\n        try:\n            table = self.get_table(alias)[0]\n            # LAST TIME WE GOT INFO FOR THIS TABLE\n            if not table:\n                table = TableDesc(\n                    name=alias,\n                    url=None,\n                    query_path=[\".\"],\n                    timestamp=Date.MIN\n                )\n                with self.meta.tables.locker:\n                    self.meta.tables.add(table)\n                columns = self._reload_columns(table)\n                DEBUG and Log.note(\"columns from reload\")\n            elif after or table.timestamp < self.es_cluster.metatdata_last_updated:\n                columns = self._reload_columns(table)\n                DEBUG and Log.note(\"columns from reload\")\n            else:\n                columns = self.meta.columns.find(alias, column_name)\n                DEBUG and Log.note(\"columns from find()\")\n\n            DEBUG and Log.note(\"columns are {{ids}}\", ids=[id(c) for c in columns])\n\n            columns = jx.sort(columns, \"name\")\n\n            if after is None:\n                return columns  # DO NOT WAIT FOR COMPLETE COLUMNS\n\n            # WAIT FOR THE COLUMNS TO UPDATE\n            while True:\n                pending = [c for c in columns if after >= c.last_updated or (c.cardinality == None and c.jx_type not in STRUCT)]\n                if not pending:\n                    break\n                if timeout:\n                    Log.error(\"trying to gets columns timed out\")\n                if DEBUG:\n                    if len(pending) > 10:\n                        Log.note(\"waiting for {{num}} columns to update by {{timestamp}}\", num=len(pending), timestamp=after)\n                    else:\n                        Log.note(\"waiting for columns to update by {{timestamp}}; {{columns|json}}\", timestamp=after, columns=[c.es_index + \".\" + c.es_column + \" id=\"+text_type(id(c)) for c in pending])\n                Till(seconds=1).wait()\n            return columns\n        except Exception as e:\n            Log.error(\"Failure to get columns for {{table}}\", table=table_name, cause=e)\n\n        return []", "response": "Get the columns for a given table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the cardinality of a single column.", "response": "def _update_cardinality(self, column):\n        \"\"\"\n        QUERY ES TO FIND CARDINALITY AND PARTITIONS FOR A SIMPLE COLUMN\n        \"\"\"\n        now = Date.now()\n        if column.es_index in self.index_does_not_exist:\n            return\n\n        if column.jx_type in STRUCT:\n            Log.error(\"not supported\")\n        try:\n            if column.es_index == \"meta.columns\":\n                partitions = jx.sort([g[column.es_column] for g, _ in jx.groupby(self.meta.columns, column.es_column) if g[column.es_column] != None])\n                self.meta.columns.update({\n                    \"set\": {\n                        \"partitions\": partitions,\n                        \"count\": len(self.meta.columns),\n                        \"cardinality\": len(partitions),\n                        \"multi\": 1,\n                        \"last_updated\": now\n                    },\n                    \"where\": {\"eq\": {\"es_index\": column.es_index, \"es_column\": column.es_column}}\n                })\n                return\n            if column.es_index == \"meta.tables\":\n                partitions = jx.sort([g[column.es_column] for g, _ in jx.groupby(self.meta.tables, column.es_column) if g[column.es_column] != None])\n                self.meta.columns.update({\n                    \"set\": {\n                        \"partitions\": partitions,\n                        \"count\": len(self.meta.tables),\n                        \"cardinality\": len(partitions),\n                        \"multi\": 1,\n                        \"last_updated\": now\n                    },\n                    \"where\": {\"eq\": {\"es_index\": column.es_index, \"es_column\": column.es_column}}\n                })\n                return\n\n            es_index = column.es_index.split(\".\")[0]\n\n            is_text = [cc for cc in self.meta.columns if cc.es_column == column.es_column and cc.es_type == \"text\"]\n            if is_text:\n                # text IS A MULTIVALUE STRING THAT CAN ONLY BE FILTERED\n                result = self.es_cluster.post(\"/\" + es_index + \"/_search\", data={\n                    \"aggs\": {\n                        \"count\": {\"filter\": {\"match_all\": {}}}\n                    },\n                    \"size\": 0\n                })\n                count = result.hits.total\n                cardinality = max(1001, count)\n                multi = 1001\n            elif column.es_column == \"_id\":\n                result = self.es_cluster.post(\"/\" + es_index + \"/_search\", data={\n                    \"query\": {\"match_all\": {}},\n                    \"size\": 0\n                })\n                count = cardinality = result.hits.total\n                multi = 1\n            elif column.es_type == BOOLEAN:\n                result = self.es_cluster.post(\"/\" + es_index + \"/_search\", data={\n                    \"aggs\": {\n                        \"count\": _counting_query(column)\n                    },\n                    \"size\": 0\n                })\n                count = result.hits.total\n                cardinality = 2\n\n                DEBUG and Log.note(\"{{table}}.{{field}} has {{num}} parts\", table=column.es_index, field=column.es_column, num=cardinality)\n                self.meta.columns.update({\n                    \"set\": {\n                        \"count\": count,\n                        \"cardinality\": cardinality,\n                        \"partitions\": [False, True],\n                        \"multi\": 1,\n                        \"last_updated\": now\n                    },\n                    \"clear\": [\"partitions\"],\n                    \"where\": {\"eq\": {\"es_index\": column.es_index, \"es_column\": column.es_column}}\n                })\n                return\n            else:\n                es_query = {\n                    \"aggs\": {\n                        \"count\": _counting_query(column),\n                        \"_filter\": {\n                            \"aggs\": {\"multi\": {\"max\": {\"script\": \"doc[\" + quote(column.es_column) + \"].values.size()\"}}},\n                            \"filter\": {\"bool\": {\"should\": [\n                                {\"range\": {\"etl.timestamp.~n~\": {\"gte\": (Date.today() - WEEK)}}},\n                                {\"bool\": {\"must_not\": {\"exists\": {\"field\": \"etl.timestamp.~n~\"}}}}\n                            ]}}\n                        }\n                    },\n                    \"size\": 0\n                }\n\n                result = self.es_cluster.post(\"/\" + es_index + \"/_search\", data=es_query)\n                agg_results = result.aggregations\n                count = result.hits.total\n                cardinality = coalesce(agg_results.count.value, agg_results.count._nested.value, agg_results.count.doc_count)\n                multi = int(coalesce(agg_results._filter.multi.value, 1))\n                if cardinality == None:\n                    Log.error(\"logic error\")\n\n            query = Data(size=0)\n\n            if column.es_column == \"_id\":\n                self.meta.columns.update({\n                    \"set\": {\n                        \"count\": cardinality,\n                        \"cardinality\": cardinality,\n                        \"multi\": 1,\n                        \"last_updated\": now\n                    },\n                    \"clear\": [\"partitions\"],\n                    \"where\": {\"eq\": {\"es_index\": column.es_index, \"es_column\": column.es_column}}\n                })\n                return\n            elif cardinality > 1000 or (count >= 30 and cardinality == count) or (count >= 1000 and cardinality / count > 0.99):\n                DEBUG and Log.note(\"{{table}}.{{field}} has {{num}} parts\", table=column.es_index, field=column.es_column, num=cardinality)\n                self.meta.columns.update({\n                    \"set\": {\n                        \"count\": count,\n                        \"cardinality\": cardinality,\n                        \"multi\": multi,\n                        \"last_updated\": now\n                    },\n                    \"clear\": [\"partitions\"],\n                    \"where\": {\"eq\": {\"es_index\": column.es_index, \"es_column\": column.es_column}}\n                })\n                return\n            elif column.es_type in elasticsearch.ES_NUMERIC_TYPES and cardinality > 30:\n                DEBUG and Log.note(\"{{table}}.{{field}} has {{num}} parts\", table=column.es_index, field=column.es_column, num=cardinality)\n                self.meta.columns.update({\n                    \"set\": {\n                        \"count\": count,\n                        \"cardinality\": cardinality,\n                        \"multi\": multi,\n                        \"last_updated\": now\n                    },\n                    \"clear\": [\"partitions\"],\n                    \"where\": {\"eq\": {\"es_index\": column.es_index, \"es_column\": column.es_column}}\n                })\n                return\n            elif len(column.nested_path) != 1:\n                query.aggs[\"_\"] = {\n                    \"nested\": {\"path\": column.nested_path[0]},\n                    \"aggs\": {\"_nested\": {\"terms\": {\"field\": column.es_column}}}\n                }\n            elif cardinality == 0:  # WHEN DOES THIS HAPPEN?\n                query.aggs[\"_\"] = {\"terms\": {\"field\": column.es_column}}\n            else:\n                query.aggs[\"_\"] = {\"terms\": {\"field\": column.es_column, \"size\": cardinality}}\n\n            result = self.es_cluster.post(\"/\" + es_index + \"/_search\", data=query)\n\n            aggs = result.aggregations._\n            if aggs._nested:\n                parts = jx.sort(aggs._nested.buckets.key)\n            else:\n                parts = jx.sort(aggs.buckets.key)\n\n            DEBUG and Log.note(\"update metadata for {{column.es_index}}.{{column.es_column}} (id={{id}}) at {{time}}\", id=id(column), column=column, time=now)\n            self.meta.columns.update({\n                \"set\": {\n                    \"count\": count,\n                    \"cardinality\": cardinality,\n                    \"multi\": multi,\n                    \"partitions\": parts,\n                    \"last_updated\": now\n                },\n                \"where\": {\"eq\": {\"es_index\": column.es_index, \"es_column\": column.es_column}}\n            })\n        except Exception as e:\n            # CAN NOT IMPORT: THE TEST MODULES SETS UP LOGGING\n            # from tests.test_jx import TEST_TABLE\n            e = Except.wrap(e)\n            TEST_TABLE = \"testdata\"\n            is_missing_index = any(w in e for w in [\"IndexMissingException\", \"index_not_found_exception\"])\n            is_test_table = column.es_index.startswith((TEST_TABLE_PREFIX, TEST_TABLE))\n            if is_missing_index:\n                # WE EXPECT TEST TABLES TO DISAPPEAR\n                Log.warning(\"Missing index {{col.es_index}}\", col=column, cause=e)\n                self.meta.columns.update({\n                    \"clear\": \".\",\n                    \"where\": {\"eq\": {\"es_index\": column.es_index}}\n                })\n                self.index_does_not_exist.add(column.es_index)\n            elif \"No field found for\" in e:\n                self.meta.columns.update({\n                    \"clear\": \".\",\n                    \"where\": {\"eq\": {\"es_index\": column.es_index, \"es_column\": column.es_column}}\n                })\n                Log.warning(\"Could not get column {{col.es_index}}.{{col.es_column}} info\", col=column, cause=e)\n            else:\n                self.meta.columns.update({\n                    \"set\": {\n                        \"last_updated\": now\n                    },\n                    \"clear\": [\n                        \"count\",\n                        \"cardinality\",\n                        \"multi\",\n                        \"partitions\",\n                    ],\n                    \"where\": {\"eq\": {\"es_index\": column.es_index, \"es_column\": column.es_column}}\n                })\n                Log.warning(\"Could not get {{col.es_index}}.{{col.es_column}} info\", col=column, cause=e)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query_paths(self):\n        output = self.namespace.alias_to_query_paths.get(self.name)\n        if output:\n            return output\n        Log.error(\"Can not find index {{index|quote}}\", index=self.name)", "response": "Return a list of all NESTED COLUMNS that are in the index."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn A LIST OF ALL SCHEMAS IN DEPTH - FIRST TOPOLOGICAL ORDER", "response": "def sorted_query_paths(self):\n        \"\"\"\n        RETURN A LIST OF ALL SCHEMA'S IN DEPTH-FIRST TOPOLOGICAL ORDER\n        \"\"\"\n        return list(reversed(sorted(p[0] for p in self.namespace.alias_to_query_paths.get(self.name))))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef leaves(self, column_name):\n        clean_name = unnest_path(column_name)\n\n        if clean_name != column_name:\n            clean_name = column_name\n            cleaner = lambda x: x\n        else:\n            cleaner = unnest_path\n\n\n        columns = self.columns\n        # TODO: '.' IMPLIES ALL FIELDS FROM ABSOLUTE PERPECTIVE, ALL OTHERS ARE A RELATIVE PERSPECTIVE\n        # TODO: HOW TO REFER TO FIELDS THAT MAY BE SHADOWED BY A RELATIVE NAME?\n        for path in reversed(self.query_path) if clean_name == '.' else self.query_path:\n            output = [\n                c\n                for c in columns\n                if (\n                    (c.name != \"_id\" or clean_name == \"_id\") and\n                    (\n                        (c.jx_type == EXISTS and column_name.endswith(\".\" + EXISTS_TYPE)) or\n                        c.jx_type not in OBJECTS or\n                        (clean_name == '.' and c.cardinality == 0)\n                    ) and\n                    startswith_field(cleaner(relative_field(c.name, path)), clean_name)\n                )\n            ]\n            if output:\n                return set(output)\n        return set()", "response": "returns a set of all the entries that are leaves of the given column_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a set of all LEAVES that are in the given column_name.", "response": "def new_leaves(self, column_name):\n        \"\"\"\n        :param column_name:\n        :return: ALL COLUMNS THAT START WITH column_name, INCLUDING DEEP COLUMNS\n        \"\"\"\n        column_name = unnest_path(column_name)\n        columns = self.columns\n        all_paths = self.snowflake.sorted_query_paths\n\n        output = {}\n        for c in columns:\n            if c.name == \"_id\" and column_name != \"_id\":\n                continue\n            if c.jx_type in OBJECTS:\n                continue\n            if c.cardinality == 0:\n                continue\n            for path in all_paths:\n                if not startswith_field(unnest_path(relative_field(c.name, path)), column_name):\n                    continue\n                existing = output.get(path)\n                if not existing:\n                    output[path] = [c]\n                    continue\n                if len(path) > len(c.nested_path[0]):\n                    continue\n                if any(\".\" + t + \".\" in c.es_column for t in (STRING_TYPE, NUMBER_TYPE, BOOLEAN_TYPE)):\n                    # ELASTICSEARCH field TYPES ARE NOT ALLOWED\n                    continue\n                # ONLY THE DEEPEST COLUMN WILL BE CHOSEN\n                output[path].append(c)\n        return set(output.values())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef values(self, column_name, exclude_type=STRUCT):\n        column_name = unnest_path(column_name)\n        columns = self.columns\n        output = []\n        for path in self.query_path:\n            full_path = untype_path(concat_field(path, column_name))\n            for c in columns:\n                if c.jx_type in exclude_type:\n                    continue\n                # if c.cardinality == 0:\n                #     continue\n                if untype_path(c.name) == full_path:\n                    output.append(c)\n            if output:\n                return output\n        return []", "response": "RETURN ALL COLUMNS THAT column_name REFERS TO THE QUERY_PATH"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmapping from the name of the class to the es_column NAME", "response": "def map_to_es(self):\n        \"\"\"\n        RETURN A MAP FROM THE NAMESPACE TO THE es_column NAME\n        \"\"\"\n        output = {}\n        for path in self.query_path:\n            set_default(\n                output,\n                {\n                    k: c.es_column\n                    for c in self.columns\n                    if c.jx_type not in STRUCT\n                    for rel_name in [relative_field(c.name, path)]\n                    for k in [rel_name, untype_path(rel_name), unnest_path(rel_name)]\n                }\n            )\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_decoders_by_path(query):\n    schema = query.frum.schema\n    output = Data()\n\n    if query.edges:\n        if query.sort and query.format != \"cube\":\n            # REORDER EDGES/GROUPBY TO MATCH THE SORT\n            query.edges = sort_edges(query, \"edges\")\n    elif query.groupby:\n        if query.sort and query.format != \"cube\":\n            query.groupby = sort_edges(query, \"groupby\")\n\n    for edge in wrap(coalesce(query.edges, query.groupby, [])):\n        limit = coalesce(edge.domain.limit, query.limit, DEFAULT_LIMIT)\n        if edge.value != None and not edge.value is NULL:\n            edge = edge.copy()\n            vars_ = edge.value.vars()\n            for v in vars_:\n                if not schema.leaves(v.var):\n                    Log.error(\"{{var}} does not exist in schema\", var=v)\n        elif edge.range:\n            vars_ = edge.range.min.vars() | edge.range.max.vars()\n            for v in vars_:\n                if not schema[v.var]:\n                    Log.error(\"{{var}} does not exist in schema\", var=v)\n        elif edge.domain.dimension:\n            vars_ = edge.domain.dimension.fields\n            edge.domain.dimension = edge.domain.dimension.copy()\n            edge.domain.dimension.fields = [schema[v].es_column for v in vars_]\n        elif all(edge.domain.partitions.where):\n            vars_ = set()\n            for p in edge.domain.partitions:\n                vars_ |= p.where.vars()\n\n        vars_ |= edge.value.vars()\n        depths = set(c.nested_path[0] for v in vars_ for c in schema.leaves(v.var))\n        if not depths:\n            Log.error(\n                \"Do not know of column {{column}}\",\n                column=unwraplist([v for v in vars_ if schema[v] == None])\n            )\n        if len(depths) > 1:\n            Log.error(\"expression {{expr|quote}} spans tables, can not handle\", expr=edge.value)\n\n        decoder = AggsDecoder(edge, query, limit)\n        output[literal_field(first(depths))] += [decoder]\n    return output", "response": "Returns a list of all decoders that match the given query path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndigging INTO ES'S RECURSIVE aggs DATA-STRUCTURE: RETURN AN ITERATOR OVER THE EFFECTIVE ROWS OF THE RESULTS :param aggs: ES AGGREGATE OBJECT :param es_query: THE ABSTRACT ES QUERY WE WILL TRACK ALONGSIDE aggs :param decoders: TO CONVERT PARTS INTO COORDINATES", "response": "def aggs_iterator(aggs, es_query, decoders, give_me_zeros=False):\n    \"\"\"\n    DIG INTO ES'S RECURSIVE aggs DATA-STRUCTURE:\n    RETURN AN ITERATOR OVER THE EFFECTIVE ROWS OF THE RESULTS\n\n    :param aggs: ES AGGREGATE OBJECT\n    :param es_query: THE ABSTRACT ES QUERY WE WILL TRACK ALONGSIDE aggs\n    :param decoders: TO CONVERT PARTS INTO COORDINATES\n    \"\"\"\n    coord = [0] * len(decoders)\n    parts = deque()\n    stack = []\n\n    gen = _children(aggs, es_query.children)\n    while True:\n        try:\n            index, c_agg, c_query, part = gen.next()\n        except StopIteration:\n            try:\n                gen = stack.pop()\n            except IndexError:\n                return\n            parts.popleft()\n            continue\n\n        if c_agg.get('doc_count') == 0 and not give_me_zeros:\n            continue\n        parts.appendleft(part)\n        for d in c_query.decoders:\n            coord[d.edge.dim] = d.get_index(tuple(p for p in parts if p is not None), c_query, index)\n\n        children = c_query.children\n        selects = c_query.selects\n        if selects or not children:\n            parts.popleft()  # c_agg WAS ON TOP\n            yield (\n                tuple(p for p in parts if p is not None),\n                tuple(coord),\n                c_agg,\n                selects\n            )\n            continue\n\n        stack.append(gen)\n        gen = _children(c_agg, children)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates an empty document that follows spec with default value set to None.", "response": "def make_default(spec):\n    \"\"\"Create an empty document that follows spec.  Any field with a default\n    will take that value, required or not.  Required fields with no default\n    will get a value of None.  If your default value does not match your\n    type or otherwise customized Field class, this can create a spec that\n    fails validation.\"\"\"\n    doc = {}\n    for key, field in spec.iteritems():\n        if field.default is not no_default:\n            doc[key] = field.default\n    return doc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(document, spec):\n    if not spec:\n        return True\n    missing = []\n    for key, field in spec.iteritems():\n        if field.required and key not in document:\n            missing.append(key)\n\n    failed = []\n    for key, field in spec.iteritems():\n        if key in document:\n            try: document[key] = field.validate(document[key])\n            except ValueError: failed.append(key)\n\n    if missing or failed:\n        if missing and not failed:\n            raise ValueError(\"Required fields missing: %s\" % (missing))\n        if failed and not missing:\n            raise ValueError(\"Keys did not match spec: %s\" % (failed))\n        raise ValueError(\"Missing fields: %s, Invalid fields: %s\" % (missing, failed))\n    # just a token of my kindness, a return for you\n    return True", "response": "Validate that a document meets a specification. Returns True if validation was successful but otherwise raises a ValueError."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef typecheck(self, t):\n        if t is None:\n            return lambda x: True\n\n        def _isinstance(types, value):\n            return isinstance(value, types)\n\n        def _enum(values, value):\n            return value in values\n\n        if t.__class__ is type:\n            return partial(_isinstance, t)\n        elif isinstance(t, (tuple, list)):\n            if all([x.__class__ is type for x in t]):\n                return partial(_isinstance, t)\n            return partial(_enum, t)\n        elif callable(t):\n            return t\n        raise TypeError('%r is not a valid field type' % r)", "response": "Create a typecheck from some value t."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate a value for this field.", "response": "def validate(self, value):\n        \"\"\"Validate a value for this field.  If the field is invalid, this\n        will raise a ValueError.  Runs ``pre_validate`` hook prior to\n        validation, and returns value if validation passes.\"\"\"\n        value = self.pre_validate(value)\n        if not self._typecheck(value):\n            raise ValueError('%r failed type check' % value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate all the tables needed for the service.", "response": "def init_db(self):\n        '''\n        Creates all the tables, and indexes needed for the service.\n\n        :return: None\n        '''\n        with self.conn.transaction() as t:\n            t.execute('''\n            CREATE TABLE temporal (\n                tuid     INTEGER,\n                revision CHAR(12) NOT NULL,\n                file     TEXT,\n                line     INTEGER\n            );''')\n\n            t.execute('''\n            CREATE TABLE annotations (\n                revision       CHAR(12) NOT NULL,\n                file           TEXT,\n                annotation     TEXT,\n                PRIMARY KEY(revision, file)\n            );''')\n\n            # Used in frontier updating\n            t.execute('''\n            CREATE TABLE latestFileMod (\n                file           TEXT,\n                revision       CHAR(12) NOT NULL,\n                PRIMARY KEY(file)\n            );''')\n\n            t.execute(\"CREATE UNIQUE INDEX temporal_rev_file ON temporal(revision, file, line)\")\n        Log.note(\"Tables created successfully\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the TUIDs for the files modified by a revision.", "response": "def get_tuids_from_revision(self, revision):\n        \"\"\"\n        Gets the TUIDs for the files modified by a revision.\n\n        :param revision: revision to get files from\n        :return: list of (file, list(tuids)) tuples\n        \"\"\"\n        result = []\n        URL_TO_FILES = self.hg_url / self.config.hg.branch / 'json-info' / revision\n        try:\n            mozobject = http.get_json(url=URL_TO_FILES, retry=RETRY)\n        except Exception as e:\n            Log.warning(\"Unexpected error trying to get file list for revision {{revision}}\", cause=e)\n            return None\n\n        files = mozobject[revision]['files']\n\n        results = self.get_tuids(files, revision)\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_branch(self, revision, branch):\n        '''\n        Used to find out if the revision is in the given branch.\n\n        :param revision: Revision to check.\n        :param branch: Branch to check revision on.\n        :return: True/False - Found it/Didn't find it\n        '''\n\n        # Get a changelog\n        clog_url = self.hg_url / branch / 'json-log' / revision\n        try:\n            Log.note(\"Searching through changelog {{url}}\", url=clog_url)\n            clog_obj = http.get_json(clog_url, retry=RETRY)\n            if isinstance(clog_obj, (text_type, str)):\n                Log.note(\n                    \"Revision {{cset}} does not exist in the {{branch}} branch\",\n                    cset=revision, branch=branch\n                )\n                return False\n        except Exception as e:\n            Log.note(\"Unexpected error getting changset-log for {{url}}: {{error}}\", url=clog_url, error=e)\n            return False\n        return True", "response": "Check if the revision is in the given branch."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_tuids_from_files(\n            self,\n            files,\n            revision,\n            going_forward=False,\n            repo=None,\n            use_thread=True,\n            max_csets_proc=30\n        ):\n        \"\"\"\n        Gets the TUIDs for a set of files, at a given revision.\n        list(tuids) is an array of tuids, one tuid for each line, in order, and `null` if no tuid assigned\n\n        Uses frontier updating to build and maintain the tuids for\n        the given set of files. Use changelog to determine what revisions\n        to process and get the files that need to be updated by looking\n        at the diffs. If the latestFileMod table is empty, for any file,\n        we perform an annotation-based update.\n\n        This function assumes the newest file names are given, if they\n        are not, then no TUIDs are returned for that file.\n\n        IMPORTANT:\n        If repo is set to None, the service will check if the revision is in\n        the correct branch (to prevent catastrophic failures down the line) - this\n        results in one extra changeset log call per request.\n        If repo is set to something other than None, then we assume that the caller has already\n        checked this and is giving a proper branch for the revision.\n\n        :param files: list of files\n        :param revision: revision to get files at\n        :param repo: Branch to get files from (mozilla-central, or try)\n        :param disable_thread: Disables the thread that spawns if the number of files to process exceeds the\n                               threshold set by FILES_TO_PROCESS_THRESH.\n        :param going_forward: When set to true, the frontiers always get updated to the given revision\n                              even if we can't find a file's frontier. Otherwise, if a frontier is too far,\n                              the latest revision will not be updated.\n        :return: The following tuple which contains:\n                    ([list of (file, list(tuids)) tuples], True/False if completed or not)\n        \"\"\"\n        completed = True\n\n        if repo is None:\n            repo = self.config.hg.branch\n            check = self._check_branch(revision, repo)\n            if not check:\n                # Error was already output by _check_branch\n                return [(file, []) for file in files], completed\n\n        if repo in ('try',):\n            # We don't need to keep latest file revisions\n            # and other related things for this condition.\n\n            # Enable the 'try' repo calls with ENABLE_TRY\n            if ENABLE_TRY:\n                return self._get_tuids_from_files_try_branch(files, revision), completed\n            return [(file, []) for file in files], completed\n\n        result = []\n        revision = revision[:12]\n        files = [file.lstrip('/') for file in files]\n        frontier_update_list = []\n\n        total = len(files)\n        latestFileMod_inserts = {}\n        new_files = []\n\n        log_existing_files = []\n        for count, file in enumerate(files):\n            # Go through all requested files and\n            # either update their frontier or add\n            # them to the DB through an initial annotation.\n\n            if DEBUG:\n                Log.note(\" {{percent|percent(decimal=0)}}|{{file}}\", file=file, percent=count / total)\n\n            with self.conn.transaction() as t:\n                latest_rev = self._get_latest_revision(file, transaction=t)\n                already_ann = self._get_annotation(revision, file, transaction=t)\n\n            # Check if the file has already been collected at\n            # this revision and get the result if so\n            if already_ann:\n                result.append((file,self.destringify_tuids(already_ann)))\n                if going_forward:\n                    latestFileMod_inserts[file] = (file, revision)\n                log_existing_files.append('exists|' + file)\n                continue\n            elif already_ann == '':\n                result.append((file,[]))\n                if going_forward:\n                    latestFileMod_inserts[file] = (file, revision)\n                log_existing_files.append('removed|' + file)\n                continue\n\n            if (latest_rev and latest_rev[0] != revision):\n                # File has a frontier, let's update it\n                if DEBUG:\n                    Log.note(\"Will update frontier for file {{file}}.\", file=file)\n                frontier_update_list.append((file, latest_rev[0]))\n            elif latest_rev == revision:\n                with self.conn.transaction() as t:\n                    t.execute(\"DELETE FROM latestFileMod WHERE file = \" + quote_value(file))\n                new_files.append(file)\n                Log.note(\n                    \"Missing annotation for existing frontier - readding: \"\n                    \"{{rev}}|{{file}} \",\n                    file=file, rev=revision\n                )\n            else:\n                Log.note(\n                    \"Frontier update - adding: \"\n                    \"{{rev}}|{{file}} \",\n                    file=file, rev=revision\n                )\n                new_files.append(file)\n\n        if DEBUG:\n            Log.note(\n                \"Frontier update - already exist in DB: \"\n                \"{{rev}} || {{file_list}} \",\n                file_list=str(log_existing_files), rev=revision\n            )\n        else:\n            Log.note(\n                \"Frontier update - already exist in DB for {{rev}}: \"\n                    \"{{count}}/{{total}} | {{percent|percent}}\",\n                count=str(len(log_existing_files)), total=str(len(files)),\n                rev=revision, percent=len(log_existing_files)/len(files)\n            )\n\n        if len(latestFileMod_inserts) > 0:\n            with self.conn.transaction() as transaction:\n                for _, inserts_list in jx.groupby(latestFileMod_inserts.values(), size=SQL_BATCH_SIZE):\n                    transaction.execute(\n                        \"INSERT OR REPLACE INTO latestFileMod (file, revision) VALUES \" +\n                        sql_list(quote_list(i) for i in inserts_list)\n                    )\n\n        def update_tuids_in_thread(\n                new_files,\n                frontier_update_list,\n                revision,\n                using_thread,\n                please_stop=None\n            ):\n            try:\n                # Processes the new files and files which need their frontier updated\n                # outside of the main thread as this can take a long time.\n                result = []\n\n                latestFileMod_inserts = {}\n                if len(new_files) > 0:\n                    # File has never been seen before, get it's initial\n                    # annotation to work from in the future.\n                    tmp_res = self.get_tuids(new_files, revision, commit=False)\n                    if tmp_res:\n                        result.extend(tmp_res)\n                    else:\n                        Log.note(\"Error occured for files \" + str(new_files) + \" in revision \" + revision)\n\n                    # If this file has not been seen before,\n                    # add it to the latest modifications, else\n                    # it's already in there so update its past\n                    # revisions.\n                    for file in new_files:\n                        latestFileMod_inserts[file] = (file, revision)\n\n                Log.note(\"Finished updating frontiers. Updating DB table `latestFileMod`...\")\n                if len(latestFileMod_inserts) > 0:\n                    with self.conn.transaction() as transaction:\n                        for _, inserts_list in jx.groupby(latestFileMod_inserts.values(), size=SQL_BATCH_SIZE):\n                            transaction.execute(\n                                \"INSERT OR REPLACE INTO latestFileMod (file, revision) VALUES \" +\n                                sql_list(quote_list(i) for i in inserts_list)\n                            )\n\n                # If we have files that need to have their frontier updated, do that now\n                if len(frontier_update_list) > 0:\n                    tmp = self._update_file_frontiers(\n                        frontier_update_list,\n                        revision,\n                        going_forward=going_forward,\n                        max_csets_proc=max_csets_proc\n                    )\n                    result.extend(tmp)\n\n                if using_thread:\n                    self.pcdaemon.update_totals(0, len(result))\n                Log.note(\"Completed work overflow for revision {{cset}}\", cset=revision)\n                return result\n            except Exception as e:\n                Log.warning(\"Thread dead becasue of problem\", cause=e)\n                return []\n\n        threaded = False\n        if use_thread:\n            # If there are too many files to process, start a thread to do\n            # that work and return completed as False.\n            if (len(new_files) + len(frontier_update_list) > FILES_TO_PROCESS_THRESH):\n                threaded = True\n\n        if threaded:\n            completed = False\n            Log.note(\"Incomplete response given\")\n            Thread.run(\n                'get_tuids_from_files (' + Random.base64(9) + \")\",\n                update_tuids_in_thread, new_files, frontier_update_list, revision, threaded\n            )\n        else:\n            result.extend(\n                update_tuids_in_thread(new_files, frontier_update_list, revision, threaded)\n            )\n\n        self.pcdaemon.update_totals(len(files), len(result))\n        return result, completed", "response": "This function returns the list of tuids for a given set of files at a given revision."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing an annotation ([(tuid,line)] - array of TuidMap objects), we change the line numbers to reflect a given diff and return them. diff must be a diff object returned from get_diff(cset, file). Only for going forward in time, not back. :param annotation: list of TuidMap objects :param diff: unified diff from get_diff :param cset: revision to apply diff at :param file: name of file diff is applied to :return:", "response": "def _apply_diff(self, transaction, annotation, diff, cset, file):\n        '''\n        Using an annotation ([(tuid,line)] - array\n        of TuidMap objects), we change the line numbers to\n        reflect a given diff and return them. diff must\n        be a diff object returned from get_diff(cset, file).\n        Only for going forward in time, not back.\n\n        :param annotation: list of TuidMap objects\n        :param diff: unified diff from get_diff\n        :param cset: revision to apply diff at\n        :param file: name of file diff is applied to\n        :return:\n        '''\n        # Ignore merges, they have duplicate entries.\n        if diff['merge']:\n            return annotation, file\n        if file.lstrip('/') == 'dev/null':\n            return [], file\n\n        list_to_insert = []\n        new_ann = [x for x in annotation]\n        new_ann.sort(key=lambda x: x.line)\n\n        def add_one(tl_tuple, lines):\n            start = tl_tuple.line\n            return lines[:start-1] + [tl_tuple] + [TuidMap(tmap.tuid, int(tmap.line) + 1) for tmap in lines[start-1:]]\n\n        def remove_one(start, lines):\n            return lines[:start-1] + [TuidMap(tmap.tuid, int(tmap.line) - 1) for tmap in lines[start:]]\n\n        for f_proc in diff['diffs']:\n            new_fname = f_proc['new'].name.lstrip('/')\n            old_fname = f_proc['old'].name.lstrip('/')\n            if new_fname != file and old_fname != file:\n                continue\n            if old_fname != new_fname:\n                if new_fname == 'dev/null':\n                    return [], file\n                # Change the file name so that new tuids\n                # are correctly created.\n                file = new_fname\n\n            f_diff = f_proc['changes']\n            for change in f_diff:\n                if change.action == '+':\n                    tuid_tmp = self._get_one_tuid(transaction, cset, file, change.line+1)\n                    if not tuid_tmp:\n                        new_tuid = self.tuid()\n                        list_to_insert.append((new_tuid, cset, file, change.line+1))\n                    else:\n                        new_tuid = tuid_tmp[0]\n                    new_ann = add_one(TuidMap(new_tuid, change.line+1), new_ann)\n                elif change.action == '-':\n                    new_ann = remove_one(change.line+1, new_ann)\n            break # Found the file, exit searching\n\n        if len(list_to_insert) > 0:\n            count = 0\n            for _, inserts_list in jx.groupby(list_to_insert, size=SQL_BATCH_SIZE):\n                transaction.execute(\n                    \"INSERT INTO temporal (tuid, revision, file, line)\"\n                    \" VALUES \" +\n                    sql_list(quote_list(tp) for tp in inserts_list)\n                )\n\n        return new_ann, file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_tuids_from_files_try_branch(self, files, revision):\n        '''\n        Gets files from a try revision. It abuses the idea that try pushes\n        will come from various, but stable points (if people make many\n        pushes on that revision). Furthermore, updates are generally done\n        to a revision that should eventually have tuids already in the DB\n        (i.e. overtime as people update to revisions that have a tuid annotation).\n\n        :param files: Files to query.\n        :param revision: Revision to get them at.\n        :return: List of (file, tuids) tuples.\n        '''\n\n        repo = 'try'\n        result = []\n        log_existing_files = []\n        files_to_update = []\n\n        # Check if the files were already annotated.\n        for file in files:\n            with self.conn.transaction() as t:\n                already_ann = self._get_annotation(revision, file, transaction=t)\n            if already_ann:\n                result.append((file, self.destringify_tuids(already_ann)))\n                log_existing_files.append('exists|' + file)\n                continue\n            elif already_ann[0] == '':\n                result.append((file, []))\n                log_existing_files.append('removed|' + file)\n                continue\n            else:\n                files_to_update.append(file)\n\n        if len(log_existing_files) > 0:\n            Log.note(\n                \"Try revision run - existing entries: {{count}}/{{total}} | {{percent}}\",\n                count=str(len(log_existing_files)),\n                total=str(len(files)),\n                percent=str(100*(len(log_existing_files)/len(files)))\n            )\n\n        if len(files_to_update) <= 0:\n            Log.note(\"Found all files for try revision request: {{cset}}\", cset=revision)\n            return result\n\n        # There are files to process, so let's find all the diffs.\n        found_mc_patch = False\n        diffs_to_get = [] # Will contain diffs in reverse order of application\n        curr_rev = revision\n        mc_revision = ''\n        while not found_mc_patch:\n            jsonrev_url = self.hg_url / repo / 'json-rev' / curr_rev\n            try:\n                Log.note(\"Searching through changelog {{url}}\", url=jsonrev_url)\n                clog_obj = http.get_json(jsonrev_url, retry=RETRY)\n                if isinstance(clog_obj, (text_type, str)):\n                    Log.error(\n                        \"Revision {{cset}} does not exist in the {{branch}} branch\",\n                        cset=curr_rev, branch=repo\n                    )\n                if 'phase' not in clog_obj:\n                    Log.warning(\n                        \"Unexpected error getting changset-log for {{url}}: `phase` entry cannot be found.\",\n                        url=jsonrev_url\n                    )\n                    return [(file, []) for file in files]\n            except Exception as e:\n                Log.warning(\n                    \"Unexpected error getting changset-log for {{url}}: {{error}}\",\n                    url=jsonrev_url, error=e\n                )\n                return [(file, []) for file in files]\n\n            # When `phase` is public, the patch is (assumed to be)\n            # in any repo other than try.\n            if clog_obj['phase'] == 'public':\n                found_mc_patch = True\n                mc_revision = curr_rev\n                continue\n            elif clog_obj['phase'] == 'draft':\n                diffs_to_get.append(curr_rev)\n            else:\n                Log.warning(\n                    \"Unknown `phase` state `{{state}}` encountered at revision {{cset}}\",\n                    cset=curr_rev, state=clog_obj['phase']\n                )\n                return [(file, []) for file in files]\n            curr_rev = clog_obj['parents'][0][:12]\n\n        added_files = {}\n        removed_files = {}\n        files_to_process = {}\n\n        Log.note(\"Gathering diffs for: {{csets}}\", csets=str(diffs_to_get))\n        all_diffs = self.get_diffs(diffs_to_get, repo=repo)\n\n        # Build a dict for faster access to the diffs\n        parsed_diffs = {entry['cset']: entry['diff'] for entry in all_diffs}\n        for csets_diff in all_diffs:\n            cset_len12 = csets_diff['cset']\n            parsed_diff = csets_diff['diff']['diffs']\n\n            for f_added in parsed_diff:\n                # Get new entries for removed files.\n                new_name = f_added['new'].name.lstrip('/')\n                old_name = f_added['old'].name.lstrip('/')\n\n                # If we don't need this file, skip it\n                if new_name not in files_to_update:\n                    # If the file was removed, set a\n                    # flag and return no tuids later.\n                    if new_name == 'dev/null':\n                        removed_files[old_name] = True\n                    continue\n\n                if old_name == 'dev/null':\n                    added_files[new_name] = True\n                    continue\n\n                if new_name in files_to_process:\n                    files_to_process[new_name].append(cset_len12)\n                else:\n                    files_to_process[new_name] = [cset_len12]\n\n        # We've found a good patch (a public one), get it\n        # for all files and apply the patch's onto it.\n        curr_annotations = self.get_tuids(files, mc_revision, commit=False)\n        curr_annots_dict = {file: mc_annot for file, mc_annot in curr_annotations}\n\n        anns_to_get = []\n        ann_inserts = []\n        tmp_results = {}\n\n        with self.conn.transaction() as transaction:\n            for file in files_to_update:\n                if file not in curr_annots_dict:\n                    Log.note(\n                        \"WARNING: Missing annotation entry in mozilla-central branch revision {{cset}} \"\n                        \"for {{file}}\",\n                        file=file, cset=mc_revision\n                    )\n                    # Try getting it from the try revision\n                    anns_to_get.append(file)\n                    continue\n\n                if file in added_files:\n                    Log.note(\"Try revision run - added: {{file}}\", file=file)\n                    anns_to_get.append(file)\n                elif file in removed_files:\n                    Log.note(\"Try revision run - removed: {{file}}\", file=file)\n                    ann_inserts.append((revision, file, ''))\n                    tmp_results[file] = []\n                elif file in files_to_process:\n                    # Reverse the list, we always find the newest diff first\n                    Log.note(\"Try revision run - modified: {{file}}\", file=file)\n                    csets_to_proc = files_to_process[file][::-1]\n                    old_ann = curr_annots_dict[file]\n\n                    # Apply all the diffs\n                    tmp_res = old_ann\n                    new_fname = file\n                    for i in csets_to_proc:\n                        tmp_res, new_fname = self._apply_diff(transaction, tmp_res, parsed_diffs[i], i, new_fname)\n\n                    ann_inserts.append((revision, file, self.stringify_tuids(tmp_res)))\n                    tmp_results[file] = tmp_res\n                else:\n                    # Nothing changed with the file, use it's current annotation\n                    Log.note(\"Try revision run - not modified: {{file}}\", file=file)\n                    ann_inserts.append((revision, file, self.stringify_tuids(curr_annots_dict[file])))\n                    tmp_results[file] = curr_annots_dict[file]\n\n            # Insert and check annotations, get all that were\n            # added by another thread.\n            anns_added_by_other_thread = {}\n            if len(ann_inserts) > 0:\n                ann_inserts = list(set(ann_inserts))\n                for _, tmp_inserts in jx.groupby(ann_inserts, size=SQL_ANN_BATCH_SIZE):\n                    # Check if any were added in the mean time by another thread\n                    recomputed_inserts = []\n                    for rev, filename, tuids in tmp_inserts:\n                        tmp_ann = self._get_annotation(rev, filename, transaction=transaction)\n                        if not tmp_ann:\n                            recomputed_inserts.append((rev, filename, tuids))\n                        else:\n                            anns_added_by_other_thread[filename] = self.destringify_tuids(tmp_ann)\n\n                    try:\n                        self.insert_annotations(transaction, recomputed_inserts)\n                    except Exception as e:\n                        Log.error(\"Error inserting into annotations table.\", cause=e)\n\n        if len(anns_to_get) > 0:\n            result.extend(self.get_tuids(anns_to_get, revision, repo=repo))\n\n        for f in tmp_results:\n            tuids = tmp_results[f]\n            if f in anns_added_by_other_thread:\n                tuids = anns_added_by_other_thread[f]\n            result.append((f, tuids))\n        return result", "response": "Get tuids from files in a try revision branch."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _update_file_frontiers(\n            self,\n            frontier_list,\n            revision,\n            max_csets_proc=30,\n            going_forward=False\n        ):\n        '''\n        Update the frontier for all given files, up to the given revision.\n\n        Built for quick continuous _forward_ updating of large sets\n        of files of TUIDs. Backward updating should be done through\n        get_tuids(files, revision). If we cannot find a frontier, we will\n        stop looking after max_csets_proc and update all files at the given\n        revision.\n\n        :param frontier_list: list of files to update\n        :param revision: revision to update files to\n        :param max_csets_proc: maximum number of changeset logs to look through\n                               to find past frontiers.\n        :param going_forward: If we know the requested revision is in front\n                              of the latest revision use this flag. Used when\n                              the frontier is too far away. If this is not set and\n                              a frontier is too far, the latest revision will not\n                              be updated.\n        :return: list of (file, list(tuids)) tuples\n        '''\n\n        # Get the changelogs and revisions until we find the\n        # last one we've seen, and get the modified files in\n        # each one.\n\n        # Holds the files modified up to the last frontiers.\n        files_to_process = {}\n\n        # Holds all frontiers to find\n        remaining_frontiers = {cset for cset in list(set([frontier for _, frontier in frontier_list]))}\n\n        if len(remaining_frontiers) <= 1 and frontier_list[0][1] == revision:\n            # If the latest revision is the requested revision,\n            # and there is only one frontier requested\n            # continue to the tuid querys.\n            remaining_frontiers = {}\n\n        # Revision we are searching from\n        final_rev = revision\n\n        # If this exceeds max_csets_proc,\n        # all frontiers not found are considered lost\n        csets_proced = 0\n\n        # Holds info on how to apply the diffs onto each frontier,\n        # and all known frontiers.\n        diffs_to_frontier = {cset: [] for cset in remaining_frontiers}\n\n        Log.note(\"Searching for frontier(s): {{frontier}} \", frontier=str(list(remaining_frontiers)))\n        Log.note(\n            \"Running on revision with HG URL: {{url}}\",\n            url=self.hg_url / self.config.hg.branch / 'rev' / revision\n        )\n        while remaining_frontiers:\n            # Get a changelog\n            clog_url = self.hg_url / self.config.hg.branch / 'json-log' / final_rev\n            try:\n                Log.note(\"Searching through changelog {{url}}\", url=clog_url)\n                clog_obj = http.get_json(clog_url, retry=RETRY)\n                if isinstance(clog_obj, (text_type, str)):\n                    Log.error(\n                        \"Revision {{cset}} does not exist in the {{branch}} branch\",\n                        cset=final_rev, branch=self.config.hg.branch\n                    )\n            except Exception as e:\n                Log.error(\n                    \"Unexpected error getting changset-log for {{url}}: {{error}}\",\n                    url=clog_url,\n                    error=e\n                )\n\n            # For each changeset in the log (except the last one\n            # which is duplicated on the next log page requested.\n            clog_obj_list = list(clog_obj['changesets'])\n            for clog_cset in clog_obj_list[:-1]:\n                nodes_cset = clog_cset['node'][:12]\n\n                if remaining_frontiers:\n                    if nodes_cset in remaining_frontiers:\n                        # Found a frontier, remove it from search list.\n                        remaining_frontiers.remove(nodes_cset)\n\n                        if not remaining_frontiers:\n                            # Found all frontiers, get out of the loop before\n                            # we add the diff to a frontier update list.\n                            break\n\n                    # Add this diff to the processing list\n                    # for each remaining frontier\n                    for cset in diffs_to_frontier:\n                        if cset in remaining_frontiers:\n                            diffs_to_frontier[cset].append(nodes_cset)\n\n            csets_proced += 1\n            if not remaining_frontiers:\n                # End searching\n                break\n            elif csets_proced >= max_csets_proc:\n                # In this case, all files need to be updated to this revision to ensure\n                # line ordering consistency (between past, and future) when a revision\n                # that is in the past is asked for.\n                files_to_process = {file: [revision] for file, _ in frontier_list}\n                break\n            else:\n                # Go to the next log page\n                last_entry = clog_obj_list[-1]\n                final_rev = last_entry['node'][:12]\n\n        if not remaining_frontiers:\n            Log.note(\"Found all frontiers: {{frontiers_list}}\", frontiers_list=str(list(diffs_to_frontier.keys())))\n        else:\n            found_frontiers = [\n                frontier for frontier in diffs_to_frontier if frontier not in remaining_frontiers\n            ]\n            Log.note(\"Found frontiers: {{found}}\", found=str(found_frontiers))\n            Log.note(\"Did not find frontiers: {{not_found}}\", not_found=str(list(remaining_frontiers)))\n\n        added_files = {}\n        removed_files = {}\n        parsed_diffs = {}\n\n        # This list is used to determine what files\n        file_to_frontier = {file: frontier for file, frontier in frontier_list}\n        if len(remaining_frontiers) != len(diffs_to_frontier.keys()):\n            # If there is at least one frontier that was found\n            # Only get diffs that are needed (if any frontiers were not found)\n            diffs_cache = []\n            for cset in diffs_to_frontier:\n                if cset not in remaining_frontiers:\n                    diffs_cache.extend(diffs_to_frontier[cset])\n\n            Log.note(\"Gathering diffs for: {{csets}}\", csets=str(diffs_cache))\n            all_diffs = self.get_diffs(diffs_cache)\n\n            # Build a dict for faster access to the diffs,\n            # to be used later when applying them.\n            parsed_diffs = {diff_entry['cset']: diff_entry['diff'] for diff_entry in all_diffs}\n\n            # In case the file name changes, this will map\n            # the requested file to the new file name so\n            # diffs can all be gathered.\n            filenames_to_seek = {}\n\n            # Parse diffs for files to process and store diffs to\n            # apply for each file in files_to_process.\n            added_and_removed_counts = {file: 1 for file in file_to_frontier}\n            for csets_diff in all_diffs:\n                cset_len12 = csets_diff['cset']\n                parsed_diff = csets_diff['diff']['diffs']\n\n                for f_added in parsed_diff:\n                    # Get new entries for removed files.\n                    new_name = f_added['new'].name.lstrip('/')\n                    old_name = f_added['old'].name.lstrip('/')\n\n                    # If we don't need this file, skip it\n                    if new_name not in file_to_frontier and \\\n                       new_name not in filenames_to_seek:\n                        if old_name not in file_to_frontier and \\\n                           old_name not in filenames_to_seek:\n                            # File not requested\n                            continue\n                        if new_name == 'dev/null':\n                            frontier_filename = old_name\n                            while frontier_filename in filenames_to_seek:\n                                frontier_filename = filenames_to_seek[frontier_filename]\n\n                            if frontier_filename not in removed_files:\n                                removed_files[frontier_filename] = 0\n                            removed_files[frontier_filename] = added_and_removed_counts[frontier_filename]\n                            added_and_removed_counts[frontier_filename] += 1\n                            continue\n\n                    if old_name == 'dev/null':\n                        frontier_filename = new_name\n                        while frontier_filename in filenames_to_seek:\n                            frontier_filename = filenames_to_seek[frontier_filename]\n\n                        if frontier_filename not in added_files:\n                            added_files[frontier_filename] = 0\n                        added_files[frontier_filename] = added_and_removed_counts[frontier_filename]\n                        added_and_removed_counts[frontier_filename] += 1\n                        continue\n                    if new_name != old_name:\n                        # File name was changed, keep the diff anyway\n                        # to add any changes it makes.\n                        filenames_to_seek[new_name] = old_name\n\n                    # Get the originally requested file name\n                    # by following filenames_to_seek entries\n                    frontier_filename = new_name\n                    while frontier_filename in filenames_to_seek:\n                        frontier_filename = filenames_to_seek[frontier_filename]\n\n                    # If we are past the frontier for this file,\n                    # or if we are at the frontier skip it.\n                    if file_to_frontier[frontier_filename] == '':\n                        # Previously found frontier, skip\n                        continue\n\n                    # At this point, file is in the database, is\n                    # asked to be processed, and we are still\n                    # searching for the last frontier.\n                    if file_to_frontier[frontier_filename] == cset_len12:\n                        file_to_frontier[frontier_filename] = ''\n                        # Found the frontier, skip\n                        continue\n\n                    if old_name != new_name:\n                        Log.note(\n                            \"{{cset}} changes a requested file's name: {{file}} from {{oldfile}}. \",\n                            file=new_name,\n                            oldfile=old_name,\n                            cset=cset\n                        )\n\n                    # Store the diff as it needs to be applied\n                    if frontier_filename in files_to_process:\n                        files_to_process[frontier_filename].append(cset_len12)\n                    else:\n                        files_to_process[frontier_filename] = [cset_len12]\n\n        # Process each file that needs it based on the\n        # files_to_process list.\n        result = []\n        ann_inserts = []\n        latestFileMod_inserts = {}\n        anns_to_get = []\n        total = len(frontier_list)\n        tmp_results = {}\n\n        with self.conn.transaction() as transaction:\n            for count, (file, old_frontier) in enumerate(frontier_list):\n                if old_frontier in remaining_frontiers:\n                    # If we were still looking for the frontier by the end, get a new\n                    # annotation for this file.\n                    anns_to_get.append(file)\n\n                    if going_forward:\n                        # If we are always going forward, update the frontier\n                        latestFileMod_inserts[file] = (file, revision)\n\n                    Log.note(\n                        \"Frontier update - can't find frontier {{lost_frontier}}: \"\n                        \"{{count}}/{{total}} - {{percent|percent(decimal=0)}} | {{rev}}|{{file}} \",\n                        count=count,\n                        total=total,\n                        file=file,\n                        rev=revision,\n                        percent=count / total,\n                        lost_frontier=old_frontier\n                    )\n                    continue\n                elif file in removed_files or file in added_files:\n                    if file not in removed_files:\n                        removed_files[file] = 0\n                    if file not in added_files:\n                        added_files[file] = 0\n\n                    if removed_files[file] <= added_files[file]:\n                        # For it to still exist it has to be\n                        # added last (to give it a larger count)\n                        anns_to_get.append(file)\n                        Log.note(\n                            \"Frontier update - adding: \"\n                            \"{{count}}/{{total}} - {{percent|percent(decimal=0)}} | {{rev}}|{{file}} \",\n                            count=count,\n                            total=total,\n                            file=file,\n                            rev=revision,\n                            percent=count / total,\n                            lost_frontier=old_frontier\n                        )\n                    else:\n                        Log.note(\n                            \"Frontier update - deleting: \"\n                            \"{{count}}/{{total}} - {{percent|percent(decimal=0)}} | {{rev}}|{{file}} \",\n                            count=count,\n                            total=total,\n                            file=file,\n                            rev=revision,\n                            percent=count / total,\n                            lost_frontier=old_frontier\n                        )\n                        tmp_results[file] = []\n                    if going_forward:\n                        # If we are always going forward, update the frontier\n                        latestFileMod_inserts[file] = (file, revision)\n\n                    continue\n\n                # If the file was modified, get it's newest\n                # annotation and update the file.\n                tmp_res = None\n                if file in files_to_process:\n                    # Process this file using the diffs found\n                    tmp_ann = self._get_annotation(old_frontier, file, transaction)\n                    if tmp_ann is None or tmp_ann == '' or self.destringify_tuids(tmp_ann) is None:\n                        Log.warning(\n                            \"{{file}} has frontier but can't find old annotation for it in {{rev}}, \"\n                            \"restarting it's frontier.\",\n                            rev=old_frontier,\n                            file=file\n                        )\n                        anns_to_get.append(file)\n                    else:\n                        # File was modified, apply it's diffs\n                        # Reverse the diff list, we always find the newest diff first\n                        csets_to_proc = files_to_process[file][::-1]\n                        tmp_res = self.destringify_tuids(tmp_ann)\n                        new_fname = file\n                        for i in csets_to_proc:\n                            tmp_res, new_fname = self._apply_diff(transaction, tmp_res, parsed_diffs[i], i, new_fname)\n\n                        ann_inserts.append((revision, file, self.stringify_tuids(tmp_res)))\n                        Log.note(\n                            \"Frontier update - modified: {{count}}/{{total}} - {{percent|percent(decimal=0)}} \"\n                            \"| {{rev}}|{{file}} \",\n                            count=count,\n                            total=total,\n                            file=file,\n                            rev=revision,\n                            percent=count / total\n                        )\n                else:\n                    old_ann = self._get_annotation(old_frontier, file, transaction)\n                    if old_ann is None or (old_ann == '' and file in added_files):\n                        # File is new (likely from an error), or re-added - we need to create\n                        # a new initial entry for this file.\n                        anns_to_get.append(file)\n                        Log.note(\n                            \"Frontier update - readded: {{count}}/{{total}} - {{percent|percent(decimal=0)}} \"\n                            \"| {{rev}}|{{file}} \",\n                            count=count,\n                            total=total,\n                            file=file,\n                            rev=revision,\n                            percent=count / total\n                        )\n                    else:\n                        # File was not modified since last\n                        # known revision\n                        tmp_res = self.destringify_tuids(old_ann) if old_ann != '' else []\n                        ann_inserts.append((revision, file, old_ann))\n                        Log.note(\n                            \"Frontier update - not modified: {{count}}/{{total}} - {{percent|percent(decimal=0)}} \"\n                            \"| {{rev}}|{{file}} \",\n                            count=count,\n                            total=total,\n                            file=file,\n                            rev=revision,\n                            percent=count / total\n                        )\n\n                if tmp_res:\n                    tmp_results[file] = tmp_res\n                else:\n                    Log.note(\n                        \"Error occured for file {{file}} in revision {{revision}}\",\n                        file=file,\n                        revision=revision\n                    )\n                    tmp_results[file] = []\n\n                # If we have found all frontiers, update to the\n                # latest revision. Otherwise, the requested\n                # revision is too far away (can't be sure\n                # if it's past). Unless we are told that we are\n                # going forward.\n                if going_forward or not remaining_frontiers:\n                    latest_rev = revision\n                else:\n                    latest_rev = old_frontier\n                latestFileMod_inserts[file] = (file, latest_rev)\n\n            Log.note(\"Updating DB tables `latestFileMod` and `annotations`...\")\n\n            # No need to double-check if latesteFileMods has been updated before,\n            # we perform an insert or replace any way.\n            if len(latestFileMod_inserts) > 0:\n                for _, inserts_list in jx.groupby(latestFileMod_inserts.values(), size=SQL_BATCH_SIZE):\n                    transaction.execute(\n                        \"INSERT OR REPLACE INTO latestFileMod (file, revision) VALUES \" +\n                        sql_list(quote_list(i) for i in inserts_list)\n                    )\n\n            anns_added_by_other_thread = {}\n            if len(ann_inserts) > 0:\n                ann_inserts = list(set(ann_inserts))\n                for _, tmp_inserts in jx.groupby(ann_inserts, size=SQL_ANN_BATCH_SIZE):\n                    # Check if any were added in the mean time by another thread\n                    recomputed_inserts = []\n                    for rev, filename, string_tuids in tmp_inserts:\n                        tmp_ann = self._get_annotation(rev, filename, transaction)\n                        if not tmp_ann or tmp_ann == '':\n                            recomputed_inserts.append((rev, filename, string_tuids))\n                        else:\n                            anns_added_by_other_thread[filename] = self.destringify_tuids(tmp_ann)\n\n                    if len(recomputed_inserts) <= 0:\n                        continue\n\n                    try:\n                        for rev, filename, tuids_ann in recomputed_inserts:\n                            tmp_ann = self.destringify_tuids(tuids_ann)\n                            for tuid_map in tmp_ann:\n                                if tuid_map is None or tuid_map.tuid is None or tuid_map.line is None:\n                                    Log.warning(\n                                        \"None value encountered in annotation insertion in {{rev}} for {{file}}: {{tuids}}\" ,\n                                        rev=rev, file=filename, tuids=str(tuid_map)\n                                    )\n                        self.insert_annotations(transaction, recomputed_inserts)\n                    except Exception as e:\n                        Log.error(\"Error inserting into annotations table: {{inserting}}\", inserting=recomputed_inserts, cause=e)\n\n        if len(anns_to_get) > 0:\n            result.extend(self.get_tuids(anns_to_get, revision, commit=False))\n\n        for f in tmp_results:\n            tuids = tmp_results[f]\n            if f in anns_added_by_other_thread:\n                tuids = anns_added_by_other_thread[f]\n            result.append((f, tuids))\n        return result", "response": "Update the file frontiers for all given files up to the given revision."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap for _get_tuids that returns a list of tuids for a given revision.", "response": "def get_tuids(self, files, revision, commit=True, chunk=50, repo=None):\n        '''\n        Wrapper for `_get_tuids` to limit the number of annotation calls to hg\n        and separate the calls from DB transactions. Also used to simplify `_get_tuids`.\n\n        :param files:\n        :param revision:\n        :param commit:\n        :param chunk:\n        :param repo:\n        :return:\n        '''\n        results = []\n        revision = revision[:12]\n\n        # For a single file, there is no need\n        # to put it in an array when given.\n        if not isinstance(files, list):\n            files = [files]\n        if repo is None:\n            repo = self.config.hg.branch\n\n        for _, new_files in jx.groupby(files, size=chunk):\n            for count, file in enumerate(new_files):\n                new_files[count] = file.lstrip('/')\n\n            annotations_to_get = []\n            for file in new_files:\n                with self.conn.transaction() as t:\n                    already_ann = self._get_annotation(revision, file, transaction=t)\n                if already_ann:\n                    results.append((file, self.destringify_tuids(already_ann)))\n                elif already_ann == '':\n                    results.append((file, []))\n                else:\n                    annotations_to_get.append(file)\n\n            if not annotations_to_get:\n                # No new annotations to get, so get next set\n                continue\n\n            # Get all the annotations in parallel and\n            # store in annotated_files\n            annotated_files = [None] * len(annotations_to_get)\n            threads = [\n                Thread.run(\n                    str(thread_count),\n                    self._get_hg_annotate,\n                    revision,\n                    annotations_to_get[thread_count],\n                    annotated_files,\n                    thread_count,\n                    repo\n                )\n                for thread_count, _ in enumerate(annotations_to_get)\n            ]\n            for t in threads:\n                t.join()\n\n            # Help for memory, because `chunk` (or a lot of)\n            # threads are started at once.\n            del threads\n\n            with self.conn.transaction() as transaction:\n                results.extend(\n                    self._get_tuids(\n                        transaction, annotations_to_get, revision, annotated_files, commit=commit, repo=repo\n                    )\n                )\n\n        # Help for memory\n        gc.collect()\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_tuids(\n            self,\n            transaction,\n            files,\n            revision,\n            annotated_files,\n            commit=True,\n            repo=None\n        ):\n        '''\n        Returns (TUID, line) tuples for a given file at a given revision.\n\n        Uses json-annotate to find all lines in this revision, then it updates\n        the database with any missing revisions for the file changes listed\n        in annotate. Then, we use the information from annotate coupled with the\n        diff information that was inserted into the DB to return TUIDs. This way\n        we don't have to deal with child, parents, dates, etc..\n\n        :param files: list of files to process\n        :param revision: revision at which to get the file\n        :param annotated_files: annotations for each file\n        :param commit: True to commit new TUIDs else False\n        :param repo: The branch to get tuids from\n        :return: List of TuidMap objects\n        '''\n        results = []\n\n        for fcount, annotated_object in enumerate(annotated_files):\n            file = files[fcount]\n\n            # TODO: Replace old empty annotation if a new one is found\n            # TODO: at the same revision and if it is not empty as well.\n            # Make sure we are not adding the same thing another thread\n            # added.\n            tmp_ann = self._get_annotation(revision, file, transaction=transaction)\n            if tmp_ann != None:\n                results.append((file, self.destringify_tuids(tmp_ann)))\n                continue\n\n            # If it's not defined at this revision, we need to add it in\n            errored = False\n            if isinstance(annotated_object, (text_type, str)):\n                errored = True\n                Log.warning(\n                    \"{{file}} does not exist in the revision={{cset}} branch={{branch_name}}\",\n                    branch_name=repo,\n                    cset=revision,\n                    file=file\n                )\n            elif annotated_object is None:\n                Log.warning(\n                    \"Unexpected error getting annotation for: {{file}} in the revision={{cset}} branch={{branch_name}}\",\n                    branch_name=repo,\n                    cset=revision,\n                    file=file\n                )\n                errored = True\n            elif 'annotate' not in annotated_object:\n                Log.warning(\n                    \"Missing annotate, type got: {{ann_type}}, expecting:dict returned when getting \"\n                    \"annotation for: {{file}} in the revision {{cset}}\",\n                    cset=revision, file=file, ann_type=type(annotated_object)\n                )\n                errored = True\n\n            if errored:\n                Log.note(\"Inserting dummy entry...\")\n                self.insert_tuid_dummy(transaction, revision, file, commit=commit)\n                self.insert_annotate_dummy(transaction, revision, file, commit=commit)\n                results.append((file, []))\n                continue\n\n            # Gather all missing csets and the\n            # corresponding lines.\n            line_origins = []\n            for node in annotated_object['annotate']:\n                cset_len12 = node['node'][:12]\n\n                # If the line added by `cset_len12` is not known\n                # add it. Use the 'abspath' field to determine the\n                # name of the file it was created in (in case it was\n                # changed).\n                line_origins.append((node['abspath'], cset_len12, int(node['targetline'])))\n\n            file_names = list(set([f for f, _, _ in line_origins]))\n            revs_to_find = list(set([rev for _, rev, _ in line_origins]))\n            lines_to_find = list(set([line for _, _, line in line_origins]))\n            existing_tuids_tmp = {\n                str((file, revision, line)): tuid\n                for tuid, file, revision, line in transaction.query(\n                    \"SELECT tuid, file, revision, line FROM temporal\"\n                    \" WHERE file IN \" + quote_list(file_names) +\n                    \" AND revision IN \" + quote_list(revs_to_find) +\n                    \" AND line IN \" + quote_list(lines_to_find)\n                ).data\n            }\n\n            # Recompute existing tuids based on line_origins\n            # entry ordering because we can't order them any other way\n            # since the `line` entry in the `temporal` table is relative\n            # to it's creation date, not the currently requested\n            # annotation.\n            existing_tuids = {\n                (line_num+1): existing_tuids_tmp[str(ann_entry)]\n                for line_num, ann_entry in enumerate(line_origins)\n                if str(ann_entry) in existing_tuids_tmp\n            }\n            new_lines = set([line_num+1 for line_num, _ in enumerate(line_origins)]) - set(existing_tuids.keys())\n\n            # Update DB with any revisions found in annotated\n            # object that are not in the DB.\n            new_line_origins = {}\n            if len(new_lines) > 0:\n                try:\n                    '''\n                        HG Annotate Bug, Issue #58:\n                        Here is where we assign the new tuids for the first\n                        time we see duplicate entries - they are left\n                        in `new_line_origins` after duplicates are found.\n                        We only remove it from the lines to insert. In future\n                        requests, `existing_tuids` above will handle duplicating\n                        tuids for the entries if needed.\n                    '''\n                    new_line_origins = {\n                        line_num: (self.tuid(),) + line_origins[line_num - 1]\n                        for line_num in new_lines\n                    }\n\n                    duplicate_lines = {\n                        line_num+1: line\n                        for line_num, line in enumerate(line_origins)\n                        if line in line_origins[:line_num]\n                    }\n                    if len(duplicate_lines) > 0:\n                        Log.note(\n                            \"Duplicates found in {{file}} at {{cset}}: {{dupes}}\",\n                            file=file,\n                            cset=revision,\n                            dupes=str(duplicate_lines)\n                        )\n                        lines_to_insert = [\n                            line\n                            for line_num, line in new_line_origins.items()\n                            if line_num not in duplicate_lines\n                        ]\n                    else:\n                        lines_to_insert = new_line_origins.values()\n\n                    for _, part_of_insert in jx.groupby(lines_to_insert, size=SQL_BATCH_SIZE):\n                        transaction.execute(\n                            \"INSERT INTO temporal (tuid, file, revision, line)\"\n                            \" VALUES \" +\n                            sql_list(\n                                sql_iso(\n                                    sql_list(map(quote_value, (tuid, f, rev, line_num)))\n                                ) for tuid, f, rev, line_num in list(part_of_insert)\n                            )\n                        )\n\n                    # Format so we don't have to use [0] to get at the tuid\n                    new_line_origins = {line_num: new_line_origins[line_num][0] for line_num in new_line_origins}\n                except Exception as e:\n                    # Something broke for this file, ignore it and go to the\n                    # next one.\n                    Log.note(\"Failed to insert new tuids {{cause}}\", cause=e)\n                    continue\n\n            tuids = []\n            for line_ind, line_origin in enumerate(line_origins):\n                line_num = line_ind + 1\n                if line_num in existing_tuids:\n                    tuids.append(TuidMap(existing_tuids[line_num], line_num))\n                else:\n                    tuids.append(TuidMap(new_line_origins[line_num], line_num))\n\n            self.insert_annotations(\n                transaction,\n                [(\n                    revision,\n                    file,\n                    self.stringify_tuids(tuids)\n                )]\n            )\n            results.append((file, tuids))\n\n        return results", "response": "Returns a list of TUIDs for a given file at a given revision."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning continuously to prefill the temporal and annotations table with the coverage revisions*. * A coverage revision is a revision which has had code coverage run on it. :param please_stop: Used to stop the daemon :return: None", "response": "def _daemon(self, please_stop, only_coverage_revisions=False):\n        '''\n        Runs continuously to prefill the temporal and\n        annotations table with the coverage revisions*.\n\n        * A coverage revision is a revision which has had\n        code coverage run on it.\n\n        :param please_stop: Used to stop the daemon\n        :return: None\n        '''\n        while not please_stop:\n            # Get all known files and their latest revisions on the frontier\n            files_n_revs = self.conn.get(\"SELECT file, revision FROM latestFileMod\")\n\n            # Split these files into groups of revisions to make it\n            # easier to update them. If we group them together, we\n            # may end up updating groups that are new back to older\n            # revisions.\n            revs = {rev: [] for rev in set([file_n_rev[1] for file_n_rev in files_n_revs])}\n            for file_n_rev in files_n_revs:\n                revs[file_n_rev[1]].append(file_n_rev[0])\n\n            # Go through each frontier and update it\n            ran_changesets = False\n            coverage_revisions = None\n            for frontier in revs:\n                if please_stop:\n                    return\n\n                files = revs[frontier]\n\n                # Go through changeset logs until we find the last\n                # known frontier for this revision group.\n                csets = []\n                final_rev = ''\n                found_last_frontier = False\n                Log.note(\"Searching for frontier: {{frontier}} \", frontier=frontier)\n                Log.note(\"HG URL: {{url}}\", url=self.hg_url / self.config.hg.branch / 'rev' / frontier)\n                while not found_last_frontier:\n                    # Get a changelog\n                    clog_url = self.hg_url / self.config.hg.branch / 'json-log' / final_rev\n                    try:\n                        clog_obj = http.get_json(clog_url, retry=RETRY)\n                    except Exception as e:\n                        Log.error(\"Unexpected error getting changset-log for {{url}}\", url=clog_url, error=e)\n\n                    cset = ''\n                    still_looking = True\n                    # For each changeset/node\n                    for clog_cset in clog_obj['changesets']:\n                        cset = clog_cset['node'][:12]\n                        if cset == frontier:\n                            still_looking = False\n                            break\n                        csets.append(cset)\n\n                    if not still_looking:\n                        found_last_frontier = True\n                    final_rev = cset\n\n                # No csets found means that we are already\n                # at the latest revisions.\n                if len(csets) == 0:\n                    continue\n\n                # Get all the latest ccov and jsdcov revisions\n                if (not coverage_revisions) and only_coverage_revisions:\n                    active_data_url = 'http://activedata.allizom.org/query'\n                    query_json = {\n                        \"limit\": 1000,\n                        \"from\": \"task\",\n                        \"where\": {\"and\": [\n                            {\"in\": {\"build.type\": [\"ccov\", \"jsdcov\"]}},\n                            {\"gte\": {\"run.timestamp\": {\"date\": \"today-day\"}}},\n                            {\"eq\": {\"repo.branch.name\": self.config.hg.branch}}\n                        ]},\n                        \"select\": [\n                            {\"aggregate\": \"min\", \"value\": \"run.timestamp\"},\n                            {\"aggregate\": \"count\"}\n                        ],\n                        \"groupby\": [\"repo.changeset.id12\"]\n                    }\n                    coverage_revisions_resp = http.post_json(active_data_url, retry=RETRY, data=query_json)\n                    coverage_revisions = [rev_arr[0] for rev_arr in coverage_revisions_resp.data]\n\n                # Reverse changeset list and for each code coverage revision\n                # found by going through the list from oldest to newest,\n                # update _all known_ file frontiers to that revision.\n                csets.reverse()\n                prev_cset = frontier\n                for cset in csets:\n                    if please_stop:\n                        return\n                    if only_coverage_revisions:\n                        if cset not in coverage_revisions:\n                            continue\n                    if DEBUG:\n                        Log.note(\"Moving frontier {{frontier}} forward to {{cset}}.\", frontier=prev_cset, cset=cset)\n\n                    # Update files\n                    self.get_tuids_from_files(files, cset, going_forward=True)\n\n                    ran_changesets = True\n                    prev_cset = cset\n\n            if not ran_changesets:\n                (please_stop | Till(seconds=DAEMON_WAIT_AT_NEWEST.seconds)).wait()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncollapsing a group by variable.", "response": "def collapsesum(data_frame, by = None, var = None):\n    '''\n    Pour une variable, fonction qui calcule la moyenne pond\u00e9r\u00e9e au sein de chaque groupe.\n    '''\n    assert by is not None\n    assert var is not None\n    grouped = data_frame.groupby([by])\n    return grouped.apply(lambda x: weighted_sum(groupe = x, var =var))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the weighted sum of a variable in a groupe", "response": "def weighted_sum(groupe, var):\n    '''\n    Fonction qui calcule la moyenne pond\u00e9r\u00e9e par groupe d'une variable\n    '''\n    data = groupe[var]\n    weights = groupe['pondmen']\n    return (data * weights).sum()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a subparser with subcommand to the subparsers object.", "response": "def addSubparser(subparsers, subcommand, description):\n    \"\"\"\n    Add a subparser with subcommand to the subparsers object\n    \"\"\"\n    parser = subparsers.add_parser(\n        subcommand, description=description, help=description)\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef createArgumentParser(description):\n    parser = argparse.ArgumentParser(\n        description=description,\n        formatter_class=SortedHelpFormatter)\n    return parser", "response": "Create an argument parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_arguments(self, actions):\n        actions = sorted(\n            actions, key=operator.attrgetter('option_strings'))\n        super(SortedHelpFormatter, self).add_arguments(actions)", "response": "Sort the flags alphabetically"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\niterating the subcommands alphabetically", "response": "def _iter_indented_subactions(self, action):\n        \"\"\"\n        Sort the subcommands alphabetically\n        \"\"\"\n        try:\n            get_subactions = action._get_subactions\n        except AttributeError:\n            pass\n        else:\n            self._indent()\n            if isinstance(action, argparse._SubParsersAction):\n                for subaction in sorted(\n                        get_subactions(), key=lambda x: x.dest):\n                    yield subaction\n            else:\n                for subaction in get_subactions():\n                    yield subaction\n            self._dedent()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls startup. call in your main function.", "response": "def main(argv):\n    \"\"\"Call startup.call() in your main().\"\"\"\n    args = startup.call(argv=argv)['args']\n    if args.v:\n        print('x * y = %d' % (args.x * args.y))\n    else:\n        print(args.x * args.y)\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resource_of_node(resources, node):\n    for resource in resources:\n        model = getattr(resource, 'model', None)\n        if type(node) == model:\n            return resource\n    return BasePageResource", "response": "Returns the resource of the node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all resources and models from config.", "response": "def resources_of_config(config):\n    \"\"\" Returns all resources and models from config.\n    \"\"\"\n    return set(             # unique values\n        sum([               # join lists to flat list\n            list(value)     # if value is iter (ex: list of resources)\n            if hasattr(value, '__iter__')\n            else [value, ]  # if value is not iter (ex: model or resource)\n            for value in config.values()\n        ], [])\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef models_of_config(config):\n    resources = resources_of_config(config)\n    models = []\n    for resource in resources:\n        if not hasattr(resource, '__table__') and hasattr(resource, 'model'):\n            models.append(resource.model)\n        else:\n            models.append(resource)\n    return models", "response": "Return list of models from all resources in config."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the size of the compressed file.", "response": "def zip2bytes(compressed):\n    \"\"\"\n    UNZIP DATA\n    \"\"\"\n    if hasattr(compressed, \"read\"):\n        return gzip.GzipFile(fileobj=compressed, mode='r')\n\n    buff = BytesIO(compressed)\n    archive = gzip.GzipFile(fileobj=buff, mode='r')\n    from pyLibrary.env.big_data import safe_size\n    return safe_size(archive)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a compressed version of the given bytes.", "response": "def bytes2zip(bytes):\n    \"\"\"\n    RETURN COMPRESSED BYTES\n    \"\"\"\n    if hasattr(bytes, \"read\"):\n        buff = TemporaryFile()\n        archive = gzip.GzipFile(fileobj=buff, mode='w')\n        for b in bytes:\n            archive.write(b)\n        archive.close()\n        buff.seek(0)\n        from pyLibrary.env.big_data import FileString, safe_size\n        return FileString(buff)\n\n    buff = BytesIO()\n    archive = gzip.GzipFile(fileobj=buff, mode='w')\n    archive.write(bytes)\n    archive.close()\n    return buff.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ini2value(ini_content):\n    from mo_future import ConfigParser, StringIO\n\n    buff = StringIO(ini_content)\n    config = ConfigParser()\n    config._read(buff, \"dummy\")\n\n    output = {}\n    for section in config.sections():\n        output[section]=s = {}\n        for k, v in config.items(section):\n            s[k]=v\n    return wrap(output)", "response": "Converts INI FILE CONTENT TO VALUE"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a list of tuples into a nice formatted csv", "response": "def table2csv(table_data):\n    \"\"\"\n    :param table_data: expecting a list of tuples\n    :return: text in nice formatted csv\n    \"\"\"\n    text_data = [tuple(value2json(vals, pretty=True) for vals in rows) for rows in table_data]\n\n    col_widths = [max(len(text) for text in cols) for cols in zip(*text_data)]\n    template = \", \".join(\n        \"{{\" + text_type(i) + \"|left_align(\" + text_type(w) + \")}}\"\n        for i, w in enumerate(col_widths)\n    )\n    text = \"\\n\".join(expand_template(template, d) for d in text_data)\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tuple_in_list_always(main, sub):\n    return True if sub in set(main) and len(set(main)) == 1 else False", "response": "Returns True if main is always in sub False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef obj_in_list_always(target_list, obj):\n    for item in set(target_list):\n        if item is not obj:\n            return False\n    return True", "response": "Returns True if the object is in target_list False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dict_partial_cmp(target_dict, dict_list, ducktype):\n    for called_dict in dict_list:\n        # ignore invalid test case\n        if len(target_dict) > len(called_dict):\n            continue\n        # get the intersection of two dicts\n        intersection = {}\n        for item in target_dict:\n            dtype = ducktype(target_dict[item])\n            if hasattr(dtype, \"mtest\"):\n                if item in called_dict and dtype.mtest(called_dict[item]):\n                    intersection[item] = target_dict[item]\n            else:\n                if item in called_dict and dtype == called_dict[item]:\n                    intersection[item] = target_dict[item]\n        if intersection == target_dict:\n            return True\n    # if no any arguments matched to called_args, return False\n    return False", "response": "Returns True if dict_list contains partial dict False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dict_partial_cmp_always(target_dict, dict_list, ducktype):\n    res = []\n    for called_dict in dict_list:\n        # ignore invalid test case\n        if len(target_dict) > len(called_dict):\n            continue\n        # get the intersection of two dicts\n        intersection = {}\n        for item in target_dict:\n            dtype = ducktype(target_dict[item])\n            if hasattr(dtype, \"mtest\"):\n                if item in called_dict and dtype.mtest(called_dict[item]):\n                    intersection[item] = target_dict[item]\n            else:\n                if item in called_dict and dtype == called_dict[item]:\n                    intersection[item] = target_dict[item]\n        ret = True if intersection == target_dict else False\n        res.append(ret)\n    # if no any arguments matched to called_args, return False\n    return True if res and False not in res else False", "response": "Whether partial dict are always in dict_list or not"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if target_tuple is partial matched to tuple_list False otherwise", "response": "def tuple_partial_cmp(target_tuple, tuple_list, ducktype):\n    \"\"\"\n    Whether partial target_tuple are in tuple_list or not\n    \"\"\"\n    for called_tuple in tuple_list:\n        # ignore invalid test case\n        if len(target_tuple) > len(called_tuple):\n            continue\n        # loop all argument from \"current arguments\"\n        dst = len(target_tuple)\n        for idx, part_target_tuple in enumerate(target_tuple):\n            # test current argument one by one, if matched to previous record, counter-1\n            dtype = ducktype(part_target_tuple)\n            if hasattr(dtype, \"mtest\"):\n                if dtype.mtest(called_tuple[idx]):\n                    dst = dst - 1\n            else:\n                if dtype == called_tuple[idx]:\n                    dst = dst - 1\n        # if counter is zero => arguments is partial matched => return True\n        if not dst:\n            return True\n    # if no any arguments matched to called_tuple, return False\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tuple_partial_cmp_always(target_tuple, tuple_list, ducktype):\n    res = []\n    for called_tuple in tuple_list:\n        # ignore invalid test case\n        if len(target_tuple) > len(called_tuple):\n            continue\n        # loop all argument from \"current arguments\"\n        dst = len(target_tuple)\n        for idx, part_target_tuple in enumerate(target_tuple):\n            # test current argument one by one, if matched to previous record, counter-1\n            dtype = ducktype(part_target_tuple)\n            if hasattr(dtype, \"mtest\"):\n                if dtype.mtest(called_tuple[idx]):\n                    dst = dst - 1\n            else:\n                if dtype == called_tuple[idx]:\n                    dst = dst - 1\n        # if counter is zero => arguments is partial matched => return True\n        ret = True if not dst else False\n        res.append(ret)\n    # if no any arguments matched to called_tuple, return False\n    return True if res and False not in res else False", "response": "Returns True if partial target_tuple are always in tuple_list False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering the spec codec using the provided options", "response": "def register_from_options(options=None, template=None, extractor=None):\n    \"\"\"Register the spec codec using the provided options\"\"\"\n    if template is None:\n        from noseOfYeti.plugins.support.spec_options import spec_options as template\n\n    if extractor is None:\n        from noseOfYeti.plugins.support.spec_options import extract_options_dict as extractor\n\n    config = Config(template)\n    config.setup(options, extractor)\n\n    imports = determine_imports(\n          extra_imports = ';'.join([d for d in config.extra_import if d])\n        , with_default_imports = config.with_default_imports\n        )\n\n    tok = Tokeniser(\n          default_kls = config.default_kls\n        , import_tokens = imports\n        , wrapped_setup = config.wrapped_setup\n        , with_describe_attrs = not config.no_describe_attrs\n        )\n\n    TokeniserCodec(tok).register()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register(self):\n        # Assume utf8 encoding\n        utf8 = encodings.search_function('utf8')\n\n        class StreamReader(utf_8.StreamReader):\n            \"\"\"Used by cPython to deal with a spec file\"\"\"\n            def __init__(sr, stream, *args, **kwargs):\n                codecs.StreamReader.__init__(sr, stream, *args, **kwargs)\n                data = self.dealwith(sr.stream.readline)\n                sr.stream = StringIO(data)\n\n        def decode(text, *args, **kwargs):\n            \"\"\"Used by pypy and pylint to deal with a spec file\"\"\"\n            return_tuple = kwargs.get(\"return_tuple\", True)\n\n            if six.PY3:\n                if hasattr(text, 'tobytes'):\n                    text = text.tobytes().decode('utf8')\n                else:\n                    text = text.decode('utf8')\n\n            buffered = StringIO(text)\n\n            # Determine if we need to have imports for this string\n            # It may be a fragment of the file\n            has_spec = regexes['encoding_matcher'].search(buffered.readline())\n            no_imports = not has_spec\n            buffered.seek(0)\n\n            # Translate the text\n            if six.PY2:\n                utf8 = encodings.search_function('utf8') # Assume utf8 encoding\n                reader = utf8.streamreader(buffered)\n            else:\n                reader = buffered\n\n            data = self.dealwith(reader.readline, no_imports=no_imports)\n\n            # If nothing was changed, then we want to use the original file/line\n            # Also have to replace indentation of original line with indentation of new line\n            # To take into account nested describes\n            if text and not regexes['only_whitespace'].match(text):\n                if regexes['whitespace'].sub('', text) == regexes['whitespace'].sub('', data):\n                    bad_indentation = regexes['leading_whitespace'].search(text).groups()[0]\n                    good_indentation = regexes['leading_whitespace'].search(data).groups()[0]\n                    data = '%s%s' % (good_indentation, text[len(bad_indentation):])\n\n            # If text is empty and data isn't, then we should return text\n            if len(text) == 0 and len(data) == 1:\n                if return_tuple:\n                    return \"\", 0\n                else:\n                    return \"\"\n\n            # Return translated version and it's length\n            if return_tuple:\n                return data, len(data)\n            else:\n                return data\n\n        incrementaldecoder = utf8.incrementaldecoder\n        if six.PY3:\n            def incremental_decode(decoder, *args, **kwargs):\n                \"\"\"Wrapper for decode from IncrementalDecoder\"\"\"\n                kwargs[\"return_tuple\"] = False\n                return decode(*args, **kwargs)\n            incrementaldecoder = type(\"IncrementalDecoder\", (utf8.incrementaldecoder, ), {\"decode\": incremental_decode})\n\n        def search_function(s):\n            \"\"\"Determine if a file is of spec encoding and return special CodecInfo if it is\"\"\"\n            if s != 'spec': return None\n            return codecs.CodecInfo(\n                  name='spec'\n                , encode=utf8.encode\n                , decode=decode\n                , streamreader=StreamReader\n                , streamwriter=utf8.streamwriter\n                , incrementalencoder=utf8.incrementalencoder\n                , incrementaldecoder=incrementaldecoder\n                )\n\n        # Do the register\n        codecs.register(search_function)", "response": "Register spec codec with cPython and PyPy."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplace the contents of spec file with the translated version readline should be a callable object , which provides the same interface as the readline() method of built-in file objects", "response": "def dealwith(self, readline, **kwargs):\n        \"\"\"\n            Replace the contents of spec file with the translated version\n            readline should be a callable object\n            , which provides the same interface as the readline() method of built-in file objects\n        \"\"\"\n        data = []\n        try:\n            # We pass in the data variable as an argument so that we\n            # get partial output even in the case of an exception.\n            self.tokeniser.translate(readline, data, **kwargs)\n        except Exception as e:\n            # Comment out partial output so that it doesn't result in\n            # a syntax error when received by the interpreter.\n            lines = []\n            for line in untokenize(data).split('\\n'):\n                lines.append(\"# {0}\".format(line))\n\n            # Create exception to put into code to announce error\n            exception = 'raise Exception(\"\"\"--- internal spec codec error --- {0}\"\"\")'.format(e)\n\n            # Need to make sure the exception doesn't add a new line and put out line numberes\n            if len(lines) == 1:\n                data = \"{0}{1}\".format(exception, lines[0])\n            else:\n                lines.append(exception)\n                first_line = lines.pop()\n                lines[0] = \"{0} {1}\".format(first_line, lines[0])\n                data = '\\n'.join(lines)\n        else:\n            # At this point, data is a list of tokens\n            data = untokenize(data)\n\n        if six.PY2 and type(data) is not unicode:\n            data = unicode(data)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef output_for_debugging(self, stream, data):\n        with open('%s.spec.out' % stream.name, 'w') as f: f.write(str(data))", "response": "This function will write the translated version of the file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting the value to the correct Python type.", "response": "def to_python(self, value):\n        \"\"\"\n        Validates that the value is in self.choices and can be coerced to the\n        right type.\n        \"\"\"\n        value = '' if value in validators.EMPTY_VALUES else smart_text(value)\n        if value == self.empty_value or value in validators.EMPTY_VALUES:\n            return self.empty_value\n        try:\n            value = self.coerce(value)\n        except (ValueError, TypeError, ValidationError):\n            self._on_invalid_value(value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating that the input is a valid entry point.", "response": "def validate(self, value):\n        \"\"\"\n        Validates that the input is in self.choices.\n        \"\"\"\n        super(ChoicesField, self).validate(value)\n        if value and not self.valid_value(value):\n            self._on_invalid_value(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the provided value is a valid choice.", "response": "def valid_value(self, value):\n        \"\"\"\n        Check if the provided value is a valid choice.\n        \"\"\"\n        if isinstance(value, Constant):\n            value = value.name\n        text_value = force_text(value)\n        for option_value, option_label, option_title in self.choices:\n            if value == option_value or text_value == force_text(option_value):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _unit_info(self) -> Tuple[str, int]:\n        abs_bytes = abs(self.size)\n        if abs_bytes < 1024:\n            unit = 'B'\n            unit_divider = 1\n        elif abs_bytes < (1024 ** 2):\n            unit = 'KB'\n            unit_divider = 1024\n        elif abs_bytes < (1024 ** 3):\n            unit = 'MB'\n            unit_divider = (1024 ** 2)\n        elif abs_bytes < (1024 ** 4):\n            unit = 'GB'\n            unit_divider = (1024 ** 3)\n        else:\n            unit = 'TB'\n            unit_divider = (1024 ** 4)\n\n        return unit, unit_divider", "response": "Returns the best unit to measure the size and its power."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pretty_print(self, printer: Optional[Printer] = None, min_width: int = 1, min_unit_width: int = 1):\n        unit, unit_divider = self._unit_info()\n        unit_color = self.SIZE_COLORS[unit]\n        # Multiply and then divide by 100 in order to have only two decimal places.\n        size_in_unit = (self.size * 100) / unit_divider / 100\n        # Add spaces to align the units.\n        unit = '{}{}'.format(' ' * (min_unit_width - len(unit)), unit)\n        size_string = f'{size_in_unit:.1f}'\n        total_len = len(size_string) + 1 + len(unit)\n        if printer is None:\n            printer = get_printer()\n        spaces_count = min_width - total_len\n        if spaces_count > 0:\n            printer.write(' ' * spaces_count)\n        printer.write(f'{size_string} {unit_color}{unit}')", "response": "Prints the size and unit of the file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute_sql(\n    host,\n    username,\n    password,\n    sql,\n    schema=None,\n    param=None,\n    kwargs=None\n):\n    \"\"\"EXECUTE MANY LINES OF SQL (FROM SQLDUMP FILE, MAYBE?\"\"\"\n    kwargs.schema = coalesce(kwargs.schema, kwargs.database)\n\n    if param:\n        with MySQL(kwargs) as temp:\n            sql = expand_template(sql, quote_param(param))\n\n    # We have no way to execute an entire SQL file in bulk, so we\n    # have to shell out to the commandline client.\n    args = [\n        \"mysql\",\n        \"-h{0}\".format(host),\n        \"-u{0}\".format(username),\n        \"-p{0}\".format(password)\n    ]\n    if schema:\n        args.append(\"{0}\".format(schema))\n\n    try:\n        proc = subprocess.Popen(\n            args,\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            bufsize=-1\n        )\n        if is_text(sql):\n            sql = sql.encode(\"utf8\")\n        (output, _) = proc.communicate(sql)\n    except Exception as e:\n        raise Log.error(\"Can not call \\\"mysql\\\"\", e)\n\n    if proc.returncode:\n        if len(sql) > 10000:\n            sql = \"<\" + text_type(len(sql)) + \" bytes of sql>\"\n        Log.error(\n            \"Unable to execute sql: return code {{return_code}}, {{output}}:\\n {{sql}}\\n\",\n            sql=indent(sql),\n            return_code=proc.returncode,\n            output=output\n        )", "response": "Execute a SQL file in bulk."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a value to mysql code for the same", "response": "def quote_value(value):\n    \"\"\"\n    convert values to mysql code for the same\n    mostly delegate directly to the mysql lib, but some exceptions exist\n    \"\"\"\n    try:\n        if value == None:\n            return SQL_NULL\n        elif isinstance(value, SQL):\n            return quote_sql(value.template, value.param)\n        elif is_text(value):\n            return SQL(\"'\" + \"\".join(ESCAPE_DCT.get(c, c) for c in value) + \"'\")\n        elif is_data(value):\n            return quote_value(json_encode(value))\n        elif is_number(value):\n            return SQL(text_type(value))\n        elif isinstance(value, datetime):\n            return SQL(\"str_to_date('\" + value.strftime(\"%Y%m%d%H%M%S.%f\") + \"', '%Y%m%d%H%i%s.%f')\")\n        elif isinstance(value, Date):\n            return SQL(\"str_to_date('\" + value.format(\"%Y%m%d%H%M%S.%f\") + \"', '%Y%m%d%H%i%s.%f')\")\n        elif hasattr(value, '__iter__'):\n            return quote_value(json_encode(value))\n        else:\n            return quote_value(text_type(value))\n    except Exception as e:\n        Log.error(\"problem quoting SQL {{value}}\", value=repr(value), cause=e)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef quote_sql(value, param=None):\n    try:\n        if isinstance(value, SQL):\n            if not param:\n                return value\n            param = {k: quote_sql(v) for k, v in param.items()}\n            return SQL(expand_template(value, param))\n        elif is_text(value):\n            return SQL(value)\n        elif is_data(value):\n            return quote_value(json_encode(value))\n        elif hasattr(value, '__iter__'):\n            return quote_list(value)\n        else:\n            return text_type(value)\n    except Exception as e:\n        Log.error(\"problem quoting SQL\", e)", "response": "Quote a value to be used in SQL"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn singletons, ranges and exclusions", "response": "def int_list_packer(term, values):\n    \"\"\"\n    return singletons, ranges and exclusions\n    \"\"\"\n    DENSITY = 10  # a range can have holes, this is inverse of the hole density\n    MIN_RANGE = 20  # min members before a range is allowed to be used\n\n    singletons = set()\n    ranges = []\n    exclude = set()\n\n    sorted = jx.sort(values)\n\n    last = sorted[0]\n    curr_start = last\n    curr_excl = set()\n\n    for v in sorted[1::]:\n        if v <= last + 1:\n            pass\n        elif v - last > 3:\n            # big step, how do we deal with it?\n            if last == curr_start:\n                # not a range yet, so just add as singlton\n                singletons.add(last)\n            elif last - curr_start - len(curr_excl) < MIN_RANGE or ((last - curr_start) < len(curr_excl) * DENSITY):\n                # small ranges are singletons, sparse ranges are singletons\n                singletons |= set(range(curr_start, last + 1))\n                singletons -= curr_excl\n            else:\n                # big enough, and dense enough range\n                ranges.append({\"gte\": curr_start, \"lte\": last})\n                exclude |= curr_excl\n            curr_start = v\n            curr_excl = set()\n        else:\n            if 1 + last - curr_start >= len(curr_excl) * DENSITY:\n                # high density, keep track of excluded and continue\n                add_me = set(range(last + 1, v))\n                curr_excl |= add_me\n            elif 1 + last - curr_start - len(curr_excl) < MIN_RANGE:\n                # not big enough, convert range to singletons\n                new_singles = set(range(curr_start, last + 1)) - curr_excl\n                singletons = singletons | new_singles\n\n                curr_start = v\n                curr_excl = set()\n            else:\n                ranges.append({\"gte\": curr_start, \"lte\": last})\n                exclude |= curr_excl\n                curr_start = v\n                curr_excl = set()\n        last = v\n\n    if last == curr_start:\n        # not a range yet, so just add as singlton\n        singletons.add(last)\n    elif last - curr_start - len(curr_excl) < MIN_RANGE or ((last - curr_start) < len(curr_excl) * DENSITY):\n        # small ranges are singletons, sparse ranges are singletons\n        singletons |= set(range(curr_start, last + 1))\n        singletons -= curr_excl\n    else:\n        # big enough, and dense enough range\n        ranges.append({\"gte\": curr_start, \"lte\": last})\n        exclude |= curr_excl\n\n    if ranges:\n        r = {\"or\": [{\"range\": {term: r}} for r in ranges]}\n        if exclude:\n            r = {\"and\": [r, {\"not\": {\"terms\": {term: jx.sort(exclude)}}}]}\n        if singletons:\n            return {\"or\": [\n                {\"terms\": {term: jx.sort(singletons)}},\n                r\n            ]}\n        else:\n            return r\n    else:\n        return {\"terms\": {term: values}}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _open(self):\n        try:\n            self.db = connect(\n                host=self.settings.host,\n                port=self.settings.port,\n                user=coalesce(self.settings.username, self.settings.user),\n                passwd=coalesce(self.settings.password, self.settings.passwd),\n                db=coalesce(self.settings.schema, self.settings.db),\n                read_timeout=coalesce(self.settings.read_timeout, (EXECUTE_TIMEOUT / 1000) - 10 if EXECUTE_TIMEOUT else None, 5*60),\n                charset=u\"utf8\",\n                use_unicode=True,\n                ssl=coalesce(self.settings.ssl, None),\n                cursorclass=cursors.SSCursor\n            )\n        except Exception as e:\n            if self.settings.host.find(\"://\") == -1:\n                Log.error(\n                    u\"Failure to connect to {{host}}:{{port}}\",\n                    host=self.settings.host,\n                    port=self.settings.port,\n                    cause=e\n                )\n            else:\n                Log.error(u\"Failure to connect.  PROTOCOL PREFIX IS PROBABLY BAD\", e)\n        self.cursor = None\n        self.partial_rollback = False\n        self.transaction_level = 0\n        self.backlog = []  # accumulate the write commands so they are sent at once\n        if self.readonly:\n            self.begin()", "response": "Open a new connection to the database and initialize the internal state."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef query(self, sql, param=None, stream=False, row_tuples=False):\n        if not self.cursor:  # ALLOW NON-TRANSACTIONAL READS\n            Log.error(\"must perform all queries inside a transaction\")\n        self._execute_backlog()\n\n        try:\n            if param:\n                sql = expand_template(sql, quote_param(param))\n            sql = self.preamble + outdent(sql)\n            self.debug and Log.note(\"Execute SQL:\\n{{sql}}\", sql=indent(sql))\n\n            self.cursor.execute(sql)\n            if row_tuples:\n                if stream:\n                    result = self.cursor\n                else:\n                    result = wrap(list(self.cursor))\n            else:\n                columns = [utf8_to_unicode(d[0]) for d in coalesce(self.cursor.description, [])]\n                if stream:\n                    result = (wrap({c: utf8_to_unicode(v) for c, v in zip(columns, row)}) for row in self.cursor)\n                else:\n                    result = wrap([{c: utf8_to_unicode(v) for c, v in zip(columns, row)} for row in self.cursor])\n\n            return result\n        except Exception as e:\n            e = Except.wrap(e)\n            if \"InterfaceError\" in e:\n                Log.error(\"Did you close the db connection?\", e)\n            Log.error(\"Problem executing SQL:\\n{{sql|indent}}\", sql=sql, cause=e, stack_depth=1)", "response": "Execute a SQL query and return the list of dicts."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef column_query(self, sql, param=None):\n        self._execute_backlog()\n        try:\n            old_cursor = self.cursor\n            if not old_cursor:  # ALLOW NON-TRANSACTIONAL READS\n                self.cursor = self.db.cursor()\n                self.cursor.execute(\"SET TIME_ZONE='+00:00'\")\n                self.cursor.close()\n                self.cursor = self.db.cursor()\n\n            if param:\n                sql = expand_template(sql, quote_param(param))\n            sql = self.preamble + outdent(sql)\n            self.debug and Log.note(\"Execute SQL:\\n{{sql}}\", sql=indent(sql))\n\n            self.cursor.execute(sql)\n            grid = [[utf8_to_unicode(c) for c in row] for row in self.cursor]\n            # columns = [utf8_to_unicode(d[0]) for d in coalesce(self.cursor.description, [])]\n            result = transpose(*grid)\n\n            if not old_cursor:  # CLEANUP AFTER NON-TRANSACTIONAL READS\n                self.cursor.close()\n                self.cursor = None\n\n            return result\n        except Exception as e:\n            if isinstance(e, InterfaceError) or e.message.find(\"InterfaceError\") >= 0:\n                Log.error(\"Did you close the db connection?\", e)\n            Log.error(\"Problem executing SQL:\\n{{sql|indent}}\", sql=sql, cause=e, stack_depth=1)", "response": "Execute SQL query and return the first row of the result set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, table_name, where_slice, new_values):\n        new_values = quote_param(new_values)\n\n        where_clause = SQL_AND.join([\n            quote_column(k) + \"=\" + quote_value(v) if v != None else quote_column(k) + SQL_IS_NULL\n            for k, v in where_slice.items()\n        ])\n\n        command = (\n            \"UPDATE \" + quote_column(table_name) + \"\\n\" +\n            \"SET \" +\n            sql_list([quote_column(k) + \"=\" + v for k, v in new_values.items()]) +\n            SQL_WHERE +\n            where_clause\n        )\n        self.execute(command, {})", "response": "Update the entries in the specified table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tokenize_tags(tags_string):\n\n    # text is parsed in two steps:\n    # the first step extract every single world that is 3 > chars long\n    # and that contains only alphanumeric characters, underscores and dashes\n    tags_string = tags_string.lower().strip(\",\")\n    single_words = set([w[:100] for w in re.split(';|,|\\*|\\n| ', tags_string)\n                          if len(w) >= 3 and re.match(\"^[A-Za-z0-9_-]*$\", w)])\n    # the second step divide the original string using comma as separator\n    comma_separated = set([t[:100] for t in tags_string.split(\",\") if t])\n    # resulting set are merged using union\n    return list(single_words | comma_separated)", "response": "This function is responsible to extract usable tags from a text."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds menage consumption by categorie fiscale dataframe", "response": "def build_depenses_homogenisees(temporary_store = None, year = None):\n    \"\"\"Build menage consumption by categorie fiscale dataframe \"\"\"\n    assert temporary_store is not None\n    assert year is not None\n\n    bdf_survey_collection = SurveyCollection.load(\n        collection = 'budget_des_familles', config_files_directory = config_files_directory\n        )\n    survey = bdf_survey_collection.get_survey('budget_des_familles_{}'.format(year))\n\n    # Homog\u00e9n\u00e9isation des bases de donn\u00e9es de d\u00e9penses\n\n    if year == 1995:\n        socioscm = survey.get_values(table = \"socioscm\")\n        poids = socioscm[['mena', 'ponderrd', 'exdep', 'exrev']]\n        # cette \u00e9tape de ne garder que les donn\u00e9es dont on est s\u00fbr de la qualit\u00e9 et de la v\u00e9racit\u00e9\n        # exdep = 1 si les donn\u00e9es sont bien remplies pour les d\u00e9penses du m\u00e9nage\n        # exrev = 1 si les donn\u00e9es sont bien remplies pour les revenus du m\u00e9nage\n        poids = poids[(poids.exdep == 1) & (poids.exrev == 1)]\n        del poids['exdep'], poids['exrev']\n        poids.rename(\n            columns = {\n                'mena': 'ident_men',\n                'ponderrd': 'pondmen',\n                },\n            inplace = True\n            )\n        poids.set_index('ident_men', inplace = True)\n\n        conso = survey.get_values(table = \"depnom\")\n        conso = conso[[\"valeur\", \"montant\", \"mena\", \"nomen5\"]]\n        conso = conso.groupby([\"mena\", \"nomen5\"]).sum()\n        conso = conso.reset_index()\n        conso.rename(\n            columns = {\n                'mena': 'ident_men',\n                'nomen5': 'poste{}'.format(year),\n                'valeur': 'depense',\n                'montant': 'depense_avt_imput',\n                },\n            inplace = True\n            )\n\n        # Passage \u00e0 l'euro\n        conso.depense = conso.depense / 6.55957\n        conso.depense_avt_imput = conso.depense_avt_imput / 6.55957\n        conso_small = conso[[u'ident_men', u'poste1995', u'depense']]\n\n        conso_unstacked = conso_small.set_index(['ident_men', 'poste1995']).unstack('poste1995')\n        conso_unstacked = conso_unstacked.fillna(0)\n\n        levels = conso_unstacked.columns.levels[1]\n        labels = conso_unstacked.columns.labels[1]\n        conso_unstacked.columns = levels[labels]\n        conso_unstacked.rename(index = {0: 'ident_men'}, inplace = True)\n        conso = conso_unstacked.merge(poids, left_index = True, right_index = True)\n        conso = conso.reset_index()\n\n    if year == 2000:\n        conso = survey.get_values(table = \"consomen\")\n        conso.rename(\n            columns = {\n                'ident': 'ident_men',\n                'pondmen': 'pondmen',\n                },\n            inplace = True,\n            )\n        for variable in ['ctotale', 'c99', 'c99999'] + \\\n                        [\"c0{}\".format(i) for i in range(1, 10)] + \\\n                        [\"c{}\".format(i) for i in range(10, 14)]:\n            del conso[variable]\n\n    if year == 2005:\n        conso = survey.get_values(table = \"c05d\")\n\n    if year == 2011:\n        try:\n            conso = survey.get_values(table = \"C05\")\n        except:\n            conso = survey.get_values(table = \"c05\")\n        conso.rename(\n            columns = {\n                'ident_me': 'ident_men',\n                },\n            inplace = True,\n            )\n        del conso['ctot']\n\n    # Grouping by coicop\n\n    poids = conso[['ident_men', 'pondmen']].copy()\n    poids.set_index('ident_men', inplace = True)\n    conso.drop('pondmen', axis = 1, inplace = True)\n    conso.set_index('ident_men', inplace = True)\n\n    matrice_passage_data_frame, selected_parametres_fiscalite_data_frame = get_transfert_data_frames(year)\n\n    coicop_poste_bdf = matrice_passage_data_frame[['poste{}'.format(year), 'posteCOICOP']]\n    coicop_poste_bdf.set_index('poste{}'.format(year), inplace = True)\n    coicop_by_poste_bdf = coicop_poste_bdf.to_dict()['posteCOICOP']\n    del coicop_poste_bdf\n\n    def reformat_consumption_column_coicop(coicop):\n        try:\n            return int(coicop.replace('c', '').lstrip('0'))\n        except:\n            return numpy.NaN\n    # cette \u00e9tape permet d'harmoniser les df pour 1995 qui ne se pr\u00e9sentent pas de la m\u00eame fa\u00e7on\n    # que pour les trois autres ann\u00e9es\n    if year == 1995:\n        coicop_labels = [\n            normalize_code_coicop(coicop_by_poste_bdf.get(poste_bdf))\n            for poste_bdf in conso.columns\n            ]\n    else:\n        coicop_labels = [\n            normalize_code_coicop(coicop_by_poste_bdf.get(reformat_consumption_column_coicop(poste_bdf)))\n            for poste_bdf in conso.columns\n            ]\n    tuples = zip(coicop_labels, conso.columns)\n    conso.columns = pandas.MultiIndex.from_tuples(tuples, names=['coicop', 'poste{}'.format(year)])\n    coicop_data_frame = conso.groupby(level = 0, axis = 1).sum()\n\n    depenses = coicop_data_frame.merge(poids, left_index = True, right_index = True)\n\n    # Cr\u00e9ation de gros postes, les 12 postes sur lesquels le calage se fera\n    def select_gros_postes(coicop):\n        try:\n            coicop = unicode(coicop)\n        except:\n            coicop = coicop\n        normalized_coicop = normalize_code_coicop(coicop)\n        grosposte = normalized_coicop[0:2]\n        return int(grosposte)\n\n    grospostes = [\n        select_gros_postes(coicop)\n        for coicop in coicop_data_frame.columns\n        ]\n    tuples_gros_poste = zip(coicop_data_frame.columns, grospostes)\n    coicop_data_frame.columns = pandas.MultiIndex.from_tuples(tuples_gros_poste, names=['coicop', 'grosposte'])\n\n    depenses_by_grosposte = coicop_data_frame.groupby(level = 1, axis = 1).sum()\n    depenses_by_grosposte = depenses_by_grosposte.merge(poids, left_index = True, right_index = True)\n\n    # TODO : understand why it does not work: depenses.rename(columns = {u'0421': 'poste_coicop_421'}, inplace = True)\n\n    produits = [column for column in depenses.columns if column.isdigit()]\n    for code in produits:\n        if code[-1:] == '0':\n            depenses.rename(columns = {code: code[:-1]}, inplace = True)\n        else:\n            depenses.rename(columns = {code: code}, inplace = True)\n    produits = [column for column in depenses.columns if column.isdigit()]\n    for code in produits:\n        if code[0:1] == '0':\n            depenses.rename(columns = {code: code[1:]}, inplace = True)\n        else:\n            depenses.rename(columns = {code: code}, inplace = True)\n    produits = [column for column in depenses.columns if column.isdigit()]\n    for code in produits:\n        depenses.rename(columns = {code: 'poste_coicop_' + code}, inplace = True)\n\n    temporary_store['depenses_{}'.format(year)] = depenses\n\n    depenses_by_grosposte.columns = depenses_by_grosposte.columns.astype(str)\n    liste_grospostes = [column for column in depenses_by_grosposte.columns if column.isdigit()]\n    for grosposte in liste_grospostes:\n        depenses_by_grosposte.rename(columns = {grosposte: 'coicop12_' + grosposte}, inplace = True)\n\n    temporary_store['depenses_by_grosposte_{}'.format(year)] = depenses_by_grosposte"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nnormalizes the code of a COICOP.", "response": "def normalize_code_coicop(code):\n    '''Normalize_coicop est function d'harmonisation de la colonne d'entiers posteCOICOP de la table\nmatrice_passage_data_frame en la transformant en une chaine de 5 caract\u00e8res afin de pouvoir par la suite agr\u00e9ger les postes\nCOICOP selon les 12 postes agr\u00e9g\u00e9s de la nomenclature de la comptabilit\u00e9 nationale. Chaque poste contient 5 caract\u00e8res,\nles deux premiers (entre 01 et 12) correspondent \u00e0 ces postes agr\u00e9g\u00e9s de la CN.\n\n    '''\n    # TODO: v\u00e9rifier la formule !!!\n\n    try:\n        code = unicode(code)\n    except:\n        code = code\n    if len(code) == 3:\n        code_coicop = \"0\" + code + \"0\"  # \"{0}{1}{0}\".format(0, code)\n    elif len(code) == 4:\n        if not code.startswith(\"0\") and not code.startswith(\"1\") and not code.startswith(\"45\") and not code.startswith(\"9\"):\n            code_coicop = \"0\" + code\n            # 022.. = cigarettes et tabacs => on les range avec l'alcool (021.0)\n        elif code.startswith(\"0\"):\n            code_coicop = code + \"0\"\n        elif code in [\"1151\", \"1181\", \"4552\", \"4522\", \"4511\", \"9122\", \"9151\", \"9211\", \"9341\", \"1411\"]:\n            # 1151 = Margarines et autres graisses v\u00e9g\u00e9tales\n            # 1181 = Confiserie\n            # 04522 = Achat de butane, propane\n            # 04511 = Facture EDF GDF non dissociables\n            code_coicop = \"0\" + code\n        else:\n            # 99 = loyer, impots et taxes, cadeaux...\n            code_coicop = code + \"0\"\n    elif len(code) == 5:\n        if not code.startswith(\"13\") and not code.startswith(\"44\") and not code.startswith(\"51\"):\n            code_coicop = code\n        else:\n            code_coicop = \"99000\"\n    else:\n        log.error(\"Problematic code {}\".format(code))\n        raise()\n    return code_coicop"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deactivate():\n\n    if hasattr(_mode, \"current_state\"):\n        del _mode.current_state\n    if hasattr(_mode, \"schema\"):\n        del _mode.schema\n\n    for k in connections:\n        con = connections[k]\n        if hasattr(con, 'reset_schema'):\n            con.reset_schema()", "response": "Deactivate a state in this thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads script ranges from Unidata scripts. txt file.", "response": "def readScriptRanges(scripts=None):\n    \"\"\"\n    Read script ranges from http://unicode.org/Public/UNIDATA/Scripts.txt file.\n    \"\"\"\n    scripts = scripts or LATIN_LIKE_SCRIPTS\n    ranges = []\n\n    f = open('Scripts.txt', 'r')\n    for line in f:\n        line = line.strip('\\n')\n        matchObj = re.match(\n            '^([0123456789ABCDEF]{4}(\\.\\.[0123456789ABCDEF]{4})?)\\s*;\\s+(%s)\\s+(#.*)?$'\n                % '|'.join(scripts),\n            line)\n        if matchObj:\n            entry = matchObj.group(1)\n            if len(entry) > 4:\n                start, stop = entry.split('..', 1)\n                ranges.append((start, stop))\n            else:\n                ranges.append(entry)\n    f.close()\n\n    return ranges"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef collections(record, key, value):\n    return {\n        'primary': value.get('a'),\n        'secondary': value.get('b'),\n        'deleted': value.get('c'),\n    }", "response": "Parse custom MARC tag 980."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reverse_collections(self, key, value):\n    return {\n        'a': value.get('primary'),\n        'b': value.get('secondary'),\n        'c': value.get('deleted'),\n    }", "response": "Populate the reverse_collections key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _select1(data, field, depth, output):\n    for d in data:\n        for i, f in enumerate(field[depth:]):\n            d = d[f]\n            if d == None:\n                output.append(None)\n                break\n            elif is_list(d):\n                _select1(d, field, i + 1, output)\n                break\n        else:\n            output.append(d)", "response": "Select a single element from a list of data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef request(self, url, post=None, method=\"GET\"):\n        dsid = self.get_dsid()\n        baseurl = \"https://auth.api.swedbank.se/TDE_DAP_Portal_REST_WEB/api/v1/%s?dsid=%s\" % (\n            url, dsid)\n\n        if self.pch is None:\n            self.pch = build_opener(HTTPCookieProcessor(self.cj))\n\n        if post:\n            post = bytearray(post, \"utf-8\")\n            request = Request(baseurl, data=post)\n            request.add_header(\"Content-Type\", \"application/json\")\n        else:\n            request = Request(baseurl)\n\n        request.add_header(\"User-Agent\", self.useragent)\n        request.add_header(\"Authorization\", self.get_authkey())\n        request.add_header(\"Accept\", \"*/*\")\n        request.add_header(\"Accept-Language\", \"sv-se\")\n        request.add_header(\"Connection\", \"keep-alive\")\n        request.add_header(\"Proxy-Connection\", \"keep-alive\")\n        self.cj.set_cookie(\n                Cookie(version=0, name='dsid', value=dsid, port=None,\n                       port_specified=False, domain='.api.swedbank.se',\n                       domain_specified=False, domain_initial_dot=False,\n                       path='/',\n                       path_specified=True, secure=False, expires=None,\n                       discard=True, comment=None, comment_url=None,\n                       rest={'HttpsOnly': None}, rfc2109=False))\n        request.get_method = lambda: method\n        tmp = self.pch.open(request)\n        self.data = tmp.read().decode(\"utf8\")", "response": "Make the request to the TDE portal REST API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef login(self, user, passwd, bank):\n        logger.info(\"login...\")\n        if bank not in self.BANKS:\n            logger.error(\"Can't find that bank.\")\n            return False\n        self.useragent = self.BANKS[bank][\"u-a\"]\n        self.bankid = self.BANKS[bank][\"id\"]\n        login = json.dumps(\n                {\"userId\": user, \"password\": passwd, \"useEasyLogin\": False,\n                 \"generateEasyLoginId\": False})\n        try:\n            self.request(\"identification/personalcode\", post=login,\n                         method=\"POST\")\n        except HTTPError as e:\n            error = json.loads(e.read().decode(\"utf8\"))\n            logger.error(error[\"errorMessages\"][\"fields\"][0][\"message\"])\n            return False\n        try:\n            self.request(\"profile/\")\n        except HTTPError as e:\n            error = json.loads(e.read().decode(\"utf8\"))\n            logger.error(error[\"errorMessages\"][\"general\"][0][\"message\"])\n            return False\n\n        profile = json.loads(self.getdata())\n        if len(profile[\"banks\"]) == 0:\n            logger.error(\"Using wrong bank? Can't find any bank info.\")\n            return False\n        try:\n            self.profile = profile[\"banks\"][0][\"privateProfile\"][\"id\"]\n        except KeyError:\n            self.profile = profile['banks'][0]['corporateProfiles'][0][\"id\"]\n        try:\n            self.request(\"profile/%s\" % self.profile, method=\"POST\")\n        except HTTPError as e:\n            error = json.loads(e.read().decode(\"utf8\"))\n            logger.error(error[\"errorMessages\"][\"general\"][0][\"message\"])\n            return False\n\n        return True", "response": "Login to the Asterisk API."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef accounts(self):\n        logger.info(\"Fetching data...\")\n        try:\n            self.request(\"engagement/overview\")\n        except HTTPError as e:\n            error = json.loads(e.read().decode(\"utf8\"))\n            logger.error(error[\"errorMessages\"][\"general\"][0][\"message\"])\n            return\n        overview = json.loads(self.getdata())\n        overviewl = reversed(list(overview))\n        ret = list()\n        for i in overviewl:\n            if len(overview[i]) > 0:\n                for n in overview[i]:\n                    if self.account is None and \"id\" in n:\n                        self.account = n[\"id\"]\n                    if n.get('balance'):\n                        ret.append({n['name']: n['balance']})\n                    elif n.get('availableAmount', None):\n                        ret.append({n['name']: n['availableAmount']})\n\n                    else:\n                        logger.error(\"Unable to parse %s\", n)\n        return ret", "response": "Returns a list of all the accounts in the database"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the history of the current user s enrollment.", "response": "def history(self):\n        \"\"\" History \"\"\"\n        logger.info(\"Transactions:\")\n        try:\n            logger.debug(\"Account: %s\", self.account)\n            self.request(\"engagement/transactions/%s\" % self.account)\n        except HTTPError as e:\n            error = json.loads(e.read().decode(\"utf8\"))\n            logger.error(error[\"errorMessages\"][\"general\"][0][\"message\"])\n            return\n\n        transactions = json.loads(self.getdata())[\"transactions\"]\n        ret = list()\n        for i in transactions:\n            ret.append([i[\"date\"], i[\"description\"], i[\"amount\"]])\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct a search form based on the fields passed as arguments.", "response": "def search_form(*fields, **kwargs):\n    \"\"\"\n    Construct a search form filter form using the fields\n    provided as arguments to this function.\n\n    By default a field will be created for each field passed\n    and hidden field will be created for search. If you pass\n    the key work argument `search_only` then only a visible\n    search field will be created on the form.\n\n    Passing `status_filter` will include a version status filter\n    on this form.\n    \"\"\"\n\n    fdict = {\n        'search_fields': set(fields)\n    }\n\n    if kwargs.get('search_only'):\n        fdict['search'] = forms.CharField(max_length=255, required=False)\n    else:\n        fdict['search'] = forms.CharField(max_length=255, required=False,\n                                          widget=forms.HiddenInput)\n        for f in fields:\n            fdict[f] = forms.CharField(max_length=255, required=False)\n\n    if kwargs.get('status_filter', False):\n        return type(\"filterform\", (VersionFilterForm,), fdict)\n    else:\n        return type(\"filterform\", (BaseFilterForm,), fdict)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_filter_fields(self, exclude=None):\n\n        exclude_set = set(self.exclude)\n        if exclude:\n            exclude_set = exclude_set.union(set(exclude))\n\n        return [name for name in self.fields\n                if name not in exclude_set]", "response": "Get the fields that are normal filter fields\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_search_fields(self, exclude=None):\n        exclude = set(exclude)\n        if self.search_fields and len(self.search_fields) > 1:\n            exclude = exclude.union(self.search_fields)\n\n        return self.get_filter_fields(exclude=exclude)", "response": "Get the fields for searching for an item."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary of keyword arguments that can be passed to the filter function.", "response": "def get_filter_kwargs(self):\n        \"\"\"\n        Translates the cleaned data into a dictionary\n        that can used to generate the filter removing\n        blank values.\n        \"\"\"\n        if self.is_valid():\n            filter_kwargs = {}\n            for field in self.get_filter_fields():\n                empty_values = EMPTY_VALUES\n                if hasattr(self.fields[field], 'empty_values'):\n                    empty_values = self.fields[field].empty_values\n\n                value = self.cleaned_data.get(field)\n                if not value in empty_values:\n                    if self.search_fields and field in self.search_fields:\n                        filter_kwargs[\"%s__icontains\" % field] = value\n                    else:\n                        filter_kwargs[field] = value\n            return filter_kwargs\n        else:\n            return {}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_filter(self):\n\n        args = []\n        filter_kwargs = self.get_filter_kwargs()\n        search = filter_kwargs.pop('search', None)\n        if search and self.search_fields:\n            search_args = []\n            for f in self.search_fields:\n                k = '%s__icontains' % f\n                filter_kwargs.pop(k, None)\n                q = Q(**{k: search})\n                if search_args:\n                    q = search_args[0] | q\n                    search_args[0] = q\n                else:\n                    search_args.append(q)\n            args.append(search_args[0])\n\n        if filter_kwargs:\n            args.append(Q(**filter_kwargs))\n\n        return args", "response": "Returns a list of Q objects that are created by passing for the keyword arguments\n        from self. get_filter_kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a JX expression to a function that can be used in the JX interpreter.", "response": "def jx_expression_to_function(expr):\n    \"\"\"\n    RETURN FUNCTION THAT REQUIRES PARAMETERS (row, rownum=None, rows=None):\n    \"\"\"\n    if is_expression(expr):\n        if is_op(expr, ScriptOp) and not is_text(expr.script):\n            return expr.script\n        else:\n            return compile_expression(Python[expr].to_python())\n    if (\n        expr != None\n        and not is_data(expr)\n        and not is_list(expr)\n        and hasattr(expr, \"__call__\")\n    ):\n        return expr\n    return compile_expression(Python[jx_expression(expr)].to_python())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_proc_name(self, subtitle):\n        proc_name = '[%s:%s %s] %s' % (\n            constants.NAME,\n            subtitle,\n            self.name,\n            ' '.join([sys.executable] + sys.argv)\n        )\n\n        return proc_name", "response": "Make a name for the process."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _validate_cmds(self):\n\n        cmd_list = list(self.rule_map.keys())\n\n        for bp in self.blueprints:\n            cmd_list.extend(bp.rule_map.keys())\n\n        duplicate_cmds = (Counter(cmd_list) - Counter(set(cmd_list))).keys()\n\n        assert not duplicate_cmds, 'duplicate cmds: %s' % duplicate_cmds", "response": "Validate that all blueprints have the same command."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize the group queues", "response": "def _init_groups(self):\n        \"\"\"\n        \u521d\u59cb\u5316group\u6570\u636e\n        :return:\n        \"\"\"\n        for group_id, conf in self.group_conf.items():\n            self.parent_input_dict[group_id] = Queue(conf.get('input_max_size', 0))\n            self.parent_output_dict[group_id] = Queue(conf.get('output_max_size', 0))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nspawning a thread to process the result of the worker.", "response": "def _spawn_poll_worker_result_thread(self):\n        \"\"\"\n        \u542f\u52a8\u83b7\u53d6worker\u6570\u636e\u7684\u7ebf\u7a0b\n        \"\"\"\n        for group_id in self.group_conf:\n            thread = Thread(target=self._poll_worker_result, args=(group_id,))\n            thread.daemon = True\n            thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _poll_worker_result(self, group_id):\n        while 1:\n            try:\n                msg = self.parent_input_dict[group_id].get()\n            except KeyboardInterrupt:\n                break\n            except:\n                logger.error('exc occur.', exc_info=True)\n                break\n\n            # \u53c2\u8003 http://twistedsphinx.funsize.net/projects/core/howto/threading.html\n            reactor.callFromThread(self._handle_worker_response, msg)", "response": "Poll the worker thread until the result is received."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_ranked_english():\n    '''\n    wikitionary has a list of ~40k English words, ranked by frequency of occurance in TV and movie transcripts.\n    more details at:\n    http://en.wiktionary.org/wiki/Wiktionary:Frequency_lists/TV/2006/explanation\n\n    the list is separated into pages of 1000 or 2000 terms each.\n    * the first 10k words are separated into pages of 1000 terms each.\n    * the remainder is separated into pages of 2000 terms each:\n    '''\n    URL_TMPL = 'http://en.wiktionary.org/wiki/Wiktionary:Frequency_lists/TV/2006/%s'\n    urls = []\n    for i in range(10):\n        freq_range = \"%d-%d\" % (i * 1000 + 1, (i+1) * 1000)\n        urls.append(URL_TMPL % freq_range)\n\n    for i in range(0,15):\n        freq_range = \"%d-%d\" % (10000 + 2 * i * 1000 + 1, 10000 + (2 * i + 2) * 1000)\n        urls.append(URL_TMPL % freq_range)\n\n    urls.append(URL_TMPL % '40001-41284')\n\n    ranked_terms = [] # ordered by rank, in decreasing frequency.\n    for url in urls:\n        html, is_cached = wiki_download(url)\n        if not is_cached:\n            time.sleep(SLEEP_TIME)\n        new_terms = parse_wiki_terms(html)\n        ranked_terms.extend(new_terms)\n\n    return ranked_terms", "response": "Get a list of ~40k English words ranked by frequency of occurance in TV and movie transcripts."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wiki_download(url):\n    '''\n    scrape friendly: sleep 20 seconds between each request, cache each result.\n    '''\n    DOWNLOAD_TMPL = '../data/tv_and_movie_freqlist%s.html'\n    freq_range = url[url.rindex('/')+1:]\n\n    tmp_path = DOWNLOAD_TMPL % freq_range\n    if os.path.exists(tmp_path):\n        print('cached.......', url)\n        with codecs.open(tmp_path, 'r', 'utf8') as f:\n            return f.read(), True\n    with codecs.open(tmp_path, 'w', 'utf8') as f:\n        print('downloading...', url)\n        req = urllib.request.Request(url, headers={\n                'User-Agent': 'zxcvbn'\n                })\n        response = urllib.request.urlopen(req)\n        result = response.read().decode('utf8')\n        f.write(result)\n        return result, False", "response": "downloads a wiki page"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_wiki_terms(doc):\n    '''who needs an html parser. fragile hax, but checks the result at the end'''\n    results = []\n    last3 = ['', '', '']\n    header = True\n    for line in doc.split('\\n'):\n        last3.pop(0)\n        last3.append(line.strip())\n        if all(s.startswith('<td>') and not s == '<td></td>' for s in last3):\n            if header:\n                header = False\n                continue\n            last3 = [s.replace('<td>', '').replace('</td>', '').strip() for s in last3]\n            rank, term, count = last3\n            rank = int(rank.split()[0])\n            term = term.replace('</a>', '')\n            term = term[term.index('>')+1:].lower()\n            results.append(term)\n    assert len(results) in [1000, 2000, 1284] # early docs have 1k entries, later have 2k, last doc has 1284\n    return results", "response": "who needs an html parser. fragile hax but checks the result at the end"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of names that are ranked in the 2000 us census.", "response": "def get_ranked_census_names():\n    '''\n    takes name lists from the the 2000 us census, prepares as a json array in order of frequency (most common names first).\n\n    more info:\n    http://www.census.gov/genealogy/www/data/2000surnames/index.html\n\n    files in data are downloaded copies of:\n    http://www.census.gov/genealogy/names/dist.all.last\n    http://www.census.gov/genealogy/names/dist.male.first\n    http://www.census.gov/genealogy/names/dist.female.first\n    '''\n    FILE_TMPL = '../data/us_census_2000_%s.txt'\n    SURNAME_CUTOFF_PERCENTILE = 85 # ie7 can't handle huge lists. cut surname list off at a certain percentile.\n    lists = []\n    for list_name in ['surnames', 'male_first', 'female_first']:\n        path = FILE_TMPL % list_name\n        lst = []\n        for line in codecs.open(path, 'r', 'utf8'):\n            if line.strip():\n                if list_name == 'surnames' and float(line.split()[2]) > SURNAME_CUTOFF_PERCENTILE:\n                    break\n                name = line.split()[0].lower()\n                lst.append(name)\n        lists.append(lst)\n    return lists"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter_dup(lst, lists):\n    '''\n    filters lst to only include terms that don't have lower rank in another list\n    '''\n    max_rank = len(lst) + 1\n    dct = to_ranked_dict(lst)\n    dicts = [to_ranked_dict(l) for l in lists]\n    return [word for word in lst if all(dct[word] < dct2.get(word, max_rank) for dct2 in dicts)]", "response": "filters lst to only include terms that don t have lower rank in another list\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfilter out words with non - ASCII characters.", "response": "def filter_ascii(lst):\n    '''\n    removes words with accent chars etc.\n    (most accented words in the english lookup exist in the same table unaccented.)\n    '''\n    return [word for word in lst if all(ord(c) < 128 for c in word)]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining the type of the matcher", "response": "def __get_type(self, expectation, options):\n        \"\"\"\n        Determining the type of Matcher\n        Return: string\n        \"\"\"\n        if \"is_custom_func\" in options.keys():\n            setattr(self, \"mtest\", expectation)\n            return \"CUSTOMFUNC\"\n        elif \"is_substring\" in options.keys():\n            return \"SUBSTRING\"\n        elif \"is_regex\" in options.keys():\n            return \"REGEX\"\n        elif isinstance(expectation, type):\n            return \"TYPE\"\n        else:\n            return \"VALUE\""}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __value_compare(self, target):\n        if self.expectation == \"__ANY__\":\n            return True\n        elif self.expectation == \"__DEFINED__\":\n            return True if target is not None else False\n        elif self.expectation == \"__TYPE__\":\n            return True if type(target) == self.target_type else False #pylint:disable=unidiomatic-typecheck\n        elif self.expectation == \"__INSTANCE__\":\n            return True if isinstance(target, self.target_type.__class__) else False\n        else:\n            return True if target == self.expectation else False", "response": "Compare target with the expectation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __get_match_result(self, ret, ret2):\n        if self.another_compare == \"__MATCH_AND__\":\n            return ret and ret2\n        elif self.another_compare == \"__MATCH_OR__\":\n            return ret or ret2\n        return ret", "response": "Get the match result."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef typeOf(cls, expected_type): #pylint: disable=no-self-argument,invalid-name,no-self-use\n        if isinstance(expected_type, type):\n            options = {}\n            options[\"target_type\"] = expected_type\n            return Matcher(\"__TYPE__\", options)\n        ErrorHandler.matcher_type_error(expected_type)", "response": "Returns a matcher that matches the given type of the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef instanceOf(cls, expected_instance): #pylint: disable=no-self-argument,invalid-name,no-self-use\n        if not inspect.isclass(expected_instance):\n            options = {}\n            options[\"target_type\"] = expected_instance\n            return Matcher(\"__INSTANCE__\", options)\n        ErrorHandler.matcher_instance_error(expected_instance)", "response": "Returns a matcher that matches the given instance of the given class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _sort(self, short_list, sorts):\n\n        sort_values = self._index_columns(sorts)\n\n        # RECURSIVE SORTING\n        output = []\n        def _sort_more(short_list, i, sorts):\n            if len(sorts) == 0:\n                output.extend(short_list)\n\n            sort = sorts[0]\n\n            index = self._index[sort_values[i]]\n            if sort.sort == 1:\n                sorted_keys = sorted(index.keys())\n            elif sort.sort == -1:\n                sorted_keys = reversed(sorted(index.keys()))\n            else:\n                sorted_keys = list(index.keys())\n\n            for k in sorted_keys:\n                self._sort(index[k] & short_list, i + 1, sorts[1:])\n\n        _sort_more(short_list, 0, sorts)\n        return output", "response": "Sort the list of entries in the given list by the given list of sorts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nattempt to read the XML from a file on - disk or via a URL.", "response": "def gather_xml(self):\n        \"\"\"Attempt to read the XML, whether from a file on-disk or via host:port.\n\n        TODO: handle when you cant gather stats, due to bad hostname\n        \"\"\"\n        if self.xml_filepath:\n            with open(self.xml_filepath, \"r\") as xml_fh:\n                self.raw_xml = xml_fh.read()\n            self.bs_xml = BeautifulSoup(self.raw_xml, 'lxml')\n        else:\n            try:\n                req = urlopen('http://%s:%s' % (self.host, self.port))\n                self.raw_xml = req.read()\n                self.bs_xml = BeautifulSoup(self.raw_xml, 'lxml')\n            except URLError as u_error:\n                raise XmlError('Unable to query BIND (%s:%s) for statistics. Reason: %s.' %\n                               (self.host, self.port, u_error))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_stats(self):\n        self.gather_xml()\n        self.xml_version = self.bs_xml.find('statistics')['version']\n\n        if self.xml_version is None:\n            raise XmlError(\"Unable to determine XML version via 'statistics' tag.\")\n\n        if self.xml_version == '3.6':\n            self.stats = XmlV36(self.bs_xml)\n        elif self.xml_version == '3.8':\n            # 3.8 uses the same XML scheme as 3.6\n            self.stats = XmlV36(self.bs_xml)\n        elif self.xml_version == '3.11':\n            # BIND 9.12 uses same XML schema as XmlV36\n            self.stats = XmlV36(self.bs_xml)\n        else:\n            raise XmlError('Support must be added before being able to support newly-encountered XML version %s.' % self.xml_version)", "response": "Given XML version parse create XMLAbstract object and sets xml_stats attribute."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the median value of the set of entries in the order of the elements in the array", "response": "def median(values, simple=True, mean_weight=0.0):\n    \"\"\"\n    RETURN MEDIAN VALUE\n\n    IF simple=False THEN IN THE EVENT MULTIPLE INSTANCES OF THE\n    MEDIAN VALUE, THE MEDIAN IS INTERPOLATED BASED ON ITS POSITION\n    IN THE MEDIAN RANGE\n\n    mean_weight IS TO PICK A MEDIAN VALUE IN THE ODD CASE THAT IS\n    CLOSER TO THE MEAN (PICK A MEDIAN BETWEEN TWO MODES IN BIMODAL CASE)\n    \"\"\"\n\n    if OR(v == None for v in values):\n        Log.error(\"median is not ready to handle None\")\n\n    try:\n        if not values:\n            return Null\n\n        l = len(values)\n        _sorted = sorted(values)\n\n        middle = int(l / 2)\n        _median = float(_sorted[middle])\n\n        if len(_sorted) == 1:\n            return _median\n\n        if simple:\n            if l % 2 == 0:\n                return (_sorted[middle - 1] + _median) / 2\n            return _median\n\n        # FIND RANGE OF THE median\n        start_index = middle - 1\n        while start_index > 0 and _sorted[start_index] == _median:\n            start_index -= 1\n        start_index += 1\n        stop_index = middle + 1\n        while stop_index < l and _sorted[stop_index] == _median:\n            stop_index += 1\n\n        num_middle = stop_index - start_index\n\n        if l % 2 == 0:\n            if num_middle == 1:\n                return (_sorted[middle - 1] + _median) / 2\n            else:\n                return (_median - 0.5) + (middle - start_index) / num_middle\n        else:\n            if num_middle == 1:\n                return (1 - mean_weight) * _median + mean_weight * (_sorted[middle - 1] + _sorted[middle + 1]) / 2\n            else:\n                return (_median - 0.5) + (middle + 0.5 - start_index) / num_middle\n    except Exception as e:\n        Log.error(\"problem with median of {{values}}\",  values= values, cause=e)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef percentile(values, percent):\n    N = sorted(values)\n    if not N:\n        return None\n    k = (len(N) - 1) * percent\n    f = int(math.floor(k))\n    c = int(math.ceil(k))\n    if f == c:\n        return N[int(k)]\n    d0 = N[f] * (c - k)\n    d1 = N[c] * (k - f)\n    return d0 + d1", "response": "This function calculates the percentile of the given values."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds items to the dict that will be indexed by self. attr.", "response": "def put(self, *items) -> \"AttrIndexedDict\":\n        \"Add items to the dict that will be indexed by self.attr.\"\n        for item in items:\n            self.data[getattr(item, self.attr)] = item\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(host, password, username):\n    client = tplink.TpLinkClient(password)\n    devices = client.get_connected_devices()\n    click.echo(json.dumps(devices, indent=4))\n    return 0", "response": "Console script for tplink."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlogging-in aws - acces - key aws - secret", "response": "def do_login(self, line):\n        \"login aws-acces-key aws-secret\"\n        if line:\n            args = self.getargs(line)\n            self.connect(args[0], args[1])\n        else:\n            self.connect()\n\n        self.do_tables('')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_describe(self, line):\n        \"describe [-c] {tablename}...\"\n        args = self.getargs(line)\n\n        if '-c' in args:\n            create_info = True\n            args.remove('-c')\n        else:\n            create_info = False\n\n        if not args:\n            if self.table:\n                args = [ self.table.table_name ]\n            else:\n                args = self.tables\n\n        for table in args:\n            desc = self.conn.describe_table(table)\n\n            if create_info:\n                info = desc['Table']\n                name = info['TableName']\n                attributes = info['AttributeDefinitions']\n                schema = info['KeySchema']\n\n                hkey = ''\n                rkey = ''\n\n                for k in schema:\n                    aname = k['AttributeName']\n                    for a in attributes:\n                        if a['AttributeName'] == aname:\n                            value = \"%s:%s\" % (a['AttributeName'], a['AttributeType'])\n                            break\n\n                    if k['KeyType'] == 'HASH':\n                        hkey = value\n                    elif k['KeyType'] == 'RANGE':\n                        rkey = ' ' + value\n\n                prov = info['ProvisionedThroughput']\n                prov = \"-c %d,%d\" % (prov['ReadCapacityUnits'], prov['WriteCapacityUnits'])\n                print \"create %s %s %s%s\" % (name, prov, hkey, rkey)\n            else:\n                self.pprint(desc, \"%s: \" % table)", "response": "describe [- c ] { tablename..."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_use(self, line):\n        \"use {tablename}\"\n        self.table = boto.dynamodb2.table.Table(line, connection=self.conn)\n        self.pprint(self.table.describe())\n        self.prompt = \"%s> \" % self.table.table_name", "response": "Use the table specified by the line argument."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_create(self, line):\n        \"create {tablename} [-c rc,wc] {hkey}[:{type} {rkey}:{type}]\"\n        args = self.getargs(line)\n        rc = wc = 5\n\n        name = args.pop(0)  #  tablename\n\n        if args[0] == \"-c\": # capacity\n            args.pop(0)  # skyp -c\n\n            capacity = args.pop(0).strip()\n            rc, _, wc = capacity.partition(\",\")\n            rc = int(rc)\n            wc = int(wc) if wc != \"\" else rc\n\n        schema = []\n\n        hkey, _, hkey_type = args.pop(0).partition(':')\n        hkey_type = self.get_type(hkey_type or 'S')\n        schema.append(boto.dynamodb2.fields.HashKey(hkey, hkey_type))\n\n        if args:\n            rkey, _, rkey_type = args.pop(0).partition(':')\n            rkey_type = self.get_type(rkey_type or 'S')\n            schema.append(boto.dynamodb2.fields.RangeKey(rkey, rkey_type))\n\n        t = boto.dynamodb2.table.Table.create(name,\n                                              schema=schema,\n                                              throughput={'read': rc, 'write': wc})\n        self.pprint(t.describe())", "response": "create - c rc wc"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_capacity(self, line):\n        \"capacity [tablename] {read_units} {write_units}\"\n        table, line = self.get_table_params(line)\n        args = self.getargs(line)\n\n        read_units = int(args[0])\n        write_units = int(args[1])\n\n        desc = table.describe()\n        prov = desc['Table']['ProvisionedThroughput']\n\n        current_read, current_write = prov['ReadCapacityUnits'], prov['WriteCapacityUnits']\n        if read_units < current_read or write_units < current_write:\n            print \"%s: updating capacity to %d read units, %d write units\" % (table.table_name, read_units, write_units)\n            print \"\"\n            if not table.update(throughput={'read': read_units, 'write': write_units}):\n                print \"update failed\"\n            else:\n                self.do_refresh(table.table_name)\n\n        else:\n            print \"%s: current capacity is %d read units, %d write units\" % (table.table_name, current_read, current_write)\n            # we can only double the current value at each call\n            while current_read < read_units or current_write < write_units:\n                if (read_units - current_read) > current_read:\n                    current_read *= 2\n                else:\n                    current_read = read_units\n\n                if (write_units - current_write) > current_write:\n                    current_write *= 2\n                else:\n                    current_write = write_units\n\n                print \"%s: updating capacity to %d read units, %d write units\" % (table.table_name, current_read, current_write)\n                if not table.update({'read': current_read, 'write': current_write}):\n                    print \"\"\n                    print \"update failed\"\n                    print \"\"\n                    break\n                else:\n                    print \"\"\n                    self.do_refresh(table.table_name)\n                    print \"\"", "response": "capacity [ tablename ] read_units write_units"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_put(self, line):\n        \"put [:tablename] [!fieldname:expectedvalue] {json-body} [{json-body}, {json-body}...]\"\n        table, line = self.get_table_params(line)\n        expected, line = self.get_expected(line)\n        if expected:\n            print \"expected: not yet implemented\"\n            return\n\n        if line.startswith('(') or line.startswith('['):\n            print \"batch: not yet implemented\"\n            return\n\n            list = self.get_list(line)\n            wlist = self.conn.new_batch_write_list()\n            wlist.add_batch(table, [ table.new_item(None, None, item) for item in list ])\n            response = self.conn.batch_write_item(wlist)\n            consumed = response['Responses'][table.table_name]['ConsumedCapacityUnits']\n\n            if 'UnprocessedItems' in response and response['UnprocessedItems']:\n                print \"\"\n                print \"unprocessed: \", response['UnprocessedItems']\n                print \"\"\n        else:\n            item = json.loads(line)\n            table.put_item(item)\n            consumed = None\n\n        if self.consumed and consumed:\n            print \"consumed units:\", consumed", "response": "put a single item from the database"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_import(self, line):\n        \"import [:tablename] filename|list\"\n        table, line = self.get_table_params(line)\n        if line[0] == '[':\n            list = self.get_list(line)\n        else:\n            with open(line) as f:\n                list = self.get_list(f.read())\n\n        items = 0\n        consumed = 0\n\n        for item in list:\n            table.put_item(item)\n            #consumed += item.consumed_units\n            items += 1\n            print item['id']\n\n        print \"imported %s items, consumed units:%s\" % (items, consumed)", "response": "import [ : tablename filename|list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the key - value pair of the current user", "response": "def do_get(self, line):\n        \"\"\"\n        get [:tablename] {haskkey} [rangekey]\n        or\n        get [:tablename] ((hkey,rkey), (hkey,rkey)...)\n\n        \"\"\"\n\n        table, line = self.get_table_params(line)\n\n        if line.startswith('(') or line.startswith('[') or \",\" in line:\n            print \"batch: not yet implemented\"\n            return\n\n            # list of IDs\n            list = self.get_list(line)\n\n            from collections import OrderedDict\n\n            ordered = OrderedDict()\n            for id in list:\n                if not isinstance(id, tuple):\n                    hkey = self.get_typed_key_value(table, unicode(id))\n                    rkey = None\n                else:\n                    hkey = self.get_typed_key_value(table, unicode(id[0]), True)\n                    rkey = self.get_typed_key_value(table, unicode(id[1]), False)\n\n                ordered[(hkey, rkey)] = None\n\n            batch = self.conn.new_batch_list()\n            batch.add_batch(table, ordered.keys())\n            response = batch.submit()\n\n            hkey = table.schema.hash_key_name\n            rkey = table.schema.range_key_name\n\n            for item in response['Responses'][table.table_name]['Items']:\n                ordered[(item.get(hkey), item.get(rkey))] = item\n\n            self.pprint(filter(None, ordered.values()))\n        else:\n            args = self.getargs(line)\n\n            key = self.get_key_name_value(table, args[0], True)\n            print key\n\n            if len(args) > 1:\n                key.update(self.get_key_name_value(table, args[1], False))\n\n            print key\n\n            item = table.get_item(consistent=self.consistent, **key)\n            self.pprint(item)\n\n            if self.consumed:\n                print \"consumed units:\", item.consumed_units"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_scan(self, line):\n\n        table, line = self.get_table_params(line)\n        args = self.getargs(line)\n\n        scan_filter = {}\n        #count = False\n        as_array = False\n        max_size = None\n        batch_size = None\n        start = None\n        cond = None\n\n        while args:\n            if args[0].startswith('+'):\n                arg = args.pop(0)\n                filter_name, filter_value = arg[1:].split('=', 1)\n\n                if \"__\" not in filter_name:\n                    filter_name += \"__eq\"\n\n                if filter_name.endswith(\"__null\"):\n                    scan_filter[filter_name] = filter_value == \"true\"\n                else:\n                    scan_filter[filter_name] = self.get_typed_value(filter_name, filter_value)\n\n            elif args[0].startswith('--batch='):\n                arg = args.pop(0)\n                batch_size = int(arg[8:])\n\n            elif args[0].startswith('--max='):\n                arg = args.pop(0)\n                max_size = int(arg[6:])\n\n            elif args[0].startswith('--start='):\n                arg = args.pop(0)\n                start = (arg[8:], )\n\n            elif args[0] == \"--and\":\n                args.pop(0)\n                cond = \"AND\"\n\n            elif args[0] == \"--or\":\n                args.pop(0)\n                cond = \"OR\"\n\n            elif args[0] == '--next':\n                arg = args.pop(0)\n                if self.next_key:\n                    start = self.next_key\n                else:\n                    print \"no next\"\n                    return\n\n            elif args[0] == '-a' or args[0] == '--array':\n                as_array = True\n                args.pop(0)\n\n            elif args[0].startswith('-'):\n                arg = args.pop(0)\n\n                #if arg == '-c' or arg == '--count':\n                #    count = True\n\n                if arg[0] == '-' and arg[1:].isdigit():\n                    max_size = int(arg[1:])\n\n                elif arg == '--':\n                    break\n\n                else:\n                    print \"invalid argument: %s\" % arg\n                    break\n\n            else:\n                break\n\n        attr_keys = args[0].split(\",\") if args else None\n        attrs = list(set(attr_keys)) if attr_keys else None\n\n        result = table.scan(limit=max_size, max_page_size=batch_size, attributes=attrs, conditional_operator=cond, exclusive_start_key=start, **scan_filter)\n\n        #\n        # enable this if you want to see when pages are fetched\n        #\n        if False:\n            _fetch_more = result.fetch_more\n            def fetch_more():\n                print \"==== fetch page ====\"\n                _fetch_more()\n\n            result.fetch_more = fetch_more\n\n        if False: # count:\n            print \"count: %s/%s\" % (result.scanned_count, result.count)\n            self.next_key = None\n        else:\n            if as_array and attr_keys:\n                self.print_iterator_array(result, attr_keys)\n            else:\n                self.print_iterator(result)\n\n            self.next_key = result._last_key_seen\n\n        if self.consumed:\n            print \"consumed units:\", result.consumed_units", "response": "Scan the log file for the related entries."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_rmall(self, line):\n        \"remove [tablename...] yes\"\n        args = self.getargs(line)\n        if args and args[-1] == \"yes\":\n            args.pop()\n\n            if not args:\n                args = [self.table.table_name]\n\n            while args:\n                table = boto.dynamodb2.table.Table(args.pop(0), connection=self.conn)\n                print \"from table \" + table.table_name\n\n                for item in table.scan(attributes_to_get=[], request_limit=10):\n                    print \"  removing %s\" % item\n                    item.delete()\n        else:\n            print \"ok, never mind...\"", "response": "remove [ tablename... ] yes"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsimulates a set of variables.", "response": "def simulate(simulated_variables, year):\n    '''\n    Construction de la DataFrame \u00e0 partir de laquelle sera faite l'analyse des donn\u00e9es\n    '''\n    input_data_frame = get_input_data_frame(year)\n    TaxBenefitSystem = openfisca_france_indirect_taxation.init_country()\n\n    tax_benefit_system = TaxBenefitSystem()\n    survey_scenario = SurveyScenario().init_from_data_frame(\n        input_data_frame = input_data_frame,\n        tax_benefit_system = tax_benefit_system,\n        year = year,\n        )\n    simulation = survey_scenario.new_simulation()\n    return DataFrame(\n        dict([\n            (name, simulation.calculate(name)) for name in simulated_variables\n\n            ])\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wavg(groupe, var):\n    '''\n    Fonction qui calcule la moyenne pond\u00e9r\u00e9e par groupe d'une variable\n    '''\n    d = groupe[var]\n    w = groupe['pondmen']\n    return (d * w).sum() / w.sum()", "response": "Calculate the average value of a variable in a groupe"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncollapse a dataframe into a single variable.", "response": "def collapse(dataframe, groupe, var):\n    '''\n    Pour une variable, fonction qui calcule la moyenne pond\u00e9r\u00e9e au sein de chaque groupe.\n    '''\n    grouped = dataframe.groupby([groupe])\n    var_weighted_grouped = grouped.apply(lambda x: wavg(groupe = x, var = var))\n    return var_weighted_grouped"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef df_weighted_average_grouped(dataframe, groupe, varlist):\n    '''\n    Agr\u00e8ge les r\u00e9sultats de weighted_average_grouped() en une unique dataframe pour la liste de variable 'varlist'.\n    '''\n    return DataFrame(\n        dict([\n            (var, collapse(dataframe, groupe, var)) for var in varlist\n            ])\n        )", "response": "Avec un dataframe de weighted average"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nflattening the value into a single numpy array and a unflatten function.", "response": "def flatten(value):\n    \"\"\"value can be any nesting of tuples, arrays, dicts.\n       returns 1D numpy array and an unflatten function.\"\"\"\n    if isinstance(value, np.ndarray):\n        def unflatten(vector):\n            return np.reshape(vector, value.shape)\n        return np.ravel(value), unflatten\n\n    elif isinstance(value, float):\n        return np.array([value]), lambda x: x[0]\n\n    elif isinstance(value, tuple):\n        if not value:\n            return np.array([]), lambda x: ()\n\n        flattened_first, unflatten_first = flatten(value[0])\n        flattened_rest, unflatten_rest = flatten(value[1:])\n\n        def unflatten(vector):\n            N = len(flattened_first)\n            return (unflatten_first(vector[:N]),) + unflatten_rest(vector[N:])\n\n        return np.concatenate((flattened_first, flattened_rest)), unflatten\n\n    elif isinstance(value, list):\n        if not value:\n            return np.array([]), lambda x: []\n        flattened_first, unflatten_first = flatten(value[0])\n        flattened_rest, unflatten_rest = flatten(value[1:])\n\n        def unflatten(vector):\n            N = len(flattened_first)\n            return [unflatten_first(vector[:N])] + unflatten_rest(vector[N:])\n\n        return np.concatenate((flattened_first, flattened_rest)), unflatten\n\n    elif isinstance(value, dict):\n        flattened = []\n        unflatteners = []\n        lengths = []\n        keys = []\n        for k, v in sorted(value.items(), key=itemgetter(0)):\n            cur_flattened, cur_unflatten = flatten(v)\n            flattened.append(cur_flattened)\n            unflatteners.append(cur_unflatten)\n            lengths.append(len(cur_flattened))\n            keys.append(k)\n\n        def unflatten(vector):\n            split_ixs = np.cumsum(lengths)\n            pieces = np.split(vector, split_ixs)\n            return {key: unflattener(piece)\n                    for piece, unflattener, key in zip(pieces,\n                                                       unflatteners,\n                                                       keys)}\n\n        return np.concatenate(flattened), unflatten\n\n    else:\n        raise Exception(\"Don't know how to flatten type {}\".format(type(value))\n                        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef switch_state(request):\n\n    if request.session.get(SESSION_KEY):\n        request.session[SESSION_KEY] = False\n    else:\n        request.session[SESSION_KEY] = True\n\n    # Get redirect location\n    # Don't go to non local paths\n    url = request.GET.get('redirect_to', '/')\n    if url.startswith('http'):\n        url = '/'\n    return redirect(url)", "response": "Switch the default version state in the session and redirect to the next location"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a JSON object to a string", "response": "def get_db_prep_value(self, value, connection, prepared=False):\n        \"\"\"Convert JSON object to a string\"\"\"\n        if isinstance(value, basestring):\n            return value\n        return json.dumps(value, **self.dump_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncollect the history of what change made to a record field.", "response": "def _CollectHistory_(lookupType, fromVal, toVal, using={}, pattern=''):\n    \"\"\"\n    Return a dictionary detailing what, if any, change was made to a record field\n\n    :param string lookupType: what cleaning rule made the change; one of: genericLookup, genericRegex, fieldSpecificLookup, fieldSpecificRegex, normLookup, normRegex, normIncludes, deriveValue, copyValue, deriveRegex\n    :param string fromVal: previous field value\n    :param string toVal: new string value\n    :param dict using: field values used to derive new values; only applicable for deriveValue, copyValue, deriveRegex\n    :param string pattern: which regex pattern was matched to make the change; only applicable for genericRegex, fieldSpecificRegex, deriveRegex\n    \"\"\"\n\n    histObj = {}\n\n    if fromVal != toVal:\n        histObj[lookupType] = {\"from\": fromVal, \"to\": toVal}\n\n        if lookupType in ['deriveValue', 'deriveRegex', 'copyValue', 'normIncludes', 'deriveIncludes'] and using!='':\n            histObj[lookupType][\"using\"] = using\n        if lookupType in ['genericRegex', 'fieldSpecificRegex', 'normRegex', 'deriveRegex'] and pattern!='':\n            histObj[lookupType][\"pattern\"] = pattern\n\n    return histObj"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _CollectHistoryAgg_(contactHist, fieldHistObj, fieldName):\n\n    if fieldHistObj!={}:\n        if fieldName not in contactHist.keys():\n            contactHist[fieldName] = {}\n        for lookupType in fieldHistObj.keys():\n            contactHist[fieldName][lookupType] = fieldHistObj[lookupType]\n\n    return contactHist", "response": "Collect the updated history dictionary with new field change\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning cleaned value to standardize lookups", "response": "def _DataClean_(fieldVal):\n    \"\"\"\n    Return 'cleaned' value to standardize lookups (convert to uppercase, remove leading/trailing whitespace, carriage returns, line breaks, and unprintable characters)\n\n    :param string fieldVal: field value\n    \"\"\"\n\n    fieldValNew = fieldVal\n\n    fieldValNew = fieldValNew.upper()\n\n    fieldValNew = fieldValNew.strip()\n\n    fieldValNew = re.sub(\"[\\s\\n\\t]+\", \" \", fieldValNew)\n\n    return fieldValNew"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning user - defined functions in a single record.", "response": "def _RunUserDefinedFunctions_(config, data, histObj, position, namespace=__name__):\n    \"\"\"\n    Return a single updated data record and history object after running user-defined functions\n\n    :param dict config: DWM configuration (see DataDictionary)\n    :param dict data: single record (dictionary) to which user-defined functions should be applied\n    :param dict histObj: History object to which changes should be appended\n    :param string position: position name of which function set from config should be run\n    :param namespace: namespace of current working script; must be passed if using user-defined functions\n    \"\"\"\n\n    udfConfig = config['userDefinedFunctions']\n\n    if position in udfConfig:\n\n        posConfig = udfConfig[position]\n\n        for udf in posConfig.keys():\n\n            posConfigUDF = posConfig[udf]\n\n            data, histObj = getattr(sys.modules[namespace], posConfigUDF)(data=data, histObj=histObj)\n\n    return data, histObj"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef feed(self):\n        \"Feed a line from the contents of the GPS log to the daemon.\"\n        line = self.testload.sentences[self.index % len(self.testload.sentences)]\n        if \"%Delay:\" in line:\n            # Delay specified number of seconds\n            delay = line.split()[1]\n            time.sleep(int(delay))\n        # self.write has to be set by the derived class\n        self.write(line)\n        if self.progress:\n            self.progress(\"gpsfake: %s feeds %d=%s\\n\" % (self.testload.name, len(line), repr(line)))\n        time.sleep(WRITE_PAD)\n        self.index += 1", "response": "Feed a line from the contents of the GPS log to the daemon."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nspawning a daemon instance.", "response": "def spawn(self, options, port, background=False, prefix=\"\"):\n        \"Spawn a daemon instance.\"\n        self.spawncmd = None\n\n\t# Look for gpsd in GPSD_HOME env variable\n        if os.environ.get('GPSD_HOME'):\n            for path in os.environ['GPSD_HOME'].split(':'):\n                _spawncmd = \"%s/gpsd\" % path\n                if os.path.isfile(_spawncmd) and os.access(_spawncmd, os.X_OK):\n                    self.spawncmd = _spawncmd\n                    break\n\n\t# if we could not find it yet try PATH env variable for it\n        if not self.spawncmd:\n            if not '/usr/sbin' in os.environ['PATH']:\n                os.environ['PATH']=os.environ['PATH'] + \":/usr/sbin\"\n            for path in os.environ['PATH'].split(':'):\n                _spawncmd = \"%s/gpsd\" % path\n                if os.path.isfile(_spawncmd) and os.access(_spawncmd, os.X_OK):\n                    self.spawncmd = _spawncmd\n                    break\n\n        if not self.spawncmd:\n            raise DaemonError(\"Cannot execute gpsd: executable not found. Set GPSD_HOME env variable\")\n        # The -b option to suppress hanging on probe returns is needed to cope\n        # with OpenBSD (and possibly other non-Linux systems) that don't support\n        # anything we can use to implement the FakeGPS.read() method\n        self.spawncmd += \" -b -N -S %s -F %s -P %s %s\" % (port, self.control_socket, self.pidfile, options)\n        if prefix:\n            self.spawncmd = prefix + \" \" + self.spawncmd.strip()\n        if background:\n            self.spawncmd += \" &\"\n        status = os.system(self.spawncmd)\n        if os.WIFSIGNALED(status) or os.WEXITSTATUS(status):\n            raise DaemonError(\"daemon exited with status %d\" % status)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wait_pid(self):\n        \"Wait for the daemon, get its PID and a control-socket connection.\"\n        while True:\n            try:\n                fp = open(self.pidfile)\n            except IOError:\n                time.sleep(0.1)\n                continue\n            try:\n                fp.seek(0)\n                pidstr = fp.read()\n                self.pid = int(pidstr)\n            except ValueError:\n                time.sleep(0.5)\n                continue\t# Avoid race condition -- PID not yet written\n            fp.close()\n            break", "response": "Wait for the daemon get its PID and a control - socket connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_device(self, path):\n        \"Add a device to the daemon's internal search list.\"\n        if self.__get_control_socket():\n            self.sock.sendall(\"+%s\\r\\n\\x00\" % path)\n            self.sock.recv(12)\n            self.sock.close()", "response": "Add a device to the daemon s internal search list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove a device from the daemon s internal search list.", "response": "def remove_device(self, path):\n        \"Remove a device from the daemon's internal search list.\"\n        if self.__get_control_socket():\n            self.sock.sendall(\"-%s\\r\\n\\x00\" % path)\n            self.sock.recv(12)\n            self.sock.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef kill(self):\n        \"Kill the daemon instance.\"\n        if self.pid:\n            try:\n                os.kill(self.pid, signal.SIGTERM)\n                # Raises an OSError for ESRCH when we've killed it.\n                while True:\n                    os.kill(self.pid, signal.SIGTERM)\n                    time.sleep(0.01)\n            except OSError:\n                pass\n            self.pid = None", "response": "Kill the daemon instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addParts(parentPart, childPath, count, index):\n    if index == None:\n        index = 0\n    if index == len(childPath):\n        return\n    c = childPath[index]\n    parentPart.count = coalesce(parentPart.count, 0) + count\n\n    if parentPart.partitions == None:\n        parentPart.partitions = FlatList()\n    for i, part in enumerate(parentPart.partitions):\n        if part.name == c.name:\n            addParts(part, childPath, count, index + 1)\n            return\n\n    parentPart.partitions.append(c)\n    addParts(c, childPath, count, index + 1)", "response": "A helper method to build a hierarchy by repeating self METHOD WITH VARIOUS childPaths count IS THE NUMBER FOUND FOR self PATH"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nencrypting a text string using a key and return a JSON object.", "response": "def encrypt(text, _key, salt=None):\n    \"\"\"\n    RETURN {\"salt\":s, \"length\":l, \"data\":d} -> JSON -> UTF8\n    \"\"\"\n\n    if is_text(text):\n        encoding = 'utf8'\n        data = bytearray(text.encode(\"utf8\"))\n    elif is_binary(text):\n        encoding = None\n        if PY2:\n            data = bytearray(text)\n        else:\n            data = text\n\n    if _key is None:\n        Log.error(\"Expecting a key\")\n    if is_binary(_key):\n        _key = bytearray(_key)\n    if salt is None:\n        salt = Random.bytes(16)\n\n    # Initialize encryption using key and iv\n    key_expander_256 = key_expander.KeyExpander(256)\n    expanded_key = key_expander_256.expand(_key)\n    aes_cipher_256 = aes_cipher.AESCipher(expanded_key)\n    aes_cbc_256 = cbc_mode.CBCMode(aes_cipher_256, 16)\n    aes_cbc_256.set_iv(salt)\n\n    output = Data()\n    output.type = \"AES256\"\n    output.salt = bytes2base64(salt)\n    output.length = len(data)\n    output.encoding = encoding\n\n    encrypted = bytearray()\n    for _, d in _groupby16(data):\n        encrypted.extend(aes_cbc_256.encrypt_block(d))\n    output.data = bytes2base64(encrypted)\n    json = get_module(\"mo_json\").value2json(output, pretty=True).encode('utf8')\n\n    if DEBUG:\n        test = decrypt(json, _key)\n        if test != text:\n            Log.error(\"problem with encryption\")\n\n    return json"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decrypt(data, _key):\n    # Key and iv have not been generated or provided, bail out\n    if _key is None:\n        Log.error(\"Expecting a key\")\n\n    _input = get_module(\"mo_json\").json2value(data.decode('utf8'), leaves=False, flexible=False)\n\n    # Initialize encryption using key and iv\n    key_expander_256 = key_expander.KeyExpander(256)\n    expanded_key = key_expander_256.expand(_key)\n    aes_cipher_256 = aes_cipher.AESCipher(expanded_key)\n    aes_cbc_256 = cbc_mode.CBCMode(aes_cipher_256, 16)\n    aes_cbc_256.set_iv(base642bytearray(_input.salt))\n\n    raw = base642bytearray(_input.data)\n    out_data = bytearray()\n    for _, e in _groupby16(raw):\n        out_data.extend(aes_cbc_256.decrypt_block(e))\n\n    if _input.encoding:\n        return binary_type(out_data[:_input.length:]).decode(_input.encoding)\n    else:\n        return binary_type(out_data[:_input.length:])", "response": "Decrypt a byte string using a key and return the decrypted data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary that can be used to generate the query string for the api url.", "response": "def get_qs(self):\n        \"\"\"\n        Returns a mapping that will be used to generate\n        the query string for the api url. Any values\n        in the the `limit_choices_to` specified on the\n        foreign key field and any arguments specified on\n        self.extra_query_kwargs are converted to a format\n        that can be used in a query string and returned as\n        a dictionary.\n        \"\"\"\n        qs = url_params_from_lookup_dict(self.rel.limit_choices_to)\n        if not qs:\n            qs = {}\n\n        if self.extra_query_kwargs:\n            qs.update(self.extra_query_kwargs)\n        return qs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the url to the API link to retrieve the available items for the current locale.", "response": "def get_api_link(self):\n        \"\"\"\n        Adds a query string to the api url. At minimum adds the type=choices\n        argument so that the return format is json. Any other filtering\n        arguments calculated by the `get_qs` method are then added to the\n        url. It is up to the destination url to respect them as filters.\n        \"\"\"\n        url = self._api_link\n        if url:\n            qs = self.get_qs()\n            url = \"%s?type=choices\" % url\n            if qs:\n                url = \"%s&amp;%s\" % (url, u'&amp;'.join([u'%s=%s' % (k, urllib.quote(unicode(v).encode('utf8'))) \\\n                                                        for k, v in qs.items()]))\n                url = \"%s&amp;%s\" % (url, u'&amp;'.join([u'exclude=%s' % x \\\n                                                        for x in qs.keys()]))\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a unicode string that corresponds to the given value.", "response": "def label_for_value(self, value, key=None):\n        \"\"\"\n        Looks up the current value of the field and returns\n        a unicode representation. Default implementation does a lookup\n        on the target model and if a match is found calls force_unicode\n        on that object. Otherwise a blank string is returned.\n        \"\"\"\n        if not key:\n            key = self.rel.get_related_field().name\n\n        if value is not None:\n            try:\n                obj = self.model._default_manager.using(self.db).get(**{key: value})\n                return force_unicode(obj)\n            except (ValueError, self.model.DoesNotExist):\n                return ''\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_links(self, request, admin_site=None):\n        if admin_site:\n            bundle = admin_site.get_bundle_for_model(self.model.to)\n\n            if bundle:\n                self._api_link = self._get_bundle_link(bundle, self.view,\n                                                       request.user)\n                self._add_link = self._get_bundle_link(bundle, self.add_view,\n                                                       request.user)", "response": "Updates the internal links for the current instance of the current widget."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new object - class based on the given object - schema and model name.", "response": "def schema_class(self, object_schema, model_name, classes=False):\n        \"\"\"\n        Create a object-class based on the object_schema.  Use\n        this class to create specific instances, and validate the\n        data values.  See the \"python-jsonschema-objects\" package\n        for details on further usage.\n\n        Parameters\n        ----------\n        object_schema : dict\n            The JSON-schema that defines the object\n\n        model_name : str\n            if provided, the name given to the new class.  if not\n            provided, then the name will be determined by\n            one of the following schema values, in this order:\n            ['x-model', 'title', 'id']\n\n        classes : bool\n            When `True`, this method will return the complete\n            dictionary of all resolved object-classes built\n            from the object_schema.  This can be helpful\n            when a deeply nested object_schema is provided; but\n            generally not necessary.  You can then create\n            a :class:`Namespace` instance using this dict.  See\n            the 'python-jschonschema-objects.utls' package\n            for further details.\n\n            When `False` (default), return only the object-class\n\n        Returns\n        -------\n            - new class for given object_schema (default)\n            - dict of all classes when :param:`classes` is True\n        \"\"\"\n\n        # if not model_name:\n        #     model_name = SchemaObjectFactory.schema_model_name(object_schema)\n\n        cls_bldr = ClassBuilder(self.resolver)\n        model_cls = cls_bldr.construct(model_name, object_schema)\n\n        # if `classes` is False(0) return the new model class,\n        # else return all the classes resolved\n        model_cls.proptype = SchemaObjectFactory.proptype\n        return [model_cls, cls_bldr.resolved][classes]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the class that is used by the lru_cache do not call directly", "response": "def __model_class(self, model_name):\n        \"\"\" this method is used by the lru_cache, do not call directly \"\"\"\n        build_schema = deepcopy(self.definitions[model_name])\n        return self.schema_class(build_schema, model_name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the binomial coefficient n choose k.", "response": "def binom(n, k):\n    \"\"\"\n    Returns binomial coefficient (n choose k).\n    \"\"\"\n    # http://blog.plover.com/math/choose.html\n    if k > n:\n        return 0\n    if k == 0:\n        return 1\n    result = 1\n    for denom in range(1, k + 1):\n        result *= n\n        result /= denom\n        n -= 1\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns number rounded to digits digits.", "response": "def round_to_x_digits(number, digits):\n    \"\"\"\n    Returns 'number' rounded to 'digits' digits.\n    \"\"\"\n    return round(number * math.pow(10, digits)) / math.pow(10, digits)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nyielding the values of the current set of CANONICAL REPRESENTATIVE entries.", "response": "def values(self):\n        \"\"\"\n        TRY NOT TO USE THIS, IT IS SLOW\n        \"\"\"\n        matrix = self.data.values()[0]  # CANONICAL REPRESENTATIVE\n        if matrix.num == 0:\n            return\n        e_names = self.edges.name\n        s_names = self.select.name\n        parts = [e.domain.partitions.value if e.domain.primitive else e.domain.partitions for e in self.edges]\n        for c in matrix._all_combos():\n            try:\n                output = {n: parts[i][c[i]] for i, n in enumerate(e_names)}\n            except Exception as e:\n                Log.error(\"problem\", cause=e)\n            for s in s_names:\n                output[s] = self.data[s][c]\n            yield wrap(output)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef forall(self, method):\n        if not self.is_value:\n            Log.error(\"Not dealing with this case yet\")\n\n        matrix = self.data.values()[0]\n        parts = [e.domain.partitions for e in self.edges]\n        for c in matrix._all_combos():\n            method(matrix[c], [parts[i][cc] for i, cc in enumerate(c)], self)", "response": "For all of the items in the current set call method on all of the items in the set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngrouping by method for the internal data structure.", "response": "def _groupby(self, edges):\n        \"\"\"\n        RETURNS LIST OF (coord, values) TUPLES, WHERE\n            coord IS THE INDEX INTO self CUBE (-1 INDEX FOR COORDINATES NOT GROUPED BY)\n            values ALL VALUES THAT BELONG TO THE SLICE\n\n        \"\"\"\n        edges = FlatList([n for e in edges for n in _normalize_edge(e)])\n\n        stacked = [e for e in self.edges if e.name in edges.name]\n        remainder = [e for e in self.edges if e.name not in edges.name]\n        selector = [1 if e.name in edges.name else 0 for e in self.edges]\n\n        if len(stacked) + len(remainder) != len(self.edges):\n            Log.error(\"can not find some edges to group by\")\n        # CACHE SOME RESULTS\n        keys = edges.name\n        getKey = [e.domain.getKey for e in self.edges]\n        lookup = [[getKey[i](p) for p in e.domain.partitions+([None] if e.allowNulls else [])] for i, e in enumerate(self.edges)]\n\n        if is_list(self.select):\n            selects = listwrap(self.select)\n            index, v = transpose(*self.data[selects[0].name].groupby(selector))\n\n            coord = wrap([coord2term(c) for c in index])\n\n            values = [v]\n            for s in selects[1::]:\n                i, v = transpose(*self.data[s.name].group_by(selector))\n                values.append(v)\n\n            output = transpose(coord, [Cube(self.select, remainder, {s.name: v[i] for i, s in enumerate(selects)}) for v in zip(*values)])\n        elif not remainder:\n            # v IS A VALUE, NO NEED TO WRAP IT IN A Cube\n            output = (\n                (\n                    coord2term(coord),\n                    v\n                )\n                for coord, v in self.data[self.select.name].groupby(selector)\n            )\n        else:\n            output = (\n                (\n                    coord2term(coord),\n                    Cube(self.select, remainder, v)\n                )\n                for coord, v in self.data[self.select.name].groupby(selector)\n            )\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving the origin_spec to a local file in JSON format", "response": "def save_swagger_spec(self, filepath=None):\n        \"\"\"\n        Saves a copy of the origin_spec to a local file in JSON format\n        \"\"\"\n        if filepath is True or filepath is None:\n            filepath = self.file_spec.format(server=self.server)\n\n        json.dump(self.origin_spec, open(filepath, 'w+'), indent=3)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the origin_spec from a local JSON file.", "response": "def load_swagger_spec(self, filepath=None):\n        \"\"\"\n        Loads the origin_spec from a local JSON file.  If `filepath`\n        is not provided, then the class `file_spec` format will be used\n        to create the file-path value.\n        \"\"\"\n        if filepath is True or filepath is None:\n            filepath = self.file_spec.format(server=self.server)\n\n        return json.load(open(filepath))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef preprocess_legislation(legislation_json):\n    '''\n    Preprocess the legislation parameters to add prices and amounts from national accounts\n    '''\n    import os\n    import pkg_resources\n    import pandas as pd\n\n    # Add fuel prices to the tree\n\n    default_config_files_directory = os.path.join(\n        pkg_resources.get_distribution('openfisca_france_indirect_taxation').location)\n    prix_annuel_carburants = pd.read_csv(\n        os.path.join(\n            default_config_files_directory,\n            'openfisca_france_indirect_taxation',\n            'assets',\n            'prix',\n            'prix_annuel_carburants.csv'\n            ), sep =';'\n        )\n    prix_annuel_carburants['Date'] = prix_annuel_carburants['Date'].astype(int)\n    prix_annuel_carburants = prix_annuel_carburants.set_index('Date')\n    all_values = {}\n    prix_carburants = {\n        \"@type\": \"Node\",\n        \"description\": \"prix des carburants en euros par hectolitre\",\n        \"children\": {},\n        }\n    # For super_95_e10, we need to use the price of super_95 between 2009 and 2012 included,\n    # because we don't have the data. We use super_95 because it is very close and won't affect the results too much\n    prix_annuel = prix_annuel_carburants['super_95_e10_ttc']\n    all_values['super_95_e10_ttc'] = []\n    for year in range(1990, 2009):\n        values1 = dict()\n        values1['start'] = u'{}-01-01'.format(year)\n        values1['stop'] = u'{}-12-31'.format(year)\n        values1['value'] = prix_annuel.loc[year] * 100\n        all_values['super_95_e10_ttc'].append(values1)\n    prix_annuel = prix_annuel_carburants['super_95_ttc']\n    for year in range(2009, 2013):\n        values2 = dict()\n        values2['start'] = u'{}-01-01'.format(year)\n        values2['stop'] = u'{}-12-31'.format(year)\n        values2['value'] = prix_annuel.loc[year] * 100\n        all_values['super_95_e10_ttc'].append(values2)\n    prix_annuel = prix_annuel_carburants['super_95_e10_ttc']\n    for year in range(2013, 2015):\n        values3 = dict()\n        values3['start'] = u'{}-01-01'.format(year)\n        values3['stop'] = u'{}-12-31'.format(year)\n        values3['value'] = prix_annuel.loc[year] * 100\n        all_values['super_95_e10_ttc'].append(values3)\n\n    prix_carburants['children']['super_95_e10_ttc'] = {\n        \"@type\": \"Parameter\",\n        \"description\": 'super_95_e10_ttc'.replace('_', ' '),\n        \"format\": \"float\",\n        \"values\": all_values['super_95_e10_ttc']\n        }\n    for element in ['diesel_ht', 'diesel_ttc', 'super_95_ht', 'super_95_ttc', 'super_98_ht', 'super_98_ttc',\n            'super_95_e10_ht', 'gplc_ht', 'gplc_ttc', 'super_plombe_ht', 'super_plombe_ttc']:\n        assert element in prix_annuel_carburants.columns\n        prix_annuel = prix_annuel_carburants[element]\n        all_values[element] = []\n        for year in range(1990, 2015):\n            values = dict()\n            values['start'] = u'{}-01-01'.format(year)\n            values['stop'] = u'{}-12-31'.format(year)\n            values['value'] = prix_annuel.loc[year] * 100\n            all_values[element].append(values)\n\n        prix_carburants['children'][element] = {\n            \"@type\": \"Parameter\",\n            \"description\": element.replace('_', ' '),\n            \"format\": \"float\",\n            \"values\": all_values[element]\n            }\n\n    legislation_json['children']['imposition_indirecte']['children']['prix_carburants'] = prix_carburants\n\n    # Add the number of vehicle in circulation to the tree\n\n    default_config_files_directory = os.path.join(\n        pkg_resources.get_distribution('openfisca_france_indirect_taxation').location)\n    parc_annuel_moyen_vp = pd.read_csv(\n        os.path.join(\n            default_config_files_directory,\n            'openfisca_france_indirect_taxation',\n            'assets',\n            'quantites',\n            'parc_annuel_moyen_vp.csv'\n            ), sep =';'\n        )\n\n    parc_annuel_moyen_vp = parc_annuel_moyen_vp.set_index('Unnamed: 0')\n    values_parc = {}\n    parc_vp = {\n        \"@type\": \"Node\",\n        \"description\": \"taille moyenne du parc automobile en France m\u00e9tropolitaine en milliers de v\u00e9hicules\",\n        \"children\": {},\n    }\n    for element in ['diesel', 'essence']:\n        taille_parc = parc_annuel_moyen_vp[element]\n        values_parc[element] = []\n        for year in range(1990, 2014):\n            values = dict()\n            values['start'] = u'{}-01-01'.format(year)\n            values['stop'] = u'{}-12-31'.format(year)\n            values['value'] = taille_parc.loc[year]\n            values_parc[element].append(values)\n\n        parc_vp['children'][element] = {\n            \"@type\": \"Parameter\",\n            \"description\": \"nombre de v\u00e9hicules particuliers immatricul\u00e9s en France \u00e0 motorisation \" + element,\n            \"format\": \"float\",\n            \"values\": values_parc[element]\n        }\n\n        legislation_json['children']['imposition_indirecte']['children']['parc_vp'] = parc_vp\n\n    # Add the total quantity of fuel consumed per year to the tree\n\n    default_config_files_directory = os.path.join(\n        pkg_resources.get_distribution('openfisca_france_indirect_taxation').location)\n    quantite_carbu_vp_france = pd.read_csv(\n        os.path.join(\n            default_config_files_directory,\n            'openfisca_france_indirect_taxation',\n            'assets',\n            'quantites',\n            'quantite_carbu_vp_france.csv'\n            ), sep =';'\n        )\n\n    quantite_carbu_vp_france = quantite_carbu_vp_france.set_index('Unnamed: 0')\n    values_quantite = {}\n    quantite_carbu_vp = {\n        \"@type\": \"Node\",\n        \"description\": \"quantite de carburants consomm\u00e9s en France m\u00e9tropolitaine\",\n        \"children\": {},\n    }\n    for element in ['diesel', 'essence']:\n        quantite_carburants = quantite_carbu_vp_france[element]\n        values_quantite[element] = []\n        for year in range(1990, 2014):\n            values = dict()\n            values['start'] = u'{}-01-01'.format(year)\n            values['stop'] = u'{}-12-31'.format(year)\n            values['value'] = quantite_carburants.loc[year]\n            values_quantite[element].append(values)\n\n        quantite_carbu_vp['children'][element] = {\n            \"@type\": \"Parameter\",\n            \"description\": \"consommation totale de \" + element + \" en France\",\n            \"format\": \"float\",\n            \"values\": values_quantite[element]\n        }\n\n        legislation_json['children']['imposition_indirecte']['children']['quantite_carbu_vp'] = quantite_carbu_vp\n\n    # Add the shares of each type of supercabrurant (SP95, SP98, E10, etc.) among supercarburants\n\n    default_config_files_directory = os.path.join(\n        pkg_resources.get_distribution('openfisca_france_indirect_taxation').location)\n    part_des_types_de_supercarburants = pd.read_csv(\n        os.path.join(\n            default_config_files_directory,\n            'openfisca_france_indirect_taxation',\n            'assets',\n            'part_des_types_de_supercarburants.csv'\n            ), sep =';'\n        )\n\n    del part_des_types_de_supercarburants['Source']\n    part_des_types_de_supercarburants = \\\n        part_des_types_de_supercarburants[part_des_types_de_supercarburants['annee'] > 0].copy()\n    part_des_types_de_supercarburants['annee'] = part_des_types_de_supercarburants['annee'].astype(int)\n    part_des_types_de_supercarburants = part_des_types_de_supercarburants.set_index('annee')\n\n    # delete share of e_85 because we have no data for its price\n    # When the sum of all shares is not one, need to multiply each share by the same coefficient\n    cols = part_des_types_de_supercarburants.columns\n    for element in cols:\n        part_des_types_de_supercarburants[element] = (\n            part_des_types_de_supercarburants[element] /\n            (part_des_types_de_supercarburants['somme'] - part_des_types_de_supercarburants['sp_e85'])\n            )\n    del part_des_types_de_supercarburants['sp_e85']\n    del part_des_types_de_supercarburants['somme']\n    cols = part_des_types_de_supercarburants.columns\n    part_des_types_de_supercarburants['somme'] = 0\n    for element in cols:\n        part_des_types_de_supercarburants['somme'] += part_des_types_de_supercarburants[element]\n    assert (part_des_types_de_supercarburants['somme'] == 1).any(), \"The weighting of the shares did not work\"\n\n\n    values_part_supercarburants = {}\n    part_type_supercaburant = {\n        \"@type\": \"Node\",\n        \"description\": \"part de la consommation totale d'essence de chaque type supercarburant\",\n        \"children\": {},\n    }\n    for element in ['super_plombe', 'sp_95', 'sp_98', 'sp_e10']:\n        part_par_carburant = part_des_types_de_supercarburants[element]\n        values_part_supercarburants[element] = []\n        for year in range(2000, 2015):\n            values = dict()\n            values['start'] = u'{}-01-01'.format(year)\n            values['stop'] = u'{}-12-31'.format(year)\n            values['value'] = part_par_carburant.loc[year]\n            values_part_supercarburants[element].append(values)\n\n        part_type_supercaburant['children'][element] = {\n            \"@type\": \"Parameter\",\n            \"description\": \"part de \" + element + \" dans la consommation totale d'essences\",\n            \"format\": \"float\",\n            \"values\": values_part_supercarburants[element]\n        }\n\n        legislation_json['children']['imposition_indirecte']['children']['part_type_supercarburants'] = \\\n            part_type_supercaburant\n\n    # Add data from comptabilite national about alcohol\n\n    alcool_conso_et_vin = {\n        \"@type\": \"Node\",\n        \"description\": \"alcools\",\n        \"children\": {},\n        }\n    alcool_conso_et_vin['children']['vin'] = {\n        \"@type\": \"Node\",\n        \"description\": \"Pour calculer le taux de taxation implicite sur le vin\",\n        \"children\": {\n            \"droit_cn_vin\": {\n                \"@type\": \"Parameter\",\n                \"description\": u\"Masse droit vin, vin mousseux, cidres et poir\u00e9s selon comptabilit\u00e9 nationale\",\n                \"format\": \"float\",\n                \"values\": [\n                    {'start': u'1995-01-01', 'stop': u'1995-12-31', 'value': 129},\n                    {'start': u'1996-01-01', 'stop': u'1996-12-31', 'value': 130},\n                    {'start': u'1997-01-01', 'stop': u'1997-12-31', 'value': 129},\n                    {'start': u'1998-01-01', 'stop': u'1998-12-31', 'value': 132},\n                    {'start': u'1999-01-01', 'stop': u'1999-12-31', 'value': 133},\n                    {'start': u'2000-01-01', 'stop': u'2000-12-31', 'value': 127},\n                    {'start': u'2001-01-01', 'stop': u'2001-12-31', 'value': 127},\n                    {'start': u'2002-01-01', 'stop': u'2002-12-31', 'value': 127},\n                    {'start': u'2003-01-01', 'stop': u'2003-12-31', 'value': 127},\n                    {'start': u'2004-01-01', 'stop': u'2004-12-31', 'value': 125},\n                    {'start': u'2005-01-01', 'stop': u'2005-12-31', 'value': 117},\n                    {'start': u'2006-01-01', 'stop': u'2006-12-31', 'value': 119},\n                    {'start': u'2007-01-01', 'stop': u'2007-12-31', 'value': 117},\n                    {'start': u'2008-01-01', 'stop': u'2008-12-31', 'value': 114},\n                    {'start': u'2009-01-01', 'stop': u'2009-12-31', 'value': 117},\n                    {'start': u'2010-01-01', 'stop': u'2010-12-31', 'value': 119},\n                    {'start': u'2011-01-01', 'stop': u'2011-12-31', 'value': 118},\n                    {'start': u'2012-01-01', 'stop': u'2012-12-31', 'value': 120},\n                    {'start': u'2013-01-01', 'stop': u'2013-12-31', 'value': 122},\n                    # {'start': u'2014-01-01', 'stop': u'2014-12-31', 'value': },\n                    ],\n                },\n            \"masse_conso_cn_vin\": {\n                \"@type\": \"Parameter\",\n                \"description\": u\"Masse consommation vin, vin mousseux, cidres et poir\u00e9s selon comptabilit\u00e9 nationale\",\n                \"format\": \"float\",\n                \"values\": [\n                    {'start': u'1995-01-01', 'stop': u'1995-12-31', 'value': 7191},\n                    {'start': u'1996-01-01', 'stop': u'1996-12-31', 'value': 7419},\n                    {'start': u'1997-01-01', 'stop': u'1997-12-31', 'value': 7636},\n                    {'start': u'1998-01-01', 'stop': u'1998-12-31', 'value': 8025},\n                    {'start': u'1999-01-01', 'stop': u'1999-12-31', 'value': 8451},\n                    {'start': u'2000-01-01', 'stop': u'2000-12-31', 'value': 8854},\n                    {'start': u'2001-01-01', 'stop': u'2001-12-31', 'value': 9168},\n                    {'start': u'2002-01-01', 'stop': u'2002-12-31', 'value': 9476},\n                    {'start': u'2003-01-01', 'stop': u'2003-12-31', 'value': 9695},\n                    {'start': u'2004-01-01', 'stop': u'2004-12-31', 'value': 9985},\n                    {'start': u'2005-01-01', 'stop': u'2005-12-31', 'value': 9933},\n                    {'start': u'2006-01-01', 'stop': u'2006-12-31', 'value': 10002},\n                    {'start': u'2007-01-01', 'stop': u'2007-12-31', 'value': 10345},\n                    {'start': u'2008-01-01', 'stop': u'2008-12-31', 'value': 10461},\n                    {'start': u'2009-01-01', 'stop': u'2009-12-31', 'value': 10728},\n                    {'start': u'2010-01-01', 'stop': u'2010-12-31', 'value': 11002},\n                    {'start': u'2011-01-01', 'stop': u'2011-12-31', 'value': 11387},\n                    {'start': u'2012-01-01', 'stop': u'2012-12-31', 'value': 11407},\n                    {'start': u'2013-01-01', 'stop': u'2013-12-31', 'value': 11515},\n                    # {'start': u'2014-01-01', 'stop': u'2014-12-31', 'value': },\n                    ],\n                },\n            },\n        }\n\n    alcool_conso_et_vin['children']['biere'] = {\n        \"@type\": \"Node\",\n        \"description\": \"Pour calculer le taux de taxation implicite sur la bi\u00e8re\",\n        \"children\": {\n            \"droit_cn_biere\": {\n                \"@type\": \"Parameter\",\n                \"description\": \"Masse droit biere selon comptabilit\u00e9 nationale\",\n                \"format\": \"float\",\n                \"values\": [\n                    {'start': u'1995-01-01', 'stop': u'1995-12-31', 'value': 361},\n                    {'start': u'1996-01-01', 'stop': u'1996-12-31', 'value': 366},\n                    {'start': u'1997-01-01', 'stop': u'1997-12-31', 'value': 364},\n                    {'start': u'1998-01-01', 'stop': u'1998-12-31', 'value': 365},\n                    {'start': u'1999-01-01', 'stop': u'1999-12-31', 'value': 380},\n                    {'start': u'2000-01-01', 'stop': u'2000-12-31', 'value': 359},\n                    {'start': u'2001-01-01', 'stop': u'2001-12-31', 'value': 364},\n                    {'start': u'2002-01-01', 'stop': u'2002-12-31', 'value': 361},\n                    {'start': u'2003-01-01', 'stop': u'2003-12-31', 'value': 370},\n                    {'start': u'2004-01-01', 'stop': u'2004-12-31', 'value': 378},\n                    {'start': u'2005-01-01', 'stop': u'2005-12-31', 'value': 364},\n                    {'start': u'2006-01-01', 'stop': u'2006-12-31', 'value': 396},\n                    {'start': u'2007-01-01', 'stop': u'2007-12-31', 'value': 382},\n                    {'start': u'2008-01-01', 'stop': u'2008-12-31', 'value': 375},                                            {'start': u'2009-01-01', 'stop': u'2009-12-31', 'value': 376},\n                    {'start': u'2010-01-01', 'stop': u'2010-12-31', 'value': 375},\n                    {'start': u'2011-01-01', 'stop': u'2011-12-31', 'value': 393},\n                    {'start': u'2012-01-01', 'stop': u'2012-12-31', 'value': 783},\n                    {'start': u'2013-01-01', 'stop': u'2013-12-31', 'value': 897},\n                    # {'start': u'2014-01-01', 'stop': u'2014-12-31', 'value': },\n                    ],\n                },\n            \"masse_conso_cn_biere\": {\n                \"@type\": \"Parameter\",\n                \"description\": u\"Masse consommation biere selon comptabilit\u00e9 nationale\",\n                \"format\": \"float\",\n                \"values\": [\n                    {'start': u'1995-01-01', 'stop': u'1995-12-31', 'value': 2111},\n                    {'start': u'1996-01-01', 'stop': u'1996-12-31', 'value': 2144},\n                    {'start': u'1997-01-01', 'stop': u'1997-12-31', 'value': 2186},\n                    {'start': u'1998-01-01', 'stop': u'1998-12-31', 'value': 2291},\n                    {'start': u'1999-01-01', 'stop': u'1999-12-31', 'value': 2334},\n                    {'start': u'2000-01-01', 'stop': u'2000-12-31', 'value': 2290},\n                    {'start': u'2001-01-01', 'stop': u'2001-12-31', 'value': 2327},\n                    {'start': u'2002-01-01', 'stop': u'2002-12-31', 'value': 2405},\n                    {'start': u'2003-01-01', 'stop': u'2003-12-31', 'value': 2554},\n                    {'start': u'2004-01-01', 'stop': u'2004-12-31', 'value': 2484},\n                    {'start': u'2005-01-01', 'stop': u'2005-12-31', 'value': 2466},\n                    {'start': u'2006-01-01', 'stop': u'2006-12-31', 'value': 2486},\n                    {'start': u'2007-01-01', 'stop': u'2007-12-31', 'value': 2458},\n                    {'start': u'2008-01-01', 'stop': u'2008-12-31', 'value': 2287},\n                    {'start': u'2009-01-01', 'stop': u'2009-12-31', 'value': 2375},\n                    {'start': u'2010-01-01', 'stop': u'2010-12-31', 'value': 2461},\n                    {'start': u'2011-01-01', 'stop': u'2011-12-31', 'value': 2769},\n                    {'start': u'2012-01-01', 'stop': u'2012-12-31', 'value': 2868},\n                    {'start': u'2013-01-01', 'stop': u'2013-12-31', 'value': 3321},\n                    # {'start': u'2014-01-01', 'stop': u'2014-12-31', 'value': },\n                    ],\n                },\n            },\n        }\n\n    alcool_conso_et_vin['children']['alcools_forts'] = {\n        \"@type\": \"Node\",\n        \"description\": \"Pour calculer le taux de taxation implicite sur alcools forts\",\n        \"children\": {\n            \"droit_cn_alcools\": {\n                \"@type\": \"Parameter\",\n                \"description\": \"Masse droit alcool selon comptabilit\u00e9 nationale sans droits sur les produits intermediaires et cotisation sp\u00e9ciale alcool fort\",\n                \"format\": \"float\",\n                \"values\": [\n                    {'start': u'2000-01-01', 'stop': u'2000-12-31', 'value': 1872},\n                    {'start': u'2001-01-01', 'stop': u'2001-12-31', 'value': 1957},\n                    {'start': u'2002-01-01', 'stop': u'2002-12-31', 'value': 1932},\n                    {'start': u'2003-01-01', 'stop': u'2003-12-31', 'value': 1891},\n                    {'start': u'2004-01-01', 'stop': u'2004-12-31', 'value': 1908},\n                    {'start': u'2005-01-01', 'stop': u'2005-12-31', 'value': 1842},\n                    {'start': u'2006-01-01', 'stop': u'2006-12-31', 'value': 1954},\n                    {'start': u'2007-01-01', 'stop': u'2007-12-31', 'value': 1990},\n                    {'start': u'2008-01-01', 'stop': u'2008-12-31', 'value': 2005},\n                    {'start': u'2009-01-01', 'stop': u'2009-12-31', 'value': 2031},\n                    {'start': u'2010-01-01', 'stop': u'2010-12-31', 'value': 2111},\n                    {'start': u'2011-01-01', 'stop': u'2011-12-31', 'value': 2150},\n                    {'start': u'2012-01-01', 'stop': u'2012-12-31', 'value': 2225},\n                    # TODO: Probl\u00e8me pour les alcools forts chiffres diff\u00e9rents entre les deux bases excel !\n                    ],\n                },\n            \"droit_cn_alcools_total\": {\n                \"@type\": \"Parameter\",\n                \"description\": u\"Masse droit alcool selon comptabilit\u00e9 nationale avec les differents droits\",\n                \"format\": \"float\",\n                \"values\": [\n                    {'start': u'1995-01-01', 'stop': u'1995-12-31', 'value': 2337},\n                    {'start': u'1996-01-01', 'stop': u'1996-12-31', 'value': 2350},\n                    {'start': u'1997-01-01', 'stop': u'1997-12-31', 'value': 2366},\n                    {'start': u'1998-01-01', 'stop': u'1998-12-31', 'value': 2369},\n                    {'start': u'1999-01-01', 'stop': u'1999-12-31', 'value': 2385},\n                    {'start': u'2000-01-01', 'stop': u'2000-12-31', 'value': 2416},                                            {'start': u'2001-01-01', 'stop': u'2001-12-31', 'value': 2514},\n                    {'start': u'2002-01-01', 'stop': u'2002-12-31', 'value': 2503},\n                    {'start': u'2003-01-01', 'stop': u'2003-12-31', 'value': 2453},\n                    {'start': u'2004-01-01', 'stop': u'2004-12-31', 'value': 2409},\n                    {'start': u'2005-01-01', 'stop': u'2005-12-31', 'value': 2352},\n                    {'start': u'2006-01-01', 'stop': u'2006-12-31', 'value': 2477},\n                    {'start': u'2007-01-01', 'stop': u'2007-12-31', 'value': 2516},\n                    {'start': u'2008-01-01', 'stop': u'2008-12-31', 'value': 2528},\n                    {'start': u'2009-01-01', 'stop': u'2009-12-31', 'value': 2629},\n                    {'start': u'2010-01-01', 'stop': u'2010-12-31', 'value': 2734},\n                    {'start': u'2011-01-01', 'stop': u'2011-12-31', 'value': 3078},\n                    {'start': u'2012-01-01', 'stop': u'2012-12-31', 'value': 2718},\n                    {'start': u'2013-01-01', 'stop': u'2013-12-31', 'value': 3022},\n                    # {'start': u'2014-01-01', 'stop': u'2014-12-31', 'value': },\n                    ],\n                },\n            \"masse_conso_cn_alcools\": {\n                \"@type\": \"Parameter\",\n                \"description\": u\"Masse consommation alcool selon comptabilit\u00e9 nationale\",\n                \"format\": \"float\",\n                \"values\": [\n                    {'start': u'1995-01-01', 'stop': u'1995-12-31', 'value': 4893},\n                    {'start': u'1996-01-01', 'stop': u'1996-12-31', 'value': 5075},\n                    {'start': u'1997-01-01', 'stop': u'1997-12-31', 'value': 5065},\n                    {'start': u'1998-01-01', 'stop': u'1998-12-31', 'value': 5123},\n                    {'start': u'1999-01-01', 'stop': u'1999-12-31', 'value': 5234},\n                    {'start': u'2000-01-01', 'stop': u'2000-12-31', 'value': 5558},\n                    {'start': u'2001-01-01', 'stop': u'2001-12-31', 'value': 5721},\n                    {'start': u'2002-01-01', 'stop': u'2002-12-31', 'value': 5932},\n                    {'start': u'2003-01-01', 'stop': u'2003-12-31', 'value': 5895},\n                    {'start': u'2004-01-01', 'stop': u'2004-12-31', 'value': 5967},\n                    {'start': u'2005-01-01', 'stop': u'2005-12-31', 'value': 5960},\n                    {'start': u'2006-01-01', 'stop': u'2006-12-31', 'value': 6106},\n                    {'start': u'2007-01-01', 'stop': u'2007-12-31', 'value': 6142},\n                    {'start': u'2008-01-01', 'stop': u'2008-12-31', 'value': 6147},\n                    {'start': u'2009-01-01', 'stop': u'2009-12-31', 'value': 6342},\n                    {'start': u'2010-01-01', 'stop': u'2010-12-31', 'value': 6618},\n                    {'start': u'2011-01-01', 'stop': u'2011-12-31', 'value': 6680},\n                    {'start': u'2012-01-01', 'stop': u'2012-12-31', 'value': 6996},\n                    {'start': u'2013-01-01', 'stop': u'2013-12-31', 'value': 7022},\n                    ],\n                },\n            },\n        }\n\n    legislation_json['children']['imposition_indirecte']['children']['alcool_conso_et_vin'] = alcool_conso_et_vin\n\n    # Make the change from francs to euros for excise taxes in ticpe\n    keys_ticpe = legislation_json['children']['imposition_indirecte']['children']['ticpe']['children'].keys()\n    for element in keys_ticpe:\n        get_values = \\\n            legislation_json['children']['imposition_indirecte']['children']['ticpe']['children'][element]['values']\n        for each_value in get_values:\n            get_character = '{}'.format(each_value['start'])\n            year = int(get_character[:4])\n            if year < 2002:\n                each_value['value'] = each_value['value'] / 6.55957\n            else:\n                each_value['value'] = each_value['value']\n\n    return legislation_json", "response": "Preprocess the legislation parameters to add prices and amounts from national accounts\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the content - type content - md5 date to the request", "response": "def set_more_headers(self, req, extra_headers=None):\n        \"\"\"Set content-type, content-md5, date to the request\n        Returns a new `PreparedRequest`\n\n        :param req: the origin unsigned request\n        :param extra_headers: extra headers you want to set, pass as dict\n        \"\"\"\n        oss_url = url.URL(req.url)\n        req.headers.update(extra_headers or {})\n\n        # set content-type\n        content_type = req.headers.get(\"content-type\")\n        if content_type is None:\n            content_type, __ = mimetypes.guess_type(oss_url.path)\n        req.headers[\"content-type\"] = content_type or self.DEFAULT_TYPE\n        logger.info(\"set content-type to: {0}\".format(content_type))\n\n        # set date\n        if self._expires is None:\n            req.headers.setdefault(\n                \"date\",\n                time.strftime(self.TIME_FMT, time.gmtime())\n            )\n        else:\n            req.headers[\"content-type\"] = \"\"\n            req.headers[\"date\"] = self._expires\n\n        logger.info(\"set date to: {0}\".format(req.headers[\"date\"]))\n\n        # set content-md5\n        if req.body is None:\n            content_md5 = \"\"\n        else:\n            content_md5 = req.headers.get(\"content-md5\", \"\")\n            if not content_md5 and self._allow_empty_md5 is False:\n                content_md5 = utils.cal_b64md5(req.body)\n        req.headers[\"content-md5\"] = content_md5\n        logger.info(\"content-md5 to: [{0}]\".format(content_md5))\n\n        return req"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_signature(self, req):\n        oss_url = url.URL(req.url)\n\n        oss_headers = [\n            \"{0}:{1}\\n\".format(key, val)\n            for key, val in req.headers.lower_items()\n            if key.startswith(self.X_OSS_PREFIX)\n        ]\n        canonicalized_headers = \"\".join(sorted(oss_headers))\n        logger.debug(\n            \"canonicalized header : [{0}]\".format(canonicalized_headers)\n        )\n\n        oss_url.params = {\n            key: val\n            for key, val in oss_url.params.items()\n            if key in self.SUB_RESOURCES or key in self.OVERRIDE_QUERIES\n        }\n\n        oss_url.forge(key=lambda x: x[0])\n        canonicalized_str = \"{0}/{1}{2}\".format(\n            canonicalized_headers,\n            self.get_bucket(oss_url.host),\n            oss_url.uri\n        )\n\n        str_to_sign = \"\\n\".join([\n            req.method,\n            req.headers[\"content-md5\"],\n            req.headers[\"content-type\"],\n            req.headers[\"date\"],\n            canonicalized_str\n        ])\n        logger.debug(\n            \"signature str is \\n{0}\\n{1}\\n{0}\\n\".format(\"#\" * 20, str_to_sign)\n        )\n        if isinstance(str_to_sign, requests.compat.str):\n            str_to_sign = str_to_sign.encode(\"utf8\")\n\n        signature_bin = hmac.new(self._secret_key, str_to_sign, hashlib.sha1)\n        signature = base64.b64encode(signature_bin.digest()).decode(\"utf8\")\n        logger.debug(\"signature is [{0}]\".format(signature))\n        return signature", "response": "calculate the signature of the oss request"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert(self, expr):\n        if expr is True or expr == None or expr is False:\n            return expr\n        elif is_number(expr):\n            return expr\n        elif expr == \".\":\n            return \".\"\n        elif is_variable_name(expr):\n            return coalesce(self.dimensions[expr], expr)\n        elif is_text(expr):\n            Log.error(\"{{name|quote}} is not a valid variable name\", name=expr)\n        elif isinstance(expr, Date):\n            return expr\n        elif is_op(expr, QueryOp):\n            return self._convert_query(expr)\n        elif is_data(expr):\n            if expr[\"from\"]:\n                return self._convert_query(expr)\n            elif len(expr) >= 2:\n                #ASSUME WE HAVE A NAMED STRUCTURE, NOT AN EXPRESSION\n                return wrap({name: self.convert(value) for name, value in expr.leaves()})\n            else:\n                # ASSUME SINGLE-CLAUSE EXPRESSION\n                k, v = expr.items()[0]\n                return converter_map.get(k, self._convert_bop)(self, k, v)\n        elif is_many(expr):\n            return wrap([self.convert(value) for value in expr])\n        else:\n            return expr", "response": "Convert a variable name to a value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _convert_clause(self, clause):\n        clause = wrap(clause)\n\n        if clause == None:\n            return None\n        elif is_data(clause):\n            return set_default({\"value\": self.convert(clause.value)}, clause)\n        else:\n            return [set_default({\"value\": self.convert(c.value)}, c) for c in clause]", "response": "Convert a single clause into a set of values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_obstory_ids(self):\n        self.con.execute('SELECT publicId FROM archive_observatories;')\n        return map(lambda row: row['publicId'], self.con.fetchall())", "response": "Retrieve the IDs of all obstorys."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the given status_id is present in the metadata item table.", "response": "def has_obstory_metadata(self, status_id):\n        \"\"\"\n        Check for the presence of the given metadata item\n\n        :param string status_id:\n            The metadata item ID\n        :return:\n            True if we have a metadata item with this ID, False otherwise\n        \"\"\"\n        self.con.execute('SELECT 1 FROM archive_metadata WHERE publicId=%s;', (status_id,))\n        return len(self.con.fetchall()) > 0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_file_id(self, repository_fname):\n        self.con.execute('SELECT 1 FROM archive_files WHERE repositoryFname = %s', (repository_fname,))\n        return len(self.con.fetchall()) > 0", "response": "Check if the given file_id contains a file record with this ID."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_file(self, repository_fname):\n        search = mp.FileRecordSearch(repository_fname=repository_fname)\n        b = search_files_sql_builder(search)\n        sql = b.get_select_sql(columns='f.uid, o.publicId AS observationId, f.mimeType, '\n                                       'f.fileName, s2.name AS semanticType, f.fileTime, '\n                                       'f.fileSize, f.fileMD5, l.publicId AS obstory_id, l.name AS obstory_name, '\n                                       'f.repositoryFname',\n                               skip=0, limit=1, order='f.fileTime DESC')\n        files = list(self.generators.file_generator(sql=sql, sql_args=b.sql_args))\n        if not files:\n            return None\n        return files[0]", "response": "Retrieve an existing meteorpi. FileRecord by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching for files in the database.", "response": "def search_files(self, search):\n        \"\"\"\n        Search for :class:`meteorpi_model.FileRecord` entities\n\n        :param search:\n            an instance of :class:`meteorpi_model.FileRecordSearch` used to constrain the observations returned from\n            the DB\n        :return:\n            a structure of {count:int total rows of an unrestricted search, observations:list of\n            :class:`meteorpi_model.FileRecord`}\n        \"\"\"\n        b = search_files_sql_builder(search)\n        sql = b.get_select_sql(columns='f.uid, o.publicId AS observationId, f.mimeType, '\n                                       'f.fileName, s2.name AS semanticType, f.fileTime, '\n                                       'f.fileSize, f.fileMD5, l.publicId AS obstory_id, l.name AS obstory_name, '\n                                       'f.repositoryFname',\n                               skip=search.skip,\n                               limit=search.limit,\n                               order='f.fileTime DESC')\n        files = list(self.generators.file_generator(sql=sql, sql_args=b.sql_args))\n        rows_returned = len(files)\n        total_rows = rows_returned + search.skip\n        if (rows_returned == search.limit > 0) or (rows_returned == 0 and search.skip > 0):\n            self.con.execute(b.get_count_sql(), b.sql_args)\n            total_rows = self.con.fetchone()['COUNT(*)']\n        return {\"count\": total_rows,\n                \"files\": files}"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a file in the database.", "response": "def register_file(self, observation_id, user_id, file_path, file_time, mime_type, semantic_type,\n                      file_md5=None, file_meta=None):\n        \"\"\"\n        Register a file in the database, also moving the file into the file store. Returns the corresponding FileRecord\n        object.\n\n        :param observation_id:\n            The publicId of the observation this file belongs to\n        :param string user_id:\n            The ID of the user who created this file\n        :param string file_path:\n            The path of the file on disk to register. This file will be moved into the file store and renamed.\n        :param string mime_type:\n            MIME type of the file\n        :param string semantic_type:\n            A string defining the semantic type of the file\n        :param float file_time:\n            UTC datetime of the import of the file into the database\n        :param list file_meta:\n            A list of :class:`meteorpi_model.Meta` used to provide additional information about this file\n        :return:\n            The resultant :class:`meteorpi_model.FileRecord` as stored in the database\n        \"\"\"\n\n        if file_meta is None:\n            file_meta = []\n\n        # Check that file exists\n        if not os.path.exists(file_path):\n            raise ValueError('No file exists at {0}'.format(file_path))\n\n        # Get checksum for file, and size\n        file_size_bytes = os.stat(file_path).st_size\n        file_name = os.path.split(file_path)[1]\n\n        if file_md5 is None:\n            file_md5 = mp.get_md5_hash(file_path)\n\n        # Fetch information about parent observation\n        self.con.execute(\"\"\"\nSELECT obsTime, l.publicId AS obstory_id, l.name AS obstory_name FROM archive_observations o\nINNER JOIN archive_observatories l ON observatory=l.uid\nWHERE o.publicId=%s\n\"\"\", (observation_id,))\n        obs = self.con.fetchall()\n        if len(obs) == 0:\n            raise ValueError(\"No observation with ID <%s>\" % observation_id)\n        obs = obs[0]\n        repository_fname = mp.get_hash(obs['obsTime'], obs['obstory_id'], file_name)\n\n        # Get ID code for obs_type\n        semantic_type_id = self.get_obs_type_id(semantic_type)\n\n        # Insert into database\n        self.con.execute(\"\"\"\nINSERT INTO archive_files\n(observationId, mimeType, fileName, semanticType, fileTime, fileSize, repositoryFname, fileMD5)\nVALUES\n((SELECT uid FROM archive_observations WHERE publicId=%s), %s, %s, %s, %s, %s, %s, %s);\n\"\"\", (observation_id, mime_type, file_name, semantic_type_id, file_time, file_size_bytes, repository_fname, file_md5))\n\n        # Move the original file from its path\n        target_file_path = os.path.join(self.file_store_path, repository_fname)\n        try:\n            shutil.move(file_path, target_file_path)\n        except OSError:\n            sys.stderr.write(\"Could not move file into repository\\n\")\n\n        # Store the file metadata\n        for meta in file_meta:\n            self.set_file_metadata(user_id, repository_fname, meta, file_time)\n\n        result_file = mp.FileRecord(obstory_id=obs['obstory_id'],\n                                    obstory_name=obs['obstory_name'],\n                                    observation_id=observation_id,\n                                    repository_fname=repository_fname,\n                                    file_time=file_time,\n                                    file_size=file_size_bytes,\n                                    file_name=file_name,\n                                    mime_type=mime_type,\n                                    semantic_type=semantic_type,\n                                    file_md5=file_md5,\n                                    meta=file_meta\n                                    )\n\n        # Return the resultant file object\n        return result_file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_observation_id(self, observation_id):\n        self.con.execute('SELECT 1 FROM archive_observations WHERE publicId = %s', (observation_id,))\n        return len(self.con.fetchall()) > 0", "response": "Check if the given observation_id is present in the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving an existing meteorpi. Observation by its ID.", "response": "def get_observation(self, observation_id):\n        \"\"\"\n        Retrieve an existing :class:`meteorpi_model.Observation` by its ID\n\n        :param string observation_id:\n            UUID of the observation\n        :return:\n            A :class:`meteorpi_model.Observation` instance, or None if not found\n        \"\"\"\n        search = mp.ObservationSearch(observation_id=observation_id)\n        b = search_observations_sql_builder(search)\n        sql = b.get_select_sql(columns='l.publicId AS obstory_id, l.name AS obstory_name, '\n                                       'o.obsTime, s.name AS obsType, o.publicId, o.uid',\n                               skip=0, limit=1, order='o.obsTime DESC')\n        obs = list(self.generators.observation_generator(sql=sql, sql_args=b.sql_args))\n        if not obs:\n            return None\n        return obs[0]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search_observations(self, search):\n        b = search_observations_sql_builder(search)\n        sql = b.get_select_sql(columns='l.publicId AS obstory_id, l.name AS obstory_name, '\n                                       'o.obsTime, s.name AS obsType, o.publicId, o.uid',\n                               skip=search.skip,\n                               limit=search.limit,\n                               order='o.obsTime DESC')\n        obs = list(self.generators.observation_generator(sql=sql, sql_args=b.sql_args))\n        rows_returned = len(obs)\n        total_rows = rows_returned + search.skip\n        if (rows_returned == search.limit > 0) or (rows_returned == 0 and search.skip > 0):\n            self.con.execute(b.get_count_sql(), b.sql_args)\n            total_rows = self.con.fetchone()['COUNT(*)']\n        return {\"count\": total_rows,\n                \"obs\": obs}", "response": "Search for the observations of the current resource."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a new observation in the archive and return the corresponding Observation object", "response": "def register_observation(self, obstory_name, user_id, obs_time, obs_type, obs_meta=None):\n        \"\"\"\n        Register a new observation, updating the database and returning the corresponding Observation object\n\n        :param string obstory_name:\n            The ID of the obstory which produced this observation\n        :param string user_id:\n            The ID of the user who created this observation\n        :param float obs_time:\n            The UTC date/time of the observation\n        :param string obs_type:\n            A string describing the semantic type of this observation\n        :param list obs_meta:\n            A list of :class:`meteorpi_model.Meta` used to provide additional information about this observation\n        :return:\n            The :class:`meteorpi_model.Observation` as stored in the database\n        \"\"\"\n\n        if obs_meta is None:\n            obs_meta = []\n\n        # Get obstory id from name\n        obstory = self.get_obstory_from_name(obstory_name)\n\n        # Create a unique ID for this observation\n        observation_id = mp.get_hash(obs_time, obstory['publicId'], obs_type)\n\n        # Get ID code for obs_type\n        obs_type_id = self.get_obs_type_id(obs_type)\n\n        # Insert into database\n        self.con.execute(\"\"\"\nINSERT INTO archive_observations (publicId, observatory, userId, obsTime, obsType)\nVALUES\n(%s, %s, %s, %s, %s);\n\"\"\", (observation_id, obstory['uid'], user_id, obs_time, obs_type_id))\n\n        # Store the observation metadata\n        for meta in obs_meta:\n            self.set_observation_metadata(user_id, observation_id, meta, obs_time)\n\n        observation = mp.Observation(obstory_name=obstory_name,\n                                     obstory_id=obstory['publicId'],\n                                     obs_time=obs_time,\n                                     obs_id=observation_id,\n                                     obs_type=obs_type,\n                                     file_records=[],\n                                     meta=obs_meta)\n        return observation"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_obsgroup_id(self, group_id):\n        self.con.execute('SELECT 1 FROM archive_obs_groups WHERE publicId = %s', (group_id,))\n        return len(self.con.fetchall()) > 0", "response": "Check if the given group_id is present in the archive_obs_groups table."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve an existing meteorpi. observation. ObservationGroup by its ID.", "response": "def get_obsgroup(self, group_id):\n        \"\"\"\n        Retrieve an existing :class:`meteorpi_model.ObservationGroup` by its ID\n\n        :param string group_id:\n            UUID of the observation\n        :return:\n            A :class:`meteorpi_model.Observation` instance, or None if not found\n        \"\"\"\n        search = mp.ObservationGroupSearch(group_id=group_id)\n        b = search_obsgroups_sql_builder(search)\n        sql = b.get_select_sql(columns='g.uid, g.time, g.setAtTime, g.setByUser, g.publicId, g.title,'\n                                       's.name AS semanticType',\n                               skip=0, limit=1, order='g.time DESC')\n        obs_groups = list(self.generators.obsgroup_generator(sql=sql, sql_args=b.sql_args))\n        if not obs_groups:\n            return None\n        return obs_groups[0]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching for the observations of a specific resource.", "response": "def search_obsgroups(self, search):\n        \"\"\"\n        Search for :class:`meteorpi_model.ObservationGroup` entities\n\n        :param search:\n            an instance of :class:`meteorpi_model.ObservationGroupSearch` used to constrain the observations returned\n            from the DB\n        :return:\n            a structure of {count:int total rows of an unrestricted search, observations:list of\n            :class:`meteorpi_model.ObservationGroup`}\n        \"\"\"\n        b = search_obsgroups_sql_builder(search)\n        sql = b.get_select_sql(columns='g.uid, g.time, g.setAtTime, g.setByUser, g.publicId, g.title,'\n                                       's.name AS semanticType',\n                               skip=search.skip,\n                               limit=search.limit,\n                               order='g.time DESC')\n        obs_groups = list(self.generators.obsgroup_generator(sql=sql, sql_args=b.sql_args))\n        rows_returned = len(obs_groups)\n        total_rows = rows_returned + search.skip\n        if (rows_returned == search.limit > 0) or (rows_returned == 0 and search.skip > 0):\n            self.con.execute(b.get_count_sql(), b.sql_args)\n            total_rows = self.con.fetchone()['COUNT(*)']\n        return {\"count\": total_rows,\n                \"obsgroups\": obs_groups}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_obsgroup(self, title, user_id, semantic_type, obs_time, set_time, obs=None, grp_meta=None):\n\n        if grp_meta is None:\n            grp_meta = []\n\n        # Create a unique ID for this observation\n        group_id = mp.get_hash(set_time, title, user_id)\n\n        # Get ID code for semantic_type\n        semantic_type_id = self.get_obs_type_id(semantic_type)\n\n        # Insert into database\n        self.con.execute(\"\"\"\nINSERT INTO archive_obs_groups (publicId, title, time, setByUser, setAtTime, semanticType)\nVALUES\n(%s, %s, %s, %s, %s, %s);\n\"\"\", (group_id, title, obs_time, user_id, set_time, semantic_type_id))\n\n        # Store list of observations into the database\n        for item in obs:\n            self.con.execute(\"\"\"\nINSERT INTO archive_obs_group_members (groupId, observationId)\nVALUES\n((SELECT uid FROM archive_obs_groups WHERE publicId=%s), (SELECT uid FROM archive_observations WHERE publicId=%s));\n\"\"\", (group_id, item))\n        # Store the observation metadata\n        for meta in grp_meta:\n            self.set_obsgroup_metadata(user_id, group_id, meta, obs_time)\n\n        obs_group = mp.ObservationGroup(group_id=group_id,\n                                        title=title,\n                                        obs_time=obs_time,\n                                        user_id=user_id,\n                                        set_time=set_time,\n                                        semantic_type=semantic_type,\n                                        obs_records=[],\n                                        meta=grp_meta)\n        return obs_group", "response": "Register a new observation group and store it in the database"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_user(self, user_id, password):\n        self.con.execute('SELECT uid, pwHash FROM archive_users WHERE userId = %s;', (user_id,))\n        results = self.con.fetchall()\n        if len(results) == 0:\n            raise ValueError(\"No such user\")\n        pw_hash = results[0]['pwHash']\n        # Check the password\n        if not passlib.hash.bcrypt.verify(password, pw_hash):\n            raise ValueError(\"Incorrect password\")\n\n        # Fetch list of roles\n        self.con.execute('SELECT name FROM archive_roles r INNER JOIN archive_user_roles u ON u.roleId=r.uid '\n                         'WHERE u.userId = %s;', (results[0]['uid'],))\n        role_list = [row['name'] for row in self.con.fetchall()]\n        return mp.User(user_id=user_id, roles=role_list)", "response": "Retrieve a user record from the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves all users in the system", "response": "def get_users(self):\n        \"\"\"\n        Retrieve all users in the system\n\n        :return:\n            A list of :class:`meteorpi_model.User`\n        \"\"\"\n        output = []\n        self.con.execute('SELECT userId, uid FROM archive_users;')\n        results = self.con.fetchall()\n\n        for result in results:\n            # Fetch list of roles\n            self.con.execute('SELECT name FROM archive_roles r INNER JOIN archive_user_roles u ON u.roleId=r.uid '\n                             'WHERE u.userId = %s;', (result['uid'],))\n            role_list = [row['name'] for row in self.con.fetchall()]\n            output.append(mp.User(user_id=result['userId'], roles=role_list))\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_or_update_user(self, user_id, password, roles):\n        action = \"update\"\n        self.con.execute('SELECT 1 FROM archive_users WHERE userId = %s;', (user_id,))\n        results = self.con.fetchall()\n        if len(results) == 0:\n            if password is None:\n                raise ValueError(\"Must specify an initial password when creating a new user!\")\n            action = \"create\"\n            self.con.execute('INSERT INTO archive_users (userId, pwHash) VALUES (%s,%s)',\n                             (user_id, passlib.hash.bcrypt.encrypt(password)))\n\n        if password is None and roles is None:\n            action = \"none\"\n        if password is not None:\n            self.con.execute('UPDATE archive_users SET pwHash = %s WHERE userId = %s',\n                             (passlib.hash.bcrypt.encrypt(password), user_id))\n        if roles is not None:\n\n            # Clear out existing roles, and delete any unused roles\n            self.con.execute(\"DELETE r FROM archive_user_roles AS r WHERE \"\n                             \"(SELECT u.userId FROM  archive_users AS u WHERE r.userId=u.uid)=%s;\", (user_id,))\n            self.con.execute(\"DELETE r FROM archive_roles AS r WHERE r.uid NOT IN \"\n                             \"(SELECT roleId FROM archive_user_roles);\")\n\n            for role in roles:\n                self.con.execute(\"SELECT uid FROM archive_roles WHERE name=%s;\", (role,))\n                results = self.con.fetchall()\n                if len(results) < 1:\n                    self.con.execute(\"INSERT INTO archive_roles (name) VALUES (%s);\", (role,))\n                    self.con.execute(\"SELECT uid FROM archive_roles WHERE name=%s;\", (role,))\n                    results = self.con.fetchall()\n\n                self.con.execute('INSERT INTO archive_user_roles (userId, roleId) VALUES '\n                                 '((SELECT u.uid FROM archive_users u WHERE u.userId=%s),'\n                                 '%s)', (user_id, results[0]['uid']))\n            return action", "response": "Create a new user record or update an existing one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve the ExportConfiguration with the given ID.", "response": "def get_export_configuration(self, config_id):\n        \"\"\"\n        Retrieve the ExportConfiguration with the given ID\n\n        :param string config_id:\n            ID for which to search\n        :return:\n            a :class:`meteorpi_model.ExportConfiguration` or None, or no match was found.\n        \"\"\"\n        sql = (\n            'SELECT uid, exportConfigId, exportType, searchString, targetURL, '\n            'targetUser, targetPassword, exportName, description, active '\n            'FROM archive_exportConfig WHERE exportConfigId = %s')\n        return first_from_generator(\n                self.generators.export_configuration_generator(sql=sql, sql_args=(config_id,)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve all ExportConfigurations held in this server", "response": "def get_export_configurations(self):\n        \"\"\"\n        Retrieve all ExportConfigurations held in this db\n\n        :return: a list of all :class:`meteorpi_model.ExportConfiguration` on this server\n        \"\"\"\n        sql = (\n            'SELECT uid, exportConfigId, exportType, searchString, targetURL, '\n            'targetUser, targetPassword, exportName, description, active '\n            'FROM archive_exportConfig ORDER BY uid DESC')\n        return list(self.generators.export_configuration_generator(sql=sql, sql_args=[]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new file export configuration or updates an existing one.", "response": "def create_or_update_export_configuration(self, export_config):\n        \"\"\"\n        Create a new file export configuration or update an existing one\n\n        :param ExportConfiguration export_config:\n            a :class:`meteorpi_model.ExportConfiguration` containing the specification for the export. If this\n            doesn't include a 'config_id' field it will be inserted as a new record in the database and the field will\n            be populated, updating the supplied object. If it does exist already this will update the other properties\n            in the database to match the supplied object.\n        :returns:\n            The supplied :class:`meteorpi_model.ExportConfiguration` as stored in the DB. This is guaranteed to have\n            its 'config_id' string field defined.\n        \"\"\"\n        search_string = json.dumps(obj=export_config.search.as_dict())\n        user_id = export_config.user_id\n        password = export_config.password\n        target_url = export_config.target_url\n        enabled = export_config.enabled\n        name = export_config.name\n        description = export_config.description\n        export_type = export_config.type\n        if export_config.config_id is not None:\n            # Update existing record\n            self.con.execute(\n                    'UPDATE archive_exportConfig c '\n                    'SET c.searchString = %s, c.targetUrl = %s, c.targetUser = %s, c.targetPassword = %s, '\n                    'c.exportName = %s, c.description = %s, c.active = %s, c.exportType = %s '\n                    'WHERE c.exportConfigId = %s',\n                    (search_string, target_url, user_id, password, name, description, enabled, export_type,\n                     export_config.config_id))\n        else:\n            # Create new record and add the ID into the supplied config\n            item_id = mp.get_hash(mp.now(), name, export_type)\n            self.con.execute(\n                    'INSERT INTO archive_exportConfig '\n                    '(searchString, targetUrl, targetUser, targetPassword, '\n                    'exportName, description, active, exportType, exportConfigId) '\n                    'VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s) ',\n                    (search_string, target_url, user_id, password,\n                     name, description, enabled, export_type, item_id))\n            export_config.config_id = item_id\n        return export_config"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mark_entities_to_export(self, export_config):\n        # Retrieve the internal ID of the export configuration, failing if it hasn't been stored\n        self.con.execute('SELECT uid FROM archive_exportConfig WHERE exportConfigID = %s;',\n                         (export_config.config_id,))\n        export_config_id = self.con.fetchall()\n        if len(export_config_id) < 1:\n            raise ValueError(\"Attempt to run export on ExportConfiguration not in database\")\n        export_config_id = export_config_id[0]['uid']\n\n        # If the export is inactive then do nothing\n        if not export_config.enabled:\n            return 0\n\n        # Track the number of rows created, return it later\n        rows_created = 0\n\n        # Handle ObservationSearch\n        if isinstance(export_config.search, mp.ObservationSearch):\n            # Create a deep copy of the search and set the properties required when creating exports\n            search = mp.ObservationSearch.from_dict(export_config.search.as_dict())\n            search.exclude_export_to = export_config.config_id\n            b = search_observations_sql_builder(search)\n\n            self.con.execute(b.get_select_sql(columns='o.uid, o.obsTime'), b.sql_args)\n            for result in self.con.fetchall():\n                self.con.execute('INSERT INTO archive_observationExport '\n                                 '(observationId, obsTime, exportConfig, exportState) '\n                                 'VALUES (%s,%s,%s,%s)', (result['uid'], result['obsTime'], export_config_id, 1))\n                rows_created += 1\n\n        # Handle FileSearch\n        elif isinstance(export_config.search, mp.FileRecordSearch):\n            # Create a deep copy of the search and set the properties required when creating exports\n            search = mp.FileRecordSearch.from_dict(export_config.search.as_dict())\n            search.exclude_export_to = export_config.config_id\n            b = search_files_sql_builder(search)\n\n            self.con.execute(b.get_select_sql(columns='f.uid, f.fileTime'), b.sql_args)\n            for result in self.con.fetchall():\n                self.con.execute('INSERT INTO archive_fileExport '\n                                 '(fileId, fileTime, exportConfig, exportState) '\n                                 'VALUES (%s,%s,%s,%s)', (result['uid'], result['fileTime'], export_config_id, 1))\n                rows_created += 1\n\n        # Handle ObservatoryMetadataSearch\n        elif isinstance(export_config.search, mp.ObservatoryMetadataSearch):\n            # Create a deep copy of the search and set the properties required when creating exports\n            search = mp.ObservatoryMetadataSearch.from_dict(export_config.search.as_dict())\n            search.exclude_export_to = export_config.config_id\n            b = search_metadata_sql_builder(search)\n\n            self.con.execute(b.get_select_sql(columns='m.uid, m.setAtTime'), b.sql_args)\n            for result in self.con.fetchall():\n                self.con.execute('INSERT INTO archive_metadataExport '\n                                 '(metadataId, setAtTime, exportConfig, exportState) '\n                                 'VALUES (%s,%s,%s,%s)', (result['uid'], result['setAtTime'], export_config_id, 1))\n                rows_created += 1\n\n        # Complain if it's anything other than these two (nothing should be at the moment but we might introduce\n        # more search types in the future\n        else:\n            raise ValueError(\"Unknown search type %s\" % str(type(export_config.search)))\n        return rows_created", "response": "Adds all entities that match the specified export configuration to the export tables."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_next_entity_to_export(self):\n\n        # If the queue of items waiting to export is old, delete it and fetch a new list from the database\n        if self.export_queue_valid_until < time.time():\n            self.export_queue_metadata = []\n            self.export_queue_observations = []\n            self.export_queue_files = []\n\n        # If we don't have a queue of items waiting to export, query database for items\n        if (not self.export_queue_metadata) and (not self.export_queue_observations) and (not self.export_queue_files):\n            self.export_queue_valid_until = time.time() + 60\n\n            # Try to retrieve the earliest record in archive_metadataExport\n            self.con.execute('SELECT c.exportConfigId, o.publicId, x.exportState, '\n                             'c.targetURL, c.targetUser, c.targetPassword '\n                             'FROM archive_metadataExport x '\n                             'INNER JOIN archive_exportConfig c ON x.exportConfig=c.uid '\n                             'INNER JOIN archive_metadata o ON x.metadataId=o.uid '\n                             'WHERE c.active = 1 AND x.exportState > 0 '\n                             'ORDER BY x.setAtTime ASC, o.uid ASC LIMIT 50')\n            self.export_queue_metadata = list(self.con.fetchall())\n\n            if not self.export_queue_metadata:\n\n                # Try to retrieve the earliest record in archive_observationExport\n                self.con.execute('SELECT c.exportConfigId, o.publicId, x.exportState, '\n                                 'c.targetURL, c.targetUser, c.targetPassword '\n                                 'FROM archive_observationExport x '\n                                 'INNER JOIN archive_exportConfig c ON x.exportConfig=c.uid '\n                                 'INNER JOIN archive_observations o ON x.observationId=o.uid '\n                                 'WHERE c.active = 1  AND x.exportState > 0 '\n                                 'ORDER BY x.obsTime ASC, o.uid ASC LIMIT 50')\n                self.export_queue_observations = list(self.con.fetchall())\n\n                if not self.export_queue_observations:\n                    # Try to retrieve the earliest record in archive_fileExport\n                    self.con.execute('SELECT c.exportConfigId, o.repositoryFname, x.exportState, '\n                                     'c.targetURL, c.targetUser, c.targetPassword '\n                                     'FROM archive_fileExport x '\n                                     'INNER JOIN archive_exportConfig c ON x.exportConfig=c.uid '\n                                     'INNER JOIN archive_files o ON x.fileId=o.uid '\n                                     'WHERE c.active = 1 AND x.exportState > 0 '\n                                     'ORDER BY x.fileTime ASC, o.uid ASC LIMIT 50')\n                    self.export_queue_files = list(self.con.fetchall())\n\n        if self.export_queue_metadata:\n            row = self.export_queue_metadata.pop(0)\n            config_id = row['exportConfigId']\n            entity_id = row['publicId']\n            status = row['exportState']\n            target_url = row['targetURL']\n            target_user = row['targetUser']\n            target_password = row['targetPassword']\n            return MetadataExportTask(db=self, config_id=config_id, metadata_id=entity_id,\n                                      status=status, target_url=target_url, target_user=target_user,\n                                      target_password=target_password)\n\n        if self.export_queue_observations:\n            row = self.export_queue_observations.pop(0)\n            config_id = row['exportConfigId']\n            entity_id = row['publicId']\n            status = row['exportState']\n            target_url = row['targetURL']\n            target_user = row['targetUser']\n            target_password = row['targetPassword']\n            return ObservationExportTask(db=self, config_id=config_id, observation_id=entity_id,\n                                         status=status, target_url=target_url, target_user=target_user,\n                                         target_password=target_password)\n\n        if self.export_queue_files:\n            row = self.export_queue_files.pop(0)\n            config_id = row['exportConfigId']\n            entity_id = row['repositoryFname']\n            status = row['exportState']\n            target_url = row['targetURL']\n            target_user = row['targetUser']\n            target_password = row['targetPassword']\n            return FileExportTask(db=self, config_id=config_id, file_id=entity_id,\n                                  status=status, target_url=target_url, target_user=target_user,\n                                  target_password=target_password)\n\n        return None", "response": "Gets the next entity to export from the queue."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_high_water_mark(self, mark_type, obstory_name=None):\n        if obstory_name is None:\n            obstory_name = self.obstory_name\n\n        obstory = self.get_obstory_from_name(obstory_name)\n        key_id = self.get_hwm_key_id(mark_type)\n\n        self.con.execute('SELECT time FROM archive_highWaterMarks WHERE markType=%s AND observatoryId=%s',\n                         (key_id, obstory['uid']))\n        results = self.con.fetchall()\n        if len(results) > 0:\n            return results[0]['time']\n        return None", "response": "Get the high water mark for a given obstory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef right(self, num=None):\n        if num == None:\n            return FlatList([_get_list(self)[-1]])\n        if num <= 0:\n            return Null\n\n        return FlatList(_get_list(self)[-num:])", "response": "Gets the last num elements from the right of the list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef left(self, num=None):\n        if num == None:\n            return FlatList([_get_list(self)[0]])\n        if num <= 0:\n            return Null\n\n        return FlatList(_get_list(self)[:num])", "response": "Return the first num elements in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new list with the elements from the left to the right.", "response": "def not_right(self, num):\n        \"\"\"\n        WITH SLICES BEING FLAT, WE NEED A SIMPLE WAY TO SLICE FROM THE LEFT [:-num:]\n        \"\"\"\n        if num == None:\n            return FlatList([_get_list(self)[:-1:]])\n        if num <= 0:\n            return FlatList.EMPTY\n\n        return FlatList(_get_list(self)[:-num:])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the elements of the elements that are not on the left.", "response": "def not_left(self, num):\n        \"\"\"\n        NOT REQUIRED, EXISTS AS OPPOSITE OF not_right()\n        \"\"\"\n        if num == None:\n            return FlatList([_get_list(self)[-1]])\n        if num <= 0:\n            return self\n\n        return FlatList(_get_list(self)[num::])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a pattern and a base return a list of files that match the glob pattern and also contain the base.", "response": "def baseglob(pat, base):\n    \"\"\"Given a pattern and a base, return files that match the glob pattern\n    and also contain the base.\"\"\"\n    return [f for f in glob(pat) if f.startswith(base)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncases insensitive baseglob. Note that it's not *actually* case insensitive, since glob is insensitive or not based on local semantics. Instead, it tries the original version, an upper() version, a lower() version, and a swapcase() version of the glob.", "response": "def cibaseglob(pat, base):\n    \"\"\"Case insensitive baseglob.  Note that it's not *actually* case\n    insensitive, since glob is insensitive or not based on local semantics.\n    Instead, it tries the original version, an upper() version, a lower()\n    version, and a swapcase() version of the glob.\"\"\"\n    results = []\n    for func in (str, str.upper, str.lower, str.swapcase):\n        results += baseglob(func(pat), base)\n    return list(sorted(set(results)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuses user dircolors settings to colorize a string which is a path.", "response": "def dircolorize(path, name_only=True):\n    \"\"\"Use user dircolors settings to colorize a string which is a path.\n    If name_only is True, it does this by the name rules (*.x) only; it\n    will not check the filesystem to colorize things like pipes, block devs,\n    doors, etc.\"\"\"\n    if not name_only:\n        raise NotImplemented(\"Filesystem checking not implemented.\")\n    for k,regex in colorremap.iteritems():\n        if regex.match(path):\n            return '\\x1b[%(color)sm%(path)s\\x1b[00m' % {'color': k, 'path': path}\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_revision():\n    proc = Process(\"git log\", [\"git\", \"log\", \"-1\"])\n\n    try:\n        while True:\n            line = proc.stdout.pop().strip().decode('utf8')\n            if not line:\n                continue\n            if line.startswith(\"commit \"):\n                return line[7:]\n    finally:\n        with suppress_exception:\n            proc.join()", "response": "Get the current revision of the current language."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the remote revision of a node.", "response": "def get_remote_revision(url, branch):\n    \"\"\"\n    GET REVISION OF A REMOTE BRANCH\n    \"\"\"\n    proc = Process(\"git remote revision\", [\"git\", \"ls-remote\", url, \"refs/heads/\" + branch])\n\n    try:\n        while True:\n            raw_line = proc.stdout.pop()\n            line = raw_line.strip().decode('utf8')\n            if not line:\n                continue\n            return line.split(\"\\t\")[0]\n    finally:\n        try:\n            proc.join()\n        except Exception:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the current branch of the current node", "response": "def get_branch():\n    \"\"\"\n    GET THE CURRENT GIT BRANCH\n    \"\"\"\n    proc = Process(\"git status\", [\"git\", \"status\"])\n\n    try:\n        while True:\n            raw_line = proc.stdout.pop()\n            line = raw_line.decode('utf8').strip()\n            if line.startswith(\"On branch \"):\n                return line[10:]\n    finally:\n        try:\n            proc.join()\n        except Exception:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _normalize(esfilter):\n    if esfilter == MATCH_ALL or esfilter == MATCH_NONE or esfilter.isNormal:\n        return esfilter\n\n    # Log.note(\"from: \" + convert.value2json(esfilter))\n    isDiff = True\n\n    while isDiff:\n        isDiff = False\n\n        if esfilter.bool.filter:\n            terms = esfilter.bool.filter\n            for (i0, t0), (i1, t1) in itertools.product(\n                enumerate(terms), enumerate(terms)\n            ):\n                if i0 == i1:\n                    continue  # SAME, IGNORE\n                # TERM FILTER ALREADY ASSUMES EXISTENCE\n                with suppress_exception:\n                    if (\n                        t0.exists.field != None\n                        and t0.exists.field == t1.term.items()[0][0]\n                    ):\n                        terms[i0] = MATCH_ALL\n                        continue\n\n                # IDENTICAL CAN BE REMOVED\n                with suppress_exception:\n                    if t0 == t1:\n                        terms[i0] = MATCH_ALL\n                        continue\n\n                # MERGE range FILTER WITH SAME FIELD\n                if i0 > i1:\n                    continue  # SAME, IGNORE\n                with suppress_exception:\n                    f0, tt0 = t0.range.items()[0]\n                    f1, tt1 = t1.range.items()[0]\n                    if f0 == f1:\n                        set_default(terms[i0].range[literal_field(f1)], tt1)\n                        terms[i1] = MATCH_ALL\n\n            output = []\n            for a in terms:\n                if is_container(a):\n                    from mo_logs import Log\n\n                    Log.error(\"and clause is not allowed a list inside a list\")\n                a_ = _normalize(a)\n                if a_ is not a:\n                    isDiff = True\n                a = a_\n                if a == MATCH_ALL:\n                    isDiff = True\n                    continue\n                if a == MATCH_NONE:\n                    return MATCH_NONE\n                if a.bool.filter:\n                    isDiff = True\n                    a.isNormal = None\n                    output.extend(a.bool.filter)\n                else:\n                    a.isNormal = None\n                    output.append(a)\n            if not output:\n                return MATCH_ALL\n            elif len(output) == 1:\n                # output[0].isNormal = True\n                esfilter = output[0]\n                break\n            elif isDiff:\n                esfilter = es_and(output)\n            continue\n\n        if esfilter.bool.should:\n            output = []\n            for a in esfilter.bool.should:\n                a_ = _normalize(a)\n                if a_ is not a:\n                    isDiff = True\n                a = a_\n\n                if a.bool.should:\n                    a.isNormal = None\n                    isDiff = True\n                    output.extend(a.bool.should)\n                else:\n                    a.isNormal = None\n                    output.append(a)\n            if not output:\n                return MATCH_NONE\n            elif len(output) == 1:\n                esfilter = output[0]\n                break\n            elif isDiff:\n                esfilter = wrap(es_or(output))\n            continue\n\n        if esfilter.term != None:\n            if esfilter.term.keys():\n                esfilter.isNormal = True\n                return esfilter\n            else:\n                return MATCH_ALL\n\n        if esfilter.terms:\n            for k, v in esfilter.terms.items():\n                if len(v) > 0:\n                    if OR(vv == None for vv in v):\n                        rest = [vv for vv in v if vv != None]\n                        if len(rest) > 0:\n                            output = es_or([es_missing(k), {\"terms\": {k: rest}}])\n                        else:\n                            output = es_missing(k)\n                        output.isNormal = True\n                        return output\n                    else:\n                        esfilter.isNormal = True\n                        return esfilter\n            return MATCH_NONE\n\n        if esfilter.bool.must_not:\n            _sub = esfilter.bool.must_not\n            sub = _normalize(_sub)\n            if sub == MATCH_NONE:\n                return MATCH_ALL\n            elif sub == MATCH_ALL:\n                return MATCH_NONE\n            elif sub is not _sub:\n                sub.isNormal = None\n                return wrap({\"bool\": {\"must_not\": sub, \"isNormal\": True}})\n            else:\n                sub.isNormal = None\n\n    esfilter.isNormal = True\n    return esfilter", "response": "Normalizes the given filter to be a list of the same size."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef split_expression_by_path(\n    where, schema, output=None, var_to_columns=None, lang=Language\n):\n    \"\"\"\n    :param where: EXPRESSION TO INSPECT\n    :param schema: THE SCHEMA\n    :param output: THE MAP FROM PATH TO EXPRESSION WE WANT UPDATED\n    :param var_to_columns: MAP FROM EACH VARIABLE NAME TO THE DEPTH\n    :return: output: A MAP FROM PATH TO EXPRESSION\n    \"\"\"\n    if var_to_columns is None:\n        var_to_columns = {v.var: schema.leaves(v.var) for v in where.vars()}\n        output = wrap({schema.query_path[0]: []})\n        if not var_to_columns:\n            output[\"\\\\.\"] += [where]  # LEGIT EXPRESSIONS OF ZERO VARIABLES\n            return output\n\n    where_vars = where.vars()\n    all_paths = set(c.nested_path[0] for v in where_vars for c in var_to_columns[v.var])\n\n    if len(all_paths) == 0:\n        output[\"\\\\.\"] += [where]\n    elif len(all_paths) == 1:\n        output[literal_field(first(all_paths))] += [\n            where.map(\n                {\n                    v.var: c.es_column\n                    for v in where.vars()\n                    for c in var_to_columns[v.var]\n                }\n            )\n        ]\n    elif is_op(where, AndOp_):\n        for w in where.terms:\n            split_expression_by_path(w, schema, output, var_to_columns, lang=lang)\n    else:\n        Log.error(\"Can not handle complex where clause\")\n\n    return output", "response": "This function splits the where clause into a list of lists where the first element is a LEGIT variable and the second is a list of all LEGIT variables."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading an Accept HTTP header and returns an array of Media Type string in descending weighted order", "response": "def _get_accept_languages_in_order(self):\n        \"\"\"\n        Reads an Accept HTTP header and returns an array of Media Type string in descending weighted order\n\n        :return: List of URIs of accept profiles in descending request order\n        :rtype: list\n        \"\"\"\n        try:\n            # split the header into individual URIs, with weights still attached\n            profiles = self.request.headers['Accept-Language'].split(',')\n            # remove \\s\n            profiles = [x.replace(' ', '').strip() for x in profiles]\n\n            # split off any weights and sort by them with default weight = 1\n            profiles = [(float(x.split(';')[1].replace('q=', '')) if len(x.split(';')) == 2 else 1, x.split(';')[0]) for x in profiles]\n\n            # sort profiles by weight, heaviest first\n            profiles.sort(reverse=True)\n\n            return[x[1] for x in profiles]\n        except Exception as e:\n            raise ViewsFormatsException(\n                'You have requested a language using an Accept-Language header that is incorrectly formatted.')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef readCfgJson(cls, working_path):\n\n        cfg_json_filename = os.path.join(working_path, cls.CFG_JSON_FILENAME)\n        if os.path.isfile(cfg_json_filename):\n            with open(cfg_json_filename) as json_file:\n                cfg = json.load(json_file)\n                return cfg\n        return None", "response": "Read cmWalk configuration data from a json file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates the top level CMakeLists. txt file.", "response": "def genTopLevelDirCMakeListsFile(self, working_path, subdirs, files, cfg):\n        \"\"\"\n        Generate top level CMakeLists.txt.\n\n        :param working_path: current working directory\n        :param subdirs: a list of subdirectories of current working directory.\n        :param files: a list of files in current working directory.\n        :return: the full path name of generated CMakeLists.txt.\n        \"\"\"\n\n        fnameOut = os.path.join(working_path, 'CMakeLists.txt')\n        template = self.envJinja.get_template(self.TOP_LEVEL_CMAKELISTS_JINJA2_TEMPLATE)\n        fcontent = template.render({'project_name':os.path.basename(os.path.abspath(working_path)),\n                                    'subdirs': subdirs,\n                                    'files': files,\n                                    'cfg': cfg})\n        with open(fnameOut, 'w') as f:\n            f.write(fcontent)\n        return fnameOut"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates CMakeLists. txt in subdirectories.", "response": "def genSubDirCMakeListsFile(self, working_path, addToCompilerIncludeDirectories, subdirs, files):\n        \"\"\"\n        Generate CMakeLists.txt in subdirectories.\n\n        :param working_path: current working directory\n        :param subdirs: a list of subdirectories of current working directory.\n        :param files: a list of files in current working directory.\n        :return: the full path name of generated CMakeLists.txt.\n        \"\"\"\n\n        fnameOut = os.path.join(working_path, 'CMakeLists.txt')\n        template = self.envJinja.get_template(self.SUBDIR_CMAKELISTS_JINJA2_TEMPLATE)\n        fcontent = template.render({'addToCompilerIncludeDirectories':addToCompilerIncludeDirectories,\n                                    'subdirs': subdirs,\n                                    'files': files})\n        with open(fnameOut, 'w') as f:\n            f.write(fcontent)\n        return fnameOut"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the object that the view is displaying.", "response": "def get_object(self, queryset=None):\n        \"\"\"\n        Returns the object the view is displaying.\n\n        Copied from SingleObjectMixin except that this allows\n        us to lookup preview objects.\n        \"\"\"\n\n        schema = manager.get_schema()\n        vid = None\n        if self.request.GET.get('vid') and self.request.user.is_staff and \\\n                self.request.user.is_active:\n            try:\n                schema = 'public'\n                vid = int(self.request.GET.get('vid'))\n                queryset = self.model.normal.filter(vid=vid)\n            except ValueError:\n                pass\n\n        with manager.SwitchSchema(schema):\n            # Use a custom queryset if provided\n            if queryset is None:\n                queryset = self.get_queryset()\n\n            # Next, try looking up by primary key.\n            pk = self.kwargs.get(self.pk_url_kwarg, None)\n            slug = self.kwargs.get(self.slug_url_kwarg, None)\n            if pk is not None:\n                if vid:\n                    queryset = queryset.filter(vid=vid)\n                else:\n                    queryset = queryset.filter(object_id=pk)\n\n            # Next, try looking up by slug.\n            elif slug is not None:\n                slug_field = self.get_slug_field()\n                queryset = queryset.filter(**{slug_field: slug})\n\n            # If none of those are defined, it's an error.\n            else:\n                raise AttributeError(u\"View %s must be called with \"\n                                     u\"either an object pk or a slug.\"\n                                     % self.__class__.__name__)\n\n            try:\n                obj = queryset.get()\n            except queryset.model.DoesNotExist:\n                raise http.Http404(\n                        u\"No %(verbose_name)s found matching the query\" %\n                         {'verbose_name': queryset.model._meta.verbose_name})\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _maybe_purge_cache(self):\n\n        if self._last_reload_check + MIN_CHECK_INTERVAL > time.time():\n            return\n\n        for name, tmpl in list(self.cache.items()):\n            if not os.stat(tmpl.path):\n                self.cache.pop(name)\n                continue\n\n            if os.stat(tmpl.path).st_mtime > tmpl.mtime:\n                self.cache.clear()\n                break\n\n        self._last_reload_check = time.time()", "response": "Check if enough time since last check has elapsed check if any of the template\n        files have changed and purge the entire cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads a named template and compiles it into memory.", "response": "def load(self, name):\n        \"\"\"\n        If not yet in the cache, load the named template and compiles it,\n        placing it into the cache.\n\n        If in cache, return the cached template.\n        \"\"\"\n\n        if self.reload:\n            self._maybe_purge_cache()\n\n        template = self.cache.get(name)\n        if template:\n            return template\n\n        path = self.resolve(name)\n        if not path:\n            raise OSError(errno.ENOENT, \"File not found: %s\" % name)\n\n        with codecs.open(path, 'r', encoding='UTF-8') as f:\n            contents = f.read()\n            mtime = os.fstat(f.fileno()).st_mtime\n\n        template = self.load_string(contents, filename=path)\n        template.mtime = mtime\n        template.path = path\n\n        self.cache[name] = template\n        return template"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_email(self,\n            from_address=None,\n            to_address=None,\n            subject=None,\n            text_data=None,\n            html_data=None\n    ):\n        \"\"\"Sends an email.\n\n        from_addr is an email address; to_addrs is a list of email adresses.\n        Addresses can be plain (e.g. \"jsmith@example.com\") or with real names\n        (e.g. \"John Smith <jsmith@example.com>\").\n\n        text_data and html_data are both strings.  You can specify one or both.\n        If you specify both, the email will be sent as a MIME multipart\n        alternative, i.e., the recipient will see the HTML content if his\n        viewer supports it; otherwise he'll see the text content.\n        \"\"\"\n\n        settings = self.settings\n\n        from_address = coalesce(from_address, settings[\"from\"], settings.from_address)\n        to_address = listwrap(coalesce(to_address, settings.to_address, settings.to_addrs))\n\n        if not from_address or not to_address:\n            raise Exception(\"Both from_addr and to_addrs must be specified\")\n        if not text_data and not html_data:\n            raise Exception(\"Must specify either text_data or html_data\")\n\n        if not html_data:\n            msg = MIMEText(text_data)\n        elif not text_data:\n            msg = MIMEText(html_data, 'html')\n        else:\n            msg = MIMEMultipart('alternative')\n            msg.attach(MIMEText(text_data, 'plain'))\n            msg.attach(MIMEText(html_data, 'html'))\n\n        msg['Subject'] = coalesce(subject, settings.subject)\n        msg['From'] = from_address\n        msg['To'] = ', '.join(to_address)\n\n        if self.server:\n            # CALL AS PART OF A SMTP SESSION\n            self.server.sendmail(from_address, to_address, msg.as_string())\n        else:\n            # CALL AS STAND-ALONE\n            with self:\n                self.server.sendmail(from_address, to_address, msg.as_string())", "response": "Sends an email.\n\n        from_addr is an email address; to_addrs is a list of email adresses.\n        Addresses can be plain (e.g. \"jsmith@example.com\") or with real names\n        (e.g. \"John Smith <jsmith@example.com>\").\n\n        text_data and html_data are both strings.  You can specify one or both.\n        If you specify both, the email will be sent as a MIME multipart\n        alternative, i.e., the recipient will see the HTML content if his\n        viewer supports it; otherwise he'll see the text content."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _esfilter2sqlwhere(db, esfilter):\n    esfilter = wrap(esfilter)\n\n    if esfilter is True:\n        return SQL_TRUE\n    elif esfilter[\"and\"]:\n        return sql_iso(SQL_AND.join([esfilter2sqlwhere(db, a) for a in esfilter[\"and\"]]))\n    elif esfilter[\"or\"]:\n        return sql_iso(SQL_OR.join([esfilter2sqlwhere(db, a) for a in esfilter[\"or\"]]))\n    elif esfilter[\"not\"]:\n        return SQL_NOT + sql_iso(esfilter2sqlwhere(db, esfilter[\"not\"]))\n    elif esfilter.term:\n        return sql_iso(SQL_AND.join([\n            quote_column(col) + SQL(\"=\") + quote_value(val)\n            for col, val in esfilter.term.items()\n        ]))\n    elif esfilter.terms:\n        for col, v in esfilter.terms.items():\n            if len(v) == 0:\n                return \"FALSE\"\n\n            try:\n                int_list = convert.value2intlist(v)\n                has_null = False\n                for vv in v:\n                    if vv == None:\n                        has_null = True\n                        break\n                if int_list:\n                    filter = int_list_packer(col, int_list)\n                    if has_null:\n                        return esfilter2sqlwhere(db, {\"or\": [{\"missing\": col}, filter]})\n                    elif 'terms' in filter and set(filter['terms'].get(col, []))==set(int_list):\n                        return quote_column(col) + \" in \" + quote_list(int_list)\n                    else:\n                        return esfilter2sqlwhere(db, filter)\n                else:\n                    if has_null:\n                        return esfilter2sqlwhere(db, {\"missing\": col})\n                    else:\n                        return \"false\"\n            except Exception as e:\n                e = Except.wrap(e)\n                pass\n            return quote_column(col) + \" in \" + quote_list(v)\n    elif esfilter.script:\n        return sql_iso(esfilter.script)\n    elif esfilter.range:\n        name2sign = {\n            \"gt\": SQL(\">\"),\n            \"gte\": SQL(\">=\"),\n            \"lte\": SQL(\"<=\"),\n            \"lt\": SQL(\"<\")\n        }\n\n        def single(col, r):\n            min = coalesce(r[\"gte\"], r[\">=\"])\n            max = coalesce(r[\"lte\"], r[\"<=\"])\n            if min != None and max != None:\n                # SPECIAL CASE (BETWEEN)\n                sql = quote_column(col) + SQL(\" BETWEEN \") + quote_value(min) + SQL_AND + quote_value(max)\n            else:\n                sql = SQL_AND.join(\n                    quote_column(col) + name2sign[sign] + quote_value(value)\n                    for sign, value in r.items()\n                )\n            return sql\n\n        terms = [single(col, ranges) for col, ranges in esfilter.range.items()]\n        if len(terms) == 1:\n            output = terms[0]\n        else:\n            output = sql_iso(SQL_AND.join(terms))\n        return output\n    elif esfilter.missing:\n        if isinstance(esfilter.missing, text_type):\n            return sql_iso(quote_column(esfilter.missing) + SQL_IS_NULL)\n        else:\n            return sql_iso(quote_column(esfilter.missing.field) + SQL_IS_NULL)\n    elif esfilter.exists:\n        if isinstance(esfilter.exists, text_type):\n            return sql_iso(quote_column(esfilter.exists) + SQL_IS_NOT_NULL)\n        else:\n            return sql_iso(quote_column(esfilter.exists.field) + SQL_IS_NOT_NULL)\n    elif esfilter.match_all:\n        return SQL_TRUE\n    elif esfilter.instr:\n        return sql_iso(SQL_AND.join([\"instr\" + sql_iso(quote_column(col) + \", \" + quote_value(val)) + \">0\" for col, val in esfilter.instr.items()]))\n    else:\n        Log.error(\"Can not convert esfilter to SQL: {{esfilter}}\", esfilter=esfilter)", "response": "Convert ElassticSearch filter to SQL WHERE"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef query(self, query, stacked=False):\n        from jx_base.query import QueryOp\n\n        query = QueryOp.wrap(query)\n\n        sql, post = self._subquery(query, isolate=False, stacked=stacked)\n        query.data = post(sql)\n        return query.data", "response": "A query that returns a dictionary of the result set"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a SQL statement that returns the aggregate of the records in the database.", "response": "def _aggop(self, query):\n        \"\"\"\n        SINGLE ROW RETURNED WITH AGGREGATES\n        \"\"\"\n        if isinstance(query.select, list):\n            # RETURN SINGLE OBJECT WITH AGGREGATES\n            for s in query.select:\n                if s.aggregate not in aggregates:\n                    Log.error(\"Expecting all columns to have an aggregate: {{select}}\", select=s)\n\n            selects = FlatList()\n            for s in query.select:\n                selects.append(sql_alias(aggregates[s.aggregate].replace(\"{{code}}\", s.value),quote_column(s.name)))\n\n            sql = expand_template(\"\"\"\n                SELECT\n                    {{selects}}\n                FROM\n                    {{table}}\n                {{where}}\n            \"\"\", {\n                \"selects\": SQL(\",\\n\".join(selects)),\n                \"table\": self._subquery(query[\"from\"])[0],\n                \"where\": self._where2sql(query.filter)\n            })\n\n            return sql, lambda sql: self.db.column(sql)[0]  # RETURNING SINGLE OBJECT WITH AGGREGATE VALUES\n        else:\n            # RETURN SINGLE VALUE\n            s0 = query.select\n            if s0.aggregate not in aggregates:\n                Log.error(\"Expecting all columns to have an aggregate: {{select}}\", select=s0)\n\n            select = sql_alias(aggregates[s0.aggregate].replace(\"{{code}}\", s0.value) , quote_column(s0.name))\n\n            sql = expand_template(\"\"\"\n                SELECT\n                    {{selects}}\n                FROM\n                    {{table}}\n                {{where}}\n            \"\"\", {\n                \"selects\": SQL(select),\n                \"table\": self._subquery(query[\"from\"])[0],\n                \"where\": self._where2sql(query.where)\n            })\n\n            def post(sql):\n                result = self.db.column_query(sql)\n                return result[0][0]\n\n            return sql, post"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset operation for the current record set.", "response": "def _setop(self, query):\n        \"\"\"\n        NO AGGREGATION, SIMPLE LIST COMPREHENSION\n        \"\"\"\n        if isinstance(query.select, list):\n            # RETURN BORING RESULT SET\n            selects = FlatList()\n            for s in listwrap(query.select):\n                if isinstance(s.value, Mapping):\n                    for k, v in s.value.items:\n                        selects.append(sql_alias(v, quote_column(s.name + \".\" + k)))\n                if isinstance(s.value, list):\n                    for i, ss in enumerate(s.value):\n                        selects.append(sql_alias(s.value, quote_column(s.name + \",\" + str(i))))\n                else:\n                    selects.append(sql_alias(s.value, quote_column(s.name)))\n\n            sql = expand_template(\"\"\"\n                SELECT\n                    {{selects}}\n                FROM\n                    {{table}}\n                {{where}}\n                {{sort}}\n                {{limit}}\n            \"\"\", {\n                \"selects\": SQL(\",\\n\".join(selects)),\n                \"table\": self._subquery(query[\"from\"])[0],\n                \"where\": self._where2sql(query.where),\n                \"limit\": self._limit2sql(query.limit),\n                \"sort\": self._sort2sql(query.sort)\n            })\n\n            def post_process(sql):\n                result = self.db.query(sql)\n                for s in listwrap(query.select):\n                    if isinstance(s.value, Mapping):\n                        for r in result:\n                            r[s.name] = {}\n                            for k, v in s.value:\n                                r[s.name][k] = r[s.name + \".\" + k]\n                                r[s.name + \".\" + k] = None\n\n                    if isinstance(s.value, list):\n                        # REWRITE AS TUPLE\n                        for r in result:\n                            r[s.name] = tuple(r[s.name + \",\" + str(i)] for i, ss in enumerate(s.value))\n                            for i, ss in enumerate(s.value):\n                                r[s.name + \",\" + str(i)] = None\n\n                expand_json(result)\n                return result\n\n            return sql, post_process  # RETURN BORING RESULT SET\n        else:\n            # RETURN LIST OF VALUES\n            if query.select.value == \".\":\n                select = \"*\"\n            else:\n                name = query.select.name\n                select = sql_alias(query.select.value, quote_column(name))\n\n            sql = expand_template(\"\"\"\n                SELECT\n                    {{selects}}\n                FROM\n                    {{table}}\n                {{where}}\n                {{sort}}\n                {{limit}}\n            \"\"\", {\n                \"selects\": SQL(select),\n                \"table\": self._subquery(query[\"from\"])[0],\n                \"where\": self._where2sql(query.where),\n                \"limit\": self._limit2sql(query.limit),\n                \"sort\": self._sort2sql(query.sort)\n            })\n\n            if query.select.value == \".\":\n                def post(sql):\n                    result = self.db.query(sql)\n                    expand_json(result)\n                    return result\n\n                return sql, post\n            else:\n                return sql, lambda sql: [r[name] for r in self.db.query(sql)]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _sort2sql(self, sort):\n        if not sort:\n            return \"\"\n        return SQL_ORDERBY + sql_list([quote_column(o.field) + (\" DESC\" if o.sort == -1 else \"\") for o in sort])", "response": "Return a SQL ORDER BY clause for the given sort."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_renderer_context(self):\n        # Note: Additionally 'response' will also be added to the context,\n        #       by the Response object.\n        return {\n            'view': self,\n            'args': getattr(self, 'args', ()),\n            'kwargs': getattr(self, 'kwargs', {}),\n            'request': getattr(self, 'request', None),\n            'extra_context': getattr(self, 'renderer_extra_context', {})\n        }", "response": "Returns a dictionary that is passed through to Renderer. render and\n            as the renderer_context keyword argument."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rebuild(self):\n        movi = self.riff.find('LIST', 'movi')\n        movi.chunks = self.combine_streams()\n        self.rebuild_index()", "response": "Rebuild RIFF tree and index from streams."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef acquire(self, **kwargs):\n        token = str(uuid.uuid4())\n        attempted = False\n        while self.token is None:\n            try:\n                self.client.test_and_set(self.key, token, \"0\", ttl=self.ttl)\n                self.token = token\n            except etcd.EtcdKeyNotFound, e:\n                try:\n                    self.client.write(self.key, token, prevExist=False, recursive=True, ttl=self.ttl)\n                    self.token = token\n                except etcd.EtcdAlreadyExist, e:\n                    pass  # someone created the right before us\n            except ValueError, e:\n                # someone else has the lock\n                if 'timeout' in kwargs or self.timeout is not None:\n                    if attempted is True: return False\n                    kwargs.setdefault(\"timeout\", self.timeout)\n                    try:\n                        self.client.read(self.key, wait=True, timeout=kwargs[\"timeout\"])\n                        attempted = True\n                    except etcd.EtcdException, e:\n                        return False\n                else:\n                    self.client.watch(self.key)\n\n        if self.renewSecondsPrior is not None:\n            timer_ttl = self.ttl - self.renewSecondsPrior\n\n            if timer_ttl > 0:\n                def renew():\n                    if self.renew():\n                        Timer(timer_ttl, renew).start()\n\n                Timer(timer_ttl, renew).start()\n        else:\n            def cleanup():\n                if self.token is token:\n                    self.token = None\n\n            Timer(self.ttl, cleanup).start()\n\n        return True", "response": "Acquires the lock. Returns True if the lock was acquired False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef renew(self):\n        if self.token is not None:\n            try:\n                self.client.test_and_set(self.key, self.token, self.token, ttl=self.ttl)\n                return True\n            except ValueError, e:\n                self.token = None\n                return False", "response": "Renew the lock if acquired."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreleasing the lock if acquired.", "response": "def release(self):\n        \"\"\"\n        Release the lock if acquired.\n        \"\"\"\n        # TODO: thread safety (currently the lock may be acquired for one more TTL length)\n        if self.token is not None:\n            try:\n                self.client.test_and_set(self.key, 0, self.token)\n            except (ValueError, etcd.EtcdKeyError, etcd.EtcdKeyNotFound) as e:\n                pass  # the key already expired or got acquired by someone else\n            finally:\n                self.token = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deconstruct(self):\n        name, path, args, kwargs = super(AssetsFileField, self).deconstruct()\n        kwargs['denormalize'] = False\n        return name, path, args, kwargs", "response": "This method is called when the assets file field is de - serialized."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_context_data(self, **kwargs):\n\n        context = {'obj': self.object }\n        if 'queryset' in kwargs:\n            context['conf_msg'] = self.get_confirmation_message(kwargs['queryset'])\n        context.update(kwargs)\n        return context", "response": "Hook for adding arguments to the context."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_object(self):\n        queryset = None\n        slug = self.kwargs.get(self.slug_url_kwarg, None)\n\n        if slug is not None:\n            queryset = self.get_queryset()\n            slug_field = self.slug_field\n            queryset = queryset.filter(**{slug_field: slug})\n            try:\n                self.object = queryset.get()\n            except ObjectDoesNotExist:\n                raise http.Http404\n        return self.object", "response": "Returns the object that has been requested."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_done_url(self):\n        data = dict(self.kwargs)\n        data.pop(self.slug_url_kwarg, None)\n        url = self.bundle.get_view_url(self.redirect_to_view,\n                                        self.request.user, data)\n        return self.customized_return_url(url)", "response": "Returns the url to redirect to after a successful update."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_selected(self, request):\n        obj = self.get_object()\n        queryset = None\n        # if single-object URL not used, check for selected objects\n        if not obj:\n            if request.GET.get(CHECKBOX_NAME):\n                selected = request.GET.get(CHECKBOX_NAME).split(',')\n            else:\n                selected = request.POST.getlist(CHECKBOX_NAME)\n        else:\n            selected = [obj.pk]\n\n        queryset = self.get_queryset().filter(pk__in=selected)\n        return queryset", "response": "Returns a queryset of the selected objects as specified by \\\n        a GET or POST request."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_action(self, request, queryset):\n        count = 0\n        try:\n            with transaction.commit_on_success():\n                for obj in queryset:\n                    self.log_action(obj, CMSLog.DELETE)\n                    count += 1\n                    obj.delete()\n            msg = \"%s object%s deleted.\" % (count, ('' if count ==1 else 's'))\n            url = self.get_done_url()\n            return self.render(request, redirect_url=url, message = msg)\n        except ProtectedError, e:\n            protected = []\n            for x in e.protected_objects:\n                if hasattr(x, 'delete_blocked_message'):\n                    protected.append(x.delete_blocked_message())\n                else:\n                    protected.append(u\"%s - %s\" % (x._meta.verbose_name, x))\n            msg = \"Cannot delete some objects because the following objects depend on them:\"\n            return self.render(request, error_msg = msg, errors = protected)", "response": "Delete the objects in the queryset. Successful deletes are logged and the error message is displayed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the object for publishing Raises a http404 error if the object is not found.", "response": "def get_object(self):\n        \"\"\"\n        Get the object for publishing\n        Raises a http404 error if the object is not found.\n        \"\"\"\n        obj = super(PublishActionView, self).get_object()\n\n        if obj:\n            if not hasattr(obj, 'publish'):\n                raise http.Http404\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npublishes the selected objects by passing the value of when to the object s publish method.", "response": "def process_action(self, request, queryset):\n        \"\"\"\n        Publishes the selected objects by passing the value of \\\n        'when' to the object's publish method. The object's \\\n        `purge_archives` method is also called to limit the number \\\n        of old items that we keep around. The action is logged as \\\n        either 'published' or 'scheduled' depending on the value of \\\n        'when', and the user is notified with a message.\n\n        Returns a 'render redirect' to the result of the \\\n        `get_done_url` method.\n        \"\"\"\n        form = self.form(request.POST)\n        if form.is_valid():\n            when = form.cleaned_data.get('when')\n            count = 0\n            for obj in queryset:\n                count += 1\n                obj.publish(user=request.user, when=when)\n                obj.purge_archives()\n                object_url = self.get_object_url(obj)\n                if obj.state == obj.PUBLISHED:\n                    self.log_action(\n                        obj, CMSLog.PUBLISH, url=object_url)\n                else:\n                    self.log_action(\n                       obj, CMSLog.SCHEDULE, url=object_url)\n            message = \"%s objects published.\" % count\n            self.write_message(message=message)\n\n            return self.render(request, redirect_url= self.get_done_url(),\n                                message=message,\n                                collect_render_data=False)\n        return self.render(request, queryset=queryset, publish_form=form, action='Publish')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the object for publishing Raises a http404 error if the object is not found.", "response": "def get_object(self):\n        \"\"\"\n        Get the object for publishing\n        Raises a http404 error if the object is not found.\n        \"\"\"\n        obj = super(PublishView, self).get_object()\n\n        if not obj or not hasattr(obj, 'publish'):\n            raise http.Http404\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the url to link to the object in the current bundle", "response": "def get_object_url(self):\n        \"\"\"\n        Returns the url to link to the object\n        The get_view_url will be called on the current bundle using\n        'edit` as the view name.\n        \"\"\"\n        return self.bundle.get_view_url('edit',\n                                        self.request.user, {}, self.kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_done_url(self):\n        url = self.bundle.get_view_url(self.redirect_to_view,\n                                        self.request.user, {}, self.kwargs)\n        return self.customized_return_url(url)", "response": "Returns the url to redirect to after a successful update."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef post(self, request, *args, **kwargs):\n\n        self.object = self.get_object()\n        form = self.form()\n        url = self.get_done_url()\n        if request.POST.get('publish'):\n            form = self.form(request.POST)\n            if form.is_valid():\n                when = form.cleaned_data.get('when')\n                self.object.publish(user=request.user, when=when)\n                self.object.purge_archives()\n                object_url = self.get_object_url()\n                if self.object.state == self.object.PUBLISHED:\n                    self.log_action(\n                        self.object, CMSLog.PUBLISH, url=object_url)\n                else:\n                    self.log_action(\n                        self.object, CMSLog.SCHEDULE, url=object_url)\n\n                message = \"%s %s\" % (self.object, self.object.state)\n                self.write_message(message=message)\n\n                return self.render(request, redirect_url=url,\n                           message=message,\n                           obj=self.object,\n                           collect_render_data=False)\n        return self.render(request, obj=self.object, form=form, done_url=url)", "response": "This method is called by the object manager when a POST request is received."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, request, *args, **kwargs):\n\n        self.object = self.get_object()\n        return self.render(request, obj=self.object,\n                           done_url=self.get_done_url())", "response": "Method for handling GET requests. Returns the object and the done_url."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef post(self, request, *args, **kwargs):\n\n        self.object = self.get_object()\n        url = self.get_done_url()\n        if request.POST.get('unpublish'):\n            self.object.unpublish()\n            object_url = self.get_object_url()\n            self.log_action(self.object, CMSLog.UNPUBLISH, url=object_url)\n            msg = self.write_message(message=\"%s unpublished\" % (self.object))\n            return self.render(request, redirect_url=url,\n                       message=msg,\n                       obj=self.object,\n                       collect_render_data=False)\n\n        return self.render(request, obj=self.object, done_url=url)", "response": "Unpublishes the object by calling the object s unpublish method. Returns a render redirect to the result of the get_done_url method."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the object for previewing.", "response": "def get_object(self):\n        \"\"\"\n        Get the object for previewing.\n        Raises a http404 error if the object is not found.\n        \"\"\"\n        obj = super(DeleteView, self).get_object()\n\n        if not obj:\n            raise http.Http404\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef post(self, request, *args, **kwargs):\n\n        self.object = self.get_object()\n        msg = None\n        if request.POST.get('delete'):\n            try:\n                with transaction.commit_on_success():\n                    self.log_action(self.object, CMSLog.DELETE)\n                    msg = \"%s deleted\" % self.object\n                    self.object.delete()\n            except ProtectedError, e:\n                protected = []\n                for x in e.protected_objects:\n                    if hasattr(x, 'delete_blocked_message'):\n                        protected.append(x.delete_blocked_message())\n                    else:\n                        protected.append(u\"%s: %s\" % (x._meta.verbose_name, x))\n                return self.render(request, obj=self.object,\n                                   protected=protected)\n\n        return self.render(request, redirect_url=self.get_done_url(),\n                           obj=self.object,\n                           message=msg,\n                           collect_render_data=False)", "response": "Method for handling POST requests. Deletes the object and returns a render redirect to the done_url."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef expand(self, key_array):\n\n        if len(key_array) != self._n:\n            raise RuntimeError('expand(): key size ' + str(len(key_array)) + ' is invalid')\n\n        # First n bytes are copied from key. Copy prevents inplace modification of original key\n        new_key = list(key_array)\n\n        rcon_iteration = 1\n        len_new_key = len(new_key)\n\n        # There are several parts of the code below that could be done with tidy list comprehensions like\n        # the one I put in _core, but I left this alone for readability.\n\n        # Grow the key until it is the correct length\n        while len_new_key < self._b:\n\n            # Copy last 4 bytes of extended key, apply _core function order i, increment i(rcon_iteration),\n            # xor with 4 bytes n bytes from end of extended key\n            t = new_key[-4:]\n            t = self._core(t, rcon_iteration)\n            rcon_iteration += 1\n            t = self._xor_list(t, new_key[-self._n : -self._n + 4])# self._n_bytes_before(len_new_key, new_key))\n            new_key.extend(t)\n            len_new_key += 4\n\n            # Run three passes of 4 byte expansion using copy of 4 byte tail of extended key\n            # which is then xor'd with 4 bytes n bytes from end of extended key\n            for j in range(3):\n                t = new_key[-4:]\n                t = self._xor_list(t, new_key[-self._n : -self._n + 4])\n                new_key.extend(t)\n                len_new_key += 4\n\n            # If key length is 256 and key is not complete, add 4 bytes tail of extended key\n            # run through sbox before xor with 4 bytes n bytes from end of extended key\n            if self._key_length == 256 and len_new_key < self._b:\n                t = new_key[-4:]\n                t2=[]\n                for x in t:\n                    t2.append(aes_tables.sbox[x])\n                t = self._xor_list(t2, new_key[-self._n : -self._n + 4])\n                new_key.extend(t)\n                len_new_key += 4\n\n            # If key length is 192 or 256 and key is not complete, run 2 or 3 passes respectively\n            # of 4 byte tail of extended key xor with 4 bytes n bytes from end of extended key\n            if self._key_length != 128 and len_new_key < self._b:\n                if self._key_length == 192:\n                    r = range(2)\n                else:\n                    r = range(3)\n\n                for j in r:\n                    t = new_key[-4:]\n                    t = self._xor_list(t, new_key[-self._n : -self._n + 4])\n                    new_key.extend(t)\n                    len_new_key += 4\n\n        return new_key", "response": "Expand the encryption key per AES key schedule specifications."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a value from a dot notation key.", "response": "def build_dot_value(key, value):\n    \"\"\"Build new dictionaries based off of the dot notation key.\n\n    For example, if a key were 'x.y.z' and the value was 'foo',\n    we would expect a return value of: ('x', {'y': {'z': 'foo'}})\n\n    Args:\n        key (str): The key to build a dictionary off of.\n        value: The value associated with the dot notation key.\n\n    Returns:\n        tuple: A 2-tuple where the first element is the key of\n            the outermost scope (e.g. left-most in the dot\n            notation key) and the value is the constructed value\n            for that key (e.g. a dictionary)\n    \"\"\"\n    # if there is no nesting in the key (as specified by the\n    # presence of dot notation), then the key/value pair here\n    # are the final key value pair.\n    if key.count('.') == 0:\n        return key, value\n\n    # otherwise, we will need to construct as many dictionaries\n    # as there are dot components to hold the value.\n    final_value = value\n    reverse_split = key.split('.')[::-1]\n    end = len(reverse_split) - 1\n    for idx, k in enumerate(reverse_split):\n        if idx == end:\n            return k, final_value\n        final_value = {k: final_value}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmerging two dictionaries or DotDicts together.", "response": "def _merge(d, u):\n    \"\"\"Merge two dictionaries (or DotDicts) together.\n\n    Args:\n          d: The dictionary/DotDict to merge into.\n          u: The source of the data to merge.\n    \"\"\"\n    for k, v in u.items():\n        # if we have a mapping, recursively merge the values\n        if isinstance(v, collections.Mapping):\n            d[k] = _merge(d.get(k, {}), v)\n\n        # if d (the dict to merge into) is a dict, just add the\n        # value to the dict.\n        elif isinstance(d, collections.MutableMapping):\n            d[k] = v\n\n        # otherwise if d (the dict to merge into) is not a dict (e.g. when\n        # recursing into it, `d.get(k, {})` may not be a dict), then do what\n        # `update` does and prefer the new value.\n        #\n        # this means that something like `{'foo': 1}` when updated with\n        # `{'foo': {'bar': 1}}` would have the original value (`1`) overwritten\n        # and would become: `{'foo': {'bar': 1}}`\n        else:\n            d = {k: v}\n\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a value from the DotDict.", "response": "def get(self, key, default=None):\n        \"\"\"Get a value from the `DotDict`.\n\n        The `key` parameter can either be a regular string key,\n        e.g. \"foo\", or it can be a string key with dot notation,\n        e.g. \"foo.bar.baz\", to signify a nested lookup.\n\n        The default value is returned if any level of the key's\n        components are not found.\n\n        Args:\n            key (str): The key to get the value for.\n            default: The return value should the given key\n                not exist in the `DotDict`.\n        \"\"\"\n        # if there are no dots in the key, its a normal get\n        if key.count('.') == 0:\n            return super(DotDict, self).get(key, default)\n\n        # set the return value to the default\n        value = default\n\n        # split the key into the first component and the rest of\n        # the components. the first component corresponds to this\n        # DotDict. the remainder components correspond to any nested\n        # DotDicts.\n        first, remainder = key.split('.', 1)\n        if first in self:\n            value = super(DotDict, self).get(first, default)\n\n            # if the value for the key at this level is a dictionary,\n            # then pass the remainder to that DotDict.\n            if isinstance(value, (dict, DotDict)):\n                return DotDict(value).get(remainder, default)\n\n            # TODO: support lists\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, key):\n        dct = self\n        keys = key.split('.')\n        last_key = keys[-1]\n        for k in keys:\n            # if the key is the last one, e.g. 'z' in 'x.y.z', try\n            # to delete it from its dict.\n            if k == last_key:\n                del dct[k]\n                break\n\n            # if the dct is a DotDict, get the value for the key `k` from it.\n            if isinstance(dct, DotDict):\n                dct = super(DotDict, dct).__getitem__(k)\n\n            # otherwise, just get the value from the default __getitem__\n            # implementation.\n            else:\n                dct = dct.__getitem__(k)\n                if not isinstance(dct, (DotDict, dict)):\n                    raise KeyError(\n                        'Subkey \"{}\" in \"{}\" invalid for deletion'.format(k, key)\n                    )", "response": "Removes a value from the DotDict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_extractor(non_default):\n    def extract_options(template, options):\n        for option, val in normalise_options(template):\n            name = option.replace('-', '_')\n\n            value = getattr(options, name)\n            if option not in non_default:\n                value = Default(value)\n\n            yield name, value\n    return extract_options", "response": "Return us a function to extract options from a template."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_option(self, name, val, action=Empty, opts=Empty):\n        if action is Empty and opts is Empty:\n            self.specified.append(name)\n            super(SpecRegister, self).set_option(name, val)\n        else:\n            super(SpecRegister, self).set_option(name, val, action, opts)", "response": "Set an option in the spec register."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new instance of the class with the given type and frum.", "response": "def new_instance(type, frum, schema=None):\n        \"\"\"\n        Factory!\n        \"\"\"\n        if not type2container:\n            _delayed_imports()\n\n        if isinstance(frum, Container):\n            return frum\n        elif isinstance(frum, _Cube):\n            return frum\n        elif isinstance(frum, _Query):\n            return _run(frum)\n        elif is_many(frum):\n            return _ListContainer(frum)\n        elif is_text(frum):\n            # USE DEFAULT STORAGE TO FIND Container\n            if not config.default.settings:\n                Log.error(\"expecting jx_base.container.config.default.settings to contain default elasticsearch connection info\")\n\n            settings = set_default(\n                {\n                    \"index\": join_field(split_field(frum)[:1:]),\n                    \"name\": frum,\n                },\n                config.default.settings\n            )\n            settings.type = None  # WE DO NOT WANT TO INFLUENCE THE TYPE BECAUSE NONE IS IN THE frum STRING ANYWAY\n            return type2container[\"elasticsearch\"](settings)\n        elif is_data(frum):\n            frum = wrap(frum)\n            if frum.type and type2container[frum.type]:\n                return type2container[frum.type](frum.settings)\n            elif frum[\"from\"]:\n                frum = copy(frum)\n                frum[\"from\"] = Container(frum[\"from\"])\n                return _Query.wrap(frum)\n            else:\n                Log.error(\"Do not know how to handle {{frum|json}}\", frum=frum)\n        else:\n            Log.error(\"Do not know how to handle {{type}}\", type=frum.__class__.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_content(cls, content):\n        parsed_content = parse_tibiacom_content(content)\n        image_column, desc_column, *_ = parsed_content.find_all('td')\n        if \"Error\" in image_column.text:\n            return None\n        image = image_column.find('img')\n        for br in desc_column.find_all(\"br\"):\n            br.replace_with(\"\\n\")\n        description = desc_column.text.replace(\"\\u00a0\", \" \").replace(\"\\n\\n\",\"\\n\")\n        lines = description.splitlines()\n        try:\n            name, beds, info, state, *_ = lines\n        except ValueError:\n            raise InvalidContent(\"content does is not from the house section of Tibia.com\")\n\n        house = cls(name.strip())\n        house.image_url = image[\"src\"]\n        house.id = int(id_regex.search(house.image_url).group(1))\n        m = bed_regex.search(beds)\n        if m:\n            house.type = HouseType.GUILDHALL if m.group(\"type\") in [\"guildhall\", \"clanhall\"] else HouseType.HOUSE\n            beds_word = m.group(\"beds\")\n            if beds_word == \"no\":\n                house.beds = 0\n            else:\n                house.beds = parse_number_words(beds_word)\n\n        m = info_regex.search(info)\n        if m:\n            house.world = m.group(\"world\")\n            house.rent = int(m.group(\"rent\"))\n            house.size = int(m.group(\"size\"))\n\n        house._parse_status(state)\n        return house", "response": "Parses a Tibia. com response into a House object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_tibiadata(cls, content):\n        json_content = parse_json(content)\n        try:\n            house_json = json_content[\"house\"]\n            if not house_json[\"name\"]:\n                return None\n            house = cls(house_json[\"name\"], house_json[\"world\"])\n\n            house.type = try_enum(HouseType, house_json[\"type\"])\n            house.id = house_json[\"houseid\"]\n            house.beds = house_json[\"beds\"]\n            house.size = house_json[\"size\"]\n            house.size = house_json[\"size\"]\n            house.rent = house_json[\"rent\"]\n            house.image_url = house_json[\"img\"]\n\n            # Parsing the original status string is easier than dealing with TibiaData fields\n            house._parse_status(house_json[\"status\"][\"original\"])\n        except KeyError:\n            raise InvalidContent(\"content is not a TibiaData house response.\")\n        return house", "response": "Parses a TibiaData response into a House object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_status(self, status):\n        m = rented_regex.search(status)\n        if m:\n            self.status = HouseStatus.RENTED\n            self.owner = m.group(\"owner\")\n            self.owner_sex = Sex.MALE if m.group(\"pronoun\") == \"He\" else Sex.FEMALE\n            self.paid_until = parse_tibia_datetime(m.group(\"paid_until\"))\n        else:\n            self.status = HouseStatus.AUCTIONED\n\n        m = transfer_regex.search(status)\n        if m:\n            self.transfer_date = parse_tibia_datetime(m.group(\"transfer_date\"))\n            self.transfer_accepted = m.group(\"verb\") == \"will\"\n            self.transferee = m.group(\"transferee\")\n            price = m.group(\"transfer_price\")\n            self.transfer_price = int(price) if price is not None else 0\n\n        m = auction_regex.search(status)\n        if m:\n            self.auction_end = parse_tibia_datetime(m.group(\"auction_end\"))\n\n        m = bid_regex.search(status)\n        if m:\n            self.highest_bid = int(m.group(\"highest_bid\"))\n            self.highest_bidder = m.group(\"bidder\")", "response": "Parses the status description and applies the corresponding values to the internal object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the content of a house list from Tibia. com into a list of houses.", "response": "def list_from_content(cls, content):\n        \"\"\"Parses the content of a house list from Tibia.com into a list of houses\n\n        Parameters\n        ----------\n        content: :class:`str`\n            The raw HTML response from the house list.\n\n        Returns\n        -------\n        :class:`list` of :class:`ListedHouse`\n\n        Raises\n        ------\n        InvalidContent`\n            Content is not the house list from Tibia.com\n        \"\"\"\n        try:\n            parsed_content = parse_tibiacom_content(content)\n            table = parsed_content.find(\"table\")\n            header, *rows = table.find_all(\"tr\")\n        except (ValueError, AttributeError):\n            raise InvalidContent(\"content does not belong to a Tibia.com house list\")\n\n        m = list_header_regex.match(header.text.strip())\n        if not m:\n            return None\n        town = m.group(\"town\")\n        world = m.group(\"world\")\n        house_type = HouseType.GUILDHALL if m.group(\"type\") == \"Guildhalls\" else HouseType.HOUSE\n        houses = []\n        for row in rows[1:]:\n            cols = row.find_all(\"td\")\n            if len(cols) != 6:\n                continue\n            name = cols[0].text.replace('\\u00a0', ' ')\n            house = ListedHouse(name, world, 0, town=town, type=house_type)\n            size = cols[1].text.replace('sqm', '')\n            house.size = int(size)\n            rent = cols[2].text.replace('gold', '')\n            house.rent = int(rent)\n            status = cols[3].text.replace('\\xa0', ' ')\n            house._parse_status(status)\n            id_input = cols[5].find(\"input\", {'name': 'houseid'})\n            house.id = int(id_input[\"value\"])\n            houses.append(house)\n        return houses"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_from_tibiadata(cls, content):\n        json_data = parse_json(content)\n        try:\n            house_data = json_data[\"houses\"]\n            houses = []\n            house_type = HouseType.HOUSE if house_data[\"type\"] == \"houses\" else HouseType.GUILDHALL\n            for house_json in house_data[\"houses\"]:\n                house = ListedHouse(house_json[\"name\"], house_data[\"world\"], house_json[\"houseid\"],\n                                    size=house_json[\"size\"], rent=house_json[\"rent\"], town=house_data[\"town\"],\n                                    type=house_type)\n                house._parse_status(house_json[\"status\"])\n                houses.append(house)\n            return houses\n        except KeyError:\n            raise InvalidContent(\"content is not a house list json response from TibiaData.com\")", "response": "Parses the content of a house list from TibiaData. com into a list of houses."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the URL to the house list on Tibia. com with the specified parameters.", "response": "def get_list_url(cls, world, town, house_type: HouseType = HouseType.HOUSE):\n        \"\"\"\n        Gets the URL to the house list on Tibia.com with the specified parameters.\n\n        Parameters\n        ----------\n        world: :class:`str`\n            The name of the world.\n        town: :class:`str`\n            The name of the town.\n        house_type: :class:`HouseType`\n            Whether to search for houses or guildhalls.\n\n        Returns\n        -------\n        :class:`str`\n            The URL to the list matching the parameters.\n        \"\"\"\n        house_type = \"%ss\" % house_type.value\n        return HOUSE_LIST_URL % (urllib.parse.quote(world), urllib.parse.quote(town), house_type)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the URL to the house list on Tibia. com with the specified parameters.", "response": "def get_list_url_tibiadata(cls, world, town, house_type: HouseType = HouseType.HOUSE):\n        \"\"\"\n        Gets the URL to the house list on Tibia.com with the specified parameters.\n\n        Parameters\n        ----------\n        world: :class:`str`\n            The name of the world.\n        town: :class:`str`\n            The name of the town.\n        house_type: :class:`HouseType`\n            Whether to search for houses or guildhalls.\n\n        Returns\n        -------\n        :class:`str`\n            The URL to the list matching the parameters.\n        \"\"\"\n        house_type = \"%ss\" % house_type.value\n        return HOUSE_LIST_URL_TIBIADATA % (urllib.parse.quote(world), urllib.parse.quote(town), house_type)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_status(self, status):\n        if \"rented\" in status:\n            self.status = HouseStatus.RENTED\n        else:\n            m = list_auction_regex.search(status)\n            if m:\n                self.highest_bid = int(m.group('bid'))\n                if m.group(\"time_unit\") == \"day\":\n                    self.time_left = datetime.timedelta(days=int(m.group(\"time_left\")))\n                else:\n                    self.time_left = datetime.timedelta(hours=int(m.group(\"time_left\")))\n            self.status = HouseStatus.AUCTIONED", "response": "Parses the status string found in the table and applies the corresponding values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the complete configuration of the current object.", "response": "def config(self):\n        \"\"\"Get the complete configuration where the default, config,\n        environment, and override values are merged together.\n\n        Returns:\n            (DotDict): A dictionary of configuration values that\n                allows lookups using dot notation.\n        \"\"\"\n        if self._full_config is None:\n            self._full_config = DotDict()\n            self._full_config.merge(self._default)\n            self._full_config.merge(self._config)\n            self._full_config.merge(self._environment)\n            self._full_config.merge(self._override)\n        return self._full_config"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets a value in the Bison configuration.", "response": "def set(self, key, value):\n        \"\"\"Set a value in the `Bison` configuration.\n\n        Args:\n            key (str): The configuration key to set a new value for.\n            value: The value to set.\n        \"\"\"\n        # the configuration changes, so we invalidate the cached config\n        self._full_config = None\n        self._override[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(self, requires_cfg=True):\n        self._parse_default()\n        self._parse_config(requires_cfg)\n        self._parse_env()", "response": "Parse the configuration sources into Bison."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch through the configured config_paths and finds the config_name file.", "response": "def _find_config(self):\n        \"\"\"Searches through the configured `config_paths` for the `config_name`\n        file.\n\n        If there are no `config_paths` defined, this will raise an error, so the\n        caller should take care to check the value of `config_paths` first.\n\n        Returns:\n            str: The fully qualified path to the configuration that was found.\n\n        Raises:\n            Exception: No paths are defined in `config_paths` or no file with\n                the `config_name` was found in any of the specified `config_paths`.\n        \"\"\"\n        for search_path in self.config_paths:\n            for ext in self._fmt_to_ext.get(self.config_format):\n                path = os.path.abspath(os.path.join(search_path, self.config_name + ext))\n                if os.path.isfile(path):\n                    self.config_file = path\n                    return\n        raise BisonError('No file named {} found in search paths {}'.format(\n            self.config_name, self.config_paths))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the configuration file and add it to the internal state.", "response": "def _parse_config(self, requires_cfg=True):\n        \"\"\"Parse the configuration file, if one is configured, and add it to\n        the `Bison` state.\n\n        Args:\n            requires_cfg (bool): Specify whether or not parsing should fail\n                if a config file is not found. (default: True)\n        \"\"\"\n        if len(self.config_paths) > 0:\n            try:\n                self._find_config()\n            except BisonError:\n                if not requires_cfg:\n                    return\n                raise\n            try:\n                with open(self.config_file, 'r') as f:\n                    parsed = self._fmt_to_parser[self.config_format](f)\n            except Exception as e:\n                raise BisonError(\n                    'Failed to parse config file: {}'.format(self.config_file)\n                ) from e\n\n            # the configuration changes, so we invalidate the cached config\n            self._full_config = None\n            self._config = parsed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_env(self):\n        env_cfg = DotDict()\n\n        # if the env prefix doesn't end with '_', we'll append it here\n        if self.env_prefix and not self.env_prefix.endswith('_'):\n            self.env_prefix = self.env_prefix + '_'\n\n        # if there is no scheme, we won't know what to look for so only parse\n        # config if there is a scheme.\n        if self.scheme:\n            for k, v in self.scheme.flatten().items():\n                value = v.parse_env(k, self.env_prefix, self.auto_env)\n                if value is not None:\n                    env_cfg[k] = value\n\n        if len(env_cfg) > 0:\n            # the configuration changes, so we invalidate the cached config\n            self._full_config = None\n            self._environment.update(env_cfg)", "response": "Parse the environment variables for any configuration if an env_prefix is set."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_default(self):\n        # the configuration changes, so we invalidate the cached config\n        self._full_config = None\n\n        if self.scheme:\n            self._default.update(self.scheme.build_defaults())", "response": "Parse the schema for the Bison instance to create the set of\n            default values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_domain(self, value):\n        return [k for k, v in self.all if v == value]", "response": "RETURN domain FOR GIVEN CODOMAIN\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_codomain(self, key):\n        return [v for k, v in self.all if k == key]", "response": "RETURN AN ARRAY OF OBJECTS THAT key MAPS TO\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, command):\n        command = wrap(command)\n        command_clear = listwrap(command[\"clear\"])\n        command_set = command.set.items()\n        command_where = jx.get(command.where)\n\n        for c in self.data:\n            if command_where(c):\n                for k in command_clear:\n                    c[k] = None\n                for k, v in command_set:\n                    c[k] = v", "response": "Updates the data of the object with the command."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, select):\n        if is_list(select):\n            return [(d[s] for s in select) for d in self.data]\n        else:\n            return [d[select] for d in self.data]", "response": "returns a simple list of the extraction\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets a custom timeout value for this session", "response": "def timeout(self, value):\n        \"\"\"Sets a custom timeout value for this session\"\"\"\n\n        if value == TIMEOUT_SESSION:\n            self._config.timeout = None\n            self._backend_client.expires = None\n        else:\n            self._config.timeout = value\n            self._calculate_expires()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _calculate_expires(self):\n        self._backend_client.expires = None\n\n        now = datetime.utcnow()\n        self._backend_client.expires = now + timedelta(seconds=self._config.timeout)", "response": "Calculates the session expiry using the timeout"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _load_cookie(self):\n\n        cookie = SimpleCookie(self._environ.get('HTTP_COOKIE'))\n        vishnu_keys = [key for key in cookie.keys() if key == self._config.cookie_name]\n\n        # no session was started yet\n        if not vishnu_keys:\n            return\n\n        morsel = cookie[vishnu_keys[0]]\n        morsel_value = morsel.value\n\n        if self._config.encrypt_key:\n            cipher = AESCipher(self._config.encrypt_key)\n            morsel_value = cipher.decrypt(morsel_value)\n\n        received_sid = Session.decode_sid(self._config.secret, morsel_value)\n        if received_sid:\n            self._sid = received_sid\n        else:\n            logging.warn(\"found cookie with invalid signature\")", "response": "Loads the cookie from the environ and sets the sid attribute"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate HTTP header for this cookie.", "response": "def header(self):\n        \"\"\"Generates HTTP header for this cookie.\"\"\"\n\n        if self._send_cookie:\n            morsel = Morsel()\n            cookie_value = Session.encode_sid(self._config.secret, self._sid)\n            if self._config.encrypt_key:\n                cipher = AESCipher(self._config.encrypt_key)\n                cookie_value = cipher.encrypt(cookie_value)\n\n                if sys.version_info > (3, 0):\n                    cookie_value = cookie_value.decode()\n\n            morsel.set(self._config.cookie_name, cookie_value, cookie_value)\n\n            # domain\n            if self._config.domain:\n                morsel[\"domain\"] = self._config.domain\n\n            # path\n            if self._config.path:\n                morsel[\"path\"] = self._config.path\n            # expires\n            if self._expire_cookie:\n                morsel[\"expires\"] = \"Wed, 01-Jan-1970 00:00:00 GMT\"\n            elif self._backend_client.expires:\n                morsel[\"expires\"] = self._backend_client.expires.strftime(EXPIRES_FORMAT)\n\n            # secure\n            if self._config.secure:\n                morsel[\"secure\"] = True\n\n            # http only\n            if self._config.http_only:\n                morsel[\"httponly\"] = True\n\n            return morsel.OutputString()\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encode_sid(cls, secret, sid):\n\n        secret_bytes = secret.encode(\"utf-8\")\n        sid_bytes = sid.encode(\"utf-8\")\n\n        sig = hmac.new(secret_bytes, sid_bytes, hashlib.sha512).hexdigest()\n        return \"%s%s\" % (sig, sid)", "response": "Computes the HMAC for the given session id."}
