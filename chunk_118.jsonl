{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntakes a dict of keys and returns a list of tuples with materialized value paths and values.", "response": "def materialize_dict(bundle: dict, separator: str = '.') -> t.List[t.Tuple[str, t.Any]]:\n    \"\"\"\n    Transforms a given ``bundle`` into a *sorted* list of tuples with materialized value paths and values:\n    ``('path.to.value', <value>)``. Output is ordered by depth: the deepest element first.\n\n    :param bundle: a dict to materialize\n    :param separator: build paths with a given separator\n    :return: a depth descending and alphabetically ascending sorted list (-deep, asc), the longest first\n\n    ::\n\n        sample = {\n            'a': 1,\n            'aa': 1,\n            'b': {\n                'c': 1,\n                'b': 1,\n                'a': 1,\n                'aa': 1,\n                'aaa': {\n                    'a': 1\n                }\n            }\n        }\n        materialize_dict(sample, '/')\n        [\n            ('b/aaa/a', 1),\n            ('b/a', 1),\n            ('b/aa', 1),\n            ('b/b', 1),\n            ('b/c', 1),\n            ('a', 1),\n            ('aa', 1)\n        ]\n    \"\"\"\n\n    def _matkeysort(tup: t.Tuple[str, t.Any]):\n        return len(tup[0].split(separator))\n\n    s1 = sorted(_materialize_dict(bundle, separator=separator), key=lambda x: x[0])\n    return sorted(s1, key=_matkeysort, reverse=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nserializes a given dictionary into a list of tuples with materialized value paths and values.", "response": "def mp_serialize_dict(\n        bundle: dict,\n        separator: str = '.',\n        serialize: t.Optional[t.Callable] = dump_yaml,\n        value_prefix: str = '::YAML::\\n') -> t.List[t.Tuple[str, bytes]]:\n    \"\"\"\n    Transforms a given ``bundle`` into a *sorted* list of tuples with materialized value paths and values:\n    ``('path.to.value', b'<some>')``. If the ``<some>`` value is not an instance of a basic type, it's serialized\n    with ``serialize`` callback. If this value is an empty string, it's serialized anyway to enforce correct\n    type if storage backend does not support saving empty strings.\n\n    :param bundle: a dict to materialize\n    :param separator: build paths with a given separator\n    :param serialize: a method to serialize non-basic types, default is ``yaml.dump``\n    :param value_prefix: a prefix for non-basic serialized types\n    :return: a list of tuples ``(mat_path, b'value')``\n\n    ::\n\n        sample = {\n            'bool_flag': '',  # flag\n            'unicode': '\u0432\u0430\u0441\u044f',\n            'none_value': None,\n            'debug': True,\n            'mixed': ['ascii', '\u044e\u043d\u0438\u043a\u043e\u0434', 1, {'d': 1}, {'b': 2}],\n            'nested': {\n                'a': {\n                    'b': 2,\n                    'c': b'bytes',\n                }\n            }\n        }\n\n        result = mp_serialize_dict(sample, separator='/')\n        assert result == [\n            ('nested/a/b', b'2'),\n            ('nested/a/c', b'bytes'),\n            ('bool_flag', b\"::YAML::\\\\n''\\\\n\"),\n            ('debug', b'true'),\n            ('mixed', b'::YAML::\\\\n- ascii\\\\n- '\n                      b'\"\\\\\\\\u044E\\\\\\\\u043D\\\\\\\\u0438\\\\\\\\u043A\\\\\\\\u043E\\\\\\\\u0434\"\\\\n- 1\\\\n- '\n                      b'{d: 1}\\\\n- {b: 2}\\\\n'),\n            ('none_value', None),\n            ('unicode', b'\\\\xd0\\\\xb2\\\\xd0\\\\xb0\\\\xd1\\\\x81\\\\xd1\\\\x8f')\n        ]\n    \"\"\"\n\n    md = materialize_dict(bundle, separator=separator)\n    res = []\n    for path, value in md:\n        # have to serialize values (value should be None or a string / binary data)\n        if value is None:\n            pass\n        elif isinstance(value, str) and value != '':\n            # check for value != '' used to armor empty string with forced serialization\n            # since it can be not recognized by a storage backend\n            pass\n        elif isinstance(value, bytes):\n            pass\n        elif isinstance(value, bool):\n            value = str(value).lower()\n        elif isinstance(value, (int, float, Decimal)):\n            value = str(value)\n        else:\n            value = (value_prefix + serialize(value))\n\n        if isinstance(value, str):\n            value = value.encode()\n\n        res.append((path, value))\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wf(raw_str: str,\n       flush: bool = True,\n       prevent_completion_polluting: bool = True,\n       stream: t.TextIO = sys.stdout):\n    \"\"\"\n    Writes a given ``raw_str`` into a ``stream``. Ignores output if ``prevent_completion_polluting`` is set and there's\n    no extra ``sys.argv`` arguments present (a bash completion issue).\n\n    :param raw_str: a raw string to print\n    :param flush: execute ``flush()``\n    :param prevent_completion_polluting: don't write anything if ``len(sys.argv) <= 1``\n    :param stream: ``sys.stdout`` by default\n    :return: None\n    \"\"\"\n    if prevent_completion_polluting and len(sys.argv) <= 1:\n        return\n\n    stream.write(raw_str)\n    flush and hasattr(stream, 'flush') and stream.flush()", "response": "Writes a given string into a stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef coerce_str_to_bool(val: t.Union[str, int, bool, None], strict: bool = False) -> bool:\n    if isinstance(val, str):\n        val = val.lower()\n\n    flag = ENV_STR_BOOL_COERCE_MAP.get(val, None)\n\n    if flag is not None:\n        return flag\n\n    if strict:\n        raise ValueError('Unsupported value for boolean flag: `%s`' % val)\n\n    return bool(val)", "response": "Converts a given string representation of boolean into a boolean."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef env_bool_flag(flag_name: str, strict: bool = False, env: t.Optional[t.Dict[str, str]] = None) -> bool:\n    env = env or os.environ\n    sentinel = object()\n    val = env.get(flag_name, sentinel)\n\n    if val is sentinel:\n        return False\n\n    return coerce_str_to_bool(val, strict=strict)", "response": "Converts an environment variable name into a boolean."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_dockerized(flag_name: str = 'DOCKERIZED', strict: bool = False):\n    return env_bool_flag(flag_name, strict=strict)", "response": "Reads env DOCKERIZED env variable as a boolean."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_production(flag_name: str = 'PRODUCTION', strict: bool = False):\n    return env_bool_flag(flag_name, strict=strict)", "response": "Reads environment variable PRODUCTION as a boolean."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the given code line by line with printing as list of lines and return variable ans.", "response": "def runcode(code):\n\t\"\"\"Run the given code line by line with printing, as list of lines, and return variable 'ans'.\"\"\"\n\tfor line in code:\n\t\tprint('# '+line)\n\t\texec(line,globals())\n\tprint('# return ans')\n\treturn ans"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exec_all_endpoints(self, *args, **kwargs):\n        results = []\n        for handler in self.endpoints:\n            if isinstance(handler, weakref.ref):\n                handler = handler()\n            if self.adapt_params:\n                bind = self._adapt_call_params(handler, args, kwargs)\n                res = handler(*bind.args, **bind.kwargs)\n            else:\n                res = handler(*args, **kwargs)\n            if isinstance(res, MultipleResults):\n                if res.done:\n                    results += res.results\n                else:\n                    results += res._results\n            elif res is not NoResult:\n                results.append(res)\n        return MultipleResults(results, concurrent=self.concurrent, owner=self)", "response": "Execute each passed endpoint and collect the results."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self, *args, **kwargs):\n        if self.fvalidation is not None:\n            try:\n                if self.fvalidation(*args, **kwargs) is False:\n                    raise ExecutionError(\"Validation returned ``False``\")\n            except Exception as e:\n                if __debug__:\n                    logger.exception(\"Validation failed\")\n                else:\n                    logger.error(\"Validation failed\")\n                raise ExecutionError(\n                    \"The validation of the arguments specified to ``run()`` \"\n                    \"has failed\") from e\n        try:\n            if self.exec_wrapper is None:\n                return self.exec_all_endpoints(*args, **kwargs)\n            else:\n                # if a exec wrapper is defined, defer notification to it,\n                # a callback to execute the default notification process\n                result = self.exec_wrapper(self.endpoints,\n                                           self.exec_all_endpoints,\n                                           *args, **kwargs)\n                if inspect.isawaitable(result):\n                    result = pull_result(result)\n                return result\n        except Exception as e:\n            if __debug__:\n                logger.exception(\"Error while executing handlers\")\n            else:\n                logger.error(\"Error while executing handlers\")\n            raise ExecutionError(\"Error while executing handlers\") from e", "response": "Execute all the handlers and return the result of the exec_wrapper method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndiscovering the minimum and maximum UID number.", "response": "def login_defs():\n    \"\"\"Discover the minimum and maximum UID number.\"\"\"\n    uid_min = None\n    uid_max = None\n    login_defs_path = '/etc/login.defs'\n    if os.path.exists(login_defs_path):\n        with io.open(text_type(login_defs_path), encoding=text_type('utf-8')) as log_defs_file:\n            login_data = log_defs_file.readlines()\n        for line in login_data:\n            if PY3:  # pragma: no cover\n                line = str(line)\n            if PY2:  # pragma: no cover\n                line = line.encode(text_type('utf8'))\n            if line[:7] == text_type('UID_MIN'):\n                uid_min = int(line.split()[1].strip())\n            if line[:7] == text_type('UID_MAX'):\n                uid_max = int(line.split()[1].strip())\n    if not uid_min:  # pragma: no cover\n        uid_min = DEFAULT_UID_MIN\n    if not uid_max:  # pragma: no cover\n        uid_max = DEFAULT_UID_MAX\n    return uid_min, uid_max"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef collect_static() -> bool:\n    from django.core.management import execute_from_command_line\n    # from django.conf import settings\n    # if not os.listdir(settings.STATIC_ROOT):\n    wf('Collecting static files... ', False)\n    execute_from_command_line(['./manage.py', 'collectstatic', '-c', '--noinput', '-v0'])\n    wf('[+]\\n')\n    return True", "response": "Runs Django collectstatic command in silent mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an instance of the inner config parser for the specified endpoint.", "response": "def inner_parser(self) -> BaseParser:\n        \"\"\"\n        Prepares inner config parser for config stored at ``endpoint``.\n\n        :return: an instance of :class:`~django_docker_helpers.config.backends.base.BaseParser`\n\n        :raises config.exceptions.KVStorageValueIsEmpty: if specified ``endpoint`` does not contain a config\n        \"\"\"\n        if self._inner_parser is not None:\n            return self._inner_parser\n\n        config = self.client.get(self.endpoint)\n        if not config:\n            raise KVStorageValueIsEmpty('Key `{0}` does not exist or value is empty'.format(self.endpoint))\n\n        config = config.decode()\n\n        self._inner_parser = self.inner_parser_class(\n            config=io.StringIO(config),\n            path_separator=self.path_separator,\n            scope=None\n        )\n        return self._inner_parser"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_add_user_command(proposed_user=None, manage_home=None):\n    command = None\n    if get_platform() in ('Linux', 'OpenBSD'):\n        command = '{0} {1}'.format(sudo_check(), LINUX_CMD_USERADD)\n        if proposed_user.uid:\n            command = '{0} -u {1}'.format(command, proposed_user.uid)\n        if proposed_user.gid:\n            command = '{0} -g {1}'.format(command, proposed_user.gid)\n        if proposed_user.gecos:\n            command = '{0} -c \\'{1}\\''.format(command, proposed_user.gecos)\n        if manage_home:\n            if proposed_user.home_dir:\n                if os.path.exists(proposed_user.home_dir):\n                    command = '{0} -d {1}'.format(command, proposed_user.home_dir)\n            elif not os.path.exists('/home/{0}'.format(proposed_user.name)):\n                command = '{0} -m'.format(command)\n        if proposed_user.shell:\n            command = '{0} -s {1}'.format(command, proposed_user.shell)\n        command = '{0} {1}'.format(command, proposed_user.name)\n    elif get_platform() == 'FreeBSD':  # pragma: FreeBSD\n        command = '{0} {1} useradd'.format(sudo_check(), FREEBSD_CMD_PW)\n        if proposed_user.uid:\n            command = '{0} -u {1}'.format(command, proposed_user.uid)\n        if proposed_user.gid:\n            command = '{0} -g {1}'.format(command, proposed_user.gid)\n        if proposed_user.gecos:\n            command = '{0} -c \\'{1}\\''.format(command, proposed_user.gecos)\n        if manage_home:\n            if proposed_user.home_dir:\n                command = '{0} -d {1}'.format(command, proposed_user.home_dir)\n            else:\n                command = '{0} -m'.format(command)\n        if proposed_user.shell:\n            command = '{0} -s {1}'.format(command, proposed_user.shell)\n        command = '{0} -n {1}'.format(command, proposed_user.name)\n\n    if command:\n        return shlex.split(str(command))", "response": "Generate command to add a user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate command to modify existing user.", "response": "def generate_modify_user_command(task=None, manage_home=None):\n    \"\"\"Generate command to modify existing user to become the proposed user.\n\n    args:\n        task (dict): A proposed user and the differences between it and the existing user\n\n    returns:\n        list: The command string split into shell-like syntax\n    \"\"\"\n    name = task['proposed_user'].name\n    comparison_result = task['user_comparison']['result']\n    command = None\n    if get_platform() in ('Linux', 'OpenBSD'):\n        command = '{0} {1}'.format(sudo_check(), LINUX_CMD_USERMOD)\n        if comparison_result.get('replacement_uid_value'):\n            command = '{0} -u {1}'.format(command, comparison_result.get('replacement_uid_value'))\n        if comparison_result.get('replacement_gid_value'):\n            command = '{0} -g {1}'.format(command, comparison_result.get('replacement_gid_value'))\n        if comparison_result.get('replacement_gecos_value'):\n            command = '{0} -c {1}'.format(command, comparison_result.get('replacement_gecos_value'))\n        if comparison_result.get('replacement_shell_value'):\n            command = '{0} -s {1}'.format(command, comparison_result.get('replacement_shell_value'))\n        if manage_home and comparison_result.get('replacement_home_dir_value'):\n                command = '{0} -d {1}'.format(command, comparison_result.get('replacement_home_dir_value'))\n        command = '{0} {1}'.format(command, name)\n    if get_platform() == 'FreeBSD':  # pragma: FreeBSD\n        command = '{0} {1} usermod'.format(sudo_check(), FREEBSD_CMD_PW)\n        if comparison_result.get('replacement_uid_value'):\n            command = '{0} -u {1}'.format(command, comparison_result.get('replacement_uid_value'))\n        if comparison_result.get('replacement_gid_value'):\n            command = '{0} -g {1}'.format(command, comparison_result.get('replacement_gid_value'))\n        if comparison_result.get('replacement_gecos_value'):\n            command = '{0} -c {1}'.format(command, comparison_result.get('replacement_gecos_value'))\n        if comparison_result.get('replacement_shell_value'):\n            command = '{0} -s {1}'.format(command, comparison_result.get('replacement_shell_value'))\n        if manage_home and comparison_result.get('replacement_home_dir_value'):\n            command = '{0} -d {1}'.format(command, comparison_result.get('replacement_home_dir_value'))\n        command = '{0} -n {1}'.format(command, name)\n    if command:\n        return shlex.split(str(command))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_delete_user_command(username=None, manage_home=None):\n    command = None\n    remove_home = '-r' if manage_home else ''\n\n    if get_platform() in ('Linux', 'OpenBSD'):\n        command = '{0} {1} {2} {3}'.format(sudo_check(), LINUX_CMD_USERDEL, remove_home, username)\n    elif get_platform() == 'FreeBSD':  # pragma: FreeBSD\n        command = '{0} {1} userdel {2} -n {3}'.format(sudo_check(), FREEBSD_CMD_PW, remove_home, username)\n    if command:\n        return shlex.split(str(command))", "response": "Generate command to delete a user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compare_user(passed_user=None, user_list=None):\n    # Check if user exists\n    returned = user_list.describe_users(users_filter=dict(name=passed_user.name))\n    replace_keys = False\n    # User exists, so compare attributes\n    comparison_result = dict()\n    if passed_user.uid and (not returned[0].uid == passed_user.uid):\n        comparison_result['uid_action'] = 'modify'\n        comparison_result['current_uid_value'] = returned[0].uid\n        comparison_result['replacement_uid_value'] = passed_user.uid\n    if passed_user.gid and (not returned[0].gid == passed_user.gid):\n        comparison_result['gid_action'] = 'modify'\n        comparison_result['current_gid_value'] = returned[0].gid\n        comparison_result['replacement_gid_value'] = passed_user.gid\n    if passed_user.gecos and (not returned[0].gecos == passed_user.gecos):\n        comparison_result['gecos_action'] = 'modify'\n        comparison_result['current_gecos_value'] = returned[0].gecos\n        comparison_result['replacement_gecos_value'] = passed_user.gecos\n    if passed_user.home_dir and (not returned[0].home_dir == passed_user.home_dir):\n        comparison_result['home_dir_action'] = 'modify'\n        comparison_result['current_home_dir_value'] = returned[0].home_dir\n        comparison_result['replacement_home_dir_value'] = passed_user.home_dir\n        # (Re)set keys if home dir changed\n        replace_keys = True\n    if passed_user.shell and (not returned[0].shell == passed_user.shell):\n        comparison_result['shell_action'] = 'modify'\n        comparison_result['current_shell_value'] = returned[0].shell\n        comparison_result['replacement_shell_value'] = passed_user.shell\n    if passed_user.sudoers_entry and (not returned[0].sudoers_entry == passed_user.sudoers_entry):\n        comparison_result['sudoers_entry_action'] = 'modify'\n        comparison_result['current_sudoers_entry'] = returned[0].sudoers_entry\n        comparison_result['replacement_sudoers_entry'] = passed_user.sudoers_entry\n    # if passed_user.public_keys and (not returned[0].public_keys == passed_user.public_keys):\n    existing_keys = returned[0].public_keys\n    passed_keys = passed_user.public_keys\n    # Check if existing and passed keys exist, and if so, compare\n    if all((existing_keys, passed_keys)) and len(existing_keys) == len(passed_user.public_keys):\n        # Compare each key, and if any differences, replace\n        existing = set(key.raw for key in existing_keys)\n        replacement = set(key.raw for key in passed_keys)\n        if set.difference(existing, replacement):\n            replace_keys = True\n    # If not existing keys but keys passed set, then\n    elif passed_keys and not existing_keys:\n        replace_keys = True\n    if replace_keys:\n        comparison_result['public_keys_action'] = 'modify'\n        comparison_result['current_public_keys_value'] = existing_keys\n        comparison_result['replacement_public_keys_value'] = passed_keys\n    return dict(state='existing', result=comparison_result, existing_user=returned)", "response": "Compare a User instance with the supplied Users list and return the differences."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gecos(self):\n        if not self._gecos:\n            return None\n        if self._gecos.startswith(text_type('\\'')) and self._gecos.endswith(text_type('\\'')):\n            self._gecos = '\\\"{0}\\\"'.format(self._gecos[1:-1])\n            return self._gecos\n        elif self._gecos.startswith(text_type('\\\"')) and self._gecos.endswith(text_type('\\\"')):\n            return self._gecos\n        else:\n            return '\\\"{0}\\\"'.format(self._gecos)", "response": "Force double quoted gecos."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the user as a dict.", "response": "def to_dict(self):\n        \"\"\" Return the user as a dict. \"\"\"\n        public_keys = [public_key.b64encoded for public_key in self.public_keys]\n        return dict(name=self.name, passwd=self.passwd, uid=self.uid, gid=self.gid, gecos=self.gecos,\n                    home_dir=self.home_dir, shell=self.shell, public_keys=public_keys)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninsert an instance of User into the collection.", "response": "def insert(self, index, value):\n        \"\"\"Insert an instance of User into the collection.\"\"\"\n        self.check(value)\n        self._user_list.insert(index, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving User instance based on supplied user name.", "response": "def remove(self, username=None):\n        \"\"\"Remove User instance based on supplied user name.\"\"\"\n        self._user_list = [user for user in self._user_list if user.name != username]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of users matching a filter ( if provided ).", "response": "def describe_users(self, users_filter=None):\n        \"\"\"Return a list of users matching a filter (if provided).\"\"\"\n        user_list = Users(oktypes=User)\n        for user in self._user_list:\n            if users_filter and (users_filter.get('name') == user.name or users_filter.get('uid') == user.uid):\n                user_list.append(user)\n        return user_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a collection from a YAML file.", "response": "def from_yaml(cls, file_path=None):\n        \"\"\"Create collection from a YAML file.\"\"\"\n        try:\n            import yaml\n        except ImportError:  # pragma: no cover\n            yaml = None\n        if not yaml:\n            import sys\n            sys.exit('PyYAML is not installed, but is required in order to parse YAML files.'\n                     '\\nTo install, run:\\n$ pip install PyYAML\\nor visit'\n                     ' http://pyyaml.org/wiki/PyYAML for instructions.')\n\n        with io.open(file_path, encoding=text_type('utf-8')) as stream:\n            users_yaml = yaml.safe_load(stream)\n            if isinstance(users_yaml, dict):\n                return cls.construct_user_list(raw_users=users_yaml.get('users'))\n            else:\n                raise ValueError('No YAML object could be decoded')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_json(cls, file_path=None):\n        with io.open(file_path, encoding=text_type('utf-8')) as stream:\n            try:\n                users_json = json.load(stream)\n            except ValueError:\n                raise ValueError('No JSON object could be decoded')\n            return cls.construct_user_list(raw_users=users_json.get('users'))", "response": "Create a collection from a JSON file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating collection from locally discovered data e. g. / etc. passwd.", "response": "def from_passwd(uid_min=None, uid_max=None):\n        \"\"\"Create collection from locally discovered data, e.g. /etc/passwd.\"\"\"\n        import pwd\n        users = Users(oktypes=User)\n        passwd_list = pwd.getpwall()\n        if not uid_min:\n            uid_min = UID_MIN\n        if not uid_max:\n            uid_max = UID_MAX\n        sudoers_entries = read_sudoers()\n        for pwd_entry in passwd_list:\n            if uid_min <= pwd_entry.pw_uid <= uid_max:\n                user = User(name=text_type(pwd_entry.pw_name),\n                            passwd=text_type(pwd_entry.pw_passwd),\n                            uid=pwd_entry.pw_uid,\n                            gid=pwd_entry.pw_gid,\n                            gecos=text_type(pwd_entry.pw_gecos),\n                            home_dir=text_type(pwd_entry.pw_dir),\n                            shell=text_type(pwd_entry.pw_shell),\n                            public_keys=read_authorized_keys(username=pwd_entry.pw_name),\n                            sudoers_entry=get_sudoers_entry(username=pwd_entry.pw_name,\n                                                            sudoers_entries=sudoers_entries))\n                users.append(user)\n        return users"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct a list of User objects from a list of dicts.", "response": "def construct_user_list(raw_users=None):\n        \"\"\"Construct a list of User objects from a list of dicts.\"\"\"\n        users = Users(oktypes=User)\n        for user_dict in raw_users:\n            public_keys = None\n            if user_dict.get('public_keys'):\n                public_keys = [PublicKey(b64encoded=x, raw=None)\n                               for x in user_dict.get('public_keys')]\n            users.append(User(name=user_dict.get('name'),\n                              passwd=user_dict.get('passwd'),\n                              uid=user_dict.get('uid'),\n                              gid=user_dict.get('gid'),\n                              home_dir=user_dict.get('home_dir'),\n                              gecos=user_dict.get('gecos'),\n                              shell=user_dict.get('shell'),\n                              public_keys=public_keys,\n                              sudoers_entry=user_dict.get('sudoers_entry')))\n        return users"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_dict(self):\n        users = dict(users=list())\n        for user in self:\n            users['users'].append(user.to_dict())\n        return users", "response": "Return a dict of the users."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting the users to a file.", "response": "def export(self, file_path=None, export_format=None):\n        \"\"\" Write the users to a file. \"\"\"\n        with io.open(file_path, mode='w', encoding=\"utf-8\") as export_file:\n            if export_format == 'yaml':\n                import yaml\n                yaml.safe_dump(self.to_dict(), export_file, default_flow_style=False)\n            elif export_format == 'json':\n                export_file.write(text_type(json.dumps(self.to_dict(), ensure_ascii=False)))\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read(path, mode='tsv'):\n    ''' Helper function to read Document in TTL-TXT format (i.e. ${docname}_*.txt)\n    E.g. read('~/data/myfile') is the same as Document('myfile', '~/data/').read()\n    '''\n    if mode == 'tsv':\n        return TxtReader.from_path(path).read()\n    elif mode == 'json':\n        return read_json(path)\n    else:\n        raise Exception(\"Invalid mode - [{}] was provided\".format(mode))", "response": "Helper function to read a TTL - TXT file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a tokens - concepts map", "response": "def tcmap(self):\n        ''' Create a tokens-concepts map '''\n        tcmap = dd(list)\n        for concept in self.__concept_map.values():\n            for w in concept.tokens:\n                tcmap[w].append(concept)\n        return tcmap"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a generator of tokens with more than one sense.", "response": "def msw(self):\n        ''' Return a generator of tokens with more than one sense. '''\n        return (t for t, c in self.tcmap().items() if len(c) > 1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the surface string that is associated with a tag object", "response": "def surface(self, tag):\n        ''' Get surface string that is associated with a tag object '''\n        if tag.cfrom is not None and tag.cto is not None and tag.cfrom >= 0 and tag.cto >= 0:\n            return self.text[tag.cfrom:tag.cto]\n        else:\n            return ''"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a sentence - level tag.", "response": "def new_tag(self, label, cfrom=-1, cto=-1, tagtype='', **kwargs):\n        ''' Create a sentence-level tag '''\n        tag_obj = Tag(label, cfrom, cto, tagtype=tagtype, **kwargs)\n        return self.add_tag(tag_obj)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_tag(self, tagtype):\n        ''' Get the first tag of a particular type'''\n        for tag in self.__tags:\n            if tag.tagtype == tagtype:\n                return tag\n        return None", "response": "Get the first tag of a particular type"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all tags of a type", "response": "def get_tags(self, tagtype):\n        ''' Get all tags of a type '''\n        return [t for t in self.__tags if t.tagtype == tagtype]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a token object into this sentence", "response": "def add_token_object(self, token):\n        ''' Add a token object into this sentence '''\n        token.sent = self  # take ownership of given token\n        self.__tokens.append(token)\n        return token"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef new_concept(self, tag, clemma=\"\", tokens=None, cidx=None, **kwargs):\n        ''' Create a new concept object and add it to concept list\n        tokens can be a list of Token objects or token indices\n        '''\n        if cidx is None:\n            cidx = self.new_concept_id()\n        if tokens:\n            tokens = (t if isinstance(t, Token) else self[t] for t in tokens)\n        c = Concept(cidx=cidx, tag=tag, clemma=clemma, sent=self, tokens=tokens, **kwargs)\n        return self.add_concept(c)", "response": "Create a new concept object and add it to concept list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_concept(self, concept_obj):\n        ''' Add a concept to current concept list '''\n        if concept_obj is None:\n            raise Exception(\"Concept object cannot be None\")\n        elif concept_obj in self.__concepts:\n            raise Exception(\"Concept object is already inside\")\n        elif concept_obj.cidx in self.__concept_map:\n            raise Exception(\"Duplicated concept ID ({})\".format(concept_obj.cidx))\n        self.__concepts.append(concept_obj)\n        self.__concept_map[concept_obj.cidx] = concept_obj\n        concept_obj.sent = self\n        return concept_obj", "response": "Add a concept to current concept list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget concept by concept ID", "response": "def concept(self, cid, **kwargs):\n        ''' Get concept by concept ID '''\n        if cid not in self.__concept_map:\n            if 'default' in kwargs:\n                return kwargs['default']\n            else:\n                raise KeyError(\"Invalid cid\")\n        else:\n            return self.__concept_map[cid]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimports a list of string as tokens", "response": "def import_tokens(self, tokens, import_hook=None, ignorecase=True):\n        ''' Import a list of string as tokens '''\n        text = self.text.lower() if ignorecase else self.text\n        has_hooker = import_hook and callable(import_hook)\n        cfrom = 0\n        if self.__tokens:\n            for tk in self.__tokens:\n                if tk.cfrom and tk.cfrom > cfrom:\n                    cfrom = tk.cfrom\n        for token in tokens:\n            if has_hooker:\n                import_hook(token)\n            to_find = token.lower() if ignorecase else token\n            start = text.find(to_find, cfrom)\n            # stanford parser\n            if to_find == '``' or to_find == \"''\":\n                start_dq = text.find('\"', cfrom)\n                if start_dq > -1 and (start == -1 or start > start_dq):\n                    to_find = '\"'\n                    start = start_dq\n            if to_find == '`' or to_find == \"'\":\n                start_dq = text.find(\"'\", cfrom)\n                if start_dq > -1 and (start == -1 or start > start_dq):\n                    to_find = \"'\"\n                    start = start_dq\n            if start == -1:\n                raise LookupError('Cannot find token `{t}` in sent `{s}`({l}) from {i} ({p})'.format(t=token, s=self.text, l=len(self.text), i=cfrom, p=self.text[cfrom:cfrom + 20]))\n            cfrom = start\n            cto = cfrom + len(to_find)\n            self.new_token(token, cfrom, cto)\n            cfrom = cto - 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a map from tagtype to list of tags", "response": "def tag_map(self):\n        ''' Build a map from tagtype to list of tags '''\n        tm = dd(list)\n        for tag in self.__tags:\n            tm[tag.tagtype].append(tag)\n        return tm"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find(self, tagtype, **kwargs):\n        '''Get the first tag with a type in this token '''\n        for t in self.__tags:\n            if t.tagtype == tagtype:\n                return t\n        if 'default' in kwargs:\n            return kwargs['default']\n        else:\n            raise LookupError(\"Token {} is not tagged with the speficied tagtype ({})\".format(self, tagtype))", "response": "Find the first tag with a type in this token"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind all token - level tags with the specified tagtype", "response": "def find_all(self, tagtype):\n        ''' Find all token-level tags with the specified tagtype '''\n        return [t for t in self.__tags if t.tagtype == tagtype]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new tag on this token", "response": "def new_tag(self, label, cfrom=None, cto=None, tagtype=None, **kwargs):\n        ''' Create a new tag on this token '''\n        if cfrom is None:\n            cfrom = self.cfrom\n        if cto is None:\n            cto = self.cto\n        tag = Tag(label=label, cfrom=cfrom, cto=cto, tagtype=tagtype, **kwargs)\n        return self.add_tag(tag)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the associated sentence object.", "response": "def get(self, sent_id, **kwargs):\n        ''' If sent_id exists, remove and return the associated sentence object else return default.\n        If no default is provided, KeyError will be raised.'''\n        if sent_id is not None and not isinstance(sent_id, int):\n            sent_id = int(sent_id)\n        if sent_id is None or not self.has_id(sent_id):\n            if 'default' in kwargs:\n                return kwargs['default']\n            else:\n                raise KeyError(\"Invalid sentence ID ({})\".format(sent_id))\n        return self.__sent_map[sent_id]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a ttl. Sentence object to this document.", "response": "def add_sent(self, sent_obj):\n        ''' Add a ttl.Sentence object to this document '''\n        if sent_obj is None:\n            raise Exception(\"Sentence object cannot be None\")\n        elif sent_obj.ID is None:\n            # if sentID is None, create a new ID\n            sent_obj.ID = next(self.__idgen)\n        elif self.has_id(sent_obj.ID):\n            raise Exception(\"Sentence ID {} exists\".format(sent_obj.ID))\n        self.__sent_map[sent_obj.ID] = sent_obj\n        self.__sents.append(sent_obj)\n        return sent_obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new sentence and add it to this Document", "response": "def new_sent(self, text, ID=None, **kwargs):\n        ''' Create a new sentence and add it to this Document '''\n        if ID is None:\n            ID = next(self.__idgen)\n        return self.add_sent(Sentence(text, ID=ID, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pop(self, sent_id, **kwargs):\n        ''' If sent_id exists, remove and return the associated sentence object else return default.\n        If no default is provided, KeyError will be raised.'''\n        if sent_id is not None and not isinstance(sent_id, int):\n            sent_id = int(sent_id)\n        if not self.has_id(sent_id):\n            if 'default' in kwargs:\n                return kwargs['default']\n            else:\n                raise KeyError(\"Sentence ID {} does not exist\".format(sent_id))\n        else:\n            # sentence exists ...\n            sent_obj = self.get(sent_id)\n            self.__sent_map.pop(sent_id)\n            self.__sents.remove(sent_obj)\n            return sent_obj", "response": "Removes and returns the associated sentence object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading tagged doc from mutliple files.", "response": "def read(self):\n        ''' Read tagged doc from mutliple files (sents, tokens, concepts, links, tags) '''\n        warnings.warn(\"Document.read() is deprecated and will be removed in near future.\", DeprecationWarning)\n        with TxtReader.from_doc(self) as reader:\n            reader.read(self)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread tagged doc from mutliple files.", "response": "def read(self, doc=None):\n        ''' Read tagged doc from mutliple files (sents, tokens, concepts, links, tags) '''\n        if not self.sent_stream:\n            raise Exception(\"There is no sentence data stream available\")\n        if doc is None:\n            doc = Document(name=self.doc_name, path=self.doc_path)\n        for row in self.sent_reader():\n            if len(row) == 2:\n                sid, text = row\n                doc.new_sent(text.strip(), ID=sid)\n            elif len(row) == 4:\n                sid, text, flag, comment = row\n                sent = doc.new_sent(text.strip(), ID=sid)\n                sent.flag = flag\n                sent.comment = comment\n        # Read tokens if available\n        if self.token_stream:\n            # read all tokens first\n            sent_tokens_map = dd(list)\n            for token_row in self.token_reader():\n                if len(token_row) == 6:\n                    sid, wid, token, lemma, pos, comment = token_row\n                else:\n                    sid, wid, token, lemma, pos = token_row\n                    comment = ''\n                sid = int(sid)\n                sent_tokens_map[sid].append((token, lemma, pos.strip(), wid, comment))\n                # TODO: verify wid?\n            # import tokens\n            for sent in doc:\n                sent_tokens = sent_tokens_map[sent.ID]\n                sent.import_tokens([x[0] for x in sent_tokens])\n                for ((tk, lemma, pos, wid, comment), token) in zip(sent_tokens, sent.tokens):\n                    token.pos = pos\n                    token.lemma = lemma\n                    token.comment = comment\n            # only read concepts if tokens are available\n            if self.concept_stream:\n                # read concepts\n                for concept_row in self.concept_reader():\n                    if len(concept_row) == 5:\n                        sid, cid, clemma, tag, comment = concept_row\n                    else:\n                        sid, cid, clemma, tag = concept_row\n                        comment = ''\n                    cid = int(cid)\n                    doc.get(sid).new_concept(tag.strip(), clemma=clemma, cidx=cid, comment=comment)\n                # only read concept-token links if tokens and concepts are available\n                for sid, cid, wid in self.link_reader():\n                    sent = doc.get(sid)\n                    cid = int(cid)\n                    wid = int(wid.strip())\n                    sent.concept(cid).add_token(sent[wid])\n        # read sentence level tags\n        if self.tag_stream:\n            for row in self.tag_reader():\n                if len(row) == 5:\n                    sid, cfrom, cto, label, tagtype = row\n                    wid = None\n                if len(row) == 6:\n                    sid, cfrom, cto, label, tagtype, wid = row\n                if cfrom:\n                    cfrom = int(cfrom)\n                if cto:\n                    cto = int(cto)\n                if wid is None or wid == '':\n                    doc.get(sid).new_tag(label, cfrom, cto, tagtype=tagtype)\n                else:\n                    doc.get(sid)[int(wid)].new_tag(label, cfrom, cto, tagtype=tagtype)\n        return doc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_page(text):\r\n    width = max(map(len, text.splitlines()))\r\n    page = \"+-\" + \"-\" * width + \"-+\\n\"\r\n    for line in text.splitlines():\r\n        page += \"| \" + line.ljust(width) + \" |\\n\"\r\n    page += \"+-\" + \"-\" * width + \"-+\\n\"\r\n    return page", "response": "Format the text for output adding ASCII frame around the text."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef table(text):\r\n\r\n    def table_bar(col_lengths):\r\n        return \"+-%s-+%s\" % (\r\n            \"-+-\".join([\"-\" * length for length in col_lengths]),\r\n            os.linesep,\r\n        )\r\n\r\n    rows = []\r\n    for line in text.splitlines():\r\n        rows.append([part.strip() for part in line.split(\"|\")])\r\n    max_cols = max(map(len, rows))\r\n    col_lengths = [0] * max_cols\r\n    for row in rows:\r\n        cols = len(row)\r\n        if cols < max_cols:\r\n            row.extend([\"\"] * (max_cols - cols))\r\n        for i, col in enumerate(row):\r\n            col_length = len(col)\r\n            if col_length > col_lengths[i]:\r\n                col_lengths[i] = col_length\r\n    text = table_bar(col_lengths)\r\n    for i, row in enumerate(rows):\r\n        cols = []\r\n        for i, col in enumerate(row):\r\n            cols.append(col.ljust(col_lengths[i]))\r\n        text += \"| %s |%s\" % (\" | \".join(cols), os.linesep)\r\n        text += table_bar(col_lengths)\r\n    return text", "response": "Format the text as a table."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats the text and prints it on stdout.", "response": "def print_page(text):\r\n    \"\"\"Format the text and prints it on stdout.\r\n\r\n    Text is formatted by adding a ASCII frame around it and coloring the text.\r\n    Colors can be added to text using color tags, for example:\r\n\r\n        My [FG_BLUE]blue[NORMAL] text.\r\n        My [BG_BLUE]blue background[NORMAL] text.\r\n    \"\"\"\r\n    color_re = re.compile(r\"\\[(?P<color>[FB]G_[A-Z_]+|NORMAL)\\]\")\r\n    width = max([len(strip_colors(x)) for x in text.splitlines()])\r\n    print(\"\\n\" + hbar(width))\r\n    for line in text.splitlines():\r\n        if line == \"[HBAR]\":\r\n            print(hbar(width))\r\n            continue\r\n        tail = width - len(strip_colors(line))\r\n        sys.stdout.write(\"| \")\r\n        previous = 0\r\n        end = len(line)\r\n        for match in color_re.finditer(line):\r\n            sys.stdout.write(line[previous : match.start()])\r\n            set_color(match.groupdict()[\"color\"])\r\n            previous = match.end()\r\n        sys.stdout.write(line[previous:end])\r\n        sys.stdout.write(\" \" * tail + \" |\\n\")\r\n    print(hbar(width))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap text to maximum width characters per line.", "response": "def wrap_text(text, width=80):\r\n    \"\"\"Wrap text lines to maximum *width* characters.\r\n\r\n    Wrapped text is aligned against the left text border.\r\n\r\n    Args:\r\n        text (str): Text to wrap.\r\n        width (int): Maximum number of characters per line.\r\n\r\n    Returns:\r\n        str: Wrapped text.\r\n    \"\"\"\r\n    text = re.sub(r\"\\s+\", \" \", text).strip()\r\n    wrapper = TextWrapper(\r\n        width=width, break_long_words=False, replace_whitespace=True\r\n    )\r\n    return wrapper.fill(text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rjust_text(text, width=80, indent=0, subsequent=None):\r\n    text = re.sub(r\"\\s+\", \" \", text).strip()\r\n    if subsequent is None:\r\n        subsequent = indent\r\n    wrapper = TextWrapper(\r\n        width=width,\r\n        break_long_words=False,\r\n        replace_whitespace=True,\r\n        initial_indent=\" \" * (indent + subsequent),\r\n        subsequent_indent=\" \" * subsequent,\r\n    )\r\n    return wrapper.fill(text)[subsequent:]", "response": "Wrap text and adjust it to right border."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef center_text(text, width=80):\r\n    centered = []\r\n    for line in text.splitlines():\r\n        centered.append(line.center(width))\r\n    return \"\\n\".join(centered)", "response": "Center all lines of the text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck various properties of a QPImage or a path to an hdf5 file.", "response": "def check(qpi_or_h5file, checks=[\"attributes\", \"background\"]):\n    \"\"\"Checks various properties of a :class:`qpimage.core.QPImage` instance\n\n    Parameters\n    ----------\n    qpi_or_h5file: qpimage.core.QPImage or str\n        A QPImage object or a path to an hdf5 file\n    checks: list of str\n        Which checks to perform (\"attributes\" and/or \"background\")\n\n    Raises\n    ------\n    IntegrityCheckError\n        if the checks fail\n    \"\"\"\n    if isinstance(checks, str):\n        checks = [checks]\n    for ch in checks:\n        if ch not in [\"attributes\", \"background\"]:\n            raise ValueError(\"Unknown check: {}\".format(check))\n\n    if isinstance(qpi_or_h5file, QPImage):\n        qpi = qpi_or_h5file\n    else:\n        qpi = QPImage(h5file=qpi_or_h5file, h5mode=\"r\")\n\n    # check attributes\n    if \"attributes\" in checks:\n        check_attributes(qpi)\n\n    # check background estimation\n    if \"background\" in checks:\n        check_background(qpi)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that the attributes of the sequence of items in the sequence are present in the meta data.", "response": "def check_attributes(qpi):\n    \"\"\"Check QPimage attributes\n\n    Parameters\n    ----------\n    qpi: qpimage.core.QPImage\n\n    Raises\n    ------\n    IntegrityCheckError\n        if the check fails\n    \"\"\"\n    missing_attrs = []\n    for key in DATA_KEYS:\n        if key not in qpi.meta:\n            missing_attrs.append(key)\n    if missing_attrs:\n        msg = \"Attributes are missing: {} \".format(missing_attrs) \\\n            + \"in {}!\".format(qpi)\n        raise IntegrityCheckError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_background(qpi):\n    for imdat in [qpi._amp, qpi._pha]:\n        try:\n            fit, attrs = imdat.get_bg(key=\"fit\", ret_attrs=True)\n        except KeyError:\n            # No bg correction performed\n            pass\n        else:\n            kwargs = dict(attrs)\n            # check if we have a user-defined mask image\n            binkey = \"estimate_bg_from_mask\"\n            if binkey in imdat.h5:\n                kwargs[\"from_mask\"] = imdat.h5[binkey][:]\n            else:\n                kwargs[\"from_mask\"] = None\n            # compute background correction\n            with h5py.File(\"check.h5\",\n                           driver=\"core\",\n                           backing_store=False) as h5:\n                # imdat.__class__ is \"Amplitude\" or \"Phase\"\n                testimdat = imdat.__class__(h5)\n                testimdat[\"raw\"] = imdat.raw\n                # Set experimental bg data if given\n                try:\n                    bg = imdat.get_bg(\"data\")\n                except KeyError:\n                    pass\n                else:\n                    testimdat.set_bg(bg, key=\"data\")\n                # fit bg\n                testimdat.estimate_bg(**kwargs)\n                # compare\n                if not np.allclose(testimdat.get_bg(key=\"fit\"), fit):\n                    msg = \"Wrong estimated (fitted) background!\"\n                    raise IntegrityCheckError(msg)", "response": "Check if background correction is correct for all images in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites an image to an HDF5 group as a dataset", "response": "def write_image_dataset(group, key, data, h5dtype=None):\n    \"\"\"Write an image to an hdf5 group as a dataset\n\n    This convenience function sets all attributes such that the image\n    can be visualized with HDFView, sets the compression and fletcher32\n    filters, and sets the chunk size to the image shape.\n\n    Parameters\n    ----------\n    group: h5py.Group\n        HDF5 group to store data to\n    key: str\n        Dataset identifier\n    data: np.ndarray of shape (M,N)\n        Image data to store\n    h5dtype: str\n        The datatype in which to store the image data. The default\n        is the datatype of `data`.\n\n    Returns\n    -------\n    dataset: h5py.Dataset\n        The created HDF5 dataset object\n    \"\"\"\n    if h5dtype is None:\n        h5dtype = data.dtype\n    if key in group:\n        del group[key]\n    if group.file.driver == \"core\":\n        kwargs = {}\n    else:\n        kwargs = {\"fletcher32\": True,\n                  \"chunks\": data.shape}\n        kwargs.update(COMPRESSION)\n\n    dset = group.create_dataset(key,\n                                data=data.astype(h5dtype),\n                                **kwargs)\n    # Create and Set image attributes\n    # HDFView recognizes this as a series of images\n    dset.attrs.create('CLASS', b'IMAGE')\n    dset.attrs.create('IMAGE_VERSION', b'1.2')\n    dset.attrs.create('IMAGE_SUBCLASS', b'IMAGE_GRAYSCALE')\n    return dset"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist of background correction parameters", "response": "def info(self):\n        \"\"\"list of background correction parameters\"\"\"\n        info = []\n        name = self.__class__.__name__.lower()\n        # get bg information\n        for key in VALID_BG_KEYS:\n            if key in self.h5[\"bg_data\"]:\n                attrs = self.h5[\"bg_data\"][key].attrs\n                for akey in attrs:\n                    atr = attrs[akey]\n                    var = \"{} background {}\".format(name, akey)\n                    info.append((var, atr))\n        if \"fit\" in self.h5[\"bg_data\"]:\n            # mask background\n            var_mask = \"{} background from mask\".format(name)\n            if (\"estimate_bg_from_mask\" in self.h5\n                    and self.h5[\"estimate_bg_from_mask\"] is not None):\n                # bg was computed from mask image\n                info.append((var_mask, True))\n            elif (\"estimate_bg_from_binary\" in self.h5\n                    and self.h5[\"estimate_bg_from_binary\"] is not None):\n                # bg was computed from mask image (old notation)\n                warnings.warn(\"Old file format detected!\", DeprecationWarning)\n                info.append((var_mask, True))\n            else:\n                info.append((var_mask, False))\n        return info"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef del_bg(self, key):\n        if key not in VALID_BG_KEYS:\n            raise ValueError(\"Invalid bg key: {}\".format(key))\n        if key in self.h5[\"bg_data\"]:\n            del self.h5[\"bg_data\"][key]\n        else:\n            msg = \"No bg data to clear for '{}' in {}.\".format(key, self)\n            warnings.warn(msg)", "response": "Removes the background image data for the specified key from the H5 file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef estimate_bg(self, fit_offset=\"mean\", fit_profile=\"tilt\",\n                    border_px=0, from_mask=None, ret_mask=False):\n        \"\"\"Estimate image background\n\n        Parameters\n        ----------\n        fit_profile: str\n            The type of background profile to fit:\n\n            - \"offset\": offset only\n            - \"poly2o\": 2D 2nd order polynomial with mixed terms\n            - \"tilt\": 2D linear tilt with offset (default)\n        fit_offset: str\n            The method for computing the profile offset\n\n            - \"fit\": offset as fitting parameter\n            - \"gauss\": center of a gaussian fit\n            - \"mean\": simple average\n            - \"mode\": mode (see `qpimage.bg_estimate.mode`)\n        border_px: float\n            Assume that a frame of `border_px` pixels around\n            the image is background.\n        from_mask: boolean np.ndarray or None\n            Use a boolean array to define the background area.\n            The mask image must have the same shape as the\n            input data.`True` elements are used for background\n            estimation.\n        ret_mask: bool\n            Return the mask image used to compute the background.\n\n        Notes\n        -----\n        If both `border_px` and `from_mask` are given, the\n        intersection of the two resulting mask images is used.\n\n        The arguments passed to this method are stored in the\n        hdf5 file `self.h5` and are used for optional integrity\n        checking using `qpimage.integrity_check.check`.\n\n        See Also\n        --------\n        qpimage.bg_estimate.estimate\n        \"\"\"\n        # remove existing bg before accessing imdat.image\n        self.set_bg(bg=None, key=\"fit\")\n        # compute bg\n        bgimage, mask = bg_estimate.estimate(data=self.image,\n                                             fit_offset=fit_offset,\n                                             fit_profile=fit_profile,\n                                             border_px=border_px,\n                                             from_mask=from_mask,\n                                             ret_mask=True)\n        attrs = {\"fit_offset\": fit_offset,\n                 \"fit_profile\": fit_profile,\n                 \"border_px\": border_px}\n        self.set_bg(bg=bgimage, key=\"fit\", attrs=attrs)\n        # save `from_mask` separately (arrays vs. h5 attributes)\n        # (if `from_mask` is `None`, this will remove the array)\n        self[\"estimate_bg_from_mask\"] = from_mask\n        # return mask image\n        if ret_mask:\n            return mask", "response": "Estimate image background of a single object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_bg(self, key=None, ret_attrs=False):\n        if key is None:\n            if ret_attrs:\n                raise ValueError(\"No attributes for combined background!\")\n            return self.bg\n        else:\n            if key not in VALID_BG_KEYS:\n                raise ValueError(\"Invalid bg key: {}\".format(key))\n            if key in self.h5[\"bg_data\"]:\n                data = self.h5[\"bg_data\"][key][:]\n                if ret_attrs:\n                    attrs = dict(self.h5[\"bg_data\"][key].attrs)\n                    # remove keys for image visualization in hdf5 files\n                    for h5k in [\"CLASS\", \"IMAGE_VERSION\", \"IMAGE_SUBCLASS\"]:\n                        if h5k in attrs:\n                            attrs.pop(h5k)\n                    ret = (data, attrs)\n                else:\n                    ret = data\n            else:\n                raise KeyError(\"No background data for {}!\".format(key))\n            return ret", "response": "Get the background image data for the specified key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the background data for the current object.", "response": "def set_bg(self, bg, key=\"data\", attrs={}):\n        \"\"\"Set the background data\n\n        Parameters\n        ----------\n        bg: numbers.Real, 2d ndarray, ImageData, or h5py.Dataset\n            The background data. If `bg` is an `h5py.Dataset` object,\n            it must exist in the same hdf5 file (a hard link is created).\n            If set to `None`, the data will be removed.\n        key: str\n            One of :const:`VALID_BG_KEYS`)\n        attrs: dict\n            List of background attributes\n\n        See Also\n        --------\n        del_bg: removing background data\n        \"\"\"\n        if key not in VALID_BG_KEYS:\n            raise ValueError(\"Invalid bg key: {}\".format(key))\n        # remove previous background key\n        if key in self.h5[\"bg_data\"]:\n            del self.h5[\"bg_data\"][key]\n        # set background\n        if isinstance(bg, (numbers.Real, np.ndarray)):\n            dset = write_image_dataset(group=self.h5[\"bg_data\"],\n                                       key=key,\n                                       data=bg,\n                                       h5dtype=self.h5dtype)\n            for kw in attrs:\n                dset.attrs[kw] = attrs[kw]\n        elif isinstance(bg, h5py.Dataset):\n            # Create a hard link\n            # (This functionality was intended for saving memory when storing\n            # large QPSeries with universal background data, i.e. when using\n            # `QPSeries.add_qpimage` with the `bg_from_idx` keyword.)\n            self.h5[\"bg_data\"][key] = bg\n        elif bg is not None:\n            msg = \"Unknown background data type: {}\".format(bg)\n            raise ValueError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncombining several background amplitude images", "response": "def _bg_combine(self, bgs):\n        \"\"\"Combine several background amplitude images\"\"\"\n        out = np.ones(self.h5[\"raw\"].shape, dtype=float)\n        # bg is an h5py.DataSet\n        for bg in bgs:\n            out *= bg[:]\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef git_tags() -> str:\n    try:\n        subprocess.check_call(['git', 'fetch', '--tags'])\n    except CalledProcessError:\n        pass\n\n    cmd = ['git', 'tag', '--list', '--sort=-v:refname']\n    rv = subprocess.check_output(cmd).decode('utf-8')\n\n    if rv == '':\n        raise NoGitTagsException('No Git tags are present in current repo.')\n\n    return rv", "response": "Returns the Git tags of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef git_tag_to_semver(git_tag: str) -> SemVer:\n    pattern = re.compile(r'[0-9]+\\.[0-9]+\\.[0-9]+$')\n    match = pattern.search(git_tag)\n    if match:\n        version = match.group(0)\n    else:\n        raise InvalidTagFormatException('Tag passed contains no SemVer.')\n\n    return SemVer.from_str(version)", "response": "Converts a Git tag to a SemVer object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef last_git_release_tag(git_tags: str) -> str:\n    semver_re = re.compile(r'[0-9]+\\.[0-9]+\\.[0-9]+$')\n    str_ver = []\n    for i in git_tags.split():\n        if semver_re.search(i):\n            str_ver.append(i)\n\n    try:\n        return str_ver[0]\n    except IndexError:\n        raise NoGitTagsException", "response": "Returns the last Git release tag in a list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dict of hash - message pairs for all commits since the given git tag.", "response": "def git_commits_since_last_tag(last_tag: str) -> dict:\n    \"\"\"\n    :last_tag: The Git tag that should serve as the starting point for the\n    commit log lookup.\n\n    Calls ``git log <last_tag>.. --format='%H %s'`` and returns the output as a\n    dict of hash-message pairs.\n    \"\"\"\n    try:\n        cmd = ['git', 'log', last_tag + '..', \"--format='%H %s'\"]\n        commit_log = subprocess.check_output(cmd).decode('utf-8')\n    except CalledProcessError:\n        raise GitTagDoesNotExistError('No such tag:', last_tag)\n\n    if not commit_log:\n        raise NoGitCommitSinceLastTagException('No commits since last tag.')\n\n    pattern = re.compile(r'([a-f0-9]{40})\\ (.*)')\n\n    rv = {}\n    for line in commit_log.split('\\n'):\n        match = pattern.search(line)\n        if match:\n            commit_hash = match.group(1)\n            commit_msg = match.group(2)\n            rv[commit_hash] = commit_msg\n\n    return rv"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_commit_log(commit_log: dict) -> str:\n    rv = 'pat'\n\n    cc_patterns = patterns()\n\n    for value in commit_log.values():\n        if re.search(cc_patterns['feat'], value):\n            rv = 'min'\n        if re.search(cc_patterns['BREAKING CHANGE'], value):\n            rv = 'maj'\n\n    return rv", "response": "Parse Git log and return either maj min or pat."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_str(cls, version_str: str):\n        o = cls()\n        o.version = version_str\n        return o", "response": "Alternative constructor that accepts a string SemVer.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef major(self, major: int) -> None:\n        self.filter_negatives(major)\n        self._major = major", "response": "Sets the major version number property."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the minor version number property.", "response": "def minor(self, minor: int) -> None:\n        \"\"\"\n        param minor\n\n        Minor version number property. Must be a non-negative integer.\n        \"\"\"\n        self.filter_negatives(minor)\n        self._minor = minor"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the patch version number property.", "response": "def patch(self, patch: int) -> None:\n        \"\"\"\n        param patch\n\n        Patch version number property. Must be a non-negative integer.\n        \"\"\"\n        self.filter_negatives(patch)\n        self._patch = patch"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the version number property.", "response": "def version(self) -> str:\n        \"\"\"\n        Version version number property. Must be a string consisting of three\n        non-negative integers delimited by periods (eg. '1.0.1').\n        \"\"\"\n        version: str = (\n            str(self._major) + '.' +\n            str(self._minor) + '.' +\n            str(self._patch)\n        )\n        return version"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef version(self, version_str: str) -> None:\n        ver = []\n        for i in version_str.split('.'):\n            ver.append(int(i))\n            self.filter_negatives(int(i))\n        self._major, self._minor, self._patch = ver[0], ver[1], ver[2]", "response": "Sets the version number property of the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nestimate the background value of an image.", "response": "def estimate(data, fit_offset=\"mean\", fit_profile=\"tilt\",\n             border_px=0, from_mask=None, ret_mask=False):\n    \"\"\"Estimate the background value of an image\n\n    Parameters\n    ----------\n    data: np.ndarray\n        Data from which to compute the background value\n    fit_profile: str\n        The type of background profile to fit:\n\n        - \"offset\": offset only\n        - \"poly2o\": 2D 2nd order polynomial with mixed terms\n        - \"tilt\": 2D linear tilt with offset (default)\n    fit_offset: str\n        The method for computing the profile offset\n\n        - \"fit\": offset as fitting parameter\n        - \"gauss\": center of a gaussian fit\n        - \"mean\": simple average\n        - \"mode\": mode (see `qpimage.bg_estimate.mode`)\n    border_px: float\n        Assume that a frame of `border_px` pixels around\n        the image is background.\n    from_mask: boolean np.ndarray or None\n        Use a boolean array to define the background area.\n        The boolean mask must have the same shape as the\n        input data. `True` elements are used for background\n        estimation.\n    ret_mask: bool\n        Return the boolean mask used to compute the background.\n\n    Notes\n    -----\n    If both `border_px` and `from_mask` are given, the\n    intersection of the two is used, i.e. the positions\n    where both, the frame mask and `from_mask`, are\n    `True`.\n    \"\"\"\n    if fit_profile not in VALID_FIT_PROFILES:\n        msg = \"`fit_profile` must be one of {}, got '{}'\".format(\n            VALID_FIT_PROFILES,\n            fit_profile)\n        raise ValueError(msg)\n    if fit_offset not in VALID_FIT_OFFSETS:\n        msg = \"`fit_offset` must be one of {}, got '{}'\".format(\n            VALID_FIT_OFFSETS,\n            fit_offset)\n        raise ValueError(msg)\n    # initial mask image\n    if from_mask is not None:\n        assert isinstance(from_mask, np.ndarray)\n        mask = from_mask.copy()\n    else:\n        mask = np.ones_like(data, dtype=bool)\n    # multiply with border mask image (intersection)\n    if border_px > 0:\n        border_px = int(np.round(border_px))\n        mask_px = np.zeros_like(mask)\n        mask_px[:border_px, :] = True\n        mask_px[-border_px:, :] = True\n        mask_px[:, :border_px] = True\n        mask_px[:, -border_px:] = True\n        # intersection\n        np.logical_and(mask, mask_px, out=mask)\n    # compute background image\n    if fit_profile == \"tilt\":\n        bgimg = profile_tilt(data, mask)\n    elif fit_profile == \"poly2o\":\n        bgimg = profile_poly2o(data, mask)\n    else:\n        bgimg = np.zeros_like(data, dtype=float)\n    # add offsets\n    if fit_offset == \"fit\":\n        if fit_profile == \"offset\":\n            msg = \"`fit_offset=='fit'` only valid when `fit_profile!='offset`\"\n            raise ValueError(msg)\n        # nothing else to do here, using offset from fit\n    elif fit_offset == \"gauss\":\n        bgimg += offset_gaussian((data - bgimg)[mask])\n    elif fit_offset == \"mean\":\n        bgimg += np.mean((data - bgimg)[mask])\n    elif fit_offset == \"mode\":\n        bgimg += offset_mode((data - bgimg)[mask])\n\n    if ret_mask:\n        ret = (bgimg, mask)\n    else:\n        ret = bgimg\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfits a gaussian model to data and return its center", "response": "def offset_gaussian(data):\n    \"\"\"Fit a gaussian model to `data` and return its center\"\"\"\n    nbins = 2 * int(np.ceil(np.sqrt(data.size)))\n    mind, maxd = data.min(), data.max()\n    drange = (mind - (maxd - mind) / 2, maxd + (maxd - mind) / 2)\n    histo = np.histogram(data, nbins, density=True, range=drange)\n    dx = abs(histo[1][1] - histo[1][2]) / 2\n    hx = histo[1][1:] - dx\n    hy = histo[0]\n    # fit gaussian\n    gauss = lmfit.models.GaussianModel()\n    pars = gauss.guess(hy, x=hx)\n    out = gauss.fit(hy, pars, x=hx)\n    return out.params[\"center\"]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef offset_mode(data):\n    nbins = int(np.ceil(np.sqrt(data.size)))\n    mind, maxd = data.min(), data.max()\n    histo = np.histogram(data, nbins, density=True, range=(mind, maxd))\n    dx = abs(histo[1][1] - histo[1][2]) / 2\n    hx = histo[1][1:] - dx\n    hy = histo[0]\n    idmax = np.argmax(hy)\n    return hx[idmax]", "response": "Compute Mode using a histogram with sqrt ( data. size ) bins"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef profile_tilt(data, mask):\n    params = lmfit.Parameters()\n    params.add(name=\"mx\", value=0)\n    params.add(name=\"my\", value=0)\n    params.add(name=\"off\", value=np.average(data[mask]))\n    fr = lmfit.minimize(tilt_residual, params, args=(data, mask))\n    bg = tilt_model(fr.params, data.shape)\n    return bg", "response": "Fit a 2D tilt to data [ mask ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfits a 2D 2nd order polynomial to data [ mask ]", "response": "def profile_poly2o(data, mask):\n    \"\"\"Fit a 2D 2nd order polynomial to `data[mask]`\"\"\"\n    # lmfit\n    params = lmfit.Parameters()\n    params.add(name=\"mx\", value=0)\n    params.add(name=\"my\", value=0)\n    params.add(name=\"mxy\", value=0)\n    params.add(name=\"ax\", value=0)\n    params.add(name=\"ay\", value=0)\n    params.add(name=\"off\", value=np.average(data[mask]))\n    fr = lmfit.minimize(poly2o_residual, params, args=(data, mask))\n    bg = poly2o_model(fr.params, data.shape)\n    return bg"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef poly2o_residual(params, data, mask):\n    bg = poly2o_model(params, shape=data.shape)\n    res = (data - bg)[mask]\n    return res.flatten()", "response": "lmfit 2nd order polynomial residuals"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef infer(args: argparse.Namespace) -> None:\n    try:\n        last_tag = last_git_release_tag(git_tags())\n    except NoGitTagsException:\n        print(SemVer(0, 1, 0))\n        exit(0)\n\n    commit_log = git_commits_since_last_tag(last_tag)\n    action = parse_commit_log(commit_log)\n\n    last_ver = git_tag_to_semver(last_tag)\n\n    if action == 'min':\n        new_ver = last_ver.bump_minor()\n    elif action == 'maj':\n        new_ver = last_ver.bump_major()\n    else:\n        new_ver = last_ver.bump_patch()\n\n    print(new_ver)", "response": "Infer the current version of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bump(args: argparse.Namespace) -> None:\n    try:\n        last_tag = last_git_release_tag(git_tags())\n    except NoGitTagsException:\n        print(SemVer(0, 1, 0))\n        exit(0)\n\n    last_ver = git_tag_to_semver(last_tag)\n\n    if args.type == 'patch':\n        print(last_ver.bump_patch())\n    elif args.type == 'minor':\n        print(last_ver.bump_minor())\n    elif args.type == 'major':\n        print(last_ver.bump_major())", "response": "Bump the current version of the current node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds the side band position of a hologram image.", "response": "def find_sideband(ft_data, which=+1, copy=True):\n    \"\"\"Find the side band position of a hologram\n\n    The hologram is Fourier-transformed and the side band\n    is determined by finding the maximum amplitude in\n    Fourier space.\n\n    Parameters\n    ----------\n    ft_data: 2d ndarray\n        Fourier transform of the hologram image\n    which: +1 or -1\n        which sideband to search for:\n\n        - +1: upper half\n        - -1: lower half\n    copy: bool\n        copy `ft_data` before modification\n\n    Returns\n    -------\n    fsx, fsy : tuple of floats\n        coordinates of the side band in Fourier space frequencies\n    \"\"\"\n    if copy:\n        ft_data = ft_data.copy()\n\n    if which not in [+1, -1]:\n        raise ValueError(\"`which` must be +1 or -1!\")\n\n    ox, oy = ft_data.shape\n    cx = ox // 2\n    cy = oy // 2\n\n    minlo = max(int(np.ceil(ox / 42)), 5)\n    if which == +1:\n        # remove lower part\n        ft_data[cx - minlo:] = 0\n    else:\n        ft_data[:cx + minlo] = 0\n\n    # remove values around axes\n    ft_data[cx - 3:cx + 3, :] = 0\n    ft_data[:, cy - 3:cy + 3] = 0\n\n    # find maximum\n    am = np.argmax(np.abs(ft_data))\n    iy = am % oy\n    ix = int((am - iy) / oy)\n\n    fx = np.fft.fftshift(np.fft.fftfreq(ft_data.shape[0]))[ix]\n    fy = np.fft.fftshift(np.fft.fftfreq(ft_data.shape[1]))[iy]\n\n    return (fx, fy)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fourier2dpad(data, zero_pad=True):\n    if zero_pad:\n        # zero padding size is next order of 2\n        (N, M) = data.shape\n        order = np.int(max(64., 2**np.ceil(np.log(2 * max(N, M)) / np.log(2))))\n\n        # this is faster than np.pad\n        datapad = np.zeros((order, order), dtype=float)\n        datapad[:data.shape[0], :data.shape[1]] = data\n    else:\n        datapad = data\n\n    # Fourier transform\n    fft = np.fft.fftshift(np.fft.fft2(datapad))\n    return fft", "response": "Compute the 2D Fourier transform with zero padding"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_field(hologram, sideband=+1, filter_name=\"disk\", filter_size=1 / 3,\n              subtract_mean=True, zero_pad=True, copy=True):\n    \"\"\"Compute the complex field from a hologram using Fourier analysis\n\n    Parameters\n    ----------\n    hologram: real-valued 2d ndarray\n        hologram data\n    sideband: +1, -1, or tuple of (float, float)\n        specifies the location of the sideband:\n\n        - +1: sideband in the upper half in Fourier space,\n          exact location is found automatically\n        - -1: sideband in the lower half in Fourier space,\n          exact location is found automatically\n        - (float, float): sideband coordinates in\n          frequencies in interval [1/\"axes size\", .5]\n    filter_name: str\n        specifies the filter to use, one of\n\n        - \"disk\": binary disk with radius `filter_size`\n        - \"smooth disk\": disk with radius `filter_size` convolved\n          with a radial gaussian (`sigma=filter_size/5`)\n        - \"gauss\": radial gaussian (`sigma=0.6*filter_size`)\n        - \"square\": binary square with side length `filter_size`\n        - \"smooth square\": square with side length `filter_size`\n          convolved with square gaussian (`sigma=filter_size/5`)\n        - \"tukey\": a square tukey window of width `2*filter_size` and\n          `alpha=0.1`\n    filter_size: float\n        Size of the filter in Fourier space in fractions of the\n        distance between central band and sideband.\n        See `filter_shape` for interpretation of `filter_size`.\n    subtract_mean: bool\n        If True, remove the mean of the hologram before performing\n        the Fourier transform. This setting is recommended as it\n        can reduce artifacts from frequencies around the central\n        band.\n    zero_pad: bool\n        Perform zero-padding before applying the FFT. Setting\n        `zero_pad` to `False` increases speed but might\n        introduce image distortions such as tilts in the phase\n        and amplitude data or dark borders in the amplitude data.\n    copy: bool\n        If set to True, input `data` is not edited.\n\n    x0 and y0 are center of the filter\n    R is factor for \"radius\" of filter (sqrt(x0\u00b2 + y0\u00b2)/np.pi)\n\n    filter_type can be \"disk\" or \"gauss\"\n\n    Notes\n    -----\n    Even though the size of the \"gauss\" filter approximately matches\n    the frequencies of the \"disk\" filter, it takes into account\n    higher frequencies as well and thus suppresses ringing artifacts\n    for data that contain jumps in the phase image.\n    \"\"\"\n    if copy:\n        hologram = hologram.astype(dtype=np.float, copy=True)\n\n    if subtract_mean:\n        # remove contributions of the central band\n        # (this affects more than one pixel in the FFT\n        # because of zero-padding)\n        if issubclass(hologram.dtype.type, np.integer):\n            hologram = hologram.astype(np.float)\n        hologram -= hologram.mean()\n\n    # Fourier transform\n    fft = fourier2dpad(hologram, zero_pad=zero_pad)\n\n    if sideband in [+1, -1]:\n        fsx, fsy = find_sideband(fft, which=sideband)\n    else:\n        fsx, fsy = sideband\n\n    # shift fft to sideband location\n    shifted = np.roll(np.roll(fft, -int(fsx * fft.shape[0]), axis=0),\n                      -int(fsy * fft.shape[1]), axis=1)\n\n    # coordinates in Fourier space\n    fx = np.fft.fftshift(np.fft.fftfreq(fft.shape[0])).reshape(-1, 1)\n    fy = np.fft.fftshift(np.fft.fftfreq(fft.shape[1])).reshape(1, -1)\n\n    # filter size based on central band - sideband - distance\n    if filter_size >= 1:\n        raise ValueError(\"`filter_size` must be < 1!\")\n    fsize = np.sqrt(fsx**2 + fsy**2) * filter_size\n\n    if filter_name == \"disk\":\n        afilter = (fx**2 + fy**2) < fsize**2\n    elif filter_name == \"smooth disk\":\n        sigma = fsize / 5\n        tau = 2 * sigma**2\n        radsq = fx**2 + fy**2\n        disk = radsq < fsize**2\n        gauss = np.exp(-radsq / tau)\n        afilter = signal.convolve(gauss, disk, mode=\"same\")\n        afilter /= afilter.max()\n    elif filter_name == \"gauss\":\n        sigma = fsize * .6\n        tau = 2 * sigma**2\n        afilter = np.exp(-(fx**2 + fy**2) / tau)\n        afilter /= afilter.max()\n    elif filter_name == \"square\":\n        afilter = (np.abs(fx) < fsize) * (np.abs(fy) < fsize)\n    elif filter_name == \"smooth square\":\n        blur = fsize / 5\n        tau = 2 * blur**2\n        square = (np.abs(fx) < fsize) * (np.abs(fy) < fsize)\n        gauss = np.exp(-(fy**2) / tau) * np.exp(-(fy**2) / tau)\n        afilter = signal.convolve(square, gauss, mode=\"same\")\n        afilter /= afilter.max()\n    elif filter_name == \"tukey\":\n        alpha = 0.1\n        rsize = np.int(min(fx.size, fy.size)*fsize) * 2\n        tukey_window_x = signal.tukey(rsize, alpha=alpha).reshape(-1, 1)\n        tukey_window_y = signal.tukey(rsize, alpha=alpha).reshape(1, -1)\n        tukey = tukey_window_x * tukey_window_y\n        afilter = np.zeros(shifted.shape)\n        s1 = (np.array(shifted.shape) - rsize)//2\n        s2 = (np.array(shifted.shape) + rsize)//2\n        afilter[s1[0]:s2[0], s1[1]:s2[1]] = tukey\n    else:\n        raise ValueError(\"Unknown filter: {}\".format(filter_name))\n\n    # apply filter\n    fft_filt = afilter * shifted\n\n    # inverse Fourier transform\n    field = np.fft.ifft2(np.fft.ifftshift(fft_filt))\n    return field[:hologram.shape[0], :hologram.shape[1]]", "response": "Compute the complex field from a real - valued 2d array containing the data of the central band and the sideband."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copyh5(inh5, outh5):\n    if not isinstance(inh5, h5py.Group):\n        inh5 = h5py.File(inh5, mode=\"r\")\n    if outh5 is None:\n        # create file in memory\n        h5kwargs = {\"name\": \"qpimage{}.h5\".format(QPImage._instances),\n                    \"driver\": \"core\",\n                    \"backing_store\": False,\n                    \"mode\": \"a\"}\n        outh5 = h5py.File(**h5kwargs)\n        return_h5obj = True\n        QPImage._instances += 1\n    elif not isinstance(outh5, h5py.Group):\n        # create new file\n        outh5 = h5py.File(outh5, mode=\"w\")\n        return_h5obj = False\n    else:\n        return_h5obj = True\n    # begin iteration\n    for key in inh5:\n        if key in outh5:\n            del outh5[key]\n        if isinstance(inh5[key], h5py.Group):\n            outh5.create_group(key)\n            copyh5(inh5[key], outh5[key])\n        else:\n            dset = write_image_dataset(group=outh5,\n                                       key=key,\n                                       data=inh5[key][:],\n                                       h5dtype=inh5[key].dtype)\n            dset.attrs.update(inh5[key].attrs)\n    outh5.attrs.update(inh5.attrs)\n    if return_h5obj:\n        # in-memory or previously created instance of h5py.File\n        return outh5\n    else:\n        # properly close the file and return its name\n        fn = outh5.filename\n        outh5.flush()\n        outh5.close()\n        return fn", "response": "Recursively copy all hdf5 data from one group to another."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert which data to string or tuple", "response": "def _conv_which_data(which_data):\n        \"\"\"Convert which data to string or tuple\n\n        This function improves user convenience,\n        as `which_data` may be of several types\n        (str, ,str with spaces and commas, list, tuple) which\n        is internally handled by this method.\n        \"\"\"\n        if isinstance(which_data, str):\n            which_data = which_data.lower().strip()\n            if which_data.count(\",\"):\n                # convert comma string to list\n                which_data = [w.strip() for w in which_data.split(\",\")]\n                # remove empty strings\n                which_data = [w for w in which_data if w]\n                if len(which_data) == 1:\n                    return which_data[0]\n                else:\n                    # convert to tuple\n                    return tuple(which_data)\n            else:\n                return which_data\n        elif isinstance(which_data, (list, tuple)):\n            which_data = [w.lower().strip() for w in which_data]\n            return tuple(which_data)\n        elif which_data is None:\n            return None\n        else:\n            msg = \"unknown type for `which_data`: {}\".format(which_data)\n            raise ValueError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_amp_pha(self, data, which_data):\n        which_data = QPImage._conv_which_data(which_data)\n        if which_data not in VALID_INPUT_DATA:\n            msg = \"`which_data` must be one of {}!\".format(VALID_INPUT_DATA)\n            raise ValueError(msg)\n\n        if which_data == \"field\":\n            amp = np.abs(data)\n            pha = np.angle(data)\n        elif which_data == \"phase\":\n            pha = data\n            amp = np.ones_like(data)\n        elif which_data == (\"phase\", \"amplitude\"):\n            amp = data[1]\n            pha = data[0]\n        elif which_data == (\"phase\", \"intensity\"):\n            amp = np.sqrt(data[1])\n            pha = data[0]\n        elif which_data == \"hologram\":\n            amp, pha = self._get_amp_pha(holo.get_field(data, **self.holo_kw),\n                                         which_data=\"field\")\n        if amp.size == 0 or pha.size == 0:\n            msg = \"`data` with shape {} has zero size!\".format(amp.shape)\n            raise ValueError(msg)\n        # phase unwrapping (take into account nans)\n        nanmask = np.isnan(pha)\n        if np.sum(nanmask):\n            # create masked array\n            # skimage.restoration.unwrap_phase cannot handle nan data\n            # (even if masked)\n            pham = pha.copy()\n            pham[nanmask] = 0\n            pham = np.ma.masked_array(pham, mask=nanmask)\n            pha = unwrap_phase(pham, seed=47)\n            pha[nanmask] = np.nan\n        else:\n            pha = unwrap_phase(pha, seed=47)\n\n        return amp, pha", "response": "Convert input data to phase and amplitude."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists of tuples with QPImage meta data", "response": "def info(self):\n        \"\"\"list of tuples with QPImage meta data\"\"\"\n        info = []\n        # meta data\n        meta = self.meta\n        for key in meta:\n            info.append((key, self.meta[key]))\n        # background correction\n        for imdat in [self._amp, self._pha]:\n            info += imdat.info\n        return info"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclear the background correction of the current object.", "response": "def clear_bg(self, which_data=(\"amplitude\", \"phase\"), keys=\"fit\"):\n        \"\"\"Clear background correction\n\n        Parameters\n        ----------\n        which_data: str or list of str\n            From which type of data to remove the background\n            information. The list contains either \"amplitude\",\n            \"phase\", or both.\n        keys: str or list of str\n            Which type of background data to remove. One of:\n\n            - \"fit\": the background data computed with\n              :func:`qpimage.QPImage.compute_bg`\n            - \"data\": the experimentally obtained background image\n        \"\"\"\n        which_data = QPImage._conv_which_data(which_data)\n        if isinstance(keys, str):\n            # make sure keys is a list of strings\n            keys = [keys]\n\n        # Get image data for clearing\n        imdats = []\n        if \"amplitude\" in which_data:\n            imdats.append(self._amp)\n        if \"phase\" in which_data:\n            imdats.append(self._pha)\n        if not imdats:\n            msg = \"`which_data` must contain 'phase' or 'amplitude'!\"\n            raise ValueError(msg)\n        # Perform clearing of backgrounds\n        for imdat in imdats:\n            for key in keys:\n                imdat.del_bg(key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes background correction of the base image of the base image.", "response": "def compute_bg(self, which_data=\"phase\",\n                   fit_offset=\"mean\", fit_profile=\"tilt\",\n                   border_m=0, border_perc=0, border_px=0,\n                   from_mask=None, ret_mask=False):\n        \"\"\"Compute background correction\n\n        Parameters\n        ----------\n        which_data: str or list of str\n            From which type of data to remove the background\n            information. The list contains either \"amplitude\",\n            \"phase\", or both.\n        fit_profile: str\n            The type of background profile to fit:\n\n            - \"offset\": offset only\n            - \"poly2o\": 2D 2nd order polynomial with mixed terms\n            - \"tilt\": 2D linear tilt with offset (default)\n        fit_offset: str\n            The method for computing the profile offset\n\n            - \"fit\": offset as fitting parameter\n            - \"gauss\": center of a gaussian fit\n            - \"mean\": simple average\n            - \"mode\": mode (see `qpimage.bg_estimate.mode`)\n        border_m: float\n            Assume that a frame of `border_m` meters around the\n            image is background. The value is converted to\n            pixels and rounded.\n        border_perc: float\n            Assume that a frame of `border_perc` percent around\n            the image is background. The value is converted to\n            pixels and rounded. If the aspect ratio of the image\n            is not one, then the average of the data's shape is\n            used to compute the percentage in pixels.\n        border_px: float\n            Assume that a frame of `border_px` pixels around\n            the image is background.\n        from_mask: boolean np.ndarray or None\n            Use a boolean array to define the background area.\n            The boolean mask must have the same shape as the\n            input data. `True` elements are used for background\n            estimation.\n        ret_mask: bool\n            Return the boolean mask used to compute the background.\n\n        Notes\n        -----\n        The `border_*` values are translated to pixel values and\n        the largest pixel border is used to generate a mask\n        image for background computation.\n\n        If any of the `border_*` arguments are non-zero and\n        `from_mask` is given, the intersection of the two\n        is used, i.e. the positions where both, the frame\n        mask and `from_mask`, are `True`.\n\n        See Also\n        --------\n        qpimage.bg_estimate.estimate\n        \"\"\"\n        which_data = QPImage._conv_which_data(which_data)\n        # check validity\n        if not (\"amplitude\" in which_data or\n                \"phase\" in which_data):\n            msg = \"`which_data` must contain 'phase' or 'amplitude'!\"\n            raise ValueError(msg)\n        # get border in px\n        border_list = []\n        if border_m:\n            if border_m < 0:\n                raise ValueError(\"`border_m` must be greater than zero!\")\n            border_list.append(border_m / self.meta[\"pixel size\"])\n        if border_perc:\n            if border_perc < 0 or border_perc > 50:\n                raise ValueError(\"`border_perc` must be in interval [0, 50]!\")\n            size = np.average(self.shape)\n            border_list.append(size * border_perc / 100)\n        if border_px:\n            border_list.append(border_px)\n        # get maximum border size\n        if border_list:\n            border_px = np.int(np.round(np.max(border_list)))\n        elif from_mask is None:\n            raise ValueError(\"Neither `from_mask` nor `border_*` given!\")\n        elif np.all(from_mask == 0):\n            raise ValueError(\"`from_mask` must not be all-zero!\")\n        # Get affected image data\n        imdat_list = []\n        if \"amplitude\" in which_data:\n            imdat_list.append(self._amp)\n        if \"phase\" in which_data:\n            imdat_list.append(self._pha)\n        # Perform correction\n        for imdat in imdat_list:\n            mask = imdat.estimate_bg(fit_offset=fit_offset,\n                                     fit_profile=fit_profile,\n                                     border_px=border_px,\n                                     from_mask=from_mask,\n                                     ret_mask=ret_mask)\n        return mask"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copy(self, h5file=None):\n        h5 = copyh5(self.h5, h5file)\n        return QPImage(h5file=h5, h5dtype=self.h5dtype)", "response": "Create a copy of the current instance of the QPImage."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef refocus(self, distance, method=\"helmholtz\", h5file=None, h5mode=\"a\"):\n        field2 = nrefocus.refocus(field=self.field,\n                                  d=distance/self[\"pixel size\"],\n                                  nm=self[\"medium index\"],\n                                  res=self[\"wavelength\"]/self[\"pixel size\"],\n                                  method=method\n                                  )\n        if \"identifier\" in self:\n            ident = self[\"identifier\"]\n        else:\n            ident = \"\"\n        meta_data = self.meta\n        meta_data[\"identifier\"] = \"{}@{}{:.5e}m\".format(ident,\n                                                        method[0],\n                                                        distance)\n        qpi2 = QPImage(data=field2,\n                       which_data=\"field\",\n                       meta_data=meta_data,\n                       h5file=h5file,\n                       h5mode=h5mode)\n        return qpi2", "response": "Compute a numerically refocused QPImage."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the background amplitude and phase data for the current object.", "response": "def set_bg_data(self, bg_data, which_data=None):\n        \"\"\"Set background amplitude and phase data\n\n        Parameters\n        ----------\n        bg_data: 2d ndarray (float or complex), list, QPImage, or `None`\n            The background data (must be same type as `data`).\n            If set to `None`, the background data is reset.\n        which_data: str\n            String or comma-separated list of strings indicating\n            the order and type of input data. Valid values are\n            \"field\", \"phase\", \"phase,amplitude\", or \"phase,intensity\",\n            where the latter two require an indexable object for\n            `bg_data` with the phase data as first element.\n        \"\"\"\n        if isinstance(bg_data, QPImage):\n            if which_data is not None:\n                msg = \"`which_data` must not be set if `bg_data` is QPImage!\"\n                raise ValueError(msg)\n            pha, amp = bg_data.pha, bg_data.amp\n        elif bg_data is None:\n            # Reset phase and amplitude\n            amp, pha = None, None\n        else:\n            # Compute phase and amplitude from data and which_data\n            amp, pha = self._get_amp_pha(bg_data, which_data)\n        # Set background data\n        self._amp.set_bg(amp, key=\"data\")\n        self._pha.set_bg(pha, key=\"data\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a QPImage instance to the series.", "response": "def add_qpimage(self, qpi, identifier=None, bg_from_idx=None):\n        \"\"\"Add a QPImage instance to the QPSeries\n\n        Parameters\n        ----------\n        qpi: qpimage.QPImage\n            The QPImage that is added to the series\n        identifier: str\n            Identifier key for `qpi`\n        bg_from_idx: int or None\n            Use the background data from the data stored in this index,\n            creating hard links within the hdf5 file.\n            (Saves memory if e.g. all qpimages is corrected with the same data)\n        \"\"\"\n        if not isinstance(qpi, QPImage):\n            raise ValueError(\"`fli` must be instance of QPImage!\")\n        if \"identifier\" in qpi and identifier is None:\n            identifier = qpi[\"identifier\"]\n        if identifier and identifier in self:\n            msg = \"The identifier '{}' already \".format(identifier) \\\n                  + \"exists! You can either change the identifier of \" \\\n                  + \" '{}' or remove it.\".format(qpi)\n            raise ValueError(msg)\n        # determine number of qpimages\n        num = len(self)\n        # indices start at zero; do not add 1\n        name = \"qpi_{}\".format(num)\n        group = self.h5.create_group(name)\n        thisqpi = qpi.copy(h5file=group)\n\n        if bg_from_idx is not None:\n            # Create hard links\n            refqpi = self[bg_from_idx]\n            thisqpi._amp.set_bg(bg=refqpi._amp.h5[\"bg_data\"][\"data\"])\n            thisqpi._pha.set_bg(bg=refqpi._pha.h5[\"bg_data\"][\"data\"])\n\n        if identifier:\n            # set identifier\n            group.attrs[\"identifier\"] = identifier"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a single QPImage of the series with the given index.", "response": "def get_qpimage(self, index):\n        \"\"\"Return a single QPImage of the series\n\n        Parameters\n        ----------\n        index: int or str\n            Index or identifier of the QPImage\n\n        Notes\n        -----\n        Instead of ``qps.get_qpimage(index)``, it is possible\n        to use the short-hand ``qps[index]``.\n        \"\"\"\n        if isinstance(index, str):\n            # search for the identifier\n            for ii in range(len(self)):\n                qpi = self[ii]\n                if \"identifier\" in qpi and qpi[\"identifier\"] == index:\n                    group = self.h5[\"qpi_{}\".format(ii)]\n                    break\n            else:\n                msg = \"QPImage identifier '{}' not found!\".format(index)\n                raise KeyError(msg)\n        else:\n            # integer index\n            if index < -len(self):\n                msg = \"Index {} out of bounds for QPSeries of size {}!\".format(\n                    index, len(self))\n                raise ValueError(msg)\n            elif index < 0:\n                index += len(self)\n            name = \"qpi_{}\".format(index)\n            if name in self.h5:\n                group = self.h5[name]\n            else:\n                msg = \"Index {} not found for QPSeries of length {}\".format(\n                    index, len(self))\n                raise KeyError(msg)\n        return QPImage(h5file=group)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _collapse_invariants(bases: List[type], namespace: MutableMapping[str, Any]) -> None:\n    invariants = []  # type: List[Contract]\n\n    # Add invariants of the bases\n    for base in bases:\n        if hasattr(base, \"__invariants__\"):\n            invariants.extend(getattr(base, \"__invariants__\"))\n\n    # Add invariants in the current namespace\n    if '__invariants__' in namespace:\n        invariants.extend(namespace['__invariants__'])\n\n    # Change the final invariants in the namespace\n    if invariants:\n        namespace[\"__invariants__\"] = invariants", "response": "Collect invariants from the bases and merge them with the invariants in the namespace."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncollapses function preconditions with the preconditions collected from the base classes.", "response": "def _collapse_preconditions(base_preconditions: List[List[Contract]], bases_have_func: bool,\n                            preconditions: List[List[Contract]], func: Callable[..., Any]) -> List[List[Contract]]:\n    \"\"\"\n    Collapse function preconditions with the preconditions collected from the base classes.\n\n    :param base_preconditions: preconditions collected from the base classes (grouped by base class)\n    :param bases_have_func: True if one of the base classes has the function\n    :param preconditions: preconditions of the function (before the collapse)\n    :param func: function whose preconditions we are collapsing\n    :return: collapsed sequence of precondition groups\n    \"\"\"\n    if not base_preconditions and bases_have_func and preconditions:\n        raise TypeError((\"The function {} can not weaken the preconditions because the bases specify \"\n                         \"no preconditions at all. Hence this function must accept all possible input since \"\n                         \"the preconditions are OR'ed and no precondition implies a dummy precondition which is always \"\n                         \"fulfilled.\").format(func.__qualname__))\n\n    return base_preconditions + preconditions"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncollapsing snapshots of pre - invocation values with the snapshots collected from the base classes.", "response": "def _collapse_snapshots(base_snapshots: List[Snapshot], snapshots: List[Snapshot]) -> List[Snapshot]:\n    \"\"\"\n    Collapse snapshots of pre-invocation values with the snapshots collected from the base classes.\n\n    :param base_snapshots: snapshots collected from the base classes\n    :param snapshots: snapshots of the function (before the collapse)\n    :return: collapsed sequence of snapshots\n    \"\"\"\n    seen_names = set()  # type: Set[str]\n    collapsed = base_snapshots + snapshots\n\n    for snap in collapsed:\n        if snap.name in seen_names:\n            raise ValueError(\"There are conflicting snapshots with the name: {!r}.\\n\\n\"\n                             \"Please mind that the snapshots are inherited from the base classes. \"\n                             \"Does one of the base classes defines a snapshot with the same name?\".format(snap.name))\n\n        seen_names.add(snap.name)\n\n    return collapsed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _collapse_postconditions(base_postconditions: List[Contract], postconditions: List[Contract]) -> List[Contract]:\n    return base_postconditions + postconditions", "response": "Collapse function postconditions with the postconditions collected from the base classes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _decorate_namespace_function(bases: List[type], namespace: MutableMapping[str, Any], key: str) -> None:\n    # pylint: disable=too-many-branches\n    # pylint: disable=too-many-locals\n\n    value = namespace[key]\n    assert inspect.isfunction(value) or isinstance(value, (staticmethod, classmethod))\n\n    # Determine the function to be decorated\n    if inspect.isfunction(value):\n        func = value\n    elif isinstance(value, (staticmethod, classmethod)):\n        func = value.__func__\n    else:\n        raise NotImplementedError(\"Unexpected value for a function: {}\".format(value))\n\n    # Collect preconditions and postconditions of the function\n    preconditions = []  # type: List[List[Contract]]\n    snapshots = []  # type: List[Snapshot]\n    postconditions = []  # type: List[Contract]\n\n    contract_checker = icontract._checkers.find_checker(func=func)\n    if contract_checker is not None:\n        preconditions = contract_checker.__preconditions__  # type: ignore\n        snapshots = contract_checker.__postcondition_snapshots__  # type: ignore\n        postconditions = contract_checker.__postconditions__  # type: ignore\n\n    # Collect the preconditions and postconditions from bases.\n    #\n    # Preconditions and postconditions of __init__ of base classes are deliberately ignored (and not collapsed) since\n    # initialization is an operation specific to the concrete class and does not relate to the class hierarchy.\n    if key not in ['__init__']:\n        base_preconditions = []  # type: List[List[Contract]]\n        base_snapshots = []  # type: List[Snapshot]\n        base_postconditions = []  # type: List[Contract]\n\n        bases_have_func = False\n        for base in bases:\n            if hasattr(base, key):\n                bases_have_func = True\n\n                # Check if there is a checker function in the base class\n                base_func = getattr(base, key)\n                base_contract_checker = icontract._checkers.find_checker(func=base_func)\n\n                # Ignore functions which don't have preconditions or postconditions\n                if base_contract_checker is not None:\n                    base_preconditions.extend(base_contract_checker.__preconditions__)  # type: ignore\n                    base_snapshots.extend(base_contract_checker.__postcondition_snapshots__)  # type: ignore\n                    base_postconditions.extend(base_contract_checker.__postconditions__)  # type: ignore\n\n        # Collapse preconditions and postconditions from the bases with the the function's own ones\n        preconditions = _collapse_preconditions(\n            base_preconditions=base_preconditions,\n            bases_have_func=bases_have_func,\n            preconditions=preconditions,\n            func=func)\n\n        snapshots = _collapse_snapshots(base_snapshots=base_snapshots, snapshots=snapshots)\n\n        postconditions = _collapse_postconditions(\n            base_postconditions=base_postconditions, postconditions=postconditions)\n\n    if preconditions or postconditions:\n        if contract_checker is None:\n            contract_checker = icontract._checkers.decorate_with_checker(func=func)\n\n            # Replace the function with the function decorated with contract checks\n            if inspect.isfunction(value):\n                namespace[key] = contract_checker\n            elif isinstance(value, staticmethod):\n                namespace[key] = staticmethod(contract_checker)\n\n            elif isinstance(value, classmethod):\n                namespace[key] = classmethod(contract_checker)\n\n            else:\n                raise NotImplementedError(\"Unexpected value for a function: {}\".format(value))\n\n        # Override the preconditions and postconditions\n        contract_checker.__preconditions__ = preconditions  # type: ignore\n        contract_checker.__postcondition_snapshots__ = snapshots  # type: ignore\n        contract_checker.__postconditions__ = postconditions", "response": "Decorate the function at the key in the base class and the base class."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecorates a property in a namespace by iterating over all base classes and checking if they are present.", "response": "def _decorate_namespace_property(bases: List[type], namespace: MutableMapping[str, Any], key: str) -> None:\n    \"\"\"Collect contracts for all getters/setters/deleters corresponding to ``key`` and decorate them.\"\"\"\n    # pylint: disable=too-many-locals\n    # pylint: disable=too-many-branches\n    # pylint: disable=too-many-statements\n\n    value = namespace[key]\n    assert isinstance(value, property)\n\n    fget = value.fget  # type: Optional[Callable[..., Any]]\n    fset = value.fset  # type: Optional[Callable[..., Any]]\n    fdel = value.fdel  # type: Optional[Callable[..., Any]]\n\n    for func in [value.fget, value.fset, value.fdel]:\n        func = cast(Callable[..., Any], func)\n\n        if func is None:\n            continue\n\n        # Collect the preconditions and postconditions from bases\n        base_preconditions = []  # type: List[List[Contract]]\n        base_snapshots = []  # type: List[Snapshot]\n        base_postconditions = []  # type: List[Contract]\n\n        bases_have_func = False\n        for base in bases:\n            if hasattr(base, key):\n                base_property = getattr(base, key)\n                assert isinstance(base_property, property), \\\n                    \"Expected base {} to have {} as property, but got: {}\".format(base, key, base_property)\n\n                if func == value.fget:\n                    base_func = getattr(base, key).fget\n                elif func == value.fset:\n                    base_func = getattr(base, key).fset\n                elif func == value.fdel:\n                    base_func = getattr(base, key).fdel\n                else:\n                    raise NotImplementedError(\"Unhandled case: func neither value.fget, value.fset nor value.fdel\")\n\n                if base_func is None:\n                    continue\n\n                bases_have_func = True\n\n                # Check if there is a checker function in the base class\n                base_contract_checker = icontract._checkers.find_checker(func=base_func)\n\n                # Ignore functions which don't have preconditions or postconditions\n                if base_contract_checker is not None:\n                    base_preconditions.extend(base_contract_checker.__preconditions__)  # type: ignore\n                    base_snapshots.extend(base_contract_checker.__postcondition_snapshots__)  # type: ignore\n                    base_postconditions.extend(base_contract_checker.__postconditions__)  # type: ignore\n\n        # Add preconditions and postconditions of the function\n        preconditions = []  # type: List[List[Contract]]\n        snapshots = []  # type: List[Snapshot]\n        postconditions = []  # type: List[Contract]\n\n        contract_checker = icontract._checkers.find_checker(func=func)\n        if contract_checker is not None:\n            preconditions = contract_checker.__preconditions__  # type: ignore\n            snapshots = contract_checker.__postcondition_snapshots__\n            postconditions = contract_checker.__postconditions__  # type: ignore\n\n        preconditions = _collapse_preconditions(\n            base_preconditions=base_preconditions,\n            bases_have_func=bases_have_func,\n            preconditions=preconditions,\n            func=func)\n\n        snapshots = _collapse_snapshots(base_snapshots=base_snapshots, snapshots=snapshots)\n\n        postconditions = _collapse_postconditions(\n            base_postconditions=base_postconditions, postconditions=postconditions)\n\n        if preconditions or postconditions:\n            if contract_checker is None:\n                contract_checker = icontract._checkers.decorate_with_checker(func=func)\n\n                # Replace the function with the function decorated with contract checks\n                if func == value.fget:\n                    fget = contract_checker\n                elif func == value.fset:\n                    fset = contract_checker\n                elif func == value.fdel:\n                    fdel = contract_checker\n                else:\n                    raise NotImplementedError(\"Unhandled case: func neither fget, fset nor fdel\")\n\n            # Override the preconditions and postconditions\n            contract_checker.__preconditions__ = preconditions  # type: ignore\n            contract_checker.__postcondition_snapshots__ = snapshots  # type: ignore\n            contract_checker.__postconditions__ = postconditions  # type: ignore\n\n    if fget != value.fget or fset != value.fset or fdel != value.fdel:\n        namespace[key] = property(fget=fget, fset=fset, fdel=fdel)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _dbc_decorate_namespace(bases: List[type], namespace: MutableMapping[str, Any]) -> None:\n    _collapse_invariants(bases=bases, namespace=namespace)\n\n    for key, value in namespace.items():\n        if inspect.isfunction(value) or isinstance(value, (staticmethod, classmethod)):\n            _decorate_namespace_function(bases=bases, namespace=namespace, key=key)\n\n        elif isinstance(value, property):\n            _decorate_namespace_property(bases=bases, namespace=namespace, key=key)\n\n        else:\n            # Ignore the value which is neither a function nor a property\n            pass", "response": "Decorate all methods in the namespace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck whether the value is representable in the error message on contract breach.", "response": "def _representable(value: Any) -> bool:\n    \"\"\"\n    Check whether we want to represent the value in the error message on contract breach.\n\n    We do not want to represent classes, methods, modules and functions.\n\n    :param value: value related to an AST node\n    :return: True if we want to represent it in the violation error\n    \"\"\"\n    return not inspect.isclass(value) and not inspect.isfunction(value) and not inspect.ismethod(value) and not \\\n        inspect.ismodule(value) and not inspect.isbuiltin(value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inspect_decorator(lines: List[str], lineno: int, filename: str) -> DecoratorInspection:\n    if lineno < 0 or lineno >= len(lines):\n        raise ValueError((\"Given line number {} of one of the decorator lines \"\n                          \"is not within the range [{}, {}) of lines in {}\").format(lineno, 0, len(lines), filename))\n\n    # Go up till a line starts with a decorator\n    decorator_lineno = None  # type: Optional[int]\n    for i in range(lineno, -1, -1):\n        if _DECORATOR_RE.match(lines[i]):\n            decorator_lineno = i\n            break\n\n    if decorator_lineno is None:\n        raise SyntaxError(\"Decorator corresponding to the line {} could not be found in file {}: {!r}\".format(\n            lineno + 1, filename, lines[lineno]))\n\n    # Find the decorator end -- it's either a function definition, a class definition or another decorator\n    decorator_end_lineno = None  # type: Optional[int]\n    for i in range(lineno + 1, len(lines)):\n        line = lines[i]\n\n        if _DECORATOR_RE.match(line) or _DEF_CLASS_RE.match(line):\n            decorator_end_lineno = i\n            break\n\n    if decorator_end_lineno is None:\n        raise SyntaxError((\"The next statement following the decorator corresponding to the line {} \"\n                           \"could not be found in file {}: {!r}\").format(lineno + 1, filename, lines[lineno]))\n\n    decorator_lines = lines[decorator_lineno:decorator_end_lineno]\n\n    # We need to dedent the decorator and add a dummy decoratee so that we can parse its text as valid source code.\n    decorator_text = textwrap.dedent(\"\".join(decorator_lines)) + \"def dummy_{}(): pass\".format(uuid.uuid4().hex)\n\n    atok = asttokens.ASTTokens(decorator_text, parse=True)\n\n    assert isinstance(atok.tree, ast.Module), \"Expected the parsed decorator text to live in an AST module.\"\n\n    module_node = atok.tree\n    assert len(module_node.body) == 1, \"Expected the module AST of the decorator text to have a single statement.\"\n    assert isinstance(module_node.body[0], ast.FunctionDef), \\\n        \"Expected the only statement in the AST module corresponding to the decorator text to be a function definition.\"\n\n    func_def_node = module_node.body[0]\n\n    assert len(func_def_node.decorator_list) == 1, \\\n        \"Expected the function AST node corresponding to the decorator text to have a single decorator.\"\n\n    assert isinstance(func_def_node.decorator_list[0], ast.Call), \\\n        \"Expected the only decorator in the function definition AST node corresponding to the decorator text \" \\\n        \"to be a call node.\"\n\n    call_node = func_def_node.decorator_list[0]\n\n    return DecoratorInspection(atok=atok, node=call_node)", "response": "Inspects the source code of a decorator call."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninspects the decorator and extract the condition as lambda function.", "response": "def find_lambda_condition(decorator_inspection: DecoratorInspection) -> Optional[ConditionLambdaInspection]:\n    \"\"\"\n    Inspect the decorator and extract the condition as lambda.\n\n    If the condition is not given as a lambda function, return None.\n    \"\"\"\n    call_node = decorator_inspection.node\n\n    lambda_node = None  # type: Optional[ast.Lambda]\n\n    if len(call_node.args) > 0:\n        assert isinstance(call_node.args[0], ast.Lambda), \\\n            (\"Expected the first argument to the decorator to be a condition as lambda AST node, \"\n             \"but got: {}\").format(type(call_node.args[0]))\n\n        lambda_node = call_node.args[0]\n\n    elif len(call_node.keywords) > 0:\n        for keyword in call_node.keywords:\n            if keyword.arg == \"condition\":\n                assert isinstance(keyword.value, ast.Lambda), \\\n                    \"Expected lambda node as value of the 'condition' argument to the decorator.\"\n\n                lambda_node = keyword.value\n                break\n\n        assert lambda_node is not None, \"Expected to find a keyword AST node with 'condition' arg, but found none\"\n    else:\n        raise AssertionError(\n            \"Expected a call AST node of a decorator to have either args or keywords, but got: {}\".format(\n                ast.dump(call_node)))\n\n    return ConditionLambdaInspection(atok=decorator_inspection.atok, node=lambda_node)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef repr_values(condition: Callable[..., bool], lambda_inspection: Optional[ConditionLambdaInspection],\n                condition_kwargs: Mapping[str, Any], a_repr: reprlib.Repr) -> List[str]:\n    # pylint: disable=too-many-locals\n    \"\"\"\n    Represent function arguments and frame values in the error message on contract breach.\n\n    :param condition: condition function of the contract\n    :param lambda_inspection:\n        inspected lambda AST node corresponding to the condition function (None if the condition was not given as a\n        lambda function)\n    :param condition_kwargs: condition arguments\n    :param a_repr: representation instance that defines how the values are represented.\n    :return: list of value representations\n    \"\"\"\n    if _is_lambda(a_function=condition):\n        assert lambda_inspection is not None, \"Expected a lambda inspection when given a condition as a lambda function\"\n    else:\n        assert lambda_inspection is None, \"Expected no lambda inspection in a condition given as a non-lambda function\"\n\n    reprs = dict()  # type: MutableMapping[str, Any]\n\n    if lambda_inspection is not None:\n        # Collect the variable lookup of the condition function:\n        variable_lookup = []  # type: List[Mapping[str, Any]]\n\n        # Add condition arguments to the lookup\n        variable_lookup.append(condition_kwargs)\n\n        # Add closure to the lookup\n        closure_dict = dict()  # type: Dict[str, Any]\n\n        if condition.__closure__ is not None:  # type: ignore\n            closure_cells = condition.__closure__  # type: ignore\n            freevars = condition.__code__.co_freevars\n\n            assert len(closure_cells) == len(freevars), \\\n                \"Number of closure cells of a condition function ({}) == number of free vars ({})\".format(\n                    len(closure_cells), len(freevars))\n\n            for cell, freevar in zip(closure_cells, freevars):\n                closure_dict[freevar] = cell.cell_contents\n\n        variable_lookup.append(closure_dict)\n\n        # Add globals to the lookup\n        if condition.__globals__ is not None:  # type: ignore\n            variable_lookup.append(condition.__globals__)  # type: ignore\n\n        # pylint: disable=protected-access\n        recompute_visitor = icontract._recompute.Visitor(variable_lookup=variable_lookup)\n\n        recompute_visitor.visit(node=lambda_inspection.node.body)\n        recomputed_values = recompute_visitor.recomputed_values\n\n        repr_visitor = Visitor(\n            recomputed_values=recomputed_values, variable_lookup=variable_lookup, atok=lambda_inspection.atok)\n        repr_visitor.visit(node=lambda_inspection.node.body)\n\n        reprs = repr_visitor.reprs\n    else:\n        for key, val in condition_kwargs.items():\n            if _representable(value=val):\n                reprs[key] = val\n\n    parts = []  # type: List[str]\n    for key in sorted(reprs.keys()):\n        parts.append('{} was {}'.format(key, a_repr.repr(reprs[key])))\n\n    return parts", "response": "Return a list of value representations of the given condition function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_message(contract: Contract, condition_kwargs: Mapping[str, Any]) -> str:\n    # pylint: disable=protected-access\n    parts = []  # type: List[str]\n\n    if contract.location is not None:\n        parts.append(\"{}:\\n\".format(contract.location))\n\n    if contract.description is not None:\n        parts.append(\"{}: \".format(contract.description))\n\n    lambda_inspection = None  # type: Optional[ConditionLambdaInspection]\n    if not _is_lambda(a_function=contract.condition):\n        condition_text = contract.condition.__name__\n    else:\n        # We need to extract the source code corresponding to the decorator since inspect.getsource() is broken with\n        # lambdas.\n\n        # Find the line corresponding to the condition lambda\n        lines, condition_lineno = inspect.findsource(contract.condition)\n        filename = inspect.getsourcefile(contract.condition)\n\n        decorator_inspection = inspect_decorator(lines=lines, lineno=condition_lineno, filename=filename)\n        lambda_inspection = find_lambda_condition(decorator_inspection=decorator_inspection)\n\n        assert lambda_inspection is not None, \\\n            \"Expected lambda_inspection to be non-None if _is_lambda is True on: {}\".format(contract.condition)\n\n        condition_text = lambda_inspection.text\n\n    parts.append(condition_text)\n\n    repr_vals = repr_values(\n        condition=contract.condition,\n        lambda_inspection=lambda_inspection,\n        condition_kwargs=condition_kwargs,\n        a_repr=contract._a_repr)\n\n    if len(repr_vals) == 0:\n        # Do not append anything since no value could be represented as a string.\n        # This could appear in case we have, for example, a generator expression as the return value of a lambda.\n        pass\n\n    elif len(repr_vals) == 1:\n        parts.append(': ')\n        parts.append(repr_vals[0])\n    else:\n        parts.append(':\\n')\n        parts.append('\\n'.join(repr_vals))\n\n    msg = \"\".join(parts)\n    return msg", "response": "Generate the message upon contract violation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visit_Name(self, node: ast.Name) -> None:\n        if node in self._recomputed_values:\n            value = self._recomputed_values[node]\n\n            # Check if it is a non-built-in\n            is_builtin = True\n            for lookup in self._variable_lookup:\n                if node.id in lookup:\n                    is_builtin = False\n                    break\n\n            if not is_builtin and _representable(value=value):\n                text = self._atok.get_text(node)\n                self.reprs[text] = value\n\n        self.generic_visit(node=node)", "response": "Resolve the name from the variable look - up and the built - in lookup."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef visit_Attribute(self, node: ast.Attribute) -> None:\n        if node in self._recomputed_values:\n            value = self._recomputed_values[node]\n\n            if _representable(value=value):\n                text = self._atok.get_text(node)\n                self.reprs[text] = value\n\n        self.generic_visit(node=node)", "response": "Represent the attribute by dumping its source code."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visit_Call(self, node: ast.Call) -> None:\n        if node in self._recomputed_values:\n            value = self._recomputed_values[node]\n            text = self._atok.get_text(node)\n\n            self.reprs[text] = value\n\n        self.generic_visit(node=node)", "response": "Represent the call by dumping its source code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrepresent the list comprehension by dumping its source code.", "response": "def visit_ListComp(self, node: ast.ListComp) -> None:\n        \"\"\"Represent the list comprehension by dumping its source code.\"\"\"\n        if node in self._recomputed_values:\n            value = self._recomputed_values[node]\n            text = self._atok.get_text(node)\n\n            self.reprs[text] = value\n\n        self.generic_visit(node=node)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef visit_DictComp(self, node: ast.DictComp) -> None:\n        if node in self._recomputed_values:\n            value = self._recomputed_values[node]\n            text = self._atok.get_text(node)\n\n            self.reprs[text] = value\n\n        self.generic_visit(node=node)", "response": "Represent the dictionary comprehension by dumping its source code."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _walk_decorator_stack(func: CallableT) -> Iterable['CallableT']:\n    while hasattr(func, \"__wrapped__\"):\n        yield func\n\n        func = getattr(func, \"__wrapped__\")\n\n    yield func", "response": "Iterate through the stack of decorated functions until the original function is decorated."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_checker(func: CallableT) -> Optional[CallableT]:\n    contract_checker = None  # type: Optional[CallableT]\n    for a_wrapper in _walk_decorator_stack(func):\n        if hasattr(a_wrapper, \"__preconditions__\") or hasattr(a_wrapper, \"__postconditions__\"):\n            contract_checker = a_wrapper\n\n    return contract_checker", "response": "Iterate through the decorator stack till we find the contract checker."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninspecting the input values received at the wrapper for the actual function call.", "response": "def _kwargs_from_call(param_names: List[str], kwdefaults: Dict[str, Any], args: Tuple[Any, ...],\n                      kwargs: Dict[str, Any]) -> MutableMapping[str, Any]:\n    \"\"\"\n    Inspect the input values received at the wrapper for the actual function call.\n\n    :param param_names: parameter (*i.e.* argument) names of the original (decorated) function\n    :param kwdefaults: default argument values of the original function\n    :param args: arguments supplied to the call\n    :param kwargs: keyword arguments supplied to the call\n    :return: resolved arguments as they would be passed to the function\n    \"\"\"\n    # pylint: disable=too-many-arguments\n    mapping = dict()  # type: MutableMapping[str, Any]\n\n    # Set the default argument values as condition parameters.\n    for param_name, param_value in kwdefaults.items():\n        mapping[param_name] = param_value\n\n    # Override the defaults with the values actually suplied to the function.\n    for i, func_arg in enumerate(args):\n        mapping[param_names[i]] = func_arg\n\n    for key, val in kwargs.items():\n        mapping[key] = val\n\n    return mapping"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _assert_precondition(contract: Contract, resolved_kwargs: Mapping[str, Any]) -> None:\n    # Check that all arguments to the condition function have been set.\n    missing_args = [arg_name for arg_name in contract.condition_args if arg_name not in resolved_kwargs]\n    if missing_args:\n        raise TypeError(\n            (\"The argument(s) of the precondition have not been set: {}. \"\n             \"Does the original function define them? Did you supply them in the call?\").format(missing_args))\n\n    condition_kwargs = {\n        arg_name: value\n        for arg_name, value in resolved_kwargs.items() if arg_name in contract.condition_arg_set\n    }\n\n    check = contract.condition(**condition_kwargs)\n\n    if not check:\n        if contract.error is not None and (inspect.ismethod(contract.error) or inspect.isfunction(contract.error)):\n            assert contract.error_arg_set is not None, \"Expected error_arg_set non-None if contract.error a function.\"\n            assert contract.error_args is not None, \"Expected error_args non-None if contract.error a function.\"\n\n            error_kwargs = {\n                arg_name: value\n                for arg_name, value in resolved_kwargs.items() if arg_name in contract.error_arg_set\n            }\n\n            missing_args = [arg_name for arg_name in contract.error_args if arg_name not in resolved_kwargs]\n            if missing_args:\n                msg_parts = []  # type: List[str]\n                if contract.location is not None:\n                    msg_parts.append(\"{}:\\n\".format(contract.location))\n\n                msg_parts.append(\n                    (\"The argument(s) of the precondition error have not been set: {}. \"\n                     \"Does the original function define them? Did you supply them in the call?\").format(missing_args))\n\n                raise TypeError(''.join(msg_parts))\n\n            raise contract.error(**error_kwargs)\n\n        else:\n            msg = icontract._represent.generate_message(contract=contract, condition_kwargs=condition_kwargs)\n            if contract.error is None:\n                raise ViolationError(msg)\n            elif isinstance(contract.error, type):\n                raise contract.error(msg)", "response": "Assert that the contract holds as a precondition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _assert_invariant(contract: Contract, instance: Any) -> None:\n    if 'self' in contract.condition_arg_set:\n        check = contract.condition(self=instance)\n    else:\n        check = contract.condition()\n\n    if not check:\n        if contract.error is not None and (inspect.ismethod(contract.error) or inspect.isfunction(contract.error)):\n            assert contract.error_arg_set is not None, \"Expected error_arg_set non-None if contract.error a function.\"\n            assert contract.error_args is not None, \"Expected error_args non-None if contract.error a function.\"\n\n            if 'self' in contract.error_arg_set:\n                raise contract.error(self=instance)\n            else:\n                raise contract.error()\n        else:\n            if 'self' in contract.condition_arg_set:\n                msg = icontract._represent.generate_message(contract=contract, condition_kwargs={\"self\": instance})\n            else:\n                msg = icontract._represent.generate_message(contract=contract, condition_kwargs=dict())\n\n            if contract.error is None:\n                raise ViolationError(msg)\n            elif isinstance(contract.error, type):\n                raise contract.error(msg)\n            else:\n                raise NotImplementedError(\"Unhandled contract.error: {}\".format(contract.error))", "response": "Assert that the contract holds as a class invariant given the instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncaptures the snapshot from the keyword arguments resolved before the function call.", "response": "def _capture_snapshot(a_snapshot: Snapshot, resolved_kwargs: Mapping[str, Any]) -> Any:\n    \"\"\"\n    Capture the snapshot from the keyword arguments resolved before the function call (including the default values).\n\n    :param a_snapshot: snapshot to be captured\n    :param resolved_kwargs: resolved keyword arguments (including the default values)\n    :return: captured value\n    \"\"\"\n    if a_snapshot.arg is not None:\n        if a_snapshot.arg not in resolved_kwargs:\n            raise TypeError((\"The argument of the snapshot has not been set: {}. \"\n                             \"Does the original function define it? Did you supply it in the call?\").format(\n                                 a_snapshot.arg))\n\n        value = a_snapshot.capture(**{a_snapshot.arg: resolved_kwargs[a_snapshot.arg]})\n    else:\n        value = a_snapshot.capture()\n\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecorates the function with a checker that verifies the preconditions and postconditions.", "response": "def decorate_with_checker(func: CallableT) -> CallableT:\n    \"\"\"Decorate the function with a checker that verifies the preconditions and postconditions.\"\"\"\n    assert not hasattr(func, \"__preconditions__\"), \\\n        \"Expected func to have no list of preconditions (there should be only a single contract checker per function).\"\n\n    assert not hasattr(func, \"__postconditions__\"), \\\n        \"Expected func to have no list of postconditions (there should be only a single contract checker per function).\"\n\n    assert not hasattr(func, \"__postcondition_snapshots__\"), \\\n        \"Expected func to have no list of postcondition snapshots (there should be only a single contract checker \" \\\n        \"per function).\"\n\n    sign = inspect.signature(func)\n    param_names = list(sign.parameters.keys())\n\n    # Determine the default argument values.\n    kwdefaults = dict()  # type: Dict[str, Any]\n\n    # Add to the defaults all the values that are needed by the contracts.\n    for param in sign.parameters.values():\n        if param.default != inspect.Parameter.empty:\n            kwdefaults[param.name] = param.default\n\n    def wrapper(*args, **kwargs):\n        \"\"\"Wrap func by checking the preconditions and postconditions.\"\"\"\n        preconditions = getattr(wrapper, \"__preconditions__\")  # type: List[List[Contract]]\n        snapshots = getattr(wrapper, \"__postcondition_snapshots__\")  # type: List[Snapshot]\n        postconditions = getattr(wrapper, \"__postconditions__\")  # type: List[Contract]\n\n        resolved_kwargs = _kwargs_from_call(param_names=param_names, kwdefaults=kwdefaults, args=args, kwargs=kwargs)\n\n        if postconditions:\n            if 'result' in resolved_kwargs:\n                raise TypeError(\"Unexpected argument 'result' in a function decorated with postconditions.\")\n\n            if 'OLD' in resolved_kwargs:\n                raise TypeError(\"Unexpected argument 'OLD' in a function decorated with postconditions.\")\n\n        # Assert the preconditions in groups. This is necessary to implement \"require else\" logic when a class\n        # weakens the preconditions of its base class.\n        violation_err = None  # type: Optional[ViolationError]\n        for group in preconditions:\n            violation_err = None\n            try:\n                for contract in group:\n                    _assert_precondition(contract=contract, resolved_kwargs=resolved_kwargs)\n                break\n            except ViolationError as err:\n                violation_err = err\n\n        if violation_err is not None:\n            raise violation_err  # pylint: disable=raising-bad-type\n\n        # Capture the snapshots\n        if postconditions:\n            old_as_mapping = dict()  # type: MutableMapping[str, Any]\n            for snap in snapshots:\n                # This assert is just a last defense.\n                # Conflicting snapshot names should have been caught before, either during the decoration or\n                # in the meta-class.\n                assert snap.name not in old_as_mapping, \"Snapshots with the conflicting name: {}\"\n                old_as_mapping[snap.name] = _capture_snapshot(a_snapshot=snap, resolved_kwargs=resolved_kwargs)\n\n            resolved_kwargs['OLD'] = _Old(mapping=old_as_mapping)\n\n        # Execute the wrapped function\n        result = func(*args, **kwargs)\n\n        if postconditions:\n            resolved_kwargs['result'] = result\n\n            # Assert the postconditions as a conjunction\n            for contract in postconditions:\n                _assert_postcondition(contract=contract, resolved_kwargs=resolved_kwargs)\n\n        return result  # type: ignore\n\n    # Copy __doc__ and other properties so that doctests can run\n    functools.update_wrapper(wrapper=wrapper, wrapped=func)\n\n    assert not hasattr(wrapper, \"__preconditions__\"), \"Expected no preconditions set on a pristine contract checker.\"\n    assert not hasattr(wrapper, \"__postcondition_snapshots__\"), \\\n        \"Expected no postcondition snapshots set on a pristine contract checker.\"\n    assert not hasattr(wrapper, \"__postconditions__\"), \"Expected no postconditions set on a pristine contract checker.\"\n\n    # Precondition is a list of condition groups (i.e. disjunctive normal form):\n    # each group consists of AND'ed preconditions, while the groups are OR'ed.\n    #\n    # This is necessary in order to implement \"require else\" logic when a class weakens the preconditions of\n    # its base class.\n    setattr(wrapper, \"__preconditions__\", [])\n    setattr(wrapper, \"__postcondition_snapshots__\", [])\n    setattr(wrapper, \"__postconditions__\", [])\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _find_self(param_names: List[str], args: Tuple[Any, ...], kwargs: Dict[str, Any]) -> Any:\n    instance_i = param_names.index(\"self\")\n    if instance_i < len(args):\n        instance = args[instance_i]\n    else:\n        instance = kwargs[\"self\"]\n\n    return instance", "response": "Find the instance of self in the arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecorate the function func with invariant checks.", "response": "def _decorate_with_invariants(func: CallableT, is_init: bool) -> CallableT:\n    \"\"\"\n    Decorate the function ``func`` of the class ``cls`` with invariant checks.\n\n    If the function has been already decorated with invariant checks, the function returns immediately.\n\n    :param func: function to be wrapped\n    :param is_init: True if the ``func`` is __init__\n    :return: function wrapped with invariant checks\n    \"\"\"\n    if _already_decorated_with_invariants(func=func):\n        return func\n\n    sign = inspect.signature(func)\n    param_names = list(sign.parameters.keys())\n\n    if is_init:\n\n        def wrapper(*args, **kwargs):\n            \"\"\"Wrap __init__ method of a class by checking the invariants *after* the invocation.\"\"\"\n            result = func(*args, **kwargs)\n            instance = _find_self(param_names=param_names, args=args, kwargs=kwargs)\n\n            for contract in instance.__class__.__invariants__:\n                _assert_invariant(contract=contract, instance=instance)\n\n            return result\n    else:\n\n        def wrapper(*args, **kwargs):\n            \"\"\"Wrap a function of a class by checking the invariants *before* and *after* the invocation.\"\"\"\n            instance = _find_self(param_names=param_names, args=args, kwargs=kwargs)\n\n            for contract in instance.__class__.__invariants__:\n                _assert_invariant(contract=contract, instance=instance)\n\n            result = func(*args, **kwargs)\n\n            for contract in instance.__class__.__invariants__:\n                _assert_invariant(contract=contract, instance=instance)\n\n            return result\n\n    functools.update_wrapper(wrapper=wrapper, wrapped=func)\n\n    setattr(wrapper, \"__is_invariant_check__\", True)\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _already_decorated_with_invariants(func: CallableT) -> bool:\n    already_decorated = False\n    for a_decorator in _walk_decorator_stack(func=func):\n        if getattr(a_decorator, \"__is_invariant_check__\", False):\n            already_decorated = True\n            break\n\n    return already_decorated", "response": "Check if the function has already been decorated with an invariant check by going through its decorator stack."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecorate each of the class methods with invariant checks if not already decorated.", "response": "def add_invariant_checks(cls: type) -> None:\n    \"\"\"Decorate each of the class functions with invariant checks if not already decorated.\"\"\"\n    # Candidates for the decoration as list of (name, dir() value)\n    init_name_func = None  # type: Optional[Tuple[str, Callable[..., None]]]\n    names_funcs = []  # type: List[Tuple[str, Callable[..., None]]]\n    names_properties = []  # type: List[Tuple[str, property]]\n\n    # Filter out entries in the directory which are certainly not candidates for decoration.\n    for name, value in [(name, getattr(cls, name)) for name in dir(cls)]:\n        # We need to ignore __repr__ to prevent endless loops when generating error messages.\n        # __getattribute__, __setattr__ and __delattr__ are too invasive and alter the state of the instance.\n        # Hence we don't consider them \"public\".\n        if name in [\"__repr__\", \"__getattribute__\", \"__setattr__\", \"__delattr__\"]:\n            continue\n\n        if name == \"__init__\":\n            assert inspect.isfunction(value) or isinstance(value, _SLOT_WRAPPER_TYPE), \\\n                \"Expected __init__ to be either a function or a slot wrapper, but got: {}\".format(type(value))\n\n            init_name_func = (name, value)\n            continue\n\n        if not inspect.isfunction(value) and not isinstance(value, _SLOT_WRAPPER_TYPE) and \\\n                not isinstance(value, property):\n            continue\n\n        # Ignore class methods\n        if getattr(value, \"__self__\", None) is cls:\n            continue\n\n        # Ignore \"protected\"/\"private\" methods\n        if name.startswith(\"_\") and not (name.startswith(\"__\") and name.endswith(\"__\")):\n            continue\n\n        if inspect.isfunction(value) or isinstance(value, _SLOT_WRAPPER_TYPE):\n            names_funcs.append((name, value))\n\n        elif isinstance(value, property):\n            names_properties.append((name, value))\n\n        else:\n            raise NotImplementedError(\"Unhandled directory entry of class {} for {}: {}\".format(cls, name, value))\n\n    if init_name_func:\n        name, func = init_name_func\n        wrapper = _decorate_with_invariants(func=func, is_init=True)\n        setattr(cls, name, wrapper)\n\n    for name, func in names_funcs:\n        wrapper = _decorate_with_invariants(func=func, is_init=False)\n        setattr(cls, name, wrapper)\n\n    for name, prop in names_properties:\n        new_prop = property(  # type: ignore\n            fget=_decorate_with_invariants(func=prop.fget, is_init=False) if prop.fget else None,\n            fset=_decorate_with_invariants(func=prop.fset, is_init=False) if prop.fset else None,\n            fdel=_decorate_with_invariants(func=prop.fdel, is_init=False) if prop.fdel else None,\n            doc=prop.__doc__)\n        setattr(cls, name, new_prop)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute the main routine.", "response": "def main() -> None:\n    \"\"\"\"Execute the main routine.\"\"\"\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\"--module\", help=\"name of the module to import\",\n                        choices=[\n                            \"functions_100_with_no_contract\",\n\n                            \"functions_100_with_1_contract\",\n                            \"functions_100_with_5_contracts\",\n                            \"functions_100_with_10_contracts\",\n\n                            \"functions_100_with_1_disabled_contract\",\n                            \"functions_100_with_5_disabled_contracts\",\n                            \"functions_100_with_10_disabled_contracts\",\n\n                            \"classes_100_with_no_invariant\",\n\n                            \"classes_100_with_1_invariant\",\n                            \"classes_100_with_5_invariants\",\n                            \"classes_100_with_10_invariants\",\n\n                            \"classes_100_with_1_disabled_invariant\",\n                            \"classes_100_with_5_disabled_invariants\",\n                            \"classes_100_with_10_disabled_invariants\",\n                        ],\n                        required=True)\n    args = parser.parse_args()\n\n\n    a_module = str(args.module)\n    if a_module == \"functions_100_with_no_contract\":\n        start = time.time()\n        import functions_100_with_no_contract\n        print(time.time() - start)\n\n    elif a_module == \"functions_100_with_1_contract\":\n        start = time.time()\n        import functions_100_with_1_contract\n        print(time.time() - start)\n\n    elif a_module == \"functions_100_with_5_contracts\":\n        start = time.time()\n        import functions_100_with_5_contracts\n        print(time.time() - start)\n\n    elif a_module == \"functions_100_with_10_contracts\":\n        start = time.time()\n        import functions_100_with_10_contracts\n        print(time.time() - start)\n\n    elif a_module == \"functions_100_with_1_disabled_contract\":\n        start = time.time()\n        import functions_100_with_1_disabled_contract\n        print(time.time() - start)\n\n    elif a_module == \"functions_100_with_5_disabled_contracts\":\n        start = time.time()\n        import functions_100_with_5_disabled_contracts\n        print(time.time() - start)\n\n    elif a_module == \"functions_100_with_10_disabled_contracts\":\n        start = time.time()\n        import functions_100_with_10_disabled_contracts\n        print(time.time() - start)\n\n    elif a_module == \"classes_100_with_no_invariant\":\n        start = time.time()\n        import classes_100_with_no_invariant\n        print(time.time() - start)\n\n    elif a_module == \"classes_100_with_1_invariant\":\n        start = time.time()\n        import classes_100_with_1_invariant\n        print(time.time() - start)\n\n    elif a_module == \"classes_100_with_5_invariants\":\n        start = time.time()\n        import classes_100_with_5_invariants\n        print(time.time() - start)\n\n    elif a_module == \"classes_100_with_10_invariants\":\n        start = time.time()\n        import classes_100_with_10_invariants\n        print(time.time() - start)\n\n    elif a_module == \"classes_100_with_1_disabled_invariant\":\n        start = time.time()\n        import classes_100_with_1_disabled_invariant\n        print(time.time() - start)\n\n    elif a_module == \"classes_100_with_5_disabled_invariants\":\n        start = time.time()\n        import classes_100_with_5_disabled_invariants\n        print(time.time() - start)\n\n    elif a_module == \"classes_100_with_10_disabled_invariants\":\n        start = time.time()\n        import classes_100_with_10_disabled_invariants\n        print(time.time() - start)\n\n    else:\n        raise NotImplementedError(\"Unhandled module: {}\".format(a_module))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main() -> None:\n    modules = [\n        \"functions_100_with_no_contract\",\n\n        \"functions_100_with_1_contract\",\n        \"functions_100_with_5_contracts\",\n        \"functions_100_with_10_contracts\",\n\n        \"functions_100_with_1_disabled_contract\",\n        \"functions_100_with_5_disabled_contracts\",\n        \"functions_100_with_10_disabled_contracts\",\n\n        \"classes_100_with_no_invariant\",\n\n        \"classes_100_with_1_invariant\",\n        \"classes_100_with_5_invariants\",\n        \"classes_100_with_10_invariants\",\n\n        \"classes_100_with_1_disabled_invariant\",\n        \"classes_100_with_5_disabled_invariants\",\n        \"classes_100_with_10_disabled_invariants\",\n    ]\n\n    for a_module in modules:\n        durations = []  # type: List[float]\n        for i in range(0, 10):\n            duration = float(\n                subprocess.check_output([\"./measure.py\", \"--module\", a_module], cwd=os.path.dirname(__file__)).strip())\n            durations.append(duration)\n\n        print(\"Duration to import the module {} (in milliseconds): {:.2f} \u00b1 {:.2f}\".format(\n            a_module, statistics.mean(durations) * 10e3, statistics.stdev(durations) * 10e3))", "response": "Execute the main routine."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute the main routine.", "response": "def main() -> None:\n    \"\"\"\"Execute the main routine.\"\"\"\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\"--outdir\", help=\"output directory\", default=os.path.dirname(__file__))\n    args = parser.parse_args()\n\n    outdir = pathlib.Path(args.outdir)\n    if not outdir.exists():\n        raise FileNotFoundError(\"Output directory is missing: {}\".format(outdir))\n\n    for contracts in [0, 1, 5, 10]:\n        if contracts == 0:\n            pth = outdir / \"functions_100_with_no_contract.py\"\n        elif contracts == 1:\n            pth = outdir / \"functions_100_with_1_contract.py\"\n        else:\n            pth = outdir / \"functions_100_with_{}_contracts.py\".format(contracts)\n\n        text = generate_functions(functions=100, contracts=contracts, disabled=False)\n        pth.write_text(text)\n\n    for contracts in [1, 5, 10]:\n        if contracts == 1:\n            pth = outdir / \"functions_100_with_1_disabled_contract.py\"\n        else:\n            pth = outdir / \"functions_100_with_{}_disabled_contracts.py\".format(contracts)\n\n        text = generate_functions(functions=100, contracts=contracts, disabled=True)\n        pth.write_text(text)\n\n    for invariants in [0, 1, 5, 10]:\n        if invariants == 0:\n            pth = outdir / \"classes_100_with_no_invariant.py\"\n        elif invariants == 1:\n            pth = outdir / \"classes_100_with_1_invariant.py\"\n        else:\n            pth = outdir / \"classes_100_with_{}_invariants.py\".format(invariants)\n\n        text = generate_classes(classes=100, invariants=invariants, disabled=False)\n        pth.write_text(text)\n\n    for invariants in [1, 5, 10]:\n        if invariants == 1:\n            pth = outdir / \"classes_100_with_1_disabled_invariant.py\"\n        else:\n            pth = outdir / \"classes_100_with_{}_disabled_invariants.py\".format(invariants)\n\n        text = generate_classes(classes=100, invariants=invariants, disabled=True)\n        pth.write_text(text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef visit_Bytes(self, node: ast.Bytes) -> bytes:\n        result = node.s\n\n        self.recomputed_values[node] = result\n        return node.s", "response": "Recompute the value as the bytes at the node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvisit the elements and assemble the results into a list.", "response": "def visit_List(self, node: ast.List) -> List[Any]:\n        \"\"\"Visit the elements and assemble the results into a list.\"\"\"\n        if isinstance(node.ctx, ast.Store):\n            raise NotImplementedError(\"Can not compute the value of a Store on a list\")\n\n        result = [self.visit(node=elt) for elt in node.elts]\n\n        self.recomputed_values[node] = result\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef visit_Tuple(self, node: ast.Tuple) -> Tuple[Any, ...]:\n        if isinstance(node.ctx, ast.Store):\n            raise NotImplementedError(\"Can not compute the value of a Store on a tuple\")\n\n        result = tuple(self.visit(node=elt) for elt in node.elts)\n\n        self.recomputed_values[node] = result\n        return result", "response": "Visit the elements and assemble the results into a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef visit_Set(self, node: ast.Set) -> Set[Any]:\n        result = set(self.visit(node=elt) for elt in node.elts)\n\n        self.recomputed_values[node] = result\n        return result", "response": "Visit the elements and assemble the results into a set."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvisit keys and values and assemble a dictionary with the results.", "response": "def visit_Dict(self, node: ast.Dict) -> Dict[Any, Any]:\n        \"\"\"Visit keys and values and assemble a dictionary with the results.\"\"\"\n        recomputed_dict = dict()  # type: Dict[Any, Any]\n        for key, val in zip(node.keys, node.values):\n            recomputed_dict[self.visit(node=key)] = self.visit(node=val)\n\n        self.recomputed_values[node] = recomputed_dict\n        return recomputed_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef visit_NameConstant(self, node: ast.NameConstant) -> Any:\n        self.recomputed_values[node] = node.value\n        return node.value", "response": "Forward the node value as a result."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visit_Name(self, node: ast.Name) -> Any:\n        if not isinstance(node.ctx, ast.Load):\n            raise NotImplementedError(\"Can only compute a value of Load on a name {}, but got context: {}\".format(\n                node.id, node.ctx))\n\n        result = None  # type: Optional[Any]\n\n        if node.id in self._name_to_value:\n            result = self._name_to_value[node.id]\n\n        if result is None and hasattr(builtins, node.id):\n            result = getattr(builtins, node.id)\n\n        if result is None and node.id != \"None\":\n            # The variable refers to a name local of the lambda (e.g., a target in the generator expression).\n            # Since we evaluate generator expressions with runtime compilation, None is returned here as a placeholder.\n            return PLACEHOLDER\n\n        self.recomputed_values[node] = result\n        return result", "response": "Load the variable by looking it up in the variable look - up and in the built - ins."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef visit_Expr(self, node: ast.Expr) -> Any:\n        result = self.visit(node=node.value)\n\n        self.recomputed_values[node] = result\n        return result", "response": "Visit the node s value and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef visit_UnaryOp(self, node: ast.UnaryOp) -> Any:\n        if isinstance(node.op, ast.UAdd):\n            result = +self.visit(node=node.operand)\n        elif isinstance(node.op, ast.USub):\n            result = -self.visit(node=node.operand)\n        elif isinstance(node.op, ast.Not):\n            result = not self.visit(node=node.operand)\n        elif isinstance(node.op, ast.Invert):\n            result = ~self.visit(node=node.operand)\n        else:\n            raise NotImplementedError(\"Unhandled op of {}: {}\".format(node, node.op))\n\n        self.recomputed_values[node] = result\n        return result", "response": "Visit the node operand and apply the operation on the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef visit_Compare(self, node: ast.Compare) -> Any:\n        # pylint: disable=too-many-branches\n        left = self.visit(node=node.left)\n\n        comparators = [self.visit(node=comparator) for comparator in node.comparators]\n\n        result = None  # type: Optional[Any]\n        for comparator, op in zip(comparators, node.ops):\n            if isinstance(op, ast.Eq):\n                comparison = left == comparator\n            elif isinstance(op, ast.NotEq):\n                comparison = left != comparator\n            elif isinstance(op, ast.Lt):\n                comparison = left < comparator\n            elif isinstance(op, ast.LtE):\n                comparison = left <= comparator\n            elif isinstance(op, ast.Gt):\n                comparison = left > comparator\n            elif isinstance(op, ast.GtE):\n                comparison = left >= comparator\n            elif isinstance(op, ast.Is):\n                comparison = left is comparator\n            elif isinstance(op, ast.IsNot):\n                comparison = left is not comparator\n            elif isinstance(op, ast.In):\n                comparison = left in comparator\n            elif isinstance(op, ast.NotIn):\n                comparison = left not in comparator\n            else:\n                raise NotImplementedError(\"Unhandled op of {}: {}\".format(node, op))\n\n            if result is None:\n                result = comparison\n            else:\n                result = result and comparison\n\n            left = comparator\n\n        self.recomputed_values[node] = result\n        return result", "response": "Recursively visit the comparators and apply the operations on them."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvisit the function and the arguments and then make the function call with them.", "response": "def visit_Call(self, node: ast.Call) -> Any:\n        \"\"\"Visit the function and the arguments and finally make the function call with them.\"\"\"\n        func = self.visit(node=node.func)\n\n        args = []  # type: List[Any]\n        for arg_node in node.args:\n            if isinstance(arg_node, ast.Starred):\n                args.extend(self.visit(node=arg_node))\n            else:\n                args.append(self.visit(node=arg_node))\n\n        kwargs = dict()  # type: Dict[str, Any]\n        for keyword in node.keywords:\n            if keyword.arg is None:\n                kw = self.visit(node=keyword.value)\n                for key, val in kw.items():\n                    kwargs[key] = val\n\n            else:\n                kwargs[keyword.arg] = self.visit(node=keyword.value)\n\n        result = func(*args, **kwargs)\n\n        self.recomputed_values[node] = result\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvisits the test and depending on its outcome the body or orelse.", "response": "def visit_IfExp(self, node: ast.IfExp) -> Any:\n        \"\"\"Visit the ``test``, and depending on its outcome, the ``body`` or ``orelse``.\"\"\"\n        test = self.visit(node=node.test)\n\n        if test:\n            result = self.visit(node=node.body)\n        else:\n            result = self.visit(node=node.orelse)\n\n        self.recomputed_values[node] = result\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef visit_Attribute(self, node: ast.Attribute) -> Any:\n        value = self.visit(node=node.value)\n        if not isinstance(node.ctx, ast.Load):\n            raise NotImplementedError(\n                \"Can only compute a value of Load on the attribute {}, but got context: {}\".format(node.attr, node.ctx))\n\n        result = getattr(value, node.attr)\n\n        self.recomputed_values[node] = result\n        return result", "response": "Visit the node s value and get the attribute from the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef visit_Index(self, node: ast.Index) -> Any:\n        result = self.visit(node=node.value)\n\n        self.recomputed_values[node] = result\n        return result", "response": "Visit the node s value and store the result in the recomputed_values dict."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvisiting lower upper and step and recompute the node as a slice.", "response": "def visit_Slice(self, node: ast.Slice) -> slice:\n        \"\"\"Visit ``lower``, ``upper`` and ``step`` and recompute the node as a ``slice``.\"\"\"\n        lower = None  # type: Optional[int]\n        if node.lower is not None:\n            lower = self.visit(node=node.lower)\n\n        upper = None  # type: Optional[int]\n        if node.upper is not None:\n            upper = self.visit(node=node.upper)\n\n        step = None  # type: Optional[int]\n        if node.step is not None:\n            step = self.visit(node=node.step)\n\n        result = slice(lower, upper, step)\n\n        self.recomputed_values[node] = result\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvisiting each dimension of the advanced slicing and assemble the dimensions in a tuple.", "response": "def visit_ExtSlice(self, node: ast.ExtSlice) -> Tuple[Any, ...]:\n        \"\"\"Visit each dimension of the advanced slicing and assemble the dimensions in a tuple.\"\"\"\n        result = tuple(self.visit(node=dim) for dim in node.dims)\n\n        self.recomputed_values[node] = result\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef visit_Subscript(self, node: ast.Subscript) -> Any:\n        value = self.visit(node=node.value)\n        a_slice = self.visit(node=node.slice)\n\n        result = value[a_slice]\n\n        self.recomputed_values[node] = result\n        return result", "response": "Visit the slice and a value and get the element."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompile the generator or comprehension from the node and execute the compiled code.", "response": "def _execute_comprehension(self, node: Union[ast.ListComp, ast.SetComp, ast.GeneratorExp, ast.DictComp]) -> Any:\n        \"\"\"Compile the generator or comprehension from the node and execute the compiled code.\"\"\"\n        args = [ast.arg(arg=name) for name in sorted(self._name_to_value.keys())]\n\n        func_def_node = ast.FunctionDef(\n            name=\"generator_expr\",\n            args=ast.arguments(args=args, kwonlyargs=[], kw_defaults=[], defaults=[]),\n            decorator_list=[],\n            body=[ast.Return(node)])\n\n        module_node = ast.Module(body=[func_def_node])\n\n        ast.fix_missing_locations(module_node)\n\n        code = compile(source=module_node, filename='<ast>', mode='exec')\n\n        module_locals = {}  # type: Dict[str, Any]\n        module_globals = {}  # type: Dict[str, Any]\n        exec(code, module_globals, module_locals)  # pylint: disable=exec-used\n\n        generator_expr_func = module_locals[\"generator_expr\"]\n\n        return generator_expr_func(**self._name_to_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncompiles the generator expression as a function and call it.", "response": "def visit_GeneratorExp(self, node: ast.GeneratorExp) -> Any:\n        \"\"\"Compile the generator expression as a function and call it.\"\"\"\n        result = self._execute_comprehension(node=node)\n\n        for generator in node.generators:\n            self.visit(generator.iter)\n\n        # Do not set the computed value of the node since its representation would be non-informative.\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef visit_ListComp(self, node: ast.ListComp) -> Any:\n        result = self._execute_comprehension(node=node)\n\n        for generator in node.generators:\n            self.visit(generator.iter)\n\n        self.recomputed_values[node] = result\n        return result", "response": "Compile the list comprehension as a function and call it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef visit_SetComp(self, node: ast.SetComp) -> Any:\n        result = self._execute_comprehension(node=node)\n\n        for generator in node.generators:\n            self.visit(generator.iter)\n\n        self.recomputed_values[node] = result\n        return result", "response": "Compile the set comprehension as a function and call it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef visit_DictComp(self, node: ast.DictComp) -> Any:\n        result = self._execute_comprehension(node=node)\n\n        for generator in node.generators:\n            self.visit(generator.iter)\n\n        self.recomputed_values[node] = result\n        return result", "response": "Compile the dictionary comprehension as a function and call it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef visit_Return(self, node: ast.Return) -> Any:  # pylint: disable=no-self-use\n        raise AssertionError(\"Unexpected return node during the re-computation: {}\".format(ast.dump(node)))", "response": "Raise an exception that this node is unexpected."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nraising an exception that this node has not been handled.", "response": "def generic_visit(self, node: ast.AST) -> None:\n        \"\"\"Raise an exception that this node has not been handled.\"\"\"\n        raise NotImplementedError(\"Unhandled recomputation of the node: {} {}\".format(type(node), node))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tokenize_words(string):\n    string = six.text_type(string)\n    return re.findall(WORD_TOKENIZATION_RULES, string)", "response": "Tokenize input text to words."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef align(self):\n        '''\n        Every step we have 3 choices:\n        1) Move pointer witness a --> omission\n        2) Move pointer witness b --> addition\n        3) Move pointer of both witness a/b  --> match\n        Note: a replacement is omission followed by an addition or the other way around\n\n        Choice 1 and 2 are only possible if token a and b are not a match OR when tokens are repeated.\n        For now I ignore token repetition..\n        '''\n        # extract tokens from witness (note that this can be done in a streaming manner if desired)\n        tokens_a = self.witness_a.tokens()\n        tokens_b = self.witness_b.tokens()\n        # create virtual decision tree (nodes are created on demand)\n        # see above\n        # create start node\n        start = DecisionTreeNode(self)\n\n        # search the decision tree\n        result = self.tree.search(start)\n        print(result)\n\n        pass", "response": "Aligns the decision tree with the witnesses"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconnect two sets of nodes near to the target set.", "response": "def connect_near(self, source, target, weight):\n        # Near edges are added to self.near_graph, not self.graph, to avoid cycles\n        \"\"\"\n        :type source: integer\n        :type target: integer\n        \"\"\"\n        self.near_graph.add_edge(source, target, weight = weight, type='near')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmerging the given graph with the given witness_sigil and returns a dictionary of all the vertices that are connected to the witness_sigil.", "response": "def merge(self, graph, witness_sigil, witness_tokens, alignments={}):\n        \"\"\"\n        :type graph: VariantGraph\n        \"\"\"\n        # NOTE: token_to_vertex only contains newly generated vertices\n        token_to_vertex = {}\n        last = graph.start\n        for token in witness_tokens:\n            vertex = alignments.get(token, None)\n            if not vertex:\n                vertex = graph.add_vertex(token, witness_sigil)\n                token_to_vertex[token] = vertex\n            else:\n                vertex.add_token(witness_sigil, token)\n                # graph.add_token_to_vertex(vertex, token, witness_sigil)\n            graph.connect(last, vertex, witness_sigil)\n            last = vertex\n        graph.connect(last, graph.end, witness_sigil)\n        return token_to_vertex"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncollate the given VariantGraph into a single variant graph for each witness in the sequence", "response": "def collate(self, graph):\n        \"\"\"\n        :type graph: VariantGraph\n        \"\"\"\n        # prepare the token index\n        self.token_index.prepare()\n        self.vertex_array = [None] * len(self.token_index.token_array)\n\n        # Build the variant graph for the first witness\n        # this is easy: generate a vertex for every token\n        first_witness = self.collation.witnesses[0]\n        tokens = first_witness.tokens()\n        token_to_vertex = self.merge(graph, first_witness.sigil, tokens)\n        # print(\"> token_to_vertex=\", token_to_vertex)\n        self.update_token_position_to_vertex(token_to_vertex)\n        self.update_token_to_vertex_array(tokens, first_witness, self.token_position_to_vertex)\n\n        # align witness 2 - n\n        for x in range(1, len(self.collation.witnesses)):\n            witness = self.collation.witnesses[x]\n            tokens = witness.tokens()\n            # print(\"\\nwitness\", witness.sigil)\n\n            variant_graph_ranking = VariantGraphRanking.of(graph)\n            # print(\"> x =\", x, \", variant_graph_ranking =\", variant_graph_ranking.byRank)\n            variant_graph_ranks = list(set(map(lambda v: variant_graph_ranking.byVertex.get(v), graph.vertices())))\n            # we leave in the rank of the start vertex, but remove the rank of the end vertex\n            variant_graph_ranks.pop()\n\n            # now the vertical stuff\n            tokens_as_index_list = self.as_index_list(tokens)\n\n            match_cube = MatchCube(self.token_index, witness, self.vertex_array, variant_graph_ranking,\n                                   self.properties_filter)\n            # print(\"> match_cube.matches=\", match_cube.matches)\n            self.fill_needleman_wunsch_table(variant_graph_ranks, tokens_as_index_list, match_cube)\n\n            aligned = self.align_matching_tokens(match_cube)\n            # print(\"> aligned=\", aligned)\n            # print(\"self.token_index.token_array=\", self.token_index.token_array)\n            # alignment = self.align_function(superbase, next_witness, token_to_vertex, match_cube)\n\n            # merge\n            witness_token_to_generated_vertex = self.merge(graph, witness.sigil, witness.tokens(), aligned)\n            # print(\"> witness_token_to_generated_vertex =\", witness_token_to_generated_vertex)\n            token_to_vertex.update(witness_token_to_generated_vertex)\n            # print(\"> token_to_vertex =\", token_to_vertex)\n            self.update_token_position_to_vertex(token_to_vertex, aligned)\n            witness_token_position_to_vertex = {}\n            for p in self.token_index.get_range_for_witness(witness.sigil):\n                # print(\"> p= \", p)\n                witness_token_position_to_vertex[p] = self.token_position_to_vertex[p]\n            self.update_token_to_vertex_array(tokens, witness, witness_token_position_to_vertex)\n            # print(\"> vertex_array =\", self.vertex_array)\n\n            #             print(\"actual\")\n            #             self._debug_edit_graph_table(self.table)\n            #             print(\"expected\")\n            #             self._debug_edit_graph_table(self.table2)\n\n            # change superbase\n            # superbase = self.new_superbase\n\n            if self.detect_transpositions:\n                detector = TranspositionDetection(self)\n                detector.detect()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a string of comma - separated x - y - step - like ranges and return a tuple of the node range info.", "response": "def _parse(self, pattern):\n        \"\"\"Parse string of comma-separated x-y/step -like ranges\"\"\"\n        # Comma separated ranges\n        if pattern.find(',') < 0:\n            subranges = [pattern]\n        else:\n            subranges = pattern.split(',')\n\n        for subrange in subranges:\n            if subrange.find('/') < 0:\n                step = 1\n                baserange = subrange\n            else:\n                baserange, step = subrange.split('/', 1)\n\n            try:\n                step = int(step)\n            except ValueError:\n                raise RangeSetParseError(subrange,\n                        \"cannot convert string to integer\")\n\n            if baserange.find('-') < 0:\n                if step != 1:\n                    raise RangeSetParseError(subrange,\n                            \"invalid step usage\")\n                begin = end = baserange\n            else:\n                begin, end = baserange.split('-', 1)\n\n            # compute padding and return node range info tuple\n            try:\n                pad = 0\n                if int(begin) != 0:\n                    begins = begin.lstrip(\"0\")\n                    if len(begin) - len(begins) > 0:\n                        pad = len(begin)\n                    start = int(begins)\n                else:\n                    if len(begin) > 1:\n                        pad = len(begin)\n                    start = 0\n                if int(end) != 0:\n                    ends = end.lstrip(\"0\")\n                else:\n                    ends = end\n                stop = int(ends)\n            except ValueError:\n                raise RangeSetParseError(subrange,\n                        \"cannot convert string to integer\")\n\n            # check preconditions\n            if stop > 1e100 or start > stop or step < 1:\n                raise RangeSetParseError(subrange,\n                                         \"invalid values in range\")\n\n            self.add_range(start, stop + 1, step, pad)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclass method that returns a new RangeSet with ranges from provided list.", "response": "def fromlist(cls, rnglist, autostep=None):\n        \"\"\"Class method that returns a new RangeSet with ranges from provided\n        list.\"\"\"\n        inst = RangeSet(autostep=autostep)\n        inst.updaten(rnglist)\n        return inst"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fromone(cls, index, pad=0, autostep=None):\n        inst = RangeSet(autostep=autostep)\n        # support slice object with duck-typing\n        try:\n            inst.add(index, pad)\n        except TypeError:\n            if not index.stop:\n                raise ValueError(\"Invalid range upper limit (%s)\" % index.stop)\n            inst.add_range(index.start or 0, index.stop, index.step or 1, pad)\n        return inst", "response": "Class method that returns a new RangeSet of one single item or\n            a single range ( from integer or slice object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset autostep value ( property", "response": "def set_autostep(self, val):\n        \"\"\"Set autostep value (property)\"\"\"\n        if val is None:\n            # disabled by default for pdsh compat (+inf is 1E400, but a bug in\n            # python 2.4 makes it impossible to be pickled, so we use less)\n            # NOTE: Later, we could consider sys.maxint here\n            self._autostep = 1E100\n        else:\n            # - 1 because user means node count, but we means real steps\n            self._autostep = int(val) - 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\niterating over each string element in RangeSet.", "response": "def striter(self):\n        \"\"\"Iterate over each (optionally padded) string element in RangeSet.\"\"\"\n        pad = self.padding or 0\n        for i in self._sorted():\n            yield \"%0*d\" % (pad, i)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nobject - based iterator over contiguous range sets.", "response": "def contiguous(self):\n        \"\"\"Object-based iterator over contiguous range sets.\"\"\"\n        pad = self.padding or 0\n        for sli in self._contiguous_slices():\n            yield RangeSet.fromone(slice(sli.start, sli.stop, sli.step), pad)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _strslices(self):\n        pad = self.padding or 0\n        for sli in self.slices():\n            if sli.start + 1 == sli.stop:\n                yield \"%0*d\" % (pad, sli.start)\n            else:\n                assert sli.step >= 0, \"Internal error: sli.step < 0\"\n                if sli.step == 1:\n                    yield \"%0*d-%0*d\" % (pad, sli.start, pad, sli.stop - 1)\n                else:\n                    yield \"%0*d-%0*d/%d\" % (pad, sli.start, pad, sli.stop - 1, \\\n                                            sli.step)", "response": "Stringify the slices list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _contiguous_slices(self):\n        k = j = None\n        for i in self._sorted():\n            if k is None:\n                k = j = i\n            if i - j > 1:\n                yield slice(k, j + 1, 1)\n                k = i\n            j = i\n        if k is not None:\n            yield slice(k, j + 1, 1)", "response": "Internal iterator over contiguous slices in RangeSet."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _folded_slices(self):\n        if len(self) == 0:\n            return\n\n        prng = None         # pending range\n        istart = None       # processing starting indice\n        m = 0               # processing step\n        for sli in self._contiguous_slices():\n            start = sli.start\n            stop = sli.stop\n            unitary = (start + 1 == stop)   # one indice?\n            if istart is None:  # first loop\n                if unitary:\n                    istart = start\n                else:\n                    prng = [start, stop, 1]\n                    istart = stop - 1\n                i = k = istart\n            elif m == 0:        # istart is set but step is unknown\n                if not unitary:\n                    if prng is not None:\n                        # yield and replace pending range\n                        yield slice(*prng)\n                    else:\n                        yield slice(istart, istart + 1, 1)\n                    prng = [start, stop, 1]\n                    istart = k = stop - 1\n                    continue\n                i = start\n            else:               # step m > 0\n                assert m > 0\n                i = start\n                # does current range lead to broken step?\n                if m != i - k or not unitary:\n                    #j = i if m == i - k else k\n                    if m == i - k: j = i\n                    else: j = k\n                    # stepped is True when autostep setting does apply\n                    stepped = (j - istart >= self._autostep * m)\n                    if prng:    # yield pending range?\n                        if stepped:\n                            prng[1] -= 1\n                        else:\n                            istart += m\n                        yield slice(*prng)\n                        prng = None\n                if m != i - k:\n                    # case: step value has changed\n                    if stepped:\n                        yield slice(istart, k + 1, m)\n                    else:\n                        for j in range(istart, k - m + 1, m):\n                            yield slice(j, j + 1, 1)\n                        if not unitary:\n                            yield slice(k, k + 1, 1)\n                    if unitary:\n                        if stepped:\n                            istart = i = k = start\n                        else:\n                            istart = k\n                    else:\n                        prng = [start, stop, 1]\n                        istart = i = k = stop - 1\n                elif not unitary:\n                    # case: broken step by contiguous range\n                    if stepped:\n                        # yield 'range/m' by taking first indice of new range\n                        yield slice(istart, i + 1, m)\n                        i += 1\n                    else:\n                        # autostep setting does not apply in that case\n                        for j in range(istart, i - m + 1, m):\n                            yield slice(j, j + 1, 1)\n                    if stop > i + 1:    # current->pending only if not unitary\n                        prng = [i, stop, 1]\n                    istart = i = k = stop - 1\n            m = i - k   # compute step\n            k = i\n        # exited loop, process pending range or indice...\n        if m == 0:\n            if prng:\n                yield slice(*prng)\n            else:\n                yield slice(istart, istart + 1, 1)\n        else:\n            assert m > 0\n            stepped = (k - istart >= self._autostep * m)\n            if prng:\n                if stepped:\n                    prng[1] -= 1\n                else:\n                    istart += m\n                yield slice(*prng)\n                prng = None\n            if stepped:\n                yield slice(istart, i + 1, m)\n            else:\n                for j in range(istart, i + 1, m):\n                    yield slice(j, j + 1, 1)", "response": "Internal generator that is able to retrieve ranges organized by step."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsplitting the rangeset into nbr sub - nodesets.", "response": "def split(self, nbr):\n        \"\"\"\n        Split the rangeset into nbr sub-rangesets (at most). Each\n        sub-rangeset will have the same number of elements more or\n        less 1. Current rangeset remains unmodified. Returns an\n        iterator.\n\n        >>> RangeSet(\"1-5\").split(3) \n        RangeSet(\"1-2\")\n        RangeSet(\"3-4\")\n        RangeSet(\"foo5\")\n        \"\"\"\n        assert(nbr > 0)\n\n        # We put the same number of element in each sub-nodeset.\n        slice_size = len(self) / nbr\n        left = len(self) % nbr\n\n        begin = 0\n        for i in range(0, min(nbr, len(self))):\n            length = slice_size + int(i < left)\n            yield self[begin:begin + length]\n            begin += length"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a range to the RangeSet.", "response": "def add_range(self, start, stop, step=1, pad=0):\n        \"\"\"\n        Add a range (start, stop, step and padding length) to RangeSet.\n        Like the Python built-in function range(), the last element is\n        the largest start + i * step less than stop.\n        \"\"\"\n        assert start < stop, \"please provide ordered node index ranges\"\n        assert step > 0\n        assert pad >= 0\n        assert stop - start < 1e9, \"range too large\"\n\n        if pad > 0 and self.padding is None:\n            self.padding = pad\n        set.update(self, range(start, stop, step))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy(self):\n        cpy = self.__class__()\n        cpy._autostep = self._autostep\n        cpy.padding = self.padding\n        cpy.update(self)\n        return cpy", "response": "Return a shallow copy of a RangeSet."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps built - in set operations for RangeSet to workaround built - in set operations.", "response": "def _wrap_set_op(self, fun, arg):\n        \"\"\"Wrap built-in set operations for RangeSet to workaround built-in set\n        base class issues (RangeSet.__new/init__ not called)\"\"\"\n        result = fun(self, arg)\n        result._autostep = self._autostep\n        result.padding = self.padding\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the intersection of two sets as a new set instance.", "response": "def intersection(self, other):\n        \"\"\"Return the intersection of two RangeSets as a new RangeSet.\n\n        (I.e. all elements that are in both sets.)\n        \"\"\"\n        #NOTE: This is a work around \n        # Python 3 return as the result of set.intersection a new set instance.\n        # Python 2 however returns as a the result a ClusterShell.RangeSet.RangeSet instance.\n        # ORIGINAL CODE: return self._wrap_set_op(set.intersection, other)\n        copy = self.copy()\n        copy.intersection_update(other)\n        return copy"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef difference(self, other):\n        #NOTE: This is a work around\n        # Python 3 return as the result of set.intersection a new set instance.\n        # Python 2 however returns as a the result a ClusterShell.RangeSet.RangeSet instance.\n        # ORIGINAL CODE: return self._wrap_set_op(set.difference, other)\n        copy = self.copy()\n        copy.difference_update(other)\n        return copy", "response": "Return the difference of two sets as a new set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef issubset(self, other):\n        self._binary_sanity_check(other)\n        return set.issubset(self, other)", "response": "Report whether this set contains another set."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreport whether this RangeSet contains another set.", "response": "def issuperset(self, other):\n        \"\"\"Report whether this RangeSet contains another set.\"\"\"\n        self._binary_sanity_check(other)\n        return set.issuperset(self, other)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate this RangeSet with the difference of the elements of another set.", "response": "def difference_update(self, other, strict=False):\n        \"\"\"Remove all elements of another set from this RangeSet.\n        \n        If strict is True, raise KeyError if an element cannot be removed.\n        (strict is a RangeSet addition)\"\"\"\n        if strict and other not in self:\n            raise KeyError(other.difference(self)[0])\n        set.difference_update(self, other)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update(self, iterable):\n        if isinstance(iterable, RangeSet):\n            # keep padding unless is has not been defined yet\n            if self.padding is None and iterable.padding is not None:\n                self.padding = iterable.padding\n        assert type(iterable) is not str\n        set.update(self, iterable)", "response": "Add all integers from an iterable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating a set of all the items in the set with the union of itself and several others.", "response": "def updaten(self, rangesets):\n        \"\"\"\n        Update a rangeset with the union of itself and several others.\n        \"\"\"\n        for rng in rangesets:\n            if isinstance(rng, set):\n                self.update(rng)\n            else:\n                self.update(RangeSet(rng))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an element to a RangeSet.", "response": "def add(self, element, pad=0):\n        \"\"\"Add an element to a RangeSet.\n        This has no effect if the element is already present.\n        \"\"\"\n        set.add(self, int(element))\n        if pad > 0 and self.padding is None:\n            self.padding = pad"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove element from the RangeSet.", "response": "def discard(self, element):\n        \"\"\"Remove element from the RangeSet if it is a member.\n\n        If the element is not a member, do nothing.\n        \"\"\"\n        try:\n            i = int(element)\n            set.discard(self, i)\n        except ValueError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _open(filename, mode=\"r\"):\n    if filename.endswith(\".gz\"):\n        return GzipFile(filename, mode, COMPRESSION_LEVEL)\n    elif filename == \"-\":\n        if mode == \"r\":\n            return _stdin\n        elif mode == \"w\":\n            return _stdout\n    else:\n        # TODO: set encoding to UTF-8?\n        return open(filename, mode=mode)", "response": "Open a file with the specified mode."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstable sort of the sequence a according to the keys given in r. >>> a=range(5) >>> b=[0]*5 >>> r=[2,1,3,0,4] >>> _radixPass(a, b, r, 5, 5) >>> b [3, 1, 0, 2, 4] When n is less than the length of a, the end of b must be left unaltered. >>> b=[5]*5 >>> _radixPass(a, b, r, 2, 2) >>> b [1, 0, 5, 5, 5] >>> _a=a=[1, 0] >>> b= [0]*2 >>> r=[0, 1] >>> _radixPass(a, b, r, 2, 2) >>> a=_a >>> b [0, 1] >>> a=[1, 1] >>> _radixPass(a, b, r, 2, 2) >>> b [1, 1] >>> a=[0, 1, 1, 0] >>> b= [0]*4 >>> r=[0, 1] >>> _radixPass(a, b, r, 4, 2) >>> a=_a >>> b [0, 0, 1, 1]", "response": "def _radixPass(a, b, r, n, K):\n    \"\"\"\n    Stable sort of the sequence a according to the keys given in r.\n\n    >>> a=range(5)\n    >>> b=[0]*5\n    >>> r=[2,1,3,0,4]\n\n    >>> _radixPass(a, b, r, 5, 5)\n    >>> b\n    [3, 1, 0, 2, 4]\n\n    When n is less than the length of a, the end of b must be left unaltered.\n    >>> b=[5]*5\n    >>> _radixPass(a, b, r, 2, 2)\n    >>> b\n    [1, 0, 5, 5, 5]\n\n    >>> _a=a=[1, 0]\n    >>> b= [0]*2\n    >>> r=[0, 1]\n    >>> _radixPass(a, b, r, 2, 2)\n    >>> a=_a\n    >>> b\n    [0, 1]\n\n    >>> a=[1, 1]\n    >>> _radixPass(a, b, r, 2, 2)\n    >>> b\n    [1, 1]\n\n    >>> a=[0, 1, 1, 0]\n    >>> b= [0]*4\n    >>> r=[0, 1]\n    >>> _radixPass(a, b, r, 4, 2)\n    >>> a=_a\n    >>> b\n    [0, 0, 1, 1]\n    \"\"\"\n    c = _array(\"i\", [0] * (K + 1))  # counter array\n\n    for i in range(n):  # count occurrences\n        c[r[a[i]]] += 1\n\n    sum = 0\n\n    for i in range(K + 1):  # exclusive prefix sums\n        t = c[i]\n        c[i] = sum\n        sum += t\n\n    for a_i in a[:n]:  # sort\n        b[c[r[a_i]]] = a_i\n        c[r[a_i]] += 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _nbOperations(n):\n    if n < 2:\n        return 0\n    else:\n        n0 = (n + 2) // 3\n        n02 = n0 + n // 3\n        return 3 * (n02) + n0 + _nbOperations(n02)", "response": "Returns the number of atomic operations in _radixPass."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the length of the longest common prefix of seq1 and seq2 starting at offset start1 and start2.", "response": "def _longestCommonPrefix(seq1, seq2, start1=0, start2=0):\n    \"\"\"\n    Returns the length of the longest common prefix of seq1\n    starting at offset start1 and seq2 starting at offset start2.\n\n    >>> _longestCommonPrefix(\"abcdef\", \"abcghj\")\n    3\n\n    >>> _longestCommonPrefix(\"abcghj\", \"abcdef\")\n    3\n\n    >>> _longestCommonPrefix(\"miss\", \"\")\n    0\n\n    >>> _longestCommonPrefix(\"\", \"mr\")\n    0\n\n    >>> _longestCommonPrefix(range(128), range(128))\n    128\n\n    >>> _longestCommonPrefix(\"abcabcabc\", \"abcdefabcdef\", 0, 6)\n    3\n\n    >>> _longestCommonPrefix(\"abcdefabcdef\", \"abcabcabc\", 6, 0)\n    3\n\n    >>> _longestCommonPrefix(\"abc\", \"abcabc\", 1, 4)\n    2\n\n    >>> _longestCommonPrefix(\"abcabc\", \"abc\", 4, 1)\n    2\n    \"\"\"\n\n    len1 = len(seq1) - start1\n    len2 = len(seq2) - start2\n\n    # We set seq2 as the shortest sequence\n    if len1 < len2:\n        seq1, seq2 = seq2, seq1\n        start1, start2 = start2, start1\n        len1, len2 = len2, len1\n\n    # if seq2 is empty returns 0\n    if len2 == 0:\n        return 0\n\n    i = 0\n    pos2 = start2\n    for i in range(min(len1, len2)):\n        # print seq1, seq2, start1, start2\n        if seq1[start1 + i] != seq2[start2 + i]:\n            return i\n\n    # we have reached the end of seq2 (need to increment i)\n    return i + 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the longest common prefix for every adjacent suffixes.", "response": "def LCP(SA):\n    \"\"\"\n    Compute the longest common prefix for every adjacent suffixes.\n    The result is a list of same size as SA.\n    Given two suffixes at positions i and i+1,\n    their LCP is stored at position i+1.\n    A zero is stored at position 0 of the output.\n\n    >>> SA=SuffixArray(\"abba\", unit=UNIT_BYTE)\n    >>> SA._LCP_values\n    array('i', [0, 1, 0, 1])\n\n    >>> SA=SuffixArray(\"\", unit=UNIT_BYTE)\n    >>> SA._LCP_values\n    array('i')\n\n    >>> SA=SuffixArray(\"\", unit=UNIT_CHARACTER)\n    >>> SA._LCP_values\n    array('i')\n\n    >>> SA=SuffixArray(\"\", unit=UNIT_WORD)\n    >>> SA._LCP_values\n    array('i')\n\n    >>> SA=SuffixArray(\"abab\", unit=UNIT_BYTE)\n    >>> SA._LCP_values\n    array('i', [0, 2, 0, 1])\n    \"\"\"\n    string = SA.string\n    length = SA.length\n    lcps = _array(\"i\", [0] * length)\n    SA = SA.SA\n\n    if _trace:\n        delta = max(length // 100, 1)\n        for i, pos in enumerate(SA):\n            if i % delta == 0:\n                percent = float((i + 1) * 100) / length\n                print >> _stderr, \"Compute_LCP %.2f%% (%i/%i)\\r\" % (percent, i + 1, length),\n            lcps[i] = _longestCommonPrefix(string, string, SA[i - 1], pos)\n    else:\n        for i, pos in enumerate(SA):\n            lcps[i] = _longestCommonPrefix(string, string, SA[i - 1], pos)\n\n    if _trace:\n        print >> _stderr, \"Compute_LCP %.2f%% (%i/%i)\\r\" % (100.0, length, length)\n\n    if lcps:  # Correct the case where string[0] == string[-1]\n        lcps[0] = 0\n    return lcps"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the command line arguments.", "response": "def parseArgv():\n    \"\"\"\n    Command line option parser.\n    \"\"\"\n    parser = OptionParser()\n    parser.usage = r\"\"\" cat <TEXT> | %prog [--unit <UNIT>] [--output <SA_FILE>]\n\nCreate the suffix array of TEXT with the processing UNIT and optionally store it in SA_FILE for subsequent use.\nUNIT may be set to 'byte', 'character' (given an encoding with the --encoding option) or 'word', which is the default.\n\"\"\"\n\n    parser.add_option(\"-i\", \"--input\",\n                      action=\"store\", type=\"string\", dest=\"input\",\n                      default=False,\n                      help=\"Path of the file containing the input text. When '-' is given, read the standard input (default). If the path ends with '.gz', reads the decompressed file.\")\n\n    parser.add_option(\"-o\", \"--output\",\n                      action=\"store\", type=\"string\", dest=\"output\",\n                      default=False,\n                      help=\"Store the suffix array of the input to the file OUTPUT. When '-' is given, writes to the standard output. If the filename ends with '.gz', the suffix array will be stored  compressed.\")\n\n    parser.add_option(\"\", \"--load\",\n                      action=\"store\", type=\"string\", dest=\"SAFile\",\n                      default=False,\n                      help=\"Load a suffix array from SAFILE, this option and --input are mutually exclusive.\")\n\n    parser.add_option(\"-u\", \"--unit\",\n                      action=\"store\", type=\"string\", dest=\"unit\",\n                      default=DEFAULT_UNIT_STR,\n                      help=\"Processing unit used for the creation of the suffix array.\" + \\\n                           'Possible values are \"byte\", \"character\" and \"word\". Default is \"%s\".' % DEFAULT_UNIT_STR + \\\n                           \"This option is ignored when the suffix array is loaded from SAFILE.\" + \\\n                           'For characters, the input is decoded according to the encoding set via the option --encoding.')\n\n    parser.add_option(\"-e\", \"--encoding\",\n                      action=\"store\", type=\"string\", dest=\"encoding\",\n                      default=DEFAULT_ENCODING,\n                      help=\"Encoding of the input. This information is required only when processing characters. Default is '%s'.\" % DEFAULT_ENCODING)\n\n    parser.add_option(\"-p\", \"--print\",\n                      action=\"store_true\", dest=\"printSA\",\n                      default=False,\n                      help=\"Prints the suffix array in a human readable format to the standard error output.\")\n\n    parser.add_option(\"\", \"--verbose\",\n                      action=\"store_true\", dest=\"verbose\",\n                      default=False,\n                      help=\"Prints more information.\")\n\n    parser.add_option(\"\", \"--no-lcps\",\n                      action=\"store_true\", dest=\"noLCPs\",\n                      default=False,\n                      help=\"Switch off the computation of LCPs. By doing so, the find functions are unusable.\")\n\n    (options, args) = parser.parse_args(_argv)\n    strings = args[1:]\n    return (options, strings)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a feature to the suffix array.", "response": "def addFeatureSA(self, callback, default=None, name=None):\n        \"\"\"\n        Add a feature to the suffix array.\n        The callback must return a sequence such that\n        the feature at position i is attached to the suffix referenced by\n        self.SA[i].\n\n        It is called with one argument: the instance of SuffixArray self.\n        The callback may traverse self.SA in any fashion.\n\n        The default behavior is to name the new feature after the callback name.\n        To give another name, set the argument name accordingly.\n\n        When the feature of an unknown substring of the text is requested,\n        the value of the default argument is used.\n\n        If the feature attached to a suffix is independent of the other suffix\n        features, then the method addFeature gives a better alternative.\n\n        You may use addFeatureSA as a decorator as in the following example.\n\n        Example: feature named bigram which attach the frequencies of the\n        leading bigram to each suffix.\n\n        >>> SA=SuffixArray(\"mississippi\", unit=UNIT_BYTE)\n\n        >>> def bigram(SA):\n        ...     res=[0]*SA.length\n        ...     end=0\n        ...     while end <= SA.length:\n        ...\n        ...         begin=end-1\n        ...         while end < SA.length and  SA._LCP_values[end]>=2:\n        ...             if SA.SA[end]+2<=SA.length: #end of string\n        ...                 end+=1\n        ...\n        ...         nbBigram=end-begin\n        ...         for i in xrange(begin, end):\n        ...             if SA.SA[i]+2<=SA.length:\n        ...                 res[i]=nbBigram\n        ...\n        ...         end+=1\n        ...     return res\n\n        >>> SA.addFeatureSA(bigram, 0)\n\n        >>> SA._bigram_values\n        [0, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2]\n\n        >>> print str(SA).expandtabs(14) #doctest: +SKIP\n        ...     10        'i'           LCP=0 ,       bigram=0\n        ...      7        'ippi'        LCP=1 ,       bigram=1\n        ...      4        'issippi'     LCP=1 ,       bigram=2\n        ...      1        'ississippi'  LCP=4 ,       bigram=2\n        ...      0        'mississipp'  LCP=0 ,       bigram=1\n        ...      9        'pi'          LCP=0 ,       bigram=1\n        ...      8        'ppi'         LCP=1 ,       bigram=1\n        ...      6        'sippi'       LCP=0 ,       bigram=2\n        ...      3        'sissippi'    LCP=2 ,       bigram=2\n        ...      5        'ssippi'      LCP=1 ,       bigram=2\n        ...      2        'ssissippi'   LCP=3 ,       bigram=2\n\n        >>> SA.bigram('ip')\n        1\n\n        >>> SA.bigram('si')\n        2\n\n        >>> SA.bigram('zw')\n        0\n\n        \"\"\"\n        if name is None:\n            featureName = callback.__name__\n        else:\n            featureName = name\n\n        featureValues = callback(self)\n        setattr(self, \"_%s_values\" % featureName, featureValues)\n        setattr(self, \"%s_default\" % featureName, default)\n        self.features.append(featureName)\n\n        def findFeature(substring):\n            res = self._findOne(substring, )\n            if res is not False:\n                return featureValues[res]\n            else:\n                return default\n\n        setattr(self, featureName, findFeature)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a feature to the suffix array.", "response": "def addFeature(self, callback, default=None, name=None, arguments=None):\n        \"\"\"\n        Add a feature to the suffix array.\n        The callback must return the feature corresponding to the suffix at\n        position self.SA[i].\n\n        The callback must be callable (a function or lambda).\n        The argument names of the callback are used to determine the data\n        needed. If an argument is the name of feature already defined, then\n        this argument will be the value of that feature for the current suffix.\n        In addition the argument pos is the position of the current suffix\n        and iSA is the index of pos in SA.\n        Other attributes of the SuffixArray instance may be use as argument\n        names.\n\n        If the feature attached to a suffix depends on other suffix features,\n        then the method addFeatureSA is the only choice.\n\n        \"\"\"\n        if name is None:\n            featureName = callback.__name__\n        else:\n            featureName = name\n\n        if arguments is None:\n            signature = getargspec(callback)[0]\n        else:\n            signature = arguments\n\n        featureValues = [default] * (self.length)\n        args = [getattr(self, \"_%s_values\" % featName) for featName in signature]\n        # print args\n        for i, pos in enumerate(self.SA):\n            arg = [j[i] for j in args]\n            # print arg\n            featureValues[i] = callback(*arg)\n        # end alternative\n\n        setattr(self, \"_%s_values\" % featureName, featureValues)\n        setattr(self, \"%s_default\" % featureName, default)\n        self.features.append(featureName)\n\n        def findFeature(substring):\n            res = self._findOne(substring)\n            if res:\n                return featureValues[res]\n            else:\n                return default\n\n        setattr(self, featureName, findFeature)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reprString(self, string, length):\n        if isinstance(string, int):\n            length = min(length, self.length - string)\n            string = self.string[string:string + length]\n\n        voc = self.voc\n        res = self.tokSep.join((voc[id] for id in string[:length]))\n        if self.unit == UNIT_WORD:\n            res = res.replace(\" \\n\", \"\\n\")\n            res = res.replace(\"\\n \", \"\\n\")\n\n        if self.unit == UNIT_CHARACTER:\n            res = res.encode(self.encoding)\n\n        return res", "response": "Return a string of length tokens in the original form."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the suffix array instance to a file.", "response": "def toFile(self, filename):\n        \"\"\"\n        Save the suffix array instance including all features attached in\n        filename. Accept any filename following the _open conventions,\n        for example if it ends with .gz the file created will be a compressed\n        GZip file.\n        \"\"\"\n        start = _time()\n        fd = _open(filename, \"w\")\n\n        savedData = [self.string, self.unit, self.voc, self.vocSize, self.SA, self.features]\n\n        for featureName in self.features:\n            featureValues = getattr(self, \"_%s_values\" % featureName)\n            featureDefault = getattr(self, \"%s_default\" % featureName)\n\n            savedData.append((featureValues, featureDefault))\n\n        fd.write(_dumps(savedData, _HIGHEST_PROTOCOL))\n        fd.flush()\n        try:\n            self.sizeOfSavedFile = getsize(fd.name)\n        except OSError:  # if stdout is used\n            self.sizeOfSavedFile = \"-1\"\n        self.toFileTime = _time() - start\n        if _trace: print >> _stderr, \"toFileTime %.2fs\" % self.toFileTime\n\n        if _trace: print >> _stderr, \"sizeOfSavedFile %sb\" % self.sizeOfSavedFile\n        fd.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fromFile(cls, filename):\n        self = cls.__new__(cls)  # new instance which does not call __init__\n\n        start = _time()\n\n        savedData = _loads(_open(filename, \"r\").read())\n\n        # load common attributes\n        self.string, self.unit, self.voc, self.vocSize, self.SA, features = savedData[:6]\n        self.length = len(self.SA)\n\n        # determine token delimiter\n        if self.unit == UNIT_WORD:\n            self.tokSep = \" \"\n        elif self.unit in (UNIT_CHARACTER, UNIT_BYTE):\n            self.tokSep = \"\"\n        else:\n            raise Exception(\"Unknown unit type identifier:\", self.unit)\n\n        # recompute tokId based on voc\n        self.tokId = dict((char, iChar) for iChar, char in enumerate(self.voc))\n        self.nbSentences = self.string.count(self.tokId.get(\"\\n\", 0))\n\n        # Load features\n        self.features = []\n        for featureName, (featureValues, featureDefault) in zip(features, savedData[6:]):\n            self.addFeatureSA((lambda _: featureValues), name=featureName, default=featureDefault)\n\n        self.fromFileTime = _time() - start\n        if _trace: print >> _stderr, \"fromFileTime %.2fs\" % self.fromFileTime\n        return self", "response": "Load a suffix array instance from a file created by toFile."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _findOne(self, subString):\n        SA = self.SA\n        LCPs = self._LCP_values\n        string = self.string\n\n        try:\n            subString = _array(\"i\", [self.tokId[c] for c in self.tokenize(subString)])\n        except KeyError:\n            # if a token of the subString is not in the vocabulary\n            # the substring can't be in the string\n            return False\n        lenSubString = len(subString)\n\n        #################################\n        # Dichotomy search of subString #\n        #################################\n        lower = 0\n        upper = self.length\n        success = False\n\n        while upper - lower > 0:\n            middle = (lower + upper) // 2\n\n            middleSubString = string[SA[middle]:min(SA[middle] + lenSubString, self.length)]\n\n            # NOTE: the cmp function is removed in Python 3\n            # Strictly speaking we are doing one comparison more now\n            if subString < middleSubString:\n                upper = middle\n            elif subString > middleSubString:\n                lower = middle + 1\n            else:\n                success = True\n                break\n\n        if not success:\n            return False\n        else:\n            return middle", "response": "This method searches for a single entry in the string in the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef escape(s, quote=False):\n    if s is None:\n        return ''\n    elif hasattr(s, '__html__'):\n        return s.__html__()\n    elif not isinstance(s, basestring):\n        s = unicode(s)\n    s = s.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')\n    if quote:\n        s = s.replace('\"', \"&quot;\")\n    return s", "response": "Escape special characters &lt and < and > to HTML - safe sequences."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a new entry to the feed.", "response": "def add(self, *args, **kwargs):\n        \"\"\"Add a new entry to the feed.  This function can either be called\n        with a :class:`FeedEntry` or some keyword and positional arguments\n        that are forwarded to the :class:`FeedEntry` constructor.\n        \"\"\"\n        if len(args) == 1 and not kwargs and isinstance(args[0], FeedEntry):\n            self.entries.append(args[0])\n        else:\n            kwargs['feed_url'] = self.feed_url\n            kwargs['timezone'] = self.timezone\n            self.entries.append(FeedEntry(*args, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a generator that yields pieces of XML.", "response": "def generate(self):\n        \"\"\"Return a generator that yields pieces of XML.\"\"\"\n        # atom demands either an author element in every entry or a global one\n        if not self.author:\n            if False in map(lambda e: bool(e.author), self.entries):\n                self.author = ({'name': u'unbekannter Autor'},)\n\n        if not self.updated:\n            dates = sorted([entry.updated for entry in self.entries])\n            self.updated = dates and dates[-1] or datetime.utcnow()\n\n        yield u'<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n'\n        yield u'<feed xmlns=\"http://www.w3.org/2005/Atom\">\\n'\n        yield '  ' + _make_text_block('title', self.title, self.title_type)\n        yield u'  <id>%s</id>\\n' % escape(self.id)\n        yield u'  <updated>%s</updated>\\n' % format_iso8601(self.updated, self.timezone)\n        if self.url:\n            yield u'  <link href=\"%s\" />\\n' % escape(self.url, True)\n        if self.feed_url:\n            yield u'  <link href=\"%s\" rel=\"self\" />\\n' % \\\n                escape(self.feed_url, True)\n        for link in self.links:\n            yield u'  <link %s/>\\n' % ''.join('%s=\"%s\" ' % \\\n                (k, escape(link[k], True)) for k in link)\n        for author in self.author:\n            yield u'  <author>\\n'\n            yield u'    <name>%s</name>\\n' % escape(author['name'])\n            if 'uri' in author:\n                yield u'    <uri>%s</uri>\\n' % escape(author['uri'])\n            if 'email' in author:\n                yield '    <email>%s</email>\\n' % escape(author['email'])\n            yield '  </author>\\n'\n        if self.subtitle:\n            yield '  ' + _make_text_block('subtitle', self.subtitle,\n                                          self.subtitle_type)\n        if self.icon:\n            yield u'  <icon>%s</icon>\\n' % escape(self.icon)\n        if self.logo:\n            yield u'  <logo>%s</logo>\\n' % escape(self.logo)\n        if self.rights:\n            yield '  ' + _make_text_block('rights', self.rights,\n                                          self.rights_type)\n        generator_name, generator_url, generator_version = self.generator\n        if generator_name or generator_url or generator_version:\n            tmp = [u'  <generator']\n            if generator_url:\n                tmp.append(u' uri=\"%s\"' % escape(generator_url, True))\n            if generator_version:\n                tmp.append(u' version=\"%s\"' % escape(generator_version, True))\n            tmp.append(u'>%s</generator>\\n' % escape(generator_name))\n            yield u''.join(tmp)\n        for entry in self.entries:\n            for line in entry.generate():\n                yield u'  ' + line\n        yield u'</feed>\\n'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding pieces of ATOM XML.", "response": "def generate(self):\n        \"\"\"Yields pieces of ATOM XML.\"\"\"\n        base = ''\n        if self.xml_base:\n            base = ' xml:base=\"%s\"' % escape(self.xml_base, True)\n        yield u'<entry%s>\\n' % base\n        yield u'  ' + _make_text_block('title', self.title, self.title_type)\n        yield u'  <id>%s</id>\\n' % escape(self.id)\n        yield u'  <updated>%s</updated>\\n' % format_iso8601(self.updated, self.timezone)\n        if self.published:\n            yield u'  <published>%s</published>\\n' % \\\n                  format_iso8601(self.published, self.timezone)\n        if self.url:\n            yield u'  <link href=\"%s\" />\\n' % escape(self.url)\n        for author in self.author:\n            yield u'  <author>\\n'\n            yield u'    <name>%s</name>\\n' % escape(author['name'])\n            if 'uri' in author:\n                yield u'    <uri>%s</uri>\\n' % escape(author['uri'])\n            if 'email' in author:\n                yield u'    <email>%s</email>\\n' % escape(author['email'])\n            yield u'  </author>\\n'\n        for link in self.links:\n            yield u'  <link %s/>\\n' % ''.join('%s=\"%s\" ' % \\\n                (k, escape(link[k], True)) for k in link)\n        if self.summary:\n            yield u'  ' + _make_text_block('summary', self.summary,\n                                           self.summary_type)\n        if self.content:\n            if issubclass(self.content.__class__, dict):\n                if \"content\" in self.content:\n                    yield u'  <content %s>%s</content>\\n' % (' '.join('%s=\"%s\"' % \\\n                        (k, escape(self.content[k], True)) for k in self.content if k != \"content\"), escape(self.content[\"content\"]))\n                else:\n                    yield u'  <content %s/>\\n' % ' '.join('%s=\"%s\" ' % \\\n                        (k, escape(self.content[k], True)) for k in self.content)\n            else:\n                yield u'  ' + _make_text_block('content', self.content,\n                                           self.content_type)\n        yield u'</entry>\\n'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef serialize(value, field):\n    assert isinstance(field, forms.Field)\n    if isinstance(field, forms.ModelMultipleChoiceField):\n        return json.dumps([v.pk for v in value])\n    # todo: remove\n    if isinstance(value, models.Model):\n        return value.pk\n    return value", "response": "Serialize a value into a form value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_version(package):\n    with io.open(os.path.join(BASE_DIR, package, '__init__.py'), encoding='utf-8') as fh:\n        return [\n            l.split('=', 1)[1].strip().strip(\"'\").strip('\"')\n            for l in fh.readlines()\n            if '__version__' in l][0]", "response": "Get version without importing the lib"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_backend():\n    # Django 1.10 does not allow\n    # both settings to be set\n    middleware = set(\n        getattr(settings, 'MIDDLEWARE', None) or\n        getattr(settings, 'MIDDLEWARE_CLASSES', None) or\n        [])\n\n    # Deprecated alias\n    if \"djconfig.middleware.DjConfigLocMemMiddleware\" in middleware:\n        return\n\n    if \"djconfig.middleware.DjConfigMiddleware\" in middleware:\n        return\n\n    raise ValueError(\n        \"djconfig.middleware.DjConfigMiddleware \"\n        \"is required but it was not found in \"\n        \"MIDDLEWARE_CLASSES nor in MIDDLEWARE\")", "response": "Check that the backend is valid."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister a config form into the registry.", "response": "def _register(self, form_class, check_middleware=True):\n        \"\"\"\n        Register a config form into the registry\n\n        :param object form_class: The form class to register.\\\n        Must be an instance of :py:class:`djconfig.forms.ConfigForm`\n        :param bool check_middleware: Check\\\n        :py:class:`djconfig.middleware.DjConfigMiddleware`\\\n        is registered into ``settings.MIDDLEWARE_CLASSES``. Default True\n        \"\"\"\n        if not issubclass(form_class, _ConfigFormBase):\n            raise ValueError(\n                \"The form does not inherit from `forms.ConfigForm`\")\n\n        self._registry.add(form_class)\n\n        if check_middleware:\n            _check_backend()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _reload(self):\n        ConfigModel = apps.get_model('djconfig.Config')\n        cache = {}\n        data = dict(\n            ConfigModel.objects\n                .all()\n                .values_list('key', 'value'))\n\n        # populate cache with initial form values,\n        # then with cleaned database values,\n        # then with raw database file/image paths\n        for form_class in self._registry:\n            empty_form = form_class()\n            cache.update({\n                name: field.initial\n                for name, field in empty_form.fields.items()})\n            form = form_class(data={\n                name: _deserialize(data[name], field)\n                for name, field in empty_form.fields.items()\n                if name in data and not isinstance(field, forms.FileField)})\n            form.is_valid()\n            cache.update({\n                name: _unlazify(value)\n                for name, value in form.cleaned_data.items()\n                if name in data})\n            # files are special because they don't have an initial value\n            # and the POSTED data must contain the file. So, we keep\n            # the stored path as is\n            # TODO: see if serialize/deserialize/unlazify can be used for this instead\n            cache.update({\n                name: data[name]\n                for name, field in empty_form.fields.items()\n                if name in data and isinstance(field, forms.FileField)})\n\n        cache['_updated_at'] = data.get('_updated_at')\n        self._cache = cache", "response": "Reloads the cache with the current values from the database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _reload_maybe(self):\n        ConfigModel = apps.get_model('djconfig.Config')\n\n        data = dict(\n            ConfigModel.objects\n                .filter(key='_updated_at')\n                .values_list('key', 'value'))\n\n        if (not hasattr(self, '_updated_at') or\n                self._updated_at != data.get('_updated_at')):\n            self._reload()", "response": "Reload the config if the config \\\nMimeType model has been updated."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave the config with the cleaned data.", "response": "def save(self):\n        \"\"\"\n        Save the config with the cleaned data,\\\n        update the last modified date so\\\n        the config is reloaded on other process/nodes.\\\n        Reload the config so it can be called right away.\n        \"\"\"\n        assert self.__class__ in conf.config._registry,\\\n            '%(class_name)s is not registered' % {\n                'class_name': self.__class__.__name__\n            }\n\n        ConfigModel = apps.get_model('djconfig.Config')\n\n        for field_name, value in self.cleaned_data.items():\n            value = utils.serialize(\n                value=value,\n                field=self.fields.get(field_name, None))\n            # TODO: use update_or_create\n            count = (ConfigModel.objects\n                .filter(key=field_name)\n                .update(value=value))\n            if not count:\n                ConfigModel.objects.create(\n                    key=field_name,\n                    value=value)\n\n        count = (ConfigModel.objects\n            .filter(key='_updated_at')\n            .update(value=str(timezone.now())))\n        if not count:\n            ConfigModel.objects.create(\n                key='_updated_at',\n                value=str(timezone.now()))\n\n        conf.config._reload()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a new admin section.", "response": "def register(conf, conf_admin, **options):\n    \"\"\"\n    Register a new admin section.\n\n    :param conf: A subclass of ``djconfig.admin.Config``\n    :param conf_admin: A subclass of ``djconfig.admin.ConfigAdmin``\n    :param options: Extra options passed to ``django.contrib.admin.site.register``\n    \"\"\"\n    assert issubclass(conf_admin, ConfigAdmin), (\n        'conf_admin is not a ConfigAdmin subclass')\n    assert issubclass(\n        getattr(conf_admin, 'change_list_form', None),\n        ConfigForm), 'No change_list_form set'\n    assert issubclass(conf, Config), (\n        'conf is not a Config subclass')\n    assert conf.app_label, 'No app_label set'\n    assert conf.verbose_name_plural, 'No verbose_name_plural set'\n    assert not conf.name or re.match(r\"^[a-zA-Z_]+$\", conf.name), (\n        'Not a valid name. Valid chars are [a-zA-Z_]')\n    config_class = type(\"Config\", (), {})\n    config_class._meta = type(\"Meta\", (_ConfigMeta,), {\n        'app_label': conf.app_label,\n        'verbose_name_plural': conf.verbose_name_plural,\n        'object_name': 'Config',\n        'model_name': conf.name,\n        'module_name': conf.name})\n    admin.site.register([config_class], conf_admin, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmix type is used to indicate a field in a schema.", "response": "def Mixed(*types):\n    \"\"\"Mixed type, used to indicate a field in a schema can be\n    one of many types. Use as a last resort only.\n    The Mixed type can be used directly as a class to indicate\n    any type is permitted for a given field:\n    `\"my_field\": {\"type\": Mixed}`\n    It can also be instantiated with list of specific types the\n    field may is allowed to be for more control:\n    `\"my_field\": {\"type\": Mixed(ObjectId, int)}`\n    \"\"\"\n    if len(types) < 2:\n        raise ValueError(\"Mixed type requires at least 2 specific types\")\n\n    types = set(types) # dedupe\n\n    class MixedType(type):\n        def __instancecheck__(cls, instance):\n            \"\"\"Returns true if the given value is an instance of\n            one of the types enclosed by this mixed type.\"\"\"\n            for mtype in types:\n                if isinstance(instance, mtype):\n                    return True\n            return False\n\n    class Mixed(object):\n        __metaclass__ = MixedType\n\n    return Mixed"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating that a field value matches one of the values AttributeNames given to this validator.", "response": "def one_of(*args):\n    \"\"\"\n    Validates that a field value matches one of the values\n    given to this validator.\n    \"\"\"\n    if len(args) == 1 and isinstance(args[0], list):\n        items = args[0]\n    else:\n        items = list(args)\n\n    def validate(value):\n        if not value in items:\n            return e(\"{} is not in the list {}\", value, items)\n    return validate"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a validator that checks that a field value is greater than or equal to the given value.", "response": "def gte(min_value):\n    \"\"\"\n    Validates that a field value is greater than or equal to the\n    value given to this validator.\n    \"\"\"\n    def validate(value):\n        if value < min_value:\n            return e(\"{} is not greater than or equal to {}\", value, min_value)\n    return validate"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a validator that checks that a field value is less than or equal to the max_value given to this validator.", "response": "def lte(max_value):\n    \"\"\"\n    Validates that a field value is less than or equal to the\n    value given to this validator.\n    \"\"\"\n    def validate(value):\n        if value > max_value:\n            return e(\"{} is not less than or equal to {}\", value, max_value)\n    return validate"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gt(gt_value):\n    def validate(value):\n        if value <= gt_value:\n            return e(\"{} is not greater than {}\", value, gt_value)\n    return validate", "response": "Returns a validator that checks that a field value is greater than the given value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a validator that checks that a field value is less than the given value.", "response": "def lt(lt_value):\n    \"\"\"\n    Validates that a field value is less than the\n    value given to this validator.\n    \"\"\"\n    def validate(value):\n        if value >= lt_value:\n            return e(\"{} is not less than {}\", value, lt_value)\n    return validate"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef between(min_value, max_value):\n    def validate(value):\n        if value < min_value:\n            return e(\"{} is not greater than or equal to {}\",\n                value, min_value)\n        if value > max_value:\n            return e(\"{} is not less than or equal to {}\",\n                value, max_value)\n    return validate", "response": "Validates that a field value is between the two values\n articles."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef length(min=None, max=None):\n\n    def validate(value):\n        if min and len(value) < min:\n            return e(\"{} does not have a length of at least {}\", value, min)\n        if max and len(value) > max:\n            return e(\"{} does not have a length of at most {}\", value, max)\n    return validate", "response": "Validates that a field value s length is between the bounds given to this\n    validator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating that a field value matches the regex pattern", "response": "def match(pattern):\n    \"\"\"\n    Validates that a field value matches the regex given to this validator.\n    \"\"\"\n    regex = re.compile(pattern)\n\n    def validate(value):\n        if not regex.match(value):\n            return e(\"{} does not match the pattern {}\", value, pattern)\n    return validate"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating that a value is a valid email address.", "response": "def is_email():\n    \"\"\"\n    Validates that a fields value is a valid email address.\n    \"\"\"\n\n    email = (\n        ur'(?!^\\.)'     # No dot at start\n        ur'(?!.*\\.@)'   # No dot before at sign\n        ur'(?!.*@\\.)'   # No dot after at sign\n        ur'(?!.*\\.$)'   # No dot at the end\n        ur'(?!.*\\.\\.)'  # No double dots anywhere\n        ur'^\\S+'        # Starts with one or more non-whitespace characters\n        ur'@'           # Contains an at sign\n        ur'\\S+$'        # Ends with one or more non-whitespace characters\n    )\n\n    regex = re.compile(email, re.IGNORECASE | re.UNICODE)\n\n    def validate(value):\n        if not regex.match(value):\n            return e(\"{} is not a valid email address\", value)\n    return validate"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_url():\n    # Stolen from Django\n    regex = re.compile(\n        r'^(?:http|ftp)s?://' # http:// or https://\n        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' #domain...\n        r'localhost|' #localhost...\n        r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip\n        r'(?::\\d+)?' # optional port\n        r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n\n    def validate(value):\n        if not regex.match(value):\n            return e(\"{} is not a valid URL\", value)\n    return validate", "response": "Validates that a fields value is a valid URL."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef distinct():\n    def validate(value):\n        for i, item in enumerate(value):\n            if item in value[i+1:]:\n                return e(\"{} is not a distinct set of values\", value)\n    return validate", "response": "Validates that all items in the given field list value are distinct"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply the defaults described by this schema to the given articles document instance as appropriate.", "response": "def apply_defaults(self, instance):\n        \"\"\"Applies the defaults described by the this schema to the given\n        document instance as appropriate. Defaults are only applied to\n        fields which are currently unset.\"\"\"\n        for field, spec in self.doc_spec.iteritems():\n            field_type = spec['type']\n            if field not in instance:\n                if 'default' in spec:\n                    default = spec['default']\n                    if callable(default):\n                        instance[field] = default()\n                    else:\n                        instance[field] = copy.deepcopy(default)\n            # Determine if a value already exists for the field\n            if field in instance:\n                value = instance[field]\n\n                # recurse into nested docs\n                if isinstance(field_type, Schema) and isinstance(value, dict):\n                    field_type.apply_defaults(value)\n\n                elif isinstance(field_type, Array) and isinstance(field_type.contained_type, Schema) and isinstance(value, list):\n                    for item in value:\n                        field_type.contained_type.apply_defaults(item)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate(self, instance):\n        errors = {}\n        self._validate_instance(instance, errors)\n\n        if len(errors) > 0:\n            raise ValidationException(errors)", "response": "Validates the given document against this schema. Raises ValidationException if there are any failures."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _verify(self, path_prefix=None):\n        for field, spec in self.doc_spec.iteritems():\n            path = self._append_path(path_prefix, field)\n\n            # Standard dict-based spec\n            if isinstance(spec, dict):\n                self._verify_field_spec(spec, path)\n            else:\n                raise SchemaFormatException(\"Invalid field definition for {}\", path)", "response": "Verifies that this schema s doc spec is valid and makes sense."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nverifies a given field specification is valid recursing into nested schemas if required.", "response": "def _verify_field_spec(self, spec, path):\n        \"\"\"Verifies a given field specification is valid, recursing into nested schemas if required.\"\"\"\n\n        # Required should be a boolean\n        if 'required' in spec and not isinstance(spec['required'], bool):\n            raise SchemaFormatException(\"{} required declaration should be True or False\", path)\n\n        # Required should be a boolean\n        if 'nullable' in spec and not isinstance(spec['nullable'], bool):\n            raise SchemaFormatException(\"{} nullable declaration should be True or False\", path)\n\n        # Must have a type specified\n        if 'type' not in spec:\n            raise SchemaFormatException(\"{} has no type declared.\", path)\n\n        self._verify_type(spec, path)\n\n        # Validations should be either a single function or array of functions\n        if 'validates' in spec:\n            self._verify_validates(spec, path)\n\n        # Defaults must be of the correct type or a function\n        if 'default' in spec:\n            self._verify_default(spec, path)\n\n        # Only expected spec keys are supported\n        if not set(spec.keys()).issubset(set(['type', 'required', 'validates', 'default', 'nullable'])):\n            raise SchemaFormatException(\"Unsupported field spec item at {}. Items: \"+repr(spec.keys()), path)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _verify_type(self, spec, path):\n        field_type = spec['type']\n\n        if isinstance(field_type, Schema):\n            # Nested documents cannot have validation\n            if not set(spec.keys()).issubset(set(['type', 'required', 'nullable', 'default'])):\n                raise SchemaFormatException(\"Unsupported field spec item at {}. Items: \"+repr(spec.keys()), path)\n            return\n\n        elif isinstance(field_type, Array):\n            if not isinstance(field_type.contained_type, (type, Schema, Array, types.FunctionType)):\n                raise SchemaFormatException(\"Unsupported field type contained by Array at {}.\", path)\n\n        elif not isinstance(field_type, type) and not isinstance(field_type, types.FunctionType):\n            raise SchemaFormatException(\"Unsupported field type at {}. Type must be a type, a function, an Array or another Schema\", path)", "response": "Verify that the type in the spec is valid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _verify_default(self, spec, path):\n        field_type = spec['type']\n        default = spec['default']\n\n        # If it's a function there's nothing we can really do except assume its valid\n        if callable(default):\n            return\n\n        if isinstance(field_type, Array):\n            # Verify we'd got a list as our default\n            if not isinstance(default, list):\n                raise SchemaFormatException(\"Default value for Array at {} is not a list of values.\", path)\n\n            # Ensure the contents are of the correct type\n            for i, item in enumerate(default):\n                if isinstance(field_type.contained_type, Schema):\n                    if not self._valid_schema_default(item):\n                        raise SchemaFormatException(\"Default value for Schema is not valid.\", path)\n                elif not isinstance(item, field_type.contained_type):\n                        raise SchemaFormatException(\"Not all items in the default list for the Array field at {} are of the correct type.\", path)\n\n        elif isinstance(field_type, Schema):\n            if not self._valid_schema_default(default):\n                raise SchemaFormatException(\"Default value for Schema is not valid.\", path)\n\n        else:\n            if not isinstance(default, field_type):\n                raise SchemaFormatException(\"Default value for {} is not of the nominated type.\", path)", "response": "Verifies that the default value specified in the given spec is valid."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _verify_validates(self, spec, path):\n        validates = spec['validates']\n\n        if isinstance(validates, list):\n            for validator in validates:\n                self._verify_validator(validator, path)\n        else:\n            self._verify_validator(validates, path)", "response": "Verify thats the validates argument is valid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _verify_validator(self, validator, path):\n\n        # Validator should be a function\n        if not callable(validator):\n            raise SchemaFormatException(\"Invalid validations for {}\", path)\n\n        # Validator should accept a single argument\n        (args, varargs, keywords, defaults) = getargspec(validator)\n        if len(args) != 1:\n            raise SchemaFormatException(\"Invalid validations for {}\", path)", "response": "Verifies that a given validator associated with the field at the given path is legitimate."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _validate_instance(self, instance, errors, path_prefix=''):\n\n        if not isinstance(instance, dict):\n            errors[path_prefix] = \"Expected instance of dict to validate against schema.\"\n            return\n\n        # validate against the schema level validators\n        self._apply_validations(errors, path_prefix, self._validates, instance)\n\n        # Loop over each field in the schema and check the instance value conforms\n        # to its spec\n        for field, spec in self.doc_spec.iteritems():\n            path = self._append_path(path_prefix, field)\n\n            # If the field is present, validate it's value.\n            if field in instance:\n                self._validate_value(instance[field], spec, path, errors)\n            else:\n                # If not, add an error if it was a required key.\n                if spec.get('required', False):\n                    errors[path] = \"{} is required.\".format(path)\n\n        # Now loop over each field in the given instance and make sure we don't\n        # have any fields not declared in the schema, unless strict mode has been\n        # explicitly disabled.\n        if self._strict:\n            for field in instance:\n                if field not in self.doc_spec:\n                    errors[self._append_path(path_prefix, field)] = \"Unexpected document field not present in schema\"", "response": "Validates that the given instance of a document conforms to the given schema s base - schema and validations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating that the given value is valid given the associated field spec and path. Any validation failures are added to the given errors collection.", "response": "def _validate_value(self, value, field_spec, path, errors):\n        \"\"\"Validates that the given field value is valid given the associated\n        field spec and path. Any validation failures are added to the given errors\n        collection.\"\"\"\n\n        # Check if the value is None and add an error if the field is not nullable.\n        # Note that for backward compatibility reasons, the default value of 'nullable'\n        # is the inverse of 'required' (which use to mean both that the key be present\n        # and not set to None).\n        if value is None:\n            if not field_spec.get('nullable', not field_spec.get('required', False)):\n                errors[path] = \"{} is not nullable.\".format(path)\n            return\n\n        # All fields should have a type\n        field_type = field_spec['type']\n        if isinstance(field_type, types.FunctionType):\n            try:\n                field_type = field_type(value)\n            except Exception as e:\n                raise SchemaFormatException(\"Dynamic schema function raised exception: {}\".format(str(e)), path)\n            if not isinstance(field_type, (type, Schema, Array)):\n                raise SchemaFormatException(\"Dynamic schema function did not return a type at path {}\", path)\n\n\n        # If our field is an embedded document, recurse into it\n        if isinstance(field_type, Schema):\n            if isinstance(value, dict):\n                field_type._validate_instance(value, errors, path)\n            else:\n                errors[path] = \"{} should be an embedded document\".format(path)\n            return\n\n        elif isinstance(field_type, Array):\n            if isinstance(value, list):\n                is_dynamic = isinstance(field_type.contained_type, types.FunctionType)\n                for i, item in enumerate(value):\n                    contained_type = field_type.contained_type\n                    if is_dynamic:\n                        contained_type = contained_type(item)\n                    instance_path = self._append_path(path, i)\n                    if isinstance(contained_type, Schema):\n                        contained_type._validate_instance(item, errors, instance_path)\n                    elif not isinstance(item, contained_type):\n                        errors[instance_path] = \"Array item at {} is of incorrect type\".format(instance_path)\n                        continue\n            else:\n                errors[path] = \"{} should be an embedded array\".format(path)\n                return\n\n        elif not isinstance(value, field_type):\n            errors[path] = \"Field should be of type {}\".format(field_type)\n            return\n\n        validations = field_spec.get('validates', None)\n        if validations is None:\n            return\n        self._apply_validations(errors, path, validations, value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_config(path=None, defaults=None):\n\n    if defaults is None:\n        defaults = DEFAULT_FILES\n\n    config = ConfigParser(allow_no_value=True)\n\n    if defaults:\n        config.read(defaults)\n\n    if path:\n        with open(path) as fh:\n            config.read_file(fh)\n\n    return config", "response": "Loads and parses an INI style configuration file using Python s built - in\n    configparser module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a ConfigParser object into a dictionary.", "response": "def as_dict(config):\n    \"\"\"\n    Converts a ConfigParser object into a dictionary.\n\n    The resulting dictionary has sections as keys which point to a dict of the\n    sections options as key => value pairs.\n    \"\"\"\n    settings = defaultdict(lambda: {})\n    for section in config.sections():\n        for key, val in config.items(section):\n            settings[section][key] = val\n    return settings"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef initialize(self, timeouts):\n\n        # Bind or connect to address\n        if self.bind is True:\n            self.socket.bind(self.address)\n        else:\n            self.socket.connect(self.address)\n\n        # Set send and recv timeouts\n        self._set_timeouts(timeouts)", "response": "Bind or connect the nanomsg socket to some address"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_timeouts(self, timeouts):\n\n        (send_timeout, recv_timeout) = (None, None)\n\n        try:\n            (send_timeout, recv_timeout) = timeouts\n        except TypeError:\n            raise EndpointError(\n                '`timeouts` must be a pair of numbers (2, 3) which represent '\n                'the timeout values for send and receive respectively')\n\n        if send_timeout is not None:\n            self.socket.set_int_option(\n                nanomsg.SOL_SOCKET, nanomsg.SNDTIMEO, send_timeout)\n\n        if recv_timeout is not None:\n            self.socket.set_int_option(\n                nanomsg.SOL_SOCKET, nanomsg.RCVTIMEO, recv_timeout)", "response": "Sets socket timeouts for send and receive respectively"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nencoding and sign the payload through the socket", "response": "def send(self, payload):\n        \"\"\" Encode and sign (optional) the send through socket \"\"\"\n        payload = self.encode(payload)\n        payload = self.sign(payload)\n        self.socket.send(payload)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreceive from socket authenticate and decode payload", "response": "def receive(self, decode=True):\n        \"\"\" Receive from socket, authenticate and decode payload \"\"\"\n        payload = self.socket.recv()\n        payload = self.verify(payload)\n        if decode:\n            payload = self.decode(payload)\n        return payload"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsign the payload using the authenticator", "response": "def sign(self, payload):\n        \"\"\" Sign payload using the supplied authenticator \"\"\"\n        if self.authenticator:\n            return self.authenticator.signed(payload)\n        return payload"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef verify(self, payload):\n        if not self.authenticator:\n            return payload\n        try:\n            self.authenticator.auth(payload)\n            return self.authenticator.unsigned(payload)\n        except AuthenticatorInvalidSignature:\n            raise\n        except Exception as exception:\n            raise AuthenticateError(str(exception))", "response": "Verify the authenticity of the payload."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef encode(self, payload):\n        try:\n            return self.encoder.encode(payload)\n        except Exception as exception:\n            raise EncodeError(str(exception))", "response": "Encode a single object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start(self):\n\n        if threading.current_thread().name == 'MainThread':\n            signal.signal(signal.SIGINT, self.stop)\n\n        logging.info('Started on {}'.format(self.address))\n\n        while True:\n            self.process()", "response": "Start and listen for calls"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stop(self, dummy_signum=None, dummy_frame=None):\n        logging.info('Shutting down ...')\n        self.socket.close()\n        sys.exit(0)", "response": "Shutdown process (this method is also a signal handler)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsummarizing the report data @param list_all: a list which save the report data @param kwargs: such as show_all: True/False report show all status cases proj_name: project name home_page: home page url", "response": "def get_summary(list_all=[], **kwargs):\r\n        ''' summarize the report data\r\n            @param list_all: a list which save the report data\r\n            @param kwargs: such as\r\n                show_all:    True/False   report show all status cases\r\n                proj_name:   project name \r\n                home_page:   home page url\r\n        \r\n        '''\r\n        all_summary = []\r\n               \r\n        for module in list_all:\r\n            summary = {\r\n                        \"module_name\" : module['Name'],\r\n                        \"show_all\" : kwargs.get(\"show_all\",True),\r\n                        \"project_name\" : kwargs.get(\"proj_name\",\"TestProject\"),\r\n                        \"home_page\" : kwargs.get(\"home_page\",__about__.HOME_PAGE),\r\n                        \"start_time\" : \"\",\r\n                        \"end_time\" : \"\",\r\n                        \"duration_seconds\" : \"\",\r\n                        \"total_case_num\" : len(module[\"TestCases\"]),\r\n                        \"pass_cases_num\" : 0,\r\n                        \"fail_cases_num\" : 0,\r\n                        \"details\" : []\r\n                    }\r\n                         \r\n            for case in module[\"TestCases\"]:\r\n                case_detail = {}\r\n                case_detail[\"linkurl\"] =  \"./caselogs/%s_%s.log\" %(case[\"case_name\"],case[\"exec_date\"])\r\n                \r\n                if case[\"status\"].lower() == \"pass\":\r\n                    summary[\"pass_cases_num\"] += 1\r\n                    case_detail[\"c_style\"] = \"tr_pass\"\r\n                else:\r\n                    summary[\"fail_cases_num\"] += 1\r\n                    case_detail[\"c_style\"] = \"tr_fail\"\r\n                \r\n                case_detail.update(case)\r\n            \r\n                summary[\"details\"].append(case_detail)                       \r\n             \r\n            try:\r\n                st = module[\"TestCases\"][0].get(\"start_at\")\r\n                et = module[\"TestCases\"][-1].get(\"end_at\")\r\n                \r\n                summary[\"start_time\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(st))    \r\n                summary[\"end_time\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(et))        \r\n                summary[\"duration_seconds\"] = float(\"%.2f\" %(et - st))\r\n            except Exception as _:\r\n                logger.log_warning(\"Will set 'start_at' and 'end_at' to 'None'\")\r\n                (summary[\"start_time\"], summary[\"end_time\"], summary[\"duration_seconds\"]) = (None,None,None)\r\n                    \r\n            if summary[\"fail_cases_num\"] > 0:\r\n                summary[\"dict_report\"] = {\"result\":0,\"message\":\"failure\",\"pass\":summary[\"pass_cases_num\"],\"fail\":summary[\"fail_cases_num\"]}\r\n            else:\r\n                summary[\"dict_report\"] = {\"result\":1,\"message\":\"success\",\"pass\":summary[\"pass_cases_num\"],\"fail\":summary[\"fail_cases_num\"]}\r\n             \r\n            all_summary.append(summary)\r\n            \r\n        return all_summary"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding report data to a list of all test set items", "response": "def add_report_data(list_all=[], module_name=\"TestModule\", **kwargs):\r\n        ''' add report data to a list\r\n            @param list_all: a list which save the report data\r\n            @param module_name: test set name or test module name\r\n            @param kwargs: such as\r\n                case_name:   testcase name\r\n                status:      test result, Pass or Fail\r\n                resp_tester: responsible tester who write this case\r\n                tester:      tester who execute the test\r\n                start_at:    tester run this case at time \r\n                end_at:      tester stop this case at time\r\n        '''\r\n        start_at = kwargs.get(\"start_at\")        \r\n        case_name = kwargs.get(\"case_name\",\"TestCase\")\r\n        raw_case_name = kwargs.get(\"raw_case_name\",\"TestCase\")\r\n                \r\n        exec_date_time = time.localtime(start_at)\r\n        execdate = time.strftime(\"%Y-%m-%d\",exec_date_time) \r\n        exectime = time.strftime(\"%H:%M:%S\",exec_date_time)\r\n        \r\n        _case_report = {\r\n                'resp_tester': kwargs.get(\"resp_tester\",\"administrator\"),\r\n                'tester': kwargs.get(\"tester\",\"administrator\"),\r\n                'case_name': case_name,\r\n                'raw_case_name': raw_case_name,\r\n                'status': kwargs.get(\"status\",\"Pass\"),\r\n                'exec_date': execdate,\r\n                'exec_time': exectime,\r\n                'start_at': start_at,\r\n                'end_at': kwargs.get(\"end_at\"),\r\n            }\r\n                \r\n        for module in list_all:\r\n            if module_name != module[\"Name\"]:\r\n                continue\r\n            \r\n            for case in module[\"TestCases\"]:\r\n                if raw_case_name == case[\"raw_case_name\"]:\r\n                    case.update(_case_report)\r\n                    return list_all\r\n            \r\n            module[\"TestCases\"].append(_case_report)\r\n            return list_all\r\n        \r\n        list_all.append({\"Name\": module_name, \"TestCases\": [_case_report]})\r\n        return list_all"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(self, subscription):\n\n        for name in self.methods:\n            tag = bytes(name.encode('utf-8'))\n            if subscription.startswith(tag):\n                fun = self.methods.get(name)\n                message = subscription[len(tag):]\n                return tag, message, fun\n        return None, None, None", "response": "Parse a given subscription into a tuple of tag message and function ID"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsubscribing to something and register a function", "response": "def subscribe(self, tag, fun, description=None):\n        \"\"\" Subscribe to something and register a function \"\"\"\n        self.methods[tag] = fun\n        self.descriptions[tag] = description\n        self.socket.set_string_option(nanomsg.SUB, nanomsg.SUB_SUBSCRIBE, tag)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process(self):\n\n        subscription = None\n        result = None\n\n        try:\n            subscription = self.socket.recv()\n\n        except AuthenticateError as exception:\n            logging.error(\n                'Subscriber error while authenticating request: {}'\n                .format(exception), exc_info=1)\n\n        except AuthenticatorInvalidSignature as exception:\n            logging.error(\n                'Subscriber error while authenticating request: {}'\n                .format(exception), exc_info=1)\n\n        except DecodeError as exception:\n            logging.error(\n                'Subscriber error while decoding request: {}'\n                .format(exception), exc_info=1)\n\n        except RequestParseError as exception:\n            logging.error(\n                'Subscriber error while parsing request: {}'\n                .format(exception), exc_info=1)\n\n        else:\n            logging.debug(\n                'Subscriber received payload: {}'\n                .format(subscription))\n\n        _tag, message, fun = self.parse(subscription)\n        message = self.verify(message)\n        message = self.decode(message)\n\n        try:\n            result = fun(message)\n        except Exception as exception:\n            logging.error(exception, exc_info=1)\n\n        # Return result to check successful execution of `fun` when testing\n        return result", "response": "Receive a subscription from the socket and process it"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_payload(self, tag, message):\n        message = self.encode(message)\n        message = self.sign(message)\n        payload = bytes(tag.encode('utf-8')) + message\n        return payload", "response": "Builds the payload for the subscription"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef publish(self, tag, message):\n        payload = self.build_payload(tag, message)\n        self.socket.send(payload)", "response": "Publish a message down the socket"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts a new subscriber service", "response": "def start_service(addr, n, authenticator):\n    \"\"\" Start a service \"\"\"\n\n    s = Subscriber(addr, authenticator=authenticator)\n\n    def do_something(line):\n        pass\n\n    s.subscribe('test', do_something)\n\n    started = time.time()\n    for _ in range(n):\n        s.process()\n    s.socket.close()\n    duration = time.time() - started\n\n    print('Subscriber service stats:')\n    util.print_stats(n, duration)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a Webpack object for a given webpack config.", "response": "def get_webpack(request, name='DEFAULT'):\n    \"\"\"\n    Get the Webpack object for a given webpack config.\n\n    Called at most once per request per config name.\n    \"\"\"\n    if not hasattr(request, '_webpack_map'):\n        request._webpack_map = {}\n    wp = request._webpack_map.get(name)\n    if wp is None:\n        wp = request._webpack_map[name] = Webpack(request, name)\n    return wp"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef includeme(config):\n    settings = config.registry.settings\n    root_package_name = config.root_package.__name__\n    config.registry.webpack = {\n        'DEFAULT': WebpackState(settings, root_package_name)\n    }\n    for extra_config in aslist(settings.get('webpack.configs', [])):\n        state = WebpackState(settings, root_package_name, name=extra_config)\n        config.registry.webpack[extra_config] = state\n\n    # Set up any static views\n    for state in six.itervalues(config.registry.webpack):\n        if state.static_view:\n            config.add_static_view(name=state.static_view_name,\n                                   path=state.static_view_path,\n                                   cache_max_age=state.cache_max_age)\n\n    config.add_request_method(get_webpack, 'webpack')", "response": "Add pyramid_webpack methods and config to the app"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads and cache the webpack - stats file", "response": "def load_stats(self, cache=None, wait=None):\n        \"\"\" Load and cache the webpack-stats file \"\"\"\n        if cache is None:\n            cache = not self.debug\n        if wait is None:\n            wait = self.debug\n        if not cache or self._stats is None:\n            self._stats = self._load_stats()\n            start = time.time()\n            while wait and self._stats.get('status') == 'compiling':\n                if self.timeout and (time.time() - start > self.timeout):\n                    raise RuntimeError(\"Webpack {0!r} timed out while compiling\"\n                                       .format(self.stats_file.path))\n                time.sleep(0.1)\n                self._stats = self._load_stats()\n        return self._stats"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_stats(self):\n        for attempt in range(0, 3):\n            try:\n                with self.stats_file.open() as f:\n                    return json.load(f)\n            except ValueError:\n                # If we failed to parse the JSON, it's possible that the\n                # webpack process is writing to it concurrently and it's in a\n                # bad state. Sleep and retry.\n                if attempt < 2:\n                    time.sleep(attempt * 0.2)\n                else:\n                    raise\n            except IOError:\n                raise IOError(\n                    \"Could not read stats file {0}. Make sure you are using the \"\n                    \"webpack-bundle-tracker plugin\" .format(self.stats_file))", "response": "Load the webpack - stats file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _chunk_filter(self, extensions):\n        if isinstance(extensions, six.string_types):\n            extensions = extensions.split()\n\n        def _filter(chunk):\n            \"\"\" Exclusion filter \"\"\"\n            name = chunk['name']\n            if extensions is not None:\n                if not any(name.endswith(e) for e in extensions):\n                    return False\n            for pattern in self.state.ignore_re:\n                if pattern.match(name):\n                    return False\n            for pattern in self.state.ignore:\n                if fnmatch.fnmatchcase(name, pattern):\n                    return False\n            return True\n        return _filter", "response": "Create a filter from the extensions and ignore files"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_url(self, chunk):\n        if 'url' in chunk:\n            return chunk\n        public_path = chunk.get('publicPath')\n        if public_path:\n            chunk['url'] = public_path\n        else:\n            fullpath = posixpath.join(self.state.static_view_path,\n                                      chunk['name'])\n            chunk['url'] = self._request.static_url(fullpath)\n        return chunk", "response": "Add a url property to a chunk and return it"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_bundle(self, bundle_name, extensions=None):\n        if self.stats.get('status') == 'done':\n            bundle = self.stats.get('chunks', {}).get(bundle_name, None)\n            if bundle is None:\n                raise KeyError('No such bundle {0!r}.'.format(bundle_name))\n            test = self._chunk_filter(extensions)\n            return [self._add_url(c) for c in bundle if test(c)]\n        elif self.stats.get('status') == 'error':\n            raise RuntimeError(\"{error}: {message}\".format(**self.stats))\n        else:\n            raise RuntimeError(\n                \"Bad webpack stats file {0} status: {1!r}\"\n                .format(self.state.stats_file, self.stats.get('status')))", "response": "Get all the chunks contained in a bundle."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates unique names of bytes.", "response": "def _unique_names():\n    \"\"\"Generates unique sequences of bytes.\n    \"\"\"\n    characters = (\"abcdefghijklmnopqrstuvwxyz\"\n                  \"0123456789\")\n    characters = [characters[i:i + 1] for i in irange(len(characters))]\n    rng = random.Random()\n    while True:\n        letters = [rng.choice(characters) for i in irange(10)]\n        yield ''.join(letters)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nescapes the path to a queue e. g. preserves ~ at the begining.", "response": "def escape_queue(s):\n    \"\"\"Escapes the path to a queue, e.g. preserves ~ at the begining.\n    \"\"\"\n    if isinstance(s, PosixPath):\n        s = unicode_(s)\n    elif isinstance(s, bytes):\n        s = s.decode('utf-8')\n    if s.startswith('~/'):\n        return '~/' + shell_escape(s[2:])\n    else:\n        return shell_escape(s)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_ssh_destination(destination):\n    match = _re_ssh.match(destination)\n    if not match:\n        raise InvalidDestination(\"Invalid destination: %s\" % destination)\n    user, password, host, port = match.groups()\n    info = {}\n    if user:\n        info['username'] = user\n    else:\n        info['username'] = getpass.getuser()\n    if password:\n        info['password'] = password\n    if port:\n        info['port'] = int(port)\n    info['hostname'] = host\n\n    return info", "response": "Parses the SSH destination argument."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting an SSH client to connect with.", "response": "def _ssh_client(self):\n        \"\"\"Gets an SSH client to connect with.\n        \"\"\"\n        ssh = paramiko.SSHClient()\n        ssh.load_system_host_keys()\n        ssh.set_missing_host_key_policy(paramiko.RejectPolicy())\n        return ssh"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the SSH client.", "response": "def get_client(self):\n        \"\"\"Gets the SSH client.\n\n        This will check that the connection is still alive first, and reconnect\n        if necessary.\n        \"\"\"\n        if self._ssh is None:\n            self._connect()\n            return self._ssh\n        else:\n            try:\n                chan = self._ssh.get_transport().open_session()\n            except (socket.error, paramiko.SSHException):\n                logger.warning(\"Lost connection, reconnecting...\")\n                self._ssh.close()\n                self._connect()\n            else:\n                chan.close()\n            return self._ssh"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling a command through the SSH connection and returns the exit status and output.", "response": "def _call(self, cmd, get_output):\n        \"\"\"Calls a command through the SSH connection.\n\n        Remote stderr gets printed to this program's stderr. Output is captured\n        and may be returned.\n        \"\"\"\n        server_err = self.server_logger()\n\n        chan = self.get_client().get_transport().open_session()\n        try:\n            logger.debug(\"Invoking %r%s\",\n                         cmd, \" (stdout)\" if get_output else \"\")\n            chan.exec_command('/bin/sh -c %s' % shell_escape(cmd))\n            output = b''\n            while True:\n                r, w, e = select.select([chan], [], [])\n                if chan not in r:\n                    continue  # pragma: no cover\n                recvd = False\n                while chan.recv_stderr_ready():\n                    data = chan.recv_stderr(1024)\n                    server_err.append(data)\n                    recvd = True\n                while chan.recv_ready():\n                    data = chan.recv(1024)\n                    if get_output:\n                        output += data\n                    recvd = True\n                if not recvd and chan.exit_status_ready():\n                    break\n            output = output.rstrip(b'\\r\\n')\n            return chan.recv_exit_status(), output\n        finally:\n            server_err.done()\n            chan.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_call(self, cmd):\n        ret, _ = self._call(cmd, False)\n        if ret != 0:  # pragma: no cover\n            raise RemoteCommandFailure(command=cmd, ret=ret)", "response": "Calls a command through SSH.\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling a command through SSH and returns its output.", "response": "def check_output(self, cmd):\n        \"\"\"Calls a command through SSH and returns its output.\n        \"\"\"\n        ret, output = self._call(cmd, True)\n        if ret != 0:  # pragma: no cover\n            raise RemoteCommandFailure(command=cmd, ret=ret)\n        logger.debug(\"Output: %r\", output)\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _resolve_queue(self, queue, depth=0, links=None):\n        if depth == 0:\n            logger.debug(\"resolve_queue(%s)\", queue)\n        answer = self.check_output(\n            'if [ -d %(queue)s ]; then '\n            '    cd %(queue)s; echo \"dir\"; cat version; pwd; '\n            'elif [ -f %(queue)s ]; then '\n            '    cat %(queue)s; '\n            'else '\n            '    echo no; '\n            'fi' % {\n                'queue': escape_queue(queue)})\n        if answer == b'no':\n            if depth > 0:\n                logger.debug(\"Broken link at depth=%d\", depth)\n            else:\n                logger.debug(\"Path doesn't exist\")\n            return None, depth\n        elif answer.startswith(b'dir\\n'):\n            version, runtime, path = answer[4:].split(b'\\n', 2)\n            try:\n                version = tuple(int(e)\n                                for e in version.decode('ascii', 'ignore')\n                                                .split('.'))\n            except ValueError:\n                version = 0, 0\n            if version[:2] != self.PROTOCOL_VERSION:\n                raise QueueExists(\n                    msg=\"Queue exists and is using incompatible protocol \"\n                        \"version %s\" % '.'.join('%s' % e for e in version))\n            path = PosixPath(path)\n            runtime = runtime.decode('ascii', 'replace')\n            if self.need_runtime is not None:\n                if (self.need_runtime is not None and\n                        runtime not in self.need_runtime):\n                    raise QueueExists(\n                        msg=\"Queue exists and is using explicitely disallowed \"\n                            \"runtime %s\" % runtime)\n            logger.debug(\"Found directory at %s, depth=%d, runtime=%s\",\n                         path, depth, runtime)\n            return path, depth\n        elif answer.startswith(b'tejdir: '):\n            new = queue.parent / answer[8:]\n            logger.debug(\"Found link to %s, recursing\", new)\n            if links is not None:\n                links.append(queue)\n            return self._resolve_queue(new, depth + 1)\n        else:  # pragma: no cover\n            logger.debug(\"Server returned %r\", answer)\n            raise RemoteCommandFailure(msg=\"Queue resolution command failed \"\n                                           \"in unexpected way\")", "response": "Resolves the queue location on the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_queue(self):\n        if self._queue is None:\n            self._links = []\n            queue, depth = self._resolve_queue(self.queue, links=self._links)\n            if queue is None and depth > 0:\n                raise QueueLinkBroken\n            self._queue = queue\n        return self._queue", "response": "Gets the actual location of the queue or None."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup(self, links=None, force=False, only_links=False):\n        if not links:\n            links = []\n\n        if only_links:\n            logger.info(\"Only creating links\")\n            for link in links:\n                self.check_call('echo \"tejdir:\" %(queue)s > %(link)s' % {\n                                'queue': escape_queue(self.queue),\n                                'link': escape_queue(link)})\n            return\n\n        queue, depth = self._resolve_queue(self.queue)\n        if queue is not None or depth > 0:\n            if force:\n                if queue is None:\n                    logger.info(\"Replacing broken link\")\n                elif depth > 0:\n                    logger.info(\"Replacing link to %s...\", queue)\n                else:\n                    logger.info(\"Replacing existing queue...\")\n                self.check_call('rm -Rf %s' % escape_queue(self.queue))\n            else:\n                if queue is not None and depth > 0:\n                    raise QueueExists(\"Queue already exists (links to %s)\\n\"\n                                      \"Use --force to replace\" % queue)\n                elif depth > 0:\n                    raise QueueExists(\"Broken link exists\\n\"\n                                      \"Use --force to replace\")\n                else:\n                    raise QueueExists(\"Queue already exists\\n\"\n                                      \"Use --force to replace\")\n\n        queue = self._setup()\n\n        for link in links:\n            self.check_call('echo \"tejdir:\" %(queue)s > %(link)s' % {\n                'queue': escape_queue(queue),\n                'link': escape_queue(link)})", "response": "Installs the runtime at the target location."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _setup(self):\n        # Expands ~user in queue\n        if self.queue.path[0:1] == b'/':\n            queue = self.queue\n        else:\n            if self.queue.path[0:1] == b'~':\n                output = self.check_output('echo %s' %\n                                           escape_queue(self.queue))\n                queue = PosixPath(output.rstrip(b'\\r\\n'))\n            else:\n                output = self.check_output('pwd')\n                queue = PosixPath(output.rstrip(b'\\r\\n')) / self.queue\n            logger.debug(\"Resolved to %s\", queue)\n\n        # Select runtime\n        if not self.setup_runtime:\n            # Autoselect\n            if self._call('which qsub', False)[0] == 0:\n                logger.debug(\"qsub is available, using runtime 'pbs'\")\n                runtime = 'pbs'\n            else:\n                logger.debug(\"qsub not found, using runtime 'default'\")\n                runtime = 'default'\n        else:\n            runtime = self.setup_runtime\n\n        if self.need_runtime is not None and runtime not in self.need_runtime:\n            raise ValueError(\"About to setup runtime %s but that wouldn't \"\n                             \"match explicitely allowed runtimes\" % runtime)\n\n        logger.info(\"Installing runtime %s%s at %s\",\n                    runtime,\n                    \"\" if self.setup_runtime else \" (auto)\",\n                    self.queue)\n\n        # Uploads runtime\n        scp_client = self.get_scp_client()\n        filename = pkg_resources.resource_filename('tej',\n                                                   'remotes/%s' % runtime)\n        scp_client.put(filename, str(queue), recursive=True)\n        logger.debug(\"Files uploaded\")\n\n        # Runs post-setup script\n        self.check_call('/bin/sh %s' % shell_escape(queue / 'commands/setup'))\n        logger.debug(\"Post-setup script done\")\n\n        self._queue = queue\n        return queue", "response": "Actually installs the runtime.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsubmitting a job to the queue.", "response": "def submit(self, job_id, directory, script=None):\n        \"\"\"Submits a job to the queue.\n\n        If the runtime is not there, it will be installed. If it is a broken\n        chain of links, error.\n        \"\"\"\n        if job_id is None:\n            job_id = '%s_%s_%s' % (Path(directory).unicodename,\n                                   self.destination['username'],\n                                   make_unique_name())\n        else:\n            check_jobid(job_id)\n\n        queue = self._get_queue()\n        if queue is None:\n            queue = self._setup()\n\n        if script is None:\n            script = 'start.sh'\n\n        # Create directory\n        ret, target = self._call('%s %s' % (\n                                 shell_escape(queue / 'commands/new_job'),\n                                 job_id),\n                                 True)\n        if ret == 4:\n            raise JobAlreadyExists\n        elif ret != 0:\n            raise JobNotFound(\"Couldn't create job\")\n        target = PosixPath(target)\n        logger.debug(\"Server created directory %s\", target)\n\n        # Upload to directory\n        try:\n            scp_client = self.get_scp_client()\n            scp_client.put(str(Path(directory)),\n                           str(target),\n                           recursive=True)\n        except BaseException as e:\n            try:\n                self.delete(job_id)\n            except BaseException:\n                raise e\n            raise\n        logger.debug(\"Files uploaded\")\n\n        # Submit job\n        self.check_call('%s %s %s %s' % (\n                        shell_escape(queue / 'commands/submit'),\n                        job_id, shell_escape(target),\n                        shell_escape(script)))\n        logger.info(\"Submitted job %s\", job_id)\n        return job_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the status of a previously - submitted job.", "response": "def status(self, job_id):\n        \"\"\"Gets the status of a previously-submitted job.\n        \"\"\"\n        check_jobid(job_id)\n\n        queue = self._get_queue()\n        if queue is None:\n            raise QueueDoesntExist\n\n        ret, output = self._call('%s %s' % (\n                                 shell_escape(queue / 'commands/status'),\n                                 job_id),\n                                 True)\n        if ret == 0:\n            directory, result = output.splitlines()\n            result = result.decode('utf-8')\n            return RemoteQueue.JOB_DONE, PosixPath(directory), result\n        elif ret == 2:\n            directory = output.splitlines()[0]\n            return RemoteQueue.JOB_RUNNING, PosixPath(directory), None\n        elif ret == 3:\n            raise JobNotFound\n        else:\n            raise RemoteCommandFailure(command=\"commands/status\",\n                                       ret=ret)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef download(self, job_id, files, **kwargs):\n        check_jobid(job_id)\n\n        if not files:\n            return\n        if isinstance(files, string_types):\n            files = [files]\n        directory = False\n        recursive = kwargs.pop('recursive', True)\n\n        if 'destination' in kwargs and 'directory' in kwargs:\n            raise TypeError(\"Only use one of 'destination' or 'directory'\")\n        elif 'destination' in kwargs:\n            destination = Path(kwargs.pop('destination'))\n            if len(files) != 1:\n                raise ValueError(\"'destination' specified but multiple files \"\n                                 \"given; did you mean to use 'directory'?\")\n        elif 'directory' in kwargs:\n            destination = Path(kwargs.pop('directory'))\n            directory = True\n        if kwargs:\n            raise TypeError(\"Got unexpected keyword arguments\")\n\n        # Might raise JobNotFound\n        status, target, result = self.status(job_id)\n\n        scp_client = self.get_scp_client()\n        for filename in files:\n            logger.info(\"Downloading %s\", target / filename)\n            if directory:\n                scp_client.get(str(target / filename),\n                               str(destination / filename),\n                               recursive=recursive)\n            else:\n                scp_client.get(str(target / filename),\n                               str(destination),\n                               recursive=recursive)", "response": "Downloads files from server."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef kill(self, job_id):\n        check_jobid(job_id)\n\n        queue = self._get_queue()\n        if queue is None:\n            raise QueueDoesntExist\n\n        ret, output = self._call('%s %s' % (\n                                 shell_escape(queue / 'commands/kill'),\n                                 job_id),\n                                 False)\n        if ret == 3:\n            raise JobNotFound\n        elif ret != 0:\n            raise RemoteCommandFailure(command='commands/kill',\n                                       ret=ret)", "response": "Kills a job on the server."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list(self):\n        queue = self._get_queue()\n        if queue is None:\n            raise QueueDoesntExist\n\n        output = self.check_output('%s' %\n                                   shell_escape(queue / 'commands/list'))\n\n        job_id, info = None, None\n        for line in output.splitlines():\n            line = line.decode('utf-8')\n            if line.startswith('    '):\n                key, value = line[4:].split(': ', 1)\n                info[key] = value\n            else:\n                if job_id is not None:\n                    yield job_id, info\n                job_id = line\n                info = {}\n        if job_id is not None:\n            yield job_id, info", "response": "Lists the jobs on the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a function that applies multiple substitutions to a single object.", "response": "def multi_substitution(*substitutions):\n\t\"\"\"\n\tTake a sequence of pairs specifying substitutions, and create\n\ta function that performs those substitutions.\n\n\t>>> multi_substitution(('foo', 'bar'), ('bar', 'baz'))('foo')\n\t'baz'\n\t\"\"\"\n\tsubstitutions = itertools.starmap(substitution, substitutions)\n\t# compose function applies last function first, so reverse the\n\t#  substitutions to get the expected order.\n\tsubstitutions = reversed(tuple(substitutions))\n\treturn compose(*substitutions)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef simple_html_strip(s):\n\thtml_stripper = re.compile('(<!--.*?-->)|(<[^>]*>)|([^<]+)', re.DOTALL)\n\ttexts = (\n\t\tmatch.group(3) or ''\n\t\tfor match\n\t\tin html_stripper.finditer(s)\n\t)\n\treturn ''.join(texts)", "response": "Remove HTML from the string s."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove the prefix from the text.", "response": "def remove_prefix(text, prefix):\n\t\"\"\"\n\tRemove the prefix from the text if it exists.\n\n\t>>> remove_prefix('underwhelming performance', 'underwhelming ')\n\t'performance'\n\n\t>>> remove_prefix('something special', 'sample')\n\t'something special'\n\t\"\"\"\n\tnull, prefix, rest = text.rpartition(prefix)\n\treturn rest"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_suffix(text, suffix):\n\trest, suffix, null = text.partition(suffix)\n\treturn rest", "response": "Remove the suffix from the text."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the common prefix of two lines.", "response": "def common_prefix(s1, s2):\n\t\t\"\"\"\n\t\tReturn the common prefix of two lines.\n\t\t\"\"\"\n\t\tindex = min(len(s1), len(s2))\n\t\twhile s1[:index] != s2[:index]:\n\t\t\tindex -= 1\n\t\treturn s1[:index]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_graph(self, ctx, bundle, extensions, caller=None):\n        request = ctx.get('request')\n        if request is None:\n            request = get_current_request()\n        if ':' in bundle:\n            config_name, bundle = bundle.split(':')\n        else:\n            config_name = 'DEFAULT'\n        webpack = request.webpack(config_name)\n        assets = (caller(a) for a in webpack.get_bundle(bundle, extensions))\n        return ''.join(assets)", "response": "Run a graph and render the tag contents for each output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nswitching to this project.", "response": "def activate(lancet, method, project):\n    \"\"\"Switch to this project.\"\"\"\n    with taskstatus(\"Looking up project\") as ts:\n        if method == \"key\":\n            func = get_project_keys\n        elif method == \"dir\":\n            func = get_project_keys\n\n        for key, project_path in func(lancet):\n            if key.lower() == project.lower():\n                break\n        else:\n            ts.abort(\n                'Project \"{}\" not found (using {}-based lookup)',\n                project,\n                method,\n            )\n\n    # Load the configuration\n    config = load_config(os.path.join(project_path, LOCAL_CONFIG))\n\n    # cd to the project directory\n    lancet.defer_to_shell(\"cd\", project_path)\n\n    # Activate virtualenv\n    venv = config.get(\"lancet\", \"virtualenv\", fallback=None)\n    if venv:\n        venv_path = os.path.join(project_path, os.path.expanduser(venv))\n        activate_script = os.path.join(venv_path, \"bin\", \"activate\")\n        lancet.defer_to_shell(\"source\", activate_script)\n    else:\n        if \"VIRTUAL_ENV\" in os.environ:\n            lancet.defer_to_shell(\"deactivate\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef workon(ctx, issue_id, new, base_branch):\n    lancet = ctx.obj\n\n    if not issue_id and not new:\n        raise click.UsageError(\"Provide either an issue ID or the --new flag.\")\n    elif issue_id and new:\n        raise click.UsageError(\n            \"Provide either an issue ID or the --new flag, but not both.\"\n        )\n\n    if new:\n        # Create a new issue\n        summary = click.prompt(\"Issue summary\")\n        issue = create_issue(\n            lancet, summary=summary, add_to_active_sprint=True\n        )\n    else:\n        issue = get_issue(lancet, issue_id)\n\n    username = lancet.tracker.whoami()\n    active_status = lancet.config.get(\"tracker\", \"active_status\")\n    if not base_branch:\n        base_branch = lancet.config.get(\"repository\", \"base_branch\")\n\n    # Get the working branch\n    branch = get_branch(lancet, issue, base_branch)\n\n    # Make sure the issue is in a correct status\n    transition = get_transition(ctx, lancet, issue, active_status)\n\n    # Make sure the issue is assigned to us\n    assign_issue(lancet, issue, username, active_status)\n\n    # Activate environment\n    set_issue_status(lancet, issue, active_status, transition)\n\n    with taskstatus(\"Checking out working branch\") as ts:\n        lancet.repo.checkout(branch.name)\n        ts.ok('Checked out working branch based on \"{}\"'.format(base_branch))\n\n    with taskstatus(\"Starting harvest timer\") as ts:\n        lancet.timer.start(issue)\n        ts.ok(\"Started harvest timer\")", "response": "This command creates a new branch and checks out the branch and environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef time(lancet, issue):\n    issue = get_issue(lancet, issue)\n\n    with taskstatus(\"Starting harvest timer\") as ts:\n        lancet.timer.start(issue)\n        ts.ok(\"Started harvest timer\")", "response": "Start an harvest timer for the given issue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pause(ctx):\n    lancet = ctx.obj\n    paused_status = lancet.config.get(\"tracker\", \"paused_status\")\n\n    # Get the issue\n    issue = get_issue(lancet)\n\n    # Make sure the issue is in a correct status\n    transition = get_transition(ctx, lancet, issue, paused_status)\n\n    # Activate environment\n    set_issue_status(lancet, issue, paused_status, transition)\n\n    with taskstatus(\"Pausing harvest timer\") as ts:\n        lancet.timer.pause()\n        ts.ok(\"Harvest timer paused\")", "response": "Pause work on the current issue."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resume(ctx):\n    lancet = ctx.obj\n\n    username = lancet.tracker.whoami()\n    active_status = lancet.config.get(\"tracker\", \"active_status\")\n\n    # Get the issue\n    issue = get_issue(lancet)\n\n    # Make sure the issue is in a correct status\n    transition = get_transition(ctx, lancet, issue, active_status)\n\n    # Make sure the issue is assigned to us\n    assign_issue(lancet, issue, username, active_status)\n\n    # Activate environment\n    set_issue_status(lancet, issue, active_status, transition)\n\n    with taskstatus(\"Resuming harvest timer\") as ts:\n        lancet.timer.start(issue)\n        ts.ok(\"Resumed harvest timer\")", "response": "Resume work on the currently active issue."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ssh(lancet, print_cmd, environment):\n    namespace = {}\n\n    with open(lancet.config.get('dploi', 'deployment_spec')) as fh:\n        code = compile(fh.read(), 'deployment.py', 'exec')\n        exec(code, {}, namespace)\n\n    config = namespace['settings'][environment]\n    host = '{}@{}'.format(config['user'], config['hosts'][0])\n    cmd = ['ssh', '-p', str(config.get('port', 22)), host]\n\n    if print_cmd:\n        click.echo(' '.join(quote(s) for s in cmd))\n    else:\n        lancet.defer_to_shell(*cmd)", "response": "SSH into the given environment"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the shell integration code.", "response": "def _setup_helper():\n    \"\"\"Print the shell integration code.\"\"\"\n    base = os.path.abspath(os.path.dirname(__file__))\n    helper = os.path.join(base, \"helper.sh\")\n    with open(helper) as fh:\n        click.echo(fh.read())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _commands(ctx):\n    ctx = ctx.parent\n    ctx.show_hidden_subcommands = False\n    main = ctx.command\n\n    for subcommand in main.list_commands(ctx):\n        cmd = main.get_command(ctx, subcommand)\n        if cmd is None:\n            continue\n        help = cmd.short_help or \"\"\n        click.echo(\"{}:{}\".format(subcommand, help))", "response": "Prints a list of commands for shell completion hooks."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _arguments(ctx, command_name=None):\n    ctx = ctx.parent\n    main = ctx.command\n    if command_name:\n        command = main.get_command(ctx, command_name)\n        if not command:\n            return\n    else:\n        command = main\n\n    types = [\"option\", \"argument\"]\n    all_params = sorted(\n        command.get_params(ctx), key=lambda p: types.index(p.param_type_name)\n    )\n\n    def get_name(param):\n        return max(param.opts, key=len)\n\n    for param in all_params:\n        if param.param_type_name == \"option\":\n            option = get_name(param)\n            same_dest = [\n                get_name(p) for p in all_params if p.name == param.name\n            ]\n            if same_dest:\n                option = \"({})\".format(\" \".join(same_dest)) + option\n            if param.help:\n                option += \"[{}]\".format(param.help or \"\")\n            if not param.is_flag:\n                option += \"=:( )\"\n            click.echo(option)\n        elif param.param_type_name == \"argument\":\n            option = get_name(param)\n            click.echo(\":{}\".format(option))", "response": "Prints a list of arguments for shell completion hooks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting the shell autocompletion code.", "response": "def _autocomplete(ctx, shell):\n    \"\"\"Print the shell autocompletion code.\"\"\"\n    if not shell:\n        shell = os.environ.get(\"SHELL\", \"\")\n        shell = os.path.basename(shell).lower()\n    if not shell:\n        click.secho(\n            \"Your shell could not be detected, please pass its name \"\n            \"as the argument.\",\n            fg=\"red\",\n        )\n        ctx.exit(-1)\n\n    base = os.path.abspath(os.path.dirname(__file__))\n    autocomplete = os.path.join(base, \"autocomplete\", \"{}.sh\".format(shell))\n\n    if not os.path.exists(autocomplete):\n        click.secho(\n            \"Autocompletion for your shell ({}) is currently not \"\n            \"supported.\",\n            fg=\"red\",\n        )\n        ctx.exit(-1)\n\n    with open(autocomplete) as fh:\n        click.echo(fh.read())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall Python 3 raise from or emulate it for Python 2", "response": "def raisefrom(exc_type, message, exc):\n    # type: (Any, str, BaseException) -> None\n    \"\"\"Call Python 3 raise from or emulate it for Python 2\n\n    Args:\n        exc_type (Any): Type of Exception\n        message (str): Error message to display\n        exc (BaseException): original exception\n\n    Returns:\n        None\n\n    \"\"\"\n    if sys.version_info[:2] >= (3, 2):\n        six.raise_from(exc_type(message), exc)\n    else:\n        six.reraise(exc_type, '%s - %s' % (message, exc), sys.exc_info()[2])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_runner(self, parser, tracers, projinfo):\r\n        ''' initial some instances for preparing to run test case\r\n        @note:  should not override\r\n        @param parser: instance of TestCaseParser\r\n        @param tracers: dict type for the instance of Tracer. Such as {\"\":tracer_obj} or {\"192.168.0.1:5555\":tracer_obj1, \"192.168.0.2:5555\":tracer_obj2} \r\n        @param proj_info: dict type of test case.  use like:  self.proj_info[\"module\"], self.proj_info[\"name\"]\r\n            yaml case like: \r\n                - project:\r\n                    name: xxx\r\n                    module: xxxx\r\n            dict case like:\r\n                {\"project\": {\"name\": xxx, \"module\": xxxx}}            \r\n                \r\n        '''\r\n        self.parser = parser\r\n        self.tracers = tracers\r\n        self.proj_info = projinfo", "response": "initialise the runner object"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns case with mutil process to support selenium grid - mode multiple web and appium grid - mode multiple devices.", "response": "def _run_grid_multiprocess(self, func, iterables):\r\n        ''' running case with mutil process to support selenium grid-mode(multiple web) and appium grid-mode(multiple devices). \r\n        @param func:  function object\r\n        @param iterables:  iterable objects\r\n        '''\r\n        multiprocessing.freeze_support()\r\n        pool = multiprocessing.Pool()        \r\n        pool_tracers = pool.map(func, iterables)\r\n        pool.close()\r\n        pool.join()\r\n        \r\n        # \u4f20\u9012\u7ed9 pool.map\u7684 \u5b9e\u4f8b\u5bf9\u8c61\uff0c\u5185\u5b58\u5730\u5740\u53d1\u751f\u53d8\u5316\uff0c \u56e0\u6b64\uff0c\u8fd9\u91cc\u5728\u8fd0\u884c\u7ed3\u675f\u540e\uff0c\u91cd\u65b0\u5b9a\u4e49 self.tracers \r\n        self.tracers = dict(zip(self._default_devices, pool_tracers))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun case with mutil process to support selenium grid - mode multiple web and appium grid - mode multiple devices.", "response": "def _run_grid_multithread(self, func, iterables):\r\n        ''' running case with mutil process to support selenium grid-mode(multiple web) and appium grid-mode(multiple devices). \r\n        @param func:  function object\r\n        @param iterables:  iterable objects\r\n        '''\r\n        \r\n        f = lambda x: threading.Thread(target = func,args = (x,))\r\n        threads = map(f, iterables)\r\n        for thread in threads:\r\n            thread.setDaemon(True)\r\n            thread.start()\r\n            thread.join()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init_project_env(subject='Automation', proj_path = None, sysencoding = \"utf-8\", debug = False):\r\n    ''' Set the environment for pyrunner '''    \r\n        \r\n#     if sysencoding:\r\n#         set_sys_encode(sysencoding)\r\n    \r\n    if not proj_path:\r\n        try:\r\n            executable_file_path = os.path.dirname(os.path.abspath(inspect.stack()[-1][1]))\r\n        except:\r\n            executable_file_path = os.path.dirname(sys.path[0])\r\n        finally:\r\n            proj_path = executable_file_path\r\n    \r\n    p = os.path.join(proj_path,subject)\r\n    \r\n    proj_conf = {\r\n        \"sys_coding\" : sysencoding,\r\n        \"debug\" : debug,\r\n        \"module_name\" : os.path.splitext(os.path.basename(subject))[0],\r\n        \"cfg_file\" : os.path.join(p,\"config.ini\"),\r\n        \"path\" : {\"root\" : p,\r\n                  \"case\" : os.path.join(p,\"testcase\"),\r\n                  \"data\" : os.path.join(p,\"data\"),\r\n                  \"buffer\" : os.path.join(p,\"buffer\"),\r\n                  \"resource\" : os.path.join(p,\"resource\"),\r\n                  \"tools\" : os.path.join(p,\"tools\"),\r\n                  \"rst\" : os.path.join(p,\"result\"),\r\n                  \"rst_log\" : os.path.join(p,\"result\",\"testcase\"),\r\n                  \"rst_shot\" : os.path.join(p,\"result\",\"screenshots\"),\r\n            },\r\n        }\r\n     \r\n    [FileSystemUtils.mkdirs(v) for v in proj_conf[\"path\"].values()]    \r\n    sys.path.append(p) if os.path.isdir(p) else \"\"\r\n    return proj_conf", "response": "Initialize the environment for pyrunner"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a string with the first N elements of the list.", "response": "def seqfy(strs):\r\n    ''' \u5e8f\u5217\u5316 \u5b57\u7b26\u4e32--->\u5b9e\u9645\u6548\u679c\u662f\uff0c\u4e3a\u5b57\u7b26\u4e32\uff0c\u6dfb\u52a0\u884c\u53f7\uff0c\u8fd4\u56de\u5b57\u7b26\u4e32\r\n    Sampe usage:\r\n        strs = [\"\", None, u\"First-line\\nSecond-line\\nThird-line\", u\"\u6ca1\u6709\u6362\u884c\u7b26\"]\r\n        for s in strs:\r\n            print \"---\"\r\n            result = seqfy(s)\r\n            print result\r\n            print unseqfy(result)\r\n    '''\r\n    \r\n    if not strs:\r\n        return\r\n    \r\n    result = \"\"\r\n    seq = 1\r\n    ss = strs.split(\"\\n\")\r\n    for i in ss:\r\n        if i:\r\n            result = \"\".join([result, str(seq), \".\", i, \"\\n\"])\r\n            seq = seq + 1            \r\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding all the stepfy strings in a string.", "response": "def stepfy(strs):\r\n    ''' \u6b65\u9aa4\u5316 \u5b57\u7b26\u4e32 --->\u5b9e\u9645\u6548\u679c\u662f, \u4f9d\u636e \u5e8f\u5217\u5316\u7684\u5b57\u7b26\u4e32\uff0c\u8f6c\u6362\u4e3a Step_%s_info \u7684\u5b57\u5178\uff0c \u8fd4\u56de\u5b57\u5178\r\n    Sample usage:\r\n        test_strs = [\r\n        \"\",\r\n        None,\r\n        u\"First-line\\nSecond-line\\nThird-line\",\r\n        u'1.First-line\\n2.Second-line\\n3.Third-line\\n',\r\n        u'3.\u6ca1\u6709\u6362\u884c\u7b26',\r\n        u'3.\u6709\u6362\u884c\u7b26\\n',\r\n        \"asdfasdfsdf\",    \r\n        \"1.asdfasdfsdf\\n2.sodfi\",\r\n        \"1.1.dfasdfahttp://192.168.1.1sdfsdf2.1.1.1.1\\n\",\r\n        \"dfasdfahttp://192.168.1.1sdfsdf2.1.1.1.1\\n\",\r\n        ]\r\n        for i in test_strs:\r\n            steps = stepfy(i)\r\n            un = unstepfy(steps)\r\n            print \"string: %r\" %i\r\n            print \"stepfy: %s\" %steps\r\n            print \"unstepfy: %r\\n\" %un\r\n    '''\r\n    \r\n    result = {}\r\n    prog_step   = re.compile(\"^\\d+\\.\")\r\n      \r\n    if not strs:\r\n        return result\r\n      \r\n    raws = strs.split(\"\\n\")\r\n    for raw in raws:\r\n        step_num = raws.index(raw) + 1\r\n        raw = prog_step.sub(\"\",raw)       \r\n        if raw:\r\n            result[\"Step_%s_info\" %step_num] = raw\r\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef map_function(func_str, fw_action_addtion=None,bw_action_addtion=None, alias_func=None):\r\n    ''' Sample usage:\r\n        print map_function('set',alias_func = \"ini_items\");# -> ini_items\r\n        print map_function('set',fw_action_addtion=\"action_steps_\",bw_action_addtion=\"_for_upd\",alias_func = \"ini_items\"); # -> action_steps_ini_items_for_upd\r\n        print map_function('set(a=1,b=2,c=Test())',\"action_steps_\",\"_for_upd\",\"ini_items\");# -> action_steps_ini_items_for_upd(a=1,b=2,c=Test())\r\n        print map_function('set(\"login\",a=\"good\",b=Test())',\"action_steps_\",\"_for_upd\");# -> action_steps_set_for_upd(\"login\",a=\"good\",b=Test())\r\n    '''\r\n    \r\n    split_action_value = re.compile(\"^(\\w+)(\\((.*)\\)$)?\")\r\n    matched   = split_action_value.match(func_str)    \r\n     \r\n    if matched:\r\n        action = matched.group(1).lower()\r\n        value = matched.group(2)\r\n        #params = matched.group(3)\r\n        \r\n        if alias_func:\r\n            action = alias_func\r\n        if fw_action_addtion:\r\n            action = fw_action_addtion + action        \r\n        if fw_action_addtion:\r\n            action = action + bw_action_addtion\r\n        \r\n        if value:\r\n            return action+value\r\n        else:\r\n            return action", "response": "Map function to list of items and actions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef until_cmd(listcmd, end_expects=None, save2logfile=None, coding = encoding):\r\n        ''' \u6267\u884c\u7cfb\u7edf\u547d\u4ee4,\u5e76\u7b49\u5f85\u6267\u884c\u5b8c\r\n            @param listcmd: \u6267\u884c\u7684\u547d\u4ee4\uff0c\u5217\u8868\u683c\u5f0f\r\n            @param end_expects: \u547d\u4ee4\u6267\u884c\u7ed3\u675f\uff0c\u5728\u8f93\u51fa\u7684\u6700\u540e\u4e00\u884c\uff0c\u6b63\u5219\u641c\u7d20\u671f\u671b\u503c\uff0c\u5e76\u8bbe\u7f6e \u7ed3\u679c\u6807\u5fd7\r\n            @param save2logfile:  \u8bbe\u7f6e\u6267\u884c\u8fc7\u7a0b\uff0c\u4fdd\u5b58\u7684\u65e5\u5fd7\r\n            @param coding: \u8bbe\u7f6e\u8f93\u51fa\u7f16\u7801        \r\n        '''\r\n        \r\n        \r\n        if end_expects and not isinstance(end_expects, p_compat.str):\r\n            raise Exception(\"invalide unicode string: '%s'\" %end_expects)\r\n        \r\n        lines = []    \r\n        subp = subprocess.Popen(listcmd,stdout=subprocess.PIPE,stderr=subprocess.STDOUT)\r\n        while subp.poll()==None:\r\n            next_line = subp.stdout.readline().decode(coding)\r\n            if next_line:\r\n#                 print(next_line)\r\n                lines.append(next_line)\r\n                if end_expects and re.search(end_expects, next_line):\r\n                    result = True\r\n                else:\r\n                    result = False        \r\n        subp.stdout.close()\r\n        \r\n        if subp.returncode:\r\n            result = False\r\n            lines.append(\"sub command error code: %s\" %subp.returncode)\r\n        \r\n        if save2logfile:\r\n            with open(save2logfile, 'a') as f:\r\n                f.writelines(lines)\r\n                                    \r\n        return result", "response": "A wrapper for subprocess. Popen that returns a list of the items in the listcmd."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling the method until the return value is not False.", "response": "def until(method, timeout = 30, message=''):\r\n        \"\"\"Calls the method until the return value is not False.\"\"\"\r\n        end_time = time.time() + timeout\r\n        while True:\r\n            try:\r\n                value = method()\r\n                if value:\r\n                    return value\r\n            except:\r\n                pass            \r\n            time.sleep(1)\r\n            if time.time() > end_time:\r\n                break\r\n        raise Exception(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks testcase file format", "response": "def _check_format(file_path, content):\r\n        \"\"\" check testcase format if valid\r\n        \"\"\"\r\n        if not content:\r\n            # testcase file content is empty\r\n            err_msg = u\"Testcase file content is empty: {}\".format(file_path)\r\n            raise p_exception.FileFormatError(err_msg)\r\n\r\n        elif not isinstance(content, (list, dict)):\r\n            # testcase file content does not match testcase format\r\n            err_msg = u\"Testcase file content format invalid: {}\".format(file_path)\r\n            raise p_exception.FileFormatError(err_msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads yaml file and check file content format", "response": "def _load_yaml_file(yaml_file):\r\n        \"\"\" load yaml file and check file content format\r\n        \"\"\"\r\n        with io.open(yaml_file, 'r', encoding='utf-8') as stream:\r\n            yaml_content = yaml.load(stream)\r\n            FileUtils._check_format(yaml_file, yaml_content)\r\n            return yaml_content"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _load_json_file(json_file):\r\n        with io.open(json_file, encoding='utf-8') as data_file:\r\n            try:\r\n                json_content = json.load(data_file)\r\n            except p_exception.JSONDecodeError:\r\n                err_msg = u\"JSONDecodeError: JSON file format error: {}\".format(json_file)\r\n                raise p_exception.FileFormatError(err_msg)\r\n\r\n            FileUtils._check_format(json_file, json_content)\r\n            return json_content", "response": "load json file and check file content format\r\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload csv file and check file content format", "response": "def _load_csv_file(csv_file):\r\n        \"\"\" load csv file and check file content format\r\n        @param\r\n            csv_file: csv file path\r\n            e.g. csv file content:\r\n                username,password\r\n                test1,111111\r\n                test2,222222\r\n                test3,333333\r\n        @return\r\n            list of parameter, each parameter is in dict format\r\n            e.g.\r\n            [\r\n                {'username': 'test1', 'password': '111111'},\r\n                {'username': 'test2', 'password': '222222'},\r\n                {'username': 'test3', 'password': '333333'}\r\n            ]\r\n        \"\"\"\r\n        csv_content_list = []\r\n\r\n        with io.open(csv_file, encoding='utf-8') as csvfile:\r\n            reader = csv.DictReader(csvfile)\r\n            for row in reader:\r\n                csv_content_list.append(row)\r\n\r\n        return csv_content_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nforce delete a file", "response": "def force_delete_file(file_path):\r\n        ''' force delete a file '''\r\n        if os.path.isfile(file_path):\r\n            try:\r\n                os.remove(file_path)\r\n                return file_path\r\n            except:           \r\n                return FileSystemUtils.add_unique_postfix(file_path)\r\n        else:\r\n            return file_path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a zip file with all the files in source_dir.", "response": "def mkzip(source_dir, output_filename):\r\n        '''Usage:\r\n            p = r'D:\\auto\\env\\ttest\\ins\\build\\lib\\rock4\\softtest\\support'\r\n            mkzip(os.path.join(p, \"appiumroot\"),os.path.join(p, \"appiumroot.zip\"))\r\n            unzip(os.path.join(p, \"appiumroot.zip\"),os.path.join(p, \"appiumroot2\"))  \r\n        '''\r\n        zipf = zipfile.ZipFile(output_filename, 'w', zipfile.zlib.DEFLATED)\r\n        pre_len = len(os.path.dirname(source_dir))\r\n        for parent, dirnames, filenames in os.walk(source_dir):\r\n            for filename in filenames:\r\n                pathfile = os.path.join(parent, filename)\r\n                arcname = pathfile[pre_len:].strip(os.path.sep);#\u76f8\u5bf9\u8def\u5f84\r\n                zipf.write(pathfile, arcname)\r\n        zipf.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimport module from python file path and return imported module", "response": "def get_imported_module_from_file(file_path):\r\n        \"\"\" import module from python file path and return imported module\r\n        \"\"\"\r\n        if p_compat.is_py3:\r\n            imported_module = importlib.machinery.SourceFileLoader('module_name', file_path).load_module()\r\n        elif p_compat.is_py2:\r\n            imported_module = imp.load_source('module_name', file_path)\r\n        else:\r\n            raise RuntimeError(\"Neither Python 3 nor Python 2.\")\r\n    \r\n        return imported_module"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfilters functions or variables from import module", "response": "def filter_module(module, filter_type):\r\n        \"\"\" filter functions or variables from import module\r\n        @params\r\n            module: imported module\r\n            filter_type: \"function\" or \"variable\"\r\n        \"\"\"\r\n        filter_type = ModuleUtils.is_function if filter_type == \"function\" else ModuleUtils.is_variable\r\n        module_functions_dict = dict(filter(filter_type, vars(module).items()))\r\n        return module_functions_dict"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch expected function or variable recursive upward", "response": "def search_conf_item(start_path, item_type, item_name):\r\n        \"\"\" search expected function or variable recursive upward\r\n        @param\r\n            start_path: search start path\r\n            item_type: \"function\" or \"variable\"\r\n            item_name: function name or variable name\r\n        e.g.\r\n            search_conf_item('C:/Users/RockFeng/Desktop/s/preference.py','function','test_func')\r\n        \"\"\"\r\n        dir_path = os.path.dirname(os.path.abspath(start_path))\r\n        target_file = os.path.join(dir_path, \"preference.py\")\r\n        \r\n        if os.path.isfile(target_file):\r\n            imported_module = ModuleUtils.get_imported_module_from_file(target_file)\r\n            items_dict = ModuleUtils.filter_module(imported_module, item_type)\r\n            if item_name in items_dict:\r\n                return items_dict[item_name]\r\n            else:\r\n                return ModuleUtils.search_conf_item(dir_path, item_type, item_name)\r\n    \r\n        if dir_path == start_path:\r\n            # system root path\r\n            err_msg = \"'{}' not found in recursive upward path!\".format(item_name)\r\n            if item_type == \"function\":\r\n                raise p_exception.FunctionNotFound(err_msg)\r\n            else:\r\n                raise p_exception.VariableNotFound(err_msg)\r\n    \r\n        return ModuleUtils.search_conf_item(dir_path, item_type, item_name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_data_files(source,target,patterns,isiter=False):\r\n        if glob.has_magic(source) or glob.has_magic(target):\r\n            raise ValueError(\"Magic not allowed in src, target\")\r\n        ret = {}\r\n        for pattern in patterns:\r\n            pattern = os.path.join(source,pattern)\r\n            for filename in glob.glob(pattern):\r\n                if os.path.isfile(filename):\r\n                    targetpath = os.path.join(target,os.path.relpath(filename,source))\r\n                    path = os.path.dirname(targetpath)\r\n                    ret.setdefault(path,[]).append(filename)\r\n                elif isiter and os.path.isdir(filename):\r\n                    source2 = os.path.join(source,filename)\r\n                    targetpath2 = \"%s/%s\" %(target,os.path.basename(filename))\r\n                    # iter_target = os.path.dirname(targetpath2)\r\n                    ret.update(SetupUtils.find_data_files(source2,targetpath2,patterns,isiter))\r\n                 \r\n        return sorted(ret.items())", "response": "Locates the specified data - files and returns the matches ;"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert mapping in list to ordered dict", "response": "def convert_to_order_dict(map_list):\r\n        \"\"\" convert mapping in list to ordered dict\r\n        @param (list) map_list\r\n            [\r\n                {\"a\": 1},\r\n                {\"b\": 2}\r\n            ]\r\n        @return (OrderDict)\r\n            OrderDict({\r\n                \"a\": 1,\r\n                \"b\": 2\r\n            })\r\n        \"\"\"\r\n        ordered_dict = OrderedDict()\r\n        for map_dict in map_list:\r\n            ordered_dict.update(map_dict)\r\n        \r\n        return ordered_dict"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_value_from_cfg(cfg_file):\r\n        ''' initial the configuration with file that you specify \r\n            Sample usage:            \r\n                config = get_value_from_cfg()            \r\n            return:\r\n                return a dict        -->config[section][option]  such as config[\"twsm\"][\"dut_ip\"]                \r\n        '''    \r\n    \r\n        if not os.path.isfile(cfg_file):\r\n            return\r\n    \r\n        cfg = {}   \r\n        config = ConfigParser.RawConfigParser()\r\n        \r\n        try:\r\n            config.read(cfg_file)\r\n        except Exception as e:\r\n    #         raise Exception(\"\\n\\tcommon exception 1.2: Not a well format configuration file. error: '%s'\" %(e))\r\n            return        \r\n        for section in config.sections():\r\n            cfg[section] = {}\r\n            for option in config.options(section):\r\n                cfg[section][option]=config.get(section,option)\r\n        return cfg", "response": "initial the configuration with file that you specify\r\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_exception_error():\r\n        ''' Get the exception info\r\n        Sample usage:\r\n            try:\r\n                raise Exception(\"asdfsdfsdf\")\r\n            except:\r\n                print common.get_exception_error()\r\n        Return:\r\n            return the exception infomation.\r\n        '''\r\n        error_message = \"\"\r\n        for i in range(len(inspect.trace())):\r\n            error_line = u\"\"\"\r\n        File:      %s - [%s]\r\n        Function:  %s\r\n        Statement: %s\r\n        -\"\"\" % (inspect.trace()[i][1], inspect.trace()[i][2], inspect.trace()[i][3], inspect.trace()[i][4])\r\n            \r\n            error_message = \"%s%s\" % (error_message, error_line)    \r\n        \r\n        error_message = u\"\"\"Error!\\n%s\\n\\t%s\\n\\t%s\\n-------------------------------------------------------------------------------------------\\n\\n\"\"\" % (error_message,sys.exc_info()[0], sys.exc_info()[1])\r\n        \r\n        return error_message", "response": "Get the exception info"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nechoes the amount of transferred and toBeTransferred", "response": "def echo(transferred, toBeTransferred, suffix=''):\r\n        ''' usage:\r\n            for i in range(101):\r\n                ProgressBarUtils.echo(i,100)\r\n        '''\r\n        bar_len = 60                \r\n        rate = transferred/float(toBeTransferred)\r\n        \r\n        filled_len = int(round(bar_len * rate))\r\n        _percents = \"%s%s\" %(round(100.0 * rate, 1), \"%\")\r\n        \r\n        end_str = \"\\r\"\r\n        _bar = '=' * filled_len + '-' * (bar_len - filled_len)\r\n        print(\"[%s] %s ...%s%s\" %(_bar, _percents, suffix, end_str))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef echo_size(self, transferred=1, status=None):\r\n        '''Sample usage:\r\n            \r\n            f=lambda x,y:x+y\r\n            ldata = range(10)\r\n            toBeTransferred = reduce(f,range(10))\r\n            \r\n            progress = ProgressBarUtils(\"refresh\", toBeTransferred=toBeTransferred, unit=\"KB\", chunk_size=1.0, run_status=\"\u6b63\u5728\u4e0b\u8f7d\", fin_status=\"\u4e0b\u8f7d\u5b8c\u6210\")\r\n            import time\r\n            for  i in ldata:\r\n                time.sleep(0.2)\r\n                progress.echo_size(transferred=i)\r\n        '''\r\n        self.transferred += transferred\r\n        # if status is not None:\r\n        self.status = status or self.status\r\n        end_str = \"\\r\"\r\n        if self.transferred == self.toBeTransferred:\r\n            end_str = '\\n'\r\n            self.status = status or self.fin_status\r\n        \r\n        print(self.__get_info() + end_str)", "response": "Print the size of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef echo_percent(self,transferred=1, status=None):\r\n        '''Sample usage:\r\n            f=lambda x,y:x+y\r\n            ldata = range(10)\r\n            toBeTransferred = reduce(f,range(10))\r\n            \r\n            import time\r\n            progress = ProgressBarUtils(\"viewbar\", toBeTransferred=toBeTransferred, run_status=\"\u6b63\u5728\u4e0b\u8f7d\", fin_status=\"\u4e0b\u8f7d\u5b8c\u6210\")    \r\n            for i in ldata:  \r\n                time.sleep(0.1)  \r\n                progress.echo_percent(i)\r\n        '''\r\n        self.transferred += transferred\r\n        self.status = status or self.status\r\n        end_str = \"\\r\"\r\n        if self.transferred == self.toBeTransferred:\r\n            end_str = '\\n'\r\n            self.status = status or self.fin_status\r\n        print(self.__get_bar() + end_str)", "response": "Print a progress bar for each of the available items."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts a service n times", "response": "def start_service(addr, n):\n    \"\"\" Start a service \"\"\"\n    s = Service(addr)\n    s.register('add', lambda x, y: x + y)\n\n    started = time.time()\n    for _ in range(n):\n        s.process()\n    duration = time.time() - started\n\n    time.sleep(0.1)\n    print('Service stats:')\n    util.print_stats(n, duration)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting a service with the given address n times.", "response": "def start_service(addr, n):\n    \"\"\" Start a service \"\"\"\n\n    s = Subscriber(addr)\n    s.socket.set_string_option(nanomsg.SUB, nanomsg.SUB_SUBSCRIBE, 'test')\n\n    started = time.time()\n    for _ in range(n):\n        msg = s.socket.recv()\n    s.socket.close()\n    duration = time.time() - started\n\n    print('Raw SUB service stats:')\n    util.print_stats(n, duration)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist Harvest projects optionally filtered with a regexp.", "response": "def projects(lancet, query):\n    \"\"\"List Harvest projects, optionally filtered with a regexp.\"\"\"\n    projects = lancet.timer.projects()\n\n    if query:\n        regexp = re.compile(query, flags=re.IGNORECASE)\n\n        def match(project):\n            match = regexp.search(project['name'])\n            if match is None:\n                return False\n            project['match'] = match\n            return True\n        projects = (p for p in projects if match(p))\n\n    for project in sorted(projects, key=lambda p: p['name'].lower()):\n        name = project['name']\n\n        if 'match' in project:\n            m = project['match']\n            s, e = m.start(), m.end()\n            match = click.style(name[s:e], fg='green')\n            name = name[:s] + match + name[e:]\n\n        click.echo('{:>9d} {} {}'.format(\n            project['id'], click.style('\u2023', fg='yellow'), name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting Harvest tasks for the given project ID.", "response": "def tasks(lancet, project_id):\n    \"\"\"List Harvest tasks for the given project ID.\"\"\"\n    for task in lancet.timer.tasks(project_id):\n        click.echo('{:>9d} {} {}'.format(\n            task['id'], click.style('\u2023', fg='yellow'), task['name']))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_long_description():\n    here = os.path.abspath(os.path.dirname(__file__))\n\n    with copen(os.path.join(here, 'DESCRIPTION.rst'), encoding='utf-8') as description:\n        return description.read()", "response": "Retrieve the long description from DESCRIPTION. rst"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef flatten(nested_list: list) -> list:\n    return list(sorted(filter(lambda y: y is not None,\n                              list(map(lambda x: (nested_list.extend(x)  # noqa: T484\n                                                  if isinstance(x, list) else x),\n                                       nested_list)))))", "response": "Flattens a list ignore all the lambdas."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_py_files(dir_name: str) -> list:\n    return flatten([\n        x for x in\n        [[\"{0}/{1}\".format(path, f) for f in files if f.endswith(\".py\")]\n         for path, _, files in os.walk(dir_name)\n         if not path.startswith(\"./build\")] if x\n    ])", "response": "Get all. py files."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nraises SystemExit with correct status code and output logs.", "response": "def exit(self) -> None:\n        \"\"\"Raise SystemExit with correct status code and output logs.\"\"\"\n        total = sum(len(logs) for logs in self.logs.values())\n        if self.json:\n            self.logs['total'] = total\n            print(json.dumps(self.logs, indent=self.indent))\n\n        else:\n            for name, log in self.logs.items():\n                if not log or self.parser[name].as_bool(\"quiet\"):\n                    continue\n\n                print(\"[[{0}]]\".format(name))\n                getattr(snekchek.format, name + \"_format\")(log)\n                print(\"\\n\")\n\n            print(\"-\" * 30)\n            print(\"Total:\", total)\n\n        sys.exit(self.status_code)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun a checker class.", "response": "def run_linter(self, linter) -> None:\n        \"\"\"Run a checker class\"\"\"\n        self.current = linter.name\n\n        if (linter.name not in self.parser[\"all\"].as_list(\"linters\")\n                or linter.base_pyversion > sys.version_info):  # noqa: W503\n            return\n\n        if any(x not in self.installed for x in linter.requires_install):\n            raise ModuleNotInstalled(linter.requires_install)\n\n        linter.add_output_hook(self.out_func)\n        linter.set_config(self.fn, self.parser[linter.name])\n        linter.run(self.files)\n        self.status_code = self.status_code or linter.status_code"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to read a rcfile from a list of paths", "response": "def read_rcfile():\n    \"\"\"\n    Try to read a rcfile from a list of paths\n    \"\"\"\n    files = [\n        '{}/.millipederc'.format(os.environ.get('HOME')),\n        '/usr/local/etc/millipederc',\n        '/etc/millipederc',\n    ]\n    for filepath in files:\n        if os.path.isfile(filepath):\n            with open(filepath) as rcfile:\n                return parse_rcfile(rcfile)\n    return {}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the rcfile into a dict of key - value pairs.", "response": "def parse_rcfile(rcfile):\n    \"\"\"\n    Parses rcfile\n\n    Invalid lines are ignored with a warning\n    \"\"\"\n    def parse_bool(value):\n        \"\"\"Parse boolean string\"\"\"\n        value = value.lower()\n        if value in ['yes', 'true']:\n            return True\n        elif value in ['no', 'false']:\n            return False\n        else:\n            raise ValueError('''Can't parse {}'''.format(value))\n\n    valid_keys = {\n        'size': int,\n        'comment': str,\n        'template': str,\n        'reverse': parse_bool,\n        'opposite': parse_bool,\n        'position': int,\n    }\n    params = {}\n\n    for linenum, line in enumerate(rcfile):\n        line = line.strip()\n        if not line or line[0] == '#':\n            continue\n        pos = line.find(' ')\n        key = line[:pos]\n        value = line[pos:].strip()\n        if key in valid_keys.keys():\n            try:\n                params[key] = valid_keys[key](value)\n            except ValueError:\n                print('Ignoring line {} from rcfile'.format(linenum + 1),\n                      file=sys.stderr)\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_settings(args, rc_settings):\n    settings = {}\n    for key, value in args.items():\n        if key in ['reverse', 'opposite']:\n            settings[key] = value ^ rc_settings.get(key, False)\n        else:\n            settings[key] = value or rc_settings.get(key)\n\n    if not settings['size']:\n        settings['size'] = DEFAULT_SIZE\n    return settings", "response": "Compute the settings from the arguments and rc_settings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\noutput the millipede of the given size.", "response": "def millipede(size, comment=None, reverse=False, template='default', position=0, opposite=False):\n    \"\"\"\n    Output the millipede\n    \"\"\"\n    padding_offsets = [2, 1, 0, 1, 2, 3, 4, 4, 3]\n    padding_suite_length = len(padding_offsets)\n    head_padding_extra_offset = 2\n\n    if opposite:\n        padding_offsets.reverse()\n\n    position = position or 0\n\n    templates = {\n        'frozen': {'bodyr': '\u2554\u2550(\u2744\u2744\u2744)\u2550\u2557', 'body': '\u255a\u2550(\u2744\u2744\u2744)\u2550\u255d',\n                   'headr': '\u2554\u2299 \u2299\u2557', 'head': '\u255a\u2299 \u2299\u255d'},\n        'love': {'bodyr': '\u2554\u2550(\u2665\u2665\u2665)\u2550\u2557', 'body': '\u255a\u2550(\u2665\u2665\u2665)\u2550\u255d',\n                 'headr': '\u2554\u2299 \u2299\u2557', 'head': '\u255a\u2299 \u2299\u255d'},\n        'corporate': {'bodyr': '\u2554\u2550(\u00a9\u00a9\u00a9)\u2550\u2557', 'body': '\u255a\u2550(\u00a9\u00a9\u00a9)\u2550\u255d',\n                      'headr': '\u2554\u2299 \u2299\u2557', 'head': '\u255a\u2299 \u2299\u255d'},\n        'musician': {'bodyr': '\u2554\u2550(\u266b\u2669\u266c)\u2550\u2557', 'body': '\u255a\u2550(\u266b\u2669\u266c)\u2550\u255d',\n                     'headr': '\u2554\u2299 \u2299\u2557', 'head': '\u255a\u2299 \u2299\u255d'},\n        'bocal': {'bodyr': '\u2554\u2550(\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f)\u2550\u2557', 'body': '\u255a\u2550(\ud83d\udc1f\ud83d\udc1f\ud83d\udc1f)\u2550\u255d',\n                  'headr': '\u2554\u2299 \u2299\u2557', 'head': '\u255a\u2299 \u2299\u255d'},\n        'ascii': {'bodyr': '|=(###)=|', 'body': '|=(###)=|',\n                  'headr': '/\u2299 \u2299\\\\', 'head': '\\\\\u2299 \u2299/'},\n        'default': {'bodyr': '\u2554\u2550(\u2588\u2588\u2588)\u2550\u2557', 'body': '\u255a\u2550(\u2588\u2588\u2588)\u2550\u255d',\n                    'headr': '\u2554\u2299 \u2299\u2557', 'head': '\u255a\u2299 \u2299\u255d'},\n        'inception': {'bodyr': '\u2554\u2550(\ud83d\udc1b\ud83d\udc1b\ud83d\udc1b)\u2550\u2557', 'body': '\u255a\u2550(\ud83d\udc1b\ud83d\udc1b\ud83d\udc1b)\u2550\u255d',\n                      'headr': '\u2554\u2299 \u2299\u2557', 'head': '\u255a\u2299 \u2299\u255d'},\n        'humancentipede': {'bodyr': '\u2554\u2550(\ud83d\ude37\ud83d\ude37\ud83d\ude37)\u2550\u2557', 'body': '\u255a\u2550(\ud83d\ude37\ud83d\ude37\ud83d\ude37)\u2550\u255d',\n                           'headr': '\u2554\u2299 \u2299\u2557', 'head': '\u255a\u2299 \u2299\u255d'},\n        'heart': {'bodyr': '\u2554\u2550(\u2764\ufe0f\u2764\ufe0f\u2764\ufe0f)\u2550\u2557', 'body': '\u255a\u2550(\u2764\ufe0f\u2764\ufe0f\u2764\ufe0f)\u2550\u255d',\n                  'headr': '\u2554\u2299 \u2299\u2557', 'head': '\u255a\u2299 \u2299\u255d'},\n    }\n\n    template = templates.get(template, templates['default'])\n\n    head = \"{}{}\\n\".format(\n        \" \" * (padding_offsets[position % padding_suite_length] + head_padding_extra_offset),\n        template['headr'] if reverse else template['head']\n    )\n\n    body_lines = [\n        \"{}{}\\n\".format(\n            \" \" * padding_offsets[(x + position) % padding_suite_length],\n            template['bodyr'] if reverse else template['body']\n        )\n        for x in range(size)\n    ]\n\n    if reverse:\n        body_lines.reverse()\n\n    body = \"\".join(body_lines)\n\n    output = \"\"\n    if reverse:\n        output += body + head\n        if comment:\n            output += \"\\n\" + comment + \"\\n\"\n    else:\n        if comment:\n            output += comment + \"\\n\\n\"\n        output += head + body\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef api_post(message, url, name, http_data=None, auth=None):\n    try:\n        import requests\n    except ImportError:\n        print('requests is required to do api post.', file=sys.stderr)\n        sys.exit(1)\n\n    data = {name : message}\n    if http_data:\n        for var in http_data:\n            key, value = var.split('=')\n            data[key] = value\n\n    response = requests.post(\n        url,\n        data=data,\n        auth=auth\n    )\n\n    if response.status_code != 200:\n        raise RuntimeError('Unable to post data')", "response": "Send message as name to url."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread package long description from README file", "response": "def read_long_description(readme_file):\n    \"\"\" Read package long description from README file \"\"\"\n    try:\n        import pypandoc\n    except (ImportError, OSError) as exception:\n        print('No pypandoc or pandoc: %s' % (exception,))\n        if sys.version_info.major == 3:\n            handle = open(readme_file, encoding='utf-8')\n        else:\n            handle = open(readme_file)\n        long_description = handle.read()\n        handle.close()\n        return long_description\n    else:\n        return pypandoc.convert(readme_file, 'rst')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the content of the specified file as a string.", "response": "def content_from_path(path, encoding='utf-8'):\n    \"\"\"Return the content of the specified file as a string.\n\n    This function also supports loading resources from packages.\n    \"\"\"\n    if not os.path.isabs(path) and ':' in path:\n        package, path = path.split(':', 1)\n        content = resource_string(package, path)\n    else:\n        path = os.path.expanduser(path)\n        with open(path, 'rb') as fh:\n            content = fh.read()\n\n    return content.decode(encoding)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes the method with args", "response": "def execute(self, method, args, ref):\n        \"\"\" Execute the method with args \"\"\"\n\n        response = {'result': None, 'error': None, 'ref': ref}\n        fun = self.methods.get(method)\n        if not fun:\n            response['error'] = 'Method `{}` not found'.format(method)\n        else:\n            try:\n                response['result'] = fun(*args)\n            except Exception as exception:\n                logging.error(exception, exc_info=1)\n                response['error'] = str(exception)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering a function on this service", "response": "def register(self, name, fun, description=None):\n        \"\"\" Register function on this service \"\"\"\n        self.methods[name] = fun\n        self.descriptions[name] = description"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a client request.", "response": "def parse(cls, payload):\n        \"\"\" Parse client request \"\"\"\n        try:\n            method, args, ref = payload\n        except Exception as exception:\n            raise RequestParseError(exception)\n        else:\n            return method, args, ref"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process(self):\n\n        response = None\n\n        try:\n            payload = self.receive()\n            method, args, ref = self.parse(payload)\n            response = self.execute(method, args, ref)\n\n        except AuthenticateError as exception:\n            logging.error(\n                'Service error while authenticating request: {}'\n                .format(exception), exc_info=1)\n\n        except AuthenticatorInvalidSignature as exception:\n            logging.error(\n                'Service error while authenticating request: {}'\n                .format(exception), exc_info=1)\n\n        except DecodeError as exception:\n            logging.error(\n                'Service error while decoding request: {}'\n                .format(exception), exc_info=1)\n\n        except RequestParseError as exception:\n            logging.error(\n                'Service error while parsing request: {}'\n                .format(exception), exc_info=1)\n\n        else:\n            logging.debug('Service received payload: {}'.format(payload))\n\n        if response:\n            self.send(response)\n        else:\n            self.send('')", "response": "Receive data from socket and process request"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding the payload to be sent to a Responder", "response": "def build_payload(cls, method, args):\n        \"\"\" Build the payload to be sent to a `Responder` \"\"\"\n        ref = str(uuid.uuid4())\n        return (method, args, ref)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes a call to a Responder and return the result", "response": "def call(self, method, *args):\n        \"\"\" Make a call to a `Responder` and return the result \"\"\"\n\n        payload = self.build_payload(method, args)\n        logging.debug('* Client will send payload: {}'.format(payload))\n        self.send(payload)\n\n        res = self.receive()\n        assert payload[2] == res['ref']\n        return res['result'], res['error']"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the json file located at filepath and return a DotDict containing the configuration items.", "response": "def load(filepath=None, filecontent=None):\n    \"\"\" Read the json file located at `filepath`\n\n    If `filecontent` is specified, its content will be json decoded\n    and loaded instead.\n\n    Usage:\n        config.load(filepath=None, filecontent=None):\n        Provide either a filepath or a json string\n    \"\"\"\n    conf = DotDict()\n\n    assert filepath or filecontent\n    if not filecontent:\n        with io.FileIO(filepath) as handle:\n            filecontent = handle.read().decode('utf-8')\n    configs = json.loads(filecontent)\n    conf.update(configs.items())\n    return conf"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun the checks and exits.", "response": "def run_main(args: argparse.Namespace, do_exit=True) -> None:\n    \"\"\"Runs the checks and exits.\n\n    To extend this tool, use this function and set do_exit to False\n    to get returned the status code.\n    \"\"\"\n    if args.init:\n        generate()\n        return None  # exit after generate instead of starting to lint\n\n    handler = CheckHandler(\n        file=args.config_file, out_json=args.json, files=args.files)\n\n    for style in get_stylers():\n        handler.run_linter(style())\n\n    for linter in get_linters():\n        handler.run_linter(linter())\n\n    for security in get_security():\n        handler.run_linter(security())\n\n    for tool in get_tools():\n        tool = tool()\n\n        # Only run pypi if everything else passed\n        if tool.name == \"pypi\" and handler.status_code != 0:\n            continue\n\n        handler.run_linter(tool)\n\n    if do_exit:\n        handler.exit()\n    return handler.status_code"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef connect(self):\n        # type: () -> None\n        \"\"\"\n        Connect to server\n\n        Returns:\n            None\n\n        \"\"\"\n        if self.connection_type.lower() == 'ssl':\n            self.server = smtplib.SMTP_SSL(host=self.host, port=self.port, local_hostname=self.local_hostname,\n                                           timeout=self.timeout, source_address=self.source_address)\n        elif self.connection_type.lower() == 'lmtp':\n            self.server = smtplib.LMTP(host=self.host, port=self.port, local_hostname=self.local_hostname,\n                                       source_address=self.source_address)\n        else:\n            self.server = smtplib.SMTP(host=self.host, port=self.port, local_hostname=self.local_hostname,\n                                       timeout=self.timeout, source_address=self.source_address)\n        self.server.login(self.username, self.password)", "response": "Connects to the server and logs in to the server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send(self, recipients, subject, text_body, html_body=None, sender=None, **kwargs):\n        # type: (List[str], str, str, Optional[str], Optional[str], Any) -> None\n        \"\"\"\n        Send email\n\n        Args:\n            recipients (List[str]): Email recipient\n            subject (str): Email subject\n            text_body (str): Plain text email body\n            html_body (Optional[str]): HTML email body\n            sender (Optional[str]): Email sender. Defaults to global sender.\n            **kwargs: See below\n            mail_options (list): Mail options (see smtplib documentation)\n            rcpt_options (list): Recipient options (see smtplib documentation)\n\n        Returns:\n            None\n\n        \"\"\"\n        if sender is None:\n            sender = self.sender\n        v = validate_email(sender, check_deliverability=False)  # validate and get info\n        sender = v['email']  # replace with normalized form\n        normalised_recipients = list()\n        for recipient in recipients:\n            v = validate_email(recipient, check_deliverability=True)  # validate and get info\n            normalised_recipients.append(v['email'])  # replace with normalized form\n\n        if html_body is not None:\n            msg = MIMEMultipart('alternative')\n            part1 = MIMEText(text_body, 'plain')\n            part2 = MIMEText(html_body, 'html')\n            msg.attach(part1)\n            msg.attach(part2)\n        else:\n            msg = MIMEText(text_body)\n        msg['Subject'] = subject\n        msg['From'] = sender\n        msg['To'] = ', '.join(normalised_recipients)\n\n        # Perform operations via server\n        self.connect()\n        self.server.sendmail(sender, normalised_recipients, msg.as_string(), **kwargs)\n        self.close()", "response": "Sends an email to the specified recipients."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_session(db_url):\n        # type: (str) -> Session\n        \"\"\"Gets SQLAlchemy session given url. Your tables must inherit\n        from Base in hdx.utilities.database.\n\n        Args:\n            db_url (str): SQLAlchemy url\n\n        Returns:\n            sqlalchemy.orm.session.Session: SQLAlchemy session\n        \"\"\"\n        engine = create_engine(db_url, poolclass=NullPool, echo=False)\n        Session = sessionmaker(bind=engine)\n        Base.metadata.create_all(engine)\n        return Session()", "response": "Gets SQLAlchemy session given url."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting PostgreSQL database connection parameters from SQLAlchemy url", "response": "def get_params_from_sqlalchemy_url(db_url):\n        # type: (str) -> Dict[str,Any]\n        \"\"\"Gets PostgreSQL database connection parameters from SQLAlchemy url\n\n        Args:\n            db_url (str): SQLAlchemy url\n\n        Returns:\n            Dict[str,Any]: Dictionary of database connection parameters\n        \"\"\"\n        result = urlsplit(db_url)\n        return {'database': result.path[1:], 'host': result.hostname, 'port': result.port,\n                'username': result.username, 'password': result.password, 'driver': result.scheme}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting SQLAlchemy url from database connection parameters.", "response": "def get_sqlalchemy_url(database=None, host=None, port=None, username=None, password=None, driver='postgres'):\n        # type: (Optional[str], Optional[str], Union[int, str, None], Optional[str], Optional[str], str) -> str\n        \"\"\"Gets SQLAlchemy url from database connection parameters\n\n        Args:\n            database (Optional[str]): Database name\n            host (Optional[str]): Host where database is located\n            port (Union[int, str, None]): Database port\n            username (Optional[str]): Username to log into database\n            password (Optional[str]): Password to log into database\n            driver (str): Database driver. Defaults to 'postgres'.\n\n        Returns:\n            db_url (str): SQLAlchemy url\n        \"\"\"\n        strings = ['%s://' % driver]\n        if username:\n            strings.append(username)\n            if password:\n                strings.append(':%s@' % password)\n            else:\n                strings.append('@')\n        if host:\n            strings.append(host)\n        if port is not None:\n            strings.append(':%d' % int(port))\n        if database:\n            strings.append('/%s' % database)\n        return ''.join(strings)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwaiting for PostgreSQL database to be up", "response": "def wait_for_postgres(database, host, port, username, password):\n        # type: (Optional[str], Optional[str], Union[int, str, None], Optional[str], Optional[str]) -> None\n        \"\"\"Waits for PostgreSQL database to be up\n\n        Args:\n            database (Optional[str]): Database name\n            host (Optional[str]): Host where database is located\n            port (Union[int, str, None]): Database port\n            username (Optional[str]): Username to log into database\n            password (Optional[str]): Password to log into database\n\n        Returns:\n            None\n        \"\"\"\n        connecting_string = 'Checking for PostgreSQL...'\n        if port is not None:\n            port = int(port)\n        while True:\n            try:\n                logger.info(connecting_string)\n                connection = psycopg2.connect(\n                    database=database,\n                    host=host,\n                    port=port,\n                    user=username,\n                    password=password,\n                    connect_timeout=3\n                )\n                connection.close()\n                logger.info('PostgreSQL is running!')\n                break\n            except psycopg2.OperationalError:\n                time.sleep(1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn : returns a tuple num_of_not_None_caches list of unset caches endpoint", "response": "def get_unset_cache(self):\n        \"\"\"return : returns a tuple (num_of_not_None_caches, [list of unset caches endpoint])\n        \"\"\"\n        caches = []\n        if self._cached_api_global_response is None:\n            caches.append('global')\n        if self._cached_api_ticker_response is None:\n            caches.append('ticker')\n        return (len(caches), caches)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting filename from url and join to provided folder or temporary folder if no folder supplied.", "response": "def get_path_for_url(url, folder=None, filename=None, overwrite=False):\n        # type: (str, Optional[str], Optional[str], bool) -> str\n        \"\"\"Get filename from url and join to provided folder or temporary folder if no folder supplied, ensuring uniqueness\n\n        Args:\n            url (str): URL to download\n            folder (Optional[str]): Folder to download it to. Defaults to None (temporary folder).\n            filename (Optional[str]): Filename to use for downloaded file. Defaults to None (derive from the url).\n            overwrite (bool): Whether to overwrite existing file. Defaults to False.\n\n        Returns:\n            str: Path of downloaded file\n\n        \"\"\"\n        if not filename:\n            urlpath = urlsplit(url).path\n            filename = basename(urlpath)\n        filename, extension = splitext(filename)\n        if not folder:\n            folder = get_temp_dir()\n        path = join(folder, '%s%s' % (filename, extension))\n        if overwrite:\n            try:\n                remove(path)\n            except OSError:\n                pass\n        else:\n            count = 0\n            while exists(path):\n                count += 1\n                path = join(folder, '%s%d%s' % (filename, count, extension))\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_full_url(self, url):\n        # type: (str) -> str\n        \"\"\"Get full url including any additional parameters\n\n        Args:\n            url (str): URL for which to get full url\n\n        Returns:\n            str: Full url including any additional parameters\n        \"\"\"\n        request = Request('GET', url)\n        preparedrequest = self.session.prepare_request(request)\n        return preparedrequest.url", "response": "Get full url including any additional parameters"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting full url for GET request including parameters", "response": "def get_url_for_get(url, parameters=None):\n        # type: (str, Optional[Dict]) -> str\n        \"\"\"Get full url for GET request including parameters\n\n        Args:\n            url (str): URL to download\n            parameters (Optional[Dict]): Parameters to pass. Defaults to None.\n\n        Returns:\n            str: Full url\n\n        \"\"\"\n        spliturl = urlsplit(url)\n        getparams = OrderedDict(parse_qsl(spliturl.query))\n        if parameters is not None:\n            getparams.update(parameters)\n        spliturl = spliturl._replace(query=urlencode(getparams))\n        return urlunsplit(spliturl)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_url_params_for_post(url, parameters=None):\n        # type: (str, Optional[Dict]) -> Tuple[str, Dict]\n        \"\"\"Get full url for POST request and all parameters including any in the url\n\n        Args:\n            url (str): URL to download\n            parameters (Optional[Dict]): Parameters to pass. Defaults to None.\n\n        Returns:\n            Tuple[str, Dict]: (Full url, parameters)\n\n        \"\"\"\n        spliturl = urlsplit(url)\n        getparams = OrderedDict(parse_qsl(spliturl.query))\n        if parameters is not None:\n            getparams.update(parameters)\n        spliturl = spliturl._replace(query='')\n        full_url = urlunsplit(spliturl)\n        return full_url, getparams", "response": "Get full url and all parameters including any in the url\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hash_stream(self, url):\n        # type: (str) -> str\n        \"\"\"Stream file from url and hash it using MD5. Must call setup method first.\n\n        Args:\n            url (str): URL to download\n\n        Returns:\n            str: MD5 hash of file\n\n        \"\"\"\n        md5hash = hashlib.md5()\n        try:\n            for chunk in self.response.iter_content(chunk_size=10240):\n                if chunk:  # filter out keep-alive new chunks\n                    md5hash.update(chunk)\n            return md5hash.hexdigest()\n        except Exception as e:\n            raisefrom(DownloadError, 'Download of %s failed in retrieval of stream!' % url, e)", "response": "Stream file from url and hash it using MD5."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stream_file(self, url, folder=None, filename=None, overwrite=False):\n        # type: (str, Optional[str], Optional[str], bool) -> str\n        \"\"\"Stream file from url and store in provided folder or temporary folder if no folder supplied.\n        Must call setup method first.\n\n        Args:\n            url (str): URL to download\n            filename (Optional[str]): Filename to use for downloaded file. Defaults to None (derive from the url).\n            folder (Optional[str]): Folder to download it to. Defaults to None (temporary folder).\n            overwrite (bool): Whether to overwrite existing file. Defaults to False.\n\n        Returns:\n            str: Path of downloaded file\n\n        \"\"\"\n        path = self.get_path_for_url(url, folder, filename, overwrite)\n        f = None\n        try:\n            f = open(path, 'wb')\n            for chunk in self.response.iter_content(chunk_size=10240):\n                if chunk:  # filter out keep-alive new chunks\n                    f.write(chunk)\n                    f.flush()\n            return f.name\n        except Exception as e:\n            raisefrom(DownloadError, 'Download of %s failed in retrieval of stream!' % url, e)\n        finally:\n            if f:\n                f.close()", "response": "Stream file from url and store in provided folder or temporary folder if no folder supplied."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef download_file(self, url, folder=None, filename=None, overwrite=False,\n                      post=False, parameters=None, timeout=None):\n        # type: (str, Optional[str], Optional[str], bool, bool, Optional[Dict], Optional[float]) -> str\n        \"\"\"Download file from url and store in provided folder or temporary folder if no folder supplied\n\n        Args:\n            url (str): URL to download\n            folder (Optional[str]): Folder to download it to. Defaults to None.\n            filename (Optional[str]): Filename to use for downloaded file. Defaults to None (derive from the url).\n            overwrite (bool): Whether to overwrite existing file. Defaults to False.\n            post (bool): Whether to use POST instead of GET. Defaults to False.\n            parameters (Optional[Dict]): Parameters to pass. Defaults to None.\n            timeout (Optional[float]): Timeout for connecting to URL. Defaults to None (no timeout).\n\n        Returns:\n            str: Path of downloaded file\n\n        \"\"\"\n        self.setup(url, stream=True, post=post, parameters=parameters, timeout=timeout)\n        return self.stream_file(url, folder, filename, overwrite)", "response": "Download file from url and store in provided folder or temporary folder if no folder supplied"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef download(self, url, post=False, parameters=None, timeout=None):\n        # type: (str, bool, Optional[Dict], Optional[float]) -> requests.Response\n        \"\"\"Download url\n\n        Args:\n            url (str): URL to download\n            post (bool): Whether to use POST instead of GET. Defaults to False.\n            parameters (Optional[Dict]): Parameters to pass. Defaults to None.\n            timeout (Optional[float]): Timeout for connecting to URL. Defaults to None (no timeout).\n\n        Returns:\n            requests.Response: Response\n\n        \"\"\"\n        return self.setup(url, stream=False, post=post, parameters=parameters, timeout=timeout)", "response": "Download the object from the specified URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a tabular stream of the naculiaci.", "response": "def get_tabular_stream(self, url, **kwargs):\n        # type: (str, Any) -> tabulator.Stream\n        \"\"\"Get Tabulator stream.\n\n        Args:\n            url (str): URL to download\n            **kwargs:\n            headers (Union[int, List[int], List[str]]): Number of row(s) containing headers or list of headers\n            file_type (Optional[str]): Type of file. Defaults to inferring.\n            delimiter (Optional[str]): Delimiter used for values in each row. Defaults to inferring.\n\n        Returns:\n            tabulator.Stream: Tabulator Stream object\n\n        \"\"\"\n        self.close_response()\n        file_type = kwargs.get('file_type')\n        if file_type is not None:\n            kwargs['format'] = file_type\n            del kwargs['file_type']\n        try:\n            self.response = tabulator.Stream(url, **kwargs)\n            self.response.open()\n            return self.response\n        except TabulatorException as e:\n            raisefrom(DownloadError, 'Getting tabular stream for %s failed!' % url, e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_tabular_rows(self, url, dict_rows=False, **kwargs):\n        # type: (str, bool, Any) -> Iterator[Dict]\n        \"\"\"Get iterator for reading rows from tabular data. Each row is returned as a dictionary.\n\n        Args:\n            url (str): URL to download\n            dict_rows (bool): Return dict (requires headers parameter) or list for each row. Defaults to False (list).\n            **kwargs:\n            headers (Union[int, List[int], List[str]]): Number of row(s) containing headers or list of headers\n            file_type (Optional[str]): Type of file. Defaults to inferring.\n            delimiter (Optional[str]): Delimiter used for values in each row. Defaults to inferring.\n\n        Returns:\n            Iterator[Union[List,Dict]]: Iterator where each row is returned as a list or dictionary.\n\n        \"\"\"\n        return self.get_tabular_stream(url, **kwargs).iter(keyed=dict_rows)", "response": "Get iterator for reading rows from tabular data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading 2 column csv from url and return a dictionary of keys and values", "response": "def download_tabular_key_value(self, url, **kwargs):\n        # type: (str, Any) -> Dict\n        \"\"\"Download 2 column csv from url and return a dictionary of keys (first column) and values (second column)\n\n        Args:\n            url (str): URL to download\n            **kwargs:\n            headers (Union[int, List[int], List[str]]): Number of row(s) containing headers or list of headers\n            file_type (Optional[str]): Type of file. Defaults to inferring.\n            delimiter (Optional[str]): Delimiter used for values in each row. Defaults to inferring.\n\n        Returns:\n            Dict: Dictionary keys (first column) and values (second column)\n\n        \"\"\"\n        output_dict = dict()\n        for row in self.get_tabular_rows(url, **kwargs):\n            if len(row) < 2:\n                continue\n            output_dict[row[0]] = row[1]\n        return output_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading multicolumn csv from url and return dictionary where keys are first column and values are dictionaries with keys from column beneath headers and values from columns beneath .", "response": "def download_tabular_rows_as_dicts(self, url, headers=1, keycolumn=1, **kwargs):\n        # type: (str, Union[int, List[int], List[str]], int, Any) -> Dict[Dict]\n        \"\"\"Download multicolumn csv from url and return dictionary where keys are first column and values are\n        dictionaries with keys from column headers and values from columns beneath\n\n        Args:\n            url (str): URL to download\n            headers (Union[int, List[int], List[str]]): Number of row(s) containing headers or list of headers. Defaults to 1.\n            keycolumn (int): Number of column to be used for key. Defaults to 1.\n            **kwargs:\n            file_type (Optional[str]): Type of file. Defaults to inferring.\n            delimiter (Optional[str]): Delimiter used for values in each row. Defaults to inferring.\n\n        Returns:\n            Dict[Dict]: Dictionary where keys are first column and values are dictionaries with keys from column\n            headers and values from columns beneath\n\n        \"\"\"\n        kwargs['headers'] = headers\n        stream = self.get_tabular_stream(url, **kwargs)\n        output_dict = dict()\n        headers = stream.headers\n        key_header = headers[keycolumn - 1]\n        for row in stream.iter(keyed=True):\n            first_val = row[key_header]\n            output_dict[first_val] = dict()\n            for header in row:\n                if header == key_header:\n                    continue\n                else:\n                    output_dict[first_val][header] = row[header]\n        return output_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef init(ctx, force):\n    if os.path.exists(PROJECT_CONFIG) and not force:\n        click.secho(\n            'An existing configuration file was found at \"{}\".\\n'\n            .format(PROJECT_CONFIG),\n            fg='red', bold=True\n        )\n        click.secho(\n            'Please remove it before in order to run the setup wizard or use\\n'\n            'the --force flag to overwrite it.'\n        )\n        ctx.exit(1)\n\n    project_key = click.prompt('Project key on the issue tracker')\n    base_branch = click.prompt('Integration branch', default='master')\n\n    virtualenvs = ('.venv', '.env', 'venv', 'env')\n    for p in virtualenvs:\n        if os.path.exists(os.path.join(p, 'bin', 'activate')):\n            venv = p\n            break\n    else:\n        venv = ''\n    venv_path = click.prompt('Path to virtual environment', default=venv)\n\n    project_id = click.prompt('Project ID on Harvest', type=int)\n    task_id = click.prompt('Task id on Harvest', type=int)\n\n    config = configparser.ConfigParser()\n\n    config.add_section('lancet')\n    config.set('lancet', 'virtualenv', venv_path)\n\n    config.add_section('tracker')\n    config.set('tracker', 'default_project', project_key)\n\n    config.add_section('harvest')\n    config.set('harvest', 'project_id', str(project_id))\n    config.set('harvest', 'task_id', str(task_id))\n\n    config.add_section('repository')\n    config.set('repository', 'base_branch', base_branch)\n\n    with open(PROJECT_CONFIG, 'w') as fh:\n        config.write(fh)\n\n    click.secho('\\nConfiguration correctly written to \"{}\".'\n                .format(PROJECT_CONFIG), fg='green')", "response": "Wizard to create a project - level configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef logout(lancet, service):\n    if service:\n        services = [service]\n    else:\n        services = ['tracker', 'harvest']\n\n    for service in services:\n        url = lancet.config.get(service, 'url')\n        key = 'lancet+{}'.format(url)\n        username = lancet.config.get(service, 'username')\n        with taskstatus('Logging out from {}', url) as ts:\n            if keyring.get_password(key, username):\n                keyring.delete_password(key, username)\n                ts.ok('Logged out from {}', url)\n            else:\n                ts.ok('Already logged out from {}', url)", "response": "Forget saved passwords for the web services."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting all currently configured services.", "response": "def _services(lancet):\n    \"\"\"List all currently configured services.\"\"\"\n    def get_services(config):\n        for s in config.sections():\n            if config.has_option(s, 'url'):\n                if config.has_option(s, 'username'):\n                    yield s\n\n    for s in get_services(lancet.config):\n        click.echo('{}[Logout from {}]'.format(s, lancet.config.get(s, 'url')))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a request to the specified endpoint.", "response": "def send_request(self, endpoint='ticker', coin_name=None, **kwargs):\n        \"\"\": param string 'ticker', it's 'ticker' if we want info about coins,\n            'global' for global market's info.\n           : param string 'coin_name', specify the name of the coin, if None,\n             we'll retrieve info about all available coins.\n        \"\"\"\n\n        built_url = self._make_url(endpoint, coin_name)\n        payload = dict(**kwargs)\n\n        self._process_request(endpoint, built_url, payload)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_response(self, data_type=None):\n        if not data_type:\n            return self.cache.get_response(r_type='ticker') or self.cache.get_response(r_type='global')\n        elif data_type == 'ticker':\n            return self.cache.get_response(r_type='ticker')\n        return self.cache.get_response(r_type='global')", "response": "return json response from API converted into python list\n          "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iso_639_alpha3(code):\n    code = normalize_code(code)\n    code = ISO3_MAP.get(code, code)\n    if code in ISO3_ALL:\n        return code", "response": "Convert a given language identifier into an ISO 639 Part 2 code such that it can be used as an ISO 639 Part 2 code such as eng deu or en."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_to_alpha3(languages, synonyms=True):\n    codes = set([])\n    for language in ensure_list(languages):\n        code = iso_639_alpha3(language)\n        if code is None:\n            continue\n        codes.add(code)\n        if synonyms:\n            codes.update(expand_synonyms(code))\n    return codes", "response": "Parse all the language codes in a given list into ISO 639 Part 2 codes\n    and optionally expand synonyms."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new pull request for this issue.", "response": "def pull_request(ctx, base_branch, open_pr, stop_timer):\n    \"\"\"Create a new pull request for this issue.\"\"\"\n    lancet = ctx.obj\n\n    review_status = lancet.config.get(\"tracker\", \"review_status\")\n    remote_name = lancet.config.get(\"repository\", \"remote_name\")\n\n    if not base_branch:\n        base_branch = lancet.config.get(\"repository\", \"base_branch\")\n\n    # Get the issue\n    issue = get_issue(lancet)\n\n    transition = get_transition(ctx, lancet, issue, review_status)\n\n    # Get the working branch\n    branch = get_branch(lancet, issue, create=False)\n\n    with taskstatus(\"Checking pre-requisites\") as ts:\n        if not branch:\n            ts.abort(\"No working branch found\")\n\n        if lancet.tracker.whoami() not in issue.assignees:\n            ts.abort(\"Issue currently not assigned to you\")\n\n        # TODO: Check mergeability\n\n    # TODO: Check remote status (PR does not already exist)\n\n    # Push to remote\n    with taskstatus('Pushing to \"{}\"', remote_name) as ts:\n        remote = lancet.repo.lookup_remote(remote_name)\n        if not remote:\n            ts.abort('Remote \"{}\" not found', remote_name)\n\n        from ..git import CredentialsCallbacks\n\n        remote.push([branch.name], callbacks=CredentialsCallbacks())\n\n        ts.ok('Pushed latest changes to \"{}\"', remote_name)\n\n    # Create pull request\n    with taskstatus(\"Creating pull request\") as ts:\n        template_path = lancet.config.get(\"repository\", \"pr_template\")\n        message = edit_template(template_path, issue=issue)\n\n        if not message:\n            ts.abort(\"You didn't provide a title for the pull request\")\n\n        title, body = message.split(\"\\n\", 1)\n        title = title.strip()\n\n        if not title:\n            ts.abort(\"You didn't provide a title for the pull request\")\n\n        try:\n            pr = lancet.scm_manager.create_pull_request(\n                branch.branch_name, base_branch, title, body.strip(\"\\n\")\n            )\n        except PullRequestAlreadyExists as e:\n            pr = e.pull_request\n            ts.ok(\"Pull request does already exist at {}\", pr.link)\n        else:\n            ts.ok(\"Pull request created at {}\", pr.link)\n\n    # Update issue\n    set_issue_status(lancet, issue, review_status, transition)\n\n    # TODO: Post to activity stream on JIRA?\n    # TODO: Post to Slack?\n\n    # Stop harvest timer\n    if stop_timer:\n        with taskstatus(\"Pausing harvest timer\") as ts:\n            lancet.timer.pause()\n            ts.ok(\"Harvest timer paused\")\n\n    # Open the pull request page in the browser if requested\n    if open_pr:\n        click.launch(pr.link)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a BeautifulSoup object for a given url.", "response": "def get_soup(url, downloader=None, user_agent=None, user_agent_config_yaml=None, user_agent_lookup=None, **kwargs):\n    # type: (str, Download, Optional[str], Optional[str], Optional[str], Any) -> BeautifulSoup\n    \"\"\"\n    Get BeautifulSoup object for a url. Requires either global user agent to be set or appropriate user agent\n    parameter(s) to be completed.\n\n    Args:\n        url (str): url to read\n        downloader (Download): Download object. Defaults to creating a Download object with given user agent values.\n        user_agent (Optional[str]): User agent string. HDXPythonUtilities/X.X.X- is prefixed.\n        user_agent_config_yaml (Optional[str]): Path to YAML user agent configuration. Ignored if user_agent supplied. Defaults to ~/.useragent.yml.\n        user_agent_lookup (Optional[str]): Lookup key for YAML. Ignored if user_agent supplied.\n\n    Returns:\n        BeautifulSoup: The BeautifulSoup object for a url\n\n    \"\"\"\n    if not downloader:\n        downloader = Download(user_agent, user_agent_config_yaml, user_agent_lookup, **kwargs)\n    response = downloader.download(url)\n    return BeautifulSoup(response.text, 'html.parser')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract HTML table as list of dictionaries", "response": "def extract_table(tabletag):\n    # type: (Tag) -> List[Dict]\n    \"\"\"\n    Extract HTML table as list of dictionaries\n\n    Args:\n        tabletag (Tag): BeautifulSoup tag\n\n    Returns:\n        str: Text of tag stripped of leading and trailing whitespace and newlines and with &nbsp replaced with space\n\n    \"\"\"\n    theadtag = tabletag.find_next('thead')\n\n    headertags = theadtag.find_all('th')\n    if len(headertags) == 0:\n        headertags = theadtag.find_all('td')\n    headers = []\n    for tag in headertags:\n        headers.append(get_text(tag))\n\n    tbodytag = tabletag.find_next('tbody')\n    trtags = tbodytag.find_all('tr')\n\n    table = list()\n    for trtag in trtags:\n        row = dict()\n        tdtags = trtag.find_all('td')\n        for i, tag in enumerate(tdtags):\n            row[headers[i]] = get_text(tag)\n        table.append(row)\n    return table"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap function - based callable_obj into a Route instance.", "response": "def wrap_callable(cls, uri, methods, callable_obj):\n        \"\"\"Wraps function-based callable_obj into a `Route` instance, else\n        proxies a `bottle_neck.handlers.BaseHandler` subclass instance.\n\n        Args:\n            uri (str):  The uri relative path.\n            methods (tuple): A tuple of valid method strings.\n            callable_obj (instance): The callable object.\n\n        Returns:\n            A route instance.\n\n        Raises:\n            RouteError for invalid callable object type.\n        \"\"\"\n        if isinstance(callable_obj, HandlerMeta):\n            callable_obj.base_endpoint = uri\n            callable_obj.is_valid = True\n            return callable_obj\n\n        if isinstance(callable_obj, types.FunctionType):\n            return cls(uri=uri, methods=methods, callable_obj=callable_obj)\n\n        raise RouteError(\"Invalid handler type.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_app(self, app):\n        app.route(self.uri, methods=self.methods)(self.callable_obj)\n\n        return self", "response": "Register the route object to a bottle. Bottle app instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a handler callable to a specific route.", "response": "def register_handler(self, callable_obj, entrypoint, methods=('GET',)):\n        \"\"\"Register a handler callable to a specific route.\n\n        Args:\n            entrypoint (str): The uri relative path.\n            methods (tuple): A tuple of valid method strings.\n            callable_obj (callable): The callable object.\n\n        Returns:\n            The Router instance (for chaining purposes).\n\n        Raises:\n            RouteError, for missing routing params or invalid callable\n            object type.\n        \"\"\"\n\n        router_obj = Route.wrap_callable(\n            uri=entrypoint,\n            methods=methods,\n            callable_obj=callable_obj\n        )\n\n        if router_obj.is_valid:\n            self._routes.add(router_obj)\n            return self\n        \n        raise RouteError(  # pragma: no cover\n            \"Missing params: methods: {} - entrypoint: {}\".format(\n                methods, entrypoint\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmounts all registered routes to a bottle. py application instance.", "response": "def mount(self, app=None):\n        \"\"\"Mounts all registered routes to a bottle.py application instance.\n\n        Args:\n            app (instance): A `bottle.Bottle()` application instance.\n\n        Returns:\n            The Router instance (for chaining purposes).\n        \"\"\"\n        for endpoint in self._routes:\n            endpoint.register_app(app)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _tolog(self,level):\r\n        def wrapper(msg):\r\n            if self.log_colors:\r\n                color = self.log_colors[level.upper()]\r\n                getattr(self.logger, level.lower())(coloring(\"- {}\".format(msg), color))\r\n            else:\r\n                getattr(self.logger, level.lower())(msg)\r\n    \r\n        return wrapper", "response": "log with different level"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_status(cls, status_line, msg=None):\n        method = getattr(cls, status_line.lower()[4:].replace(' ', '_'))\n        return method(msg)", "response": "Returns a class method from bottle. HTTPResponse. status_line attribute."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bad_request(cls, errors=None):\n        if cls.expose_status:  # pragma: no cover\n            cls.response.content_type = 'application/json'\n            cls.response._status_line = '400 Bad Request'\n\n        return cls(400, errors=errors).to_json", "response": "Shortcut API for HTTP 400 Bad Request response."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unauthorized(cls, errors=None):\n        if cls.expose_status:  # pragma: no cover\n            cls.response.content_type = 'application/json'\n            cls.response._status_line = '401 Unauthorized'\n\n        return cls(401, errors=errors).to_json", "response": "Shortcut API for HTTP 401 Unauthorized response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshort cut for JSON response service data.", "response": "def to_json(self):\n        \"\"\"Short cut for JSON response service data.\n\n        Returns:\n            Dict that implements JSON interface.\n        \"\"\"\n\n        web_resp = collections.OrderedDict()\n\n        web_resp['status_code'] = self.status_code\n        web_resp['status_text'] = dict(HTTP_CODES).get(self.status_code)\n        web_resp['data'] = self.data if self.data is not None else {}\n        web_resp['errors'] = self.errors or []\n\n        return web_resp"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setup_logging(**kwargs):\n    # type: (Any) -> None\n    \"\"\"Setup logging configuration\n\n    Args:\n        **kwargs: See below\n        logging_config_dict (dict): Logging configuration dictionary OR\n        logging_config_json (str): Path to JSON Logging configuration OR\n        logging_config_yaml (str): Path to YAML Logging configuration. Defaults to internal logging_configuration.yml.\n        smtp_config_dict (dict): Email Logging configuration dictionary if using default logging configuration OR\n        smtp_config_json (str): Path to JSON Email Logging configuration if using default logging configuration OR\n        smtp_config_yaml (str): Path to YAML Email Logging configuration if using default logging configuration\n\n    Returns:\n        None\n    \"\"\"\n    smtp_config_found = False\n    smtp_config_dict = kwargs.get('smtp_config_dict', None)\n    if smtp_config_dict:\n        smtp_config_found = True\n        print('Loading smtp configuration customisations from dictionary')\n\n    smtp_config_json = kwargs.get('smtp_config_json', '')\n    if smtp_config_json:\n        if smtp_config_found:\n            raise LoggingError('More than one smtp configuration file given!')\n        smtp_config_found = True\n        print('Loading smtp configuration customisations from: %s' % smtp_config_json)\n        smtp_config_dict = load_json(smtp_config_json)\n\n    smtp_config_yaml = kwargs.get('smtp_config_yaml', '')\n    if smtp_config_yaml:\n        if smtp_config_found:\n            raise LoggingError('More than one smtp configuration file given!')\n        smtp_config_found = True\n        print('Loading smtp configuration customisations from: %s' % smtp_config_yaml)\n        smtp_config_dict = load_yaml(smtp_config_yaml)\n\n    logging_smtp_config_dict = None\n    logging_config_found = False\n    logging_config_dict = kwargs.get('logging_config_dict', None)\n    if logging_config_dict:\n        logging_config_found = True\n        print('Loading logging configuration from dictionary')\n\n    logging_config_json = kwargs.get('logging_config_json', '')\n    if logging_config_json:\n        if logging_config_found:\n            raise LoggingError('More than one logging configuration file given!')\n        logging_config_found = True\n        print('Loading logging configuration from: %s' % logging_config_json)\n        logging_config_dict = load_json(logging_config_json)\n\n    logging_config_yaml = kwargs.get('logging_config_yaml', '')\n    if logging_config_found:\n        if logging_config_yaml:\n            raise LoggingError('More than one logging configuration file given!')\n    else:\n        if not logging_config_yaml:\n            print('No logging configuration parameter. Using default.')\n            logging_config_yaml = script_dir_plus_file('logging_configuration.yml', setup_logging)\n            if smtp_config_found:\n                logging_smtp_config_yaml = script_dir_plus_file('logging_smtp_configuration.yml', setup_logging)\n                print('Loading base SMTP logging configuration from: %s' % logging_smtp_config_yaml)\n                logging_smtp_config_dict = load_yaml(logging_smtp_config_yaml)\n        print('Loading logging configuration from: %s' % logging_config_yaml)\n        logging_config_dict = load_yaml(logging_config_yaml)\n\n    if smtp_config_found:\n        if logging_smtp_config_dict:\n            logging_config_dict = merge_dictionaries([logging_config_dict, logging_smtp_config_dict, smtp_config_dict])\n        else:\n            raise LoggingError('SMTP logging configuration file given but not using default logging configuration!')\n    file_only = os.getenv('LOG_FILE_ONLY')\n    if file_only is not None and file_only.lower() not in ['false', 'f', 'n', 'no', '0']:\n        root = logging_config_dict.get('root')\n        if root is not None:\n            handlers = root.get('handlers', list())\n            for i, handler in enumerate(handlers):\n                if handler.lower() == 'console':\n                    del handlers[i]\n                    break\n\n    logging.config.dictConfig(logging_config_dict)", "response": "Setup logging configuration\n\n    Args:\n        **kwargs: See below\n        logging_config_dict (dict): Logging configuration dictionary OR\n        logging_config_json (str): Path to JSON Logging configuration OR\n        logging_config_yaml (str): Path to YAML Logging configuration. Defaults to internal logging_configuration.yml.\n        smtp_config_dict (dict): Email Logging configuration dictionary if using default logging configuration OR\n        smtp_config_json (str): Path to JSON Email Logging configuration if using default logging configuration OR\n        smtp_config_yaml (str): Path to YAML Email Logging configuration if using default logging configuration\n\n    Returns:\n        None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _search_generator(self, item: Any) -> Generator[Tuple[Any, Any], None, None]:\n        results = 0\n        for key, value in self.enumerate(item):\n            yield key, value\n            results += 1\n        if results == 0:\n            raise SearchError(str(item))", "response": "A helper method for self. search that returns a generator rather than a list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ask_bool(question: str, default: bool = True) -> bool:\n    default_q = \"Y/n\" if default else \"y/N\"\n    answer = input(\"{0} [{1}]: \".format(question, default_q))\n    lower = answer.lower()\n    if not lower:\n        return default\n    return lower == \"y\"", "response": "Asks a question yes no style"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ask_int(question: str, default: int = None) -> int:\n    default_q = \" [default: {0}]: \".format(\n        default) if default is not None else \"\"\n    answer = input(\"{0} [{1}]: \".format(question, default_q))\n\n    if not answer:\n        if default is None:\n            print(\"No default set, try again.\")\n            return ask_int(question, default)\n        return default\n\n    if any(x not in \"1234567890\" for x in answer):\n        print(\"Please enter only numbers (0-9).\")\n        return ask_int(question, default)\n\n    return int(answer)", "response": "Asks for a number in a question"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nask for a path", "response": "def ask_path(question: str, default: str = None) -> str:\n    \"\"\"Asks for a path\"\"\"\n    default_q = \" [default: {0}]: \".format(\n        default) if default is not None else \"\"\n    answer = input(\"{0} [{1}]: \".format(question, default_q))\n\n    if answer == \"\":\n        return default\n\n    if os.path.isdir(answer):\n        return answer\n\n    print(\n        \"No such directory: {answer}, please try again\".format(answer=answer))\n    return ask_path(question, default)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ask_list(question: str, default: list = None) -> list:\n    default_q = \" [default: {0}]: \".format(\n        \",\".join(default)) if default is not None else \"\"\n    answer = input(\"{0} [{1}]: \".format(question, default_q))\n\n    if answer == \"\":\n        return default\n    return [ans.strip() for ans in answer.split(\",\")]", "response": "Asks for a comma seperated list of strings"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nask for a simple string", "response": "def ask_str(question: str, default: str = None):\n    \"\"\"Asks for a simple string\"\"\"\n    default_q = \" [default: {0}]: \".format(\n        default) if default is not None else \"\"\n    answer = input(\"{0} [{1}]: \".format(question, default_q))\n\n    if answer == \"\":\n        return default\n    return answer"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlets the user enter the tools he want to use", "response": "def get_tools(self) -> list:\n        \"\"\"Lets the user enter the tools he want to use\"\"\"\n        tools = \"flake8,pylint,vulture,pyroma,isort,yapf,safety,dodgy,pytest,pypi\".split(\n            \",\")\n        print(\"Available tools: {0}\".format(\",\".join(tools)))\n        answer = ask_list(\"What tools would you like to use?\",\n                          [\"flake8\", \"pytest\"])\n\n        if any(tool not in tools for tool in answer):\n            print(\"Invalid answer, retry.\")\n            self.get_tools()\n        return answer"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute pagination info for the current record count and base uri.", "response": "def paginator(limit, offset, record_count, base_uri, page_nav_tpl='&limit={}&offset={}'):\n    \"\"\"Compute pagination info for collection filtering.\n\n    Args:\n        limit (int): Collection filter limit.\n        offset (int): Collection filter offset.\n        record_count (int): Collection filter total record count.\n        base_uri (str): Collection filter base uri (without limit, offset)\n        page_nav_tpl (str): Pagination template.\n\n    Returns:\n        A mapping of pagination info.\n    \"\"\"\n\n    total_pages = int(math.ceil(record_count / limit))\n\n    next_cond = limit + offset <= record_count\n    prev_cond = offset >= limit\n\n    next_page = base_uri + page_nav_tpl.format(limit, offset + limit) if next_cond else None\n\n    prev_page = base_uri + page_nav_tpl.format(limit, offset - limit) if prev_cond else None\n\n    return OrderedDict([\n        ('total_count', record_count),\n        ('total_pages', total_pages),\n        ('next_page', next_page),\n        ('prev_page', prev_page)\n    ])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef serialize(obj):\n    from datetime import datetime, date, time\n    if isinstance(obj, date) and not isinstance(obj, datetime):\n        obj = datetime.combine(obj, time.min)\n    if isinstance(obj, datetime):\n        return obj.isoformat()", "response": "JSON serializer that accepts datetime & date"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck whether the status code of the response equals expected_status and raise an APIError otherwise.", "response": "def check(response, expected_status=200, url=None):\n    \"\"\"\n    Check whether the status code of the response equals expected_status and\n    raise an APIError otherwise.\n    @param url: The url of the response (for error messages).\n                Defaults to response.url\n    @param json: if True, return r.json(), otherwise return r.text\n    \"\"\"\n    if response.status_code != expected_status:\n        if url is None:\n            url = response.url\n\n        try:\n            err = response.json()\n        except:\n            err = {} # force generic error\n\n        if all(x in err for x in (\"status\", \"message\", \"description\", \"details\")):\n            raise _APIError(err[\"status\"], err['message'], url,\n                           err, err[\"description\"], err[\"details\"])\n        else: # generic error\n            suffix = \".html\" if \"<html\" in response.text else \".txt\"\n            msg = response.text\n            if len(msg) > 200:\n                with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as f:\n                    f.write(response.text.encode(\"utf-8\"))\n                msg = \"{}...\\n\\n[snipped; full response written to {f.name}\".format(msg[:100], **locals())\n                \n            msg = (\"Request {url!r} returned code {response.status_code},\"\n                   \" expected {expected_status}. \\n{msg}\".format(**locals()))\n            raise _APIError(response.status_code, msg, url, response.text)\n    if response.headers.get('Content-Type') == 'application/json':\n        try:\n            return response.json()\n        except:\n            raise Exception(\"Cannot decode json; text={response.text!r}\"\n                            .format(**locals()))\n    else:\n        return response.text"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_auth(self, user=None, password=None):\n        fn = os.path.expanduser(AUTH_FILE)\n        if os.path.exists(fn):\n            for i, line in enumerate(csv.reader(open(fn))):\n                if len(line) != 3:\n                    log.warning(\"Cannot parse line {i} in {fn}\".format(**locals()))\n                    continue\n                hostname, username, pwd = line\n                if (hostname in (\"\", \"*\", self.host)\n                    and (user is None or username == user)):\n                    return (username, pwd)\n        if user is None:\n            user = os.environ.get(\"AMCAT_USER\", os.environ.get(\"USER\"))\n        if password is None:\n            password = os.environ.get(\"AMCAT_PASSWORD\")\n        if user is None or password is None:\n            raise Exception(\"No authentication info for {user}@{self.host} \"\n                            \"from {fn} or AMCAT_USER / AMCAT_PASSWORD \"\n                            \"variables\".format(**locals()))\n        return user, password", "response": "Get the authentication info for the current user from the AUTH_FILE environment variable"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef request(self, url, method=\"get\", format=\"json\", data=None,\n                expected_status=None, headers=None, use_xpost=True, **options):\n        \"\"\"\n        Make an HTTP request to the given relative URL with the host,\n        user, and password information. Returns the deserialized json\n        if successful, and raises an exception otherwise\n        \"\"\"\n        if expected_status is None:\n            if method == \"get\":\n                expected_status = 200\n            elif method == \"post\":\n                expected_status = 201\n            else:\n                raise ValueError(\"No expected status supplied and method unknown.\")\n\n        if not url.startswith(\"http\"):\n            url = \"{self.host}/api/v4/{url}\".format(**locals())\n        if format is not None:\n            options = dict({'format': format}, **options)\n        options = {field: value for field, value in options.items() if value is not None}\n        headers = dict(headers or {}, Authorization=\"Token {}\".format(self.token))\n        #headers['Accept-encoding'] = 'gzip'\n\n        if method == \"get\" and use_xpost:\n            # If method is purely GET, we can use X-HTTP-METHOD-OVERRIDE to send our\n            # query via POST. This allows for a large number of parameters to be supplied\n            assert(data is None)\n\n            headers.update({\"X-HTTP-METHOD-OVERRIDE\": method})\n            data = options\n            options = None\n            method = \"post\"\n\n        r = requests.request(method, url, data=data, params=options, headers=headers)\n\n        log.debug(\n            \"HTTP {method} {url} (options={options!r}, data={data!r},\"\n            \"headers={headers}) -> {r.status_code}\".format(**locals())\n        )\n        return check(r, expected_status=expected_status)", "response": "Make an HTTP request to the given URL with the host user and password information. Returns the deserialized json if successful and raises an exception if not successful."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_pages(self, url, page=1, page_size=100, yield_pages=False, **filters):\n        n = 0\n        for page in itertools.count(page):\n            r = self.request(url, page=page, page_size=page_size, **filters)\n            n += len(r['results'])\n            log.debug(\"Got {url} page {page} / {pages}\".format(url=url, **r))\n            if yield_pages:\n                yield r\n            else:\n                for row in r['results']:\n                    yield row\n            if r['next'] is None:\n                break", "response": "Get all pages at url yielding individual results"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_scroll(self, url, page_size=100, yield_pages=False, **filters):\n        n = 0\n        options = dict(page_size=page_size, **filters)\n        format = filters.get('format')\n        while True:\n            r = self.request(url, use_xpost=False, **options)\n            n += len(r['results'])\n            log.debug(\"Got {} {n}/{total}\".format(url.split(\"?\")[0], total=r['total'], **locals()))\n            if yield_pages:\n                yield r\n            else:\n                for row in r['results']:\n                    yield row\n            if r['next'] is None:\n                break\n            url = r['next']\n            options = {'format': None}", "response": "Get the scroll through the resource at url and yield the individual results"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the AmCAT status page", "response": "def get_status(self):\n        \"\"\"Get the AmCAT status page\"\"\"\n        url = URL.status.format(**locals())\n        return self.get_request(url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconducts an aggregate query", "response": "def aggregate(self, **filters):\n        \"\"\"Conduct an aggregate query\"\"\"\n        url = URL.aggregate.format(**locals())\n        return self.get_pages(url, **filters)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists the articlesets in a project", "response": "def list_sets(self, project, **filters):\n        \"\"\"List the articlesets in a project\"\"\"\n        url = URL.articlesets.format(**locals())\n        return self.get_pages(url, **filters)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists the articlesets in a project", "response": "def get_set(self, project, articleset, **filters):\n        \"\"\"List the articlesets in a project\"\"\"\n        url = URL.articleset.format(**locals())\n        return self.request(url, **filters)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_articles(self, project, articleset, page=1, **filters):\n        url = URL.article.format(**locals())\n        return self.get_pages(url, page=page, **filters)", "response": "List the articles in a set"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new article set.", "response": "def create_set(self, project, json_data=None, **options):\n        \"\"\"\n        Create a new article set. Provide the needed arguments using\n        post_data or with key-value pairs\n        \"\"\"\n        url = URL.articlesets.format(**locals())\n        if json_data is None:\n            # form encoded request\n            return self.request(url, method=\"post\", data=options)\n        else:\n            if not isinstance(json_data, (string_types)):\n                json_data = json.dumps(json_data,default = serialize)\n            headers = {'content-type': 'application/json'}\n            return self.request(\n                url, method='post', data=json_data, headers=headers)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_articles(self, project, articleset, json_data=None, **options):\n        url = URL.article.format(**locals())\n        # TODO duplicated from create_set, move into requests\n        # (or separate post method?)\n        if json_data is None:\n            # form encoded request\n            return self.request(url, method=\"post\", data=options)\n        else:\n            if not isinstance(json_data, string_types):\n                json_data = json.dumps(json_data, default=serialize)\n            headers = {'content-type': 'application/json'}\n            return self.request(url, method='post', data=json_data, headers=headers)", "response": "Create one or more articles in the set."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn authentication signature of encoded bytes", "response": "def sign(self, encoded):\n        \"\"\" Return authentication signature of encoded bytes \"\"\"\n        signature = self._hmac.copy()\n        signature.update(encoded)\n        return signature.hexdigest().encode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split(self, encoded):\n        maxlen = len(encoded) - self.sig_size\n        message = encoded[:maxlen]\n        signature = encoded[-self.sig_size:]\n        return message, signature", "response": "Split into message and signature"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef auth(self, encoded):\n        message, signature = self.split(encoded)\n        computed = self.sign(message)\n        if not hmac.compare_digest(signature, computed):\n            raise AuthenticatorInvalidSignature", "response": "Validate integrity of encoded bytes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cached_classproperty(fun):\n    @functools.wraps(fun)\n    def get(cls):\n        try:\n            return cls.__cache[fun]\n        except AttributeError:\n            cls.__cache = {}\n        except KeyError:  # pragma: no cover\n            pass\n        ret = cls.__cache[fun] = fun(cls)\n        return ret\n    return classproperty(get)", "response": "A memorization decorator for class properties."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef route_method(method_name, extra_part=False):\n    def wrapper(callable_obj):\n        if method_name.lower() not in DEFAULT_ROUTES:\n            raise HandlerHTTPMethodError(\n                'Invalid http method in method: {}'.format(method_name)\n            )\n\n        callable_obj.http_method = method_name.upper()\n\n        callable_obj.url_extra_part = callable_obj.__name__ if extra_part\\\n            else None\n\n        return classmethod(callable_obj)\n    return wrapper", "response": "Custom handler routing decorator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef issue_add(lancet, assign, add_to_sprint, summary):\n    summary = \" \".join(summary)\n    issue = create_issue(\n        lancet,\n        summary,\n        # project_id=project_id,\n        add_to_active_sprint=add_to_sprint,\n    )\n    if assign:\n        if assign == \"me\":\n            username = lancet.tracker.whoami()\n        else:\n            username = assign\n        assign_issue(lancet, issue, username)\n\n    click.echo(\"Created issue\")", "response": "Create a new issue on the issue tracker."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndries helper. If the specified attribute of the user differs from the specified value, it will be updated.", "response": "def _maybe_update(self, user, attribute, new_value):\n        \"\"\"\n        DRY helper.  If the specified attribute of the user differs from the\n        specified value, it will be updated.\n        \"\"\"\n        old_value = getattr(user, attribute)\n        if new_value != old_value:\n            self.stderr.write(\n                _('Setting {attribute} for user \"{username}\" to \"{new_value}\"').format(\n                    attribute=attribute, username=user.username, new_value=new_value\n                )\n            )\n            setattr(user, attribute, new_value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that the passed email address matches the username and email.", "response": "def _check_email_match(self, user, email):\n        \"\"\"\n        DRY helper.\n\n        Requiring the user to specify both username and email will help catch\n        certain issues, for example if the expected username has already been\n        taken by someone else.\n        \"\"\"\n        if user.email != email:\n            # The passed email address doesn't match this username's email address.\n            # Assume a problem and fail.\n            raise CommandError(\n                _(\n                    'Skipping user \"{}\" because the specified and existing email '\n                    'addresses do not match.'\n                ).format(user.username)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck the provided credentials using the Harvest API.", "response": "def credentials_checker(url, username, password):\n    \"\"\"Check the provided credentials using the Harvest API.\"\"\"\n    api = HarvestAPI(url, (username, password))\n    try:\n        api.whoami()\n    except HarvestError:\n        return False\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef harvest(lancet, config_section):\n    url, username, password = lancet.get_credentials(\n        config_section, credentials_checker\n    )\n\n    project_id_getter = lancet.get_instance_from_config(\n        \"timer\", \"project_id_getter\", lancet\n    )\n    task_id_getter = lancet.get_instance_from_config(\n        \"timer\", \"task_id_getter\", lancet\n    )\n\n    client = HarvestPlatform(\n        server=url,\n        basic_auth=(username, password),\n        project_id_getter=project_id_getter,\n        task_id_getter=task_id_getter,\n    )\n    lancet.call_on_close(client.close)\n    return client", "response": "Construct a new Harvest client."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a temporary directory optionally with folder appended and created if it doesn t exist.", "response": "def temp_dir(folder=None, delete=True):\n    # type: (Optional[str], bool) -> str\n    \"\"\"Get a temporary directory optionally with folder appended (and created if it doesn't exist)\n\n    Args:\n        folder (Optional[str]): Folder to create in temporary folder. Defaults to None.\n        delete (bool): Whether to delete folder on exiting with statement\n\n    Returns:\n        str: A temporary directory\n    \"\"\"\n    tempdir = get_temp_dir()\n    if folder:\n        tempdir = join(tempdir, folder)\n    if not exists(tempdir):\n        makedirs(tempdir)\n    try:\n        yield tempdir\n    finally:\n        if delete:\n            rmtree(tempdir)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send(self, obj):\n\t\tif not isinstance(obj, NotificationMessage):\n\t\t\traise ValueError, u\"You can only send NotificationMessage objects.\"\n\t\tself._send_queue.put(obj)", "response": "Send a push notification."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the next error message from the error queue.", "response": "def get_error(self, block = True, timeout = None):\n\t\t\"\"\"\n\t\tGets the next error message.\n\t\t\n\t\tEach error message is a 2-tuple of (status, identifier).\"\"\"\n\t\treturn self._error_queue.get(block = block, timeout = timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_feedback(self, block = True, timeout = None):\n\t\tif self._feedback_greenlet is None:\n\t\t\tself._feedback_greenlet = gevent.spawn(self._feedback_loop)\n\t\treturn self._feedback_queue.get(block = block, timeout = timeout)", "response": "Get the next feedback message."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwaits until all queued messages are sent.", "response": "def wait_send(self, timeout = None):\n\t\t\"\"\"Wait until all queued messages are sent.\"\"\"\n\t\tself._send_queue_cleared.clear()\n\t\tself._send_queue_cleared.wait(timeout = timeout)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart the message sending loop.", "response": "def start(self):\n\t\t\"\"\"Start the message sending loop.\"\"\"\n\t\tif self._send_greenlet is None:\n\t\t\tself._send_greenlet = gevent.spawn(self._send_loop)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stop(self, timeout = 10.0):\n\t\tif (self._send_greenlet is not None) and \\\n\t\t\t\t(self._send_queue.qsize() > 0):\n\t\t\tself.wait_send(timeout = timeout)\n\n\t\tif self._send_greenlet is not None:\n\t\t\tgevent.kill(self._send_greenlet)\n\t\t\tself._send_greenlet = None\n\t\tif self._error_greenlet is not None:\n\t\t\tgevent.kill(self._error_greenlet)\n\t\t\tself._error_greenlet = None\n\t\tif self._feedback_greenlet is not None:\n\t\t\tgevent.kill(self._feedback_greenlet)\n\t\t\tself._feedback_greenlet = None\n\n\t\treturn self._send_queue.qsize() < 1", "response": "Stop sending all pending messages and close connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_to_ssml(text, text_format):\n    if text_format is None:\n        return text\n    elif text_format == 'plain':\n        return plain_to_ssml(text)\n    elif text_format == 'html':\n        return html_to_ssml(text)\n    else:\n        raise ValueError(text_format + ': text format not found.')", "response": "Convert text to SSML based on the text s current format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef html_to_ssml(text):\n    ssml_text = reduce(lambda x, y: x.replace(y, html_to_ssml_maps[y]), html_to_ssml_maps, text)\n    return ssml_text", "response": "Replaces specific html tags with probable SSML counterparts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_matching_text_in_strs(a, b, match_min_size=30, ignore='', end_characters=''):\n    # type: (str, str, int, str, str) -> List[str]\n    \"\"\"Returns a list of matching blocks of text in a and b\n\n    Args:\n        a (str): First string to match\n        b (str): Second string to match\n        match_min_size (int): Minimum block size to match on. Defaults to 30.\n        ignore (str): Any characters to ignore in matching. Defaults to ''.\n        end_characters (str): End characters to look for. Defaults to ''.\n\n    Returns:\n        List[str]: List of matching blocks of text\n\n    \"\"\"\n    compare = difflib.SequenceMatcher(lambda x: x in ignore)\n    compare.set_seqs(a=a, b=b)\n    matching_text = list()\n\n    for match in compare.get_matching_blocks():\n        start = match.a\n        text = a[start: start+match.size]\n        if end_characters:\n            prev_text = text\n            while len(text) != 0 and text[0] in end_characters:\n                text = text[1:]\n            while len(text) != 0 and text[-1] not in end_characters:\n                text = text[:-1]\n            if len(text) == 0:\n                text = prev_text\n        if len(text) >= match_min_size:\n            matching_text.append(text)\n    return matching_text", "response": "Returns a list of matching blocks of text in a and b."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_matching_text(string_list, match_min_size=30, ignore='', end_characters='.!\\r\\n'):\n    # type: (List[str], int, str, str) -> str\n    \"\"\"Returns a string containing matching blocks of text in a list of strings followed by non-matching.\n\n    Args:\n        string_list (List[str]): List of strings to match\n        match_min_size (int): Minimum block size to match on. Defaults to 30.\n        ignore (str): Any characters to ignore in matching. Defaults to ''.\n        end_characters (str): End characters to look for. Defaults to '.\\r\\n'.\n\n    Returns:\n        str: String containing matching blocks of text followed by non-matching\n\n    \"\"\"\n    a = string_list[0]\n    for i in range(1, len(string_list)):\n        b = string_list[i]\n        result = get_matching_text_in_strs(a, b, match_min_size=match_min_size, ignore=ignore,\n                                           end_characters=end_characters)\n        a = ''.join(result)\n    return a", "response": "Returns a string containing the matching blocks of text in a list of strings followed by non - matching."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_matching_then_nonmatching_text(string_list, separator='', match_min_size=30, ignore='',\n                                       end_characters='.!\\r\\n'):\n    # type: (List[str], str, int, str, str) -> str\n    \"\"\"Returns a string containing matching blocks of text in a list of strings followed by non-matching.\n\n    Args:\n        string_list (List[str]): List of strings to match\n        separator (str): Separator to add between blocks of text. Defaults to ''.\n        match_min_size (int): Minimum block size to match on. Defaults to 30.\n        ignore (str): Any characters to ignore in matching. Defaults to ''.\n        end_characters (str): End characters to look for. Defaults to '.\\r\\n'.\n\n    Returns:\n        str: String containing matching blocks of text followed by non-matching\n\n    \"\"\"\n    def add_separator_if_needed(text_list):\n        if separator and len(text_list) > 0 and text_list[-1][-len(separator):] != separator:\n            text_list.append(separator)\n\n    a = string_list[0]\n    for i in range(1, len(string_list)):\n        b = string_list[i]\n        combined_len = len(a) + len(b)\n        result = get_matching_text_in_strs(a, b, match_min_size=match_min_size, ignore=ignore,\n                                           end_characters=end_characters)\n        new_a = a\n        new_b = b\n        for text in result:\n            new_a = new_a.replace(text, '')\n            new_b = new_b.replace(text, '')\n        if new_a and new_a in a:\n            pos_a = a.index(new_a)\n        else:\n            pos_a = combined_len\n        if new_b and new_b in b:\n            pos_b = b.index(new_b)\n        else:\n            pos_b = combined_len\n        if pos_b > pos_a:\n            text_1 = new_b\n            pos_1 = pos_b\n            text_2 = new_a\n            pos_2 = pos_a\n        else:\n            text_1 = new_a\n            pos_1 = pos_a\n            text_2 = new_b\n            pos_2 = pos_b\n        output = list()\n        pos = 0\n        for text in result:\n            output.append(text)\n            pos += len(text)\n            if text_1 and pos >= pos_1:\n                add_separator_if_needed(output)\n                output.append(text_1)\n                pos += len(text_1)\n                text_1 = None\n            if text_2 and pos >= pos_2:\n                add_separator_if_needed(output)\n                output.append(text_2)\n                pos += len(text_2)\n                text_2 = None\n        if text_1 and pos_1 == combined_len:\n            add_separator_if_needed(output)\n            output.append(text_1)\n        if text_2 and pos_2 == combined_len:\n            add_separator_if_needed(output)\n            output.append(text_2)\n        a = ''.join(output)\n    return a", "response": "Returns a string containing the matching blocks of text followed by non - matching blocks of text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iexpand(string, keep_escapes=False):\n\n    if isinstance(string, bytes):\n        is_bytes = True\n        string = string.decode('latin-1')\n\n    else:\n        is_bytes = False\n\n    if is_bytes:\n        return (entry.encode('latin-1') for entry in ExpandBrace(keep_escapes).expand(string))\n\n    else:\n        return (entry for entry in ExpandBrace(keep_escapes).expand(string))", "response": "Expand braces and return an iterator."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets that we are expanding a sequence and return whether a release is required by the caller.", "response": "def set_expanding(self):\n        \"\"\"Set that we are expanding a sequence, and return whether a release is required by the caller.\"\"\"\n\n        status = not self.expanding\n        if status:\n            self.expanding = True\n        return status"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef squash(self, a, b):\n\n        return ((''.join(x) if isinstance(x, tuple) else x) for x in itertools.product(a, b))", "response": "Returns a generator that squashes two iterables into one."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a string literal.", "response": "def get_literals(self, c, i, depth):\n        \"\"\"\n        Get a string literal.\n\n        Gather all the literal chars up to opening curly or closing brace.\n        Also gather chars between braces and commas within a group (is_expanding).\n        \"\"\"\n\n        result = ['']\n        is_dollar = False\n\n        try:\n            while c:\n                ignore_brace = is_dollar\n                is_dollar = False\n\n                if c == '$':\n                    is_dollar = True\n\n                elif c == '\\\\':\n                    c = [self.get_escape(c, i)]\n\n                elif not ignore_brace and c == '{':\n                    # Try and get the group\n                    index = i.index\n                    try:\n                        seq = self.get_sequence(next(i), i, depth + 1)\n                        if seq:\n                            c = seq\n                    except StopIteration:\n                        # Searched to end of string\n                        # and still didn't find it.\n                        i.rewind(i.index - index)\n\n                elif self.is_expanding() and c in (',', '}'):\n                    # We are Expanding within a group and found a group delimiter\n                    # Return what we gathered before the group delimiters.\n                    i.rewind(1)\n                    return (x for x in result)\n\n                # Squash the current set of literals.\n                result = self.squash(result, [c] if isinstance(c, str) else c)\n\n                c = next(i)\n        except StopIteration:\n            if self.is_expanding():\n                return None\n\n        return (x for x in result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef combine(self, a, b):\n\n        for l in (a, b):\n            for x in l:\n                yield x", "response": "A generator that combines two iterables."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_sequence(self, c, i, depth):\n\n        result = []\n        release = self.set_expanding()\n        has_comma = False  # Used to indicate validity of group (`{1..2}` are an exception).\n        is_empty = True  # Tracks whether the current slot is empty `{slot,slot,slot}`.\n\n        # Detect numerical and alphabetic series: `{1..2}` etc.\n        i.rewind(1)\n        item = self.get_range(i)\n        i.advance(1)\n        if item is not None:\n            self.release_expanding(release)\n            return (x for x in item)\n\n        try:\n            while c:\n                # Bash has some special top level logic. if `}` follows `{` but hasn't matched\n                # a group yet, keep going except when the first 2 bytes are `{}` which gets\n                # completely ignored.\n                keep_looking = depth == 1 and not has_comma  # and i.index not in self.skip_index\n                if (c == '}' and (not keep_looking or i.index == 2)):\n                    # If there is no comma, we know the sequence is bogus.\n                    if is_empty:\n                        result = (x for x in self.combine(result, ['']))\n                    if not has_comma:\n                        result = ('{' + literal + '}' for literal in result)\n                    self.release_expanding(release)\n                    return (x for x in result)\n\n                elif c == ',':\n                    # Must be the first element in the list.\n                    has_comma = True\n                    if is_empty:\n                        result = (x for x in self.combine(result, ['']))\n                    else:\n                        is_empty = True\n\n                else:\n                    if c == '}':\n                        # Top level: If we didn't find a comma, we haven't\n                        # completed the top level group. Request more and\n                        # append to what we already have for the first slot.\n                        if not result:\n                            result = (x for x in self.combine(result, [c]))\n                        else:\n                            result = self.squash(result, [c])\n                        value = self.get_literals(next(i), i, depth)\n                        if value is not None:\n                            result = self.squash(result, value)\n                            is_empty = False\n                    else:\n                        # Lower level: Try to find group, but give up if cannot acquire.\n                        value = self.get_literals(c, i, depth)\n                        if value is not None:\n                            result = (x for x in self.combine(result, value))\n                            is_empty = False\n\n                c = next(i)\n        except StopIteration:\n            self.release_expanding(release)\n            raise", "response": "Get the sequence of the current item."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks and retrieve range if value is a valid range.", "response": "def get_range(self, i):\n        \"\"\"\n        Check and retrieve range if value is a valid range.\n\n        Here we are looking to see if the value is series or range.\n        We look for `{1..2[..inc]}` or `{a..z[..inc]}` (negative numbers are fine).\n        \"\"\"\n\n        try:\n            m = i.match(RE_INT_ITER)\n            if m:\n                return self.get_int_range(*m.groups())\n\n            m = i.match(RE_CHR_ITER)\n            if m:\n                return self.get_char_range(*m.groups())\n        except Exception:  # pragma: no cover\n            # TODO: We really should never fail here,\n            # but if we do, assume the sequence range\n            # was invalid. This catch can probably\n            # be removed in the future with more testing.\n            pass\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nformatting the value for the log entry.", "response": "def format_value(self, value, padding):\n        \"\"\"Get padding adjusting for negative values.\"\"\"\n\n        # padding = padding - 1 if value < 0 and padding > 0 else padding\n        # prefix = '-' if value < 0 else ''\n\n        if padding:\n            return \"{:0{pad}d}\".format(value, pad=padding)\n\n        else:\n            return str(value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_int_range(self, start, end, increment=None):\n\n        first, last = int(start), int(end)\n        increment = int(increment) if increment is not None else 1\n        max_length = max(len(start), len(end))\n\n        # Zero doesn't make sense as an incrementer\n        # but like bash, just assume one\n        if increment == 0:\n            increment = 1\n\n        if start[0] == '-':\n            start = start[1:]\n\n        if end[0] == '-':\n            end = end[1:]\n\n        if (len(start) > 1 and start[0] == '0') or (len(end) > 1 and end[0] == '0'):\n            padding = max_length\n\n        else:\n            padding = 0\n\n        if first < last:\n            r = range(first, last + 1, -increment if increment < 0 else increment)\n\n        else:\n            r = range(first, last - 1, increment if increment < 0 else -increment)\n\n        return (self.format_value(value, padding) for value in r)", "response": "Get an integer range between start and end and increments of increment."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_char_range(self, start, end, increment=None):\n\n        increment = int(increment) if increment else 1\n        if increment < 0:\n            increment = -increment\n\n        # Zero doesn't make sense as an incrementer\n        # but like bash, just assume one\n        if increment == 0:\n            increment = 1\n\n        inverse = start > end\n        alpha = _nalpha if inverse else _alpha\n\n        start = alpha.index(start)\n        end = alpha.index(end)\n\n        if start < end:\n            return (c for c in alpha[start:end + 1:increment])\n\n        else:\n            return (c for c in alpha[end:start + 1:increment])", "response": "Get a range of alphabetic characters."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef expand(self, string):\n\n        self.expanding = False\n        empties = []\n        found_literal = False\n        if string:\n            i = iter(StringIter(string))\n            for x in self.get_literals(next(i), i, 0):\n                # We don't want to return trailing empty strings.\n                # Store empty strings and output only when followed by a literal.\n                if not x:\n                    empties.append(x)\n                    continue\n                found_literal = True\n                while empties:\n                    yield empties.pop(0)\n                yield x\n        empties = []\n\n        # We found no literals so return an empty string\n        if not found_literal:\n            yield \"\"", "response": "Yields the entries from the given string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef merge_two_dictionaries(a, b, merge_lists=False):\n    # type: (DictUpperBound, DictUpperBound, bool) -> DictUpperBound\n    \"\"\"Merges b into a and returns merged result\n\n    NOTE: tuples and arbitrary objects are not handled as it is totally ambiguous what should happen\n\n    Args:\n        a (DictUpperBound): dictionary to merge into\n        b (DictUpperBound): dictionary to merge from\n        merge_lists (bool): Whether to merge lists (True) or replace lists (False). Default is False.\n\n    Returns:\n        DictUpperBound: Merged dictionary\n    \"\"\"\n    key = None\n    # ## debug output\n    # sys.stderr.write('DEBUG: %s to %s\\n' %(b,a))\n    try:\n        if a is None or isinstance(a, (six.string_types, six.text_type, six.integer_types, float)):\n            # border case for first run or if a is a primitive\n            a = b\n        elif isinstance(a, list):\n            # lists can be appended or replaced\n            if isinstance(b, list):\n                if merge_lists:\n                    # merge lists\n                    a.extend(b)\n                else:\n                    # replace list\n                    a = b\n            else:\n                # append to list\n                a.append(b)\n        elif isinstance(a, (dict, UserDict)):\n            # dicts must be merged\n            if isinstance(b, (dict, UserDict)):\n                for key in b:\n                    if key in a:\n                        a[key] = merge_two_dictionaries(a[key], b[key], merge_lists=merge_lists)\n                    else:\n                        a[key] = b[key]\n            else:\n                raise ValueError('Cannot merge non-dict \"%s\" into dict \"%s\"' % (b, a))\n        else:\n            raise ValueError('NOT IMPLEMENTED \"%s\" into \"%s\"' % (b, a))\n    except TypeError as e:\n        raise ValueError('TypeError \"%s\" in key \"%s\" when merging \"%s\" into \"%s\"' % (e, key, b, a))\n    return a", "response": "Merges two dicts into a and returns a new dict that is merged with b."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef merge_dictionaries(dicts, merge_lists=False):\n    # type: (List[DictUpperBound], bool) -> DictUpperBound\n    \"\"\"Merges all dictionaries in dicts into a single dictionary and returns result\n\n    Args:\n        dicts (List[DictUpperBound]): Dictionaries to merge into the first one in the list\n        merge_lists (bool): Whether to merge lists (True) or replace lists (False). Default is False.\n\n    Returns:\n        DictUpperBound: Merged dictionary\n\n    \"\"\"\n    dict1 = dicts[0]\n    for other_dict in dicts[1:]:\n        merge_two_dictionaries(dict1, other_dict, merge_lists=merge_lists)\n    return dict1", "response": "Merges all dictionaries in dicts into a single dictionary and returns the result\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompare two dictionaries returning a new dictionary with the keys that differ.", "response": "def dict_diff(d1, d2, no_key='<KEYNOTFOUND>'):\n    # type: (DictUpperBound, DictUpperBound, str) -> Dict\n    \"\"\"Compares two dictionaries\n\n    Args:\n        d1 (DictUpperBound): First dictionary to compare\n        d2 (DictUpperBound): Second dictionary to compare\n        no_key (str): What value to use if key is not found Defaults to '<KEYNOTFOUND>'.\n\n    Returns:\n        Dict: Comparison dictionary\n\n    \"\"\"\n    d1keys = set(d1.keys())\n    d2keys = set(d2.keys())\n    both = d1keys & d2keys\n    diff = {k: (d1[k], d2[k]) for k in both if d1[k] != d2[k]}\n    diff.update({k: (d1[k], no_key) for k in d1keys - both})\n    diff.update({k: (no_key, d2[k]) for k in d2keys - both})\n    return diff"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dict_of_lists_add(dictionary, key, value):\n    # type: (DictUpperBound, Any, Any) -> None\n    \"\"\"Add value to a list in a dictionary by key\n\n    Args:\n        dictionary (DictUpperBound): Dictionary to which to add values\n        key (Any): Key within dictionary\n        value (Any): Value to add to list in dictionary\n\n    Returns:\n        None\n\n    \"\"\"\n    list_objs = dictionary.get(key, list())\n    list_objs.append(value)\n    dictionary[key] = list_objs", "response": "Adds value to a list in a dictionary by key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dict_of_sets_add(dictionary, key, value):\n    # type: (DictUpperBound, Any, Any) -> None\n    \"\"\"Add value to a set in a dictionary by key\n\n    Args:\n        dictionary (DictUpperBound): Dictionary to which to add values\n        key (Any): Key within dictionary\n        value (Any): Value to add to set in dictionary\n\n    Returns:\n        None\n\n    \"\"\"\n    set_objs = dictionary.get(key, set())\n    set_objs.add(value)\n    dictionary[key] = set_objs", "response": "Adds value to a set in a dictionary by key"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_distribute_contents_simple(input_list, function=lambda x: x):\n    # type: (List, Callable[[Any], Any]) -> List\n    \"\"\"Distribute the contents of a list eg. [1, 1, 1, 2, 2, 3] -> [1, 2, 3, 1, 2, 1]. List can contain complex types\n    like dictionaries in which case the function can return the appropriate value eg.  lambda x: x[KEY]\n\n    Args:\n        input_list (List): List to distribute values\n        function (Callable[[Any], Any]): Return value to use for distributing. Defaults to lambda x: x.\n\n    Returns:\n        List: Distributed list\n\n    \"\"\"\n    dictionary = dict()\n    for obj in input_list:\n        dict_of_lists_add(dictionary, function(obj), obj)\n    output_list = list()\n    i = 0\n    done = False\n    while not done:\n        found = False\n        for key in sorted(dictionary):\n            if i < len(dictionary[key]):\n                output_list.append(dictionary[key][i])\n                found = True\n        if found:\n            i += 1\n        else:\n            done = True\n    return output_list", "response": "Distribute the contents of a list of items in a list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_distribute_contents(input_list, function=lambda x: x):\n    # type: (List, Callable[[Any], Any]) -> List\n    \"\"\"Distribute the contents of a list eg. [1, 1, 1, 2, 2, 3] -> [1, 2, 1, 2, 1, 3]. List can contain complex types\n    like dictionaries in which case the function can return the appropriate value eg.  lambda x: x[KEY]\n\n    Args:\n        input_list (List): List to distribute values\n        function (Callable[[Any], Any]): Return value to use for distributing. Defaults to lambda x: x.\n\n    Returns:\n        List: Distributed list\n\n    \"\"\"\n\n    def riffle_shuffle(piles_list):\n        def grouper(n, iterable, fillvalue=None):\n            args = [iter(iterable)] * n\n            return zip_longest(fillvalue=fillvalue, *args)\n\n        if not piles_list:\n            return []\n        piles_list.sort(key=len, reverse=True)\n        width = len(piles_list[0])\n        pile_iters_list = [iter(pile) for pile in piles_list]\n        pile_sizes_list = [[pile_position] * len(pile) for pile_position, pile in enumerate(piles_list)]\n        grouped_rows = grouper(width, itertools.chain.from_iterable(pile_sizes_list))\n        grouped_columns = zip_longest(*grouped_rows)\n        shuffled_pile = [next(pile_iters_list[position]) for position in itertools.chain.from_iterable(grouped_columns)\n                         if position is not None]\n        return shuffled_pile\n\n    dictionary = dict()\n    for obj in input_list:\n        dict_of_lists_add(dictionary, function(obj), obj)\n    intermediate_list = list()\n    for key in sorted(dictionary):\n        intermediate_list.append(dictionary[key])\n    return riffle_shuffle(intermediate_list)", "response": "Distribute the contents of a list eg. 1 2 3 4 5 5"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_list_from_list_of_dict(list_of_dict, key):\n    # type: (List[DictUpperBound], Any) -> List\n    \"\"\"Extract a list by looking up key in each member of a list of dictionaries\n\n    Args:\n        list_of_dict (List[DictUpperBound]): List of dictionaries\n        key (Any): Key to find in each dictionary\n\n    Returns:\n        List: List containing values returned from each dictionary\n\n    \"\"\"\n    result = list()\n    for dictionary in list_of_dict:\n        result.append(dictionary[key])\n    return result", "response": "Extract a list by looking up key in each member of a list of dictionaries\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef key_value_convert(dictin, keyfn=lambda x: x, valuefn=lambda x: x, dropfailedkeys=False, dropfailedvalues=False,\n                      exception=ValueError):\n    # type: (DictUpperBound, Callable[[Any], Any], Callable[[Any], Any], bool, bool, ExceptionUpperBound) -> Dict\n    \"\"\"Convert keys and/or values of dictionary using functions passed in as parameters\n\n    Args:\n        dictin (DictUpperBound): Input dictionary\n        keyfn (Callable[[Any], Any]): Function to convert keys. Defaults to lambda x: x\n        valuefn (Callable[[Any], Any]): Function to convert values. Defaults to lambda x: x\n        dropfailedkeys (bool): Whether to drop dictionary entries where key conversion fails. Defaults to False.\n        dropfailedvalues (bool): Whether to drop dictionary entries where value conversion fails. Defaults to False.\n        exception (ExceptionUpperBound): The exception to expect if keyfn or valuefn fail. Defaults to ValueError.\n\n    Returns:\n        Dict: Dictionary with converted keys and/or values\n\n    \"\"\"\n    dictout = dict()\n    for key in dictin:\n        try:\n            new_key = keyfn(key)\n        except exception:\n            if dropfailedkeys:\n                continue\n            new_key = key\n        value = dictin[key]\n        try:\n            new_value = valuefn(value)\n        except exception:\n            if dropfailedvalues:\n                continue\n            new_value = value\n        dictout[new_key] = new_value\n    return dictout", "response": "Convert keys and values of a dictionary using functions passed in as parameters\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef integer_key_convert(dictin, dropfailedkeys=False):\n    # type: (DictUpperBound, bool) -> Dict\n    \"\"\"Convert keys of dictionary to integers\n\n    Args:\n        dictin (DictUpperBound): Input dictionary\n        dropfailedkeys (bool): Whether to drop dictionary entries where key conversion fails. Defaults to False.\n\n    Returns:\n        Dict: Dictionary with keys converted to integers\n\n    \"\"\"\n    return key_value_convert(dictin, keyfn=int, dropfailedkeys=dropfailedkeys)", "response": "Convert keys of dictionary to integers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef integer_value_convert(dictin, dropfailedvalues=False):\n    # type: (DictUpperBound, bool) -> Dict\n    \"\"\"Convert values of dictionary to integers\n\n    Args:\n        dictin (DictUpperBound): Input dictionary\n        dropfailedvalues (bool): Whether to drop dictionary entries where key conversion fails. Defaults to False.\n\n    Returns:\n        Dict: Dictionary with values converted to integers\n\n    \"\"\"\n    return key_value_convert(dictin, valuefn=int, dropfailedvalues=dropfailedvalues)", "response": "Convert values of dictionary to integers"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef float_value_convert(dictin, dropfailedvalues=False):\n    # type: (DictUpperBound, bool) -> Dict\n    \"\"\"Convert values of dictionary to floats\n\n    Args:\n        dictin (DictUpperBound): Input dictionary\n        dropfailedvalues (bool): Whether to drop dictionary entries where key conversion fails. Defaults to False.\n\n    Returns:\n        Dict: Dictionary with values converted to floats\n\n    \"\"\"\n    return key_value_convert(dictin, valuefn=float, dropfailedvalues=dropfailedvalues)", "response": "Convert values of dictionary to floats"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new dictionary from two dictionaries by averaging values of keys in one dictionary.", "response": "def avg_dicts(dictin1, dictin2, dropmissing=True):\n    # type: (DictUpperBound, DictUpperBound, bool) -> Dict\n    \"\"\"Create a new dictionary from two dictionaries by averaging values\n\n    Args:\n        dictin1 (DictUpperBound): First input dictionary\n        dictin2 (DictUpperBound): Second input dictionary\n        dropmissing (bool): Whether to drop keys missing in one dictionary. Defaults to True.\n\n    Returns:\n        Dict: Dictionary with values being average of 2 input dictionaries\n\n    \"\"\"\n    dictout = dict()\n    for key in dictin1:\n        if key in dictin2:\n            dictout[key] = (dictin1[key] + dictin2[key]) / 2\n        elif not dropmissing:\n            dictout[key] = dictin1[key]\n    if not dropmissing:\n        for key in dictin2:\n            if key not in dictin1:\n                dictout[key] = dictin2[key]\n    return dictout"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a list of rows from a CSV file.", "response": "def read_list_from_csv(filepath, dict_form=False, headers=None, **kwargs):\n    # type: (str, bool, Union[int, List[int], List[str], None], Any) -> List[Union[Dict, List]]\n    \"\"\"Read a list of rows in dict or list form from a csv. (The headers argument is either a row\n       number or list of row numbers (in case of multi-line headers) to be considered as headers\n       (rows start counting at 1), or the actual headers defined a list of strings. If not set,\n       all rows will be treated as containing values.)\n\n    Args:\n        filepath (str): Path to read from\n        dict_form (bool): Return in dict form. Defaults to False.\n        headers (Union[int, List[int], List[str], None]): Row number of headers. Defaults to None.\n        **kwargs: Other arguments to pass to Tabulator Stream\n\n    Returns:\n        List[Union[Dict, List]]: List of rows in dict or list form\n\n    \"\"\"\n    stream = Stream(filepath, headers=headers, **kwargs)\n    stream.open()\n    result = stream.read(keyed=dict_form)\n    stream.close()\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites a list of rows in dict or list form to a csv file.", "response": "def write_list_to_csv(list_of_rows, filepath, headers=None):\n    # type: (List[Union[DictUpperBound, List]], str, Union[int, List[int], List[str], None]) -> None\n    \"\"\"Write a list of rows in dict or list form to a csv. (The headers argument is either a row\n       number or list of row numbers (in case of multi-line headers) to be considered as headers\n       (rows start counting at 1), or the actual headers defined a list of strings. If not set,\n       all rows will be treated as containing values.)\n\n    Args:\n        list_of_rows (List[Union[DictUpperBound, List]]): List of rows in dict or list form\n        filepath (str): Path to write to\n        headers (Union[int, List[int], List[str], None]): Headers to write. Defaults to None.\n\n    Returns:\n        None\n\n    \"\"\"\n    stream = Stream(list_of_rows, headers=headers)\n    stream.open()\n    stream.save(filepath, format='csv')\n    stream.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef args_to_dict(args):\n    # type: (str) -> DictUpperBound[str,str]\n    \"\"\"Convert command line arguments in a comma separated string to a dictionary\n\n    Args:\n        args (str): Command line arguments\n\n    Returns:\n        DictUpperBound[str,str]: Dictionary of arguments\n\n    \"\"\"\n    arguments = dict()\n    for arg in args.split(','):\n        key, value = arg.split('=')\n        arguments[key] = value\n    return arguments", "response": "Convert command line arguments in a comma separated string to a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the delta between two files using -?,? format excluding lines that are the same", "response": "def compare_files(path1, path2):\n    # type: (str, str) -> List[str]\n    \"\"\"Returns the delta between two files using -, ?, + format excluding\n    lines that are the same\n\n    Args:\n        path1 (str): Path to first file\n        path2 (str): Path to second file\n\n    Returns:\n        List[str]: Delta between the two files\n\n    \"\"\"\n    diff = difflib.ndiff(open(path1).readlines(), open(path2).readlines())\n    return [x for x in diff if x[0] in ['-', '+', '?']]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nassert that two files are the same and returns delta using -?,?, + format if not", "response": "def assert_files_same(path1, path2):\n    # type: (str, str) -> None\n    \"\"\"Asserts that two files are the same and returns delta using\n    -, ?, + format if not\n\n    Args:\n        path1 (str): Path to first file\n        path2 (str): Path to second file\n\n    Returns:\n        None\n\n    \"\"\"\n    difflines = compare_files(path1, path2)\n    assert len(difflines) == 0, ''.join(['\\n'] + difflines)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    # Locale\n    locale.setlocale(locale.LC_ALL, '')\n\n    # Encoding for output streams\n    if str == bytes:  # PY2\n        writer = codecs.getwriter(locale.getpreferredencoding())\n        o_stdout, o_stderr = sys.stdout, sys.stderr\n        sys.stdout = writer(sys.stdout)\n        sys.stdout.buffer = o_stdout\n        sys.stderr = writer(sys.stderr)\n        sys.stderr.buffer = o_stderr\n    else:  # PY3\n        sys.stdin = sys.stdin.buffer\n\n    # Parses command-line\n\n    # Runtime to setup\n    def add_runtime_option(opt):\n        opt.add_argument(\n            '-r', '--runtime', action='store',\n            help=\"runtime to deploy on the server if the queue doesn't exist. \"\n                 \"If unspecified, will auto-detect what is appropriate, and \"\n                 \"fallback on 'default'.\")\n\n    # Destination selection\n    def add_destination_option(opt):\n        opt.add_argument('destination', action='store',\n                         help=\"Machine to SSH into; [user@]host[:port]\")\n        opt.add_argument('--queue', action='store', default=DEFAULT_TEJ_DIR,\n                         help=\"Directory for tej's files\")\n\n    # Root parser\n    parser = argparse.ArgumentParser(\n        description=\"Trivial Extensible Job-submission\")\n    parser.add_argument('--version', action='version',\n                        version=\"tej version %s\" % tej_version)\n    parser.add_argument('-v', '--verbose', action='count', default=1,\n                        dest='verbosity',\n                        help=\"augments verbosity level\")\n    subparsers = parser.add_subparsers(title=\"commands\", metavar='')\n\n    # Setup action\n    parser_setup = subparsers.add_parser(\n        'setup',\n        help=\"Sets up tej on a remote machine\")\n    add_destination_option(parser_setup)\n    add_runtime_option(parser_setup)\n    parser_setup.add_argument('--make-link', action='append',\n                              dest='make_link')\n    parser_setup.add_argument('--make-default-link', action='append_const',\n                              dest='make_link', const=DEFAULT_TEJ_DIR)\n    parser_setup.add_argument('--force', action='store_true')\n    parser_setup.add_argument('--only-links', action='store_true')\n    parser_setup.set_defaults(func=_setup)\n\n    # Submit action\n    parser_submit = subparsers.add_parser(\n        'submit',\n        help=\"Submits a job to a remote machine\")\n    add_destination_option(parser_submit)\n    add_runtime_option(parser_submit)\n    parser_submit.add_argument('--id', action='store',\n                               help=\"Identifier for the new job\")\n    parser_submit.add_argument('--script', action='store',\n                               help=\"Relative name of the script in the \"\n                                    \"directory\")\n    parser_submit.add_argument('directory', action='store',\n                               help=\"Job directory to upload\")\n    parser_submit.set_defaults(func=_submit)\n\n    # Status action\n    parser_status = subparsers.add_parser(\n        'status',\n        help=\"Gets the status of a job\")\n    add_destination_option(parser_status)\n    parser_status.add_argument('--id', action='store',\n                               help=\"Identifier of the running job\")\n    parser_status.set_defaults(func=_status)\n\n    # Download action\n    parser_download = subparsers.add_parser(\n        'download',\n        help=\"Downloads files from finished job\")\n    add_destination_option(parser_download)\n    parser_download.add_argument('--id', action='store',\n                                 help=\"Identifier of the job\")\n    parser_download.add_argument('files', action='store',\n                                 nargs=argparse.ONE_OR_MORE,\n                                 help=\"Files to download\")\n    parser_download.set_defaults(func=_download)\n\n    # Kill action\n    parser_kill = subparsers.add_parser(\n        'kill',\n        help=\"Kills a running job\")\n    add_destination_option(parser_kill)\n    parser_kill.add_argument('--id', action='store',\n                             help=\"Identifier of the running job\")\n    parser_kill.set_defaults(func=_kill)\n\n    # Delete action\n    parser_delete = subparsers.add_parser(\n        'delete',\n        help=\"Deletes a finished job\")\n    add_destination_option(parser_delete)\n    parser_delete.add_argument('--id', action='store',\n                               help=\"Identifier of the finished job\")\n    parser_delete.set_defaults(func=_delete)\n\n    # List action\n    parser_list = subparsers.add_parser(\n        'list',\n        help=\"Lists remote jobs\")\n    add_destination_option(parser_list)\n    parser_list.set_defaults(func=_list)\n\n    args = parser.parse_args()\n    setup_logging(args.verbosity)\n\n    try:\n        args.func(args)\n    except Error as e:\n        # No need to show a traceback here, this is not an internal error\n        logger.critical(e)\n        sys.exit(1)\n    sys.exit(0)", "response": "Entry point when called on the command - line."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying the HTTPError wrapper to the callback.", "response": "def apply(self, callback, context):  # pragma: no cover\n        \"\"\"Apply the HTTPError wrapper to the callback.\n        \"\"\"\n\n        def wrapper(*args, **kwargs):\n            try:\n                return callback(*args, **kwargs)\n            except bottle.HTTPError as error:\n                return self.error_wrapper.from_status(\n                    status_line=error.status_line,\n                    msg=error.body\n                )\n\n        return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a new episode to the podcast.", "response": "def add_episode(self, text, text_format, title, author, summary=None,\n                    publish_date=None, synthesizer='watson', synth_args=None, sentence_break='. '):\n        \"\"\"\n        Add a new episode to the podcast.\n\n        :param text:\n            See :meth:`Episode`.\n        :param text_format:\n            See :meth:`Episode`.\n        :param title:\n            See :meth:`Episode`.\n        :param author:\n            See :meth:`Episode`.\n        :param summary:\n            See :meth:`Episode`.\n        :param publish_date:\n            See :meth:`Episode`.\n        :param synthesizer:\n            See :meth:`typecaster.utils.text_to_speech`.\n        :param synth_args:\n            See :meth:`typecaster.utils.text_to_speech`.\n        :param sentence_break:\n            See :meth:`typecaster.utils.text_to_speech`.\n        \"\"\"\n        if title in self.episodes:\n            raise ValueError('\"' + title + '\" already exists as an episode title.')\n\n        link = self.output_path + '/' + title.replace(' ', '_').lower() + '.mp3'\n        episode_text = convert_to_ssml(text, text_format)\n        new_episode = Episode(episode_text, text_format, title, author, link, summary, publish_date, synthesizer, synth_args, sentence_break)\n\n        self.episodes[title] = new_episode"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a new scheduled job to the scheduler.", "response": "def add_scheduled_job(self, text_source, cron_args, text_format, title, author, summary=None,\n                          synthesizer='watson', synth_args=None, sentence_break='. '):\n        \"\"\"\n        Add and start a new scheduled job to dynamically generate podcasts.\n\n        Note: scheduling will end when the process ends. This works best when run\n        inside an existing application.\n\n        :param text_source:\n            A function that generates podcast text. Examples: a function that\n            opens a file with today's date as a filename or a function that\n            requests a specific url and extracts the main text.\n            Also see :meth:`Episode`.\n        :param cron_args:\n            A dictionary of cron parameters. Keys can be: 'year', 'month',\n            'day', 'week', 'day_of_week', 'hour', 'minute' and 'second'. Keys\n            that are not specified will be parsed as 'any'/'*'.\n        :param text_format:\n            See :meth:`Episode`.\n        :param title:\n            See :meth:`Episode`. Since titles need to be unique, a\n            timestamp will be appended to the title for each episode.\n        :param author:\n            See :meth:`Episode`.\n        :param summary:\n            See :meth:`Episode`.\n        :param publish_date:\n            See :meth:`Episode`.\n        :param synthesizer:\n            See :meth:`typecaster.utils.text_to_speech`.\n        :param synth_args:\n            See :meth:`typecaster.utils.text_to_speech`.\n        :param sentence_break:\n            See :meth:`typecaster.utils.text_to_speech`.\n        \"\"\"\n        if not callable(text_source):\n            raise TypeError('Argument \"text\" must be a function')\n\n        def add_episode():\n            episode_text = text_source()\n            episode_title = title + '_' + datetime.utcnow().strftime('%Y%m%d%H%M%S')\n\n            self.add_episode(episode_text, text_format, episode_title, author, summary, datetime.utcnow(), synthesizer, synth_args, sentence_break)\n\n        self.scheduled_jobs[title] = self._scheduler.add_job(add_episode, 'cron', id=title, **cron_args)\n\n        if not self._scheduler.running:\n            self._scheduler.start()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npublish a set of episodes to the Podcast s RSS feed.", "response": "def publish(self, titles):\n        \"\"\"\n        Publish a set of episodes to the Podcast's RSS feed.\n\n        :param titles:\n            Either a single episode title or a sequence of episode titles to\n            publish.\n        \"\"\"\n        if isinstance(titles, Sequence) and not isinstance(titles, six.string_types):\n            for title in titles:\n                self.episodes[title].publish()\n        elif isinstance(titles, six.string_types):\n            self.episodes[titles].publish()\n        else:\n            raise TypeError('titles must be a string or a sequence of strings.')\n\n        self.update_rss_feed()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenders audio from the episode s text.", "response": "def render_audio(self):\n        \"\"\"\n        Synthesize audio from the episode's text.\n        \"\"\"\n        segment = text_to_speech(self._text, self.synthesizer, self.synth_args, self.sentence_break)\n\n        milli = len(segment)\n        seconds = '{0:.1f}'.format(float(milli) / 1000 % 60).zfill(2)\n        minutes = '{0:.0f}'.format((milli / (1000 * 60)) % 60).zfill(2)\n        hours = '{0:.0f}'.format((milli / (1000 * 60 * 60)) % 24).zfill(2)\n        self.duration = hours + ':' + minutes + ':' + seconds\n\n        segment.export(self.link, format='mp3')\n        self.length = os.path.getsize(self.link)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef publish(self):\n        if self.published is False:\n            self.published = True\n        else:\n            raise Warning(self.title + ' is already published.')", "response": "Mark an episode as published."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmarking an episode as not published.", "response": "def unpublish(self):\n        \"\"\"\n        Mark an episode as not published.\n        \"\"\"\n        if self.published is True:\n            self.published = False\n        else:\n            raise Warning(self.title + ' is already not published.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nover-writes keyword arguments with environment variables.", "response": "def _environment_variables(**kwargs):\n        # type: (Any) -> Any\n        \"\"\"\n        Overwrite keyword arguments with environment variables\n\n        Args:\n            **kwargs: See below\n            user_agent (str): User agent string.\n\n        Returns:\n            kwargs: Changed keyword arguments\n\n        \"\"\"\n        user_agent = os.getenv('USER_AGENT')\n        if user_agent is not None:\n            kwargs['user_agent'] = user_agent\n        preprefix = os.getenv('PREPREFIX')\n        if preprefix is not None:\n            kwargs['preprefix'] = preprefix\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _construct(configdict, prefix, ua):\n        # type: (Dict, str, str) -> str\n        \"\"\"\n        Construct user agent\n\n        Args:\n            configdict (str): Additional configuration for user agent\n            prefix (str): Text to put at start of user agent\n            ua (str): Custom user agent text\n\n        Returns:\n            str: Full user agent string\n\n        \"\"\"\n        if not ua:\n            raise UserAgentError(\"User_agent parameter missing. It can be your project's name for example.\")\n        preprefix = configdict.get('preprefix')\n        if preprefix:\n            user_agent = '%s:' % preprefix\n        else:\n            user_agent = ''\n        if prefix:\n            user_agent = '%s%s-' % (user_agent, prefix)\n        user_agent = '%s%s' % (user_agent, ua)\n        return user_agent", "response": "Constructs user agent string from user agent configuration and user agent string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _load(cls, prefix, user_agent_config_yaml, user_agent_lookup=None):\n        # type: (str, str, Optional[str]) -> str\n        \"\"\"\n        Load user agent YAML file\n\n        Args:\n            prefix (str): Text to put at start of user agent\n            user_agent_config_yaml (str): Path to user agent YAML file\n            user_agent_lookup (Optional[str]): Lookup key for YAML. Ignored if user_agent supplied.\n\n        Returns:\n            str: user agent\n\n        \"\"\"\n        if not user_agent_config_yaml:\n            user_agent_config_yaml = cls.default_user_agent_config_yaml\n            logger.info(\n                'No user agent or user agent config file given. Using default user agent config file: %s.' % user_agent_config_yaml)\n        if not isfile(user_agent_config_yaml):\n            raise UserAgentError(\n                \"User_agent should be supplied in a YAML config file. It can be your project's name for example.\")\n        logger.info('Loading user agent config from: %s' % user_agent_config_yaml)\n        user_agent_config_dict = load_yaml(user_agent_config_yaml)\n        if user_agent_lookup:\n            user_agent_config_dict = user_agent_config_dict.get(user_agent_lookup)\n        if not user_agent_config_dict:\n            raise UserAgentError(\"No user agent information read from: %s\" % user_agent_config_yaml)\n        ua = user_agent_config_dict.get('user_agent')\n        return cls._construct(user_agent_config_dict, prefix, ua)", "response": "Load user agent config file and construct new instance of class"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create(cls, user_agent=None, user_agent_config_yaml=None,\n                user_agent_lookup=None, **kwargs):\n        # type: (Optional[str], Optional[str], Optional[str], Any) -> str\n        \"\"\"\n        Get full user agent string\n\n        Args:\n            user_agent (Optional[str]): User agent string. HDXPythonLibrary/X.X.X- is prefixed.\n            user_agent_config_yaml (Optional[str]): Path to YAML user agent configuration. Ignored if user_agent supplied. Defaults to ~/.useragent.yml.\n            user_agent_lookup (Optional[str]): Lookup key for YAML. Ignored if user_agent supplied.\n\n        Returns:\n            str: Full user agent string\n\n        \"\"\"\n        kwargs = UserAgent._environment_variables(**kwargs)\n        if 'user_agent' in kwargs:\n            user_agent = kwargs['user_agent']\n            del kwargs['user_agent']\n        prefix = kwargs.get('prefix')\n        if prefix:\n            del kwargs['prefix']\n        else:\n            prefix = 'HDXPythonUtilities/%s' % get_utils_version()\n        if not user_agent:\n            ua = cls._load(prefix, user_agent_config_yaml, user_agent_lookup)\n        else:\n            ua = cls._construct(kwargs, prefix, user_agent)\n        return ua", "response": "Create a new user agent string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the global user agent string for this class.", "response": "def set_global(cls, user_agent=None, user_agent_config_yaml=None,\n                   user_agent_lookup=None, **kwargs):\n        # type: (Optional[str], Optional[str], Optional[str], Any) -> None\n        \"\"\"\n        Set global user agent string\n\n        Args:\n            user_agent (Optional[str]): User agent string. HDXPythonLibrary/X.X.X- is prefixed.\n            user_agent_config_yaml (Optional[str]): Path to YAML user agent configuration. Ignored if user_agent supplied. Defaults to ~/.useragent.yml.\n            user_agent_lookup (Optional[str]): Lookup key for YAML. Ignored if user_agent supplied.\n\n        Returns:\n            None\n        \"\"\"\n        cls.user_agent = cls._create(user_agent, user_agent_config_yaml, user_agent_lookup, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the full user agent string from user agent string from parameters if supplied falling back on global user agent if set.", "response": "def get(cls, user_agent=None, user_agent_config_yaml=None, user_agent_lookup=None, **kwargs):\n        # type: (Optional[str], Optional[str], Optional[str], Any) -> str\n        \"\"\"\n        Get full user agent string from parameters if supplied falling back on global user agent if set.\n\n        Args:\n            user_agent (Optional[str]): User agent string. HDXPythonLibrary/X.X.X- is prefixed.\n            user_agent_config_yaml (Optional[str]): Path to YAML user agent configuration. Ignored if user_agent supplied. Defaults to ~/.useragent.yml.\n            user_agent_lookup (Optional[str]): Lookup key for YAML. Ignored if user_agent supplied.\n\n        Returns:\n            str: Full user agent string\n\n        \"\"\"\n        if user_agent or user_agent_config_yaml or 'user_agent' in UserAgent._environment_variables(**kwargs):\n            return UserAgent._create(user_agent, user_agent_config_yaml, user_agent_lookup, **kwargs)\n        if cls.user_agent:\n            return cls.user_agent\n        else:\n            raise UserAgentError(\n                'You must either set the global user agent: UserAgent.set_global(...) or pass in user agent parameters!')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_yaml(dictionary, path, pretty=False, sortkeys=False):\n    # type: (Dict, str, bool, bool) -> None\n    \"\"\"Save dictionary to YAML file preserving order if it is an OrderedDict\n\n    Args:\n        dictionary (Dict): Python dictionary to save\n        path (str): Path to YAML file\n        pretty (bool): Whether to pretty print. Defaults to False.\n        sortkeys (bool): Whether to sort dictionary keys. Defaults to False.\n\n    Returns:\n        None\n    \"\"\"\n    if sortkeys:\n        dictionary = dict(dictionary)\n    with open(path, 'w') as f:\n        if pretty:\n            pyaml.dump(dictionary, f)\n        else:\n            yaml.dump(dictionary, f, default_flow_style=None, Dumper=yamlloader.ordereddict.CDumper)", "response": "Save dictionary to YAML file preserving order if it is an OrderedDict\n ArcGIS object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving a Python dictionary to a JSON file preserving order if it is an OrderedDict AttributeNames", "response": "def save_json(dictionary, path, pretty=False, sortkeys=False):\n    # type: (Dict, str, bool, bool) -> None\n    \"\"\"Save dictionary to JSON file preserving order if it is an OrderedDict\n\n    Args:\n        dictionary (Dict): Python dictionary to save\n        path (str): Path to JSON file\n        pretty (bool): Whether to pretty print. Defaults to False.\n        sortkeys (bool): Whether to sort dictionary keys. Defaults to False.\n\n    Returns:\n        None\n    \"\"\"\n    with open(path, 'w') as f:\n        if pretty:\n            indent = 2\n            separators = (',', ': ')\n        else:\n            indent = None\n            separators = (', ', ': ')\n        json.dump(dictionary, f, indent=indent, sort_keys=sortkeys, separators=separators)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a YAML file into an ordered dictionary", "response": "def load_yaml(path):\n    # type: (str) -> OrderedDict\n    \"\"\"Load YAML file into an ordered dictionary\n\n    Args:\n        path (str): Path to YAML file\n\n    Returns:\n        OrderedDict: Ordered dictionary containing loaded YAML file\n    \"\"\"\n    with open(path, 'rt') as f:\n        yamldict = yaml.load(f.read(), Loader=yamlloader.ordereddict.CSafeLoader)\n    if not yamldict:\n        raise (LoadError('YAML file: %s is empty!' % path))\n    return yamldict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_json(path):\n    # type: (str) -> OrderedDict\n    \"\"\"Load JSON file into an ordered dictionary\n\n    Args:\n        path (str): Path to JSON file\n\n    Returns:\n        OrderedDict: Ordered dictionary containing loaded JSON file\n    \"\"\"\n    with open(path, 'rt') as f:\n        jsondict = json.loads(f.read(), object_pairs_hook=OrderedDict)\n    if not jsondict:\n        raise (LoadError('JSON file: %s is empty!' % path))\n    return jsondict", "response": "Load a JSON file into an ordered dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads file into a string removing newlines", "response": "def load_file_to_str(path):\n    # type: (str) -> str\n    \"\"\"\n    Load file into a string removing newlines\n\n    Args:\n        path (str): Path to file\n\n    Returns:\n        str: String contents of file\n\n    \"\"\"\n    with open(path, 'rt') as f:\n        string = f.read().replace(linesep, '')\n    if not string:\n        raise LoadError('%s file is empty!' % path)\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef contributors(lancet, output):\n    sorting = pygit2.GIT_SORT_TIME | pygit2.GIT_SORT_REVERSE\n    commits = lancet.repo.walk(lancet.repo.head.target, sorting)\n    contributors = ((c.author.name, c.author.email) for c in commits)\n    contributors = OrderedDict(contributors)\n\n    template_content = content_from_path(\n        lancet.config.get('packaging', 'contributors_template'))\n    template = Template(template_content)\n    output.write(template.render(contributors=contributors).encode('utf-8'))", "response": "List all contributors visible in the git history."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef text_to_speech(text, synthesizer, synth_args, sentence_break):\n    if len(text.split()) < 50:\n        if synthesizer == 'watson':\n            with open('.temp.wav', 'wb') as temp:\n                temp.write(watson_request(text=text, synth_args=synth_args).content)\n            response = AudioSegment.from_wav('.temp.wav')\n            os.remove('.temp.wav')\n            return response\n        else:\n            raise ValueError('\"' + synthesizer + '\" synthesizer not found.')\n    else:\n        segments = []\n        for i, sentence in enumerate(text.split(sentence_break)):\n            if synthesizer == 'watson':\n                with open('.temp' + str(i) + '.wav', 'wb') as temp:\n                    temp.write(watson_request(text=sentence, synth_args=synth_args).content)\n                segments.append(AudioSegment.from_wav('.temp' + str(i) + '.wav'))\n                os.remove('.temp' + str(i) + '.wav')\n            else:\n                raise ValueError('\"' + synthesizer + '\" synthesizer not found.')\n\n        response = segments[0]\n        for segment in segments[1:]:\n            response = response + segment\n\n        return response", "response": "Converts given text to a pydub AudioSegment using a specified speech synthesizer."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake a single request to the IBM Watson text - to - speech API.", "response": "def watson_request(text, synth_args):\n    \"\"\"\n    Makes a single request to the IBM Watson text-to-speech API.\n\n    :param text:\n        The text that will be synthesized to audio.\n    :param synth_args:\n        A dictionary of arguments to add to the request. These should include\n        username and password for authentication.\n    \"\"\"\n    params = {\n        'text': text,\n        'accept': 'audio/wav'\n    }\n    if synth_args is not None:\n        params.update(synth_args)\n\n    if 'username' in params:\n        username = params.pop('username')\n    else:\n        raise Warning('The IBM Watson API requires credentials that should be passed as \"username\" and \"password\" in \"synth_args\"')\n    if 'password' in params:\n        password = params.pop('password')\n    else:\n        raise Warning('The IBM Watson API requires credentials that should be passed as \"username\" and \"password\" in \"synth_args\"')\n\n    return requests.get(watson_url, auth=(username, password), params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a podcast RSS feed and returns an xml file.", "response": "def build_rss_feed(podcast):\n    \"\"\"\n    Builds a podcast RSS feed and returns an xml file.\n\n    :param podcast:\n        A Podcast model to build the RSS feed from.\n    \"\"\"\n    if not os.path.exists(podcast.output_path):\n        os.makedirs(podcast.output_path)\n\n    rss = ET.Element('rss', attrib={'xmlns:itunes': 'http://www.itunes.com/dtds/podcast-1.0.dtd', 'version': '2.0'})\n\n    channel = ET.SubElement(rss, 'channel')\n    ET.SubElement(channel, 'title').text = podcast.title\n    ET.SubElement(channel, 'link').text = podcast.link\n    ET.SubElement(channel, 'copyright').text = podcast.copyright\n    ET.SubElement(channel, 'itunes:subtitle').text = podcast.subtitle\n    ET.SubElement(channel, 'itunes:author').text = podcast.author\n    ET.SubElement(channel, 'itunes:summary').text = podcast.description\n    ET.SubElement(channel, 'description').text = podcast.description\n\n    owner = ET.SubElement(channel, 'itunes:owner')\n    ET.SubElement(owner, 'itunes:name').text = podcast.owner_name\n    ET.SubElement(owner, 'itunes:email').text = podcast.owner_email\n\n    ET.SubElement(channel, 'itunes:image').text = podcast.image\n\n    for category in podcast.categories:\n        ET.SubElement(channel, 'itunes:category').text = category\n\n    for episode in sorted(podcast.episodes.values(), key=lambda x: x.publish_date):\n        if episode.published is True:\n            item = ET.SubElement(channel, 'item')\n            ET.SubElement(item, 'title').text = episode.title\n            ET.SubElement(item, 'author').text = episode.author\n            ET.SubElement(item, 'summary').text = episode.summary\n            ET.SubElement(item, 'enclosure', attrib={'url': podcast.link + '/' + episode.link, 'length': str(episode.length), 'type': 'audio/x-mp3'})\n            ET.SubElement(item, 'guid').text = podcast.link + '/' + episode.link\n            ET.SubElement(item, 'pubDate').text = episode.publish_date.strftime('%a, %d %b %Y %H:%M:%S UTC')\n            ET.SubElement(item, 'itunes:duration').text = episode.duration\n\n    tree = ET.ElementTree(rss)\n    with open(podcast.output_path + '/feed.xml', 'wb') as feed:\n        tree.write(feed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_pages(url):\n    while True:\n        yield url\n        doc = html.parse(url).find(\"body\")\n        links = [a for a in doc.findall(\".//a\") if a.text and a.text.startswith(\"next \")]\n        if not links:\n            break\n        url = urljoin(url, links[0].get('href'))", "response": "Get the pages from the starting url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the articles from a page", "response": "def get_article_urls(url):\n    \"\"\"\n    Return the articles from a page\n    Technically, look for a div with class mw-search-result-heading\n    and get the first link from this div\n    \"\"\"\n    doc = html.parse(url).getroot()\n    for div in doc.cssselect(\"div.mw-search-result-heading\"):\n        href = div.cssselect(\"a\")[0].get('href')\n        if \":\" in href:\n            continue # skip Category: links\n        href = urljoin(url, href)\n        yield href"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a single article as a amcat - ready dict", "response": "def get_article(url):\n    \"\"\"\n    Return a single article as a 'amcat-ready' dict\n    Uses the 'export' function of wikinews to get an xml article\n    \"\"\"\n    a = html.parse(url).getroot()\n    title = a.cssselect(\".firstHeading\")[0].text_content()\n    date = a.cssselect(\".published\")[0].text_content()\n    date = datetime.datetime.strptime(date, \"%A, %B %d, %Y\").isoformat()\n    paras = a.cssselect(\"#mw-content-text p\")\n    paras = paras[1:] # skip first paragraph, which contains date\n    text = \"\\n\\n\".join(p.text_content().strip() for p in paras)\n\n    return dict(headline=title,\n                date=date,\n                url=url,\n                text=text,\n                medium=\"Wikinews\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nscrapes wikinews articles from the given query", "response": "def scrape_wikinews(conn, project, articleset, query):\n    \"\"\"\n    Scrape wikinews articles from the given query\n    @param conn: The AmcatAPI object\n    @param articleset: The target articleset ID\n    @param category: The wikinews category name\n    \"\"\"\n    url = \"http://en.wikinews.org/w/index.php?search={}&limit=50\".format(query)\n    logging.info(url)\n    for page in get_pages(url):\n        urls = get_article_urls(page)\n        arts = list(get_articles(urls))\n        logging.info(\"Adding {} articles to set {}:{}\"\n                     .format(len(arts), project, articleset))\n        conn.create_articles(project=project, articleset=articleset,\n                            json_data=arts)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart a service n times", "response": "def start_service(addr, n):\n    \"\"\" Start a service \"\"\"\n    s = Service(addr)\n\n    started = time.time()\n    for _ in range(n):\n        msg = s.socket.recv()\n        s.socket.send(msg)\n    s.socket.close()\n    duration = time.time() - started\n\n    print('Raw REP service stats:')\n    util.print_stats(n, duration)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a callable that can be used to transmit a message with a given topic.", "response": "def pub(self, topic=b'', embed_topic=False):\n        \"\"\"\n        Returns a callable that can be used to transmit a message, with a given\n        ``topic``, in a publisher-subscriber fashion. Note that the sender\n        function has a ``print`` like signature, with an infinite number of\n        arguments. Each one being a part of the complete message.\n\n        By default, no topic will be included into published messages. Being up\n        to developers to include the topic, at the beginning of the first part\n        (i.e. frame) of every published message, so that subscribers are able\n        to receive them. For a different behaviour, check the embed_topic\n        argument.\n\n        :param topic: the topic that will be published to (default=b'')\n        :type topic: bytes\n        :param embed_topic: set for the topic to be automatically sent as the\n                            first part (i.e. frame) of every published message\n                            (default=False)\n        :type embed_topic bool\n        :rtype: function\n        \"\"\"\n        if not isinstance(topic, bytes):\n            error = 'Topic must be bytes'\n            log.error(error)\n            raise TypeError(error)\n\n        sock = self.__sock(zmq.PUB)\n        return self.__send_function(sock, topic, embed_topic)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sub(self, topics=(b'',)):\n        sock = self.__sock(zmq.SUB)\n\n        for topic in topics:\n            if not isinstance(topic, bytes):\n                error = 'Topics must be a list of bytes'\n                log.error(error)\n                raise TypeError(error)\n            sock.setsockopt(zmq.SUBSCRIBE, topic)\n\n        return self.__recv_generator(sock)", "response": "Returns an iterable that can be used to iterate over incoming messages from one of the specified topics."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef push(self):\n        sock = self.__sock(zmq.PUSH)\n        return self.__send_function(sock)", "response": "Returns a callable that can be used to transmit a message in a push - pull - noclean - mode fashion."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an iterable that can be used to iterate over incoming messages from the push socket.", "response": "def pull(self):\n        \"\"\"\n        Returns an iterable that can be used to iterate over incoming messages,\n        that were pushed by a push socket. Note that the iterable returns as\n        many parts as sent by pushers.\n\n        :rtype: generator\n        \"\"\"\n        sock = self.__sock(zmq.PULL)\n        return self.__recv_generator(sock)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef request(self):\n        sock = self.__sock(zmq.REQ)\n        return self.__send_function(sock), self.__recv_generator(sock)", "response": "Returns a callable that returns a message and an iterable respectively."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reply(self):\n        sock = self.__sock(zmq.REP)\n        return self.__send_function(sock), self.__recv_generator(sock)", "response": "Returns a callable and an iterable that returns a single message and a generator that yields all the messages that were requested by the request socket."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a callable and an iterable that returns a single message that was sent by a pair socket.", "response": "def pair(self):\n        \"\"\"\n        Returns a callable and an iterable respectively. Those can be used to\n        both transmit a message and/or iterate over incoming messages, that were\n        sent by a pair socket. Note that the iterable returns as many parts as\n        sent by a pair. Also, the sender function has a ``print`` like signature,\n        with an infinite number of arguments. Each one being a part of the\n        complete message.\n\n        :rtype: (function, generator)\n        \"\"\"\n        sock = self.__sock(zmq.PAIR)\n        return self.__send_function(sock), self.__recv_generator(sock)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconnecting to a server at the specified ip and port.", "response": "def connect(self, ip, port):\n        \"\"\"\n        Connects to a server at the specified ip and port.\n\n        :param ip: an IP address\n        :type ip: str or unicode\n        :param port: port number from 1024 up to 65535\n        :type port: int\n        :rtype: self\n        \"\"\"\n        _check_valid_port_range(port)\n\n        address = (ip, port)\n\n        if address in self._addresses:\n            error = 'Already connected to {0} on port {1}'.format(ip, port)\n            log.exception(error)\n            raise ValueError(error)\n\n        self._addresses.append(address)\n\n        if self._is_ready:\n            _check_valid_num_connections(self._sock.socket_type,\n                                         len(self._addresses))\n\n            _connect_zmq_sock(self._sock, ip, port)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndisconnect from a server at the specified ip and port.", "response": "def disconnect(self, ip, port):\n        \"\"\"\n        Disconnects from a server at the specified ip and port.\n\n        :param ip: an IP address\n        :type ip: str or unicode\n        :param port: port number from 1024 up to 65535\n        :type port: int\n        :rtype: self\n        \"\"\"\n        _check_valid_port_range(port)\n        address = (ip, port)\n\n        try:\n            self._addresses.remove(address)\n        except ValueError:\n            error = 'There was no connection to {0} on port {1}'.format(ip, port)\n            log.exception(error)\n            raise ValueError(error)\n\n        if self._is_ready:\n            _disconnect_zmq_sock(self._sock, ip, port)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndisconnects from all connected servers.", "response": "def disconnect_all(self):\n        \"\"\"\n        Disconnects from all connected servers.\n        :rtype: self\n        \"\"\"\n        addresses = deepcopy(self._addresses)\n\n        for ip, port in addresses:\n            self.disconnect(ip, port)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_exponent(d):\n    return d.quantize(Decimal(1)) if d == d.to_integral() else d.normalize()", "response": "Remove exponent from a sequence of decimal values."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nseparates with predefined separator.", "response": "def prettify(amount, separator=','):\n    \"\"\"Separate with predefined separator.\"\"\"\n    orig = str(amount)\n    new = re.sub(\"^(-?\\d+)(\\d{3})\", \"\\g<1>{0}\\g<2>\".format(separator), str(amount))\n    if orig == new:\n        return new\n    else:\n        return prettify(new)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_json(json_data, decoder=None):\n    if decoder is None:\n        decoder = DateTimeDecoder\n    return json.loads(json_data, object_hook=decoder.decode)", "response": "Load data from json string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading data from json file", "response": "def load_json_file(file, decoder=None):\n    \"\"\"\n    Load data from json file\n\n    :param file: Readable object or path to file\n    :type file: FileIO | str\n    :param decoder: Use custom json decoder\n    :type decoder: T <= DateTimeDecoder\n    :return: Json data\n    :rtype: None | int | float | str | list | dict\n    \"\"\"\n    if decoder is None:\n        decoder = DateTimeDecoder\n    if not hasattr(file, \"read\"):\n        with io.open(file, \"r\", encoding=\"utf-8\") as f:\n            return json.load(f, object_hook=decoder.decode)\n    return json.load(file, object_hook=decoder.decode)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_json(val, pretty=False, sort=True, encoder=None):\n    if encoder is None:\n        encoder = DateTimeEncoder\n    if pretty:\n        data = json.dumps(\n            val,\n            indent=4,\n            separators=(',', ': '),\n            sort_keys=sort,\n            cls=encoder\n        )\n    else:\n        data = json.dumps(\n            val,\n            separators=(',', ':'),\n            sort_keys=sort,\n            cls=encoder\n        )\n    if not sys.version_info > (3, 0) and isinstance(data, str):\n        data = data.decode(\"utf-8\")\n    return data", "response": "Save data to json string"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_json_file(\n        file, val,\n        pretty=False, compact=True, sort=True, encoder=None\n):\n    \"\"\"\n    Save data to json file\n\n    :param file: Writable object or path to file\n    :type file: FileIO | str | unicode\n    :param val: Value or struct to save\n    :type val: None | int | float | str | list | dict\n    :param pretty: Format data to be readable (default: False)\n    :type pretty: bool\n    :param compact: Format data to be compact (default: True)\n    :type compact: bool\n    :param sort: Sort keys (default: True)\n    :type sort: bool\n    :param encoder: Use custom json encoder\n    :type encoder: T <= DateTimeEncoder\n    :rtype: None\n    \"\"\"\n    # TODO: make pretty/compact into one bool?\n    if encoder is None:\n        encoder = DateTimeEncoder\n    opened = False\n\n    if not hasattr(file, \"write\"):\n        file = io.open(file, \"w\", encoding=\"utf-8\")\n        opened = True\n\n    try:\n        if pretty:\n            data = json.dumps(\n                val,\n                indent=4,\n                separators=(',', ': '),\n                sort_keys=sort,\n                cls=encoder\n            )\n        elif compact:\n            data = json.dumps(\n                val,\n                separators=(',', ':'),\n                sort_keys=sort,\n                cls=encoder\n            )\n        else:\n            data = json.dumps(val, sort_keys=sort, cls=encoder)\n        if not sys.version_info > (3, 0) and isinstance(data, str):\n            data = data.decode(\"utf-8\")\n        file.write(data)\n    finally:\n        if opened:\n            file.close()", "response": "Save data to json file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_yaml_file(file):\n    if not hasattr(file, \"read\"):\n        with io.open(file, \"r\", encoding=\"utf-8\") as f:\n            return yaml.load(f, yaml.FullLoader)\n    return yaml.load(file, yaml.FullLoader)", "response": "Load data from yaml file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave data to a yaml file", "response": "def save_yaml_file(file, val):\n    \"\"\"\n    Save data to yaml file\n\n    :param file: Writable object or path to file\n    :type file: FileIO | str | unicode\n    :param val: Value or struct to save\n    :type val: None | int | float | str | unicode | list | dict\n    \"\"\"\n    opened = False\n\n    if not hasattr(file, \"write\"):\n        file = io.open(file, \"w\", encoding=\"utf-8\")\n        opened = True\n\n    try:\n        yaml.dump(val, file)\n    finally:\n        if opened:\n            file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_file(path):\n    res = {}\n\n    if not path:\n        IOError(\"No path specified to save\")\n\n    if not os.path.isfile(path):\n        raise IOError(\"File not found {}\".format(path))\n\n    try:\n        with io.open(path, \"r\", encoding=\"utf-8\") as f:\n            if path.endswith(\".json\"):\n                res = load_json_file(f)\n            elif path.endswith(\".yaml\") or path.endswith(\".yml\"):\n                res = load_yaml_file(f)\n    except IOError:\n        raise\n    except Exception as e:\n        raise IOError(e)\n    return res", "response": "Loads the file at the specified path and returns the loaded data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves data to file", "response": "def save_file(path, data, readable=False):\n    \"\"\"\n    Save to file\n\n    :param path: File path to save\n    :type path: str | unicode\n    :param data: Data to save\n    :type data: None | int | float | str | unicode | list | dict\n    :param readable: Format file to be human readable (default: False)\n    :type readable: bool\n    :rtype: None\n    :raises IOError: If empty path or error writing file\n    \"\"\"\n    if not path:\n        IOError(\"No path specified to save\")\n\n    try:\n        with io.open(path, \"w\", encoding=\"utf-8\") as f:\n            if path.endswith(\".json\"):\n                save_json_file(\n                    f,\n                    data,\n                    pretty=readable,\n                    compact=(not readable),\n                    sort=True\n                )\n            elif path.endswith(\".yaml\") or path.endswith(\".yml\"):\n                save_yaml_file(f, data)\n    except IOError:\n        raise\n    except Exception as e:\n        raise IOError(e)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef join_path_prefix(path, pre_path=None):\n    if not path:\n        return path\n\n    if pre_path and not os.path.isabs(path):\n        return os.path.join(pre_path, path)\n\n    return path", "response": "Join path with pre_path if path is not absolute."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _load_json_file(self, file, decoder=None):\n        try:\n            res = load_json_file(file, decoder=decoder)\n        except ValueError as e:\n            if \"{}\".format(e) == \"No JSON object could be decoded\":\n                raise IOError(\"Decoding JSON failed\")\n            self.exception(\"Failed to load from {}\".format(file))\n            raise IOError(\"Loading file failed\")\n        except:\n            self.exception(\"Failed to load from {}\".format(file))\n            raise IOError(\"Loading file failed\")\n        return res", "response": "Load data from json file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _save_json_file(\n        self, file, val,\n        pretty=False, compact=True, sort=True, encoder=None\n    ):\n        \"\"\"\n        Save data to json file\n\n        :param file: Writable file or path to file\n        :type file: FileIO | str | unicode\n        :param val: Value or struct to save\n        :type val: None | int | float | str | list | dict\n        :param pretty: Format data to be readable (default: False)\n        :type pretty: bool\n        :param compact: Format data to be compact (default: True)\n        :type compact: bool\n        :param sort: Sort keys (default: True)\n        :type sort: bool\n        :param encoder: Use custom json encoder\n        :type encoder: T <= flotils.loadable.DateTimeEncoder\n        :rtype: None\n        :raises IOError: Failed to save\n        \"\"\"\n        try:\n            save_json_file(file, val, pretty, compact, sort, encoder)\n        except:\n            self.exception(\"Failed to save to {}\".format(file))\n            raise IOError(\"Saving file failed\")", "response": "Save data to json file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload data from yaml file", "response": "def _load_yaml_file(self, file):\n        \"\"\"\n        Load data from yaml file\n\n        :param file: Readable object or path to file\n        :type file: FileIO | str | unicode\n        :return: Yaml data\n        :rtype: None | int | float | str | unicode | list | dict\n        :raises IOError: Failed to load\n        \"\"\"\n        try:\n            res = load_yaml_file(file)\n        except:\n            self.exception(\"Failed to load from {}\".format(file))\n            raise IOError(\"Loading file failed\")\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _save_yaml_file(self, file, val):\n        try:\n            save_yaml_file(file, val)\n        except:\n            self.exception(\"Failed to save to {}\".format(file))\n            raise IOError(\"Saving file failed\")", "response": "Save data to yaml file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_settings(self, path):\n        res = self.load_file(path)\n        if not isinstance(res, dict):\n            raise TypeError(\"Expected settings to be dict\")\n        return res", "response": "Load settings from file"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the settings to file", "response": "def save_settings(self, path, settings, readable=False):\n        \"\"\"\n        Save settings to file\n\n        :param path: File path to save\n        :type path: str | unicode\n        :param settings: Settings to save\n        :type settings: dict\n        :param readable: Format file to be human readable (default: False)\n        :type readable: bool\n        :rtype: None\n        :raises IOError: If empty path or error writing file\n        :raises TypeError: Settings is not a dict\n        \"\"\"\n        if not isinstance(settings, dict):\n            raise TypeError(\"Expected settings to be dict\")\n        return self.save_file(path, settings, readable)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_file(self, path):\n        res = None\n\n        if not path:\n            IOError(\"No path specified to save\")\n\n        if not os.path.isfile(path):\n            raise IOError(\"File not found {}\".format(path))\n\n        try:\n            with io.open(path, \"r\", encoding=\"utf-8\") as f:\n                if path.endswith(\".json\"):\n                    res = self._load_json_file(f)\n                elif path.endswith(\".yaml\") or path.endswith(\".yml\"):\n                    res = self._load_yaml_file(f)\n        except IOError:\n            raise\n        except Exception as e:\n            self.exception(\"Failed reading {}\".format(path))\n            raise IOError(e)\n        return res", "response": "Loads the settings from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_file(self, path, data, readable=False):\n        if not path:\n            IOError(\"No path specified to save\")\n\n        try:\n            with io.open(path, \"w\", encoding=\"utf-8\") as f:\n                if path.endswith(\".json\"):\n                    self._save_json_file(\n                        f,\n                        data,\n                        pretty=readable,\n                        compact=(not readable),\n                        sort=True\n                    )\n                elif path.endswith(\".yaml\") or path.endswith(\".yml\"):\n                    self._save_yaml_file(f, data)\n        except IOError:\n            raise\n        except Exception as e:\n            self.exception(\"Failed writing {}\".format(path))\n            raise IOError(e)", "response": "Save the data to file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef name(self):\n        res = type(self).__name__\n        if self._id:\n            res += \".{}\".format(self._id)\n        return res", "response": "Get the module name of the object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget function name of calling method", "response": "def _get_function_name(self):\n        \"\"\"\n        Get function name of calling method\n\n        :return: The name of the calling function\n            (expected to be called in self.error/debug/..)\n        :rtype: str | unicode\n        \"\"\"\n        fname = inspect.getframeinfo(inspect.stack()[2][0]).function\n        if fname == \"<module>\":\n            return \"\"\n        else:\n            return fname"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting the interface :param blocking: Should the call block until stop() is called (default: False) :type blocking: bool :rtype: None", "response": "def start(self, blocking=False):\n        \"\"\"\n        Start the interface\n\n        :param blocking: Should the call block until stop() is called\n            (default: False)\n        :type blocking: bool\n        :rtype: None\n        \"\"\"\n        super(StartStopable, self).start()\n        self._is_running = True\n        # blocking\n        try:\n            while blocking and self._is_running:\n                time.sleep(self._start_block_timeout)\n        except IOError as e:\n            if not str(e).lower().startswith(\"[errno 4]\"):\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract YARA signatures embedded in Yara indicatorItem nodes.", "response": "def get_embedded_yara(self, iocid):\n        \"\"\"\n        Extract YARA signatures embedded in Yara/Yara indicatorItem nodes.\n        This is done regardless of logic structure in the OpenIOC.\n        \"\"\"\n        ioc_obj = self.iocs[iocid]\n        ids_to_process = set([])\n        signatures = ''\n        for elem in ioc_obj.top_level_indicator.xpath('.//IndicatorItem[Context/@search = \"Yara/Yara\"]'):\n            signature = elem.findtext('Content')\n            signatures = signatures + '\\n' + signature\n        if signatures:\n            signatures += '\\n'\n        return signatures"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_yara_condition_string(self, indicator_node, parameters_node, ids_to_process, condition_string='',\n                                  joining_value='or'):\n        \"\"\"\n        get_yara_condition_string\n\n        input\n            indicator_node: this is the node we walk down\n            parameters_node: this contains all the parameters in the ioc, so we\n                can look up parameters nodes as we walk them.\n            ids_to_process: set of ids to upgrade\n            condition_string: This represnts the yara condition string.  This\n                string grows as we walk nodes.\n        return\n            returns True upon completion\n            may raise ValueError\n        \"\"\"\n\n        indicator_node_id = str(indicator_node.get('id'))\n        if indicator_node_id not in ids_to_process:\n            msg = 'Entered into get_yara_condition_string with a invalid node to walk [[}]'.format(indicator_node_id)\n            raise YaraConversionError(msg)\n        expected_tag = 'Indicator'\n        if indicator_node.tag != expected_tag:\n            raise YaraConversionError('indicator_node expected tag is [%s]' % expected_tag)\n        is_set = None\n        # print 'indicator node id [%s]' % str(indicator_node_id)\n        for param in parameters_node.xpath('.//param[@ref-id=\"{}\"]'.format(indicator_node_id)):\n            if param.attrib['name'] == 'yara/set':\n                is_set = True\n                set_count = param.findtext('value', None)\n                try:\n                    temp = int(set_count)\n                    if temp < 1:\n                        raise YaraConversionError('yara/set parameter value was less than 1')\n                    if temp > len(indicator_node.getchildren()):\n                        msg = 'yara/set value is greater than the number of children' \\\n                              ' of Indicator node [%s]' % str(indicator_node_id)\n                        raise YaraConversionError(msg)\n                except ValueError:\n                    raise YaraConversionError('yara/set parameter was not a integer')\n                set_dict = {'set_count': set_count, 'set_ids': []}\n\n        for node in indicator_node.getchildren():\n            node_id = node.get('id')\n            # XXX strip out '-' characters from the ids.  If a guid is used as\n            # the id, this will cause processing errors\n            safe_node_id = node_id.replace('-', '')\n            if node_id not in ids_to_process:\n                continue\n            if node.tag == 'IndicatorItem':\n                # print 'handling indicatoritem: [%s]' % node_id\n                if is_set:\n                    set_dict['set_ids'].append('$' + safe_node_id)\n                else:\n                    # Default mapping\n                    mapping = {'prefix': '$', 'identifier': safe_node_id, 'condition': '', 'postfix': ''}\n                    # XXX: Alot of this could raise ValueError\n                    use_condition_template = False\n                    negation = node.get('negate')\n                    condition = node.get('condition')\n                    search = node.xpath('Context/@search')[0]\n                    content = node.findtext('Content')\n\n                    yara_condition = self.condition_to_yara_map[condition]\n                    if not yara_condition:\n                        msg = 'Invalid IndicatorItem condition encountered [%s][%s]' % (str(node_id), str(condition))\n                        raise YaraConversionError(msg)\n                    if negation.lower() == 'true':\n                        negation = True\n                    else:\n                        negation = False\n                    # parameters cannot modifier the condition of FileSize or Rule\n                    if search == 'Yara/FileSize':\n                        mapping['prefix'] = ''\n                        mapping['identifier'] = 'filesize'\n                        mapping['postfix'] = ' ' + content\n                        mapping['condition'] = yara_condition\n                        use_condition_template = True\n                    elif search == 'Yara/RuleName':\n                        if content not in self.ioc_names_set:\n                            if mangle_name(content) in self.ioc_names_mangled_set:\n                                msg = 'Yara/RuleName is present as a mangled name.[{}][{}]'.format(mangle_name(content),\n                                                                                                   node_id)\n                                log.warning(msg)\n                                content = mangle_name(content)\n                            else:\n                                log.warning('Yara/RuleName points to a name [{}] that is not in the set of IOCs being'\n                                            ' processed [{}]'.format(content, node_id))\n                        if mangle_name(content) != content:\n                            msg = 'Yara/RuleName contains characters which would cause libyara errors' \\\n                                  ' [{}]'.format(node_id)\n                            raise YaraConversionError(msg)\n                        mapping['prefix'] = ''\n                        mapping['identifier'] = content\n                    # handle parameters\n                    else:\n                        xp = './/param[@ref-id=\"{}\" and (@name=\"yara/count\" or @name=\"yara/offset/at\" or' \\\n                             ' @name=\"yara/offset/in\")]'.format(node_id)\n                        params = parameters_node.xpath(xp)\n                        if len(params) > 1:\n                            msg = 'More than one condition parameters assigned to IndicatorItem [{}]'.format(node_id)\n                            raise YaraConversionError(msg)\n                        for param in params:\n                            param_name = param.get('name', None)\n                            if param_name == 'yara/count':\n                                log.debug('Found [%s] attached to [%s]' % (param.attrib['name'], node_id))\n                                mapping['prefix'] = '#'\n                                mapping['postfix'] = ' ' + param.findtext('value')\n                                mapping['condition'] = yara_condition\n                                use_condition_template = True\n                                break\n                            elif param_name == 'yara/offset/at':\n                                log.debug('Found [%s] attached to [%s]' % (param.attrib['name'], node_id))\n                                mapping['condition'] = 'at'\n                                mapping['postfix'] = ' ' + param.findtext('value')\n                                use_condition_template = True\n                                break\n                            elif param_name == 'yara/offset/in':\n                                log.debug('Found [%s] attached to [%s]' % (param.attrib['name'], node_id))\n                                mapping['condition'] = 'in'\n                                mapping['postfix'] = ' ' + param.findtext('value')\n                                use_condition_template = True\n                                break\n\n                    if use_condition_template:\n                        temp_string = self.yara_II_condition_template % mapping\n                    else:\n                        temp_string = self.yara_II_template % mapping\n\n                    if condition_string == '':\n                        condition_string = temp_string\n                    else:\n                        condition_string = ' '.join([condition_string, joining_value, temp_string])\n                        # print condition_string\n\n            elif node.tag == 'Indicator':\n                if is_set:\n                    raise YaraConversionError('Cannot have Indicator nodes underneath a Indicator node with yara/set')\n                operator = node.get('operator').lower()\n                if operator not in ['or', 'and']:\n                    raise YaraConversionError('Indicator@operator is not and/or. [%s] has [%s]' % (id, operator))\n                # handle parameters\n                # XXX Temp POC\n                recursed_condition = self.get_yara_condition_string(node, parameters_node, ids_to_process, '', operator)\n                xp = './/param[@ref-id=\"{}\" and @name=\"yara/set\"]'.format(node_id)\n                if (not parameters_node.xpath(xp)) and has_siblings(node):\n                    recursed_condition = '(%s)' % recursed_condition\n\n                if condition_string == '':\n                    condition_string = recursed_condition\n                else:\n                    condition_string = ' '.join([condition_string, joining_value, recursed_condition])\n                    # print 'recursed got: [%s]' % condition_string\n            else:\n                # should never get here\n                raise YaraConversionError('node.tag is not a Indicator/IndicatorItem [%s]' % str(id))\n\n        if is_set:\n            log.debug('Building set expression for [%s]' % indicator_node_id)\n            if len(set_dict['set_ids']) == 0:\n                raise YaraConversionError('yara/set processing did not yield any set ids')\n            elif len(set_dict['set_ids']) == 1:\n                log.warning('yara/set with 1 id found for node [%s]' % node_id)\n                set_ids = ''.join(set_dict['set_ids'])\n            else:\n                set_ids = ','.join(set_dict['set_ids'])\n            set_dict['set_ids'] = set_ids\n            temp_set_string = self.yara_set_string_template % set_dict\n            # print temp_set_string\n            if condition_string == '':\n                condition_string = temp_set_string\n            else:\n                condition_string = ' '.join(\n                    [condition_string, indicator_node.getparent().get('operator').lower(), temp_set_string])\n\n        return condition_string", "response": "This function returns the string that can be used to build the yara condition string for the Yara object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_yara(self, output_file):\n        fout = open(output_file, 'wb')\n        fout.write('\\n')\n\n        for iocid in self.yara_signatures:\n            signature = self.yara_signatures[iocid]\n            fout.write(signature)\n            fout.write('\\n')\n\n        fout.close()\n        return True", "response": "Write out the yara signatures to a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking an arbitrary directory. This is safe to call for Python 2 users.", "response": "def safe_makedirs(fdir):\n    \"\"\"\n    Make an arbitrary directory.  This is safe to call for Python 2 users.\n\n    :param fdir: Directory path to make.\n    :return:\n    \"\"\"\n    if os.path.isdir(fdir):\n        pass\n        # print 'dir already exists: %s' % str(dir)\n    else:\n        try:\n            os.makedirs(fdir)\n        except WindowsError as e:\n            if 'Cannot create a file when that file already exists' in e:\n                log.debug('relevant dir already exists')\n            else:\n                raise WindowsError(e)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the iocs in self. iocs from OpenIOC 1. 1 format to OpenIOC 1. 0 format.", "response": "def convert_to_10(self):\n        \"\"\"\n        converts the iocs in self.iocs from openioc 1.1 to openioc 1.0 format.\n        the converted iocs are stored in the dictionary self.iocs_10\n        :return: A list of iocid values which had errors downgrading.\n        \"\"\"\n        if len(self) < 1:\n            log.error('no iocs available to modify')\n            return False\n        log.info('Converting IOCs from 1.1 to 1.0.')\n        errors = []\n        for iocid in self.iocs:\n            pruned = False\n            ioc_obj_11 = self.iocs[iocid]\n            metadata = ioc_obj_11.metadata\n            # record metadata\n            name_11 = metadata.findtext('.//short_description')\n            keywords_11 = metadata.findtext('.//keywords')\n            description_11 = metadata.findtext('.//description')\n            author_11 = metadata.findtext('.//authored_by')\n            created_date_11 = metadata.findtext('.//authored_date')\n            last_modified_date_11 = ioc_obj_11.root.get('last-modified')\n            links_11 = []\n            for link in metadata.xpath('//link'):\n                link_rel = link.get('rel')\n                link_text = link.text\n                links_11.append((link_rel, None, link_text))\n            # get ioc_logic\n            try:\n                ioc_logic = ioc_obj_11.root.xpath('.//criteria')[0]\n            except IndexError:\n                log.exception(\n                    'Could not find criteria nodes for IOC [{}].  Did you attempt to convert OpenIOC 1.0 iocs?'.format(\n                        iocid))\n                errors.append(iocid)\n                continue\n            try:\n                tlo_11 = ioc_logic.getchildren()[0]\n            except IndexError:\n                log.exception(\n                    'Could not find children for the top level criteria/children nodes for IOC [{}]'.format(iocid))\n                errors.append(iocid)\n                continue\n            tlo_id = tlo_11.get('id')\n            # record comment parameters\n            comment_dict = {}\n            for param in ioc_obj_11.parameters.xpath('//param[@name=\"comment\"]'):\n                param_id = param.get('ref-id')\n                param_text = param.findtext('value')\n                comment_dict[param_id] = param_text\n            # create a 1.1 indicator and populate it with the metadata from the existing 1.1\n            # we will then modify this new IOC to conform to 1.1 schema\n            ioc_obj_10 = ioc_api.IOC(name=name_11, description=description_11, author=author_11, links=links_11,\n                                     keywords=keywords_11, iocid=iocid)\n            ioc_obj_10.root.attrib['last-modified'] = last_modified_date_11\n            authored_date_node = ioc_obj_10.metadata.find('authored_date')\n            authored_date_node.text = created_date_11\n\n            # convert 1.1 ioc object to 1.0\n            # change xmlns\n            ioc_obj_10.root.attrib['xmlns'] = 'http://schemas.mandiant.com/2010/ioc'\n            # remove published data\n            del ioc_obj_10.root.attrib['published-date']\n            # remove parameters node\n            ioc_obj_10.root.remove(ioc_obj_10.parameters)\n            # change root tag\n            ioc_obj_10.root.tag = 'ioc'\n            # metadata underneath the root node\n            metadata_node = ioc_obj_10.metadata\n            criteria_node = ioc_obj_10.top_level_indicator.getparent()\n            metadata_dictionary = {}\n            for child in metadata_node:\n                metadata_dictionary[child.tag] = child\n            for tag in METADATA_REQUIRED_10:\n                if tag not in metadata_dictionary:\n                    msg = 'IOC {} is missing required metadata: [{}]'.format(iocid, tag)\n                    raise DowngradeError(msg)\n            for tag in METADATA_ORDER_10:\n                if tag in metadata_dictionary:\n                    ioc_obj_10.root.append(metadata_dictionary.get(tag))\n            ioc_obj_10.root.remove(metadata_node)\n            ioc_obj_10.root.remove(criteria_node)\n            criteria_node.tag = 'definition'\n            ioc_obj_10.root.append(criteria_node)\n\n            ioc_obj_10.top_level_indicator.attrib['id'] = tlo_id\n            # identify indicator items with 1.1 specific operators\n            # we will skip them when converting IOC from 1.1 to 1.0.\n            ids_to_skip = set()\n            indicatoritems_to_remove = set()\n            for condition_type in self.openioc_11_only_conditions:\n                for elem in ioc_logic.xpath('//IndicatorItem[@condition=\"%s\"]' % condition_type):\n                    pruned = True\n                    indicatoritems_to_remove.add(elem)\n            for elem in ioc_logic.xpath('//IndicatorItem[@preserve-case=\"true\"]'):\n                pruned = True\n                indicatoritems_to_remove.add(elem)\n            # walk up from each indicatoritem\n            # to build set of ids to skip when downconverting\n            for elem in indicatoritems_to_remove:\n                nid = None\n                current = elem\n                while nid != tlo_id:\n                    parent = current.getparent()\n                    nid = parent.get('id')\n                    if nid == tlo_id:\n                        current_id = current.get('id')\n                        ids_to_skip.add(current_id)\n                    else:\n                        current = parent\n            # walk the 1.1 IOC to convert it into a 1.0 IOC\n            # noinspection PyBroadException\n            try:\n                self.convert_branch(tlo_11, ioc_obj_10.top_level_indicator, ids_to_skip, comment_dict)\n            except DowngradeError:\n                log.exception('Problem converting IOC [{}]'.format(iocid))\n                errors.append(iocid)\n                continue\n            except Exception:\n                log.exception('Unknown error occured while converting [{}]'.format(iocid))\n                errors.append(iocid)\n                continue\n            # bucket pruned iocs / null iocs\n            if not ioc_obj_10.top_level_indicator.getchildren():\n                self.null_pruned_iocs.add(iocid)\n            elif pruned is True:\n                self.pruned_11_iocs.add(iocid)\n            # Check the original to see if there was a comment prior to the root node, and if so, copy it's content\n            comment_node = ioc_obj_11.root.getprevious()\n            while comment_node is not None:\n                log.debug('found a comment node')\n                c = et.Comment(comment_node.text)\n                ioc_obj_10.root.addprevious(c)\n                comment_node = comment_node.getprevious()\n            # Record the IOC\n            # ioc_10 = et.ElementTree(root_10)\n            self.iocs_10[iocid] = ioc_obj_10\n        return errors"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_branch(self, old_node, new_node, ids_to_skip, comment_dict=None):\n        expected_tag = 'Indicator'\n        if old_node.tag != expected_tag:\n            raise DowngradeError('old_node expected tag is [%s]' % expected_tag)\n        if not comment_dict:\n            comment_dict = {}\n        for node in old_node.getchildren():\n            node_id = node.get('id')\n            if node_id in ids_to_skip:\n                continue\n            if node.tag == 'IndicatorItem':\n                negation = node.get('negate')\n                condition = node.get('condition')\n                if 'true' in negation.lower():\n                    new_condition = condition + 'not'\n                else:\n                    new_condition = condition\n                document = node.xpath('Context/@document')[0]\n                search = node.xpath('Context/@search')[0]\n                content_type = node.xpath('Content/@type')[0]\n                content = node.findtext('Content')\n                context_type = node.xpath('Context/@type')[0]\n                new_ii_node = ioc_api.make_indicatoritem_node(condition=condition,\n                                                              document=document,\n                                                              search=search,\n                                                              content_type=content_type,\n                                                              content=content,\n                                                              context_type=context_type,\n                                                              nid=node_id)\n                # set condition\n                new_ii_node.attrib['condition'] = new_condition\n                # set comment\n                if node_id in comment_dict:\n                    comment = comment_dict[node_id]\n                    comment_node = et.Element('Comment')\n                    comment_node.text = comment\n                    new_ii_node.append(comment_node)\n                # remove preserver-case and negate\n                del new_ii_node.attrib['negate']\n                del new_ii_node.attrib['preserve-case']\n                new_node.append(new_ii_node)\n            elif node.tag == 'Indicator':\n                operator = node.get('operator')\n                if operator.upper() not in ['OR', 'AND']:\n                    raise DowngradeError('Indicator@operator is not AND/OR. [%s] has [%s]' % (node_id, operator))\n                new_i_node = ioc_api.make_indicator_node(operator, node_id)\n                new_node.append(new_i_node)\n                self.convert_branch(node, new_i_node, ids_to_skip, comment_dict)\n            else:\n                # should never get here\n                raise DowngradeError('node is not a Indicator/IndicatorItem')\n        return True", "response": "Recursively walk a branch of the Indicator node and convert it to a new node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_iocs(self, directory=None, source=None):\n        \"\"\"\n\n\n        if directory is None, write the iocs to the current working directory\n        source: allows specifying a different dictionry of elmentTree ioc objects\n        \"\"\"\n        if not source:\n            source = self.iocs_10\n        if len(source) < 1:\n            log.error('no iocs available to write out')\n            return False\n        if not directory:\n            directory = os.getcwd()\n        if os.path.isfile(directory):\n            log.error('cannot writes iocs to a directory')\n            return False\n        source_iocs = set(source.keys())\n        source_iocs = source_iocs.difference(self.pruned_11_iocs)\n        source_iocs = source_iocs.difference(self.null_pruned_iocs)\n        if not source_iocs:\n            log.error('no iocs available to write out after removing pruned/null iocs')\n            return False\n        utils.safe_makedirs(directory)\n        output_dir = os.path.abspath(directory)\n        log.info('Writing IOCs to %s' % (str(output_dir)))\n        # serialize the iocs\n        for iocid in source_iocs:\n            ioc_obj = source[iocid]\n            ioc_obj.write_ioc_to_file(output_dir=output_dir, force=True)\n        return True", "response": "Writes the IOCs to a directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_pruned_iocs(self, directory=None, pruned_source=None):\n        \"\"\"\n        write_pruned_iocs to a directory\n\n        if directory is None, write the iocs to the current working directory\n        \"\"\"\n        if pruned_source is None:\n            pruned_source = self.pruned_11_iocs\n        if len(pruned_source) < 1:\n            log.error('no iocs available to write out')\n            return False\n        if not directory:\n            directory = os.getcwd()\n        if os.path.isfile(directory):\n            log.error('cannot writes iocs to a directory')\n            return False\n        utils.safe_makedirs(directory)\n        output_dir = os.path.abspath(directory)\n        # serialize the iocs\n        for iocid in pruned_source:\n            ioc_obj = self.iocs_10[iocid]\n            ioc_obj.write_ioc_to_file(output_dir=output_dir, force=True)\n        return True", "response": "Writes the IOCs to a directory that have been pruned."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_dnsentryitem_recordname(dns_name, condition='contains', negate=False, preserve_case=False):\n    document = 'DnsEntryItem'\n    search = 'DnsEntryItem/RecordName'\n    content_type = 'string'\n    content = dns_name\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for a DnsEntryItem recordname"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_driveritem_deviceitem_devicename(device_name, condition='is', negate=False, preserve_case=False):\n    document = 'DriverItem'\n    search = 'DriverItem/DeviceItem/DeviceName'\n    content_type = 'string'\n    content = device_name\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for DriverItem and DeviceName"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_driveritem_drivername(driver_name, condition='contains', negate=False, preserve_case=False):\n    document = 'DriverItem'\n    search = 'DriverItem/DriverName'\n    content_type = 'string'\n    content = driver_name\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for DriverItem and DriverName"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a IndicatorItem node for an EventLogItem with the given EID", "response": "def make_eventlogitem_eid(eid, condition='is', negate=False):\n    \"\"\"\n    Create a node for EventLogItem/EID\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'EventLogItem'\n    search = 'EventLogItem/EID'\n    content_type = 'int'\n    content = eid\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_eventlogitem_log(log, condition='is', negate=False, preserve_case=False):\n    document = 'EventLogItem'\n    search = 'EventLogItem/log'\n    content_type = 'string'\n    content = log\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for EventLogItem and log"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_eventlogitem_message(message, condition='contains', negate=False, preserve_case=False):\n    document = 'EventLogItem'\n    search = 'EventLogItem/message'\n    content_type = 'string'\n    content = message\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for EventLogItem and a message node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a IndicatorItem node for FileItem / FileAttributes", "response": "def make_fileitem_fileattributes(attributes, condition='contains', negate=False, preserve_case=False):\n    \"\"\"\n    Create a node for FileItem/FileAttributes\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'FileItem'\n    search = 'FileItem/FileAttributes'\n    content_type = 'string'\n    content = attributes\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a IndicatorItem node for FileItem and FileExtension node", "response": "def make_fileitem_fileextension(extension, condition='is', negate=False, preserve_case=False):\n    \"\"\"\n    Create a node for FileItem/FileExtension\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'FileItem'\n    search = 'FileItem/FileExtension'\n    content_type = 'string'\n    content = extension\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a IndicatorItem node for FileItem / FileName", "response": "def make_fileitem_filename(filename, condition='is', negate=False, preserve_case=False):\n    \"\"\"\n    Create a node for FileItem/FileName\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'FileItem'\n    search = 'FileItem/FileName'\n    content_type = 'string'\n    content = filename\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_fileitem_filepath(filepath, condition='contains', negate=False, preserve_case=False):\n    document = 'FileItem'\n    search = 'FileItem/FilePath'\n    content_type = 'string'\n    content = filepath\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for FileItem / FilePath\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_fileitem_fullpath(fullpath, condition='contains', negate=False, preserve_case=False):\n    document = 'FileItem'\n    search = 'FileItem/FullPath'\n    content_type = 'string'\n    content = fullpath\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for FileItem / FullPath"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_fileitem_md5sum(md5, condition='is', negate=False):\n    document = 'FileItem'\n    search = 'FileItem/Md5sum'\n    content_type = 'md5'\n    content = md5\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate)\n    return ii_node", "response": "Create a IndicatorItem node for FileItem / Md5sum"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_fileitem_peinfo_detectedanomalies_string(anomaly, condition='is', negate=False, preserve_case=False):\n    document = 'FileItem'\n    search = 'FileItem/PEInfo/DetectedAnomalies/string'\n    content_type = 'string'\n    content = anomaly\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for FileItem / PEInfo / DetectedAnomalies / string\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_fileitem_peinfo_detectedentrypointsignature_name(entrypoint_name, condition='is', negate=False,\n                                                          preserve_case=False):\n    \"\"\"\n    Create a node for FileItem/PEInfo/DetectedEntryPointSignature/Name\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'FileItem'\n    search = 'FileItem/PEInfo/DetectedEntryPointSignature/Name'\n    content_type = 'string'\n    content = entrypoint_name\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for FileItem / PEInfo / DetectedEntryPointSignature / Name\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a IndicatorItem node for FileItem / PEInfo / DigitalSignature / SignatureExists node", "response": "def make_fileitem_peinfo_digitalsignature_signatureexists(sig_exists, condition='is', negate=False):\n    \"\"\"\n    Create a node for FileItem/PEInfo/DigitalSignature/SignatureExists\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'FileItem'\n    search = 'FileItem/PEInfo/DigitalSignature/SignatureExists'\n    content_type = 'bool'\n    content = sig_exists\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_fileitem_peinfo_digitalsignature_signatureverified(sig_verified, condition='is', negate=False):\n    document = 'FileItem'\n    search = 'FileItem/PEInfo/DigitalSignature/SignatureVerified'\n    content_type = 'bool'\n    content = sig_verified\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate)\n    return ii_node", "response": "Create a IndicatorItem node for FileItem / PEInfo / DigitalSignature / SignatureVerified\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_fileitem_peinfo_exports_dllname(dll_name, condition='is', negate=False, preserve_case=False):\n    document = 'FileItem'\n    search = 'FileItem/PEInfo/Exports/DllName'\n    content_type = 'string'\n    content = dll_name\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Creates a IndicatorItem node for FileItem / PEInfo / Exports / DllName"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_fileitem_peinfo_exports_numberoffunctions(function_count, condition='is', negate=False):\n    document = 'FileItem'\n    search = 'FileItem/PEInfo/Exports/NumberOfFunctions'\n    content_type = 'int'\n    content = function_count\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate)\n    return ii_node", "response": "Create a IndicatorItem node for FileItem / PEInfo / Exports / NumberOfFunctions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_fileitem_peinfo_importedmodules_module_importedfunctions_string(imported_function, condition='is',\n                                                                         negate=False, preserve_case=False):\n    \"\"\"\n    Create a node for FileItem/PEInfo/ImportedModules/Module/ImportedFunctions/string\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'FileItem'\n    search = 'FileItem/PEInfo/ImportedModules/Module/ImportedFunctions/string'\n    content_type = 'string'\n    content = imported_function\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Creates a IndicatorItem node for FileItem / PEInfo / ImportedModules / Module / ImportedFunctions / string\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a IndicatorItem node for FileItem / PEInfo / ImportedModules / Module / Name", "response": "def make_fileitem_peinfo_importedmodules_module_name(imported_module, condition='is', negate=False,\n                                                     preserve_case=False):\n    \"\"\"\n    Create a node for FileItem/PEInfo/ImportedModules/Module/Name\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'FileItem'\n    search = 'FileItem/PEInfo/ImportedModules/Module/Name'\n    content_type = 'string'\n    content = imported_module\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a IndicatorItem node for FileItem / PEInfo / PETimeStamp", "response": "def make_fileitem_peinfo_petimestamp(compile_time, condition='is', negate=False):\n    \"\"\"\n    Create a node for FileItem/PEInfo/PETimeStamp\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'FileItem'\n    search = 'FileItem/PEInfo/PETimeStamp'\n    content_type = 'date'\n    content = compile_time\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a IndicatorItem node for FileItem / PEInfo / ResourceInfoItem / Name", "response": "def make_fileitem_peinfo_resourceinfolist_resourceinfoitem_name(resource_name, condition='is', negate=False,\n                                                                preserve_case=False):\n    \"\"\"\n    Create a node for FileItem/PEInfo/ResourceInfoList/ResourceInfoItem/Name\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'FileItem'\n    search = 'FileItem/PEInfo/ResourceInfoList/ResourceInfoItem/Name'\n    content_type = 'string'\n    content = resource_name\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_fileitem_peinfo_type(petype, condition='is', negate=False, preserve_case=False):\n    document = 'FileItem'\n    search = 'FileItem/PEInfo/Type'\n    content_type = 'string'\n    content = petype\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for FileItem / PEInfo / Type\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a IndicatorItem node for FileItem / SizeInBytes", "response": "def make_fileitem_sizeinbytes(filesize, condition='is', negate=False):\n    \"\"\"\n    Create a node for FileItem/SizeInBytes\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'FileItem'\n    search = 'FileItem/SizeInBytes'\n    content_type = 'int'\n    content = filesize\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_fileitem_streamlist_stream_name(stream_name, condition='is', negate=False, preserve_case=False):\n    document = 'FileItem'\n    search = 'FileItem/StreamList/Stream/Name'\n    content_type = 'string'\n    content = stream_name\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for FileItem / StreamList / Stream / Name\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_fileitem_stringlist_string(file_string, condition='contains', negate=False, preserve_case=False):\n    document = 'FileItem'\n    search = 'FileItem/StringList/string'\n    content_type = 'string'\n    content = file_string\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for FileItem / StringList / string\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a IndicatorItem node for FileItem / Username", "response": "def make_fileitem_username(file_owner, condition='is', negate=False, preserve_case=False):\n    \"\"\"\n    Create a node for FileItem/Username\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'FileItem'\n    search = 'FileItem/Username'\n    content_type = 'string'\n    content = file_owner\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a IndicatorItem node for a HookItem / HookedFunction node", "response": "def make_hookitem_hookedfunction(hooked_function, condition='is', negate=False, preserve_case=False):\n    \"\"\"\n    Create a node for HookItem/HookedFunction\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'HookItem'\n    search = 'HookItem/HookedFunction'\n    content_type = 'string'\n    content = hooked_function\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a IndicatorItem node for HookItem / HookingModule", "response": "def make_hookitem_hookingmodule(hooking_module, condition='contains', negate=False, preserve_case=False):\n    \"\"\"\n    Create a node for HookItem/HookingModule\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'HookItem'\n    search = 'HookItem/HookingModule'\n    content_type = 'string'\n    content = hooking_module\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_portitem_remoteport(remote_port, condition='is', negate=False):\n    document = 'PortItem'\n    search = 'PortItem/remotePort'\n    content_type = 'int'\n    content = remote_port\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate)\n    return ii_node", "response": "Create a IndicatorItem node for PortItem and RemotePort"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_prefetchitem_accessedfilelist_accessedfile(accessed_file, condition='contains', negate=False,\n                                                    preserve_case=False):\n    \"\"\"\n    Create a node for PrefetchItem/AccessedFileList/AccessedFile\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'PrefetchItem'\n    search = 'PrefetchItem/AccessedFileList/AccessedFile'\n    content_type = 'string'\n    content = accessed_file\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for PrefetchItem / AccessedFileList"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a IndicatorItem node for PrefetchItem and ApplicationFileName", "response": "def make_prefetchitem_applicationfilename(application_filename, condition='is', negate=False, preserve_case=False):\n    \"\"\"\n    Create a node for PrefetchItem/ApplicationFileName\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'PrefetchItem'\n    search = 'PrefetchItem/ApplicationFileName'\n    content_type = 'string'\n    content = application_filename\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_prefetchitem_applicationfullpath(application_fullpath, condition='contains', negate=False,\n                                          preserve_case=False):\n    \"\"\"\n    Create a node for PrefetchItem/ApplicationFullPath\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'PrefetchItem'\n    search = 'PrefetchItem/ApplicationFullPath'\n    content_type = 'string'\n    content = application_fullpath\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for PrefetchItem and ApplicationFullPath"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a IndicatorItem node for a ProcessItem / HandleList / Handle / Name node", "response": "def make_processitem_handlelist_handle_name(handle_name, condition='contains', negate=False, preserve_case=False):\n    \"\"\"\n    Create a node for ProcessItem/HandleList/Handle/Name\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'ProcessItem'\n    search = 'ProcessItem/HandleList/Handle/Name'\n    content_type = 'string'\n    content = handle_name\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_processitem_portlist_portitem_remoteip(remote_ip, condition='is', negate=False):\n    document = 'ProcessItem'\n    search = 'ProcessItem/PortList/PortItem/remoteIP'\n    content_type = 'IP'\n    content = remote_ip\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate)\n    return ii_node", "response": "Create a IndicatorItem node for a ProcessItem / PortList / PortItem / remoteIP"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_processitem_sectionlist_memorysection_name(section_name, condition='contains', negate=False,\n                                                    preserve_case=False):\n    \"\"\"\n    Create a node for ProcessItem/SectionList/MemorySection/Name\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'ProcessItem'\n    search = 'ProcessItem/SectionList/MemorySection/Name'\n    content_type = 'string'\n    content = section_name\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for a ProcessItem section list memory section name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a IndicatorItem node for Exported Functions in Memory Section List", "response": "def make_processitem_sectionlist_memorysection_peinfo_exports_exportedfunctions_string(export_function, condition='is',\n                                                                                       negate=False,\n                                                                                       preserve_case=False):\n    \"\"\"\n    Create a node for ProcessItem/SectionList/MemorySection/PEInfo/Exports/ExportedFunctions/string\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'ProcessItem'\n    search = 'ProcessItem/SectionList/MemorySection/PEInfo/Exports/ExportedFunctions/string'\n    content_type = 'string'\n    content = export_function\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_processitem_stringlist_string(string, condition='contains', negate=False, preserve_case=False):\n    document = 'ProcessItem'\n    search = 'ProcessItem/StringList/string'\n    content_type = 'string'\n    content = string\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for a ProcessItem / StringList"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_processitem_username(username, condition='contains', negate=False, preserve_case=False):\n    document = 'ProcessItem'\n    search = 'ProcessItem/Username'\n    content_type = 'string'\n    content = username\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for a ProcessItem with the given username"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_processitem_arguments(arguments, condition='contains', negate=False, preserve_case=False):\n    document = 'ProcessItem'\n    search = 'ProcessItem/arguments'\n    content_type = 'string'\n    content = arguments\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a node for ProcessItem / arguments"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_processitem_path(path, condition='contains', negate=False, preserve_case=False):\n    document = 'ProcessItem'\n    search = 'ProcessItem/path'\n    content_type = 'string'\n    content = path\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for a ProcessItem with a given path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_registryitem_keypath(keypath, condition='contains', negate=False, preserve_case=False):\n    document = 'RegistryItem'\n    search = 'RegistryItem/KeyPath'\n    content_type = 'string'\n    content = keypath\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for RegistryItem and KeyPath"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a node for RegistryItem and Text node for RegistryItem", "response": "def make_registryitem_text(text, condition='contains', negate=False, preserve_case=False):\n    \"\"\"\n    Create a node for RegistryItem/Text\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'RegistryItem'\n    search = 'RegistryItem/Text'\n    content_type = 'string'\n    content = text\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a IndicatorItem node for RegistryItem ValueName", "response": "def make_registryitem_valuename(valuename, condition='is', negate=False, preserve_case=False):\n    \"\"\"\n    Create a node for RegistryItem/ValueName\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'RegistryItem'\n    search = 'RegistryItem/ValueName'\n    content_type = 'string'\n    content = valuename\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_serviceitem_description(description, condition='contains', negate=False, preserve_case=False):\n    document = 'ServiceItem'\n    search = 'ServiceItem/description'\n    content_type = 'string'\n    content = description\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for ServiceItem and description"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a IndicatorItem node for ServiceItem and descriptiveName", "response": "def make_serviceitem_descriptivename(descriptive_name, condition='is', negate=False, preserve_case=False):\n    \"\"\"\n    Create a node for ServiceItem/descriptiveName\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'ServiceItem'\n    search = 'ServiceItem/descriptiveName'\n    content_type = 'string'\n    content = descriptive_name\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a IndicatorItem node for ServiceItem and name", "response": "def make_serviceitem_name(name, condition='is', negate=False, preserve_case=False):\n    \"\"\"\n    Create a node for ServiceItem/name\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'ServiceItem'\n    search = 'ServiceItem/name'\n    content_type = 'string'\n    content = name\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_serviceitem_pathmd5sum(path_md5, condition='is', negate=False):\n    document = 'ServiceItem'\n    search = 'ServiceItem/pathmd5sum'\n    content_type = 'md5'\n    content = path_md5\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate)\n    return ii_node", "response": "Create a IndicatorItem node for ServiceItem / pathmd5sum"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a IndicatorItem node for ServiceItem and serviceDLL", "response": "def make_serviceitem_servicedll(servicedll, condition='contains', negate=False, preserve_case=False):\n    \"\"\"\n    Create a node for ServiceItem/serviceDLL\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'ServiceItem'\n    search = 'ServiceItem/serviceDLL'\n    content_type = 'string'\n    content = servicedll\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_serviceitem_servicedllsignatureexists(dll_sig_exists, condition='is', negate=False):\n    document = 'ServiceItem'\n    search = 'ServiceItem/serviceDLLSignatureExists'\n    content_type = 'bool'\n    content = dll_sig_exists\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate)\n    return ii_node", "response": "Create a IndicatorItem node for ServiceItem / serviceDLLSignatureExists"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_serviceitem_servicedllsignatureverified(dll_sig_verified, condition='is', negate=False):\n    document = 'ServiceItem'\n    search = 'ServiceItem/serviceDLLSignatureVerified'\n    content_type = 'bool'\n    content = dll_sig_verified\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate)\n    return ii_node", "response": "Create a IndicatorItem node for ServiceItem / serviceDLLSignatureVerified"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_serviceitem_servicedllmd5sum(servicedll_md5, condition='is', negate=False):\n    document = 'ServiceItem'\n    search = 'ServiceItem/serviceDLLmd5sum'\n    content_type = 'md5'\n    content = servicedll_md5\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate)\n    return ii_node", "response": "Create a IndicatorItem node for ServiceItem / serviceDLLmd5sum\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a IndicatorItem node for a SystemInfoItem with the given hostname", "response": "def make_systeminfoitem_hostname(hostname, condition='contains', negate=False, preserve_case=False):\n    \"\"\"\n    Create a node for SystemInfoItem/hostname\n    \n    :return: A IndicatorItem represented as an Element node\n    \"\"\"\n    document = 'SystemInfoItem'\n    search = 'SystemInfoItem/hostname'\n    content_type = 'string'\n    content = hostname\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_systemrestoreitem_originalfilename(original_filename, condition='contains', negate=False, preserve_case=False):\n    document = 'SystemRestoreItem'\n    search = 'SystemRestoreItem/OriginalFileName'\n    content_type = 'string'\n    content = original_filename\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for a SystemRestoreItem with the original filename."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_fileitem_peinfo_versioninfoitem(key, value, condition='is', negate=False, preserve_case=False):\n    document = 'FileItem'\n    search = 'FileItem/PEInfo/VersionInfoList/VersionInfoItem/' + key  # XXX: No validation of key done.\n    content_type = 'string'\n    content = value\n    ii_node = ioc_api.make_indicatoritem_node(condition, document, search, content_type, content,\n                                              negate=negate, preserve_case=preserve_case)\n    return ii_node", "response": "Create a IndicatorItem node for FileItem / PEInfo / VersionInfoList / VersionInfoItem"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfixes the ordering of children under the criteria node to ensure that IndicatorItem or Indicator order is preserved as per XML Schema.", "response": "def fix_schema_node_ordering(parent):\n        \"\"\"\n        Fix the ordering of children under the criteria node to ensure that IndicatorItem/Indicator order\n         is preserved, as per XML Schema.\n        :return:\n        \"\"\"\n        children = parent.getchildren()\n        i_nodes = [node for node in children if node.tag == 'IndicatorItem']\n        ii_nodes = [node for node in children if node.tag == 'Indicator']\n        if not ii_nodes:\n            return\n        # Remove all the children\n        for node in children:\n            parent.remove(node)\n        # Add the Indicator nodes back\n        for node in i_nodes:\n            parent.append(node)\n        # Now add the IndicatorItem nodes back\n        for node in ii_nodes:\n            parent.append(node)\n        # Now recurse\n        for node in ii_nodes:\n            fix_schema_node_ordering(node)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_indicator_node(operator, nid=None):\n    if operator.upper() not in VALID_INDICATOR_OPERATORS:\n        raise ValueError('Indicator operator must be in [{}].'.format(VALID_INDICATOR_OPERATORS))\n    i_node = et.Element('Indicator')\n    if nid:\n        i_node.attrib['id'] = nid\n    else:\n        i_node.attrib['id'] = ioc_et.get_guid()\n    i_node.attrib['operator'] = operator.upper()\n    return i_node", "response": "This function makes a Indicator node element."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_indicatoritem_node(condition,\n                            document,\n                            search,\n                            content_type,\n                            content,\n                            preserve_case=False,\n                            negate=False,\n                            context_type='mir',\n                            nid=None):\n    \"\"\"\n    This makes a IndicatorItem element.  This contains the actual threat intelligence in the IOC.\n\n    :param condition: This is the condition of the item ('is', 'contains', 'matches', etc). The following contants in ioc_api may be used:\n==================== =====================================================\nConstant             Meaning\n==================== =====================================================\nioc_api.IS           Exact String match.\nioc_api.CONTAINS     Substring match.\nioc_api.MATCHES      Regex match.\nioc_api.STARTS_WITH  String match at the beginning of a string.\nioc_api.ENDS_WITH    String match at the end of a string.\nioc_api.GREATER_THAN Integer match indicating a greater than (>) operation.\nioc_api.LESS_THAN    Integer match indicator a less than (<) operation.\n==================== =====================================================\n\n    :param document: Denotes the type of document to look for the encoded artifact in.\n    :param search: Specifies what attribute of the document type the encoded value is.\n    :param content_type: This is the display type of the item. This is normally derived from the iocterm for the search value.\n    :param content: The threat intelligence that is being encoded.\n    :param preserve_case: Specifiy that the content should be treated in a case sensitive manner.\n    :param negate: Specifify that the condition is negated. An example of this is:\n       @condition = 'is' & @negate = 'true' would be equal to the\n       @condition = 'isnot' in OpenIOC 1.0.\n    :param context_type: Gives context to the document/search information.\n    :param nid: This is used to provide a GUID for the IndicatorItem. The ID should NOT be specified under normal\n     circumstances.\n    :return: an elementTree Element item\n    \"\"\"\n    # validate condition\n    if condition not in VALID_INDICATORITEM_CONDITIONS:\n        raise ValueError('Invalid IndicatorItem condition [{}]'.format(condition))\n    ii_node = et.Element('IndicatorItem')\n    if nid:\n        ii_node.attrib['id'] = nid\n    else:\n        ii_node.attrib['id'] = ioc_et.get_guid()\n    ii_node.attrib['condition'] = condition\n    if preserve_case:\n        ii_node.attrib['preserve-case'] = 'true'\n    else:\n        ii_node.attrib['preserve-case'] = 'false'\n    if negate:\n        ii_node.attrib['negate'] = 'true'\n    else:\n        ii_node.attrib['negate'] = 'false'\n    context_node = ioc_et.make_context_node(document, search, context_type)\n    content_node = ioc_et.make_content_node(content_type, content)\n    ii_node.append(context_node)\n    ii_node.append(content_node)\n    return ii_node", "response": "This function creates an IndicatorItem element."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_top_level_indicator_node(root_node):\n    if root_node.tag != 'OpenIOC':\n        raise IOCParseError('Root tag is not \"OpenIOC\" [{}].'.format(root_node.tag))\n    elems = root_node.xpath('criteria/Indicator')\n    if len(elems) == 0:\n        log.warning('No top level Indicator node found.')\n        return None\n    elif len(elems) > 1:\n        log.warning('Multiple top level Indicator nodes found.  This is not a valid MIR IOC.')\n        return None\n    else:\n        top_level_indicator_node = elems[0]\n    if top_level_indicator_node.get('operator').lower() != 'or':\n        log.warning('Top level Indicator/@operator attribute is not \"OR\".  This is not a valid MIR IOC.')\n    return top_level_indicator_node", "response": "This returns the first top level Indicator node under the criteria node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nserializes an IOC as defined by a set of etree Elements to a. IOC file.", "response": "def write_ioc(root, output_dir=None, force=False):\n    \"\"\"\n    Serialize an IOC, as defined by a set of etree Elements, to a .IOC file.\n\n    :param root: etree Element to write out.  Should have the tag 'OpenIOC'\n    :param output_dir: Directory to write the ioc out to.  default is current working directory.\n    :param force: If set, skip the root node tag check.\n    :return: True, unless an error occurs while writing the IOC.\n    \"\"\"\n    root_tag = 'OpenIOC'\n    if not force and root.tag != root_tag:\n        raise ValueError('Root tag is not \"{}\".'.format(root_tag))\n    default_encoding = 'utf-8'\n    tree = root.getroottree()\n    # noinspection PyBroadException\n    try:\n        encoding = tree.docinfo.encoding\n    except:\n        log.debug('Failed to get encoding from docinfo')\n        encoding = default_encoding\n    ioc_id = root.attrib['id']\n    fn = ioc_id + '.ioc'\n    if output_dir:\n        fn = os.path.join(output_dir, fn)\n    else:\n        fn = os.path.join(os.getcwd(), fn)\n    try:\n        with open(fn, 'wb') as fout:\n            fout.write(et.tostring(tree, encoding=encoding, xml_declaration=True, pretty_print=True))\n    except (IOError, OSError):\n        log.exception('Failed to write out IOC')\n        return False\n    except:\n        raise\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_ioc_string(root, force=False):\n    root_tag = 'OpenIOC'\n    if not force and root.tag != root_tag:\n        raise ValueError('Root tag is not \"{}\".'.format(root_tag))\n    default_encoding = 'utf-8'\n    tree = root.getroottree()\n    # noinspection PyBroadException\n    try:\n        encoding = tree.docinfo.encoding\n    except:\n        log.debug('Failed to get encoding from docinfo')\n        encoding = default_encoding\n    return et.tostring(tree, encoding=encoding, xml_declaration=True, pretty_print=True)", "response": "Serialize an IOC to a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening an IOC file or XML string and returns the root element top level Indicator element and Parameters element.", "response": "def open_ioc(fn):\n        \"\"\"\n        Opens an IOC file, or XML string.  Returns the root element, top level\n        indicator element, and parameters element.  If the IOC or string fails\n        to parse, an IOCParseError is raised.\n\n        This is a helper function used by __init__.\n\n        :param fn: This is a path to a file to open, or a string containing XML representing an IOC.\n        :return: a tuple containing three elementTree Element objects\n         The first element, the root, contains the entire IOC itself.\n         The second element, the top level OR indicator, allows the user to add\n          additional IndicatorItem or Indicator nodes to the IOC easily.\n         The third element, the parameters node, allows the user to quickly\n          parse the parameters.\n        \"\"\"\n        parsed_xml = xmlutils.read_xml_no_ns(fn)\n        if not parsed_xml:\n            raise IOCParseError('Error occured parsing XML')\n        root = parsed_xml.getroot()\n        metadata_node = root.find('metadata')\n        top_level_indicator = get_top_level_indicator_node(root)\n        parameters_node = root.find('parameters')\n        if parameters_node is None:\n            # parameters node is not required by schema; but we add it if it is not present\n            parameters_node = ioc_et.make_parameters_node()\n            root.append(parameters_node)\n        return root, metadata_node, top_level_indicator, parameters_node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_ioc(name=None,\n                 description='Automatically generated IOC',\n                 author='IOC_api',\n                 links=None,\n                 keywords=None,\n                 iocid=None):\n        \"\"\"\n        This generates all parts of an IOC, but without any definition.\n\n        This is a helper function used by __init__.\n\n        :param name: string, Name of the ioc\n        :param description: string, description of the ioc\n        :param author: string, author name/email address\n        :param links: ist of tuples.  Each tuple should be in the form (rel, href, value).\n        :param keywords: string.  This is normally a space delimited string of values that may be used as keywords\n        :param iocid: GUID for the IOC.  This should not be specified under normal circumstances.\n        :return: a tuple containing three elementTree Element objects\n         The first element, the root, contains the entire IOC itself.\n         The second element, the top level OR indicator, allows the user to add\n          additional IndicatorItem or Indicator nodes to the IOC easily.\n         The third element, the parameters node, allows the user to quickly\n          parse the parameters.\n        \"\"\"\n        root = ioc_et.make_ioc_root(iocid)\n        root.append(ioc_et.make_metadata_node(name, description, author, links, keywords))\n        metadata_node = root.find('metadata')\n        top_level_indicator = make_indicator_node('OR')\n        parameters_node = (ioc_et.make_parameters_node())\n        root.append(ioc_et.make_criteria_node(top_level_indicator))\n        root.append(parameters_node)\n        ioc_et.set_root_lastmodified(root)\n        return root, metadata_node, top_level_indicator, parameters_node", "response": "This function generates all parts of an IOC."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_lastmodified_date(self, date=None):\n        if date:\n            match = re.match(DATE_REGEX, date)\n            if not match:\n                raise IOCParseError('last-modified date is not valid.  Must be in the form YYYY-MM-DDTHH:MM:SS')\n        ioc_et.set_root_lastmodified(self.root, date)\n        return True", "response": "Set the last modified date of a IOC to the current date."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the published date of a IOC to the current date.", "response": "def set_published_date(self, date=None):\n        \"\"\"\n        Set the published date of a IOC to the current date.\n        User may specify the date they want to set as well.\n\n        :param date: Date value to set the published date to.  This should be in the xsdDate form.\n         This defaults to the current date if it is not provided.\n         xsdDate Form: YYYY-MM-DDTHH:MM:SS\n        :return: True\n        :raises: IOCParseError if date format is not valid.\n        \"\"\"\n        if date:\n            match = re.match(DATE_REGEX, date)\n            if not match:\n                raise IOCParseError('Published date is not valid.  Must be in the form YYYY-MM-DDTHH:MM:SS')\n        ioc_et.set_root_published_date(self.root, date)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the created date of a IOC to the current date.", "response": "def set_created_date(self, date=None):\n        \"\"\"\n        Set the created date of a IOC to the current date.\n        User may specify the date they want to set as well.\n\n        :param date: Date value to set the created date to.  This should be in the xsdDate form.\n         This defaults to the current date if it is not provided.\n         xsdDate form: YYYY-MM-DDTHH:MM:SS\n        :return: True\n        :raises: IOCParseError if date format is not valid.\n        \"\"\"\n        if date:\n            match = re.match(DATE_REGEX, date)\n            if not match:\n                raise IOCParseError('Created date is not valid.  Must be in the form YYYY-MM-DDTHH:MM:SS')\n        # XXX can this use self.metadata?\n        ioc_et.set_root_created_date(self.root, date)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a parameter to the IOC.", "response": "def add_parameter(self, indicator_id, content, name='comment', ptype='string'):\n        \"\"\"\n        Add a a parameter to the IOC.\n\n        :param indicator_id: The unique Indicator/IndicatorItem id the parameter is associated with.\n        :param content: The value of the parameter.\n        :param name: The name of the parameter.\n        :param ptype: The type of the parameter content.\n        :return: True\n        :raises: IOCParseError if the indicator_id is not associated with a Indicator or IndicatorItem in the IOC.\n        \"\"\"\n        parameters_node = self.parameters\n        criteria_node = self.top_level_indicator.getparent()\n        # first check for duplicate id,name pairs    \n        elems = parameters_node.xpath('.//param[@ref-id=\"{}\" and @name=\"{}\"]'.format(indicator_id, name))\n        if len(elems) > 0:\n            # there is no actual restriction on duplicate parameters\n            log.info('Duplicate (id,name) parameter pair will be inserted [{}][{}].'.format(indicator_id, name))\n        # now check to make sure the id is present in the IOC logic\n        elems = criteria_node.xpath(\n            './/IndicatorItem[@id=\"{}\"]|.//Indicator[@id=\"{}\"]'.format(indicator_id, indicator_id))\n        if len(elems) == 0:\n            raise IOCParseError('ID does not exist in the IOC [{}][{}].'.format(str(indicator_id), str(content)))\n        parameters_node.append(ioc_et.make_param_node(indicator_id, content, name, ptype))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_link(self, rel, value, href=None):\n        links_node = self.metadata.find('links')\n        if links_node is None:\n            links_node = ioc_et.make_links_node()\n            self.metadata.append(links_node)\n        link_node = ioc_et.make_link_node(rel, value, href)\n        links_node.append(link_node)\n        return True", "response": "Add a Link metadata element to the IOC."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_name(self, name):\n        short_desc_node = self.metadata.find('short_description')\n        if short_desc_node is None:\n            log.debug('Could not find short description node for [{}].'.format(str(self.iocid)))\n            log.debug('Creating & inserting the short description node')\n            short_desc_node = ioc_et.make_short_description_node(name)\n            self.metadata.insert(0, short_desc_node)\n        else:\n            short_desc_node.text = name\n        return True", "response": "Update the name of an IOC."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the description node of an IOC.", "response": "def update_description(self, description):\n        \"\"\"\n        Update the description) of an IOC\n\n        This creates the description node if it is not present.\n        :param description: Value to set the description too\n        :return: True\n        \"\"\"\n        desc_node = self.metadata.find('description')\n        if desc_node is None:\n            log.debug('Could not find short description node for [{}].'.format(str(self.iocid)))\n            log.debug('Creating & inserting the short description node')\n            desc_node = ioc_et.make_description_node(description)\n            insert_index = 0\n            for child in self.metadata.getchildren():\n                if child.tag == 'short_description':\n                    index = self.metadata.index(child)\n                    insert_index = index + 1\n                    break\n            self.metadata.insert(insert_index, desc_node)\n        else:\n            desc_node.text = description\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_link_rel_based(self, old_rel, new_rel=None, new_text=None, single_link=False):\n        links = self.metadata.xpath('./links/link[@rel=\"{}\"]'.format(old_rel))\n        if len(links) < 1:\n            log.warning('No links with link/[@rel=\"{}\"]'.format(str(old_rel)))\n            return False\n        if new_rel and not new_text:\n            # update link/@rel value\n            for link in links:\n                link.attrib['rel'] = new_rel\n                if single_link:\n                    break\n        elif not new_rel and new_text:\n            # update link/@text() value\n            for link in links:\n                link.text = new_text\n                if single_link:\n                    break\n        elif new_rel and new_text:\n            log.warning('Cannot update rel and text at the same time')\n            return False\n        else:\n            log.warning('Must specify either new_rel or new_text arguments')\n            return False\n        return True", "response": "Update link nodes based on the existing link / @rel value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrewrite the text() value of a link based on the link/@rel and link/text() value. This is similar to update_link_rel_based but users link/@rel AND link/text() values to determine which links have their link/@text() values updated. :param old_rel: The link/@rel value used to select link nodes to update. :param old_text: The link/text() value used to select link nodes to update. :param new_text: The new link/text() value to set on link nodes. :param single_link: Determine if only the first, or multiple, linkes are modified. :return: True, unless there are no links with link/[@rel='old_rel' and text()='old_text']", "response": "def update_link_rewrite(self, old_rel, old_text, new_text, single_link=False):\n        \"\"\"\n        Rewrite the text() value of a link based on the link/@rel and link/text() value.\n\n        This is similar to update_link_rel_based but users link/@rel AND link/text() values\n        to determine which links have their link/@text() values updated.\n\n        :param old_rel: The link/@rel value used to select link nodes to update.\n        :param old_text: The link/text() value used to select link nodes to update.\n        :param new_text: The new link/text() value to set on link nodes.\n        :param single_link: Determine if only the first, or multiple, linkes are modified.\n        :return: True, unless there are no links with link/[@rel='old_rel' and text()='old_text']\n        \"\"\"\n        links = self.metadata.xpath('./links/link[@rel=\"{}\" and text()=\"{}\"]'.format(old_rel, old_text))\n        if len(links) < 1:\n            log.warning('No links with link/[@rel=\"{}\"and text()=\"{}\"]'.format(str(old_rel), str(old_text)))\n            return False\n        for link in links:\n            link.text = new_text\n            if single_link:\n                break\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_parameter(self, parameter_id, content=None, name=None, param_type=None):\n        if not (content or name or param_type):\n            log.warning('Must specify at least the value/text(), param/@name or the value/@type values to update.')\n            return False\n        parameters_node = self.parameters\n        elems = parameters_node.xpath('.//param[@id=\"{}\"]'.format(parameter_id))\n        if len(elems) != 1:\n            msg = 'Did not find a single parameter with the supplied ID[{}]. Found [{}] parameters'.format(parameter_id,\n                                                                                                           len(elems))\n            raise IOCParseError(msg)\n\n        param_node = elems[0]\n        value_node = param_node.find('value')\n\n        if name:\n            param_node.attrib['name'] = name\n\n        if value_node is None:\n            msg = 'No value node is associated with param [{}].  Not updating value node with content or tuple.' \\\n                .format(parameter_id)\n            log.warning(msg)\n        else:\n            if content:\n                value_node.text = content\n            if param_type:\n                value_node.attrib['type'] = param_type\n        return True", "response": "Updates the value of a single parameter in an Indicator or IndicatorItem node."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves a link node based on the function arguments.", "response": "def remove_link(self, rel, value=None, href=None):\n        \"\"\"\n        Removes link nodes based on the function arguments.\n\n        This can remove link nodes based on the following combinations of arguments:\n            link/@rel\n            link/@rel & link/text()\n            link/@rel & link/@href\n            link/@rel & link/text() & link/@href\n\n        :param rel: link/@rel value to remove.  Required.\n        :param value: link/text() value to remove. This is used in conjunction with link/@rel.\n        :param href: link/@href value to remove. This is used in conjunction with link/@rel.\n        :return: Return the number of link nodes removed, or False if no nodes are removed.\n        \"\"\"\n        links_node = self.metadata.find('links')\n        if links_node is None:\n            log.warning('No links node present')\n            return False\n        counter = 0\n        links = links_node.xpath('.//link[@rel=\"{}\"]'.format(rel))\n        for link in links:\n            if value and href:\n                if link.text == value and link.attrib['href'] == href:\n                    links_node.remove(link)\n                    counter += 1\n            elif value and not href:\n                if link.text == value:\n                    links_node.remove(link)\n                    counter += 1\n            elif not value and href:\n                if link.attrib['href'] == href:\n                    links_node.remove(link)\n                    counter += 1\n            else:\n                links_node.remove(link)\n                counter += 1\n        return counter"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves a Indicator or IndicatorItem node from the IOC.", "response": "def remove_indicator(self, nid, prune=False):\n        \"\"\"\n        Removes a Indicator or IndicatorItem node from the IOC.  By default,\n        if nodes are removed, any children nodes are inherited by the removed\n        node. It has the  ability to delete all children Indicator and\n        IndicatorItem nodes underneath an Indicator node if the 'prune'\n        argument is set.\n\n        This will not remove the top level Indicator node from an IOC.\n        If the id value has been reused within the IOC, this will remove the\n        first node which contains the id value.\n\n        This also removes any parameters associated with any nodes that are\n        removed.\n\n        :param nid: The Indicator/@id or IndicatorItem/@id value indicating a specific node to remove.\n        :param prune: Remove all children of the deleted node. If a Indicator node is removed and prune is set to\n         False, the children nodes will be promoted to be children of the removed nodes' parent.\n        :return: True if nodes are removed, False otherwise.\n        \"\"\"\n        try:\n            node_to_remove = self.top_level_indicator.xpath(\n                '//IndicatorItem[@id=\"{}\"]|//Indicator[@id=\"{}\"]'.format(str(nid), str(nid)))[0]\n        except IndexError:\n            log.exception('Node [{}] not present'.format(nid))\n            return False\n        if node_to_remove.tag == 'IndicatorItem':\n            node_to_remove.getparent().remove(node_to_remove)\n            self.remove_parameter(ref_id=nid)\n            return True\n        elif node_to_remove.tag == 'Indicator':\n            if node_to_remove == self.top_level_indicator:\n                raise IOCParseError('Cannot remove the top level indicator')\n            if prune:\n                pruned_ids = node_to_remove.xpath('.//@id')\n                node_to_remove.getparent().remove(node_to_remove)\n                for pruned_id in pruned_ids:\n                    self.remove_parameter(ref_id=pruned_id)\n            else:\n                for child_node in node_to_remove.getchildren():\n                    node_to_remove.getparent().append(child_node)\n                node_to_remove.getparent().remove(node_to_remove)\n                self.remove_parameter(ref_id=nid)\n            return True\n        else:\n            raise IOCParseError(\n                'Bad tag found.  Expected \"IndicatorItem\" or \"Indicator\", got [[}]'.format(node_to_remove.tag))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving parameters based on function arguments. This can remove parameters based on the following param values: param/@id param/@name param/@ref_id Each input is mutually exclusive. Calling this function with multiple values set will cause an IOCParseError exception. Calling this function without setting one value will raise an exception. :param param_id: The id of the parameter to remove. :param name: The name of the parameter to remove. :param ref_id: The IndicatorItem/Indicator id of the parameter to remove. :return: Number of parameters removed.", "response": "def remove_parameter(self, param_id=None, name=None, ref_id=None, ):\n        \"\"\"\n        Removes parameters based on function arguments.\n\n        This can remove parameters based on the following param values:\n            param/@id\n            param/@name\n            param/@ref_id\n\n        Each input is mutually exclusive.  Calling this function with multiple values set will cause an IOCParseError\n         exception. Calling this function without setting one value will raise an exception.\n\n        :param param_id: The id of the parameter to remove.\n        :param name: The name of the parameter to remove.\n        :param ref_id: The IndicatorItem/Indicator id of the parameter to remove.\n        :return: Number of parameters removed.\n        \"\"\"\n        l = []\n        if param_id:\n            l.append('param_id')\n        if name:\n            l.append('name')\n        if ref_id:\n            l.append('ref_id')\n        if len(l) > 1:\n            raise IOCParseError('Must specify only param_id, name or ref_id.  Specified {}'.format(str(l)))\n        elif len(l) < 1:\n            raise IOCParseError('Must specifiy an param_id, name or ref_id to remove a paramater')\n\n        counter = 0\n        parameters_node = self.parameters\n\n        if param_id:\n            params = parameters_node.xpath('//param[@id=\"{}\"]'.format(param_id))\n            for param in params:\n                parameters_node.remove(param)\n                counter += 1\n        elif name:\n            params = parameters_node.xpath('//param[@name=\"{}\"]'.format(name))\n            for param in params:\n                parameters_node.remove(param)\n                counter += 1\n        elif ref_id:\n            params = parameters_node.xpath('//param[@ref-id=\"{}\"]'.format(ref_id))\n            for param in params:\n                parameters_node.remove(param)\n                counter += 1\n        return counter"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the name from the metadata node.", "response": "def remove_name(self):\n        \"\"\"\n        Removes the name (short_description node) from the metadata node, if present.\n\n        :return: True if the node is removed.  False is the node is node is not present.\n        \"\"\"\n        short_description_node = self.metadata.find('short_description')\n        if short_description_node is not None:\n            self.metadata.remove(short_description_node)\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_description(self):\n        description_node = self.metadata.find('description')\n        if description_node is not None:\n            self.metadata.remove(description_node)\n            return True\n        return False", "response": "Removes the description node from the metadata node. Returns True if the description node is removed. Returns False if the description node is not present."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_ioc_to_file(self, output_dir=None, force=False):\n        return write_ioc(self.root, output_dir, force=force)", "response": "Serialize the IOC to a. ioc file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a string representation of an IOC.", "response": "def display_ioc(self, width=120, sep='  ', params=False):\n        \"\"\"\n        Get a string representation of an IOC.\n\n        :param width: Width to print the description too.\n        :param sep: Separator used for displaying the contents of the criteria nodes.\n        :param params: Boolean, set to True in order to display node parameters.\n        :return:\n        \"\"\"\n        s = 'Name: {}\\n'.format(self.metadata.findtext('short_description', default='No Name'))\n        s += 'ID: {}\\n'.format(self.root.attrib.get('id'))\n        s += 'Created: {}\\n'.format(self.metadata.findtext('authored_date', default='No authored_date'))\n        s += 'Updated: {}\\n\\n'.format(self.root.attrib.get('last-modified', default='No last-modified attrib'))\n        s += 'Author: {}\\n'.format(self.metadata.findtext('authored_by', default='No authored_by'))\n        desc = self.metadata.findtext('description', default='No Description')\n        desc = textwrap.wrap(desc, width=width)\n        desc = '\\n'.join(desc)\n        s += 'Description:\\n{}\\n\\n'.format(desc)\n        links = self.link_text()\n        if links:\n            s += '{}'.format(links)\n        content_text = self.criteria_text(sep=sep, params=params)\n        s += '\\nCriteria:\\n{}'.format(content_text)\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef link_text(self):\n        s = ''\n        links_node = self.metadata.find('links')\n        if links_node is None:\n            return s\n        links = links_node.getchildren()\n        if links is None:\n            return s\n        s += 'IOC Links\\n'\n        for link in links:\n            rel = link.attrib.get('rel', 'No Rel')\n            href = link.attrib.get('href')\n            text = link.text\n            lt = '{rel}{href}: {text}\\n'.format(rel=rel,\n                                                href=' @ {}'.format(href) if href else '',\n                                                text=text)\n            s += lt\n        return s", "response": "Get a text represention of the links node."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a text representation of the criteria node.", "response": "def criteria_text(self, sep='  ', params=False):\n        \"\"\"\n        Get a text representation of the criteria node.\n\n        :param sep: Separator used to indent the contents of the node.\n        :param params: Boolean, set to True in order to display node parameters.\n        :return:\n        \"\"\"\n\n        s = ''\n        criteria_node = self.root.find('criteria')\n        if criteria_node is None:\n            return s\n        node_texts = []\n        for node in criteria_node.getchildren():\n            nt = self.get_node_text(node, depth=0, sep=sep, params=params)\n            node_texts.append(nt)\n        s = '\\n'.join(node_texts)\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_node_text(self, node, depth, sep, params=False,):\n        indent = sep * depth\n        s = ''\n        tag = node.tag\n        if tag == 'Indicator':\n            node_text = self.get_i_text(node)\n        elif tag == 'IndicatorItem':\n            node_text = self.get_ii_text(node)\n        else:\n            raise IOCParseError('Invalid node encountered: {}'.format(tag))\n        s += '{}{}\\n'.format(indent, node_text)\n        if params:\n            param_text = self.get_param_text(node.attrib.get('id'))\n            for pt in param_text:\n                s += '{}{}\\n'.format(indent+sep, pt)\n        if node.tag == 'Indicator':\n            for child in node.getchildren():\n                s += self.get_node_text(node=child, depth=depth+1, sep=sep, params=params)\n        return s", "response": "Get the text for a given Indicator or IndicatorItem node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the text for an Indicator node.", "response": "def get_i_text(node):\n        \"\"\"\n        Get the text for an Indicator node.\n\n        :param node: Indicator node.\n        :return:\n        \"\"\"\n        if node.tag != 'Indicator':\n            raise IOCParseError('Invalid tag: {}'.format(node.tag))\n        s = node.get('operator').upper()\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the text for IndicatorItem node.", "response": "def get_ii_text(node):\n        \"\"\"\n        Get the text for IndicatorItem node.\n\n        :param node: IndicatorItem node.\n        :return:\n        \"\"\"\n        if node.tag != 'IndicatorItem':\n            raise IOCParseError('Invalid tag: {}'.format(node.tag))\n        condition = node.attrib.get('condition')\n        preserve_case = node.attrib.get('preserve-case', '')\n        negate = node.attrib.get('negate', '')\n        content = node.findtext('Content')\n        search = node.find('Context').get('search')\n        if preserve_case.lower() == 'true':\n            preserve_case = ' (Preserve Case)'\n        else:\n            preserve_case = ''\n        if negate.lower() == 'true':\n            negate = 'NOT '\n        else:\n            negate = ''\n        s = '{negate}{search} {condition} \"{content}\"{preserve_case}'.format(negate=negate,\n                                                                             search=search,\n                                                                             condition=condition,\n                                                                             content=content,\n                                                                             preserve_case=preserve_case)\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_param_text(self, nid):\n        r = []\n        params = self.parameters.xpath('.//param[@ref-id=\"{}\"]'.format(nid))\n        if not params:\n            return r\n        for param in params:\n            vnode = param.find('value')\n            s = 'Parameter: {}, type:{}, value: {}'.format(param.attrib.get('name'),\n                                                           vnode.attrib.get('type'),\n                                                           param.findtext('value', default='No Value'))\n            r.append(s)\n        return r", "response": "Get a list of parameters as text values for a given node id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading in an XML file or string into a lxml. _elementTree object.", "response": "def read_xml(filename):\n    \"\"\"\n    Use et to read in a xml file, or string, into a Element object.\n\n    :param filename: File to parse.\n    :return: lxml._elementTree object or None\n    \"\"\"\n    parser = et.XMLParser(remove_blank_text=True)\n    isfile=False\n    try:\n        isfile = os.path.exists(filename)\n    except ValueError as e:\n        if 'path too long for Windows' in str(e):\n            pass\n        else:\n            raise\n    try:\n        if isfile:\n            return et.parse(filename, parser)\n        else:\n            r = et.fromstring(filename, parser)\n            return r.getroottree()\n    except IOError:\n        log.exception('unable to open file [[}]'.format(filename))\n    except et.XMLSyntaxError:\n        log.exception('unable to parse XML [{}]'.format(filename))\n        return None\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves the specified namespace from all Element nodes within a document.", "response": "def remove_namespace(doc, namespace):\n    \"\"\"\n    Takes in a ElementTree object and namespace value.  The length of that\n    namespace value is removed from all Element nodes within the document.\n    This effectively removes the namespace from that document.\n\n    :param doc: lxml.etree\n    :param namespace: Namespace that needs to be removed.\n    :return: Returns the source document with namespaces removed.\n    \"\"\"\n    # http://homework.nwsnet.de/products/45be_remove-namespace-in-an-xml-document-using-elementtree\n    #\n    # Permission is hereby granted, free of charge, to any person obtaining\n    # a copy of this software and associated documentation files (the\n    # \"Software\"), to deal in the Software without restriction, including\n    # without limitation the rights to use, copy, modify, merge, publish,\n    # distribute, sublicense, and/or sell copies of the Software, and to\n    # permit persons to whom the Software is furnished to do so, subject to\n    # the following conditions:\n    #\n    # The above copyright notice and this permission notice shall be\n    # included in all copies or substantial portions of the Software.\n    #\n    # THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n    # EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n    # MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n    # NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n    # LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n    # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n    # WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n    ns = '{{{}}}'.format(namespace)\n    nsl = len(ns)\n    # print 'DEBUG: removing',ns\n    for elem in doc.getiterator():\n        if elem.tag.startswith(ns):\n            elem.tag = elem.tag[nsl:]\n    return doc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_namespace(parsed_xml):\n    if parsed_xml.getroot().tag.startswith('{'):\n        root = parsed_xml.getroot().tag\n        end_ns = root.find('}')\n        remove_namespace(parsed_xml, root[1:end_ns])\n    return parsed_xml", "response": "Removes the namespace associated with the root node of a XML document and returns the original XML document."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the specified file into memory and inserts them into the class.", "response": "def insert(self, filename):\n        \"\"\"\n        Parses files to load them into memory and insert them into the class.\n\n        :param filename: File or directory pointing to .ioc files.\n        :return: A list of .ioc files which could not be parsed.\n        \"\"\"\n        errors = []\n        if os.path.isfile(filename):\n            log.info('loading IOC from: {}'.format(filename))\n            if not self.parse(filename):\n                log.warning('Failed to prase [{}]'.format(filename))\n                errors.append(filename)\n        elif os.path.isdir(filename):\n            log.info('loading IOCs from: {}'.format(filename))\n            for fn in glob.glob(filename + os.path.sep + '*.ioc'):\n                if not os.path.isfile(fn):\n                    continue\n                else:\n                    if not self.parse(fn):\n                        log.warning('Failed to parse [{}]'.format(filename))\n                        errors.append(fn)\n        else:\n            pass\n        log.info('Parsed [%s] IOCs' % str(len(self)))\n        return errors"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(self, fn):\n        ioc_xml = xmlutils.read_xml_no_ns(fn)\n        if not ioc_xml:\n            return False\n        root = ioc_xml.getroot()\n        iocid = root.get('id', None)\n        if not iocid:\n            return False\n        self.iocs[iocid] = ioc_xml\n        return True", "response": "Parses a file into a lxml. etree structure with namespaces removed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_to_11(self):\n        if len(self) < 1:\n            log.error('No iocs available to modify.')\n            return False\n        log.info('Converting IOCs from 1.0 to 1.1')\n        errors = []\n        for iocid in self.iocs:\n            ioc_xml = self.iocs[iocid]\n            root = ioc_xml.getroot()\n            if root.tag != 'ioc':\n                log.error('IOC root is not \"ioc\" [%s].' % str(iocid))\n                errors.append(iocid)\n                continue\n            name_10 = root.findtext('.//short_description')\n            keywords_10 = root.findtext('.//keywords')\n            description_10 = root.findtext('.//description')\n            author_10 = root.findtext('.//authored_by')\n            created_date_10 = root.findtext('.//authored_date')\n            last_modified_date_10 = root.get('last-modified', None)\n            if last_modified_date_10:\n                last_modified_date_10 = last_modified_date_10.rstrip('Z')\n            created_date_10 = created_date_10.rstrip('Z')\n            links_10 = []\n            for link in root.xpath('//link'):\n                link_rel = link.get('rel', None)\n                link_text = link.text\n                links_10.append((link_rel, link_text, None))\n            # get ioc_logic\n            try:\n                ioc_logic = root.xpath('.//definition')[0]\n            except IndexError:\n                log.exception(\n                    'Could not find definition nodes for IOC [%s].  Did you attempt to convert OpenIOC 1.1 iocs?' % str(\n                        iocid))\n                errors.append(iocid)\n                continue\n            # create 1.1 ioc obj\n            ioc_obj = ioc_api.IOC(name=name_10, description=description_10, author=author_10, links=links_10,\n                                  keywords=keywords_10, iocid=iocid)\n            ioc_obj.set_lastmodified_date(last_modified_date_10)\n            ioc_obj.set_created_date(created_date_10)\n\n            comment_dict = {}\n            tlo_10 = ioc_logic.getchildren()[0]\n            try:\n                self.convert_branch(tlo_10, ioc_obj.top_level_indicator, comment_dict)\n            except UpgradeError:\n                log.exception('Problem converting IOC [{}]'.format(iocid))\n                errors.append(iocid)\n                continue\n            for node_id in comment_dict:\n                ioc_obj.add_parameter(node_id, comment_dict[node_id])\n            self.iocs_11[iocid] = ioc_obj\n        return errors", "response": "Convert the iocs in self. iocs from OpenIOC 1. 0 to OpenIOC 1. 1 format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_branch(self, old_node, new_node, comment_dict=None):\n        expected_tag = 'Indicator'\n        if old_node.tag != expected_tag:\n            raise UpgradeError('old_node expected tag is [%s]' % expected_tag)\n        if not comment_dict:\n            comment_dict = {}\n        for node in old_node.getchildren():\n            node_id = node.get('id')\n            if node.tag == 'IndicatorItem':\n                condition = node.get('condition')\n                negation = False\n                if condition.endswith('not'):\n                    negation = True\n                    condition = condition[:-3]\n                document = node.xpath('Context/@document')[0]\n                search = node.xpath('Context/@search')[0]\n                content_type = node.xpath('Content/@type')[0]\n                content = node.findtext('Content')\n                context_type = node.xpath('Context/@type')[0]\n                new_ii_node = ioc_api.make_indicatoritem_node(condition=condition,\n                                                              document=document,\n                                                              search=search,\n                                                              content_type=content_type,\n                                                              content=content,\n                                                              context_type=context_type,\n                                                              negate=negation,\n                                                              nid=node_id)\n                # set comment\n                comment = node.find('Comment')\n                if comment is not None:\n                    comment_dict[node_id] = comment.text\n                new_node.append(new_ii_node)\n            elif node.tag == 'Indicator':\n                operator = node.get('operator')\n                if operator.upper() not in ['OR', 'AND']:\n                    raise UpgradeError('Indicator@operator is not AND/OR. [%s] has [%s]' % (node_id, operator))\n                new_i_node = ioc_api.make_indicator_node(operator, node_id)\n                new_node.append(new_i_node)\n                self.convert_branch(node, new_i_node, comment_dict)\n            else:\n                # should never get here\n                raise UpgradeError('node is not a Indicator/IndicatorItem')\n        return True", "response": "This function recursively walks a branch of the Indicator node and converts it to a new node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a file or directory containing IOCs and inserts them into the class.", "response": "def insert(self, filename):\n        \"\"\"\n        Parses files to load them into memory and insert them into the class.\n\n        :param filename: File or directory pointing to .ioc files.\n        :return: A list of .ioc files which could not be parsed.\n        \"\"\"\n        errors = []\n        if os.path.isfile(filename):\n            log.info('loading IOC from: {}'.format(filename))\n            try:\n                self.parse(ioc_api.IOC(filename))\n            except ioc_api.IOCParseError:\n                log.exception('Parse Error')\n                errors.append(filename)\n        elif os.path.isdir(filename):\n            log.info('loading IOCs from: {}'.format(filename))\n            for fn in glob.glob(filename + os.path.sep + '*.ioc'):\n                if not os.path.isfile(fn):\n                    continue\n                else:\n                    try:\n                        self.parse(ioc_api.IOC(fn))\n                    except ioc_api.IOCParseError:\n                        log.exception('Parse Error')\n                        errors.append(fn)\n        else:\n            pass\n        log.info('Parsed [{}] IOCs'.format(len(self)))\n        return errors"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse an ioc to populate self. iocs and self. ioc_name .", "response": "def parse(self, ioc_obj):\n        \"\"\"\n        parses an ioc to populate self.iocs and self.ioc_name\n\n        :param ioc_obj:\n        :return:\n        \"\"\"\n        if ioc_obj is None:\n            return\n        iocid = ioc_obj.iocid\n        try:\n            sd = ioc_obj.metadata.xpath('.//short_description/text()')[0]\n        except IndexError:\n            sd = 'NoName'\n        if iocid in self.iocs:\n            msg = 'duplicate IOC UUID [{}] [orig_shortName: {}][new_shortName: {}]'.format(iocid,\n                                                                                           self.ioc_name[iocid],\n                                                                                           sd)\n            log.warning(msg)\n        self.iocs[iocid] = ioc_obj\n        self.ioc_name[iocid] = sd\n        if self.parser_callback:\n            self.parser_callback(ioc_obj)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_parser_callback(self, func):\n        if hasattr(func, '__call__'):\n            self.parser_callback = func\n            log.debug('Set callback to {}'.format(func))\n        else:\n            raise TypeError('Provided function is not callable: {}'.format(func))", "response": "Register a callback function that is called after self. ioc_name is populated."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates single permission for the given object.", "response": "def create(self, permission):\n        \"\"\"\n        Create single permission for the given object.\n\n        :param Permission permission: A single Permission object to be set.\n        \"\"\"\n        parent_url = self.client.get_url(self.parent_object._manager._URL_KEY, 'GET', 'single', {'id': self.parent_object.id})\n        target_url = parent_url + self.client.get_url_path(self._URL_KEY, 'POST', 'single')\n        r = self.client.request('POST', target_url, json=permission._serialize())\n        return permission._deserialize(r.json(), self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(self, permissions):\n        parent_url = self.client.get_url(self.parent_object._manager._URL_KEY, 'GET', 'single', {'id': self.parent_object.id})\n        target_url = parent_url + self.client.get_url_path(self._URL_KEY, 'PUT', 'multi')\n        r = self.client.request('PUT', target_url, json=permissions)\n        if r.status_code != 201:\n            raise exceptions.ServerError(\"Expected 201 response, got %s: %s\" % (r.status_code, target_url))\n        return self.list()", "response": "Sets the permissions for the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list(self):\n        parent_url = self.client.get_url(self.parent_object._manager._URL_KEY, 'GET', 'single', {'id': self.parent_object.id})\n        target_url = parent_url + self.client.get_url_path(self._URL_KEY, 'GET', 'multi')\n        return base.Query(self, target_url)", "response": "List permissions for the given object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, permission_id, expand=[]):\n        parent_url = self.client.get_url(self.parent_object._manager._URL_KEY, 'GET', 'single', {'id': self.parent_object.id})\n        target_url = parent_url + self.client.get_url_path(\n            self._URL_KEY, 'GET', 'single', {'permission_id': permission_id})\n        return self._get(target_url, expand=expand)", "response": "Get a specific permisison for the given object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_config():\n    configpath = get_configpath()\n    if not configpath.exists():\n        raise IOError(\"Config file {} not found.\".format(str(configpath)))\n    else:\n        config = configparser.ConfigParser()\n        config.read(str(configpath))\n        return config", "response": "Read the configfile and return a dictionary with the content of the configpath file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse to write the database path into the config.", "response": "def set_database_path(dbfolder):\n    \"\"\"Use to write the database path into the config.\n\n    Parameters\n    ----------\n    dbfolder : str or pathlib.Path\n        Path to where pyciss will store the ISS images it downloads and receives.\n    \"\"\"\n    configpath = get_configpath()\n    try:\n        d = get_config()\n    except IOError:\n        d = configparser.ConfigParser()\n        d['pyciss_db'] = {}\n    d['pyciss_db']['path'] = dbfolder\n    with configpath.open('w') as f:\n        d.write(f)\n    print(\"Saved database path into {}.\".format(configpath))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_db_root():\n    \"Read dbroot folder from config and mkdir if required.\"\n    d = get_config()\n    dbroot = Path(d['pyciss_db']['path'])\n    dbroot.mkdir(exist_ok=True)\n    return dbroot", "response": "Read dbroot folder from config and mkdir if required."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints database stats. Returns ------- pd. DataFrame pd. DataFrame", "response": "def print_db_stats():\n    \"\"\"Print database stats.\n\n    Returns\n    -------\n    pd.DataFrame\n        Table with the found data items per type.\n    \"\"\"\n    dbroot = get_db_root()\n    n_ids = len(list(dbroot.glob(\"[N,W]*\")))\n    print(\"Number of WACs and NACs in database: {}\".format(n_ids))\n    print(\"These kind of data are in the database: (returning pd.DataFrame)\")\n    d = {}\n    for key, val in PathManager.extensions.items():\n        d[key] = [len(list(dbroot.glob(\"**/*\" + val)))]\n    return pd.DataFrame(d)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the label file is LOSSY.", "response": "def is_lossy(label):\n    \"\"\"Check Label file for the compression type. \"\"\"\n    val = getkey(from_=label, keyword='INST_CMPRS_TYPE').decode().strip()\n    if val == 'LOSSY':\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef download_and_calibrate_parallel(list_of_ids, n=None):\n    setup_cluster(n_cores=n)\n    c = Client()\n    lbview = c.load_balanced_view()\n    lbview.map_async(download_and_calibrate, list_of_ids)\n    subprocess.Popen([\"ipcluster\", \"stop\", \"--quiet\"])", "response": "Download and calibrate in parallel."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndownloading and calibrate one or more image ids in parallel.", "response": "def download_and_calibrate(img_id=None, overwrite=False, recalibrate=False, **kwargs):\n    \"\"\"Download and calibrate one or more image ids, in parallel.\n\n    Parameters\n    ----------\n    img_id : str or io.PathManager, optional\n        If more than one item is in img_id, a parallel process is started\n    overwrite: bool, optional\n        If the pm.cubepath exists, this switch controls if it is being overwritten.\n        Default: False\n    \"\"\"\n    if isinstance(img_id, io.PathManager):\n        pm = img_id\n    else:\n        # get a PathManager object that knows where your data is or should be\n        logger.debug(\"Creating Pathmanager object\")\n        pm = io.PathManager(img_id)\n\n    if not pm.raw_image.exists() or overwrite is True:\n        logger.debug(\"Downloading file %s\" % pm.img_id)\n        download_file_id(pm.img_id)\n        pm = io.PathManager(img_id)  # refresh, to get proper PDS version id.\n    else:\n        logger.info(\"Found \")\n\n    if not (pm.cubepath.exists() and pm.undestriped.exists()) or overwrite is True:\n        calib = pipeline.Calibrator(img_id, **kwargs)\n        calib.standard_calib()\n    else:\n        print(\"All files exist. Use overwrite=True to redownload and calibrate.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms either normal spiceinit or outer spiceinit.", "response": "def spiceinit(self):\n        \"\"\"Perform either normal spiceinit or one for ringdata.\n\n        Note how Python name-spacing can distinguish between the method\n        and the function with the same name. `spiceinit` from the outer\n        namespace is the one imported from pysis.\n        \"\"\"\n        shape = \"ringplane\" if self.is_ring_data else None\n        spiceinit(from_=self.pm.raw_cub, cksmithed=\"yes\", spksmithed=\"yes\", shape=shape)\n        logger.info(\"spiceinit done.\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_label(self):\n        if not self.is_ring_data:\n            return\n        targetname = getkey(\n            from_=self.pm.raw_cub, grp=\"instrument\", keyword=\"targetname\"\n        )\n\n        if targetname.lower() != \"saturn\":\n            editlab(\n                from_=self.pm.raw_cub,\n                options=\"modkey\",\n                keyword=\"TargetName\",\n                value=\"Saturn\",\n                grpname=\"Instrument\",\n            )", "response": "Check label for target name and fix if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking and sets the supported content types configuration value.", "response": "def _set_supported_content_type(self, content_types_supported):\n        \"\"\" Checks and sets the supported content types configuration value.\n        \"\"\"\n        if not isinstance(content_types_supported, list):\n            raise TypeError((\"Settings 'READTIME_CONTENT_SUPPORT' must be\"\n                             \"a list of content types.\"))\n\n        self.content_type_supported = content_types_supported"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks and sets the per language WPM singular and plural values.", "response": "def _set_lang_settings(self, lang_settings):\n        \"\"\" Checks and sets the per language WPM, singular and plural values.\n        \"\"\"\n        is_int = isinstance(lang_settings, int)\n        is_dict = isinstance(lang_settings, dict)\n        if not is_int and not is_dict:\n            raise TypeError((\"Settings 'READTIME_WPM' must be either an int,\"\n                             \"or a dict with settings per language.\"))\n\n        # For backwards compatability reasons we'll allow the\n        # READTIME_WPM setting to be set as an to override just the default\n        # set WPM.\n        if is_int:\n            self.lang_settings['default']['wpm'] = lang_settings\n        elif is_dict:\n            for lang, conf in lang_settings.items():\n                if 'wpm' not in conf:\n                    raise KeyError(('Missing wpm value for the'\n                                    'language: {}'.format(lang)))\n\n                if not isinstance(conf['wpm'], int):\n                    raise TypeError(('WPM is not an integer for'\n                                     ' the language: {}'.format(lang)))\n\n                if \"min_singular\" not in conf:\n                    raise KeyError(('Missing singular form for \"minute\" for'\n                                    ' the language: {}'.format(lang)))\n\n                if \"min_plural\" not in conf:\n                    raise KeyError(('Missing plural form for \"minutes\" for'\n                                    ' the language: {}'.format(lang)))\n\n                if \"sec_singular\" not in conf:\n                    raise KeyError(('Missing singular form for \"second\" for'\n                                    ' the language: {}'.format(lang)))\n\n                if \"sec_plural\" not in conf:\n                    raise KeyError(('Missing plural form for \"seconds\" for'\n                                    ' the language: {}'.format(lang)))\n\n            self.lang_settings = lang_settings"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing the ReadTimeParser with the configuration values set by the readtime plugin.", "response": "def initialize_settings(self, sender):\n        \"\"\" Initializes ReadTimeParser with configuration values set by the\n        site author.\n        \"\"\"\n        try:\n            self.initialized = True\n\n            settings_content_types = sender.settings.get(\n                'READTIME_CONTENT_SUPPORT', self.content_type_supported)\n            self._set_supported_content_type(settings_content_types)\n\n            lang_settings = sender.settings.get(\n                'READTIME_WPM', self.lang_settings)\n            self._set_lang_settings(lang_settings)\n        except Exception as e:\n            raise Exception(\"ReadTime Plugin: %s\" % str(e))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_time(self, content):\n        if get_class_name(content) in self.content_type_supported:\n            # Exit if readtime is already set\n            if hasattr(content, 'readtime'):\n                return None\n\n            default_lang_conf = self.lang_settings['default']\n            lang_conf = self.lang_settings.get(content.lang, default_lang_conf)\n            avg_reading_wpm = lang_conf['wpm']\n\n            num_words = len(content._content.split())\n            # Floor division so we don't have to convert float -> int\n            minutes = num_words // avg_reading_wpm\n            # Get seconds to read, then subtract our minutes as seconds from\n            # the time to get remainder seconds\n            seconds = int((num_words / avg_reading_wpm * 60) - (minutes * 60))\n\n            minutes_str = self.pluralize(\n                minutes,\n                lang_conf['min_singular'],\n                lang_conf['min_plural']\n            )\n\n            seconds_str = self.pluralize(\n                seconds,\n                lang_conf['sec_singular'],\n                lang_conf['sec_plural']\n            )\n\n            content.readtime = minutes\n            content.readtime_string = minutes_str\n            content.readtime_with_seconds = (minutes, seconds,)\n            content.readtime_string_with_seconds = \"{}, {}\".format(\n                minutes_str, seconds_str)", "response": "This function generates the read time for the content."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a string that contains the measure and its plural form depending on the amount.", "response": "def pluralize(self, measure, singular, plural):\n        \"\"\" Returns a string that contains the measure (amount) and its plural\n        or singular form depending on the amount.\n\n        Parameters:\n            :param measure: Amount, value, always a numerical value\n            :param singular: The singular form of the chosen word\n            :param plural: The plural form of the chosen word\n\n        Returns:\n            String\n        \"\"\"\n        if measure == 1:\n            return \"{} {}\".format(measure, singular)\n        else:\n            return \"{} {}\".format(measure, plural)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_datasources(self, source_id):\n        target_url = self.client.get_url('DATASOURCE', 'GET', 'multi', {'source_id': source_id})\n        return base.Query(self.client.get_manager(Datasource), target_url)", "response": "Filterable list of Datasources for a Source."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_datasource(self, source_id, datasource_id):\n        target_url = self.client.get_url('DATASOURCE', 'GET', 'single', {'source_id': source_id, 'datasource_id': datasource_id})\n        return self.client.get_manager(Datasource)._get(target_url)", "response": "Get a Datasource object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist all Scans for a Source.", "response": "def list_scans(self, source_id=None):\n        \"\"\"\n        Filterable list of Scans for a Source.\n        Ordered newest to oldest by default\n        \"\"\"\n        if source_id:\n            target_url = self.client.get_url('SCAN', 'GET', 'multi', {'source_id': source_id})\n        else:\n            target_url = self.client.get_ulr('SCAN', 'GET', 'all')\n        return base.Query(self.client.get_manager(Scan), target_url)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a Scan object from the given source and scan ID.", "response": "def get_scan(self, source_id, scan_id):\n        \"\"\"\n        Get a Scan object\n\n        :rtype: Scan\n        \"\"\"\n        target_url = self.client.get_url('SCAN', 'GET', 'single', {'source_id': source_id, 'scan_id': scan_id})\n        return self.client.get_manager(Scan)._get(target_url)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_scan_log_lines(self, source_id, scan_id):\n        return self.client.get_manager(Scan).get_log_lines(source_id=source_id, scan_id=scan_id)", "response": "Get the log lines for a Scan"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts a new scan of a Source.", "response": "def start_scan(self, source_id):\n        \"\"\"\n        Start a new scan of a Source.\n\n        :rtype: Scan\n        \"\"\"\n        target_url = self.client.get_url('SCAN', 'POST', 'create', {'source_id': source_id})\n        r = self.client.request('POST', target_url, json={})\n        return self.client.get_manager(Scan).create_from_result(r.json())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self, with_data=False):\n        r = self._client.request('PUT', self.url, json=self._serialize(with_data=with_data))\n        return self._deserialize(r.json(), self._manager)", "response": "Saves this Source into the server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a single file or archive to the upload list.", "response": "def add_file(self, fp, upload_path=None, content_type=None):\n        \"\"\"\n        Add a single file or archive to upload.\n\n        To add metadata records with a file, add a .xml file with the same upload path basename\n        eg. ``points-with-metadata.geojson`` & ``points-with-metadata.xml``\n        Datasource XML must be in one of these three formats:\n\n          - ISO 19115/19139\n          - FGDC CSDGM\n          - Dublin Core (OAI-PMH)\n\n        :param fp: File to upload into this source, can be a path or a file-like object.\n        :type fp: str or file\n        :param str upload_path: relative path to store the file as within the source (eg. ``folder/0001.tif``). \\\n                                By default it will use ``fp``, either the filename from a path or the ``.name`` \\\n                                attribute of a file-like object.\n        :param str content_type: Content-Type of the file. By default it will attempt to auto-detect from the \\\n                                 file/upload_path.\n        \"\"\"\n        if isinstance(fp, six.string_types):\n            # path\n            if not os.path.isfile(fp):\n                raise ClientValidationError(\"Invalid file: %s\", fp)\n            if not upload_path:\n                upload_path = os.path.split(fp)[1]\n        else:\n            # file-like object\n            if not upload_path:\n                upload_path = os.path.split(fp.name)[1]\n\n        content_type = content_type or mimetypes.guess_type(upload_path, strict=False)[0]\n        if upload_path in self._files:\n            raise ClientValidationError(\"Duplicate upload path: %s\" % upload_path)\n\n        self._files[upload_path] = (fp, content_type)\n        logger.debug(\"UploadSource.add_file: %s -> %s (%s)\", repr(fp), upload_path, content_type)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the log lines for a given source and scan.", "response": "def get_log_lines(self, source_id, scan_id):\n        \"\"\"\n        Get the log text for a scan object\n        :rtype: Iterator over log lines.\n        \"\"\"\n        target_url = self.client.get_url('SCAN', 'GET', 'log', {'source_id': source_id, 'scan_id': scan_id})\n        r = self.client.request('GET', target_url, headers={'Accept': 'text/plain'}, stream=True)\n        return r.iter_lines(decode_unicode=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_log_lines(self):\n        rel = self._client.reverse_url('SCAN', self.url)\n        return self._manager.get_log_lines(**rel)", "response": "Get the log lines for a scan object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_creative_commons(self, slug, jurisdiction=None):\n        if not slug.startswith('cc-by'):\n            raise exceptions.ClientValidationError(\"slug needs to start with 'cc-by'\")\n\n        if jurisdiction is None:\n            jurisdiction = ''\n\n        target_url = self.client.get_url(self._URL_KEY, 'GET', 'cc', {'slug': slug, 'jurisdiction': jurisdiction})\n        return self._get(target_url)", "response": "Returns the Creative Commons license for the given attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mad(arr, relative=True):\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        med = np.nanmedian(arr, axis=1)\n        mad = np.nanmedian(np.abs(arr - med[:, np.newaxis]), axis=1)\n        if relative:\n            return mad / med\n        else:\n            return mad", "response": "Median Absolute Deviation of a sample."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calc_offset(cube):\n    i = 0\n    while pd.Series(cube.img[:, i]).count() < 200:\n        i += 1\n    return max(i, 20)", "response": "Calculate an offset from the side of data so that at least 200 image pixels are in the MAD stats."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplotting the image of the current object.", "response": "def imshow(\n        self,\n        data=None,\n        save=False,\n        ax=None,\n        interpolation=\"none\",\n        extra_title=None,\n        show_resonances=\"some\",\n        set_extent=True,\n        equalized=False,\n        rmin=None,\n        rmax=None,\n        savepath=\".\",\n        **kwargs,\n    ):\n        \"\"\"Powerful default display.\n\n        show_resonances can be True, a list, 'all', or 'some'\n        \"\"\"\n        if data is None:\n            data = self.img\n        if self.resonance_axis is not None:\n            logger.debug(\"removing resonance_axis\")\n            self.resonance_axis.remove()\n        if equalized:\n            data = np.nan_to_num(data)\n            data[data < 0] = 0\n            data = exposure.equalize_hist(data)\n        self.plotted_data = data\n\n        extent_val = self.extent if set_extent else None\n        min_, max_ = self.plot_limits\n        self.min_ = min_\n        self.max_ = max_\n        if ax is None:\n            if not _SEABORN_INSTALLED:\n                fig, ax = plt.subplots(figsize=calc_4_3(8))\n            else:\n                fig, ax = plt.subplots()\n        else:\n            fig = ax.get_figure()\n\n        with quantity_support():\n            im = ax.imshow(\n                data,\n                extent=extent_val,\n                cmap=\"gray\",\n                vmin=min_,\n                vmax=max_,\n                interpolation=interpolation,\n                origin=\"lower\",\n                aspect=\"auto\",\n                **kwargs,\n            )\n        if any([rmin is not None, rmax is not None]):\n            ax.set_ylim(rmin, rmax)\n        self.mpl_im = im\n        ax.set_xlabel(\"Longitude [deg]\")\n        ax.set_ylabel(\"Radius [Mm]\")\n        ax.ticklabel_format(useOffset=False)\n        # ax.grid('on')\n        title = self.plot_title\n        if extra_title:\n            title += \", \" + extra_title\n        ax.set_title(title, fontsize=12)\n        if show_resonances:\n            self.set_resonance_axis(ax, show_resonances, rmin, rmax)\n        if save:\n            savename = self.plotfname\n            if extra_title:\n                savename = savename[:-4] + \"_\" + extra_title + \".png\"\n            p = Path(savename)\n            fullpath = Path(savepath) / p.name\n            fig.savefig(fullpath, dpi=150)\n            logging.info(\"Created %s\", fullpath)\n        self.im = im\n        return im"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the query count property from the X - Resource - Range response header.", "response": "def _update_range(self, response):\n        \"\"\" Update the query count property from the `X-Resource-Range` response header \"\"\"\n        header_value = response.headers.get('x-resource-range', '')\n        m = re.match(r'\\d+-\\d+/(\\d+)$', header_value)\n        if m:\n            self._count = int(m.group(1))\n        else:\n            self._count = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserialising this query into a request - able URL including parameters", "response": "def _to_url(self):\n        \"\"\" Serialises this query into a request-able URL including parameters \"\"\"\n        url = self._target_url\n\n        params = collections.defaultdict(list, copy.deepcopy(self._filters))\n        if self._order_by is not None:\n            params['sort'] = self._order_by\n        for k, vl in self._extra.items():\n            params[k] += vl\n\n        if params:\n            url += \"?\" + urllib.parse.urlencode(params, doseq=True)\n\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new Query object with extra query parameters added.", "response": "def extra(self, **params):\n        \"\"\"\n        Set extra query parameters (eg. filter expressions/attributes that don't validate).\n        Appends to any previous extras set.\n\n        :rtype: Query\n        \"\"\"\n        q = self._clone()\n        for key, value in params.items():\n            q._extra[key].append(value)\n        return q"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter(self, **filters):\n\n        q = self._clone()\n        for key, value in filters.items():\n            filter_key = re.split('__', key)\n            filter_attr = filter_key[0]\n            if filter_attr not in self._valid_filter_attrs:\n                raise ClientValidationError(\"Invalid filter attribute: %s\" % key)\n\n            # we use __ as a separator in the Python library, the APIs use '.'\n            q._filters['.'.join(filter_key)].append(value)\n        return q", "response": "Add a filter to this query."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef order_by(self, sort_key=None):\n        if sort_key is not None:\n            sort_attr = re.match(r'(-)?(.*)$', sort_key).group(2)\n            if sort_attr not in self._valid_sort_attrs:\n                raise ClientValidationError(\"Invalid ordering attribute: %s\" % sort_key)\n\n        q = self._clone()\n        q._order_by = sort_key\n        return q", "response": "Sets the ordering for this query."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _serialize(self, skip_empty=True):\n        skip = set(getattr(self._meta, 'serialize_skip', []))\n\n        r = {}\n        for k, v in self.__dict__.items():\n            if k.startswith('_'):\n                continue\n            elif k in skip:\n                continue\n            elif v is None and skip_empty:\n                continue\n            elif isinstance(v, (dict, list, tuple, set)) and len(v) == 0 and skip_empty:\n                continue\n            else:\n                r[k] = self._serialize_value(v)\n        return r", "response": "Serialise this instance into JSON - style request data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _serialize_value(self, value):\n        if isinstance(value, (list, tuple, set)):\n            return [self._serialize_value(v) for v in value]\n        elif isinstance(value, dict):\n            return dict([(k, self._serialize_value(v)) for k, v in value.items()])\n        elif isinstance(value, ModelBase):\n            return value._serialize()\n        elif isinstance(value, datetime.date):  # includes datetime.datetime\n            return value.isoformat()\n        else:\n            return value", "response": "Serialize a single value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrefresh the current model s attributes with the server - defined values.", "response": "def refresh(self):\n        \"\"\"\n        Refresh this model from the server.\n\n        Updates attributes with the server-defined values. This is useful where the Model\n        instance came from a partial response (eg. a list query) and additional details\n        are required.\n\n        Existing attribute values will be overwritten.\n        \"\"\"\n        r = self._client.request('GET', self.url)\n        return self._deserialize(r.json(), self._manager)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_feature(self, croplayer_id, cropfeature_id):\n        target_url = self.client.get_url('CROPFEATURE', 'GET', 'single', {'croplayer_id': croplayer_id, 'cropfeature_id': cropfeature_id})\n        return self.client.get_manager(CropFeature)._get(target_url)", "response": "Gets a crop feature"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating and start processing a new Export.", "response": "def create(self, export):\n        \"\"\"\n        Create and start processing a new Export.\n\n        :param Export export: The Export to create.\n        :rtype: Export\n        \"\"\"\n        target_url = self.client.get_url(self._URL_KEY, 'POST', 'create')\n        r = self.client.request('POST', target_url, json=export._serialize())\n        return export._deserialize(r.json(), self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(self, export):\n        target_url = self.client.get_url(self._URL_KEY, 'POST', 'validate')\n        response_object = ExportValidationResponse()\n        r = self.client.request('POST', target_url, json=export._serialize())\n        return response_object._deserialize(r.json())", "response": "Validates an Export.\n\n\n        :param Export export:\n        :rtype: ExportValidationResponse"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _options(self):\n        if self._options_cache is None:\n            target_url = self.client.get_url(self._URL_KEY, 'OPTIONS', 'options')\n            r = self.client.request('OPTIONS', target_url)\n            self._options_cache = r.json()\n        return self._options_cache", "response": "Returns a raw options object"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary of format options keyed by data kind.", "response": "def get_formats(self):\n        \"\"\"\n        Returns a dictionary of format options keyed by data kind.\n\n        .. code-block:: python\n\n            {\n                \"vector\": {\n                    \"application/x-ogc-gpkg\": \"GeoPackage\",\n                    \"application/x-zipped-shp\": \"Shapefile\",\n                    #...\n                },\n                \"table\": {\n                    \"text/csv\": \"CSV (text/csv)\",\n                    \"application/x-ogc-gpkg\": \"GeoPackage\",\n                    #...\n                },\n                \"raster\": {\n                    \"image/jpeg\": \"JPEG\",\n                    \"image/jp2\": \"JPEG2000\",\n                    #...\n                },\n                \"grid\": {\n                    \"application/x-ogc-aaigrid\": \"ASCII Grid\",\n                    \"image/tiff;subtype=geotiff\": \"GeoTIFF\",\n                    #...\n                },\n                \"rat\": {\n                    \"application/x-erdas-hfa\": \"ERDAS Imagine\",\n                    #...\n                }\n            }\n\n        :rtype: dict\n        \"\"\"\n        format_opts = self._options()['actions']['POST']['formats']['children']\n        r = {}\n        for kind, kind_opts in format_opts.items():\n            r[kind] = {c['value']: c['display_name'] for c in kind_opts['choices']}\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a new item to the export.", "response": "def add_item(self, item, **options):\n        \"\"\"\n        Add a layer or table item to the export.\n\n        :param Layer|Table item: The Layer or Table to add\n        :rtype: self\n        \"\"\"\n        export_item = {\n            \"item\": item.url,\n        }\n        export_item.update(options)\n        self.items.append(export_item)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef download(self, path, progress_callback=None, chunk_size=1024**2):\n        if not self.download_url or self.state != 'complete':\n            raise DownloadError(\"Download not available\")\n\n        # ignore parsing the Content-Disposition header, since we know the name\n        download_filename = \"{}.zip\".format(self.name)\n        fd = None\n\n        if isinstance(getattr(path, 'write', None), collections.Callable):\n            # already open file-like object\n            fd = path\n        elif os.path.isdir(path):\n            # directory to download to, using the export name\n            path = os.path.join(path, download_filename)\n            # do not allow overwriting\n            if os.path.exists(path):\n                raise DownloadError(\"Download file already exists: %s\" % path)\n        elif path:\n            # fully qualified file path\n            # allow overwriting\n            pass\n        elif not path:\n            raise DownloadError(\"Empty download file path\")\n\n        with contextlib.ExitStack() as stack:\n            if not fd:\n                fd = open(path, 'wb')\n                # only close a file we open\n                stack.callback(fd.close)\n\n            r = self._manager.client.request('GET', self.download_url, stream=True)\n            stack.callback(r.close)\n\n            bytes_written = 0\n            try:\n                bytes_total = int(r.headers.get('content-length', None))\n            except TypeError:\n                bytes_total = None\n\n            if progress_callback:\n                # initial callback (0%)\n                progress_callback(bytes_written, bytes_total)\n\n            for chunk in r.iter_content(chunk_size=chunk_size):\n                fd.write(chunk)\n                bytes_written += len(chunk)\n                if progress_callback:\n                    progress_callback(bytes_written, bytes_total)\n\n        return download_filename", "response": "Download the export archive."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an instance of the class from a requests. ServerError.", "response": "def from_requests_error(cls, err):\n        \"\"\"\n        Raises a subclass of ServerError based on the HTTP response code.\n        \"\"\"\n        import requests\n        if isinstance(err, requests.HTTPError):\n            status_code = err.response.status_code\n            return HTTP_ERRORS.get(status_code, cls)(error=err, response=err.response)\n        else:\n            return cls(error=err)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncommanding line tool (``koordinates-create-token``) used to create an API token.", "response": "def console_create():\n    \"\"\"\n    Command line tool (``koordinates-create-token``) used to create an API token.\n    \"\"\"\n    import argparse\n    import getpass\n    import re\n    import sys\n    import requests\n    from six.moves import input\n    from koordinates.client import Client\n\n    parser = argparse.ArgumentParser(description=\"Command line tool to create a Koordinates API Token.\")\n    parser.add_argument('site', help=\"Domain (eg. labs.koordinates.com) for the Koordinates site.\", metavar='SITE')\n    parser.add_argument('email', help=\"User account email address\", metavar='EMAIL')\n    parser.add_argument('name', help=\"Description for the key\", metavar='NAME')\n    parser.add_argument('--scopes', help=\"Scopes for the new API token\", nargs='+', metavar=\"SCOPE\")\n    parser.add_argument('--referrers', help=\"Restrict the request referrers for the token. You can use * as a wildcard, eg. *.example.com\", nargs='+', metavar='HOST')\n    parser.add_argument('--expires', help=\"Expiry time in ISO 8601 (YYYY-MM-DD) format\", metavar=\"DATE\")\n    args = parser.parse_args()\n\n    # check we have a valid-ish looking domain name\n    if not re.match(r'(?=^.{4,253}$)(^((?!-)[a-zA-Z0-9-]{1,63}(?<!-)\\.)+[a-zA-Z]{2,63}$)', args.site):\n        parser.error(\"'%s' doesn't look like a valid domain name.\" % args.site)\n\n    # check we have a valid-ish looking email address\n    if not re.match(r'[^@]+@[^@]+\\.[^@]+$', args.email):\n        parser.error(\"'%s' doesn't look like a valid email address.\" % args.email)\n\n    password = getpass.getpass('Account password for %s: ' % args.email)\n    if not password:\n        parser.error(\"Empty password.\")\n\n    expires_at = make_date(args.expires)\n\n    print(\"\\nNew API Token Parameters:\")\n    print(\"  Koordinates Site: %s\" % args.site)\n    print(\"  User email address: %s\" % args.email)\n    print(\"  Name: %s\" % args.name)\n    print(\"  Scopes: %s\" % ' '.join(args.scopes or ['(default)']))\n    print(\"  Referrer restrictions: %s\" % ' '.join(args.referrers or ['(none)']))\n    print(\"  Expires: %s\" % (expires_at or '(never)'))\n    if input(\"Continue? [Yn] \").lower() == 'n':\n        sys.exit(1)\n\n    token = Token(name=args.name)\n    if args.scopes:\n        token.scopes = args.scopes\n    if args.referrers:\n        token.referrers = args.referrers\n    if expires_at:\n        token.expires_at = expires_at\n\n    print(\"\\nRequesting token...\")\n    # need a dummy token here for initialisation\n    client = Client(host=args.site, token='-dummy-')\n    try:\n        token = client.tokens.create(token, args.email, password)\n    except requests.HTTPError as e:\n        print(\"%s: %s\" % (e, e.response.text))\n\n        # Helpful tips for specific errors\n        if e.response.status_code == 401:\n            print(\"  => Check your email address, password, and site domain carefully.\")\n\n        sys.exit(1)\n\n    print(\"Token created successfully.\\n  Key: %s\\n  Scopes: %s\" % (token.key, token.scope))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new token in Koordinates user account.", "response": "def create(self, token, email, password):\n        \"\"\"\n        Create a new token\n\n        :param Token token: Token instance to create.\n        :param str email: Email address of the Koordinates user account.\n        :param str password: Koordinates user account password.\n        \"\"\"\n        target_url = self.client.get_url('TOKEN', 'POST', 'create')\n        post_data = {\n            'grant_type': 'password',\n            'username': email,\n            'password': password,\n            'name': token.name,\n        }\n        if getattr(token, 'scope', None):\n            post_data['scope'] = token.scope\n        if getattr(token, 'expires_at', None):\n            post_data['expires_at'] = token.expires_at\n        if getattr(token, 'referrers', None):\n            post_data['referrers'] = token.referrers\n\n        r = self.client._raw_request('POST', target_url, json=post_data, headers={'Content-type': 'application/json'})\n        return self.create_from_result(r.json())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_cumulative_iss_index():\n    \"Read in the whole cumulative index and return dataframe.\"\n    indexdir = get_index_dir()\n\n    path = indexdir / \"COISS_2999_index.hdf\"\n    try:\n        df = pd.read_hdf(path, \"df\")\n    except FileNotFoundError:\n        path = indexdir / \"cumindex.hdf\"\n        df = pd.read_hdf(path, \"df\")\n    # replace PDS Nan values (-1e32) with real NaNs\n    df = df.replace(-1.000000e32, np.nan)\n    return df.replace(-999.0, np.nan)", "response": "Read in the whole cumulative index and return dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfilter cumulative index for ring images.", "response": "def read_ring_images_index():\n    \"\"\"Filter cumulative index for ring images.\n\n    This is done by matching the column TARGET_DESC to contain the string 'ring'\n\n    Returns\n    -------\n    pandas.DataFrame\n        data table containing only meta-data for ring images\n    \"\"\"\n    meta = read_cumulative_iss_index()\n    ringfilter = meta.TARGET_DESC.str.contains(\"ring\", case=False)\n    return meta[ringfilter]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter_for_ringspan(clearnacs, spanlimit):\n    \"filter for covered ringspan, giver in km.\"\n    delta = clearnacs.MAXIMUM_RING_RADIUS - clearnacs.MINIMUM_RING_RADIUS\n    f = delta < spanlimit\n    ringspan = clearnacs[f].copy()\n    return ringspan", "response": "filter for covered ringspan giver in km."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(self, publish):\n        target_url = self.client.get_url('PUBLISH', 'POST', 'create')\n        r = self.client.request('POST', target_url, json=publish._serialize())\n        return self.create_from_result(r.json())", "response": "Creates a new publish group."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncancels a pending publish task", "response": "def cancel(self):\n        \"\"\" Cancel a pending publish task \"\"\"\n        target_url = self._client.get_url('PUBLISH', 'DELETE', 'single', {'id': self.id})\n        r = self._client.request('DELETE', target_url)\n        logger.info(\"cancel(): %s\", r.status_code)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_items(self):\n        from .layers import Layer\n\n        # no expansion support, just URLs\n        results = []\n        for url in self.items:\n            if '/layers/' in url:\n                r = self._client.request('GET', url)\n                results.append(self._client.get_manager(Layer).create_from_result(r.json()))\n            else:\n                raise NotImplementedError(\"No support for %s\" % url)\n        return results", "response": "Returns the item models associated with this Publish group."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a Layer to the publish group.", "response": "def add_layer_item(self, layer):\n        \"\"\"\n        Adds a Layer to the publish group.\n        \"\"\"\n        if not layer.is_draft_version:\n            raise ValueError(\"Layer isn't a draft version\")\n\n        self.items.append(layer.latest_version)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_table_item(self, table):\n        if not table.is_draft_version:\n            raise ValueError(\"Table isn't a draft version\")\n\n        self.items.append(table.latest_version)", "response": "Adds a Table to the publish group."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd new ticks to an axis.", "response": "def add_ticks_to_x(ax, newticks, newnames):\n    \"\"\"Add new ticks to an axis.\n\n    I use this for the right-hand plotting of resonance names in my plots.\n    \"\"\"\n    ticks = list(ax.get_xticks())\n    ticks.extend(newticks)\n    ax.set_xticks(ticks)\n\n    names = list(ax.get_xticklabels())\n    names.extend(newnames)\n    ax.set_xticklabels(names)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new Set.", "response": "def create(self, set):\n        \"\"\"\n        Creates a new Set.\n        \"\"\"\n        target_url = self.client.get_url('SET', 'POST', 'create')\n        r = self.client.request('POST', target_url, json=set._serialize())\n        return set._deserialize(r.json(), self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the XML metadata on a set.", "response": "def set_metadata(self, set_id, fp):\n        \"\"\"\n        Set the XML metadata on a set.\n\n        :param file fp: file-like object to read the XML metadata from.\n        \"\"\"\n        base_url = self.client.get_url('SET', 'GET', 'single', {'id': set_id})\n        self._metadata.set(base_url, fp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_metadata(self, fp):\n        base_url = self._client.get_url('SET', 'GET', 'single', {'id': self.id})\n        self._manager._metadata.set(base_url, fp)\n\n        # reload myself\n        r = self._client.request('GET', base_url)\n        return self._deserialize(r.json(), self._manager)", "response": "Set the XML metadata on a set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set(self, parent_url, fp):\n        url = parent_url + self.client.get_url_path('METADATA', 'POST', 'set', {})\n        r = self.client.request('POST', url, data=fp, headers={'Content-Type': 'text/xml'})\n        if r.status_code not in [200, 201]:\n            raise exceptions.ServerError(\"Expected success response, got %s: %s\" % (r.status_code, url))", "response": "Set the XML metadata for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the XML metadata for this source converted to the requested format.", "response": "def get_xml(self, fp, format=FORMAT_NATIVE):\n        \"\"\"\n        Returns the XML metadata for this source, converted to the requested format.\n        Converted metadata may not contain all the same information as the native format.\n\n        :param file fp: A path, or an open file-like object which the content should be written to.\n        :param str format: desired format for the output. This should be one of the available\n            formats from :py:meth:`.get_formats`, or :py:attr:`.FORMAT_NATIVE` for the native format.\n\n        If you pass this function an open file-like object as the fp parameter, the function will\n        not close that file for you.\n        \"\"\"\n        r = self._client.request('GET', getattr(self, format), stream=True)\n        filename = stream.stream_response_to_file(r, path=fp)\n        return filename"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_formats(self):\n        formats = []\n        for key in (self.FORMAT_DC, self.FORMAT_FGDC, self.FORMAT_ISO):\n            if hasattr(self, key):\n                formats.append(key)\n        return formats", "response": "Return the available format names for this metadata"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_bound(method):\n    @functools.wraps(method)\n    def wrapper(self, *args, **kwargs):\n        if not self._is_bound:\n            raise ValueError(\"%r must be bound to call %s()\" % (self, method.__name__))\n        return method(self, *args, **kwargs)\n    return wrapper", "response": "Decorator that asserts the model instance is bound."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef query_image_id(self, image_id):\n        myquery = {\"primaryfilespec\": image_id}\n        self.create_files_request(myquery, fmt=\"json\")\n        self.unpack_json_response()\n        return self.obsids", "response": "Query OPUS via the image_id. This method returns a list of URLs into the database_path attribute."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a request to get the relevant data from the API.", "response": "def create_request_with_query(self, kind, query, size=\"thumb\", fmt=\"json\"):\n        \"\"\"api/data.[fmt], api/images/[size].[fmt] api/files.[fmt]\n\n        kind = ['data', 'images', 'files']\n\n\n        \"\"\"\n        if kind == \"data\" or kind == \"files\":\n            url = \"{}/{}.{}\".format(base_url, kind, fmt)\n        elif kind == \"images\":\n            url = \"{}/images/{}.{}\".format(base_url, size, fmt)\n        self.url = url\n        self.r = requests.get(url, params=unquote(urlencode(query)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_between_times(self, t1, t2, target=None):\n        try:\n            # checking if times have isoformat() method (datetimes have)\n            t1 = t1.isoformat()\n            t2 = t2.isoformat()\n        except AttributeError:\n            # if not, should already be a string, so do nothing.\n            pass\n        myquery = self._get_time_query(t1, t2)\n        if target is not None:\n            myquery[\"target\"] = target\n        self.create_files_request(myquery, fmt=\"json\")\n        self.unpack_json_response()", "response": "Query OPUS data between times t1 and t2."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef show_images(self, size=\"small\"):\n        d = dict(small=256, med=512, thumb=100, full=1024)\n        try:\n            width = d[size]\n        except KeyError:\n            print(\"Allowed keys:\", d.keys())\n            return\n        img_urls = [i._get_img_url(size) for i in self.obsids]\n        imagesList = \"\".join(\n            [\n                \"<img style='width: {0}px; margin: 0px; float: \"\n                \"left; border: 1px solid black;' \"\n                \"src='{1}' />\".format(width, s)\n                for s in img_urls\n            ]\n        )\n        display(HTML(imagesList))", "response": "Shows preview images using the Jupyter notebook HTML display."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload the previously found and stored Opus obsids.", "response": "def download_results(self, savedir=None, raw=True, calib=False, index=None):\n        \"\"\"Download the previously found and stored Opus obsids.\n\n        Parameters\n        ==========\n        savedir: str or pathlib.Path, optional\n            If the database root folder as defined by the config.ini should not be used,\n            provide a different savedir here. It will be handed to PathManager.\n        \"\"\"\n        obsids = self.obsids if index is None else [self.obsids[index]]\n        for obsid in obsids:\n            pm = io.PathManager(obsid.img_id, savedir=savedir)\n            pm.basepath.mkdir(exist_ok=True)\n            to_download = []\n            if raw is True:\n                to_download.extend(obsid.raw_urls)\n            if calib is True:\n                to_download.extend(obsid.calib_urls)\n            for url in to_download:\n                basename = Path(url).name\n                print(\"Downloading\", basename)\n                store_path = str(pm.basepath / basename)\n                try:\n                    urlretrieve(url, store_path)\n                except Exception as e:\n                    urlretrieve(url.replace(\"https\", \"http\"), store_path)\n            return str(pm.basepath)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download_previews(self, savedir=None):\n        for obsid in self.obsids:\n            pm = io.PathManager(obsid.img_id, savedir=savedir)\n            pm.basepath.mkdir(exist_ok=True)\n            basename = Path(obsid.medium_img_url).name\n            print(\"Downloading\", basename)\n            urlretrieve(obsid.medium_img_url, str(pm.basepath / basename))", "response": "Download preview files for previously found Opus obsids."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef which_epi_janus_resonance(name, time):\n    t1 = Time('2002-01-21').to_datetime()\n    delta = Time(time).to_datetime() - t1\n    yearfraction = delta.days / 365\n    if int(yearfraction / 4) % 2 == 0:\n        return name + '2'\n    else:\n        return name + '1'", "response": "Find which swap situtation we are in by time."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_drafts(self):\n        target_url = self.client.get_url('LAYER', 'GET', 'multidraft')\n        return base.Query(self, target_url)", "response": "A filterable list views of layers returning the draft version of each layer or table."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_versions(self, layer_id):\n        target_url = self.client.get_url('VERSION', 'GET', 'multi', {'layer_id': layer_id})\n        return base.Query(self, target_url, valid_filter_attributes=('data',), valid_sort_attributes=())", "response": "Filterable list of versions of a layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a specific version of a layer.", "response": "def get_version(self, layer_id, version_id, expand=[]):\n        \"\"\"\n        Get a specific version of a layer.\n        \"\"\"\n        target_url = self.client.get_url('VERSION', 'GET', 'single', {'layer_id': layer_id, 'version_id': version_id})\n        return self._get(target_url, expand=expand)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_draft(self, layer_id, expand=[]):\n        target_url = self.client.get_url('VERSION', 'GET', 'draft', {'layer_id': layer_id})\n        return self._get(target_url, expand=expand)", "response": "Get the current draft version of a layer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the latest published version of this layer.", "response": "def get_published(self, layer_id, expand=[]):\n        \"\"\"\n        Get the latest published version of this layer.\n        :raises NotFound: if there is no published version.\n        \"\"\"\n        target_url = self.client.get_url('VERSION', 'GET', 'published', {'layer_id': layer_id})\n        return self._get(target_url, expand=expand)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_draft(self, layer_id):\n        target_url = self.client.get_url('VERSION', 'POST', 'create', {'layer_id': layer_id})\n        r = self.client.request('POST', target_url, json={})\n        return self.create_from_result(r.json())", "response": "Creates a new draft version for the given layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start_import(self, layer_id, version_id):\n        target_url = self.client.get_url('VERSION', 'POST', 'import', {'layer_id': layer_id, 'version_id': version_id})\n        r = self.client.request('POST', target_url, json={})\n        return self.create_from_result(r.json())", "response": "Starts importing the specified draft version."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start_update(self, layer_id):\n        target_url = self.client.get_url('LAYER', 'POST', 'update', {'layer_id': layer_id})\n        r = self.client.request('POST', target_url, json={})\n        return self.parent.create_from_result(r.json())", "response": "Start importing a new version of the layer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_metadata(self, layer_id, version_id, fp):\n        base_url = self.client.get_url('VERSION', 'GET', 'single', {'layer_id': layer_id, 'version_id': version_id})\n        self._metadata.set(base_url, fp)", "response": "Set the XML metadata on a layer draft version."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_published_version(self):\n        pub_ver = getattr(self, 'published_version', None)\n        this_ver = getattr(self, 'this_version', None)\n        return this_ver and pub_ver and (this_ver == pub_ver)", "response": "Return True if this version is the published version of a layer"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if this version is the draft version of a layer", "response": "def is_draft_version(self):\n        \"\"\" Return if this version is the draft version of a layer \"\"\"\n        pub_ver = getattr(self, 'published_version', None)\n        latest_ver = getattr(self, 'latest_version', None)\n        this_ver = getattr(self, 'this_version', None)\n        return this_ver and latest_ver and (this_ver == latest_ver) and (latest_ver != pub_ver)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_versions(self):\n        target_url = self._client.get_url('VERSION', 'GET', 'multi', {'layer_id': self.id})\n        return base.Query(self._manager, target_url, valid_filter_attributes=('data',), valid_sort_attributes=())", "response": "Return a list of versions of a specific version of the layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a specific version of this layer.", "response": "def get_version(self, version_id, expand=[]):\n        \"\"\"\n        Get a specific version of this layer\n        \"\"\"\n        target_url = self._client.get_url('VERSION', 'GET', 'single', {'layer_id': self.id, 'version_id': version_id})\n        return self._manager._get(target_url, expand=expand)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the current draft version of this layer.", "response": "def get_draft_version(self, expand=[]):\n        \"\"\"\n        Get the current draft version of this layer.\n        :raises NotFound: if there is no draft version.\n        \"\"\"\n        target_url = self._client.get_url('VERSION', 'GET', 'draft', {'layer_id': self.id})\n        return self._manager._get(target_url, expand=expand)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start_import(self, version_id=None):\n        if not version_id:\n            version_id = self.version.id\n\n        target_url = self._client.get_url('VERSION', 'POST', 'import', {'layer_id': self.id, 'version_id': version_id})\n        r = self._client.request('POST', target_url, json={})\n        return self._deserialize(r.json(), self._manager)", "response": "Starts importing this draft layerversion."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start_update(self):\n        target_url = self._client.get_url('LAYER', 'POST', 'update', {'layer_id': self.id})\n        r = self._client.request('POST', target_url, json={})\n        return self._manager.create_from_result(r.json())", "response": "A shortcut to create a new version and start importing it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef publish(self, version_id=None):\n        if not version_id:\n            version_id = self.version.id\n\n        target_url = self._client.get_url('VERSION', 'POST', 'publish', {'layer_id': self.id, 'version_id': version_id})\n        r = self._client.request('POST', target_url, json={})\n        return self._client.get_manager(Publish).create_from_result(r.json())", "response": "Creates a publish task just for this version which publishes as soon as any import is complete."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self, with_data=False):\n        target_url = self._client.get_url('VERSION', 'PUT', 'edit', {'layer_id': self.id, 'version_id': self.version.id})\n        r = self._client.request('PUT', target_url, json=self._serialize(with_data=with_data))\n        return self._deserialize(r.json(), self._manager)", "response": "Save this draft layerversion."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_version(self, version_id=None):\n        if not version_id:\n            version_id = self.version.id\n\n        target_url = self._client.get_url('VERSION', 'DELETE', 'single', {'layer_id': self.id, 'version_id': version_id})\n        r = self._client.request('DELETE', target_url)\n        logger.info(\"delete_version(): %s\", r.status_code)", "response": "Deletes this draft version."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_item_class(self, url):\n        if '/layers/' in url:\n            return Layer\n        elif '/tables/' in url:\n            return Table\n        elif '/sets/' in url:\n            return Set\n        # elif '/documents/' in url:\n        #     return Document\n        else:\n            raise NotImplementedError(\"No support for catalog results of type %s\" % url)", "response": "Return the model class matching a URL"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the fraction of the year since moon swap.", "response": "def get_year_since_resonance(ringcube):\n    \"Calculate the fraction of the year since moon swap.\"\n    t0 = dt(2006, 1, 21)\n    td = ringcube.imagetime - t0\n    return td.days / 365.25"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating and return a dict of all the polynomal objects for the current order of the solar prediction.", "response": "def create_polynoms():\n    \"\"\"Create and return poly1d objects.\n\n    Uses the parameters from Morgan to create poly1d objects for\n    calculations.\n    \"\"\"\n    fname = pr.resource_filename('pyciss', 'data/soliton_prediction_parameters.csv')\n    res_df = pd.read_csv(fname)\n    polys = {}\n    for resorder, row in zip('65 54 43 21'.split(),\n                             range(4)):\n        p = poly1d([res_df.loc[row, 'Slope (km/yr)'], res_df.loc[row, 'Intercept (km)']])\n        polys['janus ' + ':'.join(resorder)] = p\n    return polys"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_for_soliton(img_id):\n    pm = io.PathManager(img_id)\n    try:\n        ringcube = RingCube(pm.cubepath)\n    except FileNotFoundError:\n        ringcube = RingCube(pm.undestriped)\n    polys = create_polynoms()\n    minrad = ringcube.minrad.to(u.km)\n    maxrad = ringcube.maxrad.to(u.km)\n    delta_years = get_year_since_resonance(ringcube)\n    soliton_radii = {}\n    for k, p in polys.items():\n        current_r = p(delta_years) * u.km\n        if minrad < current_r < maxrad:\n            soliton_radii[k] = current_r\n    return soliton_radii if soliton_radii else None", "response": "Workhorse function. Returns a dict with all solitons found in a single ISS image."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_manager(self, model):\n        if isinstance(model, six.string_types):\n            # undocumented string lookup\n            for k, m in self._manager_map.items():\n                if k.__name__ == model:\n                    return m\n            else:\n                raise KeyError(model)\n\n        return self._manager_map[model]", "response": "Return the manager instance for the given model."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _assemble_headers(self, method, user_headers=None):\n\n        headers = copy.deepcopy(user_headers or {})\n\n        if method not in ('GET', 'HEAD'):\n            headers.setdefault('Content-Type', 'application/json')\n\n        return headers", "response": "Assemble the headers for the current request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reverse_url(self, datatype, url, verb='GET', urltype='single', api_version=None):\n        api_version = api_version or 'v1'\n        templates = getattr(self, 'URL_TEMPLATES__%s' % api_version)\n\n        # this is fairly simplistic, if necessary we could use the parse lib\n        template_url = r\"https://(?P<api_host>.+)/services/api/(?P<api_version>.+)\"\n        template_url += re.sub(r'{([^}]+)}', r'(?P<\\1>.+)', templates[datatype][verb][urltype])\n        # /foo/{foo_id}/bar/{id}/\n        m = re.match(template_url, url or '')\n        if not m:\n            raise KeyError(\"No reverse match from '%s' to %s.%s.%s\" % (url, datatype, verb, urltype))\n\n        r = m.groupdict()\n        del r['api_host']\n        if r.pop('api_version') != api_version:\n            raise ValueError(\"API version mismatch\")\n        return r", "response": "Returns a dictionary of parameters extracted from a populated URL."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_url(self, datatype, verb, urltype, params={}, api_host=None, api_version=None):\n        api_version = api_version or 'v1'\n        api_host = api_host or self.host\n\n        subst = params.copy()\n        subst['api_host'] = api_host\n        subst['api_version'] = api_version\n\n        url = \"https://{api_host}/services/api/{api_version}\"\n        url += self.get_url_path(datatype, verb, urltype, params, api_version)\n        return url.format(**subst)", "response": "Returns a fully formed url for the current session."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef open_store_variable(self, name, var):\n        data = indexing.LazilyOuterIndexedArray(CDMArrayWrapper(name, self))\n        return Variable(var.dimensions, data, {a: getattr(var, a) for a in var.ncattrs()})", "response": "Turn CDMRemote variable into something like a numpy. ndarray."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the global attributes from underlying data set.", "response": "def get_attrs(self):\n        \"\"\"Get the global attributes from underlying data set.\"\"\"\n        return FrozenOrderedDict((a, getattr(self.ds, a)) for a in self.ds.ncattrs())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_dimensions(self):\n        return FrozenOrderedDict((k, len(v)) for k, v in self.ds.dimensions.items())", "response": "Get the dimensions from underlying data set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _find_base_tds_url(catalog_url):\n    url_components = urlparse(catalog_url)\n    if url_components.path:\n        return catalog_url.split(url_components.path)[0]\n    else:\n        return catalog_url", "response": "Identify the base URL of the THREDDS server from the catalog URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filter_time_nearest(self, time, regex=None):\n        return min(self._get_datasets_with_times(regex),\n                   key=lambda i: abs((i[0] - time).total_seconds()))[-1]", "response": "Filter keys for an item closest to the desired time."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfiltering keys for all items within the specified time range.", "response": "def filter_time_range(self, start, end, regex=None):\n        \"\"\"Filter keys for all items within the desired time range.\n\n        Loops over all keys in the collection and uses `regex` to extract and build\n        `datetime`s. From the collection of `datetime`s, all values within `start` and `end`\n        (inclusive) are returned. If none of the keys in the collection match the regex,\n        indicating that the keys are not date/time-based, a ``ValueError`` is raised.\n\n        Parameters\n        ----------\n        start : ``datetime.datetime``\n            The start of the desired time range, inclusive\n        end : ``datetime.datetime``\n            The end of the desired time range, inclusive\n        regex : str, optional\n            The regular expression to use to extract date/time information from the key. If\n            given, this should contain named groups: 'year', 'month', 'day', 'hour', 'minute',\n            'second', and 'microsecond', as appropriate. When a match is found, any of those\n            groups missing from the pattern will be assigned a value of 0. The default pattern\n            looks for patterns like: 20171118_2356.\n\n        Returns\n        -------\n            All values corresponding to times within the specified range\n\n        \"\"\"\n        return [item[-1] for item in self._get_datasets_with_times(regex)\n                if start <= item[0] <= end]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving and return the value associated with case - insensitive key.", "response": "def pop(self, key, *args, **kwargs):\n        \"\"\"Remove and return the value associated with case-insensitive ``key``.\"\"\"\n        return super(CaseInsensitiveDict, self).pop(CaseInsensitiveStr(key))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _keys_to_lower(self):\n        for k in list(self.keys()):\n            val = super(CaseInsensitiveDict, self).__getitem__(k)\n            super(CaseInsensitiveDict, self).__delitem__(k)\n            self.__setitem__(CaseInsensitiveStr(k), val)", "response": "Convert key set to lowercase."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resolve_url(self, catalog_url):\n        if catalog_url != '':\n            resolver_base = catalog_url.split('catalog.xml')[0]\n            resolver_url = resolver_base + self.url_path\n            resolver_xml = session_manager.urlopen(resolver_url)\n            tree = ET.parse(resolver_xml)\n            root = tree.getroot()\n            if 'name' in root.attrib:\n                self.catalog_name = root.attrib['name']\n            else:\n                self.catalog_name = 'No name found'\n            resolved_url = ''\n            found = False\n            for child in root.iter():\n                if not found:\n                    tag_type = child.tag.split('}')[-1]\n                    if tag_type == 'dataset':\n                        if 'urlPath' in child.attrib:\n                            ds = Dataset(child)\n                            resolved_url = ds.url_path\n                            found = True\n            if found:\n                return resolved_url\n            else:\n                log.warning('no dataset url path found in latest.xml!')", "response": "Resolve the url of the dataset when reading latest. xml."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes fully qualified urls for the access methods enabled on the dataset.", "response": "def make_access_urls(self, catalog_url, all_services, metadata=None):\n        \"\"\"Make fully qualified urls for the access methods enabled on the dataset.\n\n        Parameters\n        ----------\n        catalog_url : str\n            The top level server url\n        all_services : List[SimpleService]\n            list of :class:`SimpleService` objects associated with the dataset\n        metadata : dict\n            Metadata from the :class:`TDSCatalog`\n\n        \"\"\"\n        all_service_dict = CaseInsensitiveDict({})\n        for service in all_services:\n            all_service_dict[service.name] = service\n            if isinstance(service, CompoundService):\n                for subservice in service.services:\n                    all_service_dict[subservice.name] = subservice\n\n        service_name = metadata.get('serviceName', None)\n\n        access_urls = CaseInsensitiveDict({})\n        server_url = _find_base_tds_url(catalog_url)\n\n        # process access urls for datasets that reference top\n        # level catalog services (individual or compound service\n        # types).\n        if service_name in all_service_dict:\n            service = all_service_dict[service_name]\n            if service.service_type != 'Resolver':\n                # if service is a CompoundService, create access url\n                # for each SimpleService\n                if isinstance(service, CompoundService):\n                    for subservice in service.services:\n                        server_base = urljoin(server_url, subservice.base)\n                        access_urls[subservice.service_type] = urljoin(server_base,\n                                                                       self.url_path)\n                else:\n                    server_base = urljoin(server_url, service.base)\n                    access_urls[service.service_type] = urljoin(server_base, self.url_path)\n\n        # process access children of dataset elements\n        for service_type in self.access_element_info:\n            url_path = self.access_element_info[service_type]\n            if service_type in all_service_dict:\n                server_base = urljoin(server_url, all_service_dict[service_type].base)\n                access_urls[service_type] = urljoin(server_base, url_path)\n\n        self.access_urls = access_urls"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_access_element_info(self, access_element):\n        service_name = access_element.attrib['serviceName']\n        url_path = access_element.attrib['urlPath']\n        self.access_element_info[service_name] = url_path", "response": "Create an access method from a catalog element."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads the dataset to a local file.", "response": "def download(self, filename=None):\n        \"\"\"Download the dataset to a local file.\n\n        Parameters\n        ----------\n        filename : str, optional\n            The full path to which the dataset will be saved\n\n        \"\"\"\n        if filename is None:\n            filename = self.name\n        with self.remote_open() as infile:\n            with open(filename, 'wb') as outfile:\n                outfile.write(infile.read())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remote_access(self, service=None, use_xarray=None):\n        if service is None:\n            service = 'CdmRemote' if 'CdmRemote' in self.access_urls else 'OPENDAP'\n\n        if service not in (CaseInsensitiveStr('CdmRemote'), CaseInsensitiveStr('OPENDAP')):\n            raise ValueError(service + ' is not a valid service for remote_access')\n\n        return self.access_with_service(service, use_xarray)", "response": "Open the remote dataset and get a netCDF4 - compatible Dataset object providing index - based subsetting capabilities."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef subset(self, service=None):\n        if service is None:\n            for serviceName in self.ncssServiceNames:\n                if serviceName in self.access_urls:\n                    service = serviceName\n                    break\n            else:\n                raise RuntimeError('Subset access is not available for this dataset.')\n        elif service not in self.ncssServiceNames:\n            raise ValueError(service + ' is not a valid service for subset. Options are: '\n                             + ', '.join(self.ncssServiceNames))\n\n        return self.access_with_service(service)", "response": "Subset the dataset.\n\n        Open the remote dataset and get a client for talking to ``service``.\n\n        Parameters\n        ----------\n        service : str, optional\n            The name of the service for subsetting the dataset. Defaults to 'NetcdfSubset'\n            or 'NetcdfServer', in that order, depending on the services listed in the\n            catalog.\n\n        Returns\n        -------\n        a client for communicating using ``service``"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef access_with_service(self, service, use_xarray=None):\n        service = CaseInsensitiveStr(service)\n        if service == 'CdmRemote':\n            if use_xarray:\n                from .cdmr.xarray_support import CDMRemoteStore\n                try:\n                    import xarray as xr\n                    provider = lambda url: xr.open_dataset(CDMRemoteStore(url))  # noqa: E731\n                except ImportError:\n                    raise ImportError('CdmRemote access needs xarray to be installed.')\n            else:\n                from .cdmr import Dataset as CDMRDataset\n                provider = CDMRDataset\n        elif service == 'OPENDAP':\n            if use_xarray:\n                try:\n                    import xarray as xr\n                    provider = xr.open_dataset\n                except ImportError:\n                    raise ImportError('xarray to be installed if `use_xarray` is True.')\n            else:\n                try:\n                    from netCDF4 import Dataset as NC4Dataset\n                    provider = NC4Dataset\n                except ImportError:\n                    raise ImportError('OPENDAP access needs netCDF4-python to be installed.')\n        elif service in self.ncssServiceNames:\n            from .ncss import NCSS\n            provider = NCSS\n        elif service == 'HTTPServer':\n            provider = session_manager.urlopen\n        else:\n            raise ValueError(service + ' is not an access method supported by Siphon')\n\n        try:\n            return provider(self.access_urls[service])\n        except KeyError:\n            raise ValueError(service + ' is not available for this dataset')", "response": "Access the dataset using a particular service."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets header information and store as metadata for the endpoint.", "response": "def _get_metadata(self):\n        \"\"\"Get header information and store as metadata for the endpoint.\"\"\"\n        self.metadata = self.fetch_header()\n        self.variables = {g.name for g in self.metadata.grids}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking a header request to the endpoint.", "response": "def fetch_header(self):\n        \"\"\"Make a header request to the endpoint.\"\"\"\n        query = self.query().add_query_parameter(req='header')\n        return self._parse_messages(self.get_query(query).content)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch_feature_type(self):\n        query = self.query().add_query_parameter(req='featureType')\n        return self.get_query(query).content", "response": "Request the featureType from the endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npull down coordinate data from the endpoint.", "response": "def fetch_coords(self, query):\n        \"\"\"Pull down coordinate data from the endpoint.\"\"\"\n        q = query.add_query_parameter(req='coord')\n        return self._parse_messages(self.get_query(q).content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_data(self):\n        # Split the list of times into begin and end dates. If only\n        # one date is supplied, set both begin and end dates equal to that date.\n\n        body, header, dates_long, dates = self._get_data_raw()\n\n        params = self._get_fwf_params()\n\n        df_body = pd.read_fwf(StringIO(body), **params['body'])\n        df_header = pd.read_fwf(StringIO(header), **params['header'])\n        df_body['date'] = dates_long\n\n        df_body = self._clean_body_df(df_body)\n        df_header = self._clean_header_df(df_header)\n        df_header['date'] = dates\n\n        return df_body, df_header", "response": "Process the IGRA2 text file for observations at site_id matching time."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload observations matching the time range.", "response": "def _get_data_raw(self):\n        \"\"\"Download observations matching the time range.\n\n        Returns a tuple with a string for the body, string for the headers,\n        and a list of dates.\n        \"\"\"\n        # Import need to be here so we can monkeypatch urlopen for testing and avoid\n        # downloading live data for testing\n        try:\n            from urllib.request import urlopen\n        except ImportError:\n            from urllib2 import urlopen\n\n        with closing(urlopen(self.ftpsite + self.site_id + self.suffix + '.zip')) as url:\n            f = ZipFile(BytesIO(url.read()), 'r').open(self.site_id + self.suffix)\n\n        lines = [line.decode('utf-8') for line in f.readlines()]\n\n        body, header, dates_long, dates = self._select_date_range(lines)\n\n        return body, header, dates_long, dates"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nselects the time range of the IGRA2 data file.", "response": "def _select_date_range(self, lines):\n        \"\"\"Identify lines containing headers within the range begin_date to end_date.\n\n        Parameters\n        -----\n        lines: list\n            list of lines from the IGRA2 data file.\n\n        \"\"\"\n        headers = []\n        num_lev = []\n        dates = []\n\n        # Get indices of headers, and make a list of dates and num_lev\n        for idx, line in enumerate(lines):\n            if line[0] == '#':\n                year, month, day, hour = map(int, line[13:26].split())\n\n                # All soundings have YMD, most have hour\n                try:\n                    date = datetime.datetime(year, month, day, hour)\n                except ValueError:\n                    date = datetime.datetime(year, month, day)\n\n                # Check date\n                if self.begin_date <= date <= self.end_date:\n                    headers.append(idx)\n                    num_lev.append(int(line[32:36]))\n                    dates.append(date)\n                if date > self.end_date:\n                    break\n\n        if len(dates) == 0:\n            # Break if no matched dates.\n            # Could improve this later by showing the date range for the station.\n            raise ValueError('No dates match selection.')\n\n        # Compress body of data into a string\n        begin_idx = min(headers)\n        end_idx = max(headers) + num_lev[-1]\n\n        # Make a boolean vector that selects only list indices within the time range\n        selector = np.zeros(len(lines), dtype=bool)\n        selector[begin_idx:end_idx + 1] = True\n        selector[headers] = False\n        body = ''.join([line for line in itertools.compress(lines, selector)])\n\n        selector[begin_idx:end_idx + 1] = ~selector[begin_idx:end_idx + 1]\n        header = ''.join([line for line in itertools.compress(lines, selector)])\n\n        # expand date vector to match length of the body dataframe.\n        dates_long = np.repeat(dates, num_lev)\n\n        return body, header, dates_long, dates"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_fwf_params(self):\n        def _cdec(power=1):\n            \"\"\"Make a function to convert string 'value*10^power' to float.\"\"\"\n            def _cdec_power(val):\n                if val in ['-9999', '-8888', '-99999']:\n                    return np.nan\n                else:\n                    return float(val) / 10**power\n            return _cdec_power\n\n        def _cflag(val):\n            \"\"\"Replace alphabetic flags A and B with numeric.\"\"\"\n            if val == 'A':\n                return 1\n            elif val == 'B':\n                return 2\n            else:\n                return 0\n\n        def _ctime(strformat='MMMSS'):\n            \"\"\"Return a function converting a string from MMMSS or HHMM to seconds.\"\"\"\n            def _ctime_strformat(val):\n                time = val.strip().zfill(5)\n\n                if int(time) < 0:\n                    return np.nan\n                elif int(time) == 9999:\n                    return np.nan\n                else:\n                    if strformat == 'MMMSS':\n                        minutes = int(time[0:3])\n                        seconds = int(time[3:5])\n                        time_seconds = minutes * 60 + seconds\n                    elif strformat == 'HHMM':\n                        hours = int(time[0:2])\n                        minutes = int(time[2:4])\n                        time_seconds = hours * 3600 + minutes * 60\n                    else:\n                        sys.exit('Unrecognized time format')\n\n                return time_seconds\n            return _ctime_strformat\n\n        def _clatlon(x):\n            n = len(x)\n            deg = x[0:n - 4]\n            dec = x[n - 4:]\n            return float(deg + '.' + dec)\n\n        if self.suffix == '-drvd.txt':\n            names_body = ['pressure', 'reported_height', 'calculated_height',\n                          'temperature', 'temperature_gradient', 'potential_temperature',\n                          'potential_temperature_gradient', 'virtual_temperature',\n                          'virtual_potential_temperature', 'vapor_pressure',\n                          'saturation_vapor_pressure', 'reported_relative_humidity',\n                          'calculated_relative_humidity', 'u_wind', 'u_wind_gradient',\n                          'v_wind', 'v_wind_gradient', 'refractive_index']\n\n            colspecs_body = [(0, 7), (8, 15), (16, 23), (24, 31), (32, 39),\n                             (40, 47), (48, 55), (56, 63), (64, 71), (72, 79),\n                             (80, 87), (88, 95), (96, 103), (104, 111), (112, 119),\n                             (120, 127), (128, 135), (137, 143), (144, 151)]\n\n            conv_body = {'pressure': _cdec(power=2),\n                         'reported_height': int,\n                         'calculated_height': int,\n                         'temperature': _cdec(),\n                         'temperature_gradient': _cdec(),\n                         'potential_temperature': _cdec(),\n                         'potential_temperature_gradient': _cdec(),\n                         'virtual_temperature': _cdec(),\n                         'virtual_potential_temperature': _cdec(),\n                         'vapor_pressure': _cdec(power=3),\n                         'saturation_vapor_pressure': _cdec(power=3),\n                         'reported_relative_humidity': _cdec(),\n                         'calculated_relative_humidity': _cdec(),\n                         'u_wind': _cdec(),\n                         'u_wind_gradient': _cdec(),\n                         'v_wind': _cdec(),\n                         'v_wind_gradient': _cdec(),\n                         'refractive_index': int}\n\n            names_header = ['site_id', 'year', 'month', 'day', 'hour', 'release_time',\n                            'number_levels', 'precipitable_water', 'inv_pressure',\n                            'inv_height', 'inv_strength', 'mixed_layer_pressure',\n                            'mixed_layer_height', 'freezing_point_pressure',\n                            'freezing_point_height', 'lcl_pressure', 'lcl_height',\n                            'lfc_pressure', 'lfc_height', 'lnb_pressure', 'lnb_height',\n                            'lifted_index', 'showalter_index', 'k_index', 'total_totals_index',\n                            'cape', 'convective_inhibition']\n\n            colspecs_header = [(1, 12), (13, 17), (18, 20), (21, 23), (24, 26),\n                               (27, 31), (31, 36), (37, 43), (43, 48), (49, 55),\n                               (55, 61), (61, 67), (67, 73), (73, 79), (79, 85),\n                               (85, 91), (91, 97), (97, 103), (103, 109), (109, 115),\n                               (115, 121), (121, 127), (127, 133), (133, 139),\n                               (139, 145), (145, 151), (151, 157)]\n\n            conv_header = {'site_id': str,\n                           'year': int,\n                           'month': int,\n                           'day': int,\n                           'hour': int,\n                           'release_time': _ctime(strformat='HHMM'),\n                           'number_levels': int,\n                           'precipitable_water': _cdec(power=2),\n                           'inv_pressure': _cdec(power=2),\n                           'inv_height': int,\n                           'inv_strength': _cdec(),\n                           'mixed_layer_pressure': _cdec(power=2),\n                           'mixed_layer_height': int,\n                           'freezing_point_pressure': _cdec(power=2),\n                           'freezing_point_height': int,\n                           'lcl_pressure': _cdec(power=2),\n                           'lcl_height': int,\n                           'lfc_pressure': _cdec(power=2),\n                           'lfc_height': int,\n                           'lnb_pressure': _cdec(power=2),\n                           'lnb_height': int,\n                           'lifted_index': int,\n                           'showalter_index': int,\n                           'k_index': int,\n                           'total_totals_index': int,\n                           'cape': int,\n                           'convective_inhibition': int}\n\n            na_vals = ['-99999']\n\n        else:\n            names_body = ['lvltyp1', 'lvltyp2', 'etime', 'pressure',\n                          'pflag', 'height', 'zflag', 'temperature', 'tflag',\n                          'relative_humidity', 'dewpoint_depression',\n                          'direction', 'speed']\n\n            colspecs_body = [(0, 1), (1, 2), (3, 8), (9, 15), (15, 16),\n                             (16, 21), (21, 22), (22, 27), (27, 28),\n                             (28, 33), (34, 39), (40, 45), (46, 51)]\n\n            conv_body = {'lvltyp1': int,\n                         'lvltyp2': int,\n                         'etime': _ctime(strformat='MMMSS'),\n                         'pressure': _cdec(power=2),\n                         'pflag': _cflag,\n                         'height': int,\n                         'zflag': _cflag,\n                         'temperature': _cdec(),\n                         'tflag': _cflag,\n                         'relative_humidity': _cdec(),\n                         'dewpoint_depression': _cdec(),\n                         'direction': int,\n                         'speed': _cdec()}\n\n            names_header = ['site_id', 'year', 'month', 'day', 'hour', 'release_time',\n                            'number_levels', 'pressure_source_code',\n                            'non_pressure_source_code',\n                            'latitude', 'longitude']\n\n            colspecs_header = [(1, 12), (13, 17), (18, 20), (21, 23), (24, 26),\n                               (27, 31), (32, 36), (37, 45), (46, 54), (55, 62), (63, 71)]\n\n            na_vals = ['-8888', '-9999']\n\n            conv_header = {'release_time': _ctime(strformat='HHMM'),\n                           'number_levels': int,\n                           'latitude': _clatlon,\n                           'longitude': _clatlon}\n\n        return {'body': {'names': names_body,\n                         'colspecs': colspecs_body,\n                         'converters': conv_body,\n                         'na_values': na_vals,\n                         'index_col': False},\n                'header': {'names': names_header,\n                           'colspecs': colspecs_header,\n                           'converters': conv_header,\n                           'na_values': na_vals,\n                           'index_col': False}}", "response": "Return a dictionary with names colspecs and dtype for IGRA2 data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats the dataframe remove empty rows and add units attribute.", "response": "def _clean_body_df(self, df):\n        \"\"\"Format the dataframe, remove empty rows, and add units attribute.\"\"\"\n        if self.suffix == '-drvd.txt':\n            df = df.dropna(subset=('temperature', 'reported_relative_humidity',\n                           'u_wind', 'v_wind'), how='all').reset_index(drop=True)\n\n            df.units = {'pressure': 'hPa',\n                        'reported_height': 'meter',\n                        'calculated_height': 'meter',\n                        'temperature': 'Kelvin',\n                        'temperature_gradient': 'Kelvin / kilometer',\n                        'potential_temperature': 'Kelvin',\n                        'potential_temperature_gradient': 'Kelvin / kilometer',\n                        'virtual_temperature': 'Kelvin',\n                        'virtual_potential_temperature': 'Kelvin',\n                        'vapor_pressure': 'Pascal',\n                        'saturation_vapor_pressure': 'Pascal',\n                        'reported_relative_humidity': 'percent',\n                        'calculated_relative_humidity': 'percent',\n                        'u_wind': 'meter / second',\n                        'u_wind_gradient': '(meter / second) / kilometer)',\n                        'v_wind': 'meter / second',\n                        'v_wind_gradient': '(meter / second) / kilometer)',\n                        'refractive_index': 'unitless'}\n\n        else:\n            df['u_wind'], df['v_wind'] = get_wind_components(df['speed'],\n                                                             np.deg2rad(df['direction']))\n            df['u_wind'] = np.round(df['u_wind'], 1)\n            df['v_wind'] = np.round(df['v_wind'], 1)\n\n            df = df.dropna(subset=('temperature', 'direction', 'speed',\n                           'dewpoint_depression', 'u_wind', 'v_wind'),\n                           how='all').reset_index(drop=True)\n\n            df['dewpoint'] = df['temperature'] - df['dewpoint_depression']\n\n            df.drop('dewpoint_depression', axis=1, inplace=True)\n\n            df.units = {'etime': 'second',\n                        'pressure': 'hPa',\n                        'height': 'meter',\n                        'temperature': 'degC',\n                        'dewpoint': 'degC',\n                        'direction': 'degrees',\n                        'speed': 'meter / second',\n                        'u_wind': 'meter / second',\n                        'v_wind': 'meter / second'}\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nformat the header dataframe and add units.", "response": "def _clean_header_df(self, df):\n        \"\"\"Format the header dataframe and add units.\"\"\"\n        if self.suffix == '-drvd.txt':\n            df.units = {'release_time': 'second',\n                        'precipitable_water': 'millimeter',\n                        'inv_pressure': 'hPa',\n                        'inv_height': 'meter',\n                        'inv_strength': 'Kelvin',\n                        'mixed_layer_pressure': 'hPa',\n                        'mixed_layer_height': 'meter',\n                        'freezing_point_pressure': 'hPa',\n                        'freezing_point_height': 'meter',\n                        'lcl_pressure': 'hPa',\n                        'lcl_height': 'meter',\n                        'lfc_pressure': 'hPa',\n                        'lfc_height': 'meter',\n                        'lnb_pressure': 'hPa',\n                        'lnb_height': 'meter',\n                        'lifted_index': 'degC',\n                        'showalter_index': 'degC',\n                        'k_index': 'degC',\n                        'total_totals_index': 'degC',\n                        'cape': 'Joule / kilogram',\n                        'convective_inhibition': 'Joule / kilogram'}\n\n        else:\n            df.units = {'release_time': 'second',\n                        'latitude': 'degrees',\n                        'longitude': 'degrees'}\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef realtime_observations(cls, buoy, data_type='txt'):\n        endpoint = cls()\n        parsers = {'txt': endpoint._parse_met,\n                   'drift': endpoint._parse_drift,\n                   'cwind': endpoint._parse_cwind,\n                   'spec': endpoint._parse_spec,\n                   'ocean': endpoint._parse_ocean,\n                   'srad': endpoint._parse_srad,\n                   'dart': endpoint._parse_dart,\n                   'supl': endpoint._parse_supl,\n                   'rain': endpoint._parse_rain}\n\n        if data_type not in parsers:\n            raise KeyError('Data type must be txt, drift, cwind, spec, ocean, srad, dart,'\n                           'supl, or rain for parsed realtime data.')\n\n        raw_data = endpoint.raw_buoy_data(buoy, data_type=data_type)\n        return parsers[data_type](raw_data)", "response": "Retrieve the realtime buoy data from NDBC."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the standard meteorological data from NDBC buoys.", "response": "def _parse_met(content):\n        \"\"\"Parse standard meteorological data from NDBC buoys.\n\n        Parameters\n        ----------\n        content : str\n            Data to parse\n\n        Returns\n        -------\n            :class:`pandas.DataFrame` containing the data\n\n        \"\"\"\n        col_names = ['year', 'month', 'day', 'hour', 'minute',\n                     'wind_direction', 'wind_speed', 'wind_gust',\n                     'wave_height', 'dominant_wave_period', 'average_wave_period',\n                     'dominant_wave_direction', 'pressure',\n                     'air_temperature', 'water_temperature', 'dewpoint',\n                     'visibility', '3hr_pressure_tendency', 'water_level_above_mean']\n\n        col_units = {'wind_direction': 'degrees',\n                     'wind_speed': 'meters/second',\n                     'wind_gust': 'meters/second',\n                     'wave_height': 'meters',\n                     'dominant_wave_period': 'seconds',\n                     'average_wave_period': 'seconds',\n                     'dominant_wave_direction': 'degrees',\n                     'pressure': 'hPa',\n                     'air_temperature': 'degC',\n                     'water_temperature': 'degC',\n                     'dewpoint': 'degC',\n                     'visibility': 'nautical_mile',\n                     '3hr_pressure_tendency': 'hPa',\n                     'water_level_above_mean': 'feet',\n                     'time': None}\n\n        df = pd.read_table(StringIO(content), comment='#', na_values='MM',\n                           names=col_names, sep=r'\\s+')\n        df['time'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']], utc=True)\n        df = df.drop(columns=['year', 'month', 'day', 'hour', 'minute'])\n        df.units = col_units\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_supl(content):\n        col_names = ['year', 'month', 'day', 'hour', 'minute',\n                     'hourly_low_pressure', 'hourly_low_pressure_time',\n                     'hourly_high_wind', 'hourly_high_wind_direction',\n                     'hourly_high_wind_time']\n\n        col_units = {'hourly_low_pressure': 'hPa',\n                     'hourly_low_pressure_time': None,\n                     'hourly_high_wind': 'meters/second',\n                     'hourly_high_wind_direction': 'degrees',\n                     'hourly_high_wind_time': None,\n                     'time': None}\n\n        df = pd.read_table(StringIO(content), comment='#', na_values='MM',\n                           names=col_names, sep=r'\\s+')\n\n        df['time'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']], utc=True)\n\n        df['hours'] = np.floor(df['hourly_low_pressure_time'] / 100)\n        df['minutes'] = df['hourly_low_pressure_time'] - df['hours'] * 100\n        df['hours'] = df['hours'].replace(99, np.nan)\n        df['minutes'] = df['minutes'].replace(99, np.nan)\n        df['hourly_low_pressure_time'] = pd.to_datetime(df[['year', 'month', 'day', 'hours',\n                                                            'minutes']], utc=True)\n\n        df['hours'] = np.floor(df['hourly_high_wind_time'] / 100)\n        df['minutes'] = df['hourly_high_wind_time'] - df['hours'] * 100\n        df['hours'] = df['hours'].replace(99, np.nan)\n        df['minutes'] = df['minutes'].replace(99, np.nan)\n        df['hourly_high_wind_time'] = pd.to_datetime(df[['year', 'month', 'day',\n                                                         'hours', 'minutes']], utc=True)\n        df = df.drop(columns=['year', 'month', 'day', 'hour', 'minute', 'hours', 'minutes'])\n        df.units = col_units\n        return df", "response": "Parse supplemental measurements data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if a url is valid or not.", "response": "def _check_if_url_valid(url):\n        \"\"\"Check if a url is valid (returns 200) or not.\n\n        Parameters\n        ----------\n        url : str\n            URL to check\n\n        Returns\n        -------\n            bool if url is valid\n\n        \"\"\"\n        r = requests.head(url)\n        if r.status_code == 200:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine which types of data are available for a given buoy.", "response": "def buoy_data_types(cls, buoy):\n        \"\"\"Determine which types of data are available for a given buoy.\n\n        Parameters\n        ----------\n        buoy : str\n            Buoy name\n\n        Returns\n        -------\n            dict of valid file extensions and their descriptions\n\n        \"\"\"\n        endpoint = cls()\n        file_types = {'txt': 'standard meteorological data',\n                      'drift': 'meteorological data from drifting buoys and limited moored'\n                               'buoy data mainly from international partners',\n                      'cwind': 'continuous wind data (10 minute average)',\n                      'spec': 'spectral wave summaries',\n                      'data_spec': 'raw spectral wave data',\n                      'swdir': 'spectral wave data (alpha1)',\n                      'swdir2': 'spectral wave data (alpha2)',\n                      'swr1': 'spectral wave data (r1)',\n                      'swr2': 'spectral wave data (r2)',\n                      'adcp': 'acoustic doppler current profiler',\n                      'ocean': 'oceanographic data',\n                      'tide': 'tide data',\n                      'srad': 'solar radiation data',\n                      'dart': 'water column height',\n                      'supl': 'supplemental measurements data',\n                      'rain': 'hourly rain data'}\n        available_data = {}\n        buoy_url = 'https://www.ndbc.noaa.gov/data/realtime2/' + buoy + '.'\n        for key in file_types:\n            if endpoint._check_if_url_valid(buoy_url + key):\n                available_data[key] = file_types[key]\n        return available_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef raw_buoy_data(cls, buoy, data_type='txt'):\n        endpoint = cls()\n        resp = endpoint.get_path('data/realtime2/{}.{}'.format(buoy, data_type))\n        return resp.text", "response": "Retrieve the raw buoy data from NDBC."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_session(self):\n        ret = requests.Session()\n        ret.headers['User-Agent'] = self.user_agent\n        for k, v in self.options.items():\n            setattr(ret, k, v)\n        return ret", "response": "Create a new HTTP session with our user - agent set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef urlopen(self, url, **kwargs):\n        return BytesIO(self.create_session().get(url, **kwargs).content)", "response": "A thin wrapper around requests. Session. get that returns a file - like object that is wrapped around the resulting content."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a latitude and longitude bounding box to the query.", "response": "def lonlat_box(self, west, east, south, north):\n        \"\"\"Add a latitude/longitude bounding box to the query.\n\n        This adds a request for a spatial bounding box, bounded by ('north', 'south')\n        for latitude and ('east', 'west') for the longitude. This modifies the query\n        in-place, but returns `self` so that multiple queries can be chained together\n        on one line.\n\n        This replaces any existing spatial queries that have been set.\n\n        Parameters\n        ----------\n        west: float\n            The bounding longitude to the west, in degrees east of the prime meridian\n        east : float\n            The bounding longitude to the east, in degrees east of the prime meridian\n        south : float\n            The bounding latitude to the south, in degrees north of the equator\n        north : float\n            The bounding latitude to the north, in degrees north of the equator\n\n        Returns\n        -------\n        self : DataQuery\n            Returns self for chaining calls\n\n        \"\"\"\n        self._set_query(self.spatial_query, west=west, east=east, south=south,\n                        north=north)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lonlat_point(self, lon, lat):\n        self._set_query(self.spatial_query, longitude=lon, latitude=lat)\n        return self", "response": "Add a latitude point to the query."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef time(self, time):\n        self._set_query(self.time_query, time=self._format_time(time))\n        return self", "response": "Add a request for a specific time to the query."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef time_range(self, start, end):\n        self._set_query(self.time_query, time_start=self._format_time(start),\n                        time_end=self._format_time(end))\n        return self", "response": "Add a request for a time range to the query."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking a GET request including a query to the endpoint.", "response": "def get_query(self, query):\n        \"\"\"Make a GET request, including a query, to the endpoint.\n\n        The path of the request is to the base URL assigned to the endpoint.\n\n        Parameters\n        ----------\n        query : DataQuery\n            The query to pass when making the request\n\n        Returns\n        -------\n        resp : requests.Response\n            The server's response to the request\n\n        See Also\n        --------\n        get_path, get\n\n        \"\"\"\n        url = self._base[:-1] if self._base[-1] == '/' else self._base\n        return self.get(url, query)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_path(self, path, query=None):\n        return self.get(self.url_path(path), query)", "response": "Make a GET request optionally including a query to a relative path."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake a GET request to the server.", "response": "def get(self, path, params=None):\n        \"\"\"Make a GET request, optionally including a parameters, to a path.\n\n        The path of the request is the full URL.\n\n        Parameters\n        ----------\n        path : str\n            The URL to request\n        params : DataQuery, optional\n            The query to pass when making the request\n\n        Returns\n        -------\n        resp : requests.Response\n            The server's response to the request\n\n        Raises\n        ------\n        HTTPError\n            If the server returns anything other than a 200 (OK) code\n\n        See Also\n        --------\n        get_query, get\n\n        \"\"\"\n        resp = self._session.get(path, params=params)\n        if resp.status_code != 200:\n            if resp.headers.get('Content-Type', '').startswith('text/html'):\n                text = resp.reason\n            else:\n                text = resp.text\n            raise requests.HTTPError('Error accessing {0}\\n'\n                                     'Server Error ({1:d}: {2})'.format(resp.request.url,\n                                                                        resp.status_code,\n                                                                        text))\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef path(self):\n        # If root, return '/'\n        if self.dataset is self:\n            return ''\n        else:  # Otherwise recurse\n            return self.dataset.path + '/' + self.name", "response": "Return the full path to the Group including any parent Groups."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_from_stream(self, group):\n        self._unpack_attrs(group.atts)\n        self.name = group.name\n\n        for dim in group.dims:\n            new_dim = Dimension(self, dim.name)\n            self.dimensions[dim.name] = new_dim\n            new_dim.load_from_stream(dim)\n\n        for var in group.vars:\n            new_var = Variable(self, var.name)\n            self.variables[var.name] = new_var\n            new_var.load_from_stream(var)\n\n        for grp in group.groups:\n            new_group = Group(self)\n            self.groups[grp.name] = new_group\n            new_group.load_from_stream(grp)\n\n        for struct in group.structs:\n            new_var = Variable(self, struct.name)\n            self.variables[struct.name] = new_var\n            new_var.load_from_stream(struct)\n\n        if group.enumTypes:\n            for en in group.enumTypes:\n                self.types[en.name] = enum.Enum(en.name,\n                                                [(typ.value, typ.code) for typ in en.map])", "response": "Load a Group from an NCStream object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_from_stream(self, var):\n        dims = []\n        for d in var.shape:\n            dim = Dimension(None, d.name)\n            dim.load_from_stream(d)\n            dims.append(dim)\n\n        self.dimensions = tuple(dim.name for dim in dims)\n        self.shape = tuple(dim.size for dim in dims)\n        self.ndim = len(var.shape)\n        self._unpack_attrs(var.atts)\n\n        data, dt, type_name = unpack_variable(var)\n        if data is not None:\n            data = data.reshape(self.shape)\n        self._data = data\n        self.dtype = dt\n        self.datatype = type_name\n\n        if hasattr(var, 'enumType') and var.enumType:\n            self.datatype = var.enumType\n            self._enum = True", "response": "Populate the Variable from an NCStream object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_from_stream(self, dim):\n        self.unlimited = dim.isUnlimited\n        self.private = dim.isPrivate\n        self.vlen = dim.isVlen\n        if not self.vlen:\n            self.size = dim.length", "response": "Load from an NCStream object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _read_header(self):\n        self._header = self.cdmrf.fetch_header()\n        self.load_from_stream(self._header)", "response": "Get the needed header information to initialize dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_from_stream(self, header):\n        self._unpack_attrs(header.atts)\n        self.name = header.name\n        self.lon_lat_domain = header.latlonRect\n        self.proj_domain = header.projRect\n        self.date_range = header.dateRange\n        self.type = header.coverageType\n\n        for sys in header.coordSys:\n            self.coord_systems[sys.name] = sys\n\n        for trans in header.coordTransforms:\n            self.transforms[trans.name] = trans\n\n        for ax in header.coordAxes:\n            self.axes[ax.name] = ax\n\n        for cov in header.grids:\n            self.grids[cov.name] = cov", "response": "Populate the CoverageDataset from the protobuf information."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrequesting data from Iowa State s archive for a single station.", "response": "def request_data(cls, time, site_id, **kwargs):\n        \"\"\"Retrieve upper air observations from Iowa State's archive for a single station.\n\n        Parameters\n        ----------\n        time : datetime\n            The date and time of the desired observation.\n\n        site_id : str\n            The three letter ICAO identifier of the station for which data should be\n            downloaded.\n\n        kwargs\n            Arbitrary keyword arguments to use to initialize source\n\n        Returns\n        -------\n            :class:`pandas.DataFrame` containing the data\n\n        \"\"\"\n        endpoint = cls()\n        df = endpoint._get_data(time, site_id, None, **kwargs)\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef request_all_data(cls, time, pressure=None, **kwargs):\n        endpoint = cls()\n        df = endpoint._get_data(time, None, pressure, **kwargs)\n        return df", "response": "Request all data from the Iowa State s archive for all stations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_data(self, time, site_id, pressure=None):\n        json_data = self._get_data_raw(time, site_id, pressure)\n        data = {}\n        for profile in json_data['profiles']:\n            for pt in profile['profile']:\n                for field in ('drct', 'dwpc', 'hght', 'pres', 'sknt', 'tmpc'):\n                    data.setdefault(field, []).append(np.nan if pt[field] is None\n                                                      else pt[field])\n                for field in ('station', 'valid'):\n                    data.setdefault(field, []).append(np.nan if profile[field] is None\n                                                      else profile[field])\n\n        # Make sure that the first entry has a valid temperature and dewpoint\n        idx = np.argmax(~(np.isnan(data['tmpc']) | np.isnan(data['dwpc'])))\n\n        # Stuff data into a pandas dataframe\n        df = pd.DataFrame()\n        df['pressure'] = ma.masked_invalid(data['pres'][idx:])\n        df['height'] = ma.masked_invalid(data['hght'][idx:])\n        df['temperature'] = ma.masked_invalid(data['tmpc'][idx:])\n        df['dewpoint'] = ma.masked_invalid(data['dwpc'][idx:])\n        df['direction'] = ma.masked_invalid(data['drct'][idx:])\n        df['speed'] = ma.masked_invalid(data['sknt'][idx:])\n        df['station'] = data['station'][idx:]\n        df['time'] = [datetime.strptime(valid, '%Y-%m-%dT%H:%M:%SZ')\n                      for valid in data['valid'][idx:]]\n\n        # Calculate the u and v winds\n        df['u_wind'], df['v_wind'] = get_wind_components(df['speed'],\n                                                         np.deg2rad(df['direction']))\n\n        # Drop any rows with all NaN values for T, Td, winds\n        df = df.dropna(subset=('temperature', 'dewpoint', 'direction', 'speed',\n                               'u_wind', 'v_wind'), how='all').reset_index(drop=True)\n\n        # Add unit dictionary\n        df.units = {'pressure': 'hPa',\n                    'height': 'meter',\n                    'temperature': 'degC',\n                    'dewpoint': 'degC',\n                    'direction': 'degrees',\n                    'speed': 'knot',\n                    'u_wind': 'knot',\n                    'v_wind': 'knot',\n                    'station': None,\n                    'time': None}\n        return df", "response": "Download data from Iowa State s upper air archive."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading data from the Iowa State s upper air archive.", "response": "def _get_data_raw(self, time, site_id, pressure=None):\n        r\"\"\"Download data from the Iowa State's upper air archive.\n\n        Parameters\n        ----------\n        time : datetime\n            Date and time for which data should be downloaded\n        site_id : str\n            Site id for which data should be downloaded\n        pressure : float, optional\n            Mandatory pressure level at which to request data (in hPa).\n\n        Returns\n        -------\n        list of json data\n\n        \"\"\"\n        query = {'ts': time.strftime('%Y%m%d%H00')}\n        if site_id is not None:\n            query['station'] = site_id\n        if pressure is not None:\n            query['pressure'] = pressure\n\n        resp = self.get_path('raob.py', query)\n        json_data = json.loads(resp.text)\n\n        # See if the return is valid, but has no data\n        if not (json_data['profiles'] and json_data['profiles'][0]['profile']):\n            message = 'No data available '\n            if time is not None:\n                message += 'for {time:%Y-%m-%d %HZ} '.format(time=time)\n            if site_id is not None:\n                message += 'for station {stid}'.format(stid=site_id)\n            if pressure is not None:\n                message += 'for pressure {pres}'.format(pres=pressure)\n            message = message[:-1] + '.'\n            raise ValueError(message)\n        return json_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses station list XML file.", "response": "def parse_station_table(root):\n    \"\"\"Parse station list XML file.\"\"\"\n    stations = [parse_xml_station(elem) for elem in root.findall('station')]\n    return {st.id: st for st in stations}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_xml_station(elem):\n    stid = elem.attrib['id']\n    name = elem.find('name').text\n    lat = float(elem.find('latitude').text)\n    lon = float(elem.find('longitude').text)\n    elev = float(elem.find('elevation').text)\n    return Station(id=stid, elevation=elev, latitude=lat, longitude=lon, name=name)", "response": "Create a : class : Station instance from an XML tag."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stations(self, *stns):\n        self._set_query(self.spatial_query, stn=stns)\n        return self", "response": "Set one or more stations for the query."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating a query. Determines whether `query` is well-formed. This includes checking for all required parameters, as well as checking parameters for valid values. Parameters ---------- query : RadarQuery The query to validate Returns ------- valid : bool Whether `query` is valid.", "response": "def validate_query(self, query):\n        \"\"\"Validate a query.\n\n        Determines whether `query` is well-formed. This includes checking for all\n        required parameters, as well as checking parameters for valid values.\n\n        Parameters\n        ----------\n        query : RadarQuery\n            The query to validate\n\n        Returns\n        -------\n        valid : bool\n            Whether `query` is valid.\n\n        \"\"\"\n        valid = True\n        # Make sure all stations are in the table\n        if 'stn' in query.spatial_query:\n            valid = valid and all(stid in self.stations\n                                  for stid in query.spatial_query['stn'])\n\n        if query.var:\n            valid = valid and all(var in self.variables for var in query.var)\n\n        return valid"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch a parsed THREDDS catalog from the radar server given the parameters in query and returns a TDSCatalog instance.", "response": "def get_catalog(self, query):\n        \"\"\"Fetch a parsed THREDDS catalog from the radar server.\n\n        Requests a catalog of radar data files data from the radar server given the\n        parameters in `query` and returns a :class:`~siphon.catalog.TDSCatalog` instance.\n\n        Parameters\n        ----------\n        query : RadarQuery\n            The parameters to send to the radar server\n\n        Returns\n        -------\n        catalog : TDSCatalog\n            The catalog of matching data files\n\n        Raises\n        ------\n        :class:`~siphon.http_util.BadQueryError`\n            When the query cannot be handled by the server\n\n        See Also\n        --------\n        get_catalog_raw\n\n        \"\"\"\n        # TODO: Refactor TDSCatalog so we don't need two requests, or to do URL munging\n        try:\n            url = self._base[:-1] if self._base[-1] == '/' else self._base\n            url += '?' + str(query)\n            return TDSCatalog(url)\n        except ET.ParseError:\n            raise BadQueryError(self.get_catalog_raw(query))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef acis_request(method, params):\n    base_url = 'http://data.rcc-acis.org/'  # ACIS Web API URL\n\n    timeout = 300 if method == 'MultiStnData' else 60\n\n    try:\n        response = session_manager.create_session().post(base_url + method, json=params,\n                                                         timeout=timeout)\n        return response.json()\n    except requests.exceptions.Timeout:\n        raise AcisApiException('Connection Timeout')\n    except requests.exceptions.TooManyRedirects:\n        raise AcisApiException('Bad URL. Check your ACIS connection method string.')\n    except ValueError:\n        raise AcisApiException('No data returned! The ACIS parameter dictionary'\n                               'may be incorrectly formatted')", "response": "This function is used to make a request to the ACIS Web Services API for data based on a given method and parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses XML data returned by NCSS.", "response": "def parse_xml(data, handle_units):\n    \"\"\"Parse XML data returned by NCSS.\"\"\"\n    root = ET.fromstring(data)\n    return squish(parse_xml_dataset(root, handle_units))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_xml_point(elem):\n    point = {}\n    units = {}\n    for data in elem.findall('data'):\n        name = data.get('name')\n        unit = data.get('units')\n        point[name] = float(data.text) if name != 'date' else parse_iso_date(data.text)\n        if unit:\n            units[name] = unit\n    return point, units", "response": "Parse an XML point tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncombines multiple Point tags into an array.", "response": "def combine_xml_points(l, units, handle_units):\n    \"\"\"Combine multiple Point tags into an array.\"\"\"\n    ret = {}\n    for item in l:\n        for key, value in item.items():\n            ret.setdefault(key, []).append(value)\n\n    for key, value in ret.items():\n        if key != 'date':\n            ret[key] = handle_units(value, units.get(key, None))\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a netCDF - like dataset from XML data.", "response": "def parse_xml_dataset(elem, handle_units):\n    \"\"\"Create a netCDF-like dataset from XML data.\"\"\"\n    points, units = zip(*[parse_xml_point(p) for p in elem.findall('point')])\n    # Group points by the contents of each point\n    datasets = {}\n    for p in points:\n        datasets.setdefault(tuple(p), []).append(p)\n\n    all_units = combine_dicts(units)\n    return [combine_xml_points(d, all_units, handle_units) for d in datasets.values()]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle CSV - formatted HTTP responses.", "response": "def parse_csv_response(data, unit_handler):\n    \"\"\"Handle CSV-formatted HTTP responses.\"\"\"\n    return squish([parse_csv_dataset(d, unit_handler) for d in data.split(b'\\n\\n')])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the CSV header returned by TDS.", "response": "def parse_csv_header(line):\n    \"\"\"Parse the CSV header returned by TDS.\"\"\"\n    units = {}\n    names = []\n    for var in line.split(','):\n        start = var.find('[')\n        if start < 0:\n            names.append(str(var))\n            continue\n        else:\n            names.append(str(var[:start]))\n        end = var.find(']', start)\n        unitstr = var[start + 1:end]\n        eq = unitstr.find('=')\n        if eq >= 0:\n            # go past = and \", skip final \"\n            units[names[-1]] = unitstr[eq + 2:-1]\n    return names, units"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_csv_dataset(data, handle_units):\n    fobj = BytesIO(data)\n    names, units = parse_csv_header(fobj.readline().decode('utf-8'))\n    arrs = np.genfromtxt(fobj, dtype=None, names=names, delimiter=',', unpack=True,\n                         converters={'date': lambda s: parse_iso_date(s.decode('utf-8'))})\n    d = {}\n    for f in arrs.dtype.fields:\n        dat = arrs[f]\n        if dat.dtype == np.object:\n            dat = dat.tolist()\n        d[f] = handle_units(dat, units.get(f, None))\n    return d", "response": "Parse CSV data into a netCDF - like dataset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate a query. Determines whether `query` is well-formed. This includes checking for all required parameters, as well as checking parameters for valid values. Parameters ---------- query : NCSSQuery The query to validate Returns ------- valid : bool Whether `query` is valid.", "response": "def validate_query(self, query):\n        \"\"\"Validate a query.\n\n        Determines whether `query` is well-formed. This includes checking for all\n        required parameters, as well as checking parameters for valid values.\n\n        Parameters\n        ----------\n        query : NCSSQuery\n            The query to validate\n\n        Returns\n        -------\n        valid : bool\n            Whether `query` is valid.\n\n        \"\"\"\n        # Make sure all variables are in the dataset\n        return bool(query.var) and all(var in self.variables for var in query.var)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_data(self, query):\n        resp = self.get_query(query)\n        return response_handlers(resp, self.unit_handler)", "response": "Fetch parsed data from a THREDDS server using NCSS."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a spatial bounding box in projected ( native ) coordinates to the query.", "response": "def projection_box(self, min_x, min_y, max_x, max_y):\n        \"\"\"Add a bounding box in projected (native) coordinates to the query.\n\n        This adds a request for a spatial bounding box, bounded by (`min_x`, `max_x`) for\n        x direction and (`min_y`, `max_y`) for the y direction. This modifies the query\n        in-place, but returns ``self`` so that multiple queries can be chained together\n        on one line.\n\n        This replaces any existing spatial queries that have been set.\n\n        Parameters\n        ----------\n        min_x : float\n            The left edge of the bounding box\n        min_y : float\n            The bottom edge of the bounding box\n        max_x : float\n            The right edge of the bounding box\n        max_y: float\n            The top edge of the bounding box\n\n        Returns\n        -------\n        self : NCSSQuery\n            Returns self for chaining calls\n\n        \"\"\"\n        self._set_query(self.spatial_query, minx=min_x, miny=min_y,\n                        maxx=max_x, maxy=max_y)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef strides(self, time=None, spatial=None):\n        if time:\n            self.add_query_parameter(timeStride=time)\n        if spatial:\n            self.add_query_parameter(horizStride=spatial)\n        return self", "response": "Sets time and spatial strides for the NCSSQuery object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register(self, mimetype):\n        def dec(func):\n            self._reg[mimetype] = func\n            return func\n        return dec", "response": "Register a function to handle a particular mimetype."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntranslates typed values into python objects.", "response": "def handle_typed_values(val, type_name, value_type):\n        \"\"\"Translate typed values into the appropriate python object.\n\n        Takes an element name, value, and type and returns a list\n        with the string value(s) properly converted to a python type.\n\n        TypedValues are handled in ucar.ma2.DataType in netcdfJava\n        in the DataType enum. Possibilities are:\n\n            \"boolean\"\n            \"byte\"\n            \"char\"\n            \"short\"\n            \"int\"\n            \"long\"\n            \"float\"\n            \"double\"\n            \"Sequence\"\n            \"String\"\n            \"Structure\"\n            \"enum1\"\n            \"enum2\"\n            \"enum4\"\n            \"opaque\"\n            \"object\"\n\n        All of these are values written as strings in the xml, so simply\n        applying int, float to the values will work in most cases (i.e.\n        the TDS encodes them as string values properly).\n\n        Examle XML element:\n\n        <attribute name=\"scale_factor\" type=\"double\" value=\"0.0010000000474974513\"/>\n\n        Parameters\n        ----------\n        val : string\n            The string representation of the value attribute of the xml element\n\n        type_name : string\n            The string representation of the name attribute of the xml element\n\n        value_type : string\n            The string representation of the type attribute of the xml element\n\n        Returns\n        -------\n        val : list\n            A list containing the properly typed python values.\n\n        \"\"\"\n        if value_type in ['byte', 'short', 'int', 'long']:\n            try:\n                val = [int(v) for v in re.split('[ ,]', val) if v]\n            except ValueError:\n                log.warning('Cannot convert \"%s\" to int. Keeping type as str.', val)\n        elif value_type in ['float', 'double']:\n            try:\n                val = [float(v) for v in re.split('[ ,]', val) if v]\n            except ValueError:\n                log.warning('Cannot convert \"%s\" to float. Keeping type as str.', val)\n        elif value_type == 'boolean':\n            try:\n                # special case for boolean type\n                val = val.split()\n                # values must be either true or false\n                for potential_bool in val:\n                    if potential_bool not in ['true', 'false']:\n                        raise ValueError\n                val = [True if item == 'true' else False for item in val]\n            except ValueError:\n                msg = 'Cannot convert values %s to boolean.'\n                msg += ' Keeping type as str.'\n                log.warning(msg, val)\n        elif value_type == 'String':\n            # nothing special for String type\n            pass\n        else:\n            # possibilities - Sequence, Structure, enum, opaque, object,\n            # and char.\n            # Not sure how to handle these as I do not have an example\n            # of how they would show up in dataset.xml\n            log.warning('%s type %s not understood. Keeping as String.',\n                        type_name, value_type)\n\n        if not isinstance(val, list):\n            val = [val]\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload and parse upper air observations from an online archive and return a pandas. DataFrame containing the data.", "response": "def _get_data(self, time, site_id):\n        r\"\"\"Download and parse upper air observations from an online archive.\n\n        Parameters\n        ----------\n        time : datetime\n            The date and time of the desired observation.\n\n        site_id : str\n            The three letter ICAO identifier of the station for which data should be\n            downloaded.\n\n        Returns\n        -------\n            :class:`pandas.DataFrame` containing the data\n\n        \"\"\"\n        raw_data = self._get_data_raw(time, site_id)\n        soup = BeautifulSoup(raw_data, 'html.parser')\n        tabular_data = StringIO(soup.find_all('pre')[0].contents[0])\n        col_names = ['pressure', 'height', 'temperature', 'dewpoint', 'direction', 'speed']\n        df = pd.read_fwf(tabular_data, skiprows=5, usecols=[0, 1, 2, 3, 6, 7], names=col_names)\n        df['u_wind'], df['v_wind'] = get_wind_components(df['speed'],\n                                                         np.deg2rad(df['direction']))\n\n        # Drop any rows with all NaN values for T, Td, winds\n        df = df.dropna(subset=('temperature', 'dewpoint', 'direction', 'speed',\n                               'u_wind', 'v_wind'), how='all').reset_index(drop=True)\n\n        # Parse metadata\n        meta_data = soup.find_all('pre')[1].contents[0]\n        lines = meta_data.splitlines()\n\n        # If the station doesn't have a name identified we need to insert a\n        # record showing this for parsing to proceed.\n        if 'Station number' in lines[1]:\n            lines.insert(1, 'Station identifier: ')\n\n        station = lines[1].split(':')[1].strip()\n        station_number = int(lines[2].split(':')[1].strip())\n        sounding_time = datetime.strptime(lines[3].split(':')[1].strip(), '%y%m%d/%H%M')\n        latitude = float(lines[4].split(':')[1].strip())\n        longitude = float(lines[5].split(':')[1].strip())\n        elevation = float(lines[6].split(':')[1].strip())\n\n        df['station'] = station\n        df['station_number'] = station_number\n        df['time'] = sounding_time\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n        df['elevation'] = elevation\n\n        # Add unit dictionary\n        df.units = {'pressure': 'hPa',\n                    'height': 'meter',\n                    'temperature': 'degC',\n                    'dewpoint': 'degC',\n                    'direction': 'degrees',\n                    'speed': 'knot',\n                    'u_wind': 'knot',\n                    'v_wind': 'knot',\n                    'station': None,\n                    'station_number': None,\n                    'time': None,\n                    'latitude': 'degrees',\n                    'longitude': 'degrees',\n                    'elevation': 'meter'}\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndownload data from the University of Wyoming s upper air archive.", "response": "def _get_data_raw(self, time, site_id):\n        \"\"\"Download data from the University of Wyoming's upper air archive.\n\n        Parameters\n        ----------\n        time : datetime\n            Date and time for which data should be downloaded\n        site_id : str\n            Site id for which data should be downloaded\n\n        Returns\n        -------\n        text of the server response\n\n        \"\"\"\n        path = ('?region=naconf&TYPE=TEXT%3ALIST'\n                '&YEAR={time:%Y}&MONTH={time:%m}&FROM={time:%d%H}&TO={time:%d%H}'\n                '&STNM={stid}').format(time=time, stid=site_id)\n\n        resp = self.get_path(path)\n        # See if the return is valid, but has no data\n        if resp.text.find('Can\\'t') != -1:\n            raise ValueError(\n                'No data available for {time:%Y-%m-%d %HZ} '\n                'for station {stid}.'.format(time=time, stid=site_id))\n\n        return resp.text"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle reading an NcStream v1 data block from a file - like object.", "response": "def read_ncstream_data(fobj):\n    \"\"\"Handle reading an NcStream v1 data block from a file-like object.\"\"\"\n    data = read_proto_object(fobj, stream.Data)\n    if data.dataType in (stream.STRING, stream.OPAQUE) or data.vdata:\n        log.debug('Reading string/opaque/vlen')\n        num_obj = read_var_int(fobj)\n        log.debug('Num objects: %d', num_obj)\n        blocks = [read_block(fobj) for _ in range(num_obj)]\n        if data.dataType == stream.STRING:\n            blocks = [b.decode('utf-8', errors='ignore') for b in blocks]\n\n        # Again endian isn't coded properly\n        dt = data_type_to_numpy(data.dataType).newbyteorder('>')\n        if data.vdata:\n            return np.array([np.frombuffer(b, dtype=dt) for b in blocks])\n        else:\n            return np.array(blocks, dtype=dt)\n    elif data.dataType in _dtypeLookup:\n        log.debug('Reading array data')\n        bin_data = read_block(fobj)\n        log.debug('Binary data: %s', bin_data)\n\n        # Hard code to big endian for now since it's not encoded correctly\n        dt = data_type_to_numpy(data.dataType).newbyteorder('>')\n\n        # Handle decompressing the bytes\n        if data.compress == stream.DEFLATE:\n            bin_data = zlib.decompress(bin_data)\n            assert len(bin_data) == data.uncompressedSize\n        elif data.compress != stream.NONE:\n            raise NotImplementedError('Compression type {0} not implemented!'.format(\n                data.compress))\n\n        # Turn bytes into an array\n        return reshape_array(data, np.frombuffer(bin_data, dtype=dt))\n    elif data.dataType == stream.STRUCTURE:\n        sd = read_proto_object(fobj, stream.StructureData)\n\n        # Make a datatype appropriate to the rows of struct\n        endian = '>' if data.bigend else '<'\n        dt = np.dtype([(endian, np.void, sd.rowLength)])\n\n        # Turn bytes into an array\n        return reshape_array(data, np.frombuffer(sd.data, dtype=dt))\n    elif data.dataType == stream.SEQUENCE:\n        log.debug('Reading sequence')\n        blocks = []\n        magic = read_magic(fobj)\n        while magic != MAGIC_VEND:\n            if magic == MAGIC_VDATA:\n                log.error('Bad magic for struct/seq data!')\n            blocks.append(read_proto_object(fobj, stream.StructureData))\n            magic = read_magic(fobj)\n        return data, blocks\n    else:\n        raise NotImplementedError(\"Don't know how to handle data type: {0}\".format(\n            data.dataType))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles reading an NcStream error from a file - like object and raise as error.", "response": "def read_ncstream_err(fobj):\n    \"\"\"Handle reading an NcStream error from a file-like object and raise as error.\"\"\"\n    err = read_proto_object(fobj, stream.Error)\n    raise RuntimeError(err.message)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_messages(fobj, magic_table):\n    messages = []\n\n    while True:\n        magic = read_magic(fobj)\n        if not magic:\n            break\n\n        func = magic_table.get(magic)\n        if func is not None:\n            messages.append(func(fobj))\n        else:\n            log.error('Unknown magic: ' + str(' '.join('{0:02x}'.format(b)\n                                                       for b in bytearray(magic))))\n\n    return messages", "response": "Read messages from a file - like object until stream is exhausted."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a block of data and parse using the given protobuf object.", "response": "def read_proto_object(fobj, klass):\n    \"\"\"Read a block of data and parse using the given protobuf object.\"\"\"\n    log.debug('%s chunk', klass.__name__)\n    obj = klass()\n    obj.ParseFromString(read_block(fobj))\n    log.debug('Header: %s', str(obj))\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a block from a file - like object.", "response": "def read_block(fobj):\n    \"\"\"Read a block.\n\n    Reads a block from a file object by first reading the number of bytes to read, which must\n    be encoded as a variable-byte length integer.\n\n    Parameters\n    ----------\n    fobj : file-like object\n        The file to read from.\n\n    Returns\n    -------\n    bytes\n        block of bytes read\n\n    \"\"\"\n    num = read_var_int(fobj)\n    log.debug('Next block: %d bytes', num)\n    return fobj.read(num)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_vlen(data_header, array):\n    source = iter(array)\n    return np.array([np.fromiter(itertools.islice(source, size), dtype=array.dtype)\n                     for size in data_header.vlens])", "response": "This function processes vlen coming back from NCStream v2."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a DataCol from NCStream v2 into an array with appropriate type.", "response": "def datacol_to_array(datacol):\n    \"\"\"Convert DataCol from NCStream v2 into an array with appropriate type.\n\n    Depending on the data type specified, this extracts data from the appropriate members\n    and packs into a :class:`numpy.ndarray`, recursing as necessary for compound data types.\n\n    Parameters\n    ----------\n    datacol : DataCol\n\n    Returns\n    -------\n    ndarray\n        array containing extracted data\n\n    \"\"\"\n    if datacol.dataType == stream.STRING:\n        arr = np.array(datacol.stringdata, dtype=np.object)\n    elif datacol.dataType == stream.OPAQUE:\n        arr = np.array(datacol.opaquedata, dtype=np.object)\n    elif datacol.dataType == stream.STRUCTURE:\n        members = OrderedDict((mem.name, datacol_to_array(mem))\n                              for mem in datacol.structdata.memberData)\n        log.debug('Struct members:\\n%s', str(members))\n\n        # str() around name necessary because protobuf gives unicode names, but dtype doesn't\n        # support them on Python 2\n        dt = np.dtype([(str(name), arr.dtype) for name, arr in members.items()])\n        log.debug('Struct dtype: %s', str(dt))\n\n        arr = np.empty((datacol.nelems,), dtype=dt)\n        for name, arr_data in members.items():\n            arr[name] = arr_data\n    else:\n        # Make an appropriate datatype\n        endian = '>' if datacol.bigend else '<'\n        dt = data_type_to_numpy(datacol.dataType).newbyteorder(endian)\n\n        # Turn bytes into an array\n        arr = np.frombuffer(datacol.primdata, dtype=dt)\n        if arr.size != datacol.nelems:\n            log.warning('Array size %d does not agree with nelems %d',\n                        arr.size, datacol.nelems)\n        if datacol.isVlen:\n            arr = process_vlen(datacol, arr)\n            if arr.dtype == np.object_:\n                arr = reshape_array(datacol, arr)\n            else:\n                # In this case, the array collapsed, need different resize that\n                # correctly sizes from elements\n                shape = tuple(r.size for r in datacol.section.range) + (datacol.vlens[0],)\n                arr = arr.reshape(*shape)\n        else:\n            arr = reshape_array(datacol, arr)\n    return arr"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts the appropriate array shape from the header.", "response": "def reshape_array(data_header, array):\n    \"\"\"Extract the appropriate array shape from the header.\n\n    Can handle taking a data header and either bytes containing data or a StructureData\n    instance, which will have binary data as well as some additional information.\n\n    Parameters\n    ----------\n    array : :class:`numpy.ndarray`\n    data_header : Data\n\n    \"\"\"\n    shape = tuple(r.size for r in data_header.section.range)\n    if shape:\n        return array.reshape(*shape)\n    else:\n        return array"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef data_type_to_numpy(datatype, unsigned=False):\n    basic_type = _dtypeLookup[datatype]\n\n    if datatype in (stream.STRING, stream.OPAQUE):\n        return np.dtype(basic_type)\n\n    if unsigned:\n        basic_type = basic_type.replace('i', 'u')\n    return np.dtype('=' + basic_type)", "response": "Convert an ncstream datatype to a numpy one."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef struct_to_dtype(struct):\n    # str() around name necessary because protobuf gives unicode names, but dtype doesn't\n    # support them on Python 2\n    fields = [(str(var.name), data_type_to_numpy(var.dataType, var.unsigned))\n              for var in struct.vars]\n    for s in struct.structs:\n        fields.append((str(s.name), struct_to_dtype(s)))\n\n    log.debug('Structure fields: %s', fields)\n    dt = np.dtype(fields)\n    return dt", "response": "Convert a Structure specification to a numpy structured dtype."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unpack_variable(var):\n    # If we actually get a structure instance, handle turning that into a variable\n    if var.dataType == stream.STRUCTURE:\n        return None, struct_to_dtype(var), 'Structure'\n    elif var.dataType == stream.SEQUENCE:\n        log.warning('Sequence support not implemented!')\n\n    dt = data_type_to_numpy(var.dataType, var.unsigned)\n    if var.dataType == stream.OPAQUE:\n        type_name = 'opaque'\n    elif var.dataType == stream.STRING:\n        type_name = 'string'\n    else:\n        type_name = dt.name\n\n    if var.data:\n        log.debug('Storing variable data: %s %s', dt, var.data)\n        if var.dataType == stream.STRING:\n            data = var.data\n        else:\n            # Always sent big endian\n            data = np.frombuffer(var.data, dtype=dt.newbyteorder('>'))\n    else:\n        data = None\n\n    return data, dt, type_name", "response": "Unpack an NCStream Variable into a numpy array and a type name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unpack_attribute(att):\n    if att.unsigned:\n        log.warning('Unsupported unsigned attribute!')\n\n    # TDS 5.0 now has a dataType attribute that takes precedence\n    if att.len == 0:  # Empty\n        val = None\n    elif att.dataType == stream.STRING:  # Then look for new datatype string\n        val = att.sdata\n    elif att.dataType:  # Then a non-zero new data type\n        val = np.frombuffer(att.data,\n                            dtype='>' + _dtypeLookup[att.dataType], count=att.len)\n    elif att.type:  # Then non-zero old-data type0\n        val = np.frombuffer(att.data,\n                            dtype=_attrConverters[att.type], count=att.len)\n    elif att.sdata:  # This leaves both 0, try old string\n        val = att.sdata\n    else:  # Assume new datatype is Char (0)\n        val = np.array(att.data, dtype=_dtypeLookup[att.dataType])\n\n    if att.len == 1:\n        val = val[0]\n\n    return att.name, val", "response": "Unpack an embedded attribute into a python or numpy object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_var_int(file_obj):\n    # Read all bytes from here, stopping with the first one that does not have\n    # the MSB set. Save the lower 7 bits, and keep stacking to the *left*.\n    val = 0\n    shift = 0\n    while True:\n        # Read next byte\n        next_val = ord(file_obj.read(1))\n        val |= ((next_val & 0x7F) << shift)\n        shift += 7\n        if not next_val & 0x80:\n            break\n\n    return val", "response": "Reads a variable - length integer from the specified file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch_data(self, **var):\n        varstr = ','.join(name + self._convert_indices(ind)\n                          for name, ind in var.items())\n        query = self.query().add_query_parameter(req='data', var=varstr)\n        return self._fetch(query)", "response": "Retrieve data from CDMRemote for one or more variables."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query(self):\n        q = super(CDMRemote, self).query()\n\n        # Turn on compression if it's been set on the object\n        if self.deflate:\n            q.add_query_parameter(deflate=self.deflate)\n\n        return q", "response": "Generate a new query for the object containing the object s ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_token(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        response = func(*args, **kwargs)\n        if response.status_code == 401:\n            raise InvalidToken('Access token invalid or no longer valid')\n        else:\n            return response\n    return wrapper", "response": "Check if access token is valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuploads a file to the remote server.", "response": "def upload(self, remote_path, file_content, ondup=None, **kwargs):\n        \"\"\"\u4e0a\u4f20\u5355\u4e2a\u6587\u4ef6\uff08<2G\uff09.\n\n        | \u767e\u5ea6PCS\u670d\u52a1\u76ee\u524d\u652f\u6301\u6700\u59272G\u7684\u5355\u4e2a\u6587\u4ef6\u4e0a\u4f20\u3002\n        | \u5982\u9700\u652f\u6301\u8d85\u5927\u6587\u4ef6\uff08>2G\uff09\u7684\u65ad\u70b9\u7eed\u4f20\uff0c\u8bf7\u53c2\u8003\u4e0b\u9762\u7684\u201c\u5206\u7247\u6587\u4ef6\u4e0a\u4f20\u201d\u65b9\u6cd5\u3002\n\n        :param remote_path: \u7f51\u76d8\u4e2d\u6587\u4ef6\u7684\u4fdd\u5b58\u8def\u5f84\uff08\u5305\u542b\u6587\u4ef6\u540d\uff09\u3002\n                            \u5fc5\u987b\u4ee5 /apps/ \u5f00\u5934\u3002\n\n                            .. warning::\n                                * \u8def\u5f84\u957f\u5ea6\u9650\u5236\u4e3a1000\uff1b\n                                * \u5f84\u4e2d\u4e0d\u80fd\u5305\u542b\u4ee5\u4e0b\u5b57\u7b26\uff1a``\\\\\\\\ ? | \" > < : *``\uff1b\n                                * \u6587\u4ef6\u540d\u6216\u8def\u5f84\u540d\u5f00\u5934\u7ed3\u5c3e\u4e0d\u80fd\u662f ``.``\n                                  \u6216\u7a7a\u767d\u5b57\u7b26\uff0c\u7a7a\u767d\u5b57\u7b26\u5305\u62ec\uff1a\n                                  ``\\\\r, \\\\n, \\\\t, \u7a7a\u683c, \\\\0, \\\\x0B`` \u3002\n        :param file_content: \u4e0a\u4f20\u6587\u4ef6\u7684\u5185\u5bb9/\u6587\u4ef6\u5bf9\u8c61 \u3002\n                             (e.g. ``open('foobar', 'rb')`` )\n        :param ondup: \uff08\u53ef\u9009\uff09\n\n                      * 'overwrite'\uff1a\u8868\u793a\u8986\u76d6\u540c\u540d\u6587\u4ef6\uff1b\n                      * 'newcopy'\uff1a\u8868\u793a\u751f\u6210\u6587\u4ef6\u526f\u672c\u5e76\u8fdb\u884c\u91cd\u547d\u540d\uff0c\u547d\u540d\u89c4\u5219\u4e3a\u201c\n                        \u6587\u4ef6\u540d_\u65e5\u671f.\u540e\u7f00\u201d\u3002\n        :return: Response \u5bf9\u8c61\n        \"\"\"\n\n        params = {\n            'path': remote_path,\n            'ondup': ondup\n        }\n        files = {'file': ('file', file_content, '')}\n        url = 'https://c.pcs.baidu.com/rest/2.0/pcs/file'\n        return self._request('file', 'upload', url=url, extra_params=params,\n                             files=files, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upload_tmpfile(self, file_content, **kwargs):\n\n        params = {\n            'type': 'tmpfile'\n        }\n        files = {'file': ('file', file_content, '')}\n        url = 'https://c.pcs.baidu.com/rest/2.0/pcs/file'\n        return self._request('file', 'upload', url=url, extra_params=params,\n                             files=files, **kwargs)", "response": "Upload a file to a temporary file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upload_superfile(self, remote_path, block_list, ondup=None, **kwargs):\n\n        params = {\n            'path': remote_path,\n            'ondup': ondup\n        }\n        data = {\n            'param': json.dumps({'block_list': block_list}),\n        }\n        return self._request('file', 'createsuperfile', extra_params=params,\n                             data=data, **kwargs)", "response": "Upload a superfile to the remote path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mkdir(self, remote_path, **kwargs):\n\n        data = {\n            'path': remote_path\n        }\n        return self._request('file', 'mkdir', data=data, **kwargs)", "response": "Create a new directory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget file meta data", "response": "def meta(self, remote_path, **kwargs):\n        \"\"\"\u83b7\u53d6\u5355\u4e2a\u6587\u4ef6\u6216\u76ee\u5f55\u7684\u5143\u4fe1\u606f.\n\n        :param remote_path: \u7f51\u76d8\u4e2d\u6587\u4ef6/\u76ee\u5f55\u7684\u8def\u5f84\uff0c\u5fc5\u987b\u4ee5 /apps/ \u5f00\u5934\u3002\n\n                            .. warning::\n                                * \u8def\u5f84\u957f\u5ea6\u9650\u5236\u4e3a1000\uff1b\n                                * \u5f84\u4e2d\u4e0d\u80fd\u5305\u542b\u4ee5\u4e0b\u5b57\u7b26\uff1a``\\\\\\\\ ? | \" > < : *``\uff1b\n                                * \u6587\u4ef6\u540d\u6216\u8def\u5f84\u540d\u5f00\u5934\u7ed3\u5c3e\u4e0d\u80fd\u662f ``.``\n                                  \u6216\u7a7a\u767d\u5b57\u7b26\uff0c\u7a7a\u767d\u5b57\u7b26\u5305\u62ec\uff1a\n                                  ``\\\\r, \\\\n, \\\\t, \u7a7a\u683c, \\\\0, \\\\x0B`` \u3002\n        :return: Response \u5bf9\u8c61\n        \"\"\"\n\n        params = {\n            'path': remote_path\n        }\n        return self._request('file', 'meta', extra_params=params, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef move(self, from_path, to_path, **kwargs):\n\n        data = {\n            'from': from_path,\n            'to': to_path,\n        }\n        return self._request('file', 'move', data=data, **kwargs)", "response": "move file from one location to another"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy(self, from_path, to_path, **kwargs):\n\n        data = {\n            'from': from_path,\n            'to': to_path,\n        }\n        return self._request('file', 'copy', data=data, **kwargs)", "response": "Copy a file from one location to another."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, remote_path, **kwargs):\n\n        data = {\n            'path': remote_path\n        }\n        return self._request('file', 'delete', data=data, **kwargs)", "response": "Delete a file from the server."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef multi_delete(self, path_list, **kwargs):\n\n        data = {\n            'param': json.dumps({\n                'list': [{'path': path} for path in path_list]\n            }),\n        }\n        return self._request('file', 'delete', data=data, **kwargs)", "response": "Delete a list of files."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef thumbnail(self, remote_path, height, width, quality=100, **kwargs):\n\n        params = {\n            'path': remote_path,\n            'height': height,\n            'width': width,\n            'quality': quality,\n        }\n        return self._request('thumbnail', 'generate', extra_params=params,\n                             **kwargs)", "response": "Get a thumbnail of a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef video_convert(self, remote_path, video_type, **kwargs):\n\n        params = {\n            'path': remote_path,\n            'type': video_type,\n        }\n        return self._request('file', 'streaming', extra_params=params,\n                             **kwargs)", "response": "Convert a file to a video type."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef download_stream(self, remote_path, **kwargs):\n\n        params = {\n            'path': remote_path,\n        }\n        url = 'https://d.pcs.baidu.com/rest/2.0/pcs/file'\n        return self._request('stream', 'download', url=url,\n                             extra_params=params, **kwargs)", "response": "Download a file from the Baidu server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rapid_upload(self, remote_path, content_length, content_md5,\n                     content_crc32, slice_md5, ondup=None, **kwargs):\n        \"\"\"\u79d2\u4f20\u4e00\u4e2a\u6587\u4ef6.\n\n        .. warning::\n           * \u88ab\u79d2\u4f20\u6587\u4ef6\u5fc5\u987b\u5927\u4e8e256KB\uff08\u5373 256*1024 B\uff09\u3002\n           * \u6821\u9a8c\u6bb5\u4e3a\u6587\u4ef6\u7684\u524d256KB\uff0c\u79d2\u4f20\u63a5\u53e3\u9700\u8981\u63d0\u4f9b\u6821\u9a8c\u6bb5\u7684MD5\u3002\n             (\u975e\u5f3a\u4e00\u81f4\u63a5\u53e3\uff0c\u4e0a\u4f20\u540e\u8bf7\u7b49\u5f851\u79d2\u540e\u518d\u8bfb\u53d6)\n\n        :param remote_path: \u4e0a\u4f20\u6587\u4ef6\u7684\u5168\u8def\u5f84\u540d\u3002\n\n                            .. warning::\n                                * \u8def\u5f84\u957f\u5ea6\u9650\u5236\u4e3a1000\uff1b\n                                * \u5f84\u4e2d\u4e0d\u80fd\u5305\u542b\u4ee5\u4e0b\u5b57\u7b26\uff1a``\\\\\\\\ ? | \" > < : *``\uff1b\n                                * \u6587\u4ef6\u540d\u6216\u8def\u5f84\u540d\u5f00\u5934\u7ed3\u5c3e\u4e0d\u80fd\u662f ``.``\n                                  \u6216\u7a7a\u767d\u5b57\u7b26\uff0c\u7a7a\u767d\u5b57\u7b26\u5305\u62ec\uff1a\n                                  ``\\\\r, \\\\n, \\\\t, \u7a7a\u683c, \\\\0, \\\\x0B`` \u3002\n        :param content_length: \u5f85\u79d2\u4f20\u6587\u4ef6\u7684\u957f\u5ea6\u3002\n        :param content_md5: \u5f85\u79d2\u4f20\u6587\u4ef6\u7684MD5\u3002\n        :param content_crc32: \u5f85\u79d2\u4f20\u6587\u4ef6\u7684CRC32\u3002\n        :param slice_md5: \u5f85\u79d2\u4f20\u6587\u4ef6\u6821\u9a8c\u6bb5\u7684MD5\u3002\n        :param ondup: \uff08\u53ef\u9009\uff09\n\n                      * 'overwrite'\uff1a\u8868\u793a\u8986\u76d6\u540c\u540d\u6587\u4ef6\uff1b\n                      * 'newcopy'\uff1a\u8868\u793a\u751f\u6210\u6587\u4ef6\u526f\u672c\u5e76\u8fdb\u884c\u91cd\u547d\u540d\uff0c\u547d\u540d\u89c4\u5219\u4e3a\u201c\n                        \u6587\u4ef6\u540d_\u65e5\u671f.\u540e\u7f00\u201d\u3002\n        :return: Response \u5bf9\u8c61\n        \"\"\"\n        data = {\n            'path': remote_path,\n            'content-length': content_length,\n            'content-md5': content_md5,\n            'content-crc32': content_crc32,\n            'slice-md5': slice_md5,\n            'ondup': ondup,\n        }\n        return self._request('file', 'rapidupload', data=data, **kwargs)", "response": "Upload a file to a rapid server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_download_task(self, source_url, remote_path,\n                          rate_limit=None, timeout=60 * 60,\n                          expires=None, callback='', **kwargs):\n        \"\"\"\u6dfb\u52a0\u79bb\u7ebf\u4e0b\u8f7d\u4efb\u52a1\uff0c\u5b9e\u73b0\u5355\u4e2a\u6587\u4ef6\u79bb\u7ebf\u4e0b\u8f7d.\n\n        :param source_url: \u6e90\u6587\u4ef6\u7684URL\u3002\n        :param remote_path: \u4e0b\u8f7d\u540e\u7684\u6587\u4ef6\u4fdd\u5b58\u8def\u5f84\u3002\n\n                            .. warning::\n                                * \u8def\u5f84\u957f\u5ea6\u9650\u5236\u4e3a1000\uff1b\n                                * \u5f84\u4e2d\u4e0d\u80fd\u5305\u542b\u4ee5\u4e0b\u5b57\u7b26\uff1a``\\\\\\\\ ? | \" > < : *``\uff1b\n                                * \u6587\u4ef6\u540d\u6216\u8def\u5f84\u540d\u5f00\u5934\u7ed3\u5c3e\u4e0d\u80fd\u662f ``.``\n                                  \u6216\u7a7a\u767d\u5b57\u7b26\uff0c\u7a7a\u767d\u5b57\u7b26\u5305\u62ec\uff1a\n                                  ``\\\\r, \\\\n, \\\\t, \u7a7a\u683c, \\\\0, \\\\x0B`` \u3002\n        :param rate_limit: \u4e0b\u8f7d\u9650\u901f\uff0c\u9ed8\u8ba4\u4e0d\u9650\u901f\u3002\n        :type rate_limit: int or long\n        :param timeout: \u4e0b\u8f7d\u8d85\u65f6\u65f6\u95f4\uff0c\u9ed8\u8ba43600\u79d2\u3002\n        :param expires: \u8bf7\u6c42\u5931\u6548\u65f6\u95f4\uff0c\u5982\u679c\u6709\uff0c\u5219\u4f1a\u6821\u9a8c\u3002\n        :type expires: int\n        :param callback: \u4e0b\u8f7d\u5b8c\u6bd5\u540e\u7684\u56de\u8c03\uff0c\u9ed8\u8ba4\u4e3a\u7a7a\u3002\n        :type callback: str\n        :return: Response \u5bf9\u8c61\n        \"\"\"\n\n        data = {\n            'source_url': source_url,\n            'save_path': remote_path,\n            'expires': expires,\n            'rate_limit': rate_limit,\n            'timeout': timeout,\n            'callback': callback,\n        }\n        return self._request('services/cloud_dl', 'add_task',\n                             data=data, **kwargs)", "response": "Add a download task to the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nqueries Cloud DL Task", "response": "def query_download_tasks(self, task_ids, operate_type=1,\n                             expires=None, **kwargs):\n        \"\"\"\u6839\u636e\u4efb\u52a1ID\u53f7\uff0c\u67e5\u8be2\u79bb\u7ebf\u4e0b\u8f7d\u4efb\u52a1\u4fe1\u606f\u53ca\u8fdb\u5ea6\u4fe1\u606f\u3002\n\n        :param task_ids: \u8981\u67e5\u8be2\u7684\u4efb\u52a1ID\u5217\u8868\n        :type task_ids: list or tuple\n        :param operate_type:\n                            * 0\uff1a\u67e5\u4efb\u52a1\u4fe1\u606f\n                            * 1\uff1a\u67e5\u8fdb\u5ea6\u4fe1\u606f\uff0c\u9ed8\u8ba4\u4e3a1\n        :param expires: \u8bf7\u6c42\u5931\u6548\u65f6\u95f4\uff0c\u5982\u679c\u6709\uff0c\u5219\u4f1a\u6821\u9a8c\u3002\n        :type expires: int\n        :return: Response \u5bf9\u8c61\n        \"\"\"\n\n        params = {\n            'task_ids': ','.join(map(str, task_ids)),\n            'op_type': operate_type,\n            'expires': expires,\n        }\n        return self._request('services/cloud_dl', 'query_task',\n                             extra_params=params, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist all the tasks in the specified base URL.", "response": "def list_download_tasks(self, need_task_info=1, start=0, limit=10, asc=0,\n                            create_time=None, status=None, source_url=None,\n                            remote_path=None, expires=None, **kwargs):\n        \"\"\"\u67e5\u8be2\u79bb\u7ebf\u4e0b\u8f7d\u4efb\u52a1ID\u5217\u8868\u53ca\u4efb\u52a1\u4fe1\u606f.\n\n        :param need_task_info: \u662f\u5426\u9700\u8981\u8fd4\u56de\u4efb\u52a1\u4fe1\u606f:\n\n                               * 0\uff1a\u4e0d\u9700\u8981\n                               * 1\uff1a\u9700\u8981\uff0c\u9ed8\u8ba4\u4e3a1\n        :param start: \u67e5\u8be2\u4efb\u52a1\u8d77\u59cb\u4f4d\u7f6e\uff0c\u9ed8\u8ba4\u4e3a0\u3002\n        :param limit: \u8bbe\u5b9a\u8fd4\u56de\u4efb\u52a1\u6570\u91cf\uff0c\u9ed8\u8ba4\u4e3a10\u3002\n        :param asc:\n\n                   * 0\uff1a\u964d\u5e8f\uff0c\u9ed8\u8ba4\u503c\n                   * 1\uff1a\u5347\u5e8f\n        :param create_time: \u4efb\u52a1\u521b\u5efa\u65f6\u95f4\uff0c\u9ed8\u8ba4\u4e3a\u7a7a\u3002\n        :type create_time: int\n        :param status: \u4efb\u52a1\u72b6\u6001\uff0c\u9ed8\u8ba4\u4e3a\u7a7a\u3002\n                       0:\u4e0b\u8f7d\u6210\u529f\uff0c1:\u4e0b\u8f7d\u8fdb\u884c\u4e2d 2:\u7cfb\u7edf\u9519\u8bef\uff0c3:\u8d44\u6e90\u4e0d\u5b58\u5728\uff0c\n                       4:\u4e0b\u8f7d\u8d85\u65f6\uff0c5:\u8d44\u6e90\u5b58\u5728\u4f46\u4e0b\u8f7d\u5931\u8d25, 6:\u5b58\u50a8\u7a7a\u95f4\u4e0d\u8db3,\n                       7:\u76ee\u6807\u5730\u5740\u6570\u636e\u5df2\u5b58\u5728, 8:\u4efb\u52a1\u53d6\u6d88.\n        :type status: int\n        :param source_url: \u6e90\u5730\u5740URL\uff0c\u9ed8\u8ba4\u4e3a\u7a7a\u3002\n        :param remote_path: \u6587\u4ef6\u4fdd\u5b58\u8def\u5f84\uff0c\u9ed8\u8ba4\u4e3a\u7a7a\u3002\n\n                            .. warning::\n                                * \u8def\u5f84\u957f\u5ea6\u9650\u5236\u4e3a1000\uff1b\n                                * \u5f84\u4e2d\u4e0d\u80fd\u5305\u542b\u4ee5\u4e0b\u5b57\u7b26\uff1a``\\\\\\\\ ? | \" > < : *``\uff1b\n                                * \u6587\u4ef6\u540d\u6216\u8def\u5f84\u540d\u5f00\u5934\u7ed3\u5c3e\u4e0d\u80fd\u662f ``.``\n                                  \u6216\u7a7a\u767d\u5b57\u7b26\uff0c\u7a7a\u767d\u5b57\u7b26\u5305\u62ec\uff1a\n                                  ``\\\\r, \\\\n, \\\\t, \u7a7a\u683c, \\\\0, \\\\x0B`` \u3002\n        :param expires: \u8bf7\u6c42\u5931\u6548\u65f6\u95f4\uff0c\u5982\u679c\u6709\uff0c\u5219\u4f1a\u6821\u9a8c\u3002\n        :type expires: int\n        :return: Response \u5bf9\u8c61\n        \"\"\"\n\n        data = {\n            'expires': expires,\n            'start': start,\n            'limit': limit,\n            'asc': asc,\n            'source_url': source_url,\n            'save_path': remote_path,\n            'create_time': create_time,\n            'status': status,\n            'need_task_info': need_task_info,\n        }\n        return self._request('services/cloud_dl', 'list_task',\n                             data=data, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cancel_download_task(self, task_id, expires=None, **kwargs):\n\n        data = {\n            'expires': expires,\n            'task_id': task_id,\n        }\n        return self._request('services/cloud_dl', 'cancle_task',\n                             data=data, **kwargs)", "response": "\u53d6\u6d88\u79bb\u7ebf\u4e0b\u8f7d\u4efb\u52a1.\n\n        :param task_id: \u8981\u53d6\u6d88\u7684\u4efb\u52a1ID\u53f7\u3002\n        :type task_id: str\n        :param expires: \u8bf7\u6c42\u5931\u6548\u65f6\u95f4\uff0c\u5982\u679c\u6709\uff0c\u5219\u4f1a\u6821\u9a8c\u3002\n        :type expires: int\n        :return: Response \u5bf9\u8c61"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_recycle_bin(self, start=0, limit=1000, **kwargs):\n\n        params = {\n            'start': start,\n            'limit': limit,\n        }\n        return self._request('file', 'listrecycle',\n                             extra_params=params, **kwargs)", "response": "List all the files in the current user s archive."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef restore_recycle_bin(self, fs_id, **kwargs):\n\n        data = {\n            'fs_id': fs_id,\n        }\n        return self._request('file', 'restore', data=data, **kwargs)", "response": "\u8fd8\u539f\u5355\u4e2a\u6587\u4ef6\u6216\u76ee\u5f55\uff08\u975e\u5f3a\u4e00\u81f4\u63a5\u53e3\uff0c\u8c03\u7528\u540e\u8bf7sleep 1\u79d2\u8bfb\u53d6\uff09.\n\n        :param fs_id: \u6240\u8fd8\u539f\u7684\u6587\u4ef6\u6216\u76ee\u5f55\u5728PCS\u7684\u4e34\u65f6\u552f\u4e00\u6807\u8bc6ID\u3002\n        :type fs_id: str\n        :return: Response \u5bf9\u8c61"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrestore all the files in a set of files", "response": "def multi_restore_recycle_bin(self, fs_ids, **kwargs):\n        \"\"\"\u6279\u91cf\u8fd8\u539f\u6587\u4ef6\u6216\u76ee\u5f55\uff08\u975e\u5f3a\u4e00\u81f4\u63a5\u53e3\uff0c\u8c03\u7528\u540e\u8bf7sleep1\u79d2 \uff09.\n\n        :param fs_ids: \u6240\u8fd8\u539f\u7684\u6587\u4ef6\u6216\u76ee\u5f55\u5728 PCS \u7684\u4e34\u65f6\u552f\u4e00\u6807\u8bc6 ID \u7684\u5217\u8868\u3002\n        :type fs_ids: list or tuple\n        :return: Response \u5bf9\u8c61\n        \"\"\"\n\n        data = {\n            'param': json.dumps({\n                'list': [{'fs_id': fs_id} for fs_id in fs_ids]\n            }),\n        }\n        return self._request('file', 'restore', data=data, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a new Access Token.", "response": "def get_new_access_token(refresh_token, client_id, client_secret,\n                         scope=None, **kwargs):\n    \"\"\"\u4f7f\u7528 Refresh Token \u5237\u65b0\u4ee5\u83b7\u5f97\u65b0\u7684 Access Token.\n\n    :param refresh_token: \u7528\u4e8e\u5237\u65b0 Access Token \u7528\u7684 Refresh Token\uff1b\n    :param client_id: \u5e94\u7528\u7684 API Key\uff1b\n    :param client_secret: \u5e94\u7528\u7684 Secret Key;\n    :param scope: \u4ee5\u7a7a\u683c\u5206\u9694\u7684\u6743\u9650\u5217\u8868\uff0c\u82e5\u4e0d\u4f20\u9012\u6b64\u53c2\u6570\uff0c\u4ee3\u8868\u8bf7\u6c42\u7684\u6570\u636e\u8bbf\u95ee\n                  \u64cd\u4f5c\u6743\u9650\u4e0e\u4e0a\u6b21\u83b7\u53d6 Access Token \u65f6\u4e00\u81f4\u3002\u901a\u8fc7 Refresh Token\n                  \u5237\u65b0 Access Token \u65f6\u6240\u8981\u6c42\u7684 scope \u6743\u9650\u8303\u56f4\u5fc5\u987b\u5c0f\u4e8e\u7b49\u4e8e\u4e0a\u6b21\n                  \u83b7\u53d6 Access Token \u65f6\u6388\u4e88\u7684\u6743\u9650\u8303\u56f4\u3002 \u5173\u4e8e\u6743\u9650\u7684\u5177\u4f53\u4fe1\u606f\u8bf7\u53c2\u8003\n                  \u201c `\u6743\u9650\u5217\u8868`__ \u201d\u3002\n    :return: Response \u5bf9\u8c61\n\n    \u5173\u4e8e ``response.json()`` \u5b57\u5178\u7684\u5185\u5bb9\u6240\u4ee3\u8868\u7684\u542b\u4e49\uff0c\n    \u8bf7\u53c2\u8003 `\u76f8\u5173\u7684\u767e\u5ea6\u5e2e\u52a9\u6587\u6863`__ \u3002\n\n     __ http://developer.baidu.com/wiki/index.php?title=docs/oauth/baiduoauth/list\n     __ http://developer.baidu.com/wiki/index.php?title=docs/oauth/refresh\n    \"\"\"\n    data = {\n        'grant_type': 'refresh_token',\n        'refresh_token': refresh_token,\n        'client_id': client_id,\n        'client_secret': client_secret,\n    }\n    if scope:\n        data['scope'] = scope\n    url = 'https://openapi.baidu.com/oauth/2.0/token'\n    return requests.post(url, data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlogs-in to verisure app api api Login before calling any read or write commands getTaxID", "response": "def login(self):\n        \"\"\" Login to verisure app api\n\n        Login before calling any read or write commands\n\n        \"\"\"\n        if os.path.exists(self._cookieFileName):\n            with open(self._cookieFileName, 'r') as cookieFile:\n                self._vid = cookieFile.read().strip()\n\n            try:\n                self._get_installations()\n            except ResponseError:\n                self._vid = None\n                os.remove(self._cookieFileName)\n\n        if self._vid is None:\n            self._create_cookie()\n            with open(self._cookieFileName, 'w') as cookieFile:\n                cookieFile.write(self._vid)\n            self._get_installations()\n\n        self._giid = self.installations[0]['giid']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting information about installations", "response": "def _get_installations(self):\n        \"\"\" Get information about installations \"\"\"\n        response = None\n        for base_url in urls.BASE_URLS:\n            urls.BASE_URL = base_url\n            try:\n                response = requests.get(\n                    urls.get_installations(self._username),\n                    headers={\n                        'Cookie': 'vid={}'.format(self._vid),\n                        'Accept': 'application/json,'\n                                  'text/javascript, */*; q=0.01',\n                    })\n                if 2 == response.status_code // 100:\n                    break\n                elif 503 == response.status_code:\n                    continue\n                else:\n                    raise ResponseError(response.status_code, response.text)\n            except requests.exceptions.RequestException as ex:\n                raise RequestError(ex)\n\n        _validate_response(response)\n        self.installations = json.loads(response.text)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget overview for installation", "response": "def get_overview(self):\n        \"\"\" Get overview for installation \"\"\"\n        response = None\n        try:\n            response = requests.get(\n                urls.overview(self._giid),\n                headers={\n                    'Accept': 'application/json, text/javascript, */*; q=0.01',\n                    'Accept-Encoding': 'gzip, deflate',\n                    'Content-Type': 'application/json',\n                    'Cookie': 'vid={}'.format(self._vid)})\n        except requests.exceptions.RequestException as ex:\n            raise RequestError(ex)\n        _validate_response(response)\n        return json.loads(response.text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nturns on or off smartplug on the specified smartplug device label.", "response": "def set_smartplug_state(self, device_label, state):\n        \"\"\" Turn on or off smartplug\n\n        Args:\n            device_label (str): Smartplug device label\n            state (boolean): new status, 'True' or 'False'\n        \"\"\"\n        response = None\n        try:\n            response = requests.post(\n                urls.smartplug(self._giid),\n                headers={\n                    'Content-Type': 'application/json',\n                    'Cookie': 'vid={}'.format(self._vid)},\n                data=json.dumps([{\n                    \"deviceLabel\": device_label,\n                    \"state\": state}]))\n        except requests.exceptions.RequestException as ex:\n            raise RequestError(ex)\n        _validate_response(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets recent events from the object.", "response": "def get_history(self, filters=(), pagesize=15, offset=0):\n        \"\"\" Get recent events\n\n        Args:\n            filters (string set): 'ARM', 'DISARM', 'FIRE', 'INTRUSION',\n                                  'TECHNICAL', 'SOS', 'WARNING', 'LOCK',\n                                  'UNLOCK'\n            pagesize (int): Number of events to display\n            offset (int): Skip pagesize * offset first events\n        \"\"\"\n        response = None\n        try:\n            response = requests.get(\n                urls.history(self._giid),\n                headers={\n                    'Accept': 'application/json, text/javascript, */*; q=0.01',\n                    'Cookie': 'vid={}'.format(self._vid)},\n                params={\n                    \"offset\": int(offset),\n                    \"pagesize\": int(pagesize),\n                    \"notificationCategories\": filters})\n        except requests.exceptions.RequestException as ex:\n            raise RequestError(ex)\n        _validate_response(response)\n        return json.loads(response.text)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_climate(self, device_label):\n        response = None\n        try:\n            response = requests.get(\n                urls.climate(self._giid),\n                headers={\n                    'Accept': 'application/json, text/javascript, */*; q=0.01',\n                    'Cookie': 'vid={}'.format(self._vid)},\n                params={\n                    \"deviceLabel\": device_label})\n        except requests.exceptions.RequestException as ex:\n            raise RequestError(ex)\n        _validate_response(response)\n        return json.loads(response.text)", "response": "Get climate history from the device."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_lock_state(self, code, device_label, state):\n        response = None\n        try:\n            response = requests.put(\n                urls.set_lockstate(self._giid, device_label, state),\n                headers={\n                    'Accept': 'application/json, text/javascript, */*; q=0.01',\n                    'Content-Type': 'application/json',\n                    'Cookie': 'vid={}'.format(self._vid)},\n                data=json.dumps({\"code\": str(code)}))\n        except requests.exceptions.RequestException as ex:\n            raise RequestError(ex)\n        _validate_response(response)\n        return json.loads(response.text)", "response": "Set lock state of a lock in a specific device."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets lock state transaction status", "response": "def get_lock_state_transaction(self, transaction_id):\n        \"\"\" Get lock state transaction status\n\n        Args:\n            transaction_id: Transaction ID received from set_lock_state\n        \"\"\"\n        response = None\n        try:\n            response = requests.get(\n                urls.get_lockstate_transaction(self._giid, transaction_id),\n                headers={\n                    'Accept': 'application/json, text/javascript, */*; q=0.01',\n                    'Cookie': 'vid={}'.format(self._vid)})\n        except requests.exceptions.RequestException as ex:\n            raise RequestError(ex)\n        _validate_response(response)\n        return json.loads(response.text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_lock_config(self, device_label):\n        response = None\n        try:\n            response = requests.get(\n                urls.lockconfig(self._giid, device_label),\n                headers={\n                    'Accept': 'application/json, text/javascript, */*; q=0.01',\n                    'Cookie': 'vid={}'.format(self._vid)})\n        except requests.exceptions.RequestException as ex:\n            raise RequestError(ex)\n        _validate_response(response)\n        return json.loads(response.text)", "response": "Get lock configuration of a specific lock in a specific device."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_lock_config(self, device_label, volume=None, voice_level=None,\n                        auto_lock_enabled=None):\n        \"\"\" Set lock configuration\n\n        Args:\n            device_label (str): device label of lock\n            volume (str): 'SILENCE', 'LOW' or 'HIGH'\n            voice_level (str): 'ESSENTIAL' or 'NORMAL'\n            auto_lock_enabled (boolean): auto lock enabled\n        \"\"\"\n        response = None\n        data = {}\n        if volume:\n            data['volume'] = volume\n        if voice_level:\n            data['voiceLevel'] = voice_level\n        if auto_lock_enabled is not None:\n            data['autoLockEnabled'] = auto_lock_enabled\n        try:\n            response = requests.put(\n                urls.lockconfig(self._giid, device_label),\n                headers={\n                    'Content-Type': 'application/json',\n                    'Cookie': 'vid={}'.format(self._vid)},\n                data=json.dumps(data))\n        except requests.exceptions.RequestException as ex:\n            raise RequestError(ex)\n        _validate_response(response)", "response": "Set lock configuration for a specific lock in the nexus."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef capture_image(self, device_label):\n        response = None\n        try:\n            response = requests.post(\n                urls.imagecapture(self._giid, device_label),\n                headers={\n                    'Content-Type': 'application/json',\n                    'Cookie': 'vid={}'.format(self._vid)})\n        except requests.exceptions.RequestException as ex:\n            raise RequestError(ex)\n        _validate_response(response)", "response": "Capture smartcam image of a specific device label."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_camera_imageseries(self, number_of_imageseries=10, offset=0):\n        response = None\n        try:\n            response = requests.get(\n                urls.get_imageseries(self._giid),\n                headers={\n                    'Accept': 'application/json, text/javascript, */*; q=0.01',\n                    'Cookie': 'vid={}'.format(self._vid)},\n                params={\n                    \"numberOfImageSeries\": int(number_of_imageseries),\n                    \"offset\": int(offset),\n                    \"fromDate\": \"\",\n                    \"toDate\": \"\",\n                    \"onlyNotViewed\": \"\",\n                    \"_\": self._giid})\n        except requests.exceptions.RequestException as ex:\n            raise RequestError(ex)\n        _validate_response(response)\n        return json.loads(response.text)", "response": "Get smartcam image series"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload image taken by a smartcam", "response": "def download_image(self, device_label, image_id, file_name):\n        \"\"\" Download image taken by a smartcam\n\n        Args:\n            device_label (str): device label of camera\n            image_id (str): image id from image series\n            file_name (str): path to file\n        \"\"\"\n        response = None\n        try:\n            response = requests.get(\n                urls.download_image(self._giid, device_label, image_id),\n                headers={\n                    'Cookie': 'vid={}'.format(self._vid)},\n                stream=True)\n        except requests.exceptions.RequestException as ex:\n            raise RequestError(ex)\n        _validate_response(response)\n        with open(file_name, 'wb') as image_file:\n            for chunk in response.iter_content(chunk_size=1024):\n                if chunk:\n                    image_file.write(chunk)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef logout(self):\n        response = None\n        try:\n            response = requests.delete(\n                urls.login(),\n                headers={\n                    'Cookie': 'vid={}'.format(self._vid)})\n        except requests.exceptions.RequestException as ex:\n            raise RequestError(ex)\n        _validate_response(response)", "response": "Logout and remove vid"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the heat pump mode for a specific user.", "response": "def set_heat_pump_mode(self, device_label, mode):\n        \"\"\" Set heatpump mode\n        Args:\n            mode (str): 'HEAT', 'COOL', 'FAN' or 'AUTO'\n        \"\"\"\n        response = None\n        try:\n            response = requests.put(\n                urls.set_heatpump_state(self._giid, device_label),\n                headers={\n                    'Accept': 'application/json',\n                    'Content-Type': 'application/json',\n                    'Cookie': 'vid={}'.format(self._vid)},\n                data=json.dumps({'mode': mode}))\n        except requests.exceptions.RequestException as ex:\n            raise RequestError(ex)\n        _validate_response(response)\n        return json.loads(response.text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the heatpump mode for a specific feature.", "response": "def set_heat_pump_feature(self, device_label, feature):\n        \"\"\" Set heatpump mode\n        Args:\n            feature: 'QUIET', 'ECONAVI', or 'POWERFUL'\n        \"\"\"\n        response = None\n        try:\n            response = requests.put(\n                urls.set_heatpump_feature(self._giid, device_label, feature),\n                headers={\n                    'Accept': 'application/json',\n                    'Content-Type': 'application/json',\n                    'Cookie': 'vid={}'.format(self._vid)})\n        except requests.exceptions.RequestException as ex:\n            raise RequestError(ex)\n        _validate_response(response)\n        return json.loads(response.text)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_result(overview, *names):\n    if names:\n        for name in names:\n            toprint = overview\n            for part in name.split('/'):\n                toprint = toprint[part]\n            print(json.dumps(toprint, indent=4, separators=(',', ': ')))\n    else:\n        print(json.dumps(overview, indent=4, separators=(',', ': ')))", "response": "Print the result of a verisure request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n    parser = argparse.ArgumentParser(\n        description='Read or change status of verisure devices')\n    parser.add_argument(\n        'username',\n        help='MyPages username')\n    parser.add_argument(\n        'password',\n        help='MyPages password')\n    parser.add_argument(\n        '-i', '--installation',\n        help='Installation number',\n        type=int,\n        default=1)\n    parser.add_argument(\n        '-c', '--cookie',\n        help='File to store cookie in',\n        default='~/.verisure-cookie')\n\n    commandsparser = parser.add_subparsers(\n        help='commands',\n        dest='command')\n\n    # installations command\n    commandsparser.add_parser(\n        COMMAND_INSTALLATIONS,\n        help='Get information about installations')\n\n    # overview command\n    overview_parser = commandsparser.add_parser(\n        COMMAND_OVERVIEW,\n        help='Read status of one or many device types')\n    overview_parser.add_argument(\n        'filter',\n        nargs='*',\n        help='Read status for device type')\n\n    # armstate command\n    commandsparser.add_parser(\n        COMMAND_ARMSTATE,\n        help='Get arm state')\n\n    # Set command\n    set_parser = commandsparser.add_parser(\n        COMMAND_SET,\n        help='Set status of a device')\n    set_device = set_parser.add_subparsers(\n        help='device',\n        dest='device')\n\n    # Set smartplug\n    set_smartplug = set_device.add_parser(\n        'smartplug',\n        help='set smartplug value')\n    set_smartplug.add_argument(\n        'device_label',\n        help='device label')\n    set_smartplug.add_argument(\n        'new_value',\n        choices=[\n            'on',\n            'off'],\n        help='new value')\n\n    # Set alarm\n    set_alarm = set_device.add_parser(\n        'alarm',\n        help='set alarm status')\n    set_alarm.add_argument(\n        'code',\n        help='alarm code')\n    set_alarm.add_argument(\n        'new_status',\n        choices=[\n            'ARMED_HOME',\n            'ARMED_AWAY',\n            'DISARMED'],\n        help='new status')\n\n    # Set lock\n    set_lock = set_device.add_parser(\n        'lock',\n        help='set lock status')\n    set_lock.add_argument(\n        'code',\n        help='alarm code')\n    set_lock.add_argument(\n        'serial_number',\n        help='serial number')\n    set_lock.add_argument(\n        'new_status',\n        choices=[\n            'lock',\n            'unlock'],\n        help='new status')\n\n    # Get climate history\n    history_climate = commandsparser.add_parser(\n        COMMAND_CLIMATE,\n        help='get climate history')\n    history_climate.add_argument(\n        'device_label',\n        help='device label')\n\n    # Event log command\n    eventlog_parser = commandsparser.add_parser(\n        COMMAND_EVENTLOG,\n        help='Get event log')\n    eventlog_parser.add_argument(\n        '-p', '--pagesize',\n        type=int,\n        default=15,\n        help='Number of elements on one page')\n    eventlog_parser.add_argument(\n        '-o', '--offset',\n        type=int,\n        default=0,\n        help='Page offset')\n    eventlog_parser.add_argument(\n        '-f', '--filter',\n        nargs='*',\n        default=[],\n        choices=[\n            'ARM',\n            'DISARM',\n            'FIRE',\n            'INTRUSION',\n            'TECHNICAL',\n            'SOS',\n            'WARNING',\n            'LOCK',\n            'UNLOCK'],\n        help='Filter event log')\n\n    # Capture command\n    capture_parser = commandsparser.add_parser(\n        COMMAND_CAPTURE,\n        help='Capture image')\n    capture_parser.add_argument(\n        'device_label',\n        help='Device label')\n\n    # Image series command\n    commandsparser.add_parser(\n        COMMAND_IMAGESERIES,\n        help='Get image series')\n\n    # Get image command\n    getimage_parser = commandsparser.add_parser(\n        COMMAND_GETIMAGE,\n        help='Download image')\n    getimage_parser.add_argument(\n        'device_label',\n        help='Device label')\n    getimage_parser.add_argument(\n        'image_id',\n        help='image ID')\n    getimage_parser.add_argument(\n        'file_name',\n        help='Output file name')\n\n    # Vacation mode command\n    commandsparser.add_parser(\n        COMMAND_VACATIONMODE,\n        help='Get vacation mode info')\n\n    # Door window status command\n    commandsparser.add_parser(\n        COMMAND_DOOR_WINDOW,\n        help='Get door/window status')\n\n    # Test ethernet command\n    commandsparser.add_parser(\n        COMMAND_TEST_ETHERNET,\n        help='Update ethernet status')\n\n    args = parser.parse_args()\n    session = verisure.Session(args.username, args.password, args.cookie)\n    session.login()\n    try:\n        session.set_giid(session.installations[args.installation - 1]['giid'])\n        if args.command == COMMAND_INSTALLATIONS:\n            print_result(session.installations)\n        if args.command == COMMAND_OVERVIEW:\n            print_result(session.get_overview(), *args.filter)\n        if args.command == COMMAND_ARMSTATE:\n            print_result(session.get_arm_state())\n        if args.command == COMMAND_SET:\n            if args.device == 'smartplug':\n                session.set_smartplug_state(\n                    args.device_label,\n                    args.new_value == 'on')\n            if args.device == 'alarm':\n                print_result(session.set_arm_state(\n                    args.code,\n                    args.new_status))\n            if args.device == 'lock':\n                print_result(session.set_lock_state(\n                    args.code,\n                    args.serial_number,\n                    args.new_status))\n        if args.command == COMMAND_CLIMATE:\n            print_result(session.get_climate(args.device_label))\n        if args.command == COMMAND_EVENTLOG:\n            print_result(\n                session.get_history(\n                    args.filter,\n                    pagesize=args.pagesize,\n                    offset=args.offset))\n        if args.command == COMMAND_CAPTURE:\n            session.capture_image(args.device_label)\n        if args.command == COMMAND_IMAGESERIES:\n            print_result(session.get_camera_imageseries())\n        if args.command == COMMAND_GETIMAGE:\n            session.download_image(\n                args.device_label,\n                args.image_id,\n                args.file_name)\n        if args.command == COMMAND_VACATIONMODE:\n            print_result(session.get_vacation_mode())\n        if args.command == COMMAND_DOOR_WINDOW:\n            print_result(session.get_door_window())\n        if args.command == COMMAND_TEST_ETHERNET:\n            session.test_ethernet()\n    except verisure.session.ResponseError as ex:\n        print(ex.text)", "response": "Start verisure command line"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the ContentType id of the model.", "response": "def type_id(self):\n        \"\"\"\n        Shortcut to retrieving the ContentType id of the model.\n        \"\"\"\n        try:\n            return ContentType.objects.get_for_model(self.model, for_concrete_model=False).id\n        except DatabaseError as e:\n            raise DatabaseError(\"Unable to fetch ContentType object, is a plugin being registered before the initial syncdb? (original error: {0})\".format(str(e)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the cache key which is used to store a rendered item.", "response": "def get_output_cache_key(self, placeholder_name, instance):\n        \"\"\"\n        .. versionadded:: 0.9\n           Return the default cache key which is used to store a rendered item.\n           By default, this function generates the cache key using :func:`get_output_cache_base_key`.\n        \"\"\"\n        cachekey = self.get_output_cache_base_key(placeholder_name, instance)\n        if self.cache_output_per_site:\n            cachekey = \"{0}-s{1}\".format(cachekey, settings.SITE_ID)\n\n        # Append language code\n        if self.cache_output_per_language:\n            # NOTE: Not using self.language_code, but using the current language instead.\n            #       That is what the {% trans %} tags are rendered as after all.\n            #       The render_placeholder() code can switch the language if needed.\n            user_language = get_language()\n            if user_language not in self.cache_supported_language_codes:\n                user_language = 'unsupported'\n            cachekey = \"{0}.{1}\".format(cachekey, user_language)\n\n        return cachekey"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_output_cache_keys(self, placeholder_name, instance):\n        base_key = self.get_output_cache_base_key(placeholder_name, instance)\n        cachekeys = [\n            base_key,\n        ]\n\n        if self.cache_output_per_site:\n            site_ids = list(Site.objects.values_list('pk', flat=True))\n            if settings.SITE_ID not in site_ids:\n                site_ids.append(settings.SITE_ID)\n\n            base_key = get_rendering_cache_key(placeholder_name, instance)\n            cachekeys = [\"{0}-s{1}\".format(base_key, site_id) for site_id in site_ids]\n\n        if self.cache_output_per_language or self.render_ignore_item_language:\n            # Append language code to all keys,\n            # have to invalidate a lot more items in memcache.\n            # Also added \"None\" suffix, since get_parent_language_code() may return that.\n            # TODO: ideally for render_ignore_item_language, only invalidate all when the fallback language changed.\n            total_list = []\n            cache_languages = list(self.cache_supported_language_codes) + ['unsupported', 'None']\n\n            # All variants of the Placeholder (for full page caching)\n            placeholder = instance.placeholder\n            total_list.extend(get_placeholder_cache_key(placeholder, lc) for lc in cache_languages)\n\n            # All variants of the ContentItem in different languages\n            for user_language in cache_languages:\n                total_list.extend(\"{0}.{1}\".format(base, user_language) for base in cachekeys)\n            cachekeys = total_list\n\n        return cachekeys", "response": "Return the possible cache keys for a rendered item."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the cached output for a rendered item.", "response": "def get_cached_output(self, placeholder_name, instance):\n        \"\"\"\n        .. versionadded:: 0.9\n           Return the cached output for a rendered item, or ``None`` if no output is cached.\n\n           This method can be overwritten to implement custom caching mechanisms.\n           By default, this function generates the cache key using :func:`get_output_cache_key`\n           and retrieves the results from the configured Django cache backend (e.g. memcached).\n        \"\"\"\n        cachekey = self.get_output_cache_key(placeholder_name, instance)\n        return cache.get(cachekey)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the cached output for a rendered item.", "response": "def set_cached_output(self, placeholder_name, instance, output):\n        \"\"\"\n        .. versionadded:: 0.9\n           Store the cached output for a rendered item.\n\n           This method can be overwritten to implement custom caching mechanisms.\n           By default, this function generates the cache key using :func:`~fluent_contents.cache.get_rendering_cache_key`\n           and stores the results in the configured Django cache backend (e.g. memcached).\n\n           When custom cache keys are used, also include those in :func:`get_output_cache_keys`\n           so the cache will be cleared when needed.\n\n        .. versionchanged:: 1.0\n           The received data is no longer a HTML string, but :class:`~fluent_contents.models.ContentItemOutput` object.\n        \"\"\"\n        cachekey = self.get_output_cache_key(placeholder_name, instance)\n        if self.cache_timeout is not DEFAULT_TIMEOUT:\n            cache.set(cachekey, output, self.cache_timeout)\n        else:\n            # Don't want to mix into the default 0/None issue.\n            cache.set(cachekey, output)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render(self, request, instance, **kwargs):\n        render_template = self.get_render_template(request, instance, **kwargs)\n        if not render_template:\n            return str(_(u\"{No rendering defined for class '%s'}\" % self.__class__.__name__))\n\n        context = self.get_context(request, instance, **kwargs)\n        return self.render_to_string(request, render_template, context)", "response": "Returns a string that can be used to render a single item."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render_to_string(self, request, template, context, content_instance=None):\n        if not content_instance:\n            content_instance = PluginContext(request)\n\n        content_instance.update(context)\n        return render_to_string(template, content_instance.flatten(), request=request)", "response": "Render a custom template with the context as context instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister a Media class to the frontend.", "response": "def register_frontend_media(request, media):\n    \"\"\"\n    Add a :class:`~django.forms.Media` class to the current request.\n    This will be rendered by the ``render_plugin_media`` template tag.\n    \"\"\"\n    if not hasattr(request, '_fluent_contents_frontend_media'):\n        request._fluent_contents_frontend_media = Media()\n\n    add_media(request._fluent_contents_frontend_media, media)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_rendering_cache_key(placeholder_name, contentitem):\n    if not contentitem.pk:\n        return None\n    return \"contentitem.@{0}.{1}.{2}\".format(\n        placeholder_name,\n        contentitem.plugin.type_name,  # always returns the upcasted name.\n        contentitem.pk,                # already unique per language_code\n    )", "response": "Returns a cache key for the content item output."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a cache key for an existing placeholder object.", "response": "def get_placeholder_cache_key(placeholder, language_code):\n    \"\"\"\n    Return a cache key for an existing placeholder object.\n\n    This key is used to cache the entire output of a placeholder.\n    \"\"\"\n    return _get_placeholder_cache_key_for_id(\n        placeholder.parent_type_id,\n        placeholder.parent_id,\n        placeholder.slot,\n        language_code\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_placeholder_cache_key_for_parent(parent_object, placeholder_name, language_code):\n    parent_type = ContentType.objects.get_for_model(parent_object)\n    return _get_placeholder_cache_key_for_id(\n        parent_type.id,\n        parent_object.pk,\n        placeholder_name,\n        language_code\n    )", "response": "Return a cache key for a placeholder."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_stale_items(self, stale_cts):\n        stale_ct_ids = list(stale_cts.keys())\n        items = (ContentItem.objects\n                 .non_polymorphic()  # very important, or polymorphic skips them on fetching derived data\n                 .filter(polymorphic_ctype__in=stale_ct_ids)\n                 .order_by('polymorphic_ctype', 'pk')\n                 )\n        if not items:\n            self.stdout.write(\"No stale items found.\")\n            return\n\n        if self.dry_run:\n            self.stdout.write(\"The following content items are stale:\")\n        else:\n            self.stdout.write(\"The following content items were stale:\")\n\n        for item in items:\n            ct = stale_cts[item.polymorphic_ctype_id]\n            self.stdout.write(\"- #{id} points to removed {app_label}.{model}\".format(\n                id=item.pk, app_label=ct.app_label, model=ct.model\n            ))\n\n            if not self.dry_run:\n                try:\n                    item.delete()\n                except PluginNotFound:\n                    Model.delete(item)", "response": "Remove stale items from the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving items that no longer point to an existing parent.", "response": "def remove_unreferenced_items(self, stale_cts):\n        \"\"\"\n        See if there are items that no longer point to an existing parent.\n        \"\"\"\n        stale_ct_ids = list(stale_cts.keys())\n        parent_types = (ContentItem.objects.order_by()\n                        .exclude(polymorphic_ctype__in=stale_ct_ids)\n                        .values_list('parent_type', flat=True).distinct())\n\n        num_unreferenced = 0\n\n        for ct_id in parent_types:\n            parent_ct = ContentType.objects.get_for_id(ct_id)\n            unreferenced_items = (ContentItem.objects\n                                  .filter(parent_type=ct_id)\n                                  .order_by('polymorphic_ctype', 'pk'))\n\n            if parent_ct.model_class() is not None:\n                # Only select the items that are part of removed pages,\n                # unless the parent type was removed - then removing all is correct.\n                unreferenced_items = unreferenced_items.exclude(\n                    parent_id__in=parent_ct.get_all_objects_for_this_type()\n                )\n\n            if unreferenced_items:\n                for item in unreferenced_items:\n                    self.stdout.write(\n                        \"- {cls}#{id} points to nonexisting {app_label}.{model}\".format(\n                            cls=item.__class__.__name__, id=item.pk,\n                            app_label=parent_ct.app_label, model=parent_ct.model\n                        ))\n                    num_unreferenced += 1\n                    if not self.dry_run and self.remove_unreferenced:\n                        item.delete()\n\n        if not num_unreferenced:\n            self.stdout.write(\"No unreferenced items found.\")\n        else:\n            self.stdout.write(\"{0} unreferenced items found.\".format(num_unreferenced))\n            if not self.remove_unreferenced:\n                self.stdout.write(\"Re-run this command with --remove-unreferenced to remove these items\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the list of elements that are not already in the queryset", "response": "def __initial_minus_queryset(self):\n        \"\"\"\n        Gives all elements from self._initial having a slot value that is not already\n        in self.get_queryset()\n        \"\"\"\n        queryset = self.get_queryset()\n\n        def initial_not_in_queryset(initial):\n            for x in queryset:\n                if x.slot == initial['slot']:\n                    return False\n\n            return True\n\n        return list(filter(initial_not_in_queryset, self._initial))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating and return the Placeholder object that points to the given placeholder object.", "response": "def _get_placeholder_arg(arg_name, placeholder):\n    \"\"\"\n    Validate and return the Placeholder object that the template variable points to.\n    \"\"\"\n    if placeholder is None:\n        raise RuntimeWarning(u\"placeholder object is None\")\n    elif isinstance(placeholder, Placeholder):\n        return placeholder\n    elif isinstance(placeholder, Manager):\n        manager = placeholder\n        try:\n            parent_object = manager.instance  # read RelatedManager code\n        except AttributeError:\n            parent_object = None\n\n        try:\n            placeholder = manager.all()[0]\n            if parent_object is not None:\n                placeholder.parent = parent_object  # Fill GFK cache\n            return placeholder\n        except IndexError:\n            raise RuntimeWarning(u\"No placeholders found for query '{0}.all.0'\".format(arg_name))\n    else:\n        raise ValueError(u\"The field '{0}' does not refer to a placeholder object!\".format(arg_name))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _split_js(media, domain):\n    # Read internal property without creating new Media instance.\n    if not media._js:\n        return ImmutableMedia.empty_instance\n\n    needs_local = domain == 'local'\n    new_js = []\n    for url in media._js:\n        if needs_local == _is_local(url):\n            new_js.append(url)\n\n    if not new_js:\n        return ImmutableMedia.empty_instance\n    else:\n        return Media(js=new_js)", "response": "Split the local or external URLs from a Media object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _split_css(media, domain):\n    # Read internal property without creating new Media instance.\n    if not media._css:\n        return ImmutableMedia.empty_instance\n\n    needs_local = domain == 'local'\n    new_css = {}\n    for medium, url in six.iteritems(media._css):\n        if needs_local == _is_local(url):\n            new_css.setdefault(medium, []).append(url)\n\n    if not new_css:\n        return ImmutableMedia.empty_instance\n    else:\n        return Media(css=new_css)", "response": "Extract the local or external URLs from a Media object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the node syntax for the national cache object.", "response": "def parse(cls, parser, token):\n        \"\"\"\n        Parse the node syntax:\n\n        .. code-block:: html+django\n\n            {% page_placeholder parentobj slotname title=\"test\" role=\"m\" %}\n        \"\"\"\n        bits, as_var = parse_as_var(parser, token)\n        tag_name, args, kwargs = parse_token_kwargs(parser, bits, allowed_kwargs=cls.allowed_kwargs, compile_args=True, compile_kwargs=True)\n\n        # Play with the arguments\n        if len(args) == 2:\n            parent_expr = args[0]\n            slot_expr = args[1]\n        elif len(args) == 1:\n            # Allow 'page' by default. Works with most CMS'es, including django-fluent-pages.\n            parent_expr = Variable('page')\n            slot_expr = args[0]\n        else:\n            raise TemplateSyntaxError(\"\"\"{0} tag allows two arguments: 'parent object' 'slot name' and optionally: title=\"..\" role=\"..\".\"\"\".format(tag_name))\n\n        cls.validate_args(tag_name, *args, **kwargs)\n        return cls(\n            tag_name=tag_name,\n            as_var=as_var,\n            parent_expr=parent_expr,\n            slot_expr=slot_expr,\n            **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the string literal that is used in the template screens.", "response": "def get_title(self):\n        \"\"\"\n        Return the string literal that is used in the template.\n        The title is used in the admin screens.\n        \"\"\"\n        try:\n            return extract_literal(self.meta_kwargs['title'])\n        except KeyError:\n            slot = self.get_slot()\n            if slot is not None:\n                return slot.replace('_', ' ').title()\n\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_literal(templatevar):\n    # FilterExpression contains another 'var' that either contains a Variable or SafeData object.\n    if hasattr(templatevar, 'var'):\n        templatevar = templatevar.var\n        if isinstance(templatevar, SafeData):\n            # Literal in FilterExpression, can return.\n            return templatevar\n        else:\n            # Variable in FilterExpression, not going to work here.\n            return None\n\n    if templatevar[0] in ('\"', \"'\") and templatevar[-1] in ('\"', \"'\"):\n        return templatevar[1:-1]\n    else:\n        return None", "response": "Returns the value of a Literal in a FilterExpression."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if a template FilterExpression holds a literal boolean value.", "response": "def extract_literal_bool(templatevar):\n    \"\"\"\n    See if a template FilterExpression holds a literal boolean value.\n\n    :type templatevar: django.template.FilterExpression\n    :rtype: bool|None\n    \"\"\"\n    # FilterExpression contains another 'var' that either contains a Variable or SafeData object.\n    if hasattr(templatevar, 'var'):\n        templatevar = templatevar.var\n        if isinstance(templatevar, SafeData):\n            # Literal in FilterExpression, can return.\n            return is_true(templatevar)\n        else:\n            # Variable in FilterExpression, not going to work here.\n            return None\n\n    return is_true(templatevar)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_markup_plugin(language, model):\n    form = type(\"{0}MarkupItemForm\".format(language.capitalize()), (MarkupItemForm,), {\n        'default_language': language,\n    })\n\n    classname = \"{0}MarkupPlugin\".format(language.capitalize())\n    PluginClass = type(classname, (MarkupPluginBase,), {\n        'model': model,\n        'form': form,\n    })\n\n    return PluginClass", "response": "Create a new MarkupPlugin class that represents the plugin type."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary of keyword arguments for the generic parent_type / parent_id fields.", "response": "def get_parent_lookup_kwargs(parent_object):\n    \"\"\"\n    Return lookup arguments for the generic ``parent_type`` / ``parent_id`` fields.\n\n    :param parent_object: The parent object.\n    :type parent_object: :class:`~django.db.models.Model`\n    \"\"\"\n    if parent_object is None:\n        return dict(\n            parent_type__isnull=True,\n            parent_id=0\n        )\n    elif isinstance(parent_object, models.Model):\n        return dict(\n            parent_type=ContentType.objects.get_for_model(parent_object),\n            parent_id=parent_object.pk\n        )\n    else:\n        raise ValueError(\"parent_object is not a model!\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_parent_active_language_choices(parent_object, exclude_current=False):\n    assert parent_object is not None, \"Missing parent_object!\"\n\n    from .db import ContentItem\n    qs = ContentItem.objects \\\n        .parent(parent_object, limit_parent_language=False) \\\n        .values_list('language_code', flat=True).distinct()\n\n    languages = set(qs)\n\n    if exclude_current:\n        parent_lang = get_parent_language_code(parent_object)\n        languages.discard(parent_lang)\n\n    if parler_appsettings.PARLER_LANGUAGES and not parler_appsettings.PARLER_SHOW_EXCLUDED_LANGUAGE_TABS:\n        site_id = get_parent_site_id(parent_object)\n        try:\n            lang_dict = parler_appsettings.PARLER_LANGUAGES[site_id]\n        except KeyError:\n            lang_dict = ()\n\n        allowed_languages = set(item['code'] for item in lang_dict)\n        languages &= allowed_languages\n\n    # No multithreading issue here, object is instantiated for this user only.\n    choices = [(lang, str(get_language_title(lang))) for lang in languages if lang]\n    choices.sort(key=lambda tup: tup[1])\n    return choices", "response": "Get the currently active languages of a parent object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a placeholder by slot.", "response": "def get_by_slot(self, parent_object, slot):\n        \"\"\"\n        Return a placeholder by key.\n        \"\"\"\n        placeholder = self.parent(parent_object).get(slot=slot)\n        placeholder.parent = parent_object  # fill the reverse cache\n        return placeholder"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new object with the given parameters and return it.", "response": "def create_for_object(self, parent_object, slot, role='m', title=None):\n        \"\"\"\n        Create a placeholder with the given parameters\n        \"\"\"\n        from .db import Placeholder\n        parent_attrs = get_parent_lookup_kwargs(parent_object)\n        obj = self.create(\n            slot=slot,\n            role=role or Placeholder.MAIN,\n            title=title or slot.title().replace('_', ' '),\n            **parent_attrs\n        )\n        obj.parent = parent_object  # fill the reverse cache\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef translated(self, *language_codes):\n        # this API has the same semantics as django-parler's .translated() for familiarity.\n        # However, since this package doesn't filter in a related field, the ORM limitations don't apply.\n        if not language_codes:\n            language_codes = (get_language(),)\n        else:\n            # Since some code operates on a True/str switch, make sure that doesn't drip into this low level code.\n            for language_code in language_codes:\n                if not isinstance(language_code, six.string_types) or language_code.lower() in ('1', '0', 'true', 'false'):\n                    raise ValueError(\"ContentItemQuerySet.translated() expected language_code to be an ISO code\")\n\n        if len(language_codes) == 1:\n            return self.filter(language_code=language_codes[0])\n        else:\n            return self.filter(language_code__in=language_codes)", "response": "Return a new QuerySet with translated objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning all content items which are associated with a given parent object.", "response": "def parent(self, parent_object, limit_parent_language=True):\n        \"\"\"\n        Return all content items which are associated with a given parent object.\n        \"\"\"\n        lookup = get_parent_lookup_kwargs(parent_object)\n\n        # Filter the items by default, giving the expected \"objects for this parent\" items\n        # when the parent already holds the language state.\n        if limit_parent_language:\n            language_code = get_parent_language_code(parent_object)\n            if language_code:\n                lookup['language_code'] = language_code\n\n        return self.filter(**lookup)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef move_to_placeholder(self, placeholder, sort_order=None):\n        qs = self.all()  # Get clone\n        for item in qs:\n            # Change the item directly in the resultset.\n            item.move_to_placeholder(placeholder, sort_order=sort_order)\n            if sort_order is not None:\n                sort_order += 1\n\n        return qs", "response": "Move the entire queryset to a new object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncopies the entire queryset to a new object.", "response": "def copy_to_placeholder(self, placeholder, sort_order=None):\n        \"\"\"\n        .. versionadded: 1.0 Copy the entire queryset to a new object.\n\n        Returns a queryset with the newly created objects.\n        \"\"\"\n        qs = self.all()  # Get clone\n        for item in qs:\n            # Change the item directly in the resultset.\n            item.copy_to_placeholder(placeholder, sort_order=sort_order, in_place=True)\n            if sort_order is not None:\n                sort_order += 1\n\n        return qs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parent(self, parent_object, limit_parent_language=True):\n        return self.all().parent(parent_object, limit_parent_language)", "response": "Return all content items which are associated with a given parent object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_for_placeholder(self, placeholder, sort_order=1, language_code=None, **kwargs):\n        if language_code is None:\n            # Could also use get_language() or appsettings.FLUENT_CONTENTS_DEFAULT_LANGUAGE_CODE\n            # thus avoid the risk of performing an extra query here to the parent.\n            # However, this identical behavior to BaseContentItemFormSet,\n            # and the parent can be set already via Placeholder.objects.create_for_object()\n            language_code = get_parent_language_code(placeholder.parent)\n\n        obj = self.create(\n            placeholder=placeholder,\n            parent_type_id=placeholder.parent_type_id,\n            parent_id=placeholder.parent_id,\n            sort_order=sort_order,\n            language_code=language_code,\n            **kwargs\n        )\n\n        # Fill the reverse caches\n        obj.placeholder = placeholder\n        parent = getattr(placeholder, '_parent_cache', None)  # by GenericForeignKey (_meta.virtual_fields[0].cache_attr)\n        if parent is not None:\n            obj.parent = parent\n\n        return obj", "response": "Create a new Content Item for a given Placeholder."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the data of the placeholder fields.", "response": "def get_placeholder_data(self, request, obj=None):\n        \"\"\"\n        Return the data of the placeholder fields.\n        \"\"\"\n        # Return all placeholder fields in the model.\n        if not hasattr(self.model, '_meta_placeholder_fields'):\n            return []\n\n        data = []\n        for name, field in self.model._meta_placeholder_fields.items():\n            assert isinstance(field, PlaceholderField)\n            data.append(PlaceholderData(\n                slot=field.slot,\n                title=field.verbose_name.capitalize(),\n                fallback_language=None,  # Information cant' be known by \"render_placeholder\" in the template.\n            ))\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_all_allowed_plugins(self):\n        # Get all allowed plugins of the various placeholders together.\n        if not hasattr(self.model, '_meta_placeholder_fields'):\n            # No placeholder fields in the model, no need for inlines.\n            return []\n\n        plugins = []\n        for name, field in self.model._meta_placeholder_fields.items():\n            assert isinstance(field, PlaceholderField)\n            if field.plugins is None:\n                # no limitations, so all is allowed\n                return extensions.plugin_pool.get_plugins()\n            else:\n                plugins += field.plugins\n\n        return list(set(plugins))", "response": "Return all allowed plugins for the current model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_markup_model(fixed_language):\n    title = backend.LANGUAGE_NAMES.get(fixed_language) or fixed_language\n\n    objects = MarkupLanguageManager(fixed_language)\n\n    def save(self, *args, **kwargs):\n        self.language = fixed_language\n        MarkupItem.save(self, *args, **kwargs)\n\n    class Meta:\n        verbose_name = title\n        verbose_name_plural = _('%s items') % title\n        proxy = True\n\n    classname = \"{0}MarkupItem\".format(fixed_language.capitalize())\n\n    new_class = type(str(classname), (MarkupItem,), {\n        '__module__': MarkupItem.__module__,\n        'objects': objects,\n        'save': save,\n        'Meta': Meta,\n    })\n\n    # Make easily browsable\n    return new_class", "response": "Create a new MarkupItem model that saves itself in a single language."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a PlaceholderFormField instance for this database Field.", "response": "def formfield(self, **kwargs):\n        \"\"\"\n        Returns a :class:`PlaceholderFormField` instance for this database Field.\n        \"\"\"\n        defaults = {\n            'label': capfirst(self.verbose_name),\n            'help_text': self.help_text,\n            'required': not self.blank,\n        }\n        defaults.update(kwargs)\n        return PlaceholderFormField(slot=self.slot, plugins=self._plugins, **defaults)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the set of plugins that this field may display.", "response": "def plugins(self):\n        \"\"\"\n        Get the set of plugins that this field may display.\n        \"\"\"\n        from fluent_contents import extensions\n        if self._plugins is None:\n            return extensions.plugin_pool.get_plugins()\n        else:\n            try:\n                return extensions.plugin_pool.get_plugins_by_name(*self._plugins)\n            except extensions.PluginNotFound as e:\n                raise extensions.PluginNotFound(str(e) + \" Update the plugin list of '{0}.{1}' field or FLUENT_CONTENTS_PLACEHOLDER_CONFIG['{2}'] setting.\".format(self.model._meta.object_name, self.name, self.slot))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef value_from_object(self, obj):\n        try:\n            # not using self.attname, access the descriptor instead.\n            placeholder = getattr(obj, self.name)\n        except Placeholder.DoesNotExist:\n            return None   # Still allow ModelForm / admin to open and create a new Placeholder if the table was truncated.\n\n        return placeholder.id if placeholder else None", "response": "Internal method used to return the value of the object instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef can_use_cached_output(self, contentitem):\n        return contentitem.plugin.search_output and not contentitem.plugin.search_fields \\\n           and super(SearchRenderingPipe, self).can_use_cached_output(contentitem)", "response": "Return True if the contentitem can be cached output."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_item(self, contentitem):\n        plugin = contentitem.plugin\n        if not plugin.search_output and not plugin.search_fields:\n            # Only render items when the item was output will be indexed.\n            raise SkipItem\n\n        if not plugin.search_output:\n            output = ContentItemOutput('', cacheable=False)\n        else:\n            output = super(SearchRenderingPipe, self).render_item(contentitem)\n\n        if plugin.search_fields:\n            # Just add the results into the output, but avoid caching that somewhere.\n            output.html += plugin.get_search_text(contentitem)\n            output.cacheable = False\n\n        return output", "response": "Render the item - but render as search text instead."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_content_item_inlines(plugins=None, base=BaseContentItemInline):\n    COPY_FIELDS = (\n        'form', 'raw_id_fields', 'filter_vertical', 'filter_horizontal',\n        'radio_fields', 'prepopulated_fields', 'formfield_overrides', 'readonly_fields',\n    )\n    if plugins is None:\n        plugins = extensions.plugin_pool.get_plugins()\n\n    inlines = []\n    for plugin in plugins:  # self.model._supported_...()\n        # Avoid errors that are hard to trace\n        if not isinstance(plugin, extensions.ContentPlugin):\n            raise TypeError(\"get_content_item_inlines() expects to receive ContentPlugin instances, not {0}\".format(plugin))\n\n        ContentItemType = plugin.model\n\n        # Create a new Type that inherits CmsPageItemInline\n        # Read the static fields of the ItemType to override default appearance.\n        # This code is based on FeinCMS, (c) Simon Meers, BSD licensed\n        class_name = '%s_AutoInline' %  ContentItemType.__name__\n        attrs = {\n            '__module__': plugin.__class__.__module__,\n            'model': ContentItemType,\n\n            # Add metadata properties for template\n            'name': plugin.verbose_name,\n            'plugin': plugin,\n            'type_name': plugin.type_name,\n            'extra_fieldsets': plugin.fieldsets,\n            'cp_admin_form_template': plugin.admin_form_template,\n            'cp_admin_init_template': plugin.admin_init_template,\n        }\n\n        # Copy a restricted set of admin fields to the inline model too.\n        for name in COPY_FIELDS:\n            if getattr(plugin, name):\n                attrs[name] = getattr(plugin, name)\n\n        inlines.append(type(class_name, (base,), attrs))\n\n    # For consistency, enforce ordering\n    inlines.sort(key=lambda inline: inline.name.lower())\n\n    return inlines", "response": "Dynamically generate genuine django inlines for all registered content item types."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_oembed_providers():\n    global _provider_list, _provider_lock\n    if _provider_list is not None:\n        return _provider_list\n\n    # Allow only one thread to build the list, or make request to embed.ly.\n    _provider_lock.acquire()\n    try:\n        # And check whether that already succeeded when the lock is granted.\n        if _provider_list is None:\n            _provider_list = _build_provider_list()\n    finally:\n        # Always release if there are errors\n        _provider_lock.release()\n\n    return _provider_list", "response": "Get the list of OEmbed providers."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding the provider list from the app settings.", "response": "def _build_provider_list():\n    \"\"\"\n    Construct the provider registry, using the app settings.\n    \"\"\"\n    registry = None\n    if appsettings.FLUENT_OEMBED_SOURCE == 'basic':\n        registry = bootstrap_basic()\n    elif appsettings.FLUENT_OEMBED_SOURCE == 'embedly':\n        params = {}\n        if appsettings.MICAWBER_EMBEDLY_KEY:\n            params['key'] = appsettings.MICAWBER_EMBEDLY_KEY\n        registry = bootstrap_embedly(**params)\n    elif appsettings.FLUENT_OEMBED_SOURCE == 'noembed':\n        registry = bootstrap_noembed(nowrap=1)\n    elif appsettings.FLUENT_OEMBED_SOURCE == 'list':\n        # Fill list manually in the settings, e.g. to have a fixed set of supported secure providers.\n        registry = ProviderRegistry()\n        for regex, provider in appsettings.FLUENT_OEMBED_PROVIDER_LIST:\n            registry.register(regex, Provider(provider))\n    else:\n        raise ImproperlyConfigured(\"Invalid value of FLUENT_OEMBED_SOURCE, only 'basic', 'list', 'noembed' or 'embedly' is supported.\")\n\n    # Add any extra providers defined in the settings\n    for regex, provider in appsettings.FLUENT_OEMBED_EXTRA_PROVIDERS:\n        registry.register(regex, Provider(provider))\n\n    return registry"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch the OEmbed object from the registry and return the response as dictionary.", "response": "def get_oembed_data(url, max_width=None, max_height=None, **params):\n    \"\"\"\n    Fetch the OEmbed object, return the response as dictionary.\n    \"\"\"\n    if max_width:  params['maxwidth'] = max_width\n    if max_height: params['maxheight'] = max_height\n\n    registry = get_oembed_providers()\n    return registry.request(url, **params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all plugins grouped by category.", "response": "def group_plugins_into_categories(plugins):\n    \"\"\"\n    Return all plugins, grouped by category.\n    The structure is a {\"Categorynane\": [list of plugin classes]}\n    \"\"\"\n    if not plugins:\n        return {}\n    plugins = sorted(plugins, key=lambda p: p.verbose_name)\n    categories = {}\n\n    for plugin in plugins:\n        title = str(plugin.category or u\"\")  # enforce resolving ugettext_lazy proxies.\n        if title not in categories:\n            categories[title] = []\n        categories[title].append(plugin)\n\n    return categories"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plugin_categories_to_choices(categories):\n    choices = []\n    for category, items in categories.items():\n        if items:\n            plugin_tuples = tuple((plugin.type_name, plugin.verbose_name) for plugin in items)\n            if category:\n                choices.append((category, plugin_tuples))\n            else:\n                choices += plugin_tuples\n\n    choices.sort(key=lambda item: item[0])\n    return choices", "response": "Return a tuple of plugin model choices suitable for a select field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a new Media object to a new Media object.", "response": "def add_media(dest, media):\n    \"\"\"\n    Optimized version of django.forms.Media.__add__() that doesn't create new objects.\n    \"\"\"\n    if django.VERSION >= (2, 2):\n        dest._css_lists += media._css_lists\n        dest._js_lists += media._js_lists\n    elif django.VERSION >= (2, 0):\n        combined = dest + media\n        dest._css = combined._css\n        dest._js = combined._js\n    else:\n        dest.add_css(media._css)\n        dest.add_js(media._js)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_dummy_request(language=None):\n\n    if settings.ALLOWED_HOSTS and settings.ALLOWED_HOSTS != \"*\":\n        host = settings.ALLOWED_HOSTS[0]\n    else:\n        host = Site.objects.get_current().domain\n\n    request = RequestFactory().get(\"/\", HTTP_HOST=host)\n    request.session = {}\n    request.LANGUAGE_CODE = language or settings.LANGUAGE_CODE\n    # Needed for plugin rendering.\n    request.current_page = None\n\n    if 'django.contrib.auth' in settings.INSTALLED_APPS:\n        from django.contrib.auth.models import AnonymousUser\n        request.user = AnonymousUser()\n\n    return request", "response": "Returns a dummy Request instance populated with cms specific attributes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_render_language(contentitem):\n    plugin = contentitem.plugin\n\n    if plugin.render_ignore_item_language \\\n    or (plugin.cache_output and plugin.cache_output_per_language):\n        # Render the template in the current language.\n        # The cache also stores the output under the current language code.\n        #\n        # It would make sense to apply this for fallback content too,\n        # but that would be ambiguous however because the parent_object could also be a fallback,\n        # and that case can't be detected here. Hence, better be explicit when desiring multi-lingual content.\n        return get_language()  # Avoid switching the content,\n    else:\n        # Render the template in the ContentItem language.\n        # This makes sure that {% trans %} tag output matches the language of the model field data.\n        return contentitem.language_code", "response": "Returns the language code that should be used to render the content item."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef optimize_logger_level(logger, log_level):\n    function_name = _log_functions[log_level]\n    if getattr(logger, function_name) is _dummy_log:\n        return False\n\n    is_level_logged = logger.isEnabledFor(log_level)\n    if not is_level_logged:\n        setattr(logger, function_name, _dummy_log)\n\n    return is_level_logged", "response": "This function is used to optimize the logging level of a logger."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_search_field_values(contentitem):\n    plugin = contentitem.plugin\n    values = []\n    for field_name in plugin.search_fields:\n        value = getattr(contentitem, field_name)\n\n        # Just assume all strings may contain HTML.\n        # Not checking for just the PluginHtmlField here.\n        if value and isinstance(value, six.string_types):\n            value = get_cleaned_string(value)\n\n        values.append(value)\n\n    return values", "response": "Extract the search fields from the model."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_layout_view(self, request):\n        template_name = request.GET['name']\n\n        # Check if template is allowed, avoid parsing random templates\n        templates = dict(appconfig.SIMPLECMS_TEMPLATE_CHOICES)\n        if template_name not in templates:\n            jsondata = {'success': False, 'error': 'Template not found'}\n            status = 404\n        else:\n            # Extract placeholders from the template, and pass to the client.\n            template = get_template(template_name)\n            placeholders = get_template_placeholder_data(template)\n\n            jsondata = {\n                'placeholders': [p.as_dict() for p in placeholders],\n            }\n            status = 200\n\n        jsonstr = json.dumps(jsondata)\n        return HttpResponse(jsonstr, content_type='application/json', status=status)", "response": "Return the metadata about a layout"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply soft hyphenation to the text.", "response": "def softhyphen_filter(textitem, html):\n    \"\"\"\n    Apply soft hyphenation to the text, which inserts ``&shy;`` markers.\n    \"\"\"\n    language = textitem.language_code\n\n    # Make sure the Django language code gets converted to what django-softhypen 1.0.2 needs.\n    if language == 'en':\n        language = 'en-us'\n    elif '-' not in language:\n        language = \"{0}-{0}\".format(language)\n\n    return hyphenate(html, language=language)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_cached_placeholder_output(parent_object, placeholder_name):\n    if not PlaceholderRenderingPipe.may_cache_placeholders():\n        return None\n\n    language_code = get_parent_language_code(parent_object)\n    cache_key = get_placeholder_cache_key_for_parent(parent_object, placeholder_name, language_code)\n    return cache.get(cache_key)", "response": "Get the cached output for a placeholder."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenders a placeholder and returns the rendered HTML output.", "response": "def render_placeholder(request, placeholder, parent_object=None, template_name=None, cachable=None, limit_parent_language=True, fallback_language=None):\n    \"\"\"\n    Render a :class:`~fluent_contents.models.Placeholder` object.\n    Returns a :class:`~fluent_contents.models.ContentItemOutput` object\n    which contains the HTML output and :class:`~django.forms.Media` object.\n\n    This function also caches the complete output of the placeholder\n    when all individual items are cacheable.\n\n    :param request: The current request object.\n    :type request: :class:`~django.http.HttpRequest`\n    :param placeholder: The placeholder object.\n    :type placeholder: :class:`~fluent_contents.models.Placeholder`\n    :param parent_object: Optional, the parent object of the placeholder (already implied by the placeholder)\n    :param template_name: Optional template name used to concatenate the placeholder output.\n    :type template_name: str | None\n    :param cachable: Whether the output is cachable, otherwise the full output will not be cached.\n                     Default: False when using a template, True otherwise.\n    :type cachable: bool | None\n    :param limit_parent_language: Whether the items should be limited to the parent language.\n    :type limit_parent_language: bool\n    :param fallback_language: The fallback language to use if there are no items in the current language. Passing ``True`` uses the default :ref:`FLUENT_CONTENTS_DEFAULT_LANGUAGE_CODE`.\n    :type fallback_language: bool/str\n    :rtype: :class:`~fluent_contents.models.ContentItemOutput`\n    \"\"\"\n    output = PlaceholderRenderingPipe(request).render_placeholder(\n        placeholder=placeholder,\n        parent_object=parent_object,\n        template_name=template_name,\n        cachable=cachable,\n        limit_parent_language=limit_parent_language,\n        fallback_language=fallback_language\n    )\n\n    # Wrap the result after it's stored in the cache.\n    if markers.is_edit_mode(request):\n        output.html = markers.wrap_placeholder_output(output.html, placeholder)\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrenders a list of items as HTML string.", "response": "def render_content_items(request, items, template_name=None, cachable=None):\n    \"\"\"\n    Render a list of :class:`~fluent_contents.models.ContentItem` objects as HTML string.\n    This is a variation of the :func:`render_placeholder` function.\n\n    Note that the items are not filtered in any way by parent or language.\n    The items are rendered as-is.\n\n    :param request: The current request object.\n    :type request: :class:`~django.http.HttpRequest`\n    :param items: The list or queryset of objects to render. Passing a queryset is preferred.\n    :type items: list or queryset of :class:`~fluent_contents.models.ContentItem`.\n    :param template_name: Optional template name used to concatenate the placeholder output.\n    :type template_name: Optional[str]\n    :param cachable: Whether the output is cachable, otherwise the full output will not be cached.\n                     Default: False when using a template, True otherwise.\n    :type cachable: Optional[bool]\n\n    :rtype: :class:`~fluent_contents.models.ContentItemOutput`\n    \"\"\"\n    if not items:\n        output = ContentItemOutput(mark_safe(u\"<!-- no items to render -->\"))\n    else:\n        output = RenderingPipe(request).render_items(\n            placeholder=None,\n            items=items,\n            parent_object=None,\n            template_name=template_name,\n            cachable=cachable\n        )\n\n    # Wrap the result after it's stored in the cache.\n    if markers.is_edit_mode(request):\n        output.html = markers.wrap_anonymous_output(output.html)\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender a placeholder object to search text.", "response": "def render_placeholder_search_text(placeholder, fallback_language=None):\n    \"\"\"\n    Render a :class:`~fluent_contents.models.Placeholder` object to search text.\n    This text can be used by an indexer (e.g. haystack) to produce content search for a parent object.\n\n    :param placeholder: The placeholder object.\n    :type placeholder: :class:`~fluent_contents.models.Placeholder`\n    :param fallback_language: The fallback language to use if there are no items in the current language.\n                              Passing ``True`` uses the default :ref:`FLUENT_CONTENTS_DEFAULT_LANGUAGE_CODE`.\n    :type fallback_language: bool|str\n    :rtype: str\n    \"\"\"\n    parent_object = placeholder.parent   # this is a cached lookup thanks to PlaceholderFieldDescriptor\n    language = get_parent_language_code(parent_object)\n    output = SearchRenderingPipe(language).render_placeholder(\n        placeholder=placeholder,\n        parent_object=parent_object,\n        fallback_language=fallback_language\n    )\n    return output.html"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render(self, name, value, attrs=None, renderer=None):\n        other_instance_languages = None\n        if value and value != \"-DUMMY-\":\n            if get_parent_language_code(self.parent_object):\n                # Parent is a multilingual object, provide information\n                # for the copy dialog.\n                other_instance_languages = get_parent_active_language_choices(\n                    self.parent_object, exclude_current=True)\n\n        context = {\n            'cp_plugin_list': list(self.plugins),\n            'placeholder_id': '',\n            'placeholder_slot': self.slot,\n            'other_instance_languages': other_instance_languages,\n        }\n        return mark_safe(render_to_string('admin/fluent_contents/placeholderfield/widget.html', context))", "response": "Render the placeholder field."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the set of plugins that this widget should display.", "response": "def plugins(self):\n        \"\"\"\n        Get the set of plugins that this widget should display.\n        \"\"\"\n        from fluent_contents import extensions   # Avoid circular reference because __init__.py imports subfolders too\n        if self._plugins is None:\n            return extensions.plugin_pool.get_plugins()\n        else:\n            return extensions.plugin_pool.get_plugins_by_name(*self._plugins)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a redirect response for the exception.", "response": "def process_exception(self, request, exception):\n        \"\"\"\n        Return a redirect response for the :class:`~fluent_contents.extensions.HttpRedirectRequest`\n        \"\"\"\n        if isinstance(exception, HttpRedirectRequest):\n            return HttpResponseRedirect(exception.url, status=exception.status)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_text(text, language=None):\n    # Get the filter\n    text_filter = SUPPORTED_LANGUAGES.get(language, None)\n    if not text_filter:\n        raise ImproperlyConfigured(\"markup filter does not exist: {0}. Valid options are: {1}\".format(\n            language, ', '.join(list(SUPPORTED_LANGUAGES.keys()))\n        ))\n\n    # Convert.\n    return text_filter(text)", "response": "Render the text using the template filters provided by Django."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the derived table data for all objects tracked as remaining.", "response": "def fetch_remaining_instances(self):\n        \"\"\"Read the derived table data for all objects tracked as remaining (=not found in the cache).\"\"\"\n        if self.remaining_items:\n            self.remaining_items = ContentItem.objects.get_real_instances(self.remaining_items)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the output in the correct ordering.", "response": "def get_output(self, include_exceptions=False):\n        \"\"\"\n        Return the output in the correct ordering.\n        :rtype: list[Tuple[contentitem, O]]\n        \"\"\"\n        # Order all rendered items in the correct sequence.\n        # Don't assume the derived tables are in perfect shape, hence the dict + KeyError handling.\n        # The derived tables could be truncated/reset or store_output() could be omitted.\n        ordered_output = []\n        for item_id in self.output_ordering:\n            contentitem = self.item_source[item_id]\n            try:\n                output = self.item_output[item_id]\n            except KeyError:\n                # The item was not rendered!\n                if not include_exceptions:\n                    continue\n\n                output = self.MISSING\n            else:\n                # Filter exceptions out.\n                if not include_exceptions:\n                    if isinstance(output, Exception) or output is self.SKIPPED:\n                        continue\n\n            ordered_output.append((contentitem, output))\n\n        return ordered_output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render_items(self, placeholder, items, parent_object=None, template_name=None, cachable=None):\n        # Unless it was done before, disable polymorphic effects.\n        is_queryset = False\n        if hasattr(items, \"non_polymorphic\"):\n            is_queryset = True\n            if not items.polymorphic_disabled and items._result_cache is None:\n                items = items.non_polymorphic()\n\n        # See if the queryset contained anything.\n        # This test is moved here, to prevent earlier query execution.\n        if not items:\n            logger.debug(\"- no items in placeholder '%s'\", get_placeholder_debug_name(placeholder))\n            return ContentItemOutput(mark_safe(u\"<!-- no items in placeholder '{0}' -->\".format(escape(get_placeholder_name(placeholder)))), cacheable=True)\n\n        # Tracked data during rendering:\n        result = self.result_class(\n            request=self.request,\n            parent_object=parent_object,\n            placeholder=placeholder,\n            items=items,\n            all_cacheable=self._can_cache_merged_output(template_name, cachable),\n        )\n        if self.edit_mode:\n            result.set_uncachable()\n\n        if is_queryset:\n            # Phase 1: get cached output\n            self._fetch_cached_output(items, result=result)\n            result.fetch_remaining_instances()\n        else:\n            # The items is either a list of manually created items, or it's a QuerySet.\n            # Can't prevent reading the subclasses only, so don't bother with caching here.\n            result.add_remaining_list(items)\n\n        # Start the actual rendering of remaining items.\n        if result.remaining_items:\n            # Phase 2: render remaining items\n            self._render_uncached_items(result.remaining_items, result=result)\n\n        # And merge all items together.\n        return self.merge_output(result, items, template_name)", "response": "Render the items in the given placeholder."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfetches all items from the cache and store them in the result.", "response": "def _fetch_cached_output(self, items, result):\n        \"\"\"\n        First try to fetch all items from the cache.\n        The items are 'non-polymorphic', so only point to their base class.\n        If these are found, there is no need to query the derived data from the database.\n        \"\"\"\n        if not appsettings.FLUENT_CONTENTS_CACHE_OUTPUT or not self.use_cached_output:\n            result.add_remaining_list(items)\n            return\n\n        for contentitem in items:\n            result.add_ordering(contentitem)\n            output = None\n\n            try:\n                plugin = contentitem.plugin\n            except PluginNotFound as ex:\n                result.store_exception(contentitem, ex)  # Will deal with that later.\n                logger.debug(\"- item #%s has no matching plugin: %s\", contentitem.pk, str(ex))\n                continue\n\n            # Respect the cache output setting of the plugin\n            if self.can_use_cached_output(contentitem):\n                result.add_plugin_timeout(plugin)\n                output = plugin.get_cached_output(result.placeholder_name, contentitem)\n\n                # Support transition to new output format.\n                if output is not None and not isinstance(output, ContentItemOutput):\n                    output = None\n                    logger.debug(\"Flushed cached output of {0}#{1} to store new ContentItemOutput format (key: {2})\".format(\n                        plugin.type_name,\n                        contentitem.pk,\n                        get_placeholder_name(contentitem.placeholder)\n                    ))\n\n            # For debugging, ignore cached values when the template is updated.\n            if output and settings.DEBUG:\n                cachekey = get_rendering_cache_key(result.placeholder_name, contentitem)\n                if is_template_updated(self.request, contentitem, cachekey):\n                    output = None\n\n            if output:\n                result.store_output(contentitem, output)\n            else:\n                result.add_remaining(contentitem)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntell whether the code should try reading cached output for the given contentitem.", "response": "def can_use_cached_output(self, contentitem):\n        \"\"\"\n        Tell whether the code should try reading cached output\n        \"\"\"\n        plugin = contentitem.plugin\n        return appsettings.FLUENT_CONTENTS_CACHE_OUTPUT and plugin.cache_output and contentitem.pk"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _render_uncached_items(self, items, result):\n        for contentitem in items:\n            # Render the item.\n            # Allow derived classes to skip it.\n            try:\n                output = self.render_item(contentitem)\n            except PluginNotFound as ex:\n                result.store_exception(contentitem, ex)\n                logger.debug(\"- item #%s has no matching plugin: %s\", contentitem.pk, str(ex))\n                continue\n            except SkipItem:\n                result.set_skipped(contentitem)\n                continue\n\n            # Try caching it.\n            self._try_cache_output(contentitem, output, result=result)\n            if self.edit_mode:\n                output.html = markers.wrap_contentitem_output(output.html, contentitem)\n\n            result.store_output(contentitem, output)", "response": "Render a list of items that didn t exist in the cache yet."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders the individual item.", "response": "def render_item(self, contentitem):\n        \"\"\"\n        Render the individual item.\n        May raise :class:`SkipItem` to ignore an item.\n        \"\"\"\n        render_language = get_render_language(contentitem)\n        with smart_override(render_language):\n            # Plugin output is likely HTML, but it should be placed in mark_safe() to raise awareness about escaping.\n            # This is just like Django's Input.render() and unlike Node.render().\n            return contentitem.plugin._render_contentitem(self.request, contentitem)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncombines all rendered items with a template.", "response": "def merge_output(self, result, items, template_name):\n        \"\"\"\n        Combine all rendered items. Allow rendering the items with a template,\n        to inserting separators or nice start/end code.\n        \"\"\"\n        html_output, media = self.get_html_output(result, items)\n\n        if not template_name:\n            merged_html = mark_safe(u''.join(html_output))\n        else:\n            context = {\n                'contentitems': list(zip(items, html_output)),\n                'parent_object': result.parent_object,  # Can be None\n                'edit_mode': self.edit_mode,\n            }\n\n            context = PluginContext(self.request, context)\n            merged_html = render_to_string(template_name, context.flatten())\n\n        return ContentItemOutput(merged_html, media, cacheable=result.all_cacheable, cache_timeout=result.all_timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncollecting all HTML from the rendered items in the correct ordering.", "response": "def get_html_output(self, result, items):\n        \"\"\"\n        Collect all HTML from the rendered items, in the correct ordering.\n        The media is also collected in the same ordering, in case it's handled by django-compressor for example.\n        \"\"\"\n        html_output = []\n        merged_media = Media()\n        for contentitem, output in result.get_output(include_exceptions=True):\n            if output is ResultTracker.MISSING:\n                # Likely get_real_instances() didn't return an item for it.\n                # The get_real_instances() didn't return an item for the derived table. This happens when either:\n                # 1. that table is truncated/reset, while there is still an entry in the base ContentItem table.\n                #    A query at the derived table happens every time the page is being rendered.\n                # 2. the model was completely removed which means there is also a stale ContentType object.\n                class_name = _get_stale_item_class_name(contentitem)\n                html_output.append(mark_safe(u\"<!-- Missing derived model for ContentItem #{id}: {cls}. -->\\n\".format(id=contentitem.pk, cls=class_name)))\n                logger.warning(\"Missing derived model for ContentItem #{id}: {cls}.\".format(id=contentitem.pk, cls=class_name))\n            elif isinstance(output, Exception):\n                html_output.append(u'<!-- error: {0} -->\\n'.format(str(output)))\n            else:\n                html_output.append(output.html)\n                add_media(merged_media, output.media)\n\n        return html_output, merged_media"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_placeholder(self, placeholder, parent_object=None, template_name=None, cachable=None, limit_parent_language=True, fallback_language=None):\n        placeholder_name = get_placeholder_debug_name(placeholder)\n        logger.debug(\"Rendering placeholder '%s'\", placeholder_name)\n\n        # Determine whether the placeholder can be cached.\n        cachable = self._can_cache_merged_output(template_name, cachable)\n        try_cache = cachable and self.may_cache_placeholders()\n        logger.debug(\"- try_cache=%s cachable=%s template_name=%s\", try_cache, cachable, template_name)\n\n        if parent_object is None:\n            # To support filtering the placeholders by parent language, the parent object needs to be known.\n            # Fortunately, the PlaceholderFieldDescriptor makes sure this doesn't require an additional query.\n            parent_object = placeholder.parent\n\n        # Fetch the placeholder output from cache.\n        language_code = get_parent_language_code(parent_object)\n        cache_key = None\n        output = None\n        if try_cache:\n            cache_key = get_placeholder_cache_key_for_parent(parent_object, placeholder.slot, language_code)\n            output = cache.get(cache_key)\n            if output:\n                logger.debug(\"- fetched cached output\")\n\n        if output is None:\n            # Get the items, and render them\n            items, is_fallback = self._get_placeholder_items(placeholder, parent_object, limit_parent_language, fallback_language, try_cache)\n            output = self.render_items(placeholder, items, parent_object, template_name, cachable)\n\n            if is_fallback:\n                # Caching fallbacks is not supported yet,\n                # content could be rendered in a different gettext language domain.\n                output.cacheable = False\n\n            # Store the full-placeholder contents in the cache.\n            if try_cache and output.cacheable:\n                if output.cache_timeout is not DEFAULT_TIMEOUT:\n                    # The timeout is based on the minimal timeout used in plugins.\n                    cache.set(cache_key, output, output.cache_timeout)\n                else:\n                    # Don't want to mix into the default 0/None issue.\n                    cache.set(cache_key, output)\n\n        return output", "response": "Render a single placeholder."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister a plugin with the CMS.", "response": "def register(self, plugin):\n        \"\"\"\n        Make a plugin known to the CMS.\n\n        :param plugin: The plugin class, deriving from :class:`ContentPlugin`.\n        :type plugin: :class:`ContentPlugin`\n\n        The plugin will be instantiated once, just like Django does this with :class:`~django.contrib.admin.ModelAdmin` classes.\n        If a plugin is already registered, this will raise a :class:`PluginAlreadyRegistered` exception.\n        \"\"\"\n        # Duck-Typing does not suffice here, avoid hard to debug problems by upfront checks.\n        assert issubclass(plugin, ContentPlugin), \"The plugin must inherit from `ContentPlugin`\"\n        assert plugin.model, \"The plugin has no model defined\"\n        assert issubclass(plugin.model, ContentItem), \"The plugin model must inherit from `ContentItem`\"\n        assert issubclass(plugin.form, ContentItemForm), \"The plugin form must inherit from `ContentItemForm`\"\n\n        name = plugin.__name__  # using class here, no instance created yet.\n        name = name.lower()\n        if name in self.plugins:\n            raise PluginAlreadyRegistered(\"{0}: a plugin with this name is already registered\".format(name))\n\n        # Avoid registering 2 plugins to the exact same model. If you want to reuse code, use proxy models.\n        if plugin.model in self._name_for_model:\n            # Having 2 plugins for one model breaks ContentItem.plugin and the frontend code\n            # that depends on using inline-model names instead of plugins. Good luck fixing that.\n            # Better leave the model==plugin dependency for now.\n            existing_plugin = self.plugins[self._name_for_model[plugin.model]]\n            raise ModelAlreadyRegistered(\"Can't register the model {0} to {2}, it's already registered to {1}!\".format(\n                plugin.model.__name__,\n                existing_plugin.name,\n                plugin.__name__\n            ))\n\n        # Make a single static instance, similar to ModelAdmin.\n        plugin_instance = plugin()\n        self.plugins[name] = plugin_instance\n        self._name_for_model[plugin.model] = name       # Track reverse for model.plugin link\n\n        # Only update lazy indexes if already created\n        if self._name_for_ctype_id is not None:\n            self._name_for_ctype_id[plugin.type_id] = name\n\n        return plugin"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_allowed_plugins(self, placeholder_slot):\n        # See if there is a limit imposed.\n        slot_config = appsettings.FLUENT_CONTENTS_PLACEHOLDER_CONFIG.get(placeholder_slot) or {}\n        plugins = slot_config.get('plugins')\n        if not plugins:\n            return self.get_plugins()\n        else:\n            try:\n                return self.get_plugins_by_name(*plugins)\n            except PluginNotFound as e:\n                raise PluginNotFound(str(e) + \" Update the plugin list of the FLUENT_CONTENTS_PLACEHOLDER_CONFIG['{0}'] setting.\".format(placeholder_slot))", "response": "Return the plugins which are supported in the given placeholder name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of plugins by name or class name.", "response": "def get_plugins_by_name(self, *names):\n        \"\"\"\n        Return a list of plugins by plugin class, or name.\n        \"\"\"\n        self._import_plugins()\n        plugin_instances = []\n        for name in names:\n            if isinstance(name, six.string_types):\n                try:\n                    plugin_instances.append(self.plugins[name.lower()])\n                except KeyError:\n                    raise PluginNotFound(\"No plugin named '{0}'.\".format(name))\n            elif isinstance(name, type) and issubclass(name, ContentPlugin):\n                # Will also allow classes instead of strings.\n                plugin_instances.append(self.plugins[self._name_for_model[name.model]])\n            else:\n                raise TypeError(\"get_plugins_by_name() expects a plugin name or class, not: {0}\".format(name))\n        return plugin_instances"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning all model classes which are exposed by plugins.", "response": "def get_model_classes(self):\n        \"\"\"\n        Return all :class:`~fluent_contents.models.ContentItem` model classes which are exposed by plugins.\n        \"\"\"\n        self._import_plugins()\n        return [plugin.model for plugin in self.plugins.values()]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_plugin_by_model(self, model_class):\n        self._import_plugins()                       # could happen during rendering that no plugin scan happened yet.\n        assert issubclass(model_class, ContentItem)  # avoid confusion between model instance and class here!\n\n        try:\n            name = self._name_for_model[model_class]\n        except KeyError:\n            raise PluginNotFound(\"No plugin found for model '{0}'.\".format(model_class.__name__))\n        return self.plugins[name]", "response": "Returns the corresponding plugin for a given model class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _import_plugins(self):\n        if self.detected:\n            return\n\n        # In some cases, plugin scanning may start during a request.\n        # Make sure there is only one thread scanning for plugins.\n        self.scanLock.acquire()\n        if self.detected:\n            return  # previous threaded released + completed\n\n        try:\n            import_apps_submodule(\"content_plugins\")\n            self.detected = True\n        finally:\n            self.scanLock.release()", "response": "Internal function to import all plugin packages."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\napplying all filters for a given HTML snippet.", "response": "def apply_filters(instance, html, field_name):\n    \"\"\"\n    Run all filters for a given HTML snippet.\n    Returns the results of the pre-filter and post-filter as tuple.\n\n    This function can be called from the :meth:`~django.db.models.Model.full_clean` method in the model.\n    That function is called when the form values are assigned.\n    For example:\n\n    .. code-block:: python\n\n        def full_clean(self, *args, **kwargs):\n            super(TextItem, self).full_clean(*args, **kwargs)\n            self.html, self.html_final = apply_filters(self, self.html, field_name='html')\n\n    :type instance: fluent_contents.models.ContentItem\n    :raise ValidationError: when one of the filters detects a problem.\n    \"\"\"\n    try:\n        html = apply_pre_filters(instance, html)\n\n        # Perform post processing. This does not effect the original 'html'\n        html_final = apply_post_filters(instance, html)\n    except ValidationError as e:\n        if hasattr(e, 'error_list'):\n            # The filters can raise a \"dump\" ValidationError with a single error.\n            # However, during post_clean it's expected that the fields are named.\n            raise ValidationError({\n                field_name: e.error_list\n            })\n        raise\n\n    return html, html_final"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply_pre_filters(instance, html):\n    # Allow pre processing. Typical use-case is HTML syntax correction.\n    for post_func in appsettings.PRE_FILTER_FUNCTIONS:\n        html = post_func(instance, html)\n\n    return html", "response": "Apply pre filters to the HTML source code."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply post processing functions to the given HTML.", "response": "def apply_post_filters(instance, html):\n    \"\"\"\n    Allow post processing functions to change the text.\n    This change is not saved in the original text.\n\n    :type instance: fluent_contents.models.ContentItem\n    :raise ValidationError: when one of the filters detects a problem.\n    \"\"\"\n    for post_func in appsettings.POST_FILTER_FUNCTIONS:\n        html = post_func(instance, html)\n\n    return html"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clear_commentarea_cache(comment):\n    parent = comment.content_object\n    for instance in CommentsAreaItem.objects.parent(parent):\n        instance.clear_cache()", "response": "Clean the plugin output cache of a rendered plugin."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parent_site(self, site):\n        # Avoid auto filter if site is already set.\n        self._parent_site = site\n\n        if sharedcontent_appsettings.FLUENT_SHARED_CONTENT_ENABLE_CROSS_SITE:\n            # Allow content to be shared between all sites:\n            return self.filter(Q(parent_site=site) | Q(is_cross_site=True))\n        else:\n            return self.filter(parent_site=site)", "response": "Filter to the given site only give content relevant for that site."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a single site instance.", "response": "def _single_site(self):\n        \"\"\"\n        Make sure the queryset is filtered on a parent site, if that didn't happen already.\n        \"\"\"\n        if appsettings.FLUENT_CONTENTS_FILTER_SITE_ID and self._parent_site is None:\n            return self.parent_site(settings.SITE_ID)\n        else:\n            return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_template_placeholder_data(template):\n    # Find the instances.\n    nodes = get_node_instances(template, PagePlaceholderNode)\n\n    # Avoid duplicates, wrap in a class.\n    names = set()\n    result = []\n    for pageplaceholdernode in nodes:\n        data = PlaceholderData(\n            slot=pageplaceholdernode.get_slot(),\n            title=pageplaceholdernode.get_title(),\n            role=pageplaceholdernode.get_role(),\n            fallback_language=pageplaceholdernode.get_fallback_language(),\n        )\n\n        if data.slot not in names:\n            result.append(data)\n            names.add(data.slot)\n\n    return result", "response": "Returns the list of PlaceholderData objects found in a template."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inspect_model(self, model):\n        # See which interesting fields the model holds.\n        url_fields = sorted(f for f in model._meta.fields if isinstance(f, (PluginUrlField, models.URLField)))\n        file_fields = sorted(f for f in model._meta.fields if isinstance(f, (PluginImageField, models.FileField)))\n        html_fields = sorted(f for f in model._meta.fields if isinstance(f, (models.TextField, PluginHtmlField)))\n        all_fields = [f.name for f in (file_fields + html_fields + url_fields)]\n        if not all_fields:\n            return []\n\n        if model.__name__ in self.exclude:\n            self.stderr.write(\"Skipping {0} ({1})\\n\".format(model.__name__, \", \".join(all_fields)))\n            return []\n\n        sys.stderr.write(\"Inspecting {0} ({1})\\n\".format(model.__name__, \", \".join(all_fields)))\n\n        q_notnull = reduce(operator.or_, (Q(**{\"{0}__isnull\".format(f): False}) for f in all_fields))\n        qs = model.objects.filter(q_notnull).order_by('pk')\n\n        urls = []\n        for object in qs:\n            # HTML fields need proper html5lib parsing\n            for field in html_fields:\n                value = getattr(object, field.name)\n                if value:\n                    html_images = self.extract_html_urls(value)\n                    urls += html_images\n\n                    for image in html_images:\n                        self.show_match(object, image)\n\n            # Picture fields take the URL from the storage class.\n            for field in file_fields:\n                value = getattr(object, field.name)\n                if value:\n                    value = unquote_utf8(value.url)\n                    urls.append(value)\n                    self.show_match(object, value)\n\n            # URL fields can be read directly.\n            for field in url_fields:\n                value = getattr(object, field.name)\n                if value:\n                    if isinstance(value, six.text_type):\n                        value = force_text(value)\n                    else:\n                        value = value.to_db_value()  # AnyUrlValue\n\n                    urls.append(value)\n                    self.show_match(object, value)\n        return urls", "response": "Inspect a single model."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntakes all <img src =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =.. srcset =", "response": "def extract_html_urls(self, html):\n        \"\"\"\n        Take all ``<img src=\"..\">`` from the HTML\n        \"\"\"\n        p = HTMLParser(tree=treebuilders.getTreeBuilder(\"dom\"))\n        dom = p.parse(html)\n        urls = []\n\n        for img in dom.getElementsByTagName('img'):\n            src = img.getAttribute('src')\n            if src:\n                urls.append(unquote_utf8(src))\n\n            srcset = img.getAttribute('srcset')\n            if srcset:\n                urls += self.extract_srcset(srcset)\n\n        for source in dom.getElementsByTagName('source'):\n            srcset = source.getAttribute('srcset')\n            if srcset:\n                urls += self.extract_srcset(srcset)\n\n        for source in dom.getElementsByTagName('a'):\n            href = source.getAttribute('href')\n            if href:\n                urls.append(unquote_utf8(href))\n\n        return urls"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract the set of images from a source set.", "response": "def extract_srcset(self, srcset):\n        \"\"\"\n        Handle ``srcset=\"image.png 1x, image@2x.jpg 2x\"``\n        \"\"\"\n        urls = []\n        for item in srcset.split(','):\n            if item:\n                urls.append(unquote_utf8(item.rsplit(' ', 1)[0]))\n        return urls"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting the translation from the ContentItems.", "response": "def on_delete_model_translation(instance, **kwargs):\n    \"\"\"\n    Make sure ContentItems are deleted when a translation in deleted.\n    \"\"\"\n    translation = instance\n\n    parent_object = translation.master\n    parent_object.set_current_language(translation.language_code)\n\n    # Also delete any associated plugins\n    # Placeholders are shared between languages, so these are not affected.\n    for item in ContentItem.objects.parent(parent_object, limit_parent_language=True):\n        item.delete()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake an HTML fragment and processes it using html5lib to ensure that the HTML is well - formed.", "response": "def clean_html(input, sanitize=False):\n    \"\"\"\n    Takes an HTML fragment and processes it using html5lib to ensure that the HTML is well-formed.\n\n    :param sanitize: Remove unwanted HTML tags and attributes.\n\n    >>> clean_html(\"<p>Foo<b>bar</b></p>\")\n    u'<p>Foo<b>bar</b></p>'\n    >>> clean_html(\"<p>Foo<b>bar</b><i>Ooops!</p>\")\n    u'<p>Foo<b>bar</b><i>Ooops!</i></p>'\n    >>> clean_html('<p>Foo<b>bar</b>& oops<a href=\"#foo&bar\">This is a <>link</a></p>')\n    u'<p>Foo<b>bar</b>&amp; oops<a href=#foo&amp;bar>This is a &lt;&gt;link</a></p>'\n    \"\"\"\n    parser_kwargs = {}\n    serializer_kwargs = {}\n    if sanitize:\n        if HTMLSanitizer is None:\n            # new syntax as of 0.99999999/1.0b9 (Released on July 14, 2016)\n            serializer_kwargs['sanitize'] = True\n        else:\n            parser_kwargs['tokenizer'] = HTMLSanitizer\n\n    p = HTMLParser(tree=treebuilders.getTreeBuilder(\"dom\"), **parser_kwargs)\n    dom_tree = p.parseFragment(input)\n    walker = treewalkers.getTreeWalker(\"dom\")\n    stream = walker(dom_tree)\n\n    s = HTMLSerializer(omit_optional_tags=False, **serializer_kwargs)\n    return \"\".join(s.serialize(stream))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the contents as a dictionary for client - side export.", "response": "def as_dict(self):\n        \"\"\"\n        Return the contents as dictionary, for client-side export.\n        The dictionary contains the fields:\n\n        * ``slot``\n        * ``title``\n        * ``role``\n        * ``fallback_language``\n        * ``allowed_plugins``\n        \"\"\"\n        plugins = self.get_allowed_plugins()\n        return {\n            'slot': self.slot,\n            'title': self.title,\n            'role': self.role,\n            'fallback_language': self.fallback_language,\n            'allowed_plugins': [plugin.name for plugin in plugins],\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nforwarding the MarkupItem model to the correct proxy model that implements the given language.", "response": "def _forwards(apps, schema_editor):\n    \"\"\"\n    Make sure that the MarkupItem model actually points\n    to the correct proxy model, that implements the given language.\n    \"\"\"\n    # Need to work on the actual models here.\n    from fluent_contents.plugins.markup.models import LANGUAGE_MODEL_CLASSES\n    from fluent_contents.plugins.markup.models import MarkupItem\n    from django.contrib.contenttypes.models import ContentType\n\n    ctype = ContentType.objects.get_for_model(MarkupItem)\n\n    for language, proxy_model in LANGUAGE_MODEL_CLASSES.items():\n        proxy_ctype = ContentType.objects.get_for_model(proxy_model, for_concrete_model=False)\n        MarkupItem.objects.filter(\n            polymorphic_ctype=ctype, language=language\n        ).update(\n            polymorphic_ctype=proxy_ctype\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_formset(self, request, obj=None, **kwargs):\n        def _placeholder_initial(p):\n            # p.as_dict() returns allowed_plugins too for the client-side API.\n            return {\n                'slot': p.slot,\n                'title': p.title,\n                'role': p.role,\n            }\n\n        # Note this method is called twice, the second time in get_fieldsets() as `get_formset(request).form`\n        initial = []\n        if request.method == \"GET\":\n            placeholder_admin = self._get_parent_modeladmin()\n\n            # Grab the initial data from the parent PlaceholderEditorBaseMixin\n            data = placeholder_admin.get_placeholder_data(request, obj)\n            initial = [_placeholder_initial(d) for d in data]\n\n            # Order initial properly,\n\n        # Inject as default parameter to the constructor\n        # This is the BaseExtendedGenericInlineFormSet constructor\n        FormSetClass = super(PlaceholderEditorInline, self).get_formset(request, obj, **kwargs)\n        FormSetClass.__init__ = curry(FormSetClass.__init__, initial=initial)\n        return FormSetClass", "response": "Returns a FormSet subclass with initial data for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_inline_instances(self, request, *args, **kwargs):\n        inlines = super(PlaceholderEditorAdmin, self).get_inline_instances(request, *args, **kwargs)\n\n        extra_inline_instances = []\n        inlinetypes = self.get_extra_inlines()\n        for InlineType in inlinetypes:\n            inline_instance = InlineType(self.model, self.admin_site)\n            extra_inline_instances.append(inline_instance)\n\n        return extra_inline_instances + inlines", "response": "Create the inlines for the admin including the placeholder and contentitem inlines."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the placeholder data as dictionary.", "response": "def get_placeholder_data_view(self, request, object_id):\n        \"\"\"\n        Return the placeholder data as dictionary.\n        This is used in the client for the \"copy\" functionality.\n        \"\"\"\n        language = 'en'  #request.POST['language']\n        with translation.override(language):  # Use generic solution here, don't assume django-parler is used now.\n            obj = self.get_object(request, object_id)\n\n        if obj is None:\n            json = {'success': False, 'error': 'Page not found'}\n            status = 404\n        elif not self.has_change_permission(request, obj):\n            json = {'success': False, 'error': 'No access to page'}\n            status = 403\n        else:\n            # Fetch the forms that would be displayed,\n            # return the data as serialized form data.\n            status = 200\n            json = {\n                'success': True,\n                'object_id': object_id,\n                'language_code': language,\n                'formset_forms': self._get_object_formset_data(request, obj),\n            }\n\n        return JsonResponse(json, status=status)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_args(method_or_func):\n    try:\n        # Python 3.0+\n        args = list(inspect.signature(method_or_func).parameters.keys())\n    except AttributeError:\n        # Python 2.7\n        args = inspect.getargspec(method_or_func).args\n    return args", "response": "Returns method or function arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef jwt_optional(fn):\n    @wraps(fn)\n    def wrapper(*args, **kwargs):\n        try:\n            jwt_data = _decode_jwt_from_headers()\n            ctx_stack.top.jwt = jwt_data\n        except (NoAuthorizationError, InvalidHeaderError):\n            pass\n        return fn(*args, **kwargs)\n    return wrapper", "response": "Decorator that will decorate a view function with this decorator that will check the request for a valid JWT and put it into the application context."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decode_jwt(encoded_token):\n    secret = config.decode_key\n    algorithm = config.algorithm\n    audience = config.audience\n    return jwt.decode(encoded_token, secret, algorithms=[algorithm], audience=audience)", "response": "Decodes a JWT encoded string into a base64 - encoded token."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init_app(self, app):\n        # Save this so we can use it later in the extension\n        if not hasattr(app, 'extensions'):   # pragma: no cover\n            app.extensions = {}\n        app.extensions['flask-jwt-simple'] = self\n\n        # Set all the default configurations for this extension\n        self._set_default_configuration_options(app)\n        self._set_error_handler_callbacks(app)\n\n        # Set propagate exceptions, so all of our error handlers properly\n        # work in production\n        app.config['PROPAGATE_EXCEPTIONS'] = True", "response": "Register this extension with the flask app"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the error handler callbacks used by this extension.", "response": "def _set_error_handler_callbacks(self, app):\n        \"\"\"\n        Sets the error handler callbacks used by this extension\n        \"\"\"\n        @app.errorhandler(NoAuthorizationError)\n        def handle_no_auth_error(e):\n            return self._unauthorized_callback(str(e))\n\n        @app.errorhandler(InvalidHeaderError)\n        def handle_invalid_header_error(e):\n            return self._invalid_token_callback(str(e))\n\n        @app.errorhandler(jwt.ExpiredSignatureError)\n        def handle_expired_error(e):\n            return self._expired_token_callback()\n\n        @app.errorhandler(jwt.InvalidTokenError)\n        def handle_invalid_token_error(e):\n            return self._invalid_token_callback(str(e))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_default_configuration_options(app):\n        # Options for JWTs when the TOKEN_LOCATION is headers\n        app.config.setdefault('JWT_HEADER_NAME', 'Authorization')\n        app.config.setdefault('JWT_HEADER_TYPE', 'Bearer')\n\n        # How long an a token created with 'create_jwt' will last before\n        # it expires (when using the default jwt_data_callback function).\n        app.config.setdefault('JWT_EXPIRES', datetime.timedelta(hours=1))\n\n        # What algorithm to use to sign the token. See here for a list of options:\n        # https://github.com/jpadilla/pyjwt/blob/master/jwt/api_jwt.py\n        app.config.setdefault('JWT_ALGORITHM', 'HS256')\n\n        # Key that acts as the identity for the JWT\n        app.config.setdefault('JWT_IDENTITY_CLAIM', 'sub')\n\n        # Expected value of the audience claim\n        app.config.setdefault('JWT_DECODE_AUDIENCE', None)\n\n        # Secret key to sign JWTs with. Only used if a symmetric algorithm is\n        # used (such as the HS* algorithms).\n        app.config.setdefault('JWT_SECRET_KEY', None)\n\n        # Keys to sign JWTs with when use when using an asymmetric\n        # (public/private key) algorithms, such as RS* or EC*\n        app.config.setdefault('JWT_PRIVATE_KEY', None)\n        app.config.setdefault('JWT_PUBLIC_KEY', None)", "response": "Sets the default configuration options used by this extension."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef releases(release_id=None, **kwargs):\n    if not 'id' in kwargs and release_id is not None:\n        kwargs['release_id'] = release_id\n        return Fred().release(**kwargs)\n    return Fred().releases(**kwargs)", "response": "Get all releases of economic data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets an economic data series.", "response": "def series(identifier=None, **kwargs):\n    \"\"\"Get an economic data series.\"\"\"\n    if identifier:\n        kwargs['series_id'] = identifier\n    if 'release' in kwargs:\n        kwargs.pop('release')\n        path = 'release'\n    elif 'releases' in kwargs:\n        kwargs.pop('releases')\n        path = 'release'\n    else:\n        path = None\n    return Fred().series(path, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef source(source_id=None, **kwargs):\n    if source_id is not None:\n        kwargs['source_id'] = source_id\n    elif 'id' in kwargs:\n        source_id = kwargs.pop('id')\n        kwargs['source_id'] = source_id\n    if 'releases' in kwargs:\n        kwargs.pop('releases')\n        path = 'releases'\n    else:\n        path = None\n    return Fred().source(path, **kwargs)", "response": "Get a source of economic data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the sources of economic data.", "response": "def sources(source_id=None, **kwargs):\n    \"\"\"Get the sources of economic data.\"\"\"\n    if source_id or 'id' in kwargs:\n        return source(source_id, **kwargs)\n    return Fred().sources(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate the URL path with the Fred endpoint and given arguments.", "response": "def _create_path(self, *args):\n        \"\"\"Create the URL path with the Fred endpoint and given arguments.\"\"\"\n        args = filter(None, args)\n        path = self.endpoint + '/'.join(args)\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms a GET request againt the Fred API endpoint.", "response": "def get(self, *args, **kwargs):\n        \"\"\"Perform a GET request againt the Fred API endpoint.\"\"\"\n        location = args[0]\n        params = self._get_keywords(location, kwargs)\n        url = self._create_path(*args)\n        request = requests.get(url, params=params)\n        content = request.content\n        self._request = request\n        return self._output(content)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_keywords(self, location, keywords):\n        if 'xml' in keywords:\n            keywords.pop('xml')\n            self.xml = True\n        else:\n            keywords['file_type'] = 'json'\n        if 'id' in keywords:\n            if location != 'series':\n                location = location.rstrip('s')\n            key = '%s_id' % location\n            value = keywords.pop('id')\n            keywords[key] = value\n        if 'start' in keywords:\n            time = keywords.pop('start')\n            keywords['realtime_start'] = time\n        if 'end' in keywords:\n            time = keywords.pop('end')\n            keywords['realtime_end'] = time\n        if 'sort' in keywords:\n            order = keywords.pop('sort')\n            keywords['sort_order'] = order\n        keywords['api_key'] = self.api_key\n        return keywords", "response": "Format GET request s parameters from keywords."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef item_extra_kwargs(self, item):\n        if use_feed_image:\n            feed_image = item.feed_image\n            if feed_image:\n                image_complete_url = urljoin(\n                    self.get_site_url(), feed_image.file.url\n                )\n            else:\n                image_complete_url = \"\"\n\n        content_field = getattr(item, self.item_content_field)\n        try:\n            content = expand_db_html(content_field)\n        except:\n            content = content_field.__html__()\n\n        soup = BeautifulSoup(content, 'html.parser')\n        # Remove style attribute to remove large botton padding\n        for div in soup.find_all(\"div\", {'class': 'responsive-object'}):\n            del div['style']\n        # Add site url to image source\n        for img_tag in soup.findAll('img'):\n            if img_tag.has_attr('src'):\n                img_tag['src'] = urljoin(self.get_site_url(), img_tag['src'])\n\n        fields_to_add = {\n            'content': soup.prettify(formatter=\"html\"),\n        }\n\n        if use_feed_image:\n            fields_to_add['image'] = image_complete_url\n        else:\n            fields_to_add['image'] = \"\"\n\n        return fields_to_add", "response": "Returns a dictionary that is used with\n            the add_item call of the custom feed generator."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef treenav_undefined_url(request, item_slug):\n    item = get_object_or_404(treenav.MenuItem, slug=item_slug)  # noqa\n    # do something with item here and return an HttpResponseRedirect\n    raise Http404", "response": "This is a sample view that can be used to provide custom handlers for undefined menu items on a per - item basis."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef refresh_hrefs(self, request):\n        for item in treenav.MenuItem.objects.all():\n            item.save()  # refreshes the HREF\n        self.message_user(request, _('Menu item HREFs refreshed successfully.'))\n        info = self.model._meta.app_label, self.model._meta.model_name\n        changelist_url = reverse('admin:%s_%s_changelist' % info, current_app=self.admin_site.name)\n        return redirect(changelist_url)", "response": "Refresh all the cached menu item HREFs in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves all MenuItems from Cache.", "response": "def clean_cache(self, request):\n        \"\"\"\n        Remove all MenuItems from Cache.\n        \"\"\"\n        treenav.delete_cache()\n        self.message_user(request, _('Cache menuitem cache cleaned successfully.'))\n        info = self.model._meta.app_label, self.model._meta.model_name\n        changelist_url = reverse('admin:%s_%s_changelist' % info, current_app=self.admin_site.name)\n        return redirect(changelist_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rebuild_tree(self, request):\n        '''\n        Rebuilds the tree and clears the cache.\n        '''\n        self.model.objects.rebuild()\n        self.message_user(request, _('Menu Tree Rebuilt.'))\n        return self.clean_cache(request)", "response": "Rebuilds the tree and clears the cache."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrebuild the tree after saving items related to parent.", "response": "def save_related(self, request, form, formsets, change):\n        \"\"\"\n        Rebuilds the tree after saving items related to parent.\n        \"\"\"\n        super(MenuItemAdmin, self).save_related(request, form, formsets, change)\n        self.model.objects.rebuild()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _calculate_dispersion(X: Union[pd.DataFrame, np.ndarray], labels: np.ndarray, centroids: np.ndarray) -> float:\n        disp = np.sum(np.sum([np.abs(inst - centroids[label]) ** 2 for inst, label in zip(X, labels)]))  # type: float\n        return disp", "response": "Calculate the dispersion between actual points and their assigned centroids"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the gap value of the given data n_refs and n_clusters and return the resutling gap value and n_clusters.", "response": "def _calculate_gap(self, X: Union[pd.DataFrame, np.ndarray], n_refs: int, n_clusters: int) -> Tuple[float, int]:\n        \"\"\"\n        Calculate the gap value of the given data, n_refs, and number of clusters.\n        Return the resutling gap value and n_clusters\n        \"\"\"\n        # Holder for reference dispersion results\n        ref_dispersions = np.zeros(n_refs)  # type: np.ndarray\n\n        # For n_references, generate random sample and perform kmeans getting resulting dispersion of each loop\n        for i in range(n_refs):\n\n            # Create new random reference set\n            random_data = np.random.random_sample(size=X.shape)  # type: np.ndarray\n\n            # Fit to it, getting the centroids and labels, and add to accumulated reference dispersions array.\n            centroids, labels = kmeans2(data=random_data,\n                                        k=n_clusters,\n                                        iter=10,\n                                        minit='points')  # type: Tuple[np.ndarray, np.ndarray]\n            dispersion = self._calculate_dispersion(X=random_data, labels=labels, centroids=centroids)  # type: float\n            ref_dispersions[i] = dispersion\n\n        # Fit cluster to original data and create dispersion calc.\n        centroids, labels = kmeans2(data=X, k=n_clusters, iter=10, minit='points')\n        dispersion = self._calculate_dispersion(X=X, labels=labels, centroids=centroids)\n\n        # Calculate gap statistic\n        gap_value = np.mean(np.log(ref_dispersions)) - np.log(dispersion)\n\n        return gap_value, int(n_clusters)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _process_with_rust(self, X: Union[pd.DataFrame, np.ndarray], n_refs: int, cluster_array: np.ndarray):\n        from gap_statistic.rust import gapstat\n        for label, gap_value in gapstat.optimal_k(X, list(cluster_array)):\n            yield (gap_value, label)", "response": "Process gap stat using pure rust\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _process_with_joblib(self, X: Union[pd.DataFrame, np.ndarray], n_refs: int, cluster_array: np.ndarray):\n        if Parallel is None:\n            raise EnvironmentError('joblib is not installed; cannot use joblib as the parallel backend!')\n\n        with Parallel(n_jobs=self.n_jobs) as parallel:\n            for gap_value, n_clusters in parallel(delayed(self._calculate_gap)(X, n_refs, n_clusters)\n                                                  for n_clusters in cluster_array):\n                yield (gap_value, n_clusters)", "response": "Process calling of. calculate_gap method using joblib."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _process_with_multiprocessing(self, X: Union[pd.DataFrame, np.ndarray], n_refs: int, cluster_array: np.ndarray):\n        with ProcessPoolExecutor(max_workers=self.n_jobs) as executor:\n\n            jobs = [executor.submit(self._calculate_gap, X, n_refs, n_clusters)\n                    for n_clusters in cluster_array\n                    ]\n\n            for future in as_completed(jobs):\n                gap_value, k = future.result()\n                yield (gap_value, k)", "response": "Process calling of. calculate_gap method using the multiprocessing library."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _process_non_parallel(self, X: Union[pd.DataFrame, np.ndarray], n_refs: int, cluster_array: np.ndarray):\n        for gap_value, n_clusters in [self._calculate_gap(X, n_refs, n_clusters)\n                                      for n_clusters in cluster_array]:\n            yield (gap_value, n_clusters)", "response": "Process calling of. calculate_gap method using no parallel backend ; simple for loop"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the last migration batch.", "response": "def get_last(self):\n        \"\"\"\n        Get the last migration batch.\n\n        :rtype: list\n        \"\"\"\n        query = self.table().where('batch', self.get_last_batch_number())\n\n        return query.order_by('migration', 'desc').get()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compile_insert(self, query, values):\n        # Essentially we will force every insert to be treated as a batch insert which\n        # simply makes creating the SQL easier for us since we can utilize the same\n        # basic routine regardless of an amount of records given to us to insert.\n        table = self.wrap_table(query.from__)\n\n        if not isinstance(values, list):\n            values = [values]\n\n        columns = self.columnize(values[0].keys())\n\n        # We need to build a list of parameter place-holders of values that are bound\n        # to the query. Each insert should have the exact same amount of parameter\n        # bindings so we can just go off the first list of values in this array.\n        parameters = self.parameterize(values[0].values())\n\n        value = ['(%s)' % parameters] * len(values)\n\n        parameters = ', '.join(value)\n\n        return 'INSERT INTO %s (%s) VALUES %s' % (table, columns, parameters)", "response": "Compile an insert SQL statement for the given values."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_alter_table_sql(self, diff):\n        sql = []\n\n        for column_diff in diff.changed_columns.values():\n            if self.is_unchanged_binary_column(column_diff):\n                continue\n\n            old_column_name = column_diff.old_column_name\n            column = column_diff.column\n\n            if any([column_diff.has_changed('type'),\n                    column_diff.has_changed('precision'),\n                    column_diff.has_changed('scale'),\n                    column_diff.has_changed('fixed')]):\n                query = 'ALTER ' + old_column_name + ' TYPE ' + self.get_sql_type_declaration(column.to_dict())\n                sql.append('ALTER TABLE ' + diff.name + ' ' + query)\n\n            if column_diff.has_changed('default') or column_diff.has_changed('type'):\n                if column.get_default() is None:\n                    default_clause = ' DROP DEFAULT'\n                else:\n                    default_clause = ' SET' + self.get_default_value_declaration_sql(column.to_dict())\n\n                query = 'ALTER ' + old_column_name + default_clause\n                sql.append('ALTER TABLE ' + diff.name + ' ' + query)\n\n            if column_diff.has_changed('notnull'):\n                op = 'DROP'\n                if column.get_notnull():\n                    op = 'SET'\n\n                query = 'ALTER ' + old_column_name + ' ' + op + ' NOT NULL'\n                sql.append('ALTER TABLE ' + diff.name + ' ' + query)\n\n            if column_diff.has_changed('autoincrement'):\n                if column.get_autoincrement():\n                    seq_name = self.get_identity_sequence_name(diff.name, old_column_name)\n\n                    sql.append('CREATE SEQUENCE ' + seq_name)\n                    sql.append('SELECT setval(\\'' + seq_name + '\\', '\n                               '(SELECT MAX(' + old_column_name + ') FROM ' + diff.name + '))')\n                    query = 'ALTER ' + old_column_name + ' SET DEFAULT nextval(\\'' + seq_name + '\\')'\n                    sql.append('ALTER TABLE ' + diff.name + ' ' + query)\n                else:\n                    query = 'ALTER ' + old_column_name + ' DROP DEFAULT'\n                    sql.append('ALTER TABLE ' + diff.name + ' ' + query)\n\n            if column_diff.has_changed('length'):\n                query = 'ALTER ' + old_column_name + ' TYPE ' + self.get_sql_type_declaration(column.to_dict())\n                sql.append('ALTER TABLE ' + diff.name + ' ' + query)\n\n        for old_column_name, column in diff.renamed_columns.items():\n            sql.append('ALTER TABLE ' + diff.name + ' '\n                       'RENAME COLUMN ' + old_column_name + ' TO ' + column.get_name())\n\n        return sql", "response": "Get the ALTER TABLE SQL statement for the table diff."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _date_based_where(self, type, query, where):\n        value = str(where['value']).zfill(2)\n        value = self.parameter(value)\n\n        return 'strftime(\\'%s\\', %s) %s %s'\\\n               % (type, self.wrap(where['column']),\n                  where['operator'], value)", "response": "Compile a date based where clause"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compile_select(self, query):\n        sql = super(MySqlQueryGrammar, self).compile_select(query)\n\n        if query.unions:\n            sql = '(%s) %s' % (sql, self._compile_unions(query))\n\n        return sql", "response": "Compile a select query into SQL\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncompiling the lock into SQL", "response": "def _compile_lock(self, query, value):\n        \"\"\"\n        Compile the lock into SQL\n\n        :param query: A QueryBuilder instance\n        :type query: QueryBuilder\n\n        :param value: The lock value\n        :type value: bool or str\n\n        :return: The compiled lock\n        :rtype: str\n        \"\"\"\n        if isinstance(value, basestring):\n            return value\n\n        if value is True:\n            return 'FOR UPDATE'\n        elif value is False:\n            return 'LOCK IN SHARE MODE'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compile_update(self, query, values):\n        sql = super(MySqlQueryGrammar, self).compile_update(query, values)\n\n        if query.orders:\n            sql += ' %s' % self._compile_orders(query, query.orders)\n\n        if query.limit_:\n            sql += ' %s' % self._compile_limit(query, query.limit_)\n\n        return sql.rstrip()", "response": "Compile an update statement into SQL"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef collapse(self):\n        results = []\n\n        if isinstance(self._items, dict):\n            items = self._items.values()\n\n        for values in items:\n            if isinstance(values, Collection):\n                values = values.all()\n\n            results += values\n\n        return Collection(results)", "response": "Collapse the collection items into a single element"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine if an element is in the collection.", "response": "def contains(self, key, value=None):\n        \"\"\"\n        Determine if an element is in the collection\n\n        :param key: The element\n        :type key: int or str\n\n        :param value: The value of the element\n        :type value: mixed\n\n        :return: Whether the element is in the collection\n        :rtype: bool\n        \"\"\"\n        if value is not None:\n            if isinstance(self._items, list):\n                return key in self._items and self._items[self._items.index(key)] == value\n\n            return self._items.get(key) == value\n\n        return key in self._items"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a list with the values of a given key.", "response": "def lists(self, value, key=None):\n        \"\"\"\n        Get a list with the values of a given key\n\n        :rtype: list\n        \"\"\"\n        results = map(lambda x: x[value], self._items)\n\n        return list(results)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns a map over each of the items in the collection.", "response": "def map(self, callback):\n        \"\"\"\n        Run a map over each of the item.\n\n        :param callback: The map function\n        :type callback: callable\n\n        :rtype: Collection\n        \"\"\"\n        if isinstance(self._items, dict):\n            return Collection(list(map(callback, self._items.values())))\n\n        return Collection(list(map(callback, self._items)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unique(self):\n        seen = set()\n        seen_add = seen.add\n\n        return Collection([x for x in self._items if not (x in seen or seen_add(x))])", "response": "Return only unique items from the collection list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a set of relationships onto the collection.", "response": "def load(self, *relations):\n        \"\"\"\n        Load a set of relationships onto the collection.\n        \"\"\"\n        if len(self._items) > 0:\n            query = self.first().new_query().with_(*relations)\n\n            self._items = query.eager_load_relations(self._items)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncompiles a foreign key command.", "response": "def compile_foreign(self, blueprint, command, _):\n        \"\"\"\n        Compile a foreign key command.\n\n        :param blueprint: The blueprint\n        :type blueprint: Blueprint\n\n        :param command: The command\n        :type command: Fluent\n\n        :rtype: str\n        \"\"\"\n        table = self.wrap_table(blueprint)\n\n        on = self.wrap_table(command.on)\n\n        columns = self.columnize(command.columns)\n\n        on_columns = self.columnize(command.references\n                                    if isinstance(command.references, list)\n                                    else [command.references])\n\n        sql = 'ALTER TABLE %s ADD CONSTRAINT %s ' % (table, command.index)\n\n        sql += 'FOREIGN KEY (%s) REFERENCES %s (%s)' % (columns, on, on_columns)\n\n        if command.get('on_delete'):\n            sql += ' ON DELETE %s' % command.on_delete\n\n        if command.get('on_update'):\n            sql += ' ON UPDATE %s' % command.on_update\n\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_columns(self, blueprint):\n        columns = []\n\n        for column in blueprint.get_added_columns():\n            sql = self.wrap(column) + ' ' + self._get_type(column)\n\n            columns.append(self._add_modifiers(sql, blueprint, column))\n\n        return columns", "response": "Get the blueprint s columns definitions."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_modifiers(self, sql, blueprint, column):\n        for modifier in self._modifiers:\n            method = '_modify_%s' % modifier\n\n            if hasattr(self, method):\n                sql += getattr(self, method)(blueprint, column)\n\n        return sql", "response": "Add the column modifiers to the sql"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the pivot attributes from a model.", "response": "def _clean_pivot_attributes(self, model):\n        \"\"\"\n        Get the pivot attributes from a model.\n\n        :type model: eloquent.Model\n        \"\"\"\n        values = {}\n        delete_keys = []\n\n        for key, value in model.get_attributes().items():\n            if key.find('pivot_') == 0:\n                values[key[6:]] = value\n\n                delete_keys.append(key)\n\n        for key in delete_keys:\n            delattr(model, key)\n\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a QuerySet that will add the constraints for a relationship count query on the same table.", "response": "def get_relation_count_query_for_self_join(self, query, parent):\n        \"\"\"\n        Add the constraints for a relationship count query on the same table.\n\n        :type query: eloquent.orm.Builder\n        :type parent: eloquent.orm.Builder\n\n        :rtype: eloquent.orm.Builder\n        \"\"\"\n        query.select(QueryExpression('COUNT(*)'))\n\n        table_prefix = self._query.get_query().get_connection().get_table_prefix()\n\n        hash_ = self.get_relation_count_hash()\n        query.from_('%s AS %s%s' % (self._table, table_prefix, hash_))\n\n        key = self.wrap(self.get_qualified_parent_key_name())\n\n        return query.where('%s.%s' % (hash_, self._foreign_key), '=', QueryExpression(key))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_select_columns(self, columns=None):\n        if columns == ['*'] or columns is None:\n            columns = ['%s.*' % self._related.get_table()]\n\n        return columns + self._get_aliased_pivot_columns()", "response": "Set the select clause for the relation query."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the pivot columns for the relation.", "response": "def _get_aliased_pivot_columns(self):\n        \"\"\"\n        Get the pivot columns for the relation.\n\n        :rtype: list\n        \"\"\"\n        defaults = [self._foreign_key, self._other_key]\n\n        columns = []\n\n        for column in defaults + self._pivot_columns:\n            value = '%s.%s AS pivot_%s' % (self._table, column, column)\n            if value not in columns:\n                columns.append('%s.%s AS pivot_%s' % (self._table, column, column))\n\n        return columns"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the join clause for the relation query.", "response": "def _set_join(self, query=None):\n        \"\"\"\n        Set the join clause for the relation query.\n\n        :param query: The query builder\n        :type query: eloquent.orm.Builder\n\n        :return: self\n        :rtype: BelongsToMany\n        \"\"\"\n        if not query:\n            query = self._query\n\n        base_table = self._related.get_table()\n\n        key = '%s.%s' % (base_table, self._related.get_key_name())\n\n        query.join(self._table, key, '=', self.get_other_key())\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmatch the eagerly loaded results to their parents.", "response": "def match(self, models, results, relation):\n        \"\"\"\n        Match the eagerly loaded results to their parents.\n\n        :type models: list\n        :type results: Collection\n        :type relation:  str\n        \"\"\"\n        dictionary = self._build_dictionary(results)\n\n        for model in models:\n            key = model.get_key()\n\n            if key in dictionary:\n                collection = self._related.new_collection(dictionary[key])\n\n                model.set_relation(relation, collection)\n\n        return models"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save(self, model, joining=None, touch=True):\n        if joining is None:\n            joining = {}\n\n        model.save({'touch': False})\n\n        self.attach(model.get_key(), joining, touch)\n\n        return model", "response": "Save a new model and attach it to the parent model."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _attach_new(self, records, current, touch=True):\n        changes = {\n            'attached': [],\n            'updated': []\n        }\n\n        for id, attributes in records.items():\n            if id not in current:\n                self.attach(id, attributes, touch)\n\n                changes['attached'].append(id)\n            elif len(attributes) > 0 and self.update_existing_pivot(id, attributes, touch):\n                changes['updated'].append(id)\n\n        return changes", "response": "Attach all of the IDs that aren t in the current dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates an existing pivot record on the table.", "response": "def update_existing_pivot(self, id, attributes, touch=True):\n        \"\"\"\n        Update an existing pivot record on the table.\n        \"\"\"\n        if self.updated_at() in self._pivot_columns:\n            attributes = self.set_timestamps_on_attach(attributes, True)\n\n        updated = self._new_picot_statement_for_id(id).update(attributes)\n\n        if touch:\n            self.touch_if_touching()\n\n        return updated"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query(self):\n        query = QueryBuilder(self, self._query_grammar, self._post_processor)\n\n        return query", "response": "Begin a fluent query"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nforce a soft delete on a soft deleted model.", "response": "def force_delete(self):\n        \"\"\"\n        Force a hard delete on a soft deleted model.\n        \"\"\"\n        self._force_deleting = True\n\n        self.delete()\n\n        self._force_deleting = False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform the actual delete query on this instance.", "response": "def _do_perform_delete_on_model(self):\n        \"\"\"\n        Perform the actual delete query on this model instance.\n        \"\"\"\n        if self._force_deleting:\n            return self.with_trashed().where(self.get_key_name(), self.get_key()).force_delete()\n\n        return self._run_soft_delete()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef restore(self):\n        setattr(self, self.get_deleted_at_column(), None)\n\n        self.set_exists(True)\n\n        result = self.save()\n\n        return result", "response": "Restore a soft - deleted model instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a join clause to the query", "response": "def join(self, table, one=None,\n             operator=None, two=None, type='inner', where=False):\n        \"\"\"\n        Add a join clause to the query\n\n        :param table: The table to join with, can also be a JoinClause instance\n        :type table: str or JoinClause\n\n        :param one: The first column of the join condition\n        :type one: str\n\n        :param operator: The operator of the join condition\n        :type operator: str\n\n        :param two: The second column of the join condition\n        :type two: str\n\n        :param type: The join type\n        :type type: str\n\n        :param where: Whether to use a \"where\" rather than a \"on\"\n        :type where: bool\n\n        :return: The current QueryBuilder instance\n        :rtype: QueryBuilder\n        \"\"\"\n        if isinstance(table, JoinClause):\n            self.joins.append(table)\n        else:\n            if one is None:\n                raise ArgumentError('Missing \"one\" argument')\n\n            join = JoinClause(table, type)\n\n            self.joins.append(join.on(\n                one, operator, two, 'and', where\n            ))\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef join_where(self, table, one, operator, two, type='inner'):\n        return self.join(table, one, operator, two, type, True)", "response": "Add a join where clause to the current QueryBuilder instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a where in with a sub select to the query", "response": "def _where_in_sub(self, column, query, boolean, negate=False):\n        \"\"\"\n        Add a where in with a sub select to the query\n\n        :param column: The column\n        :type column: str\n\n        :param query: A QueryBuilder instance\n        :type query: QueryBuilder\n\n        :param boolean: The boolean operator\n        :type boolean: str\n\n        :param negate: Whether it is a not where in\n        :param negate: bool\n\n        :return: The current QueryBuilder instance\n        :rtype: QueryBuilder\n        \"\"\"\n        if negate:\n            type = 'not_in_sub'\n        else:\n            type = 'in_sub'\n\n        self.wheres.append({\n            'type': type,\n            'column': column,\n            'query': query,\n            'boolean': boolean\n        })\n\n        self.merge_bindings(query)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef or_having(self, column, operator=None, value=None):\n        return self.having(column, operator, value, 'or')", "response": "Add a having clause to the current QueryBuilder instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef union(self, query, all=False):\n        self.unions.append({\n            'query': query,\n            'all': all\n        })\n\n        return self.merge_bindings(query)", "response": "Adds a union statement to the query"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting a query for a single record by id", "response": "def find(self, id, columns=None):\n        \"\"\"\n        Execute a query for a single record by id\n\n        :param id: The id of the record to retrieve\n        :type id: mixed\n\n        :param columns: The columns of the record to retrive\n        :type columns: list\n\n        :return: mixed\n        :rtype: mixed\n        \"\"\"\n        if not columns:\n            columns = ['*']\n\n        return self.where('id', '=', id).first(1, columns)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef first(self, limit=1, columns=None):\n        if not columns:\n            columns = ['*']\n\n        results = self.take(limit).get(columns)\n\n        if len(results) > 0:\n            return results[0]\n\n        return", "response": "Execute the query and get the first result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_fresh(self, columns=None):\n        if not columns:\n            columns = ['*']\n\n        if not self.columns:\n            self.columns = columns\n\n        return self._processor.process_select(self, self._run_select())", "response": "Execute the query as a fresh select statement and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_list_select(self, column, key=None):\n        if key is None:\n            elements = [column]\n        else:\n            elements = [column, key]\n\n        select = []\n        for elem in elements:\n            dot = elem.find('.')\n\n            if dot >= 0:\n                select.append(column[dot + 1:])\n            else:\n                select.append(elem)\n\n        return select", "response": "Returns the list of values that should be used in a list of key - value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef increment(self, column, amount=1, extras=None):\n        wrapped = self._grammar.wrap(column)\n\n        if extras is None:\n            extras = {}\n\n        columns = {\n            column: self.raw('%s + %s' % (wrapped, amount))\n        }\n        columns.update(extras)\n\n        return self.update(**columns)", "response": "Increment a column s value by a given amount"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, id=None):\n        if id is not None:\n            self.where('id', '=', id)\n\n        sql = self._grammar.compile_delete(self)\n\n        return self._connection.delete(sql, self.get_bindings())", "response": "Delete a record from the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmerging a list of where clauses and bindings into the current where list", "response": "def merge_wheres(self, wheres, bindings):\n        \"\"\"\n        Merge a list of where clauses and bindings\n\n        :param wheres: A list of where clauses\n        :type wheres: list\n\n        :param bindings: A list of bindings\n        :type bindings: list\n\n        :rtype: None\n        \"\"\"\n        self.wheres = self.wheres + wheres\n        self._bindings['where'] = self._bindings['where'] + bindings"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes the migrate make command.", "response": "def execute(self, i, o):\n        \"\"\"\n        Executes the command.\n\n        :type i: cleo.inputs.input.Input\n        :type o: cleo.outputs.output.Output\n        \"\"\"\n        super(MigrateMakeCommand, self).execute(i, o)\n\n        creator = MigrationCreator()\n\n        name = i.get_argument('name')\n        table = i.get_option('table')\n        create = bool(i.get_option('create'))\n\n        if not table and create is not False:\n            table = create\n\n        path = i.get_option('path')\n        if path is None:\n            path = self._get_migration_path()\n\n        file_ = self._write_migration(creator, name, table, create, path)\n\n        o.writeln('<info>Create migration: <comment>%s</comment></info>' % file_)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove(self, builder, model):\n        column = model.get_qualified_deleted_at_column()\n\n        query = builder.get_query()\n\n        wheres = []\n        for where in query.wheres:\n            # If the where clause is a soft delete date constraint,\n            # we will remove it from the query and reset the keys\n            # on the wheres. This allows the developer to include\n            # deleted model in a relationship result set that is lazy loaded.\n            if not self._is_soft_delete_constraint(where, column):\n                wheres.append(where)\n\n        query.wheres = wheres", "response": "Removes the scope from a given builder."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextend the query builder with the needed functions.", "response": "def extend(self, builder):\n        \"\"\"\n        Extend the query builder with the needed functions.\n\n        :param builder: The query builder\n        :type builder: eloquent.orm.builder.Builder\n        \"\"\"\n        for extension in self._extensions:\n            getattr(self, '_add_%s' % extension)(builder)\n\n        builder.on_delete(self._on_delete)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _only_trashed(self, builder):\n        model = builder.get_model()\n\n        self.remove(builder, model)\n\n        builder.get_query().where_not_null(model.get_qualified_deleted_at_column())", "response": "The only - trashed extension."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _add_fluent_indexes(self):\n        for column in self._columns:\n            for index in ['primary', 'unique', 'index']:\n                column_index = column.get(index)\n\n                if column_index is True:\n                    getattr(self, index)(column.name)\n\n                    break\n                elif column_index:\n                    getattr(self, index)(column.name, column_index)\n\n                    break", "response": "Add the index commands fluently specified on columns"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef big_integer(self, column, auto_increment=False, unsigned=False):\n        return self._add_column('big_integer', column,\n                                auto_increment=auto_increment,\n                                unsigned=unsigned)", "response": "Create a new big integer column on the table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef medium_integer(self, column, auto_increment=False, unsigned=False):\n        return self._add_column('medium_integer', column,\n                                auto_increment=auto_increment,\n                                unsigned=unsigned)", "response": "Create a new medium integer column on the table."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new tiny integer column on the table.", "response": "def tiny_integer(self, column, auto_increment=False, unsigned=False):\n        \"\"\"\n        Create a new tiny integer column on the table.\n\n        :param column: The column\n        :type column: str\n\n        :type auto_increment: bool\n\n        :type unsigned: bool\n\n        :rtype: Fluent\n        \"\"\"\n        return self._add_column('tiny_integer', column,\n                                auto_increment=auto_increment,\n                                unsigned=unsigned)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a new column to the blueprint.", "response": "def _add_column(self, type, name, **parameters):\n        \"\"\"\n        Add a new column to the blueprint.\n\n        :param type: The column type\n        :type type: str\n\n        :param name: The column name\n        :type name: str\n\n        :param parameters: The column parameters\n        :type parameters: dict\n\n        :rtype: Fluent\n        \"\"\"\n        parameters.update({\n            'type': type,\n            'name': name\n        })\n\n        column = Fluent(**parameters)\n        self._columns.append(column)\n\n        return column"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the ALTER TABLE SQL statement for the given table diff.", "response": "def get_alter_table_sql(self, diff):\n        \"\"\"\n        Get the ALTER TABLE SQL statement\n\n        :param diff: The table diff\n        :type diff: eloquent.dbal.table_diff.TableDiff\n\n        :rtype: list\n        \"\"\"\n        #sql = self._get_simple_alter_table_sql(diff)\n\n        from_table = diff.from_table\n        if not isinstance(from_table, Table):\n            raise Exception('SQLite platform requires for the alter table the table diff '\n                            'referencing the original table')\n\n        table = from_table.clone()\n        columns = {}\n        old_column_names = {}\n        new_column_names = {}\n        column_sql = []\n        for column_name, column in table.get_columns().items():\n            column_name = column_name.lower()\n            columns[column_name] = column\n            old_column_names[column_name] = column.get_name()\n            new_column_names[column_name] = column.get_name()\n\n        for column_name, column in diff.removed_columns.items():\n            column_name = column_name.lower()\n            if column_name in columns:\n                del columns[column_name]\n                del old_column_names[column_name]\n                del new_column_names[column_name]\n\n        for old_column_name, column in diff.renamed_columns.items():\n            old_column_name = old_column_name.lower()\n            if old_column_name in columns:\n                del columns[old_column_name]\n\n            columns[column.get_name().lower()] = column\n\n            if old_column_name in new_column_names:\n                new_column_names[old_column_name] = column.get_name()\n\n        for old_column_name, column_diff in diff.changed_columns.items():\n            if old_column_name in columns:\n                del columns[old_column_name]\n\n            columns[column_diff.column.get_name().lower()] = column_diff.column\n\n            if old_column_name in new_column_names:\n                new_column_names[old_column_name] = column_diff.column.get_name()\n\n        for column_name, column in diff.added_columns.items():\n            columns[column_name.lower()] = column\n\n        sql = []\n        table_sql = []\n\n        data_table = Table('__temp__' + table.get_name())\n\n        new_table = Table(table.get_name(), columns,\n                          self.get_primary_index_in_altered_table(diff),\n                          self.get_foreign_keys_in_altered_table(diff))\n        new_table.add_option('alter', True)\n\n        sql = self.get_pre_alter_table_index_foreign_key_sql(diff)\n        sql.append('CREATE TEMPORARY TABLE %s AS SELECT %s FROM %s'\n                   % (data_table.get_name(), ', '.join(old_column_names.values()), table.get_name()))\n        sql.append(self.get_drop_table_sql(from_table))\n\n        sql += self.get_create_table_sql(new_table)\n        sql.append('INSERT INTO %s (%s) SELECT %s FROM %s'\n                   % (new_table.get_name(),\n                      ', '.join(new_column_names.values()),\n                      ', '.join(old_column_names.values()),\n                      data_table.get_name()))\n        sql.append(self.get_drop_table_sql(data_table))\n\n        sql += self.get_post_alter_table_index_foreign_key_sql(diff)\n\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_foreign_keys_in_altered_table(self, diff):\n        foreign_keys = diff.from_table.get_foreign_keys()\n        column_names = self.get_column_names_in_altered_table(diff)\n\n        for key, constraint in foreign_keys.items():\n            changed = False\n            local_columns = []\n            for column_name in constraint.get_local_columns():\n                normalized_column_name = column_name.lower()\n                if normalized_column_name not in column_names:\n                    del foreign_keys[key]\n                    break\n                else:\n                    local_columns.append(column_names[normalized_column_name])\n                    if column_name != column_names[normalized_column_name]:\n                        changed = True\n\n            if changed:\n                pass\n\n        return foreign_keys", "response": "Returns a list of foreign keys that are not in the table that have been modified."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds the constraints for a relationship count query.", "response": "def get_relation_count_query(self, query, parent):\n        \"\"\"\n        Add the constraints for a relationship count query.\n\n        :type query: eloquent.orm.Builder\n        :type parent: eloquent.orm.Builder\n\n        :rtype: Builder\n        \"\"\"\n        query.select(QueryExpression('COUNT(*)'))\n\n        other_key = self.wrap('%s.%s' % (query.get_model().get_table(), self._other_key))\n\n        return query.where(self.get_qualified_foreign_key(), '=', QueryExpression(other_key))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmatch the eagerly loaded results to their parents.", "response": "def match(self, models, results, relation):\n        \"\"\"\n        Match the eagerly loaded results to their parents.\n\n        :type models: list\n        :type results: Collection\n        :type relation:  str\n        \"\"\"\n        foreign = self._foreign_key\n\n        other = self._other_key\n\n        dictionary = {}\n\n        for result in results:\n            dictionary[result.get_attribute(other)] = result\n\n        for model in models:\n            value = model.get_attribute(foreign)\n\n            if value in dictionary:\n                model.set_relation(relation, dictionary[value])\n\n        return models"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef associate(self, model):\n        self._parent.set_attribute(self._foreign_key, model.get_attribute(self._other_key))\n\n        return self._parent.set_relation(self._relation, model)", "response": "Associate the given model instance with the given parent."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dissociate(self):\n        self._parent.set_attribute(self._foreign_key, None)\n\n        return self._parent.set_relation(self._relation, None)", "response": "Dissociate previously associated model from the given parent."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting the command. :type i: cleo.inputs.input.Input :type o: cleo.outputs.output.Output", "response": "def execute(self, i, o):\n        \"\"\"\n        Executes the command.\n\n        :type i: cleo.inputs.input.Input\n        :type o: cleo.outputs.output.Output\n        \"\"\"\n        super(StatusCommand, self).execute(i, o)\n\n        database = i.get_option('database')\n        repository = DatabaseMigrationRepository(self._resolver, 'migrations')\n\n        migrator = Migrator(repository, self._resolver)\n\n        if not migrator.repository_exists():\n            return o.writeln('<error>No migrations found</error>')\n\n        self._prepare_database(migrator, database, i, o)\n\n        path = i.get_option('path')\n\n        if path is None:\n            path = self._get_migration_path()\n\n        ran = migrator.get_repository().get_ran()\n\n        migrations = []\n        for migration in migrator._get_migration_files(path):\n            if migration in ran:\n                migrations.append(['<fg=cyan>%s</>' % migration, '<info>Yes</info>'])\n            else:\n                migrations.append(['<fg=cyan>%s</>' % migration, '<fg=red>No</>'])\n\n        if migrations:\n            table = self.get_helper('table')\n            table.set_headers(['Migration', 'Ran?'])\n            table.set_rows(migrations)\n            table.render(o)\n        else:\n            return o.writeln('<error>No migrations found</error>')\n\n        for note in migrator.get_notes():\n            o.writeln(note)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compile_rename_column(self, blueprint, command, connection):\n        # The code is a little complex. It will propably change\n        # if we support complete diffs in dbal\n        sql = []\n\n        schema = connection.get_schema_manager()\n        table = self.get_table_prefix() + blueprint.get_table()\n\n        column = connection.get_column(table, command.from_)\n\n        columns = schema.list_table_columns(table)\n        indexes = schema.list_table_indexes(table)\n        foreign_keys = schema.list_table_foreign_keys(table)\n\n        diff = self._get_renamed_diff(blueprint, command, column, schema)\n        renamed_columns = diff.renamed_columns\n\n        old_column_names = list(map(lambda x: x.get_name(), columns))\n\n        # We build the new column names\n        new_column_names = []\n        for column_name in old_column_names:\n            if column_name in renamed_columns:\n                new_column_names.append(renamed_columns[column_name].get_name())\n            else:\n                new_column_names.append(column_name)\n\n        # We create a temporary table and insert the data into it\n        temp_table = '__temp__' + self.get_table_prefix() + blueprint.get_table()\n        sql.append('CREATE TEMPORARY TABLE %s AS SELECT %s FROM %s'\n                   % (temp_table, self.columnize(old_column_names), table))\n\n        # We drop the current table\n        sql += Blueprint(table).drop().to_sql(None, self)\n\n        # Building the list a new columns\n        new_columns = []\n        for column in columns:\n            for column_name, changed_column in renamed_columns.items():\n                if column_name == column.get_name():\n                    new_columns.append(changed_column)\n\n        # Here we will try to rebuild a new blueprint to create a new table\n        # with the original name\n        new_blueprint = Blueprint(table)\n        new_blueprint.create()\n        primary = []\n        for column in columns:\n            # Mapping the database type to the blueprint type\n            type = schema.get_database_platform().TYPE_MAPPING[column.get_type().lower()]\n\n            # If the column is a primary, we will add it to the blueprint later\n            if column.get_platform_option('pk'):\n                primary.append(column.get_name())\n\n            # If the column is not one that's been renamed we reinsert it into the blueprint\n            if column.get_name() not in renamed_columns.keys():\n                col = getattr(new_blueprint, type)(column.get_name())\n\n                # If the column is nullable, we flag it\n                if not column.get_notnull():\n                    col.nullable()\n\n                # If the column has a default value, we add it\n                if column.get_default() is not None:\n                    col.default(QueryExpression(column.get_default()))\n\n        # Inserting the renamed columns into the blueprint\n        for column in new_columns:\n            type = schema.get_database_platform().TYPE_MAPPING[column.get_type().lower()]\n\n            col = getattr(new_blueprint, type)(column.get_name())\n            if not column.get_notnull():\n                col.nullable()\n\n            if column.get_default() is not None:\n                col.default(QueryExpression(column.get_default()))\n\n        # We add the primary keys\n        if primary:\n            new_blueprint.primary(primary)\n\n        # We rebuild the indexes\n        for index in indexes:\n            index_columns = index['columns']\n            new_index_columns = []\n            index_name = index['name']\n\n            for column_name in index_columns:\n                if column_name in renamed_columns:\n                    new_index_columns.append(renamed_columns[column_name].get_name())\n                else:\n                    new_index_columns.append(column_name)\n\n            if index_columns != new_index_columns:\n                index_name = None\n\n            if index['unique']:\n                new_blueprint.unique(new_index_columns, index_name)\n            else:\n                new_blueprint.index(index['columns'], index_name)\n\n        for foreign_key in foreign_keys:\n            fkey_from = foreign_key['from']\n            if fkey_from in renamed_columns:\n                fkey_from = renamed_columns[fkey_from].get_name()\n\n            new_blueprint.foreign(fkey_from)\\\n                .references(foreign_key['to'])\\\n                .on(foreign_key['table'])\\\n                .on_delete(foreign_key['on_delete'])\\\n                .on_update(foreign_key['on_update'])\n\n        # We create the table\n        sql += new_blueprint.to_sql(None, self)\n\n        # We reinsert the data into the new table\n        sql.append('INSERT INTO %s (%s) SELECT %s FROM %s'\n                   % (self.wrap_table(table),\n                      ', '.join(new_column_names),\n                      self.columnize(old_column_names),\n                      self.wrap_table(temp_table)\n                      ))\n\n        # Finally we drop the temporary table\n        sql += Blueprint(temp_table).drop().to_sql(None, self)\n\n        return sql", "response": "Compile a rename column command."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompiles a change column command into a series of SQL statements.", "response": "def compile_change(self, blueprint, command, connection):\n        \"\"\"\n        Compile a change column command into a series of SQL statement.\n\n        :param blueprint: The blueprint\n        :type blueprint: eloquent.schema.Blueprint\n\n        :param command: The command\n        :type command: Fluent\n\n        :param connection: The connection\n        :type connection: eloquent.connections.Connection\n\n        :rtype: list\n        \"\"\"\n        sql = []\n\n        schema = connection.get_schema_manager()\n        table = self.get_table_prefix() + blueprint.get_table()\n\n        columns = schema.list_table_columns(table)\n        indexes = schema.list_table_indexes(table)\n        foreign_keys = schema.list_table_foreign_keys(table)\n\n        diff = self._get_changed_diff(blueprint, schema)\n        blueprint_changed_columns = blueprint.get_changed_columns()\n        changed_columns = diff.changed_columns\n\n        temp_table = '__temp__' + self.get_table_prefix() + blueprint.get_table()\n        sql.append('CREATE TEMPORARY TABLE %s AS SELECT %s FROM %s'\n                   % (temp_table, self.columnize(list(map(lambda x: x.get_name(), columns))), table))\n        sql += Blueprint(table).drop().to_sql(None, self)\n\n        new_columns = []\n        for column in columns:\n            for column_name, changed_column in changed_columns.items():\n                if column_name == column.get_name():\n                    for blueprint_column in blueprint_changed_columns:\n                        if blueprint_column.name == column_name:\n                            new_columns.append(blueprint_column)\n                            break\n\n                    break\n\n        new_blueprint = Blueprint(table)\n        new_blueprint.create()\n        primary = []\n        new_column_names = []\n        for column in columns:\n            type = schema.get_database_platform().TYPE_MAPPING[column.get_type().lower()]\n\n            if column.get_platform_option('pk'):\n                primary.append(column.get_name())\n\n            if column.get_name() not in changed_columns:\n                col = getattr(new_blueprint, type)(column.get_name())\n                if not column.get_notnull():\n                    col.nullable()\n\n                new_column_names.append(column.get_name())\n\n        for column in new_columns:\n            column.change = False\n            new_blueprint._add_column(**column.get_attributes())\n            new_column_names.append(column.name)\n\n        if primary:\n            new_blueprint.primary(primary)\n\n        for index in indexes:\n            if index['unique']:\n                new_blueprint.unique(index['columns'], index['name'])\n            else:\n                new_blueprint.index(index['columns'], index['name'])\n\n        for foreign_key in foreign_keys:\n            new_blueprint.foreign(foreign_key['from'])\\\n                .references(foreign_key['to'])\\\n                .on(foreign_key['table'])\\\n                .on_delete(foreign_key['on_delete'])\\\n                .on_update(foreign_key['on_update'])\n\n        sql += new_blueprint.to_sql(None, self)\n        sql.append('INSERT INTO %s (%s) SELECT %s FROM %s'\n                   % (self.wrap_table(table),\n                      ', '.join(sorted(new_column_names)),\n                      self.columnize(sorted(list(map(lambda x: x.get_name(), columns)))),\n                      self.wrap_table(temp_table)\n                      ))\n        sql += Blueprint(temp_table).drop().to_sql(None, self)\n\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompile a create table command.", "response": "def compile_create(self, blueprint, command, _):\n        \"\"\"\n        Compile a create table command.\n        \"\"\"\n        columns = ', '.join(self._get_columns(blueprint))\n\n        sql = 'CREATE TABLE %s (%s' % (self.wrap_table(blueprint), columns)\n\n        sql += self._add_foreign_keys(blueprint)\n\n        sql += self._add_primary_keys(blueprint)\n\n        return sql + ')'"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmatching the eargerly loaded resuls to their single parents.", "response": "def match_one(self, models, results, relation):\n        \"\"\"\n        Match the eargerly loaded resuls to their single parents.\n\n        :param models: The parents\n        :type models: list\n\n        :param results: The results collection\n        :type results: Collection\n\n        :param relation: The relation\n        :type relation: str\n\n        :rtype: list\n        \"\"\"\n        return self._match_one_or_many(models, results, relation, 'one')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef match_many(self, models, results, relation):\n        return self._match_one_or_many(models, results, relation, 'many')", "response": "Match the eargerly loaded resuls to their single parents."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmatch the eargerly loaded resuls to their single parents.", "response": "def _match_one_or_many(self, models, results, relation, type):\n        \"\"\"\n        Match the eargerly loaded resuls to their single parents.\n\n        :param models: The parents\n        :type models: list\n\n        :param results: The results collection\n        :type results: Collection\n\n        :param relation: The relation\n        :type relation: str\n\n        :param type: The match type\n        :type type: str\n\n        :rtype: list\n        \"\"\"\n        dictionary = self._build_dictionary(results)\n\n        for model in models:\n            key = model.get_attribute(self._local_key)\n\n            if key in dictionary:\n                value = self._get_relation_value(dictionary, key, type)\n\n                model.set_relation(relation, value)\n\n        return models"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the value of the relationship by one or many type.", "response": "def _get_relation_value(self, dictionary, key, type):\n        \"\"\"\n        Get the value of the relationship by one or many type.\n\n        :type dictionary: dict\n        :type key: str\n        :type type: str\n        \"\"\"\n        value = dictionary[key]\n\n        if type == 'one':\n            return value[0]\n\n        return self._related.new_collection(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the first related model record matching the attributes or instantiate it.", "response": "def first_or_new(self, _attributes=None, **attributes):\n        \"\"\"\n        Get the first related model record matching the attributes or instantiate it.\n\n        :param attributes:  The attributes\n        :type attributes: dict\n\n        :rtype: Model\n        \"\"\"\n        if _attributes is not None:\n            attributes.update(_attributes)\n\n        instance = self.where(attributes).first()\n\n        if instance is None:\n            instance = self._related.new_instance()\n            instance.set_attribute(self.get_plain_foreign_key(), self.get_parent_key())\n\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the first related record matching the attributes or create it.", "response": "def first_or_create(self, _attributes=None, **attributes):\n        \"\"\"\n        Get the first related record matching the attributes or create it.\n\n        :param attributes:  The attributes\n        :type attributes: dict\n\n        :rtype: Model\n        \"\"\"\n        if _attributes is not None:\n            attributes.update(_attributes)\n\n        instance = self.where(attributes).first()\n\n        if instance is None:\n            instance = self.create(**attributes)\n\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute the reset command.", "response": "def execute(self, i, o):\n        \"\"\"\n        Executes the command.\n\n        :type i: cleo.inputs.input.Input\n        :type o: cleo.outputs.output.Output\n        \"\"\"\n        super(ResetCommand, self).execute(i, o)\n\n        dialog = self.get_helper('dialog')\n        confirm = dialog.ask_confirmation(\n            o,\n            '<question>Are you sure you want to reset all of the migrations?</question> ',\n            False\n        )\n        if not confirm:\n            return\n\n        database = i.get_option('database')\n        repository = DatabaseMigrationRepository(self._resolver, 'migrations')\n\n        migrator = Migrator(repository, self._resolver)\n\n        self._prepare_database(migrator, database, i, o)\n\n        pretend = bool(i.get_option('pretend'))\n\n        path = i.get_option('path')\n\n        if path is None:\n            path = self._get_migration_path()\n\n        while True:\n            count = migrator.rollback(path, pretend)\n\n            for note in migrator.get_notes():\n                o.writeln(note)\n\n            if count == 0:\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_relation_count_query(self, query, parent):\n        query = super(MorphToMany, self).get_relation_count_query(query, parent)\n\n        return query.where('%s.%s' % (self._table, self._morph_type), self._morph_class)", "response": "Add the constraints for a relationship count query."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd constraints for an eager load of the relation.", "response": "def add_eager_constraints(self, models):\n        \"\"\"\n        Set the constraints for an eager load of the relation.\n\n        :type models: list\n        \"\"\"\n        super(MorphToMany, self).add_eager_constraints(models)\n\n        self._query.where('%s.%s' % (self._table, self._morph_type), self._morph_class)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create_attach_record(self, id, timed):\n        record = super(MorphToMany, self)._create_attach_record(id, timed)\n\n        record[self._morph_type] = self._morph_class\n\n        return record", "response": "Create a new pivot attachement record."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new query builder for the pivot table.", "response": "def _new_pivot_query(self):\n        \"\"\"\n        Create a new query builder for the pivot table.\n\n        :rtype: eloquent.orm.Builder\n        \"\"\"\n        query = super(MorphToMany, self)._new_pivot_query()\n\n        return query.where(self._morph_type, self._morph_class)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new pivot model instance.", "response": "def new_pivot(self, attributes=None, exists=False):\n        \"\"\"\n        Create a new pivot model instance.\n        \"\"\"\n        from .morph_pivot import MorphPivot\n\n        pivot = MorphPivot(self._parent, attributes, self._table, exists)\n\n        pivot.set_pivot_keys(self._foreign_key, self._other_key)\\\n            .set_morph_type(self._morph_type)\\\n            .set_morph_class(self._morph_class)\n\n        return pivot"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting the install command.", "response": "def execute(self, i, o):\n        \"\"\"\n        Executes the command.\n\n        :type i: cleo.inputs.input.Input\n        :type o: cleo.outputs.output.Output\n        \"\"\"\n        super(InstallCommand, self).execute(i, o)\n\n        database = i.get_option('database')\n        repository = DatabaseMigrationRepository(self._resolver, 'migrations')\n\n        repository.set_source(database)\n        repository.create_repository()\n\n        o.writeln('<info>Migration table created successfully</info>')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_insert_get_id(self, query, sql, values, sequence=None):\n        if not query.get_connection().transaction_level():\n            with query.get_connection().transaction():\n                query.get_connection().insert(sql, values)\n\n                cursor = query.get_connection().get_cursor()\n                if hasattr(cursor, 'lastrowid'):\n                    id = cursor.lastrowid\n                else:\n                    id = query.get_connection().statement('SELECT LAST_INSERT_ID()')\n        else:\n            query.get_connection().insert(sql, values)\n\n            cursor = query.get_connection().get_cursor()\n            if hasattr(cursor, 'lastrowid'):\n                id = cursor.lastrowid\n            else:\n                id = query.get_connection().statement('SELECT LAST_INSERT_ID()')\n\n        if isinstance(id, int):\n            return id\n\n        if str(id).isdigit():\n            return int(id)\n\n        return id", "response": "Process an insert get ID query."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef chunk(self, count):\n        page = 1\n        results = self.for_page(page, count).get()\n\n        while results:\n            yield results\n\n            page += 1\n\n            results = self.for_page(page, count).get()", "response": "Returns a list of count items from the query\n            API."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a list with the values of a given column and key.", "response": "def lists(self, column, key=None):\n        \"\"\"\n        Get a list with the values of a given column\n\n        :param column: The column to get the values for\n        :type column: str\n\n        :param key: The key\n        :type key: str\n\n        :return: The list of values\n        :rtype: list or dict\n        \"\"\"\n        results = self._query.lists(column, key)\n\n        if self._model.has_get_mutator(column):\n            if isinstance(results, dict):\n                for key, value in results.items():\n                    fill = {column: value}\n\n                    results[key] = self._model.new_from_builder(fill).column\n            else:\n                for i, value in enumerate(results):\n                    fill = {column: value}\n\n                    results[i] = self._model.new_from_builder(fill).column\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef increment(self, column, amount=1, extras=None):\n        extras = self._add_updated_at_column(extras)\n\n        return self._query.increment(column, amount, extras)", "response": "Increment a column s value by a given amount"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the hydrated models without eager loading.", "response": "def get_models(self, columns=None):\n        \"\"\"\n        Get the hydrated models without eager loading.\n\n        :param columns: The columns to get\n        :type columns: list\n\n        :return: A list of models\n        :rtype: list\n        \"\"\"\n        results = self._query.get(columns)\n\n        connection = self._model.get_connection_name()\n\n        return self._model.hydrate(results, connection).all()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _load_relation(self, models, name, constraints):\n        relation = self.get_relation(name)\n\n        relation.add_eager_constraints(models)\n\n        if callable(constraints):\n            constraints(relation)\n        else:\n            relation.merge_query(constraints)\n\n        models = relation.init_relation(models, name)\n\n        results = relation.get_eager()\n\n        return relation.match(models, results, name)", "response": "Load the relationship on a set of models."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding nested relationship count conditions to the query.", "response": "def _has_nested(self, relations, operator='>=', count=1, boolean='and', extra=None):\n        \"\"\"\n        Add nested relationship count conditions to the query.\n\n        :param relations: nested relations\n        :type relations: str\n\n        :param operator: The operator\n        :type operator: str\n\n        :param count: The count\n        :type count: int\n\n        :param boolean: The boolean value\n        :type boolean: str\n\n        :param extra: The extra query\n        :type extra: Builder or callable\n\n        :rtype: Builder\n        \"\"\"\n        relations = relations.split('.')\n\n        def closure(q):\n            if len(relations) > 1:\n                q.where_has(relations.pop(0), closure)\n            else:\n                q.has(relations.pop(0), operator, count, boolean, extra)\n\n        return self.where_has(relations.pop(0), closure)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a relationship count to the query.", "response": "def doesnt_have(self, relation, boolean='and', extra=None):\n        \"\"\"\n        Add a relationship count to the query.\n\n        :param relation: The relation to count\n        :type relation: str\n\n        :param boolean: The boolean value\n        :type boolean: str\n\n        :param extra: The extra query\n        :type extra: Builder or callable\n\n        :rtype: Builder\n        \"\"\"\n        return self.has(relation, '<', 1, boolean, extra)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a relationship count condition to the query with where clauses.", "response": "def where_has(self, relation, extra, operator='>=', count=1):\n        \"\"\"\n        Add a relationship count condition to the query with where clauses.\n\n        :param relation: The relation to count\n        :type relation: str\n\n        :param extra: The extra query\n        :type extra: Builder or callable\n\n        :param operator: The operator\n        :type operator: str\n\n        :param count: The count\n        :type count: int\n\n        :rtype: Builder\n        \"\"\"\n        return self.has(relation, operator, count, 'and', extra)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef or_has(self, relation, operator='>=', count=1):\n        return self.has(relation, operator, count, 'or')", "response": "Add a relationship count condition to the query with an or."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a relationship count condition to the query with where clauses and an or.", "response": "def or_where_has(self, relation, extra, operator='>=', count=1):\n        \"\"\"\n        Add a relationship count condition to the query with where clauses and an \"or\".\n\n        :param relation: The relation to count\n        :type relation: str\n\n        :param extra: The extra query\n        :type extra: Builder or callable\n\n        :param operator: The operator\n        :type operator: str\n\n        :param count: The count\n        :type count: int\n\n        :rtype: Builder\n        \"\"\"\n        return self.has(relation, operator, count, 'or', extra)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _merge_wheres_to_has(self, has_query, relation):\n        relation_query = relation.get_base_query()\n\n        has_query.merge_wheres(relation_query.wheres, relation_query.get_bindings())\n\n        self._query.merge_bindings(has_query.get_query())", "response": "Merge the wheres from the relation query to a has query."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the has relation base query", "response": "def _get_has_relation_query(self, relation):\n        \"\"\"\n        Get the \"has\" relation base query\n\n        :type relation: str\n\n        :rtype: Builder\n        \"\"\"\n        from .relations import Relation\n\n        return Relation.no_constraints(\n            lambda: getattr(self.get_model(), relation)()\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef with_(self, *relations):\n        if not relations:\n            return self\n\n        eagers = self._parse_relations(list(relations))\n\n        self._eager_load.update(eagers)\n\n        return self", "response": "Sets the relationships that should be eager loaded."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_relations(self, relations):\n        results = {}\n\n        for relation in relations:\n            if isinstance(relation, dict):\n                name = list(relation.keys())[0]\n                constraints = relation[name]\n            else:\n                name = relation\n                constraints = self.__class__(self.get_query().new_query())\n\n            results = self._parse_nested(name, results)\n\n            results[name] = constraints\n\n        return results", "response": "Parse a list of relations into individual related objects."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_nested(self, name, results):\n        progress = []\n\n        for segment in name.split('.'):\n            progress.append(segment)\n\n            last = '.'.join(progress)\n            if last not in results:\n                results[last] = self.__class__(self.get_query().new_query())\n\n        return results", "response": "Parse the nested relationship in a relation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall the given model scope.", "response": "def _call_scope(self, scope, *args, **kwargs):\n        \"\"\"\n        Call the given model scope.\n\n        :param scope: The scope to call\n        :type scope: str\n        \"\"\"\n        result = getattr(self._model, scope)(self, *args, **kwargs)\n\n        return result or self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns an up migration instance.", "response": "def _run_up(self, path, migration_file, batch, pretend=False):\n        \"\"\"\n        Run \"up\" a migration instance.\n\n        :type migration_file: str\n\n        :type batch: int\n\n        :type pretend: bool\n        \"\"\"\n        migration = self._resolve(path, migration_file)\n\n        if pretend:\n            return self._pretend_to_run(migration, 'up')\n\n        migration.up()\n\n        self._repository.log(migration_file, batch)\n\n        self._note('<info>\u2713 Migrated</info> %s' % migration_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _run_down(self, path, migration, pretend=False):\n        migration_file = migration['migration']\n\n        instance = self._resolve(path, migration_file)\n\n        if pretend:\n            return self._pretend_to_run(instance, 'down')\n\n        instance.down()\n\n        self._repository.delete(migration)\n\n        self._note('<info>\u2713 Rolled back</info> %s' % migration_file)", "response": "Run down a migration instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npretending to run the migration.", "response": "def _pretend_to_run(self, migration, method):\n        \"\"\"\n        Pretend to run the migration.\n\n        :param migration: The migration\n        :type migration: eloquent.migrations.migration.Migration\n\n        :param method: The method to execute\n        :type method: str\n        \"\"\"\n        for query in self._get_queries(migration, method):\n            name = migration.__class__.__name__\n\n            self._note('<info>%s:</info> <comment>%s</comment>' % (name, query))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all of the queries that would be run for a migration.", "response": "def _get_queries(self, migration, method):\n        \"\"\"\n        Get all of the queries that would be run for a migration.\n\n        :param migration: The migration\n        :type migration: eloquent.migrations.migration.Migration\n\n        :param method: The method to execute\n        :type method: str\n\n        :rtype: list\n        \"\"\"\n        connection = migration.get_connection()\n\n        db = self.resolve_connection(connection)\n\n        logger = logging.getLogger('eloquent.connection.queries')\n        level = logger.level\n        logger.setLevel(logging.DEBUG)\n        handler = MigratorHandler()\n        handler.setLevel(logging.DEBUG)\n        logger.addHandler(handler)\n\n        db.pretend(lambda _: getattr(migration, method)())\n\n        logger.removeHandler(handler)\n        logger.setLevel(level)\n\n        return handler.queries"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _resolve(self, path, migration_file):\n        variables = {}\n\n        name = '_'.join(migration_file.split('_')[4:])\n        migration_file = os.path.join(path, '%s.py' % migration_file)\n\n        with open(migration_file) as fh:\n            exec(fh.read(), {}, variables)\n\n        klass = variables[inflection.camelize(name)]\n\n        instance = klass()\n        instance.set_schema_builder(self.get_repository().get_connection().get_schema_builder())\n\n        return instance", "response": "Resolve a migration instance from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the ALTER TABLE SQL statement for the given table diff.", "response": "def get_alter_table_sql(self, diff):\n        \"\"\"\n        Get the ALTER TABLE SQL statement\n\n        :param diff: The table diff\n        :type diff: eloquent.dbal.table_diff.TableDiff\n\n        :rtype: list\n        \"\"\"\n        column_sql = []\n        query_parts = []\n\n        if diff.new_name is not False:\n            query_parts.append('RENAME TO %s' % diff.new_name)\n\n        # Added columns?\n\n        # Removed columns?\n\n        for column_diff in diff.changed_columns.values():\n            column = column_diff.column\n            column_dict = column.to_dict()\n\n            # Don't propagate default value changes for unsupported column types.\n            if column_diff.has_changed('default') \\\n                    and len(column_diff.changed_properties) == 1 \\\n                    and (column_dict['type'] == 'text' or column_dict['type'] == 'blob'):\n                continue\n\n            query_parts.append('CHANGE %s %s'\n                               % (column_diff.get_old_column_name(),\n                                  self.get_column_declaration_sql(column.get_name(), column_dict)))\n\n        for old_column_name, column in diff.renamed_columns.items():\n            column_dict = column.to_dict()\n            query_parts.append('CHANGE %s %s'\n                               % (self.quote(old_column_name),\n                                  self.get_column_declaration_sql(self.quote(column.get_name()), column_dict)))\n\n        sql = []\n\n        if len(query_parts) > 0:\n            sql.append('ALTER TABLE %s %s' % (diff.name, ', '.join(query_parts)))\n\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the difference between the tables table1 and table2.", "response": "def diff_table(self, table1, table2):\n        \"\"\"\n        Returns the difference between the tables table1 and table2.\n\n        :type table1: Table\n        :type table2: Table\n\n        :rtype: TableDiff\n        \"\"\"\n        changes = 0\n        table_differences = TableDiff(table1.get_name())\n        table_differences.from_table = table1\n\n        table1_columns = table1.get_columns()\n        table2_columns = table2.get_columns()\n\n        # See if all the fields in table1 exist in table2\n        for column_name, column in table2_columns.items():\n            if not table1.has_column(column_name):\n                table_differences.added_columns[column_name] = column\n                changes += 1\n\n        # See if there are any removed fields in table2\n        for column_name, column in table1_columns.items():\n            if not table2.has_column(column_name):\n                table_differences.removed_columns[column_name] = column\n                changes += 1\n                continue\n\n            # See if column has changed properties in table2\n            changed_properties = self.diff_column(column, table2.get_column(column_name))\n\n            if changed_properties:\n                column_diff = ColumnDiff(column.get_name(),\n                                         table2.get_column(column_name),\n                                         changed_properties)\n                column_diff.from_column = column\n                table_differences.changed_columns[column.get_name()] = column_diff\n                changes += 1\n\n        self.detect_column_renamings(table_differences)\n\n        # table1_indexes = table1.get_indexes()\n        # table2_indexes = table2.get_indexes()\n        #\n        # # See if all the fields in table1 exist in table2\n        # for index_name, index in table2_indexes.items():\n        #     if (index.is_primary() and table1.has_primary_key()) or table1.has_index(index_name):\n        #         continue\n        #\n        #     table_differences.added_indexes[index_name] = index\n        #     changes += 1\n        #\n        # # See if there are any removed fields in table2\n        # for index_name, index in table1_indexes.items():\n        #     if (index.is_primary() and not table2.has_primary_key())\\\n        #             or (not index.is_primary() and not table2.has_index(index_name)):\n        #         table_differences.removed_indexes[index_name] = index\n        #         changes += 1\n        #         continue\n        #\n        #     if index.is_primary():\n        #         table2_index = table2.get_primary_key()\n        #     else:\n        #         table2_index = table2.get_index(index_name)\n        #\n        #     if self.diff_index(index, table2_index):\n        #         table_differences.changed_indexes[index_name] = index\n        #         changes += 1\n        #\n        # self.detect_index_renamings(table_differences)\n        #\n        # from_fkeys = table1.get_foreign_keys()\n        # to_fkeys = table2.get_foreign_keys()\n        #\n        # for key1, constraint1 in from_fkeys.items():\n        #     for key2, constraint2 in to_fkeys.items():\n        #         if self.diff_foreign_key(constraint1, constraint2) is False:\n        #             del from_fkeys[key1]\n        #             del to_fkeys[key2]\n        #         else:\n        #             if constraint1.get_name().lower() == constraint2.get_name().lower():\n        #                 table_differences.changed_foreign_keys.append(constraint2)\n        #                 changes += 1\n        #                 del from_fkeys[key1]\n        #                 del to_fkeys[key2]\n        #\n        # for constraint1 in from_fkeys.values():\n        #     table_differences.removed_foreign_keys.append(constraint1)\n        #     changes += 1\n        #\n        # for constraint2 in to_fkeys.values():\n        #     table_differences.added_foreign_keys.append(constraint2)\n        #     changes += 1\n\n        if changes:\n            return table_differences\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetects if any of the columns that only changed their names.", "response": "def detect_column_renamings(self, table_differences):\n        \"\"\"\n        Try to find columns that only changed their names.\n\n        :type table_differences: TableDiff\n        \"\"\"\n        rename_candidates = {}\n\n        for added_column_name, added_column in table_differences.added_columns.items():\n            for removed_column in table_differences.removed_columns.values():\n                if len(self.diff_column(added_column, removed_column)) == 0:\n                    if added_column.get_name() not in rename_candidates:\n                        rename_candidates[added_column.get_name()] = []\n\n                    rename_candidates[added_column.get_name()] = (removed_column, added_column, added_column_name)\n\n        for candidate_columns in rename_candidates.values():\n            if len(candidate_columns) == 1:\n                removed_column, added_column, _ = candidate_columns[0]\n                removed_column_name = removed_column.get_name().lower()\n                added_column_name = added_column.get_name().lower()\n\n                if removed_column_name not in table_differences.renamed_columns:\n                    table_differences.renamed_columns[removed_column_name] = added_column\n                    del table_differences.added_columns[added_column_name]\n                    del table_differences.removed_columns[removed_column_name]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the difference between column1 and column2.", "response": "def diff_column(self, column1, column2):\n        \"\"\"\n        Returns the difference between column1 and column2\n\n        :type column1: eloquent.dbal.column.Column\n        :type column2: eloquent.dbal.column.Column\n\n        :rtype: list\n        \"\"\"\n        properties1 = column1.to_dict()\n        properties2 = column2.to_dict()\n\n        changed_properties = []\n\n        for prop in ['type', 'notnull', 'unsigned', 'autoincrement']:\n            if properties1[prop] != properties2[prop]:\n                changed_properties.append(prop)\n\n        if properties1['default'] != properties2['default']\\\n                or (properties1['default'] is None and properties2['default'] is not None)\\\n                or (properties2['default'] is None and properties1['default'] is not None):\n            changed_properties.append('default')\n\n        if properties1['type'] == 'string' and properties1['type'] != 'guid'\\\n                or properties1['type'] in ['binary', 'blob']:\n            length1 = properties1['length'] or 255\n            length2 = properties2['length'] or 255\n\n            if length1 != length2:\n                changed_properties.append('length')\n\n            if properties1['fixed'] != properties2['fixed']:\n                changed_properties.append('fixed')\n        elif properties1['type'] in ['decimal', 'float', 'double precision']:\n            precision1 = properties1['precision'] or 10\n            precision2 = properties2['precision'] or 10\n\n            if precision1 != precision2:\n                changed_properties.append('precision')\n\n            if properties1['scale'] != properties2['scale']:\n                changed_properties.append('scale')\n\n        return list(set(changed_properties))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes the command. :type i: cleo.inputs.input.Input :type o: cleo.outputs.output.Output", "response": "def execute(self, i, o):\n        \"\"\"\n        Executes the command.\n\n        :type i: cleo.inputs.input.Input\n        :type o: cleo.outputs.output.Output\n        \"\"\"\n        config = self._get_config(i)\n        self._resolver = DatabaseManager(config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef call(self, name, options=None, o=None):\n        if options is None:\n            options = []\n\n        command = self.get_application().find(name)\n\n        options = [('command', command.get_name())] + options\n\n        return command.run(ListInput(options), o)", "response": "Call another command.\n\n        :param name: The command name\n        :type name: str\n\n        :param options: The options\n        :type options: list or None\n\n        :param o: The output\n        :type o: cleo.outputs.output.Output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_config(self, i):\n        variables = {}\n        if not i.get_option('config'):\n            raise Exception('The --config|-c option is missing.')\n\n        with open(i.get_option('config')) as fh:\n            exec(fh.read(), {}, variables)\n\n        return variables['DATABASES']", "response": "Get the config.\n\n        :type i: cleo.inputs.input.Input\n\n        :rtype: dict"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef associate(self, model):\n        self._parent.set_attribute(self._foreign_key, model.get_key())\n        self._parent.set_attribute(self._morph_type, model.get_morph_class())\n\n        return self._parent.set_relation(self._relation, model)", "response": "Associate the given model instance with the given parent."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _create_model_by_type(self, type):\n        klass = None\n        for cls in eloquent.orm.model.Model.__subclasses__():\n            morph_class = cls.__morph_class__ or cls.__name__\n            if morph_class == type:\n                klass = cls\n                break\n\n        return klass()", "response": "Create a new model instance by type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the column listing for a given table.", "response": "def get_column_listing(self, table):\n        \"\"\"\n        Get the column listing for a given table.\n\n        :param table: The table\n        :type table: str\n\n        :rtype: list\n        \"\"\"\n        sql = self._grammar.compile_column_exists()\n        database = self._connection.get_database_name()\n        table = self._connection.get_table_prefix() + table\n\n        results = self._connection.select(sql, [database, table])\n\n        return self._connection.get_post_processor().process_column_listing(results)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _populate_stub(self, name, stub, table):\n        stub = stub.replace('DummyClass', self._get_class_name(name))\n\n        if table is not None:\n            stub = stub.replace('dummy_table', table)\n\n        return stub", "response": "Populate the placeholders in the migration stub."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the keys for a save update query.", "response": "def _set_keys_for_save_query(self, query):\n        \"\"\"\n        Set the keys for a save update query.\n\n        :param query: A Builder instance\n        :type query: eloquent.orm.Builder\n\n        :return: The Builder instance\n        :rtype: eloquent.orm.Builder\n        \"\"\"\n        query.where(self._morph_type, self._morph_class)\n\n        return super(MorphPivot, self)._set_keys_for_save_query(query)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self):\n        query = self._get_delete_query()\n\n        query.where(self._morph_type, self._morph_class)\n\n        return query.delete()", "response": "Delete the pivot model record from the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding the constraints for a relationship count query.", "response": "def get_relation_count_query(self, query, parent):\n        \"\"\"\n        Add the constraints for a relationship count query.\n\n        :type query: Builder\n        :type parent: Builder\n\n        :rtype: Builder\n        \"\"\"\n        query = super(MorphOneOrMany, self).get_relation_count_query(query, parent)\n\n        return query.where(self._morph_type, self._morph_class)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding constraints for an eager load of the relation.", "response": "def add_eager_constraints(self, models):\n        \"\"\"\n        Set the constraints for an eager load of the relation.\n\n        :type models: list\n        \"\"\"\n        super(MorphOneOrMany, self).add_eager_constraints(models)\n\n        self._query.where(self._morph_type, self._morph_class)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave a new instance of the current record.", "response": "def save(self, model):\n        \"\"\"\n        Attach a model instance to the parent models.\n\n        :param model: The model instance to attach\n        :type model: Model\n\n        :rtype: Model\n        \"\"\"\n        model.set_attribute(self.get_plain_morph_type(), self._morph_class)\n\n        return super(MorphOneOrMany, self).save(model)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds a model by its primary key or return a new instance of the related model.", "response": "def find_or_new(self, id, columns=None):\n        \"\"\"\n        Find a model by its primary key or return new instance of the related model.\n\n        :param id: The primary key\n        :type id: mixed\n\n        :param columns:  The columns to retrieve\n        :type columns: list\n\n        :rtype: Collection or Model\n        \"\"\"\n        if columns is None:\n            columns = ['*']\n\n        instance = self.find(id, columns)\n\n        if instance is None:\n            instance = self._related.new_instance()\n            self._set_foreign_attributes_for_create(instance)\n\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_foreign_attributes_for_create(self, model):\n        model.set_attribute(self.get_plain_foreign_key(), self.get_parent_key())\n\n        model.set_attribute(self.get_plain_morph_type(), self._morph_class)", "response": "Set the foreign ID and type for creation a related model."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_connection_name(self, name):\n        if name is None:\n            name = self.get_default_connection()\n\n        if name.endswith(('::read', '::write')):\n            return name.split('::', 1)\n\n        return name, None", "response": "Parse the connection name into a tuple of the name read and write types."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef purge(self, name=None):\n        self.disconnect(name)\n\n        if name in self._connections:\n            del self._connections[name]", "response": "Disconnect from the given database and remove from local cache."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef no_constraints(cls, callback):\n        cls._constraints = False\n\n        results = callback()\n\n        cls._constraints = True\n\n        return results", "response": "Runs a callback with constraints disabled on the relation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all the primary keys for an array of models.", "response": "def get_keys(self, models, key=None):\n        \"\"\"\n        Get all the primary keys for an array of models.\n\n        :type models: list\n        :type key: str\n\n        :rtype: list\n        \"\"\"\n        return list(set(map(lambda value: value.get_attribute(key) if key else value.get_key(), models)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_constraints(self):\n        parent_table = self._parent.get_table()\n\n        self._set_join()\n\n        if self._constraints:\n            self._query.where('%s.%s' % (parent_table, self._first_key), '=', self._far_parent.get_key())", "response": "Add constraints on the relation query."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_relation_count_query(self, query, parent):\n        parent_table = self._parent.get_table()\n\n        self._set_join(query)\n\n        query.select(QueryExpression('COUNT(*)'))\n\n        key = self.wrap('%s.%s' % (parent_table, self._first_key))\n\n        return query.where(self.get_has_compare_key(), '=', QueryExpression(key))", "response": "Add the constraints for a relationship count query."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the join clause for the query.", "response": "def _set_join(self, query=None):\n        \"\"\"\n        Set the join clause for the query.\n        \"\"\"\n        if not query:\n            query = self._query\n\n        foreign_key = '%s.%s' % (self._related.get_table(), self._second_key)\n\n        query.join(self._parent.get_table(), self.get_qualified_parent_key_name(), '=', foreign_key)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nplot the highest and lowest scoring of each modality.", "response": "def plot_best_worst_fits(assignments_df, data, modality_col='Modality',\n                         score='$\\log_2 K$'):\n    \"\"\"Violinplots of the highest and lowest scoring of each modality\"\"\"\n    ncols = 2\n    nrows = len(assignments_df.groupby(modality_col).groups.keys())\n\n    fig, axes = plt.subplots(nrows=nrows, ncols=ncols,\n                             figsize=(nrows*4, ncols*6))\n\n    axes_iter = axes.flat\n\n    fits = 'Highest', 'Lowest'\n\n    for modality, df in assignments_df.groupby(modality_col):\n        df = df.sort_values(score)\n\n        color = MODALITY_TO_COLOR[modality]\n\n        for fit in fits:\n            if fit == 'Highest':\n                ids = df['Feature ID'][-10:]\n            else:\n                ids = df['Feature ID'][:10]\n            fit_psi = data[ids]\n            tidy_fit_psi = fit_psi.stack().reset_index()\n            tidy_fit_psi = tidy_fit_psi.rename(columns={'level_0': 'Sample ID',\n                                                        'level_1':\n                                                            'Feature ID',\n                                                        0: '$\\Psi$'})\n            if tidy_fit_psi.empty:\n                continue\n            ax = six.next(axes_iter)\n            violinplot(x='Feature ID', y='$\\Psi$', data=tidy_fit_psi,\n                       color=color, ax=ax)\n            ax.set(title='{} {} {}'.format(fit, score, modality), xticks=[])\n    sns.despine()\n    fig.tight_layout()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps around Seaborn s Violinplot specifically for [ 0 1 ) ranged data", "response": "def violinplot(x=None, y=None, data=None, bw=0.2, scale='width',\n               inner=None, ax=None, **kwargs):\n    \"\"\"Wrapper around Seaborn's Violinplot specifically for [0, 1] ranged data\n\n    What's different:\n    - bw = 0.2: Sets bandwidth to be small and the same between datasets\n    - scale = 'width': Sets the width of all violinplots to be the same\n    - inner = None: Don't plot a boxplot or points inside the violinplot\n    \"\"\"\n    if ax is None:\n        ax = plt.gca()\n\n    sns.violinplot(x, y, data=data, bw=bw, scale=scale, inner=inner, ax=ax,\n                   **kwargs)\n    ax.set(ylim=(0, 1), yticks=(0, 0.5, 1))\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndrawing a barplot grouped by modality of modality percentage per group.", "response": "def bar(self, counts, phenotype_to_color=None, ax=None, percentages=True):\n        \"\"\"Draw barplots grouped by modality of modality percentage per group\n\n        Parameters\n        ----------\n\n\n        Returns\n        -------\n\n\n        Raises\n        ------\n\n        \"\"\"\n        if percentages:\n            counts = 100 * (counts.T / counts.T.sum()).T\n\n        # with sns.set(style='whitegrid'):\n        if ax is None:\n            ax = plt.gca()\n\n        full_width = 0.8\n        width = full_width / counts.shape[0]\n        for i, (group, series) in enumerate(counts.iterrows()):\n            left = np.arange(len(self.modality_order)) + i * width\n            height = [series[i] if i in series else 0\n                      for i in self.modality_order]\n            color = phenotype_to_color[group]\n            ax.bar(left, height, width=width, color=color, label=group,\n                   linewidth=.5, edgecolor='k')\n        ylabel = 'Percentage of events' if percentages else 'Number of events'\n        ax.set_ylabel(ylabel)\n        ax.set_xticks(np.arange(len(self.modality_order)) + full_width / 2)\n        ax.set_xticklabels(self.modality_order)\n        ax.set_xlabel('Splicing modality')\n        ax.set_xlim(0, len(self.modality_order))\n        ax.legend(loc='best')\n        ax.grid(axis='y', linestyle='-', linewidth=0.5)\n        sns.despine()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshows the values underlying bayesian modality estimations of an event", "response": "def event_estimation(self, event, logliks, logsumexps, renamed=''):\n        \"\"\"Show the values underlying bayesian modality estimations of an event\n\n        Parameters\n        ----------\n\n\n        Returns\n        -------\n\n\n        Raises\n        ------\n        \"\"\"\n        plotter = _ModelLoglikPlotter()\n        plotter.plot(event, logliks, logsumexps, self.modality_to_color,\n                     renamed=renamed)\n        return plotter"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef predict(self, fitted):\n        if fitted.shape[0] != len(self.modalities):\n            raise ValueError(\"This data doesn't look like it had the distance \"\n                             \"between it and the five modalities calculated\")\n        return fitted.idxmin()", "response": "Assign the most likely modality given the fitted data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef logliks(self, x):\n        x = x.copy()\n\n        # Replace exactly 0 and exactly 1 values with a very small number\n        # (machine epsilon, the smallest number that this computer is capable\n        # of storing) because 0 and 1 are not in the Beta distribution.\n        x[x == 0] = VERY_SMALL_NUMBER\n        x[x == 1] = 1 - VERY_SMALL_NUMBER\n\n        return np.array([np.log(prob) + rv.logpdf(x[np.isfinite(x)]).sum()\n                         for prob, rv in\n                         zip(self.prob_parameters, self.rvs)])", "response": "Calculate the log - likelihood of a feature x for each model."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert floats to integers or a nice looking fraction", "response": "def nice_number_string(number, decimal_places=2):\n        \"\"\"Convert floats to either integers or a nice looking fraction\"\"\"\n        if number == np.round(number):\n            return str(int(number))\n        elif number < 1 and number > 0:\n            inverse = 1 / number\n            if int(inverse) == np.round(inverse):\n                return r'\\frac{{1}}{{{}}}'.format(int(inverse))\n        else:\n            template = '{{:.{0}}}'.format(decimal_places)\n            return template.format(number)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef violinplot(self, n=1000, **kwargs):\n        kwargs.setdefault('palette', 'Purples')\n\n        dfs = []\n\n        for rv in self.rvs:\n            psi = rv.rvs(n)\n            df = pd.Series(psi, name=self.ylabel).to_frame()\n            alpha, beta = rv.args\n            alpha = self.nice_number_string(alpha, decimal_places=2)\n            beta = self.nice_number_string(beta, decimal_places=2)\n\n            df['parameters'] = '$\\\\alpha = {0}$\\n$\\\\beta = {1}$'.format(\n                alpha, beta)\n            dfs.append(df)\n        data = pd.concat(dfs)\n\n        if 'ax' not in kwargs:\n            fig, ax = plt.subplots(figsize=(len(self.alphas)*0.625, 4))\n        else:\n            ax = kwargs.pop('ax')\n        ax = violinplot(x='parameters', y=self.ylabel, data=data,\n                        ax=ax, **kwargs)\n        sns.despine(ax=ax)\n        return ax", "response": "Plot violins of each distribution in the model family."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _single_feature_logliks_one_step(self, feature, models):\n        x_non_na = feature[~feature.isnull()]\n        if x_non_na.empty:\n            return pd.DataFrame()\n        else:\n            dfs = []\n            for name, model in models.items():\n                df = model.single_feature_logliks(feature)\n                df['Modality'] = name\n                dfs.append(df)\n            return pd.concat(dfs, ignore_index=True)", "response": "Get log - likelihood of models at each parameterization for a single feature."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits the log2 bayes factor for each modality assignment in the data.", "response": "def fit(self, data):\n        \"\"\"Get the modality assignments of each splicing event in the data\n\n        Parameters\n        ----------\n        data : pandas.DataFrame\n            A (n_samples, n_events) dataframe of splicing events' PSI scores.\n            Must be psi scores which range from 0 to 1\n\n        Returns\n        -------\n        log2_bayes_factors : pandas.DataFrame\n            A (n_modalities, n_events) dataframe of the estimated log2\n            bayes factor for each splicing event, for each modality\n\n        Raises\n        ------\n        AssertionError\n            If any value in ``data`` does not fall only between 0 and 1.\n        \"\"\"\n        self.assert_less_than_or_equal_1(data.values.flat)\n        self.assert_non_negative(data.values.flat)\n\n        if isinstance(data, pd.DataFrame):\n            log2_bayes_factors = data.apply(self.single_feature_fit)\n        elif isinstance(data, pd.Series):\n            log2_bayes_factors = self.single_feature_fit(data)\n        log2_bayes_factors.name = self.score_name\n        return log2_bayes_factors"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npredicts the most likely modality for each event.", "response": "def predict(self, log2_bayes_factors, reset_index=False):\n        \"\"\"Guess the most likely modality for each event\n\n        For each event that has at least one non-NA value, if no modalilites\n        have logsumexp'd logliks greater than the log Bayes factor threshold,\n        then they are assigned the 'multimodal' modality, because we cannot\n        reject the null hypothesis that these did not come from the uniform\n        distribution.\n\n        Parameters\n        ----------\n        log2_bayes_factors : pandas.DataFrame\n            A (4, n_events) dataframe with bayes factors for the Psi~1, Psi~0,\n            bimodal, and middle modalities. If an event has no bayes factors\n            for any of those modalities, it is ignored\n        reset_index : bool\n            If True, remove the first level of the index from the dataframe.\n            Useful if you are using this function to apply to a grouped\n            dataframe where the first level is something other than the\n            modality, e.g. the celltype\n\n        Returns\n        -------\n        modalities : pandas.Series\n            A (n_events,) series with the most likely modality for each event\n\n        \"\"\"\n        if reset_index:\n            x = log2_bayes_factors.reset_index(level=0, drop=True)\n        else:\n            x = log2_bayes_factors\n        if isinstance(x, pd.DataFrame):\n            not_na = (x.notnull() > 0).any()\n            not_na_columns = not_na[not_na].index\n            x.ix[NULL_MODEL, not_na_columns] = self.logbf_thresh\n        elif isinstance(x, pd.Series):\n            x[NULL_MODEL] = self.logbf_thresh\n        return x.idxmax()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates log - likelihoods of each modality s parameterization for each single feature.", "response": "def single_feature_logliks(self, feature):\n        \"\"\"Calculate log-likelihoods of each modality's parameterization\n\n        Used for plotting the estimates of a single feature\n\n        Parameters\n        ----------\n        featre : pandas.Series\n            A single feature's values. All values must range from 0 to 1.\n\n        Returns\n        -------\n        logliks : pandas.DataFrame\n            The log-likelihood the data, for each model, for each\n            parameterization\n\n        Raises\n        ------\n        AssertionError\n            If any value in ``x`` does not fall only between 0 and 1.\n        \"\"\"\n        self.assert_less_than_or_equal_1(feature.values)\n        self.assert_non_negative(feature.values)\n\n        logliks = self._single_feature_logliks_one_step(\n            feature, self.one_param_models)\n\n        logsumexps = self.logliks_to_logsumexp(logliks)\n\n        # If none of the one-parameter models passed, try the two-param models\n        if (logsumexps <= self.logbf_thresh).all():\n            logliks_two_params = self._single_feature_logliks_one_step(\n                feature, self.two_param_models)\n            logliks = pd.concat([logliks, logliks_two_params])\n        return logliks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the log2 bayes factor of the fit for each modality", "response": "def single_feature_fit(self, feature):\n        \"\"\"Get the log2 bayes factor of the fit for each modality\"\"\"\n        if np.isfinite(feature).sum() == 0:\n            series = pd.Series(index=MODALITY_ORDER)\n        else:\n            logbf_one_param = pd.Series(\n                {k: v.logsumexp_logliks(feature) for\n                 k, v in self.one_param_models.items()})\n\n            # Check if none of the previous features fit\n            if (logbf_one_param <= self.logbf_thresh).all():\n                logbf_two_param = pd.Series(\n                    {k: v.logsumexp_logliks(feature)\n                     for k, v in self.two_param_models.items()})\n                series = pd.concat([logbf_one_param, logbf_two_param])\n                series[NULL_MODEL] = self.logbf_thresh\n            else:\n                series = logbf_one_param\n        series.index.name = 'Modality'\n        series.name = self.score_name\n        return series"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bin_range_strings(bins, fmt=':g'):\n    return [('{' + fmt + '}-{' + fmt + '}').format(i, j)\n            for i, j in zip(bins, bins[1:])]", "response": "Given a list of bins make a list of strings of those bin ranges"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a histogram of each column into a set of binsize", "response": "def binify(data, bins):\n    \"\"\"Makes a histogram of each column the provided binsize\n\n    Parameters\n    ----------\n    data : pandas.DataFrame\n        A samples x features dataframe. Each feature (column) will be binned\n        into the provided bins\n    bins : iterable\n        Bins you would like to use for this data. Must include the final bin\n        value, e.g. (0, 0.5, 1) for the two bins (0, 0.5) and (0.5, 1).\n        nbins = len(bins) - 1\n\n    Returns\n    -------\n    binned : pandas.DataFrame\n        An nbins x features DataFrame of each column binned across rows\n    \"\"\"\n    if bins is None:\n        raise ValueError('Must specify \"bins\"')\n    if isinstance(data, pd.DataFrame):\n        binned = data.apply(lambda x: pd.Series(np.histogram(x, bins=bins,\n                                                             range=(0, 1))[0]))\n    elif isinstance(data, pd.Series):\n        binned = pd.Series(np.histogram(data, bins=bins, range=(0, 1))[0])\n    else:\n        raise ValueError('`data` must be either a 1d vector or 2d matrix')\n    binned.index = bin_range_strings(bins)\n\n    # Normalize so each column sums to 1\n    binned = binned / binned.sum().astype(float)\n    return binned"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef kld(p, q):\n    try:\n        _check_prob_dist(p)\n        _check_prob_dist(q)\n    except ValueError:\n        return np.nan\n    # If one of them is zero, then the other should be considered to be 0.\n    # In this problem formulation, log0 = 0\n    p = p.replace(0, np.nan)\n    q = q.replace(0, np.nan)\n\n    return (np.log2(p / q) * p).sum(axis=0)", "response": "Compute the Kullback - Leiber divergence of two probability distributions pandas\n    dataframes p and q."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the Jensen - Shannon divergence between two probability distributions pandasDataFrame p and q.", "response": "def jsd(p, q):\n    \"\"\"Finds the per-column JSD between dataframes p and q\n\n    Jensen-Shannon divergence of two probability distrubutions pandas\n    dataframes, p and q. These distributions are usually created by running\n    binify() on the dataframe.\n\n    Parameters\n    ----------\n    p : pandas.DataFrame\n        An nbins x features DataFrame.\n    q : pandas.DataFrame\n        An nbins x features DataFrame.\n\n    Returns\n    -------\n    jsd : pandas.Series\n        Jensen-Shannon divergence of each column with the same names between\n        p and q\n\n    Raises\n    ------\n    ValueError\n        If the data provided is not a probability distribution, i.e. it has\n        negative values or its columns do not sum to 1, raise ValueError\n    \"\"\"\n    try:\n        _check_prob_dist(p)\n        _check_prob_dist(q)\n    except ValueError:\n        return np.nan\n    weight = 0.5\n    m = weight * (p + q)\n\n    result = weight * kld(p, m) + (1 - weight) * kld(q, m)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef entropy(binned, base=2):\n    try:\n        _check_prob_dist(binned)\n    except ValueError:\n        np.nan\n    return -((np.log(binned) / np.log(base)) * binned).sum(axis=0)", "response": "Find the entropy of each column of a dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef binify_and_jsd(df1, df2, bins, pair=None):\n    binned1 = binify(df1, bins=bins).dropna(how='all', axis=1)\n    binned2 = binify(df2, bins=bins).dropna(how='all', axis=1)\n\n    binned1, binned2 = binned1.align(binned2, axis=1, join='inner')\n\n    series = np.sqrt(jsd(binned1, binned2))\n    series.name = pair\n    return series", "response": "Binify and calculate jensen - shannon divergence between two dataframes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntransform a tall JSD dataframe to a square matrix of mean JSDs", "response": "def jsd_df_to_2d(jsd_df):\n    \"\"\"Transform a tall JSD dataframe to a square matrix of mean JSDs\n\n    Parameters\n    ----------\n    jsd_df : pandas.DataFrame\n        A (n_features, n_phenotypes^2) dataframe of the JSD between each\n        feature between and within phenotypes\n\n    Returns\n    -------\n    jsd_2d : pandas.DataFrame\n        A (n_phenotypes, n_phenotypes) symmetric dataframe of the mean JSD\n        between and within phenotypes\n    \"\"\"\n    jsd_2d = jsd_df.mean().reset_index()\n    jsd_2d = jsd_2d.rename(\n        columns={'level_0': 'phenotype1', 'level_1': 'phenotype2', 0: 'jsd'})\n    jsd_2d = jsd_2d.pivot(index='phenotype1', columns='phenotype2',\n                          values='jsd')\n    return jsd_2d + np.tril(jsd_2d.T, -1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting the loop over the interface calling the given callback for each packet intercepted .", "response": "def run(self, callback=None, limit=0):\n        \"\"\"\n        Start pcap's loop over the interface, calling the given callback for each packet\n        :param callback: a function receiving (win_pcap, param, header, pkt_data) for each packet intercepted\n        :param limit: how many packets to capture (A value of -1 or 0 is equivalent to infinity)\n        \"\"\"\n        if self._handle is None:\n            raise self.DeviceIsNotOpen()\n        # Set new callback\n        self._callback = callback\n        # Run loop with callback wrapper\n        wtypes.pcap_loop(self._handle, limit, self._callback_wrapper, None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a packet to the network interface.", "response": "def send(self, packet_buffer):\n        \"\"\"\n        send a buffer as a packet to the network interface\n        :param packet_buffer: buffer to send (length shouldn't exceed MAX_INT)\n        \"\"\"\n        if self._handle is None:\n            raise self.DeviceIsNotOpen()\n        buffer_length = len(packet_buffer)\n        buf_send = ctypes.cast(ctypes.create_string_buffer(packet_buffer, buffer_length),\n                               ctypes.POINTER(ctypes.c_ubyte))\n        wtypes.pcap_sendpacket(self._handle, buf_send, buffer_length)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncaptures packets on a specific network interface.", "response": "def capture_on(pattern, callback):\n        \"\"\"\n        :param pattern: a wildcard pattern to match the description of a network interface to capture packets on\n        :param callback: a function to call with each intercepted packet\n        \"\"\"\n        device_name, desc = WinPcapDevices.get_matching_device(pattern)\n        if device_name is not None:\n            with WinPcap(device_name) as capture:\n                capture.run(callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncaptures on a device name.", "response": "def capture_on_device_name(device_name, callback):\n        \"\"\"\n        :param device_name: the name (guid) of a device as provided by WinPcapDevices.list_devices()\n        :param callback: a function to call with each intercepted packet\n        \"\"\"\n        with WinPcap(device_name) as capture:\n            capture.run(callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a packet to a network interface and optionally capture a response on the next request.", "response": "def send_packet(self, pattern, packet_buffer, callback=None, limit=10):\n        \"\"\"\n        Send a buffer as a packet to a network interface and optionally capture a response\n        :param pattern: a wildcard pattern to match the description of a network interface to capture packets on\n        :param packet_buffer: a buffer to send (length shouldn't exceed MAX_INT)\n        :param callback: If not None, a function to call with each intercepted packet\n        :param limit: how many packets to capture (A value of -1 or 0 is equivalent to infinity)\n        \"\"\"\n        device_name, desc = WinPcapDevices.get_matching_device(pattern)\n        if device_name is not None:\n            with WinPcap(device_name) as capture:\n                capture.send(packet_buffer)\n                if callback is not None:\n                    capture.run(callback=callback, limit=limit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the next value for a given sequence.", "response": "def get_next_value(\n        sequence_name='default', initial_value=1, reset_value=None,\n        *, nowait=False, using=None):\n    \"\"\"\n    Return the next value for a given sequence.\n\n    \"\"\"\n    # Inner import because models cannot be imported before their application.\n    from .models import Sequence\n\n    if reset_value is not None:\n        assert initial_value < reset_value\n\n    if using is None:\n        using = router.db_for_write(Sequence)\n\n    connection = connections[using]\n\n    if (getattr(connection, 'pg_version', 0) >= 90500\n            and reset_value is None and not nowait):\n\n        # PostgreSQL \u2265 9.5 supports \"upsert\".\n\n        with connection.cursor() as cursor:\n            cursor.execute(UPSERT_QUERY, [sequence_name, initial_value])\n            last, = cursor.fetchone()\n        return last\n\n    else:\n\n        # Other databases require making more database queries.\n\n        with transaction.atomic(using=using, savepoint=False):\n            sequence, created = (\n                Sequence.objects\n                        .select_for_update(nowait=nowait)\n                        .get_or_create(name=sequence_name,\n                                       defaults={'last': initial_value})\n            )\n\n            if not created:\n                sequence.last += 1\n                if reset_value is not None and sequence.last >= reset_value:\n                    sequence.last = initial_value\n                sequence.save()\n\n            return sequence.last"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check(self, final_line_count):\n        if self._lines_seen[\"version\"]:\n            self._process_version_lines()\n        self._process_plan_lines(final_line_count)", "response": "Check the status of all provided data and update the suite."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _process_version_lines(self):\n        if len(self._lines_seen[\"version\"]) > 1:\n            self._add_error(_(\"Multiple version lines appeared.\"))\n        elif self._lines_seen[\"version\"][0] != 1:\n            self._add_error(_(\"The version must be on the first line.\"))", "response": "Process version line rules."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing plan line rules.", "response": "def _process_plan_lines(self, final_line_count):\n        \"\"\"Process plan line rules.\"\"\"\n        if not self._lines_seen[\"plan\"]:\n            self._add_error(_(\"Missing a plan.\"))\n            return\n\n        if len(self._lines_seen[\"plan\"]) > 1:\n            self._add_error(_(\"Only one plan line is permitted per file.\"))\n            return\n\n        plan, at_line = self._lines_seen[\"plan\"][0]\n        if not self._plan_on_valid_line(at_line, final_line_count):\n            self._add_error(\n                _(\"A plan must appear at the beginning or end of the file.\")\n            )\n            return\n\n        if plan.expected_tests != self._lines_seen[\"test\"]:\n            self._add_error(\n                _(\"Expected {expected_count} tests but only {seen_count} ran.\").format(\n                    expected_count=plan.expected_tests,\n                    seen_count=self._lines_seen[\"test\"],\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if a plan is on a valid line.", "response": "def _plan_on_valid_line(self, at_line, final_line_count):\n        \"\"\"Check if a plan is on a valid line.\"\"\"\n        # Put the common cases first.\n        if at_line == 1 or at_line == final_line_count:\n            return True\n\n        # The plan may only appear on line 2 if the version is at line 1.\n        after_version = (\n            self._lines_seen[\"version\"]\n            and self._lines_seen[\"version\"][0] == 1\n            and at_line == 2\n        )\n        if after_version:\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle a bail line.", "response": "def handle_bail(self, bail):\n        \"\"\"Handle a bail line.\"\"\"\n        self._add_error(_(\"Bailed: {reason}\").format(reason=bail.reason))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles a SKIP plan that contains a SKIP directive.", "response": "def handle_skipping_plan(self, skip_plan):\n        \"\"\"Handle a plan that contains a SKIP directive.\"\"\"\n        skip_line = Result(True, None, skip_plan.directive.text, Directive(\"SKIP\"))\n        self._suite.addTest(Adapter(self._filename, skip_line))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding an error test to the suite.", "response": "def _add_error(self, message):\n        \"\"\"Add an error test to the suite.\"\"\"\n        error_line = Result(False, None, message, Directive(\"\"))\n        self._suite.addTest(Adapter(self._filename, error_line))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nformats an exception as diagnostics output.", "response": "def format_exception(exception):\n    \"\"\"Format an exception as diagnostics output.\n\n    exception is the tuple as expected from sys.exc_info.\n    \"\"\"\n    exception_lines = traceback.format_exception(*exception)\n    # The lines returned from format_exception do not strictly contain\n    # one line per element in the list (i.e. some elements have new\n    # line characters in the middle). Normalize that oddity.\n    lines = \"\".join(exception_lines).splitlines(True)\n    return format_as_diagnostics(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a file - like object fh and return a generator of tap. line. Line objects.", "response": "def parse(self, fh):\n        \"\"\"Generate tap.line.Line objects, given a file-like object `fh`.\n\n        `fh` may be any object that implements both the iterator and\n        context management protocol (i.e. it can be used in both a\n        \"with\" statement and a \"for...in\" statement.)\n\n        Trailing whitespace and newline characters will be automatically\n        stripped from the input lines.\n        \"\"\"\n        with fh:\n            try:\n                first_line = next(fh)\n            except StopIteration:\n                return\n            first_parsed = self.parse_line(first_line.rstrip())\n            fh_new = itertools.chain([first_line], fh)\n            if first_parsed.category == \"version\" and first_parsed.version >= 13:\n                if ENABLE_VERSION_13:\n                    fh_new = peekable(itertools.chain([first_line], fh))\n                    self._try_peeking = True\n                else:  # pragma no cover\n                    print(\n                        \"\"\"\nWARNING: Optional imports not found, TAP 13 output will be\n    ignored. To parse yaml, see requirements in docs:\n    https://tappy.readthedocs.io/en/latest/consumers.html#tap-version-13\"\"\"\n                    )\n\n            for line in fh_new:\n                yield self.parse_line(line.rstrip(), fh_new)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_line(self, text, fh=None):\n        match = self.ok.match(text)\n        if match:\n            return self._parse_result(True, match, fh)\n\n        match = self.not_ok.match(text)\n        if match:\n            return self._parse_result(False, match, fh)\n\n        if self.diagnostic.match(text):\n            return Diagnostic(text)\n\n        match = self.plan.match(text)\n        if match:\n            return self._parse_plan(match)\n\n        match = self.bail.match(text)\n        if match:\n            return Bail(match.group(\"reason\"))\n\n        match = self.version.match(text)\n        if match:\n            return self._parse_version(match)\n\n        return Unknown()", "response": "Parse a line into whatever TAP category it belongs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_plan(self, match):\n        expected_tests = int(match.group(\"expected\"))\n        directive = Directive(match.group(\"directive\"))\n\n        # Only SKIP directives are allowed in the plan.\n        if directive.text and not directive.skip:\n            return Unknown()\n\n        return Plan(expected_tests, directive)", "response": "Parse a matching plan line."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a matching result line into a result instance.", "response": "def _parse_result(self, ok, match, fh=None):\n        \"\"\"Parse a matching result line into a result instance.\"\"\"\n        peek_match = None\n        try:\n            if fh is not None and self._try_peeking:\n                peek_match = self.yaml_block_start.match(fh.peek())\n        except StopIteration:\n            pass\n        if peek_match is None:\n            return Result(\n                ok,\n                number=match.group(\"number\"),\n                description=match.group(\"description\").strip(),\n                directive=Directive(match.group(\"directive\")),\n            )\n        indent = peek_match.group(\"indent\")\n        concat_yaml = self._extract_yaml_block(indent, fh)\n        return Result(\n            ok,\n            number=match.group(\"number\"),\n            description=match.group(\"description\").strip(),\n            directive=Directive(match.group(\"directive\")),\n            raw_yaml_block=concat_yaml,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _extract_yaml_block(self, indent, fh):\n        raw_yaml = []\n        indent_match = re.compile(r\"^{}\".format(indent))\n        try:\n            fh.next()\n            while indent_match.match(fh.peek()):\n                raw_yaml.append(fh.next().replace(indent, \"\", 1))\n                # check for the end and stop adding yaml if encountered\n                if self.yaml_block_end.match(fh.peek()):\n                    fh.next()\n                    break\n        except StopIteration:\n            pass\n        return \"\\n\".join(raw_yaml)", "response": "Extract a raw yaml block from a file handler"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef yaml_block(self):\n        if LOAD_YAML and self._yaml_block is not None:\n            try:\n                yaml_dict = yaml.load(self._yaml_block)\n                return yaml_dict\n            except yaml.error.YAMLError:\n                print(\"Error parsing yaml block. Check formatting.\")\n        return None", "response": "Lazy load a yaml_block."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload any files found into a test suite.", "response": "def load(self, files):\n        \"\"\"Load any files found into a suite.\n\n        Any directories are walked and their files are added as TAP files.\n\n        :returns: A ``unittest.TestSuite`` instance\n        \"\"\"\n        suite = unittest.TestSuite()\n        for filepath in files:\n            if os.path.isdir(filepath):\n                self._find_tests_in_directory(filepath, suite)\n            else:\n                suite.addTest(self.load_suite_from_file(filepath))\n        return suite"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a test suite with test lines from the provided TAP file.", "response": "def load_suite_from_file(self, filename):\n        \"\"\"Load a test suite with test lines from the provided TAP file.\n\n        :returns: A ``unittest.TestSuite`` instance\n        \"\"\"\n        suite = unittest.TestSuite()\n        rules = Rules(filename, suite)\n\n        if not os.path.exists(filename):\n            rules.handle_file_does_not_exist()\n            return suite\n\n        line_generator = self._parser.parse_file(filename)\n        return self._load_lines(filename, line_generator, suite, rules)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload a test suite with test lines from the TAP stream on STDIN.", "response": "def load_suite_from_stdin(self):\n        \"\"\"Load a test suite with test lines from the TAP stream on STDIN.\n\n        :returns: A ``unittest.TestSuite`` instance\n        \"\"\"\n        suite = unittest.TestSuite()\n        rules = Rules(\"stream\", suite)\n        line_generator = self._parser.parse_stdin()\n        return self._load_lines(\"stream\", line_generator, suite, rules)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _load_lines(self, filename, line_generator, suite, rules):\n        line_counter = 0\n        for line in line_generator:\n            line_counter += 1\n\n            if line.category in self.ignored_lines:\n                continue\n\n            if line.category == \"test\":\n                suite.addTest(Adapter(filename, line))\n                rules.saw_test()\n            elif line.category == \"plan\":\n                if line.skip:\n                    rules.handle_skipping_plan(line)\n                    return suite\n                rules.saw_plan(line, line_counter)\n            elif line.category == \"bail\":\n                rules.handle_bail(line)\n                return suite\n            elif line.category == \"version\":\n                rules.saw_version_at(line_counter)\n\n        rules.check(line_counter)\n        return suite", "response": "Load a suite with lines produced by the line generator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nkeeping track of which test cases have executed.", "response": "def _track(self, class_name):\n        \"\"\"Keep track of which test cases have executed.\"\"\"\n        if self._test_cases.get(class_name) is None:\n            if self.streaming and self.header:\n                self._write_test_case_header(class_name, self.stream)\n\n            self._test_cases[class_name] = []\n            if self.combined:\n                self.combined_test_cases_seen.append(class_name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_plan(self, total):\n        self.plan = total\n        if self.streaming:\n            # This will only write the plan if we haven't written it\n            # already but we want to check if we already wrote a\n            # test out (in which case we can't just write the plan out\n            # right here).\n            if not self.combined_test_cases_seen:\n                self._write_plan(self.stream)\n        elif not self.combined:\n            raise ValueError(\n                \"set_plan can only be used with combined or streaming output\"\n            )", "response": "Notify the tracker how many total tests there will be."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_tap_reports(self):\n        # We're streaming but set_plan wasn't called, so we can only\n        # know the plan now (at the end).\n        if self.streaming and not self._plan_written:\n            print(\"1..{0}\".format(self.combined_line_number), file=self.stream)\n            self._plan_written = True\n            return\n\n        if self.combined:\n            combined_file = \"testresults.tap\"\n            if self.outdir:\n                combined_file = os.path.join(self.outdir, combined_file)\n            with open(combined_file, \"w\") as out_file:\n                self._write_tap_version(out_file)\n                if self.plan is not None:\n                    print(\"1..{0}\".format(self.plan), file=out_file)\n                for test_case in self.combined_test_cases_seen:\n                    self.generate_tap_report(\n                        test_case, self._test_cases[test_case], out_file\n                    )\n                if self.plan is None:\n                    print(\"1..{0}\".format(self.combined_line_number), file=out_file)\n        else:\n            for test_case, tap_lines in self._test_cases.items():\n                with open(self._get_tap_file_path(test_case), \"w\") as out_file:\n                    self._write_tap_version(out_file)\n                    self.generate_tap_report(test_case, tap_lines, out_file)", "response": "Generate TAP reports.\n\n        The results are either combined into a single output file or\n        the output file name is generated from the test case."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites the plan line to the given stream.", "response": "def _write_plan(self, stream):\n        \"\"\"Write the plan line to the stream.\n\n        If we have a plan and have not yet written it out, write it to\n        the given stream.\n        \"\"\"\n        if self.plan is not None:\n            if not self._plan_written:\n                print(\"1..{0}\".format(self.plan), file=stream)\n            self._plan_written = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_tap_file_path(self, test_case):\n        sanitized_test_case = test_case.translate(self._sanitized_table)\n        tap_file = sanitized_test_case + \".tap\"\n        if self.outdir:\n            return os.path.join(self.outdir, tap_file)\n        return tap_file", "response": "Get the TAP output file path for the test case."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main(argv=sys.argv, stream=sys.stderr):\n    args = parse_args(argv)\n    suite = build_suite(args)\n    runner = unittest.TextTestRunner(verbosity=args.verbose, stream=stream)\n    result = runner.run(suite)\n\n    return get_status(result)", "response": "Entry point for tappy command."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_suite(args):\n    loader = Loader()\n    if len(args.files) == 0 or args.files[0] == \"-\":\n        suite = loader.load_suite_from_stdin()\n    else:\n        suite = loader.load(args.files)\n    return suite", "response": "Build a test suite by loading TAP files or a TAP stream."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a failure to the result.", "response": "def addFailure(self, result):\n        \"\"\"Add a failure to the result.\"\"\"\n        result.addFailure(self, (Exception, Exception(), None))\n        # Since TAP will not provide assertion data, clean up the assertion\n        # section so it is not so spaced out.\n        test, err = result.failures[-1]\n        result.failures[-1] = (test, \"\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbases on example https://bitbucket.org/zzzeek/sqlalchemy/src/73095b353124/examples/nested_sets/nested_sets.py?at=master", "response": "def mptt_before_insert(mapper, connection, instance):\n    \"\"\" Based on example\n    https://bitbucket.org/zzzeek/sqlalchemy/src/73095b353124/examples/nested_sets/nested_sets.py?at=master\n    \"\"\"\n    table = _get_tree_table(mapper)\n    db_pk = instance.get_pk_column()\n    table_pk = getattr(table.c, db_pk.name)\n\n    if instance.parent_id is None:\n        instance.left = 1\n        instance.right = 2\n        instance.level = instance.get_default_level()\n        tree_id = connection.scalar(\n            select(\n                [\n                    func.max(table.c.tree_id) + 1\n                ]\n            )\n        ) or 1\n        instance.tree_id = tree_id\n    else:\n        (parent_pos_left,\n         parent_pos_right,\n         parent_tree_id,\n         parent_level) = connection.execute(\n            select(\n                [\n                    table.c.lft,\n                    table.c.rgt,\n                    table.c.tree_id,\n                    table.c.level\n                ]\n            ).where(\n                table_pk == instance.parent_id\n            )\n        ).fetchone()\n\n        # Update key of right side\n        connection.execute(\n            table.update(\n                and_(table.c.rgt >= parent_pos_right,\n                     table.c.tree_id == parent_tree_id)\n            ).values(\n                lft=case(\n                    [\n                        (\n                            table.c.lft > parent_pos_right,\n                            table.c.lft + 2\n                        )\n                    ],\n                    else_=table.c.lft\n                ),\n                rgt=case(\n                    [\n                        (\n                            table.c.rgt >= parent_pos_right,\n                            table.c.rgt + 2\n                        )\n                    ],\n                    else_=table.c.rgt\n                )\n            )\n        )\n\n        instance.level = parent_level + 1\n        instance.tree_id = parent_tree_id\n        instance.left = parent_pos_right\n        instance.right = parent_pos_right + 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mptt_before_update(mapper, connection, instance):\n    node_id = getattr(instance, instance.get_pk_name())\n    table = _get_tree_table(mapper)\n    db_pk = instance.get_pk_column()\n    default_level = instance.get_default_level()\n    table_pk = getattr(table.c, db_pk.name)\n    mptt_move_inside = None\n    left_sibling = None\n    left_sibling_tree_id = None\n\n    if hasattr(instance, 'mptt_move_inside'):\n        mptt_move_inside = instance.mptt_move_inside\n\n    if hasattr(instance, 'mptt_move_before'):\n        (\n            right_sibling_left,\n            right_sibling_right,\n            right_sibling_parent,\n            right_sibling_level,\n            right_sibling_tree_id\n        ) = connection.execute(\n            select(\n                [\n                    table.c.lft,\n                    table.c.rgt,\n                    table.c.parent_id,\n                    table.c.level,\n                    table.c.tree_id\n                ]\n            ).where(\n                table_pk == instance.mptt_move_before\n            )\n        ).fetchone()\n        current_lvl_nodes = connection.execute(\n            select(\n                [\n                    table.c.lft,\n                    table.c.rgt,\n                    table.c.parent_id,\n                    table.c.tree_id\n                ]\n            ).where(\n                and_(\n                    table.c.level == right_sibling_level,\n                    table.c.tree_id == right_sibling_tree_id,\n                    table.c.lft < right_sibling_left\n                )\n            )\n        ).fetchall()\n        if current_lvl_nodes:\n            (\n                left_sibling_left,\n                left_sibling_right,\n                left_sibling_parent,\n                left_sibling_tree_id\n            ) = current_lvl_nodes[-1]\n            instance.parent_id = left_sibling_parent\n            left_sibling = {\n                'lft': left_sibling_left,\n                'rgt': left_sibling_right,\n                'is_parent': False\n            }\n        # if move_before to top level\n        elif not right_sibling_parent:\n            left_sibling_tree_id = right_sibling_tree_id - 1\n\n    # if placed after a particular node\n    if hasattr(instance, 'mptt_move_after'):\n        (\n            left_sibling_left,\n            left_sibling_right,\n            left_sibling_parent,\n            left_sibling_tree_id\n        ) = connection.execute(\n            select(\n                [\n                    table.c.lft,\n                    table.c.rgt,\n                    table.c.parent_id,\n                    table.c.tree_id\n                ]\n            ).where(\n                table_pk == instance.mptt_move_after\n            )\n        ).fetchone()\n        instance.parent_id = left_sibling_parent\n        left_sibling = {\n            'lft': left_sibling_left,\n            'rgt': left_sibling_right,\n            'is_parent': False\n        }\n\n    \"\"\" Get subtree from node\n\n        SELECT id, name, level FROM my_tree\n        WHERE left_key >= $left_key AND right_key <= $right_key\n        ORDER BY left_key\n    \"\"\"\n    subtree = connection.execute(\n        select([table_pk])\n        .where(\n            and_(\n                table.c.lft >= instance.left,\n                table.c.rgt <= instance.right,\n                table.c.tree_id == instance.tree_id\n            )\n        ).order_by(\n            table.c.lft\n        )\n    ).fetchall()\n    subtree = [x[0] for x in subtree]\n\n    \"\"\" step 0: Initialize parameters.\n\n        Put there left and right position of moving node\n    \"\"\"\n    (\n        node_pos_left,\n        node_pos_right,\n        node_tree_id,\n        node_parent_id,\n        node_level\n    ) = connection.execute(\n        select(\n            [\n                table.c.lft,\n                table.c.rgt,\n                table.c.tree_id,\n                table.c.parent_id,\n                table.c.level\n            ]\n        ).where(\n            table_pk == node_id\n        )\n    ).fetchone()\n\n    # if instance just update w/o move\n    # XXX why this str() around parent_id comparison?\n    if not left_sibling \\\n            and str(node_parent_id) == str(instance.parent_id) \\\n            and not mptt_move_inside:\n        if left_sibling_tree_id is None:\n            return\n\n    # fix tree shorting\n    if instance.parent_id is not None:\n        (\n            parent_id,\n            parent_pos_right,\n            parent_pos_left,\n            parent_tree_id,\n            parent_level\n        ) = connection.execute(\n            select(\n                [\n                    table_pk,\n                    table.c.rgt,\n                    table.c.lft,\n                    table.c.tree_id,\n                    table.c.level\n                ]\n            ).where(\n                table_pk == instance.parent_id\n            )\n        ).fetchone()\n        if node_parent_id is None and node_tree_id == parent_tree_id:\n            instance.parent_id = None\n            return\n\n    # delete from old tree\n    mptt_before_delete(mapper, connection, instance, False)\n\n    if instance.parent_id is not None:\n        \"\"\" Put there right position of new parent node (there moving node\n            should be moved)\n        \"\"\"\n        (\n            parent_id,\n            parent_pos_right,\n            parent_pos_left,\n            parent_tree_id,\n            parent_level\n        ) = connection.execute(\n            select(\n                [\n                    table_pk,\n                    table.c.rgt,\n                    table.c.lft,\n                    table.c.tree_id,\n                    table.c.level\n                ]\n            ).where(\n                table_pk == instance.parent_id\n            )\n        ).fetchone()\n        # 'size' of moving node (including all it's sub nodes)\n        node_size = node_pos_right - node_pos_left + 1\n\n        # left sibling node\n        if not left_sibling:\n            left_sibling = {\n                'lft': parent_pos_left,\n                'rgt': parent_pos_right,\n                'is_parent': True\n            }\n\n        # insert subtree in exist tree\n        instance.tree_id = parent_tree_id\n        _insert_subtree(\n            table,\n            connection,\n            node_size,\n            node_pos_left,\n            node_pos_right,\n            parent_pos_left,\n            parent_pos_right,\n            subtree,\n            parent_tree_id,\n            parent_level,\n            node_level,\n            left_sibling,\n            table_pk\n        )\n    else:\n        # if insert after\n        if left_sibling_tree_id or left_sibling_tree_id == 0:\n            tree_id = left_sibling_tree_id + 1\n            connection.execute(\n                table.update(\n                    table.c.tree_id > left_sibling_tree_id\n                ).values(\n                    tree_id=table.c.tree_id + 1\n                )\n            )\n        # if just insert\n        else:\n            tree_id = connection.scalar(\n                select(\n                    [\n                        func.max(table.c.tree_id) + 1\n                    ]\n                )\n            )\n\n        connection.execute(\n            table.update(\n                table_pk.in_(\n                    subtree\n                )\n            ).values(\n                lft=table.c.lft - node_pos_left + 1,\n                rgt=table.c.rgt - node_pos_left + 1,\n                level=table.c.level - node_level + default_level,\n                tree_id=tree_id\n            )\n        )", "response": "This function is used to move a node in nested set to the new tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling by the flush event listener to recursively expire left and right attributes of all modified instances in the specified session.", "response": "def after_flush_postexec(self, session, context):\n        \"\"\"\n        Event listener to recursively expire `left` and `right` attributes the\n        parents of all modified instances part of this flush.\n        \"\"\"\n        instances = self.instances[session]\n        while instances:\n            instance = instances.pop()\n            if instance not in session:\n                continue\n            parent = self.get_parent_value(instance)\n\n            while parent != NO_VALUE and parent is not None:\n                instances.discard(parent)\n                session.expire(parent, ['left', 'right', 'tree_id', 'level'])\n                parent = self.get_parent_value(parent)\n            else:\n                session.expire(instance, ['left', 'right', 'tree_id', 'level'])\n                self.expire_session_for_children(session, instance)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_ancestor_of(self, other, inclusive=False):\n        if inclusive:\n            return (self.tree_id == other.tree_id) \\\n                & (self.left <= other.left) \\\n                & (other.right <= self.right)\n        return (self.tree_id == other.tree_id) \\\n            & (self.left < other.left) \\\n            & (other.right < self.right)", "response": "class or instance level method which returns True if self is an ancestor of other else False."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef move_inside(self, parent_id):\n        session = Session.object_session(self)\n        self.parent_id = parent_id\n        self.mptt_move_inside = parent_id\n        session.add(self)", "response": "Moving one node of tree inside another node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmove one node of tree after another node", "response": "def move_after(self, node_id):\n        \"\"\" Moving one node of tree after another\n\n        For example see :mod:`sqlalchemy_mptt.tests.cases.move_node.test_move_after_function`\n        \"\"\"  # noqa\n        session = Session.object_session(self)\n        self.parent_id = self.parent_id\n        self.mptt_move_after = node_id\n        session.add(self)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef move_before(self, node_id):\n        session = Session.object_session(self)\n        table = _get_tree_table(self.__mapper__)\n        pk = getattr(table.c, self.get_pk_column().name)\n        node = session.query(table).filter(pk == node_id).one()\n        self.parent_id = node.parent_id\n        self.mptt_move_before = node_id\n        session.add(self)", "response": "Moving one node of tree before another node"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef drilldown_tree(self, session=None, json=False, json_fields=None):\n        if not session:\n            session = object_session(self)\n        return self.get_tree(\n            session,\n            json=json,\n            json_fields=json_fields,\n            query=self._drilldown_query\n        )", "response": "This method generates a branch from a tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef path_to_root(self, session=None, order=desc):\n        table = self.__class__\n        query = self._base_query_obj(session=session)\n        query = query.filter(table.is_ancestor_of(self, inclusive=True))\n        return self._base_order(query, order=order)", "response": "Generate a path from a leaf or intermediate node to the root."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rebuild_tree(cls, session, tree_id):\n        session.query(cls).filter_by(tree_id=tree_id)\\\n            .update({cls.left: 0, cls.right: 0, cls.level: 0})\n        top = session.query(cls).filter_by(parent_id=None)\\\n            .filter_by(tree_id=tree_id).one()\n        top.left = left = 1\n        top.right = right = 2\n        top.level = level = cls.get_default_level()\n\n        def recursive(children, left, right, level):\n            level = level + 1\n            for i, node in enumerate(children):\n                same_level_right = children[i - 1].right\n                left = left + 1\n\n                if i > 0:\n                    left = left + 1\n                if same_level_right:\n                    left = same_level_right + 1\n\n                right = left + 1\n                node.left = left\n                node.right = right\n                parent = node.parent\n\n                j = 0\n                while parent:\n                    parent.right = right + 1 + j\n                    parent = parent.parent\n                    j += 1\n\n                node.level = level\n                recursive(node.children, left, right, level)\n\n        recursive(top.children, left, right, level)", "response": "This method rebuid tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrebuilding the tree of the related objects.", "response": "def rebuild(cls, session, tree_id=None):\n        \"\"\" This function rebuid tree.\n\n        Args:\n            session (:mod:`sqlalchemy.orm.session.Session`): SQLAlchemy session\n\n        Kwargs:\n            tree_id (int or str): id of tree, default None\n\n        Example:\n\n        * :mod:`sqlalchemy_mptt.tests.TestTree.test_rebuild`\n        \"\"\"\n\n        trees = session.query(cls).filter_by(parent_id=None)\n        if tree_id:\n            trees = trees.filter_by(tree_id=tree_id)\n        for tree in trees:\n            cls.rebuild_tree(session, tree.tree_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the probability that a life aged x dies before 1 year Returns 0 if the age is not in the mortality table qx", "response": "def qx(mt, x):\n    \"\"\" qx: Returns the probability that a life aged x dies before 1 year\n            With the convention: the true probability is qx/1000\n    Args:\n        mt: the mortality table\n        x: the age as integer number.\n    \"\"\"\n    if x < len(mt.qx):\n        return mt.qx[x]\n    else:\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lx(mt, x):\n    if x < len(mt.lx):\n        return mt.lx[x]\n    else:\n        return 0", "response": "Returns the number of survivors at begining of age x"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dx(mt, x):\n    end_x_val = mt.lx.index(0)\n    if x < end_x_val:  \n        return mt.lx[x] - mt.lx[x + 1]\n    else:\n        return 0.0", "response": "Returns the number of dying at begining of age x"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the probability that x will survive within t years", "response": "def tpx(mt, x, t):\n    \"\"\" tpx : Returns the probability that x will survive within t years \"\"\"\n    \"\"\" npx : Returns n years survival probability at age x \"\"\"\n    return mt.lx[x + t] / mt.lx[x]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ex(mt, x):\n    sum1 = 0\n    for j in mt.lx[x + 1:-1]:\n        sum1 += j\n        #print sum1\n    try:\n        return sum1 / mt.lx[x] + 0.5\n    except:\n        return 0", "response": "ex - Returns the curtate expectation of life. Life expectancy"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the Sx of the given MT", "response": "def Sx(mt, x):\n    \"\"\" Return the Sx \"\"\"    \n    n = len(mt.Nx)\n    sum1 = 0\n    for j in range(x, n):\n        k = mt.Nx[j]\n        sum1 += k\n    return sum1"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the Cx of the given mt", "response": "def Cx(mt, x):\n    \"\"\" Return the Cx \"\"\"   \n    return ((1 / (1 + mt.i)) ** (x + 1)) * mt.dx[x] * ((1 + mt.i) ** 0.5)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the Mx of the given MT", "response": "def Mx(mt, x):\n    \"\"\" Return the Mx \"\"\"\n    n = len(mt.Cx)\n    sum1 = 0\n    for j in range(x, n):\n        k = mt.Cx[j]\n        sum1 += k\n    return sum1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Axn(mt, x, n):\n    return (mt.Mx[x] - mt.Mx[x + n]) / mt.Dx[x]", "response": "(A^1)x:n : Returns the EPV (net single premium) of a term insurance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AExn(mt, x, n):\n    return (mt.Mx[x] - mt.Mx[x + n]) / mt.Dx[x] + mt.Dx[x + n] / mt.Dx[x]", "response": "Returns the EPV of a term insurance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tAx(mt, x, t):\n    return mt.Mx[x + t] / mt.Dx[x]", "response": "n/Ax : Returns the EPV (net single premium) of a deferred whole life insurance."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the actuarial present value of a temporal annuity", "response": "def aaxn(mt, x, n, m=1):\n    \"\"\" \u00e4xn : Return the actuarial present value of a (immediate) temporal (term certain) annuity: \n    n-year temporary life annuity-anticipatory. Payable 'm' per year at the beginning of the period \n    \"\"\"\n    if m == 1:\n        return (mt.Nx[x] - mt.Nx[x + n]) / mt.Dx[x]\n    else:\n        return (mt.Nx[x] - mt.Nx[x + n]) / mt.Dx[x] - ((float(m - 1) / float(m * 2)) * (1 - nEx(mt, x, n)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef aax(mt, x, m=1):\n    return mt.Nx[x] / mt.Dx[x] - (float(m - 1) / float(m * 2))", "response": "\u00e4x : Returns the actuarial present value of an annuity of 1 per time period \n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the actuarial present value of an annuity of 1 per time period", "response": "def ax(mt, x, m=1):\n    \"\"\" ax : Returns the actuarial present value of an (immediate) annuity of 1 per time period \n    (whole life annuity-late). Payable 'm' per year at the ends of the period \n    \"\"\"\n    return (mt.Nx[x] / mt.Dx[x] - 1) + (float(m - 1) / float(m * 2))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef taax(mt, x, t, m=1):\n    return mt.Nx[x + t] / mt.Dx[x] - ((float(m - 1) / float(m * 2)) * (1 - nEx(mt, x, t)))", "response": "Return the actuarial present value of a deferred annuity at a given time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Iaaxn(mt, x, n, *args):\n    return (Sx(mt, x) - Sx(nt, x + n) - n * Nx(nt, x + n)) / Dx(nt, x)", "response": "during a term certain, IAn"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Iaxn(mt, x, n, *args):\n    return (Sx(mt, x + 1) - Sx(mt, x + n + 1) - n * Nx(mt, x + n + 1)) / Dx(mt, x)", "response": "during a term certain, IAn"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Itaax(mt, x, t):\n    return (Sx(mt, x) - Sx(mt, x + t)) / Dx(mt, x)", "response": "Itaax of a given time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _meanvalueattr(self,v):\n        sug = self.layout\n        if not self.prevlayer(): return sug.grx[v].bar\n        bars = [sug.grx[x].bar for x in self._neighbors(v)]\n        return sug.grx[v].bar if len(bars)==0 else float(sum(bars))/len(bars)", "response": "find new position of vertex v according to adjacency in prevlayer and return the mean value of adjacent positions."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding new position of vertex v according to adjacency in layer l + dir", "response": "def _medianindex(self,v):\n        \"\"\"\n        find new position of vertex v according to adjacency in layer l+dir.\n        position is given by the median value of adjacent positions.\n        median heuristic is proven to achieve at most 3 times the minimum\n        of crossings (while barycenter achieve in theory the order of |V|)\n        \"\"\"\n        assert self.prevlayer()!=None\n        N = self._neighbors(v)\n        g=self.layout.grx\n        pos = [g[x].pos for x in N]\n        lp = len(pos)\n        if lp==0: return []\n        pos.sort()\n        pos = pos[::self.layout.dirh]\n        i,j = divmod(lp-1,2)\n        return [pos[i]] if j==0 else [pos[i],pos[i+j]]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting neighbors of a node in the graph", "response": "def _neighbors(self,v):\n        \"\"\"\n        neighbors refer to upper/lower adjacent nodes.\n        Note that v.N() provides neighbors of v in the graph, while\n        this method provides the Vertex and DummyVertex adjacent to v in the\n        upper or lower layer (depending on layout.dirv state).\n        \"\"\"\n        assert self.layout.dag\n        dirv = self.layout.dirv\n        grxv = self.layout.grx[v]\n        try: #(cache)\n            return grxv.nvs[dirv]\n        except AttributeError:\n            grxv.nvs={-1:v.N(-1),+1:v.N(+1)}\n            if grxv.dummy: return grxv.nvs[dirv]\n            # v is real, v.N are graph neigbors but we need layers neighbors\n            for d in (-1,+1):\n                tr=grxv.rank+d\n                for i,x in enumerate(v.N(d)):\n                    if self.layout.grx[x].rank==tr:continue\n                    e=v.e_with(x)\n                    dum = self.layout.ctrls[e][tr]\n                    grxv.nvs[d][i]=dum\n            return grxv.nvs[dirv]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncount the number of crossings between two layers.", "response": "def _crossings(self):\n        \"\"\"\n        counts (inefficently but at least accurately) the number of\n        crossing edges between layer l and l+dirv.\n        P[i][j] counts the number of crossings from j-th edge of vertex i.\n        The total count of crossings is the sum of flattened P:\n        x = sum(sum(P,[]))\n        \"\"\"\n        g=self.layout.grx\n        P=[]\n        for v in self:\n            P.append([g[x].pos for x in self._neighbors(v)])\n        for i,p in enumerate(P):\n            candidates = sum(P[i+1:],[])\n            for j,e in enumerate(p):\n                p[j] = len(filter((lambda nx:nx<e), candidates))\n            del candidates\n        return P"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _cc(self):\n        g=self.layout.grx\n        P=[]\n        for v in self:\n            P.extend(sorted([g[x].pos for x in self._neighbors(v)]))\n        # count inversions in P:\n        s = []\n        count = 0\n        for i,p in enumerate(P):\n            j = bisect(s,p)\n            if j<i: count += (i-j)\n            s.insert(j,p)\n        return count", "response": "Returns the number of inversions in the cross count of the current instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize the layout algorithm by computing all roots and inverted edges and creates all dummy vertex and edge for long edges.", "response": "def init_all(self,roots=None,inverted_edges=None,optimize=False):\n        \"\"\"initializes the layout algorithm by computing roots (unless provided),\n           inverted edges (unless provided), vertices ranks and creates all dummy\n           vertices and layers. \n             \n             Parameters:\n                roots (list[Vertex]): set *root* vertices (layer 0)\n                inverted_edges (list[Edge]): set edges to invert to have a DAG.\n                optimize (bool): optimize ranking if True (default False)\n        \"\"\"\n        if self.initdone: return\n        # For layered sugiyama algorithm, the input graph must be acyclic,\n        # so we must provide a list of root nodes and a list of inverted edges.\n        if roots==None:\n            roots = [v for v in self.g.sV if len(v.e_in())==0]\n        if inverted_edges==None:\n            L = self.g.get_scs_with_feedback(roots)\n            inverted_edges = [x for x in self.g.sE if x.feedback]\n        self.alt_e = inverted_edges\n        # assign rank to all vertices:\n        self.rank_all(roots,optimize)\n        # add dummy vertex/edge for 'long' edges:\n        for e in self.g.E():\n            self.setdummies(e)\n        # precompute some layers values:\n        for l in self.layers: l.setup(self)\n        self.initdone = True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef draw(self,N=1.5):\n        while N>0.5:\n            for (l,mvmt) in self.ordering_step():\n                pass\n            N = N-1\n        if N>0:\n            for (l,mvmt) in self.ordering_step(oneway=True):\n                pass\n        self.setxy()\n        self.draw_edges()", "response": "draws every node coordinates after converging to optimal ordering by N - 1. 5 rounds and performs edge routing."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rank_all(self,roots,optimize=False):\n        self._edge_inverter()\n        r = [x for x in self.g.sV if (len(x.e_in())==0 and x not in roots)]\n        self._rank_init(roots+r)\n        if optimize: self._rank_optimize()\n        self._edge_inverter()", "response": "Computes the rank of all vertices in the graph."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the rank of the unranked list of vertices and all .", "response": "def _rank_init(self,unranked):\n        \"\"\"Computes rank of provided unranked list of vertices and all\n           their children. A vertex will be asign a rank when all its \n           inward edges have been *scanned*. When a vertex is asigned\n           a rank, its outward edges are marked *scanned*.\n        \"\"\"\n        assert self.dag\n        scan = {}\n        # set rank of unranked based on its in-edges vertices ranks:\n        while len(unranked)>0:\n            l = []\n            for v in unranked:\n                self.setrank(v)\n                # mark out-edges has scan-able:\n                for e in v.e_out(): scan[e]=True\n                # check if out-vertices are rank-able:\n                for x in v.N(+1):\n                    if not (False in [scan.get(e,False) for e in x.e_in()]):\n                        if x not in l: l.append(x)\n            unranked=l"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noptimize ranking by pushing long edges toward lower layers as much as possible.", "response": "def _rank_optimize(self):\n        \"\"\"optimize ranking by pushing long edges toward lower layers as much as possible.\n        see other interersting network flow solver to minimize total edge length\n        (http://jgaa.info/accepted/2005/EiglspergerSiebenhallerKaufmann2005.9.3.pdf)\n        \"\"\"\n        assert self.dag\n        for l in reversed(self.layers):\n            for v in l:\n                gv = self.grx[v]\n                for x in v.N(-1):\n                   if all((self.grx[y].rank>=gv.rank for y in x.N(+1))):\n                        gx = self.grx[x]\n                        self.layers[gx.rank].remove(x)\n                        gx.rank = gv.rank-1\n                        self.layers[gv.rank-1].append(x)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting rank value for vertex v and add it to the corresponding layer.", "response": "def setrank(self,v):\n        \"\"\"set rank value for vertex v and add it to the corresponding layer.\n           The Layer is created if it is the first vertex with this rank.\n        \"\"\"\n        assert self.dag\n        r=max([self.grx[x].rank for x in v.N(-1)]+[-1])+1\n        self.grx[v].rank=r\n        # add it to its layer:\n        try:\n            self.layers[r].append(v)\n        except IndexError:\n            assert r==len(self.layers)\n            self.layers.append(Layer([v]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dummyctrl(self,r,ctrl):\n        dv = DummyVertex(r)\n        dv.view.w,dv.view.h=self.dw,self.dh\n        self.grx[dv] = dv\n        dv.ctrl = ctrl\n        ctrl[r] = dv\n        self.layers[r].append(dv)\n        return dv", "response": "creates a DummyVertex at rank r inserted in the ctrl dict and adds it to the edge s control vertices and returns it"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setdummies(self,e):\n        v0,v1 = e.v\n        r0,r1 = self.grx[v0].rank,self.grx[v1].rank\n        if r0>r1:\n            assert e in self.alt_e\n            v0,v1 = v1,v0\n            r0,r1 = r1,r0\n        if (r1-r0)>1:\n            # \"dummy vertices\" are stored in the edge ctrl dict,\n            # keyed by their rank in layers.\n            ctrl=self.ctrls[e]={}\n            ctrl[r0]=v0\n            ctrl[r1]=v1\n            for r in xrange(r0+1,r1):\n                self.dummyctrl(r,ctrl)", "response": "creates and defines all needed dummy vertices for edge e.\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ordering_step(self,oneway=False):\n        self.dirv=-1\n        crossings = 0\n        for l in self.layers:\n            mvmt = l.order()\n            crossings += mvmt\n            yield (l,mvmt)\n        if oneway or (crossings == 0):\n            return\n        self.dirv=+1\n        while l:\n            mvmt = l.order()\n            yield (l,mvmt)\n            l = l.nextlayer()", "response": "iterator that computes all vertices ordering in the layers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute all vertex coordinates using Brandes & Kopf.", "response": "def setxy(self):\n        \"\"\"computes all vertex coordinates (x,y) using\n        an algorithm by Brandes & Kopf.\n        \"\"\"\n        self._edge_inverter()\n        self._detect_alignment_conflicts()\n        inf = float('infinity')\n        # initialize vertex coordinates attributes:\n        for l in self.layers:\n            for v in l:\n                self.grx[v].root  = v\n                self.grx[v].align = v\n                self.grx[v].sink  = v\n                self.grx[v].shift = inf\n                self.grx[v].X     = None\n                self.grx[v].x     = [0.0]*4\n        curvh = self.dirvh # save current dirvh value\n        for dirvh in xrange(4):\n            self.dirvh = dirvh\n            self._coord_vertical_alignment()\n            self._coord_horizontal_compact()\n        self.dirvh = curvh # restore it\n        # vertical coordinate assigment of all nodes:\n        Y = 0\n        for l in self.layers:\n            dY = max([v.view.h/2. for v in l])\n            for v in l:\n                vx = sorted(self.grx[v].x)\n                # mean of the 2 medians out of the 4 x-coord computed above:\n                avgm = (vx[1]+vx[2])/2.\n                # final xy-coordinates :\n                v.view.xy = (avgm,Y+dY)\n            Y += 2*dY+self.yspace\n        self._edge_inverter()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _detect_alignment_conflicts(self):\n        curvh = self.dirvh # save current dirvh value\n        self.dirvh=0\n        self.conflicts = []\n        for L in self.layers:\n            last = len(L)-1\n            prev = L.prevlayer()\n            if not prev: continue\n            k0=0\n            k1_init=len(prev)-1\n            l=0\n            for l1,v in enumerate(L):\n                if not self.grx[v].dummy: continue\n                if l1==last or v.inner(-1):\n                    k1=k1_init\n                    if v.inner(-1):\n                        k1=self.grx[v.N(-1)[-1]].pos\n                    for vl in L[l:l1+1]:\n                        for vk in L._neighbors(vl):\n                            k = self.grx[vk].pos\n                            if (k<k0 or k>k1):\n                                self.conflicts.append((vk,vl))\n                    l=l1+1\n                    k0=k1\n        self.dirvh = curvh", "response": "detect conflicts between dummy nodes and regular crossings"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms vertical alignment according to current dirvh internal state.", "response": "def _coord_vertical_alignment(self):\n        \"\"\"performs vertical alignment according to current dirvh internal state.\n        \"\"\"\n        dirh,dirv = self.dirh,self.dirv\n        g = self.grx\n        for l in self.layers[::-dirv]:\n            if not l.prevlayer(): continue\n            r=None\n            for vk in l[::dirh]:\n                for m in l._medianindex(vk):\n                    # take the median node in dirv layer:\n                    um = l.prevlayer()[m]\n                    # if vk is \"free\" align it with um's root\n                    if g[vk].align is vk:\n                        if dirv==1: vpair = (vk,um)\n                        else:       vpair = (um,vk)\n                        # if vk<->um link is used for alignment\n                        if (vpair not in self.conflicts) and \\\n                           (r==None or dirh*r<dirh*m):\n                            g[um].align = vk\n                            g[vk].root = g[um].root\n                            g[vk].align = g[vk].root\n                            r = m"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a cURL POST request to the given URL and returns the JSON response.", "response": "def make_request(cls, url, method, params=None, basic_auth=None, timeout=600):\n        \"\"\" Makes a cURL POST request to the given URL, specifying the data to be passed in as\n         {\"method\": method, \"params\": parameters}\n\n        :param str url: URL to connect to.\n        :param str method: The API method to call.\n        :param dict params: Dictionary object of the parameters associated with the `method` given. None by default.\n        :param list | tuple basic_auth: List containing your username and password as ['username', 'password'].\n         This is empty by default, however it is required by all of the `lbrycrd` methods\n        :param float timeout: Amount of seconds to wait for the server's response before we timeout.\n        :raises LBRYException: If the request returns an error when calling the API\n        :return: A `dict` of the JSON result member of the request\n        :rtype: dict, PreparedResponse\n        \"\"\"\n\n        # Default parameters\n        params = {} if params is None else params\n\n        # Increment the request ID\n        cls.request_id += 1\n\n        # Weed out all the None valued params\n        params = {k: v for (k, v) in params.items() if v is not None}\n\n        # This is the data to be sent\n        data = {\"method\": method, \"params\": params, \"jsonrpc\": \"2.0\", \"id\": cls.request_id}\n\n        headers = {\"Content-Type\": \"application/json-rpc\",  # sends the request as a json\n                   \"user-agent\": \"LBRY python3-api\"}    # Sets the user agent\n\n        # You could create a request object and then make a prepared request object\n        # And then be able to print the Request that will be sent\n        request = requests.Request('POST', url, json=data, headers=headers, auth=basic_auth)\n\n        prepared = request.prepare()\n\n        try:\n\n            # Create a session object\n            sesh = requests.Session()\n\n            # Send the prepared request object through\n            response = sesh.send(prepared, timeout=timeout)\n\n            response_json = response.json()\n\n            # Successful request was made\n            if 'result' in response_json:\n\n                # Returns the Result sub-JSON formatted as a dict\n                return response_json['result'], response\n\n            # If the response we received from the LBRY http post had an error\n            elif 'error' in response_json:\n                raise LBRYUtils.LBRYException(\"POST Request made to LBRY received an error\",\n                                              response_json, response.status_code, prepared)\n\n        except requests.HTTPError as HE:\n            print(HE)\n\n            return None, None\n\n        except requests.RequestException as RE:\n            # Print the Request Exception given\n            print(RE)\n\n            print(\"Printing Request Created:\\n\")\n\n            LBRYUtils.print_request(prepared)\n\n            return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_png(varNumVol, strPathPng, tplVslSpcSze=(200, 200), varStrtIdx=0,\n             varZfill=3):\n    \"\"\"\n    Load PNGs with stimulus information for pRF model creation.\n\n    Parameters\n    ----------\n    varNumVol : int\n        Number of PNG files.\n    strPathPng : str\n        Parent directory of PNG files. PNG files need to be organsied in\n        numerical order (e.g. `file_001.png`, `file_002.png`, etc.).\n    tplVslSpcSze : tuple\n        Pixel size (x, y) at which PNGs are sampled. In case of large PNGs it\n        is useful to sample at a lower than the original resolution.\n    varStrtIdx : int\n        Start index of PNG files. For instance, `varStrtIdx = 0` if the name of\n        the first PNG file is `file_000.png`, or `varStrtIdx = 1` if it is\n        `file_001.png`.\n    varZfill : int\n        Zero padding of PNG file names. For instance, `varStrtIdx = 3` if the\n        name of PNG files is `file_007.png`, or `varStrtIdx = 4` if it is\n        `file_0007.png`.\n\n    Returns\n    -------\n    aryPngData : np.array\n        3D Numpy array with the following structure:\n        aryPngData[x-pixel-index, y-pixel-index, PngNumber]\n\n    Notes\n    -----\n    Part of py_pRF_mapping library.\n    \"\"\"\n    # Create list of png files to load:\n    lstPngPaths = [None] * varNumVol\n    for idx01 in range(0, varNumVol):\n        lstPngPaths[idx01] = (strPathPng +\n                              str(idx01 + varStrtIdx).zfill(varZfill) +\n                              '.png')\n\n    # The png data will be saved in a numpy array of the following order:\n    # aryPngData[x-pixel, y-pixel, PngNumber].\n    aryPngData = np.zeros((tplVslSpcSze[0],\n                           tplVslSpcSze[1],\n                           varNumVol))\n\n    # Open first image in order to check dimensions (greyscale or RGB, i.e. 2D\n    # or 3D).\n    objIm = Image.open(lstPngPaths[0])\n    aryTest = np.array(objIm.resize((objIm.size[0], objIm.size[1]),\n                                    Image.ANTIALIAS))\n    varNumDim = aryTest.ndim\n    del(aryTest)\n\n    # Loop trough PNG files:\n    for idx01 in range(0, varNumVol):\n\n        # Old version of reading images with scipy\n        # aryPngData[:, :, idx01] = sp.misc.imread(lstPngPaths[idx01])[:, :, 0]\n        # aryPngData[:, :, idx01] = sp.misc.imread(lstPngPaths[idx01])[:, :]\n\n        # Load & resize image:\n        objIm = Image.open(lstPngPaths[idx01])\n        objIm = objIm.resize((tplVslSpcSze[0],\n                              tplVslSpcSze[1]),\n                             resample=Image.NEAREST)\n\n        # Casting of array depends on dimensionality (greyscale or RGB, i.e. 2D\n        # or 3D):\n        if varNumDim == 2:\n            aryPngData[:, :, idx01] = np.array(objIm.resize(\n                (objIm.size[0], objIm.size[1]), Image.ANTIALIAS))[:, :]\n        elif varNumDim == 3:\n            aryPngData[:, :, idx01] = np.array(objIm.resize(\n                (objIm.size[0], objIm.size[1]), Image.ANTIALIAS))[:, :, 0]\n        else:\n            # Error message:\n            strErrMsg = ('ERROR: PNG files for model creation need to be RGB '\n                         + 'or greyscale.')\n            raise ValueError(strErrMsg)\n\n    # Convert RGB values (0 to 255) to integer ones and zeros:\n    aryPngData = (aryPngData > 200).astype(np.int8)\n\n    return aryPngData", "response": "Load PNGs with stimulus information for pRF model creation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading information from event text file.", "response": "def load_ev_txt(strPthEv):\n    \"\"\"Load information from event text file.\n\n    Parameters\n    ----------\n    input1 : str\n        Path to event text file\n    Returns\n    -------\n    aryEvTxt : 2d numpy array, shape [n_measurements, 3]\n        Array with info about conditions: type, onset, duration\n    Notes\n    -----\n    Part of py_pRF_mapping library.\n    \"\"\"\n    aryEvTxt = np.loadtxt(strPthEv, dtype='float', comments='#', delimiter=' ',\n                          skiprows=0, usecols=(0, 1, 2))\n    return aryEvTxt"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying status mapping to a raw API result.", "response": "def adjust_status(info: dict) -> dict:\n    \"\"\"Apply status mapping to a raw API result.\"\"\"\n    modified_info = deepcopy(info)\n    modified_info.update({\n        'level':\n            get_nearest_by_numeric_key(STATUS_MAP, int(info['level'])),\n        'level2':\n            STATUS_MAP[99] if info['level2'] is None else\n            get_nearest_by_numeric_key(STATUS_MAP, int(info['level2']))\n    })\n\n    return modified_info"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the status of the CDC for the provided latitude and longitude.", "response": "async def status_by_coordinates(\n            self, latitude: float, longitude: float) -> dict:\n        \"\"\"Return the CDC status for the provided latitude/longitude.\"\"\"\n        cdc_data = await self.raw_cdc_data()\n        nearest = await self.nearest_by_coordinates(latitude, longitude)\n        return adjust_status(cdc_data[nearest['state']['name']])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the CDC status for the specified state.", "response": "async def status_by_state(self, state: str) -> dict:\n        \"\"\"Return the CDC status for the specified state.\"\"\"\n        data = await self.raw_cdc_data()\n\n        try:\n            info = next((v for k, v in data.items() if state in k))\n        except StopIteration:\n            return {}\n\n        return adjust_status(info)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the exception class and message of the exception as string.", "response": "def brief_exception_text(exception, secret_values):\n    \"\"\"\n    Returns the Exception class and the message of the exception as string.\n\n    :param exception: The exception to format\n    :param secret_values: Values to hide in output\n    \"\"\"\n    exception_text = _hide_secret_values(str(exception), secret_values)\n    return '[{}]\\n{}'.format(type(exception).__name__, exception_text)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the exception message and the name of the exception class to stderr.", "response": "def print_exception(exception, secret_values=None):\n    \"\"\"\n    Prints the exception message and the name of the exception class to stderr.\n\n    :param exception: The exception to print\n    :param secret_values: Values to hide in output\n    \"\"\"\n    print(brief_exception_text(exception, secret_values), file=sys.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insert(self, **kwargs):\n        if self.is_valid:\n            before = self.before_insert()\n            if before:\n                return before\n\n            try:\n                self._document['_id'] = self.insert_one(self._document)\n\n                self.after_insert()\n\n                return self._document\n            except PyMongoException as exc:\n                return PyMongoError(\n                    error_message=exc.details.get(\n                        'errmsg', exc.details.get('err', 'PyMongoError.')\n                    ),\n                    operation='insert', collection=type(self).__name__,\n                    document=self._document,\n                )\n\n        return self._errors", "response": "Inserts the document into the database if it is valid. Returns errors otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, **kwargs):\n        if self.is_valid:\n            if '_id' in self._document:\n                to_update = self.find_one({'_id': self._id})\n\n                if to_update:\n                    before = self.before_update(old=to_update)\n                    if before:\n                        return before\n\n                    try:\n                        self.replace_one({'_id': self._id}, self._document)\n\n                        self.after_update(old=to_update)\n\n                        return self._document\n                    except PyMongoException as exc:\n                        return PyMongoError(\n                            error_message=exc.details.get(\n                                'errmsg', exc.details.get(\n                                    'err', 'PyMongoError.'\n                                )\n                            ),\n                            operation='update', collection=type(self).__name__,\n                            document=self._document,\n                        )\n                else:\n                    return DocumentNotFoundError(type(self).__name__, self._id)\n            else:\n                return UnidentifiedDocumentError(\n                    type(self).__name__, self._document\n                )\n\n        return self._errors", "response": "Updates the document with the given _id saved in the collection if it is valid. Returns errors otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self, **kwargs):\n        if self.is_valid:\n            if '_id' in self._document:\n                to_delete = self.find_one({'_id': self._id})\n\n                if to_delete:\n                    before = self.before_delete()\n                    if before:\n                        return before\n\n                    try:\n                        self.delete_one({'_id': self._id})\n\n                        self.after_delete()\n\n                        return self._document\n                    except PyMongoException as exc:\n                        return PyMongoError(\n                            error_message=exc.details.get(\n                                'errmsg', exc.details.get(\n                                    'err', 'PyMongoError.'\n                                )\n                            ),\n                            operation='delete', collection=type(self).__name__,\n                            document=self._document,\n                        )\n                else:\n                    return DocumentNotFoundError(type(self).__name__, self._id)\n            else:\n                return UnidentifiedDocumentError(\n                    type(self).__name__, self._document\n                )", "response": "Deletes the document if it is saved in the collection."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning one document dict if one passes the filter.", "response": "def find_one(cls, filter=None, *args, **kwargs):\n        \"\"\"\n        Returns one document dict if one passes the filter.\n        Returns None otherwise.\n        \"\"\"\n        return cls.collection.find_one(filter, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find(cls, *args, **kwargs):\n        return list(cls.collection.find(*args, **kwargs))", "response": "Returns all document dicts that pass the filter\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef aggregate(cls, pipeline=None, **kwargs):\n        return list(cls.collection.aggregate(pipeline or [], **kwargs))", "response": "Returns the document dicts returned from the Aggregation Pipeline\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert_many(cls, documents, ordered=True):\n        return cls.collection.insert_many(documents, ordered).inserted_ids", "response": "Inserts a list of documents into the Collection and returns their _ids\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating all the documents that pass the filter with the update value Will upsert a new document if upsert = True", "response": "def update_many(cls, filter, update, upsert=False):\n        \"\"\"\n        Updates all documents that pass the filter with the update value\n        Will upsert a new document if upsert=True and no document is filtered\n        \"\"\"\n        return cls.collection.update_many(filter, update, upsert).raw_result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplaces a single entry in the cache with a new value.", "response": "def replace_one(cls, filter, replacement, upsert=False):\n        \"\"\"\n        Replaces a document that passes the filter.\n        Will upsert a new document if upsert=True and no document is filtered\n        \"\"\"\n        return cls.collection.replace_one(\n            filter, replacement, upsert\n        ).raw_result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a Document if any document is filtered returns None otherwise", "response": "def get(cls, filter=None, **kwargs):\n        \"\"\"\n        Returns a Document if any document is filtered, returns None otherwise\n        \"\"\"\n        document = cls(cls.find_one(filter, **kwargs))\n        return document if document.document else None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef documents(cls, filter=None, **kwargs):\n        documents = [cls(document) for document in cls.find(filter, **kwargs)]\n        return [document for document in documents if document.document]", "response": "Returns a list of Documents if any document is filtered by the filter keyword arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an iterator over all of the statements belonging to a file.", "response": "def in_file(self, fn: str) -> Iterator[Statement]:\n        \"\"\"\n        Returns an iterator over all of the statements belonging to a file.\n        \"\"\"\n        yield from self.__file_to_statements.get(fn, [])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an iterator over all of the statements located at a given line.", "response": "def at_line(self, line: FileLine) -> Iterator[Statement]:\n        \"\"\"\n        Returns an iterator over all of the statements located at a given line.\n        \"\"\"\n        num = line.num\n        for stmt in self.in_file(line.filename):\n            if stmt.location.start.line == num:\n                yield stmt"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef funcFindPrfGpu(idxPrc, vecMdlXpos, vecMdlYpos, vecMdlSd, aryFunc,  # noqa\n                   aryPrfTc, varL2reg, queOut, lgcPrint=True):\n    \"\"\"\n    Find best pRF model for voxel time course.\n\n    Parameters\n    ----------\n    idxPrc : int\n        Process ID of the process calling this function (for CPU\n        multi-threading). In GPU version, this parameter is 0 (just one thread\n        on CPU).\n    vecMdlXpos : np.array\n        1D array with pRF model x positions.\n    vecMdlYpos : np.array\n        1D array with pRF model y positions.\n    vecMdlSd : np.array\n        1D array with pRF model sizes (SD of Gaussian).\n    aryFunc : np.array\n        2D array with functional MRI data, with shape aryFunc[voxel, time].\n    aryPrfTc : np.array\n        Array with pRF model time courses, with shape\n        aryPrfTc[x-pos, y-pos, SD, motion-direction, time]\n    varL2reg : float\n        L2 regularisation factor for ridge regression.\n    queOut : multiprocessing.queues.Queue\n        Queue to put the results on.\n    lgcPrint : boolean\n        Whether print statements should be executed.\n\n    Returns\n    -------\n    lstOut : list\n        List containing the following objects:\n        idxPrc : int\n            Process ID of the process calling this function (for CPU\n            multi-threading). In GPU version, this parameter is 0.\n        vecBstXpos : np.array\n            1D array with best fitting x-position for each voxel, with shape\n            vecBstXpos[voxel].\n        vecBstYpos : np.array\n            1D array with best fitting y-position for each voxel, with shape\n            vecBstYpos[voxel].\n        vecBstSd : np.array\n            1D array with best fitting pRF size for each voxel, with shape\n            vecBstSd[voxel].\n        vecBstR2 : np.array\n            1D array with R2 value of 'winning' pRF model for each voxel, with\n            shape vecBstR2[voxel].\n        dummy : np.array\n            2D array that is supposed to contain the beta values of 'winning'\n            pRF models for each voxel, with shape aryBeta[voxel, beta]. AT THE\n            MOMENT, CONTAINS EMPTY DUMMY ARRAY (np.zeros).\n\n    Notes\n    -----\n    Uses a queue that runs in a separate thread to put model time courses on\n    the computational graph.\n    \"\"\"\n    # -------------------------------------------------------------------------\n    # *** Queue-feeding-function that will run in extra thread\n    def funcPlcIn():\n        \"\"\"Place data on queue.\"\"\"\n        # Iteration counter:\n        idxCnt = 0\n\n        while True:\n\n            # Feed example to Tensorflow placeholder\n            aryTmp02 = lstPrfTc[idxCnt]\n            dicIn = {objPlcHld01: aryTmp02}\n\n            # Push to the queue:\n            objSess.run(objEnQ, feed_dict=dicIn)\n\n            idxCnt += 1\n\n            # Stop if coordinator says stop:\n            if objCoord.should_stop():\n                break\n\n            # Stop if all data has been put on the queue:\n            elif idxCnt == varNumMdls:\n                break\n\n    # -------------------------------------------------------------------------\n    # *** Prepare pRF model time courses for graph\n    if lgcPrint:\n        print('------Prepare pRF model time courses for graph')\n\n    # Information about pRF model parameters:\n    varNumX = np.shape(vecMdlXpos)[0]\n    varNumY = np.shape(vecMdlYpos)[0]\n    varNumPrfSizes = np.shape(vecMdlSd)[0]\n\n    # Number of predictors (betas):\n    varNumBeta = aryPrfTc.shape[3]\n\n    # At this point, aryPrfTc has the following dimensions:\n    # aryPrfTc[x-pos, y-pos, SD, motion-direction, time]\n\n    # Reshape pRF model time courses:\n    aryPrfTc = np.reshape(aryPrfTc,\n                          ((aryPrfTc.shape[0]\n                            * aryPrfTc.shape[1]\n                            * aryPrfTc.shape[2]),\n                           aryPrfTc.shape[3],\n                           aryPrfTc.shape[4]))\n\n    # Now, aryPrfTc has the following dimensions:\n    # aryPrfTc[(x-pos * y-pos * SD), motion-direction, time]\n\n    # Original total number of pRF time course models (before removing models\n    # with zero variance):\n    varNumMdlsTtl = aryPrfTc.shape[0]\n\n    # Change type to float 32:\n    aryPrfTc = aryPrfTc.astype(np.float32)\n\n    # The pRF model is fitted only if variance along time dimension is not\n    # zero. Get variance along time dimension:\n    vecVarPrfTc = np.var(aryPrfTc, axis=2)\n\n    # Zero with float32 precision for comparison:\n    varZero32 = np.array(([0.0])).astype(np.float32)[0]\n\n    # Boolean array for models with variance greater than zero for at least\n    # one motion direction:\n    vecLgcVar = np.max(\n                       np.greater(vecVarPrfTc,\n                                  varZero32),\n                       axis=1\n                       )\n\n    # Take models with variance less than zero out of the array:\n    aryPrfTc = aryPrfTc[vecLgcVar, :, :]\n\n    # Swap axes, so that\n    # aryPrfTc[(x-pos * y-pos * SD), time, motion-direction]\n    aryPrfTc = np.swapaxes(aryPrfTc, 1, 2)\n\n    # Add constant term (ones):\n    # aryPrfTc = np.concatenate((aryPrfTc,\n    #                            np.ones((aryPrfTc.shape[0],\n    #                                     aryPrfTc.shape[1],\n    #                                     1)).astype(np.float32)),\n    #                           axis=2)\n\n    # Size of pRF time courses in MB:\n    varSzePrf = np.divide(float(aryPrfTc.nbytes),\n                          1000000.0)\n    if lgcPrint:\n        print(('---------Size of pRF time courses: '\n               + str(np.around(varSzePrf))\n               + ' MB'))\n\n    # Put pRF model time courses into list:\n    lstPrfTc = [None] * aryPrfTc.shape[0]\n    for idxMdl in range(int(aryPrfTc.shape[0])):\n        lstPrfTc[idxMdl] = aryPrfTc[idxMdl, :, :]\n    del(aryPrfTc)\n\n    # Total number of pRF models to fit:\n    varNumMdls = len(lstPrfTc)\n\n    # -------------------------------------------------------------------------\n    # *** Prepare functional data for graph\n    if lgcPrint:\n        print('------Prepare functional data for graph')\n\n    # Number of voxels to be fitted:\n    varNumVox = aryFunc.shape[0]\n\n    # Number of volumes:\n    varNumVol = aryFunc.shape[1]\n\n    # We reshape the voxel time courses, so that time goes down the column,\n    # i.e. from top to bottom.\n    aryFunc = aryFunc.T\n\n    # Change type to float 32:\n    aryFunc = aryFunc.astype(np.float32)\n\n    # We cannot commit the entire functional data to GPU memory, we need to\n    # create chunks. Establish the limit (maximum size) of one chunk (in MB):\n    varSzeMax = 50.0  # 20.0\n\n    # Size of functional data in MB:\n    varSzeFunc = np.divide(float(aryFunc.nbytes),\n                           1000000.0)\n    if lgcPrint:\n        print(('---------Size of functional data: '\n               + str(np.around(varSzeFunc))\n               + ' MB'))\n\n    # Number of chunks to create:\n    varNumChnk = int(np.ceil(np.divide(varSzeFunc, varSzeMax)))\n\n    if lgcPrint:\n        print(('---------Functional data will be split into '\n               + str(varNumChnk)\n               + ' batches'))\n\n    # Vector with the indicies at which the functional data will be separated\n    # in order to be chunked up for the parallel processes:\n    vecIdxChnks = np.linspace(0,\n                              varNumVox,\n                              num=varNumChnk,\n                              endpoint=False)\n    vecIdxChnks = np.hstack((vecIdxChnks, varNumVox))\n\n    # List into which the chunks of functional data are put:\n    lstFunc = [None] * varNumChnk\n\n    # Put functional data into chunks:\n    for idxChnk in range(0, varNumChnk):\n        # Index of first voxel to be included in current chunk:\n        varChnkStr = int(vecIdxChnks[idxChnk])\n        # Index of last voxel to be included in current chunk:\n        varChnkEnd = int(vecIdxChnks[(idxChnk+1)])\n        # Put voxel array into list:\n        lstFunc[idxChnk] = aryFunc[:, varChnkStr:varChnkEnd]\n\n    # We delete the original array holding the functional data to conserve\n    # memory. Therefore, we first need to calculate the mean (will be needed\n    # for calculation of R2).\n\n    # After finding the best fitting model for each voxel, we still have to\n    # calculate the coefficient of determination (R-squared) for each voxel. We\n    # start by calculating the total sum of squares (i.e. the deviation of the\n    # data from the mean). The mean of each time course:\n    vecFuncMean = np.mean(aryFunc, axis=0)\n    # Deviation from the mean for each datapoint:\n    vecFuncDev = np.subtract(aryFunc, vecFuncMean[None, :])\n    # Sum of squares:\n    vecSsTot = np.sum(np.power(vecFuncDev,\n                               2.0),\n                      axis=0)\n\n    # We don't need the original array with the functional data anymore (the\n    # above seems to have created a hard copy):\n    del(vecFuncDev)\n    del(aryFunc)\n\n    # -------------------------------------------------------------------------\n    # *** Miscellaneous preparations\n\n    # Vector for minimum squared residuals:\n    vecResSsMin = np.zeros((varNumVox), dtype=np.float32)\n\n    # Vector for indices of models with minimum residuals:\n    vecResSsMinIdx = np.zeros((varNumVox), dtype=np.int32)\n\n    # Multiply L2 regularization factor with identity matrix:\n    aryL2reg = np.multiply(np.eye(varNumBeta),\n                           varL2reg).astype(np.float32)\n\n    # Reduce logging verbosity:\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\n    # -------------------------------------------------------------------------\n    # *** Prepare status indicator\n\n    # We create a status indicator for the time consuming pRF model finding\n    # algorithm. Number of steps of the status indicator:\n    varStsStpSze = 20\n\n    # Vector with pRF values at which to give status feedback:\n    vecStatPrf = np.linspace(0,\n                             (varNumMdls * varNumChnk),\n                             num=(varStsStpSze+1),\n                             endpoint=True)\n    vecStatPrf = np.ceil(vecStatPrf)\n    vecStatPrf = vecStatPrf.astype(int)\n\n    # Vector with corresponding percentage values at which to give status\n    # feedback:\n    vecStatPrc = np.linspace(0,\n                             100,\n                             num=(varStsStpSze+1),\n                             endpoint=True)\n    vecStatPrc = np.ceil(vecStatPrc)\n    vecStatPrc = vecStatPrc.astype(int)\n\n    # Counter for status indicator:\n    varCntSts01 = 0\n    varCntSts02 = 0\n\n    # -------------------------------------------------------------------------\n    # *** Loop through chunks\n    if lgcPrint:\n        print('------Run graph')\n\n    for idxChnk in range(varNumChnk):\n        if lgcPrint:\n            print(('---------Chunk: ' + str(idxChnk)))\n            print('lstPrfTc[0].shape')\n            print(lstPrfTc[0].shape)\n\n        # Define session:\n        # objSess = tf.Session()\n        with tf.Graph().as_default(), tf.Session() as objSess:\n\n            # -----------------------------------------------------------------\n            # *** Prepare queue\n            if lgcPrint:\n                print('------Define computational graph, queue & session')\n\n            # Queue capacity:\n            varCapQ = 10\n\n            # Dimensions of placeholder have to be determined outside of the\n            # tensor object, otherwise the object on which the size is\n            # calculated is loaded into GPU memory.\n            varDim01 = lstPrfTc[0].shape[0]\n            varDim02 = lstPrfTc[0].shape[1]\n\n            # The queue:\n            objQ = tf.FIFOQueue(capacity=varCapQ,\n                                dtypes=[tf.float32],\n                                shapes=[(varDim01, varDim02)])\n\n            # Method for getting queue size:\n            objSzeQ = objQ.size()\n\n            # Placeholder that is used to put design matrix on computational\n            # graph:\n            objPlcHld01 = tf.placeholder(tf.float32,\n                                         shape=[varDim01, varDim02])\n\n            # The enqueue operation that puts data on the graph.\n            objEnQ = objQ.enqueue([objPlcHld01])\n\n            # Number of threads that will be created:\n            varNumThrd = 1\n\n            # The queue runner (places the enqueue operation on the queue?).\n            objRunQ = tf.train.QueueRunner(objQ, [objEnQ] * varNumThrd)\n            tf.train.add_queue_runner(objRunQ)\n\n            # The tensor object that is retrieved from the queue. Functions\n            # like placeholders for the data in the queue when defining the\n            # graph.\n            objDsng = objQ.dequeue()\n\n            # Coordinator needs to be initialised:\n            objCoord = tf.train.Coordinator()\n\n            # -----------------------------------------------------------------\n            # *** Fill queue\n\n            # Buffer size (number of samples to put on queue before starting\n            # execution of graph):\n            varBuff = 10\n\n            # Define & run extra thread with graph that places data on queue:\n            objThrd = threading.Thread(target=funcPlcIn)\n            objThrd.setDaemon(True)\n            objThrd.start()\n\n            # Stay in this while loop until the specified number of samples\n            # (varBuffer) have been placed on the queue).\n            varTmpSzeQ = 0\n            while varTmpSzeQ < varBuff:\n                varTmpSzeQ = objSess.run(objSzeQ)\n\n            # -----------------------------------------------------------------\n            # *** Prepare & run the graph\n\n            # Chunk of functional data:\n            aryTmp01 = np.copy(lstFunc[idxChnk])\n            with tf.device('/gpu:0'):\n                objFunc = tf.Variable(aryTmp01)\n\n            # Regularisation factor matrix:\n            with tf.device('/gpu:0'):\n                objL2reg = tf.Variable(aryL2reg)\n\n            # The computational graph. Operation that solves matrix (in the\n            # least squares sense), and calculates residuals along time\n            # dimension. There are two versions: (1) The number of measurements\n            # (e.g. volumes) is greater than or equal to the number of\n            # predictors (betas). (2) The number of measurements is less than\n            # the number of predictors.\n\n            # (1) Number of measurements greater/equal to number of predictors:\n            if np.greater_equal(varNumVol, varNumBeta):\n                objMatSlve = tf.reduce_sum(\n                                           tf.squared_difference(\n                                                                 objFunc,\n                                                                 tf.matmul(\n                                                                           objDsng,\n                                                                           tf.matmul(\n                                                                                     tf.matmul(\n                                                                                               tf.matrix_inverse(\n                                                                                                                 tf.add(\n                                                                                                                        tf.matmul(\n                                                                                                                                   objDsng,\n                                                                                                                                   objDsng,\n                                                                                                                                   transpose_a=True,\n                                                                                                                                   transpose_b=False\n                                                                                                                                   ),\n                                                                                                                        objL2reg\n                                                                                                                        )\n                                                                                                                 ),\n                                                                                               objDsng,\n                                                                                               transpose_a=False,\n                                                                                               transpose_b=True\n                                                                                               ),\n                                                                                     objFunc\n                                                                                     )\n                                                                           ),\n                                                                 ),\n                                           axis=0\n                                           )\n\n            # (2) Number of measurements less than number of predictors:\n            else:\n                objMatSlve = tf.reduce_sum(\n                                           tf.squared_difference(\n                                                                 objFunc,\n                                                                 tf.matmul(\n                                                                           objDsng,\n                                                                           tf.matmul(\n                                                                                     tf.matmul(\n                                                                                               objDsng,\n                                                                                               tf.matrix_inverse(\n                                                                                                                 tf.add(\n                                                                                                                        tf.matmul(\n                                                                                                                                   objDsng,\n                                                                                                                                   objDsng,\n                                                                                                                                   transpose_a=False,\n                                                                                                                                   transpose_b=True\n                                                                                                                                   ),\n                                                                                                                        objL2reg\n                                                                                                                        )\n                                                                                                                 ),\n                                                                                               transpose_a=True,\n                                                                                               transpose_b=False\n                                                                                               ),\n                                                                                     objFunc\n                                                                                     )\n                                                                           ),\n                                                                 ),\n                                           axis=0\n                                           )\n\n            # Variables need to be (re-)initialised:\n            objSess.run(tf.global_variables_initializer())\n\n            # Mark graph as read-only (would throw an error in case of memory\n            # leak):\n            objSess.graph.finalize()\n\n            # Index of first voxel in current chunk (needed to assign results):\n            varChnkStr = int(vecIdxChnks[idxChnk])\n\n            # Index of last voxel in current chunk (needed to assign results):\n            varChnkEnd = int(vecIdxChnks[(idxChnk+1)])\n\n            # Array for results of current chunk:\n            aryTmpRes = np.zeros((varNumMdls,\n                                  lstFunc[idxChnk].shape[1]),\n                                 dtype=np.float32)\n\n            # Loop through models:\n            for idxMdl in range(varNumMdls):\n\n                # Run main computational graph and put results in list:\n                # varTme01 = time.time()\n\n                aryTmpRes[idxMdl, :] = objSess.run(objMatSlve)\n\n                # print(('---------Time for graph call: '\n                #        + str(time.time() - varTme01)))\n\n                # Status indicator:\n                if varCntSts02 == vecStatPrf[varCntSts01]:\n                    # Number of elements on queue:\n                    varTmpSzeQ = objSess.run(objSzeQ)\n                    # Prepare status message:\n                    strStsMsg = ('---------Progress: '\n                                 + str(vecStatPrc[varCntSts01])\n                                 + ' % --- Number of elements on queue: '\n                                 + str(varTmpSzeQ))\n                    if lgcPrint:\n                        print(strStsMsg)\n                    # Only increment counter if the last value has not been\n                    # reached yet:\n                    if varCntSts01 < varStsStpSze:\n                        varCntSts01 = varCntSts01 + int(1)\n                # Increment status indicator counter:\n                varCntSts02 = varCntSts02 + 1\n\n            # Stop threads.\n            objCoord.request_stop()\n            # objSess.close()\n\n        # Get indices of models with minimum residuals (minimum along\n        # model-space) for current chunk:\n        vecResSsMinIdx[varChnkStr:varChnkEnd] = np.argmin(aryTmpRes, axis=0)\n        # Get minimum residuals of those models:\n        vecResSsMin[varChnkStr:varChnkEnd] = np.min(aryTmpRes, axis=0)\n\n    # -------------------------------------------------------------------------\n    # *** Post-process results\n    if lgcPrint:\n        print('------Post-processing results')\n\n    # Array for model parameters. At the moment, we have the indices of the\n    # best fitting models, so we need an array that tells us what model\n    # parameters these indices refer to.\n    aryMdl = np.zeros((varNumMdlsTtl, 3), dtype=np.float32)\n\n    # Model parameter can be represented as float32 as well:\n    vecMdlXpos = vecMdlXpos.astype(np.float32)\n    vecMdlYpos = vecMdlYpos.astype(np.float32)\n    vecMdlSd = vecMdlSd.astype(np.float32)\n\n    # The first column is to contain model x positions:\n    aryMdl[:, 0] = np.repeat(vecMdlXpos, int(varNumY * varNumPrfSizes))\n\n    # The second column is to contain model y positions:\n    aryMdl[:, 1] = np.repeat(\n                             np.tile(vecMdlYpos,\n                                     varNumX),\n                             varNumPrfSizes\n                             )\n\n    # The third column is to contain model pRF sizes:\n    aryMdl[:, 2] = np.tile(vecMdlSd, int(varNumX * varNumY))\n\n    # Earlier, we had removed models with a variance of zero. Thus, those\n    # models were ignored and are not present in the results. We remove them\n    # from the model-parameter-array:\n    aryMdl = aryMdl[vecLgcVar]\n\n    # Retrieve model parameters of 'winning' model for all voxels:\n    vecBstXpos = aryMdl[:, 0][vecResSsMinIdx]\n    vecBstYpos = aryMdl[:, 1][vecResSsMinIdx]\n    vecBstSd = aryMdl[:, 2][vecResSsMinIdx]\n\n    # Coefficient of determination (1 - ratio of (residual sum of squares by\n    # total sum of squares)):\n    vecBstR2 = np.subtract(1.0,\n                           np.divide(vecResSsMin,\n                                     vecSsTot)\n                           )\n\n    # Output list:\n    lstOut = [idxPrc,\n              vecBstXpos,\n              vecBstYpos,\n              vecBstSd,\n              vecBstR2,\n              np.zeros((varNumVox, (varNumBeta))).astype(np.float32)]\n\n    queOut.put(lstOut)", "response": "This function returns a list of objects containing the best pRF model for the given voxel time course."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap multiple paragraphs of text returning a list of wrapped lines.", "response": "def wrap(text, width=70, **kwargs):\n    \"\"\"Wrap multiple paragraphs of text, returning a list of wrapped lines.\n\n    Reformat the multiple paragraphs  'text' so they fit in lines of no\n    more than 'width' columns, and return a list of wrapped lines.  By\n    default, tabs in 'text' are expanded with string.expandtabs(), and\n    all other whitespace characters (including newline) are converted to\n    space.  See ParagraphWrapper class for available keyword args to customize\n    wrapping behaviour.\n    \"\"\"\n    w = ParagraphWrapper(width=width, **kwargs)\n    return w.wrap(text)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fill(text, width=70, **kwargs):\n    w = ParagraphWrapper(width=width, **kwargs)\n    return w.fill(text)", "response": "Fill multiple paragraphs of text returning a new string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split(cls, text):\n        result = [line.strip('\\n') for line in cls.parasep_re.split(text)]\n        if result == ['', '']:\n            result = ['']\n        return result", "response": "Splits text into multiple paragraphs and returns a list of each\n        paragraph."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps multiple paragraphs in text and return a list of wrapped lines.", "response": "def wrap(self, text):\n        \"\"\"wrap(text : string) -> [string]\n\n        Reformat the multiple paragraphs in 'text' so they fit in lines of\n        no more than 'self.width' columns, and return a list of wrapped\n        lines.  Tabs in 'text' are expanded with string.expandtabs(),\n        and all other whitespace characters (including newline) are\n        converted to space.\n        \"\"\"\n        lines = []\n\n        linewrap = partial(textwrap.TextWrapper.wrap, self)\n        for para in self.split(text):\n            lines.extend(linewrap(para))\n            lines.append('')    # Add newline between paragraphs\n\n        # Remove trailing newline\n        lines = lines[:-1]\n\n        return lines"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the URL of the sender number MGT.", "response": "def getSenderNumberMgtURL(self, CorpNum, UserID):\n        \"\"\" \ud329\uc2a4 \uc804\uc1a1\ub0b4\uc5ed \ud31d\uc5c5 URL\n            args\n                CorpNum : \ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                UserID  : \ud68c\uc6d0 \ud31d\ube4c\uc544\uc774\ub514\n            return\n                30\ucd08 \ubcf4\uc548 \ud1a0\ud070\uc744 \ud3ec\ud568\ud55c url\n            raise\n                PopbillException\n        \"\"\"\n        result = self._httpget('/FAX/?TG=SENDER', CorpNum, UserID)\n        return result.url"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getUnitCost(self, CorpNum):\n\n        result = self._httpget('/FAX/UnitCost', CorpNum)\n        return int(result.unitCost)", "response": "Get UnitCost of a user."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getFaxResultRN(self, CorpNum, RequestNum, UserID=None):\n\n        if RequestNum == None or RequestNum == '':\n            raise PopbillException(-99999999, \"\uc694\uccad\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        return self._httpget('/FAX/Get/' + RequestNum, CorpNum, UserID)", "response": "Get the list of Fax Result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sendFax(self, CorpNum, SenderNum, ReceiverNum, ReceiverName, FilePath, ReserveDT=None, UserID=None,\n                SenderName=None, adsYN=False, title=None, RequestNum=None):\n        \"\"\" \ud329\uc2a4 \ub2e8\uac74 \uc804\uc1a1\n            args\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                SenderNum : \ubc1c\uc2e0\uc790 \ubc88\ud638\n                ReceiverNum : \uc218\uc2e0\uc790 \ubc88\ud638\n                ReceiverName : \uc218\uc2e0\uc790 \uba85\n                FilePath : \ubc1c\uc2e0 \ud30c\uc77c\uacbd\ub85c\n                ReserveDT : \uc608\uc57d\uc2dc\uac04(\ud615\uc2dd yyyyMMddHHmmss)\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\n                SenderName : \ubc1c\uc2e0\uc790\uba85 (\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\n                adsYN : \uad11\uace0\ud329\uc2a4 \uc5ec\ubd80\n                title : \ud329\uc2a4\uc81c\ubaa9\n                RequestNum : \uc804\uc1a1\uc694\uccad\uc2dc \ud560\ub2f9\ud55c \uc804\uc1a1\uc694\uccad\ubc88\ud638\n            return\n                \uc811\uc218\ubc88\ud638 (receiptNum)\n            raise\n                PopbillException\n        \"\"\"\n        receivers = []\n        receivers.append(FaxReceiver(receiveNum=ReceiverNum,\n                                     receiveName=ReceiverName)\n                         )\n\n        return self.sendFax_multi(CorpNum, SenderNum, receivers, FilePath, ReserveDT, UserID, SenderName, adsYN, title,\n                                  RequestNum)", "response": "\ud329\uc2a4 \ub2e8\uac74 \uc804\uc1a1\n            args\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                SenderNum : \ubc1c\uc2e0\uc790 \ubc88\ud638\n                ReceiverNum : \uc218\uc2e0\uc790 \ubc88\ud638\n                ReceiverName : \uc218\uc2e0\uc790 \uba85\n                FilePath : \ubc1c\uc2e0 \ud30c\uc77c\uacbd\ub85c\n                ReserveDT : \uc608\uc57d\uc2dc\uac04(\ud615\uc2dd yyyyMMddHHmmss)\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\n                SenderName : \ubc1c\uc2e0\uc790\uba85 (\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\n                adsYN : \uad11\uace0\ud329\uc2a4 \uc5ec\ubd80\n                title : \ud329\uc2a4\uc81c\ubaa9\n                RequestNum : \uc804\uc1a1\uc694\uccad\uc2dc \ud560\ub2f9\ud55c \uc804\uc1a1\uc694\uccad\ubc88\ud638\n            return\n                \uc811\uc218\ubc88\ud638 (receiptNum)\n            raise\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending anFax message to the AFIP.", "response": "def sendFax_multi(self, CorpNum, SenderNum, Receiver, FilePath, ReserveDT=None, UserID=None, SenderName=None,\n                      adsYN=False, title=None, RequestNum=None):\n        \"\"\" \ud329\uc2a4 \uc804\uc1a1\n            args\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                SenderNum : \ubc1c\uc2e0\uc790 \ubc88\ud638 (\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\n                Receiver : \uc218\uc2e0\uc790 \ubc88\ud638(\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\n                FilePath : \ubc1c\uc2e0 \ud30c\uc77c\uacbd\ub85c\n                ReserveDT : \uc608\uc57d\uc2dc\uac04(\ud615\uc2dd yyyyMMddHHmmss)\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\n                SenderName : \ubc1c\uc2e0\uc790\uba85 (\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\n                adsYN : \uad11\uace0\ud329\uc2a4 \uc5ec\ubd80\n                title : \ud329\uc2a4\uc81c\ubaa9\n                RequestNum : \uc804\uc1a1\uc694\uccad\uc2dc \ud560\ub2f9\ud55c \uc804\uc1a1\uc694\uccad\ubc88\ud638\n            return\n                \uc811\uc218\ubc88\ud638 (receiptNum)\n            raise\n                PopbillException\n        \"\"\"\n\n        if SenderNum == None or SenderNum == \"\":\n            raise PopbillException(-99999999, \"\ubc1c\uc2e0\uc790 \ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n        if Receiver == None:\n            raise PopbillException(-99999999, \"\uc218\uc2e0\uc790 \uc815\ubcf4\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n        if not (type(Receiver) is str or type(Receiver) is FaxReceiver or type(Receiver) is list):\n            raise PopbillException(-99999999, \"'Receiver' argument type error. 'FaxReceiver' or List of 'FaxReceiver'.\")\n        if FilePath == None:\n            raise PopbillException(-99999999, \"\ubc1c\uc2e0 \ud30c\uc77c\uacbd\ub85c\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n        if not (type(FilePath) is str or type(FilePath) is list):\n            raise PopbillException(-99999999, \"\ubc1c\uc2e0 \ud30c\uc77c\uc740 \ud30c\uc77c\uacbd\ub85c \ub610\ub294 \uacbd\ub85c\ubaa9\ub85d\ub9cc \uc785\ub825 \uac00\ub2a5\ud569\ub2c8\ub2e4.\")\n        if type(FilePath) is list and (len(FilePath) < 1 or len(FilePath) > 20):\n            raise PopbillException(-99999999, \"\ud30c\uc77c\uc740 1\uac1c \uc774\uc0c1, 20\uac1c \uae4c\uc9c0 \uc804\uc1a1 \uac00\ub2a5\ud569\ub2c8\ub2e4.\")\n\n        req = {\"snd\": SenderNum, \"sndnm\": SenderName, \"fCnt\": 1 if type(FilePath) is str else len(FilePath), \"rcvs\": [],\n               \"sndDT\": None}\n\n        if (type(Receiver) is str):\n            Receiver = FaxReceiver(receiveNum=Receiver)\n\n        if (type(Receiver) is FaxReceiver):\n            Receiver = [Receiver]\n\n        if adsYN:\n            req['adsYN'] = True\n\n        for r in Receiver:\n            req['rcvs'].append({\"rcv\": r.receiveNum, \"rcvnm\": r.receiveName})\n\n        if ReserveDT != None:\n            req['sndDT'] = ReserveDT\n\n        if title != None:\n            req['title'] = title\n\n        if RequestNum != None:\n            req['requestNum'] = RequestNum\n\n        postData = self._stringtify(req)\n\n        if (type(FilePath) is str):\n            FilePath = [FilePath]\n\n        files = []\n\n        for filePath in FilePath:\n            with open(filePath, \"rb\") as f:\n                files.append(File(fieldName='file',\n                                  fileName=f.name,\n                                  fileData=f.read())\n                             )\n        result = self._httppost_files('/FAX', postData, files, CorpNum, UserID)\n\n        return result.receiptNum"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resendFaxRN(self, CorpNum, OrgRequestNum, SenderNum, SenderName, ReceiverNum, ReceiverName, ReserveDT=None,\n                    UserID=None, title=None, RequestNum=None):\n        \"\"\" \ud329\uc2a4 \ub2e8\uac74 \uc804\uc1a1\n            args\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                OrgRequestNum : \uc6d0\ubcf8 \ud329\uc2a4 \uc804\uc1a1\uc2dc \ud560\ub2f9\ud55c \uc804\uc1a1\uc694\uccad\ubc88\ud638\n                ReceiptNum : \ud329\uc2a4 \uc811\uc218\ubc88\ud638\n                SenderNum : \ubc1c\uc2e0\uc790 \ubc88\ud638\n                SenderName : \ubc1c\uc2e0\uc790\uba85\n                ReceiverNum : \uc218\uc2e0\ubc88\ud638\n                ReceiverName : \uc218\uc2e0\uc790\uba85\n                ReserveDT : \uc608\uc57d\uc2dc\uac04(\ud615\uc2dd yyyyMMddHHmmss)\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\n                title : \ud329\uc2a4\uc81c\ubaa9\n                RequestNum : \uc804\uc1a1\uc694\uccad\uc2dc \ud560\ub2f9\ud55c \uc804\uc1a1\uc694\uccad\ubc88\ud638\n            return\n                \uc811\uc218\ubc88\ud638 (receiptNum)\n            raise\n                PopbillException\n        \"\"\"\n        receivers = None\n\n        if ReceiverNum != \"\" or ReceiverName != \"\":\n            receivers = []\n            receivers.append(FaxReceiver(receiveNum=ReceiverNum,\n                                         receiveName=ReceiverName)\n                             )\n        return self.resendFaxRN_multi(CorpNum, OrgRequestNum, SenderNum, SenderName, receivers, ReserveDT,\n                                      UserID, title, RequestNum)", "response": "Resend anFaxRN to a specific sender."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets URL of a preview of a given receipt.", "response": "def getPreviewURL(self, CorpNum, ReceiptNum, UserID):\n        \"\"\" \ud329\uc2a4 \ubc1c\uc2e0\ubc88\ud638 \ubaa9\ub85d \ud655\uc778\n            args\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\n            return\n                \ucc98\ub9ac\uacb0\uacfc. list of SenderNumber\n            raise\n                PopbillException\n        \"\"\"\n        return self._httpget('/FAX/Preview/' + ReceiptNum, CorpNum, UserID).url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepare_outdir(outdir):\n    if outdir:\n        outdir = os.path.expanduser(outdir)\n        if not os.path.isdir(outdir):\n            try:\n                os.makedirs(outdir)\n            except os.error as e:\n                raise JobExecutionError('Failed to create outdir \"{}\".\\n{}'.format(outdir, str(e)))", "response": "Creates the output directory if not existing."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef requestJob(self, CorpNum, Type, SDate, EDate, UserID=None):\n\n        if Type == None or Type == '':\n            raise PopbillException(-99999999, \"\ubb38\uc11c\ud615\ud0dc\uc774 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        if SDate == None or SDate == '':\n            raise PopbillException(-99999999, \"\uc2dc\uc791\uc77c\uc790\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        if EDate == None or EDate == '':\n            raise PopbillException(-99999999, \"\uc885\ub8cc\uc77c\uc790\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        uri = '/HomeTax/Cashbill/' + Type\n        uri += '?SDate=' + SDate\n        uri += '&EDate=' + EDate\n\n        return self._httppost(uri, \"\", CorpNum, UserID).jobID", "response": "Request a job from the Cashbill."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef summary(self, CorpNum, JobID, TradeType, TradeUsage, UserID=None):\n        if JobID == None or len(JobID) != 18:\n            raise PopbillException(-99999999, \"\uc791\uc5c5\uc544\uc774\ub514(jobID)\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n\n        uri = '/HomeTax/Cashbill/' + JobID + '/Summary'\n        uri += '?TradeType=' + ','.join(TradeType)\n        uri += '&TradeUsage=' + ','.join(TradeUsage)\n\n        return self._httpget(uri, CorpNum, UserID)", "response": "\uc218\uc9d1 \uacb0\uacfc \uc694\uc57d\uc815\ubcf4 \uc870\ud68c\n            args\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                JobID : \uc791\uc5c5\uc544\uc774\ub514\n                TradeType : \ubb38\uc11c\ud615\ud0dc \ubc30\uc5f4, N-\uc77c\ubc18 \ud604\uae08\uc601\uc218\uc99d, C-\ucde8\uc18c \ud604\uae08\uc601\uc218\uc99d\n                TradeUsage : \uac70\ub798\uad6c\ubd84 \ubc30\uc5f4, P-\uc18c\ub4f1\uacf5\uc81c\uc6a9, C-\uc9c0\ucd9c\uc99d\ube59\uc6a9\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\n            return\n                \uc218\uc9d1 \uacb0\uacfc \uc694\uc57d\uc815\ubcf4\n            raise\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef model_node(**kwargs):\n    kwargs.setdefault('default', {})\n\n    def decorator(model):\n        return types.ModelType(model, **kwargs)\n\n    return decorator", "response": "A simple decorator for creating a schematics. Model class to add it as a field\n    of type schematics. types. ModelType."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef for_each_file(base_dir, func):\n\n    for dir_path, _, file_names in os.walk(base_dir):\n        for filename in file_names:\n            func(os.path.join(dir_path, filename))", "response": "Calls func for every file under base_dir."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_file_read_only(file_path):\n    old_permissions = os.stat(file_path).st_mode\n    os.chmod(file_path, old_permissions & ~WRITE_PERMISSIONS)", "response": "Removes the write permissions for the given file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_config(strCsvCnfg, lgcTest=False, lgcPrint=True):\n\n    # Dictionary with config information:\n    dicCnfg = {}\n\n    # Open file with parameter configuration:\n    # fleConfig = open(strCsvCnfg, 'r')\n    with open(strCsvCnfg, 'r') as fleConfig:\n\n        # Read file  with ROI information:\n        csvIn = csv.reader(fleConfig,\n                           delimiter='\\n',\n                           skipinitialspace=True)\n\n        # Loop through csv object to fill list with csv data:\n        for lstTmp in csvIn:\n\n            # Skip comments (i.e. lines starting with '#') and empty lines.\n            # Note: Indexing the list (i.e. lstTmp[0][0]) does not work for\n            # empty lines. However, if the first condition is no fullfilled\n            # (i.e. line is empty and 'if lstTmp' evaluates to false), the\n            # second logical test (after the 'and') is not actually carried\n            # out.\n            if lstTmp and not (lstTmp[0][0] == '#'):\n\n                # Name of current parameter (e.g. 'varTr'):\n                strParamKey = lstTmp[0].split(' = ')[0]\n                # print(strParamKey)\n\n                # Current parameter value (e.g. '2.94'):\n                strParamVlu = lstTmp[0].split(' = ')[1]\n                # print(strParamVlu)\n\n                # Put paramter name (key) and value (item) into dictionary:\n                dicCnfg[strParamKey] = strParamVlu\n\n    # Are model parameters in cartesian or polar coordinates?\n    # set either pol (polar) or crt (cartesian)\n    dicCnfg['strKwCrd'] = ast.literal_eval(dicCnfg['strKwCrd'])\n    if lgcPrint:\n        print('---Model coordinates are in: ' + str(dicCnfg['strKwCrd']))\n\n    # Number of x- or radial positions to model:\n    dicCnfg['varNum1'] = int(dicCnfg['varNum1'])\n    # Number of y- or angular positions to model:\n    dicCnfg['varNum2'] = int(dicCnfg['varNum2'])\n\n    if lgcPrint:\n        if dicCnfg['strKwCrd'] == 'crt':\n            print('---Number of x-positions to model: ' +\n                  str(dicCnfg['varNum1']))\n            print('---Number of y-positions to model: ' +\n                  str(dicCnfg['varNum2']))\n\n        elif dicCnfg['strKwCrd'] == 'pol':\n            print('---Number of radial positions to model: ' +\n                  str(dicCnfg['varNum1']))\n            print('---Number of angular positions to model: ' +\n                  str(dicCnfg['varNum2']))\n\n    # Number of pRF sizes to model:\n    dicCnfg['varNumPrfSizes'] = int(dicCnfg['varNumPrfSizes'])\n    if lgcPrint:\n        print('---Number of pRF sizes to model: '\n              + str(dicCnfg['varNumPrfSizes']))\n\n    # Extent of visual space from centre of the screen in negative x-direction\n    # (i.e. from the fixation point to the left end of the screen) in degrees\n    # of visual angle.\n    dicCnfg['varExtXmin'] = float(dicCnfg['varExtXmin'])\n    if lgcPrint:\n        print('---Extent of visual space in negative x-direction: '\n              + str(dicCnfg['varExtXmin']))\n\n    # Extent of visual space from centre of the screen in positive x-direction\n    # (i.e. from the fixation point to the right end of the screen) in degrees\n    # of visual angle.\n    dicCnfg['varExtXmax'] = float(dicCnfg['varExtXmax'])\n    if lgcPrint:\n        print('---Extent of visual space in positive x-direction: '\n              + str(dicCnfg['varExtXmax']))\n\n    # Extent of visual space from centre of the screen in negative y-direction\n    # (i.e. from the fixation point to the lower end of the screen) in degrees\n    # of visual angle.\n    dicCnfg['varExtYmin'] = float(dicCnfg['varExtYmin'])\n    if lgcPrint:\n        print('---Extent of visual space in negative y-direction: '\n              + str(dicCnfg['varExtYmin']))\n\n    # Extent of visual space from centre of the screen in positive y-direction\n    # (i.e. from the fixation point to the upper end of the screen) in degrees\n    # of visual angle.\n    dicCnfg['varExtYmax'] = float(dicCnfg['varExtYmax'])\n    if lgcPrint:\n        print('---Extent of visual space in positive y-direction: '\n              + str(dicCnfg['varExtYmax']))\n\n    # Minimum pRF model size (standard deviation of 2D Gaussian) [degrees of\n    # visual angle]:\n    dicCnfg['varPrfStdMin'] = float(dicCnfg['varPrfStdMin'])\n    if lgcPrint:\n        print('---Minimum pRF model size: ' + str(dicCnfg['varPrfStdMin']))\n\n    # Maximum pRF model size (standard deviation of 2D Gaussian) [degrees of\n    # visual angle]:\n    dicCnfg['varPrfStdMax'] = float(dicCnfg['varPrfStdMax'])\n    if lgcPrint:\n        print('---Maximum pRF model size: ' + str(dicCnfg['varPrfStdMax']))\n\n    # Volume TR of input data [s]:\n    dicCnfg['varTr'] = float(dicCnfg['varTr'])\n    if lgcPrint:\n        print('---Volume TR of input data [s]: ' + str(dicCnfg['varTr']))\n\n    # Voxel resolution of fMRI data [mm]:\n    dicCnfg['varVoxRes'] = float(dicCnfg['varVoxRes'])\n    if lgcPrint:\n        print('---Voxel resolution of fMRI data [mm]: '\n              + str(dicCnfg['varVoxRes']))\n\n    # Number of fMRI volumes and png files to load:\n    dicCnfg['varNumVol'] = int(dicCnfg['varNumVol'])\n    if lgcPrint:\n        print('---Total number of fMRI volumes and png files: '\n              + str(dicCnfg['varNumVol']))\n\n    # Extent of temporal smoothing for fMRI data and pRF time course models\n    # [standard deviation of the Gaussian kernel, in seconds]:\n    # same temporal smoothing will be applied to pRF model time courses\n    dicCnfg['varSdSmthTmp'] = float(dicCnfg['varSdSmthTmp'])\n    if lgcPrint:\n        print('---Extent of temporal smoothing (Gaussian SD in [s]): '\n              + str(dicCnfg['varSdSmthTmp']))\n\n    # Number of processes to run in parallel:\n    dicCnfg['varPar'] = int(dicCnfg['varPar'])\n    if lgcPrint:\n        print('---Number of processes to run in parallel: '\n              + str(dicCnfg['varPar']))\n\n    # Size of space model in which the pRF models are\n    # created (x- and y-dimension).\n    dicCnfg['tplVslSpcSze'] = tuple([int(dicCnfg['varVslSpcSzeX']),\n                                     int(dicCnfg['varVslSpcSzeY'])])\n    if lgcPrint:\n        print('---Size of visual space model (x & y): '\n              + str(dicCnfg['tplVslSpcSze']))\n\n    # Path(s) of functional data:\n    dicCnfg['lstPathNiiFunc'] = ast.literal_eval(dicCnfg['lstPathNiiFunc'])\n    if lgcPrint:\n        print('---Path(s) of functional data:')\n        for strTmp in dicCnfg['lstPathNiiFunc']:\n            print('   ' + str(strTmp))\n\n    # Path of mask (to restrict pRF model finding):\n    dicCnfg['strPathNiiMask'] = ast.literal_eval(dicCnfg['strPathNiiMask'])\n    if lgcPrint:\n        print('---Path of mask (to restrict pRF model finding):')\n        print('   ' + str(dicCnfg['strPathNiiMask']))\n\n    # Output basename:\n    dicCnfg['strPathOut'] = ast.literal_eval(dicCnfg['strPathOut'])\n    if lgcPrint:\n        print('---Output basename:')\n        print('   ' + str(dicCnfg['strPathOut']))\n\n    # Which version to use for pRF finding. 'numpy' or 'cython' for pRF finding\n    # on CPU, 'gpu' for using GPU.\n    dicCnfg['strVersion'] = ast.literal_eval(dicCnfg['strVersion'])\n    if lgcPrint:\n        print('---Version (numpy, cython, or gpu): '\n              + str(dicCnfg['strVersion']))\n\n    # Create pRF time course models?\n    dicCnfg['lgcCrteMdl'] = (dicCnfg['lgcCrteMdl'] == 'True')\n    if lgcPrint:\n        print('---Create pRF time course models: '\n              + str(dicCnfg['lgcCrteMdl']))\n\n    # Path to npy file with pRF time course models (to save or laod). Without\n    # file extension.\n    dicCnfg['strPathMdl'] = ast.literal_eval(dicCnfg['strPathMdl'])\n    if lgcPrint:\n        print('---Path to npy file with pRF time course models (to save '\n              + 'or load):')\n        print('   ' + str(dicCnfg['strPathMdl']))\n\n    # switch to determine which hrf functions should be used\n    # 1: canonical, 2: can and temp derivative, 3: can, temp and spat deriv\n    dicCnfg['switchHrfSet'] = ast.literal_eval(dicCnfg['switchHrfSet'])\n    if lgcPrint:\n        print('---Switch to determine which hrf functions should be used: '\n              + str(dicCnfg['switchHrfSet']))\n\n    # should model fitting be based on k-fold cross-validation?\n    # if not, set to 1\n    dicCnfg['varNumXval'] = ast.literal_eval(dicCnfg['varNumXval'])\n    if lgcPrint:\n        print('---Model fitting will have this number of folds for xval: '\n              + str(dicCnfg['varNumXval']))\n\n    # If we create new pRF time course models, the following parameters have to\n    # be provided:\n    if dicCnfg['lgcCrteMdl']:\n\n        # Name of the npy that holds spatial info about conditions\n        dicCnfg['strSptExpInf'] = ast.literal_eval(dicCnfg['strSptExpInf'])\n        if lgcPrint:\n            print('---Path to npy file with spatial condition info: ')\n            print('   ' + str(dicCnfg['strSptExpInf']))\n\n        # Name of the npy that holds temporal info about conditions\n        dicCnfg['strTmpExpInf'] = ast.literal_eval(dicCnfg['strTmpExpInf'])\n        if lgcPrint:\n            print('---Path to npy file with temporal condition info: ')\n            print('   ' + str(dicCnfg['strTmpExpInf']))\n\n        # Factor by which time courses and HRF will be upsampled for the\n        # convolutions\n        dicCnfg['varTmpOvsmpl'] = ast.literal_eval(dicCnfg['varTmpOvsmpl'])\n        if lgcPrint:\n            print('---Factor by which time courses and HRF will be upsampled: '\n                  + str(dicCnfg['varTmpOvsmpl']))\n\n    # Is this a test?\n    if lgcTest:\n\n        # Prepend absolute path of this file to config file paths:\n        dicCnfg['strPathNiiMask'] = (strDir + dicCnfg['strPathNiiMask'])\n        dicCnfg['strPathOut'] = (strDir + dicCnfg['strPathOut'])\n        dicCnfg['strPathMdl'] = (strDir + dicCnfg['strPathMdl'])\n        dicCnfg['strSptExpInf'] = (strDir + dicCnfg['strSptExpInf'])\n        dicCnfg['strTmpExpInf'] = (strDir + dicCnfg['strTmpExpInf'])\n\n        # Loop through functional runs:\n        varNumRun = len(dicCnfg['lstPathNiiFunc'])\n        for idxRun in range(varNumRun):\n            dicCnfg['lstPathNiiFunc'][idxRun] = (\n                strDir\n                + dicCnfg['lstPathNiiFunc'][idxRun]\n                )\n\n    return dicCnfg", "response": "Load the config file and return a dictionary with the ROI information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def status_by_coordinates(\n            self, latitude: float, longitude: float) -> dict:\n        \"\"\"Get symptom data for the location nearest to the user's lat/lon.\"\"\"\n        return await self.nearest_by_coordinates(latitude, longitude)", "response": "Get the status of the user from the given latitude and longitude."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets symptom data for the provided ZIP code.", "response": "async def status_by_zip(self, zip_code: str) -> dict:\n        \"\"\"Get symptom data for the provided ZIP code.\"\"\"\n        try:\n            location = next((\n                d for d in await self.user_reports()\n                if d['zip'] == zip_code))\n        except StopIteration:\n            return {}\n\n        return await self.status_by_coordinates(\n            float(location['latitude']), float(location['longitude']))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_request(request):\n    print('{}\\n{}\\n{}\\n\\n{}'.format(\n        '-----------START-----------',\n        request.method + ' ' + request.url,\n        '\\n'.join('{}: {}'.format(k, v) for k, v in request.headers.items()),\n        request.body,\n    ))", "response": "Prints a request to give the user info as to what they re sending\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_EPUB(parsed_article,\n              output_directory,\n              input_path,\n              image_directory,\n              config_module=None,\n              epub_version=None,\n              batch=False):\n    \"\"\"\n    Standard workflow for creating an EPUB document.\n\n    make_EPUB is used to produce an EPUB file from a parsed article. In addition\n    to the article it also requires a path to the appropriate image directory\n    which it will insert into the EPUB file, as well the output directory\n    location for the EPUB file.\n\n    Parameters\n    ----------\n    article : openaccess_epub.article.Article instance\n        `article` is an Article instance for the XML document to be converted to\n        EPUB.\n    output_directory : str\n        `output_directory` is a string path to the directory in which the EPUB\n        will be produced. The name of the directory will be used as the EPUB's\n        filename.\n    input_path : str\n        `input_path` is a string absolute path to the input XML file, used to\n        locate input-relative images.\n    image_directory : str\n        `image_directory` is a string path indicating an explicit image\n        directory. If supplied, other image input methods will not be used.\n    config_module : config module, optional\n        `config_module` is a pre-loaded config module for OpenAccess_EPUB; if\n        not used then this function will load the global config file. Might be\n        useful in certain cases to dynamically alter configuration.\n    epub_version : {None, 2, 3}\n        `epub_version` dictates which version of EPUB to be created. An error\n        will be raised if the specified version is not supported for the\n        publisher. If left to the default, the created version will defer to the\n        publisher default version.\n    batch : bool, optional\n        `batch` indicates that batch creation is being used (such as with the\n        `oaepub batch` command). In this case, directory conflicts will be\n        automatically resolved (in favor of keeping previous data, skipping\n        creation of EPUB).\n\n    Returns False in the case of a fatal error, True if successful.\n    \"\"\"\n    #command_log.info('Creating {0}.epub'.format(output_directory))\n    if config_module is None:\n        config_module = openaccess_epub.utils.load_config_module()\n\n    if epub_version not in (None, 2, 3):\n        log.error('Invalid EPUB version: {0}'.format(epub_version))\n        raise ValueError('Invalid EPUB version. Should be 2 or 3')\n\n    if epub_version is None:\n        epub_version = parsed_article.publisher.epub_default\n\n    #Handle directory output conflicts\n    if os.path.isdir(output_directory):\n        if batch:  # No user prompt, default to protect previous data\n            log.error('Directory conflict during batch conversion, skipping.')\n            return False\n        else:  # User prompting\n            openaccess_epub.utils.dir_exists(output_directory)\n    else:\n        try:\n            os.makedirs(output_directory)\n        except OSError as err:\n            if err.errno != 17:\n                log.exception('Unable to recursively create output directories')\n\n    #Copy over the basic epub directory\n    make_epub_base(output_directory)\n\n    #Get the images, if possible, fail gracefully if not\n    success = openaccess_epub.utils.images.get_images(output_directory,\n                                                      image_directory,\n                                                      input_path,\n                                                      config_module,\n                                                      parsed_article)\n    if not success:\n        log.critical('Images for the article were not located! Aborting!')\n        return False\n\n    #Instantiate Navigation and Package\n    epub_nav = Navigation()\n    epub_package = Package()\n\n    #Process the article for navigation and package info\n    epub_nav.process(parsed_article)\n    epub_package.process(parsed_article)\n\n    #Render the content using publisher-specific methods\n    parsed_article.publisher.render_content(output_directory, epub_version)\n    if epub_version == 2:\n        epub_nav.render_EPUB2(output_directory)\n        epub_package.render_EPUB2(output_directory)\n    elif epub_version == 3:\n        epub_nav.render_EPUB3(output_directory)\n        epub_package.render_EPUB3(output_directory)\n\n    #Zip the directory into EPUB\n    epub_zip(output_directory)\n\n    return True", "response": "This function creates an EPUB file from an OpenAccess_EPUB article."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate the base structure for an EPUB file in a specified location.", "response": "def make_epub_base(location):\n    \"\"\"\n    Creates the base structure for an EPUB file in a specified location.\n\n    This function creates constant components for the structure of the EPUB in\n    a specified directory location.\n\n    Parameters\n    ----------\n    location : str\n        A path string to a local directory in which the EPUB is to be built\n    \"\"\"\n    log.info('Making EPUB base files in {0}'.format(location))\n    with open(os.path.join(location, 'mimetype'), 'w') as out:  # mimetype file\n        out.write('application/epub+zip')\n\n    #Create EPUB and META-INF directorys\n    os.mkdir(os.path.join(location, 'META-INF'))\n    os.mkdir(os.path.join(location, 'EPUB'))\n    os.mkdir(os.path.join(location, 'EPUB', 'css'))\n\n    with open(os.path.join(location, 'META-INF', 'container.xml'), 'w') as out:\n        out.write('''\\\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<container version=\"1.0\" xmlns=\"urn:oasis:names:tc:opendocument:xmlns:container\">\n   <rootfiles>\n      <rootfile full-path=\"EPUB/package.opf\" media-type=\"application/oebps-package+xml\"/>\n   </rootfiles>\n</container>''')\n\n    with open(os.path.join(location, 'EPUB', 'css', 'default.css') ,'wb') as out:\n        out.write(bytes(DEFAULT_CSS, 'UTF-8'))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef epub_zip(outdirect):\n\n    def recursive_zip(zipf, directory, folder=None):\n        if folder is None:\n            folder = ''\n        for item in os.listdir(directory):\n            if os.path.isfile(os.path.join(directory, item)):\n                zipf.write(os.path.join(directory, item),\n                           os.path.join(directory, item))\n            elif os.path.isdir(os.path.join(directory, item)):\n                recursive_zip(zipf, os.path.join(directory, item),\n                              os.path.join(folder, item))\n\n    log.info('Zipping up the directory {0}'.format(outdirect))\n    epub_filename = outdirect + '.epub'\n    epub = zipfile.ZipFile(epub_filename, 'w')\n    current_dir = os.getcwd()\n    os.chdir(outdirect)\n    epub.write('mimetype')\n    log.info('Recursively zipping META-INF and EPUB')\n    for item in os.listdir('.'):\n        if item == 'mimetype':\n            continue\n        recursive_zip(epub, item)\n    os.chdir(current_dir)\n    epub.close()", "response": "Zips the input file directory into an EPUB file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite data to CSV file with validation.", "response": "def _write_int(fname, data, append=True):\n    \"\"\"Write data to CSV file with validation.\"\"\"\n    # pylint: disable=W0705\n    data_ex = pexdoc.exh.addex(ValueError, \"There is no data to save to file\")\n    fos_ex = pexdoc.exh.addex(\n        OSError, \"File *[fname]* could not be created: *[reason]*\"\n    )\n    data_ex((len(data) == 0) or ((len(data) == 1) and (len(data[0]) == 0)))\n    try:\n        pmisc.make_dir(fname)\n        mode = \"w\" if append is False else \"a\"\n        if sys.hexversion < 0x03000000:  # pragma: no cover, no branch\n            with open(fname, mode) as file_handle:\n                csv.writer(file_handle, delimiter=\",\").writerows(data)\n        else:  # pragma: no cover\n            with open(fname, mode, newline=\"\") as file_handle:\n                csv.writer(file_handle, delimiter=\",\").writerows(data)\n    except (IOError, OSError) as eobj:\n        fos_ex(True, _MF(\"fname\", fname, \"reason\", eobj.strerror))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a directory description from a given input directory.", "response": "def _input_directory_description(input_identifier, arg_item, input_dir):\n    \"\"\"\n     Produces a directory description. A directory description is a dictionary containing the following information.\n\n     - 'path': An array containing the paths to the specified directories.\n     - 'debugInfo': A field to possibly provide debug information.\n     - 'found': A boolean that indicates, if the directory exists in the local filesystem.\n     - 'listing': A listing that shows which files are in the given directory. This could be None.\n\n    :param input_identifier: The input identifier in the cwl description file\n    :param arg_item: The corresponding job information\n    :param input_dir: TODO\n    :return: A directory description\n    :raise DirectoryError: If the given directory does not exist or is not a directory.\n    \"\"\"\n    description = {\n        'path': None,\n        'found': False,\n        'debugInfo': None,\n        'listing': None,\n        'basename': None\n    }\n\n    try:\n        path = location(input_identifier, arg_item)\n\n        if input_dir and not os.path.isabs(path):\n            path = os.path.join(os.path.expanduser(input_dir), path)\n\n        description['path'] = path\n        if not os.path.exists(path):\n            raise DirectoryError('path does not exist')\n        if not os.path.isdir(path):\n            raise DirectoryError('path is not a directory')\n\n        description['listing'] = arg_item.get('listing')\n        description['basename'] = os.path.basename(path)\n\n        description['found'] = True\n    except:\n        description['debugInfo'] = exception_format()\n\n    return description"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck that the given directory listing is well - formed and if not raises an exception.", "response": "def _check_input_directory_listing(base_directory, listing):\n    \"\"\"\n    Raises an DirectoryError if files or directories, given in the listing, could not be found in the local filesystem.\n\n    :param base_directory: The path to the directory to check\n    :param listing: A listing given as dictionary\n    :raise DirectoryError: If the given base directory does not contain all of the subdirectories and subfiles given in\n    the listing.\n    \"\"\"\n\n    for sub in listing:\n        path = os.path.join(base_directory, sub['basename'])\n        if sub['class'] == 'File':\n            if not os.path.isfile(path):\n                raise DirectoryError('File \\'{}\\' not found but specified in listing.'.format(path))\n        if sub['class'] == 'Directory':\n            if not os.path.isdir(path):\n                raise DirectoryError('Directory \\'{}\\' not found but specified in listing'.format(path))\n            sub_listing = sub.get('listing')\n            if sub_listing:\n                _check_input_directory_listing(path, sub_listing)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses cwl type string into a dictionary containing information about the cwl type string.", "response": "def parse_cwl_type(cwl_type_string):\n    \"\"\"\n    Parses cwl type information from a cwl type string.\n\n    Examples:\n\n    - \"File[]\" -> {'type': 'File', 'isArray': True, 'isOptional': False}\n    - \"int?\" -> {'type': 'int', 'isArray': False, 'isOptional': True}\n\n    :param cwl_type_string: The cwl type string to extract information from\n    :return: A dictionary containing information about the parsed cwl type string\n    \"\"\"\n\n    is_optional = cwl_type_string.endswith('?')\n    if is_optional:\n        cwl_type_string = cwl_type_string[:-1]\n\n    is_array = cwl_type_string.endswith('[]')\n    if is_array:\n        cwl_type_string = cwl_type_string[:-2]\n\n    return {'type': cwl_type_string, 'isArray': is_array, 'isOptional': is_optional}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching for Directories and in the cwl data and produces a dictionary containing the input file information.", "response": "def cwl_input_directories(cwl_data, job_data, input_dir=None):\n    \"\"\"\n    Searches for Directories and in the cwl data and produces a dictionary containing input file information.\n\n    :param cwl_data: The cwl data as dictionary\n    :param job_data: The job data as dictionary\n    :param input_dir: TODO\n    :return: Returns the a dictionary containing information about input files.\n             The keys of this dictionary are the input/output identifiers of the files specified in the cwl description.\n             The corresponding value is a dictionary again with the following keys and values:\n             - 'isOptional': A bool indicating whether this input directory is optional\n             - 'isArray': A bool indicating whether this could be a list of directories\n             - 'files': A list of input file descriptions\n\n             A input file description is a dictionary containing the following information\n             - 'path': The path to the specified directory\n             - 'debugInfo': A field to possibly provide debug information\n    \"\"\"\n\n    results = {}\n\n    for input_identifier, input_data in cwl_data['inputs'].items():\n        cwl_type = parse_cwl_type(input_data['type'])\n\n        (is_optional, is_array, cwl_type) = itemgetter('isOptional', 'isArray', 'type')(cwl_type)\n\n        if cwl_type == 'Directory':\n            result = {\n                'isOptional': is_optional,\n                'isArray': is_array,\n                'directories': None\n            }\n\n            if input_identifier in job_data:\n                arg = job_data[input_identifier]\n\n                if is_array:\n                    result['directories'] = [_input_directory_description(input_identifier, i, input_dir) for i in arg]\n                else:\n                    result['directories'] = [_input_directory_description(input_identifier, arg, input_dir)]\n\n            results[input_identifier] = result\n\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary containing information about the output files given in cwl_data.", "response": "def cwl_output_files(cwl_data, inputs_to_reference, output_dir=None):\n    \"\"\"\n    Returns a dictionary containing information about the output files given in cwl_data.\n\n    :param cwl_data: The cwl data from where to extract the output file information.\n    :param inputs_to_reference: Inputs which are used to resolve input references.\n    :param output_dir: Path to the directory where output files are expected.\n    :return: A dictionary containing information about every output file.\n    \"\"\"\n    results = {}\n\n    for key, val in cwl_data['outputs'].items():\n        cwl_type = parse_cwl_type(val['type'])\n        (is_optional, is_array, cwl_type) = itemgetter('isOptional', 'isArray', 'type')(cwl_type)\n\n        if not cwl_type == 'File':\n            continue\n\n        result = {\n            'isOptional': is_optional,\n            'path': None,\n            'size': None,\n            'debugInfo': None\n        }\n\n        glob_path = os.path.expanduser(val['outputBinding']['glob'])\n        if output_dir and not os.path.isabs(glob_path):\n            glob_path = os.path.join(os.path.expanduser(output_dir), glob_path)\n\n        glob_path = resolve_input_references(glob_path, inputs_to_reference)\n        matches = glob(glob_path)\n        try:\n            if len(matches) != 1:\n                raise FileError('glob path \"{}\" does not match exactly one file'.format(glob_path))\n\n            file_path = matches[0]\n            result['path'] = file_path\n\n            if not os.path.isfile(file_path):\n                raise FileError('path is not a file')\n\n            result['size'] = os.path.getsize(file_path) / (1024 * 1024)\n        except:\n            result['debugInfo'] = exception_format()\n\n        results[key] = result\n\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread from the FIFO and returns the data.", "response": "def read(self, length=-1):\n        \"\"\"\n        Reads from the FIFO.\n\n        Reads as much data as possible from the FIFO up to the specified\n        length. If the length argument is negative or ommited all data\n        currently available in the FIFO will be read. If there is no data\n        available in the FIFO an empty string is returned.\n\n        Args:\n            length: The amount of data to read from the FIFO. Defaults to -1.\n        \"\"\"\n        if 0 <= length < len(self):\n            newpos = self.pos + length\n            data = self.buf[self.pos:newpos]\n            self.pos = newpos\n            self.__discard()\n            return data\n\n        data = self.buf[self.pos:]\n        self.clear()\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef readuntil(self, token, size=0):\n        self.__append()\n\n        i = self.buf.find(token, self.pos)\n        if i < 0:\n            index = max(len(token) - 1, size)\n            newpos = max(len(self.buf) - index, self.pos)\n            data = self.buf[self.pos:newpos]\n            self.pos = newpos\n            self.__discard()\n            return False, data\n\n        newpos = i + len(token)\n        data = self.buf[self.pos:newpos]\n        self.pos = newpos\n        self.__discard()\n        return True, data", "response": "Reads data from the FIFO until a token is encountered."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading a line into the FIFO.", "response": "def peekline(self):\n        \"\"\"\n        Peeks a line into the FIFO.\n\n        Perfroms the same function as readline() without removing data from the\n        FIFO. See readline() for further information.\n        \"\"\"\n        self.__append()\n\n        i = self.buf.find(self.eol, self.pos)\n        if i < 0:\n            return ''\n\n        newpos = i + len(self.eol)\n        return self.buf[self.pos:newpos]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef peekuntil(self, token, size=0):\n        self.__append()\n\n        i = self.buf.find(token, self.pos)\n        if i < 0:\n            index = max(len(token) - 1, size)\n            newpos = max(len(self.buf) - index, self.pos)\n            return False, self.buf[self.pos:newpos]\n\n        newpos = i + len(token)\n        return True, self.buf[self.pos:newpos]", "response": "Reads the next size bytes from the FIFO."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget URL from Akamai.", "response": "def getURL(self, CorpNum, UserID, ToGo):\n        \"\"\"\n        :param CorpNum: \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n        :param UserID: \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\n        :param ToGo: [PLUSFRIEND-\ud50c\ub7ec\uc2a4\uce5c\uad6c\uacc4\uc815\uad00\ub9ac, SENDER-\ubc1c\uc2e0\ubc88\ud638\uad00\ub9ac, TEMPLATE-\uc54c\ub9bc\ud1a1\ud15c\ud50c\ub9bf\uad00\ub9ac, BOX-\uce74\uce74\uc624\ud1a1\uc804\uc1a1\ub0b4\uc6a9]\n        :return: \ud31d\ube4c URL\n        \"\"\"\n        if ToGo == None or ToGo == '':\n            raise PopbillException(-99999999, \"TOGO\uac12\uc774 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        if ToGo == 'SENDER':\n            result = self._httpget('/Message/?TG=' + ToGo, CorpNum, UserID)\n        else:\n            result = self._httpget('/KakaoTalk/?TG=' + ToGo, CorpNum, UserID)\n        return result.url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget Plus Friend Mgt URL.", "response": "def getPlusFriendMgtURL(self, CorpNum, UserID):\n        \"\"\"\n        \ud50c\ub7ec\uc2a4\uce5c\uad6c \uacc4\uc815\uad00\ub9ac \ud31d\uc5c5 URL\n        :param CorpNum: \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n        :param UserID: \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\n        :return: \ud31d\ube4c URL\n        \"\"\"\n        result = self._httpget('/KakaoTalk/?TG=PLUSFRIEND', CorpNum, UserID)\n        return result.url"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getATSTemplateMgtURL(self, CorpNum, UserID):\n        result = self._httpget('/KakaoTalk/?TG=TEMPLATE', CorpNum, UserID)\n        return result.url", "response": "Get A TG URL"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the URL of the list of items.", "response": "def getSentListURL(self, CorpNum, UserID):\n        \"\"\"\n        \uce74\uce74\uc624\ud1a1 \uc804\uc1a1\ub0b4\uc5ed \ud31d\uc5c5 URL\n        :param CorpNum: \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n        :param UserID: \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\n        :return: \ud31d\ube4c URL\n        \"\"\"\n        result = self._httpget('/KakaoTalk/?TG=BOX', CorpNum, UserID)\n        return result.url"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sendATS_same(self, CorpNum, TemplateCode, Sender, Content, AltContent, AltSendType, SndDT, KakaoMessages,\n                     UserID=None, RequestNum=None, ButtonList=None):\n        \"\"\"\n       \uc54c\ub9bc\ud1a1 \ub300\ub7c9 \uc804\uc1a1\n       :param CorpNum: \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n       :param TemplateCode: \ud15c\ud50c\ub9bf\ucf54\ub4dc\n       :param Sender: \ubc1c\uc2e0\ubc88\ud638\n       :param Content: [\ub3d9\ubcf4] \uc54c\ub9bc\ud1a1 \ub0b4\uc6a9\n       :param AltContent: [\ub3d9\ubcf4] \ub300\uccb4\ubb38\uc790 \ub0b4\uc6a9\n       :param AltSendType: \ub300\uccb4\ubb38\uc790 \uc720\ud615 [\uacf5\ubc31-\ubbf8\uc804\uc1a1, C-\uc54c\ub9bc\ud1a1\ub0b4\uc6a9, A-\ub300\uccb4\ubb38\uc790\ub0b4\uc6a9]\n       :param SndDT: \uc608\uc57d\uc77c\uc2dc [\uc791\uc131\ud615\uc2dd : yyyyMMddHHmmss]\n       :param KakaoMessages: \uc54c\ub9bc\ud1a1 \ub0b4\uc6a9 (\ubc30\uc5f4)\n       :param UserID: \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\n       :param RequestNum : \uc694\uccad\ubc88\ud638\n       :return: receiptNum (\uc811\uc218\ubc88\ud638)\n       \"\"\"\n        if TemplateCode is None or TemplateCode == '':\n            raise PopbillException(-99999999, \"\uc54c\ub9bc\ud1a1 \ud15c\ud50c\ub9bf\ucf54\ub4dc\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n        if Sender is None or Sender == '':\n            raise PopbillException(-99999999, \"\ubc1c\uc2e0\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        req = {}\n\n        if TemplateCode is not None or TemplateCode != '':\n            req['templateCode'] = TemplateCode\n        if Sender is not None or Sender != '':\n            req['snd'] = Sender\n        if Content is not None or Content != '':\n            req['content'] = Content\n        if AltContent is not None or AltContent != '':\n            req['altContent'] = AltContent\n        if AltSendType is not None or AltSendType != '':\n            req['altSendType'] = AltSendType\n        if SndDT is not None or SndDT != '':\n            req['sndDT'] = SndDT\n        if KakaoMessages is not None or KakaoMessages != '':\n            req['msgs'] = KakaoMessages\n        if ButtonList is not None:\n            req['btns'] = ButtonList\n        if RequestNum is not None or RequestNum != '':\n            req['requestnum'] = RequestNum\n\n        postData = self._stringtify(req)\n\n        result = self._httppost('/ATS', postData, CorpNum, UserID)\n\n        return result.receiptNum", "response": "\uc804\uc1a1 \ubc1c\uc2e0 \ubc88\ud638 \uac00 \uc791\uc131 \ubc1c\uc2e0 \ubc88\ud638"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sendFTS_same(self, CorpNum, PlusFriendID, Sender, Content, AltContent, AltSendType, SndDT,\n                     KakaoMessages, KakaoButtons, AdsYN=False, UserID=None, RequestNum=None):\n        \"\"\"\n        \uce5c\uad6c\ud1a1 \ud14d\uc2a4\ud2b8 \ub300\ub7c9 \uc804\uc1a1\n        :param CorpNum: \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n        :param PlusFriendID: \ud50c\ub7ec\uc2a4\uce5c\uad6c \uc544\uc774\ub514\n        :param Sender: \ubc1c\uc2e0\ubc88\ud638\n        :param Content: [\ub3d9\ubcf4] \uce5c\uad6c\ud1a1 \ub0b4\uc6a9\n        :param AltContent: [\ub3d9\ubcf4] \ub300\uccb4\ubb38\uc790 \ub0b4\uc6a9\n        :param AltSendType: \ub300\uccb4\ubb38\uc790 \uc720\ud615 [\uacf5\ubc31-\ubbf8\uc804\uc1a1, C-\uc54c\ub9bc\ud1a1\ub0b4\uc6a9, A-\ub300\uccb4\ubb38\uc790\ub0b4\uc6a9]\n        :param SndDT: \uc608\uc57d\uc77c\uc2dc [\uc791\uc131\ud615\uc2dd : yyyyMMddHHmmss]\n        :param KakaoMessages: \uce5c\uad6c\ud1a1 \ub0b4\uc6a9 (\ubc30\uc5f4)\n        :param KakaoButtons: \ubc84\ud2bc \ubaa9\ub85d (\ucd5c\ub300 5\uac1c)\n        :param AdsYN: \uad11\uace0 \uc804\uc1a1\uc5ec\ubd80\n        :param UserID: \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\n        :param RequestNum : \uc694\uccad\ubc88\ud638\n        :return: receiptNum (\uc811\uc218\ubc88\ud638)\n        \"\"\"\n        if PlusFriendID is None or PlusFriendID == '':\n            raise PopbillException(-99999999, \"\ud50c\ub7ec\uc2a4\uce5c\uad6c \uc544\uc774\ub514\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n        if Sender is None or Sender == '':\n            raise PopbillException(-99999999, \"\ubc1c\uc2e0\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        req = {}\n        if PlusFriendID is not None or PlusFriendID != '':\n            req['plusFriendID'] = PlusFriendID\n        if Sender is not None or Sender != '':\n            req['snd'] = Sender\n        if AltSendType is not None or AltSendType != '':\n            req['altSendType'] = AltSendType\n        if Content is not None or Content != '':\n            req['content'] = Content\n        if AltContent is not None or AltContent != '':\n            req['altContent'] = AltContent\n        if SndDT is not None or SndDT != '':\n            req['sndDT'] = SndDT\n        if KakaoMessages:\n            req['msgs'] = KakaoMessages\n        if KakaoButtons:\n            req['btns'] = KakaoButtons\n        if AdsYN:\n            req['adsYN'] = True\n        if RequestNum is not None or RequestNum != '':\n            req['requestNum'] = RequestNum\n\n        postData = self._stringtify(req)\n\n        result = self._httppost('/FTS', postData, CorpNum, UserID)\n\n        return result.receiptNum", "response": "\uce5c\uad6c\ud1a1 \ud14d\uc2a4\ud2b8 \ub300\ub7c9 \uc804\uc1a1\n        :param CorpNum: \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n        :param PlusFriendID: \ud50c\ub7ec\uc2a4\uce5c\uad6c \uc544\uc774\ub514\n        :param Sender: \ubc1c\uc2e0\ubc88\ud638\n        :param Content: [\ub3d9\ubcf4] \uce5c\uad6c\ud1a1 \ub0b4\uc6a9\n        :param AltContent: [\ub3d9\ubcf4] \ub300\uccb4\ubb38\uc790 \ub0b4\uc6a9\n        :param AltSendType: \ub300\uccb4\ubb38\uc790 \uc720\ud615 [\uacf5\ubc31-\ubbf8\uc804\uc1a1, C-\uc54c\ub9bc\ud1a1\ub0b4\uc6a9, A-\ub300\uccb4\ubb38\uc790\ub0b4\uc6a9]\n        :param SndDT: \uc608\uc57d\uc77c\uc2dc [\uc791\uc131\ud615\uc2dd : yyyyMMddHHmmss]\n        :param KakaoMessages: \uce5c\uad6c\ud1a1 \ub0b4\uc6a9 (\ubc30\uc5f4)\n        :param KakaoButtons: \ubc84\ud2bc \ubaa9\ub85d (\ucd5c\ub300 5\uac1c)\n        :param AdsYN: \uad11\uace0 \uc804\uc1a1\uc5ec\ubd80\n        :param UserID: \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\n        :param RequestNum : \uc694\uccad\ubc88\ud638\n        :return: receiptNum (\uc811\uc218\ubc88\ud638)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets UnitCost of a user.", "response": "def getUnitCost(self, CorpNum, MsgType, UserID=None):\n        \"\"\"\n        \uc804\uc1a1\ub2e8\uac00 \ud655\uc778\n        :param CorpNum: \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n        :param MsgType: \uce74\uce74\uc624\ud1a1 \uc720\ud615\n        :param UserID: \ud31d\ube4c \ud68c\uc6d0\uc544\uc774\ub514\n        :return: unitCost\n        \"\"\"\n        if MsgType is None or MsgType == \"\":\n            raise PopbillException(-99999999, \"\uc804\uc1a1\uc720\ud615\uc774 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        result = self._httpget(\"/KakaoTalk/UnitCost?Type=\" + MsgType, CorpNum)\n        return float(result.unitCost)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef revdocs2reverts(rev_docs, radius=defaults.RADIUS, use_sha1=False,\n                    resort=False, verbose=False):\n    \"\"\"\n    Converts a sequence of page-partitioned revision documents into a sequence\n    of reverts.\n\n    :Params:\n        rev_docs : `iterable` ( `dict` )\n            a page-partitioned sequence of revision documents\n        radius : `int`\n            The maximum number of revisions that a revert can reference.\n        use_sha1 : `bool`\n            Use the sha1 field as the checksum for comparison.\n        resort : `bool`\n            If True, re-sort the revisions of each page.\n        verbose : `bool`\n            Print dots and stuff\n    \"\"\"\n\n    page_rev_docs = groupby(rev_docs, lambda rd: rd.get('page'))\n\n    for page_doc, rev_docs in page_rev_docs:\n        if verbose:\n            sys.stderr.write(page_doc.get('title') + \": \")\n            sys.stderr.flush()\n\n        if resort:\n            if verbose:\n                sys.stderr.write(\"(sorting) \")\n                sys.stderr.flush()\n            rev_docs = sorted(\n                rev_docs, key=lambda r: (r.get('timestamp'), r.get('id')))\n\n        detector = Detector(radius=radius)\n        for rev_doc in rev_docs:\n            if not use_sha1 and 'text' not in rev_doc:\n                logger.warn(\"Skipping {0}: 'text' field not found in {0}\"\n                            .format(rev_doc['id'], rev_doc))\n                continue\n\n            if use_sha1:\n                checksum = rev_doc.get('sha1') or DummyChecksum()\n            elif 'text' in rev_doc:\n                text_bytes = bytes(rev_doc['text'], 'utf8', 'replace')\n                checksum = hashlib.sha1(text_bytes).digest()\n\n            revert = detector.process(checksum, rev_doc)\n\n            if revert:\n                yield revert.to_json()\n                if verbose:\n                    sys.stderr.write(\"r\")\n                    sys.stderr.flush()\n            else:\n                if verbose:\n                    sys.stderr.write(\".\")\n                    sys.stderr.flush()\n\n        if verbose:\n            sys.stderr.write(\"\\n\")\n            sys.stderr.flush()", "response": "Takes a sequence of page - partitioned revision documents and returns a sequence of reverts."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef spm_hrf_compat(t,\n                   peak_delay=6,\n                   under_delay=16,\n                   peak_disp=1,\n                   under_disp=1,\n                   p_u_ratio=6,\n                   normalize=True,\n                   ):\n    \"\"\" SPM HRF function from sum of two gamma PDFs\n\n    This function is designed to be partially compatible with SPMs `spm_hrf.m`\n    function.\n\n    The SPN HRF is a *peak* gamma PDF (with location `peak_delay` and\n    dispersion `peak_disp`), minus an *undershoot* gamma PDF (with location\n    `under_delay` and dispersion `under_disp`, and divided by the `p_u_ratio`).\n\n    Parameters\n    ----------\n    t : array-like\n        vector of times at which to sample HRF\n    peak_delay : float, optional\n        delay of peak\n    peak_disp : float, optional\n        width (dispersion) of peak\n    under_delay : float, optional\n        delay of undershoot\n    under_disp : float, optional\n        width (dispersion) of undershoot\n    p_u_ratio : float, optional\n        peak to undershoot ratio.  Undershoot divided by this value before\n        subtracting from peak.\n    normalize : {True, False}, optional\n        If True, divide HRF values by their sum before returning. SPM does this\n        by default.\n\n    Returns\n    -------\n    hrf : array\n        vector length ``len(t)`` of samples from HRF at times `t`\n\n    Notes\n    -----\n    See ``spm_hrf.m`` in the SPM distribution.\n    \"\"\"\n    if len([v for v in [peak_delay, peak_disp, under_delay, under_disp]\n            if v <= 0]):\n        raise ValueError(\"delays and dispersions must be > 0\")\n    # gamma.pdf only defined for t > 0\n    hrf = np.zeros(t.shape, dtype=np.float)\n    pos_t = t[t > 0]\n    peak = sps.gamma.pdf(pos_t,\n                         peak_delay / peak_disp,\n                         loc=0,\n                         scale=peak_disp)\n    undershoot = sps.gamma.pdf(pos_t,\n                               under_delay / under_disp,\n                               loc=0,\n                               scale=under_disp)\n    hrf[t > 0] = peak - undershoot / p_u_ratio\n    if not normalize:\n        return hrf\n    return hrf / np.max(hrf)", "response": "This function is designed to be partially compatible with SPMs SPM HRF function from sum of two gamma PDFs at times t."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dspmt(t):\n    t = np.asarray(t)\n    return spmt(t) - spmt(t - 1)", "response": "SPM canonical HRF derivative values for time values t"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cnvlTc(idxPrc,\n           aryPrfTcChunk,\n           lstHrf,\n           varTr,\n           varNumVol,\n           queOut,\n           varOvsmpl=10,\n           varHrfLen=32,\n           ):\n    \"\"\"\n    Convolution of time courses with HRF model.\n    \"\"\"\n\n    # *** prepare hrf time courses for convolution\n    print(\"---------Process \" + str(idxPrc) +\n          \": Prepare hrf time courses for convolution\")\n    # get frame times, i.e. start point of every volume in seconds\n    vecFrms = np.arange(0, varTr * varNumVol, varTr)\n    # get supersampled frames times, i.e. start point of every volume in\n    # seconds, since convolution takes place in temp. upsampled space\n    vecFrmTms = np.arange(0, varTr * varNumVol, varTr / varOvsmpl)\n    # get resolution of supersampled frame times\n    varRes = varTr / float(varOvsmpl)\n\n    # prepare empty list that will contain the arrays with hrf time courses\n    lstBse = []\n    for hrfFn in lstHrf:\n        # needs to be a multiple of oversample\n        vecTmpBse = hrfFn(np.linspace(0, varHrfLen,\n                                      (varHrfLen // varTr) * varOvsmpl))\n        lstBse.append(vecTmpBse)\n\n    # *** prepare pixel time courses for convolution\n    print(\"---------Process \" + str(idxPrc) +\n          \": Prepare pixel time courses for convolution\")\n\n    # adjust the input, if necessary, such that input is 2D, with last dim time\n    tplInpShp = aryPrfTcChunk.shape\n    aryPrfTcChunk = aryPrfTcChunk.reshape((-1, aryPrfTcChunk.shape[-1]))\n\n    # Prepare an empty array for ouput\n    aryConv = np.zeros((aryPrfTcChunk.shape[0], len(lstHrf),\n                        aryPrfTcChunk.shape[1]))\n    print(\"---------Process \" + str(idxPrc) +\n          \": Convolve\")\n    # Each time course is convolved with the HRF separately, because the\n    # numpy convolution function can only be used on one-dimensional data.\n    # Thus, we have to loop through time courses:\n    for idxTc in range(0, aryConv.shape[0]):\n\n        # Extract the current time course:\n        vecTc = aryPrfTcChunk[idxTc, :]\n\n        # upsample the pixel time course, so that it matches the hrf time crs\n        vecTcUps = np.zeros(int(varNumVol * varTr/varRes))\n        vecOns = vecFrms[vecTc.astype(bool)]\n        vecInd = np.round(vecOns / varRes).astype(np.int)\n        vecTcUps[vecInd] = 1.\n\n        # *** convolve\n        for indBase, base in enumerate(lstBse):\n            # perform the convolution\n            col = np.convolve(base, vecTcUps, mode='full')[:vecTcUps.size]\n            # get function for downsampling\n            f = interp1d(vecFrmTms, col)\n            # downsample to original space and assign to ary\n            aryConv[idxTc, indBase, :] = f(vecFrms)\n\n    # determine output shape\n    tplOutShp = tplInpShp[:-1] + (len(lstHrf), ) + (tplInpShp[-1], )\n\n    # Create list containing the convolved timecourses, and the process ID:\n    lstOut = [idxPrc,\n              aryConv.reshape(tplOutShp)]\n\n    # Put output to queue:\n    queOut.put(lstOut)", "response": "convolves the time courses in a single hrf or pixel time courses in a single pixel time courses"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates double gamma function.", "response": "def funcHrf(varNumVol, varTr):\n    \"\"\"Create double gamma function.\n\n    Source:\n    http://www.jarrodmillman.com/rcsds/lectures/convolution_background.html\n    \"\"\"\n    vecX = np.arange(0, varNumVol, 1)\n\n    # Expected time of peak of HRF [s]:\n    varHrfPeak = 6.0 / varTr\n    # Expected time of undershoot of HRF [s]:\n    varHrfUndr = 12.0 / varTr\n    # Scaling factor undershoot (relative to peak):\n    varSclUndr = 0.35\n\n    # Gamma pdf for the peak\n    vecHrfPeak = gamma.pdf(vecX, varHrfPeak)\n    # Gamma pdf for the undershoot\n    vecHrfUndr = gamma.pdf(vecX, varHrfUndr)\n    # Combine them\n    vecHrf = vecHrfPeak - varSclUndr * vecHrfUndr\n\n    # Scale maximum of HRF to 1.0:\n    vecHrf = np.divide(vecHrf, np.max(vecHrf))\n\n    return vecHrf"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cnvlTcOld(idxPrc,\n              aryPrfTcChunk,\n              varTr,\n              varNumVol,\n              queOut):\n    \"\"\"\n    Old version:\n    Convolution of time courses with one canonical HRF model.\n    \"\"\"\n    # Create 'canonical' HRF time course model:\n    vecHrf = funcHrf(varNumVol, varTr)\n\n    # adjust the input, if necessary, such that input is 2D, with last dim time\n    tplInpShp = aryPrfTcChunk.shape\n    aryPrfTcChunk = aryPrfTcChunk.reshape((-1, aryPrfTcChunk.shape[-1]))\n\n    # Prepare an empty array for ouput\n    aryConv = np.zeros(np.shape(aryPrfTcChunk))\n\n    # Each time course is convolved with the HRF separately, because the\n    # numpy convolution function can only be used on one-dimensional data.\n    # Thus, we have to loop through time courses:\n    for idxTc, vecTc in enumerate(aryPrfTcChunk):\n\n        # In order to avoid an artefact at the end of the time series, we have\n        # to concatenate an empty array to both the design matrix and the HRF\n        # model before convolution.\n        vecTc = np.append(vecTc, np.zeros(100))\n        vecHrf = np.append(vecHrf, np.zeros(100))\n\n        # Convolve design matrix with HRF model:\n        aryConv[idxTc, :] = np.convolve(vecTc, vecHrf,\n                                        mode='full')[:varNumVol]\n\n    # determine output shape\n    tplOutShp = tplInpShp[:-1] + (1, ) + (tplInpShp[-1], )\n\n    # Create list containing the convolved timecourses, and the process ID:\n    lstOut = [idxPrc,\n              aryConv.reshape(tplOutShp)]\n\n    # Put output to queue:\n    queOut.put(lstOut)", "response": "This function is used to create a new time course model for a given time series."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def main() -> None:\n    logging.basicConfig(level=logging.INFO)\n    async with ClientSession() as websession:\n        try:\n            # Create a client:\n            client = Client(websession)\n\n            # Get user data for the client's latitude/longitude:\n            user_coord_resp = await client.user_reports.status_by_coordinates(\n                LATITUDE, LONGITUDE)\n            _LOGGER.info(\n                'User data by latitude/longitude (%s, %s): %s', LATITUDE,\n                LONGITUDE, user_coord_resp)\n\n            # Get user data for the a specific ZIP code:\n            user_zip_resp = await client.user_reports.status_by_zip(ZIP_CODE)\n            _LOGGER.info(\n                'User data by ZIP code (%s): %s', ZIP_CODE, user_zip_resp)\n\n            # Get CDC data for the client's latitude/longitude:\n            cdc_coord_resp = await client.cdc_reports.status_by_coordinates(\n                LATITUDE, LONGITUDE)\n            _LOGGER.info(\n                'CDC data by latitude/longitude (%s, %s): %s', LATITUDE,\n                LONGITUDE, cdc_coord_resp)\n\n            # Get CDC data for North Dakota\n            cdc_state_resp = await client.cdc_reports.status_by_state(STATE)\n            _LOGGER.info(\n                'CDC data by state name (%s): %s', STATE, cdc_state_resp)\n        except FluNearYouError as err:\n            print(err)", "response": "Create the aiohttp session and run the example."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef call(cls, method, params=None, timeout=600):\n\n        params = [] if params is None else params\n\n        return cls.make_request(SERVER_ADDRESS, method, params, timeout=timeout)", "response": "Makes a call to the LBRY API"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the state of a job.", "response": "def getJobState(self, CorpNum, JobID, UserID=None):\n        \"\"\" \uc218\uc9d1 \uc0c1\ud0dc \ud655\uc778\n            args\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                JobID : \uc791\uc5c5\uc544\uc774\ub514\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\n            return\n                \uc218\uc9d1 \uc0c1\ud0dc \uc815\ubcf4\n            raise\n                PopbillException\n        \"\"\"\n        if JobID == None or len(JobID) != 18:\n            raise PopbillException(-99999999, \"\uc791\uc5c5\uc544\uc774\ub514(jobID)\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n\n        return self._httpget('/HomeTax/Taxinvoice/' + JobID + '/State', CorpNum, UserID)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches Tax in Aleph", "response": "def search(self, CorpNum, JobID, Type, TaxType, PurposeType, TaxRegIDType, TaxRegIDYN, TaxRegID, Page, PerPage,\n               Order, UserID=None):\n        \"\"\" \uc218\uc9d1 \uacb0\uacfc \uc870\ud68c\n            args\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                JobID : \uc791\uc5c5\uc544\uc774\ub514\n                Type : \ubb38\uc11c\ud615\ud0dc \ubc30\uc5f4, N-\uc77c\ubc18\uc804\uc790\uc138\uae08\uacc4\uc0b0\uc11c, M-\uc218\uc815\uc804\uc790\uc138\uae08\uacc4\uc0b0\uc11c\n                TaxType : \uacfc\uc138\ud615\ud0dc \ubc30\uc5f4, T-\uacfc\uc138, N-\uba74\uc138, Z-\uc601\uc138\n                PurposeType : \uc601\uc218/\uccad\uad6c, R-\uc601\uc218, C-\uccad\uad6c, N-\uc5c6\uc74c\n                TaxRegIDType : \uc885\uc0ac\uc5c5\uc7a5\ubc88\ud638 \uc0ac\uc5c5\uc790\uc720\ud615, S-\uacf5\uae09\uc790, B-\uacf5\uae09\ubc1b\ub294\uc790, T-\uc218\ud0c1\uc790\n                TaxRegIDYN : \uc885\uc0ac\uc5c5\uc7a5\ubc88\ud638 \uc720\ubb34, \uacf5\ubc31-\uc804\uccb4\uc870\ud68c, 0-\uc885\uc0ac\uc5c5\uc7a5\ubc88\ud638 \uc5c6\uc74c, 1-\uc885\uc0ac\uc5c5\uc7a5\ubc88\ud638 \uc788\uc74c\n                TaxRegID : \uc885\uc0ac\uc5c5\uc7a5\ubc88\ud638, \ucf64\ub9c8(\",\")\ub85c \uad6c\ubd84 \ud558\uc5ec \uad6c\uc131 ex) '0001,0002'\n                Page : \ud398\uc774\uc9c0 \ubc88\ud638\n                PerPage : \ud398\uc774\uc9c0\ub2f9 \ubaa9\ub85d \uac1c\uc218, \ucd5c\ub300 1000\uac1c\n                Order : \uc815\ub82c \ubc29\ud5a5, D-\ub0b4\ub9bc\ucc28\uc21c, A-\uc624\ub984\ucc28\uc21c\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\n            return\n                \uc218\uc9d1 \uacb0\uacfc \uc815\ubcf4\n            raise\n                PopbillException\n        \"\"\"\n        if JobID == None or len(JobID) != 18:\n            raise PopbillException(-99999999, \"\uc791\uc5c5\uc544\uc774\ub514(jobID)\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n\n        uri = '/HomeTax/Taxinvoice/' + JobID\n        uri += '?Type=' + ','.join(Type)\n        uri += '&TaxType=' + ','.join(TaxType)\n        uri += '&PurposeType=' + ','.join(PurposeType)\n        uri += '&TaxRegIDType=' + TaxRegIDType\n        uri += '&TaxRegID=' + TaxRegID\n        uri += '&Page=' + str(Page)\n        uri += '&PerPage=' + str(PerPage)\n        uri += '&Order=' + Order\n\n        if TaxRegIDYN != '':\n            uri += '&TaxRegIDYN=' + TaxRegIDYN\n\n        return self._httpget(uri, CorpNum, UserID)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getTaxinvoice(self, CorpNum, NTSConfirmNum, UserID=None):\n        if NTSConfirmNum == None or len(NTSConfirmNum) != 24:\n            raise PopbillException(-99999999, \"\uad6d\uc138\uccad\uc2b9\uc778\ubc88\ud638(NTSConfirmNum)\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n\n        return self._httpget('/HomeTax/Taxinvoice/' + NTSConfirmNum, CorpNum, UserID)", "response": "\uc804\uc790\uc138\uae08\uacc4\uc0b0\uc11c \uc0c1\uc138\uc815\ubcf4 \ud655\uc778\n            args\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                NTSConfirmNum : \uad6d\uc138\uccad \uc2b9\uc778\ubc88\ud638\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\n            return\n                \uc804\uc790\uc138\uae08\uacc4\uc0b0\uc11c \uc815\ubcf4\uac1d\uccb4\n            raise\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_document(self, titlestring):\n        #root = etree.XML('''<?xml version=\"1.0\"?>\\\n#<!DOCTYPE html  PUBLIC '-//W3C//DTD XHTML 1.1//EN'  'http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd'>\\\n#<html xml:lang=\"en-US\" xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:ops=\"http://www.idpf.org/2007/ops\">\\\n#</html>''')\n\n        root = etree.XML('''<?xml version=\"1.0\"?>\\\n<!DOCTYPE html>\\\n<html xmlns=\"http://www.w3.org/1999/xhtml\">\\\n</html>''')\n\n        document = etree.ElementTree(root)\n        html = document.getroot()\n        head = etree.SubElement(html, 'head')\n        etree.SubElement(html, 'body')\n        title = etree.SubElement(head, 'title')\n        title.text = titlestring\n        #The href for the css stylesheet is a standin, can be overwritten\n        etree.SubElement(head,\n                         'link',\n                         {'href': 'css/default.css',\n                          'rel': 'stylesheet',\n                          'type': 'text/css'})\n\n        return document", "response": "This method creates a new document for writing as xml\n        to the OPS subdirectory of the ePub structure."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_document(self, name, document):\n        with open(name, 'wb') as out:\n            out.write(etree.tostring(document,\n                                     encoding='utf-8',\n                                     pretty_print=True))", "response": "This function will write a document to an XML file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef format_date_string(self, date_tuple):\n        months = ['', 'January', 'February', 'March', 'April', 'May', 'June',\n                  'July', 'August', 'September', 'October', 'November', 'December']\n        date_string = ''\n        if date_tuple.season:\n            return '{0}, {1}'.format(date_tuple.season, date_tuple.year)\n        else:\n            if not date_tuple.month and not date_tuple.day:\n                return '{0}'.format(date_tuple.year)\n            if date_tuple.month:\n                date_string += months[int(date_tuple.month)]\n            if date_tuple.day:\n                date_string += ' ' + date_tuple.day\n            return ', '.join([date_string, date_tuple.year])", "response": "Formats a date_tuple object and returns a string that can be used to place the article content in the article."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_out_of_flow_tables(self):\n        if self.article.body is None:\n            return False\n        for table_wrap in self.article.body.findall('.//table-wrap'):\n            graphic = table_wrap.xpath('./graphic | ./alternatives/graphic')\n            table = table_wrap.xpath('./table | ./alternatives/table')\n            if graphic and table:\n                return True\n        return False", "response": "Returns True if the article has out - of - flow HTML tables False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process(self, article):\n        if self.article is not None and not self.collection:\n            log.warning('Could not process additional article. Navigation only \\\nhandles one article unless collection mode is set.')\n            return False\n\n        if article.publisher is None:\n            log.error('''Navigation cannot be generated for an Article \\\nwithout a publisher!''')\n            return\n        self.article = article\n        self.article_doi = self.article.doi.split('/')[1]\n        self.all_dois.append(self.article.doi)\n        if self.collection:\n            pass\n        else:\n            self.title = self.article.publisher.nav_title()\n        for author in self.article.publisher.nav_contributors():\n            self.contributors.add(author)\n\n        #Analyze the structure of the article to create internal mapping\n        self.map_navigation()", "response": "Processes an article and creates the internal mapping."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef recursive_article_navmap(self, src_element, depth=0, first=True):\n        if depth > self.nav_depth:\n            self.nav_depth = depth\n        navpoints = []\n        tagnames = ['sec', 'fig', 'table-wrap']\n        for child in src_element:\n            try:\n                tagname = child.tag\n            except AttributeError:\n                continue\n            else:\n                if tagname not in tagnames:\n                    continue\n\n            #Safely handle missing id attributes\n            if 'id' not in child.attrib:\n                child.attrib['id'] = self.auto_id\n\n            #If in collection mode, we'll prepend the article DOI to avoid\n            #collisions\n            if self.collection:\n                child_id = '-'.join([self.article_doi,\n                                     child.attrib['id']])\n            else:\n                child_id = child.attrib['id']\n\n            #Attempt to infer the correct text as a label\n            #Skip the element if we cannot\n            child_title = child.find('title')\n            if child_title is None:\n                continue  # If there is no immediate title, skip this element\n            label = element_methods.all_text(child_title)\n            if not label:\n                continue  # If no text in the title, skip this element\n            source = 'main.{0}.xhtml#{1}'.format(self.article_doi,\n                                               child.attrib['id'])\n            if tagname == 'sec':\n                children = self.recursive_article_navmap(child, depth=depth + 1)\n                navpoints.append(navpoint(child_id,\n                                          label,\n                                          self.play_order,\n                                          source,\n                                          children))\n            #figs and table-wraps do not have children\n            elif tagname == 'fig':  # Add navpoints to list_of_figures\n                self.figures_list.append(navpoint(child.attrib['id'],\n                                                  label,\n                                                  None,\n                                                  source,\n                                                  []))\n            elif tagname == 'table-wrap':  # Add navpoints to list_of_tables\n                self.tables_list.append(navpoint(child.attrib['id'],\n                                                 label,\n                                                 None,\n                                                 source,\n                                                 []))\n        return navpoints", "response": "This function recursively traverses the content of an article and adds the correct elements to the NCX file s navMap and Lists."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates the NCX element for EPUB2.", "response": "def render_EPUB2(self, location):\n        \"\"\"\n        Creates the NCX specified file for EPUB2\n        \"\"\"\n\n        def make_navlabel(text):\n            \"\"\"\n            Creates and returns a navLabel element with the supplied text.\n            \"\"\"\n            navlabel = etree.Element('navLabel')\n            navlabel_text = etree.SubElement(navlabel, 'text')\n            navlabel_text.text = text\n            return navlabel\n\n        def make_navMap(nav=None):\n            if nav is None:\n                nav_element = etree.Element('navMap')\n                for nav_point in self.nav:\n                    nav_element.append(make_navMap(nav=nav_point))\n            else:\n                nav_element = etree.Element('navPoint')\n                nav_element.attrib['id'] = nav.id\n                nav_element.attrib['playOrder'] = nav.playOrder\n                nav_element.append(make_navlabel(nav.label))\n                content_element = etree.SubElement(nav_element, 'content')\n                content_element.attrib['src'] = nav.source\n                for child in nav.children:\n                    nav_element.append(make_navMap(nav=child))\n            return nav_element\n        root = etree.XML('''\\\n<?xml version=\"1.0\"?>\\\n<ncx version=\"2005-1\" xmlns=\"http://www.daisy.org/z3986/2005/ncx/\">\\\n<head>\\\n<meta name=\"dtb:uid\" content=\"{uid}\"/>\\\n<meta name=\"dtb:depth\" content=\"{depth}\"/>\\\n<meta name=\"dtb:totalPageCount\" content=\"0\"/>\\\n<meta name=\"dtb:maxPageNumber\" content=\"0\"/>\\\n<meta name=\"dtb:generator\" content=\"OpenAccess_EPUB {version}\"/>\\\n</head>\\\n</ncx>'''.format(**{'uid': ','.join(self.all_dois),\n                    'depth': self.nav_depth,\n                    'version': __version__}))\n        document = etree.ElementTree(root)\n        ncx = document.getroot()\n\n        #Create the docTitle element\n        doctitle = etree.SubElement(ncx, 'docTitle')\n        doctitle_text = etree.SubElement(doctitle, 'text')\n        doctitle_text.text = self.title\n\n        #Create the docAuthor elements\n        for contributor in self.contributors:\n            if contributor.role == 'author':\n                docauthor = etree.SubElement(ncx, 'docAuthor')\n                docauthor_text = etree.SubElement(docauthor, 'text')\n                docauthor_text.text = contributor.name\n\n        #Create the navMap element\n        ncx.append(make_navMap())\n\n        if self.figures_list:\n            navlist = etree.SubElement(ncx, 'navList')\n            navlist.append(make_navlabel('List of Figures'))\n            for nav_pt in self.figures_list:\n                navtarget = etree.SubElement(navlist, 'navTarget')\n                navtarget.attrib['id'] = nav_pt.id\n                navtarget.append(self.make_navlabel(nav_pt.label))\n                content = etree.SubElement(navtarget, 'content')\n                content.attrib['src'] = nav_pt.source\n\n        if self.tables_list:\n            navlist = etree.SubElement(ncx, 'navList')\n            navlist.append(make_navlabel('List of Tables'))\n            for nav_pt in self.tables_list:\n                navtarget = etree.SubElement(navlist, 'navTarget')\n                navtarget.attrib['id'] = nav_pt.id\n                navtarget.append(self.make_navlabel(nav_pt.label))\n                content = etree.SubElement(navtarget, 'content')\n                content.attrib['src'] = nav_pt.source\n\n        with open(os.path.join(location, 'EPUB', 'toc.ncx'), 'wb') as output:\n            output.write(etree.tostring(document, encoding='utf-8', pretty_print=True))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate 1D Gaussian. Source : http://mathworld. wolfram. com / GaussianFunction. html", "response": "def funcGauss1D(x, mu, sig):\n    \"\"\" Create 1D Gaussian. Source:\n    http://mathworld.wolfram.com/GaussianFunction.html\n    \"\"\"\n    arrOut = np.exp(-np.power((x - mu)/sig, 2.)/2)\n    # normalize\n#    arrOut = arrOut/(np.sqrt(2.*np.pi)*sig)\n    # normalize (laternative)\n    arrOut = arrOut/np.sum(arrOut)\n    return arrOut"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef funcGauss2D(varSizeX, varSizeY, varPosX, varPosY, varSd):\n\n    \"\"\" Create 2D Gaussian kernel. Source:\n    http://mathworld.wolfram.com/GaussianFunction.html\n    \"\"\"\n\n    varSizeX = int(varSizeX)\n    varSizeY = int(varSizeY)\n\n    # aryX and aryY are in reversed order, this seems to be necessary:\n    aryY, aryX = sp.mgrid[0:varSizeX,\n                          0:varSizeY]\n\n    # The actual creation of the Gaussian array:\n    aryGauss = (\n        (\n            np.power((aryX - varPosX), 2.0) +\n            np.power((aryY - varPosY), 2.0)\n        ) /\n        (2.0 * np.power(varSd, 2.0))\n        )\n    aryGauss = np.exp(-aryGauss)\n    # normalize\n    # aryGauss = aryGauss/(2*np.pi*np.power(varSd, 2))\n\n    return aryGauss", "response": "Create 2D Gaussian kernel. Source : mathworld. wolfram. com / GaussianFunction. html\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef funcConvPar(aryDm,\n                vecHrf,\n                varNumVol):\n\n    \"\"\"\n    Function for convolution of pixel-wise 'design matrix' with HRF model.\n    \"\"\"\n    # In order to avoid an artefact at the end of the time series, we have to\n    # concatenate an empty array to both the design matrix and the HRF model\n    # before convolution.\n    aryDm = np.concatenate((aryDm, np.zeros((aryDm.shape[0], 100))), axis=1)\n    vecHrf = np.concatenate((vecHrf, np.zeros((100,))))\n\n    aryDmConv = np.empty((aryDm.shape[0], varNumVol))\n    for idx in range(0, aryDm.shape[0]):\n        vecDm = aryDm[idx, :]\n        # Convolve design matrix with HRF model:\n        aryDmConv[idx, :] = np.convolve(vecDm, vecHrf,\n                                        mode='full')[:varNumVol]\n    return aryDmConv", "response": "Function for convolution of pixel - wise design matrix with HRF model."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsimulating an AR1 model using the parameters beta c and sigma.", "response": "def simulateAR1(n,\n                beta,\n                sigma,\n                c,\n                burnin,\n                varNumCNR,\n                varNumTP,\n                ):\n    \"\"\"\n    Simulates an AR(1) model using the parameters beta, c, and sigma.\n    Returns an array with length n\n\n    n := number of time points\n    beta := correlation weight\n    sigma := standard deviation of the noise, can be a vector\n    c := constant added to the noise, default 0\n\n    based on:\n    source1: https://github.com/ndronen/misc/blob/master/python/ar1.py\n    source2: http://stats.stackexchange.com/questions/22742/\n             problem-simulating-ar2-process\n    source3: https://kurtverstegen.wordpress.com/2013/12/07/simulation/\n    \"\"\"\n    # Output array with noise time courses\n    noise = np.empty((varNumCNR, varNumTP))\n    if burnin == 1:\n        burnin = 100\n        n = n + burnin\n\n    noiseTemp = c + sp.random.normal(0, 1, n)\n    sims = np.zeros(n)\n    sims[0] = noiseTemp[0]\n    for i in range(1, n):\n        sims[i] = beta*sims[i-1] + noiseTemp[i]\n    sims = sims[burnin:]\n    noise = sigma[:, np.newaxis]*sp.stats.mstats.zscore(sims)\n    return noise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef funcNrlTcMotPred(idxPrc,\n                     varPixX,\n                     varPixY,\n                     NrlMdlChunk,\n                     varNumTP,\n                     aryBoxCar,  # aryCond\n                     path,\n                     varNumNrlMdls,\n                     varNumMtDrctn,\n                     varPar,\n                     queOut):\n    \"\"\"\n    Function for creating neural time course models.\n    This function should be used to create neural models if different\n    predictors for every motion direction are included.\n    \"\"\"\n\n#    # if hd5 method is used: open file for reading\n#    filename = 'aryBoxCar' + str(idxPrc) + '.hdf5'\n#    hdf5_path = os.path.join(path, filename)\n#    fileH = tables.openFile(hdf5_path, mode='r')\n\n    # Output array with pRF model time courses at all modelled standard\n    # deviations for current pixel position:\n    aryOut = np.empty((len(NrlMdlChunk), varNumTP, varNumMtDrctn),\n                      dtype='float32')\n\n    # Prepare status indicator if this is the first of the parallel processes:\n    if idxPrc == 1:\n\n        # We create a status indicator for the time consuming pRF model finding\n        # algorithm. Number of steps of the status indicator:\n        varStsStpSze = 20\n\n        # Number of pRF models to fit:\n        varNumLoops = varNumNrlMdls/varPar\n\n        # Vector with pRF values at which to give status feedback:\n        vecStatus = np.linspace(0,\n                                varNumLoops,\n                                num=(varStsStpSze+1),\n                                endpoint=True)\n        vecStatus = np.ceil(vecStatus)\n        vecStatus = vecStatus.astype(int)\n\n        # Vector with corresponding percentage values at which to give status\n        # feedback:\n        vecStatusPrc = np.linspace(0,\n                                   100,\n                                   num=(varStsStpSze+1),\n                                   endpoint=True)\n        vecStatusPrc = np.ceil(vecStatusPrc)\n        vecStatusPrc = vecStatusPrc.astype(int)\n\n        # Counter for status indicator:\n        varCntSts01 = 0\n        varCntSts02 = 0\n\n    # Loop through all Gauss parameters that are in this chunk\n    for idx, NrlMdlTrpl in enumerate(NrlMdlChunk):\n\n        # Status indicator (only used in the first of the parallel\n        # processes):\n        if idxPrc == 1:\n\n            # Status indicator:\n            if varCntSts02 == vecStatus[varCntSts01]:\n\n                # Prepare status message:\n                strStsMsg = ('---------Progress: ' +\n                             str(vecStatusPrc[varCntSts01]) +\n                             ' % --- ' +\n                             str(vecStatus[varCntSts01]) +\n                             ' loops out of ' +\n                             str(varNumLoops))\n\n                print(strStsMsg)\n\n                # Only increment counter if the last value has not been\n                # reached yet:\n                if varCntSts01 < varStsStpSze:\n                    varCntSts01 = varCntSts01 + int(1)\n\n        # x pos of Gauss model: NrlMdlTrpl[0]\n        # y pos of Gauss model: NrlMdlTrpl[1]\n        # std of Gauss model: NrlMdlTrpl[2]\n        # index of tng crv model: NrlMdlTrpl[3]\n        varTmpX = int(np.around(NrlMdlTrpl[0], 0))\n        varTmpY = int(np.around(NrlMdlTrpl[1], 0))\n\n        # Create pRF model (2D):\n        aryGauss = funcGauss2D(varPixX,\n                               varPixY,\n                               varTmpX,\n                               varTmpY,\n                               NrlMdlTrpl[2])\n\n        # Multiply pixel-wise box car model with Gaussian pRF models:\n        aryNrlTcTmp = np.multiply(aryBoxCar, aryGauss[:, :, None, None])\n\n        # Calculate sum across x- and y-dimensions - the 'area under the\n        # Gaussian surface'. This is essentially an unscaled version of the\n        # neural time course model (i.e. not yet scaled for the size of\n        # the pRF).\n        aryNrlTcTmp = np.sum(aryNrlTcTmp, axis=(0, 1))\n\n        # Normalise the nrl time course model to the size of the pRF. This\n        # gives us the ratio of 'activation' of the pRF at each time point,\n        # or, in other words, the neural time course model.\n        aryNrlTcTmp = np.divide(aryNrlTcTmp,\n                                np.sum(aryGauss, axis=(0, 1)))\n\n        # Put model time courses into the function's output array:\n        aryOut[idx, :, :] = aryNrlTcTmp\n\n        # Status indicator (only used in the first of the parallel\n        # processes):\n        if idxPrc == 1:\n            # Increment status indicator counter:\n            varCntSts02 = varCntSts02 + 1\n\n    # Output list:\n    lstOut = [idxPrc,\n              aryOut,\n              ]\n\n    queOut.put(lstOut)", "response": "This function is used to create neural time courses for every motion direction."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions for finding best pRF model for voxel time course. This function should be used if there is only one predictor.", "response": "def funcFindPrf(idxPrc,\n                aryFuncChnk,\n                aryPrfTc,\n                aryMdls,\n                queOut):\n\n    \"\"\"\n    Function for finding best pRF model for voxel time course.\n    This function should be used if there is only one predictor.\n    \"\"\"\n\n    # Number of voxels to be fitted in this chunk:\n    varNumVoxChnk = aryFuncChnk.shape[0]\n\n    # Number of volumes:\n    varNumVol = aryFuncChnk.shape[1]\n\n    # Vectors for pRF finding results [number-of-voxels times one]:\n    vecBstXpos = np.zeros(varNumVoxChnk)\n    vecBstYpos = np.zeros(varNumVoxChnk)\n    vecBstSd = np.zeros(varNumVoxChnk)\n    # vecBstR2 = np.zeros(varNumVoxChnk)\n\n    # Vector for best R-square value. For each model fit, the R-square value is\n    # compared to this, and updated if it is lower than the best-fitting\n    # solution so far. We initialise with an arbitrary, high value\n    vecBstRes = np.add(np.zeros(varNumVoxChnk),\n                       100000.0)\n\n    # We reshape the voxel time courses, so that time goes down the column,\n    # i.e. from top to bottom.\n    aryFuncChnk = aryFuncChnk.T\n\n    # Constant term for the model:\n    vecConst = np.ones((varNumVol), dtype=np.float32)\n\n    # Change type to float 32:\n    aryFuncChnk = aryFuncChnk.astype(np.float32)\n    aryPrfTc = aryPrfTc.astype(np.float32)\n\n    # Number of pRF models to fit:\n    varNumMdls = len(aryMdls)\n\n    # Prepare status indicator if this is the first of the parallel processes:\n    if idxPrc == 0:\n\n        # We create a status indicator for the time consuming pRF model finding\n        # algorithm. Number of steps of the status indicator:\n        varStsStpSze = 20\n\n        # Vector with pRF values at which to give status feedback:\n        vecStatPrf = np.linspace(0,\n                                 varNumMdls,\n                                 num=(varStsStpSze+1),\n                                 endpoint=True)\n        vecStatPrf = np.ceil(vecStatPrf)\n        vecStatPrf = vecStatPrf.astype(int)\n\n        # Vector with corresponding percentage values at which to give status\n        # feedback:\n        vecStatPrc = np.linspace(0,\n                                 100,\n                                 num=(varStsStpSze+1),\n                                 endpoint=True)\n        vecStatPrc = np.ceil(vecStatPrc)\n        vecStatPrc = vecStatPrc.astype(int)\n\n        # Counter for status indicator:\n        varCntSts01 = 0\n        varCntSts02 = 0\n\n    # Loop through pRF models:\n    for idxMdls in range(0, varNumMdls):\n\n        # Status indicator (only used in the first of the parallel\n        # processes):\n        if idxPrc == 0:\n\n            # Status indicator:\n            if varCntSts02 == vecStatPrf[varCntSts01]:\n\n                # Prepare status message:\n                strStsMsg = ('---------Progress: ' +\n                             str(vecStatPrc[varCntSts01]) +\n                             ' % --- ' +\n                             str(vecStatPrf[varCntSts01]) +\n                             ' pRF models out of ' +\n                             str(varNumMdls))\n\n                print(strStsMsg)\n\n                # Only increment counter if the last value has not been\n                # reached yet:\n                if varCntSts01 < varStsStpSze:\n                    varCntSts01 = varCntSts01 + int(1)\n\n        # Current pRF time course model:\n        vecMdlTc = aryPrfTc[idxMdls, :].flatten()\n\n        # We create a design matrix including the current pRF time\n        # course model, and a constant term:\n        aryDsgn = np.vstack([vecMdlTc,\n                             vecConst]).T\n\n        # Calculation of the ratio of the explained variance (R square)\n        # for the current model for all voxel time courses.\n\n#                print('------------np.linalg.lstsq on pRF: ' +\n#                      str(idxX) +\n#                      'x ' +\n#                      str(idxY) +\n#                      'y ' +\n#                      str(idxSd) +\n#                      'z --- START')\n#                varTmeTmp01 = time.time()\n\n        # Change type to float32:\n        # aryDsgn = aryDsgn.astype(np.float32)\n\n        # Calculate the least-squares solution for all voxels:\n        vecTmpRes = np.linalg.lstsq(aryDsgn, aryFuncChnk)[1]\n\n#                varTmeTmp02 = time.time()\n#                varTmeTmp03 = np.around((varTmeTmp02 - varTmeTmp01),\n#                                        decimals=2)\n#                print('------------np.linalg.lstsq on pRF: ' +\n#                      str(idxX) +\n#                      'x ' +\n#                      str(idxY) +\n#                      'y ' +\n#                      str(idxSd) +\n#                      'z --- DONE elapsed time: ' +\n#                      str(varTmeTmp03) +\n#                      's')\n\n        # Check whether current residuals are lower than previously\n        # calculated ones:\n        vecLgcTmpRes = np.less(vecTmpRes, vecBstRes)\n\n        # Replace best x and y position values, and SD values.\n        vecBstXpos[vecLgcTmpRes] = aryMdls[idxMdls][0]\n        vecBstYpos[vecLgcTmpRes] = aryMdls[idxMdls][1]\n        vecBstSd[vecLgcTmpRes] = aryMdls[idxMdls][2]\n\n        # Replace best residual values:\n        vecBstRes[vecLgcTmpRes] = vecTmpRes[vecLgcTmpRes]\n\n#                varTmeTmp04 = time.time()\n#                varTmeTmp05 = np.around((varTmeTmp04 - varTmeTmp02),\n#                                        decimals=2)\n#                print('------------selection of best-fitting pRF model: ' +\n#                      str(idxX) +\n#                      'x ' +\n#                      str(idxY) +\n#                      'y ' +\n#                      str(idxSd) +\n#                      'z --- elapsed time: ' +\n#                      str(varTmeTmp05) +\n#                      's')\n\n        # Status indicator (only used in the first of the parallel\n        # processes):\n        if idxPrc == 0:\n\n            # Increment status indicator counter:\n            varCntSts02 = varCntSts02 + 1\n\n    # After finding the best fitting model for each voxel, we still have to\n    # calculate the coefficient of determination (R-squared) for each voxel. We\n    # start by calculating the total sum of squares (i.e. the deviation of the\n    # data from the mean). The mean of each time course:\n    vecFuncMean = np.mean(aryFuncChnk, axis=0)\n    # Deviation from the mean for each datapoint:\n    vecFuncDev = np.subtract(aryFuncChnk, vecFuncMean[None, :])\n    # Sum of squares:\n    vecSsTot = np.sum(np.power(vecFuncDev,\n                               2.0),\n                      axis=0)\n    # Coefficient of determination:\n    vecBstR2 = np.subtract(1.0,\n                           np.divide(vecBstRes,\n                                     vecSsTot))\n\n    # Output list:\n    lstOut = [idxPrc,\n              vecBstXpos,\n              vecBstYpos,\n              vecBstSd,\n              vecBstR2]\n\n    queOut.put(lstOut)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef funcFindPrfMltpPrdXVal(idxPrc,\n                           aryFuncChnkTrn,\n                           aryFuncChnkTst,\n                           aryPrfMdlsTrnConv,\n                           aryPrfMdlsTstConv,\n                           aryMdls,\n                           queOut):\n    \"\"\"\n    Function for finding best pRF model for voxel time course.\n    This function should be used if there are several predictors.\n    \"\"\"\n\n    # Number of voxels to be fitted in this chunk:\n    varNumVoxChnk = aryFuncChnkTrn.shape[0]\n\n    # Number of volumes:\n    varNumVolTrn = aryFuncChnkTrn.shape[2]\n    varNumVolTst = aryFuncChnkTst.shape[2]\n\n    # get number of cross validations\n    varNumXval = aryPrfMdlsTrnConv.shape[2]\n\n    # Vectors for pRF finding results [number-of-voxels times one]:\n    vecBstXpos = np.zeros(varNumVoxChnk)\n    vecBstYpos = np.zeros(varNumVoxChnk)\n    vecBstSd = np.zeros(varNumVoxChnk)\n    # vecBstR2 = np.zeros(varNumVoxChnk)\n\n    # Vector for temporary residuals values that are obtained during\n    # the different loops of cross validation\n    vecTmpResXVal = np.empty((varNumVoxChnk, varNumXval), dtype='float32')\n\n    # Vector for best residual values.\n    vecBstRes = np.add(np.zeros(varNumVoxChnk),\n                       100000.0)\n\n    # Constant term for the model:\n    vecConstTrn = np.ones((varNumVolTrn), dtype=np.float32)\n    vecConstTst = np.ones((varNumVolTst), dtype=np.float32)\n\n    # Change type to float 32:\n    aryPrfMdlsTrnConv = aryPrfMdlsTrnConv.astype(np.float32)\n    aryPrfMdlsTstConv = aryPrfMdlsTstConv.astype(np.float32)\n\n    # Number of pRF models to fit:\n    varNumMdls = len(aryMdls)\n\n    # Prepare status indicator if this is the first of the parallel processes:\n    if idxPrc == 0:\n\n        # We create a status indicator for the time consuming pRF model finding\n        # algorithm. Number of steps of the status indicator:\n        varStsStpSze = 20\n\n        # Vector with pRF values at which to give status feedback:\n        vecStatPrf = np.linspace(0,\n                                 varNumMdls,\n                                 num=(varStsStpSze+1),\n                                 endpoint=True)\n        vecStatPrf = np.ceil(vecStatPrf)\n        vecStatPrf = vecStatPrf.astype(int)\n\n        # Vector with corresponding percentage values at which to give status\n        # feedback:\n        vecStatPrc = np.linspace(0,\n                                 100,\n                                 num=(varStsStpSze+1),\n                                 endpoint=True)\n        vecStatPrc = np.ceil(vecStatPrc)\n        vecStatPrc = vecStatPrc.astype(int)\n\n        # Counter for status indicator:\n        varCntSts01 = 0\n        varCntSts02 = 0\n\n    # Loop through pRF models:\n    for idxMdls in range(0, varNumMdls):\n\n        # Status indicator (only used in the first of the parallel\n        # processes):\n        if idxPrc == 0:\n\n            # Status indicator:\n            if varCntSts02 == vecStatPrf[varCntSts01]:\n\n                # Prepare status message:\n                strStsMsg = ('---------Progress: ' +\n                             str(vecStatPrc[varCntSts01]) +\n                             ' % --- ' +\n                             str(vecStatPrf[varCntSts01]) +\n                             ' pRF models out of ' +\n                             str(varNumMdls))\n\n                print(strStsMsg)\n\n                # Only increment counter if the last value has not been\n                # reached yet:\n                if varCntSts01 < varStsStpSze:\n                    varCntSts01 = varCntSts01 + int(1)\n\n        # Loop through different cross validations\n        for idxXval in range(0, varNumXval):\n            # Current pRF time course model:\n            vecMdlTrn = aryPrfMdlsTrnConv[idxMdls, :, idxXval, :]\n            vecMdlTst = aryPrfMdlsTstConv[idxMdls, :, idxXval, :]\n\n            # We create a design matrix including the current pRF time\n            # course model, and a constant term:\n            aryDsgnTrn = np.vstack([vecMdlTrn,\n                                    vecConstTrn]).T\n\n            aryDsgnTst = np.vstack([vecMdlTst,\n                                    vecConstTst]).T\n\n            # Calculate the least-squares solution for all voxels\n            # and get parameter estimates from the training fit\n            aryTmpPrmEst = np.linalg.lstsq(aryDsgnTrn,\n                                           aryFuncChnkTrn[:, idxXval, :].T)[0]\n            # calculate predicted model fit based on training data\n            aryTmpMdlTc = np.dot(aryDsgnTst, aryTmpPrmEst)\n            # calculate residual sum of squares between test data and\n            # predicted model fit based on training data\n            vecTmpResXVal[:, idxXval] = np.sum(\n                (np.subtract(aryFuncChnkTst[:, idxXval, :].T,\n                             aryTmpMdlTc))**2, axis=0)\n\n        vecTmpRes = np.mean(vecTmpResXVal, axis=1)\n        # Check whether current residuals are lower than previously\n        # calculated ones:\n        vecLgcTmpRes = np.less(vecTmpRes, vecBstRes)\n\n        # Replace best x and y position values, and SD values.\n        vecBstXpos[vecLgcTmpRes] = aryMdls[idxMdls][0]\n        vecBstYpos[vecLgcTmpRes] = aryMdls[idxMdls][1]\n        vecBstSd[vecLgcTmpRes] = aryMdls[idxMdls][2]\n\n        # Replace best residual values:\n        vecBstRes[vecLgcTmpRes] = vecTmpRes[vecLgcTmpRes]\n\n        # Status indicator (only used in the first of the parallel\n        # processes):\n        if idxPrc == 0:\n\n            # Increment status indicator counter:\n            varCntSts02 = varCntSts02 + 1\n\n    # Output list:\n    lstOut = [idxPrc,\n              vecBstXpos,\n              vecBstYpos,\n              vecBstSd,\n              ]\n\n    queOut.put(lstOut)", "response": "This function finds the best pRF model for voxel time course."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef move_images_to_cache(source, destination):\n    if os.path.isdir(destination):\n        log.debug('Cached images for this article already exist')\n        return\n    else:\n        log.debug('Cache location: {0}'.format(destination))\n        try:\n            shutil.copytree(source, destination)\n        except:\n            log.exception('Images could not be moved to cache')\n        else:\n            log.info('Moved images to cache'.format(destination))", "response": "Handles the movement of images to the cache."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef image_cache(article_cache, img_dir):\n    log.debug('Looking for image directory in the cache')\n    if os.path.isdir(article_cache):\n        log.info('Cached image directory found: {0}'.format(article_cache))\n        shutil.copytree(article_cache, img_dir)\n        return True\n    return False", "response": "This method is used by get_images to copy images out of the cache."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_image_cache(img_cache):\n    log.info('Initiating the image cache at {0}'.format(img_cache))\n    if not os.path.isdir(img_cache):\n        utils.mkdir_p(img_cache)\n        utils.mkdir_p(os.path.join(img_cache, '10.1371'))\n        utils.mkdir_p(os.path.join(img_cache, '10.3389'))", "response": "Create the image cache if it does not exist"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfetches the images from Frontiers website and store them in output_dir.", "response": "def fetch_frontiers_images(doi, output_dir):\n    \"\"\"\n    Fetch the images from Frontiers' website. This method may fail to properly\n    locate all the images and should be avoided if the files can be accessed\n    locally. Downloading the images to an appropriate directory in the cache,\n    or to a directory specified by passed argument are the preferred means to\n    access images.\n    \"\"\"\n    log.info('Fetching Frontiers images')\n    log.warning('This method may fail to locate all images.')\n\n    def download_image(fetch, img_file):\n        try:\n            image = urllib.request.urlopen(fetch)\n        except urllib.error.HTTPError as e:\n            if e.code == 503:  # Server overloaded\n                time.sleep(1)  # Wait one second\n                try:\n                    image = urllib.request.urlopen(fetch)\n                except:\n                    return None\n            elif e.code == 500:\n                print('urllib.error.HTTPError {0}'.format(e.code))\n            return None\n        else:\n            with open(img_file, 'wb') as outimage:\n                outimage.write(image.read())\n        return True\n\n    def check_equation_completion(images):\n        \"\"\"\n        In some cases, equations images are not exposed in the fulltext (hidden\n        behind a rasterized table). This attempts to look for gaps and fix them\n        \"\"\"\n        log.info('Checking for complete equations')\n        files = os.listdir(output_dir)\n        inline_equations = []\n        for e in files:\n            if e[0] == 'i':\n                inline_equations.append(e)\n        missing = []\n        highest = 0\n        if inline_equations:\n            inline_equations.sort()\n            highest = int(inline_equations[-1][1:4])\n            i = 1\n            while i < highest:\n                name = 'i{0}.gif'.format(str(i).zfill(3))\n                if name not in inline_equations:\n                    missing.append(name)\n                i += 1\n        get = images[0][:-8]\n        for m in missing:\n            loc = os.path.join(output_dir, m)\n            download_image(get + m, loc)\n            print('Downloaded image {0}'.format(loc))\n        #It is possible that we need to go further than the highest\n        highest += 1\n        name = 'i{0}.gif'.format(str(highest).zfill(3))\n        loc = os.path.join(output_dir, name)\n        while download_image(get + name, loc):\n            print('Downloaded image {0}'.format(loc))\n            highest += 1\n            name = 'i{0}.gif'.format(str(highest).zfill(3))\n\n    print('Processing images for {0}...'.format(doi))\n    #We use the DOI of the article to locate the page.\n    doistr = 'http://dx.doi.org/{0}'.format(doi)\n    logging.debug('Accessing DOI address-{0}'.format(doistr))\n    page = urllib.request.urlopen(doistr)\n    if page.geturl()[-8:] == 'abstract':\n        full = page.geturl()[:-8] + 'full'\n    elif page.geturl()[-4:] == 'full':\n        full = page.geturl()\n    print(full)\n    page = urllib.request.urlopen(full)\n    with open('temp', 'w') as temp:\n        temp.write(page.read())\n    images = []\n    with open('temp', 'r') as temp:\n        for l in temp.readlines():\n            images += re.findall('<a href=\"(?P<href>http://\\w{7}.\\w{3}.\\w{3}.rackcdn.com/\\d{5}/f\\w{4}-\\d{2}-\\d{5}-HTML/image_m/f\\w{4}-\\d{2}-\\d{5}-\\D{1,2}\\d{3}.\\D{3})', l)\n            images += re.findall('<a href=\"(?P<href>http://\\w{7}.\\w{3}.\\w{3}.rackcdn.com/\\d{5}/f\\w{4}-\\d{2}-\\d{5}-r2/image_m/f\\w{4}-\\d{2}-\\d{5}-\\D{1,2}\\d{3}.\\D{3})', l)\n            images += re.findall('<img src=\"(?P<src>http://\\w{7}.\\w{3}.\\w{3}.rackcdn.com/\\d{5}/f\\w{4}-\\d{2}-\\d{5}-HTML/image_n/f\\w{4}-\\d{2}-\\d{5}-\\D{1,2}\\d{3}.\\D{3})', l)\n    os.remove('temp')\n    for i in images:\n        loc = os.path.join(output_dir, i.split('-')[-1])\n        download_image(i, loc)\n        print('Downloaded image {0}'.format(loc))\n    if images:\n        check_equation_completion(images)\n    print(\"Done downloading images\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fetch_plos_images(article_doi, output_dir, document):\n    log.info('Processing images for {0}...'.format(article_doi))\n\n    #A dict of URLs for PLoS subjournals\n    journal_urls = {'pgen': 'http://www.plosgenetics.org/article/{0}',\n                    'pcbi': 'http://www.ploscompbiol.org/article/{0}',\n                    'ppat': 'http://www.plospathogens.org/article/{0}',\n                    'pntd': 'http://www.plosntds.org/article/{0}',\n                    'pmed': 'http://www.plosmedicine.org/article/{0}',\n                    'pbio': 'http://www.plosbiology.org/article/{0}',\n                    'pone': 'http://www.plosone.org/article/{0}',\n                    'pctr': 'http://clinicaltrials.ploshubs.org/article/{0}'}\n\n    #Identify subjournal name for base URL\n    subjournal_name = article_doi.split('.')[1]\n    base_url = journal_urls[subjournal_name]\n\n    #Acquire <graphic> and <inline-graphic> xml elements\n    graphics = document.document.getroot().findall('.//graphic')\n    graphics += document.document.getroot().findall('.//inline-graphic')\n\n    #Begin to download\n    log.info('Downloading images, this may take some time...')\n    for graphic in graphics:\n        nsmap = document.document.getroot().nsmap\n        xlink_href = graphic.attrib['{' + nsmap['xlink'] + '}' + 'href']\n\n        #Equations are handled a bit differently than the others\n        #Here we decide that an image name starting with \"e\" is an equation\n        if xlink_href.split('.')[-1].startswith('e'):\n            resource = 'fetchObject.action?uri=' + xlink_href + '&representation=PNG'\n        else:\n            resource = xlink_href + '/largerimage'\n        full_url = base_url.format(resource)\n        try:\n            image = urllib.request.urlopen(full_url)\n        except urllib.error.HTTPError as e:\n            if e.code == 503:  # Server overload error\n                time.sleep(1)  # Wait a second\n                try:\n                    image = urllib.request.urlopen(full_url)\n                except:\n                    return False  # Happened twice, give up\n            else:\n                log.error('urllib.error.HTTPError {0}'.format(e.code))\n                return False\n        else:\n            img_name = xlink_href.split('.')[-1] + '.png'\n            img_path = os.path.join(output_dir, img_name)\n            with open(img_path, 'wb') as output:\n                output.write(image.read())\n            log.info('Downloaded image {0}'.format(img_name))\n    log.info('Done downloading images')\n    return True", "response": "Fetch the images for a PLoS article from the internet."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_tc_to_nii(strCsvCnfg, lgcTest=False, lstRat=None, lgcMdlRsp=False,\n                   strPathHrf=None, lgcSaveRam=False):\n    \"\"\"\n    Save empirical and fitted time courses to nii file format.\n\n    Parameters\n    ----------\n    strCsvCnfg : str\n        Absolute file path of config file used for pRF fitting.\n    lgcTest : boolean\n        Whether this is a test (pytest). If yes, absolute path of pyprf libary\n        will be prepended to config file paths.\n    lstRat : None or list\n        Ratio of size of center to size of suppressive surround.\n    lgcMdlRsp : boolean\n        Should the aperture responses for the winner model also be saved?\n    strPathHrf : str or None:\n        Path to npy file with custom hrf parameters. If None, defaults\n        parameters were used.\n    lgcSaveRam : boolean\n        Whether to also save a nii file that uses little RAM.\n\n    Notes\n    -----\n    This function does not return any arguments but, instead, saves nii files\n    to disk.\n\n    \"\"\"\n\n    # %% Load configuration settings that were used for fitting\n\n    # Load config parameters from csv file into dictionary:\n    dicCnfg = load_config(strCsvCnfg, lgcTest=lgcTest)\n\n    # Load config parameters from dictionary into namespace:\n    cfg = cls_set_config(dicCnfg)\n\n    # if fitting was done with custom hrf, make sure to retrieve results with\n    # '_hrf' appendix\n    if strPathHrf is not None:\n        cfg.strPathOut = cfg.strPathOut + '_hrf'\n\n    # If suppressive surround flag is on, make sure to retrieve results with\n    # '_supsur' appendix\n    if lstRat is not None:\n        cfg.strPathOut = cfg.strPathOut + '_supsur'\n        cfg.strPathMdl = cfg.strPathMdl + '_supsur'\n        # Append 1.0 as the first entry, which is the key for fitting without\n        # surround (only centre)\n        lstRat.insert(0, 1.0)\n\n    # %% Load previous pRF fitting results\n\n    # Derive paths to the x, y, sigma winner parameters from pyprf_feature\n    lstWnrPrm = [cfg.strPathOut + '_x_pos.nii.gz',\n                 cfg.strPathOut + '_y_pos.nii.gz',\n                 cfg.strPathOut + '_SD.nii.gz']\n\n    # Check if fitting has been performed, i.e. whether parameter files exist\n    # Throw error message if they do not exist.\n    errorMsg = 'Files that should have resulted from fitting do not exist. \\\n                \\nPlease perform pRF fitting first, calling  e.g.: \\\n                \\npyprf_feature -config /path/to/my_config_file.csv'\n    assert os.path.isfile(lstWnrPrm[0]), errorMsg\n    assert os.path.isfile(lstWnrPrm[1]), errorMsg\n    assert os.path.isfile(lstWnrPrm[2]), errorMsg\n\n    # Load the x, y, sigma winner parameters from pyprf_feature\n    aryIntGssPrm = load_res_prm(lstWnrPrm,\n                                lstFlsMsk=[cfg.strPathNiiMask])[0][0]\n\n    # Load beta parameters estimates, aka weights for time courses\n    lstPathBeta = [cfg.strPathOut + '_Betas.nii.gz']\n    aryBetas = load_res_prm(lstPathBeta, lstFlsMsk=[cfg.strPathNiiMask])[0][0]\n    assert os.path.isfile(lstPathBeta[0]), errorMsg\n\n    # Load ratio image, if fitting was obtained with suppressive surround\n    if lstRat is not None:\n        lstPathRatio = [cfg.strPathOut + '_Ratios.nii.gz']\n        aryRatio = load_res_prm(lstPathRatio,\n                                lstFlsMsk=[cfg.strPathNiiMask])[0][0]\n        assert os.path.isfile(lstPathRatio[0]), errorMsg\n\n    # Some voxels were excluded because they did not have sufficient mean\n    # and/or variance - exclude their initial parameters, too\n    # Get inclusion mask and nii header\n    aryLgcMsk, aryLgcVar, hdrMsk, aryAff, aryFunc, tplNiiShp = prep_func(\n        cfg.strPathNiiMask, cfg.lstPathNiiFunc, varAvgThr=-100)\n    # Apply inclusion mask\n    aryIntGssPrm = aryIntGssPrm[aryLgcVar, :]\n    aryBetas = aryBetas[aryLgcVar, :]\n    if lstRat is not None:\n        aryRatio = aryRatio[aryLgcVar, :]\n\n    # Get array with model parameters that were fitted on a grid\n    # [x positions, y positions, sigmas]\n    aryMdlParams = crt_mdl_prms((int(cfg.varVslSpcSzeX),\n                                int(cfg.varVslSpcSzeY)), cfg.varNum1,\n                                cfg.varExtXmin, cfg.varExtXmax, cfg.varNum2,\n                                cfg.varExtYmin, cfg.varExtYmax,\n                                cfg.varNumPrfSizes, cfg.varPrfStdMin,\n                                cfg.varPrfStdMax, kwUnt='deg',\n                                kwCrd=cfg.strKwCrd)\n    # Load logical for parameter exclusion in unstimulated area\n    lgcMdlInc = np.load(cfg.strPathMdl + '_lgcMdlInc.npy')\n    # Apply logical\n    aryMdlParams = aryMdlParams[lgcMdlInc, :]\n\n    # Get corresponding pRF model time courses\n    aryPrfTc = np.load(cfg.strPathMdl + '.npy')\n\n    # The model time courses will be preprocessed such that they are smoothed\n    # (temporally) with same factor as the data and that they will be z-scored:\n    aryPrfTc = prep_models(aryPrfTc, varSdSmthTmp=cfg.varSdSmthTmp)\n\n    if lgcMdlRsp:\n        aryMdlRsp = np.load(cfg.strPathMdl + '_mdlRsp.npy')\n\n    # %% Derive fitted time course models for all voxels\n\n    # Initialize array that will collect the fitted time courses\n    aryFitTc = np.zeros((aryFunc.shape), dtype=np.float32)\n    # If desired, initiliaze array that will collect model responses underlying\n    # the fitted time course\n    if lgcMdlRsp:\n        if lstRat is not None:\n            aryFitMdlRsp = np.zeros((aryIntGssPrm.shape[0], aryMdlRsp.shape[1],\n                                     aryMdlRsp.shape[3]),\n                                    dtype=np.float32)\n        else:\n            aryFitMdlRsp = np.zeros((aryIntGssPrm.shape[0],\n                                     aryMdlRsp.shape[1]), dtype=np.float32)\n\n    # create vector that allows to check whether every voxel is visited\n    # exactly once\n    vecVxlTst = np.zeros(aryIntGssPrm.shape[0])\n\n    # Find unique rows of fitted model parameters\n    aryUnqRows, aryUnqInd = fnd_unq_rws(aryIntGssPrm, return_index=False,\n                                        return_inverse=True)\n\n    # Loop over all best-fitting model parameter combinations found\n    print('---Assign models to voxels')\n    for indRow, vecPrm in enumerate(aryUnqRows):\n        # Get logical for voxels for which this prm combi was the best\n        lgcVxl = [aryUnqInd == indRow][0]\n        if np.all(np.invert(lgcVxl)):\n            print('---No voxel found')\n        # Mark those voxels that were visited\n        vecVxlTst[lgcVxl] += 1\n\n        # Get logical index for the model number\n        # This can only be 1 index, so we directly get 1st entry of array\n        lgcMdl = np.where(np.isclose(aryMdlParams, vecPrm,\n                                     atol=0.01).all(axis=1))[0][0]\n        # Tell user if no model was found\n        if lgcMdl is None:\n            print('---No model found')\n\n        # Get model time courses\n        aryMdlTc = aryPrfTc[lgcMdl, ...]\n        # Get beta parameter estimates\n        aryWeights = aryBetas[lgcVxl, :]\n\n        # If fitting was done with surround suppression, find ratios for voxels\n        # and the indices of these ratios in lstRat\n        if lstRat is not None:\n            aryVxlRatio = aryRatio[lgcVxl, :]\n            indRat = [ind for ind, rat1 in enumerate(lstRat) for rat2 in\n                      aryVxlRatio[:, 0] if np.isclose(rat1, rat2)]\n            indVxl = range(len(indRat))\n\n        # Combine model time courses and weights to yield fitted time course\n        if lstRat is not None:\n            aryFitTcTmp = np.tensordot(aryWeights, aryMdlTc, axes=([1], [0]))\n            aryFitTc[lgcVxl, :] = aryFitTcTmp[indVxl, indRat, :]\n        else:\n            aryFitTc[lgcVxl, :] = np.dot(aryWeights, aryMdlTc)\n\n        # If desired by user, also save the model responses per voxels\n        if lgcMdlRsp:\n            # If desired also save the model responses that won\n            if lstRat is not None:\n                aryFitMdlRsp[lgcVxl, :] = aryMdlRsp[lgcMdl, :, indRat, :]\n            else:\n                aryFitMdlRsp[lgcVxl, :] = aryMdlRsp[lgcMdl, :]\n\n    # check that every voxel was visited exactly once\n    errMsg = 'At least one voxel visited more than once for tc recreation'\n    assert len(vecVxlTst) == np.sum(vecVxlTst), errMsg\n\n    # %% Export preprocessed voxel time courses as nii\n\n    # List with name suffices of output images:\n    lstNiiNames = ['_EmpTc']\n\n    # Create full path names from nii file names and output path\n    lstNiiNames = [cfg.strPathOut + strNii + '.nii.gz' for strNii in\n                   lstNiiNames]\n\n    # export aryFunc as a single 4D nii file\n    print('---Save empirical time courses')\n    export_nii(aryFunc, lstNiiNames, aryLgcMsk, aryLgcVar, tplNiiShp,\n               aryAff, hdrMsk, outFormat='4D')\n    print('------Done.')\n\n    # If desired by user, also save RAM-saving version of nii\n    if lgcSaveRam:\n        strPthRamOut = cfg.strPathOut + '_EmpTc_saveRAM' + '.nii.gz'\n        imgNii = nb.Nifti1Image(np.expand_dims(np.expand_dims(aryFunc, axis=1),\n                                               axis=1),\n                                affine=np.eye(4))\n        nb.save(imgNii, strPthRamOut)\n\n    # %% Export fitted time courses and, if desired, model responses as nii\n\n    # List with name suffices of output images:\n    lstNiiNames = ['_FitTc']\n\n    # Create full path names from nii file names and output path\n    lstNiiNames = [cfg.strPathOut + strNii + '.nii.gz' for strNii in\n                   lstNiiNames]\n\n    # export aryFitTc as a single 4D nii file\n    print('---Save fitted time courses')\n    export_nii(aryFitTc, lstNiiNames, aryLgcMsk, aryLgcVar, tplNiiShp,\n               aryAff, hdrMsk, outFormat='4D')\n    print('------Done.')\n\n    if lgcMdlRsp:\n\n        # Create full path name\n        strNpyName = cfg.strPathOut + '_FitMdlRsp' + '.npy'\n\n        # Save aryFitMdlRsp as npy file\n        print('---Save fitted model responses')\n        np.save(strNpyName, aryFitMdlRsp)\n        print('------Done.')\n\n        # Save the mask so we know which voxels these parameters belonged to\n        strNpyMskName = cfg.strPathOut + '_FitMdlRsp_Mask' + '.npy'\n        aryLgcMsk[aryLgcMsk] = aryLgcVar\n        print('---Save mask for fitted model responses')\n        np.save(strNpyMskName, aryLgcMsk)\n        print('------Done.')\n\n    # If desired by user, also save RAM-saving version of nii\n    if lgcSaveRam:\n        strPthRamOut = cfg.strPathOut + '_FitTc_saveRAM' + '.nii.gz'\n        imgNii = nb.Nifti1Image(np.expand_dims(np.expand_dims(aryFitTc,\n                                                              axis=1),\n                                               axis=1),\n                                affine=np.eye(4))\n        nb.save(imgNii, strPthRamOut)", "response": "Save empirical and fitted time courses to nii file format."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsimulates pRF response given pRF parameters and stimulus apertures.", "response": "def pyprf_sim(strPrior, strStmApr, lgcNoise=False, lgcRtnNrl=True,\n              lstRat=None, lgcTest=False):\n    \"\"\"\n    Simulate pRF response given pRF parameters and stimulus apertures.\n\n    Parameters\n    ----------\n    strPrior : str\n        Absolute file path of config file used for pRF fitting.\n    strStmApr : str\n        Absolute file path to stimulus aperture used in in-silico experiment.\n    lgcNoise : boolean\n        Should noise be added to the simulated pRF time course. By default, no\n        noise is added.\n    lgcRtnNrl : boolean\n        Should neural time course, unconvolved with hrf, be returned as well?\n    lstRat : None or list\n        Ratio of size of center to size of suppressive surround.\n    lgcTest : boolean\n        Whether this is a test (pytest). If yes, absolute path of pyprf libary\n        will be prepended to config file paths.\n\n    Notes\n    -----\n    [1] This function does not return any arguments but, instead, saves nii\n        filex to disk.\n    [2] strStmApr should be a path to a npy file that contains a 3D numpy\n        array. This arrays consists of binary images in boolean array from that\n        represent the stimulus aperture. Images are stacked along last axis.\n\n    \"\"\"\n\n    # %% Load configuration settings that were used for fitting\n\n    # Load config parameters from csv file into dictionary:\n    dicCnfg = load_config(strPrior, lgcTest=lgcTest)\n\n    # Load config parameters from dictionary into namespace:\n    cfg = cls_set_config(dicCnfg)\n\n    # If suppressive surround flag is on, make sure to retrieve results from\n    # that fitting\n    if lstRat is not None:\n        cfg.strPathOut = cfg.strPathOut + '_supsur'\n\n    # %% Load previous pRF fitting results\n\n    # Derive paths to the x, y, sigma winner parameters from pyprf_feature\n    lstWnrPrm = [cfg.strPathOut + '_x_pos.nii.gz',\n                 cfg.strPathOut + '_y_pos.nii.gz',\n                 cfg.strPathOut + '_SD.nii.gz']\n\n    # Check if fitting has been performed, i.e. whether parameter files exist\n    # Throw error message if they do not exist.\n    errorMsg = 'Files that should have resulted from fitting do not exist. \\\n                \\nPlease perform pRF fitting first, calling  e.g.: \\\n                \\npyprf_feature -config /path/to/my_config_file.csv'\n    assert os.path.isfile(lstWnrPrm[0]), errorMsg\n    assert os.path.isfile(lstWnrPrm[1]), errorMsg\n    assert os.path.isfile(lstWnrPrm[2]), errorMsg\n\n    # Load the x, y, sigma winner parameters from pyprf_feature\n    aryIntGssPrm = load_res_prm(lstWnrPrm,\n                                lstFlsMsk=[cfg.strPathNiiMask])[0][0]\n\n    # Also load suppresive surround params if suppressive surround flag was on\n    if lstRat is not None:\n        # Load beta parameters estimates, aka weights, this is later needed to\n        # scale responses of the center wrt to the surround\n        lstPathBeta = [cfg.strPathOut + '_Betas.nii.gz']\n        aryBetas = load_res_prm(lstPathBeta,\n                                lstFlsMsk=[cfg.strPathNiiMask])[0][0]\n        # Load ratio of prf sizes\n        lstPathRat = [cfg.strPathOut + '_Ratios.nii.gz']\n        aryRat = load_res_prm(lstPathRat, lstFlsMsk=[cfg.strPathNiiMask])[0][0]\n\n    # Some voxels were excluded because they did not have sufficient mean\n    # and/or variance - exclude their initial parameters, too\n    # Get inclusion mask and nii header\n    aryLgcMsk, aryLgcVar, hdrMsk, aryAff, _, tplNiiShp = prep_func(\n        cfg.strPathNiiMask, cfg.lstPathNiiFunc, varAvgThr=100.)\n    # Apply inclusion mask\n    aryIntGssPrm = aryIntGssPrm[aryLgcVar, :]\n    if lstRat is not None:\n        aryBetas = aryBetas[aryLgcVar, :]\n        aryRat = aryRat[aryLgcVar]\n\n    # %% Load stimulus aperture and create model responses to stimuli\n\n    # Load stimulus aperture\n    aryStmApr = np.load(strStmApr)\n    # Which dimensions does the representation have in pixel space?\n    tplStmApr = aryStmApr.shape[:2]\n\n    # Convert winner parameters from degrees of visual angle to pixel\n    vecIntX, vecIntY, vecIntSd = rmp_deg_pixel_xys(aryIntGssPrm[:, 0],\n                                                   aryIntGssPrm[:, 1],\n                                                   aryIntGssPrm[:, 2],\n                                                   tplStmApr,\n                                                   cfg.varExtXmin,\n                                                   cfg.varExtXmax,\n                                                   cfg.varExtYmin,\n                                                   cfg.varExtYmax)\n\n    aryIntGssPrmPxl = np.column_stack((vecIntX, vecIntY, vecIntSd))\n\n    # Create 2D Gauss model responses to spatial conditions.\n    print('---Create 2D Gauss model responses to spatial conditions')\n    aryMdlRsp = crt_mdl_rsp(aryStmApr, tplStmApr, aryIntGssPrmPxl, cfg.varPar)\n\n    # If supsur flag was provided, also create responses with supsur params\n    # and combine positive center response with negative surround response\n    if lstRat is not None:\n        aryIntGssPrmPxlSur = np.copy(aryIntGssPrmPxl)\n        # Adjust pRF sizes using the ratio of pRF sizes\n        aryIntGssPrmPxlSur[:, 2] = np.multiply(aryIntGssPrmPxlSur[:, 2],\n                                               aryRat)\n        aryMdlRspSur = crt_mdl_rsp(aryStmApr, tplStmApr, aryIntGssPrmPxlSur,\n                                   cfg.varPar)\n        # Now the responses of the center and the surround need to be combined\n        # in a meaningful way. One way this could be done is to take the ratio\n        # of gain parameters that were found when fitting (i.e. betas)\n        varGainRat = np.divide(aryBetas[:, 0], aryBetas[:, 1])\n        aryMdlRsp = np.subtract(aryMdlRsp,\n                                np.multiply(varGainRat, aryMdlRspSur))\n\n    # %% Convolve time courses with hrf function\n\n    # First temporally upsamle the model response\n    aryMdlRspUps = np.repeat(aryMdlRsp, cfg.varTmpOvsmpl, axis=-1)\n    # Convolve with hrf function\n    arySimRsp = crt_prf_tc(aryMdlRspUps, aryMdlRsp.shape[-1], cfg.varTr,\n                           cfg.varTmpOvsmpl, 1, tplStmApr, cfg.varPar)\n    # Squeeze simulated reponse. This step is necessary because crt_prf_tc is,\n    # in principle, capable of convolving with deriavtes of canonical function\n    if arySimRsp.shape[1] > 1:\n        print('***WARNING: pyprf_sim expects 1 hrf function, currently***')\n    arySimRsp = np.squeeze(arySimRsp)\n    # Save memory by deleting upsampled time course\n    del(aryMdlRspUps)\n\n    # %% Add auto-correlated noise\n\n    if lgcNoise:\n        print('***Adding noise feature not yet implemented***')\n\n    # %% Export simulated prf, and if desired neural, time courses as nii\n\n    # List with name suffices of output images:\n    lstNiiNames = ['_SimPrfTc']\n\n    # Create full path names from nii file names and output path\n    lstNiiNames = [cfg.strPathOut + strNii + '.nii.gz' for strNii in\n                   lstNiiNames]\n\n    # export beta parameter as a single 4D nii file\n    print('---Save simulated pRF time courses')\n    export_nii(arySimRsp, lstNiiNames, aryLgcMsk, aryLgcVar, tplNiiShp,\n               aryAff, hdrMsk, outFormat='4D')\n    print('------Done.')\n\n    if lgcRtnNrl:\n\n        # List with name suffices of output images:\n        lstNiiNames = ['_SimNrlTc']\n\n        # Create full path names from nii file names and output path\n        lstNiiNames = [cfg.strPathOut + strNii + '.nii.gz' for strNii in\n                       lstNiiNames]\n\n        # export beta parameter as a single 4D nii file\n        print('---Save simulated neural time courses')\n        export_nii(aryMdlRsp, lstNiiNames, aryLgcMsk, aryLgcVar, tplNiiShp,\n                   aryAff, hdrMsk, outFormat='4D')\n        print('------Done.')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_nearest_by_numeric_key(data: dict, key: int) -> Any:\n    return data.get(key, data[min(data.keys(), key=lambda k: abs(k - key))])", "response": "Return the dict element whose numeric key is closest to a target."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resource(self, uri, methods=frozenset({'GET'}), host=None,\n                 strict_slashes=None, stream=False, version=None, name=None,\n                 **kwargs):\n        \"\"\"\n        Create a blueprint resource route from a decorated function.\n\n        :param uri: endpoint at which the route will be accessible.\n        :param methods: list of acceptable HTTP methods.\n        :param host:\n        :param strict_slashes:\n        :param version:\n        :param name: user defined route name for url_for\n        :return: function or class instance\n\n        Accepts any keyword argument that will be passed to the app resource.\n        \"\"\"\n        if strict_slashes is None:\n            strict_slashes = self.strict_slashes\n\n        def decorator(handler):\n            self.resources.append((\n                FutureRoute(handler, uri, methods, host, strict_slashes,\n                            stream, version, name),\n                kwargs))\n\n            return handler\n        return decorator", "response": "Create a blueprint resource route from a function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a blueprint resource route to the app.", "response": "def add_resource(self, handler, uri, methods=frozenset({'GET'}),\n                     host=None, strict_slashes=None, version=None, name=None,\n                     **kwargs):\n        \"\"\"\n        Create a blueprint resource route from a function.\n\n        :param uri: endpoint at which the route will be accessible.\n        :param methods: list of acceptable HTTP methods.\n        :param host:\n        :param strict_slashes:\n        :param version:\n        :param name: user defined route name for url_for\n        :return: function or class instance\n\n        Accepts any keyword argument that will be passed to the app resource.\n        \"\"\"\n        self.resource(uri=uri, methods=methods, host=host,\n                      strict_slashes=strict_slashes, version=version,\n                      name=name, **kwargs)(handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_db():\n    from .settings import settings\n    mongo = settings.MONGODB\n\n    if 'URI' in mongo and mongo['URI']:\n        uri = mongo['URI']\n    else:\n        uri = 'mongodb://'\n\n        if all(mongo.get(key) for key in ('USERNAME', 'PASSWORD')):\n            uri += '{0}:{1}@'.format(mongo['USERNAME'], mongo['PASSWORD'])\n\n        if 'HOSTS' in mongo and mongo['HOSTS']:\n            uri += ','.join(\n                '{0}:{1}'.format(host, port)\n                for (host, port) in zip(mongo['HOSTS'], mongo['PORTS']),\n            )\n        else:\n            uri += '{0}:{1}'.format(mongo['HOST'], mongo.get('PORT', 27017))\n\n        uri += '/' + mongo['DATABASE']\n\n        if 'OPTIONS' in mongo and mongo['OPTIONS']:\n            uri += '?{0}'.format('&'.join(mongo['OPTIONS']))\n\n    client = ConnectionFailureProxy(MongoClient(uri, connect=False))\n    database = client[parse_uri(uri)['database']]\n\n    return database", "response": "Returns the connection to the database using the settings. MONGODB"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates voxel betas and R^2 for the best model.", "response": "def getBetas(idxPrc,\n             aryPrfTc,\n             lstAllMdlInd,\n             aryFuncChnk,\n             aryBstIndChnk,\n             betaSw,\n             queOut):\n    \"\"\"Calculate voxel betas and R^2 for the best model.\n\n    Parameters\n    ----------\n    idxPrc : TODO\n        (?)\n    aryPrfTc : np.array, shape (?)\n        Population receptive field time courses.\n    lstAllMdlInd : list\n        List of the indices of all models.\n    aryFuncChnk : TODO\n        Chunk of something(?)\n    aryBstIndChnk : np.array, shape (?)\n        Points for every voxel to the index of the best model\n    betaSw : str, iterator, or np.array, shape (?)\n        Best beta correlation coefficients found in training.\n    queOut : TODO\n        Queue output (?)\n\n    Notes\n    -----\n    This is done after fitting with cross validation, since during the\n    fitting process, we never fit the model to the entire data.\n    \"\"\"\n\n    # get number of motion directions\n    varNumMtnDrctns = aryPrfTc.shape[3]\n    varNumVoxChnk = aryBstIndChnk.shape[0]\n    # prepare array for best beta weights\n    if type(betaSw) is sklearn.model_selection._split.KFold:\n        aryEstimMtnCrvTrn = np.zeros((varNumVoxChnk, varNumMtnDrctns,\n                                      betaSw.get_n_splits()), dtype='float32')\n        aryEstimMtnCrvTst = np.zeros((varNumVoxChnk, varNumMtnDrctns,\n                                      betaSw.get_n_splits()), dtype='float32')\n        resTrn = np.zeros((varNumVoxChnk, betaSw.get_n_splits()),\n                          dtype='float32')\n        resTst = np.zeros((varNumVoxChnk, betaSw.get_n_splits()),\n                          dtype='float32')\n        aryErrorTrn = np.zeros((varNumVoxChnk), dtype='float32')\n        aryErrorTst = np.zeros((varNumVoxChnk), dtype='float32')\n        contrast = np.array([\n                     [1, 0, 0, 0, 0],\n                     [0, 1, 0, 0, 0],\n                     [0, 0, 1, 0, 0],\n                     [0, 0, 0, 1, 0],\n                     ])\n        denomTrn = np.zeros((varNumVoxChnk, betaSw.get_n_splits(),\n                             len(contrast)), dtype='float32')\n        denomTst = np.zeros((varNumVoxChnk, betaSw.get_n_splits(),\n                             len(contrast)), dtype='float32')\n\n    elif type(betaSw) is np.ndarray and betaSw.dtype == 'bool':\n        aryEstimMtnCrvTrn = np.zeros((varNumVoxChnk, varNumMtnDrctns,\n                                      ), dtype='float32')\n        aryEstimMtnCrvTst = np.zeros((varNumVoxChnk, varNumMtnDrctns,\n                                      ), dtype='float32')\n        resTrn = np.zeros((varNumVoxChnk),\n                          dtype='float32')\n        resTst = np.zeros((varNumVoxChnk),\n                          dtype='float32')\n        aryErrorTrn = np.zeros((varNumVoxChnk), dtype='float32')\n        aryErrorTst = np.zeros((varNumVoxChnk), dtype='float32')\n        contrast = np.array([\n                     [1, 0, 0, 0, 0],\n                     [0, 1, 0, 0, 0],\n                     [0, 0, 1, 0, 0],\n                     [0, 0, 0, 1, 0],\n                     ])\n        denomTrn = np.zeros((varNumVoxChnk,\n                             len(contrast)), dtype='float32')\n        denomTst = np.zeros((varNumVoxChnk,\n                             len(contrast)), dtype='float32')\n\n    else:\n        aryEstimMtnCrv = np.zeros((varNumVoxChnk, varNumMtnDrctns),\n                                  dtype='float32')\n    # prepare array for best residuals\n    vecBstRes = np.zeros(varNumVoxChnk, dtype='float32')\n    vecBstRes[:] = np.inf\n    # prepare counter to check that every voxel is matched to one winner mdl\n    vecLgcCounter = np.zeros(varNumVoxChnk, dtype='float32')\n\n    # We reshape the voxel time courses, so that time goes down the column\n    aryFuncChnk = aryFuncChnk.T\n\n    # Change type to float 32:\n    aryFuncChnk = aryFuncChnk.astype(np.float32)\n    aryPrfTc = aryPrfTc.astype(np.float32)\n\n    # Prepare status indicator if this is the first of the parallel processes:\n    if idxPrc == 0:\n\n        # We create a status indicator for the time consuming pRF model finding\n        # algorithm. Number of steps of the status indicator:\n        varStsStpSze = 20\n\n        # Number of pRF models to fit:\n        varNumMdls = len(lstAllMdlInd)\n\n        # Vector with pRF values at which to give status feedback:\n        vecStatPrf = np.linspace(0,\n                                 varNumMdls,\n                                 num=(varStsStpSze+1),\n                                 endpoint=True)\n        vecStatPrf = np.ceil(vecStatPrf)\n        vecStatPrf = vecStatPrf.astype(int)\n\n        # Vector with corresponding percentage values at which to give status\n        # feedback:\n        vecStatPrc = np.linspace(0,\n                                 100,\n                                 num=(varStsStpSze+1),\n                                 endpoint=True)\n        vecStatPrc = np.ceil(vecStatPrc)\n        vecStatPrc = vecStatPrc.astype(int)\n\n        # Counter for status indicator:\n        varCntSts01 = 0\n        varCntSts02 = 0\n\n    # Loop through pRF models:\n    for idx, mdlInd in enumerate(lstAllMdlInd):\n\n        # Status indicator (only used in the first of the parallel\n        # processes):\n        if idxPrc == 0:\n\n            # Status indicator:\n            if varCntSts02 == vecStatPrf[varCntSts01]:\n\n                # Prepare status message:\n                strStsMsg = ('---------Progress: ' +\n                             str(vecStatPrc[varCntSts01]) +\n                             ' % --- ' +\n                             str(vecStatPrf[varCntSts01]) +\n                             ' pRF models out of ' +\n                             str(varNumMdls))\n\n                print(strStsMsg)\n\n                # Only increment counter if the last value has not been\n                # reached yet:\n                if varCntSts01 < varStsStpSze:\n                    varCntSts01 = varCntSts01 + int(1)\n\n        # check whether any model had this particular x, y, sigma combination\n        # as its best model\n        lgcTemp = [aryBstIndChnk == idx][0]\n\n        if np.greater(np.sum(lgcTemp), 0):\n            # get current design matrix\n            aryDsgnTmp = aryPrfTc[mdlInd].T\n\n            if betaSw is 'train':  # training\n\n                aryTmpPrmEst, aryTmpRes = np.linalg.lstsq(\n                    aryDsgnTmp, aryFuncChnk[:, lgcTemp])[0:2]\n                aryEstimMtnCrv[lgcTemp, :] = aryTmpPrmEst.T\n                vecBstRes[lgcTemp] = aryTmpRes\n\n            elif type(betaSw) is np.ndarray and betaSw.dtype == 'float':\n                # get beta weights for axis of motion tuning curves\n                aryEstimMtnCrv[lgcTemp, :] = np.linalg.lstsq(\n                    aryDsgnTmp, aryFuncChnk[:, lgcTemp])[0].T\n                # calculate prediction\n                aryPredTc = np.dot(aryDsgnTmp,\n                                   betaSw[lgcTemp, :].T)\n                # Sum of squares:\n                vecBstRes[lgcTemp] = np.sum((aryFuncChnk[:, lgcTemp] -\n                                             aryPredTc) ** 2,  axis=0)\n\n            elif type(betaSw) is np.ndarray and betaSw.dtype == 'bool':\n                # get beta weights for training\n                betas, resTrn[lgcTemp] = np.linalg.lstsq(\n                    aryDsgnTmp[betaSw, :], aryFuncChnk[betaSw][:, lgcTemp])[0:2]\n                aryEstimMtnCrvTrn[lgcTemp, :] = betas.T\n                # get beta weights for validation\n                betas, resTst[lgcTemp] = np.linalg.lstsq(\n                    aryDsgnTmp[~betaSw, :], aryFuncChnk[~betaSw][:, lgcTemp])[0:2]\n                aryEstimMtnCrvTrn[lgcTemp, :] = betas.T\n                # calculate CC for training\n                aryCcTrn = np.linalg.pinv(\n                    np.dot(aryDsgnTmp[betaSw, :].T,\n                           aryDsgnTmp[betaSw, :]))\n                aryCcTst = np.linalg.pinv(\n                    np.dot(aryDsgnTmp[~betaSw, :].T,\n                           aryDsgnTmp[~betaSw, :]))\n                # calculate Error for training\n                aryErrorTrn[lgcTemp] = np.var(\n                    np.subtract(aryFuncChnk[betaSw][:, lgcTemp],\n                                np.dot(aryDsgnTmp[betaSw, :],\n                                       aryEstimMtnCrvTrn[lgcTemp, :].T)), axis=0)\n                # calculate Error for test\n                aryErrorTst[lgcTemp] = np.var(\n                    np.subtract(aryFuncChnk[~betaSw][:, lgcTemp],\n                                np.dot(aryDsgnTmp[~betaSw, :],\n                                       aryEstimMtnCrvTst[lgcTemp, :].T)), axis=0)\n                # calculate denominator for training\n                for indContr, contr in enumerate(contrast):\n                    denomTrn[lgcTemp, indContr] = np.sqrt(\n                        aryErrorTrn[lgcTemp] * np.dot(\n                            np.dot(contr, aryCcTrn), contr.T))\n                    denomTst[lgcTemp, indContr] = np.sqrt(\n                        aryErrorTst[lgcTemp] * np.dot(\n                            np.dot(contr, aryCcTst), contr.T))\n\n            elif type(betaSw) is sklearn.model_selection._split.KFold:\n                for idxCV, (idxTrn, idxVal) in enumerate(betaSw.split(aryDsgnTmp)):\n                    # get beta weights for training\n                    betas, resTrn[lgcTemp, idxCV] = np.linalg.lstsq(\n                        aryDsgnTmp[idxTrn], aryFuncChnk[idxTrn][:, lgcTemp])[0:2]\n                    aryEstimMtnCrvTrn[lgcTemp, :, idxCV] = betas.T\n                    # get beta weights for validation\n                    betas, resTst[lgcTemp, idxCV] = np.linalg.lstsq(\n                        aryDsgnTmp[idxVal], aryFuncChnk[idxVal][:, lgcTemp])[0:2]\n                    aryEstimMtnCrvTst[lgcTemp, :, idxCV] = betas.T\n                    # calculate CC for training\n                    aryCcTrn = np.linalg.pinv(\n                        np.dot(aryDsgnTmp[idxTrn].T,\n                               aryDsgnTmp[idxTrn]))\n                    aryCcTst = np.linalg.pinv(\n                        np.dot(aryDsgnTmp[idxVal].T,\n                               aryDsgnTmp[idxVal]))\n                    # calculate Error for training\n                    aryErrorTrn[lgcTemp] = np.var(\n                        np.subtract(aryFuncChnk[idxTrn][:, lgcTemp],\n                                    np.dot(aryDsgnTmp[idxTrn],\n                                           aryEstimMtnCrvTrn[lgcTemp, :, idxCV].T)), axis=0)\n                    # calculate Error for test\n                    aryErrorTst[lgcTemp] = np.var(\n                        np.subtract(aryFuncChnk[idxVal][:, lgcTemp],\n                                    np.dot(aryDsgnTmp[idxVal],\n                                           aryEstimMtnCrvTst[lgcTemp, :, idxCV].T)), axis=0)\n                    # calculate denominator for training\n                    for indContr, contr in enumerate(contrast):\n                        denomTrn[lgcTemp, idxCV, indContr] = np.sqrt(\n                            aryErrorTrn[lgcTemp] * np.dot(\n                                np.dot(contr, aryCcTrn), contr.T))\n                        denomTst[lgcTemp, idxCV, indContr] = np.sqrt(\n                            aryErrorTst[lgcTemp] * np.dot(\n                                np.dot(contr, aryCcTst), contr.T))\n\n            # increase logical counter to verify later that every voxel\n            # was visited only once\n            vecLgcCounter[lgcTemp] += 1\n\n        # Status indicator (only used in the first of the parallel\n        # processes):\n        if idxPrc == 0:\n            # Increment status indicator counter:\n            varCntSts02 = varCntSts02 + 1\n\n    # check that every voxel was visited only once\n    strErrMsg = ('It looks like at least voxel was revisted more than once. ' +\n                 'Check whether the R2 was calculated correctly')\n    assert np.sum(vecLgcCounter) == len(vecLgcCounter), strErrMsg\n\n    if type(betaSw) is sklearn.model_selection._split.KFold:\n\n        # calculate t-values\n        aryTvalsTrn = np.empty((varNumVoxChnk, contrast.shape[0],\n                                betaSw.get_n_splits()))\n        aryTvalsTst = np.empty((varNumVoxChnk, contrast.shape[0],\n                                betaSw.get_n_splits()))\n\n        for ind1, contr in enumerate(contrast):\n            for ind2 in range(betaSw.get_n_splits()):\n                aryTvalsTrn[:, ind1, ind2] = np.divide(\n                    np.dot(contr, aryEstimMtnCrvTrn[:, :, ind2].T),\n                    denomTrn[:, ind2, ind1])\n                aryTvalsTst[:, ind1, ind2] = np.divide(\n                    np.dot(contr, aryEstimMtnCrvTst[:, :, ind2].T),\n                    denomTst[:, ind2, ind1])\n\n        # Output list:\n        lstOut = [idxPrc,\n                  aryEstimMtnCrvTrn,\n                  aryEstimMtnCrvTst,\n                  aryTvalsTrn,\n                  aryTvalsTst,\n                  ]\n        queOut.put(lstOut)\n\n    elif type(betaSw) is np.ndarray and betaSw.dtype == 'bool':\n        # calculate t-values\n        aryTvalsTrn = np.empty((varNumVoxChnk, contrast.shape[0],\n                                ))\n        aryTvalsTst = np.empty((varNumVoxChnk, contrast.shape[0],\n                                ))\n\n        for ind1, contr in enumerate(contrast):\n                aryTvalsTrn[:, ind1] = np.divide(\n                    np.dot(contr, aryEstimMtnCrvTrn.T),\n                    denomTrn[:, ind1])\n                aryTvalsTst[:, ind1] = np.divide(\n                    np.dot(contr, aryEstimMtnCrvTst.T),\n                    denomTst[:, ind1])\n\n        # Output list:\n        lstOut = [idxPrc,\n                  aryEstimMtnCrvTrn,\n                  aryEstimMtnCrvTst,\n                  aryTvalsTrn,\n                  aryTvalsTst,\n                  ]\n        queOut.put(lstOut)\n\n    else:\n        # After finding the best fitting model for each voxel, we still have to\n        # calculate the coefficient of determination (R-squared) for each voxel. We\n        # start by calculating the total sum of squares (i.e. the deviation of the\n        # data from the mean). The mean of each time course:\n        vecFuncMean = np.mean(aryFuncChnk, axis=0)\n        # Deviation from the mean for each datapoint:\n        vecFuncDev = np.subtract(aryFuncChnk, vecFuncMean[None, :])\n        # Sum of squares:\n        vecSsTot = np.sum(np.power(vecFuncDev,\n                                   2.0),\n                          axis=0)\n        # Coefficient of determination:\n        vecBstR2 = np.subtract(1.0,\n                               np.divide(vecBstRes,\n                                         vecSsTot))\n        # Output list:\n        lstOut = [idxPrc,\n                  vecBstR2,\n                  aryEstimMtnCrv]\n        queOut.put(lstOut)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nav_creators(self, article):\n        creator_list = []\n        for contrib_group in article.metadata.front.article_meta.contrib_group:\n            for contrib in contrib_group.contrib:\n                if not contrib.attrs['contrib-type'] == 'author':\n                    continue\n                if contrib.collab:\n                    auth = etree.tostring(contrib.collab[0].node, method='text', encoding='utf-8')\n                    file_as = auth\n                elif contrib.anonymous:\n                    auth = 'Anonymous'\n                    file_as = auth\n                else:\n                    name = contrib.name[0]  # Work with only first name listed\n                    surname = name.surname.text\n                    given = name.given_names\n                    if given:  # Given is optional\n                        if given.text:  # Odd instances of empty tags\n                            auth = ' '.join([surname, given.text])\n                            given_initial = given.text[0]\n                            file_as = ', '.join([surname, given_initial])\n                        else:\n                            auth = surname\n                            file_as = auth\n                    else:\n                        auth = surname\n                        file_as = auth\n                new_creator = creator(auth, 'aut', file_as)\n                creator_list.append(new_creator)\n        return creator_list", "response": "This method returns the list of creator objects that are available for the article."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nav_title(self, article):\n        article_title = article.metadata.front.article_meta.title_group.article_title.node\n        return str(etree.tostring(article_title, method='text', encoding='utf-8'), encoding='utf-8')", "response": "This method returns the string representation of the article s title."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format_citation(citation, citation_type=None):\n    cite_types = {'book': self.format_book_citation,\n                  'commun': self.format_commun_citation,\n                  'confproc': self.format_confproc_citation,\n                  'discussion': self.format_discussion_citation,\n                  'gov': self.format_gov_citation,\n                  'journal': self.format_journal_citation,\n                  'list': self.format_list_citation,\n                  'other': self.format_other_citation,\n                  'patent': self.format_patent_citation,\n                  'thesis': self.format_thesis_citation,\n                  'web': self.format_web_citation,\n                  '': self.format_other_citation,  # Empty becomes 'other'\n                  None: self.format_other_citation}  # None becomes 'other'\n\n    #Only check if no citation_type value is passed\n    if citation_type is None:\n        #Get the citation-type attribute value\n        if 'citation-type' in nlm_citation.attrib:\n            citation_type = nlm_citation.attrib['citation-type']\n\n    #Pass the citation to the appropriate function and return result\n    return cite_types[citation_type](citation)\n\n    @staticmethod\n    def format_book_citation(self, citation):\n        \"\"\"\n        citation-type=\\\"book\\\"\n        \"\"\"\n\n        #Get the count of authors\n        author_group_count = int(citation.xpath('count(person-group) + count(collab)'))\n        #Detect if there are non-authors\n        if citation.xpath('person-group[@person-group-type!=\\'author\\']'):\n            non_authors = True\n        else:\n            non_authors= False\n        #Detect article-title\n        if citation.xpath('article-title'):\n            article_title = True\n        else:\n            article_title = False\n        #Find out if there is at least one author or compiler\n        auth_or_comp = False\n        for person_group in citation.findall('person-group'):\n            if 'person-group-type' in person_group.attrib:\n                if person_group.attrib['person-group-type'] in ['author', 'compiler']:\n                    auth_or_comp = True\n                    break\n\n        #These pieces of information allow us to provide two special use cases\n        #and one general use case.\n        #First special case:\n        if author_group_count > 0 and non_authors and article_title:\n            pass\n\n        #Second special case\n        elif auth_or_comp:\n            pass\n\n        #General case\n        else:\n            pass\n\n    @staticmethod\n    def format_commun_citation(self, citation):\n        \"\"\"\n        citation-type=\\\"commun\\\"\n        \"\"\"\n\n    @staticmethod\n    def format_confproc_citation(self, citation):\n        \"\"\"\n        citation-type=\\\"confproc\\\"\n        \"\"\"\n\n    @staticmethod\n    def format_discussion_citation(self, citation):\n        \"\"\"\n        citation-type=\\\"discussion\\\"\n        \"\"\"\n\n    @staticmethod\n    def format_gov_citation(self, citation):\n        \"\"\"\n        citation-type=\\\"gov\\\"\n        \"\"\"\n\n    @staticmethod\n    def format_journal_citation(self, citation):\n        \"\"\"\n        citation-type=\\\"journal\\\"\n        \"\"\"\n\n    @staticmethod\n    def format_list_citation(self, citation):\n        \"\"\"\n        citation-type=\\\"list\\\"\n        \"\"\"\n    @staticmethod\n    def format_other_citation(self, citation):\n        \"\"\"\n        citation-type=\\\"other\\\"\n        \"\"\"\n\n    @staticmethod\n    def format_patent_citation(self, citation):\n        \"\"\"\n        citation-type=\\\"patent\\\"\n        \"\"\"\n\n    @staticmethod\n    def format_thesis_citation(self, citation):\n        \"\"\"\n        citation-type=\\\"thesis\\\"\n        \"\"\"\n        #Treat the same as \"book\"\n        return format_book_citation(citation)\n\n    @staticmethod\n    def format_web_citation(self, citation):\n        \"\"\"\n        citation-type=\\\"web\\\"\n        \"\"\"", "response": "This method formats the given citation into a single - level citation list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plos_doi_to_xmlurl(doi_string):\n    #Create URL to request DOI resolution from http://dx.doi.org\n    doi_url = 'http://dx.doi.org/{0}'.format(doi_string)\n    log.debug('DOI URL: {0}'.format(doi_url))\n    #Open the page, follow the redirect\n    try:\n        resolved_page = urllib.request.urlopen(doi_url)\n    except urllib.error.URLError as err:\n        print('Unable to resolve DOI URL, or could not connect')\n        raise err\n    else:\n        #Given the redirection, attempt to shape new request for PLoS servers\n        resolved_address = resolved_page.geturl()\n        log.debug('DOI resolved to {0}'.format(resolved_address))\n        parsed = urllib.parse.urlparse(resolved_address)\n        xml_url = '{0}://{1}'.format(parsed.scheme, parsed.netloc)\n        xml_url += '/article/fetchObjectAttachment.action?uri='\n        xml_path = parsed.path.replace(':', '%3A').replace('/', '%2F')\n        xml_path = xml_path.split('article%2F')[1]\n        xml_url += '{0}{1}'.format(xml_path, '&representation=XML')\n        log.debug('Shaped PLoS request for XML {0}'.format(xml_url))\n        #Return this url to the calling function\n        return xml_url", "response": "Given a PLoS DOI into a URL path to the XML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef url_input(url_string, download=True):\n    log.debug('URL Input - {0}'.format(url_string))\n    try:\n        open_xml = urllib.request.urlopen(url_string)\n    except urllib.error.URLError as err:\n        print('utils.input.url_input received a bad URL, or could not connect')\n        raise err\n    else:\n        #Employ a quick check on the mimetype of the link\n        if not open_xml.headers['Content-Type'] == 'text/xml':\n            sys.exit('URL request does not appear to be XML')\n        filename = open_xml.headers['Content-Disposition'].split('\\\"')[1]\n        if download:\n            with open(filename, 'wb') as xml_file:\n                xml_file.write(open_xml.read())\n        return openaccess_epub.utils.file_root_name(filename)", "response": "This method expects a URL string and returns the root name of the xml file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate a given listing against the CWL job listing schema.", "response": "def _red_listing_validation(key, listing):\n    \"\"\"\n    Raises an RedValidationError, if the given listing does not comply with cwl_job_listing_schema.\n    If listing is None or an empty list, no exception is thrown.\n\n    :param key: The input key to build an error message if needed.\n    :param listing: The listing to validate\n    :raise RedValidationError: If the given listing does not comply with cwl_job_listing_schema\n    \"\"\"\n\n    if listing:\n        try:\n            jsonschema.validate(listing, cwl_job_listing_schema)\n        except ValidationError as e:\n            raise RedValidationError('REDFILE listing of input \"{}\" does not comply with jsonschema: {}'\n                                     .format(key, e.context))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of mounting connectors from the red data.", "response": "def red_get_mount_connectors(red_data, ignore_outputs):\n    \"\"\"\n    Returns a list of mounting connectors\n\n    :param red_data: The red data to be searched\n    :param ignore_outputs: If outputs should be ignored\n    :return: A list of connectors with active mount option.\n    \"\"\"\n\n    keys = []\n\n    batches = red_data.get('batches')\n    inputs = red_data.get('inputs')\n    if batches:\n        for batch in batches:\n            keys.extend(red_get_mount_connectors_from_inputs(batch['inputs']))\n    elif inputs:\n        keys.extend(red_get_mount_connectors_from_inputs(inputs))\n\n    if not ignore_outputs:\n        outputs = red_data.get('outputs')\n        if batches:\n            for batch in batches:\n                batch_outputs = batch.get('outputs')\n                if batch_outputs:\n                    keys.extend(red_get_mount_connectors_from_outputs(batch_outputs))\n\n        elif outputs:\n            keys.extend(red_get_mount_connectors_from_outputs(outputs))\n\n    return keys"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninvoking the cleanup functions for all inputs.", "response": "def cleanup(connector_manager, red_data, tmp_dir):\n    \"\"\"\n    Invokes the cleanup functions for all inputs.\n    \"\"\"\n    for key, arg in red_data['inputs'].items():\n        val = arg\n\n        if isinstance(arg, list):\n            for index, i in enumerate(arg):\n                if not isinstance(i, dict):\n                    continue\n\n                # connector_class should be one of 'File' or 'Directory'\n                connector_class = i['class']\n                input_key = '{}_{}'.format(key, index)\n                path = os.path.join(tmp_dir, input_key)\n                connector_data = i['connector']\n                internal = {URL_SCHEME_IDENTIFIER: path}\n\n                if connector_class == 'File':\n                    connector_manager.receive_cleanup(connector_data, input_key, internal)\n                elif connector_class == 'Directory':\n                    connector_manager.receive_directory_cleanup(connector_data, input_key, internal)\n\n        elif isinstance(arg, dict):\n            # connector_class should be one of 'File' or 'Directory'\n            connector_class = arg['class']\n            input_key = key\n            path = os.path.join(tmp_dir, input_key)\n            connector_data = val['connector']\n            internal = {URL_SCHEME_IDENTIFIER: path}\n\n            if connector_class == 'File':\n                connector_manager.receive_cleanup(connector_data, input_key, internal)\n            elif connector_class == 'Directory':\n                connector_manager.receive_directory_cleanup(connector_data, input_key, internal)\n\n    try:\n        os.rmdir(tmp_dir)\n    except (OSError, FileNotFoundError):\n        # Maybe, raise a warning here, because not all connectors have cleaned up their contents correctly.\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _execute_connector(connector_command, top_level_argument, *file_contents, listing=None):\n        # create temp_files for every file_content\n        temp_files = []\n        for file_content in file_contents:\n            if file_content is None:\n                continue\n            tmp_file = tempfile.NamedTemporaryFile('w')\n            json.dump(file_content, tmp_file)\n            tmp_file.flush()\n            temp_files.append(tmp_file)\n\n        tmp_listing_file = None\n        if listing:\n            tmp_listing_file = tempfile.NamedTemporaryFile('w')\n            json.dump(listing, tmp_listing_file)\n            tmp_listing_file.flush()\n\n        command = [connector_command, top_level_argument]\n        command.extend([t.name for t in temp_files])\n\n        if tmp_listing_file:\n            command.append('--listing {}'.format(tmp_listing_file.name))\n\n        result = execute(' '.join(command))\n\n        # close temp_files\n        for temp_file in temp_files:\n            temp_file.close()\n\n        if tmp_listing_file:\n            tmp_listing_file.close()\n\n        return result['returnCode'], result['stdErr']", "response": "Executes a connector command and returns the return code and stderr of the connector command."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef directory_listing_content_check(directory_path, listing):\n        if listing:\n            for sub in listing:\n                path = os.path.join(directory_path, sub['basename'])\n                if sub['class'] == 'File':\n                    if not os.path.isfile(path):\n                        return 'listing contains \"{}\" but this file could not be found on disk.'.format(path)\n                elif sub['class'] == 'Directory':\n                    if not os.path.isdir(path):\n                        return 'listing contains \"{}\" but this directory could not be found on disk'.format(path)\n                    listing = sub.get('listing')\n                    if listing:\n                        return ConnectorManager.directory_listing_content_check(path, listing)\n        return None", "response": "Checks if a given listing is present under the given directory path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_cuda_devices():\n\n    devices = []\n\n    try:\n        import pycuda.autoinit\n        import pycuda.driver as cuda\n\n        for device_id in range(cuda.Device.count()):\n            vram = cuda.Device(device_id).total_memory()\n\n            devices.append(GPUDevice(device_id, vram))\n    except ImportError:\n        raise InsufficientGPUError('No Nvidia-GPUs could be found, because \"pycuda\" could not be imported.')\n\n    return devices", "response": "Imports pycuda at runtime and reads GPU information."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining sufficient GPUs for the given requirements and returns a list of GPUDevices.", "response": "def match_gpus(available_devices, requirements):\n    \"\"\"\n    Determines sufficient GPUs for the given requirements and returns a list of GPUDevices.\n    If there aren't sufficient GPUs a InsufficientGPUException is thrown.\n\n    :param available_devices: A list of GPUDevices\n    :param requirements: A list of GPURequirements\n\n    :return: A list of sufficient devices\n    \"\"\"\n\n    if not requirements:\n        return []\n\n    if not available_devices:\n        raise InsufficientGPUError(\"No GPU devices available, but {} devices required.\".format(len(requirements)))\n\n    available_devices = available_devices.copy()\n\n    used_devices = []\n\n    for req in requirements:\n        dev = search_device(req, available_devices)\n        if dev:\n            used_devices.append(dev)\n            available_devices.remove(dev)\n        else:\n            raise InsufficientGPUError(\"Not all GPU requirements could be fulfilled.\")\n\n    return used_devices"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_gpu_requirements(gpus_reqs):\n    requirements = []\n\n    if gpus_reqs:\n        if type(gpus_reqs) is dict:\n            count = gpus_reqs.get('count')\n            if count:\n                for i in range(count):\n                    requirements.append(GPURequirement())\n        elif type(gpus_reqs) is list:\n            for gpu_req in gpus_reqs:\n                requirements.append(GPURequirement(min_vram=gpu_req['minVram']))\n        return requirements\n    else:\n        # If no requirements are supplied\n        return []", "response": "Extracts the GPU from a dictionary requirements as list of GPURequirements."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_nvidia_environment_variables(environment, gpu_ids):\n\n    if gpu_ids:\n        nvidia_visible_devices = \"\"\n        for gpu_id in gpu_ids:\n            nvidia_visible_devices += \"{},\".format(gpu_id)\n        environment[\"NVIDIA_VISIBLE_DEVICES\"] = nvidia_visible_devices", "response": "Sets the environment variables that are set in the Nvidia - GPUs environment variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_sufficient(self, device):\n\n        sufficient = True\n        if (self.min_vram is not None) and (device.vram < self.min_vram):\n            sufficient = False\n\n        return sufficient", "response": "Returns whether the device is sufficient for this requirement."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cache_location():\n    '''Cross-platform placement of cached files'''\n    plat = platform.platform()\n    log.debug('Platform read as: {0}'.format(plat))\n    if plat.startswith('Windows'):\n        log.debug('Windows platform detected')\n        return os.path.join(os.environ['APPDATA'], 'OpenAccess_EPUB')\n    elif plat.startswith('Darwin'):\n        log.debug('Mac platform detected')\n    elif plat.startswith('Linux'):\n        log.debug('Linux platform detected')\n    else:\n        log.warning('Unhandled platform for cache_location')\n\n    #This code is written for Linux and Mac, don't expect success for others\n    path = os.path.expanduser('~')\n    if path == '~':\n        path = os.path.expanduser('~user')\n        if path == '~user':\n            log.critical('Could not resolve the correct cache location')\n            sys.exit('Could not resolve the correct cache location')\n    cache_loc = os.path.join(path, '.OpenAccess_EPUB')\n    log.debug('Cache located: {0}'.format(cache_loc))\n    return cache_loc", "response": "Cross - platform placement of cached files"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_config_module():\n    import imp\n    config_path = config_location()\n    try:\n        config = imp.load_source('config', config_path)\n    except IOError:\n        log.critical('Config file not found. oaepub exiting...')\n        sys.exit('Config file not found. Please run \\'oaepub configure\\'')\n    else:\n        log.debug('Config file loaded from {0}'.format(config_path))\n        return config", "response": "Load the config. py file and return the module object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_absolute_path(some_path):\n    if os.path.isabs(some_path):\n        return some_path\n    else:\n        return evaluate_relative_path(os.getcwd(), some_path)", "response": "This function returns an absolute path for the input path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef file_root_name(name):\n    base = os.path.basename(name)\n    root = os.path.splitext(base)[0]\n    if not root:\n        warning = 'file_root_name returned an empty root name from \\\"{0}\\\"'\n        log.warning(warning.format(name))\n    return root", "response": "Returns the root name of a file from a full file path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef files_with_ext(extension, directory='.', recursive=False):\n    if recursive:\n        log.info('Recursively searching {0} for files with extension \"{1}\"'.format(directory, extension))\n        for dirname, subdirnames, filenames in os.walk(directory):\n            for filename in filenames:\n                filepath = os.path.join(dirname, filename)\n                _root, ext = os.path.splitext(filepath)\n                if extension.lower() == ext.lower():\n                    yield filepath\n\n    else:\n        log.info('Looking in {0} for files with extension:  \"{1}\"'.format(directory, extension))\n        for name in os.listdir(directory):\n            filepath = os.path.join(directory, name)\n            if not os.path.isfile(filepath):  # Skip non-files\n                continue\n            _root, ext = os.path.splitext(filepath)\n            if extension.lower() == ext.lower():\n                yield filepath", "response": "Generator function that will iterate over all files in the specified directory and return a path to the files which possess a matching extension."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if a directory already exists and if yes deletes it if it does not.", "response": "def dir_exists(directory):\n    \"\"\"\n    If a directory already exists that will be overwritten by some action, this\n    will ask the user whether or not to continue with the deletion.\n\n    If the user responds affirmatively, then the directory will be removed. If\n    the user responds negatively, then the process will abort.\n    \"\"\"\n    log.info('Directory exists! Asking the user')\n    reply = input('''The directory {0} already exists.\nIt will be overwritten if the operation continues.\nReplace? [Y/n]'''.format(directory))\n    if reply.lower() in ['y', 'yes', '']:\n        shutil.rmtree(directory)\n        os.makedirs(directory)\n    else:\n        log.critical('Aborting process, user declined overwriting {0}'.format(directory))\n        sys.exit('Aborting process!')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the nearest dict entry based on latitude and longitude.", "response": "def get_nearest_by_coordinates(\n        data: list, latitude_key: str, longitude_key: str,\n        target_latitude: float, target_longitude: float) -> Any:\n    \"\"\"Get the closest dict entry based on latitude/longitude.\"\"\"\n    return min(\n        data,\n        key=lambda p: haversine(\n            target_latitude,\n            target_longitude,\n            float(p[latitude_key]),\n            float(p[longitude_key])\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine the distance between two latitude and longitude pairs.", "response": "def haversine(lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n    \"\"\"Determine the distance between two latitude/longitude pairs.\"\"\"\n    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n\n    # haversine formula\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n    calc_a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n    calc_c = 2 * asin(sqrt(calc_a))\n\n    return 6371 * calc_c"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef in_file(self, fn: str) -> Iterator[InsertionPoint]:\n        logger.debug(\"finding insertion points in file: %s\", fn)\n        yield from self.__file_insertions.get(fn, [])", "response": "Returns an iterator over all of the insertion points in a given file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an iterator over all of the insertion points located at a specific line.", "response": "def at_line(self, line: FileLine) -> Iterator[InsertionPoint]:\n        \"\"\"\n        Returns an iterator over all of the insertion points located at a\n        given line.\n        \"\"\"\n        logger.debug(\"finding insertion points at line: %s\", str(line))\n        filename = line.filename  # type: str\n        line_num = line.num  # type: int\n        for ins in self.in_file(filename):\n            if line_num == ins.location.line:\n                logger.debug(\"found insertion point at line [%s]: %s\",\n                             str(line), ins)\n                yield ins"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getUnitCost(self, CorpNum):\n\n        result = self._httpget('/CloseDown/UnitCost', CorpNum)\n\n        return float(result.unitCost)", "response": "Get UnitCost of a particular item."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef checkCorpNums(self, MemberCorpNum, CorpNumList):\n        if CorpNumList == None or len(CorpNumList) < 1:\n            raise PopbillException(-99999999,\"\uc870\uc8c4\ud560 \uc0ac\uc5c5\uc790\ubc88\ud638 \ubaa9\ub85d\uc774 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        postData = self._stringtify(CorpNumList)\n\n        return self._httppost('/CloseDown',postData,MemberCorpNum)", "response": "\ud734\ud3d0\uc5c5\uc870\ud68c \ub300\ub7c9 \ud655\uc778, \ucd5c\ub300 1000\uac74\n            args\n                MemberCorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                CorpNumList : \uc870\ud68c\ud560 \uc0ac\uc5c5\uc790\ubc88\ud638 \ubc30\uc5f4\n            return\n                \ud734\ud3d0\uc5c5\uc815\ubcf4 Object as List\n            raise\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef loadPng(varNumVol, tplPngSize, strPathPng):\n    print('------Load PNGs')\n    # Create list of png files to load:\n    lstPngPaths = [None] * varNumVol\n    for idx01 in range(0, varNumVol):\n        lstPngPaths[idx01] = (strPathPng + str(idx01) + '.png')\n\n    # Load png files. The png data will be saved in a numpy array of the\n    # following order: aryPngData[x-pixel, y-pixel, PngNumber]. The\n    # sp.misc.imread function actually contains three values per pixel (RGB),\n    # but since the stimuli are black-and-white, any one of these is sufficient\n    # and we discard the others.\n    aryPngData = np.zeros((tplPngSize[0],\n                           tplPngSize[1],\n                           varNumVol))\n    for idx01 in range(0, varNumVol):\n        aryPngData[:, :, idx01] = np.array(Image.open(lstPngPaths[idx01]))\n\n    # Convert RGB values (0 to 255) to integer ones and zeros:\n    aryPngData = (aryPngData > 0).astype(int)\n\n    return aryPngData", "response": "Load PNG files and return a 2d numpy array of the size of the image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading presentation order of motion directions.", "response": "def loadPrsOrd(vecRunLngth, strPathPresOrd, vecVslStim):\n    \"\"\"Load presentation order of motion directions.\n\n    Parameters\n    ----------\n    vecRunLngth : list\n        Number of volumes in every run\n    strPathPresOrd : str\n        Path to the npy vector containing order of presented motion directions.\n    vecVslStim: list\n        Key of (stimulus) condition presented in every run\n    Returns\n    -------\n    aryPresOrdAprt : 1d numpy array, shape [n_vols]\n        Presentation order of aperture position.\n    aryPresOrdMtn : 1d numpy array, shape [n_vols]\n        Presentation order of motion direction.\n    \"\"\"\n    print('------Load presentation order of motion directions')\n    aryPresOrd = np.empty((0, 2))\n    for idx01 in range(0, len(vecRunLngth)):\n        # reconstruct file name\n        # ---> consider: some runs were shorter than others(replace next row)\n        filename1 = (strPathPresOrd + str(vecVslStim[idx01]) +\n                     '.pickle')\n        # filename1 = (strPathPresOrd + str(idx01+1) + '.pickle')\n        # load array\n        with open(filename1, 'rb') as handle:\n            array1 = pickle.load(handle)\n        tempCond = array1[\"Conditions\"]\n        tempCond = tempCond[:vecRunLngth[idx01], :]\n        # add temp array to aryPresOrd\n        aryPresOrd = np.concatenate((aryPresOrd, tempCond), axis=0)\n    aryPresOrdAprt = aryPresOrd[:, 0].astype(int)\n    aryPresOrdMtn = aryPresOrd[:, 1].astype(int)\n\n    return aryPresOrdAprt, aryPresOrdMtn"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate pixel - wise boxcar functions.", "response": "def crtPwBoxCarFn(varNumVol, aryPngData, aryPresOrd, vecMtDrctn):\n    \"\"\"Create pixel-wise boxcar functions.\n\n    Parameters\n    ----------\n    input1 : 2d numpy array, shape [n_samples, n_measurements]\n        Description of input 1.\n    input2 : float, positive\n      Description of input 2.\n    Returns\n    -------\n    data : 2d numpy array, shape [n_samples, n_measurements]\n        Closed data.\n    Reference\n    ---------\n    [1]\n    \"\"\"\n    print('------Create pixel-wise boxcar functions')\n    aryBoxCar = np.empty(aryPngData.shape[0:2] + (len(vecMtDrctn),) +\n                         (varNumVol,), dtype='int64')\n    for ind, num in enumerate(vecMtDrctn):\n        aryCondTemp = np.zeros((aryPngData.shape), dtype='int64')\n        lgcTempMtDrctn = [aryPresOrd == num][0]\n        aryCondTemp[:, :, lgcTempMtDrctn] = np.copy(\n            aryPngData[:, :, lgcTempMtDrctn])\n        aryBoxCar[:, :, ind, :] = aryCondTemp\n\n    return aryBoxCar"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef crtGauss2D(varSizeX, varSizeY, varPosX, varPosY, varSd):\n    varSizeX = int(varSizeX)\n    varSizeY = int(varSizeY)\n\n    # aryX and aryY are in reversed order, this seems to be necessary:\n    aryY, aryX = sp.mgrid[0:varSizeX,\n                          0:varSizeY]\n\n    # The actual creation of the Gaussian array:\n    aryGauss = (\n        (np.square((aryX - varPosX)) + np.square((aryY - varPosY))) /\n        (2.0 * np.square(varSd))\n        )\n    aryGauss = np.exp(-aryGauss) / (2 * np.pi * np.square(varSd))\n\n    return aryGauss", "response": "Create 2D Gaussian kernel."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cnvlGauss2D(idxPrc, aryBoxCar, aryMdlParamsChnk, tplPngSize, varNumVol,\n                queOut):\n    \"\"\"Spatially convolve boxcar functions with 2D Gaussian.\n\n    Parameters\n    ----------\n    idxPrc : 2d numpy array, shape [n_samples, n_measurements]\n        Description of input 1.\n    aryBoxCar : float, positive\n      Description of input 2.\n    aryMdlParamsChnk : 2d numpy array, shape [n_samples, n_measurements]\n        Description of input 1.\n    tplPngSize : float, positive\n      Description of input 2.\n    varNumVol : 2d numpy array, shape [n_samples, n_measurements]\n        Description of input 1.\n    queOut : float, positive\n      Description of input 2.\n    Returns\n    -------\n    data : 2d numpy array, shape [n_samples, n_measurements]\n        Closed data.\n    Reference\n    ---------\n    [1]\n    \"\"\"\n    # Number of combinations of model parameters in the current chunk:\n    varChnkSze = np.size(aryMdlParamsChnk, axis=0)\n\n    # Determine number of motion directions\n    varNumMtnDrtn = aryBoxCar.shape[2]\n\n    # Output array with pRF model time courses:\n    aryOut = np.zeros([varChnkSze, varNumMtnDrtn, varNumVol])\n\n    # Loop through different motion directions:\n    for idxMtn in range(0, varNumMtnDrtn):\n        # Loop through combinations of model parameters:\n        for idxMdl in range(0, varChnkSze):\n\n            # Spatial parameters of current model:\n            varTmpX = aryMdlParamsChnk[idxMdl, 1]\n            varTmpY = aryMdlParamsChnk[idxMdl, 2]\n            varTmpSd = aryMdlParamsChnk[idxMdl, 3]\n\n            # Create pRF model (2D):\n            aryGauss = crtGauss2D(tplPngSize[0],\n                                  tplPngSize[1],\n                                  varTmpX,\n                                  varTmpY,\n                                  varTmpSd)\n\n            # Multiply pixel-time courses with Gaussian pRF models:\n            aryPrfTcTmp = np.multiply(aryBoxCar[:, :, idxMtn, :],\n                                      aryGauss[:, :, None])\n\n            # Calculate sum across x- and y-dimensions - the 'area under the\n            # Gaussian surface'. This is essentially an unscaled version of the\n            # pRF time course model (i.e. not yet scaled for size of the pRF).\n            aryPrfTcTmp = np.sum(aryPrfTcTmp, axis=(0, 1))\n\n            # Put model time courses into function's output with 2d Gaussian\n            # arrray:\n            aryOut[idxMdl, idxMtn, :] = aryPrfTcTmp\n\n    # Put column with the indicies of model-parameter-combinations into the\n    # output array (in order to be able to put the pRF model time courses into\n    # the correct order after the parallelised function):\n    lstOut = [idxPrc,\n              aryOut]\n\n    # Put output to queue:\n    queOut.put(lstOut)", "response": "Spatially convolve boxcar functions with 2D Gaussian."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate neural time courses from pixel - wise boxcar functions.", "response": "def crtPrfNrlTc(aryBoxCar, varNumMtDrctn, varNumVol, tplPngSize, varNumX,\n                varExtXmin,  varExtXmax, varNumY, varExtYmin, varExtYmax,\n                varNumPrfSizes, varPrfStdMin, varPrfStdMax, varPar):\n    \"\"\"Create neural model time courses from pixel-wise boxcar functions.\n\n    Parameters\n    ----------\n    aryBoxCar : 4d numpy array, shape [n_x_pix, n_y_pix, n_mtn_dir, n_vol]\n        Description of input 1.\n    varNumMtDrctn : float, positive\n        Description of input 2.\n    varNumVol : float, positive\n        Description of input 2.\n    tplPngSize : tuple\n        Description of input 2.\n    varNumX : float, positive\n        Description of input 2.\n    varExtXmin : float, positive\n        Description of input 2.\n    varExtXmax : float, positive\n        Description of input 2.\n    varNumY : float, positive\n        Description of input 2.\n    varExtYmin : float, positive\n        Description of input 2.\n    varExtYmax : float, positive\n        Description of input 2.\n    varNumPrfSizes : float, positive\n        Description of input 2.\n    varPrfStdMin : float, positive\n        Description of input 2.\n    varPrfStdMax : float, positive\n        Description of input 2.\n    varPar : float, positive\n        Description of input 2.\n    Returns\n    -------\n    aryNrlTc : 5d numpy array, shape [n_x_pos, n_y_pos, n_sd, n_mtn_dir, n_vol]\n        Closed data.\n    Reference\n    ---------\n    [1]\n    \"\"\"\n    print('------Create neural time course models')\n\n    # Vector with the x-indicies of the positions in the super-sampled visual\n    # space at which to create pRF models.\n    vecX = np.linspace(0, (tplPngSize[0] - 1), varNumX, endpoint=True)\n\n    # Vector with the y-indicies of the positions in the super-sampled visual\n    # space at which to create pRF models.\n    vecY = np.linspace(0, (tplPngSize[1] - 1), varNumY, endpoint=True)\n\n    # We calculate the scaling factor from degrees of visual angle to pixels\n    # separately for the x- and the y-directions (the two should be the same).\n    varDgr2PixX = tplPngSize[0] / (varExtXmax - varExtXmin)\n    varDgr2PixY = tplPngSize[1] / (varExtYmax - varExtYmin)\n\n    # Check whether varDgr2PixX and varDgr2PixY are similar:\n    strErrMsg = 'ERROR. The ratio of X and Y dimensions in stimulus ' + \\\n        'space (in degrees of visual angle) and the ratio of X and Y ' + \\\n        'dimensions in the upsampled visual space do not agree'\n    assert 0.5 > np.absolute((varDgr2PixX - varDgr2PixY)), strErrMsg\n\n    # Vector with pRF sizes to be modelled (still in degree of visual angle):\n    vecPrfSd = np.linspace(varPrfStdMin, varPrfStdMax, varNumPrfSizes,\n                           endpoint=True)\n\n    # We multiply the vector containing pRF sizes with the scaling factors.\n    # Now the vector with the pRF sizes can be used directly for creation of\n    # Gaussian pRF models in visual space.\n    vecPrfSd = np.multiply(vecPrfSd, varDgr2PixX)\n\n    # Number of pRF models to be created (i.e. number of possible combinations\n    # of x-position, y-position, and standard deviation):\n    varNumMdls = varNumX * varNumY * varNumPrfSizes\n\n    # Array for the x-position, y-position, and standard deviations for which\n    # pRF model time courses are going to be created, where the columns\n    # correspond to: (0) an index starting from zero, (1) the x-position, (2)\n    # the y-position, and (3) the standard deviation. The parameters are in\n    # units of the upsampled visual space.\n    aryMdlParams = np.zeros((varNumMdls, 4))\n\n    # Counter for parameter array:\n    varCntMdlPrms = 0\n\n    # Put all combinations of x-position, y-position, and standard deviations\n    # into the array:\n\n    # Loop through x-positions:\n    for idxX in range(0, varNumX):\n\n        # Loop through y-positions:\n        for idxY in range(0, varNumY):\n\n            # Loop through standard deviations (of Gaussian pRF models):\n            for idxSd in range(0, varNumPrfSizes):\n\n                # Place index and parameters in array:\n                aryMdlParams[varCntMdlPrms, 0] = varCntMdlPrms\n                aryMdlParams[varCntMdlPrms, 1] = vecX[idxX]\n                aryMdlParams[varCntMdlPrms, 2] = vecY[idxY]\n                aryMdlParams[varCntMdlPrms, 3] = vecPrfSd[idxSd]\n\n                # Increment parameter index:\n                varCntMdlPrms = varCntMdlPrms + 1\n\n    # The long array with all the combinations of model parameters is put into\n    # separate chunks for parallelisation, using a list of arrays.\n    lstMdlParams = np.array_split(aryMdlParams, varPar)\n\n    # Create a queue to put the results in:\n    queOut = mp.Queue()\n\n    # Empty list for results from parallel processes (for pRF model time course\n    # results):\n    lstPrfTc = [None] * varPar\n\n    # Empty list for processes:\n    lstPrcs = [None] * varPar\n\n    print('---------Creating parallel processes')\n\n    # Create processes:\n    for idxPrc in range(0, varPar):\n        lstPrcs[idxPrc] = mp.Process(target=cnvlGauss2D,\n                                     args=(idxPrc, aryBoxCar,\n                                           lstMdlParams[idxPrc], tplPngSize,\n                                           varNumVol, queOut)\n                                     )\n        # Daemon (kills processes when exiting):\n        lstPrcs[idxPrc].Daemon = True\n\n    # Start processes:\n    for idxPrc in range(0, varPar):\n        lstPrcs[idxPrc].start()\n\n    # Collect results from queue:\n    for idxPrc in range(0, varPar):\n        lstPrfTc[idxPrc] = queOut.get(True)\n\n    # Join processes:\n    for idxPrc in range(0, varPar):\n        lstPrcs[idxPrc].join()\n\n    print('---------Collecting results from parallel processes')\n    # Put output arrays from parallel process into one big array\n    lstPrfTc = sorted(lstPrfTc)\n    aryPrfTc = np.empty((0, varNumMtDrctn, varNumVol))\n    for idx in range(0, varPar):\n        aryPrfTc = np.concatenate((aryPrfTc, lstPrfTc[idx][1]), axis=0)\n\n    # check that all the models were collected correctly\n    assert aryPrfTc.shape[0] == varNumMdls\n\n    # Clean up:\n    del(aryMdlParams)\n    del(lstMdlParams)\n    del(lstPrfTc)\n\n    # Array representing the low-resolution visual space, of the form\n    # aryPrfTc[x-position, y-position, pRF-size, varNum Vol], which will hold\n    # the pRF model time courses.\n    aryNrlTc = np.zeros([varNumX, varNumY, varNumPrfSizes, varNumMtDrctn,\n                         varNumVol])\n\n    # We use the same loop structure for organising the pRF model time courses\n    # that we used for creating the parameter array. Counter:\n    varCntMdlPrms = 0\n\n    # Put all combinations of x-position, y-position, and standard deviations\n    # into the array:\n\n    # Loop through x-positions:\n    for idxX in range(0, varNumX):\n\n        # Loop through y-positions:\n        for idxY in range(0, varNumY):\n\n            # Loop through standard deviations (of Gaussian pRF models):\n            for idxSd in range(0, varNumPrfSizes):\n\n                # Put the pRF model time course into its correct position in\n                # the 4D array, leaving out the first column (which contains\n                # the index):\n                aryNrlTc[idxX, idxY, idxSd, :, :] = aryPrfTc[\n                    varCntMdlPrms, :, :]\n\n                # Increment parameter index:\n                varCntMdlPrms = varCntMdlPrms + 1\n\n    return aryNrlTc"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate 2D Gaussian kernel. Parameters ---------- aryNrlTc : 5d numpy array, shape [n_x_pos, n_y_pos, n_sd, n_mtn_dir, n_vol] Description of input 1. varNumVol : float, positive Description of input 2. varTr : float, positive Description of input 1. tplPngSize : tuple Description of input 1. varNumMtDrctn : int, positive Description of input 1. switchHrfSet : Description of input 1. lgcOldSchoolHrf : int, positive Description of input 1. varPar : int, positive Description of input 1. Returns ------- data : 2d numpy array, shape [n_samples, n_measurements] Closed data. Reference --------- [1]", "response": "def cnvlPwBoxCarFn(aryNrlTc, varNumVol, varTr, tplPngSize, varNumMtDrctn,\n                   switchHrfSet, lgcOldSchoolHrf, varPar,):\n    \"\"\"Create 2D Gaussian kernel.\n\n    Parameters\n    ----------\n    aryNrlTc : 5d numpy array, shape [n_x_pos, n_y_pos, n_sd, n_mtn_dir, n_vol]\n        Description of input 1.\n    varNumVol : float, positive\n        Description of input 2.\n    varTr : float, positive\n        Description of input 1.\n    tplPngSize : tuple\n        Description of input 1.\n    varNumMtDrctn : int, positive\n        Description of input 1.\n    switchHrfSet :\n        Description of input 1.\n    lgcOldSchoolHrf : int, positive\n        Description of input 1.\n    varPar : int, positive\n        Description of input 1.\n    Returns\n    -------\n    data : 2d numpy array, shape [n_samples, n_measurements]\n        Closed data.\n    Reference\n    ---------\n    [1]\n    \"\"\"\n    print('------Convolve every pixel box car function with hrf function(s)')\n\n    # Create hrf time course function:\n    if switchHrfSet == 3:\n        lstHrf = [spmt, dspmt, ddspmt]\n    elif switchHrfSet == 2:\n        lstHrf = [spmt, dspmt]\n    elif switchHrfSet == 1:\n        lstHrf = [spmt]\n\n    # adjust the input, if necessary, such that input is 2D, with last dim time\n    tplInpShp = aryNrlTc.shape\n    aryNrlTc = np.reshape(aryNrlTc, (-1, aryNrlTc.shape[-1]))\n\n    # Put input data into chunks:\n    lstNrlTc = np.array_split(aryNrlTc, varPar)\n\n    # Create a queue to put the results in:\n    queOut = mp.Queue()\n\n    # Empty list for processes:\n    lstPrcs = [None] * varPar\n\n    # Empty list for results of parallel processes:\n    lstConv = [None] * varPar\n\n    print('---------Creating parallel processes')\n\n    if lgcOldSchoolHrf:\n        for idxPrc in range(0, varPar):\n            lstPrcs[idxPrc] = mp.Process(target=cnvlTcOld,\n                                         args=(idxPrc,\n                                               lstNrlTc[idxPrc],\n                                               varTr,\n                                               varNumVol,\n                                               queOut)\n                                         )\n            # Daemon (kills processes when exiting):\n            lstPrcs[idxPrc].Daemon = True\n\n    else:\n        # Create processes:\n        for idxPrc in range(0, varPar):\n            lstPrcs[idxPrc] = mp.Process(target=cnvlTc,\n                                         args=(idxPrc,\n                                               lstNrlTc[idxPrc],\n                                               lstHrf,\n                                               varTr,\n                                               varNumVol,\n                                               queOut)\n                                         )\n\n            # Daemon (kills processes when exiting):\n            lstPrcs[idxPrc].Daemon = True\n\n    # Start processes:\n    for idxPrc in range(0, varPar):\n        lstPrcs[idxPrc].start()\n\n    # Collect results from queue:\n    for idxPrc in range(0, varPar):\n        lstConv[idxPrc] = queOut.get(True)\n\n    # Join processes:\n    for idxPrc in range(0, varPar):\n        lstPrcs[idxPrc].join()\n\n    print('---------Collecting results from parallel processes')\n    # Put output into correct order:\n    lstConv = sorted(lstConv)\n    # Concatenate convolved pixel time courses (into the same order\n    aryNrlTcConv = np.zeros((0, switchHrfSet, varNumVol))\n    for idxRes in range(0, varPar):\n        aryNrlTcConv = np.concatenate((aryNrlTcConv, lstConv[idxRes][1]),\n                                      axis=0)\n    # clean up\n    del(aryNrlTc)\n    del(lstConv)\n\n    # Reshape results:\n    tplOutShp = tplInpShp[:-2] + (varNumMtDrctn * len(lstHrf), ) + \\\n        (tplInpShp[-1], )\n\n    # Return:\n    return np.reshape(aryNrlTcConv, tplOutShp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rsmplInHighRes(aryBoxCarConv,\n                   tplPngSize,\n                   tplVslSpcHighSze,\n                   varNumMtDrctn,\n                   varNumVol):\n    \"\"\"Resample pixel-time courses in high-res visual space.\n\n    Parameters\n    ----------\n    input1 : 2d numpy array, shape [n_samples, n_measurements]\n        Description of input 1.\n    input2 : float, positive\n      Description of input 2.\n    Returns\n    -------\n    data : 2d numpy array, shape [n_samples, n_measurements]\n        Closed data.\n    Reference\n    ---------\n    [1]\n    \"\"\"\n    # Array for super-sampled pixel-time courses:\n    aryBoxCarConvHigh = np.zeros((tplVslSpcHighSze[0],\n                                  tplVslSpcHighSze[1],\n                                  varNumMtDrctn,\n                                  varNumVol))\n\n    # Loop through volumes:\n    for idxMtn in range(0, varNumMtDrctn):\n\n        for idxVol in range(0, varNumVol):\n\n            # Range for the coordinates:\n            vecRange = np.arange(0, tplPngSize[0])\n\n            # The following array describes the coordinates of the pixels in\n            # the flattened array (i.e. \"vecOrigPixVal\"). In other words, these\n            # are the row and column coordinates of the original pizel values.\n            crd2, crd1 = np.meshgrid(vecRange, vecRange)\n            aryOrixPixCoo = np.column_stack((crd1.flatten(), crd2.flatten()))\n\n            # The following vector will contain the actual original pixel\n            # values:\n\n            vecOrigPixVal = aryBoxCarConv[:, :, idxMtn, idxVol]\n            vecOrigPixVal = vecOrigPixVal.flatten()\n\n            # The sampling interval for the creation of the super-sampled pixel\n            # data (complex numbers are used as a convention for inclusive\n            # intervals in \"np.mgrid()\").:\n\n            varStpSzeX = np.complex(tplVslSpcHighSze[0])\n            varStpSzeY = np.complex(tplVslSpcHighSze[1])\n\n            # The following grid has the coordinates of the points at which we\n            # would like to re-sample the pixel data:\n            aryPixGridX, aryPixGridY = np.mgrid[0:tplPngSize[0]:varStpSzeX,\n                                                0:tplPngSize[1]:varStpSzeY]\n\n            # The actual resampling:\n            aryResampled = griddata(aryOrixPixCoo,\n                                    vecOrigPixVal,\n                                    (aryPixGridX, aryPixGridY),\n                                    method='nearest')\n\n            # Put super-sampled pixel time courses into array:\n            aryBoxCarConvHigh[:, :, idxMtn, idxVol] = aryResampled\n\n    return aryBoxCarConvHigh", "response": "Resample pixel - time courses in high - res visual space."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the Command Line Arguments using argparse.", "response": "def get_arg_parse():\n    \"\"\"Parses the Command Line Arguments using argparse.\"\"\"\n    # Create parser object:\n    objParser = argparse.ArgumentParser()\n\n    # Add argument to namespace -strCsvPrf results file path:\n    objParser.add_argument('-strCsvPrf', required=True,\n                           metavar='/path/to/my_prior_res',\n                           help='Absolute file path of prior pRF results. \\\n                                 Ignored if in testing mode.'\n                           )\n\n    # Add argument to namespace -strStmApr results file path:\n    objParser.add_argument('-strStmApr', required=True,\n                           metavar='/path/to/my_prior_res',\n                           help='Absolute file path to npy file with \\\n                                 stimulus apertures. Ignored if in testing \\\n                                 mode.'\n                           )\n\n    # Add argument to namespace -lgcNoise flag:\n    objParser.add_argument('-lgcNoise', dest='lgcNoise',\n                           action='store_true', default=False,\n                           help='Should noise be added to the simulated pRF\\\n                                 time course?')\n\n    # Add argument to namespace -lgcRtnNrl flag:\n    objParser.add_argument('-lgcRtnNrl', dest='lgcRtnNrl',\n                           action='store_true', default=False,\n                           help='Should neural time course, unconvolved with \\\n                                 hrf, be returned as well?')\n\n    objParser.add_argument('-supsur', nargs='+',\n                           help='List of floats that represent the ratio of \\\n                                 size neg surround to size pos center.',\n                           type=float, default=None)\n\n    # Namespace object containign arguments and values:\n    objNspc = objParser.parse_args()\n\n    return objNspc"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef login_required(wrapped):\n    @wraps(wrapped)\n    def wrapper(*args, **kwargs):\n        request = args[1]\n\n        auth_collection = settings.AUTH_COLLECTION[\n            settings.AUTH_COLLECTION.rfind('.') + 1:\n        ].lower()\n        auth_document = request.environ.get(auth_collection)\n\n        if auth_document and auth_document.is_authorized(request):\n            setattr(request, auth_collection, auth_document)\n            return wrapped(*args, **kwargs)\n\n        return Response(response=serialize(UnauthorizedError()), status=401)\n\n    if hasattr(wrapped, 'decorators'):\n        wrapper.decorators = wrapped.decorators\n        wrapper.decorators.append('login_required')\n    else:\n        wrapper.decorators = ['login_required']\n\n    return wrapper", "response": "Decorator that ensures that the user is logged in and authorized to execute requests\n    Except if the method is in authorized_methods of the auth_collection\n SARL"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _doAtomicFileCreation(filePath):\n    try:\n        _os.close(_os.open(filePath, _os.O_CREAT | _os.O_EXCL))\n        return True\n    except OSError as e:\n        if e.errno == _errno.EEXIST:\n            return False\n        else:\n            raise e", "response": "Tries to atomically create the requested file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind the next available file-name in a sequence. This function will create a file of zero size and will return the path to it to the caller. No files which exist will be altered in this operation and concurrent executions of this function will return separate files. In case of conflict, the function will attempt to generate a new file name up to maxattempts number of times before failing. The sequence will start from the base argument (default: 0). If used with the prefix/suffix, it will look for the next file in the sequence ignoring any gaps. Hence, if the files \"a.0.txt\" and \"a.3.txt\" exist, then the next file returned will be \"a.4.txt\" when called with prefix=\"a.\" and suffix=\".txt\". In case fnameGen is provided, the first generated filename which does not exist will be created and its path will be returned. Hence, if the files \"a.0.txt\" and \"a.3.txt\" exist, then the next file returned will be \"a.1.txt\" when called with fnameGen = lambda x : \"a.\" + str(x) + \".txt\" Args: folder - string which has path to the folder where the file should be created (default: '.') prefix - prefix of the file to be generated (default: '') suffix - suffix of the file to be generated (default: '') fnameGen - function which generates the filenames given a number as input (default: None) base - the first index to count (default: 0) maxattempts - number of attempts to create the file before failing with OSError (default: 10) Returns: Path of the file which follows the provided pattern and can be opened for writing. Raises: RuntimeError - If an incorrect combination of arguments is provided. OSError - If is unable to create a file (wrong path, drive full, illegal character in filename, etc.).", "response": "def findNextFile(folder='.',\n                 prefix=None,\n                 suffix=None,\n                 fnameGen=None,\n                 base=0,\n                 maxattempts=10):\n    \"\"\"Finds the next available file-name in a sequence.\n\n    This function will create a file of zero size and will return the path to\n    it to the caller. No files which exist will be altered in this operation\n    and concurrent executions of this function will return separate files. In\n    case of conflict, the function will attempt to generate a new file name up\n    to maxattempts number of times before failing.\n\n    The sequence will start from the base argument (default: 0).\n\n    If used with the prefix/suffix, it will look for the next file in the\n    sequence ignoring any gaps. Hence, if the files \"a.0.txt\" and \"a.3.txt\"\n    exist, then the next file returned will be \"a.4.txt\" when called with\n    prefix=\"a.\" and suffix=\".txt\".\n\n    In case fnameGen is provided, the first generated filename which does not\n    exist will be created and its path will be returned. Hence, if the files\n    \"a.0.txt\" and \"a.3.txt\" exist, then the next file returned will be\n    \"a.1.txt\" when called with fnameGen = lambda x : \"a.\" + str(x) + \".txt\"\n\n    Args:\n        folder      - string which has path to the folder where the file should\n                      be created (default: '.')\n        prefix      - prefix of the file to be generated (default: '')\n        suffix      - suffix of the file to be generated (default: '')\n        fnameGen    - function which generates the filenames given a number as\n                      input (default: None)\n        base        - the first index to count (default: 0)\n        maxattempts - number of attempts to create the file before failing with\n                      OSError (default: 10)\n\n    Returns:\n        Path of the file which follows the provided pattern and can be opened\n        for writing.\n\n    Raises:\n        RuntimeError - If an incorrect combination of arguments is provided.\n        OSError      - If is unable to create a file (wrong path, drive full,\n                       illegal character in filename, etc.).\n    \"\"\"\n    expFolder = _os.path.expanduser(_os.path.expandvars(folder))\n    return _findNextFile(expFolder, prefix, suffix, fnameGen,\n                         base, maxattempts, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes the command line script and returns the path of the next available file in the sequence.", "response": "def _run(passedArgs=None, stderr=None, stdout=None, exitFn=None):\n    \"\"\"Executes the script, gets prefix/suffix from the command prompt and\n    produces output on STDOUT. For help with command line options, invoke\n    script with '--help'.\n    \"\"\"\n\n    description = \"\"\"Finds the next available file-name in a sequence.\n\n    This program will create a file of zero size and will output the path to it\n    on STDOUT. No files which exist will be altered in this operation and\n    concurrent invocations of this program will return separate files. In case\n    of conflict, this program will attempt to generate a new file name up to\n    'maxattempts' number of times before failing. (See --max-attempts)\n\n    The sequence will start from the base argument (See --base, default: 0).\n\n    This program will look for the next file in the sequence ignoring any gaps.\n    Hence, if the files \"a.0.txt\" and \"a.3.txt\" exist, then the next file\n    returned will be \"a.4.txt\" when called with prefix=\"a.\" and suffix=\".txt\".\n\n    Returns:\n        Path of the file which follows the provided pattern and can be opened\n        for writing.\n\n        Otherwise, it prints an error (wrong path, drive full, illegal\n        character in filename, etc.) to stderr and exits with a non-zero error\n        code.\n    \"\"\"\n\n    argParser = _argparse.ArgumentParser(\n            description=description,\n            formatter_class=_argparse.RawTextHelpFormatter)\n\n    argParser.add_argument('prefix',\n                           help='Prefix for the sequence of files.')\n    argParser.add_argument('suffix',\n                           help='Suffix for the sequence of files.',\n                           nargs='?',\n                           default='')\n    argParser.add_argument('folder',\n                           help='The folder where the file will be created.',\n                           nargs='?',\n                           default=_os.getcwd())\n    argParser.add_argument('-m', '--max-attempts',\n                           help='Number of attempts to make before giving up.',\n                           default=10)\n    argParser.add_argument('-b', '--base',\n                           help='From where to start counting (default: 0).',\n                           default=0)\n\n    passedArgs = passedArgs if passedArgs is not None else _sys.argv[1:]\n    args = argParser.parse_args(passedArgs)\n\n    stdout = _sys.stdout if stdout is None else stdout\n    stderr = _sys.stderr if stderr is None else stderr\n\n    try:\n        nextFile = findNextFile(args.folder, prefix=args.prefix,\n                                suffix=args.suffix,\n                                maxattempts=args.max_attempts,\n                                base=args.base)\n        # The newline will be converted to the correct platform specific line\n        # ending as `sys.stdout` is opened in non-binary mode.\n        # Hence, we do not need to explicitly print out `\\r\\n` for Windows.\n        stdout.write(nextFile + u'\\n')\n    except OSError as e:\n        stderr.write(_os.strerror(e.errno) + u'\\n')\n        _sys.exit(e.errno)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the value str truncated to MAX_ERROR_STR_LEN characters. If the value is truncated it will be truncated to MAX_ERROR_STR_LEN characters. If the value is truncated it will be appended to the end.", "response": "def _errstr(value):\n    \"\"\"Returns the value str, truncated to MAX_ERROR_STR_LEN characters. If\n    it's truncated, the returned value will have '...' on the end.\n    \"\"\"\n\n    value = str(value) # We won't make the caller convert value to a string each time.\n    if len(value) > MAX_ERROR_STR_LEN:\n        return value[:MAX_ERROR_STR_LEN] + '...'\n    else:\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _getStrippedValue(value, strip):\n    if strip is None:\n        value = value.strip() # Call strip() with no arguments to strip whitespace.\n    elif isinstance(strip, str):\n        value = value.strip(strip) # Call strip(), passing the strip argument.\n    elif strip is False:\n        pass # Don't strip anything.\n    return value", "response": "Like the strip method except the strip argument describes\n    different behavior."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _raiseValidationException(standardExcMsg, customExcMsg=None):\n    if customExcMsg is None:\n        raise ValidationException(str(standardExcMsg))\n    else:\n        raise ValidationException(str(customExcMsg))", "response": "Raise ValidationException with standardExcMsg unless customExcMsg is specified."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _prevalidationCheck(value, blank, strip, allowlistRegexes, blocklistRegexes, excMsg=None):\n\n    # TODO - add a allowlistFirst and blocklistFirst to determine which is checked first. (Right now it's allowlist)\n\n    value = str(value)\n\n    # Optionally strip whitespace or other characters from value.\n    value = _getStrippedValue(value, strip)\n\n    # Validate for blank values.\n    if not blank and value == '':\n        # value is blank but blanks aren't allowed.\n        _raiseValidationException(_('Blank values are not allowed.'), excMsg)\n    elif blank and value == '':\n        return True, value # The value is blank and blanks are allowed, so return True to indicate that the caller should return value immediately.\n\n    # NOTE: We check if something matches the allow-list first, then we check the block-list second.\n\n    # Check the allowlistRegexes.\n    if allowlistRegexes is not None:\n        for regex in allowlistRegexes:\n            if isinstance(regex, re.Pattern):\n                if regex.search(value, re.IGNORECASE) is not None:\n                    return True, value # The value is in the allowlist, so return True to indicate that the caller should return value immediately.\n            else:\n                if re.search(regex, value, re.IGNORECASE) is not None:\n                    return True, value # The value is in the allowlist, so return True to indicate that the caller should return value immediately.\n\n    # Check the blocklistRegexes.\n    if blocklistRegexes is not None:\n        for blocklistRegexItem in blocklistRegexes:\n            if isinstance(blocklistRegexItem, str):\n                regex, response = blocklistRegexItem, DEFAULT_BLOCKLIST_RESPONSE\n            else:\n                regex, response = blocklistRegexItem\n\n            if isinstance(regex, re.Pattern) and regex.search(value, re.IGNORECASE) is not None:\n                _raiseValidationException(response, excMsg) # value is on a blocklist\n            elif re.search(regex, value, re.IGNORECASE) is not None:\n                _raiseValidationException(response, excMsg) # value is on a blocklist\n\n    return False, value", "response": "Internal function to perform the prevalidation check of the value passed for the parameter."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks that the input parameters are valid for the current base class. Returns None if the input parameters are invalid. Raises a PySimpleValidateException if any of the arguments are invalid.", "response": "def _validateGenericParameters(blank, strip, allowlistRegexes, blocklistRegexes):\n    \"\"\"Returns None if the blank, strip, and blocklistRegexes parameters are valid\n    of PySimpleValidate's validation functions have. Raises a PySimpleValidateException\n    if any of the arguments are invalid.\"\"\"\n\n    # Check blank parameter.\n    if not isinstance(blank, bool):\n        raise PySimpleValidateException('blank argument must be a bool')\n\n    # Check strip parameter.\n    if not isinstance(strip, (bool, str, type(None))):\n        raise PySimpleValidateException('strip argument must be a bool, None, or str')\n\n    # Check allowlistRegexes parameter (including each regex in it).\n    if allowlistRegexes is None:\n        allowlistRegexes = [] # allowlistRegexes defaults to a blank list.\n\n    try:\n        len(allowlistRegexes) # Make sure allowlistRegexes is a sequence.\n    except:\n        raise PySimpleValidateException('allowlistRegexes must be a sequence of regex_strs')\n    for response in allowlistRegexes:\n        if not isinstance(response[0], str):\n            raise PySimpleValidateException('allowlistRegexes must be a sequence of regex_strs')\n\n    # Check allowlistRegexes parameter (including each regex in it).\n    # NOTE: blocklistRegexes is NOT the same format as allowlistRegex, it can\n    # include an \"invalid input reason\" string to display if the input matches\n    # the blocklist regex.\n    if blocklistRegexes is None:\n        blocklistRegexes = [] # blocklistRegexes defaults to a blank list.\n\n    try:\n        len(blocklistRegexes) # Make sure blocklistRegexes is a sequence of (regex_str, str) or strs.\n    except:\n        raise PySimpleValidateException('blocklistRegexes must be a sequence of (regex_str, str) tuples or regex_strs')\n    for response in blocklistRegexes:\n        if isinstance(response, str):\n            continue\n        if len(response) != 2:\n            raise PySimpleValidateException('blocklistRegexes must be a sequence of (regex_str, str) tuples or regex_strs')\n        if not isinstance(response[0], str) or not isinstance(response[1], str):\n            raise PySimpleValidateException('blocklistRegexes must be a sequence of (regex_str, str) tuples or regex_strs')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nraises an exception if the arguments are invalid.", "response": "def _validateParamsFor_validateNum(min=None, max=None, lessThan=None, greaterThan=None):\n    \"\"\"Raises an exception if the arguments are invalid. This is called by\n    the validateNum(), validateInt(), and validateFloat() functions to\n    check its arguments. This code was refactored out to a separate function\n    so that the PyInputPlus module (or other modules) could check their\n    parameters' arguments for inputNum() etc.\n    \"\"\"\n\n    if (min is not None) and (greaterThan is not None):\n        raise PySimpleValidateException('only one argument for min or greaterThan can be passed, not both')\n    if (max is not None) and (lessThan is not None):\n        raise PySimpleValidateException('only one argument for max or lessThan can be passed, not both')\n\n    if (min is not None) and (max is not None) and (min > max):\n        raise PySimpleValidateException('the min argument must be less than or equal to the max argument')\n    if (min is not None) and (lessThan is not None) and (min >= lessThan):\n        raise PySimpleValidateException('the min argument must be less than the lessThan argument')\n    if (max is not None) and (greaterThan is not None) and (max <= greaterThan):\n        raise PySimpleValidateException('the max argument must be greater than the greaterThan argument')\n\n    for name, val in (('min', min), ('max', max),\n                      ('lessThan', lessThan), ('greaterThan', greaterThan)):\n        if not isinstance(val, (int, float, type(None))):\n            raise PySimpleValidateException(name + ' argument must be int, float, or NoneType')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nraises ValidationException if value is not a string.", "response": "def validateStr(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None, excMsg=None):\n    \"\"\"Raises ValidationException if value is not a string. This function\n    is identical to the built-in input() function, but also offers the\n    PySimpleValidate features of not allowing blank values by default,\n    automatically stripping whitespace, and having allowlist/blocklist\n    regular expressions.\n\n    Returns value, so it can be used inline in an expression:\n\n        print('Hello, ' + validateStr(your_name))\n\n    * value (str): The value being validated as a string.\n    * blank (bool): If True, a blank string will be accepted. Defaults to False. Defaults to False.\n    * strip (bool, str, None): If None, whitespace is stripped from value. If a str, the characters in it are stripped from value. If False, nothing is stripped.\n    * allowlistRegexes (Sequence, None): A sequence of regex str that will explicitly pass validation, even if they aren't numbers.\n    * blocklistRegexes (Sequence, None): A sequence of regex str or (regex_str, response_str) tuples that, if matched, will explicitly fail validation.\n    * excMsg (str): A custom message to use in the raised ValidationException.\n\n    >>> import pysimplevalidate as pysv\n    >>> pysv.validateStr('hello')\n    'hello'\n    >>> pysv.validateStr('')\n    Traceback (most recent call last):\n      ...\n    pysimplevalidate.ValidationException: Blank values are not allowed.\n    >>> pysv.validateStr('', blank=True)\n    ''\n    >>> pysv.validateStr('    hello    ')\n    'hello'\n    >>> pysv.validateStr('hello', blocklistRegexes=['hello'])\n    Traceback (most recent call last):\n      ...\n    pysimplevalidate.ValidationException: This response is invalid.\n    >>> pysv.validateStr('hello', blocklistRegexes=[('hello', 'Hello is not allowed')])\n    Traceback (most recent call last):\n        ...\n    pysimplevalidate.ValidationException: Hello is not allowed\n    >>> pysv.validateStr('hello', allowlistRegexes=['hello'], blocklistRegexes=['llo'])\n    'hello'\n    \"\"\"\n\n    # Validate parameters.\n    _validateGenericParameters(blank=blank, strip=strip, allowlistRegexes=None, blocklistRegexes=blocklistRegexes)\n    returnNow, value = _prevalidationCheck(value, blank, strip, allowlistRegexes, blocklistRegexes, excMsg)\n\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nraise ValidationException if value is not a number or int.", "response": "def validateNum(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None, _numType='num',\n                min=None, max=None, lessThan=None, greaterThan=None, excMsg=None):\n    \"\"\"Raises ValidationException if value is not a float or int.\n\n    Returns value, so it can be used inline in an expression:\n\n        print(2 + validateNum(your_number))\n\n    Note that since int() and float() ignore leading or trailing whitespace\n    when converting a string to a number, so does this validateNum().\n\n    * value (str): The value being validated as an int or float.\n    * blank (bool): If True, a blank string will be accepted. Defaults to False.\n    * strip (bool, str, None): If None, whitespace is stripped from value. If a str, the characters in it are stripped from value. If False, nothing is stripped.\n    * allowlistRegexes (Sequence, None): A sequence of regex str that will explicitly pass validation, even if they aren't numbers.\n    * blocklistRegexes (Sequence, None): A sequence of regex str or (regex_str, response_str) tuples that, if matched, will explicitly fail validation.\n    * _numType (str): One of 'num', 'int', or 'float' for the kind of number to validate against, where 'num' means int or float.\n    * min (int, float): The (inclusive) minimum value for the value to pass validation.\n    * max (int, float): The (inclusive) maximum value for the value to pass validation.\n    * lessThan (int, float): The (exclusive) minimum value for the value to pass validation.\n    * greaterThan (int, float): The (exclusive) maximum value for the value to pass validation.\n    * excMsg (str): A custom message to use in the raised ValidationException.\n\n    If you specify min or max, you cannot also respectively specify lessThan\n    or greaterThan. Doing so will raise PySimpleValidateException.\n\n    >>> import pysimplevalidate as pysv\n    >>> pysv.validateNum('3')\n    3\n    >>> pysv.validateNum('3.0')\n    3.0\n    >>> pysv.validateNum('    3.0    ')\n    3.0\n    >>> pysv.validateNum('549873259847598437598435798435793.589985743957435794357')\n    5.498732598475984e+32\n    >>> pysv.validateNum('4', lessThan=4)\n    Traceback (most recent call last):\n        ...\n    pysimplevalidate.ValidationException: Number must be less than 4.\n    >>> pysv.validateNum('4', max=4)\n    4\n    >>> pysv.validateNum('4', min=2, max=5)\n    4\n    \"\"\"\n\n    # Validate parameters.\n    _validateGenericParameters(blank=blank, strip=strip, allowlistRegexes=None, blocklistRegexes=blocklistRegexes)\n    _validateParamsFor_validateNum(min=min, max=max, lessThan=lessThan, greaterThan=greaterThan)\n\n    returnNow, value = _prevalidationCheck(value, blank, strip, allowlistRegexes, blocklistRegexes, excMsg)\n    if returnNow:\n        # If we can convert value to an int/float, then do so. For example,\n        # if an allowlist regex allows '42', then we should return 42/42.0.\n        if (_numType == 'num' and '.' in value) or (_numType == 'float'):\n            try:\n                return float(value)\n            except ValueError:\n                return value # Return the value as is.\n        if (_numType == 'num' and '.' not in value) or (_numType == 'int'):\n            try:\n                return int(value)\n            except ValueError:\n                return value # Return the value as is.\n\n    # Validate the value's type (and convert value back to a number type).\n    if (_numType == 'num' and '.' in value):\n        # We are expecting a \"num\" (float or int) type and the user entered a float.\n        try:\n            value = float(value)\n        except:\n            _raiseValidationException(_('%r is not a number.') % (_errstr(value)), excMsg)\n    elif (_numType == 'num' and '.' not in value):\n        # We are expecting a \"num\" (float or int) type and the user entered an int.\n        try:\n            value = int(value)\n        except:\n            _raiseValidationException(_('%r is not a number.') % (_errstr(value)), excMsg)\n    elif _numType == 'float':\n        try:\n            value = float(value)\n        except:\n            _raiseValidationException(_('%r is not a float.') % (_errstr(value)), excMsg)\n    elif _numType == 'int':\n        try:\n            if float(value) % 1 != 0:\n                # The number is a float that doesn't end with \".0\"\n                _raiseValidationException(_('%r is not an integer.') % (_errstr(value)), excMsg)\n            value = int(float(value))\n        except:\n            _raiseValidationException(_('%r is not an integer.') % (_errstr(value)), excMsg)\n\n    # Validate against min argument.\n    if min is not None and value < min:\n        _raiseValidationException(_('Number must be at minimum %s.') % (min), excMsg)\n\n    # Validate against max argument.\n    if max is not None and value > max:\n        _raiseValidationException(_('Number must be at maximum %s.') % (max), excMsg)\n\n    # Validate against max argument.\n    if lessThan is not None and value >= lessThan:\n        _raiseValidationException(_('Number must be less than %s.') % (lessThan), excMsg)\n\n    # Validate against max argument.\n    if greaterThan is not None and value <= greaterThan:\n        _raiseValidationException(_('Number must be greater than %s.') % (greaterThan), excMsg)\n\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nraising ValidationException if value is not an int.", "response": "def validateInt(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None,\n                min=None, max=None, lessThan=None, greaterThan=None, excMsg=None):\n    \"\"\"Raises ValidationException if value is not a int.\n\n    Returns value, so it can be used inline in an expression:\n\n        print(2 + validateInt(your_number))\n\n    Note that since int() and ignore leading or trailing whitespace\n    when converting a string to a number, so does this validateNum().\n\n    * value (str): The value being validated as an int or float.\n    * blank (bool): If True, a blank string will be accepted. Defaults to False.\n    * strip (bool, str, None): If None, whitespace is stripped from value. If a str, the characters in it are stripped from value. If False, nothing is stripped.\n    * allowlistRegexes (Sequence, None): A sequence of regex str that will explicitly pass validation, even if they aren't numbers.\n    * blocklistRegexes (Sequence, None): A sequence of regex str or (regex_str, response_str) tuples that, if matched, will explicitly fail validation.\n    * _numType (str): One of 'num', 'int', or 'float' for the kind of number to validate against, where 'num' means int or float.\n    * min (int, float): The (inclusive) minimum value for the value to pass validation.\n    * max (int, float): The (inclusive) maximum value for the value to pass validation.\n    * lessThan (int, float): The (exclusive) minimum value for the value to pass validation.\n    * greaterThan (int, float): The (exclusive) maximum value for the value to pass validation.\n    * excMsg (str): A custom message to use in the raised ValidationException.\n\n    If you specify min or max, you cannot also respectively specify lessThan\n    or greaterThan. Doing so will raise PySimpleValidateException.\n\n    >>> import pysimplevalidate as pysv\n    >>> pysv.validateInt('42')\n    42\n    >>> pysv.validateInt('forty two')\n    Traceback (most recent call last):\n        ...\n    pysimplevalidate.ValidationException: 'forty two' is not an integer.\n    \"\"\"\n    return validateNum(value=value, blank=blank, strip=strip, allowlistRegexes=None,\n                       blocklistRegexes=blocklistRegexes, _numType='int', min=min, max=max,\n                       lessThan=lessThan, greaterThan=greaterThan)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nraises PySimpleValidateException if the arguments are invalid.", "response": "def _validateParamsFor_validateChoice(choices, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None,\n                   numbered=False, lettered=False, caseSensitive=False, excMsg=None):\n    \"\"\"Raises PySimpleValidateException if the arguments are invalid. This is called by\n    the validateChoice() function to check its arguments. This code was\n    refactored out to a separate function so that the PyInputPlus module (or\n    other modules) could check their parameters' arguments for inputChoice().\n    \"\"\"\n\n    if not isinstance(caseSensitive, bool):\n        raise PySimpleValidateException('caseSensitive argument must be a bool')\n\n    try:\n        len(choices)\n    except:\n        raise PySimpleValidateException('choices arg must be a sequence')\n    if blank == False and len(choices) < 2:\n        raise PySimpleValidateException('choices must have at least two items if blank is False')\n    elif blank == True and len(choices) < 1:\n        raise PySimpleValidateException('choices must have at least one item')\n\n\n    _validateGenericParameters(blank=blank, strip=strip, allowlistRegexes=None, blocklistRegexes=blocklistRegexes)\n\n    for choice in choices:\n        if not isinstance(choice, str):\n            raise PySimpleValidateException('choice %r must be a string' % (_errstr(choice)))\n    if lettered and len(choices) > 26:\n        raise PySimpleValidateException('lettered argument cannot be True if there are more than 26 choices')\n    if numbered and lettered:\n        raise PySimpleValidateException('numbered and lettered arguments cannot both be True')\n\n    if len(choices) != len(set(choices)):\n        raise PySimpleValidateException('duplicate entries in choices argument')\n\n    if not caseSensitive and len(choices) != len(set([choice.upper() for choice in choices])):\n        raise PySimpleValidateException('duplicate case-insensitive entries in choices argument')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nraising ValidationException if value is not one of the values in choices. Returns the selected choice.", "response": "def validateChoice(value, choices, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None,\n                   numbered=False, lettered=False, caseSensitive=False, excMsg=None):\n    \"\"\"Raises ValidationException if value is not one of the values in\n    choices. Returns the selected choice.\n\n    Returns the value in choices that was selected, so it can be used inline\n    in an expression:\n\n        print('You chose ' + validateChoice(your_choice, ['cat', 'dog']))\n\n    Note that value itself is not returned: validateChoice('CAT', ['cat', 'dog'])\n    will return 'cat', not 'CAT'.\n\n    If lettered is True, lower or uppercase letters will be accepted regardless\n    of what caseSensitive is set to. The caseSensitive argument only matters\n    for matching with the text of the strings in choices.\n\n    * value (str): The value being validated.\n    * blank (bool): If True, a blank string will be accepted. Defaults to False.\n    * strip (bool, str, None): If None, whitespace is stripped from value. If a str, the characters in it are stripped from value. If False, nothing is stripped.\n    * allowlistRegexes (Sequence, None): A sequence of regex str that will explicitly pass validation, even if they aren't numbers.\n    * blocklistRegexes (Sequence, None): A sequence of regex str or (regex_str, response_str) tuples that, if matched, will explicitly fail validation.\n    * numbered (bool): If True, this function will also accept a string of the choice's number, i.e. '1' or '2'.\n    * lettered (bool): If True, this function will also accept a string of the choice's letter, i.e. 'A' or 'B' or 'a' or 'b'.\n    * caseSensitive (bool): If True, then the exact case of the option must be entered.\n    * excMsg (str): A custom message to use in the raised ValidationException.\n\n    Returns the choice selected as it appeared in choices. That is, if 'cat'\n    was a choice and the user entered 'CAT' while caseSensitive is False,\n    this function will return 'cat'.\n\n\n    >>> import pysimplevalidate as pysv\n    >>> pysv.validateChoice('dog', ['dog', 'cat', 'moose'])\n    'dog'\n\n    >>> pysv.validateChoice('DOG', ['dog', 'cat', 'moose'])\n    'dog'\n\n    >>> pysv.validateChoice('2', ['dog', 'cat', 'moose'], numbered=True)\n    'cat'\n\n    >>> pysv.validateChoice('a', ['dog', 'cat', 'moose'], lettered=True)\n    'dog'\n\n    >>> pysv.validateChoice('C', ['dog', 'cat', 'moose'], lettered=True)\n    'moose'\n\n    >>> pysv.validateChoice('dog', ['dog', 'cat', 'moose'], lettered=True)\n    'dog'\n\n    >>> pysv.validateChoice('spider', ['dog', 'cat', 'moose'])\n    Traceback (most recent call last):\n        ...\n    pysimplevalidate.ValidationException: 'spider' is not a valid choice.\n    \"\"\"\n\n    # Validate parameters.\n    _validateParamsFor_validateChoice(choices=choices, blank=blank, strip=strip, allowlistRegexes=None,\n        blocklistRegexes=blocklistRegexes, numbered=numbered, lettered=lettered, caseSensitive=caseSensitive)\n\n    if '' in choices:\n        # blank needs to be set to True here, otherwise '' won't be accepted as a choice.\n        blank = True\n\n    returnNow, value = _prevalidationCheck(value, blank, strip, allowlistRegexes, blocklistRegexes, excMsg)\n    if returnNow:\n        return value\n\n    # Validate against choices.\n    if value in choices:\n        return value\n    if numbered and value.isdigit() and 0 < int(value) <= len(choices): # value must be 1 to len(choices)\n        # Numbered options begins at 1, not 0.\n        return choices[int(value) - 1] # -1 because the numbers are 1 to len(choices) but the index are 0 to len(choices) - 1\n    if lettered and len(value) == 1 and value.isalpha() and 0 < ord(value.upper()) - 64 <= len(choices):\n        # Lettered options are always case-insensitive.\n        return choices[ord(value.upper()) - 65]\n    if not caseSensitive and value.upper() in [choice.upper() for choice in choices]:\n        # Return the original item in choices that value has a case-insensitive match with.\n        return choices[[choice.upper() for choice in choices].index(value.upper())]\n\n    _raiseValidationException(_('%r is not a valid choice.') % (_errstr(value)), excMsg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _validateParamsFor__validateToDateTimeFormat(formats, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None, excMsg=None):\n    _validateGenericParameters(blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes)\n    if formats is None:\n        raise PySimpleValidateException('formats parameter must be specified')\n\n    if isinstance(formats, str):\n        raise PySimpleValidateException('formats argument must be a non-str sequence of strftime format strings')\n\n    try:\n        len(formats)\n    except:\n        raise PySimpleValidateException('formats argument must be a non-str sequence of strftime format strings')\n\n    for format in formats:\n        try:\n            time.strftime(format) # This will raise an exception if the format is invalid.\n        except:\n            raise PySimpleValidateException('formats argument contains invalid strftime format strings')", "response": "Raises PySimpleValidateException if the arguments are invalid."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nraising ValidationException if value is not a time formatted in one of the formats formats. Returns a datetime. time object of value.", "response": "def validateTime(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None,\n                 formats=('%H:%M:%S', '%H:%M', '%X'), excMsg=None):\n    \"\"\"Raises ValidationException if value is not a time formatted in one\n    of the formats formats. Returns a datetime.time object of value.\n\n    * value (str): The value being validated as a time.\n    * blank (bool): If True, a blank string will be accepted. Defaults to False.\n    * strip (bool, str, None): If None, whitespace is stripped from value. If a str, the characters in it are stripped from value. If False, nothing is stripped.\n    * allowlistRegexes (Sequence, None): A sequence of regex str that will explicitly pass validation, even if they aren't numbers.\n    * blocklistRegexes (Sequence, None): A sequence of regex str or (regex_str, response_str) tuples that, if matched, will explicitly fail validation.\n    * formats: A tuple of strings that can be passed to time.strftime, dictating the possible formats for a valid time.\n    * excMsg (str): A custom message to use in the raised ValidationException.\n\n    >>> import pysimplevalidate as pysv\n    >>> pysv.validateTime('12:00:01')\n    datetime.time(12, 0, 1)\n    >>> pysv.validateTime('13:00:01')\n    datetime.time(13, 0, 1)\n    >>> pysv.validateTime('25:00:01')\n    Traceback (most recent call last):\n        ...\n    pysimplevalidate.ValidationException: '25:00:01' is not a valid time.\n    >>> pysv.validateTime('hour 12 minute 01', formats=['hour %H minute %M'])\n    datetime.time(12, 1)\n    \"\"\"\n\n    # TODO - handle this\n\n    # Reuse the logic in _validateToDateTimeFormat() for this function.\n    try:\n        dt = _validateToDateTimeFormat(value, formats, blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes)\n        return datetime.time(dt.hour, dt.minute, dt.second, dt.microsecond)\n    except ValidationException:\n        _raiseValidationException(_('%r is not a valid time.') % (_errstr(value)), excMsg)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nraise ValidationException if value is not a time formatted in one of the formats formats. Returns a datetime. date object of value.", "response": "def validateDate(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None,\n                 formats=('%Y/%m/%d', '%y/%m/%d', '%m/%d/%Y', '%m/%d/%y', '%x'), excMsg=None):\n    \"\"\"Raises ValidationException if value is not a time formatted in one\n    of the formats formats. Returns a datetime.date object of value.\n\n    * value (str): The value being validated as a time.\n    * blank (bool): If True, a blank string for value will be accepted.\n    * strip (bool, str, None): If None, whitespace is stripped from value. If a str, the characters in it are stripped from value. If False, nothing is stripped.\n    * allowlistRegexes (Sequence, None): A sequence of regex str that will explicitly pass validation, even if they aren't numbers.\n    * blocklistRegexes (Sequence, None): A sequence of regex str or (regex_str, response_str) tuples that, if matched, will explicitly fail validation.\n    * formats: A tuple of strings that can be passed to time.strftime, dictating the possible formats for a valid date.\n    * excMsg (str): A custom message to use in the raised ValidationException.\n\n    >>> import pysimplevalidate as pysv\n    >>> pysv.validateDate('2/29/2004')\n    datetime.date(2004, 2, 29)\n    >>> pysv.validateDate('2/29/2005')\n    Traceback (most recent call last):\n        ...\n    pysimplevalidate.ValidationException: '2/29/2005' is not a valid date.\n    >>> pysv.validateDate('September 2019', formats=['%B %Y'])\n    datetime.date(2019, 9, 1)\n    \"\"\"\n    # Reuse the logic in _validateToDateTimeFormat() for this function.\n    try:\n        dt = _validateToDateTimeFormat(value, formats, blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes)\n        return datetime.date(dt.year, dt.month, dt.day)\n    except ValidationException:\n        _raiseValidationException(_('%r is not a valid date.') % (_errstr(value)), excMsg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validateDatetime(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None,\n                     formats=('%Y/%m/%d %H:%M:%S', '%y/%m/%d %H:%M:%S', '%m/%d/%Y %H:%M:%S', '%m/%d/%y %H:%M:%S', '%x %H:%M:%S',\n                              '%Y/%m/%d %H:%M', '%y/%m/%d %H:%M', '%m/%d/%Y %H:%M', '%m/%d/%y %H:%M', '%x %H:%M',\n                              '%Y/%m/%d %H:%M:%S', '%y/%m/%d %H:%M:%S', '%m/%d/%Y %H:%M:%S', '%m/%d/%y %H:%M:%S', '%x %H:%M:%S'), excMsg=None):\n    \"\"\"Raises ValidationException if value is not a datetime formatted in one\n    of the formats formats. Returns a datetime.datetime object of value.\n\n    * value (str): The value being validated as a datetime.\n    * blank (bool): If True, a blank string will be accepted. Defaults to False.\n    * strip (bool, str, None): If None, whitespace is stripped from value. If a str, the characters in it are stripped from value. If False, nothing is stripped.\n    * allowlistRegexes (Sequence, None): A sequence of regex str that will explicitly pass validation, even if they aren't numbers.\n    * blocklistRegexes (Sequence, None): A sequence of regex str or (regex_str, response_str) tuples that, if matched, will explicitly fail validation.\n    * formats: A tuple of strings that can be passed to time.strftime, dictating the possible formats for a valid datetime.\n    * excMsg (str): A custom message to use in the raised ValidationException.\n\n    >>> import pysimplevalidate as pysv\n    >>> pysv.validateDatetime('2018/10/31 12:00:01')\n    datetime.datetime(2018, 10, 31, 12, 0, 1)\n    >>> pysv.validateDatetime('10/31/2018 12:00:01')\n    datetime.datetime(2018, 10, 31, 12, 0, 1)\n    >>> pysv.validateDatetime('10/31/2018')\n    Traceback (most recent call last):\n        ...\n    pysimplevalidate.ValidationException: '10/31/2018' is not a valid date and time.\n    \"\"\"\n\n    # Reuse the logic in _validateToDateTimeFormat() for this function.\n    try:\n        return _validateToDateTimeFormat(value, formats, blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes)\n    except ValidationException:\n        _raiseValidationException(_('%r is not a valid date and time.') % (_errstr(value)), excMsg)", "response": "Raises ValidationException if value is not a datetime formatted in one\n    of the formats formats. Returns a datetime. datetime object of the datetime formatted in one\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validateFilename(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None, excMsg=None):\n\n    returnNow, value = _prevalidationCheck(value, blank, strip, allowlistRegexes, blocklistRegexes, excMsg)\n    if returnNow:\n        return value\n\n    if (value != value.strip()) or (any(c in value for c in '\\\\/:*?\"<>|')):\n        _raiseValidationException(_('%r is not a valid filename.') % (_errstr(value)), excMsg)\n    return value", "response": "Raises ValidationException if value is not a valid filename."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validateFilepath(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None, excMsg=None, mustExist=False):\n    returnNow, value = _prevalidationCheck(value, blank, strip, allowlistRegexes, blocklistRegexes, excMsg)\n    if returnNow:\n        return value\n\n    if (value != value.strip()) or (any(c in value for c in '*?\"<>|')): # Same as validateFilename, except we allow \\ and / and :\n        if ':' in value:\n            if value.find(':', 2) != -1 or not value[0].isalpha():\n                # For Windows: Colon can only be found at the beginning, e.g. 'C:\\', or the first letter is not a letter drive.\n                _raiseValidationException(_('%r is not a valid file path.') % (_errstr(value)), excMsg)\n        _raiseValidationException(_('%r is not a valid file path.') % (_errstr(value)), excMsg)\n    return value\n    raise NotImplementedError()", "response": "Raises ValidationException if value is not a valid file path. Returns the value argument."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validateIP(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None, excMsg=None):\n    # Validate parameters.\n    _validateGenericParameters(blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes)\n\n    returnNow, value = _prevalidationCheck(value, blank, strip, allowlistRegexes, blocklistRegexes, excMsg)\n    if returnNow:\n        return value\n\n    # Reuse the logic in validateRegex()\n    try:\n        try:\n            # Check if value is an IPv4 address.\n            if validateRegex(value=value, regex=IPV4_REGEX, blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes):\n                return value\n        except:\n            pass # Go on to check if it's an IPv6 address.\n\n        # Check if value is an IPv6 address.\n        if validateRegex(value=value, regex=IPV6_REGEX, blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes):\n            return value\n    except ValidationException:\n        _raiseValidationException(_('%r is not a valid IP address.') % (_errstr(value)), excMsg)", "response": "Raises ValidationException if value is not an IPv4 or IPv6 address."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nraises ValidationException if value does not match the regular expression in regex.", "response": "def validateRegex(value, regex, flags=0, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None, excMsg=None):\n    \"\"\"Raises ValidationException if value does not match the regular expression in regex.\n    Returns the value argument.\n\n    This is similar to calling inputStr() and using the allowlistRegexes\n    keyword argument, however, validateRegex() allows you to pass regex\n    flags such as re.IGNORECASE or re.VERBOSE. You can also pass a regex\n    object directly.\n\n    If you want to check if a string is a regular expression string, call\n    validateRegexStr().\n\n    * value (str): The value being validated as a regular expression string.\n    * regex (str, regex): The regular expression to match the value against.\n    * flags (int): Identical to the flags argument in re.compile(). Pass re.VERBOSE et al here.\n    * blank (bool): If True, a blank string will be accepted. Defaults to False.\n    * strip (bool, str, None): If None, whitespace is stripped from value. If a str, the characters in it are stripped from value. If False, nothing is stripped.\n    * allowlistRegexes (Sequence, None): A sequence of regex str that will explicitly pass validation, even if they aren't numbers.\n    * blocklistRegexes (Sequence, None): A sequence of regex str or (regex_str, response_str) tuples that, if matched, will explicitly fail validation.\n    * excMsg (str): A custom message to use in the raised ValidationException.\n\n    >>> pysv.validateRegex('cat bat rat', r'(cat)|(dog)|(moose)', re.IGNORECASE)\n    'cat'\n    >>> pysv.validateRegex('He said \"Hello\".', r'\"(.*?)\"', re.IGNORECASE)\n    '\"Hello\"'\n    \"\"\"\n\n    # Validate parameters.\n    _validateGenericParameters(blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes)\n\n    returnNow, value = _prevalidationCheck(value, blank, strip, allowlistRegexes, blocklistRegexes, excMsg)\n    if returnNow:\n        return value\n\n    # Search value with regex, whether regex is a str or regex object.\n    if isinstance(regex, str):\n        # TODO - check flags to see they're valid regex flags.\n        mo = re.compile(regex, flags).search(value)\n    elif isinstance(regex, REGEX_TYPE):\n        mo = regex.search(value)\n    else:\n        raise PySimpleValidateException('regex must be a str or regex object')\n\n    if mo is not None:\n        return mo.group()\n    else:\n        _raiseValidationException(_('%r does not match the specified pattern.') % (_errstr(value)), excMsg)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validateRegexStr(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None, excMsg=None):\n\n    # TODO - I'd be nice to check regexes in other languages, i.e. JS and Perl.\n    _validateGenericParameters(blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes)\n\n    returnNow, value = _prevalidationCheck(value, blank, strip, allowlistRegexes, blocklistRegexes, excMsg)\n    if returnNow:\n        return value\n\n    try:\n        return re.compile(value)\n    except Exception as ex:\n        _raiseValidationException(_('%r is not a valid regular expression: %s') % (_errstr(value), ex), excMsg)", "response": "Raises ValidationException if value can t be used as a regular expression string. Returns the value argument as a regex object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validateURL(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None, excMsg=None):\n\n    # Reuse the logic in validateRegex()\n    try:\n        result = validateRegex(value=value, regex=URL_REGEX, blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes)\n        if result is not None:\n            return result\n    except ValidationException:\n        # 'localhost' is also an acceptable URL:\n        if value == 'localhost':\n            return value\n\n        _raiseValidationException(_('%r is not a valid URL.') % (value), excMsg)", "response": "Raises ValidationException if value is not a URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validateEmail(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None, excMsg=None):\n\n    # Reuse the logic in validateRegex()\n    try:\n        result = validateRegex(value=value, regex=EMAIL_REGEX, blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes)\n        if result is not None:\n            return result\n    except ValidationException:\n        _raiseValidationException(_('%r is not a valid email address.') % (value), excMsg)", "response": "Raises ValidationException if value is not an email address. Returns the value argument."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nraising ValidationException if value is not a yes or no response.", "response": "def validateYesNo(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None, yesVal='yes', noVal='no', caseSensitive=False, excMsg=None):\n    \"\"\"Raises ValidationException if value is not a yes or no response.\n    Returns the yesVal or noVal argument, not value.\n\n    Note that value can be any case (by default) and can also just match the\n\n    * value (str): The value being validated as an email address.\n    * blank (bool):  If True, a blank string will be accepted. Defaults to False.\n    * strip (bool, str, None): If None, whitespace is stripped from value. If a str, the characters in it are stripped from value. If False, nothing is stripped.\n    * allowlistRegexes (Sequence, None): A sequence of regex str that will explicitly pass validation, even if they aren't numbers.\n    * blocklistRegexes (Sequence, None): A sequence of regex str or (regex_str, response_str) tuples that, if matched, will explicitly fail validation.\n    * caseSensitive (bool): Determines if value must match the case of yesVal and noVal. Defaults to False.\n    * excMsg (str): A custom message to use in the raised ValidationException.\n\n    >>> import pysimplevalidate as pysv\n    >>> pysv.validateYesNo('y')\n    'yes'\n    >>> pysv.validateYesNo('YES')\n    'yes'\n    >>> pysv.validateYesNo('No')\n    'no'\n    >>> pysv.validateYesNo('OUI', yesVal='oui', noVal='no')\n    'oui'\n    \"\"\"\n\n    # Validate parameters. TODO - can probably improve this to remove the duplication.\n    _validateGenericParameters(blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes)\n\n    returnNow, value = _prevalidationCheck(value, blank, strip, allowlistRegexes, blocklistRegexes, excMsg)\n    if returnNow:\n        return value\n\n    yesVal = str(yesVal)\n    noVal = str(noVal)\n    if len(yesVal) == 0:\n        raise PySimpleValidateException('yesVal argument must be a non-empty string.')\n    if len(noVal) == 0:\n        raise PySimpleValidateException('noVal argument must be a non-empty string.')\n    if (yesVal == noVal) or (not caseSensitive and yesVal.upper() == noVal.upper()):\n        raise PySimpleValidateException('yesVal and noVal arguments must be different.')\n    if (yesVal[0] == noVal[0]) or (not caseSensitive and yesVal[0].upper() == noVal[0].upper()):\n        raise PySimpleValidateException('first character of yesVal and noVal arguments must be different')\n\n    returnNow, value = _prevalidationCheck(value, blank, strip, allowlistRegexes, blocklistRegexes, excMsg)\n    if returnNow:\n        return value\n\n    if caseSensitive:\n        if value in (yesVal, yesVal[0]):\n            return yesVal\n        elif value in (noVal, noVal[0]):\n            return noVal\n    else:\n        if value.upper() in (yesVal.upper(), yesVal[0].upper()):\n            return yesVal\n        elif value.upper() in (noVal.upper(), noVal[0].upper()):\n            return noVal\n\n    _raiseValidationException(_('%r is not a valid %s/%s response.') % (_errstr(value), yesVal, noVal), excMsg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nraise ValidationException if value is not an email address. Returns the yesVal or noVal argument.", "response": "def validateBool(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None, trueVal='True', falseVal='False', caseSensitive=False, excMsg=None):\n    \"\"\"Raises ValidationException if value is not an email address.\n    Returns the yesVal or noVal argument, not value.\n\n    * value (str): The value being validated as an email address.\n    * blank (bool):  If True, a blank string will be accepted. Defaults to False.\n    * strip (bool, str, None): If None, whitespace is stripped from value. If a str, the characters in it are stripped from value. If False, nothing is stripped.\n    * allowlistRegexes (Sequence, None): A sequence of regex str that will explicitly pass validation, even if they aren't numbers.\n    * blocklistRegexes (Sequence, None): A sequence of regex str or (regex_str, response_str) tuples that, if matched, will explicitly fail validation.\n    * excMsg (str): A custom message to use in the raised ValidationException.\n\n    >>> import pysimplevalidate as pysv\n    >>> pysv.validateYesNo('y')\n    'yes'\n    >>> pysv.validateYesNo('YES')\n    'yes'\n    >>> pysv.validateYesNo('No')\n    'no'\n    >>> pysv.validateYesNo('OUI', yesVal='oui', noVal='no')\n    'oui'\n    \"\"\"\n\n    # Validate parameters. TODO - can probably improve this to remove the duplication.\n    _validateGenericParameters(blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes)\n\n    returnNow, value = _prevalidationCheck(value, blank, strip, allowlistRegexes, blocklistRegexes, excMsg)\n    if returnNow:\n        return value\n\n    # Replace the exception messages used in validateYesNo():\n    trueVal = str(trueVal)\n    falseVal = str(falseVal)\n    if len(trueVal) == 0:\n        raise PySimpleValidateException('trueVal argument must be a non-empty string.')\n    if len(falseVal) == 0:\n        raise PySimpleValidateException('falseVal argument must be a non-empty string.')\n    if (trueVal == falseVal) or (not caseSensitive and trueVal.upper() == falseVal.upper()):\n        raise PySimpleValidateException('trueVal and noVal arguments must be different.')\n    if (trueVal[0] == falseVal[0]) or (not caseSensitive and trueVal[0].upper() == falseVal[0].upper()):\n        raise PySimpleValidateException('first character of trueVal and noVal arguments must be different')\n\n    result = validateYesNo(value, blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes, yesVal=trueVal, noVal=falseVal, caseSensitive=caseSensitive, excMsg=None)\n\n    # Return a bool value instead of a string.\n    if result == trueVal:\n        return True\n    elif result == falseVal:\n        return False\n    else:\n        assert False, 'inner validateYesNo() call returned something that was not yesVal or noVal. This should never happen.'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validateState(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None, excMsg=None, returnStateName=False):\n\n    # TODO - note that this is USA-centric. I should work on trying to make this more international.\n\n    # Validate parameters.\n    _validateGenericParameters(blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes)\n\n    returnNow, value = _prevalidationCheck(value, blank, strip, allowlistRegexes, blocklistRegexes, excMsg)\n    if returnNow:\n        return value\n\n    if value.upper() in USA_STATES_UPPER.keys(): # check if value is a state abbreviation\n        if returnStateName:\n            return USA_STATES[value.upper()] # Return full state name.\n        else:\n            return value.upper() # Return abbreviation.\n    elif value.title() in USA_STATES.values(): # check if value is a state name\n        if returnStateName:\n            return value.title() # Return full state name.\n        else:\n            return USA_STATES_REVERSED[value.title()] # Return abbreviation.\n\n    _raiseValidationException(_('%r is not a state.') % (_errstr(value)), excMsg)", "response": "Raises ValidationException if value is not a USA state. Returns the capitalized state abbreviation unless returnStateName is True\n    Returns the titlecased state name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nraise ValidationException if value is not a month. Returns the titlecased month name.", "response": "def validateMonth(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None, monthNames=ENGLISH_MONTHS, excMsg=None):\n    \"\"\"Raises ValidationException if value is not a month, like 'Jan' or 'March'.\n    Returns the titlecased month.\n\n    * value (str): The value being validated as an email address.\n    * blank (bool):  If True, a blank string will be accepted. Defaults to False.\n    * strip (bool, str, None): If None, whitespace is stripped from value. If a str, the characters in it are stripped from value. If False, nothing is stripped.\n    * allowlistRegexes (Sequence, None): A sequence of regex str that will explicitly pass validation, even if they aren't numbers.\n    * blocklistRegexes (Sequence, None): A sequence of regex str or (regex_str, response_str) tuples that, if matched, will explicitly fail validation.\n    * monthNames (Mapping): A mapping of uppercase month abbreviations to month names, i.e. {'JAN': 'January', ... }. The default provides English month names.\n    * excMsg (str): A custom message to use in the raised ValidationException.\n\n    >>> import pysimplevalidate as pysv\n    >>> pysv.validateMonth('Jan')\n    'January'\n    >>> pysv.validateMonth('MARCH')\n    'March'\n    \"\"\"\n\n    # returns full month name, e.g. 'January'\n\n    # Validate parameters.\n    _validateGenericParameters(blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes)\n\n    returnNow, value = _prevalidationCheck(value, blank, strip, allowlistRegexes, blocklistRegexes, excMsg)\n    if returnNow:\n        return value\n\n\n    try:\n        if (monthNames == ENGLISH_MONTHS) and (1 <= int(value) <= 12): # This check here only applies to months, not when validateDayOfWeek() calls this function.\n            return ENGLISH_MONTH_NAMES[int(value) - 1]\n    except:\n        pass # continue if the user didn't enter a number 1 to 12.\n\n    # Both month names and month abbreviations will be at least 3 characters.\n    if len(value) < 3:\n        _raiseValidationException(_('%r is not a month.') % (_errstr(value)), excMsg)\n\n    if value[:3].upper() in monthNames.keys(): # check if value is a month abbreviation\n        return monthNames[value[:3].upper()] # It turns out that titlecase is good for all the month.\n    elif value.upper() in monthNames.values(): # check if value is a month name\n        return value.title()\n\n    _raiseValidationException(_('%r is not a month.') % (_errstr(value)), excMsg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nraise ValidationException if value is not a day of the week such as Mon or Friday. Returns the titlecased day of the week.", "response": "def validateDayOfWeek(value, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None, dayNames=ENGLISH_DAYS_OF_WEEK, excMsg=None):\n    \"\"\"Raises ValidationException if value is not a day of the week, such as 'Mon' or 'Friday'.\n    Returns the titlecased day of the week.\n\n    * value (str): The value being validated as a day of the week.\n    * blank (bool):  If True, a blank string will be accepted. Defaults to False.\n    * strip (bool, str, None): If None, whitespace is stripped from value. If a str, the characters in it are stripped from value. If False, nothing is stripped.\n    * allowlistRegexes (Sequence, None): A sequence of regex str that will explicitly pass validation, even if they aren't numbers.\n    * blocklistRegexes (Sequence, None): A sequence of regex str or (regex_str, response_str) tuples that, if matched, will explicitly fail validation.\n    * dayNames (Mapping): A mapping of uppercase day abbreviations to day names, i.e. {'SUN': 'Sunday', ...} The default provides English day names.\n    * excMsg (str): A custom message to use in the raised ValidationException.\n\n    >>> import pysimplevalidate as pysv\n    >>> pysv.validateDayOfWeek('mon')\n    'Monday'\n    >>> pysv.validateDayOfWeek('THURSday')\n    'Thursday'\n    \"\"\"\n\n    # TODO - reuse validateChoice for this function\n\n    # returns full day of the week str, e.g. 'Sunday'\n\n    # Reuses validateMonth.\n    try:\n        return validateMonth(value, blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes, monthNames=ENGLISH_DAYS_OF_WEEK)\n    except:\n        # Replace the exception message.\n        _raiseValidationException(_('%r is not a day of the week') % (_errstr(value)), excMsg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validateDayOfMonth(value, year, month, blank=False, strip=None, allowlistRegexes=None, blocklistRegexes=None, excMsg=None):\n    try:\n        daysInMonth = calendar.monthrange(year, month)[1]\n    except:\n        raise PySimpleValidateException('invalid arguments for year and/or month')\n\n    try:\n        return validateInt(value, blank=blank, strip=strip, allowlistRegexes=allowlistRegexes, blocklistRegexes=blocklistRegexes, min=1, max=daysInMonth)\n    except:\n        # Replace the exception message.\n        _raiseValidationException(_('%r is not a day in the month of %s %s') % (_errstr(value), ENGLISH_MONTH_NAMES[month - 1], year), excMsg)", "response": "Raises ValidationException if value is not a day of the month from the given year month."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_level(level_string):\n    levels = {'debug': logging.DEBUG, 'info': logging.INFO,\n              'warning': logging.WARNING, 'error': logging.ERROR,\n              'critical': logging.CRITICAL}\n    try:\n        level = levels[level_string.lower()]\n    except KeyError:\n        sys.exit('{0} is not a recognized logging level'.format(level_string))\n    else:\n        return level", "response": "Returns an appropriate logging level integer from a string name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconfiguring the logging system.", "response": "def config_logging(no_log_file, log_to, log_level, silent, verbosity):\n    \"\"\"\n    Configures and generates a Logger object, 'openaccess_epub' based on common\n    parameters used for console interface script execution in OpenAccess_EPUB.\n\n    These parameters are:\n      no_log_file\n          Boolean. Disables logging to file. If set to True, log_to and\n          log_level become irrelevant.\n      log_to\n          A string name indicating a file path for logging.\n      log_level\n          Logging level, one of: 'debug', 'info', 'warning', 'error', 'critical'\n      silent\n          Boolean\n      verbosity\n          Console logging level, one of: 'debug', 'info', 'warning', 'error',\n          'critical\n\n    This method currently only configures a console StreamHandler with a\n    message-only Formatter.\n    \"\"\"\n\n    log_level = get_level(log_level)\n    console_level = get_level(verbosity)\n\n    #We want to configure our openaccess_epub as the parent log\n    log = logging.getLogger('openaccess_epub')\n    log.setLevel(logging.DEBUG)  # Don't filter at the log level\n    standard = logging.Formatter(STANDARD_FORMAT)\n    message_only = logging.Formatter(MESSAGE_ONLY_FORMAT)\n\n    #Only add FileHandler IF it's allowed AND we have a name for it\n    if not no_log_file and log_to is not None:\n        fh = logging.FileHandler(filename=log_to)\n        fh.setLevel(log_level)\n        fh.setFormatter(standard)\n        log.addHandler(fh)\n\n    #Add on the console StreamHandler at verbosity level if silent not set\n    if not silent:\n        sh_echo = logging.StreamHandler(sys.stdout)\n        sh_echo.setLevel(console_level)\n        sh_echo.setFormatter(message_only)\n        log.addHandler(sh_echo)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rmp_pixel_deg_xys(vecX, vecY, vecPrfSd, tplPngSize,\n                      varExtXmin, varExtXmax, varExtYmin, varExtYmax):\n    \"\"\"Remap x, y, sigma parameters from pixel to degree.\n\n    Parameters\n    ----------\n    vecX : 1D numpy array\n        Array with possible x parametrs in pixels\n    vecY : 1D numpy array\n        Array with possible y parametrs in pixels\n    vecPrfSd : 1D numpy array\n        Array with possible sd parametrs in pixels\n    tplPngSize : tuple, 2\n        Pixel dimensions of the visual space in pixel (width, height).\n    varExtXmin : float\n        Extent of visual space from centre in negative x-direction (width)\n    varExtXmax : float\n        Extent of visual space from centre in positive x-direction (width)\n    varExtYmin : int\n        Extent of visual space from centre in negative y-direction (height)\n    varExtYmax : float\n        Extent of visual space from centre in positive y-direction (height)\n\n    Returns\n    -------\n    vecX : 1D numpy array\n        Array with possible x parametrs in degree\n    vecY : 1D numpy array\n        Array with possible y parametrs in degree\n    vecPrfSd : 1D numpy array\n        Array with possible sd parametrs in degree\n\n    \"\"\"\n\n    # Remap modelled x-positions of the pRFs:\n    vecXdgr = rmp_rng(vecX, varExtXmin, varExtXmax, varOldThrMin=0.0,\n                      varOldAbsMax=(tplPngSize[0] - 1))\n\n    # Remap modelled y-positions of the pRFs:\n    vecYdgr = rmp_rng(vecY, varExtYmin, varExtYmax, varOldThrMin=0.0,\n                      varOldAbsMax=(tplPngSize[1] - 1))\n\n    # We calculate the scaling factor from pixels to degrees of visual angle to\n    # separately for the x- and the y-directions (the two should be the same).\n    varPix2DgrX = np.divide((varExtXmax - varExtXmin), tplPngSize[0])\n    varPix2DgrY = np.divide((varExtYmax - varExtYmin), tplPngSize[1])\n\n    # Check whether varDgr2PixX and varDgr2PixY are similar:\n    strErrMsg = 'ERROR. The ratio of X and Y dimensions in ' + \\\n        'stimulus space (in pixels) do not agree'\n    assert 0.5 > np.absolute((varPix2DgrX - varPix2DgrY)), strErrMsg\n\n    # Convert prf sizes from degrees of visual angles to pixel\n    vecPrfSdDgr = np.multiply(vecPrfSd, varPix2DgrX)\n\n    # Return new values.\n    return vecXdgr, vecYdgr, vecPrfSdDgr", "response": "Remap x y sigma parameters from pixel to degree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an array with all possible model parameter combinations for a given set of pRF models.", "response": "def crt_mdl_prms(tplPngSize, varNum1, varExtXmin,  varExtXmax, varNum2,\n                 varExtYmin, varExtYmax, varNumPrfSizes, varPrfStdMin,\n                 varPrfStdMax, kwUnt='pix', kwCrd='crt'):\n    \"\"\"Create an array with all possible model parameter combinations\n\n    Parameters\n    ----------\n    tplPngSize : tuple, 2\n        Pixel dimensions of the visual space (width, height).\n    varNum1 : int, positive\n        Number of x-positions to model\n    varExtXmin : float\n        Extent of visual space from centre in negative x-direction (width)\n    varExtXmax : float\n        Extent of visual space from centre in positive x-direction (width)\n    varNum2 : float, positive\n        Number of y-positions to model.\n    varExtYmin : int\n        Extent of visual space from centre in negative y-direction (height)\n    varExtYmax : float\n        Extent of visual space from centre in positive y-direction (height)\n    varNumPrfSizes : int, positive\n        Number of pRF sizes to model.\n    varPrfStdMin : float, positive\n        Minimum pRF model size (standard deviation of 2D Gaussian)\n    varPrfStdMax : float, positive\n        Maximum pRF model size (standard deviation of 2D Gaussian)\n    kwUnt: str\n        Keyword to set the unit for model parameter combinations; model\n        parameters can be in pixels [\"pix\"] or degrees of visual angles [\"deg\"]\n    kwCrd: str\n        Keyword to set the coordinate system for model parameter combinations;\n        parameters can be in cartesian [\"crt\"] or polar [\"pol\"] coordinates\n\n    Returns\n    -------\n    aryMdlParams : 2d numpy array, shape [n_x_pos*n_y_pos*n_sd, 3]\n        Model parameters (x, y, sigma) for all models.\n\n    \"\"\"\n\n    # Number of pRF models to be created (i.e. number of possible\n    # combinations of x-position, y-position, and standard deviation):\n    varNumMdls = varNum1 * varNum2 * varNumPrfSizes\n\n    # Array for the x-position, y-position, and standard deviations for\n    # which pRF model time courses are going to be created, where the\n    # columns correspond to: (1) the x-position, (2) the y-position, and\n    # (3) the standard deviation. The parameters are in units of the\n    # upsampled visual space.\n    aryMdlParams = np.zeros((varNumMdls, 3), dtype=np.float32)\n\n    # Counter for parameter array:\n    varCntMdlPrms = 0\n\n    if kwCrd == 'crt':\n\n        # Vector with the moddeled x-positions of the pRFs:\n        vecX = np.linspace(varExtXmin, varExtXmax, varNum1, endpoint=True)\n\n        # Vector with the moddeled y-positions of the pRFs:\n        vecY = np.linspace(varExtYmin, varExtYmax, varNum2, endpoint=True)\n\n        # Vector with standard deviations pRF models (in degree of vis angle):\n        vecPrfSd = np.linspace(varPrfStdMin, varPrfStdMax, varNumPrfSizes,\n                               endpoint=True)\n\n        if kwUnt == 'deg':\n            # since parameters are already in degrees of visual angle,\n            # we do nothing\n            pass\n\n        elif kwUnt == 'pix':\n            # convert parameters to pixels\n            vecX, vecY, vecPrfSd = rmp_deg_pixel_xys(vecX, vecY, vecPrfSd,\n                                                     tplPngSize, varExtXmin,\n                                                     varExtXmax, varExtYmin,\n                                                     varExtYmax)\n\n        else:\n            print('Unknown keyword provided for possible model parameter ' +\n                  'combinations: should be either pix or deg')\n\n        # Put all combinations of x-position, y-position, and standard\n        # deviations into the array:\n\n        # Loop through x-positions:\n        for idxX in range(0, varNum1):\n\n            # Loop through y-positions:\n            for idxY in range(0, varNum2):\n\n                # Loop through standard deviations (of Gaussian pRF models):\n                for idxSd in range(0, varNumPrfSizes):\n\n                    # Place index and parameters in array:\n                    aryMdlParams[varCntMdlPrms, 0] = vecX[idxX]\n                    aryMdlParams[varCntMdlPrms, 1] = vecY[idxY]\n                    aryMdlParams[varCntMdlPrms, 2] = vecPrfSd[idxSd]\n\n                    # Increment parameter index:\n                    varCntMdlPrms += 1\n\n    elif kwCrd == 'pol':\n\n        # Vector with the radial position:\n        vecRad = np.linspace(0.0, varExtXmax, varNum1, endpoint=True)\n\n        # Vector with the angular position:\n        vecTht = np.linspace(0.0, 2*np.pi, varNum2, endpoint=False)\n\n        # Get all possible combinations on the grid, using matrix indexing ij\n        # of output\n        aryRad, aryTht = np.meshgrid(vecRad, vecTht, indexing='ij')\n\n        # Flatten arrays to be able to combine them with meshgrid\n        vecRad = aryRad.flatten()\n        vecTht = aryTht.flatten()\n\n        # Convert from polar to cartesian\n        vecX, vecY = map_pol_to_crt(vecTht, vecRad)\n\n        # Vector with standard deviations pRF models (in degree of vis angle):\n        vecPrfSd = np.linspace(varPrfStdMin, varPrfStdMax, varNumPrfSizes,\n                               endpoint=True)\n\n        if kwUnt == 'deg':\n            # since parameters are already in degrees of visual angle,\n            # we do nothing\n            pass\n\n        elif kwUnt == 'pix':\n            # convert parameters to pixels\n            vecX, vecY, vecPrfSd = rmp_deg_pixel_xys(vecX, vecY, vecPrfSd,\n                                                     tplPngSize, varExtXmin,\n                                                     varExtXmax, varExtYmin,\n                                                     varExtYmax)\n        # Put all combinations of x-position, y-position, and standard\n        # deviations into the array:\n\n        # Loop through x-positions:\n        for idxXY in range(0, varNum1*varNum2):\n\n            # Loop through standard deviations (of Gaussian pRF models):\n            for idxSd in range(0, varNumPrfSizes):\n\n                # Place index and parameters in array:\n                aryMdlParams[varCntMdlPrms, 0] = vecX[idxXY]\n                aryMdlParams[varCntMdlPrms, 1] = vecY[idxXY]\n                aryMdlParams[varCntMdlPrms, 2] = vecPrfSd[idxSd]\n\n                # Increment parameter index:\n                varCntMdlPrms += 1\n\n    else:\n        print('Unknown keyword provided for coordinate system for model ' +\n              'parameter combinations: should be either crt or pol')\n\n    return aryMdlParams"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating 2D Gauss models to spatial conditions.", "response": "def crt_mdl_rsp(arySptExpInf, tplPngSize, aryMdlParams, varPar, strCrd='crt',\n                lgcPrint=True):\n    \"\"\"Create responses of 2D Gauss models to spatial conditions.\n\n    Parameters\n    ----------\n    arySptExpInf : 3d numpy array, shape [n_x_pix, n_y_pix, n_conditions]\n        All spatial conditions stacked along second axis.\n    tplPngSize : tuple, 2\n        Pixel dimensions of the visual space (width, height).\n    aryMdlParams : 2d numpy array, shape [n_x_pos*n_y_pos*n_sd, 3]\n        Model parameters (x, y, sigma) for all models.\n    varPar : int, positive\n        Number of cores to parallelize over.\n    strCrd, string, either 'crt' or 'pol'\n        Whether model parameters are provided in cartesian or polar coordinates\n    lgcPrint : boolean\n        Whether print statements should be executed.\n\n    Returns\n    -------\n    aryMdlCndRsp : 2d numpy array, shape [n_x_pos*n_y_pos*n_sd, n_cond]\n        Responses of 2D Gauss models to spatial conditions.\n\n    \"\"\"\n\n    if varPar == 1:\n        # if the number of cores requested by the user is equal to 1,\n        # we save the overhead of multiprocessing by calling aryMdlCndRsp\n        # directly\n        aryMdlCndRsp = cnvl_2D_gauss(0, aryMdlParams, arySptExpInf,\n                                     tplPngSize, None, strCrd=strCrd)\n\n    else:\n\n        # The long array with all the combinations of model parameters is put\n        # into separate chunks for parallelisation, using a list of arrays.\n        lstMdlParams = np.array_split(aryMdlParams, varPar)\n\n        # Create a queue to put the results in:\n        queOut = mp.Queue()\n\n        # Empty list for results from parallel processes (for pRF model\n        # responses):\n        lstMdlTc = [None] * varPar\n\n        # Empty list for processes:\n        lstPrcs = [None] * varPar\n        \n        if lgcPrint:\n            print('---------Running parallel processes')\n\n        # Create processes:\n        for idxPrc in range(0, varPar):\n            lstPrcs[idxPrc] = mp.Process(target=cnvl_2D_gauss,\n                                         args=(idxPrc, lstMdlParams[idxPrc],\n                                               arySptExpInf, tplPngSize, queOut\n                                               ),\n                                         kwargs={'strCrd': strCrd},\n                                         )\n            # Daemon (kills processes when exiting):\n            lstPrcs[idxPrc].Daemon = True\n\n        # Start processes:\n        for idxPrc in range(0, varPar):\n            lstPrcs[idxPrc].start()\n\n        # Collect results from queue:\n        for idxPrc in range(0, varPar):\n            lstMdlTc[idxPrc] = queOut.get(True)\n\n        # Join processes:\n        for idxPrc in range(0, varPar):\n            lstPrcs[idxPrc].join()\n\n        if lgcPrint:\n            print('---------Collecting results from parallel processes')\n        # Put output arrays from parallel process into one big array\n        lstMdlTc = sorted(lstMdlTc)\n        aryMdlCndRsp = np.empty((0, arySptExpInf.shape[-1]))\n        for idx in range(0, varPar):\n            aryMdlCndRsp = np.concatenate((aryMdlCndRsp, lstMdlTc[idx][1]),\n                                          axis=0)\n\n        # Clean up:\n        del(lstMdlParams)\n        del(lstMdlTc)\n\n    return aryMdlCndRsp.astype('float16')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef crt_nrl_tc(aryMdlRsp, aryCnd, aryOns, aryDrt, varTr, varNumVol,\n               varTmpOvsmpl, lgcPrint=True):\n    \"\"\"Create temporally upsampled neural time courses.\n\n    Parameters\n    ----------\n    aryMdlRsp : 2d numpy array, shape [n_x_pos * n_y_pos * n_sd, n_cond]\n        Responses of 2D Gauss models to spatial conditions.\n    aryCnd : np.array\n        1D array with condition identifiers (every condition has its own int)\n    aryOns : np.array, same len as aryCnd\n        1D array with condition onset times in seconds.\n    aryDrt : np.array, same len as aryCnd\n        1D array with condition durations of different conditions in seconds.\n    varTr : float, positive\n        Time to repeat (TR) of the (fMRI) experiment\n    varNumVol : float, positive\n        Number of data point (volumes) in the (fMRI) data\n    varTmpOvsmpl : float, positive\n        Factor by which the time courses should be temporally upsampled.\n    lgcPrint: boolean, default True\n        Should print messages be sent to user?\n\n    Returns\n    -------\n    aryNrlTc : 2d numpy array,\n               shape [n_x_pos * n_y_pos * n_sd, varNumVol*varTmpOvsmpl]\n        Neural time course models in temporally upsampled space\n\n    Notes\n    ---------\n    [1] This function first creates boxcar functions based on the  conditions\n        as they are specified in the temporal experiment information, provided\n        by the user in the csv file. Second, it then replaces the 1s in the\n        boxcar function by predicted condition values that were previously\n        calculated based on the overlap between the assumed 2D Gaussian for the\n        current model and the presented stimulus aperture for that condition.\n        Since the 2D Gaussian is normalized, the overlap value will be between\n        0 and 1.\n\n    \"\"\"\n\n    # adjust the input, if necessary, such that input is 2D\n    tplInpShp = aryMdlRsp.shape\n    aryMdlRsp = aryMdlRsp.reshape((-1, aryMdlRsp.shape[-1]))\n\n    # the first spatial condition might code the baseline (blank periods) with\n    # all zeros. If this is the case, remove the first spatial condition, since\n    # for temporal conditions this is removed automatically below and we need\n    # temporal and sptial conditions to maych\n    if np.all(aryMdlRsp[:, 0] == 0):\n        if lgcPrint:\n            print('------------Removed first spatial condition (all zeros)')\n        aryMdlRsp = aryMdlRsp[:, 1:]\n\n    # create boxcar functions in temporally upsampled space\n    aryBxCarTmp = create_boxcar(aryCnd, aryOns, aryDrt, varTr, varNumVol,\n                                aryExclCnd=np.array([0.]),\n                                varTmpOvsmpl=varTmpOvsmpl).T\n\n    # Make sure that aryMdlRsp and aryBxCarTmp have the same number of\n    # conditions\n    assert aryMdlRsp.shape[-1] == aryBxCarTmp.shape[0]\n\n    # pre-allocate pixelwise boxcar array\n    aryNrlTc = np.zeros((aryMdlRsp.shape[0], aryBxCarTmp.shape[-1]),\n                        dtype='float16')\n    # loop through boxcar functions of conditions\n    for ind, vecCndOcc in enumerate(aryBxCarTmp):\n        # get response predicted by models for this specific spatial condition\n        rspValPrdByMdl = aryMdlRsp[:, ind]\n        # insert predicted response value several times using broad-casting\n        aryNrlTc[..., vecCndOcc.astype('bool')] = rspValPrdByMdl[:, None]\n\n    # determine output shape\n    tplOutShp = tplInpShp[:-1] + (int(varNumVol*varTmpOvsmpl), )\n\n    return aryNrlTc.reshape(tplOutShp).astype('float16')", "response": "This function creates a neural time courses in a temporary space that is compatible with the neural time courses provided by the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates all spatial x feature prf time courses for a given set of features.", "response": "def crt_prf_ftr_tc(aryMdlRsp, aryTmpExpInf, varNumVol, varTr, varTmpOvsmpl,\n                   switchHrfSet, tplPngSize, varPar, dctPrm=None,\n                   lgcPrint=True):\n    \"\"\"Create all spatial x feature prf time courses.\n\n    Parameters\n    ----------\n    aryMdlRsp : 2d numpy array, shape [n_x_pos * n_y_pos * n_sd, n_cond]\n        Responses of 2D Gauss models to spatial conditions\n    aryTmpExpInf: 2d numpy array, shape [unknown, 4]\n        Temporal information about conditions\n    varNumVol : float, positive\n        Number of volumes of the (fMRI) data.\n    varTr : float, positive\n        Time to repeat (TR) of the (fMRI) experiment.\n    varTmpOvsmpl : int, positive\n        Factor by which the data hs been temporally upsampled.\n    switchHrfSet : int, (1, 2, 3)\n        Switch to determine which hrf basis functions are used\n    tplPngSize : tuple\n        Pixel dimensions of the visual space (width, height).\n    varPar : int, positive\n        Description of input 1.\n    dctPrm : dictionary, default None\n        Dictionary with customized hrf parameters. If this is None, default\n        hrf parameters will be used.\n    lgcPrint: boolean, default True\n        Should print messages be sent to user?\n\n    Returns\n    -------\n    aryNrlTcConv : 3d numpy array,\n                   shape [nr of models, nr of unique feautures, varNumVol]\n        Prf time course models\n\n    \"\"\"\n\n    # Identify number of unique features\n    vecFeat = np.unique(aryTmpExpInf[:, 3])\n    vecFeat = vecFeat[np.nonzero(vecFeat)[0]]\n\n    # Preallocate the output array\n    aryPrfTc = np.zeros((aryMdlRsp.shape[0], 0, varNumVol),\n                        dtype=np.float32)\n\n    # Loop over unique features\n    for indFtr, ftr in enumerate(vecFeat):\n\n        if lgcPrint:\n            print('---------Create prf time course model for feature ' +\n                  str(ftr))\n        # Derive sptial conditions, onsets and durations for this specific\n        # feature\n        aryTmpCnd = aryTmpExpInf[aryTmpExpInf[:, 3] == ftr, 0]\n        aryTmpOns = aryTmpExpInf[aryTmpExpInf[:, 3] == ftr, 1]\n        aryTmpDrt = aryTmpExpInf[aryTmpExpInf[:, 3] == ftr, 2]\n\n        # Create temporally upsampled neural time courses.\n        aryNrlTcTmp = crt_nrl_tc(aryMdlRsp, aryTmpCnd, aryTmpOns, aryTmpDrt,\n                                 varTr, varNumVol, varTmpOvsmpl,\n                                 lgcPrint=lgcPrint)\n        # Convolve with hrf to create model pRF time courses.\n        aryPrfTcTmp = crt_prf_tc(aryNrlTcTmp, varNumVol, varTr, varTmpOvsmpl,\n                                 switchHrfSet, tplPngSize, varPar,\n                                 dctPrm=dctPrm, lgcPrint=lgcPrint)\n        # Add temporal time course to time course that will be returned\n        aryPrfTc = np.concatenate((aryPrfTc, aryPrfTcTmp), axis=1)\n\n    return aryPrfTc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fnd_unq_rws(A, return_index=False, return_inverse=False):\n\n    A = np.require(A, requirements='C')\n    assert A.ndim == 2, \"array must be 2-dim'l\"\n\n    B = np.unique(A.view([('', A.dtype)]*A.shape[1]),\n                  return_index=return_index,\n                  return_inverse=return_inverse)\n\n    if return_index or return_inverse:\n        return (B[0].view(A.dtype).reshape((-1, A.shape[1]), order='C'),) \\\n            + B[1:]\n    else:\n        return B.view(A.dtype).reshape((-1, A.shape[1]), order='C')", "response": "Find unique rows in 2D array."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def _request(\n            self, method: str, endpoint: str, *, headers: dict = None) -> dict:\n        \"\"\"Make a request against air-matters.com.\"\"\"\n        url = '{0}/{1}'.format(API_URL_SCAFFOLD, endpoint)\n\n        if not headers:\n            headers = {}\n        headers.update({\n            'Host': DEFAULT_HOST,\n            'Origin': DEFAULT_ORIGIN,\n            'Referer': DEFAULT_ORIGIN,\n            'User-Agent': DEFAULT_USER_AGENT,\n        })\n\n        async with self._websession.request(\n                method,\n                url,\n                headers=headers,\n        ) as resp:\n            try:\n                resp.raise_for_status()\n                return await resp.json(content_type=None)\n            except client_exceptions.ClientError as err:\n                raise RequestError(\n                    'Error requesting data from {0}: {1}'.format(\n                        endpoint, err)) from None", "response": "Make a request against air - matters. com."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter_transform_response(get_response, params):\n\n    async def decorated_filter(request, *args, **kwargs):\n        response = await get_response(request, *args, **kwargs)\n\n        if isinstance(response, HTTPResponse) and \\\n                not isinstance(response, Response):\n            return response\n\n        if not isinstance(response, Response):\n            response = Response(response)\n\n        return response\n\n    return decorated_filter", "response": "This filter handles the response and transforms it to a Response instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning user report data.", "response": "async def _raw_user_report_data(self) -> list:\n        \"\"\"Return user report data (if accompanied by latitude/longitude).\"\"\"\n        data = await self._request('get', 'map/markers')\n        return [\n            location for location in data\n            if location['latitude'] and location['longitude']\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of states.", "response": "async def _raw_state_data(self) -> list:\n        \"\"\"Return a list of states.\"\"\"\n        data = await self._request('get', 'states')\n        return [\n            location for location in data\n            if location['name'] != 'United States'\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the nearest report to a lat / lon.", "response": "async def nearest_by_coordinates(\n            self, latitude: float, longitude: float) -> dict:\n        \"\"\"Get the nearest report (with local and state info) to a lat/lon.\"\"\"\n        # Since user data is more granular than state or CDC data, find the\n        # user report whose coordinates are closest to the provided\n        # coordinates:\n        nearest_user_report = get_nearest_by_coordinates(\n            await self.user_reports(), 'latitude', 'longitude', latitude,\n            longitude)\n\n        try:\n            # If the user report corresponds to a known state in\n            # flunearyou.org's database, we can safely assume that's the\n            # correct state:\n            nearest_state = next((\n                state for state in await self.state_data()\n                if state['place_id'] == nearest_user_report['contained_by']))\n        except StopIteration:\n            # If a place ID doesn't exist (e.g., ZIP Code 98012 doesn't have a\n            # place ID), calculate the nearest state by measuring the distance\n            # from the provided latitude/longitude to flunearyou.org's\n            # latitude/longitude that defines each state:\n            nearest_state = get_nearest_by_coordinates(\n                await self.state_data(), 'lat', 'lon', latitude, longitude)\n\n        return {'local': nearest_user_report, 'state': nearest_state}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef initialize(self, maxsize, history=None):\n        '''size specifies the maximum amount of history to keep'''\n        super().__init__()\n\n        self.maxsize = int(maxsize)\n        self.history = deque(maxlen=self.maxsize)  # Preserves order history\n\n        # If `items` are specified, then initialize with them\n        if history is not None:\n            for key, value in history:\n                self.insert(key, value)", "response": "initialize the internal state of the object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insert(self, key, value):\n        '''Adds a new key-value pair. Returns any discarded values.'''\n\n        # Add to history and catch expectorate\n        if len(self.history) == self.maxsize:\n            expectorate = self.history[0]\n        else:\n            expectorate = None\n\n        self.history.append((key, value))\n\n        # Add to the appropriate list of values\n        if key in self:\n            super().__getitem__(key).append(value)\n        else:\n            super().__setitem__(key, [value])\n\n        # Clean up old values\n        if expectorate is not None:\n            old_key, old_value = expectorate\n            super().__getitem__(old_key).pop(0)\n            if len(super().__getitem__(old_key)) == 0:\n                super().__delitem__(old_key)\n\n            return (old_key, old_value)", "response": "Adds a new key - value pair. Returns any discarded values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the recently inserted values up to a key", "response": "def up_to(self, key):\n        '''Gets the recently inserted values up to a key'''\n        for okey, ovalue in reversed(self.history):\n            if okey == key:\n                break\n            else:\n                yield ovalue"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resource(self, uri, methods=frozenset({'GET'}), **kwargs):\n        def decorator(f):\n            if kwargs.get('stream'):\n                f.is_stream = kwargs['stream']\n            self.add_resource(f, uri=uri, methods=methods, **kwargs)\n\n        return decorator", "response": "Decorator to add a resource route to the routing list."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a resource route.", "response": "def add_resource(self, handler, uri, methods=frozenset({'GET'}),\n                     **kwargs):\n        \"\"\"\n        Register a resource route.\n\n        :param handler: function or class instance\n        :param uri: path of the URL\n        :param methods: list or tuple of methods allowed\n        :param host:\n        :param strict_slashes:\n        :param version:\n        :param name: user defined route name for url_for\n        :param filters: List of callable that will filter request and\n                        response data\n        :param validators: List of callable added to the filter list.\n\n        :return: function or class instance\n        \"\"\"\n\n        sanic_args = ('host', 'strict_slashes', 'version', 'name')\n        view_kwargs = dict((k, v) for k, v in kwargs.items()\n                           if k in sanic_args)\n\n        filters = kwargs.get('filters', self.default_filters)\n        validators = kwargs.get('validators', [])\n\n        filter_list = list(filters) + list(validators)\n        filter_options = {\n            'filter_list': filter_list,\n            'handler': handler,\n            'uri': uri,\n            'methods': methods\n        }\n        filter_options.update(kwargs)\n\n        handler = self.init_filters(filter_list, filter_options)(handler)\n        return self.add_route(handler=handler, uri=uri, methods=methods,\n                              **view_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check(session, rev_id, page_id=None, radius=defaults.RADIUS,\n          before=None, window=None, rvprop=None):\n    \"\"\"\n    Checks the revert status of a revision.  With this method, you can\n    determine whether an edit is a 'reverting' edit, was 'reverted' by another\n    edit and/or was 'reverted_to' by another edit.\n\n    :Parameters:\n        session : :class:`mwapi.Session`\n            An API session to make use of\n        rev_id : int\n            the ID of the revision to check\n        page_id : int\n            the ID of the page the revision occupies (slower if not provided)\n        radius : int\n            a positive integer indicating the maximum number of revisions\n            that can be reverted\n        before : :class:`mwtypes.Timestamp`\n            if set, limits the search for *reverting* revisions to those which\n            were saved before this timestamp\n        window : int\n            if set, limits the search for *reverting* revisions to those which\n            were saved within `window` seconds after the reverted edit\n        rvprop : set( str )\n            a set of properties to include in revisions\n\n    :Returns:\n        A triple :class:`mwreverts.Revert` | `None`\n\n        * reverting -- If this edit reverted other edit(s)\n        * reverted -- If this edit was reverted by another edit\n        * reverted_to -- If this edit was reverted to by another edit\n\n    :Example:\n\n        >>> import mwapi\n        >>> import mwreverts.api\n        >>>\n        >>> session = mwapi.Session(\"https://en.wikipedia.org\")\n        >>>\n        >>> def print_revert(revert):\n        ...     if revert is None:\n        ...         print(None)\n        ...     else:\n        ...         print(revert.reverting['revid'],\n        ...               [r['revid'] for r in revert.reverteds],\n        ...               revert.reverted_to['revid'])\n        ...\n        >>> reverting, reverted, reverted_to = \\\n        ...     mwreverts.api.check(session, 679778587)\n        >>> print_revert(reverting)\n        None\n        >>> print_revert(reverted)\n        679778743 [679778587] 679742862\n        >>> print_revert(reverted_to)\n        None\n\n    \"\"\"\n\n    rev_id = int(rev_id)\n    radius = int(radius)\n    if radius < 1:\n        raise TypeError(\"invalid radius.  Expected a positive integer.\")\n\n    page_id = int(page_id) if page_id is not None else None\n    before = Timestamp(before) if before is not None else None\n\n    rvprop = set(rvprop) if rvprop is not None else set()\n\n    # If we don't have the page_id, we're going to need to look them up\n    if page_id is None:\n        page_id = get_page_id(session, rev_id)\n\n    # Load history and current rev\n    current_and_past_revs = list(n_edits_before(\n        session,\n        rev_id,\n        page_id,\n        n=radius + 1,\n        rvprop={'ids', 'timestamp', 'sha1'} | rvprop\n    ))\n\n    if len(current_and_past_revs) < 1:\n        raise KeyError(\"Revision {0} not found in page {1}.\"\n                       .format(rev_id, page_id))\n\n    current_rev, past_revs = (\n        current_and_past_revs[-1],  # Current\n        current_and_past_revs[:-1]  # Past revisions\n    )\n\n    if window is not None and before is None:\n        before = Timestamp(current_rev['timestamp']) + window\n\n    # Load future revisions\n    future_revs = list(n_edits_after(\n        session,\n        rev_id + 1,\n        page_id,\n        n=radius,\n        timestamp=before,\n        rvprop={'ids', 'timestamp', 'sha1'} | rvprop\n    ))\n\n    return build_revert_tuple(\n        rev_id, past_revs, current_rev, future_revs, radius)", "response": "This method checks the revert status of a revision."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking the revert status of a deleted revision.", "response": "def check_deleted(session, rev_id, title=None, timestamp=None,\n                  radius=defaults.RADIUS, before=None, window=None,\n                  rvprop=None):\n    \"\"\"\n    Checks the revert status of a deleted revision.  With this method, you can\n    determine whether an edit is a 'reverting' edit, was 'reverted' by another\n    edit and/or was 'reverted_to' by another edit.\n\n    :Parameters:\n        session : :class:`mwapi.Session`\n            An API session to make use of\n        rev_id : int\n            the ID of the revision to check\n        title : str\n            the title of the page the revision occupies (slower if not\n            provided) Note that the MediaWiki API expects the title to\n            include the namespace prefix (e.g. \"User_talk:EpochFail\")\n        radius : int\n            a positive integer indicating the maximum number of revisions\n            that can be reverted\n        before : :class:`mwtypes.Timestamp`\n            if set, limits the search for *reverting* revisions to those which\n            were saved before this timestamp\n        window : int\n            if set, limits the search for *reverting* revisions to those which\n            were saved within `window` seconds after the reverted edit\n        rvprop : set( str )\n            a set of properties to include in revisions\n\n    :Returns:\n        A triple :class:`mwreverts.Revert` | `None`\n\n        * reverting -- If this edit reverted other edit(s)\n        * reverted -- If this edit was reverted by another edit\n        * reverted_to -- If this edit was reverted to by another edit\n    \"\"\"\n\n    rev_id = int(rev_id)\n    radius = int(radius)\n    if radius < 1:\n        raise TypeError(\"invalid radius.  Expected a positive integer.\")\n\n    title = str(title) if title is not None else None\n    before = Timestamp(before) if before is not None else None\n\n    rvprop = set(rvprop) if rvprop is not None else set()\n\n    # If we don't have the title, we're going to need to look it up\n    if title is None or timestamp is None:\n        title, timestamp = get_deleted_title_and_timestamp(session, rev_id)\n\n    # Load history and current rev\n    current_and_past_revs = list(n_deleted_edits_before(\n        session, rev_id, title, timestamp, n=radius + 1,\n        rvprop={'ids', 'timestamp', 'sha1'} | rvprop\n    ))\n\n    if len(current_and_past_revs) < 1:\n        raise KeyError(\"Revision {0} not found in page {1}.\"\n                       .format(rev_id, title))\n\n    current_rev, past_revs = (\n        current_and_past_revs[-1],  # Current\n        current_and_past_revs[:-1]  # Past revisions\n    )\n\n    if window is not None and before is None:\n        before = Timestamp(current_rev['timestamp']) + window\n\n    # Load future revisions\n    future_revs = list(n_deleted_edits_after(\n        session, rev_id + 1, title, timestamp, n=radius, before=before,\n        rvprop={'ids', 'timestamp', 'sha1'} | rvprop\n    ))\n\n    return build_revert_tuple(\n        rev_id, past_revs, current_rev, future_revs, radius)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_commits(repo_dir, old_commit, new_commit, hide_merges=True):\n    repo = Repo(repo_dir)\n    commits = repo.iter_commits(rev=\"{0}..{1}\".format(old_commit, new_commit))\n    if hide_merges:\n        return [x for x in commits if not x.summary.startswith(\"Merge \")]\n    else:\n        return list(commits)", "response": "Find all commits between two commit SHAs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_commit_url(repo_url):\n    if \"github.com\" in repo_url:\n        return repo_url[:-4] if repo_url.endswith(\".git\") else repo_url\n    if \"git.openstack.org\" in repo_url:\n        uri = '/'.join(repo_url.split('/')[-2:])\n        return \"https://github.com/{0}\".format(uri)\n\n    # If it didn't match these conditions, just return it.\n    return repo_url", "response": "Determine URL to view commits for repo."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_projects(osa_repo_dir, commit):\n    # Check out the correct commit SHA from the repository\n    repo = Repo(osa_repo_dir)\n    checkout(repo, commit)\n\n    yaml_files = glob.glob(\n        '{0}/playbooks/defaults/repo_packages/*.yml'.format(osa_repo_dir)\n    )\n    yaml_parsed = []\n    for yaml_file in yaml_files:\n        with open(yaml_file, 'r') as f:\n            yaml_parsed.append(yaml.load(f))\n\n    merged_dicts = {k: v for d in yaml_parsed for k, v in d.items()}\n\n    return normalize_yaml(merged_dicts)", "response": "Get all projects from multiple YAML files."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads OSA role information at a particular commit.", "response": "def get_roles(osa_repo_dir, commit, role_requirements):\n    \"\"\"Read OSA role information at a particular commit.\"\"\"\n    repo = Repo(osa_repo_dir)\n\n    checkout(repo, commit)\n\n    log.info(\"Looking for file {f} in repo {r}\".format(r=osa_repo_dir,\n                                                       f=role_requirements))\n    filename = \"{0}/{1}\".format(osa_repo_dir, role_requirements)\n    with open(filename, 'r') as f:\n        roles_yaml = yaml.load(f)\n\n    return normalize_yaml(roles_yaml)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an OAI - OSS report header for OpenStack - Ansible.", "response": "def make_osa_report(repo_dir, old_commit, new_commit,\n                    args):\n    \"\"\"Create initial RST report header for OpenStack-Ansible.\"\"\"\n    update_repo(repo_dir, args.osa_repo_url, args.update)\n\n    # Are these commits valid?\n    validate_commits(repo_dir, [old_commit, new_commit])\n\n    # Do we have a valid commit range?\n    validate_commit_range(repo_dir, old_commit, new_commit)\n\n    # Get the commits in the range\n    commits = get_commits(repo_dir, old_commit, new_commit)\n\n    # Start off our report with a header and our OpenStack-Ansible commits.\n    template_vars = {\n        'args': args,\n        'repo': 'openstack-ansible',\n        'commits': commits,\n        'commit_base_url': get_commit_url(args.osa_repo_url),\n        'old_sha': old_commit,\n        'new_sha': new_commit\n    }\n    return render_template('offline-header.j2', template_vars)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_report(storage_directory, old_pins, new_pins, do_update=False,\n                version_mappings=None):\n    \"\"\"Create RST report from a list of projects/roles.\"\"\"\n    report = \"\"\n    version_mappings = version_mappings or {}\n    for new_pin in new_pins:\n        repo_name, repo_url, commit_sha = new_pin\n        commit_sha = version_mappings.get(repo_name, {}\n                                          ).get(commit_sha, commit_sha)\n\n        # Prepare our repo directory and clone the repo if needed. Only pull\n        # if the user requests it.\n        repo_dir = \"{0}/{1}\".format(storage_directory, repo_name)\n        update_repo(repo_dir, repo_url, do_update)\n\n        # Get the old SHA from the previous pins. If this pin didn't exist\n        # in the previous OSA revision, skip it. This could happen with newly-\n        # added projects and roles.\n        try:\n            commit_sha_old = next(x[2] for x in old_pins if x[0] == repo_name)\n        except Exception:\n            continue\n        else:\n            commit_sha_old = version_mappings.get(repo_name, {}\n                                                  ).get(commit_sha_old,\n                                                        commit_sha_old)\n\n        # Loop through the commits and render our template.\n        validate_commits(repo_dir, [commit_sha_old, commit_sha])\n        commits = get_commits(repo_dir, commit_sha_old, commit_sha)\n        template_vars = {\n            'repo': repo_name,\n            'commits': commits,\n            'commit_base_url': get_commit_url(repo_url),\n            'old_sha': commit_sha_old,\n            'new_sha': commit_sha\n        }\n        rst = render_template('offline-repo-changes.j2', template_vars)\n        report += rst\n\n    return report", "response": "Create a RST report from a list of projects and roles."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalize_yaml(yaml):\n    if isinstance(yaml, list):\n        # Normalize the roles YAML data\n        normalized_yaml = [(x['name'], x['src'], x.get('version', 'HEAD'))\n                           for x in yaml]\n    else:\n        # Extract the project names from the roles YAML and create a list of\n        # tuples.\n        projects = [x[:-9] for x in yaml.keys() if x.endswith('git_repo')]\n        normalized_yaml = []\n        for project in projects:\n            repo_url = yaml['{0}_git_repo'.format(project)]\n            commit_sha = yaml['{0}_git_install_branch'.format(project)]\n            normalized_yaml.append((project, repo_url, commit_sha))\n\n    return normalized_yaml", "response": "Normalize the YAML from project and role lookups."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nposts the report to a GitHub Gist and return the URL of the gist.", "response": "def post_gist(report_data, old_sha, new_sha):\n    \"\"\"Post the report to a GitHub Gist and return the URL of the gist.\"\"\"\n    payload = {\n        \"description\": (\"Changes in OpenStack-Ansible between \"\n                        \"{0} and {1}\".format(old_sha, new_sha)),\n        \"public\": True,\n        \"files\": {\n            \"osa-diff-{0}-{1}.rst\".format(old_sha, new_sha): {\n                \"content\": report_data\n            }\n        }\n    }\n    url = \"https://api.github.com/gists\"\n    r = requests.post(url, data=json.dumps(payload))\n    response = r.json()\n    return response['html_url']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prepare_storage_dir(storage_directory):\n    storage_directory = os.path.expanduser(storage_directory)\n    if not os.path.exists(storage_directory):\n        os.mkdir(storage_directory)\n\n    return storage_directory", "response": "Prepare the storage directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenders a jinja template.", "response": "def render_template(template_file, template_vars):\n    \"\"\"Render a jinja template.\"\"\"\n    # Load our Jinja templates\n    template_dir = \"{0}/templates\".format(\n        os.path.dirname(os.path.abspath(__file__))\n    )\n    jinja_env = jinja2.Environment(\n        loader=jinja2.FileSystemLoader(template_dir),\n        trim_blocks=True\n    )\n    rendered = jinja_env.get_template(template_file).render(template_vars)\n\n    return rendered"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresetting repository and optionally update it.", "response": "def repo_pull(repo_dir, repo_url, fetch=False):\n    \"\"\"Reset repository and optionally update it.\"\"\"\n    # Make sure the repository is reset to the master branch.\n    repo = Repo(repo_dir)\n    repo.git.clean(\"-df\")\n    repo.git.reset(\"--hard\")\n    repo.git.checkout(\"master\")\n    repo.head.reset(index=True, working_tree=True)\n\n    # Compile the refspec appropriately to ensure\n    # that if the repo is from github it includes\n    # all the refs needed, including PR's.\n    refspec_list = [\n        \"+refs/heads/*:refs/remotes/origin/*\",\n        \"+refs/heads/*:refs/heads/*\",\n        \"+refs/tags/*:refs/tags/*\"\n    ]\n    if \"github.com\" in repo_url:\n        refspec_list.extend([\n            \"+refs/pull/*:refs/remotes/origin/pr/*\",\n            \"+refs/heads/*:refs/remotes/origin/*\"])\n\n    # Only get the latest updates if requested.\n    if fetch:\n        repo.git.fetch([\"-u\", \"-v\", \"-f\",\n                        repo_url,\n                        refspec_list])\n    return repo"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncloning the repo if it doesn t exist already otherwise update it.", "response": "def update_repo(repo_dir, repo_url, fetch=False):\n    \"\"\"Clone the repo if it doesn't exist already, otherwise update it.\"\"\"\n    repo_exists = os.path.exists(repo_dir)\n    if not repo_exists:\n        log.info(\"Cloning repo {}\".format(repo_url))\n        repo = repo_clone(repo_dir, repo_url)\n\n    # Make sure the repo is properly prepared\n    # and has all the refs required\n    log.info(\"Fetching repo {} (fetch: {})\".format(repo_url, fetch))\n    repo = repo_pull(repo_dir, repo_url, fetch)\n\n    return repo"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntest if a commit exists in the repository.", "response": "def validate_commits(repo_dir, commits):\n    \"\"\"Test if a commit is valid for the repository.\"\"\"\n    log.debug(\"Validating {c} exist in {r}\".format(c=commits, r=repo_dir))\n    repo = Repo(repo_dir)\n    for commit in commits:\n        try:\n            commit = repo.commit(commit)\n        except Exception:\n            msg = (\"Commit {commit} could not be found in repo {repo}. \"\n                   \"You may need to pass --update to fetch the latest \"\n                   \"updates to the git repositories stored on \"\n                   \"your local computer.\".format(repo=repo_dir, commit=commit))\n            raise exceptions.InvalidCommitException(msg)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_commit_range(repo_dir, old_commit, new_commit):\n    # Are there any commits between the two commits that were provided?\n    try:\n        commits = get_commits(repo_dir, old_commit, new_commit)\n    except Exception:\n        commits = []\n    if len(commits) == 0:\n        # The user might have gotten their commits out of order. Let's flip\n        # the order of the commits and try again.\n        try:\n            commits = get_commits(repo_dir, new_commit, old_commit)\n        except Exception:\n            commits = []\n        if len(commits) == 0:\n            # Okay, so there really are no commits between the two commits\n            # provided by the user. :)\n            msg = (\"The commit range {0}..{1} is invalid for {2}.\"\n                   \"You may need to use the --update option to fetch the \"\n                   \"latest updates to the git repositories stored on your \"\n                   \"local computer.\".format(old_commit, new_commit, repo_dir))\n            raise exceptions.InvalidCommitRangeException(msg)\n        else:\n            return 'flip'\n\n    return True", "response": "Check if commit range is valid. Flip it if needed."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_release_notes(osa_repo_dir, osa_old_commit, osa_new_commit):\n    repo = Repo(osa_repo_dir)\n\n    # Get a list of tags, sorted\n    tags = repo.git.tag().split('\\n')\n    tags = sorted(tags, key=LooseVersion)\n    # Currently major tags are being printed after rc and\n    # b tags. We need to fix the list so that major\n    # tags are printed before rc and b releases\n    tags = _fix_tags_list(tags)\n\n    # Find the closest tag from a given SHA\n    # The tag found here is the tag that was cut\n    # either on or before the given SHA\n    checkout(repo, osa_old_commit)\n    old_tag = repo.git.describe()\n\n    # If the SHA given is between two release tags, then\n    # 'git describe' will return a tag in form of\n    # <tag>-<commitNum>-<sha>. For example:\n    # 14.0.2-3-g6931e26\n    # Since reno does not support this format, we need to\n    # strip away the commit number and sha bits.\n    if '-' in old_tag:\n        old_tag = old_tag[0:old_tag.index('-')]\n\n    # Get the nearest tag associated with the new commit\n    checkout(repo, osa_new_commit)\n    new_tag = repo.git.describe()\n    if '-' in new_tag:\n        nearest_new_tag = new_tag[0:new_tag.index('-')]\n    else:\n        nearest_new_tag = new_tag\n\n    # Truncate the tags list to only include versions\n    # between old_sha and new_sha. The latest release\n    # is not included in this list. That version will be\n    # printed separately in the following step.\n    tags = tags[tags.index(old_tag):tags.index(nearest_new_tag)]\n\n    release_notes = \"\"\n    # Checkout the new commit, then run reno to get the latest\n    # releasenotes that have been created or updated between\n    # the latest release and this new commit.\n    repo.git.checkout(osa_new_commit, '-f')\n    reno_report_command = ['reno',\n                           'report',\n                           '--earliest-version',\n                           nearest_new_tag]\n    reno_report_p = subprocess.Popen(reno_report_command,\n                                     cwd=osa_repo_dir,\n                                     stdout=subprocess.PIPE,\n                                     stderr=subprocess.PIPE)\n    reno_output = reno_report_p.communicate()[0].decode('UTF-8')\n    release_notes += reno_output\n\n    # We want to start with the latest packaged release first, so\n    # the tags list is reversed\n    for version in reversed(tags):\n        # If version is an rc or b tag, and it has a major\n        # release tag, then skip it. There is no need to print\n        # release notes for an rc or b release unless we are\n        # comparing shas between two rc or b releases.\n        repo.git.checkout(version, '-f')\n        # We are outputing one version at a time here\n        reno_report_command = ['reno',\n                               'report',\n                               '--branch',\n                               version,\n                               '--earliest-version',\n                               version]\n        reno_report_p = subprocess.Popen(reno_report_command,\n                                         cwd=osa_repo_dir,\n                                         stdout=subprocess.PIPE,\n                                         stderr=subprocess.PIPE)\n        reno_output = reno_report_p.communicate()[0].decode('UTF-8')\n        # We need to ensure the output includes the version we are concerned\n        # about.\n        # This is due to https://bugs.launchpad.net/reno/+bug/1670173\n        if version in reno_output:\n            release_notes += reno_output\n\n    # Clean up \"Release Notes\" title. We don't need this title for\n    # each tagged release.\n    release_notes = release_notes.replace(\n        \"=============\\nRelease Notes\\n=============\",\n        \"\"\n    )\n    # Replace headers that contain '=' with '~' to comply with osa-differ's\n    # formatting\n    release_notes = re.sub('===+', _equal_to_tilde, release_notes)\n    # Replace headers that contain '-' with '#' to comply with osa-differ's\n    # formatting\n    release_notes = re.sub('---+', _dash_to_num, release_notes)\n    return release_notes", "response": "Get release notes between the two revisions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompare to xml.dom.minidom, lxml's treatment of text as .text and .tail attributes of elements is an oddity. It can even be a little frustrating when one is attempting to copy everything underneath some element to another element; one has to write in extra code to handle the text. This method provides the functionality of adding everything underneath the source element, in preserved order, to the destination element.", "response": "def append_all_below(destination, source, join_str=None):\n    \"\"\"\n    Compared to xml.dom.minidom, lxml's treatment of text as .text and .tail\n    attributes of elements is an oddity. It can even be a little frustrating\n    when one is attempting to copy everything underneath some element to\n    another element; one has to write in extra code to handle the text. This\n    method provides the functionality of adding everything underneath the\n    source element, in preserved order, to the destination element.\n    \"\"\"\n    if join_str is None:\n        join_str = ' '\n    if source.text is not None:  # If source has text\n        if len(destination) == 0:  # Destination has no children\n            if destination.text is None:  # Destination has no text\n                destination.text = source.text\n            else:  # Destination has a text\n                destination.text = join_str.join([destination.text, source.text])\n        else:  # Destination has children\n            #Select last child\n            last = destination[-1]\n            if last.tail is None:  # Last child has no tail\n                last.tail = source.text\n            else:  # Last child has a tail\n                last.tail = join_str.join([last.tail, source.text])\n    for each_child in source:\n        destination.append(deepcopy(each_child))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef all_text(element):\n    if element.text is None:\n        text = []\n    else:\n        text = [element.text]\n    tails = [child.tail for child in element if child.tail is not None]\n    tails = [tail.strip() for tail in tails if tail.strip()]\n    return ' '.join(text + tails)", "response": "This method returns all text data underneath the given element."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ns_format(element, namespaced_string):\n    if ':' not in namespaced_string:\n        print('This name contains no namespace, returning it unmodified: ' + namespaced_string)\n        return namespaced_string\n    namespace, name = namespaced_string.split(':')\n    return '{' + element.nsmap[namespace] + '}' + name", "response": "This method returns a convenient method for adapting a tag or attribute name to a tag or attribute name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rename_attributes(element, attrs):\n    for name in attrs.keys():\n        if name not in element.attrib:\n            continue\n        else:\n            element.attrib[attrs[name]] = element.attrib.pop(name)", "response": "Renames the attributes of the element."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replace(old, new):\n    parent = old.getparent()\n    parent.replace(old, new)", "response": "A simple way to replace one element node with another."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the node received to a comment in place and returns the comment element.", "response": "def comment(node):\n    \"\"\"\n    Converts the node received to a comment, in place, and will also return the\n    comment element.\n    \"\"\"\n    parent = node.parentNode\n    comment = node.ownerDocument.createComment(node.toxml())\n    parent.replaceChild(comment, node)\n    return comment"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef uncomment(comment):\n    parent = comment.parentNode\n    h = html.parser.HTMLParser()\n    data = h.unescape(comment.data)\n    try:\n        node = minidom.parseString(data).firstChild\n    except xml.parsers.expat.ExpatError:  # Could not parse!\n        log.error('Could not uncomment node due to parsing error!')\n        return None\n    else:\n        parent.replaceChild(node, comment)\n        return node", "response": "Converts the comment node received to a non - commented element in place and returns the new node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserializing an element to text.", "response": "def serialize(element, strip=False):\n    \"\"\"\n    A handy way to serialize an element to text.\n    \"\"\"\n    text = etree.tostring(element, method='text', encoding='utf-8')\n    if strip:\n        text = text.strip()\n    return str(text, encoding='utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the Command Line Arguments using argparse.", "response": "def get_arg_parse():\n    \"\"\"Parses the Command Line Arguments using argparse.\"\"\"\n    # Create parser object:\n    objParser = argparse.ArgumentParser()\n\n    # Add argument to namespace -config file path:\n    objParser.add_argument('-config', required=True,\n                           metavar='/path/to/config.csv',\n                           help='Absolute file path of config file with \\\n                                 parameters for pRF analysis. Ignored if in \\\n                                 testing mode.'\n                           )\n\n    # Add argument to namespace -prior results file path:\n    objParser.add_argument('-strPthPrior', required=True,\n                           metavar='/path/to/my_prior_res',\n                           help='Absolute file path of prior pRF results. \\\n                                 Ignored if in testing mode.'\n                           )\n\n    # Add argument to namespace -varNumOpt1 flag:\n    objParser.add_argument('-varNumOpt1', required=True, type=int,\n                           metavar='N1',\n                           help='Number of radial positions.'\n                           )\n\n    # Add argument to namespace -varNumOpt2 flag:\n    objParser.add_argument('-varNumOpt2', required=True, type=int,\n                           metavar='N2',\n                           help='Number of angular positions.'\n                           )\n\n    # Add argument to namespace -varNumOpt3 flag:\n    objParser.add_argument('-varNumOpt3', default=None, metavar='N3',\n                           help='Max displacement in radial direction.'\n                           )\n\n    # Add argument to namespace -lgcRstrCentre flag:\n    objParser.add_argument('-lgcRstrCentre', dest='lgcRstrCentre',\n                           action='store_true', default=False,\n                           help='Restrict fitted models to stimulated area.')\n\n    objParser.add_argument('-strPathHrf', default=None, required=False,\n                           metavar='/path/to/custom_hrf_parameter.npy',\n                           help='Path to npy file with custom hrf parameters. \\\n                           Ignored if in testing mode.')\n\n    objParser.add_argument('-supsur', nargs='+',\n                           help='List of floats that represent the ratio of \\\n                                 size neg surround to size pos center.',\n                           type=float, default=None)\n\n    # Namespace object containign arguments and values:\n    objNspc = objParser.parse_args()\n\n    return objNspc"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _homogenize_data_filter(dfilter):\n    if isinstance(dfilter, tuple) and (len(dfilter) == 1):\n        dfilter = (dfilter[0], None)\n    if (dfilter is None) or (dfilter == (None, None)) or (dfilter == (None,)):\n        dfilter = (None, None)\n    elif isinstance(dfilter, dict):\n        dfilter = (dfilter, None)\n    elif isinstance(dfilter, (list, str)) or (\n        isinstance(dfilter, int) and (not isinstance(dfilter, bool))\n    ):\n        dfilter = (None, dfilter if isinstance(dfilter, list) else [dfilter])\n    elif isinstance(dfilter[0], dict) or (\n        (dfilter[0] is None) and (not isinstance(dfilter[1], dict))\n    ):\n        pass\n    else:\n        dfilter = (dfilter[1], dfilter[0])\n    return dfilter", "response": "Make data filter definition consistent."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _tofloat(obj):\n    if \"inf\" in obj.lower().strip():\n        return obj\n    try:\n        return int(obj)\n    except ValueError:\n        try:\n            return float(obj)\n        except ValueError:\n            return obj", "response": "Convert to float string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating column identifier ( s ).", "response": "def _in_header(self, col):\n        \"\"\"Validate column identifier(s).\"\"\"\n        # pylint: disable=R1704\n        if not self._has_header:\n            # Conditionally register exceptions so that they do not appear\n            # in situations where has_header is always True. In this way\n            # they are not auto-documented by default\n            icol_ex = pexdoc.exh.addex(RuntimeError, \"Invalid column specification\")\n        hnf_ex = pexdoc.exh.addex(ValueError, \"Column *[column_identifier]* not found\")\n        col_list = [col] if isinstance(col, (str, int)) else col\n        for col in col_list:\n            edata = {\"field\": \"column_identifier\", \"value\": col}\n            if not self._has_header:\n                # Condition not subsumed in raise_exception_if\n                # so that calls that always have has_header=True\n                # do not pick up this exception\n                icol_ex(not isinstance(col, int))\n                hnf_ex((col < 0) or (col > len(self._header) - 1), edata)\n            else:\n                hnf_ex(\n                    (isinstance(col, int) and ((col < 0) or (col > self._data_cols)))\n                    or (\n                        isinstance(col, str) and (col.upper() not in self._header_upper)\n                    ),\n                    edata,\n                )\n        return col_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate that all columns in filter are in header.", "response": "def _validate_rfilter(self, rfilter, letter=\"d\"):\n        \"\"\"Validate that all columns in filter are in header.\"\"\"\n        if letter == \"d\":\n            pexdoc.exh.addai(\n                \"dfilter\",\n                (\n                    (not self._has_header)\n                    and any([not isinstance(item, int) for item in rfilter.keys()])\n                ),\n            )\n        else:\n            pexdoc.exh.addai(\n                \"rfilter\",\n                (\n                    (not self._has_header)\n                    and any([not isinstance(item, int) for item in rfilter.keys()])\n                ),\n            )\n        for key in rfilter:\n            self._in_header(key)\n            rfilter[key] = (\n                [rfilter[key]] if isinstance(rfilter[key], str) else rfilter[key]\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef data(self, filtered=False, no_empty=False):\n        return self._apply_filter(filtered, no_empty)", "response": "r Returns the file data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef header(self, filtered=False):\n        return (\n            self._header\n            if (not filtered) or (filtered and self._cfilter is None)\n            else self._cfilter\n        )", "response": "r Returns the data header."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write(self, fname=None, filtered=False, header=True, append=False):\n        # pylint: disable=R0913\n        write_ex = pexdoc.exh.addex(ValueError, \"There is no data to save to file\")\n        fname = self._fname if fname is None else fname\n        data = self.data(filtered=filtered)\n        write_ex((len(data) == 0) or ((len(data) == 1) and (len(data[0]) == 0)))\n        if header:\n            header = [header] if isinstance(header, str) else header\n            cfilter = self._gen_col_index(filtered=filtered)\n            filtered_header = (\n                [self._header[item] for item in cfilter]\n                if self._has_header\n                else cfilter\n            )\n            file_header = filtered_header if isinstance(header, bool) else header\n        # Convert None's to ''\n        data = [[\"''\" if item is None else item for item in row] for row in data]\n        _write_int(fname, [file_header] + data if header else data, append=append)", "response": "r Write the data to a specified comma - separated values file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef model_creation(dicCnfg, varRat=None, strPathHrf=None):\n    # *************************************************************************\n    # *** Load parameters from config file\n\n    # Load config parameters from dictionary into namespace:\n    cfg = cls_set_config(dicCnfg)\n    # *************************************************************************\n\n    if cfg.lgcCrteMdl:\n\n        # *********************************************************************\n        # *** Load spatial condition information\n\n        print('------Load spatial condition information')\n\n        arySptExpInf = np.load(cfg.strSptExpInf)\n\n        # Here we assume scientific convention and orientation of images where\n        # the origin should fall in the lower left corner, the x-axis occupies\n        # the width and the y-axis occupies the height dimension of the screen.\n        # We also assume that the first dimension that the user provides\n        # indexes x and the second indexes the y-axis. Since python is column\n        # major (i.e. first indexes columns, only then rows), we need to rotate\n        # arySptExpInf by 90 degrees rightward. This will insure that with the\n        # 0th axis we index the scientific x-axis and higher values move us to\n        # the right on that x-axis. It will also ensure that the 1st\n        # python axis indexes the scientific y-axis and higher values will\n        # move us up.\n        arySptExpInf = np.rot90(arySptExpInf, k=3)\n\n        # Calculate the areas that were stimulated during the experiment\n        aryStimArea = np.sum(arySptExpInf, axis=-1).astype(np.bool)\n\n        # *********************************************************************\n\n        # *********************************************************************\n        # *** Load temporal condition information\n\n        print('------Load temporal condition information')\n\n        aryTmpExpInf = np.load(cfg.strTmpExpInf)\n        # add fourth column to make it appropriate for pyprf_feature\n        if aryTmpExpInf.shape[-1] == 3:\n            print('---------Added fourth column')\n            vecNewCol = np.greater(aryTmpExpInf[:, 0], 0).astype(np.float16)\n            aryTmpExpInf = np.concatenate(\n                (aryTmpExpInf, np.expand_dims(vecNewCol, axis=1)), axis=1)\n\n        # *********************************************************************\n\n        # *********************************************************************\n        # *** Create model parameter combination, for now in pixel.\n        aryMdlParams = crt_mdl_prms((int(cfg.varVslSpcSzeX),\n                                     int(cfg.varVslSpcSzeY)), cfg.varNum1,\n                                    cfg.varExtXmin, cfg.varExtXmax,\n                                    cfg.varNum2, cfg.varExtYmin,\n                                    cfg.varExtYmax, cfg.varNumPrfSizes,\n                                    cfg.varPrfStdMin, cfg.varPrfStdMax,\n                                    kwUnt='pix', kwCrd=cfg.strKwCrd)\n\n        # If desired by user, also create model parameters for supp surround\n        if varRat is not None:\n            aryMdlParamsSur = np.copy(aryMdlParams)\n            aryMdlParamsSur[:, 2] = aryMdlParamsSur[:, 2] * varRat\n\n        # Exclude model parameters whose prf center would lie outside the\n        # stimulated area\n        print('------Exclude model params with prf center outside stim area')\n        varNumMdlBfr = aryMdlParams.shape[0]\n        # Get logical for model inclusion\n        lgcMdlInc = aryStimArea[aryMdlParams[:, 0].astype(np.int32),\n                                aryMdlParams[:, 1].astype(np.int32)]\n        # Exclude models with prf center outside stimulated area\n        aryMdlParams = aryMdlParams[lgcMdlInc, :]\n        # Also apply the logical to the surround parameters, if they exist\n        if varRat is not None:\n            aryMdlParamsSur = aryMdlParamsSur[lgcMdlInc, :]\n\n        print('---------Number of models excluded: ' +\n              str(varNumMdlBfr-aryMdlParams.shape[0]))\n\n        # *********************************************************************\n\n        # *********************************************************************\n        # *** Create 2D Gauss model responses to spatial conditions.\n\n        print('------Create 2D Gauss model responses to spatial conditions')\n\n        aryMdlRsp = crt_mdl_rsp(arySptExpInf, (int(cfg.varVslSpcSzeX),\n                                               int(cfg.varVslSpcSzeY)),\n                                aryMdlParams, cfg.varPar)\n\n        # If desired by user, also create model responses for supp surround\n        if varRat is not None:\n            aryMdlRspSur = crt_mdl_rsp(arySptExpInf, (int(cfg.varVslSpcSzeX),\n                                                      int(cfg.varVslSpcSzeY)),\n                                       aryMdlParamsSur, cfg.varPar)\n\n        # Delete array to save memory\n        del(arySptExpInf)\n\n        # *********************************************************************\n\n        # *********************************************************************\n        # *** Create prf time course models\n\n        print('------Create prf time course models')\n\n        # Check whether path to npy file with hrf parameters was provided\n        if strPathHrf is not None:\n            print('---------Load custom hrf parameters')\n            aryCstPrm = np.load(strPathHrf)\n            dctPrm = {}\n            dctPrm['peak_delay'] = aryCstPrm[0]\n            dctPrm['under_delay'] = aryCstPrm[1]\n            dctPrm['peak_disp'] = aryCstPrm[2]\n            dctPrm['under_disp'] = aryCstPrm[3]\n            dctPrm['p_u_ratio'] = aryCstPrm[4]\n        # If not, set dctPrm to None, which will result in default hrf params\n        else:\n            print('---------Use default hrf parameters')\n            dctPrm = None\n\n        aryPrfTc = crt_prf_ftr_tc(aryMdlRsp, aryTmpExpInf, cfg.varNumVol,\n                                  cfg.varTr, cfg.varTmpOvsmpl,\n                                  cfg.switchHrfSet, (int(cfg.varVslSpcSzeX),\n                                                     int(cfg.varVslSpcSzeY)),\n                                  cfg.varPar, dctPrm=dctPrm)\n\n        # If desired by user, create prf time course models for supp surround\n        if varRat is not None:\n            print('---------Add suppressive surround')\n            aryPrfTcSur = crt_prf_ftr_tc(aryMdlRspSur, aryTmpExpInf,\n                                         cfg.varNumVol, cfg.varTr,\n                                         cfg.varTmpOvsmpl, cfg.switchHrfSet,\n                                         (int(cfg.varVslSpcSzeX),\n                                          int(cfg.varVslSpcSzeY)),\n                                         cfg.varPar, dctPrm=dctPrm)\n            # Concatenate aryPrfTc and aryPrfTcSur\n            aryPrfTc = np.concatenate((aryPrfTc, aryPrfTcSur), axis=1)\n\n        # *********************************************************************\n\n        # *********************************************************************\n        # *** Save pRF time course models, corresponding params and responses\n\n        print('------Save pRF time course models to disk')\n\n        # Prepare file name extensions\n        strNmeExtMdl = ''\n        strNmeExtPrm = '_params'\n        strNmeExtRsp = '_mdlRsp'\n        strNmeExtMdlInc = '_lgcMdlInc'\n\n        # Check whether extensions need to be modified with ratio name\n        if varRat is not None:\n            strNmeExtMdl = strNmeExtMdl + '_' + str(varRat)\n            strNmeExtPrm = strNmeExtPrm + '_' + str(varRat)\n            strNmeExtRsp = strNmeExtRsp + '_' + str(varRat)\n            # Also include model the parameters and responses of the surround\n            # For the pRF time course models, the surround is included above\n            aryMdlParams = np.stack((aryMdlParams, aryMdlParamsSur),\n                                    axis=1)\n            aryMdlRsp = np.stack((aryMdlRsp, aryMdlRspSur),\n                                 axis=1)\n            # Append the npy file name for model exlusion in unstimulated area\n            # with general _supsur suffic since it does not depend on specific\n            # surround\n            strNmeExtMdlInc = '_supsur' + strNmeExtMdlInc\n\n        # Save pRF time course models\n        np.save(cfg.strPathMdl + strNmeExtMdl, aryPrfTc)\n        # Save the corresponding model parameters\n        np.save(cfg.strPathMdl + strNmeExtPrm, aryMdlParams)\n        # Save the corresponding model responses\n        np.save(cfg.strPathMdl + strNmeExtRsp, aryMdlRsp)\n\n        # Save logical for parameter exclusion in unstimulated area\n        np.save(cfg.strPathMdl + strNmeExtMdlInc, lgcMdlInc)\n\n        del(aryMdlParams)\n        del(aryMdlRsp)\n\n        # *********************************************************************\n\n    else:\n\n        # *********************************************************************\n        # %% Load existing pRF time course models\n\n        print('------Load pRF time course models from disk')\n\n        # Load the file:\n        aryPrfTc = np.load((cfg.strPathMdl + '.npy'))\n\n        # Check whether pRF time course model matrix has the expected\n        # dimensions:\n        vecPrfTcShp = aryPrfTc.shape\n\n        # Logical test for correct dimensions:\n        strErrMsg = ('---Error: Dimensions of specified pRF time course ' +\n                     'models do not agree with specified model parameters')\n        assert vecPrfTcShp[0] == cfg.varNum1 * \\\n            cfg.varNum2 * cfg.varNumPrfSizes, strErrMsg\n        assert vecPrfTcShp[-1] == cfg.varNumVol, strErrMsg\n        # Check number of feature. If fitting is performed with sup surround,\n        # number of features will be twice as many as simple fitting\n        if varRat is None:\n            assert vecPrfTcShp[1] == cfg.switchHrfSet, strErrMsg\n        else:\n            assert vecPrfTcShp[1] == cfg.switchHrfSet*2, strErrMsg\n\n        # Load logical for parameter exclusion in unstimulated area\n        lgcMdlInc = np.load(cfg.strPathMdl + '_lgcMdlInc.npy')\n\n    # *************************************************************************\n\n    return aryPrfTc, lgcMdlInc", "response": "Create or load pRF model time courses."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register(self, CorpNum, cashbill, UserID=None):\r\n        if cashbill == None:\r\n            raise PopbillException(-99999999, \"\ud604\uae08\uc601\uc218\uc99d \uc815\ubcf4\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        postData = self._stringtify(cashbill)\r\n\r\n        return self._httppost('/Cashbill', postData, CorpNum, UserID)", "response": "\uc694\uccad\ucc98\ud2b8 \uc815\ubcf4 \uc694\uccad\ucc98\ud2b8 \uc815\ubcf4 \uc694\uccad\ucc98\ud2b8 \uc815\ubcf4 \uc694\uccad\ucc98\ud2b8 \uc815\ubcf4 \uc694\uccad\ucc98\ud2b8 \uc815\ufffd"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, CorpNum, MgtKey, cashbill, UserID=None):\r\n        if MgtKey == None or MgtKey == \"\":\r\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n        if cashbill == None:\r\n            raise PopbillException(-99999999, \"\ud604\uae08\uc601\uc218\uc99d \uc815\ubcf4\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        postData = self._stringtify(cashbill)\r\n\r\n        return self._httppost('/Cashbill/' + MgtKey, postData, CorpNum, UserID, \"PATCH\")", "response": "A method to update a single entry in a particular resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nissue a new entry in the specified resource.", "response": "def issue(self, CorpNum, MgtKey, Memo=None, UserID=None):\r\n        \"\"\" \ubc1c\ud589\r\n            args\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                MgtKey : \uc6d0\ubcf8 \ud604\uae08\uc601\uc218\uc99d \ubb38\uc11c\uad00\ub9ac\ubc88\ud638\r\n                Memo : \ubc1c\ud589 \uba54\ubaa8\r\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\r\n            return\r\n                \ucc98\ub9ac\uacb0\uacfc. consist of code and message\r\n            raise\r\n                PopbillException\r\n        \"\"\"\r\n\r\n        if MgtKey == None or MgtKey == \"\":\r\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        postData = \"\"\r\n        req = {}\r\n\r\n        if Memo != None or Memo != '':\r\n            req[\"memo\"] = Memo\r\n\r\n        postData = self._stringtify(req)\r\n\r\n        return self._httppost('/Cashbill/' + MgtKey, postData, CorpNum, UserID, \"ISSUE\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, CorpNum, MgtKey, UserID=None):\r\n\r\n        if MgtKey == None or MgtKey == \"\":\r\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        return self._httppost('/Cashbill/' + MgtKey, '', CorpNum, UserID, \"DELETE\")", "response": "\uc0ad\uc81c \uc81c \uc601\uc218\uc99d \ud604\uae08\uc601\uc218\uc99d \uc11c \uc815\ubcf4 \uc54a\uc558\uc2b5\ub2c8\ub2e4."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getInfo(self, CorpNum, MgtKey):\r\n\r\n        if MgtKey == None or MgtKey == \"\":\r\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        return self._httpget('/Cashbill/' + MgtKey, CorpNum)", "response": "Get information about a particular item."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the details of a particular item.", "response": "def getDetailInfo(self, CorpNum, MgtKey):\r\n        \"\"\" \uc0c1\uc138\uc815\ubcf4 \uc870\ud68c\r\n            args\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                MgtKey : \ubb38\uc11c\uad00\ub9ac\ubc88\ud638\r\n            return\r\n                \ubb38\uc11c \uc0c1\uc138\uc815\ubcf4 object\r\n            raise\r\n                PopbillException\r\n        \"\"\"\r\n\r\n        if MgtKey == None or MgtKey == \"\":\r\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        return self._httpget('/Cashbill/' + MgtKey + '?Detail', CorpNum)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getLogs(self, CorpNum, MgtKey):\r\n        if MgtKey == None or MgtKey == \"\":\r\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        return self._httpget('/Cashbill/' + MgtKey + '/Logs', CorpNum)", "response": "\ubb38\uc11c\uc774\ub825 \uc870\ud68c\r\n            args\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                MgtKey : \ubb38\uc11c\uad00\ub9ac\ubc88\ud638\r\n            return\r\n                \ubb38\uc11c \uc774\ub825 \ubaa9\ub85d as List\r\n            raise\r\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef updateEmailConfig(self, Corpnum, EmailType, SendYN, UserID=None):\r\n        if EmailType == None or EmailType == '':\r\n            raise PopbillException(-99999999, \"\uba54\uc77c\uc804\uc1a1 \ud0c0\uc785\uc774 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        if SendYN == None or SendYN == '':\r\n            raise PopbillException(-99999999, \"\uba54\uc77c\uc804\uc1a1 \uc5ec\ubd80 \ud56d\ubaa9\uc774 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        uri = \"/Cashbill/EmailSendConfig?EmailType=\" + EmailType + \"&SendYN=\" + str(SendYN)\r\n        return self._httppost(uri, \"\", Corpnum, UserID)", "response": "\uc804\uc1a1 \uc694\uccad\ud55c \uc815\ubcf4 \uc694\uccad\ud55c \uc815\ubcf4 \uc694\uccad\ud55c \uc815\ubcf4 \uc694\uccad\ud55c \uc815\ubcf4 \uc694\uccad\ud55c \uc815\ubcf4 \uc694\uccad\ud574\uc694\uacfc\uacfc\uacfc \uc694\uc790 \uc815\ubcf4 \uc694\uc790 \uc815\ubcf4 \uc694\uc790 \uc815\ubcf4 \uc694\uc790 \uc815\ubcf4 \uc694\uc694\uacfc \uc694\uc694\uc790 \uc815\ubcf4 \uc694\uc790 \uc815\ubcf4 \uc694\uc790 \uc815\ubcf4 \uc815\ubcf4\uc815\ubcf4\uc815\ubcf4\uc694\uc790 \uc790 \uc815\ubcf4\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc790 \uc694\uc790 \uc815\ubcf4 \uc694\uc790 \uc815\ubcf4 \uc815\ubcf4\uc694\uc694\uc694\uc790 \uc790 \uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc790 \uc790 \uc694\uc694\uc694\uc694\uc694\uc694\uc790 \uc790 \uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\uc694\ufffd \uc694\uc694\uc694\ufffd \uc694\uc694\ufffd \uc694\uc694\ufffd\uc694\ufffd\uc694\ufffd\uc694\ufffd\uc694\ufffd\uc694\ufffd\ufffd"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list(self, request):\n        pipeline = [{'$match': request.args.pop('match', {})}]\n\n        sort = request.args.pop('sort', {})\n        if sort:\n            pipeline.append({'$sort': sort})\n\n        project = request.args.pop('project', {})\n        if project:\n            pipeline.append({'$project': project})\n\n        return Response(serialize(self.collection.aggregate(pipeline)))", "response": "Returns the list of documents found on the collection"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new document based on the given data.", "response": "def create(self, request):\n        \"\"\"\n        Creates a new document based on the given data\n        \"\"\"\n        document = self.collection(request.json)\n        document.created_at = datetime.utcnow()\n        document.updated_at = document.created_at\n\n        created = document.insert()\n        return Response(\n            response=serialize(created),\n            status=(\n                201 if not all(\n                    key in created for key in [\n                        'error_code', 'error_type', 'error_message'\n                    ]\n                ) else 400\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving the document with the given _id or 404", "response": "def retrieve(self, request, _id):\n        \"\"\"\n        Returns the document containing the given _id or 404\n        \"\"\"\n        _id = deserialize(_id)\n\n        retrieved = self.collection.find_one({'_id': _id})\n        if retrieved:\n            return Response(serialize(retrieved))\n        else:\n            return Response(\n                response=serialize(\n                    DocumentNotFoundError(self.collection.__name__, _id)\n                ),\n                status=400\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the document with the given _id using the given data", "response": "def update(self, request, _id):\n        \"\"\"\n        Updates the document with the given _id using the given data\n        \"\"\"\n        _id = deserialize(_id)\n\n        to_update = self.collection.find_one({'_id': _id})\n        if to_update:\n            document = self.collection(dict(to_update, **request.json))\n            document.updated_at = datetime.utcnow()\n\n            updated = document.update()\n            return Response(\n                response=serialize(updated),\n                status=(\n                    200 if not all(\n                        key in updated for key in [\n                            'error_code', 'error_type', 'error_message'\n                        ]\n                    ) else 400\n                )\n            )\n        else:\n            return Response(\n                response=serialize(\n                    DocumentNotFoundError(self.collection.__name__, _id)\n                ),\n                status=400\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting the document with the given _id if it exists.", "response": "def delete(self, request, _id):\n        \"\"\"\n        Deletes the document with the given _id if it exists\n        \"\"\"\n        _id = deserialize(_id)\n\n        to_delete = self.collection.get({'_id': _id})\n        if to_delete:\n            deleted = to_delete.delete()\n\n            return Response(\n                response=serialize(deleted),\n                status=(\n                    200 if not all(\n                        key in deleted for key in [\n                            'error_code', 'error_type', 'error_message'\n                        ]\n                    ) else 400\n                )\n            )\n        else:\n            return Response(\n                response=serialize(\n                    DocumentNotFoundError(self.collection.__name__, _id)\n                ),\n                status=404\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef with_reactor(*dec_args, **dec_kwargs):\n    \n    # This method takes care of the decorator protocol, it\n    # distinguishes between using the decorator with brackets\n    # and without brackets. It then calls `_twisted_test_sync()`.\n\n    if len(dec_args) == 1 and callable(dec_args[0]) and not dec_kwargs:\n        # decorator used without brackets:\n        #   @twisted_test\n        #   def test_xxx():\n        #     ....\n        callee = dec_args[0]\n        dec_args = ()\n        dec_kwargs = {}\n        \n        @functools.wraps(callee)\n        def wrapper(*call_args, **call_kwargs):\n            return _twisted_test_sync(callee, call_args, call_kwargs)\n        return wrapper\n\n    else:\n        # decorator used with brackets:\n        #   @twisted_test(*dec_args, **dec_args)\n        #   def test_xxx():\n        #     ....\n        def decorator(callee):\n            @functools.wraps(callee)\n            def wrapper(*call_args, **call_kwargs):\n                return _twisted_test_sync(callee, call_args, call_kwargs, *dec_args, **dec_kwargs)\n            return wrapper\n        return decorator", "response": "Decorator for test functions that require a running reactor."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart the twisted reactor if it is not running already.", "response": "def _ensure_reactor_running():\n    \"\"\"\n    Starts the twisted reactor if it is not running already.\n    \n    The reactor is started in a new daemon-thread.\n    \n    Has to perform dirty hacks so that twisted can register\n    signals even if it is not running in the main-thread.\n    \"\"\"\n    if not reactor.running:\n        \n        # Some of the `signal` API can only be called\n        # from the main-thread. So we do a dirty workaround.\n        #\n        # `signal.signal()` and `signal.wakeup_fd_capture()`\n        # are temporarily monkey-patched while the reactor is\n        # starting.\n        #\n        # The patched functions record the invocations in\n        # `signal_registrations`. \n        #\n        # Once the reactor is started, the main-thread\n        # is used to playback the recorded invocations.\n        \n        signal_registrations = []\n\n        # do the monkey patching\n        def signal_capture(*args, **kwargs):\n            signal_registrations.append((orig_signal, args, kwargs))\n        def set_wakeup_fd_capture(*args, **kwargs):\n            signal_registrations.append((orig_set_wakeup_fd, args, kwargs))\n        orig_signal = signal.signal\n        signal.signal = signal_capture\n        orig_set_wakeup_fd = signal.set_wakeup_fd\n        signal.set_wakeup_fd = set_wakeup_fd_capture\n        \n        \n        # start the reactor in a daemon-thread\n        reactor_thread = threading.Thread(target=reactor.run, name=\"reactor\")\n        reactor_thread.daemon = True\n        reactor_thread.start()\n        while not reactor.running:\n            time.sleep(0.01)\n            \n        # Give the reactor a moment to register the signals. \n        # Apparently the 'running' flag is set before that.\n        time.sleep(0.01)\n        \n        # Undo the monkey-paching\n        signal.signal = orig_signal\n        signal.set_wakeup_fd = orig_set_wakeup_fd\n        \n        # Playback the recorded calls\n        for func, args, kwargs in signal_registrations:\n            func(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _timeoutDeferred(deferred, timeout):\n    delayedCall = reactor.callLater(timeout, deferred.cancel)\n    def gotResult(result):\n        if delayedCall.active():\n            delayedCall.cancel()\n        return result\n    deferred.addBoth(gotResult)", "response": "Cancels the given deferred after the given time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_prf_cpu(idxPrc, aryFuncChnk, aryPrfTc, aryMdlParams, strVersion,\n                 lgcXval, varNumXval, queOut, lgcRstr=None, lgcPrint=True):\n    \"\"\"\n    Find best fitting pRF model for voxel time course, using the CPU.\n\n    Parameters\n    ----------\n    idxPrc : int\n        Process ID of the process calling this function (for CPU\n        multi-threading). In GPU version, this parameter is 0 (just one thread\n        on CPU).\n    aryFunc : np.array\n        2D array with functional MRI data, with shape aryFunc[voxel, time].\n    aryPrfTc : np.array\n        Array with pRF model time courses, with shape\n        aryPrfTc[x-pos*y-pos*SD, number of feautures, number of volumes]\n    aryMdlParams : np.array\n        2D array with all pRF model parameter combinations.\n    strVersion : str\n        Which version to use for pRF finding; 'numpy' or 'cython'.\n    lgcXval: boolean\n        Logical to determine whether we cross-validate.\n    varNumXval: int\n        Number of folds for k-fold cross-validation.\n    queOut : multiprocessing.queues.Queue\n        Queue to put the results on.\n    lgcRstr : boolean numpy array or None, default None\n        Logical to restrict certain models to particular voxels.\n    lgcPrint : boolean\n        Whether print statements should be executed.\n\n    Returns\n    -------\n    lstOut : list\n        List containing the following objects:\n        idxPrc : int\n            Process ID of the process calling this function (for CPU\n            multi-threading). In GPU version, this parameter is 0.\n        vecBstXpos : np.array\n            1D array with best fitting x-position for each voxel, with shape\n            vecBstXpos[voxel].\n        vecBstYpos : np.array\n            1D array with best fitting y-position for each voxel, with shape\n            vecBstYpos[voxel].\n        vecBstSd : np.array\n            1D array with best fitting pRF size for each voxel, with shape\n            vecBstSd[voxel].\n        vecBstR2 : np.array\n            1D array with R2 value of 'winning' pRF model for each voxel, with\n            shape vecBstR2[voxel].\n        aryBstBts : np.array\n            2D array with beta parameter estimates of 'winning' pRF model for\n            each voxel, with shape aryBstBts[voxel, feautures].\n\n    Notes\n    -----\n    The list with results is not returned directly, but placed on a\n    multiprocessing queue. This version performs the model finding on the CPU,\n    using numpy or cython (depending on the value of `strVersion`).\n\n    \"\"\"\n\n    # Number of models in the visual space:\n    varNumMdls = aryPrfTc.shape[0]\n\n    # Number of feautures\n    varNumFtr = aryPrfTc.shape[1]\n\n    # Number of voxels to be fitted in this chunk:\n    varNumVoxChnk = aryFuncChnk.shape[0]\n\n    # Vectors for pRF finding results [number-of-voxels times one]:\n    # make sure they have the same precision as aryMdlParams, since this\n    # is important for later comparison\n    vecBstXpos = np.zeros(varNumVoxChnk, dtype=aryMdlParams.dtype)\n    vecBstYpos = np.zeros(varNumVoxChnk, dtype=aryMdlParams.dtype)\n    vecBstSd = np.zeros(varNumVoxChnk, dtype=aryMdlParams.dtype)\n\n    # Vector for best R-square value. For each model fit, the R-square value is\n    # compared to this, and updated if it is lower than the best-fitting\n    # solution so far. We initialise with an arbitrary, high value\n    vecBstRes = np.add(np.zeros(varNumVoxChnk), np.inf).astype(np.float32)\n\n    # array for best beta values. If we update the residual value above because\n    # it is lower, we also update the beta values of these voxels\n    aryBstBts = np.zeros((varNumVoxChnk, varNumFtr)).astype(np.float32)\n\n    # In case we cross-validate we also save and replace the best\n    # residual values for every fold (not only mean across folds):\n    if lgcXval:\n        aryBstResFlds = np.zeros((varNumVoxChnk, varNumXval), dtype=np.float32)\n\n    # We reshape the voxel time courses, so that time goes down the column,\n    # i.e. from top to bottom.\n    aryFuncChnk = aryFuncChnk.T\n\n    # Change type to float 32:\n    aryFuncChnk = aryFuncChnk.astype(np.float32)\n    aryPrfTc = aryPrfTc.astype(np.float32)\n\n    # if lgc for Xval is true we already prepare indices for xvalidation\n    if lgcXval:\n        # obtain iterator for cross-validation\n        itXval = KFold(n_splits=varNumXval)\n        vecSplts = np.arange(aryPrfTc.shape[-1], dtype=np.int32)\n\n        # prepare lists that will hold indices for xvalidation\n        lstIdxTrn = []\n        lstIdxtst = []\n        # Loop over the cross-validations to put indcies in array\n        for idxTrn, idxTst in itXval.split(vecSplts):\n            lstIdxTrn.append(idxTrn)\n            lstIdxtst.append(idxTst)\n        # trun lists into array\n        aryIdxTrn = np.stack(lstIdxTrn, axis=-1).astype(np.int32)\n        aryIdxTst = np.stack(lstIdxtst, axis=-1).astype(np.int32)\n\n    # Prepare status indicator if this is the first of the parallel processes:\n    if idxPrc == 0:\n\n        # We create a status indicator for the time consuming pRF model finding\n        # algorithm. Number of steps of the status indicator:\n        varStsStpSze = 20\n\n        # Vector with pRF values at which to give status feedback:\n        vecStatPrf = np.linspace(0,\n                                 varNumMdls,\n                                 num=(varStsStpSze+1),\n                                 endpoint=True)\n        vecStatPrf = np.ceil(vecStatPrf)\n        vecStatPrf = vecStatPrf.astype(int)\n\n        # Vector with corresponding percentage values at which to give status\n        # feedback:\n        vecStatPrc = np.linspace(0,\n                                 100,\n                                 num=(varStsStpSze+1),\n                                 endpoint=True)\n        vecStatPrc = np.ceil(vecStatPrc)\n        vecStatPrc = vecStatPrc.astype(int)\n\n        # Counter for status indicator:\n        varCntSts01 = 0\n        varCntSts02 = 0\n\n    # If user does not restrict model space for particular voxels, select\n    # all voxels\n    if lgcRstr is None:\n        lgcVxl = np.arange(varNumVoxChnk, dtype=np.int32)\n\n    # There can be pRF model time courses with a variance of zero (i.e. pRF\n    # models that are not actually responsive to the stimuli). For time\n    # efficiency, and in order to avoid division by zero, we ignore these\n    # model time courses.\n    aryPrfTcVar = np.var(aryPrfTc, axis=-1)\n\n    # Zero with float32 precision for comparison:\n    varZero32 = np.array(([0.0])).astype(np.float32)[0]\n\n    # Loop through pRF models:\n    for idxMdl in range(0, varNumMdls):\n\n        # If desired by user, restrict the model fitting such that certain\n        # models are restricted to particular voxels\n        if lgcRstr is not None:\n            # Apply flatnonzero, so we can use cascaded integer indexing later\n            lgcVxl = np.flatnonzero(lgcRstr[:, idxMdl])\n\n        # Status indicator (only used in the first of the parallel\n        # processes):\n        if idxPrc == 0:\n\n            # Status indicator:\n            if varCntSts02 == vecStatPrf[varCntSts01]:\n\n                # Prepare status message:\n                strStsMsg = ('------------Progress: ' +\n                             str(vecStatPrc[varCntSts01]) +\n                             ' % --- ' +\n                             str(vecStatPrf[varCntSts01]) +\n                             ' pRF models out of ' +\n                             str(varNumMdls))\n                if lgcPrint:\n                    print(strStsMsg)\n\n                # Only increment counter if the last value has not been\n                # reached yet:\n                if varCntSts01 < varStsStpSze:\n                    varCntSts01 = varCntSts01 + int(1)\n\n        # Only fit pRF model if:\n        # 1) all feature predictors have a variance greater than zero AND\n        # 2) at least one voxel is being tested\n        if np.logical_and(np.all(np.greater(aryPrfTcVar[idxMdl], varZero32),\n                                 axis=0),\n                          np.greater(lgcVxl.size, 0)):\n\n            # Get predictor time courses for this specific model\n            vecMdl = aryPrfTc[idxMdl, :, :].T\n\n            # Check whether we need to crossvalidate\n            if lgcXval:\n                # We do crossvalidate. In this case, we loop through\n                # the different folds of the crossvalidation and\n                # calculate the cross-validation error for the current\n                # model for all voxel time courses.\n\n                # Cython version:\n                if strVersion == 'cython':\n\n                    # A cython function is used to calculate the residuals and\n                    # beta parameter estimates of the current model:\n                    if varNumFtr == 1:\n                        # For time course with one predictors\n                        aryResXval = cy_lst_sq_xval_one(np.squeeze(vecMdl),\n                                                        aryFuncChnk[:, lgcVxl],\n                                                        aryIdxTrn,\n                                                        aryIdxTst)\n\n                    elif varNumFtr == 2:\n                        # For time course with two predictors\n                        aryResXval = cy_lst_sq_xval_two(vecMdl,\n                                                        aryFuncChnk[:, lgcVxl],\n                                                        aryIdxTrn,\n                                                        aryIdxTst)\n\n                    else:\n                        if lgcPrint:\n                            print('Cython currently not implemented for ' +\n                                  'more than two predictors.')\n\n                # Numpy version:\n                elif strVersion == 'numpy':\n\n                    aryResXval = np_lst_sq_xval(vecMdl, aryFuncChnk[:, lgcVxl],\n                                                aryIdxTrn, aryIdxTst)\n\n                # calculate the average cross validation error across\n                # all folds\n                vecTmpRes = np.mean(aryResXval, axis=1)\n\n            else:\n                # We do not crossvalidate. In this case, we calculate\n                # the ratio of the explained variance (R squared)\n                # for the current model for all voxel time courses.\n\n                # Cython version:\n                if strVersion == 'cython':\n\n                    # A cython function is used to calculate the residuals and\n                    # beta parameter estimates of the current model:\n                    if varNumFtr == 1:\n                        # For time course with one predictor\n                        aryTmpBts, vecTmpRes = cy_lst_sq_one(\n                            np.squeeze(vecMdl), aryFuncChnk[:, lgcVxl])\n\n                    elif varNumFtr == 2:\n                        # For time course with two predictors\n                        aryTmpBts, vecTmpRes = \\\n                            cy_lst_sq_two(vecMdl, aryFuncChnk[:, lgcVxl])\n                    else:\n                        if lgcPrint:\n                            print('Cython currently not implemented for ' +\n                                  'more than two two predictors.')\n\n                # Numpy version:\n                elif strVersion == 'numpy':\n\n                    # Numpy linalg.lstsq is used to calculate the\n                    # beta values and residuals of the current model:\n                    aryTmpBts, vecTmpRes = np_lst_sq(vecMdl,\n                                                     aryFuncChnk[:, lgcVxl])\n\n            # Check whether current crossvalidation error (xval=True)\n            # or residuals (xval=False) are lower than previously\n            # calculated ones:\n            vecLgcTmpRes = np.less(vecTmpRes, vecBstRes[lgcVxl])\n            # Apply np.flatnonzero for cascaded integer-indexing\n            vecLgcTmpRes = np.flatnonzero(vecLgcTmpRes)\n\n            # Replace best x and y position values, and SD values:\n            vecBstXpos[lgcVxl[vecLgcTmpRes]] = aryMdlParams[idxMdl, 0]\n            vecBstYpos[lgcVxl[vecLgcTmpRes]] = aryMdlParams[idxMdl, 1]\n            vecBstSd[lgcVxl[vecLgcTmpRes]] = aryMdlParams[idxMdl, 2]\n\n            # Replace best mean residual values:\n            vecBstRes[lgcVxl[vecLgcTmpRes]] = vecTmpRes[vecLgcTmpRes]\n\n            if not lgcXval:\n                # Replace best beta values:\n                aryBstBts[lgcVxl[vecLgcTmpRes], :] = \\\n                    aryTmpBts[:, vecLgcTmpRes].T\n\n            # In case we cross-validate we also save and replace the best\n            # residual values for every fold (not only mean across folds):\n            if lgcXval:\n                aryBstResFlds[lgcVxl[vecLgcTmpRes], :] = \\\n                    aryResXval[vecLgcTmpRes, :]\n\n        # Status indicator (only used in the first of the parallel\n        # processes):\n        if idxPrc == 0:\n\n            # Increment status indicator counter:\n            varCntSts02 = varCntSts02 + 1\n\n    # After finding the best fitting model for each voxel, we still have to\n    # calculate the average correlation coefficient between predicted and\n    # measured time course (xval=True) or the coefficient of determination\n    # (xval=False) for each voxel.\n\n    if lgcXval:\n\n        # create vector that allows to check whether every voxel is visited\n        # exactly once\n        vecVxlTst = np.zeros(aryFuncChnk.shape[1])\n\n        # Since we did not do this during finding the best model, we still need\n        # to calculate deviation from a mean model for every voxel and fold\n        # arySsTotXval as well as calculate the best betas for the full model\n\n        # concatenate vectors with best x, y, sigma params\n        aryBstPrm = np.stack((vecBstXpos, vecBstYpos, vecBstSd), axis=1)\n\n        # Find unique rows\n        aryUnqRows = fnd_unq_rws(aryBstPrm, return_index=False,\n                                 return_inverse=False)\n\n        # Calculate deviation from a mean model for every voxel and fold\n        arySsTotXval = np.zeros((aryBstResFlds.shape),\n                                dtype=aryBstResFlds.dtype)\n\n        # Loop over all best-fitting model parameter combinations found\n        for vecPrm in aryUnqRows:\n            # Get logical for voxels for which this prm combi was the best\n            lgcPrm = np.isclose(aryBstPrm, vecPrm, atol=1e-04).all(axis=1)\n            # Get logical index for the model number\n            # This can only be 1 index, so we directly get 1st entry of array\n            lgcIndMdl = np.where(np.isclose(aryMdlParams, vecPrm,\n                                            atol=1e-04).all(axis=1))[0][0]\n\n            if np.all(np.invert(lgcPrm)):\n                if lgcPrint:\n                    print('------------No voxel found, process ' + str(idxPrc))\n            # Mark those voxels that were visited\n            vecVxlTst[lgcPrm] += 1\n\n            # Get voxel time course\n            aryVxlTc = aryFuncChnk[:, lgcPrm]\n\n            # Get model time courses\n            aryMdlTc = aryPrfTc[lgcIndMdl, :, :].T\n\n            # Calculate beta parameter estimates for entire model\n            aryBstBts[lgcPrm, :] = np.linalg.lstsq(aryMdlTc,\n                                                   aryVxlTc,\n                                                   rcond=-1)[0].T\n\n            # loop over cross-validation folds\n            for idxXval in range(varNumXval):\n                # Get functional data for tst:\n                aryFuncChnkTst = aryVxlTc[\n                    aryIdxTst[:, idxXval], :]\n                # Deviation from the mean for each datapoint:\n                aryFuncDev = np.subtract(aryFuncChnkTst,\n                                         np.mean(aryFuncChnkTst,\n                                                 axis=0)[None, :])\n                # Sum of squares:\n                vecSsTot = np.sum(np.power(aryFuncDev,\n                                           2.0),\n                                  axis=0)\n                arySsTotXval[lgcPrm, idxXval] = vecSsTot\n\n        # check that every voxel was visited exactly once\n        errMsg = 'At least one voxel visited more than once for SStot calc'\n        assert len(vecVxlTst) == np.sum(vecVxlTst), errMsg\n\n        # Calculate coefficient of determination by comparing:\n        # aryBstResFlds vs. arySsTotXval\n\n        # get logical to check that arySsTotXval is greater than zero in all\n        # voxels and folds\n        lgcExclZeros = np.all(np.greater(arySsTotXval,  np.array([0.0])),\n                              axis=1)\n        if lgcPrint:\n            print('------------Nr of voxels: ' + str(len(lgcExclZeros)))\n            print('------------Nr of voxels avove 0: ' +\n                  str(np.sum(lgcExclZeros)))\n\n        # Calculate R2 for every crossvalidation fold seperately\n        aryBstR2fld = np.subtract(\n            1.0, np.divide(aryBstResFlds,\n                           arySsTotXval))\n\n        # Calculate mean R2 across folds here\n        vecBstR2 = np.subtract(\n            1.0, np.mean(np.divide(aryBstResFlds,\n                                   arySsTotXval),\n                         axis=1))\n\n        # Output list:\n        lstOut = [idxPrc,\n                  vecBstXpos,\n                  vecBstYpos,\n                  vecBstSd,\n                  vecBstR2,\n                  aryBstBts,\n                  aryBstR2fld]\n\n        queOut.put(lstOut)\n\n    else:\n        # To calculate the coefficient of determination, we start with the\n        # total sum of squares (i.e. the deviation of the data from the mean).\n        # The mean of each time course:\n        vecFuncMean = np.mean(aryFuncChnk, axis=0)\n        # Deviation from the mean for each datapoint:\n        aryFuncDev = np.subtract(aryFuncChnk, vecFuncMean[None, :])\n        # Sum of squares:\n        vecSsTot = np.sum(np.power(aryFuncDev,\n                                   2.0),\n                          axis=0)\n        # Coefficient of determination:\n        vecBstR2 = np.subtract(1.0,\n                               np.divide(vecBstRes,\n                                         vecSsTot))\n\n        # Output list:\n        lstOut = [idxPrc,\n                  vecBstXpos,\n                  vecBstYpos,\n                  vecBstSd,\n                  vecBstR2,\n                  aryBstBts]\n\n        queOut.put(lstOut)", "response": "This function finds the best fitting pRF model for a specific voxel time course using the CPU."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck the revert status of a revision. With this method, you can determine whether an edit is a 'reverting' edit, was 'reverted' by another edit and/or was 'reverted_to' by another edit. :Parameters: session : :class:`mwapi.Session` An API session to make use of rev_id : int the ID of the revision to check page_id : int the ID of the page the revision occupies (slower if not provided) radius : int a positive integer indicating the maximum number of revisions that can be reverted before : :class:`mwtypes.Timestamp` if set, limits the search for *reverting* revisions to those which were saved before this timestamp window : int if set, limits the search for *reverting* revisions to those which were saved within `window` seconds after the reverted edit rvprop : set( str ) a set of properties to include in revisions :Returns: A triple :class:`mwreverts.Revert` | `None` * reverting -- If this edit reverted other edit(s) * reverted -- If this edit was reverted by another edit * reverted_to -- If this edit was reverted to by another edit :Example: >>> import mwdb >>> import mwreverts.api >>> >>> schema = mwdb.Schema(\"mysql+pymysql://enwiki.labsdb/enwiki_p\" + \"?read_default_file=~/replica.my.cnf\") >>> >>> def print_revert(revert): ... if revert is None: ... print(None) ... else: ... print(revert.reverting['rev_id'], ... [r['rev_id'] for r in revert.reverteds], ... revert.reverted_to['rev_id']) ... >>> reverting, reverted, reverted_to = \\\\ ... mwreverts.db.check(schema, 679778587) >>> print_revert(reverting) None >>> print_revert(reverted) 679778743 [679778587] 679742862 >>> print_revert(reverted_to) None", "response": "def check(schema, rev_id, page_id=None, radius=defaults.RADIUS,\n          before=None, window=None):\n    \"\"\"\n    Checks the revert status of a revision.  With this method, you can\n    determine whether an edit is a 'reverting' edit, was 'reverted' by another\n    edit and/or was 'reverted_to' by another edit.\n\n    :Parameters:\n        session : :class:`mwapi.Session`\n            An API session to make use of\n        rev_id : int\n            the ID of the revision to check\n        page_id : int\n            the ID of the page the revision occupies (slower if not provided)\n        radius : int\n            a positive integer indicating the maximum number of revisions\n            that can be reverted\n        before : :class:`mwtypes.Timestamp`\n            if set, limits the search for *reverting* revisions to those which\n            were saved before this timestamp\n        window : int\n            if set, limits the search for *reverting* revisions to those which\n            were saved within `window` seconds after the reverted edit\n        rvprop : set( str )\n            a set of properties to include in revisions\n\n    :Returns:\n        A triple :class:`mwreverts.Revert` | `None`\n\n        * reverting -- If this edit reverted other edit(s)\n        * reverted -- If this edit was reverted by another edit\n        * reverted_to -- If this edit was reverted to by another edit\n\n    :Example:\n\n        >>> import mwdb\n        >>> import mwreverts.api\n        >>>\n        >>> schema = mwdb.Schema(\"mysql+pymysql://enwiki.labsdb/enwiki_p\" +\n                                 \"?read_default_file=~/replica.my.cnf\")\n        >>>\n        >>> def print_revert(revert):\n        ...     if revert is None:\n        ...         print(None)\n        ...     else:\n        ...         print(revert.reverting['rev_id'],\n        ...               [r['rev_id'] for r in revert.reverteds],\n        ...               revert.reverted_to['rev_id'])\n        ...\n        >>> reverting, reverted, reverted_to = \\\\\n        ...     mwreverts.db.check(schema, 679778587)\n        >>> print_revert(reverting)\n        None\n        >>> print_revert(reverted)\n        679778743 [679778587] 679742862\n        >>> print_revert(reverted_to)\n        None\n\n    \"\"\"\n\n    rev_id = int(rev_id)\n    radius = int(radius)\n    if radius < 1:\n        raise TypeError(\"invalid radius.  Expected a positive integer.\")\n\n    page_id = int(page_id) if page_id is not None else None\n    before = Timestamp(before) if before is not None else None\n\n    # If we don't have the page_id, we're going to need to look them up\n    if page_id is None:\n        page_id = get_page_id(schema, rev_id)\n\n    # Load history and current rev\n    current_and_past_revs = list(n_edits_before(\n        schema, rev_id + 1, page_id, n=radius + 1))\n\n    if len(current_and_past_revs) < 1:\n        raise KeyError(\"Revision {0} not found in page {1}.\"\n                       .format(rev_id, page_id))\n\n    current_rev, past_revs = (\n        current_and_past_revs[-1],  # Current rev is the last one returned\n        current_and_past_revs[:-1]  # The rest are past revs\n    )\n    if current_rev.rev_id != rev_id:\n        raise KeyError(\"Revision {0} not found in page {1}.\"\n                       .format(rev_id, page_id))\n\n    if window is not None and before is None:\n        before = Timestamp(current_rev.rev_timestamp) + window\n\n    # Load future revisions\n    future_revs = list(n_edits_after(\n        schema, rev_id, page_id, n=radius, before=before))\n\n    return build_revert_tuple(\n        rev_id, past_revs, current_rev, future_revs, radius)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_archive(schema, rev_id, namespace=None, title=None, timestamp=None,\n                  radius=defaults.RADIUS,\n                  before=None, window=None):\n    \"\"\"\n    Checks the revert status of an archived revision (from a deleted page).\n    With this method, you can determine whether an edit is a 'reverting'\n    edit, was 'reverted' by another edit and/or was 'reverted_to' by\n    another edit.\n\n    :Parameters:\n        session : :class:`mwapi.Session`\n            An API session to make use of\n        rev_id : int\n            the ID of the revision to check\n        namespace : int\n            the namespace ID of the page the revision exists in\n        title : str\n            the title of the page the revision exists in\n        timestamp : :class:`mwtypes.Timestamp`\n            the timestamp that the revision for `rev_id` was saved\n        radius : int\n            a positive integer indicating the maximum number of revisions\n            that can be reverted\n        before : :class:`mwtypes.Timestamp`\n            if set, limits the search for *reverting* revisions to those which\n            were saved before this timestamp\n        window : int\n            if set, limits the search for *reverting* revisions to those which\n            were saved within `window` seconds after the reverted edit\n        rvprop : set( str )\n            a set of properties to include in revisions\n\n    :Returns:\n        A triple :class:`mwreverts.Revert`\n\n        * reverting -- If this edit reverted other edit(s)\n        * reverted -- If this edit was reverted by another edit\n        * reverted_to -- If this edit was reverted to by another edit\n\n    \"\"\"\n\n    rev_id = int(rev_id)\n    radius = int(radius)\n    if radius < 1:\n        raise TypeError(\"invalid radius.  Expected a positive integer.\")\n\n    namespace = int(namespace) if namespace is not None else None\n    title = str(title) if title is not None else None\n    timestamp = Timestamp(timestamp) if timestamp is not None else None\n    before = Timestamp(before) if before is not None else None\n\n    # If we don't have the page_id, we're going to need to look them up\n    if namespace is None or title is None or timestamp is None:\n        namespace, title, timestamp = \\\n            get_archived_namespace_title_and_timestamp(schema, rev_id)\n\n    # Load history and current rev\n    current_and_past_revs = list(n_archived_edits_before(\n        schema, rev_id + 1, namespace, title, timestamp + 1, n=radius + 1))\n\n    if len(current_and_past_revs) < 1:\n        raise KeyError(\"Revision {0} not found in page {1}(ns={2}) @ {3}.\"\n                       .format(rev_id, title, namespace, timestamp))\n\n    current_rev, past_revs = (\n        current_and_past_revs[-1],  # Current rev is the last one returned\n        current_and_past_revs[:-1]  # The rest are past revs\n    )\n    if current_rev.ar_rev_id != rev_id:\n        raise KeyError(\"Revision {0} not found in page {1}(ns={2}) @ {3}.\"\n                       .format(rev_id, title, namespace, timestamp))\n\n    if window is not None and before is None:\n        before = Timestamp(current_rev.ar_timestamp) + window\n\n    # Load future revisions\n    future_revs = list(n_archived_edits_after(\n        schema, rev_id, namespace, title, timestamp, n=radius, before=before))\n\n    return build_revert_tuple(\n        rev_id, past_revs, current_rev, future_revs, radius)", "response": "Checks the revert status of an archived revision."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert the given value to a JSON object.", "response": "def _get_json(value):\n    \"\"\"Convert the given value to a JSON object.\"\"\"\n    if hasattr(value, 'replace'):\n        value = value.replace('\\n', ' ')\n    try:\n        return json.loads(value)\n    except json.JSONDecodeError:\n        # Escape double quotes.\n        if hasattr(value, 'replace'):\n            value = value.replace('\"', '\\\\\"')\n        # try putting the value into a string\n        return json.loads('\"{}\"'.format(value))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_list(key, *values):\n    return json.dumps({key: [_get_json(value) for value in values]})", "response": "Convert the given list of parameters to a JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts the given parameters to a special JSON object.", "response": "def save_file(key, file_path, *refs):\n    \"\"\"Convert the given parameters to a special JSON object.\n\n    JSON object is of the form:\n    { key: {\"file\": file_path}}, or\n    { key: {\"file\": file_path, \"refs\": [refs[0], refs[1], ... ]}}\n\n    \"\"\"\n    if not os.path.isfile(file_path):\n        return error(\"Output '{}' set to a missing file: '{}'.\".format(key, file_path))\n\n    result = {key: {\"file\": file_path}}\n\n    if refs:\n        missing_refs = [\n            ref for ref in refs if not (os.path.isfile(ref) or os.path.isdir(ref))\n        ]\n        if len(missing_refs) > 0:\n            return error(\n                \"Output '{}' set to missing references: '{}'.\".format(\n                    key, ', '.join(missing_refs)\n                )\n            )\n        result[key]['refs'] = refs\n\n    return json.dumps(result)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert the given parameters to a special JSON object.", "response": "def save_file_list(key, *files_refs):\n    \"\"\"Convert the given parameters to a special JSON object.\n\n    Each parameter is a file-refs specification of the form:\n    <file-path>:<reference1>,<reference2>, ...,\n    where the colon ':' and the list of references are optional.\n\n    JSON object is of the form:\n    { key: {\"file\": file_path}}, or\n    { key: {\"file\": file_path, \"refs\": [refs[0], refs[1], ... ]}}\n\n    \"\"\"\n    file_list = []\n    for file_refs in files_refs:\n        if ':' in file_refs:\n            try:\n                file_name, refs = file_refs.split(':')\n            except ValueError as e:\n                return error(\"Only one colon ':' allowed in file-refs specification.\")\n        else:\n            file_name, refs = file_refs, None\n        if not os.path.isfile(file_name):\n            return error(\n                \"Output '{}' set to a missing file: '{}'.\".format(key, file_name)\n            )\n        file_obj = {'file': file_name}\n\n        if refs:\n            refs = [ref_path.strip() for ref_path in refs.split(',')]\n            missing_refs = [\n                ref for ref in refs if not (os.path.isfile(ref) or os.path.isdir(ref))\n            ]\n            if len(missing_refs) > 0:\n                return error(\n                    \"Output '{}' set to missing references: '{}'.\".format(\n                        key, ', '.join(missing_refs)\n                    )\n                )\n            file_obj['refs'] = refs\n\n        file_list.append(file_obj)\n\n    return json.dumps({key: file_list})"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_dir(key, dir_path, *refs):\n    if not os.path.isdir(dir_path):\n        return error(\n            \"Output '{}' set to a missing directory: '{}'.\".format(key, dir_path)\n        )\n\n    result = {key: {\"dir\": dir_path}}\n\n    if refs:\n        missing_refs = [\n            ref for ref in refs if not (os.path.isfile(ref) or os.path.isdir(ref))\n        ]\n        if len(missing_refs) > 0:\n            return error(\n                \"Output '{}' set to missing references: '{}'.\".format(\n                    key, ', '.join(missing_refs)\n                )\n            )\n        result[key][\"refs\"] = refs\n\n    return json.dumps(result)", "response": "Convert the given parameters to a special JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_dir_list(key, *dirs_refs):\n    dir_list = []\n    for dir_refs in dirs_refs:\n        if ':' in dir_refs:\n            try:\n                dir_path, refs = dir_refs.split(':')\n            except ValueError as e:\n                return error(\"Only one colon ':' allowed in dir-refs specification.\")\n        else:\n            dir_path, refs = dir_refs, None\n        if not os.path.isdir(dir_path):\n            return error(\n                \"Output '{}' set to a missing directory: '{}'.\".format(key, dir_path)\n            )\n        dir_obj = {'dir': dir_path}\n\n        if refs:\n            refs = [ref_path.strip() for ref_path in refs.split(',')]\n            missing_refs = [\n                ref for ref in refs if not (os.path.isfile(ref) or os.path.isdir(ref))\n            ]\n            if len(missing_refs) > 0:\n                return error(\n                    \"Output '{}' set to missing references: '{}'.\".format(\n                        key, ', '.join(missing_refs)\n                    )\n                )\n            dir_obj['refs'] = refs\n\n        dir_list.append(dir_obj)\n\n    return json.dumps({key: dir_list})", "response": "Convert the given parameters to a special JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef progress(progress):\n    if isinstance(progress, int) or isinstance(progress, float):\n        progress = float(progress)\n    else:\n        try:\n            progress = float(json.loads(progress))\n        except (TypeError, ValueError):\n            return warning(\"Progress must be a float.\")\n\n    if not 0 <= progress <= 1:\n        return warning(\"Progress must be a float between 0 and 1.\")\n\n    return json.dumps({'proc.progress': progress})", "response": "Convert given progress to a JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef checkrc(rc, *args):\n    try:\n        rc = int(rc)\n    except (TypeError, ValueError):\n        return error(\"Invalid return code: '{}'.\".format(rc))\n\n    acceptable_rcs = []\n    error_msg = \"\"\n\n    if len(args):\n        for code in args[:-1]:\n            try:\n                acceptable_rcs.append(int(code))\n            except (TypeError, ValueError):\n                return error(\"Invalid return code: '{}'.\".format(code))\n\n        try:\n            acceptable_rcs.append(int(args[-1]))\n        except (TypeError, ValueError):\n            error_msg = args[-1]\n\n    if rc in acceptable_rcs:\n        rc = 0\n\n    ret = {'proc.rc': rc}\n    if rc and error_msg:\n        ret['proc.error'] = error_msg\n\n    return json.dumps(ret)", "response": "Check if return code is in list that contains acceptable return codes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef import_file(\n    src,\n    file_name,\n    imported_format=ImportedFormat.BOTH,\n    progress_from=0.0,\n    progress_to=None,\n):\n    \"\"\"Import file to working directory.\n\n    :param src: Source file path or URL\n    :param file_name: Source file name\n    :param imported_format: Import file format (extracted, compressed or both)\n    :param progress_from: Initial progress value\n    :param progress_to: Final progress value\n    :return: Destination file path (if extracted and compressed, extracted path given)\n    \"\"\"\n\n    if progress_to is not None:\n        if not isinstance(progress_from, float) or not isinstance(progress_to, float):\n            raise ValueError(\"Progress_from and progress_to must be float\")\n\n        if progress_from < 0 or progress_from > 1:\n            raise ValueError(\"Progress_from must be between 0 and 1\")\n\n        if progress_to < 0 or progress_to > 1:\n            raise ValueError(\"Progress_to must be between 0 and 1\")\n\n        if progress_from >= progress_to:\n            raise ValueError(\"Progress_to must be higher than progress_from\")\n\n    print(\"Importing and compressing {}...\".format(file_name))\n\n    def importGz():\n        \"\"\"Import gzipped file.\n\n        The file_name must have .gz extension.\n        \"\"\"\n        if imported_format != ImportedFormat.COMPRESSED:  # Extracted file required\n            with open(file_name[:-3], 'wb') as f_out, gzip.open(src, 'rb') as f_in:\n                try:\n                    shutil.copyfileobj(f_in, f_out, CHUNK_SIZE)\n                except zlib.error:\n                    raise ValueError(\"Invalid gzip file format: {}\".format(file_name))\n\n        else:  # Extracted file not-required\n            # Verify the compressed file.\n            with gzip.open(src, 'rb') as f:\n                try:\n                    while f.read(CHUNK_SIZE) != b'':\n                        pass\n                except zlib.error:\n                    raise ValueError(\"Invalid gzip file format: {}\".format(file_name))\n\n        if imported_format != ImportedFormat.EXTRACTED:  # Compressed file required\n            try:\n                shutil.copyfile(src, file_name)\n            except shutil.SameFileError:\n                pass  # Skip copy of downloaded files\n\n        if imported_format == ImportedFormat.COMPRESSED:\n            return file_name\n        else:\n            return file_name[:-3]\n\n    def import7z():\n        \"\"\"Import compressed file in various formats.\n\n        Supported extensions: .bz2, .zip, .rar, .7z, .tar.gz, and .tar.bz2.\n        \"\"\"\n        extracted_name, _ = os.path.splitext(file_name)\n        destination_name = extracted_name\n        temp_dir = 'temp_{}'.format(extracted_name)\n\n        cmd = '7z x -y -o{} {}'.format(shlex.quote(temp_dir), shlex.quote(src))\n        try:\n            subprocess.check_call(cmd, shell=True)\n        except subprocess.CalledProcessError as err:\n            if err.returncode == 2:\n                raise ValueError(\"Failed to extract file: {}\".format(file_name))\n            else:\n                raise\n\n        paths = os.listdir(temp_dir)\n        if len(paths) == 1 and os.path.isfile(os.path.join(temp_dir, paths[0])):\n            # Single file in archive.\n            temp_file = os.path.join(temp_dir, paths[0])\n\n            if imported_format != ImportedFormat.EXTRACTED:  # Compressed file required\n                with open(temp_file, 'rb') as f_in, gzip.open(\n                    extracted_name + '.gz', 'wb'\n                ) as f_out:\n                    shutil.copyfileobj(f_in, f_out, CHUNK_SIZE)\n\n            if imported_format != ImportedFormat.COMPRESSED:  # Extracted file required\n                shutil.move(temp_file, './{}'.format(extracted_name))\n\n                if extracted_name.endswith('.tar'):\n                    with tarfile.open(extracted_name) as tar:\n                        tar.extractall()\n\n                    os.remove(extracted_name)\n                    destination_name, _ = os.path.splitext(extracted_name)\n            else:\n                destination_name = extracted_name + '.gz'\n        else:\n            # Directory or several files in archive.\n            if imported_format != ImportedFormat.EXTRACTED:  # Compressed file required\n                with tarfile.open(extracted_name + '.tar.gz', 'w:gz') as tar:\n                    for fname in glob.glob(os.path.join(temp_dir, '*')):\n                        tar.add(fname, os.path.basename(fname))\n\n            if imported_format != ImportedFormat.COMPRESSED:  # Extracted file required\n                for path in os.listdir(temp_dir):\n                    shutil.move(os.path.join(temp_dir, path), './{}'.format(path))\n            else:\n                destination_name = extracted_name + '.tar.gz'\n\n        shutil.rmtree(temp_dir)\n        return destination_name\n\n    def importUncompressed():\n        \"\"\"Import uncompressed file.\"\"\"\n        if imported_format != ImportedFormat.EXTRACTED:  # Compressed file required\n            with open(src, 'rb') as f_in, gzip.open(file_name + '.gz', 'wb') as f_out:\n                shutil.copyfileobj(f_in, f_out, CHUNK_SIZE)\n\n        if imported_format != ImportedFormat.COMPRESSED:  # Extracted file required\n            try:\n                shutil.copyfile(src, file_name)\n            except shutil.SameFileError:\n                pass  # Skip copy of downloaded files\n\n        return (\n            file_name + '.gz'\n            if imported_format == ImportedFormat.COMPRESSED\n            else file_name\n        )\n\n    # Large file download from Google Drive requires cookie and token.\n    try:\n        response = None\n        if re.match(\n            r'^https://drive.google.com/[-A-Za-z0-9\\+&@#/%?=~_|!:,.;]*[-A-Za-z0-9\\+&@#/%=~_|]$',\n            src,\n        ):\n            session = requests.Session()\n            response = session.get(src, stream=True)\n\n            token = None\n            for key, value in response.cookies.items():\n                if key.startswith('download_warning'):\n                    token = value\n                    break\n\n            if token is not None:\n                params = {'confirm': token}\n                response = session.get(src, params=params, stream=True)\n\n        elif re.match(\n            r'^(https?|ftp)://[-A-Za-z0-9\\+&@#/%?=~_|!:,.;]*[-A-Za-z0-9\\+&@#/%=~_|]$',\n            src,\n        ):\n            response = requests.get(src, stream=True)\n    except requests.exceptions.ConnectionError:\n        raise requests.exceptions.ConnectionError(\"Could not connect to {}\".format(src))\n\n    if response:\n        with open(file_name, 'wb') as f:\n            total = response.headers.get('content-length')\n            total = float(total) if total else None\n            downloaded = 0\n            current_progress = 0\n            for content in response.iter_content(chunk_size=CHUNK_SIZE):\n                f.write(content)\n\n                if total is not None and progress_to is not None:\n                    downloaded += len(content)\n                    progress_span = progress_to - progress_from\n                    next_progress = progress_from + progress_span * downloaded / total\n                    next_progress = round(next_progress, 2)\n\n                    if next_progress > current_progress:\n                        print(progress(next_progress))\n                        current_progress = next_progress\n\n        # Check if a temporary file exists.\n        if not os.path.isfile(file_name):\n            raise ValueError(\"Downloaded file not found {}\".format(file_name))\n\n        src = file_name\n    else:\n        if not os.path.isfile(src):\n            raise ValueError(\"Source file not found {}\".format(src))\n\n    # Decide which import should be used.\n    if re.search(r'\\.(bz2|zip|rar|7z|tgz|tar\\.gz|tar\\.bz2)$', file_name):\n        destination_file_name = import7z()\n    elif file_name.endswith('.gz'):\n        destination_file_name = importGz()\n    else:\n        destination_file_name = importUncompressed()\n\n    if progress_to is not None:\n        print(progress(progress_to))\n\n    return destination_file_name", "response": "Imports a file from a source file to a target file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload nii data from nii files", "response": "def loadNiiData(lstNiiFls,\n                strPathNiiMask=None,\n                strPathNiiFunc=None):\n    \"\"\"load nii data.\n\n        Parameters\n        ----------\n        lstNiiFls : list, list of str with nii file names\n        strPathNiiMask : str, path to nii file with mask (optional)\n        strPathNiiFunc : str, parent path to nii files (optional)\n        Returns\n        -------\n        aryFunc : np.array\n            Nii data   \n    \"\"\"\n    print('---------Loading nii data')\n    # check whether  a mask is available\n    if strPathNiiMask is not None:\n        aryMask = nb.load(strPathNiiMask).get_data().astype('bool')\n    # check a parent path is available that needs to be preprended to nii files\n    if strPathNiiFunc is not None:\n        lstNiiFls = [os.path.join(strPathNiiFunc, i) for i in lstNiiFls]\n\n    aryFunc = []\n    for idx, path in enumerate(lstNiiFls):\n        print('------------Loading run: ' + str(idx+1))\n        # Load 4D nii data:\n        niiFunc = nb.load(path).get_data()\n        # append to list\n        if strPathNiiMask is not None:\n            aryFunc.append(niiFunc[aryMask, :])\n        else:\n            aryFunc.append(niiFunc)\n    # concatenate arrys in list along time dimension\n    aryFunc = np.concatenate(aryFunc, axis=-1)\n    # set to type float32\n    aryFunc = aryFunc.astype('float32')\n\n    return aryFunc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating coefficient of determination. Assumes that axis = 0 is time", "response": "def calcR2(predTst, yTest, axis=0):\n    \"\"\"calculate coefficient of determination. Assumes that axis=0 is time\n\n        Parameters\n        ----------\n        predTst : np.array, predicted reponse for yTest\n        yTest : np.array, acxtually observed response for yTest\n        Returns\n        -------\n        aryFunc : np.array\n            R2\n    \"\"\"\n    rss = np.sum((yTest - predTst) ** 2, axis=axis)\n    tss = np.sum((yTest - yTest.mean()) ** 2, axis=axis)\n\n    return 1 - rss/tss"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calcFstats(predTst, yTest, p, axis=0):\n    rss = np.sum((yTest - predTst) ** 2, axis=axis)\n    tss = np.sum((yTest - yTest.mean()) ** 2, axis=axis)\n    # derive number of measurements\n    n = yTest.shape[0]\n    # calculate Fvalues\n    vecFvals = ((tss - rss)/p)/(rss/(n-p-1))\n    # calculate corresponding po values\n    df1 = p - 1\n    df2 = n-1\n    vecPvals = stats.f.cdf(vecFvals, df1, df2)\n\n    return vecFvals, vecPvals", "response": "calculate coefficient of determination. Assumes that axis = 0 is time\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calcMse(predTst, yTest, axis=0):\n    return np.mean((yTest - predTst) ** 2, axis=axis)", "response": "calculate mean squared error. Assumes that axis = 0 is time\n getTerminal"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetecting reverts that occur in a sequence of revisions.", "response": "def detect(checksum_revisions, radius=defaults.RADIUS):\n    \"\"\"\n    Detects reverts that occur in a sequence of revisions.  Note that,\n    `revision` data meta will simply be returned in the case of a revert.\n\n    This function serves as a convenience wrapper around calls to\n    :class:`mwreverts.Detector`'s :func:`~mwreverts.Detector.process`\n    method.\n\n    :Parameters:\n        checksum_revisions : `iterable` ( (checksum, revision) )\n            an iterable over tuples of checksum and revision meta data\n        radius : int\n            a positive integer indicating the maximum revision distance that a\n            revert can span.\n\n    :Return:\n        a iterator over :class:`mwreverts.Revert`\n\n    :Example:\n        >>> import mwreverts\n        >>>\n        >>> checksum_revisions = [\n        ...     (\"aaa\", {'rev_id': 1}),\n        ...     (\"bbb\", {'rev_id': 2}),\n        ...     (\"aaa\", {'rev_id': 3}),\n        ...     (\"ccc\", {'rev_id': 4})\n        ... ]\n        >>>\n        >>> list(mwreverts.detect(checksum_revisions))\n        [Revert(reverting={'rev_id': 3},\n                reverteds=[{'rev_id': 2}],\n                reverted_to={'rev_id': 1})]\n\n    \"\"\"\n\n    revert_detector = Detector(radius)\n\n    for checksum, revision in checksum_revisions:\n        revert = revert_detector.process(checksum, revision)\n        if revert is not None:\n            yield revert"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getChargeInfo(self, CorpNum, ItemCode, UserID=None):\r\n        if ItemCode == None or ItemCode == '':\r\n            raise PopbillException(-99999999, \"\uba85\uc138\uc11c \uc885\ub958 \ucf54\ub4dc\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        return self._httpget('/Statement/ChargeInfo/' + ItemCode, CorpNum, UserID)", "response": "\uc694\uccad\ubc88\ud638 Returns a list of ChargeInfo objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getUnitCost(self, CorpNum, ItemCode):\r\n        if ItemCode == None or ItemCode == \"\":\r\n            raise PopbillException(-99999999, \"\uba85\uc138\uc11c \uc885\ub958 \ucf54\ub4dc\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        result = self._httpget('/Statement/' + str(ItemCode) + '?cfg=UNITCOST', CorpNum)\r\n        return float(result.unitCost)", "response": "\uc804\uc790\ubc88\ud638 \uc804\uc790\ubc88\ud638 \uc815\uc11c \ufffd"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef registIssue(self, CorpNum, statement, Memo=None, UserID=None):\r\n        if statement == None:\r\n            raise PopbillException(-99999999, \"\ub4f1\ub85d\ud560 \uc804\uc790\uba85\uc138\uc11c \uc815\ubcf4\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        if Memo != None or Memo != '':\r\n            statement.memo = Memo\r\n\r\n        postData = self._stringtify(statement)\r\n\r\n        return self._httppost('/Statement', postData, CorpNum, UserID, \"ISSUE\")", "response": "\uc989\uc2dc\ubc1c\ud589\r\n            args\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                statement : \ub4f1\ub85d\ud560 \uc804\uc790\uba85\uc138\uc11c object. made with Statement(...)\r\n                Memo : \uc989\uc2dc\ubc1c\ud589\uba54\ubaa8\r\n\r\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\r\n            return\r\n                \ucc98\ub9ac\uacb0\uacfc. consist of code and message\r\n            raise\r\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register(self, CorpNum, statement, UserID=None):\r\n        if statement == None:\r\n            raise PopbillException(-99999999, \"\ub4f1\ub85d\ud560 \uc804\uc790\uba85\uc138\uc11c \uc815\ubcf4\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        postData = self._stringtify(statement)\r\n\r\n        return self._httppost('/Statement', postData, CorpNum, UserID)", "response": "\uc784\uc2dc\uc800\uc7a5\r\n            args\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                statement : \ub4f1\ub85d\ud560 \uc804\uc790\uba85\uc138\uc11c object. made with Statement(...)\r\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\r\n            return\r\n                \ucc98\ub9ac\uacb0\uacfc. consist of code and message\r\n            raise\r\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, CorpNum, ItemCode, MgtKey, Statement, UserID=None):\r\n\r\n        if Statement == None:\r\n            raise PopbillException(-99999999, \"\ub4f1\ub85d\ud560 \uc804\uc790\uba85\uc138\uc11c \uc815\ubcf4\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n        if MgtKey == None or MgtKey == \"\":\r\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n        if ItemCode == None or ItemCode == \"\":\r\n            raise PopbillException(-99999999, \"\uba85\uc138\uc11c \uc885\ub958 \ucf54\ub4dc\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        postData = self._stringtify(Statement)\r\n\r\n        return self._httppost('/Statement/' + str(ItemCode) + '/' + MgtKey, postData, CorpNum, UserID, 'PATCH')", "response": "\uc784\uc2dc\uc800\uc7a5\r\n            args\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                ItemCode : \uba85\uc138\uc11c \uc885\ub958 \ucf54\ub4dc\r\n                    [121 - \uac70\ub798\uba85\uc138\uc11c], [122 - \uccad\uad6c\uc11c], [123 - \uacac\uc801\uc11c],\r\n                    [124 - \ubc1c\uc8fc\uc11c], [125 - \uc785\uae08\ud45c], [126 - \uc601\uc218\uc99d]\r\n                MgtKey : \ud30c\ud2b8\ub108 \ubb38\uc11c\uad00\ub9ac\ubc88\ud638\r\n                Statement : \ub4f1\ub85d\ud560 \uc804\uc790\uba85\uc138\uc11c object. made with Statement(...)\r\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\r\n            return\r\n                \ucc98\ub9ac\uacb0\uacfc. consist of code and message\r\n            raise\r\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nissuing a new item from the given CorpNum.", "response": "def issue(self, CorpNum, ItemCode, MgtKey, Memo=None, EmailSubject=None, UserID=None):\r\n        \"\"\" \ubc1c\ud589\r\n            args\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                ItemCode : \uba85\uc138\uc11c \uc885\ub958 \ucf54\ub4dc\r\n                    [121 - \uac70\ub798\uba85\uc138\uc11c], [122 - \uccad\uad6c\uc11c], [123 - \uacac\uc801\uc11c],\r\n                    [124 - \ubc1c\uc8fc\uc11c], [125 - \uc785\uae08\ud45c], [126 - \uc601\uc218\uc99d]\r\n                MgtKey : \ud30c\ud2b8\ub108 \ubb38\uc11c\uad00\ub9ac\ubc88\ud638\r\n                Memo : \ucc98\ub9ac\uba54\ubaa8\r\n                EmailSubject : \ubc1c\ud589\uba54\uc77c \uc81c\ubaa9(\ubbf8\uae30\uc7ac\uc2dc \uae30\ubcf8\uc591\uc2dd\uc73c\ub85c \uc804\uc1a1)\r\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\r\n            return\r\n                \ucc98\ub9ac\uacb0\uacfc. consist of code and message\r\n            raise\r\n                PopbillException\r\n        \"\"\"\r\n        if MgtKey == None or MgtKey == \"\":\r\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n        if ItemCode == None or ItemCode == \"\":\r\n            raise PopbillException(-99999999, \"\uba85\uc138\uc11c \uc885\ub958 \ucf54\ub4dc\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        req = {}\r\n        postData = \"\"\r\n\r\n        if Memo != None and Memo != '':\r\n            req[\"memo\"] = Memo\r\n        if EmailSubject != None and EmailSubject != '':\r\n            req[\"emailSubject\"] = EmailSubject\r\n\r\n        postData = self._stringtify(req)\r\n\r\n        return self._httppost('/Statement/' + str(ItemCode) + '/' + MgtKey, postData, CorpNum, UserID, \"ISSUE\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cancel(self, CorpNum, ItemCode, MgtKey, Memo=None, UserID=None):\r\n\r\n        if MgtKey == None or MgtKey == \"\":\r\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n        if ItemCode == None or ItemCode == \"\":\r\n            raise PopbillException(-99999999, \"\uba85\uc138\uc11c \uc885\ub958 \ucf54\ub4dc\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        postData = ''\r\n\r\n        if Memo != None and Memo != '':\r\n            postData = self._stringtify({\"memo\": Memo})\r\n\r\n        return self._httppost('/Statement/' + str(ItemCode) + '/' + MgtKey, postData, CorpNum, UserID, \"CANCEL\")", "response": "Cancel a single item from a given CorpNum."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting Info from Alembic.", "response": "def getInfo(self, CorpNum, ItemCode, MgtKey):\r\n        \"\"\" \uc0c1\ud0dc/\uc694\uc57d \uc815\ubcf4 \ud655\uc778\r\n            args\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                ItemCode : \uba85\uc138\uc11c \uc885\ub958 \ucf54\ub4dc\r\n                    [121 - \uac70\ub798\uba85\uc138\uc11c], [122 - \uccad\uad6c\uc11c], [123 - \uacac\uc801\uc11c],\r\n                    [124 - \ubc1c\uc8fc\uc11c], [125 - \uc785\uae08\ud45c], [126 - \uc601\uc218\uc99d]\r\n                MgtKey : \ud30c\ud2b8\ub108 \ubb38\uc11c\uad00\ub9ac\ubc88\ud638\r\n            return\r\n                \ubb38\uc11c \uc0c1\ud0dc/\uc694\uc57d\uc815\ubcf4 object\r\n            raise\r\n                PopbillException\r\n        \"\"\"\r\n        if MgtKey == None or MgtKey == \"\":\r\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n        if ItemCode == None or ItemCode == \"\":\r\n            raise PopbillException(-99999999, \"\uba85\uc138\uc11c \uc885\ub958 \ucf54\ub4dc\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        return self._httpget('/Statement/' + str(ItemCode) + '/' + MgtKey, CorpNum)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getDetailInfo(self, CorpNum, ItemCode, MgtKey):\r\n        if MgtKey == None or MgtKey == \"\":\r\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n        if ItemCode == None or ItemCode == \"\":\r\n            raise PopbillException(-99999999, \"\uba85\uc138\uc11c \uc885\ub958 \ucf54\ub4dc\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        return self._httpget('/Statement/' + str(ItemCode) + '/' + MgtKey + '?Detail', CorpNum)", "response": "Get the details of a particular item in a particular CorpNum."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nattaches File to CorpNum", "response": "def attachFile(self, CorpNum, ItemCode, MgtKey, FilePath, UserID=None):\r\n        \"\"\" \ud30c\uc77c \ucca8\ubd80\r\n            args\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                ItemCode : \uba85\uc138\uc11c \uc885\ub958 \ucf54\ub4dc\r\n                    [121 - \uac70\ub798\uba85\uc138\uc11c], [122 - \uccad\uad6c\uc11c], [123 - \uacac\uc801\uc11c],\r\n                    [124 - \ubc1c\uc8fc\uc11c], [125 - \uc785\uae08\ud45c], [126 - \uc601\uc218\uc99d]\r\n                MgtKey : \ud30c\ud2b8\ub108 \ubb38\uc11c\uad00\ub9ac\ubc88\ud638\r\n                FilePath : \ucca8\ubd80\ud30c\uc77c\uc758 \uacbd\ub85c\r\n                UserID : \ud31d\ube4c \ud68c\uc6d0\uc544\uc774\ub514\r\n            return\r\n                \ucc98\ub9ac\uacb0\uacfc. consist of code and message\r\n            raise\r\n                PopbillException\r\n        \"\"\"\r\n        if MgtKey == None or MgtKey == \"\":\r\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n        if FilePath == None or FilePath == \"\":\r\n            raise PopbillException(-99999999, \"\ud30c\uc77c\uacbd\ub85c\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n        if ItemCode == None or ItemCode == \"\":\r\n            raise PopbillException(-99999999, \"\uba85\uc138\uc11c \uc885\ub958 \ucf54\ub4dc\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n        files = []\r\n\r\n        try:\r\n            with open(FilePath, \"rb\") as F:\r\n                files = [File(fieldName='Filedata',\r\n                              fileName=F.name,\r\n                              fileData=F.read())]\r\n        except IOError:\r\n            raise PopbillException(-99999999, \"\ud574\ub2f9\uacbd\ub85c\uc5d0 \ud30c\uc77c\uc774 \uc5c6\uac70\ub098 \uc77d\uc744 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        return self._httppost_files('/Statement/' + str(ItemCode) + '/' + MgtKey + '/Files', None, files, CorpNum,\r\n                                    UserID)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a file from the given CorpNum and MgtKey.", "response": "def deleteFile(self, CorpNum, ItemCode, MgtKey, FileID, UserID=None):\r\n        \"\"\" \ucca8\ubd80\ud30c\uc77c \uc0ad\uc81c\r\n            args\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                ItemCode : \uba85\uc138\uc11c \uc885\ub958 \ucf54\ub4dc\r\n                    [121 - \uac70\ub798\uba85\uc138\uc11c], [122 - \uccad\uad6c\uc11c], [123 - \uacac\uc801\uc11c],\r\n                    [124 - \ubc1c\uc8fc\uc11c], [125 - \uc785\uae08\ud45c], [126 - \uc601\uc218\uc99d]\r\n                MgtKey : \ud30c\ud2b8\ub108 \ubb38\uc11c\uad00\ub9ac\ubc88\ud638\r\n                FileID : \ud30c\uc77c\uc544\uc774\ub514, \ucca8\ubd80\ud30c\uc77c \ubaa9\ub85d\ud655\uc778(getFiles) API \uc751\ub2f5\uc804\ubb38\uc758 AttachedFile \ubcc0\uc218\uac12\r\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\r\n            return\r\n                \ucca8\ubd80\ud30c\uc77c \uc815\ubcf4 \ubaa9\ub85d as List\r\n            raise\r\n                PopbillException\r\n        \"\"\"\r\n        if MgtKey == None or MgtKey == \"\":\r\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n        if ItemCode == None or ItemCode == \"\":\r\n            raise PopbillException(-99999999, \"\uba85\uc138\uc11c \uc885\ub958 \ucf54\ub4dc\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n        if FileID == None or FileID == \"\":\r\n            raise PopbillException(-99999999, \"\ud30c\uc77c\uc544\uc774\ub514\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        postData = ''\r\n\r\n        return self._httppost('/Statement/' + str(ItemCode) + '/' + MgtKey + '/Files/' + FileID, postData, CorpNum,\r\n                              UserID, 'DELETE')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getMassPrintURL(self, CorpNum, ItemCode, MgtKeyList, UserID=None):\r\n        if MgtKeyList == None:\r\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638 \ubc30\uc5f4\uc774 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n        if ItemCode == None or ItemCode == \"\":\r\n            raise PopbillException(-99999999, \"\uba85\uc138\uc11c \uc885\ub958 \ucf54\ub4dc\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        postData = self._stringtify(MgtKeyList)\r\n\r\n        result = self._httppost('/Statement/' + str(ItemCode) + '?Print', postData, CorpNum, UserID)\r\n\r\n        return result.url", "response": "\uc778\uc1c4 URL \ud655\uc778 \ud655\uc778"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef attachStatement(self, CorpNum, ItemCode, MgtKey, SubItemCode, SubMgtKey, UserID=None):\r\n        if MgtKey == None or MgtKey == \"\":\r\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n        if ItemCode == None or ItemCode == \"\":\r\n            raise PopbillException(-99999999, \"\uba85\uc138\uc11c \uc885\ub958 \ucf54\ub4dc\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        uri = '/Statement/' + ItemCode + '/' + MgtKey + '/AttachStmt'\r\n\r\n        postData = self._stringtify({\"ItemCode\": ItemCode, \"MgtKey\": SubMgtKey})\r\n\r\n        return self._httppost(uri, postData, CorpNum, UserID)", "response": "A method to attach a statement to a CorpNum."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process(self, article):\n        if self.article is not None and not self.collection:\n            log.warning('Could not process additional article. Package only \\\nhandles one article unless collection mode is set.')\n            return False\n\n        if article.publisher is None:\n            log.error('''Package cannot be generated for an Article \\\nwithout a publisher!''')\n            return\n        self.article = article\n        self.article_doi = self.article.doi.split('/')[1]\n        self.all_dois.append(self.article.doi)\n\n        #Analyze the article to add entries to the spine\n        dash_doi = self.article_doi.replace('.', '-')\n\n        #Entry for the main content document\n        main_idref = 'main-{0}-xhtml'.format(dash_doi)\n        self.spine_list.append(spine_item(main_idref, True))\n\n        #Entry for the biblio content document\n        biblio_idref = 'biblio-{0}-xhtml'.format(dash_doi)\n        if self.article.root.xpath('./back/ref-list/ref'):\n                self.spine_list.append(spine_item(biblio_idref, True))\n\n        #Entry for the tables content document\n        tables_idref = 'tables-{0}-xhtml'.format(dash_doi)\n        if self.article.publisher.has_out_of_flow_tables():\n            self.spine_list.append(spine_item(tables_idref, False))\n\n        self.acquire_metadata()", "response": "Processes an article and adds the appropriate spine items to the internal spine list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef acquire_metadata(self):\n        #For space economy\n        publisher = self.article.publisher\n\n        if self.collection:  # collection mode metadata gathering\n            pass\n        else:  # single mode metadata gathering\n            self.pub_id = publisher.package_identifier()\n            self.title = publisher.package_title()\n            for date in publisher.package_date():\n                self.dates.add(date)\n\n        #Common metadata gathering\n        for lang in publisher.package_language():\n            self.languages.add(lang)  # languages\n        for contributor in publisher.package_contributors():  # contributors\n            self.contributors.add(contributor)\n        self.publishers.add(publisher.package_publisher())  # publisher names\n        desc = publisher.package_description()\n        if desc is not None:\n            self.descriptions.add(desc)\n        for subj in publisher.package_subject():\n            self.subjects.add(subj)  # subjects\n        #Rights\n        art_rights = publisher.package_rights()\n        self.rights.add(art_rights)\n        if art_rights not in self.rights_associations:\n            self.rights_associations[art_rights] = [self.article.doi]\n        else:\n            self.rights_associations[art_rights].append(self.article.doi)", "response": "Handles the acquisition of metadata for both collection mode and single mode."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef file_manifest(self, location):\n        #Maps file extensions to mimetypes\n        mimetypes = {'.jpg': 'image/jpeg',\n                     '.jpeg': 'image/jpeg',\n                     '.xml': 'application/xhtml+xml',\n                     '.png': 'image/png',\n                     '.css': 'text/css',\n                     '.ncx': 'application/x-dtbncx+xml',\n                     '.gif': 'image/gif',\n                     '.tif': 'image/tif',\n                     '.pdf': 'application/pdf',\n                     '.xhtml': 'application/xhtml+xml',\n                     '.ttf': 'application/vnd.ms-opentype',\n                     '.otf': 'application/vnd.ms-opentype'}\n\n        current_dir = os.getcwd()\n        os.chdir(location)\n        for dirpath, _dirnames, filenames in os.walk('.'):\n            dirpath = dirpath[2:]  # A means to avoid dirpath prefix of './'\n            for fn in filenames:\n                fn_ext = os.path.splitext(fn)[-1]\n                item = etree.Element('item')\n                #Here we set three attributes: href, media-type, and id\n                if not dirpath:\n                    item.attrib['href'] = fn\n                else:\n                    item.attrib['href'] = '/'.join([dirpath, fn])\n                item.attrib['media-type'] = mimetypes[fn_ext]\n                #Special handling for common image types\n                if fn_ext in ['.jpg', '.png', '.tif', '.jpeg']:\n                    #the following lines assume we are using the convention\n                    #where the article doi is prefixed by 'images-'\n                    item.attrib['id'] = '-'.join([dirpath[7:],\n                                                  fn.replace('.', '-')])\n                else:\n                    item.attrib['id'] = fn.replace('.', '-')\n                yield item\n        os.chdir(current_dir)", "response": "Returns an iterator over the files in a location which yields item elements that can be inserted into the package manifest."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an appropriate Name and File - As - Name for a contrib element.", "response": "def get_contrib_names(self, contrib):\n        \"\"\"\n        Returns an appropriate Name and File-As-Name for a contrib element.\n\n        This code was refactored out of nav_contributors and\n        package_contributors to provide a single definition point for a common\n        job. This is a useful utility that may be well-employed for other\n        publishers as well.\n        \"\"\"\n        collab = contrib.find('collab')\n        anon = contrib.find('anonymous')\n        if collab is not None:\n            proper_name = serialize(collab, strip=True)\n            file_as_name = proper_name\n        elif anon is not None:\n            proper_name = 'Anonymous'\n            file_as_name = proper_name\n        else:\n            name = contrib.find('name')\n            surname = name.find('surname').text\n            given = name.find('given-names')\n            if given is not None:\n                if given.text:  # Sometimes these tags are empty\n                    proper_name = ' '.join([surname, given.text])\n                    #File-as name is <surname>, <given-initial-char>\n                    file_as_name = ', '.join([surname, given.text[0]])\n                else:\n                    proper_name = surname\n                    file_as_name = proper_name\n            else:\n                proper_name = surname\n                file_as_name = proper_name\n        return proper_name, file_as_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the article description for the current article.", "response": "def package_description(self):\n        \"\"\"\n        Given an Article class instance, this is responsible for returning an\n        article description. For this method I have taken the approach of\n        serializing the article's first abstract, if it has one. This results\n        in 0 or 1 descriptions per article.\n        \"\"\"\n        abstract = self.article.root.xpath('./front/article-meta/abstract')\n        return serialize(abstract[0], strip=True) if abstract else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef heading_title(self):\n        art_title = self.article.root.xpath('./front/article-meta/title-group/article-title')[0]\n        article_title = deepcopy(art_title)\n        article_title.tag = 'h1'\n        article_title.attrib['id'] = 'title'\n        article_title.attrib['class'] = 'article-title'\n        return article_title", "response": "Makes the Article Title for the Heading."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_heading_authors(self, authors):\n        author_element = etree.Element('h3', {'class': 'authors'})\n        #Construct content for the author element\n        first = True\n        for author in authors:\n            if first:\n                first = False\n            else:\n                append_new_text(author_element, ',', join_str='')\n            collab = author.find('collab')\n            anon = author.find('anon')\n            if collab is not None:\n                append_all_below(author_element, collab)\n            elif anon is not None:  # If anonymous, just add \"Anonymous\"\n                append_new_text(author_element, 'Anonymous')\n            else:  # Author is neither Anonymous or a Collaboration\n                author_name, _ = self.get_contrib_names(author)\n                append_new_text(author_element, author_name)\n            #TODO: Handle author footnote references, also put footnotes in the ArticleInfo\n            #Example: journal.pbio.0040370.xml\n            first = True\n            for xref in author.xpath(\"./xref[@ref-type='corresp' or @ref-type='aff']\"):\n                _sup = xref.find('sup')\n                sup_text = all_text(_sup) if _sup is not None else ''\n                auth_sup = etree.SubElement(author_element, 'sup')\n                sup_link = etree.SubElement(auth_sup,\n                                            'a',\n                                            {'href': self.main_fragment.format(xref.attrib['rid'])})\n                sup_link.text = sup_text\n                if first:\n                    first = False\n                else:\n                    append_new_text(auth_sup, ', ', join_str='')\n            #for xref in author.findall('xref'):\n                #if xref.attrs['ref-type'] in ['corresp', 'aff']:\n\n                    #try:\n                        #sup_element = xref.sup[0].node\n                    #except IndexError:\n                        #sup_text = ''\n                    #else:\n                        #sup_text = all_text(sup_element)\n                    #new_sup = etree.SubElement(author_element, 'sup')\n                    #sup_link = etree.SubElement(new_sup, 'a')\n                    #sup_link.attrib['href'] = self.main_fragment.format(xref.attrs['rid'])\n                    #sup_link.text = sup_text\n                    #if first:\n                        #first = False\n                    #else:\n                        #new_sup.text = ','\n        return author_element", "response": "Constructs the Authors element for the Heading element. This should display the Heading element directly after the Article Title. This should display the Heading element directly after the Article Title."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_heading_affiliations(self, heading_div):\n        #Get all of the aff element tuples from the metadata\n        affs = self.article.root.xpath('./front/article-meta/aff')\n        #Create a list of all those pertaining to the authors\n        author_affs = [i for i in affs if 'aff' in i.attrib['id']]\n        #Count them, used for formatting\n        if len(author_affs) == 0:\n            return None\n        else:\n            affs_list = etree.SubElement(heading_div,\n                                         'ul',\n                                         {'id': 'affiliations',\n                                          'class': 'simple'})\n\n        for aff in author_affs:\n            #Create a span element to accept extracted content\n            aff_item = etree.SubElement(affs_list, 'li')\n            aff_item.attrib['id'] = aff.attrib['id']\n            #Get the first label node and the first addr-line node\n            label = aff.find('label')\n            addr_line = aff.find('addr-line')\n            if label is not None:\n                bold = etree.SubElement(aff_item, 'b')\n                bold.text = all_text(label) + ' '\n            if addr_line is not None:\n                append_new_text(aff_item, all_text(addr_line))\n            else:\n                append_new_text(aff_item, all_text(aff))", "response": "Makes the content for the Author Affiliations element displays after the Heading."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_heading_abstracts(self, heading_div):\n        for abstract in self.article.root.xpath('./front/article-meta/abstract'):\n            #Make a copy of the abstract\n            abstract_copy = deepcopy(abstract)\n            abstract_copy.tag = 'div'\n            #Abstracts are a rather diverse bunch, keep an eye on them!\n            title_text = abstract_copy.xpath('./title[1]/text()')\n            for title in abstract_copy.findall('.//title'):\n                remove(title)\n            #Create a header for the abstract\n            abstract_header = etree.Element('h2')\n            remove_all_attributes(abstract_copy)\n            #Set the header text and abstract id according to abstract type\n            abstract_type = abstract.attrib.get('abstract-type')\n            log.debug('Handling Abstrace of with abstract-type=\"{0}\"'.format(abstract_type))\n            if abstract_type == 'summary':\n                abstract_header.text = 'Author Summary'\n                abstract_copy.attrib['id'] = 'author-summary'\n            elif abstract_type == 'editors-summary':\n                abstract_header.text = 'Editors\\' Summary'\n                abstract_copy.attrib['id'] = 'editor-summary'\n            elif abstract_type == 'synopsis':\n                abstract_header.text = 'Synopsis'\n                abstract_copy.attrib['id'] = 'synopsis'\n            elif abstract_type == 'alternate':\n                #Right now, these will only be included if there is a title to\n                #give it\n                if title_text:\n                    abstract_header.text= title_text[0]\n                    abstract_copy.attrib['id'] = 'alternate'\n                else:\n                    continue\n            elif abstract_type is None:\n                abstract_header.text = 'Abstract'\n                abstract_copy.attrib['id'] = 'abstract'\n            elif abstract_type == 'toc':  # We don't include these\n                continue\n            else:  # Warn about these, then skip\n                log.warning('No handling for abstract-type=\"{0}\"'.format(abstract_type))\n                continue\n                #abstract_header.text = abstract_type\n                #abstract_copy.attrib['id'] = abstract_type\n            heading_div.append(abstract_header)\n            heading_div.append(abstract_copy)", "response": "This method creates the headings for all abstracts in the article."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate the Article Info element for the current article.", "response": "def make_article_info(self):\n        \"\"\"\n        The Article Info contains the (self) Citation, Editors, Dates,\n        Copyright, Funding Statement, Competing Interests Statement,\n        Correspondence, and Footnotes. Maybe more...\n\n        This content follows the Heading and precedes the Main segment in the\n        output.\n\n        This function accepts the receiving_node argument, which will receive\n        all generated output as new childNodes.\n        \"\"\"\n        body = self.main.getroot().find('body')\n        #Create a div for ArticleInfo, exposing it to linking and formatting\n        article_info_div = etree.Element('div', {'id': 'ArticleInfo'})\n        body.insert(1, article_info_div)\n        #Creation of the self Citation\n        article_info_div.append(self.make_article_info_citation())\n        #Creation of the Editors\n        editors = self.article.root.xpath(\"./front/article-meta/contrib-group/contrib[@contrib-type='editor']\")\n        self.make_article_info_editors(editors, article_info_div)\n        #Creation of the important Dates segment\n        article_info_div.append(self.make_article_info_dates())\n        #Creation of the Copyright statement\n        self.make_article_info_copyright(article_info_div)\n        #Creation of the Funding statement\n        self.make_article_info_funding(article_info_div)\n        #Creation of the Competing Interests statement\n        self.make_article_info_competing_interests(article_info_div)\n        #Creation of the Correspondences (contact information) for the article\n        self.make_article_info_correspondences(article_info_div)\n        #Creation of the Footnotes (other) for the ArticleInfo\n        self.make_article_info_footnotes_other(article_info_div)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a self citation node for the ArticleInfo of the article.", "response": "def make_article_info_citation(self):\n        \"\"\"\n        Creates a self citation node for the ArticleInfo of the article.\n\n        This method uses code from this page as a reference implementation:\n        https://github.com/PLOS/ambra/blob/master/base/src/main/resources/articleTransform-v3.xsl\n        \"\"\"\n        citation_div = etree.Element('div', {'id': 'article-citation'})\n        b = etree.SubElement(citation_div, 'b')\n        b.text = 'Citation: '\n\n        #Add author stuff to the citation\n        authors = self.article.root.xpath(\"./front/article-meta/contrib-group/contrib[@contrib-type='author']\")\n        for author in authors:\n            author_index = authors.index(author)\n            #At the 6th author, simply append an et al., then stop iterating\n            if author_index == 5:\n                append_new_text(citation_div, 'et al.', join_str='')\n                break\n            else:\n                #Check if the author contrib has a collab\n                collab = author.find('collab')\n                if collab is not None:\n                    collab_copy = deepcopy(collab)\n                    for contrib_group in collab_copy.findall('contrib_group'):\n                        remove(contrib_group)\n                    append_all_below(citation_div, collab, join_str='')\n                else:  # Author element is not a collab\n                    name = author.find('name')\n                    #Note that this does not support eastern names\n                    #Grab the surname information\n                    surname = name.find('surname')\n                    given_names = name.find('given-names')\n                    suffix = name.find('suffix')\n                    append_new_text(citation_div, surname.text, join_str='')\n                    #Make initials from the given-name information\n                    if given_names is not None:\n                        #Add a space\n                        append_new_text(citation_div, ' ', join_str='')\n                        #Split by whitespace and take first character\n                        given_initials = [i[0] for i in given_names.text.split() if i]\n                        for initial in given_initials:\n                            append_new_text(citation_div, initial, join_str='')\n                    #If there is a suffix, add its text, but don't include the\n                    #trailing period if there is one\n                    if suffix is not None:\n                        #Add a space\n                        append_new_text(citation_div, ' ', join_str='')\n                        suffix_text = suffix.text\n                        #Check for the trailing period\n                        if suffix_text[-1] == '.':\n                            suffix_text = suffix_text[:-1]\n                        append_new_text(citation_div, suffix_text, join_str='')\n                #If this is not the last author to be added, add a \", \"\n                #This is satisfied by being less than the 6th author, or less\n                #than the length of the author_list - 1\n                if author_index < 5 or author_index < len(author_list) -1:\n                    append_new_text(citation_div, ', ', join_str='')\n        #Add Publication Year to the citation\n        #Find pub-date elements, use pub-type=collection, or else pub-type=ppub\n        d = './front/article-meta/pub-date'\n        coll = self.article.root.xpath(d + \"[@pub-type='collection']\")\n        ppub = self.article.root.xpath(d + \"[@pub-type='ppub']\")\n        if coll:\n            pub_year = coll[0].find('year').text\n        elif ppub:\n            pub_year = ppub[0].find('year').text\n        append_new_text(citation_div, ' ({0}) '.format(pub_year), join_str='')\n        #Add the Article Title to the Citation\n        #As best as I can tell from the reference implementation, they\n        #serialize the article title to text-only, and expunge redundant spaces\n        #This might need later review\n        article_title = self.article.root.xpath('./front/article-meta/title-group/article-title')[0]\n        article_title_text = serialize(article_title)\n        normalized = ' '.join(article_title_text.split())  # Remove redundant whitespace\n        #Add a period unless there is some other valid punctuation\n        if normalized[-1] not in '.?!':\n            normalized += '.'\n        append_new_text(citation_div, normalized + ' ', join_str='')\n        #Add the article's journal name using the journal-id of type \"nlm-ta\"\n        journal = self.article.root.xpath(\"./front/journal-meta/journal-id[@journal-id-type='nlm-ta']\")\n        append_new_text(citation_div, journal[0].text + ' ', join_str='')\n        #Add the article's volume, issue, and elocation_id  values\n        volume = self.article.root.xpath('./front/article-meta/volume')[0].text\n        issue = self.article.root.xpath('./front/article-meta/issue')[0].text\n        elocation_id = self.article.root.xpath('./front/article-meta/elocation-id')[0].text\n        form = '{0}({1}): {2}. '.format(volume, issue, elocation_id)\n        append_new_text(citation_div, form, join_str='')\n        append_new_text(citation_div, 'doi:{0}'.format(self.article.doi), join_str='')\n\n        return citation_div"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_article_info_dates(self):\n        dates_div = etree.Element('div', {'id': 'article-dates'})\n\n        d = './front/article-meta/history/date'\n        received = self.article.root.xpath(d + \"[@date-type='received']\")\n        accepted = self.article.root.xpath(d + \"[@date-type='accepted']\")\n        if received:\n            b = etree.SubElement(dates_div, 'b')\n            b.text = 'Received: '\n            dt = self.date_tuple_from_date(received[0], 'Received')\n            formatted_date_string = self.format_date_string(dt)\n            append_new_text(dates_div, formatted_date_string + '; ')\n        if accepted:\n            b = etree.SubElement(dates_div, 'b')\n            b.text = 'Accepted: '\n            dt = self.date_tuple_from_date(accepted[0], 'Accepted')\n            formatted_date_string = self.format_date_string(dt)\n            append_new_text(dates_div, formatted_date_string + '; ')\n        #Published date is required\n        pub_date = self.article.root.xpath(\"./front/article-meta/pub-date[@pub-type='epub']\")[0]\n        b = etree.SubElement(dates_div, 'b')\n        b.text = 'Published: '\n        dt = self.date_tuple_from_date(pub_date, 'Published')\n        formatted_date_string = self.format_date_string(dt)\n        append_new_text(dates_div, formatted_date_string)\n\n        return dates_div", "response": "Makes the section containing important dates for the article."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_article_info_funding(self, article_info_div):\n        funding_group = self.article.root.xpath('./front/article-meta/funding-group')\n        if funding_group:\n            funding_div = etree.SubElement(article_info_div,\n                                           'div',\n                                           {'id': 'funding'})\n            funding_b = etree.SubElement(funding_div, 'b')\n            funding_b.text = 'Funding: '\n            #As far as I can tell, PLoS only uses one funding-statement\n            funding_statement = funding_group[0].find('funding-statement')\n            append_all_below(funding_div, funding_statement)", "response": "Creates the element for declaring Funding in the article info."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_article_info_competing_interests(self, article_info_div):\n        #Check for author-notes\n        con_expr = \"./front/article-meta/author-notes/fn[@fn-type='conflict']\"\n        conflict = self.article.root.xpath(con_expr)\n        if not conflict:\n            return\n        conflict_div = etree.SubElement(article_info_div,\n                                        'div',\n                                        {'id': 'conflict'})\n        b = etree.SubElement(conflict_div, 'b')\n        b.text = 'Competing Interests: '\n        fn_p = conflict[0].find('p')\n        if fn_p is not None:\n            append_all_below(conflict_div, fn_p)", "response": "Creates the element for declaring competing interests in the article."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds the corresponding articles to the article_info_div.", "response": "def make_article_info_correspondences(self, article_info_div):\n        \"\"\"\n        Articles generally provide a first contact, typically an email address\n        for one of the authors. This will supply that content.\n        \"\"\"\n        corresps = self.article.root.xpath('./front/article-meta/author-notes/corresp')\n        if corresps:\n            corresp_div = etree.SubElement(article_info_div,\n                                           'div',\n                                           {'id': 'correspondence'})\n        for corresp in corresps:\n            sub_div = etree.SubElement(corresp_div,\n                                       'div',\n                                       {'id': corresp.attrib['id']})\n            append_all_below(sub_div, corresp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_article_info_footnotes_other(self, article_info_div):\n        other_fn_expr = \"./back/fn-group/fn[@fn-type='other']\"\n        other_fns = self.article.root.xpath(other_fn_expr)\n        if other_fns:\n            other_fn_div = etree.SubElement(article_info_div,\n                                            'div',\n                                            {'class': 'back-fn-other'})\n        for other_fn in other_fns:\n            append_all_below(other_fn_div, other_fn)", "response": "This will create the other footnotes in the article info div."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef move_back_boxed_texts(self):\n        body = self.main.getroot().find('body')\n        back = self.article.root.find('back')\n        if back is None:\n            return\n        boxed_texts = back.xpath('.//boxed-text')\n        for boxed_text in boxed_texts:\n            body.append(deepcopy(boxed_text))", "response": "Move anyboxed - text elements over to the receiving element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking the back - acks element.", "response": "def make_back_acknowledgments(self):\n        \"\"\"\n        The <ack> is an important piece of back matter information, and will be\n        including immediately after the main text.\n\n        This element should only occur once, optionally, for PLoS, if a need\n        becomes known, then multiple instances may be supported.\n        \"\"\"\n        acks = self.article.root.xpath('./back/ack')\n        if not acks:\n            return\n        ack = deepcopy(acks[0])\n        #Modify the tag to div\n        ack.tag = 'div'\n        #Give it an id\n        ack.attrib['id'] = 'acknowledgments'\n        #Give it a title element--this is not an EPUB element but doing so will\n        #allow it to later be depth-formatted by self.convert_div_titles()\n        ack_title = etree.Element('title')\n        ack_title.text = 'Acknowledgments'\n        ack.insert(0, ack_title)  # Make it the first element\n        return ack"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_back_glossary(self, body):\n        for glossary in self.article.root.xpath('./back/glossary'):\n            gloss_copy = deepcopy(glossary)\n            gloss_copy.tag = 'div'\n            gloss_copy.attrib['class'] = 'back-glossary'\n            body.append(gloss_copy)", "response": "Glossaries are a fairly common item in papers for PLoS, but it also\n        seems that they are rarely incorporated into the PLoS web-site or PDF\n        formats. They are included in the ePub output however because they are\n        helpful and because we can."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_back_notes(self, body):\n        for notes in self.article.root.xpath('./back/notes'):\n            notes_sec = deepcopy(notes.find('sec'))\n            notes_sec.tag = 'div'\n            notes_sec.attrib['class'] = 'back-notes'\n            body.append(notes_sec)", "response": "Make back - notes elements."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert the disp - formula elements to conforming elements", "response": "def convert_disp_formula_elements(self):\n        \"\"\"\n        <disp-formula> elements must be converted to conforming elements\n        \"\"\"\n        for disp in self.main.getroot().findall('.//disp-formula'):\n            #find label element\n            label_el = disp.find('label')\n            graphic_el = disp.find('graphic')\n            if graphic_el is None:  # No graphic, assume math as text instead\n                text_span = etree.Element('span', {'class': 'disp-formula'})\n                if 'id' in disp.attrib:\n                    text_span.attrib['id'] = disp.attrib['id']\n                append_all_below(text_span, disp)\n                #Insert the text span before the disp-formula\n                insert_before(disp, text_span)\n                #If a label exists, modify and insert before text_span\n                if label_el is not None:\n                    label_el.tag = 'b'\n                    insert_before(text_span, label_el)\n                #Remove the disp-formula\n                remove(disp)\n                #Skip the rest, which deals with the graphic element\n                continue\n            #The graphic element is present\n            #Create a file reference for the image\n            xlink_href = ns_format(graphic_el, 'xlink:href')\n            graphic_xlink_href = graphic_el.attrib[xlink_href]\n            file_name = graphic_xlink_href.split('.')[-1] + '.png'\n            img_dir = 'images-' + self.doi_suffix()\n            img_path = '/'.join([img_dir, file_name])\n\n            #Create the img element\n            img_element = etree.Element('img', {'alt': 'A Display Formula',\n                                                'class': 'disp-formula',\n                                                'src': img_path})\n            #Transfer the id attribute\n            if 'id' in disp.attrib:\n                img_element.attrib['id'] = disp.attrib['id']\n            #Insert the img element\n            insert_before(disp, img_element)\n            #Create content for the label\n            if label_el is not None:\n                label_el.tag = 'b'\n                insert_before(img_element, label_el)\n            #Remove the old disp-formula element\n            remove(disp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert inline - formula elements to the corresponding image elements.", "response": "def convert_inline_formula_elements(self):\n        \"\"\"\n        <inline-formula> elements must be converted to be conforming\n\n        These elements may contain <inline-graphic> elements, textual content,\n        or both.\n        \"\"\"\n        for inline in self.main.getroot().findall('.//inline-formula'):\n            #inline-formula elements will be modified in situ\n            remove_all_attributes(inline)\n            inline.tag = 'span'\n            inline.attrib['class'] = 'inline-formula'\n            inline_graphic = inline.find('inline-graphic')\n            if inline_graphic is None:\n                # Do nothing more if there is no graphic\n                continue\n            #Need to conver the inline-graphic element to an img element\n            inline_graphic.tag = 'img'\n            #Get a copy of the attributes, then remove them\n            inline_graphic_attributes = copy(inline_graphic.attrib)\n            remove_all_attributes(inline_graphic)\n            #Create a file reference for the image\n            xlink_href = ns_format(inline_graphic, 'xlink:href')\n            graphic_xlink_href = inline_graphic_attributes[xlink_href]\n            file_name = graphic_xlink_href.split('.')[-1] + '.png'\n            img_dir = 'images-' + self.doi_suffix()\n            img_path = '/'.join([img_dir, file_name])\n            #Set the source to the image path\n            inline_graphic.attrib['src'] = img_path\n            inline_graphic.attrib['class'] = 'inline-formula'\n            inline_graphic.attrib['alt'] = 'An Inline Formula'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_disp_quote_elements(self):\n        for disp_quote in self.main.getroot().findall('.//disp-quote'):\n            if disp_quote.getparent().tag == 'p':\n                elevate_element(disp_quote)\n            disp_quote.tag = 'div'\n            disp_quote.attrib['class'] = 'disp-quote'", "response": "Convert disp - quote elements to divs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_boxed_text_elements(self):\n        for boxed_text in self.main.getroot().findall('.//boxed-text'):\n            sec_el = boxed_text.find('sec')\n            if sec_el is not None:\n                sec_el.tag = 'div'\n                title = sec_el.find('title')\n                if title is not None:\n                    title.tag = 'b'\n                sec_el.attrib['class'] = 'boxed-text'\n                if 'id' in boxed_text.attrib:\n                    sec_el.attrib['id'] = boxed_text.attrib['id']\n                replace(boxed_text, sec_el)\n            else:\n                div_el = etree.Element('div', {'class': 'boxed-text'})\n                if 'id' in boxed_text.attrib:\n                    div_el.attrib['id'] = boxed_text.attrib['id']\n                append_all_below(div_el, boxed_text)\n                replace(boxed_text, div_el)", "response": "Convert all the boxed - text elements in the main XML file into a single boxed - text element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert supplementary material elements into a div element.", "response": "def convert_supplementary_material_elements(self):\n        \"\"\"\n        Supplementary material are not, nor are they generally expected to be,\n        packaged into the epub file. Though this is a technical possibility,\n        and certain epub reading systems (such as those run on a PC) might be\n        reasonably capable of the external handling of diverse file formats\n        I presume that supplementary material will remain separate from the\n        document. So special cases aside, external links to supplementary\n        material will be employed; this will require internet connection for\n        access.\n\n        As for content in <supplementary-material>, they appear to strictly\n        contain 1 <label> element, followed by a <caption><title><p></caption>\n        substructure.\n        \"\"\"\n        for supplementary in self.main.getroot().findall('.//supplementary-material'):\n            #Create a div element to hold the supplementary content\n            suppl_div = etree.Element('div')\n            if 'id' in supplementary.attrib:\n                suppl_div.attrib['id'] = supplementary.attrib['id']\n            insert_before(supplementary, suppl_div)\n            #Get the sub elements\n            label = supplementary.find('label')\n            caption = supplementary.find('caption')\n            #Get the external resource URL for the supplementary information\n            ns_xlink_href = ns_format(supplementary, 'xlink:href')\n            xlink_href = supplementary.attrib[ns_xlink_href]\n            resource_url = self.fetch_single_representation(xlink_href)\n            if label is not None:\n                label.tag = 'a'\n                label.attrib['href'] = resource_url\n                append_new_text(label, '. ', join_str='')\n                suppl_div.append(label)\n            if caption is not None:\n                title = caption.find('title')\n                paragraphs = caption.findall('p')\n                if title is not None:\n                    title.tag = 'b'\n                    suppl_div.append(title)\n                for paragraph in paragraphs:\n                    suppl_div.append(paragraph)\n            #This is a fix for odd articles with <p>s outside of <caption>\n            #See journal.pctr.0020006, PLoS themselves fail to format this for\n            #the website, though the .pdf is good\n            #It should be noted that journal.pctr.0020006 does not pass\n            #validation because it places a <p> before a <caption>\n            #By placing this at the end of the method, it conforms to the spec\n            #by expecting such p tags after caption. This causes a hiccup in\n            #the rendering for journal.pctr.0020006, but it's better than\n            #skipping the data entirely AND it should also work for conforming\n            #articles.\n            for paragraph in supplementary.findall('p'):\n                suppl_div.append(paragraph)\n            remove(supplementary)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch_single_representation(self, item_xlink_href):\n        #A dict of URLs for PLoS subjournals\n        journal_urls = {'pgen': 'http://www.plosgenetics.org/article/{0}',\n                        'pcbi': 'http://www.ploscompbiol.org/article/{0}',\n                        'ppat': 'http://www.plospathogens.org/article/{0}',\n                        'pntd': 'http://www.plosntds.org/article/{0}',\n                        'pmed': 'http://www.plosmedicine.org/article/{0}',\n                        'pbio': 'http://www.plosbiology.org/article/{0}',\n                        'pone': 'http://www.plosone.org/article/{0}',\n                        'pctr': 'http://clinicaltrials.ploshubs.org/article/{0}'}\n        #Identify subjournal name for base URl\n        subjournal_name = self.article.doi.split('.')[2]\n        base_url = journal_urls[subjournal_name]\n        #Compose the address for fetchSingleRepresentation\n        resource = 'fetchSingleRepresentation.action?uri=' + item_xlink_href\n        return base_url.format(resource)", "response": "This function will render a formatted URL for accessing the PLoS serverSingleRepresentation of an object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_fig_elements(self):\n        for fig in self.main.getroot().findall('.//fig'):\n            if fig.getparent().tag == 'p':\n                elevate_element(fig)\n        for fig in self.main.getroot().findall('.//fig'):\n            #self.convert_fn_elements(fig)\n            #self.convert_disp_formula_elements(fig)\n            #Find label and caption\n            label_el = fig.find('label')\n            caption_el = fig.find('caption')\n            #Get the graphic node, this should be mandatory later on\n            graphic_el = fig.find('graphic')\n            #Create a file reference for the image\n            xlink_href = ns_format(graphic_el, 'xlink:href')\n            graphic_xlink_href = graphic_el.attrib[xlink_href]\n            file_name = graphic_xlink_href.split('.')[-1] + '.png'\n            img_dir = 'images-' + self.doi_suffix()\n            img_path = '/'.join([img_dir, file_name])\n\n            #Create the content: using image path, label, and caption\n            img_el = etree.Element('img', {'alt': 'A Figure', 'src': img_path,\n                                           'class': 'figure'})\n            if 'id' in fig.attrib:\n                img_el.attrib['id'] = fig.attrib['id']\n            insert_before(fig, img_el)\n\n            #Create content for the label and caption\n            if caption_el is not None or label_el is not None:\n                img_caption_div = etree.Element('div', {'class': 'figure-caption'})\n                img_caption_div_b = etree.SubElement(img_caption_div, 'b')\n                if label_el is not None:\n                    append_all_below(img_caption_div_b, label_el)\n                    append_new_text(img_caption_div_b, '. ', join_str='')\n                if caption_el is not None:\n                    caption_title = caption_el.find('title')\n                    if caption_title is not None:\n                        append_all_below(img_caption_div_b, caption_title)\n                        append_new_text(img_caption_div_b, ' ', join_str='')\n                    for each_p in caption_el.findall('p'):\n                        append_all_below(img_caption_div, each_p)\n                insert_before(fig, img_caption_div)\n\n            #Remove the original <fig>\n            remove(fig)", "response": "Converts the JPTS 3. 0 <fig > elements to EPUB 3. 0 <img > elements to EPUB 3. 0 <fig > elements to EPUB 3. 0 <img > elements to EPUB 3. 0 <fig > elements to EPUB 3. 0 <fig > elements to EPUB 3. 0 <fig > elements to EPUB 3. 0 <fig > elements to EPUB 3. 0 <fig > elements to EPUB 3. 0."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_verse_group_elements(self):\n        for verse_group in self.main.getroot().findall('.//verse-group'):\n            #Find some possible sub elements for the heading\n            label = verse_group.find('label')\n            title = verse_group.find('title')\n            subtitle = verse_group.find('subtitle')\n            #Modify the verse-group element\n            verse_group.tag = 'div'\n            verse_group.attrib['id'] = 'verse-group'\n            #Create a title for the verse_group\n            if label is not None or title is not None or subtitle is not None:\n                new_verse_title = etree.Element('b')\n                #Insert it at the beginning\n                verse_group.insert(0, new_verse_title)\n                #Induct the title elements into the new title\n                if label is not None:\n                    append_all_below(new_verse_title, label)\n                    remove(label)\n                if title is not None:\n                    append_all_below(new_verse_title, title)\n                    remove(title)\n                if subtitle is not None:\n                    append_all_below(new_verse_title, subtitle)\n                    remove(subtitle)\n            for verse_line in verse_group.findall('verse-line'):\n                verse_line.tag = 'p'\n                verse_line.attrib['class'] = 'verse-line'", "response": "Convert the verse - group elements into italicized lines."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_fn_elements(self):\n        for footnote in self.main.getroot().findall('.//fn'):\n            #Use only the first paragraph\n            paragraph = footnote.find('p')\n            #If no paragraph, move on\n            if paragraph is None:\n                remove(footnote)\n                continue\n            #Simply remove corrected errata items\n            paragraph_text = str(etree.tostring(paragraph, method='text', encoding='utf-8'), encoding='utf-8')\n            if paragraph_text.startswith('Erratum') and 'Corrected' in paragraph_text:\n                remove(footnote)\n                continue\n            #Transfer some attribute information from the fn element to the paragraph\n            if 'id' in footnote.attrib:\n                paragraph.attrib['id'] = footnote.attrib['id']\n            if 'fn-type' in footnote.attrib:\n                paragraph.attrib['class'] = 'fn-type-{0}'.footnote.attrib['fn-type']\n            else:\n                paragraph.attrib['class'] = 'fn'\n                #Replace the\n            replace(footnote, paragraph)", "response": "Convert all fn elements in the main text body into a list of nparrays."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_list_elements(self):\n        #I have yet to gather many examples of this element, and may have to\n        #write a recursive method for the processing of lists depending on how\n        #PLoS produces their XML, for now this method is ignorant of nesting\n\n        #TODO: prefix-words, one possible solution would be to have this method\n        #edit the CSS to provide formatting support for arbitrary prefixes...\n\n        #This is a block level element, so elevate it if found in p\n        for list_el in self.main.getroot().findall('.//list'):\n            if list_el.getparent().tag == 'p':\n                elevate_element(list_el)\n\n        #list_el is used instead of list (list is reserved)\n        for list_el in self.main.getroot().findall('.//list'):\n            if 'list-type' not in list_el.attrib:\n                list_el_type = 'order'\n            else:\n                list_el_type = list_el.attrib['list-type']\n            #Unordered lists\n            if list_el_type in ['', 'bullet', 'simple']:\n                list_el.tag = 'ul'\n                #CSS must be used to recognize the class and suppress bullets\n                if list_el_type == 'simple':\n                    list_el.attrib['class'] = 'simple'\n            #Ordered lists\n            else:\n                list_el.tag = 'ol'\n                list_el.attrib['class'] = list_el_type\n            #Convert the list-item element tags to 'li'\n            for list_item in list_el.findall('list-item'):\n                list_item.tag = 'li'\n            remove_all_attributes(list_el, exclude=['id', 'class'])", "response": "Convert the list elements to XML."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_def_list_elements(self):\n        for def_list in self.main.getroot().findall('.//def-list'):\n            #Remove the attributes, excepting id\n            remove_all_attributes(def_list, exclude=['id'])\n            #Modify the def-list element\n            def_list.tag = 'div'\n            def_list.attrib['class'] = 'def-list'\n            for def_item in def_list.findall('def-item'):\n                #Get the term being defined, modify it\n                term = def_item.find('term')\n                term.tag = 'p'\n                term.attrib['class']= 'def-item-term'\n                #Insert it before its parent def_item\n                insert_before(def_item, term)\n                #Get the definition, handle missing with a warning\n                definition = def_item.find('def')\n                if definition is None:\n                    log.warning('Missing def element in def-item')\n                    remove(def_item)\n                    continue\n                #PLoS appears to consistently place all definition text in a\n                #paragraph subelement of the def element\n                def_para = definition.find('p')\n                def_para.attrib['class'] = 'def-item-def'\n                #Replace the def-item element with the p element\n                replace(def_item, def_para)", "response": "This method converts the XML elements in the def - list element to a list of elements which are in turn of two parts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_ref_list_elements(self):\n        #TODO: Handle nested ref-lists\n        for ref_list in self.main.getroot().findall('.//ref-list'):\n            remove_all_attributes(ref_list)\n            ref_list.tag = 'div'\n            ref_list.attrib['class'] = 'ref-list'\n            label = ref_list.find('label')\n            if label is not None:\n                label.tag = 'h3'\n            for ref in ref_list.findall('ref'):\n                ref_p = etree.Element('p')\n                ref_p.text = str(etree.tostring(ref, method='text', encoding='utf-8'), encoding='utf-8')\n                replace(ref, ref_p)", "response": "Convert all the ref - list elements in the article to the appropriate format."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts JPTS 3. 0 <table - wrap > elements to EPUB content.", "response": "def convert_table_wrap_elements(self):\n        \"\"\"\n        Responsible for the correct conversion of JPTS 3.0 <table-wrap>\n        elements to EPUB content.\n\n        The 'id' attribute is treated as mandatory by this method.\n        \"\"\"\n        for table_wrap in self.main.getroot().findall('.//table-wrap'):\n\n            table_div = etree.Element('div', {'id': table_wrap.attrib['id']})\n\n            label = table_wrap.find('label')\n            caption = table_wrap.find('caption')\n            alternatives = table_wrap.find('alternatives')\n            graphic = table_wrap.find('graphic')\n            table = table_wrap.find('table')\n            if graphic is None:\n                if alternatives is not None:\n                    graphic = alternatives.find('graphic')\n            if table is None:\n                if alternatives is not None:\n                    table = alternatives.find('table')\n\n            #Handling the label and caption\n            if label is not None and caption is not None:\n                caption_div = etree.Element('div', {'class': 'table-caption'})\n                caption_div_b = etree.SubElement(caption_div, 'b')\n                if label is not None:\n                    append_all_below(caption_div_b, label)\n                if caption is not None:\n                    #Find, optional, title element and paragraph elements\n                    caption_title = caption.find('title')\n                    if caption_title is not None:\n                        append_all_below(caption_div_b, caption_title)\n                    caption_ps = caption.findall('p')\n                    #For title and each paragraph, give children to the div\n                    for caption_p in caption_ps:\n                        append_all_below(caption_div, caption_p)\n                #Add this to the table div\n                table_div.append(caption_div)\n\n            ### Practical Description ###\n            #A table may have both, one of, or neither of graphic and table\n            #The different combinations should be handled, but a table-wrap\n            #with neither should fail with an error\n            #\n            #If there is both an image and a table, the image should be placed\n            #in the text flow with a link to the html table\n            #\n            #If there is an image and no table, the image should be placed in\n            #the text flow without a link to an html table\n            #\n            #If there is a table with no image, then the table should be placed\n            #in the text flow.\n\n            if graphic is not None:\n                #Create the image path for the graphic\n                xlink_href = ns_format(graphic, 'xlink:href')\n                graphic_xlink_href = graphic.attrib[xlink_href]\n                file_name = graphic_xlink_href.split('.')[-1] + '.png'\n                img_dir = 'images-' + self.doi_suffix()\n                img_path = '/'.join([img_dir, file_name])\n                #Create the new img element\n                img_element = etree.Element('img', {'alt': 'A Table',\n                                                    'src': img_path,\n                                                    'class': 'table'})\n                #Add this to the table div\n                table_div.append(img_element)\n                #If table, add it to the list, and link to it\n                if table is not None:  # Both graphic and table\n                    #The label attribute is just a means of transmitting some\n                    #plaintext which will be used for the labeling in the html\n                    #tables file\n                    div = etree.SubElement(self.tables.find('body'),\n                                           'div',\n                                           {'id': table_wrap.attrib['id']})\n\n                    if label is not None:\n                        bold_label = etree.SubElement(div, 'b')\n                        append_all_below(bold_label, label)\n                    #Add the table to the tables list\n                    div.append(deepcopy(table))\n                    #Also add the table's foot if it exists\n                    table_wrap_foot = table_wrap.find('table-wrap-foot')\n                    if table_wrap_foot is not None:\n                        table_wrap_foot.tag = 'div'\n                        table_wrap_foot.attrib['class'] = 'table-wrap-foot'\n                        div.append(table_wrap_foot)\n                    #Create a link to the html version of the table\n                    html_table_link = etree.Element('a')\n                    html_table_link.attrib['href'] = self.tables_fragment.format(table_wrap.attrib['id'])\n                    html_table_link.text = 'Go to HTML version of this table'\n                    #Add this to the table div\n                    table_div.append(html_table_link)\n                    remove(table)\n\n            elif table is not None:  # Table only\n                #Simply append the table to the table div\n                table_div.append(table)\n            elif graphic is None and table is None:\n                sys.exit('Encountered table-wrap element with neither graphic nor table. Exiting.')\n\n            #Replace the original table-wrap with the newly constructed div\n            replace(table_wrap, table_div)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts all graphic elements in the main XML file into a single image.", "response": "def convert_graphic_elements(self):\n        \"\"\"\n        This is a method for the odd special cases where <graphic> elements are\n        standalone, or rather, not a part of a standard graphical element such\n        as a figure or a table. This method should always be employed after the\n        standard cases have already been handled.\n        \"\"\"\n        for graphic in self.main.getroot().findall('.//graphic'):\n            graphic.tag = 'img'\n            graphic.attrib['alt'] = 'unowned-graphic'\n            ns_xlink_href = ns_format(graphic, 'xlink:href')\n            if ns_xlink_href in graphic.attrib:\n                xlink_href = graphic.attrib[ns_xlink_href]\n                file_name = xlink_href.split('.')[-1] + '.png'\n                img_dir = 'images-' + self.doi_suffix()\n                img_path = '/'.join([img_dir, file_name])\n                graphic.attrib['src'] = img_path\n            remove_all_attributes(graphic, exclude=['id', 'class', 'alt', 'src'])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getChargeInfo(self, CorpNum, MsgType, UserID=None):\r\n        if MsgType == None or MsgType == \"\":\r\n            raise PopbillException(-99999999, \"\uc804\uc1a1\uc720\ud615\uc774 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        return self._httpget('/Message/ChargeInfo?Type=' + MsgType, CorpNum, UserID)", "response": "\uacfc\uae08\uc815\ubcf4 \ud655\uc778\r\n            args\r\n                CorpNum : \ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                MsgType : \ubb38\uc790\uc804\uc1a1 \uc720\ud615\r\n                UserID : \ud31d\ube4c \ud68c\uc6d0\uc544\uc774\ub514\r\n            return\r\n                \uacfc\uae08\uc815\ubcf4 \uac1d\uccb4\r\n            raise\r\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sendMMS_Multi(self, CorpNum, Sender, Subject, Contents, Messages, FilePath, reserveDT, adsYN=False, UserID=None,\r\n                      RequestNum=None):\r\n        \"\"\" \uba40\ud2f0 \ubb38\uc790\uba54\uc2dc\uc9c0 \ub2e4\ub7c9 \uc804\uc1a1\r\n            args\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                Sender : \ubc1c\uc2e0\uc790\ubc88\ud638 (\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\r\n                Subject : \uc7a5\ubb38 \uba54\uc2dc\uc9c0 \uc81c\ubaa9 (\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\r\n                Contents : \uc7a5\ubb38 \ubb38\uc790 \ub0b4\uc6a9 (\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\r\n                Messages : \uac1c\ubcc4\uc804\uc1a1\uc815\ubcf4 \ubc30\uc5f4\r\n                FilePath : \uc804\uc1a1\ud558\uace0\uc790 \ud558\ub294 \ud30c\uc77c \uacbd\ub85c\r\n                reserveDT : \uc608\uc57d\uc804\uc1a1\uc2dc\uac04 (\ud615\uc2dd. yyyyMMddHHmmss)\r\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\r\n                RequestNum = \uc804\uc1a1\uc694\uccad\ubc88\ud638\r\n            return\r\n                \uc811\uc218\ubc88\ud638 (receiptNum)\r\n            raise\r\n                PopbillException\r\n        \"\"\"\r\n        if Messages == None or len(Messages) < 1:\r\n            raise PopbillException(-99999999, \"\uc804\uc1a1\ud560 \uba54\uc2dc\uc9c0\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        req = {}\r\n\r\n        if Sender != None or Sender != '':\r\n            req['snd'] = Sender\r\n        if Contents != None or Contents != '':\r\n            req['content'] = Contents\r\n        if Subject != None or Subject != '':\r\n            req['subject'] = Subject\r\n        if reserveDT != None or reserveDT != '':\r\n            req['sndDT'] = reserveDT\r\n        if Messages != None or Messages != '':\r\n            req['msgs'] = Messages\r\n        if RequestNum != None or RequestNum != '':\r\n            req['requestNum'] = RequestNum\r\n        if adsYN:\r\n            req['adsYN'] = True\r\n\r\n        postData = self._stringtify(req)\r\n\r\n        files = []\r\n        try:\r\n            with open(FilePath, \"rb\") as F:\r\n                files = [File(fieldName='file',\r\n                              fileName=F.name,\r\n                              fileData=F.read())]\r\n        except IOError:\r\n            raise PopbillException(-99999999, \"\ud574\ub2f9\uacbd\ub85c\uc5d0 \ud30c\uc77c\uc774 \uc5c6\uac70\ub098 \uc77d\uc744 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        result = self._httppost_files('/MMS', postData, files, CorpNum, UserID)\r\n\r\n        return result.receiptNum", "response": "\uba40\ud2f0 \ubb38\uc790\uba54\uc2dc\uc9c0 \ub2e4\ub7c9 \uc804\uc1a1\r\n            args\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                Sender : \ubc1c\uc2e0\uc790\ubc88\ud638 (\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\r\n                Subject : \uc7a5\ubb38 \uba54\uc2dc\uc9c0 \uc81c\ubaa9 (\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\r\n                Contents : \uc7a5\ubb38 \ubb38\uc790 \ub0b4\uc6a9 (\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\r\n                Messages : \uac1c\ubcc4\uc804\uc1a1\uc815\ubcf4 \ubc30\uc5f4\r\n                FilePath : \uc804\uc1a1\ud558\uace0\uc790 \ud558\ub294 \ud30c\uc77c \uacbd\ub85c\r\n                reserveDT : \uc608\uc57d\uc804\uc1a1\uc2dc\uac04 (\ud615\uc2dd. yyyyMMddHHmmss)\r\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\r\n                RequestNum = \uc804\uc1a1\uc694\uccad\ubc88\ud638\r\n            return\r\n                \uc811\uc218\ubc88\ud638 (receiptNum)\r\n            raise\r\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sendMessage(self, MsgType, CorpNum, Sender, SenderName, Subject, Contents, Messages, reserveDT, adsYN=False,\r\n                    UserID=None, RequestNum=None):\r\n        \"\"\" \ubb38\uc790 \uba54\uc2dc\uc9c0 \uc804\uc1a1\r\n            args\r\n                MsgType : \ubb38\uc790 \uc804\uc1a1 \uc720\ud615(\ub2e8\ubb38:SMS, \uc7a5\ubb38:LMS, \ub2e8/\uc7a5\ubb38:XMS)\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                Sender : \ubc1c\uc2e0\uc790\ubc88\ud638 (\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\r\n                Subject : \uc7a5\ubb38 \uba54\uc2dc\uc9c0 \uc81c\ubaa9 (\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\r\n                Contents : \uc7a5\ubb38 \ubb38\uc790 \ub0b4\uc6a9 (\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\r\n                Messages : \uac1c\ubcc4\uc804\uc1a1\uc815\ubcf4 \ubc30\uc5f4\r\n                reserveDT : \uc608\uc57d\uc804\uc1a1\uc2dc\uac04 (\ud615\uc2dd. yyyyMMddHHmmss)\r\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\r\n                RequestNum : \uc804\uc1a1\uc694\uccad\ubc88\ud638\r\n            return\r\n                \uc811\uc218\ubc88\ud638 (receiptNum)\r\n            raise\r\n                PopbillException\r\n        \"\"\"\r\n        if MsgType == None or MsgType == '':\r\n            raise PopbillException(-99999999, \"\ubb38\uc790 \uc804\uc1a1 \uc720\ud615\uc774 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        if Messages == None or len(Messages) < 1:\r\n            raise PopbillException(-99999999, \"\uc804\uc1a1\ud560 \uba54\uc2dc\uc9c0\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        req = {}\r\n\r\n        if Sender != None or Sender != '':\r\n            req['snd'] = Sender\r\n        if SenderName != None or SenderName != '':\r\n            req['sndnm'] = SenderName\r\n        if Contents != None or Contents != '':\r\n            req['content'] = Contents\r\n        if Subject != None or Subject != '':\r\n            req['subject'] = Subject\r\n        if reserveDT != None or reserveDT != '':\r\n            req['sndDT'] = reserveDT\r\n        if Messages != None or Messages != '':\r\n            req['msgs'] = Messages\r\n        if RequestNum != None or RequestNum != '':\r\n            req['requestnum'] = RequestNum\r\n        if adsYN:\r\n            req['adsYN'] = True\r\n\r\n        postData = self._stringtify(req)\r\n\r\n        result = self._httppost('/' + MsgType, postData, CorpNum, UserID)\r\n\r\n        return result.receiptNum", "response": "\ubb38\uc790 \uba54\uc2dc\uc9c0 \uc804\uc1a1\r\n            args\r\n                MsgType : \ubb38\uc790 \uc804\uc1a1 \uc720\ud615(\ub2e8\ubb38:SMS, \uc7a5\ubb38:LMS, \ub2e8/\uc7a5\ubb38:XMS)\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                Sender : \ubc1c\uc2e0\uc790\ubc88\ud638 (\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\r\n                Subject : \uc7a5\ubb38 \uba54\uc2dc\uc9c0 \uc81c\ubaa9 (\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\r\n                Contents : \uc7a5\ubb38 \ubb38\uc790 \ub0b4\uc6a9 (\ub3d9\ubcf4\uc804\uc1a1\uc6a9)\r\n                Messages : \uac1c\ubcc4\uc804\uc1a1\uc815\ubcf4 \ubc30\uc5f4\r\n                reserveDT : \uc608\uc57d\uc804\uc1a1\uc2dc\uac04 (\ud615\uc2dd. yyyyMMddHHmmss)\r\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\r\n                RequestNum : \uc804\uc1a1\uc694\uccad\ubc88\ud638\r\n            return\r\n                \uc811\uc218\ubc88\ud638 (receiptNum)\r\n            raise\r\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncanceling a reserve request.", "response": "def cancelReserveRN(self, CorpNum, RequestNum, UserID=None):\r\n        \"\"\" \ubb38\uc790 \uc608\uc57d\uc804\uc1a1 \ucde8\uc18c\r\n            args\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                RequestNum : \uc804\uc1a1\uc694\uccad\uc2dc \ud560\ub2f9\ud55c \uc804\uc1a1\uc694\uccad\ubc88\ud638\r\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\r\n            return\r\n                \ucc98\ub9ac\uacb0\uacfc. consist of code and message\r\n            raise\r\n                PopbillException\r\n        \"\"\"\r\n        if RequestNum == None or RequestNum == '':\r\n            raise PopbillException(-99999999, \"\uc694\uccad\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        return self._httpget('/Message/Cancel/' + RequestNum, CorpNum, UserID)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getURL(self, CorpNum, UserID, ToGo):\r\n        if ToGo == None or ToGo == '':\r\n            raise PopbillException(-99999999, \"TOGO\uac12\uc774 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        result = self._httpget('/Message/?TG=' + ToGo, CorpNum, UserID)\r\n\r\n        return result.url", "response": "\ubb38\uc790 \uad00\ub828 \ud31d\ube4c URL\r\n            args\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\r\n                TOGO : BOX (\uc804\uc1a1\ub0b4\uc5ed\uc870\ud68c \ud31d\uc5c5)\r\n            return\r\n                \ud31d\ube4c URL\r\n            raise\r\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getStates(self, Corpnum, reciptNumList, UserID=None):\r\n        if reciptNumList == None or len(reciptNumList) < 1:\r\n            raise PopbillException(-99999999, \"\uc811\uc218\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\r\n\r\n        postData = self._stringtify(reciptNumList)\r\n\r\n        return self._httppost('/Message/States', postData, Corpnum, UserID)", "response": "\uc804\uc1a1\ub0b4\uc5ed \uc694\uc57d\uc815\ubcf4 \ud655\uc778\r\n            args\r\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\r\n                reciptNumList : \ubb38\uc790\uc804\uc1a1 \uc811\uc218\ubc88\ud638 \ubc30\uc5f4\r\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\r\n            return\r\n                \uc804\uc1a1\uc815\ubcf4 as list\r\n            raise\r\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef funcGauss1D(x, mu, sig):\n    arrOut = np.exp(-np.power((x - mu)/sig, 2.)/2)\n    # normalize\n    arrOut = arrOut/(np.sqrt(2.*np.pi)*sig)\n\n    return arrOut", "response": "Create 1D Gaussian. Source :\n    http://mathworld. wolfram. com / GaussianFunction. html\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef absolute_path(user_path):\n    if os.path.abspath(user_path):\n        return unix_path_coercion(user_path)\n    else:\n        try:\n            openaccess_epub.utils.evaluate_relative_path(relative=user_path)\n        except:\n            raise ValidationError('This path could not be rendered as absolute')", "response": "Convert user_path to absolute path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconfiguring the quickstart base control loops for user interaction during quickstart configuration.", "response": "def configure(default=None, dev=None):\n    \"\"\"\n    The inner control loops for user interaction during quickstart\n    configuration.\n    \"\"\"\n    cache_loc = openaccess_epub.utils.cache_location()\n    config_loc = openaccess_epub.utils.config_location()\n\n    #Make the cache directory\n    openaccess_epub.utils.mkdir_p(cache_loc)\n\n    defaults = {'now': time.asctime(),\n                'oae-version': openaccess_epub.__version__,\n                'cache-location': unix_path_coercion(cache_loc),\n                'input-relative-images': 'images-*',\n                'use-input-relative-images': 'y',\n                'image-cache': os.path.join(cache_loc, 'img_cache'),\n                'use-image-cache': 'n',\n                'use-image-fetching': 'y',\n                'default-output': '.',\n                'input-relative-css': '.',\n                'epubcheck-jarfile': os.path.join(cache_loc,\n                                                 'epubcheck-3.0',\n                                                 'epubcheck-3.0.jar')}\n\n    if default or dev:  # Skip interactive and apply defaults\n        #Pass through the validation/modification steps\n        if dev:  # The only current difference between dev and default\n            defaults['use-image-cache'] = 'y'\n        defaults['input-relative-images'] = list_opts(defaults['input-relative-images'])\n        defaults['use-input-relative-images'] = boolean(defaults['use-input-relative-images'])\n        defaults['image-cache'] = absolute_path(defaults['image-cache'])\n        defaults['use-image-cache'] = boolean(defaults['use-image-cache'])\n        defaults['use-image-fetching'] = boolean(defaults['use-image-fetching'])\n        defaults['default-output'] = nonempty(defaults['default-output'])\n        defaults['input-relative-css'] = nonempty(defaults['input-relative-css'])\n        defaults['epubcheck-jarfile'] = absolute_path(defaults['epubcheck-jarfile'])\n        config = config_formatter(CONFIG_TEXT, defaults)\n\n        with open(config_loc, 'wb') as conf_out:\n            conf_out.write(bytes(config, 'UTF-8'))\n        print('The config file has been written to {0}'.format(config_loc))\n        return\n\n    config_dict = {'now': time.asctime(),\n                   'oae-version': openaccess_epub.__version__,\n                   'cache-location': unix_path_coercion(cache_loc)}\n\n    print('''\\nWelcome to the interactive configuration for OpenAccess_EPUB''')\n    print('''\nPlease enter values for the following settings. To accept the default value\nfor the settings, shown in brackets, just push Enter.\n\n-------------------------------------------------------------------------------\\\n''')\n    print('''\nOpenAccess_EPUB defines a default cache location for the storage of various\ndata (and the global config.py file), this location is:\\n\\n{0}\n'''.format(cache_loc))\n\n    input('Press Enter to start...')\n\n    #Image Configuration\n    print('''\n -- Configure Image Behavior --\n\nWhen OpenAccess_EPUB is executed using the oaepub script, it can find the\nimages for the input articles using the following strategies (in order of\npreference):\n\n Input-Relative: a path relative to the input file\n Cached Images: locate the images in a cache\n Fetched Online: attempts to download from the Internet (may fail)\n\nWe'll configure some values for each of these, and you\\'ll also have the option\nto turn them off.''')\n    #Input-relative image details\n    print('''\nWhere should OpenAccess_EPUB look for images relative to the input file?\nA star \"*\" may be used as a wildcard to match the name of the input file.\nMultiple path values may be specified if separated by commas.''')\n    user_prompt(config_dict, 'input-relative-images', 'Input-relative images?:',\n                default=defaults['input-relative-images'], validator=list_opts)\n    print('''\nShould OpenAccess_EPUB look for images relative to the input file by default?\\\n''')\n    user_prompt(config_dict, 'use-input-relative-images',\n                'Use input-relative images?: (Y/n)',\n                default=defaults['use-input-relative-images'],\n                validator=boolean)\n    #Image cache details\n    print('''\nWhere should OpenAccess_EPUB place the image cache?''')\n    user_prompt(config_dict, 'image-cache', 'Image cache?:',\n                default=defaults['image-cache'],\n                validator=absolute_path)\n    print('''\nShould OpenAccess_EPUB use the image cache by default? This feature is intended\nfor developers and testers without local access to the image files and will\nconsume extra disk space for storage.''')\n    user_prompt(config_dict, 'use-image-cache', 'Use image cache?: (y/N)',\n                default=defaults['use-image-cache'],\n                validator=boolean)\n    #Image fetching online details\n    print('''\nShould OpenAccess_EPUB attempt to download the images from the Internet? This\nis not supported for all publishers and not 100% guaranteed to succeed, you may\nneed to download them manually if this does not work.''')\n    user_prompt(config_dict, 'use-image-fetching', 'Attempt image download?: (Y/n)',\n                default=defaults['use-image-fetching'],\n                validator=boolean)\n    #Output configuration\n    print('''\n -- Configure Output Behavior --\n\nOpenAccess_EPUB produces ePub and log files as output. The following options\nwill determine what is done with these.\n\nWhere should OpenAccess_EPUB place the output ePub and log files? If you supply\na relative path, the output path will be relative to the input; if you supply\nan absolute path, the output will always be placed there. The default behavior\nis to place them in the same directory as the input.''')\n    user_prompt(config_dict, 'default-output', 'Output path?:',\n                default=defaults['default-output'],\n                validator=nonempty)\n    print('''\n -- Configure CSS Behavior --\n\nePub files use CSS for improved styling, and ePub-readers must support a basic\nsubset of CSS functions. OpenAccess_EPUB provides a default CSS file, but a\nmanual one may be supplied, relative to the input. Please define an\nappropriate input-relative path.''')\n    user_prompt(config_dict, 'input-relative-css', 'Input-relative CSS path?:',\n                default=defaults['input-relative-css'],\n                validator=nonempty)\n    print('''\n -- Configure EpubCheck --\n\nEpubCheck is a program written and maintained by the IDPF as a tool to validate\nePub. In order to use it, your system must have Java installed and it is\nrecommended to use the latest version. Downloads of this program are found here:\n\nhttps://github.com/IDPF/epubcheck/releases\n\nOnce you have downloaded the zip file for the program, unzip the archive and\nwrite a path to the .jar file here.''')\n    user_prompt(config_dict, 'epubcheck-jarfile', 'Absolute path to epubcheck?:',\n                default=defaults['epubcheck-jarfile'], validator=absolute_path)\n    #Write the config.py file\n    config = config_formatter(CONFIG_TEXT, config_dict)\n    with open(config_loc, 'wb') as conf_out:\n        conf_out.write(bytes(config, 'UTF-8'))\n    print('''\nDone configuring OpenAccess_EPUB!''')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef checkMgtKeyInUse(self, CorpNum, MgtKeyType, MgtKey):\n        if MgtKeyType not in self.__MgtKeyTypes:\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638 \ud615\ud0dc\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n        if MgtKey == None or MgtKey == \"\":\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        try:\n            result = self._httpget('/Taxinvoice/' + MgtKeyType + \"/\" + MgtKey, CorpNum)\n            return result.itemKey != None and result.itemKey != \"\"\n        except PopbillException as PE:\n            if PE.code == -11000005:\n                return False\n            raise PE", "response": "Check if a MgtKey is in the list of items in the CorpNum."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister a new Taxinvoice.", "response": "def register(self, CorpNum, taxinvoice, writeSpecification=False, UserID=None):\n        \"\"\" \uc784\uc2dc\uc800\uc7a5\n            args\n                CorpNum : \ud68c\uc6d0 \uc0ac\uc5c5\uc790 \ubc88\ud638\n                taxinvoice : \ub4f1\ub85d\ud560 \uc138\uae08\uacc4\uc0b0\uc11c object. Made with Taxinvoice(...)\n                writeSpecification : \ub4f1\ub85d\uc2dc \uac70\ub798\uba85\uc138\uc11c \ub3d9\uc2dc \uc791\uc131 \uc5ec\ubd80\n                UserID : \ud31d\ube4c \ud68c\uc6d0\uc544\uc774\ub514\n            return\n                \ucc98\ub9ac\uacb0\uacfc. consist of code and message\n            raise\n                PopbillException\n        \"\"\"\n        if taxinvoice == None:\n            raise PopbillException(-99999999, \"\ub4f1\ub85d\ud560 \uc138\uae08\uacc4\uc0b0\uc11c \uc815\ubcf4\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n        if writeSpecification:\n            taxinvoice.writeSpecification = True\n\n        postData = self._stringtify(taxinvoice)\n\n        return self._httppost('/Taxinvoice', postData, CorpNum, UserID)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, CorpNum, MgtKeyType, MgtKey, taxinvoice, writeSpecification=False, UserID=None):\n        if MgtKeyType not in self.__MgtKeyTypes:\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638 \ud615\ud0dc\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n        if MgtKey == None or MgtKey == \"\":\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n        if taxinvoice == None:\n            raise PopbillException(-99999999, \"\uc218\uc815\ud560 \uc138\uae08\uacc4\uc0b0\uc11c \uc815\ubcf4\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n        if writeSpecification:\n            taxinvoice.writeSpecification = True\n\n        postData = self._stringtify(taxinvoice)\n\n        return self._httppost('/Taxinvoice/' + MgtKeyType + '/' + MgtKey, postData, CorpNum, UserID, 'PATCH')", "response": "Update a Taxinvoice in the given CorpNum."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getInfo(self, CorpNum, MgtKeyType, MgtKey):\n        if MgtKeyType not in self.__MgtKeyTypes:\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638 \ud615\ud0dc\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n        if MgtKey == None or MgtKey == \"\":\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        return self._httpget('/Taxinvoice/' + MgtKeyType + '/' + MgtKey, CorpNum)", "response": "Get information about a particular Tax item."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getDetailInfo(self, CorpNum, MgtKeyType, MgtKey):\n        if MgtKeyType not in self.__MgtKeyTypes:\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638 \ud615\ud0dc\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n        if MgtKey == None or MgtKey == \"\":\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        return self._httpget('/Taxinvoice/' + MgtKeyType + \"/\" + MgtKey + \"?Detail\", CorpNum)", "response": "Get the details of a particular Tax item."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, CorpNum, MgtKeyType, MgtKey, UserID=None):\n        if MgtKeyType not in self.__MgtKeyTypes:\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638 \ud615\ud0dc\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n        if MgtKey == None or MgtKey == \"\":\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        return self._httppost('/Taxinvoice/' + MgtKeyType + \"/\" + MgtKey, '', CorpNum, UserID, \"DELETE\")", "response": "Delete a Tax entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending an email to a tax invoice.", "response": "def send(self, CorpNum, MgtKeyType, MgtKey, Memo=None, EmailSubject=None, UserID=None):\n        \"\"\" \uc2b9\uc778\uc694\uccad\n            args\n                CorpNum : \ud68c\uc6d0 \uc0ac\uc5c5\uc790 \ubc88\ud638\n                MgtKeyType : \uad00\ub9ac\ubc88\ud638 \uc720\ud615 one of ['SELL','BUY','TRUSTEE']\n                MgtKey : \ud30c\ud2b8\ub108 \uad00\ub9ac\ubc88\ud638\n                Memo : \ucc98\ub9ac \uba54\ubaa8\n                UserID : \ud31d\ube4c \ud68c\uc6d0\uc544\uc774\ub514\n            return\n                \ucc98\ub9ac\uacb0\uacfc. consist of code and message\n            raise\n                PopbillException\n        \"\"\"\n        if MgtKeyType not in self.__MgtKeyTypes:\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638 \ud615\ud0dc\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n        if MgtKey == None or MgtKey == \"\":\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        req = {}\n\n        if Memo != None and Memo != '':\n            req[\"memo\"] = Memo\n        if EmailSubject != None and EmailSubject != '':\n            req[\"emailSubject\"] = EmailSubject\n\n        postData = self._stringtify(req)\n\n        return self._httppost('/Taxinvoice/' + MgtKeyType + \"/\" + MgtKey, postData, CorpNum, UserID, \"SEND\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cancelSend(self, CorpNum, MgtKeyType, MgtKey, Memo=None, UserID=None):\n        if MgtKeyType not in self.__MgtKeyTypes:\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638 \ud615\ud0dc\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n        if MgtKey == None or MgtKey == \"\":\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        if Memo != None and Memo != '':\n            postData = self._stringtify({\"memo\": Memo})\n        else:\n            postData = ''\n\n        return self._httppost('/Taxinvoice/' + MgtKeyType + \"/\" + MgtKey, postData, CorpNum, UserID, \"CANCELSEND\")", "response": "\uc2b9\uc778\uc694\uccad \ucde8\uc18c\n            args\n                CorpNum : \ud68c\uc6d0 \uc0ac\uc5c5\uc790 \ubc88\ud638\n                MgtKeyType : \uad00\ub9ac\ubc88\ud638 \uc720\ud615 one of ['SELL','BUY','TRUSTEE']\n                MgtKey : \ud30c\ud2b8\ub108 \uad00\ub9ac\ubc88\ud638\n                Memo : \ucc98\ub9ac \uba54\ubaa8\n                UserID : \ud31d\ube4c \ud68c\uc6d0\uc544\uc774\ub514\n            return\n                \ucc98\ub9ac\uacb0\uacfc. consist of code and message\n            raise\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nissues a new message in the specified MgtKey.", "response": "def issue(self, CorpNum, MgtKeyType, MgtKey, Memo=None, EmailSubject=None, ForceIssue=False, UserID=None):\n        \"\"\" \ubc1c\ud589\n            args\n                CorpNum : \ud68c\uc6d0 \uc0ac\uc5c5\uc790 \ubc88\ud638\n                MgtKeyType : \uad00\ub9ac\ubc88\ud638 \uc720\ud615 one of ['SELL','BUY','TRUSTEE']\n                MgtKey : \ud30c\ud2b8\ub108 \uad00\ub9ac\ubc88\ud638\n                Memo : \ucc98\ub9ac \uba54\ubaa8\n                EmailSubject : \ubc1c\ud589\uba54\uc77c \uc774\uba54\uc77c \uc81c\ubaa9\n                ForceIssue : \uc9c0\uc5f0\ubc1c\ud589 \uc138\uae08\uacc4\uc0b0\uc11c \uac15\uc81c\ubc1c\ud589 \uc5ec\ubd80.\n                UserID : \ud31d\ube4c \ud68c\uc6d0\uc544\uc774\ub514\n            return\n                \ucc98\ub9ac\uacb0\uacfc. consist of code and message\n            raise\n                PopbillException\n        \"\"\"\n        if MgtKeyType not in self.__MgtKeyTypes:\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638 \ud615\ud0dc\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n        if MgtKey == None or MgtKey == \"\":\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        req = {\"forceIssue\": ForceIssue}\n\n        if Memo != None and Memo != '':\n            req[\"memo\"] = Memo\n\n        if EmailSubject != None and EmailSubject != '':\n            req[\"emailSubject\"] = EmailSubject\n\n        postData = self._stringtify(req)\n\n        return self._httppost('/Taxinvoice/' + MgtKeyType + \"/\" + MgtKey, postData, CorpNum, UserID, \"ISSUE\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sendToNTS(self, CorpNum, MgtKeyType, MgtKey, UserID=None):\n        if MgtKeyType not in self.__MgtKeyTypes:\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638 \ud615\ud0dc\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n        if MgtKey == None or MgtKey == \"\":\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        postData = ''\n\n        return self._httppost('/Taxinvoice/' + MgtKeyType + \"/\" + MgtKey, postData, CorpNum, UserID, \"NTS\")", "response": "\uad6d\uc138\uccad \uc989\uc2dc\uc804\uc1a1\n            args\n                CorpNum : \ud68c\uc6d0 \uc0ac\uc5c5\uc790 \ubc88\ud638\n                MgtKeyType : \uad00\ub9ac\ubc88\ud638 \uc720\ud615 one of ['SELL','BUY','TRUSTEE']\n                MgtKey : \ud30c\ud2b8\ub108 \uad00\ub9ac\ubc88\ud638\n                UserID : \ud31d\ube4c \ud68c\uc6d0\uc544\uc774\ub514\n            return\n                \ucc98\ub9ac\uacb0\uacfc. consist of code and message\n            raise\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getFiles(self, CorpNum, MgtKeyType, MgtKey):\n        if MgtKeyType not in self.__MgtKeyTypes:\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638 \ud615\ud0dc\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n        if MgtKey == None or MgtKey == \"\":\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        return self._httpget('/Taxinvoice/' + MgtKeyType + \"/\" + MgtKey + \"/Files\", CorpNum)", "response": "\ucca8\ubd80\ud30c\uc77c \ubaa9\ub85d \ud655\uc778\n            args\n                CorpNum : \ud68c\uc6d0 \uc0ac\uc5c5\uc790 \ubc88\ud638\n                MgtKeyType : \uad00\ub9ac\ubc88\ud638 \uc720\ud615 one of ['SELL','BUY','TRUSTEE']\n                MgtKey : \ud30c\ud2b8\ub108 \uad00\ub9ac\ubc88\ud638\n            return\n                \ucca9\ubd80\ud30c\uc77c \uc815\ubcf4 \ubaa9\ub85d as List\n            raise\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a file from a Taxinvoice.", "response": "def deleteFile(self, CorpNum, MgtKeyType, MgtKey, FileID, UserID=None):\n        \"\"\" \ucca8\ubd80\ud30c\uc77c \uc0ad\uc81c\n            args\n                CorpNum : \ud68c\uc6d0 \uc0ac\uc5c5\uc790 \ubc88\ud638\n                MgtKeyType : \uad00\ub9ac\ubc88\ud638 \uc720\ud615 one of ['SELL','BUY','TRUSTEE']\n                MgtKey : \ud30c\ud2b8\ub108 \uad00\ub9ac\ubc88\ud638\n                UserID : \ud31d\ube4c \ud68c\uc6d0\uc544\uc774\ub514\n            return\n                \ucc98\ub9ac\uacb0\uacfc. consist of code and message\n            raise\n                PopbillException\n        \"\"\"\n        if MgtKeyType not in self.__MgtKeyTypes:\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638 \ud615\ud0dc\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n        if MgtKey == None or MgtKey == \"\":\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n        if FileID == None or FileID == \"\":\n            raise PopbillException(-99999999, \"\ud30c\uc77c\uc544\uc774\ub514\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        postData = ''\n\n        return self._httppost('/Taxinvoice/' + MgtKeyType + \"/\" + MgtKey + \"/Files/\" + FileID, postData, CorpNum,\n                              UserID, 'DELETE')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getMassPrintURL(self, CorpNum, MgtKeyType, MgtKeyList, UserID=None):\n        if MgtKeyList == None or len(MgtKeyList) < 1:\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        postData = self._stringtify(MgtKeyList)\n\n        Result = self._httppost('/Taxinvoice/' + MgtKeyType + \"?Print\", postData, CorpNum, UserID)\n\n        return Result.url", "response": "Get the URL of a particular Tax item."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search(self, CorpNum, MgtKeyType, DType, SDate, EDate, State, Type, TaxType, LateOnly, TaxRegIDYN, TaxRegIDType,\n               TaxRegID, Page, PerPage, Order, UserID=None, QString=None, InterOPYN=None, IssueType=None):\n        \"\"\" \ubaa9\ub85d \uc870\ud68c\n            args\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                MgtKeyType : \uc138\uae08\uacc4\uc0b0\uc11c\uc720\ud615, SELL-\ub9e4\ucd9c, BUY-\ub9e4\uc785, TRUSTEE-\uc704\uc218\ud0c1\n                DType : \uc77c\uc790\uc720\ud615, R-\ub4f1\ub85d\uc77c\uc2dc, W-\uc791\uc131\uc77c\uc790, I-\ubc1c\ud589\uc77c\uc2dc \uc911 \ud0dd 1\n                SDate : \uc2dc\uc791\uc77c\uc790, \ud45c\uc2dc\ud615\uc2dd(yyyyMMdd)\n                EDate : \uc885\ub8cc\uc77c\uc790, \ud45c\uc2dc\ud615\uc2dd(yyyyMMdd)\n                State : \uc0c1\ud0dc\ucf54\ub4dc, 2,3\ubc88\uc9f8 \uc790\ub9ac\uc5d0 \uc640\uc77c\ub4dc\uce74\ub4dc(*) \uc0ac\uc6a9\uac00\ub2a5\n                Type : \ubb38\uc11c\ud615\ud0dc \ubc30\uc5f4, N-\uc77c\ubc18\uc138\uae08\uacc4\uc0b0\uc11c, M-\uc218\uc815\uc138\uae08\uacc4\uc0b0\uc11c\n                TaxType : \uacfc\uc138\ud615\ud0dc \ubc30\uc5f4, T-\uacfc\uc138, N-\uba74\uc138, Z-\uc601\uc138\n                LateOnly : \uc9c0\uc5f0\ubc1c\ud589, \uacf5\ubc31-\uc804\uccb4\uc870\ud68c, 0-\uc815\uc0c1\ubc1c\ud589\uc870\ud68c, 1-\uc9c0\uc5f0\ubc1c\ud589 \uc870\ud68c\n                TaxRegIdYN : \uc885\uc0ac\uc5c5\uc7a5\ubc88\ud638 \uc720\ubb34, \uacf5\ubc31-\uc804\uccb4\uc870\ud68c, 0-\uc885\uc0ac\uc5c5\uc7a5\ubc88\ud638 \uc5c6\uc74c 1-\uc885\uc0ac\uc5c5\uc7a5\ubc88\ud638 \uc788\uc74c\n                TaxRegIDType : \uc885\uc0ac\uc5c5\uc7a5\ubc88\ud638 \uc0ac\uc5c5\uc790\uc720\ud615, S-\uacf5\uae09\uc790, B-\uacf5\uae09\ubc1b\ub294\uc790, T-\uc218\ud0c1\uc790\n                TaxRegID : \uc885\uc0ac\uc5c5\uc7a5\ubc88\ud638, \ucf64\ub9c8(,)\ub85c \uad6c\ubd84\ud558\uc5ec \uad6c\uc131 ex)'0001,1234'\n                Page : \ud398\uc774\uc9c0\ubc88\ud638\n                PerPage : \ud398\uc774\uc9c0\ub2f9 \ubaa9\ub85d\uac1c\uc218\n                Order : \uc815\ub82c\ubc29\ud5a5, D-\ub0b4\ub9bc\ucc28\uc21c, A-\uc624\ub984\ucc28\uc21c\n                UserID : \ud31d\ube4c \ud68c\uc6d0\uc544\uc774\ub514\n                QString : \uac70\ub798\ucc98 \uc815\ubcf4, \uac70\ub798\ucc98 \uc0c1\ud638 \ub610\ub294 \uc0ac\uc5c5\uc790\ub4f1\ub85d\ubc88\ud638 \uae30\uc7ac, \ubbf8\uae30\uc7ac\uc2dc \uc804\uccb4\uc870\ud68c\n                InterOPYN : \uc5f0\ub3d9\ubb38\uc11c \uc5ec\ubd80, \uacf5\ubc31-\uc804\uccb4\uc870\ud68c, 0-\uc77c\ubc18\ubb38\uc11c \uc870\ud68c, 1-\uc5f0\ub3d9\ubb38\uc11c \uc870\ud68c\n                IssueType : \ubc1c\ud589\ud615\ud0dc \ubc30\uc5f4, N-\uc815\ubc1c\ud589, R-\uc5ed\ubc1c\ud589, T-\uc704\uc218\ud0c1\n            return\n                \uc870\ud68c\ubaa9\ub85d Object\n            raise\n                PopbillException\n        \"\"\"\n\n        if MgtKeyType not in self.__MgtKeyTypes:\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638 \ud615\ud0dc\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n\n        if DType == None or DType == '':\n            raise PopbillException(-99999999, \"\uc77c\uc790\uc720\ud615\uc774 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        if SDate == None or SDate == '':\n            raise PopbillException(-99999999, \"\uc2dc\uc791\uc77c\uc790\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        if EDate == None or EDate == '':\n            raise PopbillException(-99999999, \"\uc885\ub8cc\uc77c\uc790\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        uri = '/Taxinvoice/' + MgtKeyType\n        uri += '?DType=' + DType\n        uri += '&SDate=' + SDate\n        uri += '&EDate=' + EDate\n        uri += '&State=' + ','.join(State)\n        uri += '&Type=' + ','.join(Type)\n        uri += '&TaxType=' + ','.join(TaxType)\n        uri += '&TaxRegIDType=' + TaxRegIDType\n        uri += '&TaxRegID=' + TaxRegID\n        uri += '&Page=' + str(Page)\n        uri += '&PerPage=' + str(PerPage)\n        uri += '&Order=' + Order\n        uri += '&InterOPYN=' + InterOPYN\n\n        if LateOnly != '':\n            uri += '&LateOnly=' + LateOnly\n        if TaxRegIDYN != '':\n            uri += '&TaxRegIDType=' + TaxRegIDType\n\n        if QString is not None:\n            uri += '&QString=' + QString\n\n        if IssueType is not None:\n            uri += '&IssueType=' + ','.join(IssueType)\n\n        return self._httpget(uri, CorpNum, UserID)", "response": "\ubaa9\ub85d \uc870\ud68c\n            args\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                MgtKeyType : \uc138\uae08\uacc4\uc0b0\uc11c\uc720\ud615, SELL-\ub9e4\ucd9c, BUY-\ub9e4\uc785, TRUSTEE-\uc704\uc218\ud0c1\n                DType : \uc77c\uc790\uc720\ud615, R-\ub4f1\ub85d\uc77c\uc2dc, W-\uc791\uc131\uc77c\uc790, I-\ubc1c\ud589\uc77c\uc2dc \uc911 \ud0dd 1\n                SDate : \uc2dc\uc791\uc77c\uc790, \ud45c\uc2dc\ud615\uc2dd(yyyyMMdd)\n                EDate : \uc885\ub8cc\uc77c\uc790, \ud45c\uc2dc\ud615\uc2dd(yyyyMMdd)\n                State : \uc0c1\ud0dc\ucf54\ub4dc, 2,3\ubc88\uc9f8 \uc790\ub9ac\uc5d0 \uc640\uc77c\ub4dc\uce74\ub4dc(*) \uc0ac\uc6a9\uac00\ub2a5\n                Type : \ubb38\uc11c\ud615\ud0dc \ubc30\uc5f4, N-\uc77c\ubc18\uc138\uae08\uacc4\uc0b0\uc11c, M-\uc218\uc815\uc138\uae08\uacc4\uc0b0\uc11c\n                TaxType : \uacfc\uc138\ud615\ud0dc \ubc30\uc5f4, T-\uacfc\uc138, N-\uba74\uc138, Z-\uc601\uc138\n                LateOnly : \uc9c0\uc5f0\ubc1c\ud589, \uacf5\ubc31-\uc804\uccb4\uc870\ud68c, 0-\uc815\uc0c1\ubc1c\ud589\uc870\ud68c, 1-\uc9c0\uc5f0\ubc1c\ud589 \uc870\ud68c\n                TaxRegIdYN : \uc885\uc0ac\uc5c5\uc7a5\ubc88\ud638 \uc720\ubb34, \uacf5\ubc31-\uc804\uccb4\uc870\ud68c, 0-\uc885\uc0ac\uc5c5\uc7a5\ubc88\ud638 \uc5c6\uc74c 1-\uc885\uc0ac\uc5c5\uc7a5\ubc88\ud638 \uc788\uc74c\n                TaxRegIDType : \uc885\uc0ac\uc5c5\uc7a5\ubc88\ud638 \uc0ac\uc5c5\uc790\uc720\ud615, S-\uacf5\uae09\uc790, B-\uacf5\uae09\ubc1b\ub294\uc790, T-\uc218\ud0c1\uc790\n                TaxRegID : \uc885\uc0ac\uc5c5\uc7a5\ubc88\ud638, \ucf64\ub9c8(,)\ub85c \uad6c\ubd84\ud558\uc5ec \uad6c\uc131 ex)'0001,1234'\n                Page : \ud398\uc774\uc9c0\ubc88\ud638\n                PerPage : \ud398\uc774\uc9c0\ub2f9 \ubaa9\ub85d\uac1c\uc218\n                Order : \uc815\ub82c\ubc29\ud5a5, D-\ub0b4\ub9bc\ucc28\uc21c, A-\uc624\ub984\ucc28\uc21c\n                UserID : \ud31d\ube4c \ud68c\uc6d0\uc544\uc774\ub514\n                QString : \uac70\ub798\ucc98 \uc815\ubcf4, \uac70\ub798\ucc98 \uc0c1\ud638 \ub610\ub294 \uc0ac\uc5c5\uc790\ub4f1\ub85d\ubc88\ud638 \uae30\uc7ac, \ubbf8\uae30\uc7ac\uc2dc \uc804\uccb4\uc870\ud68c\n                InterOPYN : \uc5f0\ub3d9\ubb38\uc11c \uc5ec\ubd80, \uacf5\ubc31-\uc804\uccb4\uc870\ud68c, 0-\uc77c\ubc18\ubb38\uc11c \uc870\ud68c, 1-\uc5f0\ub3d9\ubb38\uc11c \uc870\ud68c\n                IssueType : \ubc1c\ud589\ud615\ud0dc \ubc30\uc5f4, N-\uc815\ubc1c\ud589, R-\uc5ed\ubc1c\ud589, T-\uc704\uc218\ud0c1\n            return\n                \uc870\ud68c\ubaa9\ub85d Object\n            raise\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nattaching a statement to a CorpNum.", "response": "def attachStatement(self, CorpNum, MgtKeyType, MgtKey, ItemCode, StmtMgtKey, UserID=None):\n        \"\"\" \uc804\uc790\uba85\uc138\uc11c \ucca8\ubd80\n            args\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                MgtKeyType : \uc138\uae08\uacc4\uc0b0\uc11c \uc720\ud615, SELL-\ub9e4\ucd9c, BUY-\ub9e4\uc785, TRUSTEE-\uc704\uc218\ud0c1\n                MgtKey : \uc138\uae08\uacc4\uc0b0\uc11c \ubb38\uc11c\uad00\ub9ac\ubc88\ud638\n                StmtCode : \uba85\uc138\uc11c \uc885\ub958\ucf54\ub4dc, 121-\uba85\uc138\uc11c, 122-\uccad\uad6c\uc11c, 123-\uacac\uc801\uc11c, 124-\ubc1c\uc8fc\uc11c 125-\uc785\uae08\ud45c, 126-\uc601\uc218\uc99d\n                StmtMgtKey : \uc804\uc790\uba85\uc138\uc11c \ubb38\uc11c\uad00\ub9ac\ubc88\ud638\n                UserID : \ud31d\ube4c\ud68c\uc6d0 \uc544\uc774\ub514\n            return\n                \ucc98\ub9ac\uacb0\uacfc. consist of code and message\n            raise\n                PopbillException\n        \"\"\"\n\n        if MgtKeyType not in self.__MgtKeyTypes:\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638 \ud615\ud0dc\uac00 \uc62c\ubc14\ub974\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n        if MgtKey == None or MgtKey == \"\":\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        uri = '/Taxinvoice/' + MgtKeyType + '/' + MgtKey + '/AttachStmt'\n\n        postData = self._stringtify({\"ItemCode\": ItemCode, \"MgtKey\": StmtMgtKey})\n\n        return self._httppost(uri, postData, CorpNum, UserID)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assignMgtKey(self, CorpNum, MgtKeyType, ItemKey, MgtKey, UserID=None):\n        if MgtKeyType == None or MgtKeyType == '':\n            raise PopbillException(-99999999, \"\uc138\uae08\uacc4\uc0b0\uc11c \ubc1c\ud589\uc720\ud615\uc774 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        if ItemKey == None or ItemKey == '':\n            raise PopbillException(-99999999, \"\uc544\uc774\ud15c\ud0a4\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        if MgtKey == None or MgtKey == '':\n            raise PopbillException(-99999999, \"\uad00\ub9ac\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        postDate = \"MgtKey=\" + MgtKey\n        return self._httppost('/Taxinvoice/' + ItemKey + '/' + MgtKeyType, postDate, CorpNum, UserID, \"\",\n                              \"application/x-www-form-urlencoded; charset=utf-8\")", "response": "Assign a new MgtKey to a CorpNum."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getSealURL(self, CorpNum, UserID):\n        result = self._httpget('/?TG=SEAL', CorpNum, UserID)\n        return result.url", "response": "Get the URL of the Seal."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting Tax Cert URL.", "response": "def getTaxCertURL(self, CorpNum, UserID):\n        \"\"\" \uacf5\uc778\uc778\uc99d\uc11c \ub4f1\ub85d URL\n            args\n                CorpNum : \ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                UserID  : \ud68c\uc6d0 \ud31d\ube4c\uc544\uc774\ub514\n            return\n                30\ucd08 \ubcf4\uc548 \ud1a0\ud070\uc744 \ud3ec\ud568\ud55c url\n            raise\n                PopbillException\n        \"\"\"\n        result = self._httpget('/?TG=CERT', CorpNum, UserID)\n        return result.url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encloses(self,\n                 location: FileLocation\n                 ) -> Optional[FunctionDesc]:\n        \"\"\"\n        Returns the function, if any, that encloses a given location.\n        \"\"\"\n        for func in self.in_file(location.filename):\n            if location in func.location:\n                return func\n        return None", "response": "Returns the function that encloses a given location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an iterator over all functions that are contained within a given file.", "response": "def in_file(self, filename: str) -> Iterator[FunctionDesc]:\n        \"\"\"\n        Returns an iterator over all of the functions definitions that are\n        contained within a given file.\n        \"\"\"\n        yield from self.__filename_to_functions.get(filename, [])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating or load pRF model time courses.", "response": "def model_creation_opt(dicCnfg, aryMdlParams, strPathHrf=None, varRat=None,\n                       lgcPrint=True):\n    \"\"\"\n    Create or load pRF model time courses.\n\n    Parameters\n    ----------\n    dicCnfg : dict\n        Dictionary containing config parameters.\n    aryMdlParams : numpy arrays\n        x, y and sigma parameters.\n    strPathHrf : str or None:\n        Path to npy file with custom hrf parameters. If None, default\n        parameters will be used.\n    varRat : float, default None\n        Ratio of size suppressive surround to size of center pRF\n    lgcPrint : boolean\n        Whether print statements should be executed.\n\n    Returns\n    -------\n    aryPrfTc : np.array\n        4D numpy array with pRF time course models, with following dimensions:\n        `aryPrfTc[x-position, y-position, SD, volume]`.\n    \"\"\"\n    # *************************************************************************\n    # *** Load parameters from config file\n\n    # Load config parameters from dictionary into namespace:\n    cfg = cls_set_config(dicCnfg)\n    # *************************************************************************\n\n    if cfg.lgcCrteMdl:\n\n        # *********************************************************************\n        # *** Load spatial condition information\n\n        arySptExpInf = np.load(cfg.strSptExpInf)\n\n        # Here we assume scientific convention and orientation of images where\n        # the origin should fall in the lower left corner, the x-axis occupies\n        # the width and the y-axis occupies the height dimension of the screen.\n        # We also assume that the first dimension that the user provides\n        # indexes x and the second indexes the y-axis. Since python is column\n        # major (i.e. first indexes columns, only then rows), we need to rotate\n        # arySptExpInf by 90 degrees rightward. This will insure that with the\n        # 0th axis we index the scientific x-axis and higher values move us to\n        # the right on that x-axis. It will also ensure that the 1st\n        # python axis indexes the scientific y-axis and higher values will\n        # move us up.\n        arySptExpInf = np.rot90(arySptExpInf, k=3)\n\n        # *********************************************************************\n\n        # *********************************************************************\n        # *** Load temporal condition information\n\n        # load temporal information about presented stimuli\n        aryTmpExpInf = np.load(cfg.strTmpExpInf)\n        # add fourth column to make it appropriate for pyprf_feature\n        if aryTmpExpInf.shape[-1] == 3:\n            vecNewCol = np.greater(aryTmpExpInf[:, 0], 0).astype(np.float16)\n            aryTmpExpInf = np.concatenate(\n                (aryTmpExpInf, np.expand_dims(vecNewCol, axis=1)), axis=1)\n\n        # *********************************************************************\n\n        # *********************************************************************\n\n        # If desired by user, also create model parameters for supp surround\n        if varRat is not None:\n            aryMdlParamsSur = np.copy(aryMdlParams)\n            aryMdlParamsSur[:, 2] = aryMdlParamsSur[:, 2] * varRat\n\n        # *********************************************************************\n\n        # *********************************************************************\n        # *** Create 2D Gauss model responses to spatial conditions.\n\n        aryMdlRsp = crt_mdl_rsp(arySptExpInf, (int(cfg.varVslSpcSzeX),\n                                               int(cfg.varVslSpcSzeY)),\n                                aryMdlParams, cfg.varPar, lgcPrint=lgcPrint)\n                \n        # If desired by user, also create model responses for supp surround\n        if varRat is not None:\n            aryMdlRspSur = crt_mdl_rsp(arySptExpInf, (int(cfg.varVslSpcSzeX),\n                                                      int(cfg.varVslSpcSzeY)),\n                                       aryMdlParamsSur, cfg.varPar,\n                                       lgcPrint=lgcPrint)\n\n        del(arySptExpInf)\n\n        # *********************************************************************\n\n        # *********************************************************************\n        # *** Create prf time course models\n\n        # Check whether path to npy file with hrf parameters was provided\n        if strPathHrf is not None:\n            if lgcPrint:\n                print('---------Load custom hrf parameters')\n            aryCstPrm = np.load(strPathHrf)\n            dctPrm = {}\n            dctPrm['peak_delay'] = aryCstPrm[0]\n            dctPrm['under_delay'] = aryCstPrm[1]\n            dctPrm['peak_disp'] = aryCstPrm[2]\n            dctPrm['under_disp'] = aryCstPrm[3]\n            dctPrm['p_u_ratio'] = aryCstPrm[4]\n        # If not, set dctPrm to None, which will result in default hrf params\n        else:\n            if lgcPrint:\n                print('---------Use default hrf parameters')\n            dctPrm = None\n\n        aryPrfTc = crt_prf_ftr_tc(aryMdlRsp, aryTmpExpInf, cfg.varNumVol,\n                                  cfg.varTr, cfg.varTmpOvsmpl,\n                                  cfg.switchHrfSet, (int(cfg.varVslSpcSzeX),\n                                                     int(cfg.varVslSpcSzeY)),\n                                  cfg.varPar, dctPrm=dctPrm, lgcPrint=lgcPrint)\n\n        # If desired by user, create prf time course models for supp surround\n        if varRat is not None:\n            if lgcPrint:\n                print('---------Add suppressive surround')\n            aryPrfTcSur = crt_prf_ftr_tc(aryMdlRspSur, aryTmpExpInf,\n                                         cfg.varNumVol, cfg.varTr,\n                                         cfg.varTmpOvsmpl, cfg.switchHrfSet,\n                                         (int(cfg.varVslSpcSzeX),\n                                          int(cfg.varVslSpcSzeY)),\n                                         cfg.varPar, dctPrm=dctPrm,\n                                         lgcPrint=lgcPrint)\n            # Concatenate aryPrfTc and aryPrfTcSur\n            aryPrfTc = np.concatenate((aryPrfTc, aryPrfTcSur), axis=1)\n\n        # *********************************************************************\n\n    return aryPrfTc"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_entry(journal_location, date):\n    if not isinstance(date, datetime.date):\n        return None\n    try:\n        with open(build_journal_path(journal_location, date), \"r\") as entry_file:\n            return entry_file.read()\n    except IOError:\n        return None", "response": "returns the entry text of the specified date"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nnormalizes SPM HRF function from sum of two gamma PDFs Parameters ---------- t : array-like vector of times at which to sample HRF Returns ------- hrf : array vector length ``len(t)`` of samples from HRF at times `t` Notes ----- [1] This is the canonical HRF function as used in SPM. It has the following defaults: - delay of response (relative to onset) : 6s - delay of undershoot (relative to onset) : 16s - dispersion of response : 1s - dispersion of undershoot : 1s - ratio of response to undershoot : 6s - onset : 0s - length of kernel : 32s References: ----- [1] http://nipy.org/ [2] https://github.com/fabianp/hrf_estimation", "response": "def spmt(t, peak_delay=6, under_delay=16, peak_disp=1, under_disp=1,\n         p_u_ratio=6):\n    \"\"\"Normalized SPM HRF function from sum of two gamma PDFs\n\n    Parameters\n    ----------\n    t : array-like\n        vector of times at which to sample HRF\n\n    Returns\n    -------\n    hrf : array\n        vector length ``len(t)`` of samples from HRF at times `t`\n\n    Notes\n    -----\n    [1] This is the canonical HRF function as used in SPM. It\n    has the following defaults:\n        - delay of response (relative to onset) : 6s\n        - delay of undershoot (relative to onset) : 16s\n        - dispersion of response : 1s\n        - dispersion of undershoot : 1s\n        - ratio of response to undershoot : 6s\n        - onset : 0s\n        - length of kernel : 32s\n\n    References:\n    -----\n    [1] http://nipy.org/\n    [2] https://github.com/fabianp/hrf_estimation\n    \"\"\"\n    return spm_hrf_compat(t, peak_delay=peak_delay, under_delay=under_delay,\n                          peak_disp=peak_disp, under_disp=under_disp,\n                          p_u_ratio=p_u_ratio, normalize=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the canonical HRF dispersion derivative function for the given time values t.", "response": "def ddspmt(t, peak_delay=6, under_delay=16, peak_disp=1, under_disp=1,\n           p_u_ratio=6):\n    \"\"\" SPM canonical HRF dispersion derivative, values for time values `t`\n\n    Parameters\n    ----------\n    t : array-like\n        vector of times at which to sample HRF\n\n    Returns\n    -------\n    hrf : array\n        vector length ``len(t)`` of samples from HRF at times `t`\n\n    Notes\n    -----\n    [1] This is the canonical HRF dispersion derivative function as used in SPM\n    [2] It is the numerical difference between the HRF sampled at time `t`, and\n    values at `t` for another HRF shape with a small change in the peak\n    dispersion parameter (``peak_disp`` in func:`spm_hrf_compat`).\n\n    References:\n    -----\n    [1] http://nipy.org/\n    [2] https://github.com/fabianp/hrf_estimation\n    \"\"\"\n\n    _spm_dd_func = partial(spmt, peak_delay=peak_delay,\n                           under_delay=under_delay,\n                           under_disp=under_disp, p_u_ratio=p_u_ratio,\n                           peak_disp=1.01)\n\n    return (spmt(t) - _spm_dd_func(t)) / 0.01"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_boxcar(aryCnd, aryOns, aryDrt, varTr, varNumVol,\n                  aryExclCnd=None, varTmpOvsmpl=1000.):\n    \"\"\"\n    Creation of condition time courses in temporally upsampled space.\n\n    Parameters\n    ----------\n\n    aryCnd : np.array\n        1D array with condition identifiers (every condition has its own int)\n    aryOns : np.array, same len as aryCnd\n        1D array with condition onset times in seconds.\n    aryDrt : np.array, same len as aryCnd\n        1D array with condition durations of different conditions in seconds.\n    varTr : float, positive\n        Time to repeat (TR) of the (fMRI) experiment.\n    varNumVol : float, positive\n        Number of volumes of the (fMRI) data.\n    aryExclCnd : array\n        1D array containing condition identifiers for conditions to be excluded\n    varTmpOvsmpl : float, positive\n        Factor by which the time courses should be temporally upsampled.\n\n    Returns\n    -------\n    aryBxCrOut : np.array, float16\n        Condition time courses in temporally upsampled space.\n\n    References:\n    -----\n    [1] https://github.com/fabianp/hrf_estimation\n\n    \"\"\"\n    if aryExclCnd is not None:\n        for cond in aryExclCnd:\n            aryOns = aryOns[aryCnd != cond]\n            aryDrt = aryDrt[aryCnd != cond]\n            aryCnd = aryCnd[aryCnd != cond]\n\n    resolution = varTr / float(varTmpOvsmpl)\n    aryCnd = np.asarray(aryCnd)\n    aryOns = np.asarray(aryOns, dtype=np.float)\n    unique_conditions = np.sort(np.unique(aryCnd))\n    boxcar = []\n\n    for c in unique_conditions:\n        tmp = np.zeros(int(varNumVol * varTr/resolution))\n        onset_c = aryOns[aryCnd == c]\n        duration_c = aryDrt[aryCnd == c]\n        onset_idx = np.round(onset_c / resolution).astype(np.int)\n        duration_idx = np.round(duration_c / resolution).astype(np.int)\n        aux = np.arange(int(varNumVol * varTr/resolution))\n        for start, dur in zip(onset_idx, duration_idx):\n            lgc = np.logical_and(aux >= start, aux < start + dur)\n            tmp = tmp + lgc\n        assert np.all(np.less(tmp, 2))\n        boxcar.append(tmp)\n    aryBxCrOut = np.array(boxcar).T\n    if aryBxCrOut.shape[1] == 1:\n        aryBxCrOut = np.squeeze(aryBxCrOut)\n    return aryBxCrOut.astype('float16')", "response": "Create a boxcar for the given set of conditions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cnvl_tc(idxPrc, aryPrfTcChunk, lstHrf, varTr, varNumVol, varTmpOvsmpl,\n            queOut, varHrfLen=32., dctPrm=None):\n    \"\"\"Convolution of time courses with HRF model.\n\n    Parameters\n    ----------\n    idxPrc : int, positive\n        Process ID of the process calling this function (for CPU\n        multi-threading). In GPU version, this parameter is 0 (just one thread\n        on CPU).\n    aryPrfTcChunk : np.array\n        2D array with model time course to be convolved with HRF.\n    lstHrf : list\n        List containing the different HRF functions.\n    varTr : float, positive\n        Time to repeat (TR) of the (fMRI) experiment.\n    varNumVol : float, positive\n        Number of volumes of the (fMRI) data.\n    varTmpOvsmpl : float, positive\n        Factor by which the time courses should be temporally upsampled.\n    queOut : multiprocessing.queues.Queue\n        Queue to put the results on.\n    varHrfLen : float, positive, default=32\n        Length of the HRF time course in seconds.\n    dctPrm : dictionary, default None\n        Dictionary with customized hrf parameters. If this is None, default\n        hrf parameters will be used.\n\n    Returns\n    -------\n    lstOut : list\n        int, positive : Process ID of the process calling this function.\n        2D np.array, float16 : Model time course convolved with HRF.\n\n    References:\n    -----\n    [1] https://github.com/fabianp/hrf_estimation\n\n    \"\"\"\n\n    # Adjust the input, if necessary, such that input is 2D, with last dim time\n    tplInpShp = aryPrfTcChunk.shape\n    aryPrfTcChunk = aryPrfTcChunk.reshape((-1, aryPrfTcChunk.shape[-1]))\n\n    # Prepare list to collect hrf basis functions\n    lstBse = []\n    # Prepare array that contains time intervals\n    aryTme = np.linspace(0, varHrfLen, (varHrfLen // varTr) * varTmpOvsmpl)\n    for fnHrf in lstHrf:\n        # If hrf parameter dictionary is None, run with default parameters\n        if dctPrm is None:\n            vecTmpBse = fnHrf(aryTme)\n        # Otherwise, run with custom parameters\n        else:\n            vecTmpBse = fnHrf(aryTme, **dctPrm)\n        # Normalise HRF so that the sum of values is 1 (see FSL)\n        # otherwise, after convolution values for predictors are very high\n        vecTmpBse = np.divide(vecTmpBse, np.sum(vecTmpBse))\n\n        lstBse.append(vecTmpBse)\n\n    # Get frame times, i.e. start point of every volume in seconds\n    vecFrms = np.arange(0, varTr * varNumVol, varTr)\n    # Get supersampled frames times, i.e. start point of every volume in\n    # upsampled res, since convolution takes place in temp. upsampled space\n    vecFrmTms = np.arange(0, varTr * varNumVol, varTr / varTmpOvsmpl)\n\n    # Prepare an empty array for ouput\n    aryConv = np.zeros((aryPrfTcChunk.shape[0], len(lstHrf), varNumVol),\n                       dtype=np.float16)\n    # Each time course is convolved with the HRF separately, because the\n    # numpy convolution function can only be used on one-dimensional data.\n    # Thus, we have to loop through time courses:\n    for idxTc in range(0, aryConv.shape[0]):\n\n        # Extract the current time course (already in upsampled space):\n        vecTcUps = aryPrfTcChunk[idxTc, :]\n\n        # *** convolve\n        for indBase, base in enumerate(lstBse):\n            # Make sure base and vecTcUps are float64 to avoid overflow\n            base = base.astype(np.float64)\n            vecTcUps = vecTcUps.astype(np.float64)\n            # Perform the convolution (previously: np.convolve)\n            col = fftconvolve(base, vecTcUps, mode='full')[:vecTcUps.size]\n            # Get function for downsampling\n            f = interp1d(vecFrmTms, col)\n            # Downsample to original resoltuion to match res of data\n            # take the value from the centre of each volume's period (see FSL)\n            aryConv[idxTc, indBase, :] = f(vecFrms + varTr/2.\n                                           ).astype(np.float16)\n\n    # Determine output shape\n    tplOutShp = tplInpShp[:-1] + (len(lstHrf), ) + (varNumVol, )\n\n    if queOut is None:\n        # if user is not using multiprocessing, return the array directly\n        return aryConv.reshape(tplOutShp)\n\n    else:\n        # Create list containing the convolved timecourses, and the process ID:\n        lstOut = [idxPrc,\n                  aryConv.reshape(tplOutShp)]\n\n        # Put output to queue:\n        queOut.put(lstOut)", "response": "Convolution of time courses with HRF model."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_inputs_to_reference(job_data, input_files, input_directories):\n\n    return {**deepcopy(job_data), **deepcopy(input_files), **deepcopy(input_directories)}", "response": "Creates a dictionary with the summarized information in job_data input_files and input_directories."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nuse str.partition() to split every occurrence of sep in s. The returned list does not contain empty strings. :param s: The string to split. :param sep: A separator string. :return: A list of parts split by sep", "response": "def _partition_all_internal(s, sep):\n    \"\"\"\n    Uses str.partition() to split every occurrence of sep in s. The returned list does not contain empty strings.\n\n    :param s: The string to split.\n    :param sep: A separator string.\n    :return: A list of parts split by sep\n    \"\"\"\n    parts = list(s.partition(sep))\n\n    # if sep found\n    if parts[1] == sep:\n        new_parts = partition_all(parts[2], sep)\n        parts.pop()\n        parts.extend(new_parts)\n        return [p for p in parts if p]\n    else:\n        if parts[0]:\n            return [parts[0]]\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse str. partition to split every occurrence of sep in s.", "response": "def partition_all(s, sep):\n    \"\"\"\n    Uses str.partition() to split every occurrence of sep in s. The returned list does not contain empty strings.\n    If sep is a list, all separators are evaluated.\n\n    :param s: The string to split.\n    :param sep: A separator string or a list of separator strings.\n    :return: A list of parts split by sep\n    \"\"\"\n    if isinstance(sep, list):\n        parts = _partition_all_internal(s, sep[0])\n        sep = sep[1:]\n\n        for s in sep:\n            tmp = []\n            for p in parts:\n                tmp.extend(_partition_all_internal(p, s))\n            parts = tmp\n\n        return parts\n    else:\n        return _partition_all_internal(s, sep)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsplit a string into normal strings and unresolved input references.", "response": "def split_input_references(to_split):\n    \"\"\"\n    Returns the given string in normal strings and unresolved input references.\n    An input reference is identified as something of the following form $(...).\n\n    Example:\n    split_input_reference(\"a$(b)cde()$(fg)\") == [\"a\", \"$(b)\", \"cde()\", \"$(fg)\"]\n\n    :param to_split: The string to split\n    :raise InvalidInputReference: If an input reference is not closed and a new reference starts or the string ends.\n    :return: A list of normal strings and unresolved input references.\n    \"\"\"\n    parts = partition_all(to_split, [INPUT_REFERENCE_START, INPUT_REFERENCE_END])\n\n    result = []\n    part = []\n    in_reference = False\n    for p in parts:\n        if in_reference:\n            if p == INPUT_REFERENCE_START:\n                raise InvalidInputReference('A new input reference has been started, although the old input reference'\n                                            'has not yet been completed.\\n{}'.format(to_split))\n            elif p == \")\":\n                part.append(\")\")\n                result.append(''.join(part))\n                part = []\n                in_reference = False\n            else:\n                part.append(p)\n        else:\n            if p == INPUT_REFERENCE_START:\n                if part:\n                    result.append(''.join(part))\n                part = [INPUT_REFERENCE_START]\n                in_reference = True\n            else:\n                part.append(p)\n\n    if in_reference:\n        raise InvalidInputReference('Input reference not closed.\\n{}'.format(to_split))\n    elif part:\n        result.append(''.join(part))\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsplit a given string at a given separator or list of separators.", "response": "def split_all(reference, sep):\n    \"\"\"\n    Splits a given string at a given separator or list of separators.\n\n    :param reference: The reference to split.\n    :param sep: Separator string or list of separator strings.\n    :return: A list of split strings\n    \"\"\"\n    parts = partition_all(reference, sep)\n    return [p for p in parts if p not in sep]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresolves the file attributes in demand of the input file.", "response": "def _resolve_file(attributes, input_file, input_identifier, input_reference):\n    \"\"\"\n    Returns the attributes in demand of the input file.\n\n    :param attributes: A list of attributes to get from the input_file.\n    :param input_file: The file from which to get the attributes.\n    :param input_identifier: The input identifier of the given file.\n    :param input_reference: The reference string\n    :return: The attribute in demand\n    \"\"\"\n    if input_file['isArray']:\n        raise InvalidInputReference('Input References to Arrays of input files are currently not supported.\\n'\n                                    '\"{}\" is an array of files and can not be resolved for input references:'\n                                    '\\n{}'.format(input_identifier, input_reference))\n    single_file = input_file['files'][0]\n\n    try:\n        return _get_dict_element(single_file, attributes)\n    except KeyError:\n        raise InvalidInputReference('Could not get attributes \"{}\" from input file \"{}\", needed in input reference:'\n                                    '\\n{}'.format(attributes, input_identifier, input_reference))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _resolve_directory(attributes, input_directory, input_identifier, input_reference):\n    if input_directory['isArray']:\n        raise InvalidInputReference('Input References to Arrays of input directories are currently not supported.\\n'\n                                    'input directory \"{}\" is an array of directories and can not be resolved for input'\n                                    'references:\\n{}'.format(input_identifier, input_reference))\n    single_directory = input_directory['directories'][0]\n\n    try:\n        return _get_dict_element(single_directory, attributes)\n    except KeyError:\n        raise InvalidInputReference('Could not get attributes \"{}\" from input directory \"{}\", needed in input'\n                                    'reference:\\n{}'.format(attributes, input_identifier, input_reference))", "response": "Resolves the attributes in demand of the input directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resolve_input_reference(reference, inputs_to_reference):\n    if not reference.startswith('{}inputs.'.format(INPUT_REFERENCE_START)):\n        raise InvalidInputReference('An input reference must have the following form'\n                                    '\"$(inputs.<input_name>[.<attribute>]\".\\n'\n                                    'The invalid reference is: \"{}\"'.format(reference))\n    # remove \"$(inputs.\" and \")\"\n    reference = reference[2:-1]\n    parts = split_all(reference, ATTRIBUTE_SEPARATOR_SYMBOLS)\n\n    if len(parts) < 2:\n        raise InvalidInputReference('InputReference should at least contain \"$(inputs.identifier)\". The following input'\n                                    'reference does not comply with it:\\n{}'.format(reference))\n    elif parts[0] != \"inputs\":\n        raise InvalidInputReference('InputReference should at least contain \"$(inputs.identifier)\". The following input'\n                                    ' reference does not comply with it:\\n$({})'.format(reference))\n    else:\n        input_identifier = parts[1]\n        input_to_reference = inputs_to_reference.get(input_identifier)\n        if input_to_reference is None:\n            raise InvalidInputReference('Input identifier \"{}\" not found in inputs, but needed in input reference:\\n{}'\n                                        .format(input_identifier, reference))\n        elif isinstance(input_to_reference, dict):\n            if 'files' in input_to_reference:\n                return _resolve_file(parts[2:], input_to_reference, input_identifier, reference)\n            elif 'directories' in input_to_reference:\n                return _resolve_directory(parts[2:], input_to_reference, input_identifier, reference)\n            else:\n                raise InvalidInputReference('Unknown input type for input identifier \"{}\"'.format(input_identifier))\n        else:\n            if len(parts) > 2:\n                raise InvalidInputReference('Attribute \"{}\" of input reference \"{}\" could not be resolved'\n                                            .format(parts[2], reference))\n            else:\n                return parts[1]", "response": "Resolves a given input reference by a string extracted from inputs_to_reference."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nresolve input references given in the string to_resolve by using inputs_to_reference.", "response": "def resolve_input_references(to_resolve, inputs_to_reference):\n    \"\"\"\n    Resolves input references given in the string to_resolve by using the inputs_to_reference.\n\n    See http://www.commonwl.org/user_guide/06-params/index.html for more information.\n\n    Example:\n    \"$(inputs.my_file.nameroot).md\" -> \"filename.md\"\n\n    :param to_resolve: The path to match\n    :param inputs_to_reference: Inputs which are used to resolve input references like $(inputs.my_input_file.basename).\n\n    :return: A string in which the input references are replaced with actual values.\n    \"\"\"\n\n    splitted = split_input_references(to_resolve)\n\n    result = []\n\n    for part in splitted:\n        if is_input_reference(part):\n            result.append(str(resolve_input_reference(part, inputs_to_reference)))\n        else:\n            result.append(part)\n\n    return ''.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef data(self):\n        res = {'error_list': self.error_list}\n        res.update(super(ValidationErrors, self).data)\n        return res", "response": "Returns a dictionnary containing all the passed data and an item\n        which holds the result of validation errors."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the circular difference between two arrays", "response": "def circDiff(length, ary1, ary2):\n    \"\"\"calculate the circular difference between two paired arrays.\n    This function will return the difference between pairs of numbers; however\n    the difference that is output will be minimal in the sense that if we\n    assume an array with length = 4: [0, 1, 2, 3], the difference between\n    0 and 3 will not be 3, but 1 (i.e. circular difference)\"\"\"\n    x = np.arange(length)\n    mod = length % 2\n    if mod == 0:\n        temp = np.ones(length)\n        temp[length/2:] = -1\n    else:\n        x = x - np.floor(length/2)\n        temp = np.copy(x)\n        temp[np.less(x, 0)] = 1\n        temp[np.greater(x, 0)] = -1\n    x = np.cumsum(temp)\n\n    diagDiffmat = np.empty((length, length))\n    for idx in np.arange(length):\n        x = np.roll(x, 1)\n        diagDiffmat[idx, :] = x\n    # return diagDiffmat[ary1][ary2]\n    flat = diagDiffmat.flatten()\n    ind = ary1*diagDiffmat.shape[0] + ary2\n    ind = ind.astype('int')\n    return flat[ind]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getPartnerURL(self, CorpNum, TOGO):\n        try:\n            return linkhub.getPartnerURL(self._getToken(CorpNum), TOGO)\n        except LinkhubException as LE:\n            raise PopbillException(LE.code, LE.message)", "response": "\ud31d\ube4c \ud68c\uc6d0 \uc794\uc5ec\ud3ec\uc778\ud2b8 \ud655\uc778\n            args\n                CorpNum : \ud31d\ube4c\ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                TOGO : \"CHRG\"\n            return\n                URL\n            raise\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getAccessURL(self, CorpNum, UserID):\n        result = self._httpget('/?TG=LOGIN', CorpNum, UserID)\n        return result.url", "response": "\ud31d\ube4c \ub85c\uadf8\uc778 URL\n            args\n                CorpNum : \ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                UserID  : \ud68c\uc6d0 \ud31d\ube4c\uc544\uc774\ub514\n            return\n                30\ucd08 \ubcf4\uc548 \ud1a0\ud070\uc744 \ud3ec\ud568\ud55c url\n            raise\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getChargeURL(self, CorpNum, UserID):\n        result = self._httpget('/?TG=CHRG', CorpNum, UserID)\n        return result.url", "response": "\ud31d\ube4c \uc5f0\ub3d9\ud68c\uc6d0 \ud3ec\uc778\ud2b8 \ucda9\uc804 URL\n            args\n                CorpNum : \ud68c\uc6d0 \uc0ac\uc5c5\uc790\ubc88\ud638\n                UserID  : \ud68c\uc6d0 \ud31d\ube4c\uc544\uc774\ub514\n            return\n                30\ucd08 \ubcf4\uc548 \ud1a0\ud070\uc744 \ud3ec\ud568\ud55c url\n            raise\n                PopbillException"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef checkIsMember(self, CorpNum):\n        if CorpNum == None or CorpNum == '':\n            raise PopbillException(-99999999, \"\uc0ac\uc5c5\uc790\ubc88\ud638\uac00 \uc785\ub825\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n\n        return self._httpget('/Join?CorpNum=' + CorpNum + '&LID=' + self.__linkID, None, None)", "response": "Check if a user is a member of the room."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef joinMember(self, JoinInfo):\n        JoinInfo.LinkID = self.__linkID\n        postData = self._stringtify(JoinInfo)\n        return self._httppost('/Join', postData)", "response": "\uc804\uc6a9 \uc815\ubcf4 \ud31d\ube4c \ud68c\uc6d0\uac00\uc785 \uc815\ubcf4."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef registContact(self, CorpNum, ContactInfo, UserID=None):\n        postData = self._stringtify(ContactInfo)\n        return self._httppost('/IDs/New', postData, CorpNum, UserID)", "response": "registContact - Regist a new contact"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef TemplateValidator(value):\n\n    try:\n        Template(value)\n    except Exception as e:\n        raise ValidationError(\n            _(\"Cannot compile template (%(exception)s)\"),\n            params={\"exception\": e}\n        )", "response": "Validate a string into a Django template."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef merge(\n    fname1,\n    fname2,\n    dfilter1=None,\n    dfilter2=None,\n    has_header1=True,\n    has_header2=True,\n    frow1=0,\n    frow2=0,\n    ofname=None,\n    ocols=None,\n):\n    r\"\"\"\n    Merge two comma-separated values files.\n\n    Data columns from the second file are appended after data columns from the\n    first file. Empty values in columns are used if the files have different\n    number of rows\n\n    :param fname1: Name of the first comma-separated values file, the file\n                   whose columns appear first in the output file\n    :type  fname1: FileNameExists_\n\n    :param fname2: Name of the second comma-separated values file, the file\n                   whose columns appear last in the output file\n    :type  fname2: FileNameExists_\n\n    :param dfilter1: Row and/or column filter for the first file. If None no\n                     data filtering is done on the file\n    :type  dfilter1: :ref:`CsvDataFilter` or None\n\n    :param dfilter2: Row and/or column filter for the second file. If None no\n                     data filtering is done on the file\n    :type  dfilter2: :ref:`CsvDataFilter` or None\n\n    :param has_header1: Flag that indicates whether the first comma-separated\n                        values file has column headers in its first line (True)\n                        or not (False)\n    :type  has_header1: boolean\n\n    :param has_header2: Flag that indicates whether the second comma-separated\n                        values file has column headers in its first line (True)\n                        or not (False)\n    :type  has_header2: boolean\n\n    :param frow1: First comma-separated values file first data row (starting\n                  from 1). If 0 the row where data starts is auto-detected as\n                  the first row that has a number (integer of float) in at\n                  least one of its columns\n    :type  frow1: NonNegativeInteger_\n\n    :param frow2: Second comma-separated values file first data row (starting\n                  from 1). If 0 the row where data starts is auto-detected as\n                  the first row that has a number (integer of float) in at\n                  least one of its columns\n    :type  frow2: NonNegativeInteger_\n\n    :param ofname: Name of the output comma-separated values file, the file\n                   that will contain the data from the first and second files.\n                   If None the first file is replaced \"in place\"\n    :type  ofname: FileName_ or None\n\n    :param ocols: Column names of the output comma-separated values file.\n                  If None the column names in the first and second files are\n                  used if **has_header1** and/or **has_header2** are True. The\n                  column labels :code:`'Column [column_number]'` are used when\n                  one of the two files does not have a header, where\n                  :code:`[column_number]` is an integer representing the column\n                  number (column 0 is the leftmost column). No header is used\n                  if **has_header1** and **has_header2** are False\n    :type  ocols: list or None\n\n    .. [[[cog cog.out(exobj.get_sphinx_autodoc(raised=True)) ]]]\n    .. Auto-generated exceptions documentation for pcsv.merge.merge\n\n    :raises:\n     * OSError (File *[fname]* could not be found)\n\n     * RuntimeError (Argument \\`dfilter1\\` is not valid)\n\n     * RuntimeError (Argument \\`dfilter2\\` is not valid)\n\n     * RuntimeError (Argument \\`fname1\\` is not valid)\n\n     * RuntimeError (Argument \\`fname2\\` is not valid)\n\n     * RuntimeError (Argument \\`frow1\\` is not valid)\n\n     * RuntimeError (Argument \\`frow2\\` is not valid)\n\n     * RuntimeError (Argument \\`ocols\\` is not valid)\n\n     * RuntimeError (Argument \\`ofname\\` is not valid)\n\n     * RuntimeError (Column headers are not unique in file *[fname]*)\n\n     * RuntimeError (Combined columns in data files and output columns are\n       different)\n\n     * RuntimeError (File *[fname]* has no valid data)\n\n     * RuntimeError (File *[fname]* is empty)\n\n     * RuntimeError (Invalid column specification)\n\n     * ValueError (Column *[column_identifier]* not found)\n\n    .. [[[end]]]\n    \"\"\"\n    # pylint: disable=R0913,R0914\n    iomm_ex = pexdoc.exh.addex(\n        RuntimeError, \"Combined columns in data files and output columns are different\"\n    )\n    # Read and validate file 1\n    obj1 = CsvFile(fname=fname1, dfilter=dfilter1, has_header=has_header1, frow=frow1)\n    # Read and validate file 2\n    obj2 = CsvFile(fname=fname2, dfilter=dfilter2, has_header=has_header2, frow=frow2)\n    # Assign output data structure\n    ofname = fname1 if ofname is None else ofname\n    cfilter1 = obj1.header() if obj1.cfilter is None else obj1.cfilter\n    cfilter2 = obj2.header() if obj1.cfilter is None else obj2.cfilter\n    # Create new header\n    cols1 = len(cfilter1)\n    cols2 = len(cfilter2)\n    if (ocols is None) and has_header1 and has_header2:\n        ocols = [cfilter1 + cfilter2]\n    elif (ocols is None) and has_header1 and (not has_header2):\n        ocols = [\n            cfilter1\n            + [\n                \"Column {0}\".format(item)\n                for item in range(cols1 + 1, cols1 + cols2 + 1)\n            ]\n        ]\n    elif (ocols is None) and (not has_header1) and has_header2:\n        ocols = [[\"Column {0}\".format(item) for item in range(1, cols1 + 1)] + cfilter2]\n    elif ocols is None:\n        ocols = []\n    else:\n        iomm_ex(cols1 + cols2 != len(ocols))\n        ocols = [ocols]\n    # Even out rows\n    delta = obj1.rows(filtered=True) - obj2.rows(filtered=True)\n    data1 = obj1.data(filtered=True)\n    data2 = obj2.data(filtered=True)\n    if delta > 0:\n        row = [cols2 * [None]]\n        data2 += delta * row\n    elif delta < 0:\n        row = [cols1 * [None]]\n        data1 += abs(delta) * row\n    data = ocols\n    for item1, item2 in zip(data1, data2):\n        data.append(item1 + item2)\n    write(fname=ofname, data=data, append=False)", "response": "r Merge two comma - separated values files into one."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pyprf_opt_brute(strCsvCnfg, objNspc, lgcTest=False, strPathHrf=None,\n                    varRat=None):\n    \"\"\"\n    Function for optimizing given pRF paramaters using brute-force grid search.\n\n    Parameters\n    ----------\n    strCsvCnfg : str\n        Absolute file path of config file.\n    objNspc : object\n        Name space from command line arguments.\n    lgcTest : Boolean\n        Whether this is a test (pytest). If yes, absolute path of pyprf libary\n        will be prepended to config file paths.\n    strPathHrf : str or None:\n        Path to npy file with custom hrf parameters. If None, default\n        parameters will be used.\n    varRat : float, default None\n        Ratio of size suppressive surround to size of center pRF\n\n    \"\"\"\n    # *************************************************************************\n    # *** Check time\n    print('---pRF analysis')\n    varTme01 = time.time()\n    # *************************************************************************\n\n    # *************************************************************************\n    # *** Preparations\n\n    # Load config parameters from csv file into dictionary:\n    dicCnfg = load_config(strCsvCnfg, lgcTest=lgcTest)\n\n    # Load config parameters from dictionary into namespace:\n    cfg = cls_set_config(dicCnfg)\n\n    # Conditional imports:\n    if cfg.strVersion == 'gpu':\n        from pyprf_feature.analysis.find_prf_gpu import find_prf_gpu\n    if ((cfg.strVersion == 'cython') or (cfg.strVersion == 'numpy')):\n        from pyprf_feature.analysis.find_prf_cpu import find_prf_cpu\n\n    # Convert preprocessing parameters (for temporal smoothing)\n    # from SI units (i.e. [s]) into units of data array (volumes):\n    cfg.varSdSmthTmp = np.divide(cfg.varSdSmthTmp, cfg.varTr)\n    # *************************************************************************\n\n    # *************************************************************************\n    # *** Preprocessing\n\n    # The functional data will be masked and demeaned:\n    aryLgcMsk, aryLgcVar, hdrMsk, aryAff, aryFunc, tplNiiShp = prep_func(\n        cfg.strPathNiiMask, cfg.lstPathNiiFunc, varAvgThr=-100.)\n\n    # set the precision of the header to np.float32 so that the prf results\n    # will be saved in this precision later\n    hdrMsk.set_data_dtype(np.float32)\n\n    print('---Number of voxels included in analysis: ' +\n          str(np.sum(aryLgcVar)))\n\n    # *************************************************************************\n    # *** Checks\n\n    # Make sure that if gpu fitting is used, the number of cross-validations is\n    # set to 1, not higher\n    if cfg.strVersion == 'gpu':\n        strErrMsg = 'Stopping program. ' + \\\n            'Cross-validation on GPU is currently not supported. ' + \\\n            'Set varNumXval equal to 1 in csv file in order to continue. '\n        assert cfg.varNumXval == 1, strErrMsg\n\n    # For the GPU version, we need to set down the parallelisation to 1 now,\n    # because no separate CPU threads are to be created. We may still use CPU\n    # parallelisation for preprocessing, which is why the parallelisation\n    # factor is only reduced now, not earlier.\n    if cfg.strVersion == 'gpu':\n        cfg.varPar = 1\n\n    # check whether we need to crossvalidate\n    if np.greater(cfg.varNumXval, 1):\n        cfg.lgcXval = True\n    elif np.equal(cfg.varNumXval, 1):\n        cfg.lgcXval = False\n    strErrMsg = 'Stopping program. ' + \\\n        'Set numXval (number of crossvalidation folds) to 1 or higher'\n    assert np.greater_equal(cfg.varNumXval, 1), strErrMsg\n    \n    # derive number of feature for fitting\n    if varRat is not None:\n        # since there will be a beta parameter estimate both for the center and\n        # the surround, we multiply by 2\n        varNumFtr = int(2*cfg.switchHrfSet)    \n    else:\n        varNumFtr = cfg.switchHrfSet\n\n    # *************************************************************************\n\n    # *************************************************************************\n    # Load previous pRF fitting results\n    print('---String to prior results provided by user:')\n    print(objNspc.strPthPrior)\n\n    # Load the x, y, sigma winner parameters from pyprf_feature\n    lstWnrPrm = [objNspc.strPthPrior + '_x_pos.nii.gz',\n                 objNspc.strPthPrior + '_y_pos.nii.gz',\n                 objNspc.strPthPrior + '_SD.nii.gz',\n                 objNspc.strPthPrior + '_eccentricity.nii.gz']\n    lstPrmInt, objHdr, aryAff = load_res_prm(lstWnrPrm,\n                                             lstFlsMsk=[cfg.strPathNiiMask])\n    # Convert list to array\n    assert len(lstPrmInt) == 1\n    aryIntGssPrm = lstPrmInt[0]\n    del(lstPrmInt)\n\n    # Some voxels were excluded because they did not have sufficient mean\n    # and/or variance - exclude their nitial parameters, too\n    aryIntGssPrm = aryIntGssPrm[aryLgcVar, :]\n\n    # *************************************************************************\n\n    # *************************************************************************\n    # *** Sort voxels by polar angle/previous parameters\n\n    # Calculate the polar angles that were found in independent localiser\n    aryPlrAng = np.arctan2(aryIntGssPrm[:, 1], aryIntGssPrm[:, 0])\n\n    # Calculate the unique polar angles that are expected from grid search\n    aryUnqPlrAng = np.linspace(0.0, 2*np.pi, objNspc.varNumOpt2,\n                               endpoint=False)\n\n    # Expected polar angle values are range from 0 to 2*pi, while\n    # the calculated angle values will range from -pi to pi\n    # Thus, bring empirical values from range -pi, pi to range 0, 2pi\n    aryPlrAng = (aryPlrAng + 2 * np.pi) % (2 * np.pi)\n\n    # For every empirically found polar angle get the index of the nearest\n    # theoretically expected polar angle, this is to offset small imprecisions\n    aryUnqPlrAngInd, aryDstPlrAng = find_near_pol_ang(aryPlrAng, aryUnqPlrAng)\n\n    # Make sure that the maximum distance from a found polar angle to a grid\n    # point is smaller than the distance between two neighbor grid points\n    assert np.max(aryDstPlrAng) < np.divide(2*np.pi, objNspc.varNumOpt2)\n\n    # Update unique polar angles such that it contains only the ones which\n    # were found in data\n    aryUnqPlrAng = aryUnqPlrAng[np.unique(aryUnqPlrAngInd)]\n    # Update indices\n    aryUnqPlrAngInd, aryDstPlrAng = find_near_pol_ang(aryPlrAng, aryUnqPlrAng)\n\n    # Get logical arrays that index voxels with particular polar angle\n    lstLgcUnqPlrAng = []\n    for indPlrAng in range(len(aryUnqPlrAng)):\n        lstLgcUnqPlrAng.append([aryUnqPlrAngInd == indPlrAng][0])\n\n    print('---Number of radial position options provided by user: ' +\n          str(objNspc.varNumOpt1))\n    print('---Number of angular position options provided by user: ' +\n          str(objNspc.varNumOpt2))\n    print('---Number of unique polar angles found in prior estimates: ' +\n          str(len(aryUnqPlrAng)))\n    print('---Maximum displacement in radial direction that is allowed: ' +\n          str(objNspc.varNumOpt3))\n    print('---Fitted modelled are restricted to stimulated area: ' +\n          str(objNspc.lgcRstrCentre))\n\n    # *************************************************************************\n    # *** Perform prf fitting\n\n    # Create array for collecting winner parameters\n    aryBstXpos = np.zeros((aryPlrAng.shape[0]))\n    aryBstYpos = np.zeros((aryPlrAng.shape[0]))\n    aryBstSd = np.zeros((aryPlrAng.shape[0]))\n    aryBstR2 = np.zeros((aryPlrAng.shape[0]))\n    aryBstBts = np.zeros((aryPlrAng.shape[0], varNumFtr))\n    if np.greater(cfg.varNumXval, 1):\n        aryBstR2Single = np.zeros((aryPlrAng.shape[0],\n                                   len(cfg.lstPathNiiFunc)))\n\n    # loop over all found instances of polar angle/previous parameters\n    for indPlrAng in range(len(aryUnqPlrAng)):\n\n        print('------Polar angle number ' + str(indPlrAng+1) + ' out of ' +\n              str(len(aryUnqPlrAng)))\n\n        # get the polar angle for the current voxel batch\n        varPlrAng = np.array(aryUnqPlrAng[indPlrAng])\n\n        # get logical array to index voxels with this particular polar angle\n        lgcUnqPlrAng = lstLgcUnqPlrAng[indPlrAng]\n\n        # get prior eccentricities for current voxel batch\n        vecPrrEcc = aryIntGssPrm[lgcUnqPlrAng, 3]\n\n        print('---------Number of voxels of this polar angle: ' +\n              str(np.sum(lgcUnqPlrAng)))\n\n        # *********************************************************************\n\n        # *********************************************************************\n        # *** Create time course models for this particular polar angle\n\n        # Vector with the radial position:\n        vecRad = np.linspace(0.0, cfg.varExtXmax, objNspc.varNumOpt1,\n                             endpoint=True)\n\n        # Get all possible combinations on the grid, using matrix indexing ij\n        # of output\n        aryRad, aryTht = np.meshgrid(vecRad, varPlrAng, indexing='ij')\n\n        # Flatten arrays to be able to combine them with meshgrid\n        vecRad = aryRad.flatten()\n        vecTht = aryTht.flatten()\n\n        # Convert from polar to cartesian\n        vecX, vecY = map_pol_to_crt(vecTht, vecRad)\n\n        # Vector with standard deviations pRF models (in degree of vis angle):\n        vecPrfSd = np.linspace(cfg.varPrfStdMin, cfg.varPrfStdMax,\n                               cfg.varNumPrfSizes, endpoint=True)\n\n        # Create model parameters\n        varNumMdls = len(vecX) * len(vecPrfSd)\n        aryMdlParams = np.zeros((varNumMdls, 3), dtype=np.float32)\n\n        varCntMdlPrms = 0\n\n        # Loop through x-positions:\n        for idxXY in range(0, len(vecX)):\n\n            # Loop through standard deviations (of Gaussian pRF models):\n            for idxSd in range(0, len(vecPrfSd)):\n\n                # Place index and parameters in array:\n                aryMdlParams[varCntMdlPrms, 0] = vecX[idxXY]\n                aryMdlParams[varCntMdlPrms, 1] = vecY[idxXY]\n                aryMdlParams[varCntMdlPrms, 2] = vecPrfSd[idxSd]\n\n                # Increment parameter index:\n                varCntMdlPrms += 1\n\n        # Convert winner parameters from degrees of visual angle to pixel\n        vecIntX, vecIntY, vecIntSd = rmp_deg_pixel_xys(aryMdlParams[:, 0],\n                                                       aryMdlParams[:, 1],\n                                                       aryMdlParams[:, 2],\n                                                       cfg.tplVslSpcSze,\n                                                       cfg.varExtXmin,\n                                                       cfg.varExtXmax,\n                                                       cfg.varExtYmin,\n                                                       cfg.varExtYmax)\n\n        aryMdlParamsPxl = np.column_stack((vecIntX, vecIntY, vecIntSd))\n\n        if objNspc.lgcRstrCentre:\n            # Calculate the areas that were stimulated during the experiment\n            arySptExpInf = np.load(cfg.strSptExpInf)\n            arySptExpInf = np.rot90(arySptExpInf, k=3)\n            aryStimArea = np.sum(arySptExpInf, axis=-1).astype(np.bool)\n\n            # Get logical to exclude models with pRF centre outside stim area\n            lgcMdlInc = aryStimArea[aryMdlParamsPxl[:, 0].astype(np.int32),\n                                    aryMdlParamsPxl[:, 1].astype(np.int32)]\n            # Exclude models with prf center outside stimulated area\n            aryMdlParams = aryMdlParams[lgcMdlInc, :]\n            aryMdlParamsPxl = aryMdlParamsPxl[lgcMdlInc, :]\n\n        # Create model time courses\n        aryPrfTc = model_creation_opt(dicCnfg, aryMdlParamsPxl,\n                                      strPathHrf=strPathHrf, varRat=varRat,\n                                      lgcPrint=False)\n\n        # The model time courses will be preprocessed such that they are\n        # smoothed (temporally) with same factor as the data and that they will\n        # be z-scored:\n        aryPrfTc = prep_models(aryPrfTc, varSdSmthTmp=cfg.varSdSmthTmp,\n                               lgcPrint=False)\n\n        # *********************************************************************\n        # *** Create logical to restrict model fitting in radial direction\n\n        if objNspc.varNumOpt3 is not None:\n\n            # Calculate eccentricity of currently tested model parameters\n            vecMdlEcc = np.sqrt(np.add(np.square(aryMdlParams[:, 0]),\n                                       np.square(aryMdlParams[:, 1])))\n            # Compare model eccentricity against prior eccentricity\n            vecPrrEccGrd, vecMdlEccGrd = np.meshgrid(vecPrrEcc, vecMdlEcc,\n                                                     indexing='ij')\n            # Consider allowed eccentricity shift as specified by user\n            lgcRstr = np.logical_and(np.less_equal(vecMdlEccGrd,\n                                                   np.add(vecPrrEccGrd,\n                                                          objNspc.varNumOpt3)),\n                                     np.greater(vecMdlEccGrd,\n                                                np.subtract(vecPrrEccGrd,\n                                                            objNspc.varNumOpt3)\n                                                )\n                                     )\n        else:\n            lgcRstr = np.ones((np.sum(lgcUnqPlrAng),\n                               aryMdlParams.shape[0]), dtype=np.bool)\n\n        # *********************************************************************\n        # *** Check for every voxel there is at least one model being tried\n\n        # Is there at least 1 model for each voxel?\n        lgcMdlPerVxl = np.greater(np.sum(lgcRstr, axis=1), 0)\n        print('---------Number of voxels fitted: ' + str(np.sum(lgcMdlPerVxl)))\n\n        # Those voxels for which no model would be tried, for example because\n        # the pRF parameters estimated in the prior were outside the stimulated\n        # area, are escluded from model fitting by setting their logical False\n        lgcUnqPlrAng[lgcUnqPlrAng] = lgcMdlPerVxl\n\n        # We need to update the index table for restricting model fitting\n        lgcRstr = lgcRstr[lgcMdlPerVxl, :]\n\n        # *********************************************************************\n        # *** Find best model for voxels with this particular polar angle\n\n        # Only perform the fitting if there are voxels with models to optimize\n        if np.any(lgcUnqPlrAng):\n            # Empty list for results (parameters of best fitting pRF model):\n            lstPrfRes = [None] * cfg.varPar\n\n            # Empty list for processes:\n            lstPrcs = [None] * cfg.varPar\n\n            # Create a queue to put the results in:\n            queOut = mp.Queue()\n\n            # Put logical for model restriction in list\n            lstRst = np.array_split(lgcRstr, cfg.varPar)\n            del(lgcRstr)\n\n            # Create list with chunks of func data for parallel processes:\n            lstFunc = np.array_split(aryFunc[lgcUnqPlrAng, :], cfg.varPar)\n\n            # CPU version (using numpy or cython for pRF finding):\n            if ((cfg.strVersion == 'numpy') or (cfg.strVersion == 'cython')):\n\n                # Create processes:\n                for idxPrc in range(0, cfg.varPar):\n                    lstPrcs[idxPrc] = mp.Process(target=find_prf_cpu,\n                                                 args=(idxPrc,\n                                                       lstFunc[idxPrc],\n                                                       aryPrfTc,\n                                                       aryMdlParams,\n                                                       cfg.strVersion,\n                                                       cfg.lgcXval,\n                                                       cfg.varNumXval,\n                                                       queOut),\n                                                 kwargs={'lgcRstr':\n                                                         lstRst[idxPrc],\n                                                         'lgcPrint': False},\n                                                 )\n                    # Daemon (kills processes when exiting):\n                    lstPrcs[idxPrc].Daemon = True\n\n            # GPU version (using tensorflow for pRF finding):\n            elif cfg.strVersion == 'gpu':\n\n                # Create processes:\n                for idxPrc in range(0, cfg.varPar):\n                    lstPrcs[idxPrc] = mp.Process(target=find_prf_gpu,\n                                                 args=(idxPrc,\n                                                       aryMdlParams,\n                                                       lstFunc[idxPrc],\n                                                       aryPrfTc,\n                                                       queOut),\n                                                 kwargs={'lgcRstr':\n                                                         lstRst[idxPrc],\n                                                         'lgcPrint': False},\n                                                 )\n                    # Daemon (kills processes when exiting):\n                    lstPrcs[idxPrc].Daemon = True\n\n            # Start processes:\n            for idxPrc in range(0, cfg.varPar):\n                lstPrcs[idxPrc].start()\n\n            # Delete reference to list with function data (the data continues\n            # to exists in child process):\n            del(lstFunc)\n\n            # Collect results from queue:\n            for idxPrc in range(0, cfg.varPar):\n                lstPrfRes[idxPrc] = queOut.get(True)\n\n            # Join processes:\n            for idxPrc in range(0, cfg.varPar):\n                lstPrcs[idxPrc].join()\n\n            # *****************************************************************\n\n            # *****************************************************************\n            # *** Prepare pRF finding results for export\n\n            # Put output into correct order:\n            lstPrfRes = sorted(lstPrfRes)\n\n            # collect results from parallelization\n            aryBstTmpXpos = joinRes(lstPrfRes, cfg.varPar, 1, inFormat='1D')\n            aryBstTmpYpos = joinRes(lstPrfRes, cfg.varPar, 2, inFormat='1D')\n            aryBstTmpSd = joinRes(lstPrfRes, cfg.varPar, 3, inFormat='1D')\n            aryBstTmpR2 = joinRes(lstPrfRes, cfg.varPar, 4, inFormat='1D')\n            aryBstTmpBts = joinRes(lstPrfRes, cfg.varPar, 5, inFormat='2D')\n            if np.greater(cfg.varNumXval, 1):\n                aryTmpBstR2Single = joinRes(lstPrfRes, cfg.varPar, 6,\n                                            inFormat='2D')\n            # Delete unneeded large objects:\n            del(lstPrfRes)\n\n            # *****************************************************************\n\n            # *****************************************************************\n            # Put findings for voxels with specific polar angle into ary with\n            # result for all voxels\n            aryBstXpos[lgcUnqPlrAng] = aryBstTmpXpos\n            aryBstYpos[lgcUnqPlrAng] = aryBstTmpYpos\n            aryBstSd[lgcUnqPlrAng] = aryBstTmpSd\n            aryBstR2[lgcUnqPlrAng] = aryBstTmpR2\n            aryBstBts[lgcUnqPlrAng, :] = aryBstTmpBts\n            if np.greater(cfg.varNumXval, 1):\n                aryBstR2Single[lgcUnqPlrAng, :] = aryTmpBstR2Single\n\n            # *****************************************************************\n\n    # *************************************************************************\n    # Calculate polar angle map:\n    aryPlrAng = np.arctan2(aryBstYpos, aryBstXpos)\n    # Calculate eccentricity map (r = sqrt( x^2 + y^2 ) ):\n    aryEcc = np.sqrt(np.add(np.square(aryBstXpos),\n                            np.square(aryBstYpos)))\n\n    # It is possible that after optimization the pRF has moved to location 0, 0\n    # In this cases, the polar angle parameter is arbitrary and will be\n    # assigned either 0 or pi. To preserve smoothness of the map, assign the\n    # initial polar angle value from independent localiser\n    lgcMvdOrgn = np.logical_and(aryBstXpos == 0.0, aryBstYpos == 0.0)\n    lgcMvdOrgn = np.logical_and(lgcMvdOrgn, aryBstSd > 0)\n    aryIntPlrAng = np.arctan2(aryIntGssPrm[:, 1], aryIntGssPrm[:, 0])\n    aryPlrAng[lgcMvdOrgn] = np.copy(aryIntPlrAng[lgcMvdOrgn])\n\n    # *************************************************************************\n\n    # *************************************************************************\n    # Export each map of best parameters as a 3D nii file\n\n    print('---------Exporting results')\n\n    # Append 'hrf' to cfg.strPathOut, if fitting was done with custom hrf\n    if strPathHrf is not None:\n        cfg.strPathOut = cfg.strPathOut + '_hrf'\n\n    # Xoncatenate all the best voxel maps\n    aryBstMaps = np.stack([aryBstXpos, aryBstYpos, aryBstSd, aryBstR2,\n                           aryPlrAng, aryEcc], axis=1)\n\n    # List with name suffices of output images:\n    lstNiiNames = ['_x_pos_brute',\n                   '_y_pos_brute',\n                   '_SD_brute',\n                   '_R2_brute',\n                   '_polar_angle_brute',\n                   '_eccentricity_brute']\n\n    if varRat is not None:\n        lstNiiNames = [strNii + '_' + str(varRat) for strNii in lstNiiNames]\n\n    # Create full path names from nii file names and output path\n    lstNiiNames = [cfg.strPathOut + strNii + '.nii.gz' for strNii in\n                   lstNiiNames]\n\n    # export map results as seperate 3D nii files\n    export_nii(aryBstMaps, lstNiiNames, aryLgcMsk, aryLgcVar, tplNiiShp,\n               aryAff, hdrMsk, outFormat='3D')\n\n    # *************************************************************************\n\n    # *************************************************************************\n    # Save beta parameter estimates for every feature:\n\n    # List with name suffices of output images:\n    lstNiiNames = ['_Betas_brute']\n\n    if varRat is not None:\n        lstNiiNames = [strNii + '_' + str(varRat) for strNii in lstNiiNames]\n\n    # Create full path names from nii file names and output path\n    lstNiiNames = [cfg.strPathOut + strNii + '.nii.gz' for strNii in\n                   lstNiiNames]\n\n    # export beta parameter as a single 4D nii file\n    export_nii(aryBstBts, lstNiiNames, aryLgcMsk, aryLgcVar, tplNiiShp,\n               aryAff, hdrMsk, outFormat='4D')\n\n    # *************************************************************************\n\n    # *************************************************************************\n    # Save R2 maps from crossvalidation (saved for every run) as nii:\n\n    if np.greater(cfg.varNumXval, 1):\n\n        # truncate extremely negative R2 values\n        aryBstR2Single[np.where(np.less_equal(aryBstR2Single, -1.0))] = -1.0\n\n        # List with name suffices of output images:\n        lstNiiNames = ['_R2_single_brute']\n\n        if varRat is not None:\n            lstNiiNames = [strNii + '_' + str(varRat) for strNii in\n                           lstNiiNames]\n\n        # Create full path names from nii file names and output path\n        lstNiiNames = [cfg.strPathOut + strNii + '.nii.gz' for strNii in\n                       lstNiiNames]\n\n        # export R2 maps as a single 4D nii file\n        export_nii(aryBstR2Single, lstNiiNames, aryLgcMsk, aryLgcVar,\n                   tplNiiShp, aryAff, hdrMsk, outFormat='4D')\n\n    # *************************************************************************\n\n    # *************************************************************************\n    # *** Report time\n\n    varTme02 = time.time()\n    varTme03 = varTme02 - varTme01\n    print('---Elapsed time: ' + str(varTme03) + ' s')\n    print('---Done.')", "response": "Function for optimizing given pRF paramaters using brute - force grid search."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_lbry_api_function_docs(url=LBRY_API_RAW_JSON_URL):\n\n    try:\n        # Grab the page content\n        docs_page = urlopen(url)\n\n        # Read the contents of the actual url we grabbed and decode them into UTF-8\n        contents = docs_page.read().decode(\"utf-8\")\n\n        # Return the contents loaded as JSON\n        return loads(contents)\n\n        # If we get an exception, simply exit\n    except URLError as UE:\n        print(UE)\n\n    except Exception as E:\n        print(E)\n\n    return []", "response": "Scrapes the given URL to obtain the documentation for the LBRY API and returns the contents as JSON"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_method_definition(func):\n    indent = 4\n\n    # initial definition\n    method_definition = (\" \" * indent) + \"def \" + func[\"name\"]\n\n    # Here we just create a queue and put all the parameters\n    # into the queue in the order that they were given,\n    params_required = [\n        param for param in func[\"arguments\"] if param[\"is_required\"]\n    ]\n    params_optional = [\n        param for param in func[\"arguments\"]\n        if not param[\"is_required\"]\n    ]\n\n    # Open the parameter definitions\n    method_definition += \"(self, \"\n\n    for param in params_required:\n        # Put the parameter into the queue\n\n        method_definition += param[\"name\"]\n        method_definition += \", \"\n\n    for param in params_optional:\n        method_definition += param[\"name\"]\n\n        # Default methods not required\n        method_definition += \"=None, \"\n\n    # Peel off the final \", \" and close off the parameter definition\n    method_definition = method_definition.rstrip(\", \") + \"):\\n\"\n\n    indent += 4\n\n    # re-indent\n    method_definition += \" \" * indent\n\n    # Begin with description.\n\n    method_definition += '\"\"\"' + func[\"description\"]\n\n    # re-indent\n    method_definition += \"\\n\\n\" + \" \" * indent\n\n    # Go through each parameter and insert description & type hint\n    for param in params_required + params_optional:\n        # Add the type\n        method_definition += \":param \" + DTYPE_MAPPING[param[\"type\"].lower()]\n\n        # Add the name\n        method_definition += \" \" + param[\"name\"] + \": \"\n\n        # Add the description\n        method_definition += param[\"description\"]\n\n        # Add optionality & reindent\n        method_definition += \"\\n\" if param[\n            \"is_required\"] else \" (Optional)\\n\"\n\n        method_definition += \" \" * indent\n\n    open_index = func[\"returns\"].find('(')\n    close_index = func[\"returns\"].find(\n        ')', (open_index if open_index > -1 else 0))\n\n    func[\"returns\"] = func[\"returns\"].replace(\"\\t\", \" \" * 4)\n    return_string = func[\"returns\"].replace(\"\\n\", \"\")\n\n    if open_index < close_index and func[\"returns\"][\n                                    open_index + 1:close_index] in DTYPE_MAPPING:\n        method_definition += \":rtype: \" + DTYPE_MAPPING[\n            func[\"returns\"][open_index + 1:close_index]]\n\n        func[\"returns\"] = func[\"returns\"].replace(\n            func[\"returns\"][open_index:close_index + 1], \"\")\n\n        method_definition += \"\\n\" + \" \" * indent\n\n    method_definition += \":return: \" + return_string\n\n    for i in range(0, len(return_string) + 1, 80 - (indent + 2)):\n        method_definition += return_string[i:i + (\n                80 - (indent + 2))] + \"\\n\" + \" \" * indent\n\n    # Close it off & reindent\n    method_definition += '\"\"\"' + \"\\n\" + \" \" * indent\n\n    # Create the params map\n    params_map = \"__params_map = {\"\n\n    # Save the indent\n    params_indent, num_params = len(\n        params_map), len(params_required) + len(params_optional)\n\n    # Append the map to the method_definition\n    method_definition += params_map\n\n    # Go through the required parameters first\n    for i, param in enumerate(params_required + params_optional):\n\n        # append the methods to the map\n        method_definition += \"'\" + param[\"name\"] + \"': \" + param[\"name\"]\n\n        if not param[\"is_required\"]:\n            method_definition + \" if \" + param[\n                \"name\"] + \"is not None else None\"\n\n        # add commas or ending bracket if needed & reindent correctly\n        method_definition += \",\\n\" + \" \" * indent + ' ' * params_indent if i + 1 < num_params else \"\"\n\n    method_definition += '}\\n\\n' + ' ' * indent\n\n    method_definition += \"return self.make_request(SERVER_ADDRESS, '\" + func[\"name\"] + \"', \" \\\n                         + params_map.rstrip(\" = {\") + \", timeout=self.timeout)\\n\\n\"\n\n    return method_definition", "response": "Generates the body for the given function and returns the string containing the function definition"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_lbryd_wrapper(url=LBRY_API_RAW_JSON_URL, read_file=__LBRYD_BASE_FPATH__, write_file=LBRYD_FPATH):\n\n    functions = get_lbry_api_function_docs(url)\n\n    # Open the actual file for appending\n    with open(write_file, 'w') as lbry_file:\n\n        lbry_file.write(\"# This file was generated at build time using the generator function\\n\")\n        lbry_file.write(\"# You may edit but do so with caution\\n\")\n\n        with open(read_file, 'r') as template:\n            header = template.read()\n\n        lbry_file.write(header)\n\n        # Iterate through all the functions we retrieved\n        for func in functions:\n\n            method_definition = generate_method_definition(func)\n\n            # Write to file\n            lbry_file.write(method_definition)\n\n    try:\n        from yapf.yapflib.yapf_api import FormatFile\n\n        # Now we should format the file using the yapf formatter\n        FormatFile(write_file, in_place=True)\n\n    except ImportError as IE:\n        print(\"[Warning]: yapf is not installed, so the generated code will not follow an easy-to-read standard\")\n        print(IE)", "response": "Generates the actual functions for lbryd_api. py based on the given url and writes the generated file to write_file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading nii file and return array containing nii data.", "response": "def load_nii(strPathIn, varSzeThr=5000.0):\n    \"\"\"\n    Load nii file.\n\n    Parameters\n    ----------\n    strPathIn : str\n        Path to nii file to load.\n    varSzeThr : float\n        If the nii file is larger than this threshold (in MB), the file is\n        loaded volume-by-volume in order to prevent memory overflow. Default\n        threshold is 1000 MB.\n\n    Returns\n    -------\n    aryNii : np.array\n        Array containing nii data. 32 bit floating point precision.\n    objHdr : header object\n        Header of nii file.\n    aryAff : np.array\n        Array containing 'affine', i.e. information about spatial positioning\n        of nii data.\n\n    Notes\n    -----\n    If the nii file is larger than the specified threshold (`varSzeThr`), the\n    file is loaded volume-by-volume in order to prevent memory overflow. The\n    reason for this is that nibabel imports data at float64 precision, which\n    can lead to a memory overflow even for relatively small files.\n    \"\"\"\n    # Load nii file (this does not load the data into memory yet):\n    objNii = nb.load(strPathIn)\n\n    # Get size of nii file:\n    varNiiSze = os.path.getsize(strPathIn)\n\n    # Convert to MB:\n    varNiiSze = np.divide(float(varNiiSze), 1000000.0)\n\n    # Load volume-by-volume or all at once, depending on file size:\n    if np.greater(varNiiSze, float(varSzeThr)):\n\n        # Load large nii file\n\n        print(('---------Large file size ('\n              + str(np.around(varNiiSze))\n              + ' MB), reading volume-by-volume'))\n\n        # Get image dimensions:\n        tplSze = objNii.shape\n\n        # Create empty array for nii data:\n        aryNii = np.zeros(tplSze, dtype=np.float32)\n\n        # Loop through volumes:\n        for idxVol in range(tplSze[3]):\n            aryNii[..., idxVol] = np.asarray(\n                  objNii.dataobj[..., idxVol]).astype(np.float32)\n\n    else:\n\n        # Load small nii file\n\n        # Load nii file (this doesn't load the data into memory yet):\n        objNii = nb.load(strPathIn)\n\n        # Load data into array:\n        aryNii = np.asarray(objNii.dataobj).astype(np.float32)\n\n    # Get headers:\n    objHdr = objNii.header\n\n    # Get 'affine':\n    aryAff = objNii.affine\n\n    # Output nii data (as numpy array), header, and 'affine':\n    return aryNii, objHdr, aryAff"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads result parameters from multiple nii files with optional mask.", "response": "def load_res_prm(lstFunc, lstFlsMsk=None):\n    \"\"\"Load result parameters from multiple nii files, with optional mask.\n\n    Parameters\n    ----------\n    lstFunc : list,\n        list of str with file names of 3D or 4D nii files\n    lstFlsMsk : list, optional\n        list of str with paths to 3D nii files that can act as mask/s\n    Returns\n    -------\n    lstPrmAry : list\n        The list will contain as many numpy arrays as masks were provided.\n        Each array is 2D with shape [nr voxel in mask, nr nii files in lstFunc]\n    objHdr : header object\n        Header of nii file.\n    aryAff : np.array\n        Array containing 'affine', i.e. information about spatial positioning\n        of nii data.\n\n    \"\"\"\n\n    # load parameter/functional maps into a list\n    lstPrm = []\n    for ind, path in enumerate(lstFunc):\n        aryFnc = load_nii(path)[0].astype(np.float32)\n        if aryFnc.ndim == 3:\n            lstPrm.append(aryFnc)\n        # handle cases where nii array is 4D, in this case split arrays up in\n        # 3D arrays and appenbd those\n        elif aryFnc.ndim == 4:\n            for indAx in range(aryFnc.shape[-1]):\n                lstPrm.append(aryFnc[..., indAx])\n\n    # load mask/s if available\n    if lstFlsMsk is not None:\n        lstMsk = [None] * len(lstFlsMsk)\n        for ind, path in enumerate(lstFlsMsk):\n            aryMsk = load_nii(path)[0].astype(np.bool)\n            lstMsk[ind] = aryMsk\n    else:\n        print('------------No masks were provided')\n\n    if lstFlsMsk is None:\n        # if no mask was provided we just flatten all parameter array in list\n        # and return resulting list\n        lstPrmAry = [ary.flatten() for ary in lstPrm]\n    else:\n        # if masks are available, we loop over masks and then over parameter\n        # maps to extract selected voxels and parameters\n        lstPrmAry = [None] * len(lstFlsMsk)\n        for indLst, aryMsk in enumerate(lstMsk):\n            # prepare array that will hold parameter values of selected voxels\n            aryPrmSel = np.empty((np.sum(aryMsk), len(lstPrm)),\n                                 dtype=np.float32)\n            # loop over different parameter maps\n            for indAry, aryPrm in enumerate(lstPrm):\n                # get voxels specific to this mask\n                aryPrmSel[:, indAry] = aryPrm[aryMsk, ...]\n            # put array away in list, if only one parameter map was provided\n            # the output will be squeezed\n            lstPrmAry[indLst] = aryPrmSel\n\n    # also get header object and affine array\n    # we simply take it for the first functional nii file, cause that is the\n    # only file that has to be provided by necessity\n    objHdr, aryAff = load_nii(lstFunc[0])[1:]\n\n    return lstPrmAry, objHdr, aryAff"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexporting nii file(s). Parameters ---------- ary2dNii : numpy array Numpy array with results to be exported to nii. lstNiiNames : list List that contains strings with the complete file names. aryLgcMsk : numpy array If the nii file is larger than this threshold (in MB), the file is loaded volume-by-volume in order to prevent memory overflow. Default threshold is 1000 MB. aryLgcVar : np.array 1D numpy array containing logical values. One value per voxel after mask has been applied. If `True`, the variance and mean of the voxel's time course are greater than the provided thresholds in all runs and the voxel is included in the output array (`aryFunc`). If `False`, the variance or mean of the voxel's time course is lower than threshold in at least one run and the voxel has been excluded from the output (`aryFunc`). This is to avoid problems in the subsequent model fitting. This array is necessary to put results into original dimensions after model fitting. tplNiiShp : tuple Tuple that describes the 3D shape of the output volume aryAff : np.array Array containing 'affine', i.e. information about spatial positioning of nii data. hdrMsk : nibabel-header-object Nii header of mask. outFormat : string, either '3D' or '4D' String specifying whether images will be saved as seperate 3D nii files or one 4D nii file Notes ----- [1] This function does not return any arrays but instead saves to disk. [2] Depending on whether outFormat is '3D' or '4D' images will be saved as seperate 3D nii files or one 4D nii file.", "response": "def export_nii(ary2dNii, lstNiiNames, aryLgcMsk, aryLgcVar, tplNiiShp, aryAff,\n               hdrMsk, outFormat='3D'):\n    \"\"\"\n    Export nii file(s).\n\n    Parameters\n    ----------\n    ary2dNii : numpy array\n        Numpy array with results to be exported to nii.\n    lstNiiNames : list\n        List that contains strings with the complete file names.\n    aryLgcMsk : numpy array\n        If the nii file is larger than this threshold (in MB), the file is\n        loaded volume-by-volume in order to prevent memory overflow. Default\n        threshold is 1000 MB.\n    aryLgcVar : np.array\n        1D numpy array containing logical values. One value per voxel after\n        mask has been applied. If `True`, the variance and mean of the voxel's\n        time course are greater than the provided thresholds in all runs and\n        the voxel is included in the output array (`aryFunc`). If `False`, the\n        variance or mean of the voxel's time course is lower than threshold in\n        at least one run and the voxel has been excluded from the output\n        (`aryFunc`). This is to avoid problems in the subsequent model fitting.\n        This array is necessary to put results into original dimensions after\n        model fitting.\n    tplNiiShp : tuple\n        Tuple that describes the 3D shape of the output volume\n    aryAff : np.array\n        Array containing 'affine', i.e. information about spatial positioning\n        of nii data.\n    hdrMsk : nibabel-header-object\n        Nii header of mask.\n    outFormat : string, either '3D' or '4D'\n        String specifying whether images will be saved as seperate 3D nii\n        files or one 4D nii file\n\n    Notes\n    -----\n    [1] This function does not return any arrays but instead saves to disk.\n    [2] Depending on whether outFormat is '3D' or '4D' images will be saved as\n        seperate 3D nii files or one 4D nii file.\n    \"\"\"\n\n    # Number of voxels that were included in the mask:\n    varNumVoxMsk = np.sum(aryLgcMsk)\n\n    # Number of maps in ary2dNii\n    varNumMaps = ary2dNii.shape[-1]\n\n    # Place voxels based on low-variance exlusion:\n    aryPrfRes01 = np.zeros((varNumVoxMsk, varNumMaps), dtype=np.float32)\n    for indMap in range(varNumMaps):\n        aryPrfRes01[aryLgcVar, indMap] = ary2dNii[:, indMap]\n\n    # Total number of voxels:\n    varNumVoxTlt = (tplNiiShp[0] * tplNiiShp[1] * tplNiiShp[2])\n\n    # Place voxels based on mask-exclusion:\n    aryPrfRes02 = np.zeros((varNumVoxTlt, aryPrfRes01.shape[-1]),\n                           dtype=np.float32)\n    for indDim in range(aryPrfRes01.shape[-1]):\n        aryPrfRes02[aryLgcMsk, indDim] = aryPrfRes01[:, indDim]\n\n    # Reshape pRF finding results into original image dimensions:\n    aryPrfRes = np.reshape(aryPrfRes02,\n                           [tplNiiShp[0],\n                            tplNiiShp[1],\n                            tplNiiShp[2],\n                            aryPrfRes01.shape[-1]])\n\n    if outFormat == '3D':\n        # Save nii results:\n        for idxOut in range(0, aryPrfRes.shape[-1]):\n            # Create nii object for results:\n            niiOut = nb.Nifti1Image(aryPrfRes[..., idxOut],\n                                    aryAff,\n                                    header=hdrMsk\n                                    )\n            # Save nii:\n            strTmp = lstNiiNames[idxOut]\n            nb.save(niiOut, strTmp)\n\n    elif outFormat == '4D':\n\n        # adjust header\n        hdrMsk.set_data_shape(aryPrfRes.shape)\n\n        # Create nii object for results:\n        niiOut = nb.Nifti1Image(aryPrfRes,\n                                aryAff,\n                                header=hdrMsk\n                                )\n        # Save nii:\n        strTmp = lstNiiNames[0]\n        nb.save(niiOut, strTmp)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\njoin results from different processing units.", "response": "def joinRes(lstPrfRes, varPar, idxPos, inFormat='1D'):\n    \"\"\"Join results from different processing units (here cores).\n\n    Parameters\n    ----------\n    lstPrfRes : list\n        Output of results from parallelization.\n    varPar : integer, positive\n        Number of cores that were used during parallelization\n    idxPos : integer, positive\n        List position index that we expect the results to be collected to have.\n    inFormat : string\n        Specifies whether input will be 1d or 2d.\n\n    Returns\n    -------\n    aryOut : numpy array\n        Numpy array with results collected from different cores\n\n    \"\"\"\n\n    if inFormat == '1D':\n        # initialize output array\n        aryOut = np.zeros((0,))\n        # gather arrays from different processing units\n        for idxRes in range(0, varPar):\n            aryOut = np.append(aryOut, lstPrfRes[idxRes][idxPos])\n\n    elif inFormat == '2D':\n        # initialize output array\n        aryOut = np.zeros((0, lstPrfRes[0][idxPos].shape[-1]))\n        # gather arrays from different processing units\n        for idxRes in range(0, varPar):\n            aryOut = np.concatenate((aryOut, lstPrfRes[idxRes][idxPos]),\n                                    axis=0)\n\n    return aryOut"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cmp_res_R2(lstRat, lstNiiNames, strPathOut, strPathMdl, lgcSveMdlTc=True,\n               lgcDel=False, strNmeExt=''):\n    \"\"\"\"Compare results for different exponents and create winner nii.\n\n    Parameters\n    ----------\n    lstRat : list\n        List of floats containing the ratios that were tested for surround\n        suppression.\n    lstNiiNames : list\n        List of names of the different pRF maps (e.g. xpos, ypos, SD)\n    strPathOut : string\n        Path to the parent directory where the results should be saved.\n    strPathMdl : string\n        Path to the parent directory where pRF models should be saved.\n    lgcDel : boolean\n        Should model time courses be saved as npy file?\n    lgcDel : boolean\n        Should inbetween results (in form of nii files) be deleted?\n    strNmeExt : string\n        Extra name appendix to denominate experiment name. If undesidered,\n        provide empty string.\n\n    Notes\n    -----\n    [1] This function does not return any arrays but instead saves to disk.\n\n    \"\"\"\n\n    print('---Compare results for different ratios')\n\n    # Extract the index position for R2 and Betas map in lstNiiNames\n    indPosR2 = [ind for ind, item in enumerate(lstNiiNames) if 'R2' in item]\n    indPosBetas = [ind for ind, item in enumerate(lstNiiNames) if 'Betas' in\n                   item]\n    # Check that only one index was found\n    msgError = 'More than one nii file was provided that could serve as R2 map'\n    assert len(indPosR2) == 1, msgError\n    assert len(indPosBetas) == 1, msgError\n    # turn list int index\n    indPosR2 = indPosR2[0]\n    indPosBetas = indPosBetas[0]\n\n    # Get the names of the nii files with in-between results\n    lstCmpRes = []\n    for indRat in range(len(lstRat)):\n        # Get strExpSve\n        strExpSve = '_' + str(lstRat[indRat])\n        # If ratio is marked with 1.0, set empty string to find results.\n        # 1.0 is the key for fitting without a surround.\n        if lstRat[indRat] == 1.0:\n            strExpSve = ''\n        # Create full path names from nii file names and output path\n        lstPthNames = [strPathOut + strNii + strNmeExt + strExpSve + '.nii.gz'\n                       for strNii in lstNiiNames]\n        # Append list to list that contains nii names for all exponents\n        lstCmpRes.append(lstPthNames)\n\n    print('------Find ratio that yielded highest R2 per voxel')\n\n    # Initialize winner R2 map with R2 values from fit without surround\n    aryWnrR2 = load_nii(lstCmpRes[0][indPosR2])[0]\n    # Initialize ratio map with 1 where no-surround model was fit, otherwise 0\n    aryRatMap = np.zeros(aryWnrR2.shape)\n    aryRatMap[np.nonzero(aryWnrR2)] = 1.0\n\n    # Loop over R2 maps to establish which exponents wins\n    # Skip the first ratio, since this is the reference ratio (no surround)\n    # and is reflected already in the initialized arrays - aryWnrR2 & aryRatMap\n    for indRat, lstMaps in zip(lstRat[1:], lstCmpRes[1:]):\n        # Load R2 map for this particular exponent\n        aryTmpR2 = load_nii(lstMaps[indPosR2])[0]\n        # Load beta values for this particular exponent\n        aryTmpBetas = load_nii(lstMaps[indPosBetas])[0]\n        # Get logical that tells us where current R2 map is greater than\n        # previous ones\n        aryLgcWnr = np.greater(aryTmpR2, aryWnrR2)\n        # Get logical that tells us where the beta parameter estimate for the\n        # centre is positive and the estimate for the surround is negative\n        aryLgcCtrSur1 = np.logical_and(np.greater(aryTmpBetas[..., 0], 0.0),\n                                       np.less(aryTmpBetas[..., 1], 0.0))\n        # Get logical that tells us where the absolute beta parameter estimate\n        # for the surround is less than beta parameter estimate for the center\n        aryLgcCtrSur2 = np.less(np.abs(aryTmpBetas[..., 1]),\n                                np.abs(aryTmpBetas[..., 0]))\n        # Combine the two logicals\n        aryLgcCtrSur = np.logical_and(aryLgcCtrSur1, aryLgcCtrSur2)\n        # Combine logical for winner R2 and center-surround conditions\n        aryLgcWnr = np.logical_and(aryLgcWnr, aryLgcCtrSur)\n        # Replace values of R2, where current R2 map was greater\n        aryWnrR2[aryLgcWnr] = np.copy(aryTmpR2[aryLgcWnr])\n        # Remember the index of the exponent that gave rise to this new R2\n        aryRatMap[aryLgcWnr] = indRat\n\n    # Initialize list with winner maps. The winner maps are initialized with\n    # the same shape as the maps that the last tested ratio maps had.\n    lstRatMap = []\n    for strPthMaps in lstCmpRes[-1]:\n        lstRatMap.append(np.zeros(nb.load(strPthMaps).shape))\n\n    # Compose other maps by assigning map value from the map that resulted from\n    # the exponent that won for particular voxel\n    for indRat, lstMaps in zip(lstRat, lstCmpRes):\n        # Find out where this exponent won in terms of R2\n        lgcWinnerMap = [aryRatMap == indRat][0]\n        # Loop over all the maps\n        for indMap, _ in enumerate(lstMaps):\n            # Load map for this particular ratio\n            aryTmpMap = load_nii(lstMaps[indMap])[0]\n            # Handle exception: beta map will be 1D, if from ratio 1.0\n            # In this case we want to make it 2D. In particular, the second\n            # set of beta weights should be all zeros, so that later when\n            # forming the model time course, the 2nd predictors contributes 0\n            if indRat == 1.0 and indMap == indPosBetas:\n                aryTmpMap = np.concatenate((aryTmpMap,\n                                            np.zeros(aryTmpMap.shape)),\n                                           axis=-1)\n            # Load current winner map from array\n            aryCrrWnrMap = np.copy(lstRatMap[indMap])\n            # Assign values in temporary map to current winner map for voxels\n            # where this ratio won\n            aryCrrWnrMap[lgcWinnerMap] = np.copy(aryTmpMap[lgcWinnerMap])\n            lstRatMap[indMap] = aryCrrWnrMap\n\n    print('------Export results as nii')\n\n    # Save winner maps as nii files\n    # Get header and affine array\n    hdrMsk, aryAff = load_nii(lstMaps[indPosR2])[1:]\n    # Loop over all the maps\n    for indMap, aryMap in enumerate(lstRatMap):\n        # Create nii object for results:\n        niiOut = nb.Nifti1Image(aryMap,\n                                aryAff,\n                                header=hdrMsk\n                                )\n        # Save nii:\n        strTmp = strPathOut + '_supsur' + lstNiiNames[indMap] + strNmeExt + \\\n            '.nii.gz'\n        nb.save(niiOut, strTmp)\n\n    # Save map with best ratios as nii\n    niiOut = nb.Nifti1Image(aryRatMap,\n                            aryAff,\n                            header=hdrMsk\n                            )\n    # Save nii:\n    strTmp = strPathOut + '_supsur' + '_Ratios' + strNmeExt + '.nii.gz'\n    nb.save(niiOut, strTmp)\n\n    if lgcSveMdlTc:\n        print('------Save model time courses/parameters/responses for ' +\n              'centre and surround, across all ratios')\n    \n        # Get the names of the npy files with inbetween model responses\n        lstCmpMdlRsp = []\n        for indRat in range(len(lstRat)):\n            # Get strExpSve\n            strExpSve = '_' + str(lstRat[indRat])\n            # If ratio is marked with 0, set empty string to find results.\n            # This is the code for fitting without a surround.\n            if lstRat[indRat] == 1.0:\n                strExpSve = ''\n            # Create full path names from npy file names and output path\n            lstPthNames = [strPathMdl + strNpy + strNmeExt + strExpSve + '.npy'\n                           for strNpy in ['', '_params', '_mdlRsp']]\n            # Append list to list that contains nii names for all exponents\n            lstCmpMdlRsp.append(lstPthNames)\n    \n        # Load tc/parameters/responses for different ratios, for now skip \"0.0\"\n        # ratio because its tc/parameters/responses differs in shape\n        lstPrfTcSur = []\n        lstMdlParamsSur = []\n        lstMdlRspSur = []\n        for indNpy, lstNpy in enumerate(lstCmpMdlRsp[1:]):\n            lstPrfTcSur.append(np.load(lstNpy[0]))\n            lstMdlParamsSur.append(np.load(lstNpy[1]))\n            lstMdlRspSur.append(np.load(lstNpy[2]))\n        # Turn into arrays\n        aryPrfTcSur = np.stack(lstPrfTcSur, axis=2)\n        aryMdlParamsSur = np.stack(lstMdlParamsSur, axis=2)\n        aryMdlRspSur = np.stack(lstMdlRspSur, axis=2)\n    \n        # Now handle the \"1.0\" ratio\n        # Load the tc/parameters/responses of the \"1.0\" ratio\n        aryPrfTc = np.load(lstCmpMdlRsp[0][0])\n        aryMdlParams = np.load(lstCmpMdlRsp[0][1])\n        aryMdlRsp = np.load(lstCmpMdlRsp[0][2])\n        # Make 2nd row of time courses all zeros so they get no weight in lstsq\n        aryPrfTc = np.concatenate((aryPrfTc, np.zeros(aryPrfTc.shape)), axis=1)\n        # Make 2nd row of parameters the same as first row\n        aryMdlParams = np.stack((aryMdlParams, aryMdlParams), axis=1)\n        # Make 2nd row of responses all zeros so they get no weight in lstsq\n        aryMdlRsp = np.stack((aryMdlRsp, np.zeros(aryMdlRsp.shape)), axis=1)\n        # Add the \"1.0\" ratio to tc/parameters/responses of other ratios\n        aryPrfTcSur = np.concatenate((np.expand_dims(aryPrfTc, axis=2),\n                                      aryPrfTcSur), axis=2)\n        aryMdlParamsSur = np.concatenate((np.expand_dims(aryMdlParams, axis=2),\n                                         aryMdlParamsSur), axis=2)\n        aryMdlRspSur = np.concatenate((np.expand_dims(aryMdlRsp, axis=2),\n                                      aryMdlRspSur), axis=2)\n    \n        # Save parameters/response for centre and surround, for all ratios\n        np.save(strPathMdl + '_supsur' + '', aryPrfTcSur)\n        np.save(strPathMdl + '_supsur' + '_params', aryMdlParamsSur)\n        np.save(strPathMdl + '_supsur' + '_mdlRsp', aryMdlRspSur)\n\n    # Delete all the inbetween results, if desired by user, skip \"0.0\" ratio\n    if lgcDel:\n        lstCmpRes = [item for sublist in lstCmpRes[1:] for item in sublist]\n        print('------Delete in-between results')\n        for strMap in lstCmpRes[:]:\n            os.remove(strMap)\n        if lgcSveMdlTc:\n            lstCmpMdlRsp = [item for sublist in lstCmpMdlRsp[1:] for item in\n                            sublist]\n            for strMap in lstCmpMdlRsp[:]:\n                os.remove(strMap)", "response": "Compare results for different exponents and create winner nii."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef map_crt_to_pol(aryXCrds, aryYrds):\n\n    aryRad = np.sqrt(aryXCrds**2+aryYrds**2)\n    aryTht = np.arctan2(aryYrds, aryXCrds)\n\n    return aryTht, aryRad", "response": "Remap coordinates from cartesian to polar"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning index of nearest expected polar angle.", "response": "def find_near_pol_ang(aryEmpPlrAng, aryExpPlrAng):\n    \"\"\"Return index of nearest expected polar angle.\n\n    Parameters\n    ----------\n    aryEmpPlrAng : 1D numpy array\n        Empirically found polar angle estimates\n    aryExpPlrAng : 1D numpy array\n        Theoretically expected polar angle estimates\n\n    Returns\n    -------\n    aryXCrds : 1D numpy array\n        Indices of nearest theoretically expected polar angle.\n    aryYrds : 1D numpy array\n        Distances to nearest theoretically expected polar angle.\n    \"\"\"\n\n    dist = np.abs(np.subtract(aryEmpPlrAng[:, None],\n                              aryExpPlrAng[None, :]))\n\n    return np.argmin(dist, axis=-1), np.min(dist, axis=-1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rmp_rng(aryVls, varNewMin, varNewMax, varOldThrMin=None,\n            varOldAbsMax=None):\n    \"\"\"Remap values in an array from one range to another.\n\n    Parameters\n    ----------\n    aryVls : 1D numpy array\n        Array with values that need to be remapped.\n    varNewMin : float\n        Desired minimum value of new, remapped array.\n    varNewMax : float\n        Desired maximum value of new, remapped array.\n    varOldThrMin : float\n        Theoretical minimum of old distribution. Can be specified if this\n        theoretical minimum does not occur in empirical distribution but\n        should be considered nontheless.\n    varOldThrMin : float\n        Theoretical maximum of old distribution. Can be specified if this\n        theoretical maximum does not occur in empirical distribution but\n        should be considered nontheless.\n\n    Returns\n    -------\n    aryVls : 1D numpy array\n        Array with remapped values.\n    \"\"\"\n    if varOldThrMin is None:\n        varOldMin = aryVls.min()\n    else:\n        varOldMin = varOldThrMin\n    if varOldAbsMax is None:\n        varOldMax = aryVls.max()\n    else:\n        varOldMax = varOldAbsMax\n\n    aryNewVls = np.empty((aryVls.shape), dtype=aryVls.dtype)\n    for ind, val in enumerate(aryVls):\n        aryNewVls[ind] = (((val - varOldMin) * (varNewMax - varNewMin)) /\n                          (varOldMax - varOldMin)) + varNewMin\n\n    return aryNewVls", "response": "Remap values in an array from one range to another."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses a new revision and detect a revert if it occurred.", "response": "def process(self, checksum, revision=None):\n        \"\"\"\n        Process a new revision and detect a revert if it occurred.  Note that\n        you can pass whatever you like as `revision` and it will be returned in\n        the case that a revert occurs.\n\n        :Parameters:\n            checksum : str\n                Any identity-machable string-based hash of revision content\n            revision : `mixed`\n                Revision metadata.  Note that any data will just be returned\n                in the case of a revert.\n\n        :Returns:\n            a :class:`~mwreverts.Revert` if one occured or `None`\n        \"\"\"\n        revert = None\n\n        if checksum in self:  # potential revert\n\n            reverteds = list(self.up_to(checksum))\n\n            if len(reverteds) > 0:  # If no reverted revisions, this is a noop\n                revert = Revert(revision, reverteds, self[checksum])\n\n        self.insert(checksum, revision)\n        return revert"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply spatial smoothing to the input data.", "response": "def funcSmthSpt(aryFuncChnk, varSdSmthSpt):\n    \"\"\"Apply spatial smoothing to the input data.\n\n    Parameters\n    ----------\n    aryFuncChnk : np.array\n        TODO\n    varSdSmthSpt : float (?)\n        Extent of smoothing.\n    Returns\n    -------\n    aryFuncChnk : np.array\n        Smoothed data.\n    \"\"\"\n    varNdim = aryFuncChnk.ndim\n\n    # Number of time points in this chunk:\n    varNumVol = aryFuncChnk.shape[-1]\n\n    # Loop through volumes:\n    if varNdim == 4:\n        for idxVol in range(0, varNumVol):\n\n            aryFuncChnk[:, :, :, idxVol] = gaussian_filter(\n                aryFuncChnk[:, :, :, idxVol],\n                varSdSmthSpt,\n                order=0,\n                mode='nearest',\n                truncate=4.0)\n    elif varNdim == 5:\n        varNumMtnDrctns = aryFuncChnk.shape[3]\n        for idxVol in range(0, varNumVol):\n            for idxMtn in range(0, varNumMtnDrctns):\n                aryFuncChnk[:, :, :, idxMtn, idxVol] = gaussian_filter(\n                    aryFuncChnk[:, :, :, idxMtn, idxVol],\n                    varSdSmthSpt,\n                    order=0,\n                    mode='nearest',\n                    truncate=4.0)\n\n    # Output list:\n    return aryFuncChnk"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef funcSmthTmp(aryFuncChnk, varSdSmthTmp):\n    # For the filtering to perform well at the ends of the time series, we\n    # set the method to 'nearest' and place a volume with mean intensity\n    # (over time) at the beginning and at the end.\n    aryFuncChnkMean = np.mean(aryFuncChnk,\n                              axis=1,\n                              keepdims=True)\n\n    aryFuncChnk = np.concatenate((aryFuncChnkMean,\n                                  aryFuncChnk,\n                                  aryFuncChnkMean), axis=1)\n\n    # In the input data, time goes from left to right. Therefore, we apply\n    # the filter along axis=1.\n    aryFuncChnk = gaussian_filter1d(aryFuncChnk,\n                                    varSdSmthTmp,\n                                    axis=1,\n                                    order=0,\n                                    mode='nearest',\n                                    truncate=4.0)\n\n    # Remove mean-intensity volumes at the beginning and at the end:\n    aryFuncChnk = aryFuncChnk[:, 1:-1]\n\n    # Output list:\n    return aryFuncChnk", "response": "Apply temporal smoothing to fMRI data & pRF time course models."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prep_models(aryPrfTc, varSdSmthTmp=2.0, lgcPrint=True):\n    if lgcPrint:\n        print('------Prepare pRF time course models')\n\n    # Define temporal smoothing of pRF time course models\n    def funcSmthTmp(aryPrfTc, varSdSmthTmp, lgcPrint=True):\n        \"\"\"Apply temporal smoothing to fMRI data & pRF time course models.\n\n        Parameters\n        ----------\n        aryPrfTc : np.array\n            4D numpy array with pRF time course models, with following\n            dimensions: `aryPrfTc[x-position, y-position, SD, volume]`.\n        varSdSmthTmp : float, positive\n            Extent of temporal smoothing that is applied to functional data and\n            pRF time course models, [SD of Gaussian kernel, in seconds]. If\n            `zero`, no temporal smoothing is applied.\n        lgcPrint : boolean\n            Whether print statements should be executed.\n\n        Returns\n        -------\n        aryPrfTc : np.array\n            4D numpy array with prepared pRF time course models, same dimension\n            as input (`aryPrfTc[x-position, y-position, SD, volume]`).\n        \"\"\"\n\n        # adjust the input, if necessary, such that input is 2D, with last\n        # dim time\n        tplInpShp = aryPrfTc.shape\n        aryPrfTc = aryPrfTc.reshape((-1, aryPrfTc.shape[-1]))\n\n        # For the filtering to perform well at the ends of the time series, we\n        # set the method to 'nearest' and place a volume with mean intensity\n        # (over time) at the beginning and at the end.\n        aryPrfTcMean = np.mean(aryPrfTc, axis=-1, keepdims=True).reshape(-1, 1)\n\n        aryPrfTc = np.concatenate((aryPrfTcMean, aryPrfTc, aryPrfTcMean),\n                                  axis=-1)\n\n        # In the input data, time goes from left to right. Therefore, we apply\n        # the filter along axis=1.\n        aryPrfTc = gaussian_filter1d(aryPrfTc.astype('float32'), varSdSmthTmp,\n                                     axis=-1, order=0, mode='nearest',\n                                     truncate=4.0)\n\n        # Remove mean-intensity volumes at the beginning and at the end:\n        aryPrfTc = aryPrfTc[..., 1:-1]\n\n        # Output array:\n        return aryPrfTc.reshape(tplInpShp).astype('float16')\n\n    # Perform temporal smoothing of pRF time course models\n    if 0.0 < varSdSmthTmp:\n        if lgcPrint:\n            print('---------Temporal smoothing on pRF time course models')\n            print('------------SD tmp smooth is: ' + str(varSdSmthTmp))\n        aryPrfTc = funcSmthTmp(aryPrfTc, varSdSmthTmp)\n\n    # Z-score the prf time course models\n    if lgcPrint:\n        print('---------Zscore the pRF time course models')\n    # De-mean the prf time course models:\n    aryPrfTc = np.subtract(aryPrfTc, np.mean(aryPrfTc, axis=-1)[..., None])\n\n    # Standardize the prf time course models:\n    # In order to avoid devision by zero, only divide those voxels with a\n    # standard deviation greater than zero:\n    aryTmpStd = np.std(aryPrfTc, axis=-1)\n    aryTmpLgc = np.greater(aryTmpStd, np.array([0.0]))\n    aryPrfTc[aryTmpLgc, :] = np.divide(aryPrfTc[aryTmpLgc, :],\n                                       aryTmpStd[aryTmpLgc, None])\n\n    return aryPrfTc", "response": "Prepare pRF time courses and pRF model time courses."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload & prepare functional data for a specific nii file.", "response": "def prep_func(strPathNiiMask, lstPathNiiFunc, varAvgThr=100.,\n              varVarThr=0.0001, strPrePro='demean'):\n    \"\"\"\n    Load & prepare functional data.\n\n    Parameters\n    ----------\n    strPathNiiMask: str\n        Path to mask used to restrict pRF model finding. Only voxels with\n        a value greater than zero in the mask are considered.\n    lstPathNiiFunc : list\n        List of paths of functional data (nii files).\n    varAvgThr : float, positive, default = 100.\n        Float. Voxels that have at least one run with a mean lower than this\n        (before demeaning) will be excluded from model fitting.\n    varVarThr : float, positive, default = 0.0001\n        Float. Voxels that have at least one run with a variance lower than\n        this (after demeaning) will be excluded from model fitting.\n    strPrePro : string, default 'demean'\n        Preprocessing that will be applied to the data.\n        By default they are demeaned.\n\n    Returns\n    -------\n    aryLgcMsk : np.array\n        3D numpy array with logial values. Externally supplied mask (e.g grey\n        matter mask). Voxels that are `False` in the mask are excluded.\n    vecLgcIncl : np.array\n        1D numpy array containing logical values. One value per voxel after\n        mask has been applied. If `True`, the variance and mean of the voxel's\n        time course are greater than the provided thresholds in all runs and\n        the voxel is included in the output array (`aryFunc`). If `False`, the\n        variance or mean of the voxel's time course is lower than threshold in\n        at least one run and the voxel has been excluded from the output\n        (`aryFunc`). This is to avoid problems in the subsequent model fitting.\n        This array is necessary to put results into original dimensions after\n        model fitting.\n    hdrMsk : nibabel-header-object\n        Nii header of mask.\n    aryAff : np.array\n        Array containing 'affine', i.e. information about spatial positioning\n        of mask nii data.\n    aryFunc : np.array\n        2D numpy array containing prepared functional data, of the form\n        aryFunc[voxelCount, time].\n    tplNiiShp : tuple\n        Spatial dimensions of input nii data (number of voxels in x, y, z\n        direction). The data are reshaped during preparation, this\n        information is needed to fit final output into original spatial\n        dimensions.\n\n    Notes\n    -----\n    Functional data is loaded from disk. The functional data is reshaped, into\n    the form aryFunc[voxel, time]. A mask is applied (externally supplied, e.g.\n    a grey matter mask). Subsequently, the functional data is de-meaned.\n    \"\"\"\n    print('------Load & prepare nii data')\n\n    # Load mask (to restrict model fitting):\n    aryMask, hdrMsk, aryAff = load_nii(strPathNiiMask)\n\n    # Mask is loaded as float32, but is better represented as integer:\n    aryMask = np.array(aryMask).astype(np.int16)\n\n    # Number of non-zero voxels in mask:\n    # varNumVoxMsk = int(np.count_nonzero(aryMask))\n\n    # Dimensions of nii data:\n    tplNiiShp = aryMask.shape\n\n    # Total number of voxels:\n    varNumVoxTlt = (tplNiiShp[0] * tplNiiShp[1] * tplNiiShp[2])\n\n    # Reshape mask:\n    aryMask = np.reshape(aryMask, varNumVoxTlt)\n\n    # List for arrays with functional data (possibly several runs):\n    lstFunc = []\n\n    # List for averages of the individual runs (before demeaning)\n    lstFuncAvg = []\n\n    # List for variances of the individual runs (after demeaning)\n    lstFuncVar = []\n\n    # Number of runs:\n    varNumRun = len(lstPathNiiFunc)\n\n    # Loop through runs and load data:\n    for idxRun in range(varNumRun):\n\n        print(('---------Prepare run ' + str(idxRun + 1)))\n\n        # Load 4D nii data:\n        aryTmpFunc, _, _ = load_nii(lstPathNiiFunc[idxRun])\n\n        # Dimensions of nii data (including temporal dimension; spatial\n        # dimensions need to be the same for mask & functional data):\n        tplNiiShp = aryTmpFunc.shape\n\n        # Reshape functional nii data, from now on of the form\n        # aryTmpFunc[voxelCount, time]:\n        aryTmpFunc = np.reshape(aryTmpFunc, [varNumVoxTlt, tplNiiShp[3]])\n\n        # Apply mask:\n        print('------------Mask')\n        aryLgcMsk = np.greater(aryMask.astype(np.int16),\n                               np.array([0], dtype=np.int16)[0])\n        aryTmpFunc = aryTmpFunc[aryLgcMsk, :]\n\n        # save the mean of the run\n        lstFuncAvg.append(np.mean(aryTmpFunc, axis=1, dtype=np.float32))\n\n        # also save the variance of the run\n        lstFuncVar.append(np.var(aryTmpFunc, axis=1, dtype=np.float32))\n\n        # De-mean functional data:\n        if strPrePro == 'demean':\n            print('------------Demean')\n            aryTmpFunc = np.subtract(aryTmpFunc,\n                                     np.mean(aryTmpFunc,\n                                             axis=1,\n                                             dtype=np.float32)[:, None])\n        elif strPrePro == 'zscore':\n            print('------------Zscore')\n            aryTmpFunc = np.subtract(aryTmpFunc,\n                                     np.mean(aryTmpFunc,\n                                             axis=1,\n                                             dtype=np.float32)[:, None])\n\n            # Standardize the data time courses:\n            # In order to avoid devision by zero, only divide\n            # those voxels with a standard deviation greater\n            # than zero:\n            aryTmpStd = np.std(aryTmpFunc, axis=-1)\n            aryTmpLgc = np.greater(aryTmpStd, np.array([0.0]))\n            aryTmpFunc[aryTmpLgc, :] = np.divide(aryTmpFunc[aryTmpLgc, :],\n                                                 aryTmpStd[aryTmpLgc, None])\n\n        # Put prepared functional data of current run into list:\n        lstFunc.append(aryTmpFunc)\n        del(aryTmpFunc)\n\n    # Put functional data from separate runs into one array. 2D array of the\n    # form aryFunc[voxelCount, time]\n    aryFunc = np.concatenate(lstFunc, axis=1).astype(np.float32, copy=False)\n    del(lstFunc)\n\n    # Put the averages (before demeaning) from the separate runs into one\n    # array. 2D array of the form aryFuncVar[voxelCount, nr of runs]\n    aryFuncAvg = np.stack(lstFuncAvg, axis=1).astype(np.float32, copy=False)\n    del(lstFuncAvg)\n\n    # Put the variance (after demeaning) from the separate runs into one array.\n    # 2D array of the form aryFuncVar[voxelCount, nr of runs]\n    aryFuncVar = np.stack(lstFuncVar, axis=1).astype(np.float32, copy=False)\n    del(lstFuncVar)\n\n    # Especially if data were recorded in different sessions, there can\n    # sometimes be voxels that have close to zero signal in runs from one\n    # session but regular signal in the runs from another session. These voxels\n    # are very few, are located at the edge of the functional and can cause\n    # problems during model fitting. They are therefore excluded.\n\n    # Is the mean greater than threshold?\n    aryLgcAvg = np.greater(aryFuncAvg,\n                           np.array([varAvgThr]).astype(np.float32)[0])\n    # Mean needs to be greater than threshold in every single run\n    vecLgcAvg = np.all(aryLgcAvg, axis=1)\n\n    # Voxels that are outside the brain and have no, or very little, signal\n    # should not be included in the pRF model finding. We take the variance\n    # over time and exclude voxels with a suspiciously low variance, if they\n    # have low variance in at least one run. Because the data given into the\n    # cython or GPU function has float32 precision, we calculate the variance\n    # on data with float32 precision.\n\n    # Is the variance greater than threshold?\n    aryLgcVar = np.greater(aryFuncVar,\n                           np.array([varVarThr]).astype(np.float32)[0])\n    # Variance needs to be greater than threshold in every single run\n    vecLgcVar = np.all(aryLgcVar, axis=1)\n\n    # Are there any nan values in the functional time series?\n    vecLgcNan = np.invert(np.any(np.isnan(aryFunc), axis=1))\n\n    # combine the logical vectors for exclusion resulting from low variance and\n    # low mean signal time course\n    vecLgcIncl = np.logical_and(vecLgcAvg, vecLgcVar)\n\n    # combine logical vectors for mean/variance with vector for nan exclsion\n    vecLgcIncl = np.logical_and(vecLgcIncl, vecLgcNan)\n\n    # Array with functional data for which conditions (mask inclusion and\n    # cutoff value) are fullfilled:\n    aryFunc = aryFunc[vecLgcIncl, :]\n\n    # print info about the exclusion of voxels\n    print('---------Minimum mean threshold for voxels applied at: ' +\n          str(varAvgThr))\n    print('---------Minimum variance threshold for voxels applied at:  ' +\n          str(varVarThr))\n    print('---------Number of voxels excluded due to low mean or variance: ' +\n          str(np.sum(np.invert(vecLgcIncl))))\n\n    return aryLgcMsk, vecLgcIncl, hdrMsk, aryAff, aryFunc, tplNiiShp"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self,style):\n        level = len(self.stack) -1\n        while level >= 0:\n            if style in self.stack[level]:\n                return self.stack[level][style]\n            else:\n                level = level - 1\n        return None", "response": "what s the value of a style at the current stack level"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enforce_type(self, attr, val):\n        if not attr in self.types:\n            return utfstr(val)\n        elif self.types[attr] == 'int':\n            return int(float(val))\n        elif self.types[attr] == 'float':\n            return float(val)\n        else:\n            return utfstr(val)", "response": "converts a value to the attribute s type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npush a new level on the stack with a style dictionnary containing style : value pairs", "response": "def push(self, style={}):\n        \"\"\"push a new level on the stack with a style dictionnary containing style:value pairs\"\"\"\n        _style = {}\n        for attr in style:\n            if attr in self.cmds and not style[attr] in self.cmds[attr]:\n                print 'WARNING: ESC/POS PRINTING: ignoring invalid value: '+utfstr(style[attr])+' for style: '+utfstr(attr)\n            else:\n                _style[attr] = self.enforce_type(attr, style[attr])\n        self.stack.append(_style)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set(self, style={}):\n        _style = {}\n        for attr in style:\n            if attr in self.cmds and not style[attr] in self.cmds[attr]:\n                print 'WARNING: ESC/POS PRINTING: ignoring invalid value: '+utfstr(style[attr])+' for style: '+utfstr(attr)\n            else:\n                self.stack[-1][attr] = self.enforce_type(attr, style[attr])", "response": "overrides style values at the current stack level"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the current style to an escpos command string", "response": "def to_escpos(self):\n        \"\"\" converts the current style to an escpos command string \"\"\"\n        cmd = ''\n        ordered_cmds = self.cmds.keys()\n        ordered_cmds.sort(lambda x,y: cmp(self.cmds[x]['_order'], self.cmds[y]['_order']))\n        for style in ordered_cmds:\n            cmd += self.cmds[style][self.get(style)]\n        return cmd"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_inline(self,stylestack=None):\n        self.stack.append('inline')\n        if self.dirty:\n            self.escpos._raw(' ')\n        if stylestack:\n            self.style(stylestack)", "response": "starts an inline entity with an optional style definition"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_block(self,stylestack=None):\n        if self.dirty:\n            self.escpos._raw('\\n')\n            self.dirty = False\n        self.stack.append('block')\n        if stylestack:\n            self.style(stylestack)", "response": "starts a block entity with an optional style definition"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef end_entity(self):\n        if self.stack[-1] == 'block' and self.dirty:\n            self.escpos._raw('\\n')\n            self.dirty = False\n        if len(self.stack) > 1:\n            self.stack = self.stack[:-1]", "response": "Ends the entity definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nputs a string of text in the entity keeping the whitespace intact", "response": "def pre(self,text):\n        \"\"\" puts a string of text in the entity keeping the whitespace intact \"\"\"\n        if text:\n            self.escpos.text(text)\n            self.dirty = True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef text(self,text):\n        if text:\n            text = utfstr(text)\n            text = text.strip()\n            text = re.sub('\\s+',' ',text)\n            if text:\n                self.dirty = True\n                self.escpos.text(text)", "response": "puts text in the entity. Whitespace and newlines are stripped to single spaces."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck and fix the size of the image to 32 bits", "response": "def _check_image_size(self, size):\n        \"\"\" Check and fix the size of the image to 32 bits \"\"\"\n        if size % 32 == 0:\n            return (0, 0)\n        else:\n            image_border = 32 - (size % 32)\n            if (image_border % 2) == 0:\n                return (image_border / 2, image_border / 2)\n            else:\n                return (image_border / 2, (image_border / 2) + 1)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing image and prepare it to a printable format", "response": "def _convert_image(self, im):\n        \"\"\" Parse image and prepare it to a printable format \"\"\"\n        pixels   = []\n        pix_line = \"\"\n        im_left  = \"\"\n        im_right = \"\"\n        switch   = 0\n        img_size = [ 0, 0 ]\n\n\n        if im.size[0] > 512:\n            print  \"WARNING: Image is wider than 512 and could be truncated at print time \"\n        if im.size[1] > 255:\n            raise ImageSizeError()\n\n        im_border = self._check_image_size(im.size[0])\n        for i in range(im_border[0]):\n            im_left += \"0\"\n        for i in range(im_border[1]):\n            im_right += \"0\"\n\n        for y in range(im.size[1]):\n            img_size[1] += 1\n            pix_line += im_left\n            img_size[0] += im_border[0]\n            for x in range(im.size[0]):\n                img_size[0] += 1\n                RGB = im.getpixel((x, y))\n                im_color = (RGB[0] + RGB[1] + RGB[2])\n                im_pattern = \"1X0\"\n                pattern_len = len(im_pattern)\n                switch = (switch - 1 ) * (-1)\n                for x in range(pattern_len):\n                    if im_color <= (255 * 3 / pattern_len * (x+1)):\n                        if im_pattern[x] == \"X\":\n                            pix_line += \"%d\" % switch\n                        else:\n                            pix_line += im_pattern[x]\n                        break\n                    elif im_color > (255 * 3 / pattern_len * pattern_len) and im_color <= (255 * 3):\n                        pix_line += im_pattern[-1]\n                        break \n            pix_line += im_right\n            img_size[0] += im_border[1]\n\n        return (pix_line, img_size)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef image(self,path_img):\n        im_open = Image.open(path_img)\n        im = im_open.convert(\"RGB\")\n        # Convert the RGB image in printable image\n        pix_line, img_size = self._convert_image(im)\n        self._print_image(pix_line, img_size)", "response": "Open image file and print it in printable image"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints QR Code for the provided string", "response": "def qr(self,text):\n        \"\"\" Print QR Code for the provided string \"\"\"\n        qr_code = qrcode.QRCode(version=4, box_size=4, border=1)\n        qr_code.add_data(text)\n        qr_code.make(fit=True)\n        qr_img = qr_code.make_image()\n        im = qr_img._img.convert(\"RGB\")\n        # Convert the RGB image in printable image\n        self._convert_image(im)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef receipt(self,xml):\n\n        def strclean(string):\n            if not string:\n                string = ''\n            string = string.strip()\n            string = re.sub('\\s+',' ',string)\n            return string\n\n        def format_value(value, decimals=3, width=0, decimals_separator='.', thousands_separator=',', autoint=False, symbol='', position='after'):\n            decimals = max(0,int(decimals))\n            width    = max(0,int(width))\n            value    = float(value)\n\n            if autoint and math.floor(value) == value:\n                decimals = 0\n            if width == 0:\n                width = ''\n\n            if thousands_separator:\n                formatstr = \"{:\"+str(width)+\",.\"+str(decimals)+\"f}\"\n            else:\n                formatstr = \"{:\"+str(width)+\".\"+str(decimals)+\"f}\"\n\n\n            ret = formatstr.format(value)\n            ret = ret.replace(',','COMMA')\n            ret = ret.replace('.','DOT')\n            ret = ret.replace('COMMA',thousands_separator)\n            ret = ret.replace('DOT',decimals_separator)\n\n            if symbol:\n                if position == 'after':\n                    ret = ret + symbol\n                else:\n                    ret = symbol + ret\n            return ret\n\n        def print_elem(stylestack, serializer, elem, indent=0):\n\n            elem_styles = {\n                'h1': {'bold': 'on', 'size':'double'},\n                'h2': {'size':'double'},\n                'h3': {'bold': 'on', 'size':'double-height'},\n                'h4': {'size': 'double-height'},\n                'h5': {'bold': 'on'},\n                'em': {'font': 'b'},\n                'b':  {'bold': 'on'},\n            }\n\n            stylestack.push()\n            if elem.tag in elem_styles:\n                stylestack.set(elem_styles[elem.tag])\n            stylestack.set(elem.attrib)\n\n            if elem.tag in ('p','div','section','article','receipt','header','footer','li','h1','h2','h3','h4','h5'):\n                serializer.start_block(stylestack)\n                serializer.text(elem.text)\n                for child in elem:\n                    print_elem(stylestack,serializer,child)\n                    serializer.start_inline(stylestack)\n                    serializer.text(child.tail)\n                    serializer.end_entity()\n                serializer.end_entity()\n\n            elif elem.tag in ('span','em','b','left','right'):\n                serializer.start_inline(stylestack)\n                serializer.text(elem.text)\n                for child in elem:\n                    print_elem(stylestack,serializer,child)\n                    serializer.start_inline(stylestack)\n                    serializer.text(child.tail)\n                    serializer.end_entity()\n                serializer.end_entity()\n\n            elif elem.tag == 'value':\n                serializer.start_inline(stylestack)\n                serializer.pre(format_value( \n                                              elem.text,\n                                              decimals=stylestack.get('value-decimals'),\n                                              width=stylestack.get('value-width'),\n                                              decimals_separator=stylestack.get('value-decimals-separator'),\n                                              thousands_separator=stylestack.get('value-thousands-separator'),\n                                              autoint=(stylestack.get('value-autoint') == 'on'),\n                                              symbol=stylestack.get('value-symbol'),\n                                              position=stylestack.get('value-symbol-position') \n                                            ))\n                serializer.end_entity()\n\n            elif elem.tag == 'line':\n                width = stylestack.get('width')\n                if stylestack.get('size') in ('double', 'double-width'):\n                    width = width / 2\n\n                lineserializer = XmlLineSerializer(stylestack.get('indent')+indent,stylestack.get('tabwidth'),width,stylestack.get('line-ratio'))\n                serializer.start_block(stylestack)\n                for child in elem:\n                    if child.tag == 'left':\n                        print_elem(stylestack,lineserializer,child,indent=indent)\n                    elif child.tag == 'right':\n                        lineserializer.start_right()\n                        print_elem(stylestack,lineserializer,child,indent=indent)\n                serializer.pre(lineserializer.get_line())\n                serializer.end_entity()\n\n            elif elem.tag == 'ul':\n                serializer.start_block(stylestack)\n                bullet = stylestack.get('bullet')\n                for child in elem:\n                    if child.tag == 'li':\n                        serializer.style(stylestack)\n                        serializer.raw(' ' * indent * stylestack.get('tabwidth') + bullet)\n                    print_elem(stylestack,serializer,child,indent=indent+1)\n                serializer.end_entity()\n\n            elif elem.tag == 'ol':\n                cwidth = len(str(len(elem))) + 2\n                i = 1\n                serializer.start_block(stylestack)\n                for child in elem:\n                    if child.tag == 'li':\n                        serializer.style(stylestack)\n                        serializer.raw(' ' * indent * stylestack.get('tabwidth') + ' ' + (str(i)+')').ljust(cwidth))\n                        i = i + 1\n                    print_elem(stylestack,serializer,child,indent=indent+1)\n                serializer.end_entity()\n\n            elif elem.tag == 'pre':\n                serializer.start_block(stylestack)\n                serializer.pre(elem.text)\n                serializer.end_entity()\n\n            elif elem.tag == 'hr':\n                width = stylestack.get('width')\n                if stylestack.get('size') in ('double', 'double-width'):\n                    width = width / 2\n                serializer.start_block(stylestack)\n                serializer.text('-'*width)\n                serializer.end_entity()\n\n            elif elem.tag == 'br':\n                serializer.linebreak()\n\n            elif elem.tag == 'img':\n                if 'src' in elem.attrib and 'data:' in elem.attrib['src']:\n                    self.print_base64_image(elem.attrib['src'])\n\n            elif elem.tag == 'barcode' and 'encoding' in elem.attrib:\n                serializer.start_block(stylestack)\n                self.barcode(strclean(elem.text),elem.attrib['encoding'])\n                serializer.end_entity()\n\n            elif elem.tag == 'cut':\n                self.cut()\n            elif elem.tag == 'partialcut':\n                self.cut(mode='part')\n            elif elem.tag == 'cashdraw':\n                self.cashdraw(2)\n                self.cashdraw(5)\n\n            stylestack.pop()\n\n        try:\n            stylestack      = StyleStack() \n            serializer      = XmlSerializer(self)\n            root            = ET.fromstring(xml.encode('utf-8'))\n            if 'sheet' in root.attrib and root.attrib['sheet'] == 'slip':\n                self._raw(SHEET_SLIP_MODE)\n                self.slip_sheet_mode = True\n            else:\n                self._raw(SHEET_ROLL_MODE)\n\n            self._raw(stylestack.to_escpos())\n\n            print_elem(stylestack,serializer,root)\n\n            if 'open-cashdrawer' in root.attrib and root.attrib['open-cashdrawer'] == 'true':\n                self.cashdraw(2)\n                self.cashdraw(5)\n            if not 'cut' in root.attrib or root.attrib['cut'] == 'true' :\n                if self.slip_sheet_mode:\n                    self._raw(CTL_FF)\n                else:\n                    self.cut()\n\n        except Exception as e:\n            errmsg = str(e)+'\\n'+'-'*48+'\\n'+traceback.format_exc() + '-'*48+'\\n'\n            self.text(errmsg)\n            self.cut()\n\n            raise e", "response": "Prints an xml based receipt definition"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef text(self,txt):\n        if not txt:\n            return\n        try:\n            txt = txt.decode('utf-8')\n        except:\n            try:\n                txt = txt.decode('utf-16')\n            except:\n                pass\n\n        self.extra_chars = 0\n        \n        def encode_char(char):  \n            \"\"\" \n            Encodes a single utf-8 character into a sequence of \n            esc-pos code page change instructions and character declarations \n            \"\"\" \n            char_utf8 = char.encode('utf-8')\n            encoded  = ''\n            encoding = self.encoding # we reuse the last encoding to prevent code page switches at every character\n            encodings = {\n                    # TODO use ordering to prevent useless switches\n                    # TODO Support other encodings not natively supported by python ( Thai, Khazakh, Kanjis )\n                    'cp437': TXT_ENC_PC437,\n                    'cp850': TXT_ENC_PC850,\n                    'cp852': TXT_ENC_PC852,\n                    'cp857': TXT_ENC_PC857,\n                    'cp858': TXT_ENC_PC858,\n                    'cp860': TXT_ENC_PC860,\n                    'cp863': TXT_ENC_PC863,\n                    'cp865': TXT_ENC_PC865,\n                    'cp866': TXT_ENC_PC866,\n                    'cp862': TXT_ENC_PC862,\n                    'cp720': TXT_ENC_PC720,\n                    'cp936': TXT_ENC_PC936,\n                    'iso8859_2': TXT_ENC_8859_2,\n                    'iso8859_7': TXT_ENC_8859_7,\n                    'iso8859_9': TXT_ENC_8859_9,\n                    'cp1254'   : TXT_ENC_WPC1254,\n                    'cp1255'   : TXT_ENC_WPC1255,\n                    'cp1256'   : TXT_ENC_WPC1256,\n                    'cp1257'   : TXT_ENC_WPC1257,\n                    'cp1258'   : TXT_ENC_WPC1258,\n                    'katakana' : TXT_ENC_KATAKANA,\n            }\n            remaining = copy.copy(encodings)\n\n            if not encoding :\n                encoding = 'cp437'\n\n            while True: # Trying all encoding until one succeeds\n                try:\n                    if encoding == 'katakana': # Japanese characters\n                        if jcconv:\n                            # try to convert japanese text to a half-katakanas \n                            kata = jcconv.kata2half(jcconv.hira2kata(char_utf8))\n                            if kata != char_utf8:\n                                self.extra_chars += len(kata.decode('utf-8')) - 1\n                                # the conversion may result in multiple characters\n                                return encode_str(kata.decode('utf-8')) \n                        else:\n                             kata = char_utf8\n                        \n                        if kata in TXT_ENC_KATAKANA_MAP:\n                            encoded = TXT_ENC_KATAKANA_MAP[kata]\n                            break\n                        else: \n                            raise ValueError()\n                    else:\n                        encoded = char.encode(encoding)\n                        break\n\n                except ValueError: #the encoding failed, select another one and retry\n                    if encoding in remaining:\n                        del remaining[encoding]\n                    if len(remaining) >= 1:\n                        encoding = remaining.items()[0][0]\n                    else:\n                        encoding = 'cp437'\n                        encoded  = '\\xb1'    # could not encode, output error character\n                        break;\n\n            if encoding != self.encoding:\n                # if the encoding changed, remember it and prefix the character with\n                # the esc-pos encoding change sequence\n                self.encoding = encoding\n                encoded = encodings[encoding] + encoded\n\n            return encoded\n        \n        def encode_str(txt):\n            buffer = ''\n            for c in txt:\n                buffer += encode_char(c)\n            return buffer\n\n        txt = encode_str(txt)\n\n        # if the utf-8 -> codepage conversion inserted extra characters, \n        # remove double spaces to try to restore the original string length\n        # and prevent printing alignment issues\n        while self.extra_chars > 0: \n            dspace = txt.find('  ')\n            if dspace > 0:\n                txt = txt[:dspace] + txt[dspace+1:]\n                self.extra_chars -= 1\n            else:\n                break\n\n        self._raw(txt)", "response": "Print Unicode encoded alpha - numeric text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncutting the log entry for a given entry.", "response": "def cut(self, mode=''):\n        \"\"\" Cut paper \"\"\"\n        # Fix the size between last line and cut\n        # TODO: handle this with a line feed\n        self._raw(\"\\n\\n\\n\\n\\n\\n\")\n        if mode.upper() == \"PART\":\n            self._raw(PAPER_PART_CUT)\n        else: # DEFAULT MODE: FULL CUT\n            self._raw(PAPER_FULL_CUT)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cashdraw(self, pin):\n        if pin == 2:\n            self._raw(CD_KICK_2)\n        elif pin == 5:\n            self._raw(CD_KICK_5)\n        else:\n            raise CashDrawerError()", "response": "Send pulse to kick the cash drawer"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef open(self):\n        \n        self.device = usb.core.find(idVendor=self.idVendor, idProduct=self.idProduct)\n        if self.device is None:\n            raise NoDeviceError()\n        try:\n            if self.device.is_kernel_driver_active(self.interface):\n                self.device.detach_kernel_driver(self.interface) \n            self.device.set_configuration()\n            usb.util.claim_interface(self.device, self.interface)\n        except usb.core.USBError as e:\n            raise HandleDeviceError(e)", "response": "Open USB tree and set is as escpos device"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _raw(self, msg):\n        if len(msg) != self.device.write(self.out_ep, msg, self.interface):\n            self.device.write(self.out_ep, self.errorText, self.interface)\n            raise TicketNotPrinted()", "response": "Print any command sent in raw format"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef open(self):\n        self.device = serial.Serial(port=self.devfile, baudrate=self.baudrate, bytesize=self.bytesize, parity=serial.PARITY_NONE, stopbits=serial.STOPBITS_ONE, timeout=self.timeout, dsrdtr=True)\n\n        if self.device is not None:\n            print \"Serial printer enabled\"\n        else:\n            print \"Unable to open serial printer on: %s\" % self.devfile", "response": "Open the device and set it as escpos device"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening TCP socket and set it as escpos device", "response": "def open(self):\n        \"\"\" Open TCP socket and set it as escpos device \"\"\"\n        self.device = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.device.connect((self.host, self.port))\n\n        if self.device is None:\n            print \"Could not open socket for %s\" % self.host"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a list of Pinyin characters for a given set of characters.", "response": "def _pinyin_generator(chars, format):\n    \"\"\"Generate pinyin for chars, if char is not chinese character,\n    itself will be returned.\n    Chars must be unicode list.\n    \"\"\"\n    for char in chars:\n        key = \"%X\" % ord(char)\n        pinyin = pinyin_dict.get(key, char)\n        tone = pinyin_tone.get(key, 0)\n\n        if tone == 0 or format == \"strip\":\n            pass\n        elif format == \"numerical\":\n            pinyin += str(tone)\n        elif format == \"diacritical\":\n            # Find first vowel -- where we should put the diacritical mark\n            vowels = itertools.chain((c for c in pinyin if c in \"aeo\"),\n                                     (c for c in pinyin if c in \"iuv\"))\n            vowel = pinyin.index(next(vowels)) + 1\n            pinyin = pinyin[:vowel] + tonemarks[tone] + pinyin[vowel:]\n        else:\n            error = \"Format must be one of: numerical/diacritical/strip\"\n            raise ValueError(error)\n\n        yield unicodedata.normalize('NFC', pinyin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(s, delimiter='', format=\"diacritical\"):\n    return delimiter.join(_pinyin_generator(u(s), format=format))", "response": "Return pinyin of string"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the 1st char of pinyin of string", "response": "def get_initial(s, delimiter=' '):\n    \"\"\"Return the 1st char of pinyin of string, the string must be unicode\n    \"\"\"\n    initials = (p[0] for p in _pinyin_generator(u(s), format=\"strip\"))\n    return delimiter.join(initials)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a word to the tree.", "response": "def _add_to_tree(tree, word, meaning):\n    '''\n    We build word search trees, where we walk down\n    the letters of a word. For example:\n      \u4f60 Good\n      \u4f60\u597d Hello\n    Would build the tree\n         \u4f60\n        /  \\\n      You   \u597d\n             \\\n           Hello\n    '''\n    if len(word) == 0:\n        tree[''] = meaning\n    else:\n        _add_to_tree(tree[word[0]], word[1:], meaning)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading in the Chinese - English dictionary. This takes 1 - 2 seconds. It is done when other functions are used.", "response": "def init():\n    '''\n    Load in the Chinese-English dictionary. This takes 1-2 seconds. It\n    is done when the other functions are used, but this is public since\n    preloading sometimes makes sense.\n    '''\n    global dictionaries, trees\n\n    dictionaries = {\n        'traditional': {},\n        'simplified': {}\n    }\n\n    trees = {\n        'traditional': Tree(),\n        'simplified': Tree()\n    }\n\n    lines = gzip.open(\n        os.path.join(os.path.dirname(__file__), \"cedict.txt.gz\"),\n        mode='rt',\n        encoding='utf-8'\n    )\n    exp = re.compile(\"^([^ ]+) ([^ ]+) \\[(.*)\\] /(.+)/\")\n    parsed_lines = (exp.match(line).groups()\n                    for line in lines\n                    if line[0] != '#')\n\n    for traditional, simplified, pinyin, meaning in parsed_lines:\n        meaning = meaning.split('/')\n        dictionaries['traditional'][traditional] = meaning\n        dictionaries['simplified'][simplified] = meaning\n        _add_to_tree(trees['traditional'], traditional, meaning)\n        _add_to_tree(trees['simplified'], simplified, meaning)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntranslates a single character or word into a set of translations.", "response": "def translate_word(word, dictionary=['simplified']):\n    '''\n    Return the set of translations for a single character or word, if\n    available.\n    '''\n    if not dictionaries:\n        init()\n    for d in dictionary:\n        if word in dictionaries[d]:\n            return dictionaries[d][word]\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _words_at_the_beginning(word, tree, prefix=\"\"):\n    '''\n    We return all portions of the tree corresponding to the beginning\n    of `word`. This is used recursively, so we pass the prefix so we\n    can return meaningful words+translations.\n    '''\n    l = []\n    if \"\" in tree:\n        l.append([prefix, tree[\"\"]])\n    if len(word) > 0 and word[0] in tree:\n        l.extend(_words_at_the_beginning(\n            word[1:],\n            tree[word[0]],\n            prefix=prefix+word[0]\n        ))\n    return l", "response": "Returns all words in the tree corresponding to the beginning of the word."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef all_phrase_translations(phrase):\n    '''\n    Return the set of translations for all possible words in a full\n    phrase. Chinese is sometimes ambiguous. We do not attempt to\n    disambiguate, or handle unknown letters especially well. Full\n    parsing is left to upstream logic.\n    '''\n    if not trees:\n        init()\n    phrase = phrase.split(string.whitespace)\n    for word in phrase:\n        for x in range(len(word)):\n            for translation in _words_at_the_beginning(\n                    word[x+1:],\n                    trees['simplified'][word[x]],\n                    prefix=word[x]):\n                yield translation", "response": "Yields all possible translations for all possible words in a full\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a key used to set a status on a field", "response": "def get_status_key(self, instance):\n        \"\"\"Generates a key used to set a status on a field\"\"\"\n        key_id = \"inst_%s\" % id(instance) if instance.pk is None else instance.pk\n        return \"%s.%s-%s-%s\" % (instance._meta.app_label,\n                                get_model_name(instance),\n                                key_id,\n                                self.field.name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_status(self, instance):\n        status_key, status = self._get_status(instance)\n        if status['state'] in ['complete', 'error']:\n            cache.delete(status_key)\n        return status", "response": "Retrives a status of a field from cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the status of the given instance in the cache.", "response": "def set_status(self, instance, status):\n        \"\"\"Sets the field status for up to 5 minutes.\"\"\"\n        status_key = self.get_status_key(instance)\n        cache.set(status_key, status, timeout=300)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_mode(self, old_mode=None):\n        if self.mode is not None:\n            return self.mode\n        assert self.can_write, \"This format does not have a supported output mode.\"\n        if old_mode is None:\n            return self.output_modes[0]\n        if old_mode in self.output_modes:\n            return old_mode\n        # now let's get best mode available from supported\n        try:\n            idx = PILLOW_MODES.index(old_mode)\n        except ValueError:\n            # maybe some unknown or uncommon mode\n            return self.output_modes[0]\n        for mode in PILLOW_MODES[idx+1:]:\n            if mode in self.output_modes:\n                return mode\n        # since there is no better one, lets' look for closest one in opposite direction\n        opposite = PILLOW_MODES[:idx]\n        opposite.reverse()\n        for mode in opposite:\n            if mode in self.output_modes:\n                return mode", "response": "Returns output mode. If mode is not set it will try to guess best mode from old mode and if it is not available."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the token present at the cursor position in the code buffer.", "response": "def token_at_cursor(code, pos=0):\n    \"\"\"\n    Find the token present at the passed position in the code buffer\n     :return (tuple): a pair (token, start_position)\n    \"\"\"\n    l = len(code)\n    end = start = pos\n    # Go forwards while we get alphanumeric chars\n    while end < l and code[end].isalpha():\n        end += 1\n    # Go backwards while we get alphanumeric chars\n    while start > 0 and code[start-1].isalpha():\n        start -= 1\n    # If previous character is a %, add it (potential magic)\n    if start > 0 and code[start-1] == '%':\n        start -= 1\n    return code[start:end], start"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _send(self, data, msg_type='ok', silent=False):\n        # Data to send back\n        if data is not None:\n            # log the message\n            try:\n                self._klog.debug(u\"msg to frontend (%d): %.160s...\", silent, data)\n            except Exception as e:\n                self._klog.warn(u\"can't log response: %s\", e)\n            # send it to the frontend\n            if not silent:\n                if msg_type != 'raw':\n                    data = data_msg(data, mtype=msg_type)\n                self.send_response(self.iopub_socket, 'display_data', data)\n\n        # Result message\n        return {'status': 'error' if msg_type == 'error' else 'ok',\n                # The base class will increment the execution count\n                'execution_count': self.execution_count,\n                'payload': [],\n                'user_expressions': {}\n                }", "response": "Send a response to the frontend and return an execute message\n        "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_execute(self, code, silent, store_history=True,\n                   user_expressions=None, allow_stdin=False):\n        \"\"\"\n        Method called to execute a cell\n        \"\"\"\n        self._klog.info(\"[%.30s] [%d] [%s]\", code, silent, user_expressions)\n\n        # Split lines and remove empty lines & comments\n        code_noc = [line.strip() for line in code.split('\\n')\n                    if line and line[0] != '#']\n        if not code_noc:\n            return self._send(None)\n\n        # Process\n        try:\n            # Detect if we've got magics\n            magic_lines = []\n            for line in code_noc:\n                if line[0] != '%':\n                    break\n                magic_lines.append(line)\n\n            # Process magics. Once done, remove them from the query buffer\n            if magic_lines:\n                out = [self._k.magic(line) for line in magic_lines]\n                self._send(out, 'multi', silent=silent)\n                code = '\\n'.join(code_noc[len(magic_lines):])\n\n            # If we have a regular SPARQL query, process it now\n            result = self._k.query(code, num=self.execution_count) if code else None\n\n            # Return the result\n            return self._send(result, 'raw', silent=silent)\n\n        except Exception as e:\n            return self._send(e, 'error', silent=silent)", "response": "Execute a cell and return the result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef escape( x, lb=False ):\n    # Insert a linebreak? Roughly around the middle of the string,\n    if lb:\n        l = len(x)\n        if l >= 10:\n            l >>= 1                     # middle of the string\n            s1 = x.find( ' ', l )       # first ws to the right\n            s2 = x.rfind( ' ', 0, l )   # first ws to the left\n            if s2 > 0:\n                s = s2 if s1<0 or l-s1 > s2-l else s1\n                x = x[:s] + '\\\\n' + x[s+1:]\n            elif s1 > 0:\n                x = x[:s1] + '\\\\n' + x[s1+1:]\n    # Escape HTML reserved characters\n    return x.replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\").replace('\"', \"&quot;\")", "response": "Escape a string with HTML - reserved characters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef div( txt, *args, **kwargs ):\n    if args:\n        txt = txt.format( *args )\n    css = kwargs.get('css',HTML_DIV_CLASS)\n    return u'<div class=\"{}\">{!s}</div>'.format( css, txt )", "response": "Create & return an HTML div element by wrapping the passed text buffer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a Jupyter display_data message in both HTML & text formats by joining together all passed messages.", "response": "def data_msglist( msglist ):\n    \"\"\"\n    Return a Jupyter display_data message, in both HTML & text formats, by \n    joining together all passed messages.\n\n      @param msglist (iterable): an iterable containing a list of tuples\n        (message, css_style)      \n\n    Each message is either a text string, or a list. In the latter case it is\n    assumed to be a format string + parameters.\n    \"\"\"\n    txt = html = u''\n    for msg, css in msglist:\n        if is_collection(msg):\n            msg = msg[0].format(*msg[1:])\n        html += div( escape(msg).replace('\\n','<br/>'), css=css or 'msg' )\n        txt += msg + \"\\n\"\n    return { 'data': {'text/html' : div(html),\n                      'text/plain' : txt },\n             'metadata' : {} }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a Jupyter display_data message in both HTML & text formats by", "response": "def data_msg( msg, mtype=None ):\n    \"\"\"\n    Return a Jupyter display_data message, in both HTML & text formats, by \n    formatting a given single message. The passed message may be:\n      * An exception (including a KrnlException): will generate an error message\n      * A list of messages (with \\c mtype equal to \\c multi)\n      * A single message\n\n      @param msg (str,list): a string, or a list of format string + args,\n        or an iterable of (msg,mtype)\n      @param mtype (str): the message type (used for the CSS class). If\n        it's \\c multi, then \\c msg will be treated as a multi-message. If\n        not passed, \\c krn-error will be used for exceptions and \\c msg for\n        everything else\n    \"\"\"\n    if isinstance(msg,KrnlException):\n        return msg()    # a KrnlException knows how to format itself\n    elif isinstance(msg,Exception):\n        return KrnlException(msg)()\n    elif mtype == 'multi':\n        return data_msglist( msg )\n    else:\n        return data_msglist( [ (msg, mtype) ] )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncopying a resource file to a destination directory", "response": "def copyresource( resource, filename, destdir ):\n    \"\"\"\n    Copy a resource file to a destination\n    \"\"\"\n    data = pkgutil.get_data(resource, os.path.join('resources',filename) )\n    #log.info( \"Installing %s\", os.path.join(destdir,filename) )\n    with open( os.path.join(destdir,filename), 'wb' ) as fp:\n        fp.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef install_kernel_resources( destdir, resource=PKGNAME, files=None ):\n    if files is None:\n        files = ['logo-64x64.png', 'logo-32x32.png']\n    for filename in files:\n        try:\n            copyresource( resource, filename, destdir )\n        except Exception as e:\n            sys.stderr.write(str(e))", "response": "Copy the kernel resources to the kernelspec folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef install_custom_css( destdir, cssfile, resource=PKGNAME ):\n    ensure_dir_exists( destdir )\n    custom = os.path.join( destdir, 'custom.css' )\n    prefix = css_frame_prefix(resource)\n\n    # Check if custom.css already includes it. If so, let's remove it first\n    exists = False\n    if os.path.exists( custom ):\n        with io.open(custom) as f:\n            for line in f:\n                if line.find( prefix ) >= 0:\n                    exists = True\n                    break\n    if exists:\n        remove_custom_css( destdir, resource )\n\n    # Fetch the CSS file\n    cssfile += '.css'\n    data = pkgutil.get_data( resource, os.path.join('resources',cssfile) )\n    # get_data() delivers encoded data, str (Python2) or bytes (Python3)\n\n    # Add the CSS at the beginning of custom.css\n    # io.open uses unicode strings (unicode in Python2, str in Python3)\n    with io.open(custom + '-new', 'wt', encoding='utf-8') as fout:\n        fout.write( u'{}START ======================== */\\n'.format(prefix))\n        fout.write( data.decode('utf-8') )\n        fout.write( u'{}END ======================== */\\n'.format(prefix))\n        if os.path.exists( custom ):\n            with io.open( custom, 'rt', encoding='utf-8' ) as fin:\n                for line in fin:\n                    fout.write( unicode(line) )\n    os.rename( custom+'-new',custom)", "response": "Installs the kernel CSS file in the specified destination directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_custom_css(destdir, resource=PKGNAME ):\n\n    # Remove the inclusion in the main CSS\n    if not os.path.isdir( destdir ):\n        return False\n    custom = os.path.join( destdir, 'custom.css' )\n    copy = True\n    found = False\n    prefix = css_frame_prefix(resource)\n    with io.open(custom + '-new', 'wt') as fout:\n        with io.open(custom) as fin:\n            for line in fin:\n                if line.startswith( prefix + 'START' ):\n                    copy = False\n                    found = True\n                elif line.startswith( prefix + 'END' ):\n                    copy = True\n                elif copy:\n                    fout.write( line )\n\n    if found:\n        os.rename( custom+'-new',custom)\n    else:\n        os.unlink( custom+'-new')\n\n    return found", "response": "Remove the kernel CSS from custom. css"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nformatting a result element as an HTML table cell.", "response": "def html_elem(e, ct, withtype=False):\n    \"\"\"\n    Format a result element as an HTML table cell.\n      @param e (list): a pair \\c (value,type)\n      @param ct (str): cell type (th or td)\n      @param withtype (bool): add an additional cell with the element type\n    \"\"\"\n    # Header cell\n    if ct == 'th':\n        return '<th>{0}</th><th>{1}</th>'.format(*e) if withtype else '<th>{}</th>'.format(e)\n    # Content cell\n    if e[1] in ('uri', 'URIRef'):\n        html = u'<{0} class=val><a href=\"{1}\" target=\"_other\">{2}</a></{0}>'.format(ct, e[0], escape(e[0]))\n    else:\n        html = u'<{0} class=val>{1}</{0}>'.format(ct, escape(e[0]))\n    # Create the optional cell for the type\n    if withtype:\n        html += u'<{0} class=typ>{1}</{0}>'.format(ct, e[1])\n    return html"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef html_table(data, header=True, limit=None, withtype=False):\n    if header and limit:\n        limit += 1\n    ct = 'th' if header else 'td'\n    rc = 'hdr' if header else 'odd'\n\n    # import codecs\n    # import datetime\n    # with codecs.open( '/tmp/dump', 'w', encoding='utf-8') as f:\n    #     print( '************', datetime.datetime.now(), file=f )\n    #     for n, row in enumerate(data):\n    #         print( '-------', n,  file=f )\n    #         for n, c in enumerate(row):\n    #             print( type(c), repr(c), file=f )\n\n    html = u'<table>'\n    rn = -1\n    for rn, row in enumerate(data):\n        html += u'<tr class={}>'.format(rc)\n        html += '\\n'.join((html_elem(c, ct, withtype) for c in row))\n        html += u'</tr>'\n        rc = 'even' if rc == 'odd' else 'odd'\n        ct = 'td'\n        if limit:\n            limit -= 1\n            if not limit:\n                break\n    return (0, '') if rn < 0 else (rn+1-header, html+u'</table>')", "response": "Returns a double iterable as an HTML table."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef jtype(c):\n    ct = c['type']\n    return ct if ct != 'literal' else '{}, {}'.format(ct, c.get('xml:lang'))", "response": "Returns the data type of a value for JSON data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gtype(n):\n    t = type(n).__name__\n    return str(t) if t != 'Literal' else 'Literal, {}'.format(n.language)", "response": "Returns the data type of a value for Graph data\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lang_match_json(row, hdr, accepted_languages):\n    '''Find if the JSON row contains acceptable language data'''\n    if not accepted_languages:\n        return True\n    languages = set([row[c].get('xml:lang') for c in hdr\n                     if c in row and row[c]['type'] == 'literal'])\n    return (not languages) or (languages & accepted_languages)", "response": "Find if the JSON row contains acceptable language data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds if the RDF triple contains acceptable language data", "response": "def lang_match_rdf(triple, accepted_languages):\n    '''Find if the RDF triple contains acceptable language data'''\n    if not accepted_languages:\n        return True\n    languages = set([n.language for n in triple if isinstance(n, Literal)])\n    return (not languages) or (languages & accepted_languages)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lang_match_xml(row, accepted_languages):\n    '''Find if the XML row contains acceptable language data'''\n    if not accepted_languages:\n        return True\n    column_languages = set()\n    for elem in row:\n        lang = elem[0].attrib.get(XML_LANG, None)\n        if lang:\n            column_languages.add(lang)\n    return (not column_languages) or (column_languages & accepted_languages)", "response": "Find if the XML row contains acceptable language data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef json_iterator(hdr, rowlist, lang, add_vtype=False):\n    # Return the header row\n    yield hdr if not add_vtype else ((h, 'type') for h in hdr)\n    # Now the data rows\n    for row in rowlist:\n        if lang and not lang_match_json(row, hdr, lang):\n            continue\n        yield ((row[c]['value'], jtype(row[c])) if c in row else ('', '')\n               for c in hdr)", "response": "Convert a JSON response into a double iterable by rows and columns"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rdf_iterator(graph, lang, add_vtype=False):\n    # Return the header row\n    hdr = ('subject', 'predicate', 'object')\n    yield hdr if not add_vtype else ((h, 'type') for h in hdr)\n    # Now the data rows\n    for row in graph:\n        if lang and not lang_match_rdf(row, lang):\n            continue\n        yield ((unicode(c), gtype(c)) for c in row)", "response": "Convert a Graph response into a double iterable by triples and elements. lang - Language of the resource to be used. add_vtype - True to add type if not added to the header. lang - Language of the resource to be used to filter the data by language"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render_json(result, cfg, **kwargs):\n    result = json.loads(result.decode('utf-8'))\n    head = result['head']\n    if 'results' not in result:\n        if 'boolean' in result:\n            r = u'Result: {}'.format(result['boolean'])\n        else:\n            r = u'Unsupported result: \\n' + unicode(result)\n        return {'data': {'text/plain': r},\n                'metadata': {}}\n\n    vars = head['vars']\n    nrow = len(result['results']['bindings'])\n    if cfg.dis == 'table':\n        j = json_iterator(vars, result['results']['bindings'], set(cfg.lan),\n                          add_vtype=cfg.typ)\n        n, data = html_table(j, limit=cfg.lmt, withtype=cfg.typ)\n        data += div('Total: {}, Shown: {}', nrow, n, css=\"tinfo\")\n        data = {'text/html': div(data)}\n    else:\n        result = json.dumps(result,\n                            ensure_ascii=False, indent=2, sort_keys=True)\n        data = {'text/plain': unicode(result)}\n\n    return {'data': data,\n            'metadata': {}}", "response": "Render to output a result in JSON format\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting an XML response into a double iterable by rows and columns", "response": "def xml_iterator(columns, rowlist, lang, add_vtype=False):\n    \"\"\"\n    Convert an XML response into a double iterable, by rows and columns\n    Options are: filter triples by language (on literals), add element type\n    \"\"\"\n    # Return the header row\n    yield columns if not add_vtype else ((h, 'type') for h in columns)\n    # Now the data rows\n    for row in rowlist:\n        if not lang_match_xml(row, lang):\n            continue\n        rowdata = {nam: val for nam, val in xml_row(row, lang)}\n        yield (rowdata.get(field, ('', '')) for field in columns)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering to output a result in XML format", "response": "def render_xml(result, cfg, **kwargs):\n    \"\"\"\n    Render to output a result in XML format\n    \"\"\"\n    # Raw mode\n    if cfg.dis == 'raw':\n        return {'data': {'text/plain': result.decode('utf-8')},\n                'metadata': {}}\n    # Table\n    try:\n        import xml.etree.cElementTree as ET\n    except ImportError:\n        import xml.etree.ElementTree as ET\n    root = ET.fromstring(result)\n    try:\n        ns = {'ns': re.match(r'\\{([^}]+)\\}', root.tag).group(1)}\n    except Exception:\n        raise KrnlException('Invalid XML data: cannot get namespace')\n    columns = [c.attrib['name'] for c in root.find('ns:head', ns)]\n    results = root.find('ns:results', ns)\n    nrow = len(results)\n    j = xml_iterator(columns, results, set(cfg.lan), add_vtype=cfg.typ)\n    n, data = html_table(j, limit=cfg.lmt, withtype=cfg.typ)\n    data += div('Total: {}, Shown: {}', nrow, n, css=\"tinfo\")\n    return {'data': {'text/html': div(data)},\n            'metadata': {}}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_graph(result, cfg, **kwargs):\n    # Mapping from MIME types to formats accepted by RDFlib\n    rdflib_formats = {'text/rdf+n3': 'n3',\n                      'text/turtle': 'turtle',\n                      'application/x-turtle': 'turtle',\n                      'text/turtle': 'turtle',\n                      'application/rdf+xml': 'xml',\n                      'text/rdf': 'xml',\n                      'application/rdf+xml': 'xml'}\n\n\n    try:\n        got = kwargs.get('format', 'text/rdf+n3')\n        fmt = rdflib_formats[got]\n    except KeyError:\n        raise KrnlException('Unsupported format for graph processing: {!s}', got)\n\n    g = ConjunctiveGraph()\n    g.load(StringInputSource(result), format=fmt)\n\n    display = cfg.dis[0] if is_collection(cfg.dis) else cfg.dis\n    if display in ('png', 'svg'):\n        try:\n            literal = len(cfg.dis) > 1 and cfg.dis[1].startswith('withlit')\n            opt = {'lang': cfg.lan, 'literal': literal, 'graphviz': []}\n            data, metadata = draw_graph(g, fmt=display, options=opt)\n            return {'data': data,\n                    'metadata': metadata}\n        except Exception as e:\n            raise KrnlException('Exception while drawing graph: {!r}', e)\n    elif display == 'table':\n        it = rdf_iterator(g, set(cfg.lan), add_vtype=cfg.typ)\n        n, data = html_table(it, limit=cfg.lmt, withtype=cfg.typ)\n        data += div('Shown: {}, Total rows: {}', n if cfg.lmt else 'all',\n                    len(g), css=\"tinfo\")\n        data = {'text/html': div(data)}\n    elif len(g) == 0:\n        data = {'text/html': div(div('empty graph', css='krn-warn'))}\n    else:\n        data = {'text/plain': g.serialize(format='nt').decode('utf-8')}\n\n    return {'data': data,\n            'metadata': {}}", "response": "Render to output a result that can be parsed as an RDF graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef query(self, query, num=0, silent=False):\n        if self.srv is None:\n            raise KrnlException('no endpoint defined')\n\n        # Add to the query all predefined SPARQL prefixes\n        if self.cfg.pfx:\n            prefix = '\\n'.join(('PREFIX {} {}'.format(*v)\n                                for v in self.cfg.pfx.items()))\n            query = prefix + '\\n' + query\n\n        # Prepend to the query all predefined Header entries\n        # The header should be before the prefix and other sparql commands\n        if self.cfg.hdr:\n            query = '\\n'.join(self.cfg.hdr) + '\\n' + query\n\n        if self.log.isEnabledFor(logging.DEBUG):\n            self.log.debug(\"\\n%50s%s\", query, '...' if len(query) > 50 else '')\n\n        # Select requested format\n        if self.cfg.fmt is not None:\n            fmt_req = self.cfg.fmt\n        elif re.search(r'\\bselect\\b', query, re.I):\n            fmt_req = SPARQLWrapper.JSON\n        elif re.search(r'\\b(?:describe|construct)\\b', query, re.I):\n            fmt_req = SPARQLWrapper.N3\n        else:\n            fmt_req = False\n\n        # Set the query\n        self.srv.resetQuery()\n        if self.cfg.aut:\n            self.srv.setHTTPAuth(self.cfg.aut[0])\n            self.srv.setCredentials(*self.cfg.aut[1:])\n        else:\n            self.srv.setCredentials(None, None)\n        self.log.debug(u'request-format: %s  display: %s', fmt_req, self.cfg.dis)\n        if fmt_req:\n            self.srv.setReturnFormat(fmt_req)\n        if self.cfg.grh:\n            self.srv.addParameter(\"default-graph-uri\", self.cfg.grh)\n        for p in self.cfg.par.items():\n            self.srv.addParameter(*p)\n        self.srv.setQuery(query)\n\n        if not silent or self.cfg.out:\n            try:\n                # Launch query\n                start = datetime.datetime.utcnow()\n                res = self.srv.query()\n                now = datetime.datetime.utcnow()\n                self.log.debug(u'response elapsed=%s', now-start)\n                start = now\n\n                # See what we got\n                info = res.info()\n                self.log.debug(u'response info: %s', info)\n                fmt_got = info['content-type'].split(';')[0] if 'content-type' in info else None\n\n                # Check we received a MIME type according to what we requested\n                if fmt_req and fmt_got not in mime_type[fmt_req]:\n                    raise KrnlException(u'Unexpected response format: {} (requested: {})', fmt_got, fmt_req)\n\n                # Get the result\n                data = b''.join((line for line in res))\n\n            except KrnlException:\n                raise\n            except SPARQLWrapperException as e:\n                raise KrnlException(u'SPARQL error: {}', touc(e))\n            except Exception as e:\n                raise KrnlException(u'Query processing error: {!s}', e)\n\n            # Write the raw result to a file\n            if self.cfg.out:\n                try:\n                    outname = self.cfg.out % num\n                except TypeError:\n                    outname = self.cfg.out\n                with io.open(outname, 'wb') as f:\n                    f.write(data)\n\n            # Render the result into the desired display format\n            try:\n                # Data format we will render\n                fmt = (fmt_req if fmt_req else\n                       SPARQLWrapper.JSON if fmt_got in mime_type[SPARQLWrapper.JSON] else\n                       SPARQLWrapper.N3 if fmt_got in mime_type[SPARQLWrapper.N3] else\n                       SPARQLWrapper.XML if fmt_got in mime_type[SPARQLWrapper.XML] else\n                       'text/plain' if self.cfg.dis == 'raw' else\n                       fmt_got if fmt_got in ('text/plain', 'text/html') else\n                       'text/plain')\n                #self.log.debug(u'format: req=%s got=%s rend=%s',fmt_req,fmt_got,fmt)\n\n                # Can't process? Just write the data as is\n                if fmt in ('text/plain', 'text/html'):\n                    out = data.decode('utf-8') if isinstance(data, bytes) else data\n                    r = {'data': {fmt: out}, 'metadata': {}}\n                else:\n                    f = render_json if fmt == SPARQLWrapper.JSON else render_xml if fmt == SPARQLWrapper.XML else render_graph\n                    r = f(data, self.cfg, format=fmt_got)\n                    now = datetime.datetime.utcnow()\n                    self.log.debug(u'response formatted=%s', now-start)\n                if not silent:\n                    return r\n\n            except Exception as e:\n                raise KrnlException(u'Response processing error: {}', touc(e))", "response": "Launch an SPARQL query and process the results and return them"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_logging( logfilename=None, level=None ):\n    if logfilename is None:\n        # Find the logging diectory\n        logdir = os.environ.get( 'LOGDIR' )\n        if logdir is None:\n            logdir = os.environ.get( 'LOGDIR_DEFAULT', tempfile.gettempdir() )\n        # Define the log filename\n        basename = __name__.split('.')[-2]\n        logfilename = os.path.join( logdir, basename + '.log' )\n    LOGCONFIG['handlers']['default']['filename'] = logfilename\n\n    if level is not None:\n        LOGCONFIG['loggers']['sparqlkernel']['level'] = level\n\n    dictConfig( LOGCONFIG )", "response": "Set a logging configuration with a rolling file appender."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef smartfields_get_field_status(self, field_name):\n        manager = self._smartfields_managers.get(field_name, None)\n        if manager is not None:\n            return manager.get_status(self)\n        return {'state': 'ready'}", "response": "A way to find out a status of a filed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_ext(self, format=None, **kwargs):\n        try:\n            format = format or self.default_params['format']\n            return \".%s\" % format.lower()\n        except KeyError: pass", "response": "Returns new file extension based on a processor s format parameter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a temporary file.", "response": "def get_output_file(self, in_file, instance, field, **kwargs):\n        \"\"\"Creates a temporary file. With regular `FileSystemStorage` it does not \n        need to be deleted, instaed file is safely moved over. With other cloud\n        based storage it is a good idea to set `delete=True`.\"\"\"\n        return NamedTemporaryFile(mode='rb', suffix='_%s_%s%s' % (\n            get_model_name(instance), field.name, self.get_ext()), delete=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the best available label for the passed entity in the passed graph.", "response": "def label(x, gr, preferred_languages=None):\n    \"\"\"\n      @param x : graph entity\n      @param gr (Graph): RDF graph\n      @param preferred_languages (iterable)\n\n    Return the best available label in the graph for the passed entity.\n    If a set of preferred languages is given, try them in order. If none is\n    found, an arbitrary language will be chosen\n    \"\"\"\n    # Find all labels & their language\n    labels = { l.language : l\n               for labelProp in LABEL_PROPERTIES\n               for l in gr.objects(x,labelProp) }\n    if labels:\n        #return repr(preferred_languages) + repr(labels)\n        #return u'|'.join(preferred_languages) +  u' -> ' + u'/'.join( u'{}:{}'.format(*i) for i in labels.items() )\n        if preferred_languages is not None:\n            for l in preferred_languages:\n                if l in labels:\n                    return labels[l]\n        return labels.itervalues().next()\n\n    # No labels available. Try to generate a QNAME, or else, the string itself\n    try:\n        return gr.namespace_manager.compute_qname(x)[2].replace('_',' ')\n    except:\n        # Attempt to extract the trailing part of an URI\n        m = re.search( '([^/]+)$', x )\n        return m.group(1).replace('_',' ') if m else x"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the RDF graph to DOT format", "response": "def rdf2dot( g, stream, opts={} ):\n    \"\"\"\n    Convert the RDF graph to DOT\n    Write the dot output to the stream\n    \"\"\"\n\n    accept_lang = set( opts.get('lang',[]) )\n    do_literal = opts.get('literal')\n    nodes = {}\n    links = []\n\n    def node_id(x):\n        if x not in nodes:\n            nodes[x] = \"node%d\" % len(nodes)\n        return nodes[x]\n\n    def qname(x, g):\n        try:\n            q = g.compute_qname(x)\n            return q[0] + \":\" + q[2]\n        except:\n            return x\n\n    def accept( node ):\n        if isinstance( node, (rdflib.URIRef,rdflib.BNode) ):\n            return True\n        if not do_literal:\n            return False\n        return (not accept_lang) or (node.language in accept_lang)\n\n\n    stream.write( u'digraph { \\n node [ fontname=\"DejaVu Sans,Tahoma,Geneva,sans-serif\" ] ; \\n' )\n\n    # Write all edges. In the process make a list of all nodes\n    for s, p, o in g:\n        # skip triples for labels\n        if p == rdflib.RDFS.label:\n            continue\n\n        # Create a link if both objects are graph nodes\n        # (or, if literals are also included, if their languages match)\n        if not (accept(s) and accept(o)):\n            continue\n\n        # add the nodes to the list\n        sn = node_id(s)\n        on = node_id(o)\n\n        # add the link\n        q = qname(p,g)\n        if isinstance(p, rdflib.URIRef):\n            opstr = u'\\t%s -> %s [ arrowhead=\"open\", color=\"#9FC9E560\", fontsize=9, fontcolor=\"#204080\", label=\"%s\", href=\"%s\", target=\"_other\" ] ;\\n' % (sn,on,q,p)\n        else:\n            opstr = u'\\t%s -> %s [ arrowhead=\"open\", color=\"#9FC9E560\", fontsize=9, fontcolor=\"#204080\", label=\"%s\" ] ;\\n'%(sn,on,q)\n        stream.write( opstr )\n\n    # Write all nodes\n    for u, n in nodes.items():\n        lbl = escape( label(u,g,accept_lang), True )\n        if isinstance(u, rdflib.URIRef):\n            opstr = u'%s [ shape=none, fontsize=10, fontcolor=%s, label=\"%s\", href=\"%s\", target=_other ] \\n' % (n, 'blue', lbl, u )\n        else:\n            opstr = u'%s [ shape=none, fontsize=10, fontcolor=%s, label=\"%s\" ] \\n' % (n, 'black', lbl )\n        stream.write( u\"# %s %s\\n\" % (u, n) )\n        stream.write( opstr )\n\n    stream.write(u'}\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef draw_graph( g, fmt='svg', prg='dot', options={} ):\n    # Convert RDF to Graphviz\n    buf = StringIO()\n    rdf2dot( g, buf, options )\n\n    gv_options = options.get('graphviz',[])\n    if fmt == 'png':\n        gv_options += [ '-Gdpi=220', '-Gsize=25,10!' ]\n        metadata = { \"width\": 5500, \"height\": 2200, \"unconfined\" : True }\n\n    #import codecs\n    #with codecs.open('/tmp/sparqlkernel-img.dot','w',encoding='utf-8') as f:\n    #    f.write( buf.getvalue() )\n    \n    # Now use Graphviz to generate the graph\n    image = run_dot( buf.getvalue(), fmt=fmt, options=gv_options, prg=prg )\n\n    #with open('/tmp/sparqlkernel-img.'+fmt,'w') as f:\n    #    f.write( image )\n\n    # Return it\n    if fmt == 'png':\n        return { 'image/png' : base64.b64encode(image).decode('ascii') }, \\\n               { \"image/png\" : metadata }\n    elif fmt == 'svg':\n        return { 'image/svg+xml' : image.decode('utf-8').replace('<svg','<svg class=\"unconfined\"',1) }, \\\n               { \"unconfined\" : True }", "response": "Draw an RDF graph as an image\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_SZ(self, psd, geometry):\n        if (self._S_table is None) or (self._Z_table is None):\n            raise AttributeError(\n                \"Initialize or load the scattering table first.\")\n\n        if (not isinstance(psd, PSD)) or self._previous_psd != psd:\n            self._S_dict = {}\n            self._Z_dict = {}\n            psd_w = psd(self._psd_D)\n\n            for geom in self.geometries:\n                self._S_dict[geom] = \\\n                    trapz(self._S_table[geom] * psd_w, self._psd_D)\n                self._Z_dict[geom] = \\\n                    trapz(self._Z_table[geom] * psd_w, self._psd_D)\n\n            self._previous_psd = psd\n\n        return (self._S_dict[geometry], self._Z_dict[geometry])", "response": "Compute the S and Z matrices for the given PSD and geometries."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef init_scatter_table(self, tm, angular_integration=False, verbose=False):\n        self._psd_D = np.linspace(self.D_max/self.num_points, self.D_max, \n            self.num_points)\n\n        self._S_table = {}\n        self._Z_table = {}\n        self._previous_psd = None\n        self._m_table = np.empty(self.num_points, dtype=complex)\n        if angular_integration:\n            self._angular_table = {\"sca_xsect\": {}, \"ext_xsect\": {}, \n                \"asym\": {}}\n        else:\n            self._angular_table = None\n        \n        (old_m, old_axis_ratio, old_radius, old_geom, old_psd_integrator) = \\\n            (tm.m, tm.axis_ratio, tm.radius, tm.get_geometry(), \n                tm.psd_integrator)\n        \n        try:\n            # temporarily disable PSD integration to avoid recursion\n            tm.psd_integrator = None \n\n            for geom in self.geometries:\n                self._S_table[geom] = \\\n                    np.empty((2,2,self.num_points), dtype=complex)\n                self._Z_table[geom] = np.empty((4,4,self.num_points))\n\n                if angular_integration:\n                    for int_var in [\"sca_xsect\", \"ext_xsect\", \"asym\"]:\n                        self._angular_table[int_var][geom] = \\\n                            np.empty(self.num_points)\n\n            for (i,D) in enumerate(self._psd_D):\n                if verbose:\n                    print(\"Computing point {i} at D={D}...\".format(i=i, D=D))\n                if self.m_func != None:\n                    tm.m = self.m_func(D)\n                if self.axis_ratio_func != None:\n                    tm.axis_ratio = self.axis_ratio_func(D)\n                self._m_table[i] = tm.m\n                tm.radius = D/2.0\n                for geom in self.geometries:\n                    tm.set_geometry(geom)\n                    (S, Z) = tm.get_SZ_orient()\n                    self._S_table[geom][:,:,i] = S\n                    self._Z_table[geom][:,:,i] = Z\n\n                    if angular_integration:\n                        self._angular_table[\"sca_xsect\"][geom][i] = \\\n                            scatter.sca_xsect(tm)\n                        self._angular_table[\"ext_xsect\"][geom][i] = \\\n                            scatter.ext_xsect(tm)\n                        self._angular_table[\"asym\"][geom][i] = \\\n                            scatter.asym(tm)\n        finally:\n            #restore old values\n            (tm.m, tm.axis_ratio, tm.radius, tm.psd_integrator) = \\\n                (old_m, old_axis_ratio, old_radius, old_psd_integrator) \n            tm.set_geometry(old_geom)", "response": "Initialize the scattering lookup tables for the given object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_scatter_table(self, fn, description=\"\"):\n        data = {\n           \"description\": description,\n           \"time\": datetime.now(),\n           \"psd_scatter\": (self.num_points, self.D_max, self._psd_D, \n                self._S_table, self._Z_table, self._angular_table, \n                self._m_table, self.geometries),\n           \"version\": tmatrix_aux.VERSION\n           }\n        pickle.dump(data, file(fn, 'w'), pickle.HIGHEST_PROTOCOL)", "response": "Save the state of the scattering lookup tables to a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_scatter_table(self, fn):\n        data = pickle.load(file(fn))\n\n        if (\"version\" not in data) or (data[\"version\"]!=tmatrix_aux.VERSION):\n            warnings.warn(\"Loading data saved with another version.\", Warning)\n\n        (self.num_points, self.D_max, self._psd_D, self._S_table, \n            self._Z_table, self._angular_table, self._m_table, \n            self.geometries) = data[\"psd_scatter\"]\n        return (data[\"time\"], data[\"description\"])", "response": "Loads the scattering lookup tables from a file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gaussian_pdf(std=10.0, mean=0.0):\n    norm_const = 1.0\n    def pdf(x):\n        return norm_const*np.exp(-0.5 * ((x-mean)/std)**2) * \\\n            np.sin(np.pi/180.0 * x)\n    norm_dev = quad(pdf, 0.0, 180.0)[0]\n    # ensure that the integral over the distribution equals 1\n    norm_const /= norm_dev \n    return pdf", "response": "Returns the spherical Jacobian - edition standard deviation Gaussian PDF for orientation averaging."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuniform PDF for orientation averaging.", "response": "def uniform_pdf():\n    \"\"\"Uniform PDF for orientation averaging.\n\n    Returns:\n        pdf(x), a function that returns the value of the spherical Jacobian-\n        normalized uniform PDF. It is normalized for the interval [0, 180].\n    \"\"\"\n    norm_const = 1.0\n    def pdf(x):\n        return norm_const * np.sin(np.pi/180.0 * x)\n    norm_dev = quad(pdf, 0.0, 180.0)[0]\n    # ensure that the integral over the distribution equals 1\n    norm_const /= norm_dev \n    return pdf"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the T - matrix using variable orientation scatterers.", "response": "def orient_averaged_adaptive(tm):\n    \"\"\"Compute the T-matrix using variable orientation scatterers.\n    \n    This method uses a very slow adaptive routine and should mainly be used\n    for reference purposes. Uses the set particle orientation PDF, ignoring\n    the alpha and beta attributes.\n\n    Args:\n        tm: TMatrix (or descendant) instance\n\n    Returns:\n        The amplitude (S) and phase (Z) matrices.\n    \"\"\"\n    S = np.zeros((2,2), dtype=complex)\n    Z = np.zeros((4,4))\n\n    def Sfunc(beta, alpha, i, j, real):\n        (S_ang, Z_ang) = tm.get_SZ_single(alpha=alpha, beta=beta)\n        s = S_ang[i,j].real if real else S_ang[i,j].imag            \n        return s * tm.or_pdf(beta)\n\n    ind = range(2)\n    for i in ind:\n        for j in ind:\n            S.real[i,j] = dblquad(Sfunc, 0.0, 360.0, \n                lambda x: 0.0, lambda x: 180.0, (i,j,True))[0]/360.0        \n            S.imag[i,j] = dblquad(Sfunc, 0.0, 360.0, \n                lambda x: 0.0, lambda x: 180.0, (i,j,False))[0]/360.0\n\n    def Zfunc(beta, alpha, i, j):\n        (S_and, Z_ang) = tm.get_SZ_single(alpha=alpha, beta=beta)\n        return Z_ang[i,j] * tm.or_pdf(beta)\n\n    ind = range(4)\n    for i in ind:\n        for j in ind:\n            Z[i,j] = dblquad(Zfunc, 0.0, 360.0, \n                lambda x: 0.0, lambda x: 180.0, (i,j))[0]/360.0\n\n    return (S, Z)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the T - matrix using variable orientation scatterers.", "response": "def orient_averaged_fixed(tm):\n    \"\"\"Compute the T-matrix using variable orientation scatterers.\n    \n    This method uses a fast Gaussian quadrature and is suitable\n    for most use. Uses the set particle orientation PDF, ignoring\n    the alpha and beta attributes.\n\n    Args:\n        tm: TMatrix (or descendant) instance.\n\n    Returns:\n        The amplitude (S) and phase (Z) matrices.\n    \"\"\"\n    S = np.zeros((2,2), dtype=complex)\n    Z = np.zeros((4,4))\n    ap = np.linspace(0, 360, tm.n_alpha+1)[:-1]\n    aw = 1.0/tm.n_alpha\n\n    for alpha in ap:\n        for (beta, w) in zip(tm.beta_p, tm.beta_w):\n            (S_ang, Z_ang) = tm.get_SZ_single(alpha=alpha, beta=beta)\n            S += w * S_ang\n            Z += w * Z_ang\n\n    sw = tm.beta_w.sum()\n    #normalize to get a proper average\n    S *= aw/sw\n    Z *= aw/sw\n\n    return (S, Z)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _init_tmatrix(self):\n\n        if self.radius_type == Scatterer.RADIUS_MAXIMUM:\n            # Maximum radius is not directly supported in the original\n            # so we convert it to equal volume radius\n            radius_type = Scatterer.RADIUS_EQUAL_VOLUME\n            radius = self.equal_volume_from_maximum()\n        else:\n            radius_type = self.radius_type\n            radius = self.radius\n\n        self.nmax = pytmatrix.calctmat(radius, radius_type,\n            self.wavelength, self.m.real, self.m.imag, self.axis_ratio,\n            self.shape, self.ddelt, self.ndgs)\n        self._tm_signature = (self.radius, self.radius_type, self.wavelength,\n            self.m, self.axis_ratio, self.shape, self.ddelt, self.ndgs)", "response": "Initialize the T - matrix."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _init_orient(self):\n        if self.orient == orientation.orient_averaged_fixed:\n            (self.beta_p, self.beta_w) = quadrature.get_points_and_weights(\n                self.or_pdf, 0, 180, self.n_beta)\n        self._set_orient_signature()", "response": "Retrieve the quadrature points and weights if needed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_scatter_signature(self):\n        self._scatter_signature = (self.thet0, self.thet, self.phi0, self.phi,\n            self.alpha, self.beta, self.orient)", "response": "Mark the amplitude and scattering matrices as up to date."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_SZ_single(self, alpha=None, beta=None):\n        if alpha == None:\n            alpha = self.alpha\n        if beta == None:\n            beta = self.beta\n\n        tm_outdated = self._tm_signature != (self.radius, self.radius_type, \n            self.wavelength, self.m, self.axis_ratio, self.shape, self.ddelt, \n            self.ndgs)\n        if tm_outdated:\n            self._init_tmatrix()\n\n        scatter_outdated = self._scatter_signature != (self.thet0, self.thet, \n            self.phi0, self.phi, alpha, beta, self.orient)\n\n        outdated = tm_outdated or scatter_outdated\n\n        if outdated:\n            (self._S_single, self._Z_single) = pytmatrix.calcampl(self.nmax, \n                self.wavelength, self.thet0, self.thet, self.phi0, self.phi, \n                alpha, beta)\n            self._set_scatter_signature()\n\n        return (self._S_single, self._Z_single)", "response": "Get the S and Z matrices for a single orientation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the S and Z matrices using the specified orientation averaging.", "response": "def get_SZ_orient(self):\n        \"\"\"Get the S and Z matrices using the specified orientation averaging.\n        \"\"\"\n\n        tm_outdated = self._tm_signature != (self.radius, self.radius_type, \n            self.wavelength, self.m, self.axis_ratio, self.shape, self.ddelt, \n            self.ndgs)\n        scatter_outdated = self._scatter_signature != (self.thet0, self.thet, \n            self.phi0, self.phi, self.alpha, self.beta, self.orient)\n\n        orient_outdated = self._orient_signature != \\\n            (self.orient, self.or_pdf, self.n_alpha, self.n_beta)\n        if orient_outdated:\n            self._init_orient()\n        \n        outdated = tm_outdated or scatter_outdated or orient_outdated\n\n        if outdated:\n            (self._S_orient, self._Z_orient) = self.orient(self)\n            self._set_scatter_signature()\n\n        return (self._S_orient, self._Z_orient)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_SZ(self):\n        if self.psd_integrator is None:\n            (self._S, self._Z) = self.get_SZ_orient()\n        else:\n            scatter_outdated = self._scatter_signature != (self.thet0, \n                self.thet, self.phi0, self.phi, self.alpha, self.beta, \n                self.orient)            \n            psd_outdated = self._psd_signature != (self.psd,)\n            outdated = scatter_outdated or psd_outdated\n\n            if outdated:\n                (self._S, self._Z) = self.psd_integrator(self.psd, \n                    self.get_geometry())\n                self._set_scatter_signature()\n                self._set_psd_signature()\n\n        return (self._S, self._Z)", "response": "Get the S and Z matrices using the current parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nscatter intensity for the current setup.", "response": "def sca_intensity(scatterer, h_pol=True):\n    \"\"\"Scattering intensity (phase function) for the current setup.    \n\n    Args:\n        scatterer: a Scatterer instance.\n        h_pol: If True (default), use horizontal polarization.\n        If False, use vertical polarization.\n\n    Returns:\n        The differential scattering cross section.\n    \"\"\"\n    Z = scatterer.get_Z()\n    return (Z[0,0] - Z[0,1]) if h_pol else (Z[0,0] + Z[0,1])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nscatter cross section for the current setup with polarization.", "response": "def sca_xsect(scatterer, h_pol=True):\n    \"\"\"Scattering cross section for the current setup, with polarization.    \n\n    Args:\n        scatterer: a Scatterer instance.\n        h_pol: If True (default), use horizontal polarization.\n        If False, use vertical polarization.\n\n    Returns:\n        The scattering cross section.\n    \"\"\"\n\n    if scatterer.psd_integrator is not None:\n        return scatterer.psd_integrator.get_angular_integrated(\n            scatterer.psd, scatterer.get_geometry(), \"sca_xsect\")\n\n    old_geom = scatterer.get_geometry()    \n\n    def d_xsect(thet, phi):\n        (scatterer.phi, scatterer.thet) = (phi*rad_to_deg, thet*rad_to_deg)        \n        Z = scatterer.get_Z()        \n        I = sca_intensity(scatterer, h_pol)\n        return I * np.sin(thet)\n\n    try:\n        xsect = dblquad(d_xsect, 0.0, 2*np.pi, lambda x: 0.0, \n            lambda x: np.pi)[0]\n    finally:\n        scatterer.set_geometry(old_geom)\n\n    return xsect"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ext_xsect(scatterer, h_pol=True):\n\n    if scatterer.psd_integrator is not None:\n        try:\n            return scatterer.psd_integrator.get_angular_integrated(\n                scatterer.psd, scatterer.get_geometry(), \"ext_xsect\")\n        except AttributeError:\n            # Fall back to the usual method of computing this from S\n            pass\n\n    old_geom = scatterer.get_geometry()\n    (thet0, thet, phi0, phi, alpha, beta) = old_geom\n    try:\n        scatterer.set_geometry((thet0, thet0, phi0, phi0, alpha, beta))\n        S = scatterer.get_S()        \n    finally:\n        scatterer.set_geometry(old_geom)\n\n\n\n    if h_pol:\n        return 2 * scatterer.wavelength * S[1,1].imag\n    else:\n        return 2 * scatterer.wavelength * S[0,0].imag", "response": "Returns the extinction cross section for the current setup."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsingles - scattering albedo for the current setup with polarization.", "response": "def ssa(scatterer, h_pol=True):\n    \"\"\"Single-scattering albedo for the current setup, with polarization.    \n\n    Args:\n        scatterer: a Scatterer instance.\n        h_pol: If True (default), use horizontal polarization.\n        If False, use vertical polarization.\n\n    Returns:\n        The single-scattering albedo.\n    \"\"\"\n\n    ext_xs = ext_xsect(scatterer, h_pol=h_pol)\n    return sca_xsect(scatterer, h_pol=h_pol)/ext_xs if ext_xs > 0.0 else 0.0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef asym(scatterer, h_pol=True):\n\n    if scatterer.psd_integrator is not None:\n        return scatterer.psd_integrator.get_angular_integrated(\n            scatterer.psd, scatterer.get_geometry(), \"asym\")\n\n    old_geom = scatterer.get_geometry()\n\n    cos_t0 = np.cos(scatterer.thet0 * deg_to_rad)\n    sin_t0 = np.sin(scatterer.thet0 * deg_to_rad)\n    p0 = scatterer.phi0 * deg_to_rad\n    def integrand(thet, phi):\n        (scatterer.phi, scatterer.thet) = (phi*rad_to_deg, thet*rad_to_deg)\n        cos_T_sin_t = 0.5 * (np.sin(2*thet)*cos_t0 + \\\n            (1-np.cos(2*thet))*sin_t0*np.cos(p0-phi))\n        I = sca_intensity(scatterer, h_pol)\n        return I * cos_T_sin_t\n\n    try:\n        cos_int = dblquad(integrand, 0.0, 2*np.pi, lambda x: 0.0, \n            lambda x: np.pi)[0]\n    finally:\n        scatterer.set_geometry(old_geom)\n\n    return cos_int/sca_xsect(scatterer, h_pol)", "response": "Asymmetry parameter for the current setup."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef radar_xsect(scatterer, h_pol=True):\n    Z = scatterer.get_Z()\n    if h_pol:\n        return 2 * np.pi * \\\n            (Z[0,0] - Z[0,1] - Z[1,0] + Z[1,1])\n    else:\n        return 2 * np.pi * \\\n            (Z[0,0] + Z[0,1] + Z[1,0] + Z[1,1])", "response": "Radar cross section for the current setup."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef refl(scatterer, h_pol=True):\n    return scatterer.wavelength**4/(np.pi**5*scatterer.Kw_sqr) * \\\n        radar_xsect(scatterer, h_pol)", "response": "Reflectivity of the current setup."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delta_hv(scatterer):\n    Z = scatterer.get_Z()\n    return np.arctan2(Z[2,3] - Z[3,2], -Z[2,2] - Z[3,3])", "response": "Returns the delta_hv for the current setup."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the Copolarized correlation coefficient for the current setup.", "response": "def rho_hv(scatterer):\n    \"\"\"\n    Copolarized correlation (rho_hv) for the current setup.\n\n    Args:\n        scatterer: a Scatterer instance.\n\n    Returns:\n       rho_hv.\n    \"\"\"\n    Z = scatterer.get_Z()\n    a = (Z[2,2] + Z[3,3])**2 + (Z[3,2] - Z[2,3])**2\n    b = (Z[0,0] - Z[0,1] - Z[1,0] + Z[1,1])\n    c = (Z[0,0] + Z[0,1] + Z[1,0] + Z[1,1])\n    return np.sqrt(a / (b*c))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Kdp(scatterer):\n    if (scatterer.thet0 != scatterer.thet) or \\\n        (scatterer.phi0 != scatterer.phi):\n        \n        raise ValueError(\"A forward scattering geometry is needed to \" + \\\n            \"compute the specific differential phase.\")\n\n    S = scatterer.get_S()\n    return 1e-3 * (180.0/np.pi) * scatterer.wavelength * (S[1,1]-S[0,0]).real", "response": "Returns the K_dp of the current setup."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mg_refractive(m, mix):\n\n    if len(m) == 2:\n        cF = float(mix[1]) / (mix[0]+mix[1]) * \\\n            (m[1]**2-m[0]**2) / (m[1]**2+2*m[0]**2)\n        er = m[0]**2 * (1.0+2.0*cF) / (1.0-cF)\n        m = np.sqrt(er)\n    else:\n        m_last = mg_refractive(m[-2:], mix[-2:])\n        mix_last = mix[-2] + mix[-1]\n        m = mg_refractive(m[:-2] + (m_last,), mix[:-2] + (mix_last,))\n    return m", "response": "Maxwell - Garnett approximation for the complex refractive index of \n      ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dsr_thurai_2007(D_eq):\n\n    if D_eq < 0.7:\n        return 1.0\n    elif D_eq < 1.5:\n        return 1.173 - 0.5165*D_eq + 0.4698*D_eq**2 - 0.1317*D_eq**3 - \\\n            8.5e-3*D_eq**4\n    else:\n        return 1.065 - 6.25e-2*D_eq - 3.99e-3*D_eq**2 + 7.66e-4*D_eq**3 - \\\n            4.095e-5*D_eq**4", "response": "D_eq is the drop - volume - equivalent diameter of the class in the Thurai 2007."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting and order feature importances from a sklearn model or array - like structure.", "response": "def feature_importances(data, top_n=None, feature_names=None):\n    \"\"\"\n    Get and order feature importances from a scikit-learn model\n    or from an array-like structure.\n\n    If data is a scikit-learn model with sub-estimators (e.g. RandomForest,\n    AdaBoost) the function will compute the standard deviation of each\n    feature.\n\n    Parameters\n    ----------\n    data : sklearn model or array-like structure\n        Object to get the data from.\n    top_n : int\n        Only get results for the top_n features.\n    feature_names : array-like\n        Feature_names\n\n    Returns\n    -------\n    numpy structured array\n        Returns a numpy structured array with the data. Columns are\n        feature_name, importance and std_ if an sklearn model with\n        sub-estimators was passed in data.\n\n    \"\"\"\n    # data can be either a sklearn estimator or an iterator with\n    # the actual importances values, try to get the values\n    try:\n        imp = data.feature_importances_\n    except:\n        imp = np.array(data)\n\n    # in case the user passed an estimator, it may have an estimators_\n    # attribute, which includes importnaces for every sub-estimator\n    # get them if possible\n    try:\n        sub_imp = np.array([e.feature_importances_ for e in data.estimators_])\n        # calculate std\n        std = np.std(sub_imp, axis=0)\n    except:\n        std = None\n\n    # get the number of features\n    n_features = len(imp)\n\n    # check that the data has the correct format\n    if top_n and top_n > n_features:\n        raise ValueError(('top_n ({}) cannot be greater than the number of'\n                          ' features ({})'.format(top_n, n_features)))\n    if top_n and top_n < 1:\n        raise ValueError('top_n cannot be less than 1')\n    if feature_names and len(feature_names) != n_features:\n        raise ValueError(('feature_names ({}) must match the number of'\n                          ' features ({})'.format(len(feature_names),\n                                                  n_features)))\n\n    # if the user did not pass feature names create generic names\n    if feature_names is None:\n        feature_names = ['Feature {}'.format(n) for n in range(1, n_features+1)]\n        feature_names = np.array(feature_names)\n    else:\n        feature_names = np.array(feature_names)\n\n    # order the data according to the importance for the feature\n    idx = np.argsort(imp)[::-1]\n    imp = imp[idx]\n    feature_names = feature_names[idx]\n    if std is not None:\n        std = std[idx]\n\n    # build the structured array\n    if std is not None:\n        names = 'feature_name,importance,std_'\n        res = np.core.records.fromarrays([feature_names, imp, std],\n                                         names=names)\n    else:\n        names = 'feature_name,importance'\n        res = np.core.records.fromarrays([feature_names, imp],\n                                         names=names)\n\n    # get subset if top_n is not none\n    if top_n:\n        res = res[:top_n]\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _group_by(data, criteria):\n    if isinstance(criteria, str):\n        criteria_str = criteria\n\n        def criteria(x):\n            return x[criteria_str]\n\n    res = defaultdict(list)\n    for element in data:\n        key = criteria(element)\n        res[key].append(element)\n    return res", "response": "Group the data by a function or a key"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a function that takes a list of parameters and returns a tuple of the form k1 k2", "response": "def _get_params_value(params):\n    \"\"\"\n        Given an iterator (k1, k2), returns a function that when called\n        with an object obj returns a tuple of the form:\n        ((k1, obj.parameters[k1]), (k2, obj.parameters[k2]))\n    \"\"\"\n    # sort params for consistency\n    ord_params = sorted(params)\n\n    def fn(obj):\n        l = []\n        for p in ord_params:\n            try:\n                l.append((p, obj.parameters[p]))\n            except:\n                raise ValueError('{} is not a valid parameter'.format(p))\n        return tuple(l)\n    return fn"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform the product between two objects even if they don t support iteration", "response": "def _product(k, v):\n    \"\"\"\n        Perform the product between two objects\n        even if they don't support iteration\n    \"\"\"\n    if not _can_iterate(k):\n        k = [k]\n    if not _can_iterate(v):\n        v = [v]\n    return list(product(k, v))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a mapping object such as a dictionary to tuple pairs", "response": "def _mapping_to_tuple_pairs(d):\n    \"\"\"\n        Convert a mapping object (such as a dictionary) to tuple pairs,\n        using its keys and values to generate the pairs and then generating\n        all possible combinations between those\n        e.g. {1: (1,2,3)} -> (((1, 1),), ((1, 2),), ((1, 3),))\n    \"\"\"\n    # order the keys, this will prevent different implementations of Python,\n    # return different results from the same dictionary since the order of\n    # iteration depends on it\n    t = []\n    ord_keys = sorted(d.keys())\n    for k in ord_keys:\n        t.append(_product(k, d[k]))\n    return tuple(product(*t))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot a learning curve for the training set and test set.", "response": "def learning_curve(train_scores, test_scores, train_sizes, ax=None):\n    \"\"\"Plot a learning curve\n\n    Plot a metric vs number of examples for the training and test set\n\n    Parameters\n    ----------\n    train_scores : array-like\n        Scores for the training set\n    test_scores : array-like\n        Scores for the test set\n    train_sizes : array-like\n        Relative or absolute numbers of training examples used to generate\n        the learning curve\n    ax : matplotlib Axes\n        Axes object to draw the plot onto, otherwise uses current Axes\n\n    Returns\n    -------\n    ax: matplotlib Axes\n        Axes containing the plot\n\n    Examples\n    --------\n\n    .. plot:: ../../examples/learning_curve.py\n\n    \"\"\"\n    if ax is None:\n        ax = plt.gca()\n\n    ax.grid()\n    ax.set_title(\"Learning Curve\")\n    ax.set_xlabel(\"Training examples\")\n    ax.set_ylabel(\"Score mean\")\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1,\n                    color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n            label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n            label=\"Cross-validation score\")\n\n    ax.legend(loc=\"best\")\n    ax.margins(0.05)\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nplotting precision - recall curve.", "response": "def precision_recall(y_true, y_score, ax=None):\n    \"\"\"\n    Plot precision-recall curve.\n\n    Parameters\n    ----------\n    y_true : array-like, shape = [n_samples]\n        Correct target values (ground truth).\n    y_score : array-like, shape = [n_samples] or [n_samples, 2] for binary\n              classification or [n_samples, n_classes] for multiclass\n\n        Target scores (estimator predictions).\n    ax : matplotlib Axes\n        Axes object to draw the plot onto, otherwise uses current Axes\n\n    Notes\n    -----\n    It is assumed that the y_score parameter columns are in order. For example,\n    if ``y_true = [2, 2, 1, 0, 0, 1, 2]``, then the first column in y_score\n    must countain the scores for class 0, second column for class 1 and so on.\n\n\n    Returns\n    -------\n    ax: matplotlib Axes\n        Axes containing the plot\n\n    Examples\n    --------\n    .. plot:: ../../examples/precision_recall.py\n\n    \"\"\"\n    if any((val is None for val in (y_true, y_score))):\n        raise ValueError('y_true and y_score are needed to plot '\n                         'Precision-Recall')\n\n    if ax is None:\n        ax = plt.gca()\n\n    # get the number of classes from y_score\n    y_score_is_vector = is_column_vector(y_score) or is_row_vector(y_score)\n    if y_score_is_vector:\n        n_classes = 2\n    else:\n        _, n_classes = y_score.shape\n\n    # check data shape?\n\n    if n_classes > 2:\n        # convert y_true to binary format\n        y_true_bin = label_binarize(y_true, classes=np.unique(y_true))\n        _precision_recall_multi(y_true_bin, y_score, ax=ax)\n        for i in range(n_classes):\n            _precision_recall(y_true_bin[:, i], y_score[:, i], ax=ax)\n    else:\n        if y_score_is_vector:\n            _precision_recall(y_true, y_score, ax)\n        else:\n            _precision_recall(y_true, y_score[:, 1], ax)\n\n    # raise error if n_classes = 1?\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _precision_recall(y_true, y_score, ax=None):\n    precision, recall, _ = precision_recall_curve(y_true, y_score)\n    average_precision = average_precision_score(y_true, y_score)\n\n    if ax is None:\n        ax = plt.gca()\n\n    ax.plot(recall, precision, label=('Precision-Recall curve: AUC={0:0.2f}'\n                                      .format(average_precision)))\n    _set_ax_settings(ax)\n    return ax", "response": "Plot precision - recall curve."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _precision_recall_multi(y_true, y_score, ax=None):\n    # Compute micro-average ROC curve and ROC area\n    precision, recall, _ = precision_recall_curve(y_true.ravel(),\n                                                  y_score.ravel())\n\n    avg_prec = average_precision_score(y_true, y_score, average=\"micro\")\n\n    if ax is None:\n        ax = plt.gca()\n\n    ax.plot(recall, precision,\n            label=('micro-average Precision-recall curve (area = {0:0.2f})'\n                   .format(avg_prec)))\n    _set_ax_settings(ax)\n    return ax", "response": "Plots precision - recall curve for a single base class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef precision_at(y_true, y_score, proportion, ignore_nas=False):\n    '''\n    Calculates precision at a given proportion.\n    Only supports binary classification.\n    '''\n    # Sort scores in descending order\n    scores_sorted = np.sort(y_score)[::-1]\n\n    # Based on the proportion, get the index to split the data\n    # if value is negative, return 0\n    cutoff_index = max(int(len(y_true) * proportion) - 1, 0)\n    # Get the cutoff value\n    cutoff_value = scores_sorted[cutoff_index]\n\n    # Convert scores to binary, by comparing them with the cutoff value\n    scores_binary = np.array([int(y >= cutoff_value) for y in y_score])\n    # Calculate precision using sklearn function\n    if ignore_nas:\n        precision = __precision(y_true, scores_binary)\n    else:\n        precision = precision_score(y_true, scores_binary)\n\n    return precision, cutoff_value", "response": "Calculates precision at a given proportion."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the precision of the data in the cluster hierarchy.", "response": "def __precision(y_true, y_pred):\n    '''\n        Precision metric tolerant to unlabeled data in y_true,\n        NA values are ignored for the precision calculation\n    '''\n    # make copies of the arrays to avoid modifying the original ones\n    y_true = np.copy(y_true)\n    y_pred = np.copy(y_pred)\n\n    # precision = tp/(tp+fp)\n    # True nehatives do not affect precision value, so for every missing\n    # value in y_true, replace it with 0 and also replace the value\n    # in y_pred with 0\n    is_nan = np.isnan(y_true)\n    y_true[is_nan] = 0\n    y_pred[is_nan] = 0\n    precision = precision_score(y_true, y_pred)\n    return precision"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef labels_at(y_true, y_score, proportion, normalize=False):\n    '''\n        Return the number of labels encountered in the top  X proportion\n    '''\n    # Get indexes of scores sorted in descending order\n    indexes = np.argsort(y_score)[::-1]\n\n    # Sort true values in the same order\n    y_true_sorted = y_true[indexes]\n\n    # Grab top x proportion of true values\n    cutoff_index = max(int(len(y_true_sorted) * proportion) - 1, 0)\n    # add one to index to grab values including that index\n    y_true_top = y_true_sorted[:cutoff_index+1]\n\n    # Count the number of non-nas in the top x proportion\n    # we are returning a count so it should be an int\n    values = int((~np.isnan(y_true_top)).sum())\n\n    if normalize:\n        values = float(values)/(~np.isnan(y_true)).sum()\n\n    return values", "response": "Return the number of labels encountered in the top X proportion"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots a validation curve for the training set and test set.", "response": "def validation_curve(train_scores, test_scores, param_range, param_name=None,\n                     semilogx=False, ax=None):\n    \"\"\"Plot a validation curve\n\n    Plot a metric vs hyperpameter values for the training and test set\n\n    Parameters\n    ----------\n    train_scores : array-like\n        Scores for the training set\n    test_scores : array-like\n        Scores for the test set\n    param_range : array-like\n        Hyperparameter values used to generate the curve\n    param_range : str\n        Hyperparameter name\n    semilgo : bool\n        Sets a log scale on the x axis\n    ax : matplotlib Axes\n        Axes object to draw the plot onto, otherwise uses current Axes\n\n    Returns\n    -------\n    ax: matplotlib Axes\n        Axes containing the plot\n\n    Examples\n    --------\n\n    .. plot:: ../../examples/validation_curve.py\n\n    \"\"\"\n\n    if ax is None:\n        ax = plt.gca()\n\n    if semilogx:\n        ax.set_xscale('log')\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    ax.set_title(\"Validation Curve\")\n    ax.set_ylabel(\"Score mean\")\n\n    if param_name:\n        ax.set_xlabel(param_name)\n\n    ax.plot(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n    ax.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n            color=\"g\")\n\n    ax.fill_between(param_range, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.2, color=\"r\")\n    ax.fill_between(param_range, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.2, color=\"g\")\n\n    ax.legend(loc=\"best\")\n    ax.margins(0.05)\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef confusion_matrix(y_true, y_pred, target_names=None, normalize=False,\n                     cmap=None, ax=None):\n    \"\"\"\n    Plot confustion matrix.\n\n    Parameters\n    ----------\n    y_true : array-like, shape = [n_samples]\n        Correct target values (ground truth).\n    y_pred : array-like, shape = [n_samples]\n        Target predicted classes (estimator predictions).\n    target_names : list\n        List containing the names of the target classes. List must be in order\n        e.g. ``['Label for class 0', 'Label for class 1']``. If ``None``,\n        generic labels will be generated e.g. ``['Class 0', 'Class 1']``\n    ax: matplotlib Axes\n        Axes object to draw the plot onto, otherwise uses current Axes\n    normalize : bool\n        Normalize the confusion matrix\n    cmap : matplotlib Colormap\n        If ``None`` uses a modified version of matplotlib's OrRd colormap.\n\n\n    Returns\n    -------\n    ax: matplotlib Axes\n        Axes containing the plot\n\n    Examples\n    --------\n    .. plot:: ../../examples/confusion_matrix.py\n\n    \"\"\"\n    if any((val is None for val in (y_true, y_pred))):\n        raise ValueError(\"y_true and y_pred are needed to plot confusion \"\n                         \"matrix\")\n\n    # calculate how many names you expect\n    values = set(y_true).union(set(y_pred))\n    expected_len = len(values)\n\n    if target_names and (expected_len != len(target_names)):\n        raise ValueError(('Data cointains {} different values, but target'\n                         ' names contains {} values.'.format(expected_len,\n                                                             len(target_names)\n                                                             )))\n\n    # if the user didn't pass target_names, create generic ones\n    if not target_names:\n        values = list(values)\n        values.sort()\n        target_names = ['Class {}'.format(v) for v in values]\n\n    cm = sk_confusion_matrix(y_true, y_pred)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    np.set_printoptions(precision=2)\n\n    if ax is None:\n        ax = plt.gca()\n\n    # this (y, x) may sound counterintuitive. The reason is that\n    # in a matrix cell (i, j) is in row=i and col=j, translating that\n    # to an x, y plane (which matplotlib uses to plot), we need to use\n    # i as the y coordinate (how many steps down) and j as the x coordinate\n    # how many steps to the right.\n    for (y, x), v in np.ndenumerate(cm):\n        try:\n            label = '{:.2}'.format(v)\n        except:\n            label = v\n        ax.text(x, y, label, horizontalalignment='center',\n                verticalalignment='center')\n\n    if cmap is None:\n        cmap = default_heatmap()\n\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.colorbar(im, ax=ax)\n    tick_marks = np.arange(len(target_names))\n    ax.set_xticks(tick_marks)\n    ax.set_xticklabels(target_names)\n    ax.set_yticks(tick_marks)\n    ax.set_yticklabels(target_names)\n\n    title = 'Confusion matrix'\n    if normalize:\n        title += ' (normalized)'\n    ax.set_title(title)\n\n    ax.set_ylabel('True label')\n    ax.set_xlabel('Predicted label')\n    return ax", "response": "Plots the confusion matrix for the current language."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef feature_importances(data, top_n=None, feature_names=None, ax=None):\n    if data is None:\n        raise ValueError('data is needed to plot feature importances. '\n                         'When plotting using the evaluator you need to pass '\n                         'an estimator ')\n\n    # If no feature_names is provided, assign numbers\n    res = compute.feature_importances(data, top_n, feature_names)\n    # number of features returned\n    n_feats = len(res)\n\n    if ax is None:\n        ax = plt.gca()\n\n    ax.set_title(\"Feature importances\")\n\n    try:\n        ax.bar(range(n_feats), res.importance, yerr=res.std_, color='red',\n               align=\"center\")\n    except:\n        ax.bar(range(n_feats), res.importance, color='red',\n               align=\"center\")\n\n    ax.set_xticks(range(n_feats))\n    ax.set_xticklabels(res.feature_name)\n    ax.set_xlim([-1, n_feats])\n    return ax", "response": "Returns a matplotlib Axes object containing the feature importances of each feature in the top_n features."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot precision values at different proportions.", "response": "def precision_at_proportions(y_true, y_score, ax=None):\n    \"\"\"\n    Plot precision values at different proportions.\n\n    Parameters\n    ----------\n    y_true : array-like\n        Correct target values (ground truth).\n    y_score : array-like\n        Target scores (estimator predictions).\n    ax : matplotlib Axes\n        Axes object to draw the plot onto, otherwise uses current Axes\n\n    Returns\n    -------\n    ax: matplotlib Axes\n        Axes containing the plot\n\n    \"\"\"\n    if any((val is None for val in (y_true, y_score))):\n        raise ValueError('y_true and y_score are needed to plot precision at '\n                         'proportions')\n\n    if ax is None:\n        ax = plt.gca()\n\n    y_score_is_vector = is_column_vector(y_score) or is_row_vector(y_score)\n    if not y_score_is_vector:\n        y_score = y_score[:, 1]\n\n    # Calculate points\n    proportions = [0.01 * i for i in range(1, 101)]\n    precs_and_cutoffs = [precision_at(y_true, y_score, p) for p in proportions]\n    precs, cutoffs = zip(*precs_and_cutoffs)\n\n    # Plot and set nice defaults for title and axis labels\n    ax.plot(proportions, precs)\n    ax.set_title('Precision at various proportions')\n    ax.set_ylabel('Precision')\n    ax.set_xlabel('Proportion')\n    ticks = [0.1 * i for i in range(1, 11)]\n    ax.set_xticks(ticks)\n    ax.set_xticklabels(ticks)\n    ax.set_yticks(ticks)\n    ax.set_yticklabels(ticks)\n    ax.set_ylim([0, 1.0])\n    ax.set_xlim([0, 1.0])\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a table with the feature importances for the given data.", "response": "def feature_importances(data, top_n=None, feature_names=None):\n    \"\"\"\n    Get and order feature importances from a scikit-learn model\n    or from an array-like structure.\n\n    If data is a scikit-learn model with sub-estimators (e.g. RandomForest,\n    AdaBoost) the function will compute the standard deviation of each\n    feature.\n\n    Parameters\n    ----------\n    data : sklearn model or array-like structure\n        Object to get the data from.\n    top_n : int\n        Only get results for the top_n features.\n    feature_names : array-like\n        Feature_names\n\n    Returns\n    -------\n    table\n        Table object with the data. Columns are\n        feature_name, importance (`std_` only included for models with\n        sub-estimators)\n\n    \"\"\"\n    if data is None:\n        raise ValueError('data is needed to tabulate feature importances. '\n                         'When plotting using the evaluator you need to pass '\n                         'an estimator ')\n\n    res = compute.feature_importances(data, top_n, feature_names)\n    return Table(res, res.dtype.names)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparts is a string of ipython text, comprised of at most one input, one output, comments, and blank lines. The block parser parses the text into a list of:: blocks = [ (TOKEN0, data0), (TOKEN1, data1), ...] where TOKEN is one of [COMMENT | INPUT | OUTPUT ] and data is, depending on the type of token:: COMMENT : the comment string INPUT: the (DECORATOR, INPUT_LINE, REST) where DECORATOR: the input decorator (or None) INPUT_LINE: the input as string (possibly multi-line) REST : any stdout generated by the input line (not OUTPUT) OUTPUT: the output string, possibly multi-line", "response": "def block_parser(part, rgxin, rgxout, fmtin, fmtout):\n    \"\"\"\n    part is a string of ipython text, comprised of at most one\n    input, one output, comments, and blank lines.  The block parser\n    parses the text into a list of::\n\n      blocks = [ (TOKEN0, data0), (TOKEN1, data1), ...]\n\n    where TOKEN is one of [COMMENT | INPUT | OUTPUT ] and\n    data is, depending on the type of token::\n\n      COMMENT : the comment string\n\n      INPUT: the (DECORATOR, INPUT_LINE, REST) where\n         DECORATOR: the input decorator (or None)\n         INPUT_LINE: the input as string (possibly multi-line)\n         REST : any stdout generated by the input line (not OUTPUT)\n\n      OUTPUT: the output string, possibly multi-line\n\n    \"\"\"\n    block = []\n    lines = part.split('\\n')\n    N = len(lines)\n    i = 0\n    decorator = None\n    while 1:\n\n        if i==N:\n            # nothing left to parse -- the last line\n            break\n\n        line = lines[i]\n        i += 1\n        line_stripped = line.strip()\n        if line_stripped.startswith('#'):\n            block.append((COMMENT, line))\n            continue\n\n        if line_stripped.startswith('@'):\n            # Here is where we assume there is, at most, one decorator.\n            # Might need to rethink this.\n            decorator = line_stripped\n            continue\n\n        # does this look like an input line?\n        matchin = rgxin.match(line)\n        if matchin:\n            lineno, inputline = int(matchin.group(1)), matchin.group(2)\n\n            # the ....: continuation string\n            continuation = '   %s:'%''.join(['.']*(len(str(lineno))+2))\n            Nc = len(continuation)\n            # input lines can continue on for more than one line, if\n            # we have a '\\' line continuation char or a function call\n            # echo line 'print'.  The input line can only be\n            # terminated by the end of the block or an output line, so\n            # we parse out the rest of the input line if it is\n            # multiline as well as any echo text\n\n            rest = []\n            while i<N:\n\n                # look ahead; if the next line is blank, or a comment, or\n                # an output line, we're done\n\n                nextline = lines[i]\n                matchout = rgxout.match(nextline)\n                #print \"nextline=%s, continuation=%s, starts=%s\"%(nextline, continuation, nextline.startswith(continuation))\n                if matchout or nextline.startswith('#'):\n                    break\n                elif nextline.startswith(continuation):\n                    # The default ipython_rgx* treat the space following the colon as optional.\n                    # However, If the space is there we must consume it or code\n                    # employing the cython_magic extension will fail to execute.\n                    #\n                    # This works with the default ipython_rgx* patterns,\n                    # If you modify them, YMMV.\n                    nextline = nextline[Nc:]\n                    if nextline and nextline[0] == ' ':\n                        nextline = nextline[1:]\n\n                    inputline += '\\n' +  nextline\n                else:\n                    rest.append(nextline)\n                i+= 1\n\n            block.append((INPUT, (decorator, inputline, '\\n'.join(rest))))\n            continue\n\n        # if it looks like an output line grab all the text to the end\n        # of the block\n        matchout = rgxout.match(line)\n        if matchout:\n            lineno, output = int(matchout.group(1)), matchout.group(2)\n            if i<N-1:\n                output = '\\n'.join([output] + lines[i:])\n\n            block.append((OUTPUT, output))\n            break\n\n    return block"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing a block from the block parser and return a list of processed lines", "response": "def process_block(self, block):\n        \"\"\"\n        process block from the block_parser and return a list of processed lines\n        \"\"\"\n        ret = []\n        output = None\n        input_lines = None\n        lineno = self.IP.execution_count\n\n        input_prompt = self.promptin % lineno\n        output_prompt = self.promptout % lineno\n        image_file = None\n        image_directive = None\n\n        found_input = False\n        for token, data in block:\n            if token == COMMENT:\n                out_data = self.process_comment(data)\n            elif token == INPUT:\n                found_input = True\n                (out_data, input_lines, output, is_doctest,\n                 decorator, image_file, image_directive) = \\\n                          self.process_input(data, input_prompt, lineno)\n            elif token == OUTPUT:\n                if not found_input:\n\n                    TAB = ' ' * 4\n                    linenumber = 0\n                    source = 'Unavailable'\n                    content = 'Unavailable'\n                    if self.directive:\n                        linenumber = self.directive.state.document.current_line\n                        source = self.directive.state.document.current_source\n                        content = self.directive.content\n                        # Add tabs and join into a single string.\n                        content = '\\n'.join([TAB + line for line in content])\n\n                    e = ('\\n\\nInvalid block: Block contains an output prompt '\n                         'without an input prompt.\\n\\n'\n                         'Document source: {0}\\n\\n'\n                         'Content begins at line {1}: \\n\\n{2}\\n\\n'\n                         'Problematic block within content: \\n\\n{TAB}{3}\\n\\n')\n                    e = e.format(source, linenumber, content, block, TAB=TAB)\n\n                    # Write, rather than include in exception, since Sphinx\n                    # will truncate tracebacks.\n                    sys.stdout.write(e)\n                    raise RuntimeError('An invalid block was detected.')\n\n                out_data = \\\n                    self.process_output(data, output_prompt, input_lines,\n                                        output, is_doctest, decorator,\n                                        image_file)\n                if out_data:\n                    # Then there was user submitted output in verbatim mode.\n                    # We need to remove the last element of `ret` that was\n                    # added in `process_input`, as it is '' and would introduce\n                    # an undesirable newline.\n                    assert(ret[-1] == '')\n                    del ret[-1]\n\n            if out_data:\n                ret.extend(out_data)\n\n        # save the image files\n        if image_file is not None:\n            self.save_image(image_file)\n\n        return ret, image_directive"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot a sklearn grid search for a set of items in the order of the items in the list of named tuples.", "response": "def grid_search(grid_scores, change, subset=None, kind='line', cmap=None,\n                ax=None):\n    \"\"\"\n    Plot results from a sklearn grid search by changing two parameters at most.\n\n    Parameters\n    ----------\n    grid_scores : list of named tuples\n        Results from a sklearn grid search (get them using the\n        `grid_scores_` parameter)\n    change : str or iterable with len<=2\n        Parameter to change\n    subset : dictionary-like\n        parameter-value(s) pairs to subset from grid_scores.\n        (e.g. ``{'n_estimartors': [1, 10]}``), if None all combinations will be\n        used.\n    kind : ['line', 'bar']\n        This only applies whe change is a single parameter. Changes the\n        type of plot\n    cmap : matplotlib Colormap\n        This only applies when change are two parameters. Colormap used for\n        the matrix. If None uses a modified version of matplotlib's OrRd\n        colormap.\n    ax: matplotlib Axes\n        Axes object to draw the plot onto, otherwise uses current Axes\n\n    Returns\n    -------\n    ax: matplotlib Axes\n        Axes containing the plot\n\n    Examples\n    --------\n\n    .. plot:: ../../examples/grid_search.py\n\n    \"\"\"\n    if change is None:\n        raise ValueError(('change can\\'t be None, you need to select at least'\n                          ' one value to make the plot.'))\n\n    if ax is None:\n        ax = plt.gca()\n\n    if cmap is None:\n        cmap = default_heatmap()\n\n    if isinstance(change, string_types) or len(change) == 1:\n        return _grid_search_single(grid_scores, change, subset, kind, ax)\n    elif len(change) == 2:\n        return _grid_search_double(grid_scores, change, subset, cmap, ax)\n    else:\n        raise ValueError('change must have length 1 or 2 or be a string')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef roc(self):\n        return plot.roc(self.y_true, self.y_score, ax=_gen_ax())", "response": "ROC plot for this object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef precision_recall(self):\n        return plot.precision_recall(self.y_true, self.y_score, ax=_gen_ax())", "response": "Precision - recall plot"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef precision_at_proportions(self):\n        return plot.precision_at_proportions(self.y_true, self.y_score,\n                                             ax=_gen_ax())", "response": "Precision at proportions plot"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_report(self, template, path=None, style=None):\n        from .report import generate\n\n        return generate(self, template, path, style)", "response": "Generate the HTML report for the current configuration."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef roc(y_true, y_score, ax=None):\n    if any((val is None for val in (y_true, y_score))):\n        raise ValueError(\"y_true and y_score are needed to plot ROC\")\n\n    if ax is None:\n        ax = plt.gca()\n\n    # get the number of classes based on the shape of y_score\n    y_score_is_vector = is_column_vector(y_score) or is_row_vector(y_score)\n    if y_score_is_vector:\n        n_classes = 2\n    else:\n        _, n_classes = y_score.shape\n\n    # check data shape?\n\n    if n_classes > 2:\n        # convert y_true to binary format\n        y_true_bin = label_binarize(y_true, classes=np.unique(y_true))\n        _roc_multi(y_true_bin, y_score, ax=ax)\n        for i in range(n_classes):\n            _roc(y_true_bin[:, i], y_score[:, i], ax=ax)\n    else:\n        if y_score_is_vector:\n            _roc(y_true, y_score, ax)\n        else:\n            _roc(y_true, y_score[:, 1], ax)\n\n    # raise error if n_classes = 1?\n    return ax", "response": "Plots ROC curve for the current binary entry set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _roc(y_true, y_score, ax=None):\n    # check dimensions\n\n    fpr, tpr, _ = roc_curve(y_true, y_score)\n    roc_auc = auc(fpr, tpr)\n\n    ax.plot(fpr, tpr, label=('ROC curve (area = {0:0.2f})'.format(roc_auc)))\n    _set_ax_settings(ax)\n    return ax", "response": "Plots ROC curve for binary classification."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplotting ROC curve for multi classification.", "response": "def _roc_multi(y_true, y_score, ax=None):\n    \"\"\"\n    Plot ROC curve for multi classification.\n\n    Parameters\n    ----------\n    y_true : array-like, shape = [n_samples, n_classes]\n        Correct target values (ground truth).\n    y_score : array-like, shape = [n_samples, n_classes]\n        Target scores (estimator predictions).\n    ax: matplotlib Axes\n        Axes object to draw the plot onto, otherwise uses current Axes\n\n    Returns\n    -------\n    ax: matplotlib Axes\n        Axes containing the plot\n\n    \"\"\"\n    # Compute micro-average ROC curve and ROC area\n    fpr, tpr, _ = roc_curve(y_true.ravel(), y_score.ravel())\n    roc_auc = auc(fpr, tpr)\n\n    if ax is None:\n        ax = plt.gca()\n\n    ax.plot(fpr, tpr, label=('micro-average ROC curve (area = {0:0.2f})'\n                             .format(roc_auc)))\n    _set_ax_settings(ax)\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def get_connection(self, container):\n        '''\n        Get an exclusive connection, useful for blocked commands and transactions.\n        \n        You must call release or shutdown (not recommanded) to return the connection after use.\n        \n        :param container: routine container\n        \n        :returns: RedisClientBase object, with some commands same as RedisClient like execute_command,\n                  batch_execute, register_script etc.\n        '''\n        if self._connpool:\n            conn = self._connpool.pop()\n            return RedisClientBase(conn, self)\n        else:\n            conn = self._create_client(container)\n            await RedisClientBase._get_connection(self, container, conn)\n            await self._protocol.send_command(conn, container, 'SELECT', str(self.db))\n            return RedisClientBase(conn, self)", "response": "Get an exclusive connection."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting a command on Redis server.", "response": "async def execute_command(self, container, *args):\n        '''\n        Execute command on Redis server:\n          - For (P)SUBSCRIBE/(P)UNSUBSCRIBE, the command is sent to the subscribe connection.\n            It is recommended to use (p)subscribe/(p)unsubscribe method instead of directly call the command\n          - For BLPOP, BRPOP, BRPOPLPUSH, the command is sent to a separated connection. The connection is\n            recycled after command returns.\n          - For other commands, the command is sent to the default connection.\n        '''\n        if args:\n            cmd = _str(args[0]).upper()\n            if cmd in ('SUBSCRIBE', 'UNSUBSCRIBE', 'PSUBSCRIBE', 'PUNSUBSCRIBE'):\n                await self._get_subscribe_connection(container)\n                return await self._protocol.execute_command(self._subscribeconn, container, *args)\n            elif cmd in ('BLPOP', 'BRPOP', 'BRPOPLPUSH'):\n                c = await self.get_connection(container)\n                with c.context(container):\n                    return await c.execute_command(container, *args)\n        return await RedisClientBase.execute_command(self, container, *args)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsubscribing to the specified channels.", "response": "async def subscribe(self, container, *keys):\n        '''\n        Subscribe to specified channels\n        \n        :param container: routine container\n        \n        :param *keys: subscribed channels\n        \n        :returns: list of event matchers for the specified channels\n        '''\n        await self._get_subscribe_connection(container)\n        realkeys = []\n        for k in keys:\n            count = self._subscribecounter.get(k, 0)\n            if count == 0:\n                realkeys.append(k)\n            self._subscribecounter[k] = count + 1\n        if realkeys:\n            await self._protocol.execute_command(self._subscribeconn, container, 'SUBSCRIBE', *realkeys)\n        return [self._protocol.subscribematcher(self._subscribeconn, k, None, RedisSubscribeMessageEvent.MESSAGE) for k in keys]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def unsubscribe(self, container, *keys):\n        '''\n        Unsubscribe specified channels. Every subscribed key should be unsubscribed exactly once, even if duplicated subscribed.\n        \n        :param container: routine container\n        \n        :param \\*keys: subscribed channels\n        '''\n        await self._get_subscribe_connection(container)\n        realkeys = []\n        for k in keys:\n            count = self._subscribecounter.get(k, 0)\n            if count <= 1:\n                realkeys.append(k)\n                try:\n                    del self._subscribecounter[k]\n                except KeyError:\n                    pass\n            else:\n                self._subscribecounter[k] = count - 1\n        if realkeys:\n            await self._protocol.execute_command(self._subscribeconn, container, 'UNSUBSCRIBE', *realkeys)", "response": "Unsubscribe specified channels. Every subscribed key should be unsubscribed exactly once, even if duplicated subscribed.\n        \n        :param container: routine container\n        \n        :param \\*keys: subscribed channels"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsubscribing to specified globs", "response": "async def psubscribe(self, container, *keys):\n        '''\n        Subscribe to specified globs\n        \n        :param container: routine container\n        \n        :param \\*keys: subscribed globs\n        \n        :returns: list of event matchers for the specified globs \n        '''\n        await self._get_subscribe_connection(container)\n        realkeys = []\n        for k in keys:\n            count = self._psubscribecounter.get(k, 0)\n            if count == 0:\n                realkeys.append(k)\n            self._psubscribecounter[k] = count + 1\n        await self._protocol.execute_command(self._subscribeconn, container, 'PSUBSCRIBE', *realkeys)\n        return [self._protocol.subscribematcher(self._subscribeconn, k, None, RedisSubscribeMessageEvent.PMESSAGE) for k in keys]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subscribe_state_matcher(self, container, connected = True):\n        '''\n        Return a matcher to match the subscribe connection status.\n        \n        :param container: a routine container. NOTICE: this method is not a routine.\n        \n        :param connected: if True, the matcher matches connection up. If False, the matcher matches\n               connection down.\n        \n        :returns: an event matcher.\n        '''\n        if not self._subscribeconn:\n            self._subscribeconn = self._create_client(container)\n        return RedisConnectionStateEvent.createMatcher(\n                    RedisConnectionStateEvent.CONNECTION_UP if connected else RedisConnectionStateEvent.CONNECTION_DOWN,\n                    self._subscribeconn\n                    )", "response": "Returns a matcher to match the subscribe connection status."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nescaping a path in a bytestring.", "response": "def _escape_path(key):\n    '''\n    Replace '/', '\\\\' in key\n    '''\n    return _tobytes(key).replace(b'$', b'$_').replace(b'/', b'$+').replace(b'\\\\', b'$$')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reassemble_options(payload):\n    '''\n    Reassemble partial options to options, returns a list of dhcp_option\n    \n    DHCP options are basically `|tag|length|value|` structure. When an\n    option is longer than 255 bytes, it can be splitted into multiple\n    structures with the same tag. The splitted structures must be\n    joined back to get the original option.\n    \n    `dhcp_option_partial` is used to present the splitted options,\n    and `dhcp_option` is used for reassembled option.\n    '''\n    options = []\n    option_indices = {}\n    def process_option_list(partials):\n        for p in partials:\n            if p.tag == OPTION_END:\n                break\n            if p.tag == OPTION_PAD:\n                continue\n            if p.tag in option_indices:\n                # Reassemble the data\n                options[option_indices[p.tag]][1].append(p.data)\n            else:\n                options.append((p.tag, [p.data]))\n                option_indices[p.tag] = len(options) - 1\n    # First process options field\n    process_option_list(payload.options)\n    if OPTION_OVERLOAD in option_indices:\n        # There is an overload option\n        data = b''.join(options[option_indices[OPTION_OVERLOAD]][1])\n        overload_option = dhcp_overload.create(data)\n        if overload_option & OVERLOAD_FILE:\n            process_option_list(dhcp_option_partial[0].create(payload.file))\n        if overload_option & OVERLOAD_SNAME:\n            process_option_list(dhcp_option_partial[0].create(payload.sname))\n    def _create_dhcp_option(tag, data):\n        opt = dhcp_option(tag = tag)\n        opt._setextra(data)\n        opt._autosubclass()\n        return opt\n    return [_create_dhcp_option(tag, b''.join(data)) for tag,data in options]", "response": "Reassemble partial options to options returns a list of dhcp_option objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_options(payload, options, maxsize = 576, overload = OVERLOAD_FILE | OVERLOAD_SNAME, allowpartial = True):\n    '''\n    Split a list of options\n    \n    This is the reverse operation of `reassemble_options`, it splits `dhcp_option` into\n    `dhcp_option_partial` if necessary, and set overload option if field overloading is\n    used.\n    \n    :param options: a list of `dhcp_option`\n    \n    :param maxsize: Limit the maximum DHCP message size. If options cannot fit into the DHCP\n                    message, specified fields are overloaded for options. If options cannot\n                    fit after overloading, extra options are DROPPED if allowpartial = True.\n                    \n                    It is important to sort the dhcp options by priority.\n    \n    :param overload: fields that are allowed to be overloaded\n    \n    :param allowpartial: When options cannot fit into the DHCP message, allow the rest options\n                         to be dropped.\n                         \n    :return: Number of options that are dropped i.e. `options[:-return_value]` are dropped\n    '''\n    if maxsize < 576:\n        maxsize = 576\n    max_options_size = maxsize - 240\n    # Ignore OPTION_PAD and OPTION_END\n    options = [o for o in options if o.tag not in (OPTION_PAD, OPTION_END)]\n    # Only preserve data\n    option_data = [(o.tag, o._tobytes()[2:]) for o in options]\n    def split_options(option_data, limits):\n        \"\"\"\n        Split options into multiple fields\n        \n        :param option_data: list of (tag, data) pair\n        \n        :param limits: list of int for limit of each field (excluding PAD and END)\n        \n        :return: number of options that are dropped\n        \"\"\"\n        # List of (dhcp_option_partial, option_not_finished)\n        partial_options = []\n        buffers = [0]\n        if not options:\n            return ([], 0)\n        def create_result():\n            # Remove any unfinished partial options\n            while partial_options and partial_options[-1][1]:\n                partial_options.pop()\n            buffers.append(len(partial_options))\n            r = [[po for po,_ in partial_options[buffers[i]:buffers[i+1]]] for i in range(0, len(buffers) - 1)]\n            # Remove empty fields\n            while r and not r[-1]:\n                r.pop()\n            return r\n        # Current field used size\n        current_size = 0\n        limit_iter = iter(limits)\n        try:\n            next_limit = next(limit_iter)\n        except (StopIteration, GeneratorExit):\n            return ([], False)\n        for i, (tag, data) in enumerate(option_data):\n            # Current used data size\n            data_size = 0\n            # Do not split very small options on boundary, this may prevent some broken DHCP clients/servers\n            # to cause problem\n            nosplit = (len(data) <= 32)\n            while True:\n                # next partial option size should be:\n                # 1. no more than the current field limit (minus 1-byte tag and 1-byte length)\n                # 2. no more than the single dhcp_option_partial data limit (255 due to single byte length)\n                # 3. no more than the rest data size\n                next_size = min(next_limit - current_size - 2, 255, len(data) - data_size)\n                if next_size < 0 or (next_size == 0 and data_size < len(data)) \\\n                        or (next_size < len(data) - data_size and nosplit):\n                    # Cannot put this part of data on the current field, find the next field\n                    try:\n                        next_limit = next(limit_iter)\n                    except (StopIteration, GeneratorExit):\n                        return (create_result(), len(option_data) - i)\n                    # Record field boundary\n                    buffers.append(len(partial_options))\n                    current_size = 0\n                else:\n                    # Put this partial option on current field\n                    partial_options.append((dhcp_option_partial(tag = tag, data = data[data_size : data_size + next_size]),\n                                            (next_size < len(data) - data_size)))\n                    data_size += next_size\n                    current_size += next_size + 2\n                    if data_size >= len(data):\n                        # finished current option\n                        break\n        return (create_result(), 0)\n    # First try to fit all options in options field\n    # preserve a byte for OPTION_END\n    result, not_finished = split_options(option_data, [max_options_size - 1])\n    if not_finished:\n        if overload & (OVERLOAD_FILE | OVERLOAD_SNAME):\n            # Try overload\n            # minus a overload option (1-byte tag, 1-byte lenght, 1-byte dhcp_overload) and 1-byte OPTION_END\n            limits = [max_options_size - 4]\n            if overload & OVERLOAD_FILE:\n                # preserve a byte for OPTION_END\n                limits.append(127)\n            if overload & OVERLOAD_SNAME:\n                # preserve a byte for OPTION_END\n                limits.append(63)\n            result2, not_finished2 = split_options(option_data, limits)\n            # Only overload if we have a better result\n            if len(result2) > 1:\n                result = result2\n                not_finished = not_finished2\n    if not allowpartial and not_finished:\n        raise ValueError(\"%d options cannot fit into a DHCP message\" % (not_finished,))\n    if not result:\n        return not_finished\n    elif len(result) <= 1:\n        # No overload\n        payload.options = result[0] + [dhcp_option_partial(tag = OPTION_END)]\n    else:\n        overload_option = 0\n        if len(result) >= 2 and result[1]:\n            overload_option |= OVERLOAD_FILE\n            # overload file field\n            payload.file = dhcp_option_partial[0].tobytes(result[1] + [dhcp_option_partial(tag = OPTION_END)])\n        if len(result) >= 3 and result[2]:\n            overload_option |= OVERLOAD_SNAME\n            # overload sname field\n            payload.sname = dhcp_option_partial[0].tobytes(result[2] + [dhcp_option_partial(tag = OPTION_END)])\n        # Put an overload option before any other options\n        payload.options = [dhcp_option_partial(tag = OPTION_OVERLOAD, data = dhcp_overload.tobytes(overload_option))] \\\n                        + result[0] + [dhcp_option_partial(tag = OPTION_END)]\n    return not_finished", "response": "Builds the dhcp options for a given message."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates DHCP option from value.", "response": "def create_option_from_value(tag, value):\n    \"\"\"\n    Set DHCP option with human friendly value\n    \"\"\"\n    dhcp_option.parser()\n    fake_opt = dhcp_option(tag = tag)\n    for c in dhcp_option.subclasses:\n        if c.criteria(fake_opt):\n            if hasattr(c, '_parse_from_value'):\n                return c(tag = tag, value = c._parse_from_value(value))\n            else:\n                raise ValueError('Invalid DHCP option ' + str(tag) + \": \" + repr(value))\n    else:\n        fake_opt._setextra(_tobytes(value))\n        return fake_opt"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_dhcp_options(input_dict, ignoreError = False, generateNone = False):\n    retdict = {}\n    for k,v in dict(input_dict).items():\n        try:\n            if generateNone and v is None:\n                retdict[k] = None\n            else:\n                try:\n                    retdict[k] = create_option_from_value(k, v)\n                except _EmptyOptionException:\n                    if generateNone:\n                        retdict[k] = None\n        except Exception:\n            if ignoreError:\n                continue\n            else:\n                raise\n    return retdict", "response": "Try to create dhcp_options from human friendly values ignoring invalid values ignoring invalid values generateNone = True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef with_indices(*args):\n    '''\n    Create indices for an event class. Every event class must be decorated with this decorator.\n    '''\n    def decorator(cls):\n        for c in cls.__bases__:\n            if hasattr(c, '_indicesNames'):\n                cls._classnameIndex = c._classnameIndex + 1\n                for i in range(0, cls._classnameIndex):\n                    setattr(cls, '_classname' + str(i), getattr(c, '_classname' + str(i)))\n                setattr(cls, '_classname' + str(cls._classnameIndex), cls._getTypename())\n                cls._indicesNames = c._indicesNames + ('_classname' + str(cls._classnameIndex),) + args\n                cls._generateTemplate()\n                return cls\n        cls._classnameIndex = -1\n        cls._indicesNames = args\n        cls._generateTemplate()\n        return cls\n    return decorator", "response": "Decorator to create indices for an event class. Every event class must be decorated with this decorator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn two way difference between two sets of keys.", "response": "def two_way_difference(self, b, extra_add = (), extra_remove = ()):\n        \"\"\"\n        Return (self - b, b - self)\n        \"\"\"\n        if self is b:\n            return ((), ())\n        if isinstance(b, DiffRef_):\n            extra_remove = extra_remove + b.add\n            b = b.origin\n        if extra_add == extra_remove:\n            extra_add = extra_remove = ()\n        if isinstance(b, Diff_):\n            if self.base is b.base:\n                first = self.add + b.remove\n                second = self.remove + b.add\n            elif self.base is b:\n                first = self.add\n                second = self.remove\n            elif b.base is self:\n                first = b.remove\n                second = b.add\n            else:\n                first = self\n                second = b\n        else:\n            first = self\n            second = b\n        if not first and not extra_add:\n            return ((), tuple(second) + tuple(extra_remove))\n        elif not second and not extra_remove:\n            return (tuple(first) + tuple(extra_add), ())\n        else:\n            first = set(first)\n            first.update(extra_add)\n            second = set(second)\n            second.update(extra_remove)\n            return tuple(first.difference(second)), tuple(second.difference(first))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getTypename(cls):\n        '''\n        :returns: return the proper name to match\n        '''\n        if cls is Event:\n            return None\n        else:\n            for c in cls.__bases__:\n                if issubclass(c, Event):\n                    if c is Event:\n                        return cls._getTypename()\n                    else:\n                        return c.getTypename()", "response": "returns the proper name to match\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef createMatcher(cls, *args, **kwargs):\n        '''\n        :param _ismatch: user-defined function ismatch(event) for matching test\n        :param \\*args: indices\n        :param \\*\\*kwargs: index_name=index_value for matching criteria\n        '''\n        if kwargs and not args:\n            return EventMatcher(tuple(getattr(cls, ind) if ind[:10] == '_classname' else kwargs.get(ind) for ind in cls.indicesNames()), kwargs.get('_ismatch'))\n        else:\n            return EventMatcher(tuple(cls._generateIndices(args)), kwargs.get('_ismatch'))", "response": "Create a new EventMatcher object for the given class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlimiting the number of resources acquired by the current task.", "response": "async def limit(self, use = 1):\n        \"\"\"\n        Acquire \"resources\", wait until enough \"resources\" are acquired. For each loop,\n        `limit` number of \"resources\" are permitted.\n        \n        :param use: number of \"resouces\" to be used.\n        \n        :return: True if is limited\n        \"\"\"\n        c = self._counter\n        self._counter = c + use\n        if self._task is None:\n            self._task = self._container.subroutine(self._limiter_task(), False)\n        if c >= self._bottom_line:\n            # Limited\n            await RateLimitingEvent.createMatcher(self, c // self._limit)\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning task in task pool. Raise an exception or return the return value", "response": "async def run_task(self, container, task, newthread = False):\n        \"Run task() in task pool. Raise an exception or return the return value\"\n        e = TaskEvent(self, task=task, newthread = newthread)\n        await container.wait_for_send(e)\n        ev = await TaskDoneEvent.createMatcher(e)\n        if hasattr(ev, 'exception'):\n            raise ev.exception\n        else:\n            return ev.result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def run_gen_task(self, container, gentask, newthread = True):\n        \"Run generator gentask() in task pool, yield customized events\"\n        e = TaskEvent(self, gen_task = gentask, newthread = newthread)\n        await container.wait_for_send(e)\n        ev = await TaskDoneEvent.createMatcher(e)\n        if hasattr(ev, 'exception'):\n            raise ev.exception\n        else:\n            return ev.result", "response": "Run generator gentask() in task pool yield customized events"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning asynctask in task pool call sender ( events to send customized events return result", "response": "async def run_async_task(self, container, asynctask, newthread = True):\n        \"Run asynctask(sender) in task pool, call sender(events) to send customized events, return result\"\n        e = TaskEvent(self, async_task = asynctask, newthread = newthread)\n        await container.wait_for_send(e)\n        ev = await TaskDoneEvent.createMatcher(e)\n        if hasattr(ev, 'exception'):\n            raise ev.exception\n        else:\n            return ev.result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def lock(self, container = None):\n        \"Wait for lock acquire\"\n        if container is None:\n            container = RoutineContainer.get_container(self.scheduler)\n        if self.locked:\n            pass\n        elif self.lockroutine:\n            await LockedEvent.createMatcher(self)\n        else:\n            await container.wait_for_send(LockEvent(self.context, self.key, self))\n            self.locked = True", "response": "Wait for lock acquire"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef trylock(self):\n        \"Try to acquire lock and return True; if cannot acquire the lock at this moment, return False.\"\n        if self.locked:\n            return True\n        if self.lockroutine:\n            return False\n        waiter = self.scheduler.send(LockEvent(self.context, self.key, self))\n        if waiter:\n            return False\n        else:\n            self.locked = True\n            return True", "response": "Try to acquire lock and return True ; if cannot acquire the lock at this moment return False."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart to acquire lock in another routine. Call trylock or lock later to acquire the lock. Call unlock to cancel the lock routine", "response": "def beginlock(self, container):\n        \"Start to acquire lock in another routine. Call trylock or lock later to acquire the lock. Call unlock to cancel the lock routine\"\n        if self.locked:\n            return True\n        if self.lockroutine:\n            return False\n        self.lockroutine = container.subroutine(self._lockroutine(container), False)\n        return self.locked"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(self):\n        self.queue = self.scheduler.queue.addSubQueue(self.priority, LockEvent.createMatcher(self.context, self.key),\n                                         maxdefault = self.size, defaultQueueClass = CBQueue.AutoClassQueue.initHelper('locker', subqueuelimit = 1))", "response": "Create the subqueue for this lock."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def destroy(self, container = None):\n        if container is None:\n            container = RoutineContainer(self.scheduler)\n        if self.queue is not None:\n            await container.syscall_noreturn(syscall_removequeue(self.scheduler.queue, self.queue))\n            self.queue = None", "response": "Destroy the created subqueue"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def shutdown(self, force = False, connmark = -1):\n        '''\n        Can call without delegate\n        '''\n        if connmark is None:\n            connmark = self.connmark\n        self.scheduler.emergesend(ConnectionControlEvent(self, ConnectionControlEvent.SHUTDOWN, force, connmark))", "response": "Send a shutdown event to the scheduler."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreconnecting to the next available session.", "response": "async def reconnect(self, force = True, connmark = None):\n        '''\n        Can call without delegate\n        '''\n        if connmark is None:\n            connmark = self.connmark\n        self.scheduler.emergesend(ConnectionControlEvent(self, ConnectionControlEvent.RECONNECT, force, connmark))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresetting the internal state of the object.", "response": "async def reset(self, force = True, connmark = None):\n        '''\n        Can call without delegate\n        '''\n        if connmark is None:\n            connmark = self.connmark\n        self.scheduler.emergesend(ConnectionControlEvent(self, ConnectionControlEvent.RESET, force, connmark))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites an event to the broker.", "response": "async def write(self, event, ignoreException = True):\n        '''\n        Can call without delegate\n        '''\n        connmark = self.connmark\n        if self.connected:\n            def _until():\n                if not self.connected or self.connmark != connmark:\n                    return True\n            r = await self.wait_for_send(event, until=_until)\n            if r:\n                if ignoreException:\n                    return\n                else:\n                    raise\n        else:\n            if not ignoreException:\n                raise ConnectionResetException"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def shutdown(self, connmark = -1):\n        '''\n        Can call without delegate\n        '''\n        if connmark is None:\n            connmark = self.connmark\n        self.scheduler.emergesend(ConnectionControlEvent(self, ConnectionControlEvent.SHUTDOWN, True, connmark))", "response": "Send a shutdown event to the scheduler."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstops listens for a specific object.", "response": "async def stoplisten(self, connmark = -1):\n        '''\n        Can call without delegate\n        '''\n        if connmark is None:\n            connmark = self.connmark\n        self.scheduler.emergesend(ConnectionControlEvent(self, ConnectionControlEvent.STOPLISTEN, True, connmark))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def startlisten(self, connmark = -1):\n        '''\n        Can call without delegate\n        '''\n        if connmark is None:\n            connmark = self.connmark\n        self.scheduler.emergesend(ConnectionControlEvent(self, ConnectionControlEvent.STARTLISTEN, True, connmark))", "response": "Start listening for a specific object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef default_start():\n    (config, daemon, pidfile, startup, fork) = parsearg()\n    if config is None:\n        if os.path.isfile('/etc/vlcp.conf'):\n            config = '/etc/vlcp.conf'\n        else:\n            print('/etc/vlcp.conf is not found; start without configurations.')\n    elif not config:\n        config = None\n    main(config, startup, daemon, pidfile, fork)", "response": "Use `sys.argv` for starting parameters. This is the entry-point of `vlcp-start`"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstopping the output stream but further download will still perform", "response": "def close(self):\n        \"Stop the output stream, but further download will still perform\"\n        if self.stream:\n            self.stream.close(self.scheduler)\n            self.stream = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nforce stop the output stream if there are more data to download shutdown the connection", "response": "async def shutdown(self):\n        \"Force stop the output stream, if there are more data to download, shutdown the connection\"\n        if self.stream:\n            if not self.stream.dataeof and not self.stream.dataerror:\n                self.stream.close(self.scheduler)\n                await self.connection.shutdown()\n            else:\n                self.stream.close(self.scheduler)\n            self.stream = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef createphysicalnetwork(type, create_processor = partial(default_processor, excluding=('id', 'type')),\n                                      reorder_dict = default_iterate_dict):\n    \"\"\"\n    :param type: physical network type\n    \n    :param create_processor: create_processor(physicalnetwork, walk, write, \\*, parameters)\n    \"\"\"\n    # create an new physical network\n    def walker(walk, write, timestamp, parameters_dict):\n        for key, parameters in reorder_dict(parameters_dict):\n            try:\n                value = walk(key)\n            except KeyError:\n                pass\n            else:\n                id_ = parameters['id']\n                new_network = create_new(PhysicalNetwork, value, id_)\n                new_network.type = type\n                \n                create_processor(new_network, walk, write, parameters=parameters)\n                write(key, new_network)\n                new_networkmap = PhysicalNetworkMap.create_instance(id_)\n                new_networkmap.network = new_network.create_weakreference()\n                write(new_networkmap.getkey(), new_networkmap)\n                \n                # Save into network set\n                try:\n                    physet = walk(PhysicalNetworkSet.default_key())\n                except KeyError:\n                    pass\n                else:\n                    physet.set.dataset().add(new_network.create_weakreference())\n                    write(physet.getkey(), physet)\n    return walker", "response": "Create a new physical network of the specified type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deletephysicalnetwork(check_processor = default_physicalnetwork_delete_check,\n                                reorder_dict = default_iterate_dict):\n    \"\"\"\n    :param check_processor: check_processor(physicalnetwork, physicalnetworkmap, walk, write, \\*, parameters)\n    \"\"\"\n    def walker(walk, write, timestamp, parameters_dict):\n        for key, parameters in reorder_dict(parameters_dict):\n            try:\n                value = walk(key)\n            except KeyError:\n                pass\n            else:\n                id_ = parameters['id']\n                try:\n                    phy_map = walk(PhysicalNetworkMap.default_key(id_))\n                except KeyError:\n                    pass\n                else:\n                    check_processor(value, phy_map, walk, write, parameters=parameters)\n                    write(phy_map.getkey(), None)\n                try:\n                    phynetset = walk(PhysicalNetworkSet.default_key())\n                except KeyError:\n                    pass\n                else:\n                    phynetset.set.dataset().discard(value.create_weakreference())\n                    write(phynetset.getkey(), phynetset)\n                write(key, None)\n    return walker", "response": "Returns a walker that deletes all physical network in the virtual network."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new PhysicalPort object.", "response": "def createphysicalport(create_processor = partial(default_processor, excluding=('vhost', 'systemid',\n                                                                                       'bridge', 'name',\n                                                                                       'physicalnetwork')),\n                       reorder_dict = default_iterate_dict):\n    \"\"\"\n    :param create_processor: create_processor(physicalport, physicalnetwork, physicalnetworkmap, walk, write, \\*, parameters)\n    \"\"\"\n    def walker(walk, write, timestamp, parameters_dict):\n        for key, parameters in reorder_dict(parameters_dict):\n            try:\n                value = walk(key)\n            except KeyError:\n                pass\n            else:\n                p = create_new(PhysicalPort, value, parameters['vhost'], parameters['systemid'],\n                                                    parameters['bridge'], parameters['name'])\n                try:\n                    physicalnetwork = walk(PhysicalNetwork.default_key(parameters['physicalnetwork']))\n                except KeyError:\n                    pass\n                else:\n                    # Should already been check from outside\n                    p.physicalnetwork = physicalnetwork.create_reference()\n                    try:\n                        phymap = walk(PhysicalNetworkMap._network.leftkey(physicalnetwork))\n                    except KeyError:\n                        pass\n                    else:\n                        create_processor(p, physicalnetwork, phymap, walk, write, parameters=parameters)\n                        phymap.ports.dataset().add(p.create_weakreference())\n                        write(phymap.getkey(), phymap)\n                try:\n                    phyportset = walk(PhysicalPortSet.default_key())\n                except KeyError:\n                    pass\n                else:\n                    phyportset.set.dataset().add(p.create_weakreference())\n                    write(phyportset.getkey(), phyportset)\n                write(p.getkey(), p)\n    return walker"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deletephysicalport(check_processor=_false_processor,\n                       reorder_dict = default_iterate_dict):\n    \"\"\"\n    :param check_processor: check_processor(physicalport, physicalnetwork, physicalnetworkmap,\n                            walk, write \\*, parameters)\n    \"\"\"\n    def walker(walk, write, timestamp, parameters_dict):\n        for key, parameters in reorder_dict(parameters_dict):\n            try:\n                value = walk(key)\n            except KeyError:\n                pass\n            else:\n                try:\n                    phynet = walk(value.physicalnetwork.getkey())\n                except KeyError:\n                    pass\n                else:\n                    try:\n                        phymap = walk(PhysicalNetworkMap._network.leftkey(phynet))\n                    except KeyError:\n                        pass\n                    else:\n                        check_processor(value, phynet, phymap, walk, write, parameters=parameters)\n                        phymap.ports.dataset().discard(value.create_weakreference())\n                        write(phymap.getkey(), phymap)\n                try:\n                    physet = walk(PhysicalPortSet.default_key())\n                except KeyError:\n                    pass\n                else:\n                    physet.set.dataset().discard(value.create_weakreference())\n                    write(physet.getkey(), physet)\n                write(key, None)\n    return walker", "response": "This function deletes a physicalport from the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new LogicalNetwork object and return it.", "response": "def createlogicalnetwork(create_processor = partial(default_processor, excluding=('id', 'physicalnetwork')),\n                         reorder_dict = default_iterate_dict):\n    \"\"\"\n    :param create_processor: create_processor(logicalnetwork, logicalnetworkmap, physicalnetwork,\n                             physicalnetworkmap, walk, write, \\*, parameters)\n    \"\"\"\n    def walker(walk, write, timestamp, parameters_dict):\n        for key, parameters in reorder_dict(parameters_dict):\n            try:\n                value = walk(key)\n            except KeyError:\n                pass\n            else:\n                id_ = parameters['id']\n                lognet = create_new(LogicalNetwork, value, id_)\n                logmap = LogicalNetworkMap.create_instance(id_)\n                logmap.network = lognet.create_reference()\n                try:\n                    phynet = walk(PhysicalNetwork.default_key(parameters['physicalnetwork']))\n                except KeyError:\n                    pass\n                else:\n                    lognet.physicalnetwork = phynet.create_reference()\n                    try:\n                        phymap = walk(PhysicalNetworkMap._network.leftkey(phynet))\n                    except KeyError:\n                        pass\n                    else:\n                        create_processor(lognet, logmap, phynet, phymap, walk, write, parameters=parameters)\n                        phymap.logicnetworks.dataset().add(lognet.create_weakreference())\n                        write(phymap.getkey(), phymap)\n                        write(lognet.getkey(), lognet)\n                        write(logmap.getkey(), logmap)\n                try:\n                    logicalnetworkset = walk(LogicalNetworkSet.default_key())\n                except KeyError:\n                    pass\n                else:\n                    logicalnetworkset.set.dataset().add(lognet.create_weakreference())\n                    write(logicalnetworkset.getkey(), logicalnetworkset)\n    return walker"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a walker that deletes the logicalnetwork from the logmap and physicalnetworkmap.", "response": "def deletelogicalnetwork(check_processor=default_logicalnetwork_delete_check,\n                         reorder_dict = default_iterate_dict):\n    \"\"\"\n    :param check_processor: check_processor(logicalnetwork, logicalnetworkmap,\n                                            physicalnetwork, physicalnetworkmap,\n                                            walk, write, \\*, parameters)\n    \"\"\"\n    def walker(walk, write, timestamp, parameters_dict):\n        for key, parameters in reorder_dict(parameters_dict):\n            try:\n                value = walk(key)\n            except KeyError:\n                pass\n            else:\n                try:\n                    logmap = walk(LogicalNetworkMap._network.leftkey(key))\n                except KeyError:\n                    pass\n                else:\n                    try:\n                        phynet = walk(value.physicalnetwork.getkey())\n                    except KeyError:\n                        pass\n                    else:\n                        try:\n                            phymap = walk(PhysicalNetworkMap._network.leftkey(phynet))\n                        except KeyError:\n                            pass\n                        else:\n                            check_processor(value, logmap, phynet, phymap, walk, write, parameters=parameters)\n                            phymap.logicnetworks.dataset().discard(value.create_weakreference())\n                            write(phymap.getkey(), phymap)\n                            write(key, None)\n                            write(logmap.getkey(), None)\n                try:\n                    logicalnetworkset = walk(LogicalNetworkSet.default_key())\n                except KeyError:\n                    pass\n                else:\n                    logicalnetworkset.set.dataset().discard(value.create_weakreference())\n                    write(logicalnetworkset.getkey(), logicalnetworkset)\n    return walker"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nforces an update notification on specified objects even if they are not actually updated in the DB.", "response": "def updateobjects(self, updatedvalues):\n        \"\"\"\n        Force a update notification on specified objects, even if they are not actually updated\n        in ObjectDB\n        \"\"\"\n        if not self._updatedset:\n            self.scheduler.emergesend(FlowUpdaterNotification(self, FlowUpdaterNotification.DATAUPDATED))\n        self._updatedset.update(set(updatedvalues).intersection(self._savedresult))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def _flowupdater(self):\n        lastresult = set(v for v in self._savedresult if v is not None and not v.isdeleted())\n        flowupdate = FlowUpdaterNotification.createMatcher(self, FlowUpdaterNotification.FLOWUPDATE)\n        while True:\n            currentresult = [v for v in self._savedresult if v is not None and not v.isdeleted()]\n            # Calculating differences\n            additems = []\n            updateditems = []\n            updatedset2 = self._updatedset2\n            for v in currentresult:\n                if v not in lastresult:\n                    additems.append(v)\n                else:\n                    lastresult.remove(v)\n                    if v in updatedset2:\n                        # Updated\n                        updateditems.append(v)\n            removeitems = lastresult\n            self._updatedset2.clear()\n            # Save current result for next difference\n            lastresult = set(currentresult)\n            if not additems and not removeitems and not updateditems:\n                await flowupdate\n                continue\n            await self.updateflow(self._connection, set(additems), removeitems, set(updateditems))", "response": "Coroutine calling updateflow for all flow updates."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nclearing a queue and call processor on all events in it", "response": "def syscall_clearqueue(queue):\n    '''\n    Clear a queue\n    '''\n    def _syscall(scheduler, processor):\n        qes, qees = queue.clear()\n        events = scheduler.queue.unblockqueue(queue)\n        for e in events:\n            scheduler.eventtree.remove(e)\n        for e in qes:\n            processor(e)\n        for e in qees:\n            processor(e)\n    return _syscall"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove subqueue from queue.", "response": "def syscall_removequeue(queue, index):\n    '''\n    Remove subqueue `queue[index]` from queue.\n    '''\n    def _syscall(scheduler, processor):\n        events = scheduler.queue.unblockqueue(queue[index])\n        for e in events:\n            scheduler.eventtree.remove(e)\n        qes, qees = queue.removeSubQueue(index)\n        for e in qes:\n            processor(e)\n        for e in qees:\n            processor(e)\n    return _syscall"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef syscall_clearremovequeue(queue, index):\n    '''\n    Clear the subqueue `queue[index]` and remove it from queue.\n    '''\n    def _syscall(scheduler, processor):\n        qes, qees = queue[index].clear()\n        events = scheduler.queue.unblockqueue(queue[index])\n        for e in events:\n            scheduler.eventtree.remove(e)\n        qes2, qees2 = queue.removeSubQueue(index)\n        for e in qes:\n            processor(e)\n        for e in qes2:\n            processor(e)\n        for e in qees:\n            processor(e)\n        for e in qees2:\n            processor(e)\n    return _syscall", "response": "Clear the subqueue queue [ index and remove it from queue.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register(self, matchers, runnable):\n        '''\n        Register an iterator(runnable) to scheduler and wait for events\n        \n        :param matchers: sequence of EventMatchers\n        \n        :param runnable: an iterator that accept send method\n        \n        :param daemon: if True, the runnable will be registered as a daemon.\n        '''\n        if getattr(self, 'syscallfunc', None) is not None and getattr(self, 'syscallrunnable', None) is None:\n            # Inject this register\n            self.syscallrunnable = runnable\n        else:\n            for m in matchers:\n                self.matchtree.insert(m, runnable)\n                events = self.eventtree.findAndRemove(m)\n                for e in events:\n                    self.queue.unblock(e)\n                if m.indices[0] == PollEvent._classname0 and len(m.indices) >= 2:\n                    self.polling.onmatch(m.indices[1], None if len(m.indices) <= 2 else m.indices[2], True)\n            self.registerIndex.setdefault(runnable, set()).update(matchers)", "response": "Register an iterator that accepts send method\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unregister(self, matchers, runnable):\n        '''\n        Unregister an iterator(runnable) and stop waiting for events\n        \n        :param matchers: sequence of EventMatchers\n        \n        :param runnable: an iterator that accept send method\n        '''\n        for m in matchers:\n            self.matchtree.remove(m, runnable)\n            if m.indices[0] == PollEvent._classname0 and len(m.indices) >= 2:\n                self.polling.onmatch(m.indices[1], None if len(m.indices) <= 2 else m.indices[2], False)\n        self.registerIndex.setdefault(runnable, set()).difference_update(matchers)", "response": "Unregisters an iterator that accepts send method\n yizi"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unregisterall(self, runnable):\n        '''\n        Unregister all matches and detach the runnable. Automatically called when runnable returns StopIteration.\n        '''\n        if runnable in self.registerIndex:\n            for m in self.registerIndex[runnable]:\n                self.matchtree.remove(m, runnable)\n                if m.indices[0] == PollEvent._classname0 and len(m.indices) >= 2:\n                    self.polling.onmatch(m.indices[1], None if len(m.indices) <= 2 else m.indices[2], False)\n            del self.registerIndex[runnable]\n            self.daemons.discard(runnable)", "response": "Unregisters all matches and detach the runnable. Automatically called when runnable returns StopIteration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nunblock and ignore the matched events", "response": "def ignore(self, matcher):\n        '''\n        Unblock and ignore the matched events, if any. \n        '''\n        events  = self.eventtree.findAndRemove(matcher)\n        for e in events:\n            self.queue.unblock(e)\n            e.canignore = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef quit(self, daemononly = False):\n        '''\n        Send quit event to quit the main loop\n        '''\n        if not self.quitting:\n            self.quitting = True\n            self.queue.append(SystemControlEvent(SystemControlEvent.QUIT, daemononly = daemononly), True)", "response": "Send quit event to quit the main loop"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a TimerEvent on the specified time.", "response": "def setTimer(self, start, interval = None):\n        '''\n        Generate a TimerEvent on specified time\n        \n        :param start: offset for time from now (seconds), or datetime for a fixed time\n        \n        :param interval: if not None, the timer is regenerated by interval seconds.\n        \n        :returns: a timer handle to wait or cancel the timer\n        '''\n        if isinstance(start, datetime):\n            timestamp = (start - datetime.fromtimestamp(0)).total_seconds()\n        else:\n            timestamp = self.current_time + start\n        if interval is not None:\n            if not (interval > 0):\n                raise ValueError('interval must be positive.')\n        th = self.TimerHandle(timestamp, interval)\n        self.timers.push(th, timestamp)\n        return th"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef registerPolling(self, fd, options = POLLING_IN|POLLING_OUT, daemon = False):\n        '''\n        register a polling file descriptor\n        \n        :param fd: file descriptor or socket object\n        \n        :param options: bit mask flags. Polling object should ignore the incompatible flag.\n        '''\n        self.polling.register(fd, options, daemon)", "response": "register a polling file descriptor fd"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setDaemon(self, runnable, isdaemon, noregister = False):\n        '''\n        If a runnable is a daemon, it will not keep the main loop running. The main loop will end when all alived runnables are daemons.\n        '''\n        if not noregister and runnable not in self.registerIndex:\n            self.register((), runnable)\n        if isdaemon:\n            self.daemons.add(runnable)\n        else:\n            self.daemons.discard(runnable)", "response": "Sets the runnable to be a daemon."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef syscall(self, func):\n        '''\n        Call the func in core context (main loop).\n        \n        func should like::\n        \n            def syscall_sample(scheduler, processor):\n                something...\n\n        where processor is a function which accept an event. When calling processor, scheduler directly process this event without\n        sending it to queue.\n        \n        An event matcher is returned to the caller, and the caller should wait for the event immediately to get the return value from the system call.\n        The SyscallReturnEvent will have 'retvalue' as the return value, or 'exception' as the exception thrown: (type, value, traceback)\n        \n        :param func: syscall function\n        \n        :returns: an event matcher to wait for the SyscallReturnEvent. If None is returned, a syscall is already scheduled;\n                  return to core context at first.\n        \n        '''\n        if getattr(self, 'syscallfunc', None) is not None:\n            return None\n        self.syscallfunc = func\n        self.syscallmatcher = SyscallReturnEvent.createMatcher()\n        return self.syscallmatcher", "response": "Call the function in core context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn current servers of vhost if vhost is None return all servers.", "response": "def getservers(self, vhost = None):\n        '''\n        Return current servers\n        \n        :param vhost: return only servers of vhost if specified. '' to return only default servers.\n                      None for all servers.\n        '''\n        if vhost is not None:\n            return [s for s in self.connections if s.protocol.vhost == vhost]\n        else:\n            return list(self.connections)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def stoplisten(self, vhost = None):\n        '''\n        Stop listen on current servers\n        \n        :param vhost: return only servers of vhost if specified. '' to return only default servers.\n                      None for all servers.\n        '''\n        servers = self.getservers(vhost)\n        for s in servers:\n            await s.stoplisten()\n        return len(servers)", "response": "Stop listen on current servers\n        \nCOOKIE"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def startlisten(self, vhost = None):\n        '''\n        Start listen on current servers\n        \n        :param vhost: return only servers of vhost if specified. '' to return only default servers.\n                      None for all servers.\n        '''\n        servers = self.getservers(vhost)\n        for s in servers:\n            await s.startlisten()\n        return len(servers)", "response": "Start listening on all servers in vhost."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def updateconfig(self):\n        \"Reload configurations, remove non-exist servers, add new servers, and leave others unchanged\"\n        exists = {}\n        for s in self.connections:\n            exists[(s.protocol.vhost, s.rawurl)] = s\n        self._createServers(self, '', exists = exists)\n        for _,v in exists.items():\n            await v.shutdown()\n            self.connections.remove(v)", "response": "Reload configurations remove non - exist servers add new servers and leave others unchanged"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getconnections(self, vhost = None):\n        \"Return accepted connections, optionally filtered by vhost\"\n        if vhost is None:\n            return list(self.managed_connections)\n        else:\n            return [c for c in self.managed_connections if c.protocol.vhost == vhost]", "response": "Return accepted connections optionally filtered by vhost"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle DHCP packets from OpenFlow.", "response": "async def _dhcp_handler(self):\n        \"\"\"\n        Mini DHCP server, respond DHCP packets from OpenFlow\n        \"\"\"\n        conn = self._connection\n        ofdef = self._connection.openflowdef\n        l3 = self._parent._gettableindex('l3input', self._connection.protocol.vhost)\n        dhcp_packet_matcher = OpenflowAsyncMessageEvent.createMatcher(ofdef.OFPT_PACKET_IN, None, None, l3, 1,\n                                                              self._connection, self._connection.connmark)\n        # These tags are important options. They are sent first to make sure the client\n        # correctly receive these options.\n        required_tags = [d.OPTION_MESSAGE_TYPE, d.OPTION_SERVER_IDENTIFIER,\n                         d.OPTION_NETMASK, d.OPTION_ROUTER,\n                         d.OPTION_DNSSERVER, d.OPTION_BROADCAST, d.OPTION_MTU,\n                         d.OPTION_LEASE_TIME, d.OPTION_T1, d.OPTION_T2]\n        server_mac = mac_addr(self._parent.servermac)\n        # IP fragment identifier\n        trans_id = uint16.create(os.urandom(2))\n        def set_options(payload, option_dict, provide_options, message_type, remove_lease = False):\n            \"\"\"\n            Set DHCP options to output payload regarding the incoming request\n            \n            :param payload: output DHCP payload\n            \n            :param option_dict: incoming DHCP options in request\n            \n            :param provide_options: all DHCP options that are ready to sent to the client\n            \n            :param message_type: output DHCP message type\n            \n            :param remove_lease: remove all leases options. DHCPINFORM cannot contain\n                                 leases options. See https://tools.ietf.org/html/rfc2131#section-3.4\n            \"\"\"\n            message_type_opt = d.dhcp_option_message_type(value = message_type)\n            if d.OPTION_REQUESTED_OPTIONS in option_dict:\n                # First requested options, then required options, then others\n                reqs = set(option_dict[d.OPTION_REQUESTED_OPTIONS].value)\n                send_tags = [t for t in option_dict[d.OPTION_REQUESTED_OPTIONS].value\n                             if t == d.OPTION_MESSAGE_TYPE or t in provide_options] \\\n                            + [t for t in required_tags\n                               if (t in provide_options or t == d.OPTION_MESSAGE_TYPE) and t not in reqs] \\\n                            + [t for t in provide_options\n                               if t not in reqs and t not in required_tags]\n            else:\n                # Required options, then others\n                send_tags = [t for t in required_tags\n                             if t in provide_options or t == d.OPTION_MESSAGE_TYPE] \\\n                            + [t for t in set(provide_options.keys()).difference(required_tags)]\n            # If the client has sent an option for max message size, use it; or use the RFC required 576 bytes\n            not_finished = d.build_options(\n                                payload,\n                                [message_type_opt if t == d.OPTION_MESSAGE_TYPE\n                                  else provide_options[t] for t in send_tags\n                                  if not remove_lease or (t != d.OPTION_LEASE_TIME and t != d.OPTION_T1 and t != OPTION_T2)],\n                                max(min(option_dict[d.OPTION_MAX_MESSAGE_SIZE].value, 1400), 576)\n                                if d.OPTION_MAX_MESSAGE_SIZE in option_dict\n                                else 576)\n        async def send_packet(pid, packet):\n            \"\"\"\n            Send DHCP packet to specified port\n            \"\"\"\n            await self.execute_commands(conn,\n                            [ofdef.ofp_packet_out(\n                                    buffer_id = ofdef.OFP_NO_BUFFER,\n                                    in_port = ofdef.OFPP_CONTROLLER,\n                                    actions = [ofdef.ofp_action_output(port = pid,\n                                                                       max_len = ofdef.OFPCML_NO_BUFFER)],\n                                    data = packet._tobytes()\n                                )])\n        while True:\n            ev = await dhcp_packet_matcher\n            msg = ev.message\n            try:\n                in_port = ofdef.ofp_port_no.create(ofdef.get_oxm(msg.match.oxm_fields, ofdef.OXM_OF_IN_PORT))\n                if in_port not in self._dhcpentries:\n                    # Not a DHCP-enabled port\n                    continue\n                port_mac, port_ip, server_ip, provide_options = self._dhcpentries[in_port]\n                # Fragmented DHCP packets are not supported - this is allowed according\n                # to RFC: server and clients are only needed to support at least 576 bytes\n                # DHCP messages.\n                l7_packet = ethernet_l7.create(msg.data)\n                dhcp_packet = d.dhcp_payload.create(l7_packet.data)\n                # We only process a DHCP request directly sent from the logical port\n                if (dhcp_packet.op != d.BOOTREQUEST                            # A DHCP server packet\n                        or dhcp_packet.hlen != 6 or dhcp_packet.htype != 1     # Hardware address not ethernet (48-bit)\n                        or dhcp_packet.magic_cookie != d.BOOTP_MAGIC_COOKIE    # Magic cookie not match\n                        or dhcp_packet.giaddr != 0):                           # A relayed DHCP message\n                    raise ValueError('Unsupported DHCP packet')\n                # Reassemble DHCP options\n                options = d.reassemble_options(dhcp_packet)\n                option_dict = dict((o.tag, o) for o in options)\n                if d.OPTION_MESSAGE_TYPE not in option_dict:\n                    raise ValueError('Message type not found')\n                message_type = option_dict[d.OPTION_MESSAGE_TYPE].value\n                is_nak = False\n                if message_type == d.DHCPDISCOVER:\n                    # A DHCPDISCOVER should get a DHCPOFFER response\n                    if dhcp_packet.chaddr[:6].ljust(6, b'\\x00') != mac_addr.tobytes(port_mac):\n                        # MAC address not match, ignore this packet\n                        continue\n                    dhcp_reply = d.dhcp_payload(op = d.BOOTREPLY,\n                                                htype = 1,\n                                                hlen = 6,\n                                                hops = 0,\n                                                xid = dhcp_packet.xid,\n                                                secs = 0,\n                                                flags = dhcp_packet.flags,\n                                                ciaddr = 0,\n                                                yiaddr = port_ip,\n                                                siaddr = 0,\n                                                giaddr = dhcp_packet.giaddr,\n                                                chaddr = dhcp_packet.chaddr,\n                                                magic_cookie = d.BOOTP_MAGIC_COOKIE\n                                                )\n                    set_options(dhcp_reply, option_dict, provide_options, d.DHCPOFFER)\n                elif message_type == d.DHCPREQUEST:\n                    # A DHCPREQUEST should get a DHCPACK reply\n                    if d.OPTION_SERVER_IDENTIFIER in option_dict and option_dict[d.OPTION_SERVER_IDENTIFIER].value != server_ip:\n                        # Ignore packets to wrong address\n                        continue\n                    if dhcp_packet.chaddr[:6].ljust(6, b'\\x00') != mac_addr.tobytes(port_mac) \\\n                            or (d.OPTION_REQUESTED_IP in option_dict and option_dict[d.OPTION_REQUESTED_IP].value != port_ip) \\\n                            or (dhcp_packet.ciaddr != 0 and dhcp_packet.ciaddr != port_ip):\n                        # Requested MAC or IP not matched, send a NACK\n                        dhcp_reply = d.dhcp_payload(op = d.BOOTREPLY,\n                                                    htype = 1,\n                                                    hlen = 6,\n                                                    hops = 0,\n                                                    xid = dhcp_packet.xid,\n                                                    secs = 0,\n                                                    flags = dhcp_packet.flags,\n                                                    ciaddr = 0,\n                                                    yiaddr = 0,\n                                                    siaddr = 0,\n                                                    giaddr = dhcp_packet.giaddr,\n                                                    chaddr = dhcp_packet.chaddr,\n                                                    magic_cookie = d.BOOTP_MAGIC_COOKIE\n                                                    )\n                        # Do not send more options in NACK\n                        d.build_options(dhcp_reply, [d.dhcp_option_message_type(value = d.DHCPNAK),\n                                                     d.dhcp_option_address(tag = d.OPTION_SERVER_IDENTIFIER,\n                                                                           value = server_ip)], 576, 0)\n                        is_nak = True\n                    else:\n                        dhcp_reply = d.dhcp_payload(op = d.BOOTREPLY,\n                                                    htype = 1,\n                                                    hlen = 6,\n                                                    hops = 0,\n                                                    xid = dhcp_packet.xid,\n                                                    secs = 0,\n                                                    flags = dhcp_packet.flags,\n                                                    ciaddr = dhcp_packet.ciaddr,\n                                                    yiaddr = port_ip,\n                                                    siaddr = 0,\n                                                    giaddr = dhcp_packet.giaddr,\n                                                    chaddr = dhcp_packet.chaddr,\n                                                    magic_cookie = d.BOOTP_MAGIC_COOKIE\n                                                    )\n                        set_options(dhcp_reply, option_dict, provide_options, d.DHCPACK)\n                elif message_type == d.DHCPDECLINE:\n                    # Address already in use?\n                    self._logger.warning('DHCP client reports DHCPDECLINE, there should be some problems.'\\\n                                         ' Connection = %r(%016x), port = %d.',\n                                         self._connection, self._connection.openflow_datapathid)\n                elif message_type == d.DHCPRELEASE:\n                    # Safe to ignore, we do not use a dynamic IP address pool\n                    continue\n                elif message_type == d.DHCPINFORM:\n                    # Client setup IP addresses itself, but requesting more information\n                    # DHCPINFORM reply cannot have lease options, and yiaddr = 0\n                    dhcp_reply = d.dhcp_payload(op = d.BOOTREPLY,\n                                                htype = 1,\n                                                hlen = 6,\n                                                hops = 0,\n                                                xid = dhcp_packet.xid,\n                                                secs = 0,\n                                                flags = dhcp_packet.flags,\n                                                ciaddr = dhcp_packet.ciaddr,\n                                                yiaddr = 0,\n                                                siaddr = 0,\n                                                giaddr = dhcp_packet.giaddr,\n                                                chaddr = dhcp_packet.chaddr,\n                                                magic_cookie = d.BOOTP_MAGIC_COOKIE\n                                                )\n                    set_options(dhcp_reply, option_dict, provide_options, d.DHCPACK, True)\n                trans_id = (trans_id + 1) & 0xffff\n                if (dhcp_packet.flags & d.DHCPFLAG_BROADCAST) or is_nak:\n                    # client request broadcast, or DHCPNAK\n                    # RFC requires that DHCPNAK uses broadcast\n                    dl_dst = [0xff, 0xff, 0xff, 0xff, 0xff, 0xff]\n                    ip_dst = 0xffffffff\n                else:\n                    dl_dst = l7_packet.dl_src\n                    ip_dst = port_ip\n                reply_packet = ip4_packet_l7((ip4_payload, ip4_udp_payload),\n                                           dl_src = server_mac,\n                                           dl_dst = dl_dst,\n                                           identifier = trans_id,\n                                           ttl = 128,\n                                           ip_src = server_ip,\n                                           ip_dst = ip_dst,\n                                           sport = 67,\n                                           dport = 68,\n                                           data = dhcp_reply._tobytes()\n                                           )\n                # Send packet to the incoming port\n                self.subroutine(send_packet(in_port, reply_packet), True)\n            except Exception:\n                self._logger.info('Invalid DHCP packet received: %r', msg.data, exc_info = True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef return_self_updater(func):\n    '''\n    Run func, but still return v. Useful for using knowledge.update with operates like append, extend, etc.\n    e.g. return_self(lambda k,v: v.append('newobj'))\n    '''\n    @functools.wraps(func)\n    def decorator(k,v):\n        func(k,v)\n        return v\n    return decorator", "response": "Decorator for returning self updater."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef date_time_string(timestamp=None):\n    global _last_date_time_string\n    _last_timestamp, _last_str = _last_date_time_string\n    if timestamp is None:\n        timestamp = time.time()\n    _curr_timestamp = int(timestamp)\n    if _curr_timestamp == _last_timestamp:\n        return _last_str\n    else:\n        year, month, day, hh, mm, ss, wd, y, z = time.gmtime(timestamp)\n        s = b\"%s, %02d %3s %4d %02d:%02d:%02d GMT\" % (\n                weekdayname[wd],\n                day, monthname[month], year,\n                hh, mm, ss)\n        _last_date_time_string = (_curr_timestamp, s)\n        return s", "response": "Return the current date and time formatted for a message header."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef escape_b(s, quote=True):\n    '''Replace special characters \"&\", \"<\" and \">\" to HTML-safe sequences.\n    If the optional flag quote is true, the quotation mark character (\")\n    is also translated.'''\n    s = s.replace(b\"&\", b\"&amp;\") # Must be done first!\n    s = s.replace(b\"<\", b\"&lt;\")\n    s = s.replace(b\">\", b\"&gt;\")\n    if quote:\n        s = s.replace(b'\"', b\"&quot;\")\n    return s", "response": "Replace special characters &lt and > to HTML - safe sequences."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeprecates - use request_context for most use cases", "response": "def watch_context(keys, result, reqid, container, module = 'objectdb'):\n    \"\"\"\n    DEPRECATED - use request_context for most use cases\n    \"\"\"\n    try:\n        keys = [k for k,r in zip(keys, result) if r is not None]\n        yield result\n    finally:\n        if keys:\n            async def clearup():\n                try:\n                    await send_api(container, module, 'munwatch', {'keys': keys, 'requestid': reqid})\n                except QuitException:\n                    pass\n            container.subroutine(clearup(), False)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef updater(f):\n    \"Decorate a function with named arguments into updater for transact\"\n    @functools.wraps(f)\n    def wrapped_updater(keys, values):\n        result = f(*values)\n        return (keys[:len(result)], result)\n    return wrapped_updater", "response": "Decorate a function with named arguments into updater for transact"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecorate a function with named lists into updater for transact. :params \\*args: parameter list sizes. -1 means all other items. None means a single item instead of a list. only one -1 is allowed.", "response": "def list_updater(*args):\n    \"\"\"\n    Decorate a function with named lists into updater for transact.\n    \n    :params \\*args: parameter list sizes. -1 means all other items. None means a single item instead of a list.\n                    only one -1 is allowed.\n    \"\"\"\n    neg_index = [i for v,i in izip(args, itertools.count()) if v is not None and v < 0]\n    if len(neg_index) > 1:\n        raise ValueError(\"Cannot use negative values more than once\")\n    if not neg_index:\n        slice_list = []\n        size = 0\n        for arg in args:\n            if arg is None:\n                slice_list.append(size)\n                size += 1\n            else:\n                slice_list.append(slice(size, size + arg))\n                size += arg\n    else:\n        sep = neg_index[0]\n        slice_list = []\n        size = 0\n        for arg in args[:sep]:\n            if arg is None:\n                slice_list.append(size)\n                size += 1\n            else:\n                slice_list.append(slice(size, size + arg))\n                size += arg\n        rslice_list = []\n        rsize = 0\n        for arg in args[:sep:-1]:\n            if arg is None:\n                rslice_list.append(-1-rsize)\n                rsize += 1\n            else:\n                rslice_list.append(slice(None if not rsize else -rsize, -(rsize + arg)))\n                rsize += arg\n        slice_list.append(slice(size, rsize))\n        slice_list.extend(reversed(rslice_list))\n    def inner_wrapper(f):\n        @functools.wraps(f)\n        def wrapped_updater(keys, values):\n            result = f(*[values[s] for s in slice_list])\n            return (keys[:len(result)], result)\n        return wrapped_updater\n    return inner_wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_new(cls, oldvalue, *args):\n    \"Raise  if the old value already exists\"\n    if oldvalue is not None:\n        raise AlreadyExistsException('%r already exists' % (oldvalue,))\n    return cls.create_instance(*args)", "response": "Raise if the old value already exists"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_from_key(cls, oldvalue, key):\n    \"Raise  if the old value already exists\"\n    if oldvalue is not None:\n        raise AlreadyExistsException('%r already exists' % (oldvalue,))\n    return cls.create_from_key(key)", "response": "Raise if the old value already exists"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshowing full value of a data object", "response": "def dump(obj, attributes = True, _refset = None):\n    \"Show full value of a data object\"\n    if _refset is None:\n        _refset = set()\n    if obj is None:\n        return None\n    elif isinstance(obj, DataObject):        \n        if id(obj) in _refset:\n            attributes = False\n        else:\n            _refset.add(id(obj))\n        cls = type(obj)\n        clsname = getattr(cls, '__module__', '<unknown>') + '.' + getattr(cls, '__name__', '<unknown>')\n        baseresult = {'_type': clsname, '_key': obj.getkey()}\n        if not attributes:\n            return baseresult\n        else:\n            baseresult.update((k,dump(v, attributes, _refset)) for k,v in vars(obj).items() if k[:1] != '_')\n            _refset.remove(id(obj))\n        return baseresult\n    elif isinstance(obj, ReferenceObject):\n        if obj._ref is not None:\n            return dump(obj._ref, attributes, _refset)\n        else:\n            return {'_ref':obj.getkey()}\n    elif isinstance(obj, WeakReferenceObject):\n        return {'_weakref':obj.getkey()}\n    elif isinstance(obj, DataObjectSet):\n        return dump(list(obj.dataset()))\n    elif isinstance(obj, dict):\n        return dict((k, dump(v, attributes, _refset)) for k,v in obj.items())\n    elif isinstance(obj, list) or isinstance(obj, tuple) or isinstance(obj, set):\n        return [dump(v, attributes, _refset) for v in obj]\n    else:\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall vtep controller in sequence, merge mutiple calls if possible When a bind relationship is updated, we always send all logical ports to a logicalswitch, to make sure it recovers from some failed updates (so called idempotency). When multiple calls are pending, we only need to send the last of them.", "response": "async def action_handler(self):\n        \"\"\"\n        Call vtep controller in sequence, merge mutiple calls if possible\n        \n        When a bind relationship is updated, we always send all logical ports to a logicalswitch,\n        to make sure it recovers from some failed updates (so called idempotency). When multiple\n        calls are pending, we only need to send the last of them.\n        \"\"\"\n        bind_event = VtepControllerCall.createMatcher(self._conn)\n        event_queue = []\n        timeout_flag = [False]\n\n        async def handle_action():\n            while event_queue or timeout_flag[0]:\n                events = event_queue[:]\n                del event_queue[:]\n\n                for e in events:\n                    # every event must have physname , phyiname\n                    # physname: physical switch name - must be same with OVSDB-VTEP switch\n                    # phyiname: physical port name - must be same with the corresponding port\n                    physname = e.physname\n                    phyiname = e.phyiname\n                    if e.type == VtepControllerCall.UNBINDALL:\n                        # clear all other event info\n                        self._store_event[(physname,phyiname)] = {\"all\":e}\n                    elif e.type == VtepControllerCall.BIND:\n                        # bind will combine bind event before\n                        vlanid = e.vlanid\n                        if (physname,phyiname) in self._store_event:\n                            v = self._store_event[(physname,phyiname)]\n\n                            if vlanid in v:\n                                logicalports = e.logicalports\n                                v.update({vlanid:(e.type,e.logicalnetworkid,e.vni,logicalports)})\n                                self._store_event[(physname,phyiname)] = v\n                            else:\n                                # new bind info , no combind event\n                                v.update({vlanid:(e.type,e.logicalnetworkid,e.vni,e.logicalports)})\n                                self._store_event[(physname,phyiname)] = v\n                        else:\n                            self._store_event[(physname,phyiname)] = {vlanid:(e.type,e.logicalnetworkid,\n                                                                              e.vni,e.logicalports)}\n\n                    elif e.type == VtepControllerCall.UNBIND:\n\n                        vlanid = e.vlanid\n\n                        if (physname,phyiname) in self._store_event:\n                            v = self._store_event[(physname,phyiname)]\n                            v.update({vlanid:(e.type,e.logicalnetworkid)})\n                            self._store_event[(physname,phyiname)] = v\n                        else:\n                            self._store_event[(physname,phyiname)] = {vlanid:(e.type,e.logicalnetworkid)}\n\n                    else:\n                        self._parent._logger.warning(\"catch error type event %r , ignore it\", exc_info=True)\n                        continue\n\n                call = []\n                target_name = \"vtepcontroller\"\n                for k,v in self._store_event.items():\n                    if \"all\" in v:\n                        # send unbindall\n                        call.append(self.api(self,target_name,\"unbindphysicalport\",\n                                             {\"physicalswitch\": k[0], \"physicalport\": k[1]},\n                                             timeout=10))\n                        # unbindall , del it whatever\n                        del v[\"all\"]\n\n                try:\n                    await self.execute_all(call)\n                except Exception:\n                    self._parent._logger.warning(\"unbindall remove call failed\", exc_info=True)\n\n                for k,v in self._store_event.items():\n                    for vlanid , e in dict(v).items():\n                        if vlanid != \"all\":\n                            if e[0] == VtepControllerCall.BIND:\n\n                                params = {\"physicalswitch\": k[0],\n                                            \"physicalport\": k[1],\n                                            \"vlanid\": vlanid,\n                                            \"logicalnetwork\": e[1],\n                                            \"vni\":e[2],\n                                            \"logicalports\": e[3]}\n\n                                try:\n                                    await self.api(self,target_name,\"updatelogicalswitch\",\n                                                  params,timeout=10)\n                                except Exception:\n                                    self._parent._logger.warning(\"update logical switch error,try next %r\",params, exc_info=True)\n                                else:\n                                    del self._store_event[k][vlanid]\n\n                            elif e[0] == VtepControllerCall.UNBIND:\n\n                                params = {\"logicalnetwork\":e[1],\n                                                \"physicalswitch\":k[0],\n                                                \"physicalport\":k[1],\n                                                  \"vlanid\":vlanid}\n\n                                try:\n                                    await self.api(self,target_name,\"unbindlogicalswitch\",\n                                                      params,timeout=10)\n                                except Exception:\n                                    self._parent._logger.warning(\"unbind logical switch error,try next %r\",params, exc_info=True)\n                                else:\n                                    del self._store_event[k][vlanid]\n\n                self._store_event = dict((k,v) for k,v in self._store_event.items() if v)\n\n                if timeout_flag[0]:\n                    timeout_flag[0] = False\n\n        def append_event(event, matcher):\n            event_queue.append(event)\n\n        while True:\n            timeout, ev, m = await self.wait_with_timeout(10, bind_event)\n\n            if not timeout:\n                event_queue.append(ev)\n            else:\n                timeout_flag[0] = True\n\n            await self.with_callback(handle_action(), append_event, bind_event)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def update_ports(self, ports, ovsdb_ports):\n        new_port_names = dict((p['name'], _to32bitport(p['ofport'])) for p in ovsdb_ports)\n        new_port_ids = dict((p['id'], _to32bitport(p['ofport'])) for p in ovsdb_ports if p['id'])\n        if new_port_names == self._portnames and new_port_ids == self._portids:\n            return\n        self._portnames.clear()\n        self._portnames.update(new_port_names)\n        self._portids.clear()\n        self._portids.update(new_port_ids)\n\n        logicalportkeys = [LogicalPort.default_key(id) for id in self._portids]\n\n        self._original_initialkeys = logicalportkeys + [PhysicalPortSet.default_key()]\n        self._initialkeys = tuple(itertools.chain(self._original_initialkeys, self._append_initialkeys))\n        phy_walker = partial(self._physicalport_walker, _portnames=new_port_names)\n        log_walker = partial(self._logicalport_walker, _portids=new_port_ids)\n        self._walkerdict = dict(itertools.chain(\n            ((PhysicalPortSet.default_key(),phy_walker),),\n            ((lgportkey,log_walker) for lgportkey in logicalportkeys)\n        ))\n        self._portnames = new_port_names\n        self._portids = new_port_ids\n        await self.restart_walk()", "response": "Update the internal port information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_proxy(root_package = 'vlcp'):\n    '''\n    Walk through all the sub modules, find subclasses of vlcp.server.module._ProxyModule,\n    list their default values\n    '''\n    proxy_dict = OrderedDict()\n    pkg = __import__(root_package, fromlist=['_'])\n    for imp, module, _ in walk_packages(pkg.__path__, root_package + '.'):\n        m = __import__(module, fromlist = ['_'])\n        for _, v in vars(m).items():\n            if v is not None and isinstance(v, type) and issubclass(v, _ProxyModule) \\\n                    and v is not _ProxyModule \\\n                    and v.__module__ == module \\\n                    and hasattr(v, '_default'):\n                name = v.__name__.lower()\n                if name not in proxy_dict:\n                    proxy_dict[name] = {'defaultmodule': v._default.__name__.lower(),\n                                        'class': repr(v._default.__module__ + '.' + v._default.__name__)}\n    return proxy_dict", "response": "List all the proxy modules in the specified root_package."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_modules(root_package = 'vlcp'):\n    '''\n    Walk through all the sub modules, find subclasses of vlcp.server.module.Module,\n    list their apis through apidefs\n    '''\n    pkg = __import__(root_package, fromlist=['_'])\n    module_dict = OrderedDict()\n    _server = Server()\n    for imp, module, _ in walk_packages(pkg.__path__, root_package + '.'):\n        m = __import__(module, fromlist = ['_'])\n        for name, v in vars(m).items():\n            if v is not None and isinstance(v, type) and issubclass(v, Module) \\\n                    and v is not Module \\\n                    and not isinstance(v, _ProxyModule) \\\n                    and hasattr(v, '__dict__') and 'configkey' in v.__dict__ \\\n                    and v.__module__ == module:\n                module_name = v.__name__.lower()\n                if module_name not in module_dict:\n                    _inst = v(_server)\n                    module_info = OrderedDict((('class', v.__module__ + '.' + v.__name__),\n                                                ('dependencies', [d.__name__.lower()\n                                                                  for d in v.depends]),\n                                                ('classdescription', getdoc(v)),\n                                                ('apis', [])))\n                    if hasattr(_inst, 'apiHandler'):\n                        apidefs = _inst.apiHandler.apidefs\n                        module_info['apis'] = [(d[0], d[3])\n                                               for d in apidefs\n                                               if len(d) > 3 and \\\n                                               not d[0].startswith('public/')]\n                    module_dict[module_name] = module_info\n    return module_dict", "response": "List all the modules in the specified root_package."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nappends an event to the queue.", "response": "def append(self, event, force = False):\n        '''\n        Append an event to queue. The events are classified and appended to sub-queues\n        \n        :param event: input event\n        \n        :param force: if True, the event is appended even if the queue is full\n        \n        :returns: None if appended successfully, or a matcher to match a QueueCanWriteEvent otherwise\n        '''\n        if self.tree is None:\n            if self.parent is None:\n                raise IndexError('The queue is removed')\n            else:\n                return self.parent.parent.append(event, force)\n        q = self.tree.matchfirst(event)\n        return q.append(event, force)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nblocks the specified event and all subsequent events until unblock.", "response": "def block(self, event, emptyEvents = ()):\n        '''\n        Return a recently popped event to queue, and block all later events until unblock.\n        \n        Only the sub-queue directly containing the event is blocked, so events in other queues may still be processed.\n        It is illegal to call block and unblock in different queues with a same event.\n        \n        :param event: the returned event. When the queue is unblocked later, this event will be popped again.\n        \n        :param emptyEvents: reactivate the QueueIsEmptyEvents\n        '''\n        q = self.tree.matchfirst(event)\n        q.block(event)\n        self.blockEvents[event] = q\n        for ee in emptyEvents:\n            ee.queue.waitForEmpty()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unblock(self, event):\n        '''\n        Remove a block \n        '''\n        if event not in self.blockEvents:\n            return\n        self.blockEvents[event].unblock(event)\n        del self.blockEvents[event]", "response": "Remove a block \n        from the event list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving blocked events from the queue and all subqueues. Usually used after queue clear or unblockall.", "response": "def unblockqueue(self, queue):\n        '''\n        Remove blocked events from the queue and all subqueues. Usually used after queue clear/unblockall to prevent leak.\n        \n        :returns: the cleared events\n        '''\n        subqueues = set()\n        def allSubqueues(q):\n            subqueues.add(q)\n            subqueues.add(q.defaultQueue)\n            for v in q.queueindex.values():\n                if len(v) == 3:\n                    allSubqueues(v[1])\n        allSubqueues(queue)\n        events = [k for k,v in self.blockEvents.items() if v in subqueues]\n        for e in events:\n            del self.blockEvents[e]\n        return events"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unblockall(self):\n        '''\n        Remove all blocks from the queue and all sub-queues\n        '''\n        for q in self.queues.values():\n            q.unblockall()\n        self.blockEvents.clear()", "response": "Remove all blocks from the queue and all sub - queues."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef notifyPop(self, queue, length = 1):\n        '''\n        Internal notify for sub-queues been poped\n        \n        :returns: List of any events generated by this pop\n        '''\n        self.totalSize = self.totalSize - length\n        ret1 = []\n        ret2 = []\n        if self.isWaited and self.canAppend():\n            self.isWaited = False\n            ret1.append(QueueCanWriteEvent(self))\n        if self.isWaitEmpty and not self:\n            self.isWaitEmpty = False\n            ret2.append(QueueIsEmptyEvent(self))\n        if self.parent is not None:\n            pr = self.parent.notifyPop(self, length)\n            ret1 += pr[0]\n            ret2 += pr[1]\n        newblocked =  not self.canPop()\n        if newblocked != self.blocked:\n            self.blocked = newblocked\n            if self.parent is not None:\n                self.parent.notifyBlock(self, newblocked)\n        return (ret1, ret2)", "response": "Internal notify for sub - queues been popped\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npopping an event from the queue.", "response": "def pop(self):\n        '''\n        Pop an event from the queue. The event in the queue with higher priority is popped before ones in lower priority.\n        If there are multiple queues with the same priority, events are taken in turn from each queue.\n        May return some queueEvents indicating that some of the queues can be written into.\n        \n        :returns: `(obj, (queueEvents,...), (queueEmptyEvents,...))` where obj is the popped event, queueEvents are QueueCanWriteEvents generated by this pop\n                  and queueEmptyEvents are QueueIsEmptyEvents generated by this pop\n        '''\n        ret = self._pop()\n        if self.parent is not None:\n            pr = self.parent.notifyPop(self)\n            ret[1].extend(pr[0])\n            ret[2].extend(pr[1])\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _pop(self):\n        '''\n        Actual pop\n        '''\n        if not self.canPop():\n            raise IndexError('pop from an empty or blocked queue')\n        priority = self.prioritySet[-1]\n        ret = self.queues[priority]._pop()\n        self.outputStat = self.outputStat + 1\n        self.totalSize = self.totalSize - 1\n        if self.isWaited and self.canAppend():\n            self.isWaited = False\n            ret[1].append(QueueCanWriteEvent(self))\n        if self.isWaitEmpty and not self:\n            self.isWaitEmpty = False\n            ret[2].append(QueueIsEmptyEvent(self))\n        return ret", "response": "Actual pop\n            from the queue."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclears all the events in this queue including any sub - queues.", "response": "def clear(self):\n        '''\n        Clear all the events in this queue, including any sub-queues.\n        \n        :returns: ((queueEvents,...), (queueEmptyEvents,...)) where queueEvents are QueueCanWriteEvents generated by clearing.\n        '''\n        l = len(self)\n        ret = self._clear()\n        if self.parent is not None:\n            pr = self.parent.notifyPop(self, l)\n            ret[0].extend(pr[0])\n            ret[1].extend(pr[1])\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _clear(self):\n        '''\n        Actual clear\n        '''\n        ret = ([],[])\n        for q in self.queues.values():\n            pr = q._clear()\n            ret[0].extend(pr[0])\n            ret[1].extend(pr[1])\n        self.totalSize = 0\n        del self.prioritySet[:]\n        if self.isWaited and self.canAppend():\n            self.isWaited = False\n            ret[0].append(QueueCanWriteEvent(self))\n        if self.isWaitEmpty and not self:\n            self.isWaitEmpty = False\n            ret[1].append(QueueIsEmptyEvent(self))\n        self.blockEvents.clear()\n        return ret", "response": "Internal method to clear the internal state of the internal state."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setPriority(self, queue, priority):\n        '''\n        Set priority of a sub-queue\n        '''\n        q = self.queueindex[queue]\n        self.queues[q[0]].removeSubQueue(q[1])\n        newPriority = self.queues.setdefault(priority, CBQueue.MultiQueue(self, priority))\n        q[0] = priority\n        newPriority.addSubQueue(q[1])", "response": "Set priority of a sub - queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a sub - queue to current queue with a priority and a matcher", "response": "def addSubQueue(self, priority, matcher, name = None, maxdefault = None, maxtotal = None, defaultQueueClass = FifoQueue):\n        '''\n        add a sub queue to current queue, with a priority and a matcher\n        \n        :param priority: priority of this queue. Larger is higher, 0 is lowest.\n        \n        :param matcher: an event matcher to catch events. Every event match the criteria will be stored in this queue.\n        \n        :param name: a unique name to identify the sub-queue. If none, the queue is anonymous. It can be any hashable value.\n        \n        :param maxdefault: max length for default queue.\n        \n        :param maxtotal: max length for sub-queue total, including sub-queues of sub-queue\n        '''\n        if name is not None and name in self.queueindex:\n            raise IndexError(\"Duplicated sub-queue name '\" + str(name) + \"'\")\n        subtree = self.tree.subtree(matcher, True)\n        newPriority = self.queues.setdefault(priority, CBQueue.MultiQueue(self, priority))\n        newQueue = CBQueue(subtree, newPriority, maxdefault, maxtotal, defaultQueueClass)\n        newPriority.addSubQueue(newQueue)\n        qi = [priority, newQueue, name]\n        if name is not None:\n            self.queueindex[name] = qi\n        self.queueindex[newQueue] = qi\n        return newQueue"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving a sub - queue from current queue.", "response": "def removeSubQueue(self, queue):\n        '''\n        remove a sub queue from current queue.\n        \n        This unblock the sub-queue, retrieve all events from the queue and put them back to the parent.\n        \n        Call clear on the sub-queue first if the events are not needed any more.\n        \n        :param queue: the name or queue object to remove\n        \n        :returns: ((queueevents,...), (queueEmptyEvents,...)) Possible queue events from removing sub-queues\n        '''\n        q = self.queueindex[queue]\n        q[1].unblockall()\n        q[1]._removeFromTree()\n        ret = ([],[])\n        while q[1].canPop():\n            r = q[1].pop()\n            self.append(r[0], True)\n            ret[0].extend(r[1])\n            ret[1].extend(r[2])\n        self.queues[q[0]].removeSubQueue(q[1])\n        # Remove from index\n        if q[2] is not None:\n            del self.queueindex[q[2]]\n        del self.queueindex[q[1]]\n        newblocked =  not self.canPop()\n        if newblocked != self.blocked:\n            self.blocked = newblocked\n            if self.parent is not None:\n                self.parent.notifyBlock(self, newblocked)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ensure_keys(walk, *keys):\n    all_retrieved = True\n    for k in keys:\n        try:\n            walk(k)\n        except WalkKeyNotRetrieved:\n            all_retrieved = False\n    return all_retrieved", "response": "Check if all keys are available in a tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_config(root_package = 'vlcp'):\n    '''\n    Walk through all the sub modules, find subclasses of vlcp.config.Configurable,\n    list their available configurations through _default_ prefix\n    '''\n    pkg = __import__(root_package, fromlist=['_'])\n    return_dict = OrderedDict()\n    for imp, module, _ in walk_packages(pkg.__path__, root_package + '.'):\n        m = __import__(module, fromlist = ['_'])\n        for name, v in vars(m).items():\n            if v is not None and isinstance(v, type) and issubclass(v, Configurable) \\\n                    and v is not Configurable \\\n                    and hasattr(v, '__dict__') and 'configkey' in v.__dict__ \\\n                    and v.__module__ == module:\n                configkey = v.__dict__['configkey']\n                if configkey not in return_dict:\n                    configs = OrderedDict()\n                    v2 = v\n                    parents = [v2]\n                    while True:\n                        parent = None\n                        for c in v2.__bases__:\n                            if issubclass(c, Configurable):\n                                parent = c\n                        if parent is None or parent is Configurable:\n                            break\n                        if hasattr(parent, '__dict__') and 'configkey' not in parent.__dict__:\n                            parents.append(parent)\n                            v2 = parent\n                        else:\n                            break\n                    for v2 in reversed(parents):\n                        tmp_configs = {}\n                        for k, default_value in v2.__dict__.items():\n                            if k.startswith('_default_'):\n                                config_attr = k[len('_default_'):]\n                                if config_attr in v.__dict__:\n                                    continue\n                                configname = configkey + '.' + config_attr\n                                tmp_configs.setdefault(configname, OrderedDict())['default'] = \\\n                                    pformat(default_value, width=10)\n                        # Inspect the source lines to find remarks for these configurations\n                        lines, _ = getsourcelines(v2)\n                        last_remark = []\n                        for l in lines:\n                            l = l.strip()\n                            if not l:\n                                continue\n                            if l.startswith('#'):\n                                last_remark.append(l[1:])\n                            else:\n                                if l.startswith('_default_'):\n                                    key, sep, _ = l.partition('=')\n                                    if sep and key.startswith('_default_'):\n                                        configname = configkey + '.' +  key[len('_default_'):].strip()\n                                        if configname in tmp_configs and configname not in configs:\n                                            configs[configname] = tmp_configs.pop(configname)\n                                        if configname in configs and last_remark:\n                                            configs[configname]['description'] = cleandoc('\\n' + '\\n'.join(last_remark))\n                                del last_remark[:]\n                        for key in tmp_configs:\n                            if key not in configs:\n                                configs[key] = tmp_configs[key]\n                    if configs:\n                        return_dict[configkey] = OrderedDict((('class', v.__module__ + '.' + name),\n                                                             ('classdescription', getdoc(v)),\n                                                             ('configs', configs)))\n    return return_dict", "response": "List all available configurations in a VLCP package."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwrapping a WSGI - style class method to a HTTPRequest event handler", "response": "def http(container = None):\n    \"wrap a WSGI-style class method to a HTTPRequest event handler\"\n    def decorator(func):\n        @functools.wraps(func)\n        def handler(self, event):\n            return _handler(self if container is None else container, event, lambda env: func(self, env))\n        return handler\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwrapping a WSGI - style function to a HTTPRequest event handler", "response": "def statichttp(container = None):\n    \"wrap a WSGI-style function to a HTTPRequest event handler\"\n    def decorator(func):\n        @functools.wraps(func)\n        def handler(event):\n            return _handler(container, event, func)\n        if hasattr(func, '__self__'):\n            handler.__self__ = func.__self__\n        return handler\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting to send response", "response": "def start_response(self, status = 200, headers = [], clearheaders = True, disabletransferencoding = False):\n        \"Start to send response\"\n        if self._sendHeaders:\n            raise HttpProtocolException('Cannot modify response, headers already sent')\n        self.status = status\n        self.disabledeflate = disabletransferencoding\n        if clearheaders:\n            self.sent_headers = headers[:]\n        else:\n            self.sent_headers.extend(headers)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a new header", "response": "def header(self, key, value, replace = True):\n        \"Send a new header\"\n        if hasattr(key, 'encode'):\n            key = key.encode('ascii')\n        if hasattr(value, 'encode'):\n            value = value.encode(self.encoding)\n        if replace:\n            self.sent_headers = [(k,v) for k,v in self.sent_headers if k.lower() != key.lower()]\n        self.sent_headers.append((key, value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rawheader(self, kv, replace = True):\n        if hasattr(kv, 'encode'):\n            kv = kv.encode(self.encoding)\n        k,v = kv.split(b':', 1)\n        self.header(k, v.strip(), replace)", "response": "Add a header with \"<Header>: Value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setcookie(self, key, value, max_age=None, expires=None, path='/', domain=None, secure=None, httponly=False):\n        newcookie = Morsel()\n        newcookie.key = key\n        newcookie.value = value\n        newcookie.coded_value = value\n        if max_age is not None:\n            newcookie['max-age'] = max_age\n        if expires is not None:\n            newcookie['expires'] = expires\n        if path is not None:\n            newcookie['path'] = path\n        if domain is not None:\n            newcookie['domain'] = domain\n        if secure:\n            newcookie['secure'] = secure\n        if httponly:\n            newcookie['httponly'] = httponly\n        self.sent_cookies = [c for c in self.sent_cookies if c.key != key]\n        self.sent_cookies.append(newcookie)", "response": "Add a new cookie to the list of sent cookies."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuffers the whole output until EOF or flushed.", "response": "def bufferoutput(self):\n        \"\"\"\n        Buffer the whole output until write EOF or flushed.\n        \"\"\"\n        new_stream = Stream(writebufferlimit=None)\n        if self._sendHeaders:\n            # An extra copy\n            self.container.subroutine(new_stream.copy_to(self.outputstream, self.container, buffering=False))\n        self.outputstream = Stream(writebufferlimit=None)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def rewrite(self, path, method = None, keepresponse = True):\n        \"Rewrite this request to another processor. Must be called before header sent\"\n        if self._sendHeaders:\n            raise HttpProtocolException('Cannot modify response, headers already sent')\n        if getattr(self.event, 'rewritedepth', 0) >= getattr(self.protocol, 'rewritedepthlimit', 32):\n            raise HttpRewriteLoopException\n        newpath = urljoin(quote_from_bytes(self.path).encode('ascii'), path)\n        if newpath == self.fullpath or newpath == self.originalpath:\n            raise HttpRewriteLoopException\n        extraparams = {}\n        if keepresponse:\n            if hasattr(self, 'status'):\n                extraparams['status'] = self.status\n            extraparams['sent_headers'] = self.sent_headers\n            extraparams['sent_cookies'] = self.sent_cookies\n        r = HttpRequestEvent(self.host,\n                               newpath,\n                               self.method if method is None else method,\n                               self.connection,\n                               self.connmark,\n                               self.xid,\n                               self.protocol,\n                               headers = self.headers,\n                               headerdict = self.headerdict,\n                               setcookies = self.setcookies,\n                               stream = self.inputstream,\n                               rewritefrom = self.fullpath,\n                               originalpath = self.originalpath,\n                               rewritedepth = getattr(self.event, 'rewritedepth', 0) + 1,\n                               **extraparams\n                               )\n        await self.connection.wait_for_send(r)\n        self._sendHeaders = True\n        self.outputstream = None", "response": "Rewrite this request to another processor. Must be called before header sent"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nredirect this request with 3xx status", "response": "async def redirect(self, path, status = 302):\n        \"\"\"\n        Redirect this request with 3xx status\n        \"\"\"\n        location = urljoin(urlunsplit((b'https' if self.https else b'http',\n                                                                     self.host,\n                                                                     quote_from_bytes(self.path).encode('ascii'),\n                                                                     '',\n                                                                     ''\n                                                                     )), path)\n        self.start_response(status, [(b'Location', location)])\n        await self.write(b'<a href=\"' + self.escape(location, True) + b'\">' + self.escape(location) + b'</a>')\n        await self.flush(True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef escape(self, text, quote = True):\n        if isinstance(text, bytes):\n            return escape_b(text, quote)\n        else:\n            return escape(text, quote)", "response": "Escape special characters in HTML."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting an error response.", "response": "async def error(self, status=500, allowredirect = True, close = True, showerror = None, headers = []):\n        \"\"\"\n        Show default error response\n        \"\"\"\n        if showerror is None:\n            showerror = self.showerrorinfo\n        if self._sendHeaders:\n            if showerror:\n                typ, exc, tb = sys.exc_info()\n                if exc:\n                    await self.write('<span style=\"white-space:pre-wrap\">\\n', buffering = False)\n                    await self.writelines((self.nl2br(self.escape(v)) for v in traceback.format_exception(typ, exc, tb)), buffering = False)\n                    await self.write('</span>\\n', close, False)\n        elif allowredirect and status in self.protocol.errorrewrite:\n            await self.rewrite(self.protocol.errorrewrite[status], b'GET')\n        elif allowredirect and status in self.protocol.errorredirect:\n            await self.redirect(self.protocol.errorredirect[status])\n        else:\n            self.start_response(status, headers)\n            typ, exc, tb = sys.exc_info()\n            if showerror and exc:\n                await self.write('<span style=\"white-space:pre-wrap\">\\n', buffering = False)\n                await self.writelines((self.nl2br(self.escape(v)) for v in traceback.format_exception(typ, exc, tb)), buffering = False)\n                await self.write('</span>\\n', close, False)\n            else:\n                await self.write(b'<h1>' + _createstatus(status) + b'</h1>', close, False)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting data to the current output stream.", "response": "async def write(self, data, eof = False, buffering = True):\n        \"\"\"\n        Write output to current output stream\n        \"\"\"\n        if not self.outputstream:\n            self.outputstream = Stream()\n            self._startResponse()\n        elif (not buffering or eof) and not self._sendHeaders:\n            self._startResponse()\n        if not isinstance(data, bytes):\n            data = data.encode(self.encoding)\n        await self.outputstream.write(data, self.connection, eof, False, buffering)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def writelines(self, lines, eof = False, buffering = True):\n        for l in lines:\n            await self.write(l, False, buffering)\n        if eof:\n            await self.write(b'', eof, buffering)", "response": "Write a list of lines to the current output stream."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef output(self, stream, disabletransferencoding = None):\n        if self._sendHeaders:\n            raise HttpProtocolException('Cannot modify response, headers already sent')\n        self.outputstream = stream\n        try:\n            content_length = len(stream)\n        except Exception:\n            pass\n        else:\n            self.header(b'Content-Length', str(content_length).encode('ascii'))\n        if disabletransferencoding is not None:\n            self.disabledeflate = disabletransferencoding\n        self._startResponse()", "response": "Send a response to the client."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends data to the client.", "response": "def outputdata(self, data):\n        \"\"\"\n        Send output with fixed length data\n        \"\"\"\n        if not isinstance(data, bytes):\n            data = str(data).encode(self.encoding)\n        self.output(MemoryStream(data))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def close(self):\n        if not self._sendHeaders:\n            self._startResponse()\n        if self.inputstream is not None:\n            self.inputstream.close(self.connection.scheduler)\n        if self.outputstream is not None:\n            await self.flush(True)\n        if hasattr(self, 'session') and self.session:\n            self.session.unlock()", "response": "Close this request send all data and close the connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def parseform(self, limit = 67108864, tostr = True, safename = True):\n        '''\n        Parse form-data with multipart/form-data or application/x-www-form-urlencoded\n        In Python3, the keys of form and files are unicode, but values are bytes\n        If the key ends with '[]', it is considered to be a list:\n        a=1&b=2&b=3          =>    {'a':1,'b':3}\n        a[]=1&b[]=2&b[]=3    =>    {'a':[1],'b':[2,3]}\n        :param limit: limit total input size, default to 64MB. None = no limit. Note that all the form\n        data is stored in memory (including upload files), so it is dangerous to accept a very large input.\n        :param tostr: convert values to str in Python3. Only apply to form, files data are always bytes\n        :param safename: if True, extra security checks are performed on filenames to reduce known security risks.\n        '''\n        if tostr:\n            def _str(s):\n                try:\n                    if not isinstance(s, str):\n                        return s.decode(self.encoding)\n                    else:\n                        return s\n                except Exception:\n                    raise HttpInputException('Invalid encoding in post data: ' + repr(s))\n        else:\n            def _str(s):\n                return s\n        try:\n            form = {}\n            files = {}\n            # If there is not a content-type header, maybe there is not a content.\n            if b'content-type' in self.headerdict and self.inputstream is not None:\n                contenttype = self.headerdict[b'content-type']\n                m = Message()\n                # Email library expects string, which is unicode in Python 3\n                try:\n                    m.add_header('Content-Type', str(contenttype.decode('ascii')))\n                except UnicodeDecodeError:\n                    raise HttpInputException('Content-Type has non-ascii characters')\n                if m.get_content_type() == 'multipart/form-data':\n                    fp = BytesFeedParser()\n                    fp.feed(b'Content-Type: ' + contenttype + b'\\r\\n\\r\\n')\n                    total_length = 0\n                    while True:\n                        try:\n                            await self.inputstream.prepareRead(self.container)\n                            data = self.inputstream.readonce()\n                            total_length += len(data)\n                            if limit is not None and total_length > limit:\n                                raise HttpInputException('Data is too large')\n                            fp.feed(data)\n                        except EOFError:\n                            break\n                    msg = fp.close()\n                    if not msg.is_multipart() or msg.defects:\n                        # Reject the data\n                        raise HttpInputException('Not valid multipart/form-data format')\n                    for part in msg.get_payload():\n                        if part.is_multipart() or part.defects:\n                            raise HttpInputException('Not valid multipart/form-data format')\n                        disposition = part.get_params(header='content-disposition')\n                        if not disposition:\n                            raise HttpInputException('Not valid multipart/form-data format')\n                        disposition = dict(disposition)\n                        if 'form-data' not in disposition or 'name' not in disposition:\n                            raise HttpInputException('Not valid multipart/form-data format')\n                        if 'filename' in disposition:\n                            name = disposition['name']\n                            filename = disposition['filename']\n                            if safename:\n                                filename = _safename(filename)\n                            if name.endswith('[]'):\n                                files.setdefault(name[:-2], []).append({'filename': filename, 'content': part.get_payload(decode=True)})\n                            else:\n                                files[name] = {'filename': filename, 'content': part.get_payload(decode=True)}\n                        else:\n                            name = disposition['name']\n                            if name.endswith('[]'):\n                                form.setdefault(name[:-2], []).append(_str(part.get_payload(decode=True)))\n                            else:\n                                form[name] = _str(part.get_payload(decode=True))\n                elif m.get_content_type() == 'application/x-www-form-urlencoded' or \\\n                        m.get_content_type() == 'application/x-url-encoded':\n                    if limit is not None:\n                        data = await self.inputstream.read(self.container, limit + 1)\n                        if len(data) > limit:\n                            raise HttpInputException('Data is too large')\n                    else:\n                        data = await self.inputstream.read(self.container)\n                    result = parse_qs(data, True)\n                    def convert(k,v):\n                        try:\n                            k = str(k.decode('ascii'))\n                        except Exception:\n                            raise HttpInputException('Form-data key must be ASCII')\n                        if not k.endswith('[]'):\n                            v = _str(v[-1])\n                        else:\n                            k = k[:-2]\n                            v = [_str(i) for i in v]\n                        return (k,v)\n                    form = dict(convert(k,v) for k,v in result.items())\n                else:\n                    # Other formats, treat like no data\n                    pass\n            self.form = form\n            self.files = files                \n        except Exception as exc:\n            raise HttpInputException('Failed to parse form-data: ' + str(exc))", "response": "Parse the form - data and return the form data as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def sessionstart(self):\n        \"Start session. Must start service.utils.session.Session to use this method\"\n        if not hasattr(self, 'session') or not self.session:\n            self.session, setcookies = await call_api(self.container, 'session', 'start', {'cookies':self.rawcookie})\n            for nc in setcookies:\n                self.sent_cookies = [c for c in self.sent_cookies if c.key != nc.key]\n                self.sent_cookies.append(nc)", "response": "Start session. Must start service. utils. session. Session to use this method"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndestroy current session. The session object is discarded and can no longer be used in other requests.", "response": "async def sessiondestroy(self):\n        \"\"\"\n        Destroy current session. The session object is discarded and can no longer be used in other requests.\n        \"\"\"\n        if hasattr(self, 'session') and self.session:\n            setcookies = await call_api(self.container, 'session', 'destroy', {'sessionid':self.session.id})\n            self.session.unlock()\n            del self.session\n            for nc in setcookies:\n                self.sent_cookies = [c for c in self.sent_cookies if c.key != nc.key]\n                self.sent_cookies.append(nc)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntry to get the basic authorize info return ( username password ) if succeeded return 401 otherwise", "response": "def basicauth(self, realm = b'all', nofail = False):\n        \"Try to get the basic authorize info, return (username, password) if succeeded, return 401 otherwise\"\n        if b'authorization' in self.headerdict:\n            auth = self.headerdict[b'authorization']\n            auth_pair = auth.split(b' ', 1)\n            if len(auth_pair) < 2:\n                raise HttpInputException('Authorization header is malformed')\n            if auth_pair[0].lower() == b'basic':\n                try:\n                    userpass = base64.b64decode(auth_pair[1])\n                except Exception:\n                    raise HttpInputException('Invalid base-64 string')\n                userpass_pair = userpass.split(b':', 1)\n                if len(userpass_pair) != 2:\n                    raise HttpInputException('Authorization header is malformed')\n                return userpass_pair\n        if nofail:\n            return (None, None)\n        else:\n            self.basicauthfail(realm)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef basicauthfail(self, realm = b'all'):\n        if not isinstance(realm, bytes):\n            realm = realm.encode('ascii')\n        self.start_response(401, [(b'WWW-Authenticate', b'Basic realm=\"' + realm + b'\"')])\n        self.exit(b'<h1>' + _createstatus(401) + b'</h1>')", "response": "Return 401 for authentication failure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the real path on disk from the query path from a root path.", "response": "def getrealpath(self, root, path):\n        '''\n        Return the real path on disk from the query path, from a root path.\n        The input path from URL might be absolute '/abc', or point to parent '../test',\n        or even with UNC or drive '\\\\test\\abc', 'c:\\test.abc',\n        which creates security issues when accessing file contents with the path.\n        With getrealpath, these paths cannot point to files beyond the root path.\n        \n        :param root: root path of disk files, any query is limited in root directory.\n        \n        :param path: query path from URL.\n        '''\n        if not isinstance(path, str):\n            path = path.decode(self.encoding)\n        # In windows, if the path starts with multiple / or \\, the os.path library may consider it an UNC path\n        # remove them; also replace \\ to /\n        path = pathrep.subn('/', path)[0]\n        # The relative root is considered ROOT, eliminate any relative path like ../abc, which create security issues\n        # We can use os.path.relpath(..., '/') but python2.6 os.path.relpath is buggy \n        path = os.path.normpath(os.path.join('/', path))\n        # The normalized path can be an UNC path, or event a path with drive letter\n        # Send bad request for these types\n        if os.path.splitdrive(path)[0]:\n            raise HttpInputException('Bad path')\n        return os.path.join(root, path[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nqueries string arguments are bytes in Python3. This function Convert bytes to string with env. encoding default to utf - 8.", "response": "def argstostr(self):\n        \"Query string arguments are bytes in Python3. This function Convert bytes to string with env.encoding(default to utf-8).\"\n        self.args = dict((k, self._tostr(v)) for k,v in self.args.items())\n        return self.args"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new anti - CSRF token in the session", "response": "async def createcsrf(self, csrfarg = '_csrf'):\n        \"\"\"\n        Create a anti-CSRF token in the session\n        \"\"\"\n        await self.sessionstart()\n        if not csrfarg in self.session.vars:\n            self.session.vars[csrfarg] = uuid.uuid4().hex"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef outputjson(self, obj):\n        self.header('Content-Type', 'application/json')\n        self.outputdata(json.dumps(obj).encode('ascii'))", "response": "Serialize obj with JSON and output to the client\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nroutes an event to a specific routine.", "response": "def routeevent(self, path, routinemethod, container = None, host = None, vhost = None, method = [b'GET', b'HEAD']):\n        '''\n        Route specified path to a routine factory\n        \n        :param path: path to match, can be a regular expression\n         \n        :param routinemethod: factory function routinemethod(event), event is the HttpRequestEvent\n        \n        :param container: routine container. If None, default to self for bound method, or event.connection if not\n         \n        :param host: if specified, only response to request to specified host\n        \n        :param vhost: if specified, only response to request to specified vhost.\n                      If not specified, response to dispatcher default vhost.\n        \n        :param method: if specified, response to specified methods\n        '''\n        regm = re.compile(path + b'$')\n        if vhost is None:\n            vhost = self.vhost\n        if container is None:\n            container = getattr(routinemethod, '__self__', None)\n        def ismatch(event):\n            # Check vhost\n            if vhost is not None and getattr(event.createby, 'vhost', '') != vhost:\n                return False\n            # First parse the path\n            # RFC said we should accept absolute path\n            psplit = urlsplit(event.path)\n            if psplit.path[:1] != b'/':\n                # For security reason, ignore unrecognized path\n                return False\n            if psplit.netloc and host is not None and host != psplit.netloc:\n                # Maybe a proxy request, ignore it\n                return False\n            if getattr(event.createby, 'unquoteplus', True):\n                realpath = unquote_plus_to_bytes(psplit.path)\n            else:\n                realpath = unquote_to_bytes(psplit.path)\n            m = regm.match(realpath)\n            if m is None:\n                return False\n            event.realpath = realpath\n            event.querystring = psplit.query\n            event.path_match = m\n            return True\n        def func(event, scheduler):\n            try:\n                if event.canignore:\n                    # Already processed\n                    return\n                event.canignore = True\n                c = event.connection if container is None else container\n                c.subroutine(routinemethod(event), False)\n            except Exception:\n                pass\n        for m in method:\n            self.registerHandler(HttpRequestEvent.createMatcher(host, None, m, _ismatch = ismatch), func)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrouting specified path to a WSGI - styled routine factory", "response": "def route(self, path, routinemethod, container = None, host = None, vhost = None, method = [b'GET', b'HEAD']):\n        '''\n        Route specified path to a WSGI-styled routine factory\n        \n        :param path: path to match, can be a regular expression\n         \n        :param routinemethod: factory function routinemethod(env), env is an Environment object\n                see also utils.http.Environment\n        \n        :param container: routine container\n        \n        :param host: if specified, only response to request to specified host\n        \n        :param vhost: if specified, only response to request to specified vhost.\n                      If not specified, response to dispatcher default vhost.\n        \n        :param method: if specified, response to specified methods\n        '''\n        self.routeevent(path, statichttp(container)(routinemethod), container, host, vhost, method)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef routeargs(self, path, routinemethod, container = None, host = None, vhost = None, method = [b'POST'],\n                  tostr = True, matchargs = (), fileargs=(), queryargs=(), cookieargs=(), sessionargs=(),\n                  csrfcheck = False, csrfarg = '_csrf', formlimit = 67108864):\n        '''\n        Convenient way to route a processor with arguments. Automatically parse arguments and pass them to\n        the corresponding handler arguments. If required arguments are missing, HttpInputException is thrown which\n        creates a 400 Bad Request response. If optional arguments are missing, they are replaced with default values\n        just as normal Python call does. If handler accepts keyword arguments, extra arguments are sent\n        with kwargs. If not, they are safely ignored.\n        \n        :param path: path to match, can be a regular expression\n        \n        :param routinemethod: factory function routinemethod(env, arga, argb, argc...). env is an Environment\n                object. form or querystring arguments 'arga', 'argb', 'argc' are passed to arga, argb, argc.\n        \n        :param container: routine container\n        \n        :param host: if specified, only response to request to specified host\n        \n        :param vhost: if specified, only response to request to specified vhost.\n                      If not specified, response to dispatcher default vhost.\n        \n        :param method: methods allowed. With POST method, arguments are extracted from form by default;\n                        With GET or HEAD method, arguments are extracted from querystring(args).\n        \n        :param tostr: In Python3, convert bytes to str before sending arguments to handler.\n        \n        :param matchargs: Instead of using form or args, extract arguments from path match.\n                        matchargs is a sequence of matcher group names. If specified a group name\n                        by number, the argument is used as positional arguments; if specified a group\n                        name by name(str), the argument is used as a keyword argument.\n        \n        :param fileargs: Instead of using form or args, extract specified arguments from files.\n        \n        :param queryargs: Instead of using form, extract specified arguments from args. Notice that when\n                          GET is allowed, the arguments are always extracted from args by default.\n        \n        :param cookieargs: Instead of using form or args, extract specified arguments from cookies.\n        \n        :param sessionargs: Instead of using form or args, extract specified arguments from session.\n                            Notice that if sessionargs is not empty, env.sessionstart() is called,\n                            so vlcp.service.utils.session.Session module must be loaded.\n                \n        :param csrfcheck: If True, check <csrfarg> in input arguments against <csrfarg> in session.\n                          Notice that csrfcheck=True cause env.sessionstart() to be called, so\n                          vlcp.service.utils.session.Session module must be loaded.\n        \n        :param csrfarg: argument name to check, default to \"_csrf\"\n         \n        :param formlimit: limit on parseform, default to 64MB. None to no limit.\n        \n        For example, if using::\n        \n           async def handler(env, target, arga, argb, argc):\n              ...\n           \n           dispatcher.routeargs(b'/do/(.*)', handler, matchargs=(1,), queryargs=('argc'))\n        \n        And there is a HTTP POST::\n        \n           POST /do/mytarget?argc=1 HTTP/1.1\n           Host: ...\n           ...\n        \n           arga=test&argb=test2\n        \n        then handler accepts arguments: target=\"mytarget\", arga=\"test\", argb=\"test2\", argc=\"1\"\n        '''\n        code = routinemethod.__code__\n        if code.co_flags & 0x08:\n            haskwargs = True\n        else:\n            haskwargs = False\n        # Remove argument env\n        arguments = code.co_varnames[1:code.co_argcount]\n        if hasattr(routinemethod, '__self__') and routinemethod.__self__:\n            # First argument is self, remove an extra argument\n            arguments=arguments[1:]\n        # Optional arguments\n        if hasattr(routinemethod, '__defaults__') and routinemethod.__defaults__:\n            requires = arguments[:-len(routinemethod.__defaults__)]\n        else:\n            requires = arguments[:]\n        async def handler(env):\n            if tostr:\n                def _str(s):\n                    if not isinstance(s, str):\n                        return s.decode(env.encoding)\n                    else:\n                        return s\n            else:\n                def _str(s):\n                    return s\n            if tostr:\n                env.argstostr()\n                env.cookietostr()\n            if env.method == b'POST':\n                await env.parseform(formlimit, tostr)\n                argfrom = env.form\n            else:\n                # Ignore input\n                env.form = {}\n                env.files = {}\n                argfrom = env.args\n            args = []\n            kwargs = dict(argfrom)\n            def discard(k):\n                if k in kwargs:\n                    del kwargs[k]\n            def extract(k, source):\n                if k in source:\n                    kwargs[k] = source[k]\n                else:\n                    discard(k)\n            try:\n                ps = 0\n                for ma in matchargs:\n                    v = _str(env.path_match.group(ma))\n                    if v is not None:\n                        if isinstance(ma, str):\n                            kwargs[ma] = v\n                        else:\n                            args.append(v)\n                            ps += 1\n                    else:\n                        if isinstance(ma, str):\n                            discard(ma)\n                        else:\n                            if ps < len(arguments):\n                                discard(arguments[ps])\n                            ps += 1\n                for fa in fileargs:\n                    extract(fa, env.files)\n                if env.method == b'POST':\n                    for qa in queryargs:\n                        extract(qa, env.args)\n                for ca in cookieargs:\n                    extract(ca, env.cookies)\n                # CSRF check is done before session arguments to prevent check against session self\n                if csrfcheck:\n                    if csrfarg not in kwargs:\n                        raise HttpInputException('CSRF check failed')\n                    await env.sessionstart()\n                    if env.session.vars[csrfarg] != kwargs[csrfarg]:\n                        raise HttpInputException('CSRF check failed')\n                if sessionargs:\n                    await env.sessionstart()\n                    for sa in sessionargs:\n                        extract(sa, env.session.vars)\n                # Check required arguments\n                for k in requires[ps:]:\n                    if k not in kwargs:\n                        raise HttpInputException('Argument \"' + k + '\" is required')\n                # Remove positional arguments\n                for k in requires[:ps]:\n                    if k in kwargs:\n                        del kwargs[k]\n                if not haskwargs:\n                    # Remove extra parameters\n                    validargs = arguments[ps:]\n                    kwargs = dict((k,v) for (k,v) in kwargs.items() if k in validargs)\n                r = routinemethod(env, *args, **kwargs)\n            except KeyError as exc:\n                raise HttpInputException('Missing argument: ' + str(exc))\n            except Exception as exc:\n                raise HttpInputException(str(exc))\n            if r:\n                return await r\n        self.route(path, handler, container, host, vhost, method)", "response": "This method is used to route arguments to a specific handler."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef expand(cls, match, expand):\n        return re._expand(match.re, cls._EncodedMatch(match), expand)", "response": "Expand the context of a tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rewrite(self, path, expand, newmethod = None, host = None, vhost = None, method = [b'GET', b'HEAD'], keepquery = True):\n        \"Automatically rewrite a request to another location\"\n        async def func(env):\n            newpath = self.expand(env.path_match, expand)\n            if keepquery and getattr(env, 'querystring', None):\n                if b'?' in newpath:\n                    newpath += b'&' + env.querystring\n                else:\n                    newpath += b'?' + env.querystring\n            await env.rewrite(newpath, newmethod)\n        self.route(path, func)", "response": "Automatically rewrite a request to another location"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _close_generator(g):\n    if isinstance(g, generatorwrapper):\n        g.close()\n    elif _get_frame(g) is not None:\n        try:\n            g.throw(GeneratorExit_)\n        except (StopIteration, GeneratorExit_):\n            return\n        else:\n            raise RuntimeError(\"coroutine ignored GeneratorExit\")", "response": "PyPy 3 generator has a bug that calling `close` caused\n    memory leak. Before it is fixed, use `throw` instead"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Routine(coroutine, scheduler, asyncStart = True, container = None, manualStart = False, daemon = False):\n    def run():\n        iterator = _await(coroutine)\n        iterself = yield\n        if manualStart:\n            yield\n        try:\n            if asyncStart:\n                scheduler.yield_(iterself)\n                yield\n            if container is not None:\n                container.currentroutine = iterself\n            if daemon:\n                scheduler.setDaemon(iterself, True)\n            try:\n                matchers = next(iterator)\n            except StopIteration:\n                return\n            while matchers is None:\n                scheduler.yield_(iterself)\n                yield\n                try:\n                    matchers = next(iterator)\n                except StopIteration:\n                    return\n            try:\n                scheduler.register(matchers, iterself)\n            except Exception:\n                try:\n                    iterator.throw(IllegalMatchersException(matchers))\n                except StopIteration:\n                    pass\n                raise\n            while True:\n                try:\n                    etup = yield\n                except GeneratorExit_:\n                    raise\n                except:\n                    #scheduler.unregister(matchers, iterself)\n                    lmatchers = matchers\n                    t,v,tr = sys.exc_info()  # @UnusedVariable\n                    if container is not None:\n                        container.currentroutine = iterself\n                    try:\n                        matchers = iterator.throw(t,v)\n                    except StopIteration:\n                        return\n                else:\n                    #scheduler.unregister(matchers, iterself)\n                    lmatchers = matchers\n                    if container is not None:\n                        container.currentroutine = iterself\n                    try:\n                        matchers = iterator.send(etup)\n                    except StopIteration:\n                        return\n                while matchers is None:\n                    scheduler.yield_(iterself)\n                    yield\n                    try:\n                        matchers = next(iterator)\n                    except StopIteration:\n                        return\n                try:\n                    if hasattr(matchers, 'two_way_difference'):\n                        reg, unreg = matchers.two_way_difference(lmatchers)\n                    else:\n                        reg = set(matchers).difference(lmatchers)\n                        unreg = set(lmatchers).difference(matchers)\n                    scheduler.register(reg, iterself)\n                    scheduler.unregister(unreg, iterself)\n                except Exception:\n                    try:\n                        iterator.throw(IllegalMatchersException(matchers))\n                    except StopIteration:\n                        pass\n                    raise\n        finally:\n            # iterator.close() can be called in other routines, we should restore the currentroutine variable\n            if container is not None:\n                lastcurrentroutine = getattr(container, 'currentroutine', None)\n                container.currentroutine = iterself\n            else:\n                lastcurrentroutine = None\n            _close_generator(coroutine)\n            if container is not None:\n                container.currentroutine = lastcurrentroutine\n            scheduler.unregisterall(iterself)\n    r = generatorwrapper(run())\n    next(r)\n    r.send(r)\n    return r", "response": "A VLCP routine that wraps a coroutine to become a VLCP routine."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters a handler for the given matcher", "response": "def registerHandler(self, matcher, handler):\n        '''\n        Register self to scheduler\n        '''\n        self.handlers[matcher] = handler\n        self.scheduler.register((matcher,), self)\n        self._setDaemon()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef registerAllHandlers(self, handlerDict):\n        '''\n        Register self to scheduler\n        '''\n        self.handlers.update(handlerDict)\n        if hasattr(handlerDict, 'keys'):\n            self.scheduler.register(handlerDict.keys(), self)\n        else:\n            self.scheduler.register(tuple(h[0] for h in handlerDict), self)\n        self._setDaemon()", "response": "Register all handlers in handlerDict to scheduler"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting the main routine.", "response": "def start(self, asyncStart = False):\n        \"\"\"\n        Start `container.main` as the main routine.\n        \n        :param asyncStart: if True, start the routine in background. By default, the routine\n                           starts in foreground, which means it is executed to the first\n                           `yield` statement before returning. If the started routine raises\n                           an exception, the exception is re-raised to the caller of `start`\n        \"\"\"\n        r = Routine(self.main(), self.scheduler, asyncStart, self, True, self.daemon)\n        self.mainroutine = r\n        try:\n            next(r)\n        except StopIteration:\n            pass\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart a subroutine in this container.", "response": "def subroutine(self, iterator, asyncStart = True, name = None, daemon = False):\n        \"\"\"\n        Start extra routines in this container.\n        \n        :param iterator: A coroutine object i.e the return value of an async method `my_routine()`\n        \n        :param asyncStart: if False, start the routine in foreground. By default, the routine\n                           starts in background, which means it is not executed until the current caller\n                           reaches the next `yield` statement or quit.\n        \n        :param name: if not None, `container.<name>` is set to the routine object. This is useful when\n                     you want to terminate the routine from outside.\n                     \n        :param daemon: if True, this routine is set to be a daemon routine.\n                       A daemon routine does not stop the scheduler from quitting; if all non-daemon routines\n                       are quit, the scheduler stops. \n        \"\"\"\n        r = Routine(iterator, self.scheduler, asyncStart, self, True, daemon)\n        if name is not None:\n            setattr(self, name, r)\n        # Call subroutine may change the currentroutine, we should restore it\n        currentroutine = getattr(self, 'currentroutine', None)\n        try:\n            next(r)\n        except StopIteration:\n            pass\n        self.currentroutine = currentroutine\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def wait_for_send(self, event, *, until=None):\n        '''\n        Send an event to the main event queue. Can call without delegate.\n        \n        :param until: if the callback returns True, stop sending and return\n        \n        :return: the last True value the callback returns, or None\n        '''\n        while True:\n            if until:\n                r = until()\n                if r:\n                    return r\n            waiter = self.scheduler.send(event)\n            if waiter is None:\n                break\n            await waiter", "response": "Send an event to the main event queue. Can call without delegate."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def wait_with_timeout(self, timeout, *matchers):\n        if timeout is None:\n            ev, m = await M_(*matchers)\n            return False, ev, m\n        else:\n            th = self.scheduler.setTimer(timeout)\n            try:\n                tm = TimerEvent.createMatcher(th)\n                ev, m = await M_(*(tuple(matchers) + (tm,)))\n                if m is tm:\n                    return True, None, None\n                else:\n                    return False, ev, m\n            finally:\n                self.scheduler.cancelTimer(th)", "response": "Wait for multiple event matchers or until timeout."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute a subprocess with timeout.", "response": "async def execute_with_timeout(self, timeout, subprocess):\n        \"\"\"\n        Execute a subprocess with timeout. If time limit exceeds, the subprocess is terminated,\n        and `is_timeout` is set to True; otherwise the `is_timeout` is set to False.\n        \n        You can uses `execute_with_timeout` with other help functions to create time limit for them::\n        \n            timeout, result = await container.execute_with_timeout(10, container.execute_all([routine1(), routine2()]))\n        \n        :return: (is_timeout, result) When is_timeout = True, result = None\n        \"\"\"\n        if timeout is None:\n            return (False, await subprocess)\n        else:\n            th = self.scheduler.setTimer(timeout)\n            try:\n                tm = TimerEvent.createMatcher(th)\n                try:\n                    r = await self.with_exception(subprocess, tm)\n                except RoutineException as exc:\n                    if exc.matcher is tm:\n                        return True, None\n                    else:\n                        raise\n                else:\n                    return False, r\n            finally:\n                self.scheduler.cancelTimer(th)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def with_exception(self, subprocess, *matchers):\n        def _callback(event, matcher):\n            raise RoutineException(matcher, event)\n        return await self.with_callback(subprocess, _callback, *matchers)", "response": "A decorator that raises RoutineException when a subprocess terminates."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmonitoring event matchers while executing a subprocess. `callback(event, matcher)` is called each time an event is matched by any event matchers. If the callback raises an exception, the subprocess is terminated. :param intercept_callback: a callback called before a event is delegated to the inner subprocess", "response": "def with_callback(self, subprocess, callback, *matchers, intercept_callback = None):\n        \"\"\"\n        Monitoring event matchers while executing a subprocess. `callback(event, matcher)` is called each time\n        an event is matched by any event matchers. If the callback raises an exception, the subprocess is terminated.\n        \n        :param intercept_callback: a callback called before a event is delegated to the inner subprocess\n        \"\"\"\n        it_ = _await(subprocess)\n        if not matchers and not intercept_callback:\n            return (yield from it_)\n        try:\n            try:\n                m = next(it_)\n            except StopIteration as e:\n                return e.value\n            while True:\n                if m is None:\n                    try:\n                        yield\n                    except GeneratorExit_:\n                        raise\n                    except:\n                        t,v,tr = sys.exc_info()  # @UnusedVariable\n                        try:\n                            m = it_.throw(t,v)\n                        except StopIteration as e:\n                            return e.value\n                    else:                        \n                        try:\n                            m = next(it_)\n                        except StopIteration as e:\n                            return e.value\n                else:\n                    while True:\n                        try:\n                            ev, matcher = yield m + tuple(matchers)\n                        except GeneratorExit_:\n                            # subprocess is closed in `finally` clause\n                            raise\n                        except:\n                            # delegate this exception inside\n                            t,v,tr = sys.exc_info()  # @UnusedVariable\n                            try:\n                                m = it_.throw(t,v)\n                            except StopIteration as e:\n                                return e.value\n                        else:\n                            if matcher in matchers:\n                                callback(ev, matcher)\n                            else:\n                                if intercept_callback:\n                                    intercept_callback(ev, matcher)\n                                break\n                    try:\n                        m = it_.send((ev, matcher))\n                    except StopIteration as e:\n                        return e.value\n        finally:\n            _close_generator(subprocess)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwaiting until all the matchers match an event.", "response": "async def wait_for_all(self, *matchers, eventlist = None, eventdict = None, callback = None):\n        \"\"\"\n        Wait until each matcher matches an event. When this coroutine method returns,\n        `eventlist` is set to the list of events in the arriving order (may not\n        be the same as the matchers); `eventdict` is set to a dictionary\n        `{matcher1: event1, matcher2: event2, ...}`\n        \n        :param eventlist: use external event list, so when an exception occurs\n                          (e.g. routine close), you can retrieve the result\n                          from the passed-in list\n        \n        :param eventdict: use external event dict\n        \n        :param callback: if not None, the callback should be a callable callback(event, matcher)\n                         which is called each time an event is received\n        \n        :return: (eventlist, eventdict)\n        \"\"\"\n        if eventdict is None:\n            eventdict = {}\n        if eventlist is None:\n            eventlist = []\n        ms = len(matchers)\n        last_matchers = Diff_(matchers)\n        while ms:\n            ev, m = await last_matchers\n            ms -= 1\n            if callback:\n                callback(ev, m)\n            eventlist.append(ev)\n            eventdict[m] = ev\n            last_matchers = Diff_(last_matchers, remove=(m,))\n        return eventlist, eventdict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def wait_for_all_to_process(self, *matchers, eventlist = None, eventdict = None,\n                                            callback = None):\n        \"\"\"\n        Similar to `waitForAll`, but set `canignore=True` for these events. This ensures\n        blocking events are processed correctly.\n        \"\"\"\n        def _callback(event, matcher):\n            event.canignore = True\n            if callback:\n                callback(event, matcher)\n        return await self.wait_for_all(*matchers, eventlist=eventlist,\n                                       eventdict=eventdict, callback=_callback)", "response": "This method waits for all the specified eventlist and eventdict to be processed."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwaits for all queues to be empty at the same time.", "response": "async def wait_for_all_empty(self, *queues):\n        \"\"\"\n        Wait for multiple queues to be empty at the same time.\n\n        Require delegate when calling from coroutines running in other containers\n        \"\"\"\n        matchers = [m for m in (q.waitForEmpty() for q in queues) if m is not None]\n        while matchers:\n            await self.wait_for_all(*matchers)\n            matchers = [m for m in (q.waitForEmpty() for q in queues) if m is not None]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef syscall_noreturn(self, func):\n        '''\n        Call a syscall method. A syscall method is executed outside of any routines, directly\n        in the scheduler loop, which gives it chances to directly operate the event loop.\n        See :py:method::`vlcp.event.core.Scheduler.syscall`.\n        '''\n        matcher = self.scheduler.syscall(func)\n        while not matcher:\n            yield\n            matcher = self.scheduler.syscall(func)\n        ev, _ = yield (matcher,)\n        return ev", "response": "A syscall method that does not return an event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling a syscall method and retrieve its return value", "response": "async def syscall(self, func, ignoreException = False):\n        \"\"\"\n        Call a syscall method and retrieve its return value\n        \"\"\"\n        ev = await self.syscall_noreturn(func)\n        if hasattr(ev, 'exception'):\n            if ignoreException:\n                return\n            else:\n                raise ev.exception[1]\n        else:\n            return ev.retvalue"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def delegate(self, subprocess, forceclose = False):\n        '''\n        Run a subprocess without container support\n        \n        Many subprocess assume itself running in a specified container, it uses container reference\n        like self.events. Calling the subprocess in other containers will fail.\n        \n        With delegate, you can call a subprocess in any container (or without a container)::\n        \n            r = await c.delegate(c.someprocess())\n        \n        :return: original return value\n        '''\n        finish, r = self.begin_delegate(subprocess)\n        return await self.end_delegate(finish, r, forceclose)", "response": "Delegate a subprocess to a specific container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nend a delegate operation.", "response": "async def end_delegate(self, delegate_matcher, routine = None, forceclose = False):\n        \"\"\"\n        Retrieve a begin_delegate result. Must be called immediately after begin_delegate\n        before any other `await`, or the result might be lost.\n        \n        Do not use this method without thinking. Always use `RoutineFuture` when possible.\n        \"\"\"\n        try:\n            ev = await delegate_matcher\n            if hasattr(ev, 'exception'):\n                raise ev.exception\n            else:\n                return ev.result\n        finally:\n            if forceclose and routine:\n                routine.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef begin_delegate(self, subprocess):\n        '''\n        Start the delegate routine, but do not wait for result, instead returns a (matcher, routine) tuple.\n        Useful for advanced delegates (e.g. delegate multiple subprocesses in the same time).\n        This is NOT a coroutine method.\n        \n        WARNING: this is not a safe way for asynchronous executing and get the result. Use `RoutineFuture` instead.\n        \n        :param subprocess: a coroutine\n        \n        :returns: (matcher, routine) where matcher is a event matcher to get the delegate result, routine is the created routine\n        '''\n        async def delegateroutine():\n            try:\n                r = await subprocess\n            except:\n                _, val, _ = sys.exc_info()\n                e = RoutineControlEvent(RoutineControlEvent.DELEGATE_FINISHED, self.currentroutine,\n                                        exception=val)\n                self.scheduler.emergesend(e)\n                raise\n            else:\n                e = RoutineControlEvent(RoutineControlEvent.DELEGATE_FINISHED, self.currentroutine,\n                                        result = r)\n                await self.wait_for_send(e)\n        r = self.subroutine(generatorwrapper(delegateroutine(), 'subprocess', 'delegate'), True)\n        finish = RoutineControlEvent.createMatcher(RoutineControlEvent.DELEGATE_FINISHED, r)\n        return finish, r", "response": "Start the delegate routine and wait for result."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts the delegate routine and wait for result.", "response": "def begin_delegate_other(self, subprocess, container, retnames = ('',)):\n        '''\n        DEPRECATED Start the delegate routine, but do not wait for result, instead returns a (matcher routine) tuple.\n        Useful for advanced delegates (e.g. delegate multiple subprocesses in the same time).\n        This is NOT a coroutine method.\n        \n        :param subprocess: a coroutine\n        \n        :param container: container in which to start the routine\n        \n        :param retnames: get return values from keys. '' for the return value (for compatibility with earlier versions)\n        \n        :returns: (matcher, routine) where matcher is a event matcher to get the delegate result, routine is the created routine\n        '''\n        async def delegateroutine():\n            try:\n                r = await subprocess\n            except:\n                _, val, _ = sys.exc_info()\n                e = RoutineControlEvent(RoutineControlEvent.DELEGATE_FINISHED, container.currentroutine, exception = val)\n                container.scheduler.emergesend(e)\n                raise\n            else:\n                e = RoutineControlEvent(RoutineControlEvent.DELEGATE_FINISHED, container.currentroutine,\n                                        result = tuple(r if n == '' else getattr(container, n, None)\n                                                       for n in retnames))\n                await container.waitForSend(e)\n        r = container.subroutine(generatorwrapper(delegateroutine(), 'subprocess', 'delegate'), True)\n        return (RoutineControlEvent.createMatcher(RoutineControlEvent.DELEGATE_FINISHED, r), r)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeprecating Another format of delegate allows delegate a subprocess in another container, and get some returning values the subprocess is actually running in 'container'. :: ret = await self.delegate_other(c.method(), c) :return: a tuple for retnames values", "response": "async def delegate_other(self, subprocess, container, retnames = ('',), forceclose = False):\n        '''\n        DEPRECATED Another format of delegate allows delegate a subprocess in another container, and get some returning values\n        the subprocess is actually running in 'container'. ::\n        \n            ret = await self.delegate_other(c.method(), c)\n        \n        :return: a tuple for retnames values\n        \n        '''\n        finish, r = self.beginDelegateOther(subprocess, container, retnames)\n        return await self.end_delegate(finish, r, forceclose)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute all subprocesses with names in retnames.", "response": "async def execute_all_with_names(self, subprocesses, container = None, retnames = ('',), forceclose = True):\n        '''\n        DEPRECATED Execute all subprocesses and get the return values.\n        \n        :param subprocesses: sequence of subroutines (coroutines)\n        \n        :param container: if specified, run subprocesses in another container.\n        \n        :param retnames: DEPRECATED get return value from container.(name) for each name in retnames.\n                         '' for return value (to be compatible with earlier versions)\n        \n        :param forceclose: force close the routines on exit, so all the subprocesses are terminated\n                           on timeout if used with executeWithTimeout\n        \n        :returns: a list of tuples, one for each subprocess, with value of retnames inside:\n                  `[('retvalue1',),('retvalue2',),...]`\n        '''\n        if not subprocesses:\n            return []\n        subprocesses = list(subprocesses)\n        if len(subprocesses) == 1 and (container is None or container is self) and forceclose:\n            # Directly run the process to improve performance\n            return [await subprocesses[0]]\n        if container is None:\n            container = self\n        delegates = [self.begin_delegate_other(p, container, retnames) for p in subprocesses]\n        matchers = [d[0] for d in delegates]\n        try:\n            _, eventdict = await self.wait_for_all(*matchers)\n            events = [eventdict[m] for m in matchers]\n            exceptions = [e.exception for e in events if hasattr(e, 'exception')]\n            if exceptions:\n                if len(exceptions) == 1:\n                    raise exceptions[0]\n                else:\n                    raise MultipleException(exceptions)\n            return [e.result for e in events]\n        finally:\n            if forceclose:\n                for d in delegates:\n                    try:\n                        container.terminate(d[1])\n                    except Exception:\n                        pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def execute_all(self, subprocesses, forceclose=True):\n        '''\n        Execute all subprocesses and get the return values.\n        \n        :param subprocesses: sequence of subroutines (coroutines)\n        \n        :param forceclose: force close the routines on exit, so all the subprocesses are terminated\n                           on timeout if used with executeWithTimeout\n        \n        :returns: a list of return values for each subprocess\n        '''\n        if not subprocesses:\n            return []\n        subprocesses = list(subprocesses)\n        if len(subprocesses) == 1 and forceclose:\n            return [await subprocesses[0]]\n        delegates = [self.begin_delegate(p) for p in subprocesses]\n        matchers = [d[0] for d in delegates]\n        try:\n            _, eventdict = await self.wait_for_all(*matchers)\n            events = [eventdict[m] for m in matchers]\n            exceptions = [e.exception for e in events if hasattr(e, 'exception')]\n            if exceptions:\n                if len(exceptions) == 1:\n                    raise exceptions[0]\n                else:\n                    raise MultipleException(exceptions)\n            return [e.result for e in events]\n        finally:\n            if forceclose:\n                for d in delegates:\n                    try:\n                        d[1].close()\n                    except Exception:\n                        pass", "response": "Execute all subprocesses and get the return values."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_container(cls, scheduler):\n        if scheduler in cls._container_cache:\n            return cls._container_cache[scheduler]\n        else:\n            c = cls(scheduler)\n            cls._container_cache[scheduler] = c\n            return c", "response": "Returns a container instance for the given scheduler."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an API definition for a generic function", "response": "def api(func, container = None, criteria = None):\n    '''\n    Return an API def for a generic function\n    \n    :param func: a function or bounded method\n    \n    :param container: if None, this is used as a synchronous method, the return value of the method\n                      is used for the return value. If not None, this is used as an asynchronous method,\n                      the return value should be a generator, and it is executed in `container` as a routine.\n                      The return value should be set to `container.retvalue`.\n    \n    :param criteria: An extra function used to test whether this function should process the API. This allows\n                     multiple API definitions to use the same API method name.\n    '''\n    return (func.__name__.lower(), functools.update_wrapper(lambda n,p: func(**p), func), container,\n            create_discover_info(func), criteria)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef proxy(name, default = None):\n    proxymodule = _ProxyMetaClass(name, (_ProxyModule,), {'_default': default})\n    proxymodule.__module__ = sys._getframe(1).f_globals.get('__name__')\n    return proxymodule", "response": "Create a proxy module."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends API to a node.", "response": "async def send_api(container, targetname, name, params = {}):\n    \"\"\"\n    Send API and discard the result\n    \"\"\"\n    handle = object()\n    apiEvent = ModuleAPICall(handle, targetname, name, params = params)\n    await container.wait_for_send(apiEvent)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls a module API with parameters.", "response": "async def call_api(container, targetname, name, params = {}, timeout = 120.0):\n    \"\"\"\n    Call module API `targetname/name` with parameters.\n    \n    :param targetname: module targetname. Usually the lower-cased name of the module class, or 'public' for\n                       public APIs.\n    \n    :param name: method name\n    \n    :param params: module API parameters, should be a dictionary of `{parameter: value}`\n    \n    :param timeout: raise an exception if the API call is not returned for a long time\n    \n    :return: API return value\n    \"\"\"\n    handle = object()\n    apiEvent = ModuleAPICall(handle, targetname, name, params = params)\n    await container.wait_for_send(apiEvent)\n    replyMatcher = ModuleAPIReply.createMatcher(handle)\n    timeout_, ev, m = await container.wait_with_timeout(timeout, replyMatcher)\n    if timeout_:\n        # Ignore the Event\n        apiEvent.canignore = True\n        container.scheduler.ignore(ModuleAPICall.createMatcher(handle))\n        raise ModuleAPICallTimeoutException('API call timeout')\n    else:\n        return get_api_result(ev)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def batch_call_api(container, apis, timeout = 120.0):\n    apiHandles = [(object(), api) for api in apis]\n    apiEvents = [ModuleAPICall(handle, targetname, name, params = params)\n                 for handle, (targetname, name, params) in apiHandles]\n    apiMatchers = tuple(ModuleAPIReply.createMatcher(handle) for handle, _ in apiHandles)\n    async def process():\n        for e in apiEvents:\n            await container.wait_for_send(e)\n    container.subroutine(process(), False)\n    eventdict = {}\n    async def process2():\n        ms = len(apiMatchers)\n        matchers = Diff_(apiMatchers)\n        while ms:\n            ev, m = await matchers\n            matchers = Diff_(matchers, remove=(m,))\n            eventdict[ev.handle] = ev\n    await container.execute_with_timeout(timeout, process2())\n    for e in apiEvents:\n        if e.handle not in eventdict:\n            e.canignore = True\n            container.scheduler.ignore(ModuleAPICall.createMatcher(e.handle))\n    return [eventdict.get(handle, None) for handle, _ in apiHandles]", "response": "Execute a list of apis in a single thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef registerAPI(self, name, handler, container = None, discoverinfo = None, criteria = None):\n        self.handler.registerHandler(*self._createHandler(name, handler, container, criteria))\n        if discoverinfo is None:\n            self.discoverinfo[name] = {'description': cleandoc(handler.__doc__)}\n        else:\n            self.discoverinfo[name] = discoverinfo", "response": "Register a new API with the handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unregisterAPI(self, name):\n        if name.startswith('public/'):\n            target = 'public'\n            name = name[len('public/'):]\n        else:\n            target = self.servicename\n            name = name\n        removes = [m for m in self.handler.handlers.keys() if m.target == target and m.name == name]\n        for m in removes:\n            self.handler.unregisterHandler(m)", "response": "Remove an API from this handler."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndiscover API definitions. Set details = true to show details", "response": "def discover(self, details = False):\n        'Discover API definitions. Set details=true to show details'\n        if details and not (isinstance(details, str) and details.lower() == 'false'):\n            return copy.deepcopy(self.discoverinfo)\n        else:\n            return dict((k,v.get('description', '')) for k,v in self.discoverinfo.items())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def loadmodule(self, module):\n        '''\n        Load a module class\n        '''\n        self._logger.debug('Try to load module %r', module)\n        if hasattr(module, '_instance'):\n            self._logger.debug('Module is already initialized, module state is: %r', module._instance.state)\n            if module._instance.state == ModuleLoadStateChanged.UNLOADING or module._instance.state == ModuleLoadStateChanged.UNLOADED:\n                # Wait for unload\n                um = ModuleLoadStateChanged.createMatcher(module._instance.target, ModuleLoadStateChanged.UNLOADED)\n                await um\n            elif module._instance.state == ModuleLoadStateChanged.SUCCEEDED:\n                pass\n            elif module._instance.state == ModuleLoadStateChanged.FAILED:\n                raise ModuleLoadException('Cannot load module %r before unloading the failed instance' % (module,))\n            elif module._instance.state == ModuleLoadStateChanged.NOTLOADED or module._instance.state == ModuleLoadStateChanged.LOADED or module._instance.state == ModuleLoadStateChanged.LOADING:\n                # Wait for succeeded or failed\n                sm = ModuleLoadStateChanged.createMatcher(module._instance.target, ModuleLoadStateChanged.SUCCEEDED)\n                fm = ModuleLoadStateChanged.createMatcher(module._instance.target, ModuleLoadStateChanged.FAILED)\n                _, m = await M_(sm, fm)\n                if m is sm:\n                    pass\n                else:\n                    raise ModuleLoadException('Module load failed for %r' % (module,))\n        if not hasattr(module, '_instance'):\n            self._logger.info('Loading module %r', module)\n            inst = module(self.server)\n            # Avoid duplicated loading\n            module._instance = inst\n            # When reloading, some of the dependencies are broken, repair them\n            if hasattr(module, 'referencedBy'):\n                inst.dependedBy = set([m for m in module.referencedBy if hasattr(m, '_instance') and m._instance.state != ModuleLoadStateChanged.UNLOADED])\n            # Load Module\n            for d in module.depends:\n                if hasattr(d, '_instance') and d._instance.state == ModuleLoadStateChanged.FAILED:\n                    raise ModuleLoadException('Cannot load module %r, it depends on %r, which is in failed state.' % (module, d))\n            try:\n                for d in module.depends:\n                    if hasattr(d, '_instance') and d._instance.state == ModuleLoadStateChanged.SUCCEEDED:\n                        d._instance.dependedBy.add(module)\n                preloads = [d for d in module.depends if not hasattr(d, '_instance') or \\\n                            d._instance.state != ModuleLoadStateChanged.SUCCEEDED]\n                for d in preloads:\n                    self.subroutine(self.loadmodule(d), False)\n                sms = [ModuleLoadStateChanged.createMatcher(d, ModuleLoadStateChanged.SUCCEEDED) for d in preloads]\n                fms = [ModuleLoadStateChanged.createMatcher(d, ModuleLoadStateChanged.FAILED) for d in preloads]\n                def _callback(event, matcher):\n                    raise ModuleLoadException('Cannot load module %r, it depends on %r, which is in failed state.' % (module, event.module))\n                await self.with_callback(self.wait_for_all(*sms), _callback, *fms)\n            except:\n                for d in module.depends:\n                    if hasattr(d, '_instance') and module in d._instance.dependedBy:\n                        self._removeDepend(module, d)\n                self._logger.warning('Loading module %r stopped', module, exc_info=True)\n                # Not loaded, send a message to notify that parents can not \n                async def _msg():\n                    await self.wait_for_send(ModuleLoadStateChanged(module, ModuleLoadStateChanged.UNLOADED, inst))\n                self.subroutine(_msg(), False)\n                del module._instance\n                raise\n            for d in preloads:\n                d._instance.dependedBy.add(module)\n            self.activeModules[inst.getServiceName()] = module\n            await module._instance.changestate(ModuleLoadStateChanged.LOADING, self)\n            await module._instance.load(self)\n            if module._instance.state == ModuleLoadStateChanged.LOADED or module._instance.state == ModuleLoadStateChanged.LOADING:\n                sm = ModuleLoadStateChanged.createMatcher(module._instance.target, ModuleLoadStateChanged.SUCCEEDED)\n                fm = ModuleLoadStateChanged.createMatcher(module._instance.target, ModuleLoadStateChanged.FAILED)\n                _, m = await M_(sm, fm)\n                if m is sm:\n                    pass\n                else:\n                    raise ModuleLoadException('Module load failed for %r' % (module,))\n            self._logger.info('Loading module %r completed, module state is %r', module, module._instance.state)\n            if module._instance.state == ModuleLoadStateChanged.FAILED:\n                raise ModuleLoadException('Module load failed for %r' % (module,))", "response": "Load a module class and return the ID of the loaded module."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def unloadmodule(self, module, ignoreDependencies = False):\n        '''\n        Unload a module class\n        '''\n        self._logger.debug('Try to unload module %r', module)\n        if hasattr(module, '_instance'):\n            self._logger.debug('Module %r is loaded, module state is %r', module, module._instance.state)\n            inst = module._instance\n            if inst.state == ModuleLoadStateChanged.LOADING or inst.state == ModuleLoadStateChanged.LOADED:\n                # Wait for loading\n                # Wait for succeeded or failed\n                sm = ModuleLoadStateChanged.createMatcher(module._instance.target, ModuleLoadStateChanged.SUCCEEDED)\n                fm = ModuleLoadStateChanged.createMatcher(module._instance.target, ModuleLoadStateChanged.FAILED)\n                await M_(sm, fm)\n            elif inst.state == ModuleLoadStateChanged.UNLOADING or inst.state == ModuleLoadStateChanged.UNLOADED:\n                um = ModuleLoadStateChanged.createMatcher(module, ModuleLoadStateChanged.UNLOADED)\n                await um\n        if hasattr(module, '_instance') and (module._instance.state == ModuleLoadStateChanged.SUCCEEDED or\n                                             module._instance.state == ModuleLoadStateChanged.FAILED):\n            self._logger.info('Unloading module %r', module)\n            inst = module._instance\n            # Change state to unloading to prevent more dependencies\n            await inst.changestate(ModuleLoadStateChanged.UNLOADING, self)\n            if not ignoreDependencies:\n                deps = [d for d in inst.dependedBy if hasattr(d, '_instance') and d._instance.state != ModuleLoadStateChanged.UNLOADED]\n                ums = [ModuleLoadStateChanged.createMatcher(d, ModuleLoadStateChanged.UNLOADED) for d in deps]\n                for d in deps:\n                    self.subroutine(self.unloadmodule(d), False)\n                await self.wait_for_all(*ums)\n            await inst.unload(self)\n            del self.activeModules[inst.getServiceName()]\n            self._logger.info('Module %r is unloaded', module)\n            if not ignoreDependencies:\n                for d in module.depends:\n                    if hasattr(d, '_instance') and module in d._instance.dependedBy:\n                        self._removeDepend(module, d)", "response": "Unload a module class"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def load_by_path(self, path):\n        try:\n            p, module = findModule(path, True)\n        except KeyError as exc:\n            raise ModuleLoadException('Cannot load module ' + repr(path) + ': ' + str(exc) + 'is not defined in the package')\n        except Exception as exc:\n            raise ModuleLoadException('Cannot load module ' + repr(path) + ': ' + str(exc))\n        if module is None:\n            raise ModuleLoadException('Cannot find module: ' + repr(path))\n        return await self.loadmodule(module)", "response": "Load a module by full path."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nunloads a module by full path.", "response": "async def unload_by_path(self, path):\n        \"\"\"\n        Unload a module by full path. Dependencies are automatically unloaded if they are marked to be\n        services.\n        \"\"\"\n        p, module = findModule(path, False)\n        if module is None:\n            raise ModuleLoadException('Cannot find module: ' + repr(path))\n        return await self.unloadmodule(module)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def reload_modules(self, pathlist):\n        loadedModules = []\n        failures = []\n        for path in pathlist:\n            p, module = findModule(path, False)\n            if module is not None and hasattr(module, '_instance') and module._instance.state != ModuleLoadStateChanged.UNLOADED:\n                loadedModules.append(module)\n        # Unload all modules\n        ums = [ModuleLoadStateChanged.createMatcher(m, ModuleLoadStateChanged.UNLOADED) for m in loadedModules]\n        for m in loadedModules:\n            # Only unload the module itself, not its dependencies, since we will restart the module soon enough\n            self.subroutine(self.unloadmodule(m, True), False)\n        await self.wait_for_all(*ums)\n        # Group modules by package\n        grouped = {}\n        for path in pathlist:\n            dotpos = path.rfind('.')\n            if dotpos == -1:\n                raise ModuleLoadException('Must specify module with full path, including package name')\n            package = path[:dotpos]\n            classname = path[dotpos + 1:]\n            mlist = grouped.setdefault(package, [])\n            p, module = findModule(path, False)\n            mlist.append((classname, module))\n        for package, mlist in grouped.items():\n            # Reload each package only once\n            try:\n                p = sys.modules[package]\n                # Remove cache to ensure a clean import from source file\n                removeCache(p)\n                p = reload(p)\n            except KeyError:\n                try:\n                    p = __import__(package, fromlist=[m[0] for m in mlist])\n                except Exception:\n                    self._logger.warning('Failed to import a package: %r, resume others', package, exc_info = True)\n                    failures.append('Failed to import: ' + package)\n                    continue\n            except Exception:\n                self._logger.warning('Failed to import a package: %r, resume others', package, exc_info = True)\n                failures.append('Failed to import: ' + package)\n                continue                \n            for cn, module in mlist:\n                try:\n                    module2 = getattr(p, cn)\n                except AttributeError:\n                    self._logger.warning('Cannot find module %r in package %r, resume others', package, cn)\n                    failures.append('Failed to import: ' + package + '.' + cn)\n                    continue\n                if module is not None and module is not module2:\n                    # Update the references\n                    try:\n                        lpos = loadedModules.index(module)\n                        loaded = True\n                    except Exception:\n                        loaded = False\n                    for d in module.depends:\n                        # The new reference is automatically added on import, only remove the old reference\n                        d.referencedBy.remove(module)\n                        if loaded and hasattr(d, '_instance'):\n                            try:\n                                d._instance.dependedBy.remove(module)\n                                d._instance.dependedBy.add(module2)\n                            except ValueError:\n                                pass\n                    if hasattr(module, 'referencedBy'):\n                        for d in module.referencedBy:\n                            pos = d.depends.index(module)\n                            d.depends[pos] = module2\n                            if not hasattr(module2, 'referencedBy'):\n                                module2.referencedBy = []\n                            module2.referencedBy.append(d)\n                    if loaded:\n                        loadedModules[lpos] = module2\n        # Start the uploaded modules\n        for m in loadedModules:\n            self.subroutine(self.loadmodule(m))\n        if failures:\n            raise ModuleLoadException('Following errors occurred during reloading, check log for more details:\\n' + '\\n'.join(failures))", "response": "Reloads modules with a full path in the pathlist."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the module instance for a target name.", "response": "def get_module_by_name(self, targetname):\n        \"\"\"\n        Return the module instance for a target name.\n        \"\"\"\n        if targetname == 'public':\n            target = None\n        elif not targetname not in self.activeModules:\n            raise KeyError('Module %r not exists or is not loaded' % (targetname,))\n        else:\n            target = self.activeModules[targetname]\n        return target"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a default configuration mapping for this class.", "response": "def defaultconfig(cls):\n    \"\"\"\n    Generate a default configuration mapping bases on the class name. If this class does not have a\n    parent with `configbase` defined, it is set to a configuration base with\n    `configbase=<lowercase-name>` and `configkey=<lowercase-name>.default`; otherwise it inherits\n    `configbase` of its parent and set `configkey=<parentbase>.<lowercase-name>`\n    \n    Refer to :ref::`configurations` for normal rules.\n    \"\"\"\n    parentbase = None\n    for p in cls.__bases__:\n        if issubclass(p, Configurable):\n            parentbase = getattr(p, 'configbase', None)\n            break\n    if parentbase is None:\n        base = cls.__name__.lower()\n        cls.configbase = base\n        cls.configkey = base + '.default'\n    else:\n        key = cls.__name__.lower()\n        #=======================================================================\n        # parentkeys = parentbase.split('.')\n        # for pk in parentkeys:\n        #     if key.endswith(pk):\n        #         key = key[0:-len(pk)]\n        #     elif key.startswith(pk):\n        #         key = key[len(pk):]\n        #=======================================================================\n        cls.configkey = parentbase + \".\" + key\n    return cls"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn all configuration keys in this node including configurations on children nodes.", "response": "def config_keys(self, sortkey = False):\n        \"\"\"\n        Return all configuration keys in this node, including configurations on children nodes.\n        \"\"\"\n        if sortkey:\n            items = sorted(self.items())\n        else:\n            items = self.items()\n        for k,v in items:\n            if isinstance(v, ConfigTree):\n                for k2 in v.config_keys(sortkey):\n                    yield k + '.' + k2\n            else:\n                yield k"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef config_items(self, sortkey = False):\n        if sortkey:\n            items = sorted(self.items())\n        else:\n            items = self.items()\n        for k,v in items:\n            if isinstance(v, ConfigTree):\n                for k2,v2 in v.config_items(sortkey):\n                    yield (k + '.' + k2, v2)\n            else:\n                yield (k,v)", "response": "Return all key value tuples for configurations in this node including configurations on children nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of configuration keys stored in this node.", "response": "def config_value_keys(self, sortkey = False):\n        \"\"\"\n        Return configuration keys directly stored in this node. Configurations in child nodes are not included.\n        \"\"\"\n        if sortkey:\n            items = sorted(self.items())\n        else:\n            items = self.items()\n        return (k for k,v in items if not isinstance(v,ConfigTree))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef loadconfig(self, keysuffix, obj):\n        subtree = self.get(keysuffix)\n        if subtree is not None and isinstance(subtree, ConfigTree):\n            for k,v in subtree.items():\n                if isinstance(v, ConfigTree):\n                    if hasattr(obj, k) and not isinstance(getattr(obj, k), ConfigTree):\n                        v.loadconfig(getattr(obj,k))\n                    else:\n                        setattr(obj, k, v)\n                elif not hasattr(obj, k):\n                    setattr(obj, k, v)", "response": "Load all configurations from this node into obj\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef withconfig(self, keysuffix):\n        def decorator(cls):\n            return self.loadconfig(keysuffix, cls)\n        return decorator", "response": "Returns a decorator that can be used to decorate load configurations with this class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gettree(self, key, create = False):\n        tree, _ = self._getsubitem(key + '.tmp', create)\n        return tree", "response": "Get a subtree node from the key"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a key from the cache.", "response": "def get(self, key, defaultvalue = None):\n        \"\"\"\n        Support dict-like get (return a default value if not found)\n        \"\"\"\n        (t, k) = self._getsubitem(key, False)\n        if t is None:\n            return defaultvalue\n        else:\n            return t.__dict__.get(k, defaultvalue)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsupporting dict - like setdefault", "response": "def setdefault(self, key, defaultvalue = None):\n        \"\"\"\n        Support dict-like setdefault (create if not existed)\n        \"\"\"\n        (t, k) = self._getsubitem(key, True)\n        return t.__dict__.setdefault(k, defaultvalue)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts this node to a dictionary tree.", "response": "def todict(self):\n        \"\"\"\n        Convert this node to a dictionary tree.\n        \"\"\"\n        dict_entry = []\n        for k,v in self.items():\n            if isinstance(v, ConfigTree):\n                dict_entry.append((k, v.todict()))\n            else:\n                dict_entry.append((k, v))\n        return dict(dict_entry)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a configuration from a file - like object or a sequence of strings.", "response": "def loadfromfile(self, filelike):\n        \"\"\"\n        Read configurations from a file-like object, or a sequence of strings. Old values are not\n        cleared, if you want to reload the configurations completely, you should call `clear()`\n        before using `load*` methods.\n        \"\"\"\n        line_format = re.compile(r'((?:[a-zA-Z][a-zA-Z0-9_]*\\.)*[a-zA-Z][a-zA-Z0-9_]*)\\s*=\\s*')\n        space = re.compile(r'\\s')\n        line_no = 0\n        # Suport multi-line data\n        line_buffer = []\n        line_key = None\n        last_line_no = None\n        for l in filelike:\n            line_no += 1\n            ls = l.strip()\n            # If there is a # in start, the whole line is remarked.\n            # ast.literal_eval already processed any # after '='.\n            if not ls or ls.startswith('#'):\n                continue\n            if space.match(l):\n                if not line_key:\n                    # First line cannot start with space\n                    raise ValueError('Error format in line %d: first line cannot start with space%s\\n' % (line_no, l))\n                line_buffer.append(l)\n            else:\n                if line_key:\n                    # Process buffered lines\n                    try:\n                        value = ast.literal_eval(''.join(line_buffer))\n                    except Exception:\n                        typ, val, tb = sys.exc_info()\n                        raise ValueError('Error format in line %d(%s: %s):\\n%s' % (last_line_no, typ.__name__, str(val), ''.join(line_buffer)))\n                    self[line_key] = value\n                # First line\n                m = line_format.match(l)\n                if not m:\n                    raise ValueError('Error format in line %d:\\n%s' % (line_no, l))\n                line_key = m.group(1)\n                last_line_no = line_no\n                del line_buffer[:]\n                line_buffer.append(l[m.end():])\n        if line_key:\n            # Process buffered lines\n            try:\n                value = ast.literal_eval(''.join(line_buffer))\n            except Exception:\n                typ, val, tb = sys.exc_info()\n                raise ValueError('Error format in line %d(%s: %s):\\n%s' % (last_line_no, typ.__name__, str(val), ''.join(line_buffer)))\n            self[line_key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save(self, sortkey = True):\n        return [k + '=' + repr(v) for k,v in self.config_items(sortkey)]", "response": "Save the configuration to a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving the configuration to a string.", "response": "def savetostr(self, sortkey = True):\n        \"\"\"\n        Save configurations to a single string\n        \"\"\"\n        return ''.join(k + '=' + repr(v) + '\\n' for k,v in self.config_items(sortkey))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef savetofile(self, filelike, sortkey = True):\n        filelike.writelines(k + '=' + repr(v) + '\\n' for k,v in self.config_items(sortkey))", "response": "Save the configuration to a file - like object which supports writelines"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef saveto(self, path, sortkey = True):\n        with open(path, 'w') as f:\n            self.savetofile(f, sortkey)", "response": "Save the current configuration to path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the parent of the class that this class inherits configurations", "response": "def getConfigurableParent(cls):\n        \"\"\"\n        Return the parent from which this class inherits configurations\n        \"\"\"\n        for p in cls.__bases__:\n            if isinstance(p, Configurable) and p is not Configurable:\n                return p\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getConfigRoot(cls, create = False):\n        try:\n            return manager.gettree(getattr(cls, 'configkey'), create)\n        except AttributeError:\n            return None", "response": "Returns the mapped configuration root node for the given class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef config_value_keys(self, sortkey = False):\n        ret = set()\n        cls = type(self)\n        while True:\n            root = cls.getConfigRoot()\n            if root:\n                ret = ret.union(set(root.config_value_keys()))\n            parent = None\n            for c in cls.__bases__:\n                if issubclass(c, Configurable):\n                    parent = c\n            if parent is None:\n                break\n            cls = parent\n        if sortkey:\n            return sorted(list(ret))\n        else:\n            return list(ret)", "response": "Return all configuration keys for this object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of tuples for all mapped configurations for this object.", "response": "def config_value_items(self, sortkey = False):\n        \"\"\"\n        Return `(key, value)` tuples for all mapped configurations for this object\n        \"\"\"\n        return ((k, getattr(self, k)) for k in self.config_value_keys(sortkey))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(configpath = None, startup = None, daemon = False, pidfile = None, fork = None):\n    if configpath is not None:\n        manager.loadfrom(configpath)\n    if startup is not None:\n        manager['server.startup'] = startup\n    if not manager.get('server.startup'):\n        # No startup modules, try to load from __main__\n        startup = []\n        import __main__\n        for k in dir(__main__):\n            m = getattr(__main__, k)\n            if isinstance(m, type) and issubclass(m, Module) and m is not Module:\n                startup.append('__main__.' + k)\n        manager['server.startup'] = startup\n    if fork is not None and fork > 1:\n        if not hasattr(os, 'fork'):\n            raise ValueError('Fork is not supported in this operating system.')\n    def start_process():\n        s = Server()\n        s.serve()\n    def main_process():\n        if fork is not None and fork > 1:\n            import multiprocessing\n            from time import sleep\n            sub_procs = []\n            for i in range(0, fork):\n                p = multiprocessing.Process(target = start_process)\n                sub_procs.append(p)\n            for i in range(0, fork):\n                sub_procs[i].start()\n            try:\n                import signal\n                def except_return(sig, frame):\n                    raise SystemExit\n                signal.signal(signal.SIGTERM, except_return)\n                signal.signal(signal.SIGINT, except_return)\n                if hasattr(signal, 'SIGHUP'):\n                    signal.signal(signal.SIGHUP, except_return)\n                while True:\n                    sleep(2)\n                    for i in range(0, fork):\n                        if sub_procs[i].is_alive():\n                            break\n                    else:\n                        break\n            finally:\n                for i in range(0, fork):\n                    if sub_procs[i].is_alive():\n                        sub_procs[i].terminate()\n                for i in range(0, fork):\n                    sub_procs[i].join()\n        else:\n            start_process()\n    if daemon:\n        import daemon\n        if not pidfile:\n            pidfile = manager.get('daemon.pidfile')\n        uid = manager.get('daemon.uid')\n        gid = manager.get('daemon.gid')\n        if gid is None:\n            group = manager.get('daemon.group')\n            if group is not None:\n                import grp\n                gid = grp.getgrnam(group)[2]\n        if uid is None:\n            import pwd\n            user = manager.get('daemon.user')\n            if user is not None:\n                user_pw = pwd.getpwnam(user)\n                uid = user_pw.pw_uid\n                if gid is None:\n                    gid = user_pw.pw_gid\n        if uid is not None and gid is None:\n            import pwd\n            gid = pwd.getpwuid(uid).pw_gid\n        if pidfile:\n            import fcntl\n            class PidLocker(object):\n                def __init__(self, path):\n                    self.filepath = path\n                    self.fd = None\n                def __enter__(self):\n                    # Create pid file\n                    self.fd = os.open(pidfile, os.O_WRONLY | os.O_TRUNC | os.O_CREAT, 0o644)\n                    fcntl.lockf(self.fd, fcntl.LOCK_EX|fcntl.LOCK_NB)\n                    os.write(self.fd, str(os.getpid()).encode('ascii'))\n                    os.fsync(self.fd)\n                def __exit__(self, typ, val, tb):\n                    if self.fd:\n                        try:\n                            fcntl.lockf(self.fd, fcntl.LOCK_UN)\n                        except Exception:\n                            pass\n                        os.close(self.fd)\n                        self.fd = None\n            locker = PidLocker(pidfile)\n        else:\n            locker = None\n        import sys\n        # Module loading is related to current path, add it to sys.path\n        cwd = os.getcwd()\n        if cwd not in sys.path:\n            sys.path.append(cwd)\n        # Fix path issues on already-loaded modules\n        for m in sys.modules.values():\n            if getattr(m, '__path__', None):\n                m.__path__ = [os.path.abspath(p) for p in m.__path__]\n            # __file__ is used for module-relative resource locate\n            if getattr(m, '__file__', None):\n                m.__file__ = os.path.abspath(m.__file__)\n        configs = {'gid':gid,'uid':uid,'pidfile':locker}\n        config_filters = ['chroot_directory', 'working_directory', 'umask', 'detach_process',\n                          'prevent_core']\n        if hasattr(manager, 'daemon'):\n            configs.update((k,v) for k,v in manager.daemon.config_value_items() if k in config_filters)\n        if not hasattr(os, 'initgroups'):\n            configs['initgroups'] = False\n        with daemon.DaemonContext(**configs):\n            main_process()\n    else:\n        main_process()", "response": "Main function for the VLCP framework."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def wait_for_group(self, container, networkid, timeout = 120):\n        if networkid in self._current_groups:\n            return self._current_groups[networkid]\n        else:\n            if not self._connection.connected:\n                raise ConnectionResetException\n            groupchanged = VXLANGroupChanged.createMatcher(self._connection, networkid, VXLANGroupChanged.UPDATED)\n            conn_down = self._connection.protocol.statematcher(self._connection)\n            timeout_, ev, m = await container.wait_with_timeout(timeout, groupchanged, conn_down)\n            if timeout_:\n                raise ValueError('VXLAN group is still not created after a long time')\n            elif m is conn_down:\n                raise ConnectionResetException\n            else:\n                return ev.physicalportid", "response": "Wait for a VXLAN group to be created."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a single element from the current buffer.", "response": "def readonce(self, size = None):\n        \"\"\"\n        Read from current buffer. If current buffer is empty, returns an empty string. You can use `prepareRead`\n        to read the next chunk of data.\n        \n        This is not a coroutine method.\n        \"\"\"\n        if self.eof:\n            raise EOFError\n        if self.errored:\n            raise IOError('Stream is broken before EOF')\n        if size is not None and size < len(self.data) - self.pos:\n            ret = self.data[self.pos: self.pos + size]\n            self.pos += size\n            return ret\n        else:\n            ret = self.data[self.pos:]\n            self.pos = len(self.data)\n            if self.dataeof:\n                self.eof = True\n            return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds a subtree from a matcher.", "response": "def subtree(self, matcher, create = False):\n        '''\n        Find a subtree from a matcher\n        \n        :param matcher: the matcher to locate the subtree. If None, return the root of the tree.\n        \n        :param create: if True, the subtree is created if not exists; otherwise return None if not exists\n        '''\n        if matcher is None:\n            return self\n        current = self\n        for i in range(self.depth, len(matcher.indices)):\n            ind = matcher.indices[i]\n            if ind is None:\n                # match Any\n                if hasattr(current, 'any'):\n                    current = current.any\n                else:\n                    if create:\n                        cany = MatchTree(current)\n                        cany.parentIndex = None\n                        current.any = cany\n                        current = cany\n                    else:\n                        return None\n            else:\n                current2 = current.index.get(ind)\n                if current2 is None:\n                    if create:\n                        cind = MatchTree(current)\n                        cind.parentIndex = ind \n                        current.index[ind] = cind\n                        current = cind\n                    else:\n                        return None\n                else:\n                    current = current2\n        return current"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef insert(self, matcher, obj):\n        '''\n        Insert a new matcher\n        \n        :param matcher: an EventMatcher\n        \n        :param obj: object to return\n        '''\n        current = self.subtree(matcher, True)\n        #current.matchers[(obj, matcher)] = None\n        if current._use_dict:\n            current.matchers_dict[(obj, matcher)] = None\n        else:\n            current.matchers_list.append((obj, matcher))\n        return current", "response": "Insert a new event matcher into the tree."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove(self, matcher, obj):\n        '''\n        Remove the matcher\n        \n        :param matcher: an EventMatcher\n        \n        :param obj: the object to remove\n        '''\n        current = self.subtree(matcher, False)\n        if current is None:\n            return\n        # Assume that this pair only appears once\n        if current._use_dict:\n            try:\n                del current.matchers_dict[(obj, matcher)]\n            except KeyError:\n                pass\n        else:\n            if len(current.matchers_list) > 10:\n                # Convert to dict\n                current.matchers_dict = OrderedDict((v, None) for v in current.matchers_list\n                                                    if v != (obj, matcher))\n                current.matchers_list = None\n                current._use_dict = True\n            else:\n                try:\n                    current.matchers_list.remove((obj, matcher))\n                except ValueError:\n                    pass\n        while ((not current.matchers_dict) if current._use_dict\n               else (not current.matchers_list))\\\n                and not current.matchers_dict\\\n                and not hasattr(current,'any')\\\n                and not current.index and current.parent is not None:\n            # remove self from parents\n            ind = current.parentIndex\n            if ind is None:\n                del current.parent.any\n            else:\n                del current.parent.index[ind]\n            p = current.parent\n            current.parent = None\n            current = p", "response": "Removes the object from the event matcher."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef matchesWithMatchers(self, event):\n        '''\n        Return all matches for this event. The first matcher is also returned for each matched object.\n        \n        :param event: an input event\n        '''\n        ret = []\n        self._matches(event, set(), ret)\n        return tuple(ret)", "response": "Returns all matches for this event."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning all matches for this event.", "response": "def matches(self, event):\n        '''\n        Return all matches for this event. The first matcher is also returned for each matched object.\n        \n        :param event: an input event\n        '''\n        ret = []\n        self._matches(event, set(), ret)\n        return tuple(r[0] for r in ret)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the first match for this event", "response": "def matchfirst(self, event):\n        '''\n        Return first match for this event\n        \n        :param event: an input event\n        '''\n        # 1. matches(self.index[ind], event)\n        # 2. matches(self.any, event)\n        # 3. self.matches\n        if self.depth < len(event.indices):\n            ind = event.indices[self.depth]\n            if ind in self.index:\n                m = self.index[ind].matchfirst(event)\n                if m is not None:\n                    return m\n            if hasattr(self, 'any'):\n                m = self.any.matchfirst(event)\n                if m is not None:\n                    return m\n        if self._use_dict:\n            for o, m in self.matchers_dict:\n                if m is None or m.judge(event):\n                    return o\n        else:\n            for o, m in self.matchers_list:\n                if m is None or m.judge(event):\n                    return o"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef subtree(self, event, create = False):\n        '''\n        Find a subtree from an event\n        '''\n        current = self\n        for i in range(self.depth, len(event.indices)):\n            if not hasattr(current, 'index'):\n                return current\n            ind = event.indices[i]\n            if create:\n                current = current.index.setdefault(ind, EventTree(current, self.branch))\n                current.parentIndex = ind\n            else:\n                current = current.index.get(ind)\n                if current is None:\n                    return None\n        return current", "response": "Find a subtree from an event."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lognet_vxlan_walker(prepush = True):\n    def _walk_lognet(key, value, walk, save):\n        save(key)\n        if value is None:\n            return\n        try:\n            phynet = walk(value.physicalnetwork.getkey())\n        except KeyError:\n            pass\n        else:\n            if phynet is not None and getattr(phynet, 'type') == 'vxlan':\n                try:\n                    vxlan_endpoint_key = VXLANEndpointSet.default_key(value.id)\n                    walk(vxlan_endpoint_key)\n                except KeyError:\n                    pass\n                else:\n                    save(vxlan_endpoint_key)\n                if prepush:\n                    # Acquire all logical ports\n                    try:\n                        netmap = walk(LogicalNetworkMap.default_key(value.id))\n                    except KeyError:\n                        pass\n                    else:\n                        save(netmap.getkey())\n                        for logport in netmap.ports.dataset():\n                            try:\n                                _ = walk(logport.getkey())\n                            except KeyError:\n                                pass\n                            else:\n                                save(logport.getkey())\n                            try:\n                                _, (portid,) = LogicalPort._getIndices(logport.getkey())\n                                portinfokey = LogicalPortVXLANInfo.default_key(portid)\n                                _ = walk(portinfokey)\n                            except KeyError:\n                                pass\n                            else:\n                                save(portinfokey)                            \n    return _walk_lognet", "response": "Returns a walker function to retrieve necessary information from ObjectDB object DB objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate all VXLAN informations in a VXLAN container.", "response": "async def update_vxlaninfo(container, network_ip_dict, created_ports, removed_ports,\n                ovsdb_vhost, system_id, bridge,\n                allowedmigrationtime, refreshinterval):\n    '''\n    Do an ObjectDB transact to update all VXLAN informations\n    \n    :param container: Routine container\n    \n    :param network_ip_dict: a {logicalnetwork_id: tunnel_ip} dictionary\n    \n    :param created_ports: logical ports to be added, a {logicalport_id: tunnel_ip} dictionary\n    \n    :param removed_ports: logical ports to be removed, a {logicalport_id: tunnel_ip} dictionary\n    \n    :param ovsdb_vhost: identifier for the bridge, vhost name\n    \n    :param system_id: identifier for the bridge, OVSDB systemid\n    \n    :param bridge: identifier for the bridge, bridge name\n    \n    :param allowedmigrationtime: time allowed for port migration, secondary endpoint info will be removed\n                                 after this time\n    \n    :param refreshinterval: refreshinterval * 2 will be the timeout for network endpoint\n    '''\n    network_list = list(network_ip_dict.keys())\n    vxlanendpoint_list = [VXLANEndpointSet.default_key(n) for n in network_list]\n    all_tun_ports2 = list(set(created_ports.keys()).union(set(removed_ports.keys())))\n    def update_vxlanendpoints(keys, values, timestamp):\n        # values = List[VXLANEndpointSet]\n        # endpointlist is [src_ip, vhost, systemid, bridge, expire]\n        for v,n in zip(values[0:len(network_list)], network_list):\n            if v is not None:\n                v.endpointlist = [ep for ep in v.endpointlist\n                                  if (ep[1], ep[2], ep[3]) != (ovsdb_vhost, system_id, bridge)\n                                  and ep[4] >= timestamp]\n                ip_address = network_ip_dict[n]\n                if ip_address is not None:\n                    v.endpointlist.append([ip_address,\n                              ovsdb_vhost,\n                              system_id,\n                              bridge,\n                              None if refreshinterval is None else\n                                    refreshinterval * 1000000 * 2 + timestamp\n                              ])\n        written_values = {}\n        if all_tun_ports2:\n            for k,v,vxkey,vxinfo in zip(keys[len(network_list):len(network_list) + len(all_tun_ports2)],\n                           values[len(network_list):len(network_list) + len(all_tun_ports2)],\n                           keys[len(network_list) + len(all_tun_ports2):len(network_list) + 2 * len(all_tun_ports2)],\n                           values[len(network_list) + len(all_tun_ports2):len(network_list) + 2 * len(all_tun_ports2)]):\n                if v is None:\n                    if vxinfo is not None:\n                        # The port is deleted? Then we should also delete the vxinfo\n                        written_values[vxkey] = None\n                else:\n                    if v.id in created_ports:\n                        if vxinfo is None:\n                            vxinfo = LogicalPortVXLANInfo.create_from_key(vxkey)\n                        # There maybe more than one endpoint at the same time (on migrating)\n                        # so we keep all possible endpoints, but move our endpoint to the first place\n                        myendpoint = {'vhost': ovsdb_vhost,\n                                      'systemid': system_id,\n                                      'bridge': bridge,\n                                      'tunnel_dst': created_ports[v.id],\n                                      'updated_time': timestamp}\n                        vxinfo.endpoints = [ep for ep in vxinfo.endpoints\n                                            if ep['updated_time'] + allowedmigrationtime * 1000000 >= timestamp\n                                            and (ep['vhost'], ep['systemid'], ep['bridge']) != (ovsdb_vhost, system_id, bridge)]\n                        vxinfo.endpoints = [myendpoint] + vxinfo.endpoints\n                        written_values[vxkey] = vxinfo\n                    elif v.id in removed_ports:\n                        if vxinfo is not None:\n                            # Remove endpoint\n                            vxinfo.endpoints = [ep for ep in vxinfo.endpoints\n                                                if (ep['vhost'], ep['systemid'], ep['bridge']) != (ovsdb_vhost, system_id, bridge)]\n                            if not vxinfo.endpoints:\n                                written_values[vxkey] = None\n                            else:\n                                written_values[vxkey] = vxinfo\n        written_values_list = tuple(written_values.items())\n        return (tuple(itertools.chain(keys[:len(network_list)], (k for k,_ in written_values_list))),\n                tuple(itertools.chain(values[:len(network_list)], (v for _,v in written_values_list))))\n    return await call_api(container, 'objectdb', 'transact', {'keys': tuple(vxlanendpoint_list + [LogicalPort.default_key(p) for p in all_tun_ports2] +\n                                                                  [LogicalPortVXLANInfo.default_key(p) for p in all_tun_ports2]),\n                                                    'updater': update_vxlanendpoints,\n                                                    'withtime': True\n                                                    })"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_broadcast_ips(vxlan_endpointset, local_ip, ovsdb_vhost, system_id, bridge):\n    '''\n    Get all IP addresses that are not local\n    \n    :param vxlan_endpointset: a VXLANEndpointSet object\n    \n    :param local_ips: list of local IP address to exclude with\n    \n    :param ovsdb_vhost: identifier, vhost\n    \n    :param system_id: identifier, system-id\n    \n    :param bridge: identifier, bridge name\n    \n    :return: `[(ip, ipnum)]` list where IPs are the original string of the IP address, and ipnum\n             are 32-bit numeric IPv4 address.\n    '''\n    localip_addr = _get_ip(local_ip)\n    allips = [(ip, ipnum) for ip, ipnum in ((ep[0], _get_ip(ep[0])) for ep in vxlan_endpointset.endpointlist\n              if (ep[1], ep[2], ep[3]) != (ovsdb_vhost, system_id, bridge))\n              if ipnum is not None and ipnum != localip_addr]\n    return allips", "response": "Get all broadcast IP addresses that are not local_ip."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the result of the sequence.", "response": "def result(self):\n        '''\n        :return: None if the result is not ready, the result from set_result, or raise the exception\n                 from set_exception. If the result can be None, it is not possible to tell if the result is\n                 available; use done() to determine that.\n        '''\n        try:\n            r = getattr(self, '_result')\n        except AttributeError:\n            return None\n        else:\n            if hasattr(self, '_exception'):\n                raise self._exception\n            else:\n                return r"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwait for the current routine to return the result or raise the exception from set_exception.", "response": "async def wait(self, container = None):\n        '''\n        :param container: DEPRECATED container of current routine\n        \n        :return: The result, or raise the exception from set_exception.\n        '''\n        if hasattr(self, '_result'):\n            if hasattr(self, '_exception'):\n                raise self._exception\n            else:\n                return self._result\n        else:\n            ev = await FutureEvent.createMatcher(self)\n            if hasattr(ev, 'exception'):\n                raise ev.exception\n            else:\n                return ev.result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_result(self, result):\n        '''\n        Set the result to Future object, wake up all the waiters\n        \n        :param result: result to set\n        '''\n        if hasattr(self, '_result'):\n            raise ValueError('Cannot set the result twice')\n        self._result = result\n        self._scheduler.emergesend(FutureEvent(self, result = result))", "response": "Set the result of the job to the given result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_exception(self, exception):\n        '''\n        Set an exception to Future object, wake up all the waiters\n        \n        :param exception: exception to set\n        '''\n        if hasattr(self, '_result'):\n            raise ValueError('Cannot set the result twice')\n        self._result = None\n        self._exception = exception\n        self._scheduler.emergesend(FutureEvent(self, exception = exception))", "response": "Set the exception of the object to the given exception."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef freeze(result, format='csv', filename='freeze.csv', fileobj=None,\n           prefix='.', mode='list', **kw):\n    \"\"\"\n    Perform a data export of a given result set. This is a very\n    flexible exporter, allowing for various output formats, metadata\n    assignment, and file name templating to dump each record (or a set\n    of records) into individual files.\n\n    ::\n\n        result = db['person'].all()\n        dataset.freeze(result, format='json', filename='all-persons.json')\n\n    Instead of passing in the file name, you can also pass a file object::\n\n        result = db['person'].all()\n        fh = open('/dev/null', 'wb')\n        dataset.freeze(result, format='json', fileobj=fh)\n\n    Be aware that this will disable file name templating and store all\n    results to the same file.\n\n    If ``result`` is a table (rather than a result set), all records in\n    the table are exported (as if ``result.all()`` had been called).\n\n\n    freeze supports two values for ``mode``:\n\n        *list* (default)\n            The entire result set is dumped into a single file.\n\n        *item*\n            One file is created for each row in the result set.\n\n    You should set a ``filename`` for the exported file(s). If ``mode``\n    is set to *item* the function would generate one file per row. In\n    that case you can  use values as placeholders in filenames::\n\n            dataset.freeze(res, mode='item', format='json',\n                           filename='item-{{id}}.json')\n\n    The following output ``format`` s are supported:\n\n        *csv*\n            Comma-separated values, first line contains column names.\n\n        *json*\n            A JSON file containing a list of dictionaries for each row\n            in the table. If a ``callback`` is given, JSON with padding\n            (JSONP) will be generated.\n\n        *tabson*\n            Tabson is a smart combination of the space-efficiency of the\n            CSV and the parsability and structure of JSON.\n\n    You can pass additional named parameters specific to the used format.\n\n        As an example, you can freeze to minified JSON with the following:\n\n            dataset.freeze(res, format='json', indent=4, wrap=False,\n                           filename='output.json')\n\n        *json* and *tabson*\n            *callback*:\n                if provided, generate a JSONP string using the given callback\n                function, i.e. something like `callback && callback({...})`\n\n            *indent*:\n                if *indent* is a non-negative integer (it is ``2`` by default\n                when you call `dataset.freeze`, and ``None`` via the\n                ``datafreeze`` command), then JSON array elements and object\n                members will be pretty-printed with that indent level.\n                An indent level of 0 will only insert newlines.\n                ``None`` is the most compact representation.\n\n            *meta*:\n                if *meta* is not ``None`` (default: ``{}``), it will be included\n                in the JSON output (for *json*, only if *wrap* is ``True``).\n\n            *wrap* (only for *json*):\n                if *wrap* is ``True`` (default), the JSON output is an object\n                of the form ``{\"count\": 2, \"results\": [...]}``.\n                if ``meta`` is not ``None``, a third property ``meta`` is added\n                to the wrapping object, with this value.\n    \"\"\"\n    kw.update({\n        'format': format,\n        'filename': filename,\n        'fileobj': fileobj,\n        'prefix': prefix,\n        'mode': mode\n    })\n\n    # Special cases when freezing comes from dataset.freeze\n    if format in ['json', 'tabson'] and 'indent' not in kw:\n        kw['indent'] = 2\n\n    records = result.all() if isinstance(result, dataset.Table) else result\n    return freeze_export(Export({}, kw), result=records)", "response": "This function is used to export a set of items in a result set into a single file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decode_cert(cert):\n\n    ret_dict = {}\n    subject_xname = X509_get_subject_name(cert.value)\n    ret_dict[\"subject\"] = _create_tuple_for_X509_NAME(subject_xname)\n\n    notAfter = X509_get_notAfter(cert.value)\n    ret_dict[\"notAfter\"] = ASN1_TIME_print(notAfter)\n\n    peer_alt_names = _get_peer_alt_names(cert)\n    if peer_alt_names is not None:\n        ret_dict[\"subjectAltName\"] = peer_alt_names\n\n    return ret_dict", "response": "Convert an X509 certificate into a Python dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_server_certificate(addr, ssl_version=PROTOCOL_SSLv23, ca_certs=None):\n\n    if ssl_version not in (PROTOCOL_DTLS, PROTOCOL_DTLSv1, PROTOCOL_DTLSv1_2):\n        return _orig_get_server_certificate(addr, ssl_version, ca_certs)\n\n    if ca_certs is not None:\n        cert_reqs = ssl.CERT_REQUIRED\n    else:\n        cert_reqs = ssl.CERT_NONE\n    af = getaddrinfo(addr[0], addr[1])[0][0]\n    s = ssl.wrap_socket(socket(af, SOCK_DGRAM),\n                        ssl_version=ssl_version,\n                        cert_reqs=cert_reqs, ca_certs=ca_certs)\n    s.connect(addr)\n    dercert = s.getpeercert(True)\n    s.close()\n    return ssl.DER_cert_to_PEM_cert(dercert)", "response": "Retrieve a server certificate at the specified address and return it as PEM - encoded string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_curves(self, curves):\n        u''' Set supported curves by name, nid or nist.\n\n        :param str | tuple(int) curves: Example \"secp384r1:secp256k1\", (715, 714), \"P-384\", \"K-409:B-409:K-571\", ...\n        :return: 1 for success and 0 for failure\n        '''\n        retVal = None\n        if isinstance(curves, str):\n            retVal = SSL_CTX_set1_curves_list(self._ctx, curves)\n        elif isinstance(curves, tuple):\n            retVal = SSL_CTX_set1_curves(self._ctx, curves, len(curves))\n        return retVal", "response": "u Set supported curves by name nid or nist."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_ecdh_curve(self, curve_name=None):\n        u''' Select a curve to use for ECDH(E) key exchange or set it to auto mode\n\n        Used for server only!\n\n        s.a. openssl.exe ecparam -list_curves\n\n        :param None | str curve_name: None = Auto-mode, \"secp256k1\", \"secp384r1\", ...\n        :return: 1 for success and 0 for failure\n        '''\n        if curve_name:\n            retVal = SSL_CTX_set_ecdh_auto(self._ctx, 0)\n            avail_curves = get_elliptic_curves()\n            key = [curve for curve in avail_curves if curve.name == curve_name][0].to_EC_KEY()\n            retVal &= SSL_CTX_set_tmp_ecdh(self._ctx, key)\n        else:\n            retVal = SSL_CTX_set_ecdh_auto(self._ctx, 1)\n        return retVal", "response": "u Select a curve to use for ECDH key exchange or set it to auto - mode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_cert_chain(self, flags=SSL_BUILD_CHAIN_FLAG_NONE):\n        u'''\n        Used for server side only!\n\n        :param flags:\n        :return: 1 for success and 0 for failure\n        '''\n        retVal = SSL_CTX_build_cert_chain(self._ctx, flags)\n        return retVal", "response": "u Used for server side only!"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve a socket used by this connection", "response": "def get_socket(self, inbound):\n        \"\"\"Retrieve a socket used by this connection\n\n        When inbound is True, then the socket from which this connection reads\n        data is retrieved. Otherwise the socket to which this connection writes\n        data is retrieved.\n\n        Read and write sockets differ depending on whether this is a server- or\n        a client-side connection, and on whether a routing demux is in use.\n        \"\"\"\n\n        if inbound and hasattr(self, \"_rsock\"):\n            return self._rsock\n        return self._sock"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef accept(self):\n\n        if not self._pending_peer_address:\n            if not self.listen():\n                _logger.debug(\"Accept returning without connection\")\n                return\n        new_conn = SSLConnection(self, self._keyfile, self._certfile, True,\n                                 self._cert_reqs, self._ssl_version,\n                                 self._ca_certs, self._do_handshake_on_connect,\n                                 self._suppress_ragged_eofs, self._ciphers,\n                                 cb_user_config_ssl_ctx=self._user_config_ssl_ctx,\n                                 cb_user_config_ssl=self._user_config_ssl)\n        new_peer = self._pending_peer_address\n        self._pending_peer_address = None\n        if self._do_handshake_on_connect:\n            # Note that since that connection's socket was just created in its\n            # constructor, the following operation must be blocking; hence\n            # handshake-on-connect can only be used with a routing demux if\n            # listen is serviced by a separate application thread, or else we\n            # will hang in this call\n            new_conn.do_handshake()\n        _logger.debug(\"Accept returning new connection for new peer\")\n        return new_conn, new_peer", "response": "This method returns a server - side UDP connection establishment of the current peer and the new peer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect(self, peer_address):\n\n        self._sock.connect(peer_address)\n        peer_address = self._sock.getpeername()  # substituted host addrinfo\n        BIO_dgram_set_connected(self._wbio.value, peer_address)\n        assert self._wbio is self._rbio\n        if self._do_handshake_on_connect:\n            self.do_handshake()", "response": "Client - side UDP connection establishment"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_handshake(self):\n\n        _logger.debug(\"Initiating handshake...\")\n        try:\n            self._wrap_socket_library_call(\n                lambda: SSL_do_handshake(self._ssl.value),\n                ERR_HANDSHAKE_TIMEOUT)\n        except openssl_error() as err:\n            if err.ssl_error == SSL_ERROR_SYSCALL and err.result == -1:\n                raise_ssl_error(ERR_PORT_UNREACHABLE, err)\n            raise\n        self._handshake_done = True\n        _logger.debug(\"...completed handshake\")", "response": "Perform an explicit handshake with the peer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(self, len=1024, buffer=None):\n\n        try:\n            return self._wrap_socket_library_call(\n                lambda: SSL_read(self._ssl.value, len, buffer), ERR_READ_TIMEOUT)\n        except openssl_error() as err:\n            if err.ssl_error == SSL_ERROR_SYSCALL and err.result == -1:\n                raise_ssl_error(ERR_PORT_UNREACHABLE, err)\n            raise", "response": "Read up to len bytes and return them."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, data):\n\n        try:\n            ret = self._wrap_socket_library_call(\n                lambda: SSL_write(self._ssl.value, data), ERR_WRITE_TIMEOUT)\n        except openssl_error() as err:\n            if err.ssl_error == SSL_ERROR_SYSCALL and err.result == -1:\n                raise_ssl_error(ERR_PORT_UNREACHABLE, err)\n            raise\n        if ret:\n            self._handshake_done = True\n        return ret", "response": "Write data to the connection."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshut down the DTLS connection.", "response": "def shutdown(self):\n        \"\"\"Shut down the DTLS connection\n\n        This method attemps to complete a bidirectional shutdown between\n        peers. For non-blocking sockets, it should be called repeatedly until\n        it no longer raises continuation request exceptions.\n        \"\"\"\n\n        if hasattr(self, \"_listening\"):\n            # Listening server-side sockets cannot be shut down\n            return\n\n        try:\n            self._wrap_socket_library_call(\n                lambda: SSL_shutdown(self._ssl.value), ERR_READ_TIMEOUT)\n        except openssl_error() as err:\n            if err.result == 0:\n                # close-notify alert was just sent; wait for same from peer\n                # Note: while it might seem wise to suppress further read-aheads\n                # with SSL_set_read_ahead here, doing so causes a shutdown\n                # failure (ret: -1, SSL_ERROR_SYSCALL) on the DTLS shutdown\n                # initiator side. And test_starttls does pass.\n                self._wrap_socket_library_call(\n                    lambda: SSL_shutdown(self._ssl.value), ERR_READ_TIMEOUT)\n            else:\n                raise\n        if hasattr(self, \"_rsock\"):\n            # Return wrapped connected server socket (non-listening)\n            return _UnwrappedSocket(self._sock, self._rsock, self._udp_demux,\n                                    self._ctx,\n                                    BIO_dgram_get_peer(self._wbio.value))\n        # Return unwrapped client-side socket or unwrapped server-side socket\n        # for single-socket servers\n        return self._sock"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the peer s certificate and return it as a dictionary.", "response": "def getpeercert(self, binary_form=False):\n        \"\"\"Retrieve the peer's certificate\n\n        When binary form is requested, the peer's DER-encoded certficate is\n        returned if it was transmitted during the handshake.\n\n        When binary form is not requested, and the peer's certificate has been\n        validated, then a certificate dictionary is returned. If the certificate\n        was not validated, an empty dictionary is returned.\n\n        In all cases, None is returned if no certificate was received from the\n        peer.\n        \"\"\"\n\n        try:\n            peer_cert = _X509(SSL_get_peer_certificate(self._ssl.value))\n        except openssl_error():\n            return\n\n        if binary_form:\n            return i2d_X509(peer_cert.value)\n        if self._cert_reqs == CERT_NONE:\n            return {}\n        return decode_cert(peer_cert)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cipher(self):\n\n        if not self._handshake_done:\n            return\n\n        current_cipher = SSL_get_current_cipher(self._ssl.value)\n        cipher_name = SSL_CIPHER_get_name(current_cipher)\n        cipher_version = SSL_CIPHER_get_version(current_cipher)\n        cipher_bits = SSL_CIPHER_get_bits(current_cipher)\n        return cipher_name, cipher_version, cipher_bits", "response": "Retrieve information about the current cipher and return a triple consisting of the cipher name SSL protocol version and number of secret bits."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares the base directories for the next bin of the current platform.", "response": "def _prep_bins():\n    \"\"\"\n    Support for running straight out of a cloned source directory instead\n    of an installed distribution\n    \"\"\"\n\n    from os import path\n    from sys import platform, maxsize\n    from shutil import copy\n    bit_suffix = \"-x86_64\" if maxsize > 2**32 else \"-x86\"\n    package_root = path.abspath(path.dirname(__file__))\n    prebuilt_path = path.join(package_root, \"prebuilt\", platform + bit_suffix)\n    config = {\"MANIFEST_DIR\": prebuilt_path}\n    try:\n        execfile(path.join(prebuilt_path, \"manifest.pycfg\"), config)\n    except IOError:\n        return  # there are no prebuilts for this platform - nothing to do\n    files = map(lambda x: path.join(prebuilt_path, x), config[\"FILES\"])\n    for prebuilt_file in files:\n        try:\n            copy(path.join(prebuilt_path, prebuilt_file), package_root)\n        except IOError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_connection(self, address):\n\n        if not address:\n            return self._datagram_socket\n\n        # Create a new datagram socket bound to the same interface and port as\n        # the root socket, but connected to the given peer\n        conn = socket.socket(self._datagram_socket.family,\n                             self._datagram_socket.type,\n                             self._datagram_socket.proto)\n        conn.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        conn.bind(self._datagram_socket.getsockname())\n        conn.connect(address)\n        _logger.debug(\"Created new connection for address: %s\", address)\n        return conn", "response": "Create or retrieve a muxed datagram socket instance for the given peer endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the info callback for the current context.", "response": "def SSL_CTX_set_info_callback(ctx, app_info_cb):\n    \"\"\"\n    Set the info callback\n\n    :param callback: The Python callback to use\n    :return: None\n    \"\"\"\n    def py_info_callback(ssl, where, ret):\n        try:\n            app_info_cb(SSL(ssl), where, ret)\n        except:\n            pass\n        return\n\n    global _info_callback\n    _info_callback[ctx] = _rvoid_voidp_int_int(py_info_callback)\n    _SSL_CTX_set_info_callback(ctx, _info_callback[ctx])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef raise_ssl_error(code, nested=None):\n    err_string = str(code) + \": \" + _ssl_errors[code]\n    if nested:\n        raise SSLError(code, err_string + str(nested))\n    raise SSLError(code, err_string)", "response": "Raise an SSL error with the given error code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_connection(self, address):\n\n        if self.connections.has_key(address):\n            return self.connections[address]\n        \n        # We need a new datagram socket on a dynamically assigned ephemeral port\n        conn = socket.socket(self._forwarding_socket.family,\n                             self._forwarding_socket.type,\n                             self._forwarding_socket.proto)\n        conn.bind((self._forwarding_socket.getsockname()[0], 0))\n        conn.connect(self._forwarding_socket.getsockname())\n        if not address:\n            conn.setblocking(0)\n        self.connections[address] = conn\n        _logger.debug(\"Created new connection for address: %s\", address)\n        return conn", "response": "Create or retrieve a muxed connection for the given peer endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nservice the root socket and forward one datagram to the next connection.", "response": "def service(self):\n        \"\"\"Service the root socket\n\n        Read from the root socket and forward one datagram to a\n        connection. The call will return without forwarding data\n        if any of the following occurs:\n\n          * An error is encountered while reading from the root socket\n          * Reading from the root socket times out\n          * The root socket is non-blocking and has no data available\n          * An empty payload is received\n          * A non-empty payload is received from an unknown peer (a peer\n            for which get_connection has not yet been called); in this case,\n            the payload is held by this instance and will be forwarded when\n            the forward method is called\n\n        Return:\n        if the datagram received was from a new peer, then the peer's\n        address; otherwise None\n        \"\"\"\n\n        self.payload, self.payload_peer_address = \\\n          self.datagram_socket.recvfrom(UDP_MAX_DGRAM_LENGTH)\n        _logger.debug(\"Received datagram from peer: %s\",\n                      self.payload_peer_address)\n        if not self.payload:\n            self.payload_peer_address = None\n            return\n        if self.connections.has_key(self.payload_peer_address):\n            self.forward()\n        else:\n            return self.payload_peer_address"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nforwards a stored datagram from another peer to the new peer.", "response": "def forward(self):\n        \"\"\"Forward a stored datagram\n\n        When the service method returns the address of a new peer, it holds\n        the datagram from that peer in this instance. In this case, this\n        method will perform the forwarding step. The target connection is the\n        one associated with address None if get_connection has not been called\n        since the service method returned the new peer's address, and the\n        connection associated with the new peer's address if it has.\n        \"\"\"\n\n        assert self.payload\n        assert self.payload_peer_address\n        if self.connections.has_key(self.payload_peer_address):\n            conn = self.connections[self.payload_peer_address]\n            default = False\n        else:\n            conn = self.connections[None]  # propagate exception if not created\n            default = True\n        _logger.debug(\"Forwarding datagram from peer: %s, default: %s\",\n                      self.payload_peer_address, default)\n        self._forwarding_socket.sendto(self.payload, conn.getsockname())\n        self.payload = \"\"\n        self.payload_peer_address = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting any emoji in a string into accessible content.", "response": "def emojificate_filter(content, autoescape=True):\n    \"Convert any emoji in a string into accessible content.\"\n    # return mark_safe(emojificate(content))\n    if autoescape:\n        esc = conditional_escape\n    else:\n        esc = lambda x: x\n    return mark_safe(emojificate(esc(content)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the orders with the latest price and price.", "response": "def updateorders(self):\n        \"\"\" Update the orders\n        \"\"\"\n        log.info(\"Replacing orders\")\n\n        # Canceling orders\n        self.cancelall()\n\n        # Target\n        target = self.bot.get(\"target\", {})\n        price = self.getprice()\n\n        # prices\n        buy_price = price * (1 - target[\"offsets\"][\"buy\"] / 100)\n        sell_price = price * (1 + target[\"offsets\"][\"sell\"] / 100)\n\n        # Store price in storage for later use\n        self[\"feed_price\"] = float(price)\n\n        # Buy Side\n        if float(self.balance(self.market[\"base\"])) < buy_price * target[\"amount\"][\"buy\"]:\n            InsufficientFundsError(Amount(target[\"amount\"][\"buy\"] * float(buy_price), self.market[\"base\"]))\n            self[\"insufficient_buy\"] = True\n        else:\n            self[\"insufficient_buy\"] = False\n            self.market.buy(\n                buy_price,\n                Amount(target[\"amount\"][\"buy\"], self.market[\"quote\"]),\n                account=self.account\n            )\n\n        # Sell Side\n        if float(self.balance(self.market[\"quote\"])) < target[\"amount\"][\"sell\"]:\n            InsufficientFundsError(Amount(target[\"amount\"][\"sell\"], self.market[\"quote\"]))\n            self[\"insufficient_sell\"] = True\n        else:\n            self[\"insufficient_sell\"] = False\n            self.market.sell(\n                sell_price,\n                Amount(target[\"amount\"][\"sell\"], self.market[\"quote\"]),\n                account=self.account\n            )\n\n        pprint(self.execute())"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the price for the quote and make sure it has a feed price", "response": "def getprice(self):\n        \"\"\" Here we obtain the price for the quote and make sure it has\n            a feed price\n        \"\"\"\n        target = self.bot.get(\"target\", {})\n        if target.get(\"reference\") == \"feed\":\n            assert self.market == self.market.core_quote_market(), \"Wrong market for 'feed' reference!\"\n            ticker = self.market.ticker()\n            price = ticker.get(\"quoteSettlement_price\")\n            assert abs(price[\"price\"]) != float(\"inf\"), \"Check price feed of asset! (%s)\" % str(price)\n        return price"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tick(self, d):\n        if self.test_blocks:\n            if not (self.counter[\"blocks\"] or 0) % self.test_blocks:\n                self.test()\n            self.counter[\"blocks\"] += 1", "response": "tick come in on every block\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef orders(self):\n        self.account.refresh()\n        return [o for o in self.account.openorders if self.bot[\"market\"] == o.market and self.account.openorders]", "response": "Return the bot s open orders in the current market"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute(self):\n        self.bitshares.blocking = \"head\"\n        r = self.bitshares.txbuffer.broadcast()\n        self.bitshares.blocking = False\n        return r", "response": "Execute a bundle of operations"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncancels all orders of this bot", "response": "def cancelall(self):\n        \"\"\" Cancel all orders of this bot\n        \"\"\"\n        if self.orders:\n            return self.bitshares.cancel(\n                [o[\"id\"] for o in self.orders],\n                account=self.account\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the XML representation of the current object.", "response": "def raw_xml(self) -> _RawXML:\n        \"\"\"Bytes representation of the XML content.\n        (`learn more <http://www.diveintopython3.net/strings.html>`_).\n        \"\"\"\n        if self._xml:\n            return self._xml\n        else:\n            return etree.tostring(self.element, encoding='unicode').strip().encode(self.encoding)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the PyQuery representation of the XML.", "response": "def pq(self) -> PyQuery:\n        \"\"\"`PyQuery <https://pythonhosted.org/pyquery/>`_ representation\n        of the :class:`Element <Element>` or :class:`HTML <HTML>`.\n        \"\"\"\n        if self._pq is None:\n            self._pq = PyQuery(self.raw_xml)\n\n        return self._pq"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef links(self) -> _Links:\n        return list(set(x.text for x in self.xpath('//link')))", "response": "All found links on page in as\u2013is form. Only works for Atom feeds."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef encoding(self) -> _Encoding:\n        if self._encoding:\n            return self._encoding\n\n        # Scan meta tags for charset.\n        if self._xml:\n            self._encoding = html_to_unicode(self.default_encoding, self._xml)[0]\n\n        return self._encoding if self._encoding else self.default_encoding", "response": "The encoding string to be used extracted from the XML and the XML header."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef xpath(self, selector: str, *, first: bool = False, _encoding: str = None) -> _XPath:\n        selected = self.lxml.xpath(selector)\n\n        elements = [\n            Element(element=selection, default_encoding=_encoding or self.encoding)\n            if not isinstance(selection, etree._ElementUnicodeResult) else str(selection)\n            for selection in selected\n        ]\n\n        return _get_first_or_list(elements, first)", "response": "Given an XPath selector returns a list of Element <Element > objects or a single one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching the parse XML for the given parse template.", "response": "def search(self, template: str, first: bool = False) -> _Result:\n        \"\"\"Search the :class:`Element <Element>` for the given parse\n        template.\n\n        :param template: The Parse template to use.\n        \"\"\"\n        elements = [r for r in findall(template, self.xml)]\n\n        return _get_first_or_list(elements, first)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding an element in the list of elements that match the provided selector.", "response": "def find(self, selector: str = '*', containing: _Containing = None, first: bool = False, _encoding: str = None) -> _Find:\n            \"\"\"Given a simple element name, returns a list of\n            :class:`Element <Element>` objects or a single one.\n\n            :param selector: Element name to find.\n            :param containing: If specified, only return elements that contain the provided text.\n            :param first: Whether or not to return just the first result.\n            :param _encoding: The encoding format.\n\n            If ``first`` is ``True``, only returns the first\n            :class:`Element <Element>` found.\n            \"\"\"\n\n            # Convert a single containing into a list.\n            if isinstance(containing, str):\n                containing = [containing]\n\n            encoding = _encoding or self.encoding\n            elements = [\n                Element(element=found, default_encoding=encoding)\n                for found in self.pq(selector)\n            ]\n\n            if containing:\n                elements_copy = elements.copy()\n                elements = []\n\n                for element in elements_copy:\n                    if any([c.lower() in element.text.lower() for c in containing]):\n                        elements.append(element)\n\n                elements.reverse()\n\n            return _get_first_or_list(elements, first)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_response(response, **kwargs) -> XMLResponse:\n        if not response.encoding:\n            response.encoding = DEFAULT_ENCODING\n\n        return response", "response": "Requests HTTP Response handler. Attaches .html property to\n        class:`requests.Response <requests.Response>` objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking an HTTP Request with mocked User - Agent headers. Returns a class : HTTPResponse <HTTPResponse >.", "response": "def request(self, *args, **kwargs) -> XMLResponse:\n        \"\"\"Makes an HTTP Request, with mocked User\u2013Agent headers.\n        Returns a class:`HTTPResponse <HTTPResponse>`.\n        \"\"\"\n        # Convert Request object into HTTPRequest object.\n        r = super(XMLSession, self).request(*args, **kwargs)\n\n        return XMLResponse._from_response(r)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchanges response enconding and replace it by a HTMLResponse.", "response": "def response_hook(response, **kwargs) -> XMLResponse:\n        \"\"\" Change response enconding and replace it by a HTMLResponse. \"\"\"\n        response.encoding = DEFAULT_ENCODING\n        return XMLResponse._from_response(response)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart the background process.", "response": "def start(self):\n        \"\"\"Start the background process.\"\"\"\n        self._lc = LoopingCall(self._download)\n        # Run immediately, and then every 30 seconds:\n        self._lc.start(30, now=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister an EventualResult. May be called in any thread.", "response": "def register(self, result):\n        \"\"\"\n        Register an EventualResult.\n\n        May be called in any thread.\n        \"\"\"\n        if self._stopped:\n            raise ReactorStopped()\n        self._results.add(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nindicates no more results will get pushed into EventualResults, since the reactor has stopped. This should be called in the reactor thread.", "response": "def stop(self):\n        \"\"\"\n        Indicate no more results will get pushed into EventualResults, since\n        the reactor has stopped.\n\n        This should be called in the reactor thread.\n        \"\"\"\n        self._stopped = True\n        for result in self._results:\n            result._set_result(Failure(ReactorStopped()))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _connect_deferred(self, deferred):\n        self._deferred = deferred\n\n        # Because we use __del__, we need to make sure there are no cycles\n        # involving this object, which is why we use a weakref:\n        def put(result, eventual=weakref.ref(self)):\n            eventual = eventual()\n            if eventual:\n                eventual._set_result(result)\n            else:\n                err(result, \"Unhandled error in EventualResult\")\n\n        deferred.addBoth(put)", "response": "Connect the Deferred that will be the result of the eventual."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the result of the EventualResult.", "response": "def _set_result(self, result):\n        \"\"\"\n        Set the result of the EventualResult, if not already set.\n\n        This can only happen in the reactor thread, either as a result of\n        Deferred firing, or as a result of ResultRegistry.stop(). So, no need\n        for thread-safety.\n        \"\"\"\n        if self._result_set.isSet():\n            return\n        self._value = result\n        self._result_set.set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _result(self, timeout=None):\n        if timeout is None:\n            warnings.warn(\n                \"Unlimited timeouts are deprecated.\",\n                DeprecationWarning,\n                stacklevel=3)\n            # Queue.get(None) won't get interrupted by Ctrl-C...\n            timeout = 2**31\n        self._result_set.wait(timeout)\n        # In Python 2.6 we can't rely on the return result of wait(), so we\n        # have to check manually:\n        if not self._result_set.is_set():\n            raise TimeoutError()\n        self._result_retrieved = True\n        return self._value", "response": "Return the result of the current call."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwaiting for the result of the eventual result.", "response": "def wait(self, timeout=None):\n        \"\"\"\n        Return the result, or throw the exception if result is a failure.\n\n        It may take an unknown amount of time to return the result, so a\n        timeout option is provided. If the given number of seconds pass with\n        no result, a TimeoutError will be thrown.\n\n        If a previous call timed out, additional calls to this function will\n        still wait for a result and return it if available. If a result was\n        returned or raised on one call, additional calls will return/raise the\n        same result.\n        \"\"\"\n        if threadable.isInIOThread():\n            raise RuntimeError(\n                \"EventualResult.wait() must not be run in the reactor thread.\")\n\n        if imp.lock_held():\n            try:\n                imp.release_lock()\n            except RuntimeError:\n                # The lock is held by some other thread. We should be safe\n                # to continue.\n                pass\n            else:\n                # If EventualResult.wait() is run during module import, if the\n                # Twisted code that is being run also imports something the\n                # result will be a deadlock. Even if that is not an issue it\n                # would prevent importing in other threads until the call\n                # returns.\n                raise RuntimeError(\n                    \"EventualResult.wait() must not be run at module \"\n                    \"import time.\")\n\n        result = self._result(timeout)\n        if isinstance(result, Failure):\n            result.raiseException()\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef original_failure(self):\n        try:\n            result = self._result(0.0)\n        except TimeoutError:\n            return None\n        if isinstance(result, Failure):\n            return result\n        else:\n            return None", "response": "Return the underlying Failure object or None if the result is an error."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting a LoopingCall that calls reapAllProcesses.", "response": "def _startReapingProcesses(self):\n        \"\"\"\n        Start a LoopingCall that calls reapAllProcesses.\n        \"\"\"\n        lc = LoopingCall(self._reapAllProcesses)\n        lc.clock = self._reactor\n        lc.start(0.1, False)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup(self):\n        if self._started:\n            return\n        self._common_setup()\n        if platform.type == \"posix\":\n            self._reactor.callFromThread(self._startReapingProcesses)\n        if self._startLoggingWithObserver:\n            observer = ThreadLogObserver(PythonLoggingObserver().emit)\n\n            def start():\n                # Twisted is going to override warnings.showwarning; let's\n                # make sure that has no effect:\n                from twisted.python import log\n                original = log.showwarning\n                log.showwarning = warnings.showwarning\n                self._startLoggingWithObserver(observer, False)\n                log.showwarning = original\n\n            self._reactor.callFromThread(start)\n\n            # We only want to stop the logging thread once the reactor has\n            # shut down:\n            self._reactor.addSystemEventTrigger(\n                \"after\", \"shutdown\", observer.stop)\n        t = threading.Thread(\n            target=lambda: self._reactor.run(installSignalHandlers=False),\n            name=\"CrochetReactor\")\n        t.start()\n        self._atexit_register(self._reactor.callFromThread, self._reactor.stop)\n        self._atexit_register(_store.log_errors)\n        if self._watchdog_thread is not None:\n            self._watchdog_thread.start()", "response": "Initializes the crochet library."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_in_reactor(self, function):\n        result = self._run_in_reactor(function)\n        # Backwards compatibility; use __wrapped__ instead.\n        try:\n            result.wrapped_function = function\n        except AttributeError:\n            pass\n        return result", "response": "A decorator that ensures the wrapped function runs in the reactor thread."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wait_for_reactor(self, function):\n        warnings.warn(\n            \"@wait_for_reactor is deprecated, use @wait_for instead\",\n            DeprecationWarning,\n            stacklevel=2)\n        # This will timeout, in theory. In practice the process will be dead\n        # long before that.\n        return self.wait_for(2**31)(function)", "response": "A decorator that ensures that the wrapped function runs in the reactor s thread."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef in_reactor(self, function):\n        warnings.warn(\n            \"@in_reactor is deprecated, use @run_in_reactor\",\n            DeprecationWarning,\n            stacklevel=2)\n\n        @self.run_in_reactor\n        @wraps(function)\n        def add_reactor(*args, **kwargs):\n            return function(self._reactor, *args, **kwargs)\n\n        return add_reactor", "response": "A function that ensures that the passed in function runs in the reactor thread."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _mx(domain):\n    def got_records(result):\n        return sorted(\n            [(int(record.payload.preference), str(record.payload.name))\n             for record in result[0]])\n    d = lookupMailExchange(domain)\n    d.addCallback(got_records)\n    return d", "response": "Returns a Deferred that fires with a list of MX domain tuples for\n    a given domain."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstore a EventualResult. Return an integer, a unique identifier that can be used to retrieve the object.", "response": "def store(self, deferred_result):\n        \"\"\"\n        Store a EventualResult.\n\n        Return an integer, a unique identifier that can be used to retrieve\n        the object.\n        \"\"\"\n        self._counter += 1\n        self._stored[self._counter] = deferred_result\n        return self._counter"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlogs errors for all stored EventualResults that have error results.", "response": "def log_errors(self):\n        \"\"\"\n        Log errors for all stored EventualResults that have error results.\n        \"\"\"\n        for result in self._stored.values():\n            failure = result.original_failure()\n            if failure is not None:\n                log.err(failure, \"Unhandled error in stashed EventualResult:\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start_ssh_server(port, username, password, namespace):\n    # This is a lot of boilerplate, see http://tm.tl/6429 for a ticket to\n    # provide a utility function that simplifies this.\n    from twisted.internet import reactor\n    from twisted.conch.insults import insults\n    from twisted.conch import manhole, manhole_ssh\n    from twisted.cred.checkers import (\n        InMemoryUsernamePasswordDatabaseDontUse as MemoryDB)\n    from twisted.cred.portal import Portal\n\n    sshRealm = manhole_ssh.TerminalRealm()\n    def chainedProtocolFactory():\n        return insults.ServerProtocol(manhole.Manhole, namespace)\n    sshRealm.chainedProtocolFactory = chainedProtocolFactory\n\n    sshPortal = Portal(sshRealm, [MemoryDB(**{username: password})])\n    reactor.listenTCP(port, manhole_ssh.ConchFactory(sshPortal),\n                      interface=\"127.0.0.1\")", "response": "Start an SSH server on the given port."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register(self, f, *args, **kwargs):\n        self._functions.append(lambda: f(*args, **kwargs))", "response": "Register a function and arguments to be called later."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register_function(self, function, name=None):\n        if name is None:\n            name = function.__name__\n        self.funcs[name] = function\n        return function", "response": "Register a function to be called from EPC client."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_method(self, name):\n        try:\n            return self.funcs[name]\n        except KeyError:\n            try:\n                return self.instance._get_method(name)\n            except AttributeError:\n                return SimpleXMLRPCServer.resolve_dotted_attribute(\n                    self.instance, name, self.allow_dotted_names)", "response": "Get registered method callend name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_debugger(self, debugger):\n        if debugger == 'pdb':\n            import pdb\n            self.debugger = pdb\n        elif debugger == 'ipdb':\n            import ipdb\n            self.debugger = ipdb\n        else:\n            self.debugger = debugger", "response": "Sets the debugger to run when an error occurs in published method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconnect to server and start serving registered functions.", "response": "def connect(self, socket_or_address):\n        \"\"\"\n        Connect to server and start serving registered functions.\n\n        :type socket_or_address: tuple or socket object\n        :arg  socket_or_address: A ``(host, port)`` pair to be passed\n                                 to `socket.create_connection`, or\n                                 a socket object.\n\n        \"\"\"\n        if isinstance(socket_or_address, tuple):\n            import socket\n            self.socket = socket.create_connection(socket_or_address)\n        else:\n            self.socket = socket_or_address\n\n        # This is what BaseServer.finish_request does:\n        address = None  # it is not used, so leave it empty\n        self.handler = EPCClientHandler(self.socket, address, self)\n\n        self.call = self.handler.call\n        self.call_sync = self.handler.call_sync\n        self.methods = self.handler.methods\n        self.methods_sync = self.handler.methods_sync\n\n        self.handler_thread = newthread(self, target=self.handler.start)\n        self.handler_thread.daemon = self.thread_daemon\n        self.handler_thread.start()\n        self.handler.wait_until_ready()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting the port number of this EPC server runs on.", "response": "def print_port(self, stream=sys.stdout):\n        \"\"\"\n        Print port this EPC server runs on.\n\n        As Emacs client reads port number from STDOUT, you need to\n        call this just before calling :meth:`serve_forever`.\n\n        :type stream: text stream\n        :arg  stream: A stream object to write port on.\n                      Default is :data:`sys.stdout`.\n\n        \"\"\"\n        stream.write(str(self.server_address[1]))\n        stream.write(\"\\n\")\n        stream.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef call(self, name, *args, **kwds):\n        self.callmanager.call(self, name, *args, **kwds)", "response": "Call a method on the current object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrequesting info of callable remote methods.", "response": "def methods(self, *args, **kwds):\n        \"\"\"\n        Request info of callable remote methods.\n\n        Arguments for :meth:`call` except for `name` can be applied to\n        this function too.\n\n        \"\"\"\n        self.callmanager.methods(self, *args, **kwds)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef call_sync(self, name, args, timeout=None):\n        return self._blocking_request(self.call, timeout, name, args)", "response": "This method is blocking and will call the remote function with the given name and arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef func_call_as_str(name, *args, **kwds):\n    return '{0}({1})'.format(\n        name,\n        ', '.join(itertools.chain(\n            map('{0!r}'.format, args),\n            map('{0[0]!s}={0[1]!r}'.format, sorted(kwds.items())))))", "response": "Return arguments and keyword arguments as formatted string\n ArcGIS API call"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef newthread(template=\"EPCThread-{0}\", **kwds):\n    if not isinstance(template, str):\n        template = '{0}.{1}-{{0}}'.format(template.__module__,\n                                          template.__class__.__name__)\n    return threading.Thread(\n        name=newname(template), **kwds)", "response": "Instantiate a new thread with an appropriate name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef callwith(context_manager):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwds):\n            with context_manager:\n                return func(*args, **kwds)\n        return wrapper\n    return decorator", "response": "A decorator to wrap execution of function with a context manager."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _scene_centroid(self):\n        ul_lat = self.corner_ul_lat_product\n        ll_lat = self.corner_ll_lat_product\n        ul_lon = self.corner_ul_lon_product\n        ur_lon = self.corner_ur_lon_product\n        lat = (ul_lat + ll_lat) / 2.\n        lon = (ul_lon + ur_lon) / 2.\n\n        return lat, lon", "response": "Compute image center coordinates in lat lon"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef earth_sun_d(dtime):\n        doy = int(dtime.strftime('%j'))\n        rad_term = 0.9856 * (doy - 4) * pi / 180\n        distance_au = 1 - 0.01672 * cos(rad_term)\n        return distance_au", "response": "Earth - sun distance in AU\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the reflectance of the satellite in the specified band", "response": "def reflectance(self, band):\n        \"\"\" \n        :param band: An optical band, i.e. 1-5, 7\n        :return: At satellite reflectance, [-]\n        \"\"\"\n        if band == 6:\n            raise ValueError('LT5 reflectance must be other than  band 6')\n\n        rad = self.radiance(band)\n        esun = self.ex_atm_irrad[band - 1]\n        toa_reflect = (pi * rad * self.earth_sun_dist ** 2) / (esun * cos(self.solar_zenith_rad))\n\n        return toa_reflect"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef albedo(self, model='smith'):\n        if model == 'smith':\n            blue, red, nir, swir1, swir2 = (self.reflectance(1), self.reflectance(3), self.reflectance(4),\n                                            self.reflectance(5), self.reflectance(7))\n            alb = (0.356 * blue + 0.130 * red + 0.373 * nir + 0.085 * swir1 + 0.072 * swir2 - 0.0018) / 1.014\n        elif model == 'tasumi':\n            pass\n        # add tasumi algorithm TODO\n        return alb", "response": "Finds the albedo of the resource in the given model"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef saturation_mask(self, band, value=255):\n        dn = self._get_band('b{}'.format(band))\n        mask = self.mask()\n        mask = where((dn == value) & (mask > 0), True, False)\n\n        return mask", "response": "Mask saturated pixels 1 is saturated."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnormalizing difference vegetation index.", "response": "def ndvi(self):\n        \"\"\" Normalized difference vegetation index.\n        :return: NDVI\n        \"\"\"\n        red, nir = self.reflectance(3), self.reflectance(4)\n        ndvi = self._divide_zero((nir - red), (nir + red), nan)\n\n        return ndvi"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lai(self):\n        ndvi = self.ndvi()\n        lai = 7.0 * (ndvi ** 3)\n        lai = where(lai > 6., 6., lai)\n        return lai", "response": "get the LAI of the leaf area"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef land_surface_temp(self):\n        rp = 0.91\n        tau = 0.866\n        rsky = 1.32\n        epsilon = self.emissivity(approach='tasumi')\n        radiance = self.radiance(6)\n        rc = ((radiance - rp) / tau) - ((1 - epsilon) * rsky)\n        lst = self.k2 / (log((epsilon * self.k1 / rc) + 1))\n        return lst", "response": "Mean values from Allen 2007 - > land surface temperature"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the brightness temperature of the Landsat 8 module", "response": "def brightness_temp(self, band, temp_scale='K'):\n        \"\"\"Calculate brightness temperature of Landsat 8\n    as outlined here: http://landsat.usgs.gov/Landsat8_Using_Product.php\n\n    T = K2 / log((K1 / L)  + 1)\n\n    and\n\n    L = ML * Q + AL\n\n    where:\n        T  = At-satellite brightness temperature (degrees kelvin)\n        L  = TOA spectral radiance (Watts / (m2 * srad * mm))\n        ML = Band-specific multiplicative rescaling factor from the metadata\n             (RADIANCE_MULT_BAND_x, where x is the band number)\n        AL = Band-specific additive rescaling factor from the metadata\n             (RADIANCE_ADD_BAND_x, where x is the band number)\n        Q  = Quantized and calibrated standard product pixel values (DN)\n             (ndarray img)\n        K1 = Band-specific thermal conversion constant from the metadata\n             (K1_CONSTANT_BAND_x, where x is the thermal band number)\n        K2 = Band-specific thermal conversion constant from the metadata\n             (K1_CONSTANT_BAND_x, where x is the thermal band number)\n\n    Returns\n    --------\n    ndarray:\n        float32 ndarray with shape == input shape\n    \"\"\"\n\n        if band in self.oli_bands:\n            raise ValueError('Landsat 8 brightness should be TIRS band (i.e. 10 or 11)')\n\n        k1 = getattr(self, 'k1_constant_band_{}'.format(band))\n        k2 = getattr(self, 'k2_constant_band_{}'.format(band))\n        rad = self.radiance(band)\n        brightness = k2 / log((k1 / rad) + 1)\n\n        if temp_scale == 'K':\n            return brightness\n\n        elif temp_scale == 'F':\n            return brightness * (9 / 5.0) - 459.67\n\n        elif temp_scale == 'C':\n            return brightness - 273.15\n\n        else:\n            raise ValueError('{} is not a valid temperature scale'.format(temp_scale))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the top of atmosphere reflectance of the Landsat 8.", "response": "def reflectance(self, band):\n        \"\"\"Calculate top of atmosphere reflectance of Landsat 8\n        as outlined here: http://landsat.usgs.gov/Landsat8_Using_Product.php\n    \n        R_raw = MR * Q + AR\n    \n        R = R_raw / cos(Z) = R_raw / sin(E)\n    \n        Z = 90 - E (in degrees)\n    \n        where:\n    \n            R_raw = TOA planetary reflectance, without correction for solar angle.\n            R = TOA reflectance with a correction for the sun angle.\n            MR = Band-specific multiplicative rescaling factor from the metadata\n                (REFLECTANCE_MULT_BAND_x, where x is the band number)\n            AR = Band-specific additive rescaling factor from the metadata\n                (REFLECTANCE_ADD_BAND_x, where x is the band number)\n            Q = Quantized and calibrated standard product pixel values (DN)\n            E = Local sun elevation angle. The scene center sun elevation angle\n                in degrees is provided in the metadata (SUN_ELEVATION).\n            Z = Local solar zenith angle (same angle as E, but measured from the\n                zenith instead of from the horizon).\n    \n        Returns\n        --------\n        ndarray:\n            float32 ndarray with shape == input shape\n    \n        \"\"\"\n\n        if band not in self.oli_bands:\n            raise ValueError('Landsat 8 reflectance should OLI band (i.e. bands 1-8)')\n\n        elev = getattr(self, 'sun_elevation')\n        dn = self._get_band('b{}'.format(band))\n        mr = getattr(self, 'reflectance_mult_band_{}'.format(band))\n        ar = getattr(self, 'reflectance_add_band_{}'.format(band))\n\n        if elev < 0.0:\n            raise ValueError(\"Sun elevation must be non-negative \"\n                             \"(sun must be above horizon for entire scene)\")\n\n        rf = ((mr * dn.astype(float32)) + ar) / sin(deg2rad(elev))\n\n        return rf"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef radiance(self, band):\n        ml = getattr(self, 'radiance_mult_band_{}'.format(band))\n        al = getattr(self, 'radiance_add_band_{}'.format(band))\n        dn = self._get_band('b{}'.format(band))\n        rad = ml * dn.astype(float32) + al\n\n        return rad", "response": "Calculate top of atmosphere radiance of Landsat 8\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ndsi(self):\n        green, swir1 = self.reflectance(3), self.reflectance(6)\n        ndsi = self._divide_zero((green - swir1), (green + swir1), nan)\n\n        return ndsi", "response": "Normalized difference snow index."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the index of the whiteness of the color bands.", "response": "def whiteness_index(self):\n        \"\"\"Index of \"Whiteness\" based on visible bands.\n        Parameters\n        ----------\n\n        Output\n        ------\n        ndarray:\n            whiteness index\n        \"\"\"\n        mean_vis = (self.blue + self.green + self.red) / 3\n\n        blue_absdiff = np.absolute(self._divide_zero(self.blue - mean_vis, mean_vis))\n        green_absdiff = np.absolute(self._divide_zero(self.green - mean_vis, mean_vis))\n        red_absdiff = np.absolute(self._divide_zero(self.red - mean_vis, mean_vis))\n\n        return blue_absdiff + green_absdiff + red_absdiff"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef potential_cloud_pixels(self):\n        eq1 = self.basic_test()\n        eq2 = self.whiteness_test()\n        eq3 = self.hot_test()\n        eq4 = self.nirswir_test()\n        if self.sat == 'LC8':\n            cir = self.cirrus_test()\n            return (eq1 & eq2 & eq3 & eq4) | cir\n        else:\n            return eq1 & eq2 & eq3 & eq4", "response": "Return a boolean array containing the potential cloud pixels for the given cloud class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse water to mask tirs and find 82. 5th percentile temperature over water", "response": "def temp_water(self):\n        \"\"\"Use water to mask tirs and find 82.5 pctile\n        Equation 7 and 8 (Zhu and Woodcock, 2012)\n        Parameters\n        ----------\n        is_water: ndarray, boolean\n            water mask, water is True, land is False\n        swir2: ndarray\n        tirs1: ndarray\n        Output\n        ------\n        float:\n            82.5th percentile temperature over water\n        \"\"\"\n        # eq7\n        th_swir2 = 0.03\n        water = self.water_test()\n        clear_sky_water = water & (self.swir2 < th_swir2)\n\n        # eq8\n        clear_water_temp = self.tirs1.copy()\n        clear_water_temp[~clear_sky_water] = np.nan\n        clear_water_temp[~self.mask] = np.nan\n        pctl_clwt = np.nanpercentile(clear_water_temp, 82.5)\n        return pctl_clwt"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef brightness_prob(self, clip=True):\n        thresh = 0.11\n        bp = np.minimum(thresh, self.nir) / thresh\n        if clip:\n            bp[bp > 1] = 1\n            bp[bp < 0] = 0\n        return bp", "response": "The brightness probability of the brightest water."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef temp_land(self, pcps, water):\n        # eq 12\n        clearsky_land = ~(pcps | water)\n\n        # use clearsky_land to mask tirs1\n        clear_land_temp = self.tirs1.copy()\n        clear_land_temp[~clearsky_land] = np.nan\n        clear_land_temp[~self.mask] = np.nan\n\n        # take 17.5 and 82.5 percentile, eq 13\n        low, high = np.nanpercentile(clear_land_temp, (17.5, 82.5))\n        return low, high", "response": "Derive high and low percentiles of land temperature over clearsky land\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing the probability of the spectral variability of clouds over land based on the variability of clouds over land.", "response": "def variability_prob(self, whiteness):\n        \"\"\"Use the probability of the spectral variability\n        to identify clouds over land.\n        Equation 15 (Zhu and Woodcock, 2012)\n        Parameters\n        ----------\n        ndvi: ndarray\n        ndsi: ndarray\n        whiteness: ndarray\n        Output\n        ------\n        ndarray :\n            probability of cloud over land based on variability\n        \"\"\"\n\n        if self.sat in ['LT5', 'LE7']:\n            # check for green and red saturation\n\n            # if red is saturated and less than nir, ndvi = LE07_clip_L1TP_039027_20150529_20160902_01_T1_B1.TIF\n            mod_ndvi = np.where(self.red_saturated & (self.nir > self.red), 0, self.ndvi)\n\n            # if green is saturated and less than swir1, ndsi = LE07_clip_L1TP_039027_20150529_20160902_01_T1_B1.TIF\n            mod_ndsi = np.where(self.green_saturated & (self.swir1 > self.green), 0, self.ndsi)\n            ndi_max = np.fmax(np.absolute(mod_ndvi), np.absolute(mod_ndsi))\n\n        else:\n            ndi_max = np.fmax(np.absolute(self.ndvi), np.absolute(self.ndsi))\n\n        f_max = 1.0 - np.fmax(ndi_max, whiteness)\n\n        return f_max"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the potential cloud layer from source data *This is the high level function which ties together all the equations for generating potential clouds* Parameters ---------- blue: ndarray green: ndarray red: ndarray nir: ndarray swir1: ndarray swir2: ndarray cirrus: ndarray tirs1: ndarray min_filter: 2-element tuple, default=(3,3) Defines the window for the minimum_filter, for removing outliers max_filter: 2-element tuple, default=(21, 21) Defines the window for the maximum_filter, for \"buffering\" the edges combined: make a boolean array masking all (cloud, shadow, water) Output ------ ndarray, boolean: potential cloud layer; True = cloud ndarray, boolean potential cloud shadow layer; True = cloud shadow :param cloud_and_shadow:", "response": "def cloud_mask(self, min_filter=(3, 3), max_filter=(10, 10), combined=False, cloud_and_shadow=False):\n        \"\"\"Calculate the potential cloud layer from source data\n        *This is the high level function which ties together all\n        the equations for generating potential clouds*\n        Parameters\n        ----------\n        blue: ndarray\n        green: ndarray\n        red: ndarray\n        nir: ndarray\n        swir1: ndarray\n        swir2: ndarray\n        cirrus: ndarray\n        tirs1: ndarray\n        min_filter: 2-element tuple, default=(3,3)\n            Defines the window for the minimum_filter, for removing outliers\n        max_filter: 2-element tuple, default=(21, 21)\n            Defines the window for the maximum_filter, for \"buffering\" the edges\n        combined: make a boolean array masking all (cloud, shadow, water)\n        Output\n        ------\n        ndarray, boolean:\n            potential cloud layer; True = cloud\n        ndarray, boolean\n            potential cloud shadow layer; True = cloud shadow\n            :param cloud_and_shadow:\n        \"\"\"\n        # logger.info(\"Running initial testsr\")\n        whiteness = self.whiteness_index()\n        water = self.water_test()\n\n        # First pass, potential clouds\n        pcps = self.potential_cloud_pixels()\n\n        if self.sat == 'LC8':\n            cirrus_prob = self.cirrus / 0.04\n        else:\n            cirrus_prob = 0.0\n\n        # Clouds over water\n        wtp = self.water_temp_prob()\n        bp = self.brightness_prob()\n        water_cloud_prob = (wtp * bp) + cirrus_prob\n        wthreshold = 0.5\n\n        # Clouds over land\n        tlow, thigh = self.temp_land(pcps, water)\n        ltp = self.land_temp_prob(tlow, thigh)\n        vp = self.variability_prob(whiteness)\n        land_cloud_prob = (ltp * vp) + cirrus_prob\n        lthreshold = self.land_threshold(land_cloud_prob, pcps, water)\n\n        # logger.info(\"Calculate potential clouds\")\n        pcloud = self.potential_cloud_layer(\n            pcps, water, tlow,\n            land_cloud_prob, lthreshold,\n            water_cloud_prob, wthreshold)\n\n        # Ignoring snow for now as it exhibits many false positives and negatives\n        # when used as a binary mask\n        # psnow = potential_snow_layer(ndsi, green, nir, tirs1)\n        # pcloud = pcloud & ~psnow\n\n        # logger.info(\"Calculate potential cloud shadows\")\n        pshadow = self.potential_cloud_shadow_layer(water)\n\n        # The remainder of the algorithm differs significantly from Fmask\n        # In an attempt to make a more visually appealling cloud mask\n        # with fewer inclusions and more broad shapes\n\n        if min_filter:\n            # Remove outliers\n            # logger.info(\"Remove outliers with minimum filter\")\n\n            from scipy.ndimage.filters import minimum_filter\n            from scipy.ndimage.morphology import distance_transform_edt\n\n            # remove cloud outliers by nibbling the edges\n            pcloud = minimum_filter(pcloud, size=min_filter)\n\n            # crude, just look x pixels away for potential cloud pixels\n            dist = distance_transform_edt(~pcloud)\n            pixel_radius = 100.0\n            pshadow = (dist < pixel_radius) & pshadow\n\n            # remove cloud shadow outliers\n            pshadow = minimum_filter(pshadow, size=min_filter)\n\n        if max_filter:\n            # grow around the edges\n            # logger.info(\"Buffer edges with maximum filter\")\n\n            from scipy.ndimage.filters import maximum_filter\n\n            pcloud = maximum_filter(pcloud, size=max_filter)\n            pshadow = maximum_filter(pshadow, size=max_filter)\n\n        # mystery, save pcloud here, shows no nan in qgis, save later, shows nan\n        # outfile = '/data01/images/sandbox/pcloud.tif'\n        # georeference = self.sat_image.rasterio_geometry\n        # array = pcloud\n        # array = array.reshape(1, array.shape[LE07_clip_L1TP_039027_20150529_20160902_01_T1_B1.TIF], array.shape[1])\n        # array = np.array(array, dtype=georeference['dtype'])\n        # with rasterio.open(outfile, 'w', **georeference) as dst:\n        #     dst.write(array)\n        # mystery test\n        if combined:\n            return pcloud | pshadow | water\n\n        if cloud_and_shadow:\n            return pcloud | pshadow\n\n        return pcloud, pshadow, water"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the GDAL - style uint8 mask for missing data.", "response": "def gdal_nodata_mask(pcl, pcsl, tirs_arr):\n        \"\"\"\n        Given a boolean potential cloud layer,\n        a potential cloud shadow layer and a thermal band\n        Calculate the GDAL-style uint8 mask\n        \"\"\"\n        tirs_mask = np.isnan(tirs_arr) | (tirs_arr == 0)\n        return ((~(pcl | pcsl | tirs_mask)) * 255).astype('uint8')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the metadata file and returns a dictionary of the object that represents the metadata.", "response": "def parsemeta(metadataloc):\n    \"\"\"Parses the metadata from a Landsat image bundle.\n    \n    Arguments:\n        metadataloc: a filename or a directory.\n        \n    Returns metadata dictionary\n    \n    \"\"\"\n\n    # filename or directory? if several fit, use first one and warn\n    if os.path.isdir(metadataloc):\n        metalist = glob.glob(os.path.join(metadataloc, METAPATTERN))\n        if not metalist:\n            raise MTLParseError(\n                \"No files matching metadata file pattern in directory %s.\"\n                % metadataloc)\n        elif len(metalist) > 0:\n            metadatafn = metalist[0]\n            filehandle = open(metadatafn, 'r')\n            if len(metalist) > 1:\n                logging.warning(\n                    \"More than one file in directory match metadata \"\n                    + \"file pattern. Using %s.\" % metadatafn)\n    elif os.path.isfile(metadataloc):\n        metadatafn = metadataloc\n        filehandle = open(metadatafn, 'r')\n        logging.info(\"Using file %s.\" % metadatafn)\n    elif 'L1_METADATA_FILE' in metadataloc:\n        filehandle = StringIO(metadataloc)\n    else:\n        raise MTLParseError(\n            \"File location %s is unavailable \" % metadataloc\n            + \"or doesn't contain a suitable metadata file.\")\n\n    # Reading file line by line and inserting data into metadata dictionary\n    status = 0\n    metadata = {}\n    grouppath = []\n    dictpath = [metadata]\n\n    for line in filehandle:\n        if status == 4:\n            # we reached the end in the previous iteration,\n            # but are still reading lines\n            logging.warning(\n                \"Metadata file %s appears to \" % metadatafn\n                + \"have extra lines after the end of the metadata. \"\n                + \"This is probably, but not necessarily, harmless.\")\n        status = _checkstatus(status, line)\n        grouppath, dictpath = _transstat(status, grouppath, dictpath, line)\n\n    return metadata"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking the status of a single line of a segmented log file.", "response": "def _checkstatus(status, line):\n    \"\"\"Returns state/status after reading the next line.\n    The status codes are::\n        LE07_clip_L1TP_039027_20150529_20160902_01_T1_B1.TIF - BEGIN parsing; 1 - ENTER METADATA GROUP, 2 - READ METADATA LINE,\n        3 - END METDADATA GROUP, 4 - END PARSING\n    Permitted Transitions::\n        LE07_clip_L1TP_039027_20150529_20160902_01_T1_B1.TIF --> 1, LE07_clip_L1TP_039027_20150529_20160902_01_T1_B1.TIF --> 4\n        1 --> 1, 1 --> 2, 1 --> 3\n        2 --> 2, 2 --> 3\n        3 --> 1, 1 --> 3, 3 --> 4\n    \"\"\"\n    newstatus = 0\n    if status == 0:\n        # begin --> enter metadata group OR end\n        if _islinetype(line, GRPSTART):\n            newstatus = 1\n        elif _isfinal(line):\n            newstatus = 4\n    elif status == 1:\n        # enter metadata group --> enter metadata group\n        # OR add metadata item OR leave metadata group\n        if _islinetype(line, GRPSTART):\n            newstatus = 1\n        elif _islinetype(line, GRPEND):\n            newstatus = 3\n        elif _isassignment(line):\n            # test AFTER start and end, as both are also assignments\n            newstatus = 2\n    elif status == 2:\n        if _islinetype(line, GRPEND):\n            newstatus = 3\n        elif _isassignment(line):\n            # test AFTER start and end, as both are also assignments\n            newstatus = 2\n    elif status == 3:\n        if _islinetype(line, GRPSTART):\n            newstatus = 1\n        elif _islinetype(line, GRPEND):\n            newstatus = 3\n        elif _isfinal(line):\n            newstatus = 4\n    if newstatus != 0:\n        return newstatus\n    elif status != 4:\n        raise MTLParseError(\n            \"Cannot parse the following line after status \"\n            + \"'%s':\\n%s\" % (STATUSCODE[status], line))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting processing steps when reading a line.", "response": "def _transstat(status, grouppath, dictpath, line):\n    \"\"\"Executes processing steps when reading a line\"\"\"\n    if status == 0:\n        raise MTLParseError(\n            \"Status should not be '%s' after reading line:\\n%s\"\n            % (STATUSCODE[status], line))\n    elif status == 1:\n        currentdict = dictpath[-1]\n        currentgroup = _getgroupname(line)\n        grouppath.append(currentgroup)\n        currentdict[currentgroup] = {}\n        dictpath.append(currentdict[currentgroup])\n    elif status == 2:\n        currentdict = dictpath[-1]\n        newkey, newval = _getmetadataitem(line)\n\n        # USGS has started quoting the scene center time.  If this\n        # happens strip quotes before post processing.\n        if newkey == 'SCENE_CENTER_TIME' and newval.startswith('\"') \\\n                and newval.endswith('\"'):\n            # logging.warning('Strip quotes off SCENE_CENTER_TIME.')\n            newval = newval[1:-1]\n\n        currentdict[newkey] = _postprocess(newval)\n    elif status == 3:\n        oldgroup = _getendgroupname(line)\n        if oldgroup != grouppath[-1]:\n            raise MTLParseError(\n                \"Reached line '%s' while reading group '%s'.\"\n                % (line.strip(), grouppath[-1]))\n        del grouppath[-1]\n        del dictpath[-1]\n        try:\n            currentgroup = grouppath[-1]\n        except IndexError:\n            currentgroup = None\n    elif status == 4:\n        if grouppath:\n            raise MTLParseError(\n                \"Reached end before end of group '%s'\" % grouppath[-1])\n    return grouppath, dictpath"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _postprocess(valuestr):\n    # USGS has started quoting time sometimes.  Grr, strip quotes in this case\n    intpattern = re.compile(r'^\\-?\\d+$')\n    floatpattern = re.compile(r'^\\-?\\d+\\.\\d+(E[+-]?\\d\\d+)?$')\n    datedtpattern = '%Y-%m-%d'\n    datedttimepattern = '%Y-%m-%dT%H:%M:%SZ'\n    timedtpattern = '%H:%M:%S.%f'\n    timepattern = re.compile(r'^\\d{2}:\\d{2}:\\d{2}(\\.\\d{6})?')\n    if valuestr.startswith('\"') and valuestr.endswith('\"'):\n        # it's a string\n        return valuestr[1:-1]\n    elif re.match(intpattern, valuestr):\n        # it's an integer\n        return int(valuestr)\n    elif re.match(floatpattern, valuestr):\n        # floating point number\n        return float(valuestr)\n    # now let's try the datetime objects; throws exception if it doesn't match\n    try:\n        return datetime.datetime.strptime(valuestr, datedtpattern).date()\n    except ValueError:\n        pass\n    try:\n        return datetime.datetime.strptime(valuestr, datedttimepattern)\n    except ValueError:\n        pass\n    # time parsing is complicated: Python's datetime module only accepts\n    # fractions of a second only up to 6 digits\n    mat = re.match(timepattern, valuestr)\n    if mat:\n        test = mat.group(0)\n        try:\n            return datetime.datetime.strptime(test, timedtpattern).time()\n        except ValueError:\n            pass\n\n    # If we get here, we still haven't returned anything.\n    logging.info(\n        \"The value %s couldn't be parsed as \" % valuestr\n        + \"int, float, date, time, datetime. Returning it as string.\")\n    return valuestr", "response": "Takes value as str returns int float date datetime or time\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwarps all images in a directory to a single image.", "response": "def warp_vrt(directory, delete_extra=False, use_band_map=False,\n             overwrite=False, remove_bqa=True, return_profile=False):\n    \"\"\" Read in image geometry, resample subsequent images to same grid.\n\n    The purpose of this function is to snap many Landsat images to one geometry. Use Landsat578\n    to download and unzip them, then run them through this to get identical geometries for analysis.\n    Files\n    :param use_band_map:\n    :param delete_extra:\n    :param directory: A directory containing sub-directories of Landsat images.\n    :return: None\n    \"\"\"\n\n    if 'resample_meta.txt' in os.listdir(directory) and not overwrite:\n        print('{} has already had component images warped'.format(directory))\n        return None\n\n    mapping = {'LC8': Landsat8, 'LE7': Landsat7, 'LT5': Landsat5}\n\n    vrt_options = {}\n    list_dir = [x[0] for x in os.walk(directory) if os.path.basename(x[0])[:3] in mapping.keys()]\n    extras = [os.path.join(directory, x) for x in os.listdir(directory) if x.endswith('.tif')]\n    first = True\n\n    for d in list_dir:\n        sat = LandsatImage(d).satellite\n        paths = extras\n        root = os.path.join(directory, d)\n        if os.path.isdir(root):\n            for x in os.listdir(root):\n\n                if remove_bqa and x.endswith('BQA.TIF'):\n                    try:\n                        os.remove(x)\n                    except FileNotFoundError:\n                        pass\n\n                elif use_band_map:\n                    bands = BandMap().selected\n                    for y in bands[sat]:\n                        if x.endswith('B{}.TIF'.format(y)):\n                            paths.append(os.path.join(directory, d, x))\n                else:\n                    if x.endswith('.TIF') or x.endswith('.tif'):\n                        paths.append(os.path.join(directory, d, x))\n\n                if x.endswith('MTL.txt'):\n                    mtl = os.path.join(directory, d, x)\n\n        if first:\n\n            landsat = mapping[sat](os.path.join(directory, d))\n            dst = landsat.rasterio_geometry\n\n            vrt_options = {'resampling': Resampling.nearest,\n                           'dst_crs': dst['crs'],\n                           'dst_transform': dst['transform'],\n                           'dst_height': dst['height'],\n                           'dst_width': dst['width']}\n\n\n            message = \"\"\"\n            This directory has been resampled to same grid.\n            Master grid is {}.\n            {}\n            \"\"\".format(d, datetime.now())\n            with open(os.path.join(directory, 'resample_meta.txt'), 'w') as f:\n                f.write(message)\n            first = False\n\n        for tif_path in paths:\n            print('warping {}'.format(os.path.basename(tif_path)))\n            with rasopen(tif_path, 'r') as src:\n                with WarpedVRT(src, **vrt_options) as vrt:\n                    data = vrt.read()\n                    dst_dir, name = os.path.split(tif_path)\n                    outfile = os.path.join(dst_dir, name)\n                    meta = vrt.meta.copy()\n                    meta['driver'] = 'GTiff'\n                    with rasopen(outfile, 'w', **meta) as dst:\n                        dst.write(data)\n\n        if delete_extra:\n            for x in os.listdir(os.path.join(directory, d)):\n                x_file = os.path.join(directory, d, x)\n                if x_file not in paths:\n                    if x[-7:] not in ['ask.tif', 'MTL.txt']:\n                        print('removing {}'.format(x_file))\n                        os.remove(x_file)\n\n    if return_profile:\n        return dst"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tox_get_python_executable(envconfig):\n    try:\n        # pylint: disable=no-member\n        pyenv = (getattr(py.path.local.sysfind('pyenv'), 'strpath', 'pyenv')\n                 or 'pyenv')\n        cmd = [pyenv, 'which', envconfig.basepython]\n        pipe = subprocess.Popen(\n            cmd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            universal_newlines=True\n        )\n        out, err = pipe.communicate()\n    except OSError:\n        err = '\\'pyenv\\': command not found'\n        LOG.warning(\n            \"pyenv doesn't seem to be installed, you probably \"\n            \"don't want this plugin installed either.\"\n        )\n    else:\n        if pipe.poll() == 0:\n            return out.strip()\n        else:\n            if not envconfig.tox_pyenv_fallback:\n                raise PyenvWhichFailed(err)\n    LOG.debug(\"`%s` failed thru tox-pyenv plugin, falling back. \"\n              \"STDERR: \\\"%s\\\" | To disable this behavior, set \"\n              \"tox_pyenv_fallback=False in your tox.ini or use \"\n              \" --tox-pyenv-no-fallback on the command line.\",\n              ' '.join([str(x) for x in cmd]), err)", "response": "Return a python executable for the given testenv base name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _setup_no_fallback(parser):\n\n    cli_dest = 'tox_pyenv_fallback'\n    halp = ('If `pyenv which {basepython}` exits non-zero when looking '\n            'up the python executable, do not allow fallback to tox\\'s '\n            'built-in default logic.')\n    # Add a command-line option.\n    tox_pyenv_group = parser.argparser.add_argument_group(\n        title='{0} plugin options'.format(__title__),\n    )\n    tox_pyenv_group.add_argument(\n        '--tox-pyenv-no-fallback', '-F',\n        dest=cli_dest,\n        default=True,\n        action='store_false',\n        help=halp\n    )\n\n    def _pyenv_fallback(testenv_config, value):\n        cli_says = getattr(testenv_config.config.option, cli_dest)\n        return cli_says or value\n\n    # Add an equivalent tox.ini [testenv] section option.\n    parser.add_testenv_attribute(\n        name=cli_dest,\n        type=\"bool\",\n        postprocess=_pyenv_fallback,\n        default=False,\n        help=('If `pyenv which {basepython}` exits non-zero when looking '\n              'up the python executable, allow fallback to tox\\'s '\n              'built-in default logic.'),\n    )", "response": "Setups the option for the no - fallback plugin."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending one or more emails from Salesforce.", "response": "def sendEmail(self, emails, massType='SingleEmailMessage'):\n        \"\"\"\n        Send one or more emails from Salesforce.\n\n        Parameters:\n            emails - a dictionary or list of dictionaries, each representing a\n                     single email as described by https://www.salesforce.com/us\n                     /developer/docs/api/Content/sforce_api_calls_sendemail.htm\n            massType - 'SingleEmailMessage' or 'MassEmailMessage'.\n                       MassEmailMessage is used for mailmerge of up to 250\n                       recepients in a single pass.\n\n        Note:\n            Newly created Salesforce Sandboxes default to System email only. In\n            this situation, sendEmail() will fail with NO_MASS_MAIL_PERMISSION.\n        \"\"\"\n        return SendEmailRequest(\n            self.__serverUrl,\n            self.sessionId,\n            emails,\n            massType\n        ).post(self.__conn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _doPrep(field_dict):\n    fieldsToNull = []\n    for key, value in field_dict.items():\n        if value is None:\n            fieldsToNull.append(key)\n            field_dict[key] = []\n        if hasattr(value, '__iter__'):\n            if len(value) == 0:\n                fieldsToNull.append(key)\n            elif isinstance(value, dict):\n                innerCopy = copy.deepcopy(value)\n                _doPrep(innerCopy)\n                field_dict[key] = innerCopy\n            else:\n                field_dict[key] = \";\".join(value)\n    if 'fieldsToNull' in field_dict:\n        raise ValueError(\n            \"fieldsToNull should be populated by the client, not the caller.\"\n        )\n    field_dict['fieldsToNull'] = fieldsToNull", "response": "This function is makes changes in - place."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _prepareSObjects(sObjects):\n    '''Prepare a SObject'''\n    sObjectsCopy = copy.deepcopy(sObjects)\n    if isinstance(sObjectsCopy, dict):\n        # If root element is a dict, then this is a single object not an array\n        _doPrep(sObjectsCopy)\n    else:\n        # else this is an array, and each elelment should be prepped.\n        for listitems in sObjectsCopy:\n            _doPrep(listitems)\n    return sObjectsCopy", "response": "Prepare a list of SObjects."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends one or more emails from Salesforce.", "response": "def sendEmail(self, emails, mass_type='SingleEmailMessage'):\n        \"\"\"\n        Send one or more emails from Salesforce.\n\n        Parameters:\n            emails - a dictionary or list of dictionaries, each representing\n                     a single email as described by https://www.salesforce.com\n                     /us/developer/docs/api/Content/sforce_api_calls_sendemail\n                     .htm\n            massType - 'SingleEmailMessage' or 'MassEmailMessage'.\n                       MassEmailMessage is used for mailmerge of up to 250\n                       recepients in a single pass.\n\n        Note:\n            Newly created Salesforce Sandboxes default to System email only.\n            In this situation, sendEmail() will fail with\n            NO_MASS_MAIL_PERMISSION.\n        \"\"\"\n        preparedEmails = _prepareSObjects(emails)\n        if isinstance(preparedEmails, dict):\n            # If root element is a dict, then this is a single object not an\n            # array\n            del preparedEmails['fieldsToNull']\n        else:\n            # else this is an array, and each elelment should be prepped.\n            for listitems in preparedEmails:\n                del listitems['fieldsToNull']\n        res = BaseClient.sendEmail(self, preparedEmails, mass_type)\n        if type(res) not in (TupleType, ListType):\n            res = [res]\n        data = list()\n        for resu in res:\n            d = dict()\n            data.append(d)\n            d['success'] = success = _bool(resu[_tPartnerNS.success])\n            if not success:\n                d['errors'] = [_extractError(e)\n                               for e in resu[_tPartnerNS.errors,]]\n            else:\n                d['errors'] = list()\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a list of types construct a dictionary such that each key is a type and each value is the corresponding sObject for that type.", "response": "def queryTypesDescriptions(self, types):\n        \"\"\"\n        Given a list of types, construct a dictionary such that\n        each key is a type, and each value is the corresponding sObject\n        for that type.\n        \"\"\"\n        types = list(types)\n        if types:\n            types_descs = self.describeSObjects(types)\n        else:\n            types_descs = []\n        return dict(map(lambda t, d: (t, d), types, types_descs))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a session protection token for this client.", "response": "def create_token(self):\n        \"\"\"Create a session protection token for this client.\n\n        This method generates a session protection token for the cilent, which\n        consists in a hash of the user agent and the IP address. This method\n        can be overriden by subclasses to implement different token generation\n        algorithms.\n        \"\"\"\n        user_agent = request.headers.get('User-Agent')\n        if user_agent is None:  # pragma: no cover\n            user_agent = 'no user agent'\n        user_agent = user_agent.encode('utf-8')\n        base = self._get_remote_addr() + b'|' + user_agent\n        h = sha256()\n        h.update(base)\n        return h.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear_session(self, response):\n        session.clear()\n\n        # if flask-login is installed, we try to clear the\n        # \"remember me\" cookie, just in case it is set\n        if 'flask_login' in sys.modules:\n            remember_cookie = current_app.config.get('REMEMBER_COOKIE',\n                                                     'remember_token')\n            response.set_cookie(remember_cookie, '', expires=0, max_age=0)", "response": "Clear the session.\n\n        This method is invoked when the session is found to be invalid.\n        Subclasses can override this method to implement a custom session\n        reset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a random Haikunate - style random name.", "response": "def haikunate(self, delimiter='-', token_length=4, token_hex=False, token_chars='0123456789'):\n        \"\"\"\n        Generate heroku-like random names to use in your python applications\n\n        :param delimiter: Delimiter\n        :param token_length: TokenLength\n        :param token_hex: TokenHex\n        :param token_chars: TokenChars\n        :type delimiter: str\n        :type token_length: int\n        :type token_hex: bool\n        :type token_chars: str\n        :return: heroku-like random string\n        :rtype: str\n        \"\"\"\n        if token_hex:\n            token_chars = '0123456789abcdef'\n\n        adjective = self._random_element(self._adjectives)\n        noun = self._random_element(self._nouns)\n        token = ''.join(self._random_element(token_chars) for _ in range(token_length))\n\n        sections = [adjective, noun, token]\n        return delimiter.join(filter(None, sections))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_parser_class():\n    global distro\n    if distro == 'Linux':\n        Parser = parser.LinuxParser\n        if not os.path.exists(Parser.get_command()[0]):\n            Parser = parser.UnixIPParser\n    elif distro in ['Darwin', 'MacOSX']:\n        Parser = parser.MacOSXParser\n    elif distro == 'Windows':\n        # For some strange reason, Windows will always be win32, see:\n        # https://stackoverflow.com/a/2145582/405682\n        Parser = parser.WindowsParser\n    else:\n        Parser = parser.NullParser\n        Log.error(\"Unknown distro type '%s'.\" % distro)\n    Log.debug(\"Distro detected as '%s'\" % distro)\n    Log.debug(\"Using '%s'\" % Parser)\n\n    return Parser", "response": "Returns the parser class according to the system platform"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef default_interface(ifconfig=None, route_output=None):\n    global Parser\n    return Parser(ifconfig=ifconfig)._default_interface(route_output=route_output)", "response": "Return just the default interface device dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(self, ifconfig=None):  # noqa: max-complexity=12\n        if not ifconfig:\n            ifconfig, __, __ = exec_cmd(self.get_command())\n        self.ifconfig_data = ifconfig\n        cur = None\n        patterns = self.get_patterns()\n        for line in self.ifconfig_data.splitlines():\n            for pattern in patterns:\n                m = re.match(pattern, line)\n                if not m:\n                    continue\n                groupdict = m.groupdict()\n                # Special treatment to trigger which interface we're\n                # setting for if 'device' is in the line.  Presumably the\n                # device of the interface is within the first line of the\n                # device block.\n                if 'device' in groupdict:\n                    cur = groupdict['device']\n                    self.add_device(cur)\n                elif cur is None:\n                    raise RuntimeError(\n                        \"Got results that don't belong to a device\"\n                    )\n\n                for k, v in groupdict.items():\n                    if k in self._interfaces[cur]:\n                        if self._interfaces[cur][k] is None:\n                            self._interfaces[cur][k] = v\n                        elif hasattr(self._interfaces[cur][k], 'append'):\n                            self._interfaces[cur][k].append(v)\n                        elif self._interfaces[cur][k] == v:\n                            # Silently ignore if the it's the same value as last. Example: Multiple\n                            # inet4 addresses, result in multiple netmasks. Cardinality mismatch\n                            continue\n                        else:\n                            raise RuntimeError(\n                                \"Tried to add {}={} multiple times to {}, it was already: {}\".format(\n                                    k,\n                                    v,\n                                    cur,\n                                    self._interfaces[cur][k]\n                                )\n                            )\n                    else:\n                        self._interfaces[cur][k] = v\n\n        # Copy the first 'inet4' ip address to 'inet' for backwards compatibility\n        for device, device_dict in self._interfaces.items():\n            if len(device_dict['inet4']) > 0:\n                device_dict['inet'] = device_dict['inet4'][0]\n\n        # fix it up\n        self._interfaces = self.alter(self._interfaces)", "response": "Parse the output of the ifconfig command into the internal dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef alter(self, interfaces):\n        # fixup some things\n        for device, device_dict in interfaces.items():\n            if len(device_dict['inet4']) > 0:\n                device_dict['inet'] = device_dict['inet4'][0]\n            if 'inet' in device_dict and not device_dict['inet'] is None:\n                try:\n                    host = socket.gethostbyaddr(device_dict['inet'])[0]\n                    interfaces[device]['hostname'] = host\n                except (socket.herror, socket.gaierror):\n                    interfaces[device]['hostname'] = None\n\n            # To be sure that hex values and similar are always consistent, we\n            # return everything in lowercase. For instance, Windows writes\n            # MACs in upper-case.\n            for key, device_item in device_dict.items():\n                if hasattr(device_item, 'lower'):\n                    interfaces[device][key] = device_dict[key].lower()\n\n        return interfaces", "response": "This function is used to alter the internal dictionary of the interfaces dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the default interface for the current user.", "response": "def _default_interface(self, route_output=None):\n        \"\"\"\n        :param route_output: For mocking actual output\n        \"\"\"\n        if not route_output:\n            out, __, __ = exec_cmd('/sbin/ip route')\n            lines = out.splitlines()\n        else:\n            lines = route_output.split(\"\\n\")\n\n        for line in lines:\n            line = line.split()\n            if 'default' in line:\n                iface = line[4]\n                return self.interfaces.get(iface, None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, line_number):\n        if line_number not in self._get_cache:\n            self._get_cache[line_number] = self._get(line_number)\n        return self._get_cache[line_number]", "response": "Return the needle positions for a specific line."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_bytes(self, line_number):\n        if line_number not in self._needle_position_bytes_cache:\n            line = self._get(line_number)\n            if line is None:\n                line_bytes = None\n            else:\n                line_bytes = self._machine.needle_positions_to_bytes(line)\n            self._needle_position_bytes_cache[line_number] = line_bytes\n        return self._needle_position_bytes_cache[line_number]", "response": "Get the bytes that represent the needle positions or None."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the cnfLine message without id for the line.", "response": "def get_line_configuration_message(self, line_number):\n        \"\"\"Return the cnfLine content without id for the line.\n\n        :param int line_number: the number of the line\n        :rtype: bytes\n        :return: a cnfLine message without id as defined in :ref:`cnfLine`\n        \"\"\"\n        if line_number not in self._line_configuration_message_cache:\n            line_bytes = self.get_bytes(line_number)\n            if line_bytes is not None:\n                line_bytes = bytes([line_number & 255]) + line_bytes\n                line_bytes += bytes([self.is_last(line_number)])\n                line_bytes += crc8(line_bytes).digest()\n            self._line_configuration_message_cache[line_number] = line_bytes\n            del line_bytes\n        line = self._line_configuration_message_cache[line_number]\n        if line is None:\n            # no need to cache a lot of empty lines\n            line = (bytes([line_number & 255]) +\n                    b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00' +\n                    b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01')\n            line += crc8(line).digest()\n        return line"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_message_type(file):\n    message_byte = file.read(1)\n    if message_byte == b'':\n        return ConnectionClosed\n    message_number = message_byte[0]\n    return _message_types.get(message_number, UnknownMessage)", "response": "Read the message type from a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the b\\\\ r \\ n at the end of the message.", "response": "def read_end_of_message(self):\n        \"\"\"Read the b\"\\\\r\\\\n\" at the end of the message.\"\"\"\n        read = self._file.read\n        last = read(1)\n        current = read(1)\n        while last != b'' and current != b'' and not \\\n                (last == b'\\r' and current == b'\\n'):\n            last = current\n            current = read(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init(self):\n        self._api_version = self._file.read(1)[0]\n        self._firmware_version = FirmwareVersion(*self._file.read(2))", "response": "Read the success byte and initialize the internal attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the line number.", "response": "def _init(self):\n        \"\"\"Read the line number.\"\"\"\n        self._line_number = next_line(\n            self._communication.last_requested_line_number,\n            self._file.read(1)[0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _init(self):\n        self._ready = self._file.read(1)\n        self._hall_left = self._file.read(2)\n        self._hall_right = self._file.read(2)\n        self._carriage_type = self._file.read(1)[0]\n        self._carriage_position = self._file.read(1)[0]", "response": "Read the success byte and initialize the internal state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init(self):\n        read_values = []\n        read = self._file.read\n        last = read(1)\n        current = read(1)\n        while last != b'' and current != b'' and not \\\n                (last == b'\\r' and current == b'\\n'):\n            read_values.append(last)\n            last = current\n            current = read(1)\n        if current == b'' and last != b'\\r':\n            read_values.append(last)\n        self._bytes = b''.join(read_values)", "response": "Read the b\\\\ r \\\\ n at the end of the message."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend this message to the controller.", "response": "def send(self):\n        \"\"\"Send this message to the controller.\"\"\"\n        self._file.write(self.as_bytes())\n        self._file.write(b'\\r\\n')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize the StartRequest with start and stop needle.", "response": "def init(self, left_end_needle, right_end_needle):\n        \"\"\"Initialize the StartRequest with start and stop needle.\n\n        :raises TypeError: if the arguments are not integers\n        :raises ValueError: if the values do not match the\n          :ref:`specification <m4-01>`\n        \"\"\"\n        if not isinstance(left_end_needle, int):\n\n            raise TypeError(_left_end_needle_error_message(left_end_needle))\n        if left_end_needle < 0 or left_end_needle > 198:\n            raise ValueError(_left_end_needle_error_message(left_end_needle))\n        if not isinstance(right_end_needle, int):\n            raise TypeError(_right_end_needle_error_message(right_end_needle))\n        if right_end_needle < 1 or right_end_needle > 199:\n            raise ValueError(_right_end_needle_error_message(right_end_needle))\n        self._left_end_needle = left_end_needle\n        self._right_end_needle = right_end_needle"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the start and stop needle.", "response": "def content_bytes(self):\n        \"\"\"Return the start and stop needle.\"\"\"\n        get_message = \\\n            self._communication.needle_positions.get_line_configuration_message\n        return get_message(self._line_number)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sum_all(iterable, start):\n    if hasattr(start, \"__add__\"):\n        for value in iterable:\n            start += value\n    else:\n        for value in iterable:\n            start |= value\n    return start", "response": "Sum up an iterable starting with a start value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef next_line(last_line, next_line_8bit):\n    # compute the line without the lowest byte\n    base_line = last_line - (last_line & 255)\n    # compute the three different lines\n    line = base_line + next_line_8bit\n    lower_line = line - 256\n    upper_line = line + 256\n    # compute the next line\n    if last_line - lower_line <= line - last_line:\n        return lower_line\n    if upper_line - last_line < last_line - line:\n        return upper_line\n    return line", "response": "Compute the next line based on the last line and a 8bit next line."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the underscore name of a camel case name.", "response": "def camel_case_to_under_score(camel_case_name):\n    \"\"\"Return the underscore name of a camel case name.\n\n    :param str camel_case_name: a name in camel case such as\n      ``\"ACamelCaseName\"``\n    :return: the name using underscores, e.g. ``\"a_camel_case_name\"``\n    :rtype: str\n    \"\"\"\n    result = []\n    for letter in camel_case_name:\n        if letter.lower() != letter:\n            result.append(\"_\" + letter.lower())\n        else:\n            result.append(letter.lower())\n    if result[0].startswith(\"_\"):\n        result[0] = result[0][1:]\n    return \"\".join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _message_received(self, message):\n        with self.lock:\n            self._state.receive_message(message)\n            for callable in chain(self._on_message_received, self._on_message):\n                callable(message)", "response": "Notify the observers about the received message."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreceives a message from the file.", "response": "def receive_message(self):\n        \"\"\"Receive a message from the file.\"\"\"\n        with self.lock:\n            assert self.can_receive_messages()\n            message_type = self._read_message_type(self._file)\n            message = message_type(self._file, self)\n            self._message_received(message)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the tihs communication can receive messages.", "response": "def can_receive_messages(self):\n        \"\"\"Whether tihs communication is ready to receive messages.]\n\n        :rtype: bool\n\n        .. code:: python\n\n            assert not communication.can_receive_messages()\n            communication.start()\n            assert communication.can_receive_messages()\n            communication.stop()\n            assert not communication.can_receive_messages()\n\n        \"\"\"\n        with self.lock:\n            return not self._state.is_waiting_for_start() and \\\n                not self._state.is_connection_closed()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstopping the communication with the shield.", "response": "def stop(self):\n        \"\"\"Stop the communication with the shield.\"\"\"\n        with self.lock:\n            self._message_received(ConnectionClosed(self._file, self))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send(self, host_message_class, *args):\n        message = host_message_class(self._file, self, *args)\n        with self.lock:\n            message.send()\n            for callable in self._on_message:\n                callable(message)", "response": "Send a host message."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef state(self, new_state):\n        with self.lock:\n            self._state.exit()\n            self._state = new_state\n            self._state.enter()", "response": "Set the state of the resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parallelize(self, seconds_to_wait=2):\n        with self.lock:\n            thread = Thread(target=self._parallel_receive_loop,\n                            args=(seconds_to_wait,))\n            thread.deamon = True\n            thread.start()\n            self._thread = thread", "response": "Start a thread for receiving messages."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the receiving in parallel.", "response": "def _parallel_receive_loop(self, seconds_to_wait):\n        \"\"\"Run the receiving in parallel.\"\"\"\n        sleep(seconds_to_wait)\n        with self._lock:\n            self._number_of_threads_receiving_messages += 1\n        try:\n            with self._lock:\n                if self.state.is_waiting_for_start():\n                    self.start()\n            while True:\n                with self.lock:\n                    if self.state.is_connection_closed():\n                        return\n                    self.receive_message()\n        finally:\n            with self._lock:\n                self._number_of_threads_receiving_messages -= 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransition into the next state.", "response": "def _next(self, state_class, *args):\n        \"\"\"Transition into the next state.\n\n        :param type state_class: a subclass of :class:`State`. It is intialized\n          with the communication object and :paramref:`args`\n        :param args: additional arguments\n        \"\"\"\n        self._communication.state = state_class(self._communication, *args)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef receive_information_confirmation(self, message):\n        if message.api_version_is_supported():\n            self._next(InitializingMachine)\n        else:\n            self._next(UnsupportedApiVersion)\n\n        self._communication.controller = message", "response": "A InformationConfirmation is received."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreceive a StartConfirmation message.", "response": "def receive_start_confirmation(self, message):\n        \"\"\"Receive a StartConfirmation message.\n\n        :param message: a :class:`StartConfirmation\n          <AYABInterface.communication.hardware_messages.StartConfirmation>`\n          message\n\n        If the message indicates success, the communication object transitions\n        into :class:`KnittingStarted` or else, into :class:`StartingFailed`.\n        \"\"\"\n        if message.is_success():\n            self._next(KnittingStarted)\n        else:\n            self._next(StartingFailed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef enter(self):\n        self._communication.last_requested_line_number = self._line_number\n        self._communication.send(LineConfirmation, self._line_number)", "response": "Send a LineConfirmation to the controller."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts rows to needle positions.", "response": "def colors_to_needle_positions(rows):\n    \"\"\"Convert rows to needle positions.\n\n    :return:\n    :rtype: list\n    \"\"\"\n    needles = []\n    for row in rows:\n        colors = set(row)\n        if len(colors) == 1:\n            needles.append([NeedlePositions(row, tuple(colors), False)])\n        elif len(colors) == 2:\n            color1, color2 = colors\n            if color1 != row[0]:\n                color1, color2 = color2, color1\n            needles_ = _row_color(row, color1)\n            needles.append([NeedlePositions(needles_, (color1, color2), True)])\n        else:\n            colors = []\n            for color in row:\n                if color not in colors:\n                    colors.append(color)\n            needles_ = []\n            for color in colors:\n                needles_.append(NeedlePositions(_row_color(row, color),\n                                                (color,), False))\n            needles.append(needles_)\n    return needles"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that the contents of the rows of the log file are valid.", "response": "def check(self):\n        \"\"\"Check for validity.\n\n        :raises ValueError:\n\n          - if not all lines are as long as the :attr:`number of needles\n            <AYABInterface.machines.Machine.number_of_needles>`\n          - if the contents of the rows are not :attr:`needle positions\n            <AYABInterface.machines.Machine.needle_positions>`\n        \"\"\"\n        # TODO: This violates the law of demeter.\n        #       The architecture should be changed that this check is either\n        #       performed by the machine or by the unity of machine and\n        #       carriage.\n        expected_positions = self._machine.needle_positions\n        expected_row_length = self._machine.number_of_needles\n        for row_index, row in enumerate(self._rows):\n            if len(row) != expected_row_length:\n                message = _ROW_LENGTH_ERROR_MESSAGE.format(\n                    row_index, len(row), expected_row_length)\n                raise ValueError(message)\n            for needle_index, needle_position in enumerate(row):\n                if needle_position not in expected_positions:\n                    message = _NEEDLE_POSITION_ERROR_MESSAGE.format(\n                        row_index, needle_index, repr(needle_position),\n                        \", \".join(map(repr, expected_positions)))\n                    raise ValueError(message)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the row at the given index or the default value.", "response": "def get_row(self, index, default=None):\n        \"\"\"Return the row at the given index or the default value.\"\"\"\n        if not isinstance(index, int) or index < 0 or index >= len(self._rows):\n            return default\n        return self._rows[index]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmarks the row at index as completed.", "response": "def row_completed(self, index):\n        \"\"\"Mark the row at index as completed.\n\n        .. seealso:: :meth:`completed_row_indices`\n\n        This method notifies the obsevrers from :meth:`on_row_completed`.\n        \"\"\"\n        self._completed_rows.append(index)\n        for row_completed in self._on_row_completed:\n            row_completed(index)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef actions(self):\n        actions = []\n        do = actions.append\n\n        # determine the number of colors\n        colors = self.colors\n\n        # rows and colors\n        movements = (\n            MoveCarriageToTheRight(KnitCarriage()),\n            MoveCarriageToTheLeft(KnitCarriage()))\n        rows = self._rows\n        first_needles = self._get_row_needles(0)\n\n        # handle switches\n        if len(colors) == 1:\n            actions.extend([\n                SwitchOffMachine(),\n                SwitchCarriageToModeNl()])\n        else:\n            actions.extend([\n                SwitchCarriageToModeKc(),\n                SwitchOnMachine()])\n\n        # move needles\n        do(MoveNeedlesIntoPosition(\"B\", first_needles))\n        do(MoveCarriageOverLeftHallSensor())\n\n        # use colors\n        if len(colors) == 1:\n            do(PutColorInNutA(colors[0]))\n        if len(colors) == 2:\n            do(PutColorInNutA(colors[0]))\n            do(PutColorInNutB(colors[1]))\n\n        # knit\n        for index, row in enumerate(rows):\n            do(movements[index & 1])\n        return actions", "response": "A list of actions to perform."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the needle positions to the wire format.", "response": "def needle_positions_to_bytes(self, needle_positions):\n        \"\"\"Convert the needle positions to the wire format.\n\n        This conversion is used for :ref:`cnfline`.\n\n        :param needle_positions: an iterable over :attr:`needle_positions` of\n          length :attr:`number_of_needles`\n        :rtype: bytes\n        \"\"\"\n        bit = self.needle_positions\n        assert len(bit) == 2\n        max_length = len(needle_positions)\n        assert max_length == self.number_of_needles\n        result = []\n        for byte_index in range(0, max_length, 8):\n            byte = 0\n            for bit_index in range(8):\n                index = byte_index + bit_index\n                if index >= max_length:\n                    break\n                needle_position = needle_positions[index]\n                if bit.index(needle_position) == 1:\n                    byte |= 1 << bit_index\n            result.append(byte)\n            if byte_index >= max_length:\n                break\n        result.extend(b\"\\x00\" * (25 - len(result)))\n        return bytes(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef name(self):\n        name = self.__class__.__name__\n        for i, character in enumerate(name):\n            if character.isdigit():\n                return name[:i] + \"-\" + name[i:]\n        return name", "response": "The identifier of the machine."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _id(self):\n        return (self.__class__, self.number_of_needles, self.needle_positions,\n                self.left_end_needle)", "response": "What this object is equal to."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a Chapter to the epub.", "response": "def add_chapter(self, c):\n        \"\"\"\n        Add a Chapter to your epub.\n\n        Args:\n            c (Chapter): A Chapter object representing your chapter.\n\n        Raises:\n            TypeError: Raised if a Chapter object isn't supplied to this\n                method.\n        \"\"\"\n        try:\n            assert type(c) == chapter.Chapter\n        except AssertionError:\n            raise TypeError('chapter must be of type Chapter')\n        chapter_file_output = os.path.join(self.OEBPS_DIR, self.current_chapter_path)\n        c._replace_images_in_chapter(self.OEBPS_DIR)\n        c.write(chapter_file_output)\n        self._increase_current_chapter_number()\n        self.chapters.append(c)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_epub(self, output_directory, epub_name=None):\n        def createTOCs_and_ContentOPF():\n            for epub_file, name in ((self.toc_html, 'toc.html'), (self.toc_ncx, 'toc.ncx'), (self.opf, 'content.opf'),):\n                epub_file.add_chapters(self.chapters)\n                epub_file.write(os.path.join(self.OEBPS_DIR, name))\n\n        def create_zip_archive(epub_name):\n            try:\n                assert isinstance(epub_name, basestring) or epub_name is None\n            except AssertionError:\n                raise TypeError('epub_name must be string or None')\n            if epub_name is None:\n                epub_name = self.title\n            epub_name = ''.join([c for c in epub_name if c.isalpha() or c.isdigit() or c == ' ']).rstrip()\n            epub_name_with_path = os.path.join(output_directory, epub_name)\n            try:\n                os.remove(os.path.join(epub_name_with_path, '.zip'))\n            except OSError:\n                pass\n            shutil.make_archive(epub_name_with_path, 'zip', self.EPUB_DIR)\n            return epub_name_with_path + '.zip'\n\n        def turn_zip_into_epub(zip_archive):\n            epub_full_name = zip_archive.strip('.zip') + '.epub'\n            try:\n                os.remove(epub_full_name)\n            except OSError:\n                pass\n            os.rename(zip_archive, epub_full_name)\n            return epub_full_name\n        createTOCs_and_ContentOPF()\n        epub_path = turn_zip_into_epub(create_zip_archive(epub_name))\n        return epub_path", "response": "Creates an epub file from this object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_image(image_url, image_directory, image_name):\n    image_type = get_image_type(image_url)\n    if image_type is None:\n        raise ImageErrorException(image_url)\n    full_image_file_name = os.path.join(image_directory, image_name + '.' + image_type)\n\n    # If the image is present on the local filesystem just copy it\n    if os.path.exists(image_url):\n        shutil.copy(image_url, full_image_file_name)\n        return image_type\n\n    try:\n        # urllib.urlretrieve(image_url, full_image_file_name)\n        with open(full_image_file_name, 'wb') as f:\n            user_agent = r'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0'\n            request_headers = {'User-Agent': user_agent}\n            requests_object = requests.get(image_url, headers=request_headers)\n            try:\n                content = requests_object.content\n                # Check for empty response\n                f.write(content)\n            except AttributeError:\n                raise ImageErrorException(image_url)\n    except IOError:\n        raise ImageErrorException(image_url)\n    return image_type", "response": "Saves an online image from image_url to image_directory with the name image_name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplace the src of an image in the ebook with the local copy in the images folder of the ebook.", "response": "def _replace_image(image_url, image_tag, ebook_folder,\n                   image_name=None):\n    \"\"\"\n    Replaces the src of an image to link to the local copy in the images folder of the ebook. Tightly coupled with bs4\n        package.\n\n    Args:\n        image_url (str): The url of the image.\n        image_tag (bs4.element.Tag): The bs4 tag containing the image.\n        ebook_folder (str): The directory where the ebook files are being saved. This must contain a subdirectory\n            called \"images\".\n        image_name (Option[str]): The short name to save the image as. Should not contain a directory or an extension.\n    \"\"\"\n    try:\n        assert isinstance(image_tag, bs4.element.Tag)\n    except AssertionError:\n        raise TypeError(\"image_tag cannot be of type \" + str(type(image_tag)))\n    if image_name is None:\n        image_name = str(uuid.uuid4())\n    try:\n        image_full_path = os.path.join(ebook_folder, 'images')\n        assert os.path.exists(image_full_path)\n        image_extension = save_image(image_url, image_full_path,\n                                     image_name)\n        image_tag['src'] = 'images' + '/' + image_name + '.' + image_extension\n    except ImageErrorException:\n        image_tag.decompose()\n    except AssertionError:\n        raise ValueError('%s doesn\\'t exist or doesn\\'t contain a subdirectory images' % ebook_folder)\n    except TypeError:\n        image_tag.decompose()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write(self, file_name):\n        try:\n            assert file_name[-6:] == '.xhtml'\n        except (AssertionError, IndexError):\n            raise ValueError('filename must end with .xhtml')\n        with open(file_name, 'wb') as f:\n            f.write(self.content.encode('utf-8'))", "response": "Writes the chapter object to an xhtml file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a Chapter object from a given url.", "response": "def create_chapter_from_url(self, url, title=None):\n        \"\"\"\n        Creates a Chapter object from a url. Pulls the webpage from the\n        given url, sanitizes it using the clean_function method, and saves\n        it as the content of the created chapter. Basic webpage loaded\n        before any javascript executed.\n\n        Args:\n            url (string): The url to pull the content of the created Chapter\n                from\n            title (Option[string]): The title of the created Chapter. By\n                default, this is None, in which case the title will try to be\n                inferred from the webpage at the url.\n\n        Returns:\n            Chapter: A chapter object whose content is the webpage at the given\n                url and whose title is that provided or inferred from the url\n\n        Raises:\n            ValueError: Raised if unable to connect to url supplied\n        \"\"\"\n        try:\n            request_object = requests.get(url, headers=self.request_headers, allow_redirects=False)\n        except (requests.exceptions.MissingSchema,\n                requests.exceptions.ConnectionError):\n            raise ValueError(\"%s is an invalid url or no network connection\" % url)\n        except requests.exceptions.SSLError:\n            raise ValueError(\"Url %s doesn't have valid SSL certificate\" % url)\n        unicode_string = request_object.text\n        return self.create_chapter_from_string(unicode_string, url, title)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_chapter_from_file(self, file_name, url=None, title=None):\n        with codecs.open(file_name, 'r', encoding='utf-8') as f:\n            content_string = f.read()\n        return self.create_chapter_from_string(content_string, url, title)", "response": "Creates a Chapter object from a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a Chapter object from a string.", "response": "def create_chapter_from_string(self, html_string, url=None, title=None):\n        \"\"\"\n        Creates a Chapter object from a string. Sanitizes the\n        string using the clean_function method, and saves\n        it as the content of the created chapter.\n\n        Args:\n            html_string (string): The html or xhtml content of the created\n                Chapter\n            url (Option[string]): A url to infer the title of the chapter from\n            title (Option[string]): The title of the created Chapter. By\n                default, this is None, in which case the title will try to be\n                inferred from the webpage at the url.\n\n        Returns:\n            Chapter: A chapter object whose content is the given string\n                and whose title is that provided or inferred from the url\n        \"\"\"\n        clean_html_string = self.clean_function(html_string)\n        clean_xhtml_string = clean.html_to_xhtml(clean_html_string)\n        if title:\n            pass\n        else:\n            try:\n                root = BeautifulSoup(html_string, 'html.parser')\n                title_node = root.title\n                if title_node is not None:\n                    title = unicode(title_node.string)\n                else:\n                    raise ValueError\n            except (IndexError, ValueError):\n                title = 'Ebook Chapter'\n        return Chapter(clean_xhtml_string, title, url)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate full html tree from a fragment. Assumes that the tag is wrapped in a body.", "response": "def create_html_from_fragment(tag):\n    \"\"\"\n    Creates full html tree from a fragment. Assumes that tag should be wrapped in a body and is currently not\n\n    Args:\n        tag: a bs4.element.Tag\n\n    Returns:\"\n        bs4.element.Tag: A bs4 tag representing a full html document\n    \"\"\"\n\n    try:\n        assert isinstance(tag, bs4.element.Tag)\n    except AssertionError:\n        raise TypeError\n    try:\n        assert tag.find_all('body') == []\n    except AssertionError:\n        raise ValueError\n\n    soup = BeautifulSoup('<html><head></head><body></body></html>', 'html.parser')\n    soup.body.append(tag)\n    return soup"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsanitize HTML. Tags not contained as keys in the tag_dictionary input are removed, and child nodes are recursively moved to parent of removed node. Attributes not contained as arguments in tag_dictionary are removed. Doctype is set to <!DOCTYPE html>. Args: input_string (basestring): A (possibly unicode) string representing HTML. tag_dictionary (Option[dict]): A dictionary with tags as keys and attributes as values. This operates as a whitelist--i.e. if a tag isn't contained, it will be removed. By default, this is set to use the supported tags and attributes for the Amazon Kindle, as found at https://kdp.amazon.com/help?topicId=A1JPUWCSD6F59O Returns: str: A (possibly unicode) string representing HTML. Raises: TypeError: Raised if input_string isn't a unicode string or string.", "response": "def clean(input_string,\n          tag_dictionary=constants.SUPPORTED_TAGS):\n    \"\"\"\n    Sanitizes HTML. Tags not contained as keys in the tag_dictionary input are\n    removed, and child nodes are recursively moved to parent of removed node.\n    Attributes not contained as arguments in tag_dictionary are removed.\n    Doctype is set to <!DOCTYPE html>.\n\n    Args:\n        input_string (basestring): A (possibly unicode) string representing HTML.\n        tag_dictionary (Option[dict]): A dictionary with tags as keys and\n            attributes as values. This operates as a whitelist--i.e. if a tag\n            isn't contained, it will be removed. By default, this is set to\n            use the supported tags and attributes for the Amazon Kindle,\n            as found at https://kdp.amazon.com/help?topicId=A1JPUWCSD6F59O\n\n    Returns:\n        str: A (possibly unicode) string representing HTML.\n\n    Raises:\n        TypeError: Raised if input_string isn't a unicode string or string.\n    \"\"\"\n    try:\n        assert isinstance(input_string, basestring)\n    except AssertionError:\n        raise TypeError\n    root = BeautifulSoup(input_string, 'html.parser')\n    article_tag = root.find_all('article')\n    if article_tag:\n        root = article_tag[0]\n    stack = root.findAll(True, recursive=False)\n    while stack:\n        current_node = stack.pop()\n        child_node_list = current_node.findAll(True, recursive=False)\n        if current_node.name not in tag_dictionary.keys():\n            parent_node = current_node.parent\n            current_node.extract()\n            for n in child_node_list:\n                parent_node.append(n)\n        else:\n            attribute_dict = current_node.attrs\n            for attribute in attribute_dict.keys():\n                if attribute not in tag_dictionary[current_node.name]:\n                    attribute_dict.pop(attribute)\n        stack.extend(child_node_list)\n    #wrap partial tree if necessary\n    if root.find_all('html') == []:\n        root = create_html_from_fragment(root)\n    # Remove img tags without src attribute\n    image_node_list = root.find_all('img')\n    for node in image_node_list:\n        if not node.has_attr('src'):\n            node.extract()\n    unformatted_html_unicode_string = unicode(root.prettify(encoding='utf-8',\n                                                            formatter=EntitySubstitution.substitute_html),\n                                              encoding='utf-8')\n    # fix <br> tags since not handled well by default by bs4\n    unformatted_html_unicode_string = unformatted_html_unicode_string.replace('<br>', '<br/>')\n    # remove &nbsp; and replace with space since not handled well by certain e-readers\n    unformatted_html_unicode_string = unformatted_html_unicode_string.replace('&nbsp;', ' ')\n    return unformatted_html_unicode_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef condense(input_string):\n    try:\n        assert isinstance(input_string, basestring)\n    except AssertionError:\n        raise TypeError\n    removed_leading_whitespace = re.sub('>\\s+', '>', input_string).strip()\n    removed_trailing_whitespace = re.sub('\\s+<', '<', removed_leading_whitespace).strip()\n    return removed_trailing_whitespace", "response": "Removes leading and trailing whitespace between tags in an html document."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef html_to_xhtml(html_unicode_string):\n    try:\n        assert isinstance(html_unicode_string, basestring)\n    except AssertionError:\n        raise TypeError\n    root = BeautifulSoup(html_unicode_string, 'html.parser')\n    # Confirm root node is html\n    try:\n        assert root.html is not None\n    except AssertionError:\n        raise ValueError(''.join(['html_unicode_string cannot be a fragment.',\n                         'string is the following: %s', unicode(root)]))\n    # Add xmlns attribute to html node\n    root.html['xmlns'] = 'http://www.w3.org/1999/xhtml'\n    unicode_string = unicode(root.prettify(encoding='utf-8', formatter='html'), encoding='utf-8')\n    # Close singleton tag_dictionary\n    for tag in constants.SINGLETON_TAG_LIST:\n        unicode_string = unicode_string.replace(\n                '<' + tag + '/>',\n                '<' + tag + ' />')\n    return unicode_string", "response": "Converts a unicode string representing HTML to XHTML."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmerge dict2 into dict1", "response": "def _merge_dicts(self, dict1, dict2, path=[]):\n        \"merges dict2 into dict1\"\n        for key in dict2:\n            if key in dict1:\n                if isinstance(dict1[key], dict) and isinstance(dict2[key], dict):\n                    self._merge_dicts(dict1[key], dict2[key], path + [str(key)])\n                elif dict1[key] != dict2[key]:\n                    if self._options.get('allowmultioptions', True):\n                        if not isinstance(dict1[key], list):\n                            dict1[key] = [dict1[key]]\n                        if not isinstance(dict2[key], list):\n                            dict2[key] = [dict2[key]]\n                        dict1[key] = self._merge_lists(dict1[key], dict2[key])\n                    else:\n                        if self._options.get('mergeduplicateoptions', False):\n                            dict1[key] = dict2[key]\n                        else:\n                            raise error.ApacheConfigError('Duplicate option \"%s\" prohibited' % '.'.join(path + [str(key)]))\n            else:\n                dict1[key] = dict2[key]\n        return dict1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_statements(self, p):\n        n = len(p)\n        if n == 3:\n            p[0] = p[1] + [p[2]]\n        elif n == 2:\n            p[0] = ['statements', p[1]]", "response": "A helper function to add the statements to the list of statements."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_contents(self, p):\n        n = len(p)\n        if n == 3:\n            p[0] = p[1] + [p[2]]\n        else:\n            p[0] = ['contents', p[1]]", "response": "contents section of the log"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the block tag", "response": "def p_block(self, p):\n        \"\"\"block : OPEN_TAG contents CLOSE_TAG\n                 | OPEN_TAG CLOSE_TAG\n                 | OPEN_CLOSE_TAG\n        \"\"\"\n        n = len(p)\n        if n == 4:\n            p[0] = ['block', p[1], p[2], p[3]]\n        elif n == 3:\n            p[0] = ['block', p[1],  [], p[2]]\n        else:\n            p[0] = ['block', p[1], [], p[1]]\n\n        if self.options.get('lowercasenames'):\n            for tag in (1, 3):\n                p[0][tag] = p[0][tag].lower()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef t_CCOMMENT(self, t):\n        r'\\/\\*'\n        t.lexer.code_start = t.lexer.lexpos\n        t.lexer.ccomment_level = 1  # Initial comment level\n        t.lexer.begin('ccomment')", "response": "r \\ * \\ *"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef t_OPTION_AND_VALUE(self, t):\n        r'[^ \\n\\r\\t=#]+[ \\t=]+[^\\r\\n#]+'  # TODO(etingof) escape hash\n        if t.value.endswith('\\\\'):\n            t.lexer.multiline_newline_seen = False\n            t.lexer.code_start = t.lexer.lexpos - len(t.value)\n            t.lexer.begin('multiline')\n            return\n\n        lineno = len(re.findall(r'\\r\\n|\\n|\\r', t.value))\n\n        option, value = self._parse_option_value(t.value)\n\n        process, option, value = self._pre_parse_value(option, value)\n        if not process:\n            return\n\n        if value.startswith('<<'):\n            t.lexer.heredoc_anchor = value[2:].strip()\n            t.lexer.heredoc_option = option\n            t.lexer.code_start = t.lexer.lexpos\n            t.lexer.begin('heredoc')\n            return\n\n        t.value = option, value\n\n        t.lexer.lineno += lineno\n\n        return t", "response": "t_OPTION_AND_VALUE returns a tuple of option and value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef t_multiline_OPTION_AND_VALUE(self, t):\n        r'[^\\r\\n]+'\n        t.lexer.multiline_newline_seen = False\n\n        if t.value.endswith('\\\\'):\n            return\n\n        t.type = \"OPTION_AND_VALUE\"\n        t.lexer.begin('INITIAL')\n\n        value = t.lexer.lexdata[t.lexer.code_start:t.lexer.lexpos + 1]\n        t.lexer.lineno += len(re.findall(r'\\r\\n|\\n|\\r', value))\n        value = value.replace('\\\\\\n', '').replace('\\r', '').replace('\\n', '')\n\n        option, value = self._parse_option_value(value)\n\n        process, option, value = self._pre_parse_value(option, value)\n        if not process:\n            return\n\n        t.value = option, value\n\n        return t", "response": "t_multiline_OPTION_AND_VALUE t. lexer. begin"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreplaces the current application default depot", "response": "def set_default(cls, name):\n        \"\"\"Replaces the current application default depot\"\"\"\n        if name not in cls._depots:\n            raise RuntimeError('%s depot has not been configured' % (name,))\n        cls._default_depot = name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the application wide depot instance.", "response": "def get(cls, name=None):\n        \"\"\"Gets the application wide depot instance.\n\n        Might return ``None`` if :meth:`configure` has not been\n        called yet.\n\n        \"\"\"\n        if name is None:\n            name = cls._default_depot\n\n        name = cls.resolve_alias(name)  # resolve alias\n        return cls._depots.get(name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves a file by storage name and fileid in the form of a path.", "response": "def get_file(cls, path):\n        \"\"\"Retrieves a file by storage name and fileid in the form of a path\n\n        Path is expected to be ``storage_name/fileid``.\n        \"\"\"\n        depot_name, file_id = path.split('/', 1)\n        depot = cls.get(depot_name)\n        return depot.get(file_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef configure(cls, name, config, prefix='depot.'):\n        if name in cls._depots:\n            raise RuntimeError('Depot %s has already been configured' % (name,))\n\n        if cls._default_depot is None:\n            cls._default_depot = name\n\n        cls._depots[name] = cls.from_config(config, prefix)\n        return cls._depots[name]", "response": "Configures an application wide depot."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_middleware(cls, app, **options):\n        from depot.middleware import DepotMiddleware\n        mw = DepotMiddleware(app, **options)\n        cls.set_middleware(mw)\n        return mw", "response": "Creates the application WSGI middleware in charge of serving local files from a local file storage and a gridFS storage."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_config(cls, config, prefix='depot.'):\n        config = config or {}\n\n        # Get preferred storage backend\n        backend = config.get(prefix + 'backend', 'depot.io.local.LocalFileStorage')\n\n        # Get all options\n        prefixlen = len(prefix)\n        options = dict((k[prefixlen:], config[k]) for k in config.keys() if k.startswith(prefix))\n\n        # Backend is already passed as a positional argument\n        options.pop('backend', None)\n        return cls._new(backend, **options)", "response": "Creates a new depot from a settings dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreset the status of the current set of DepotManager items.", "response": "def _clear(cls):\n        \"\"\"This is only for testing pourposes, resets the DepotManager status\n\n        This is to simplify writing test fixtures, resets the DepotManager global\n        status and removes the informations related to the current configured depots\n        and middleware.\n        \"\"\"\n        cls._default_depot = None\n        cls._depots = {}\n        cls._middleware = None\n        cls._aliases = {}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup_schema(command, conf, vars):\n    # Load the models\n\n    # <websetup.websetup.schema.before.model.import>\n    from depotexample import model\n    # <websetup.websetup.schema.after.model.import>\n\n    \n    # <websetup.websetup.schema.before.metadata.create_all>\n    print(\"Creating tables\")\n    model.metadata.create_all(bind=config['tg.app_globals'].sa_engine)\n    # <websetup.websetup.schema.after.metadata.create_all>\n    transaction.commit()\n    print('Initializing Migrations')\n    import alembic.config, alembic.command\n    alembic_cfg = alembic.config.Config()\n    alembic_cfg.set_main_option(\"script_location\", \"migration\")\n    alembic_cfg.set_main_option(\"sqlalchemy.url\", config['sqlalchemy.url'])\n    alembic.command.stamp(alembic_cfg, \"head\")", "response": "Place any commands to setup depotexample here"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef permissions(self):\n        perms = set()\n        for g in self.groups:\n            perms = perms | set(g.permissions)\n        return perms", "response": "Return a set with all permissions granted to the user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef by_email_address(cls, email):\n        return DBSession.query(cls).filter_by(email_address=email).first()", "response": "Return the user object whose email address is email."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef by_user_name(cls, username):\n        return DBSession.query(cls).filter_by(user_name=username).first()", "response": "Return the user object whose user name is username."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck the password against existing credentials.", "response": "def validate_password(self, password):\n        \"\"\"\n        Check the password against existing credentials.\n\n        :param password: the password that was provided by the user to\n            try and authenticate. This is the clear text version that we will\n            need to match against the hashed one in the database.\n        :type password: unicode object.\n        :return: Whether the password is valid.\n        :rtype: bool\n\n        \"\"\"\n        hash = sha256()\n        hash.update((password + self.password[:64]).encode('utf-8'))\n        return self.password[64:] == hash.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender the error document", "response": "def document(self, *args, **kwargs):\n        \"\"\"Render the error document\"\"\"\n        resp = request.environ.get('pylons.original_response')\n        default_message = (\"<p>We're sorry but we weren't able to process \"\n                           \" this request.</p>\")\n        values = dict(prefix=request.environ.get('SCRIPT_NAME', ''),\n                      code=request.params.get('code', resp.status_int),\n                      message=request.params.get('message', default_message))\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new TurboGears 2 application with all the relevant middleware and settings.", "response": "def make_app(global_conf, full_stack=True, **app_conf):\n    \"\"\"\n    Set depotexample up with the settings found in the PasteDeploy configuration\n    file used.\n    \n    :param global_conf: The global settings for depotexample (those\n        defined under the ``[DEFAULT]`` section).\n    :type global_conf: dict\n    :param full_stack: Should the whole TG2 stack be set up?\n    :type full_stack: str or bool\n    :return: The depotexample application with all the relevant middleware\n        loaded.\n    \n    This is the PasteDeploy factory for the depotexample application.\n    \n    ``app_conf`` contains all the application-specific settings (those defined\n    under ``[app:main]``.\n    \n   \n    \"\"\"\n    app = make_base_app(global_conf, full_stack=True, **app_conf)\n    \n    # Wrap your base TurboGears 2 application with custom middleware here\n    from depot.manager import DepotManager\n    app = DepotManager.make_middleware(app)\n\n    return app"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplace any commands to setup depotexample here", "response": "def bootstrap(command, conf, vars):\n    \"\"\"Place any commands to setup depotexample here\"\"\"\n\n    # <websetup.bootstrap.before.auth\n    from sqlalchemy.exc import IntegrityError\n    try:\n        u = model.User()\n        u.user_name = 'manager'\n        u.display_name = 'Example manager'\n        u.email_address = 'manager@somedomain.com'\n        u.password = 'managepass'\n    \n        model.DBSession.add(u)\n    \n        g = model.Group()\n        g.group_name = 'managers'\n        g.display_name = 'Managers Group'\n    \n        g.users.append(u)\n    \n        model.DBSession.add(g)\n    \n        p = model.Permission()\n        p.permission_name = 'manage'\n        p.description = 'This permission give an administrative right to the bearer'\n        p.groups.append(g)\n    \n        model.DBSession.add(p)\n    \n        u1 = model.User()\n        u1.user_name = 'editor'\n        u1.display_name = 'Example editor'\n        u1.email_address = 'editor@somedomain.com'\n        u1.password = 'editpass'\n    \n        model.DBSession.add(u1)\n        model.DBSession.flush()\n        transaction.commit()\n    except IntegrityError:\n        print('Warning, there was a problem adding your auth data, it may have already been added:')\n        import traceback\n        print(traceback.format_exc())\n        transaction.abort()\n        print('Continuing with bootstrapping...')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef file_from_content(content):\n    f = content\n    if isinstance(content, cgi.FieldStorage):\n        f = content.file\n    elif isinstance(content, FileIntent):\n        f = content._fileobj\n    elif isinstance(content, byte_string):\n        f = SpooledTemporaryFile(INMEMORY_FILESIZE)\n        f.write(content)\n    f.seek(0)\n    return f", "response": "Provides a real file object from a cgi. FieldStorage FileIntent and bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to extract from the given input the actual file object filename and content_type and existing. Returns None if no information was found.", "response": "def fileinfo(fileobj, filename=None, content_type=None, existing=None):\n        \"\"\"Tries to extract from the given input the actual file object, filename and content_type\n\n        This is used by the create and replace methods to correctly deduce their parameters\n        from the available information when possible.\n        \"\"\"\n        return _FileInfo(fileobj, filename, content_type).get_info(existing)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart the user login.", "response": "def login(self, came_from=lurl('/')):\n        \"\"\"Start the user login.\"\"\"\n        login_counter = request.environ.get('repoze.who.logins', 0)\n        if login_counter > 0:\n            flash(_('Wrong credentials'), 'warning')\n        return dict(page='login', login_counter=str(login_counter),\n                    came_from=came_from)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef post_login(self, came_from=lurl('/')):\n        if not request.identity:\n            login_counter = request.environ.get('repoze.who.logins', 0) + 1\n            redirect('/login',\n                params=dict(came_from=came_from, __logins=login_counter))\n        userid = request.identity['repoze.who.userid']\n        flash(_('Welcome back, %s!') % userid)\n        redirect(came_from)", "response": "Redirect the user to the initially requested page on successful\n        authentication or redirect her back to the login page on successful\n        authentication or redirect her back to the login page on successful\n        authentication."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninfer the most likely date format from the examples.", "response": "def infer(examples, alt_rules=None):\n    \"\"\"\n    Returns a datetime.strptime-compliant format string for parsing the *most likely* date format\n    used in examples. examples is a list containing example date strings.\n    \"\"\"\n    date_classes = _tag_most_likely(examples)\n\n    if alt_rules:\n        date_classes = _apply_rewrites(date_classes, alt_rules)\n    else:\n        date_classes = _apply_rewrites(date_classes, RULES)\n\n    date_string = ''\n    for date_class in date_classes:\n        date_string += date_class.directive\n\n    return date_string"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying rewrites to the initial date element list.", "response": "def _apply_rewrites(date_classes, rules):\n    \"\"\"\n    Return a list of date elements by applying rewrites to the initial date element list\n    \"\"\"\n    for rule in rules:\n        date_classes = rule.execute(date_classes)\n\n    return date_classes"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the mode of the given list of elements.", "response": "def _mode(elems):\n    \"\"\"\n    Find the mode (most common element) in list elems. If there are ties, this function returns the least value.\n\n    If elems is an empty list, returns None.\n    \"\"\"\n    if len(elems) == 0:\n        return None\n\n    c = collections.Counter()\n    c.update(elems)\n\n    most_common = c.most_common(1)\n    most_common.sort()\n    return most_common[0][0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _most_restrictive(date_elems):\n    most_index = len(DATE_ELEMENTS)\n    for date_elem in date_elems:\n        if date_elem in DATE_ELEMENTS and DATE_ELEMENTS.index(date_elem) < most_index:\n            most_index = DATE_ELEMENTS.index(date_elem)\n    if most_index < len(DATE_ELEMENTS):\n        return DATE_ELEMENTS[most_index]\n    else:\n        raise KeyError('No least restrictive date element found')", "response": "Return the date_elem that has the most restrictive range from date_elems\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the percentage of tokens that the class matched.", "response": "def _percent_match(date_classes, tokens):\n    \"\"\"\n    For each date class, return the percentage of tokens that the class matched (floating point [0.0 - 1.0]). The\n    returned value is a tuple of length patterns. Tokens should be a list.\n    \"\"\"\n    match_count = [0] * len(date_classes)\n\n    for i, date_class in enumerate(date_classes):\n        for token in tokens:\n            if date_class.is_match(token):\n                match_count[i] += 1\n\n    percentages = tuple([float(m) / len(tokens) for m in match_count])\n    return percentages"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _tag_most_likely(examples):\n    tokenized_examples = [_tokenize_by_character_class(example) for example in examples]\n\n    # We currently need the tokenized_examples to all have the same length, so drop instances that have a length\n    # that does not equal the mode of lengths within tokenized_examples\n    token_lengths = [len(e) for e in tokenized_examples]\n    token_lengths_mode = _mode(token_lengths)\n    tokenized_examples = [example for example in tokenized_examples if len(example) == token_lengths_mode]\n\n    # Now, we iterate through the tokens, assigning date elements based on their likelihood. In cases where\n    # the assignments are unlikely for all date elements, assign filler.\n    most_likely = []\n    for token_index in range(0, token_lengths_mode):\n        tokens = [token[token_index] for token in tokenized_examples]\n        probabilities = _percent_match(DATE_ELEMENTS, tokens)\n        max_prob = max(probabilities)\n        if max_prob < 0.5:\n            most_likely.append(Filler(_mode(tokens)))\n        else:\n            if probabilities.count(max_prob) == 1:\n                most_likely.append(DATE_ELEMENTS[probabilities.index(max_prob)])\n            else:\n                choices = []\n                for index, prob in enumerate(probabilities):\n                    if prob == max_prob:\n                        choices.append(DATE_ELEMENTS[index])\n                most_likely.append(_most_restrictive(choices))\n\n    return most_likely", "response": "Return a list of date elements by choosing the most likely element for a token within examples."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of strings by splitting s by character class.", "response": "def _tokenize_by_character_class(s):\n    \"\"\"\n    Return a list of strings by splitting s (tokenizing) by character class.\n\n    For example:\n    _tokenize_by_character_class('Sat Jan 11 19:54:52 MST 2014') => ['Sat', ' ', 'Jan', ' ', '11', ' ', '19', ':',\n        '54', ':', '52', ' ', 'MST', ' ', '2014']\n    _tokenize_by_character_class('2013-08-14') => ['2013', '-', '08', '-', '14']\n    \"\"\"\n    character_classes = [string.digits, string.ascii_letters, string.punctuation, string.whitespace]\n\n    result = []\n    rest = list(s)\n    while rest:\n        progress = False\n        for character_class in character_classes:\n            if rest[0] in character_class:\n                progress = True\n                token = ''\n                for take_away in itertools.takewhile(lambda c: c in character_class, rest[:]):\n                    token += take_away\n                    rest.pop(0)\n                result.append(token)\n                break\n        if not progress:  # none of the character classes matched; unprintable character?\n            result.append(rest[0])\n            rest = rest[1:]\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute the condition and return a new list of elements.", "response": "def execute(self, elem_list):\n        \"\"\"\n        If condition, return a new elem_list provided by executing action.\n        \"\"\"\n        if self.condition.is_true(elem_list):\n            return self.action.act(elem_list)\n        else:\n            return elem_list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if elem matches seq_expr", "response": "def match(elem, seq_expr):\n        \"\"\"\n        Return True if elem (an element of elem_list) matches seq_expr, an element in self.sequence\n        \"\"\"\n        if type(seq_expr) is str:  # wild-card\n            if seq_expr == '.':  # match any element\n                return True\n            elif seq_expr == '\\d':\n                return elem.is_numerical()\n            elif seq_expr == '\\D':\n                return not elem.is_numerical()\n            else:  # invalid wild-card specified\n                raise LookupError('{0} is not a valid wild-card'.format(seq_expr))\n        else:  # date element\n            return elem == seq_expr"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find(find_seq, elem_list):\n        seq_pos = 0\n        for index, elem in enumerate(elem_list):\n            if Sequence.match(elem, find_seq[seq_pos]):\n                seq_pos += 1\n                if seq_pos == len(find_seq):  # found matching sequence\n                    return index - seq_pos + 1\n            else:  # exited sequence\n                seq_pos = 0\n        raise LookupError('Failed to find sequence in elem_list')", "response": "Find the first element in elem_list where find_seq starts"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the point in the nation of the current state of the current node.", "response": "def get_point(grade_str):\n    \"\"\"\n    \u6839\u636e\u6210\u7ee9\u5224\u65ad\u7ee9\u70b9\n\n    :param grade_str: \u4e00\u4e2a\u5b57\u7b26\u4e32,\u56e0\u4e3a\u53ef\u80fd\u662f\u767e\u5206\u5236\u6210\u7ee9\u6216\u7b49\u7ea7\u5236\u6210\u7ee9\n    :return: \u6210\u7ee9\u7ee9\u70b9\n    :rtype: float\n    \"\"\"\n    try:\n        grade = float(grade_str)\n        assert 0 <= grade <= 100\n        if 95 <= grade <= 100:\n            return 4.3\n        elif 90 <= grade < 95:\n            return 4.0\n        elif 85 <= grade < 90:\n            return 3.7\n        elif 82 <= grade < 85:\n            return 3.3\n        elif 78 <= grade < 82:\n            return 3.0\n        elif 75 <= grade < 78:\n            return 2.7\n        elif 72 <= grade < 75:\n            return 2.3\n        elif 68 <= grade < 72:\n            return 2.0\n        elif 66 <= grade < 68:\n            return 1.7\n        elif 64 <= grade < 66:\n            return 1.3\n        elif 60 <= grade < 64:\n            return 1.0\n        else:\n            return 0.0\n    except ValueError:\n        if grade_str == '\u4f18':\n            return 3.9\n        elif grade_str == '\u826f':\n            return 3.0\n        elif grade_str == '\u4e2d':\n            return 2.0\n        elif grade_str == '\u53ca\u683c':\n            return 1.2\n        elif grade_str in ('\u4e0d\u53ca\u683c', '\u514d\u4fee', '\u672a\u8003'):\n            return 0.0\n        else:\n            raise ValueError('{:s} \u4e0d\u662f\u6709\u6548\u7684\u6210\u7ee9'.format(grade_str))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cal_gpa(grades):\n    # \u8bfe\u7a0b\u603b\u6570\n    courses_sum = len(grades)\n    # \u8bfe\u7a0b\u7ee9\u70b9\u548c\n    points_sum = 0\n    # \u5b66\u5206\u548c\n    credit_sum = 0\n    # \u8bfe\u7a0b\u5b66\u5206 x \u8bfe\u7a0b\u7ee9\u70b9\u4e4b\u548c\n    gpa_points_sum = 0\n    for grade in grades:\n        point = get_point(grade.get('\u8865\u8003\u6210\u7ee9') or grade['\u6210\u7ee9'])\n        credit = float(grade['\u5b66\u5206'])\n\n        points_sum += point\n        credit_sum += credit\n        gpa_points_sum += credit * point\n    ave_point = points_sum / courses_sum\n    gpa = gpa_points_sum / credit_sum\n    return round(ave_point, 5), round(gpa, 5)", "response": "cal_gpa - \u53c2\u8003 return ave_point gpa"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a term_str to a term_code", "response": "def term_str2code(term_str):\n    \"\"\"\n    \u5c06\u5b66\u671f\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5bf9\u5e94\u7684\u5b66\u671f\u4ee3\u7801\u4e32\n\n    :param term_str: \u5f62\u5982 \"2012-2013\u5b66\u5e74\u7b2c\u4e8c\u5b66\u671f\" \u7684\u5b66\u671f\u5b57\u7b26\u4e32\n    :return: \u5f62\u5982 \"022\" \u7684\u5b66\u671f\u4ee3\u7801\n    \"\"\"\n    result = ENV['TERM_PATTERN'].match(term_str).groups()\n    year = int(result[0])\n    return cal_term_code(year, result[1] == '\u4e00')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsort hosts by url", "response": "def sort_hosts(hosts, method='GET', path='/', timeout=(5, 10), **kwargs):\n    \"\"\"\n    \u6d4b\u8bd5\u5404\u4e2a\u5730\u5740\u7684\u901f\u5ea6\u5e76\u8fd4\u56de\u6392\u540d, \u5f53\u51fa\u73b0\u9519\u8bef\u65f6\u6d88\u8017\u65f6\u95f4\u4e3a INFINITY = 10000000\n\n    :param method: \u8bf7\u6c42\u65b9\u6cd5\n    :param path: \u9ed8\u8ba4\u7684\u8bbf\u95ee\u8def\u5f84\n    :param hosts: \u8fdb\u884c\u7684\u4e3b\u673a\u5730\u5740\u5217\u8868, \u5982 `['http://222.195.8.201/']`\n    :param timeout: \u8d85\u65f6\u65f6\u95f4, \u53ef\u4ee5\u662f\u4e00\u4e2a\u6d6e\u70b9\u6570\u6216 \u5f62\u5982 ``(\u8fde\u63a5\u8d85\u65f6, \u8bfb\u53d6\u8d85\u65f6)`` \u7684\u5143\u7956\n    :param kwargs: \u5176\u4ed6\u4f20\u9012\u5230 ``requests.request`` \u7684\u53c2\u6570\n    :return: \u5f62\u5982 ``[(\u8bbf\u95ee\u8017\u65f6, \u5730\u5740)]`` \u7684\u6392\u540d\u6570\u636e\n    \"\"\"\n    ranks = []\n\n    class HostCheckerThread(Thread):\n        def __init__(self, host):\n            super(HostCheckerThread, self).__init__()\n            self.host = host\n\n        def run(self):\n            INFINITY = 10000000\n            try:\n                url = urllib.parse.urljoin(self.host, path)\n                res = requests.request(method, url, timeout=timeout, **kwargs)\n                res.raise_for_status()\n                cost = res.elapsed.total_seconds() * 1000\n            except Exception as e:\n                logger.warning('\u8bbf\u95ee\u51fa\u9519: %s', e)\n                cost = INFINITY\n            # http://stackoverflow.com/questions/6319207/are-lists-thread-safe\n            ranks.append((cost, self.host))\n\n    threads = [HostCheckerThread(u) for u in hosts]\n\n    for t in threads:\n        t.start()\n\n    for t in threads:\n        t.join()\n\n    ranks.sort()\n    return ranks"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfilter the curriculum by week.", "response": "def filter_curriculum(curriculum, week, weekday=None):\n    \"\"\"\n    \u7b5b\u9009\u51fa\u6307\u5b9a\u661f\u671f[\u548c\u6307\u5b9a\u661f\u671f\u51e0]\u7684\u8bfe\u7a0b\n\n    :param curriculum: \u8bfe\u7a0b\u8868\u6570\u636e\n    :param week: \u9700\u8981\u7b5b\u9009\u7684\u5468\u6570, \u662f\u4e00\u4e2a\u4ee3\u8868\u5468\u6570\u7684\u6b63\u6574\u6570\n    :param weekday: \u661f\u671f\u51e0, \u662f\u4e00\u4e2a\u4ee3\u8868\u661f\u671f\u7684\u6574\u6570, 1-7 \u5bf9\u5e94\u5468\u4e00\u5230\u5468\u65e5\n    :return: \u5982\u679c weekday \u53c2\u6570\u6ca1\u7ed9\u51fa, \u8fd4\u56de\u7684\u683c\u5f0f\u4e0e\u539f\u8bfe\u8868\u4e00\u81f4, \u4f46\u53ea\u5305\u62ec\u4e86\u5728\u6307\u5b9a\u5468\u6570\u7684\u8bfe\u7a0b, \u5426\u5219\u8fd4\u56de\u6307\u5b9a\u5468\u6570\u548c\u661f\u671f\u51e0\u7684\u5f53\u5929\u8bfe\u7a0b\n    \"\"\"\n    if weekday:\n        c = [deepcopy(curriculum[weekday - 1])]\n    else:\n        c = deepcopy(curriculum)\n    for d in c:\n        l = len(d)\n        for t_idx in range(l):\n            t = d[t_idx]\n            if t is None:\n                continue\n            # \u4e00\u822c\u540c\u4e00\u65f6\u95f4\u8bfe\u7a0b\u4e0d\u4f1a\u91cd\u590d\uff0c\u91cd\u590d\u65f6\u7ed9\u51fa\u8b66\u544a\n            t = list(filter(lambda k: week in k['\u4e0a\u8bfe\u5468\u6570'], t)) or None\n            if t is not None and len(t) > 1:\n                logger.warning('\u7b2c %d \u5468\u5468 %d \u7b2c %d \u8282\u8bfe\u6709\u51b2\u7a81: %s', week, weekday or c.index(d) + 1, t_idx + 1, t)\n            d[t_idx] = t\n    return c[0] if weekday else c"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef schedule2calendar(schedule, name='\u8bfe\u8868', using_todo=True):\n    # https://zh.wikipedia.org/wiki/ICalendar\n    # http://icalendar.readthedocs.io/en/latest\n    # https://tools.ietf.org/html/rfc5545\n    cal = icalendar.Calendar()\n    cal.add('X-WR-TIMEZONE', 'Asia/Shanghai')\n    cal.add('X-WR-CALNAME', name)\n    cls = icalendar.Todo if using_todo else icalendar.Event\n    for week, start, end, data in schedule:\n        # \"\u4e8b\u4ef6\"\u7ec4\u4ef6\u66f4\u5177\u901a\u7528\u6027, Google \u65e5\u5386\u4e0d\u652f\u6301\"\u5f85\u529e\"\u7ec4\u4ef6\n        item = cls(\n            SUMMARY='\u7b2c{:02d}\u5468-{}'.format(week, data),\n            DTSTART=icalendar.vDatetime(start),\n            DTEND=icalendar.vDatetime(end),\n            DESCRIPTION='\u8d77\u59cb\u4e8e {}, \u7ed3\u675f\u4e8e {}'.format(start.strftime('%H:%M'), end.strftime('%H:%M'))\n        )\n        now = datetime.now()\n        # \u8fd9\u4e2a\u72b6\u6001\"\u4e8b\u4ef6\"\u7ec4\u4ef6\u662f\u6ca1\u6709\u7684, \u5bf9\u4e8e\u5f85\u529e\u5217\u8868\u7c7b\u5e94\u7528\u6709\u4f5c\u7528\n        # https://tools.ietf.org/html/rfc5545#section-3.2.12\n        if using_todo:\n            if start < now < end:\n                item.add('STATUS', 'IN-PROCESS')\n            elif now > end:\n                item.add('STATUS', 'COMPLETED')\n        cal.add_component(item)\n    return cal", "response": "Convert a schedule to an icalendar. Calendar object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_new_game(self, with_tcp=True):\n        self.board = self.create_board(self.board_width, self.board_height,\n                                       self.num_mines)\n        self.game_status = 2\n        self.num_moves = 0\n        self.move_history = []\n\n        if with_tcp is True:\n            # init TCP communication.\n            self.tcp_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self.tcp_socket.bind((self.TCP_IP, self.TCP_PORT))\n            self.tcp_socket.listen(1)", "response": "Init a new game."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a move is valid and return a dictionary of move parameters.", "response": "def check_move(self, move_type, move_x, move_y):\n        \"\"\"Check if a move is valid.\n\n        If the move is not valid, then shut the game.\n        If the move is valid, then setup a dictionary for the game,\n        and update move counter.\n\n        TODO: maybe instead of shut the game, can end the game or turn it into\n        a valid move?\n\n        Parameters\n        ----------\n        move_type : string\n            one of four move types:\n            \"click\", \"flag\", \"unflag\", \"question\"\n        move_x : int\n            X position of the move\n        move_y : int\n            Y position of the move\n        \"\"\"\n        if move_type not in self.move_types:\n            raise ValueError(\"This is not a valid move!\")\n        if move_x < 0 or move_x >= self.board_width:\n            raise ValueError(\"This is not a valid X position of the move!\")\n        if move_y < 0 or move_y >= self.board_height:\n            raise ValueError(\"This is not a valid Y position of the move!\")\n\n        move_des = {}\n        move_des[\"move_type\"] = move_type\n        move_des[\"move_x\"] = move_x\n        move_des[\"move_y\"] = move_y\n        self.num_moves += 1\n\n        return move_des"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef play_move(self, move_type, move_x, move_y):\n        # record the move\n        if self.game_status == 2:\n            self.move_history.append(self.check_move(move_type, move_x,\n                                                     move_y))\n        else:\n            self.end_game()\n\n        # play the move, update the board\n        if move_type == \"click\":\n            self.board.click_field(move_x, move_y)\n        elif move_type == \"flag\":\n            self.board.flag_field(move_x, move_y)\n        elif move_type == \"unflag\":\n            self.board.unflag_field(move_x, move_y)\n        elif move_type == \"question\":\n            self.board.question_field(move_x, move_y)\n\n        # check the status, see if end the game\n        if self.board.check_board() == 0:\n            self.game_status = 0  # game loses\n            # self.print_board()\n            self.end_game()\n        elif self.board.check_board() == 1:\n            self.game_status = 1  # game wins\n            # self.print_board()\n            self.end_game()\n        elif self.board.check_board() == 2:\n            self.game_status = 2", "response": "Updat board by a given move.\n\n        Parameters\n        ----------\n        move_type : string\n            one of four move types:\n            \"click\", \"flag\", \"unflag\", \"question\"\n        move_x : int\n            X position of the move\n        move_y : int\n            Y position of the move"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_move(self, move_msg):\n        # TODO: some condition check\n        type_idx = move_msg.index(\":\")\n        move_type = move_msg[:type_idx]\n        pos_idx = move_msg.index(\",\")\n        move_x = int(move_msg[type_idx+1:pos_idx])\n        move_y = int(move_msg[pos_idx+1:])\n\n        return move_type, move_x, move_y", "response": "Parse a move from a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tcp_accept(self):\n        self.conn, self.addr = self.tcp_socket.accept()\n        print(\"[MESSAGE] The connection is established at: \", self.addr)\n        self.tcp_send(\"> \")", "response": "Waiting for a TCP connection."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tcp_receive(self):\n        data = self.conn.recv(self.BUFFER_SIZE)\n\n        if type(data) != str:\n            # Python 3 specific\n            data = data.decode(\"utf-8\")\n\n        return str(data)", "response": "Receive data from TCP port."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_tr_strs(trs):\n    tr_strs = []\n    for tr in trs:\n        strs = []\n        for td in tr.find_all('td'):\n            text = td.get_text(strip=True)\n            strs.append(text or None)\n        tr_strs.append(strs)\n    logger.debug('\u4ece\u884c\u4e2d\u89e3\u6790\u51fa\u4ee5\u4e0b\u6570\u636e\\n%s', pformat(tr_strs))\n    return tr_strs", "response": "parse_tr_strs - \u5c06\u6ca1\u6709\u5fc5\u987b\u8981\u7684\u5355\u5143\u683c\u7684\u503c\u4f46\u6709\u5fc5\u987b\u8981\u7684\u5355\u5143\u683c\u7684\u503c\u8bbe\u7f6e\u4e3a None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef flatten_list(multiply_list):\n    if isinstance(multiply_list, list):\n        return [rv for l in multiply_list for rv in flatten_list(l)]\n    else:\n        return [multiply_list]", "response": "flatten_list - flattens a list of n - tuple"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a dictionary list to a matrix", "response": "def dict_list_2_matrix(dict_list, columns):\n    \"\"\"\n        >>> dict_list_2_matrix([{'a': 1, 'b': 2}, {'a': 3, 'b': 4}], ('a', 'b'))\n        [[1, 2], [3, 4]]\n\n    :param dict_list: \u5b57\u5178\u5217\u8868\n    :param columns: \u5b57\u5178\u7684\u952e\n    \"\"\"\n    k = len(columns)\n    n = len(dict_list)\n\n    result = [[None] * k for i in range(n)]\n    for i in range(n):\n        row = dict_list[i]\n        for j in range(k):\n            col = columns[j]\n            if col in row:\n                result[i][j] = row[col]\n            else:\n                result[i][j] = None\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_course(course_str):\n    # \u89e3\u6790\u8bfe\u7a0b\u5355\u5143\u683c\n    # \u6240\u6709\u60c5\u51b5\n    # \u673a\u68b0\u539f\u7406[\u4e00\u6559416 (1-14\u5468)]/\n    # \u7a0b\u5e8f\u4e0e\u7b97\u6cd5\u7efc\u5408\u8bbe\u8ba1[\u4e0d\u5360\u7528\u6559\u5ba4 (18\u5468)]/\n    # \u8d22\u52a1\u7ba1\u7406[\u4e00\u6559323 (11-17\u5355\u5468)]/\n    # \u8d22\u52a1\u7ba1\u7406[\u4e00\u6559323 (10-16\u53cc\u5468)]/\n    # \u5f62\u52bf\u4e0e\u653f\u7b56(4)[\u4e00\u6559220 (2,4,6-7\u5468)]/\n    p = re.compile(r'(.+?)\\[(.+?)\\s+\\(([\\d,-\u5355\u53cc]+?)\u5468\\)\\]/')\n    courses = p.findall(course_str)\n    results = []\n    for course in courses:\n        d = {'\u8bfe\u7a0b\u540d\u79f0': course[0], '\u8bfe\u7a0b\u5730\u70b9': course[1]}\n        # \u89e3\u6790\u4e0a\u8bfe\u5468\u6570\n        week_str = course[2]\n        l = week_str.split(',')\n        weeks = []\n        for v in l:\n            m = re.match(r'(\\d+)$', v) or re.match(r'(\\d+)-(\\d+)$', v) or re.match(r'(\\d+)-(\\d+)(\u5355|\u53cc)$', v)\n            g = m.groups()\n            gl = len(g)\n            if gl == 1:\n                weeks.append(int(g[0]))\n            elif gl == 2:\n                weeks.extend([i for i in range(int(g[0]), int(g[1]) + 1)])\n            else:\n                weeks.extend([i for i in range(int(g[0]), int(g[1]) + 1, 2)])\n        d['\u4e0a\u8bfe\u5468\u6570'] = weeks\n        results.append(d)\n    return results", "response": "Parse a course string into a list of dicts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_class_students(self, xqdm, kcdm, jxbh):\n        return self.query(GetClassStudents(xqdm, kcdm, jxbh))", "response": "\u6559\u5b66\u73ed\u67e5\u8be2, \u67e5\u8be2\u6307\u5b9a\u6559\u5b66\u73ed\u7684\u6240\u6709\u5b66\u751f\n\n        @structure {'\u5b66\u671f': str, '\u73ed\u7ea7\u540d\u79f0': str, '\u5b66\u751f': [{'\u59d3\u540d': str, '\u5b66\u53f7': int}]}\n\n        :param xqdm: \u5b66\u671f\u4ee3\u7801\n        :param kcdm: \u8bfe\u7a0b\u4ee3\u7801\n        :param jxbh: \u6559\u5b66\u73ed\u53f7"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_class_info(self, xqdm, kcdm, jxbh):\n        return self.query(GetClassInfo(xqdm, kcdm, jxbh))", "response": "\u83b7\u53d6\u6559\u5b66\u73ed\u8be6\u60c5, \u5305\u62ec\u4e0a\u8bfe\u65f6\u95f4\u5730\u70b9, \u8003\u67e5\u65b9\u5f0f, \u8001\u5e08, \u9009\u4e2d\u4eba\u6570, \u8bfe\u7a0b\u5bb9\u91cf\u7b49\u7b49\u4fe1\u606f\n\n        @structure {'\u6821\u533a': str,'\u5f00\u8bfe\u5355\u4f4d': str,'\u8003\u6838\u7c7b\u578b': str,'\u8bfe\u7a0b\u7c7b\u578b': str,'\u8bfe\u7a0b\u540d\u79f0': str,'\u6559\u5b66\u73ed\u53f7': str,'\u8d77\u6b62\u5468': str,\n        '\u65f6\u95f4\u5730\u70b9': str,'\u5b66\u5206': float,'\u6027\u522b\u9650\u5236': str,'\u4f18\u9009\u8303\u56f4': str,'\u7981\u9009\u8303\u56f4': str,'\u9009\u4e2d\u4eba\u6570': int,'\u5907\u6ce8': str}\n\n        :param xqdm: \u5b66\u671f\u4ee3\u7801\n        :param kcdm: \u8bfe\u7a0b\u4ee3\u7801\n        :param jxbh: \u6559\u5b66\u73ed\u53f7"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch course by name.", "response": "def search_course(self, xqdm, kcdm=None, kcmc=None):\n        \"\"\"\n        \u8bfe\u7a0b\u67e5\u8be2\n\n        @structure [{'\u4efb\u8bfe\u6559\u5e08': str, '\u8bfe\u7a0b\u540d\u79f0': str, '\u6559\u5b66\u73ed\u53f7': str, '\u8bfe\u7a0b\u4ee3\u7801': str, '\u73ed\u7ea7\u5bb9\u91cf': int}]\n\n        :param xqdm: \u5b66\u671f\u4ee3\u7801\n        :param kcdm: \u8bfe\u7a0b\u4ee3\u7801\n        :param kcmc: \u8bfe\u7a0b\u540d\u79f0\n        \"\"\"\n        return self.query(SearchCourse(xqdm, kcdm, kcmc))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_teaching_plan(self, xqdm, kclx='b', zydm=''):\n        return self.query(GetTeachingPlan(xqdm, kclx, zydm))", "response": "\u4e13\u4e1a\u6559\u5b66\u8ba1\u5212\u67e5\u8be2, \u53ef\u4ee5\u67e5\u8be2\u5168\u6821\u516c\u9009\u8bfe, \u6b64\u65f6\u53ef\u4ee5\u4e0d\u586b `zydm`\n\n        @structure [{'\u5f00\u8bfe\u5355\u4f4d': str, '\u5b66\u65f6': int, '\u8bfe\u7a0b\u540d\u79f0': str, '\u8bfe\u7a0b\u4ee3\u7801': str, '\u5b66\u5206': float}]\n\n        :param xqdm: \u5b66\u671f\u4ee3\u7801\n        :param kclx: \u8bfe\u7a0b\u7c7b\u578b\u53c2\u6570,\u53ea\u6709\u4e24\u4e2a\u503c b:\u4e13\u4e1a\u5fc5\u4fee\u8bfe, x:\u5168\u6821\u516c\u9009\u8bfe\n        :param zydm: \u4e13\u4e1a\u4ee3\u7801, \u53ef\u4ee5\u4ece :meth:`models.StudentSession.get_code` \u83b7\u5f97"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nchange the password of the user.", "response": "def change_password(self, new_password):\n        \"\"\"\n        \u4fee\u6539\u6559\u52a1\u5bc6\u7801, **\u6ce8\u610f** \u5408\u80a5\u6821\u533a\u4f7f\u7528\u4fe1\u606f\u4e2d\u5fc3\u8d26\u53f7\u767b\u5f55, \u4e0e\u6559\u52a1\u5bc6\u7801\u4e0d\u4e00\u81f4, \u5373\u4f7f\u4fee\u6539\u4e86\u4e5f\u6ca1\u6709\u4f5c\u7528, \u56e0\u6b64\u5408\u80a5\u6821\u533a\u5e10\u53f7\u8c03\u7528\u6b64\u63a5\u53e3\u4f1a\u76f4\u63a5\u62a5\u9519\n\n        @structure bool\n\n        :param new_password: \u65b0\u5bc6\u7801\n        \"\"\"\n\n        if self.session.campus == HF:\n            raise ValueError('\u5408\u80a5\u6821\u533a\u4f7f\u7528\u4fe1\u606f\u4e2d\u5fc3\u8d26\u53f7\u767b\u5f55, \u4fee\u6539\u6559\u52a1\u5bc6\u7801\u6ca1\u6709\u4f5c\u7528')\n        # \u82e5\u65b0\u5bc6\u7801\u4e0e\u539f\u5bc6\u7801\u76f8\u540c, \u76f4\u63a5\u8fd4\u56de True\n        if new_password == self.session.password:\n            raise ValueError('\u539f\u5bc6\u7801\u4e0e\u65b0\u5bc6\u7801\u76f8\u540c')\n\n        result = self.query(ChangePassword(self.session.password, new_password))\n        if result:\n            self.session.password = new_password\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef evaluate_course(self, kcdm, jxbh,\n                        r101=1, r102=1, r103=1, r104=1, r105=1, r106=1, r107=1, r108=1, r109=1,\n                        r201=3, r202=3, advice=''):\n        \"\"\"\n        \u8bfe\u7a0b\u8bc4\u4ef7, \u6570\u503c\u4e3a 1-5, r1 \u7c7b\u9009\u9879 1 \u4e3a\u6700\u597d, 5 \u4e3a\u6700\u5dee, r2 \u7c7b\u9009\u9879\u7a0b\u5ea6\u7531\u6df1\u5230\u6d45, 3 \u4e3a\u6700\u597d.\n\n        \u9ed8\u8ba4\u90fd\u662f\u6700\u597d\u7684\u9009\u9879\n\n        :param kcdm: \u8bfe\u7a0b\u4ee3\u7801\n        :param jxbh: \u6559\u5b66\u73ed\u53f7\n        :param r101: \u6559\u5b66\u6001\u5ea6\u8ba4\u771f\uff0c\u8bfe\u524d\u51c6\u5907\u5145\u5206\n        :param r102: \u6559\u6388\u5185\u5bb9\u5145\u5b9e\uff0c\u8981\u70b9\u91cd\u70b9\u7a81\u51fa\n        :param r103: \u7406\u8bba\u8054\u7cfb\u5b9e\u9645\uff0c\u53cd\u6620\u6700\u65b0\u6210\u679c\n        :param r104: \u6559\u5b66\u65b9\u6cd5\u7075\u6d3b\uff0c\u5e08\u751f\u4e92\u52a8\u5f97\u5f53\n        :param r105: \u8fd0\u7528\u73b0\u4ee3\u6280\u672f\uff0c\u6559\u5b66\u624b\u6bb5\u591a\u6837\n        :param r106: \u6ce8\u91cd\u56e0\u6750\u65bd\u6559\uff0c\u52a0\u5f3a\u80fd\u529b\u57f9\u517b\n        :param r107: \u4e25\u683c\u8981\u6c42\u7ba1\u7406\uff0c\u5173\u5fc3\u7231\u62a4\u5b66\u751f\n        :param r108: \u5904\u5904\u4e3a\u4eba\u5e08\u8868\uff0c\u6ce8\u91cd\u6559\u4e66\u80b2\u4eba\n        :param r109: \u6559\u5b66\u7efc\u5408\u6548\u679c\n        :param r201: \u8bfe\u7a0b\u5185\u5bb9\n        :param r202: \u8bfe\u7a0b\u8d1f\u62c5\n        :param advice: \u5176\u4ed6\u5efa\u8bae\uff0c\u4e0d\u80fd\u8d85\u8fc7120\u5b57\u4e14\u4e0d\u80fd\u4f7f\u7528\u5206\u53f7,\u5355\u5f15\u53f7,\u90fd\u597d\n        :return:\n        \"\"\"\n        return self.query(EvaluateCourse(\n            kcdm, jxbh,\n            r101, r102, r103, r104, r105, r106, r107, r108, r109,\n            r201, r202, advice\n        ))", "response": "\u8bfe\u7a0b\u8bc4\u4ef7, \u6570\u503c\u4e3a 1-5, r1 \u7c7b\u9009\u9879 1 \u4e3a\u6700\u597d, 5 \u4e3a\u6700\u5dee, r2 \u7c7b\u9009\u9879\u7a0b\u5ea6\u7531\u6df1\u5230\u6d45, 3 \u4e3a\u6700\u597d.\n\n        \u9ed8\u8ba4\u90fd\u662f\u6700\u597d\u7684\u9009\u9879\n\n        :param kcdm: \u8bfe\u7a0b\u4ee3\u7801\n        :param jxbh: \u6559\u5b66\u73ed\u53f7\n        :param r101: \u6559\u5b66\u6001\u5ea6\u8ba4\u771f\uff0c\u8bfe\u524d\u51c6\u5907\u5145\u5206\n        :param r102: \u6559\u6388\u5185\u5bb9\u5145\u5b9e\uff0c\u8981\u70b9\u91cd\u70b9\u7a81\u51fa\n        :param r103: \u7406\u8bba\u8054\u7cfb\u5b9e\u9645\uff0c\u53cd\u6620\u6700\u65b0\u6210\u679c\n        :param r104: \u6559\u5b66\u65b9\u6cd5\u7075\u6d3b\uff0c\u5e08\u751f\u4e92\u52a8\u5f97\u5f53\n        :param r105: \u8fd0\u7528\u73b0\u4ee3\u6280\u672f\uff0c\u6559\u5b66\u624b\u6bb5\u591a\u6837\n        :param r106: \u6ce8\u91cd\u56e0\u6750\u65bd\u6559\uff0c\u52a0\u5f3a\u80fd\u529b\u57f9\u517b\n        :param r107: \u4e25\u683c\u8981\u6c42\u7ba1\u7406\uff0c\u5173\u5fc3\u7231\u62a4\u5b66\u751f\n        :param r108: \u5904\u5904\u4e3a\u4eba\u5e08\u8868\uff0c\u6ce8\u91cd\u6559\u4e66\u80b2\u4eba\n        :param r109: \u6559\u5b66\u7efc\u5408\u6548\u679c\n        :param r201: \u8bfe\u7a0b\u5185\u5bb9\n        :param r202: \u8bfe\u7a0b\u8d1f\u62c5\n        :param advice: \u5176\u4ed6\u5efa\u8bae\uff0c\u4e0d\u80fd\u8d85\u8fc7120\u5b57\u4e14\u4e0d\u80fd\u4f7f\u7528\u5206\u53f7,\u5355\u5f15\u53f7,\u90fd\u597d\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef change_course(self, select_courses=None, delete_courses=None):\n        # \u6846\u67b6\u91cd\u6784\u540e\u8c03\u6574\u63a5\u53e3\u7684\u8c03\u7528\n        t = self.get_system_status()\n        if t['\u5f53\u524d\u8f6e\u6570'] is None:\n            raise ValueError('\u5f53\u524d\u4e3a %s,\u9009\u8bfe\u7cfb\u7edf\u5c1a\u672a\u5f00\u542f', t['\u5f53\u524d\u5b66\u671f'])\n        if not (select_courses or delete_courses):\n            raise ValueError('select_courses, delete_courses \u53c2\u6570\u4e0d\u80fd\u90fd\u4e3a\u7a7a!')\n        # \u53c2\u6570\u5904\u7406\n        select_courses = select_courses or []\n        delete_courses = {l.upper() for l in (delete_courses or [])}\n\n        selected_courses = self.get_selected_courses()\n        selected_kcdms = {course['\u8bfe\u7a0b\u4ee3\u7801'] for course in selected_courses}\n\n        # \u5c1d\u8bd5\u5220\u9664\u6ca1\u6709\u88ab\u9009\u4e2d\u7684\u8bfe\u7a0b\u4f1a\u51fa\u9519\n        unselected = delete_courses.difference(selected_kcdms)\n        if unselected:\n            msg = '\u65e0\u6cd5\u5220\u9664\u6ca1\u6709\u88ab\u9009\u7684\u8bfe\u7a0b {}'.format(unselected)\n            logger.warning(msg)\n\n        # \u8981\u63d0\u4ea4\u7684 kcdm \u6570\u636e\n        kcdms_data = []\n        # \u8981\u63d0\u4ea4\u7684 jxbh \u6570\u636e\n        jxbhs_data = []\n\n        # \u5fc5\u987b\u6dfb\u52a0\u5df2\u9009\u8bfe\u7a0b, \u540c\u65f6\u53bb\u6389\u8981\u5220\u9664\u7684\u8bfe\u7a0b\n        for course in selected_courses:\n            if course['\u8bfe\u7a0b\u4ee3\u7801'] not in delete_courses:\n                kcdms_data.append(course['\u8bfe\u7a0b\u4ee3\u7801'])\n                jxbhs_data.append(course['\u6559\u5b66\u73ed\u53f7'])\n\n        # \u9009\u8bfe\n        for kv in select_courses:\n            kcdm = kv['kcdm'].upper()\n            jxbhs = set(kv['jxbhs']) if kv.get('jxbhs') else set()\n\n            teaching_classes = self.get_course_classes(kcdm)\n            if not teaching_classes:\n                logger.warning('\u8bfe\u7a0b[%s]\u6ca1\u6709\u53ef\u9009\u73ed\u7ea7', kcdm)\n                continue\n\n            # \u53cd\u6b63\u662f\u7edf\u4e00\u63d0\u4ea4, \u4e0d\u9700\u8981\u5224\u65ad\u662f\u5426\u5df2\u6ee1\n            optional_jxbhs = {c['\u6559\u5b66\u73ed\u53f7'] for c in teaching_classes['\u53ef\u9009\u73ed\u7ea7']}\n            if jxbhs:\n                wrong_jxbhs = jxbhs.difference(optional_jxbhs)\n                if wrong_jxbhs:\n                    msg = '\u8bfe\u7a0b[{}]{}\u6ca1\u6709\u6559\u5b66\u73ed\u53f7{}'.format(kcdm, teaching_classes['\u8bfe\u7a0b\u540d\u79f0'], wrong_jxbhs)\n                    logger.warning(msg)\n                jxbhs = jxbhs.intersection(optional_jxbhs)\n            else:\n                jxbhs = optional_jxbhs\n\n            for jxbh in jxbhs:\n                kcdms_data.append(kcdm)\n                jxbhs_data.append(jxbh)\n\n        return self.query(ChangeCourse(self.session.account, select_courses, delete_courses))", "response": "Change the course of the user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a list of selectable courses.", "response": "def get_selectable_courses(self, kcdms=None, pool_size=5, dump_result=True, filename='\u53ef\u9009\u8bfe\u7a0b.json', encoding='utf-8'):\n        \"\"\"\n        \u83b7\u53d6\u6240\u6709\u80fd\u591f\u9009\u4e0a\u7684\u8bfe\u7a0b\u7684\u8bfe\u7a0b\u73ed\u7ea7, \u6ce8\u610f\u8fd9\u4e2a\u65b9\u6cd5\u904d\u5386\u6240\u7ed9\u51fa\u7684\u8bfe\u7a0b\u548c\u5b83\u4eec\u7684\u53ef\u9009\u73ed\u7ea7, \u5f53\u9009\u4e2d\u4eba\u6570\u5927\u4e8e\u7b49\u4e8e\u8bfe\u7a0b\u5bb9\u91cf\u65f6\u8868\u793a\u4e0d\u53ef\u9009.\n\n        \u7531\u4e8e\u8bf7\u6c42\u975e\u5e38\u8017\u65f6\u4e14\u4e00\u822c\u60c5\u51b5\u4e0b\u7528\u4e0d\u5230, \u56e0\u6b64\u9ed8\u8ba4\u63a8\u8350\u5728\u7b2c\u4e00\u8f6e\u9009\u8bfe\u7ed3\u675f\u540e\u5230\u7b2c\u4e09\u8f6e\u9009\u8bfe\u7ed3\u675f\u4e4b\u524d\u7684\u65f6\u95f4\u6bb5\u4f7f\u7528, \u5982\u679c\u4f60\u4ecd\u7136\u575a\u6301\u4f7f\u7528, \u4f60\u5c06\u4f1a\u5f97\u5230\u4e00\u4e2a\u8b66\u544a.\n\n        @structure [{'\u53ef\u9009\u73ed\u7ea7': [{'\u8d77\u6b62\u5468': str, '\u8003\u6838\u7c7b\u578b': str, '\u6559\u5b66\u73ed\u9644\u52a0\u4fe1\u606f': str, '\u8bfe\u7a0b\u5bb9\u91cf': int, '\u9009\u4e2d\u4eba\u6570': int,\n         '\u6559\u5b66\u73ed\u53f7': str, '\u7981\u9009\u4e13\u4e1a': str, '\u6559\u5e08': [str], '\u6821\u533a': str, '\u4f18\u9009\u8303\u56f4': [str], '\u5f00\u8bfe\u65f6\u95f4,\u5f00\u8bfe\u5730\u70b9': [str]}],\n        '\u8bfe\u7a0b\u4ee3\u7801': str, '\u8bfe\u7a0b\u540d\u79f0': str}]\n\n        :param kcdms: \u8bfe\u7a0b\u4ee3\u7801\u5217\u8868, \u9ed8\u8ba4\u4e3a\u6240\u6709\u53ef\u9009\u8bfe\u7a0b\u7684\u8bfe\u7a0b\u4ee3\u7801\n        :param dump_result: \u662f\u5426\u4fdd\u5b58\u7ed3\u679c\u5230\u672c\u5730\n        :param filename: \u4fdd\u5b58\u7684\u6587\u4ef6\u8def\u5f84\n        :param encoding: \u6587\u4ef6\u7f16\u7801\n        \"\"\"\n        now = time.time()\n        t = self.get_system_status()\n        if not (t['\u9009\u8bfe\u8ba1\u5212'][0][1] < now < t['\u9009\u8bfe\u8ba1\u5212'][2][1]):\n            logger.warning('\u53ea\u63a8\u8350\u5728\u7b2c\u4e00\u8f6e\u9009\u8bfe\u7ed3\u675f\u5230\u7b2c\u4e09\u8f6e\u9009\u8bfe\u7ed3\u675f\u4e4b\u95f4\u7684\u65f6\u95f4\u6bb5\u4f7f\u7528\u672c\u63a5\u53e3!')\n\n        def iter_kcdms():\n            for l in self.get_optional_courses():\n                yield l['\u8bfe\u7a0b\u4ee3\u7801']\n\n        kcdms = kcdms or iter_kcdms()\n\n        def target(kcdm):\n            course_classes = self.get_course_classes(kcdm)\n            if not course_classes:\n                return\n            course_classes['\u53ef\u9009\u73ed\u7ea7'] = [c for c in course_classes['\u53ef\u9009\u73ed\u7ea7'] if c['\u8bfe\u7a0b\u5bb9\u91cf'] > c['\u9009\u4e2d\u4eba\u6570']]\n            if len(course_classes['\u53ef\u9009\u73ed\u7ea7']) > 0:\n                return course_classes\n\n        # Python 2.7 \u4e0d\u652f\u6301 with \u8bed\u6cd5\n        pool = Pool(pool_size)\n        result = list(filter(None, pool.map(target, kcdms)))\n        pool.close()\n        pool.join()\n\n        if dump_result:\n            json_str = json.dumps(result, ensure_ascii=False, indent=4, sort_keys=True)\n            with open(filename, 'wb') as fp:\n                fp.write(json_str.encode(encoding))\n            logger.info('\u53ef\u9009\u8bfe\u7a0b\u7ed3\u679c\u5bfc\u51fa\u5230\u4e86:%s', filename)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a request to the server.", "response": "def send(self, request, **kwargs):\n        \"\"\"\n        \u6240\u6709\u63a5\u53e3\u7528\u6765\u53d1\u9001\u8bf7\u6c42\u7684\u65b9\u6cd5, \u53ea\u662f :meth:`requests.sessions.Session.send` \u7684\u4e00\u4e2a\u94a9\u5b50\u65b9\u6cd5, \u7528\u6765\u5904\u7406\u8bf7\u6c42\u524d\u540e\u7684\u5de5\u4f5c\n        \"\"\"\n        response = super(BaseSession, self).send(request, **kwargs)\n        if ENV['RAISE_FOR_STATUS']:\n            response.raise_for_status()\n\n        parsed = parse.urlparse(response.url)\n        if parsed.netloc == parse.urlparse(self.host).netloc:\n            response.encoding = ENV['SITE_ENCODING']\n            # \u5feb\u901f\u5224\u65ad\u54cd\u5e94 IP \u662f\u5426\u88ab\u5c01, \u90a3\u4e2a\u8b66\u544a\u54cd\u5e94\u5185\u5bb9\u957f\u5ea6\u4e3a 327 \u6216 328, \u4fdd\u7559\u4e00\u70b9\u4f59\u91cf\u786e\u4fdd\u51c6\u786e\n            min_length, max_length, pattern = ENV['IP_BANNED_RESPONSE']\n            if min_length <= len(response.content) <= max_length and pattern.search(response.text):\n                msg = '\u5f53\u524d IP \u5df2\u88ab\u9501\u5b9a, \u5982\u679c\u53ef\u4ee5\u8bf7\u5c1d\u8bd5\u5207\u6362\u6559\u52a1\u7cfb\u7edf\u5730\u5740, \u5426\u5219\u8bf7\u5728\u66f4\u6362\u7f51\u7edc\u73af\u5883\u6216\u7b49\u5f85\u89e3\u5c01\u540e\u91cd\u8bd5!'\n                raise IPBanned(msg)\n\n        self.histories.append(response)\n        logger.debug(report_response(response, redirection=kwargs.get('allow_redirects')))\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing a valid board by given settings.", "response": "def init_board(self):\n        \"\"\"Init a valid board by given settings.\n\n        Parameters\n        ----------\n        mine_map : numpy.ndarray\n            the map that defines the mine\n            0 is empty, 1 is mine\n        info_map : numpy.ndarray\n            the map that presents to gamer\n            0-8 is number of mines in srrounding.\n            9 is flagged field.\n            10 is questioned field.\n            11 is undiscovered field.\n            12 is a mine field.\n        \"\"\"\n        self.mine_map = np.zeros((self.board_height, self.board_width),\n                                 dtype=np.uint8)\n        idx_list = np.random.permutation(self.board_width*self.board_height)\n        idx_list = idx_list[:self.num_mines]\n\n        for idx in idx_list:\n            idx_x = int(idx % self.board_width)\n            idx_y = int(idx / self.board_width)\n\n            self.mine_map[idx_y, idx_x] = 1\n\n        self.info_map = np.ones((self.board_height, self.board_width),\n                                dtype=np.uint8)*11"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclicking one grid by given position.", "response": "def click_field(self, move_x, move_y):\n        \"\"\"Click one grid by given position.\"\"\"\n        field_status = self.info_map[move_y, move_x]\n\n        # can only click blank region\n        if field_status == 11:\n            if self.mine_map[move_y, move_x] == 1:\n                self.info_map[move_y, move_x] = 12\n            else:\n                # discover the region.\n                self.discover_region(move_x, move_y)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef discover_region(self, move_x, move_y):\n        field_list = deque([(move_y, move_x)])\n\n        while len(field_list) != 0:\n            field = field_list.popleft()\n\n            (tl_idx, br_idx, region_sum) = self.get_region(field[1], field[0])\n            if region_sum == 0:\n                self.info_map[field[0], field[1]] = region_sum\n                # get surrounding to queue\n                region_mat = self.info_map[tl_idx[0]:br_idx[0]+1,\n                                           tl_idx[1]:br_idx[1]+1]\n                x_list, y_list = np.nonzero(region_mat == 11)\n\n                for x_idx, y_idx in zip(x_list, y_list):\n                    field_temp = (x_idx+max(field[0]-1, 0),\n                                  y_idx+max(field[1]-1, 0))\n                    if field_temp not in field_list:\n                        field_list.append(field_temp)\n            elif region_sum > 0:\n                self.info_map[field[0], field[1]] = region_sum", "response": "Discover region from given location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting region around a location.", "response": "def get_region(self, move_x, move_y):\n        \"\"\"Get region around a location.\"\"\"\n        top_left = (max(move_y-1, 0), max(move_x-1, 0))\n        bottom_right = (min(move_y+1, self.board_height-1),\n                        min(move_x+1, self.board_width-1))\n        region_sum = self.mine_map[top_left[0]:bottom_right[0]+1,\n                                   top_left[1]:bottom_right[1]+1].sum()\n\n        return top_left, bottom_right, region_sum"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nflag a grid by given position.", "response": "def flag_field(self, move_x, move_y):\n        \"\"\"Flag a grid by given position.\"\"\"\n        field_status = self.info_map[move_y, move_x]\n\n        # a questioned or undiscovered field\n        if field_status != 9 and (field_status == 10 or field_status == 11):\n            self.info_map[move_y, move_x] = 9"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unflag_field(self, move_x, move_y):\n        field_status = self.info_map[move_y, move_x]\n\n        if field_status == 9 or field_status == 10:\n            self.info_map[move_y, move_x] = 11", "response": "Unflag a grid by given position."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef question_field(self, move_x, move_y):\n        field_status = self.info_map[move_y, move_x]\n\n        # a questioned or undiscovered field\n        if field_status != 10 and (field_status == 9 or field_status == 11):\n            self.info_map[move_y, move_x] = 10", "response": "Question a grid by given position."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck the board status and give feedback.", "response": "def check_board(self):\n        \"\"\"Check the board status and give feedback.\"\"\"\n        num_mines = np.sum(self.info_map == 12)\n        num_undiscovered = np.sum(self.info_map == 11)\n        num_questioned = np.sum(self.info_map == 10)\n\n        if num_mines > 0:\n            return 0\n        elif np.array_equal(self.info_map == 9, self.mine_map):\n            return 1\n        elif num_undiscovered > 0 or num_questioned > 0:\n            return 2"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef board_msg(self):\n        board_str = \"s\\t\\t\"\n        for i in xrange(self.board_width):\n            board_str += str(i)+\"\\t\"\n        board_str = board_str.expandtabs(4)+\"\\n\\n\"\n\n        for i in xrange(self.board_height):\n            temp_line = str(i)+\"\\t\\t\"\n            for j in xrange(self.board_width):\n                if self.info_map[i, j] == 9:\n                    temp_line += \"@\\t\"\n                elif self.info_map[i, j] == 10:\n                    temp_line += \"?\\t\"\n                elif self.info_map[i, j] == 11:\n                    temp_line += \"*\\t\"\n                elif self.info_map[i, j] == 12:\n                    temp_line += \"!\\t\"\n                else:\n                    temp_line += str(self.info_map[i, j])+\"\\t\"\n            board_str += temp_line.expandtabs(4)+\"\\n\"\n\n        return board_str", "response": "Return a string representation of the board as in print_board."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreports a response to the log.", "response": "def report_response(response,\n                    request_headers=True, request_body=True,\n                    response_headers=False, response_body=False,\n                    redirection=False):\n    \"\"\"\n    \u751f\u6210\u54cd\u5e94\u62a5\u544a\n\n    :param response: ``requests.models.Response`` \u5bf9\u8c61\n    :param request_headers: \u662f\u5426\u52a0\u5165\u8bf7\u6c42\u5934\n    :param request_body: \u662f\u5426\u52a0\u5165\u8bf7\u6c42\u4f53\n    :param response_headers: \u662f\u5426\u52a0\u5165\u54cd\u5e94\u5934\n    :param response_body: \u662f\u5426\u52a0\u5165\u54cd\u5e94\u4f53\n    :param redirection: \u662f\u5426\u52a0\u5165\u91cd\u5b9a\u5411\u54cd\u5e94\n    :return: str\n    \"\"\"\n    # https://docs.python.org/3/library/string.html#formatstrings\n    url = 'Url: [{method}]{url} {status} {elapsed:.2f}ms'.format(\n        method=response.request.method, url=response.url,\n        status=response.status_code, elapsed=response.elapsed.total_seconds() * 1000\n    )\n    pieces = [url]\n\n    if request_headers:\n        request_headers = 'Request headers: {request_headers}'.format(request_headers=response.request.headers)\n        pieces.append(request_headers)\n    if request_body:\n        request_body = 'Request body: {request_body}'.format(request_body=response.request.body)\n        pieces.append(request_body)\n    if response_headers:\n        response_headers = 'Response headers: {response_headers}'.format(response_headers=response.headers)\n        pieces.append(response_headers)\n    if response_body:\n        response_body = 'Response body: {response_body}'.format(response_body=response.text)\n        pieces.append(response_body)\n\n    reporter = '\\n'.join(pieces)\n\n    if redirection and response.history:\n        for h in response.history[::-1]:\n            redirect_reporter = report_response(\n                h,\n                request_headers, request_body,\n                response_headers, response_body,\n                redirection=False\n            )\n            reporter = '\\n'.join([redirect_reporter, ' Redirect \u2193 '.center(72, '-'), reporter])\n\n    return reporter"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a grid layout with stacked widgets.", "response": "def create_grid(self, grid_width, grid_height):\n        \"\"\"Create a grid layout with stacked widgets.\n\n        Parameters\n        ----------\n        grid_width : int\n            the width of the grid\n        grid_height : int\n            the height of the grid\n        \"\"\"\n        self.grid_layout = QGridLayout()\n        self.setLayout(self.grid_layout)\n        self.grid_layout.setSpacing(1)\n        self.grid_wgs = {}\n        for i in xrange(grid_height):\n            for j in xrange(grid_width):\n                self.grid_wgs[(i, j)] = FieldWidget()\n                self.grid_layout.addWidget(self.grid_wgs[(i, j)], i, j)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisplays the current time for the game.", "response": "def timing_game(self):\n        \"\"\"Timing game.\"\"\"\n        self.ctrl_wg.game_timer.display(self.time)\n        self.time += 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate grid according to info map.", "response": "def update_grid(self):\n        \"\"\"Update grid according to info map.\"\"\"\n        info_map = self.ms_game.get_info_map()\n        for i in xrange(self.ms_game.board_height):\n            for j in xrange(self.ms_game.board_width):\n                self.grid_wgs[(i, j)].info_label(info_map[i, j])\n\n        self.ctrl_wg.move_counter.display(self.ms_game.num_moves)\n        if self.ms_game.game_status == 2:\n            self.ctrl_wg.reset_button.setIcon(QtGui.QIcon(CONTINUE_PATH))\n        elif self.ms_game.game_status == 1:\n            self.ctrl_wg.reset_button.setIcon(QtGui.QIcon(WIN_PATH))\n            self.timer.stop()\n        elif self.ms_game.game_status == 0:\n            self.ctrl_wg.reset_button.setIcon(QtGui.QIcon(LOSE_PATH))\n            self.timer.stop()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mousePressEvent(self, event):\n        if event.button() == QtCore.Qt.LeftButton:\n            # get label position\n            p_wg = self.parent()\n            p_layout = p_wg.layout()\n            idx = p_layout.indexOf(self)\n            loc = p_layout.getItemPosition(idx)[:2]\n            if p_wg.ms_game.game_status == 2:\n                p_wg.ms_game.play_move(\"click\", loc[1], loc[0])\n                p_wg.update_grid()\n        elif event.button() == QtCore.Qt.RightButton:\n            p_wg = self.parent()\n            p_layout = p_wg.layout()\n            idx = p_layout.indexOf(self)\n            loc = p_layout.getItemPosition(idx)[:2]\n            if p_wg.ms_game.game_status == 2:\n                if self.id == 9:\n                    self.info_label(10)\n                    p_wg.ms_game.play_move(\"question\", loc[1], loc[0])\n                    p_wg.update_grid()\n                elif self.id == 11:\n                    self.info_label(9)\n                    p_wg.ms_game.play_move(\"flag\", loc[1], loc[0])\n                    p_wg.update_grid()\n                elif self.id == 10:\n                    self.info_label(11)\n                    p_wg.ms_game.play_move(\"unflag\", loc[1], loc[0])\n                    p_wg.update_grid()", "response": "Define mouse press event."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef info_label(self, indicator):\n        if indicator in xrange(1, 9):\n            self.id = indicator\n            self.setPixmap(QtGui.QPixmap(NUMBER_PATHS[indicator]).scaled(\n                    self.field_width, self.field_height))\n        elif indicator == 0:\n            self.id == 0\n            self.setPixmap(QtGui.QPixmap(NUMBER_PATHS[0]).scaled(\n                    self.field_width, self.field_height))\n        elif indicator == 12:\n            self.id = 12\n            self.setPixmap(QtGui.QPixmap(BOOM_PATH).scaled(self.field_width,\n                                                           self.field_height))\n            self.setStyleSheet(\"QLabel {background-color: black;}\")\n        elif indicator == 9:\n            self.id = 9\n            self.setPixmap(QtGui.QPixmap(FLAG_PATH).scaled(self.field_width,\n                                                           self.field_height))\n            self.setStyleSheet(\"QLabel {background-color: #A3C1DA;}\")\n        elif indicator == 10:\n            self.id = 10\n            self.setPixmap(QtGui.QPixmap(QUESTION_PATH).scaled(\n                    self.field_width, self.field_height))\n            self.setStyleSheet(\"QLabel {background-color: yellow;}\")\n        elif indicator == 11:\n            self.id = 11\n            self.setPixmap(QtGui.QPixmap(EMPTY_PATH).scaled(\n                    self.field_width*3, self.field_height*3))\n            self.setStyleSheet('QLabel {background-color: blue;}')", "response": "Set info label by given indicator."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconfigures which kinds of exceptions trigger plugin.", "response": "def configure(self, options, conf):\n        \"\"\"Configure which kinds of exceptions trigger plugin.\n        \"\"\"\n        self.conf = conf\n        self.enabled = options.epdb_debugErrors or options.epdb_debugFailures\n        self.enabled_for_errors = options.epdb_debugErrors\n        self.enabled_for_failures = options.epdb_debugFailures"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_trace_cond(*args, **kw):\n    for key, val in kw.items():\n        Epdb.set_trace_cond(key, val)\n    for arg in args:\n        Epdb.set_trace_cond(arg, True)", "response": "Sets a condition for set_trace statements that have the\n        specified marker."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds a match for a file on a directory.", "response": "def matchFileOnDirPath(curpath, pathdir):\n    \"\"\"Find match for a file by slicing away its directory elements\n       from the front and replacing them with pathdir.  Assume that the\n       end of curpath is right and but that the beginning may contain\n       some garbage (or it may be short)\n       Overlaps are allowed:\n       e.g /tmp/fdjsklf/real/path/elements, /all/the/real/ =>\n       /all/the/real/path/elements (assuming that this combined\n       path exists)\n    \"\"\"\n    if os.path.exists(curpath):\n        return curpath\n    filedirs = curpath.split('/')[1:]\n    filename = filedirs[-1]\n    filedirs = filedirs[:-1]\n    if pathdir[-1] == '/':\n        pathdir = pathdir[:-1]\n    # assume absolute paths\n    pathdirs = pathdir.split('/')[1:]\n    lp = len(pathdirs)\n    # Cut off matching file elements from the ends of the two paths\n    for x in range(1, min(len(filedirs), lp)):\n        # XXX this will not work if you have\n        # /usr/foo/foo/filename.py\n        if filedirs[-1] == pathdirs[-x]:\n            filedirs = filedirs[:-1]\n        else:\n            break\n\n    # Now cut try cuting off incorrect initial elements of curpath\n    while filedirs:\n        tmppath = '/' + '/'.join(pathdirs + filedirs + [filename])\n        if os.path.exists(tmppath):\n            return tmppath\n        filedirs = filedirs[1:]\n    tmppath = '/' + '/'.join(pathdirs + [filename])\n    if os.path.exists(tmppath):\n        return tmppath\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lookupmodule(self, filename):\n        if os.path.isabs(filename) and os.path.exists(filename):\n            return filename\n        f = os.path.join(sys.path[0], filename)\n        if os.path.exists(f) and self.canonic(f) == self.mainpyfile:\n            return f\n        root, ext = os.path.splitext(filename)\n        origFileName = filename\n        if ext == '':\n            filename = filename + '.py'\n        if os.path.isabs(filename):\n            return filename\n        for dirname in sys.path:\n            while os.path.islink(dirname):\n                dirname = os.path.realpath(os.path.join(\n                    os.path.dirname(dirname),\n                    os.readlink(dirname)))\n            fullname = os.path.join(dirname, filename)\n            if os.path.exists(fullname):\n                return fullname\n        if origFileName in sys.modules:\n            return sys.modules[origFileName].__file__\n        return None", "response": "This function translates a file name into an absolute file name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_trace_cond(klass, marker='default', cond=None):\n        tc = klass.trace_counts\n        tc[marker] = [cond, 0]", "response": "Sets a condition for set_trace statements that have the\n            specified marker."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_trace(self, skip=0):\n        frame = sys._getframe().f_back\n        # go up the specified number of frames\n        for i in range(skip):\n            frame = frame.f_back\n        self.reset()\n        while frame:\n            frame.f_trace = self.trace_dispatch\n            self.botframe = frame\n            frame = frame.f_back\n        self.set_step()\n        sys.settrace(self.trace_dispatch)", "response": "Start debugging from here."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef user_exception(self, frame, exc_info):\n        pdb.Pdb.user_exception(self, frame, exc_info)", "response": "This function is called if an exception occurs and only if we are at the top level of this level."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a chain of traceback or frame objects into a list of frames.", "response": "def stackToList(stack):\n    \"\"\"\n    Convert a chain of traceback or frame objects into a list of frames.\n    \"\"\"\n    if isinstance(stack, types.TracebackType):\n        while stack.tb_next:\n            stack = stack.tb_next\n        stack = stack.tb_frame\n    out = []\n    while stack:\n        out.append(stack)\n        stack = stack.f_back\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread in and parse IAC commands as passed by telnetlib. SB/SE commands are stored in sbdataq, and passed in w/ a command of SE.", "response": "def process_IAC(self, sock, cmd, option):\n        \"\"\"\n            Read in and parse IAC commands as passed by telnetlib.\n\n            SB/SE commands are stored in sbdataq, and passed in w/ a command\n            of SE.\n        \"\"\"\n        if cmd == DO:\n            if option == TM:\n                # timing mark - send WILL into outgoing stream\n                os.write(self.remote, IAC + WILL + TM)\n            else:\n                pass\n        elif cmd == IP:\n            # interrupt process\n            os.write(self.local, IPRESP)\n        elif cmd == SB:\n            pass\n        elif cmd == SE:\n            option = self.sbdataq[0]\n            if option == NAWS[0]:\n                # negotiate window size.\n                cols = six.indexbytes(self.sbdataq, 1)\n                rows = six.indexbytes(self.sbdataq, 2)\n                s = struct.pack('HHHH', rows, cols, 0, 0)\n                fcntl.ioctl(self.local, termios.TIOCSWINSZ, s)\n        elif cmd == DONT:\n            pass\n        else:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle(self):\n        while True:\n            toRead = select.select([self.local, self.remote], [], [], 0.1)[0]\n            if self.local in toRead:\n                data = os.read(self.local, 4096)\n                self.sock.sendall(data)\n                continue\n            if self.remote in toRead or self.rawq:\n                buf = self.read_eager()\n                os.write(self.local, buf)\n                continue", "response": "This method handles the local process."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle the current request.", "response": "def handle(self):\n        \"\"\"\n            Creates a child process that is fully controlled by this\n            request handler, and serves data to and from it via the\n            protocol handler.\n        \"\"\"\n        pid, fd = pty.fork()\n        if pid:\n            protocol = TelnetServerProtocolHandler(self.request, fd)\n            protocol.handle()\n        else:\n            self.execute()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_request(self):\n        try:\n            request, client_address = self.get_request()\n        except socket.error:\n            return\n        if self.verify_request(request, client_address):\n            try:\n                # we only serve once, and we want to free up the port\n                # for future serves.\n                self.socket.close()\n                self.process_request(request, client_address)\n            except SocketConnected as err:\n                self._serve_process(err.slaveFd, err.serverPid)\n                return\n            except Exception as err:\n                self.handle_error(request, client_address)\n                self.close_request()", "response": "Handle one request - serve current process to one connection."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nserving a process by connecting its outputs and inputs to the pty slaveFd.", "response": "def _serve_process(self, slaveFd, serverPid):\n        \"\"\"\n            Serves a process by connecting its outputs/inputs to the pty\n            slaveFd.  serverPid is the process controlling the master fd\n            that passes that output over the socket.\n        \"\"\"\n        self.serverPid = serverPid\n        if sys.stdin.isatty():\n            self.oldTermios = termios.tcgetattr(sys.stdin.fileno())\n        else:\n            self.oldTermios = None\n        self.oldStderr = SavedFile(2, sys, 'stderr')\n        self.oldStdout = SavedFile(1, sys, 'stdout')\n        self.oldStdin = SavedFile(0, sys, 'stdin')\n        self.oldStderr.save(slaveFd, mode=\"w\")\n        self.oldStdout.save(slaveFd, mode=\"w\")\n        self.oldStdin.save(slaveFd, mode=\"r\")\n        os.close(slaveFd)\n        self.closed = False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nasks a user for an integer between two values.", "response": "def int_input(message, low, high, show_range = True):\n    '''\n    Ask a user for a int input between two values\n\n    args:\n        message (str): Prompt for user\n        low (int): Low value, user entered value must be > this value to be accepted\n        high (int): High value, user entered value must be < this value to be accepted\n        show_range (boolean, Default True): Print hint to user the range\n\n    returns:\n        int_in (int): Input integer\n    '''\n\n    int_in = low - 1\n    while (int_in < low) or (int_in > high):\n        if show_range:\n            suffix = ' (integer between ' + str(low) + ' and ' + str(high) + ')'\n        else:\n            suffix = ''\n        inp = input('Enter a ' + message + suffix + ': ')\n        if re.match('^-?[0-9]+$', inp) is not None:\n            int_in = int(inp)\n        else:\n            print(colored('Must be an integer, try again!', 'red'))\n    return int_in"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nasks a user for a float input between two values.", "response": "def float_input(message, low, high):\n    '''\n    Ask a user for a float input between two values\n\n    args:\n        message (str): Prompt for user\n        low (float): Low value, user entered value must be > this value to be accepted\n        high (float): High value, user entered value must be < this value to be accepted\n\n    returns:\n        float_in (int): Input float\n    '''\n\n    float_in = low - 1.0\n    while (float_in < low) or (float_in > high):\n        inp = input('Enter a ' + message + ' (float between ' + str(low) + ' and ' + str(high) + '): ')\n        if re.match('^([0-9]*[.])?[0-9]+$', inp) is not None:\n            float_in = float(inp)\n        else:\n            print(colored('Must be a float, try again!', 'red'))\n    return float_in"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bool_input(message):\n    '''\n    Ask a user for a boolean input\n\n    args:\n        message (str): Prompt for user\n\n    returns:\n        bool_in (boolean): Input boolean\n    '''\n\n    while True:\n        suffix = ' (true or false): '\n        inp = input(message + suffix)\n        if inp.lower() == 'true':\n            return True\n        elif inp.lower() == 'false':\n            return False\n        else:\n            print(colored('Must be either true or false, try again!', 'red'))", "response": "Ask a user for a boolean input"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main(args = None):\n    '''\n    Main entry point for transfer command line tool.\n\n    This essentially will marshall the user to the functions they need.\n    '''\n\n    parser = argparse.ArgumentParser(description = 'Tool to perform transfer learning')\n\n    parser.add_argument('-c','--configure',\n                        action = 'store_true',\n                        help = 'Configure transfer')\n\n    parser.add_argument('-e','--export',\n                        action = 'store_true',\n                        dest = 'export_config',\n                        help = 'Export configuration and models')\n\n    parser.add_argument('-i','--import',\n                        action = 'store',\n                        type = str,\n                        default = None,\n                        dest = 'import_config',\n                        help = 'Import configuration and models')\n\n    parser.add_argument('-p','--project',\n                        action = 'store',\n                        type = str,\n                        default = None,\n                        dest = 'project',\n                        help = 'Specify a project, if not supplied it will be picked from configured projects')\n\n    parser.add_argument('-r','--run',\n                        action = 'store_true',\n                        help = 'Run all transfer learning operations')\n\n    parser.add_argument('-f','--final',\n                        action = 'store_true',\n                        help = 'Run final training on all layers: Warning SLOW!')\n\n    parser.add_argument('-l','--last-weights',\n                        action = 'store_true',\n                        dest = 'last',\n                        help = 'Restart from the last weights, rather than the best intermediate weights')\n\n    parser.add_argument('--predict',\n                        action = 'store',\n                        type = str,\n                        default = None,\n                        const = 'default',\n                        dest = 'predict',\n                        nargs='?',\n                        help = 'Predict model on file or directory')\n\n    parser.add_argument('--prediction-rest-api',\n                        action = 'store_true',\n                        dest = 'rest_api',\n                        help = 'Start rest api to make predictions on files or directories')\n\n    if len(sys.argv) == 1:\n        parser.print_help()\n        return\n\n    args = parser.parse_args()\n\n    if args.import_config is not None:\n        import_config(args.import_config)\n        return\n    elif args.export_config:\n        project = select_project(args.project)\n        weights = model_input(project)\n        ind = model_individual_input(project, weights)\n        export_config(project, weights, ind)\n        return\n    elif args.configure:\n        configure()\n        return\n    else:\n        project = select_project(args.project)\n\n    if args.run:\n\n        if project['is_array'] == False:\n            project = images_to_array(project)\n            update_config(project)\n\n        if project['is_augmented'] == False:\n            project = augment_arrays(project)\n            update_config(project)\n\n        if project['is_pre_model'] == False:\n            project = pre_model(project)\n            update_config(project)\n\n        project = train_model(project, final = args.final, last = args.last)\n        update_config(project)\n\n        print('')\n        print(colored('Completed modeling round: ' + str(project['model_round']), 'cyan'))\n        print('')\n        print('Best current model: ', colored(project['best_weights'], 'yellow'))\n        print('Last current model: ', colored(project['last_weights'], 'yellow'))\n        print('')\n        print('To further refine the model, run again with:')\n        print('')\n        print(colored('    transfer --run --project ' + project['name'], 'green'))\n        print('')\n        print('To make predictions:')\n        print('')\n        print(colored('    transfer --predict [optional dir or file] --project ' + project['name'], 'yellow'))\n        print('')\n\n    elif args.rest_api:\n        if project['server_weights'] is not None:\n            start_server(project, 'server_weights')\n\n        elif project['best_weights'] is not None:\n            weights = model_input(project)\n            start_server(project, weights)\n\n        else:\n            print('Model is not trained.  Please first run your project:')\n            print('')\n            print(colored('    transfer --run', 'green'))\n            print('')\n    elif args.predict is not None:\n        if args.predict == 'default':\n\n            completer = Completer()\n            readline.set_completer_delims('\\t')\n            readline.parse_and_bind('tab: complete')\n            readline.set_completer(completer.path_completer)\n            args.predict = str_input('Enter a path to file(s): ')\n        if project['server_weights'] is not None:\n            predict_model(project, 'server_weights', args.predict)\n\n        elif project['best_weights'] is not None:\n            weights = model_input(project)\n            print('Predicting on image(s) in: ', colored(args.predict, 'yellow'))\n            predict_model(project, weights, args.predict)\n\n        else:\n            print('Model is not trained.  Please first run your project:')\n            print('')\n            print(colored('    transfer --run', 'green'))\n            print('')", "response": "Entry point for the main function of the command line tool."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef configure():\n    '''\n    Configure the transfer environment and store\n    '''\n    completer = Completer()\n    readline.set_completer_delims('\\t')\n    readline.parse_and_bind('tab: complete')\n    readline.set_completer(completer.path_completer)\n\n    home = os.path.expanduser('~')\n    if os.path.isfile(os.path.join(home, '.transfer', 'config.yaml')):\n        with open(os.path.join(home, '.transfer', 'config.yaml'), 'r') as fp:\n            config = yaml.load(fp.read())\n    else:\n        config = []\n\n    project_name = input('Name your project: ')\n    existing_project = None\n    for project in config:\n        if project_name == project['name']:\n            existing_project = project_name\n    if existing_project is not None:\n        print(colored('Project ' + project_name + ' already exists', 'red'))\n        overwrite = str_input('Would you like to overwrite this project? (yes or no) ', ['yes', 'no'])\n        if overwrite == 'no':\n            return\n        else:\n            config = [project for project in config if project_name != project['name']]\n\n    image_path = os.path.expanduser(input('Select parent directory for your images: '))\n    path_unset = True\n    while path_unset:\n        project_path = os.path.expanduser(input('Select destination for your project: '))\n        if (project_path.find(image_path) == 0):\n            print('Project destination should not be same or within image directory!')\n        else:\n            path_unset = False\n\n    print('Select architecture:')\n    print('[0] resnet50')\n    print('[1] xception')\n    print('[2] inception_v3')\n    architecture = int_input('choice', 0, 2, show_range = False)\n    if architecture == 0:\n        arch = 'resnet50'\n        img_dim = 224\n        conv_dim = 7\n        final_cutoff = 80\n    elif architecture == 1:\n        arch = 'xception'\n        img_dim = 299\n        conv_dim = 10\n        final_cutoff = 80\n    else:\n        arch = 'inception_v3'\n        img_dim = 299\n        conv_dim = 8\n        final_cutoff = 80\n    api_port = int_input('port for local prediction API (suggested: 5000)', 1024, 49151)\n    kfold = int_input('number of folds to use (suggested: 5)', 3, 10)\n    kfold_every = bool_input('Fit a model for every fold? (if false, just fit one)')\n    print('Warning: if working on a remote computer, you may not be able to plot!')\n    plot_cm = bool_input('Plot a confusion matrix after training?')\n    batch_size = int_input('batch size (suggested: 8)', 1, 64)\n    learning_rate = float_input('learning rate (suggested: 0.001)', 0, 1)\n    learning_rate_decay = float_input('learning decay rate (suggested: 0.000001)', 0, 1)\n    cycle = int_input('number of cycles before resetting the learning rate (suggested: 3)', 1, 10)\n    num_rounds = int_input('number of rounds (suggested: 3)', 1, 100)\n    print('Select image resolution:')\n    print('[0] low (' + str(img_dim) + ' px)')\n    print('[1] mid (' + str(img_dim * 2) + ' px)')\n    print('[2] high (' + str(img_dim * 4) + ' px)')\n    img_resolution_index = int_input('choice', 0, 2, show_range = False)\n    if img_resolution_index == 0:\n        img_size = 1\n    elif img_resolution_index == 1:\n        img_size = 2\n    else:\n        img_size = 4\n    use_augmentation = str_input('Would you like to add image augmentation? (yes or no) ', ['yes', 'no'])\n    if use_augmentation == 'yes':\n        augmentations = select_augmentations()\n    else:\n        augmentations = None\n\n    project = {'name': project_name,\n               'img_path': image_path,\n               'path': project_path,\n               'plot': plot_cm,\n               'api_port': api_port,\n               'kfold': kfold,\n               'kfold_every': kfold_every,\n               'cycle': cycle,\n               'seed': np.random.randint(9999),\n               'batch_size': batch_size,\n               'learning_rate': learning_rate,\n               'learning_rate_decay': learning_rate_decay,\n               'final_cutoff': final_cutoff,\n               'rounds': num_rounds,\n               'img_size': img_size,\n               'augmentations': augmentations,\n               'architecture': arch,\n               'img_dim': img_dim,\n               'conv_dim': conv_dim,\n               'is_split': False,\n               'is_array': False,\n               'is_augmented': False,\n               'is_pre_model': False,\n               'is_final': False,\n               'model_round': 0,\n               'server_weights': None,\n               'last_weights': None,\n               'best_weights': None}\n\n    config.append(project)\n    store_config(config)\n    print('')\n    print(colored('Project configure saved!', 'cyan'))\n    print('')\n    print('To run project:')\n    print('')\n    print(colored('    transfer --run --project ' + project_name, 'green'))\n    print('or')\n    print(colored('    transfer -r -p ' + project_name, 'green'))", "response": "Configure the transfer environment and store the result in a new file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef configure_server():\n    '''\n    Configure the transfer environment and store\n    '''\n\n    home = os.path.expanduser('~')\n    if os.path.isfile(os.path.join(home, '.transfer', 'config.yaml')):\n        with open(os.path.join(home, '.transfer', 'config.yaml'), 'r') as fp:\n            config = yaml.load(fp.read())\n    else:\n        config = []\n\n    project_name = input('Name your project: ')\n    existing_project = None\n    for project in config:\n        if project_name == project['name']:\n            existing_project = project_name\n    if existing_project is not None:\n        print(colored('Project ' + project_name + ' already exists', 'red'))\n        overwrite = str_input('Would you like to overwrite this project? (yes or no) ', ['yes', 'no'])\n        if overwrite == 'no':\n            return\n        else:\n            config = [project for project in config if project_name != project['name']]\n\n    api_port = int_input('port for local prediction API (suggested: 5000)', 1024, 49151)\n    print('Select image resolution:')\n    print('[0] low (224 px)')\n    print('[1] mid (448 px)')\n    print('[2] high (896 px)')\n    img_resolution_index = int_input('choice', 0, 2, show_range = False)\n    if img_resolution_index == 0:\n        img_size = 1\n    elif img_resolution_index == 1:\n        img_size = 2\n    else:\n        img_size = 4\n    num_categories = int_input('number of image categories in your model', 0, 10000000)\n\n    weights = False\n    while weights == False:\n        server_weights = os.path.expanduser(input('Select weights file: '))\n        if os.path.isfile(server_weights):\n            weights = True\n        else:\n            print('Cannot find the weight file: ', server_weights)\n\n    project = {'name': project_name,\n               'api_port': api_port,\n               'img_size': img_size,\n               'number_categories': num_categories,\n               'server_weights': server_weights}\n\n    config.append(project)\n    store_config(config)\n    print('')\n    print(colored('Project configure saved!', 'cyan'))\n    print('')\n    print('To start the server:')\n    print('')\n    print(colored('    transfer --prediction-rest-api --project ' + project_name, 'green'))\n    print('or')\n    print(colored('    transfer --prediction-rest-api -p ' + project_name, 'green'))", "response": "Configure the server and store the current transfer environment and store the result in the store"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select_project(user_provided_project):\n    '''\n    Select a project from configuration to run transfer on\n\n    args:\n        user_provided_project (str): Project name that should match a project in the config\n\n    returns:\n        project (dict): Configuration settings for a user selected project\n\n    '''\n\n    home = os.path.expanduser('~')\n    if os.path.isfile(os.path.join(home, '.transfer', 'config.yaml')):\n        with open(os.path.join(home, '.transfer', 'config.yaml'), 'r') as fp:\n            projects = yaml.load(fp.read())\n        if len(projects) == 1:\n            project = projects[0]\n        else:\n            if user_provided_project in [project['name'] for project in projects]:\n                for inner_project in projects:\n                    if user_provided_project == inner_project['name']:\n                        project = inner_project\n            else:\n                print('Select your project')\n                for i, project in enumerate(projects):\n                    print('[' + str(i) + ']: ' + project['name'])\n                project_index = int_input('project', -1, len(projects), show_range = False)\n                project = projects[project_index]\n    else:\n        print('Transfer is not configured.')\n        print('Please run:')\n        print('')\n        print(colored('    transfer --configure', 'green'))\n        return\n\n    print(colored('Project selected: ' + project['name'], 'cyan'))\n    return project", "response": "Select a project from configuration to run transfer on"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef store_config(config, suffix = None):\n    '''\n    Store configuration\n\n    args:\n        config (list[dict]): configurations for each project\n    '''\n    home = os.path.expanduser('~')\n    if suffix is not None:\n        config_path = os.path.join(home, '.transfer', suffix)\n    else:\n        config_path = os.path.join(home, '.transfer')\n\n    os.makedirs(config_path, exist_ok = True)\n    with open(os.path.join(config_path, 'config.yaml'), 'w') as fp:\n        yaml.dump(config, fp)", "response": "Store configuration for each project\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_config(updated_project):\n    '''\n    Update project in configuration\n\n    args:\n        updated_project (dict): Updated project configuration values\n\n    '''\n\n    home = os.path.expanduser('~')\n    if os.path.isfile(os.path.join(home, '.transfer', 'config.yaml')):\n        with open(os.path.join(home, '.transfer', 'config.yaml'), 'r') as fp:\n            projects = yaml.load(fp.read())\n        replace_index = -1\n        for i, project in enumerate(projects):\n            if project['name'] == updated_project['name']:\n                replace_index = i\n\n        if replace_index > -1:\n            projects[replace_index] = updated_project\n            store_config(projects)\n        else:\n            print('Not saving configuration')\n            print(colored('Project: ' + updated_project['name'] + ' was not found in configured projects!', 'red'))\n\n    else:\n        print('Transfer is not configured.')\n        print('Please run:')\n        print('')\n        print(colored('    transfer --configure', 'cyan'))\n        return", "response": "Update project in configuration"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_symbols(self, symbols):\n        if len(symbols) != self.size:\n            raise TypeError(\"The number of symbols in the graph does not \"\n                \"match the length of the atomic numbers array.\")\n        for symbol in symbols:\n            if not isinstance(symbol, str):\n                raise TypeError(\"All symbols must be strings.\")", "response": "Checks that the given array of atomic numbers is a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing a MolecularGraph object from a Molecule object.", "response": "def from_geometry(cls, molecule, do_orders=False, scaling=1.0):\n        \"\"\"Construct a MolecularGraph object based on interatomic distances\n\n           All short distances are computed with the binning module and compared\n           with a database of bond lengths. Based on this comparison, bonded\n           atoms are detected.\n\n           Before marking a pair of atoms A and B as bonded, it is also checked\n           that there is no third atom C somewhat between A and B.\n           When an atom C exists that is closer to B (than A) and the angle\n           A-B-C is less than 45 degrees, atoms A and B are not bonded.\n           Similarly if C is closer to A (than B) and the angle B-A-C is less\n           then 45 degrees, A and B are not connected.\n\n           Argument:\n            | ``molecule``  --  The molecule to derive the graph from\n\n           Optional arguments:\n            | ``do_orders``  --  set to True to estimate the bond order\n            | ``scaling``  --  scale the threshold for the connectivity. increase\n                               this to 1.5 in case of transition states when a\n                               fully connected topology is required.\n        \"\"\"\n        from molmod.bonds import bonds\n\n        unit_cell = molecule.unit_cell\n        pair_search = PairSearchIntra(\n            molecule.coordinates,\n            bonds.max_length*bonds.bond_tolerance*scaling,\n            unit_cell\n        )\n\n        orders = []\n        lengths = []\n        edges = []\n\n        for i0, i1, delta, distance in pair_search:\n            bond_order = bonds.bonded(molecule.numbers[i0], molecule.numbers[i1], distance/scaling)\n            if bond_order is not None:\n                if do_orders:\n                    orders.append(bond_order)\n                lengths.append(distance)\n                edges.append((i0,i1))\n\n        if do_orders:\n            result = cls(edges, molecule.numbers, orders, symbols=molecule.symbols)\n        else:\n            result = cls(edges, molecule.numbers, symbols=molecule.symbols)\n\n        # run a check on all neighbors. if two bonds point in a direction that\n        # differs only by 45 deg. the longest of the two is discarded. the\n        # double loop over the neighbors is done such that the longest bonds\n        # are eliminated first\n        slated_for_removal = set([])\n        threshold = 0.5**0.5\n        for c, ns in result.neighbors.items():\n            lengths_ns = []\n            for n in ns:\n                delta = molecule.coordinates[n] - molecule.coordinates[c]\n                if unit_cell is not None:\n                    delta = unit_cell.shortest_vector(delta)\n                length = np.linalg.norm(delta)\n                lengths_ns.append([length, delta, n])\n            lengths_ns.sort(reverse=True, key=(lambda r: r[0]))\n            for i0, (length0, delta0, n0) in enumerate(lengths_ns):\n                for i1, (length1, delta1, n1) in enumerate(lengths_ns[:i0]):\n                    if length1 == 0.0:\n                        continue\n                    cosine = np.dot(delta0, delta1)/length0/length1\n                    if cosine > threshold:\n                        # length1 > length0\n                        slated_for_removal.add((c,n1))\n                        lengths_ns[i1][0] = 0.0\n        # construct a mask\n        mask = np.ones(len(edges), bool)\n        for i0, i1 in slated_for_removal:\n            edge_index = result.edge_index.get(frozenset([i0,i1]))\n            if edge_index is None:\n                raise ValueError('Could not find edge that has to be removed: %i %i' % (i0, i1))\n            mask[edge_index] = False\n        # actual removal\n        edges = [edges[i] for i in range(len(edges)) if mask[i]]\n        if do_orders:\n            bond_order = [bond_order[i] for i in range(len(bond_order)) if mask[i]]\n            result = cls(edges, molecule.numbers, orders)\n        else:\n            result = cls(edges, molecule.numbers)\n\n        lengths = [lengths[i] for i in range(len(lengths)) if mask[i]]\n        result.bond_lengths = np.array(lengths)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs a molecular graph from the blob representation", "response": "def from_blob(cls, s):\n        \"\"\"Construct a molecular graph from the blob representation\"\"\"\n        atom_str, edge_str = s.split()\n        numbers = np.array([int(s) for s in atom_str.split(\",\")])\n        edges = []\n        orders = []\n        for s in edge_str.split(\",\"):\n            i, j, o = (int(w) for w in s.split(\"_\"))\n            edges.append((i, j))\n            orders.append(o)\n        return cls(edges, numbers, np.array(orders))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_vertex_string(self, i):\n        number = self.numbers[i]\n        if number == 0:\n            return Graph.get_vertex_string(self, i)\n        else:\n            # pad with zeros to make sure that string sort is identical to number sort\n            return \"%03i\" % number", "response": "Return a string based on the atom number"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_edge_string(self, i):\n        order = self.orders[i]\n        if order == 0:\n            return Graph.get_edge_string(self, i)\n        else:\n            # pad with zeros to make sure that string sort is identical to number sort\n            return \"%03i\" % order", "response": "Return a string based on the bond order"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a subgraph of the current graph with the given subvertices.", "response": "def get_subgraph(self, subvertices, normalize=False):\n        \"\"\"Creates a subgraph of the current graph\n\n           See :meth:`molmod.graphs.Graph.get_subgraph` for more information.\n        \"\"\"\n        graph = Graph.get_subgraph(self, subvertices, normalize)\n        if normalize:\n            new_numbers = self.numbers[graph._old_vertex_indexes] # vertices do change\n        else:\n            new_numbers = self.numbers # vertices don't change!\n        if self.symbols is None:\n            new_symbols = None\n        elif normalize:\n            new_symbols = tuple(self.symbols[i] for i in graph._old_vertex_indexes)\n        else:\n            new_symbols = self.symbols\n        new_orders = self.orders[graph._old_edge_indexes]\n        result = MolecularGraph(graph.edges, new_numbers, new_orders, new_symbols)\n        if normalize:\n            result._old_vertex_indexes = graph._old_vertex_indexes\n        result._old_edge_indexes = graph._old_edge_indexes\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a molecular graph where hydrogens are added explicitely.", "response": "def add_hydrogens(self, formal_charges=None):\n        \"\"\"Returns a molecular graph where hydrogens are added explicitely\n\n           When the bond order is unknown, it assumes bond order one. If the\n           graph  has an attribute formal_charges, this routine will take it\n           into account when counting the number of hydrogens to be added. The\n           returned graph will also have a formal_charges attribute.\n\n           This routine only adds hydrogen atoms for a limited set of atoms from\n           the periodic system: B, C, N, O, F, Al, Si, P, S, Cl, Br.\n        \"\"\"\n\n        new_edges = list(self.edges)\n        counter = self.num_vertices\n        for i in range(self.num_vertices):\n            num_elec = self.numbers[i]\n            if formal_charges is not None:\n                num_elec -= int(formal_charges[i])\n            if num_elec >= 5 and num_elec <= 9:\n                num_hydrogen = num_elec - 10 + 8\n            elif num_elec >= 13 and num_elec <= 17:\n                num_hydrogen = num_elec - 18 + 8\n            elif num_elec == 35:\n                num_hydrogen = 1\n            else:\n                continue\n            if num_hydrogen > 4:\n                num_hydrogen = 8 - num_hydrogen\n            for n in self.neighbors[i]:\n                bo = self.orders[self.edge_index[frozenset([i, n])]]\n                if bo <= 0:\n                    bo = 1\n                num_hydrogen -= int(bo)\n            for j in range(num_hydrogen):\n                new_edges.append((i, counter))\n                counter += 1\n        new_numbers = np.zeros(counter, int)\n        new_numbers[:self.num_vertices] = self.numbers\n        new_numbers[self.num_vertices:] = 1\n        new_orders = np.zeros(len(new_edges), int)\n        new_orders[:self.num_edges] = self.orders\n        new_orders[self.num_edges:] = 1\n        result = MolecularGraph(new_edges, new_numbers, new_orders)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the next match can be a valid ( part of a ) ring.", "response": "def check_next_match(self, match, new_relations, subject_graph, one_match):\n        \"\"\"Check if the (onset for a) match can be a valid (part of a) ring\"\"\"\n        if not CustomPattern.check_next_match(self, match, new_relations, subject_graph, one_match):\n            return False\n        if self.strong:\n            # can this ever become a strong ring?\n            vertex1_start = match.forward[self.pattern_graph.central_vertex]\n            for vertex1 in new_relations.values():\n                paths = list(subject_graph.iter_shortest_paths(vertex1, vertex1_start))\n                if self.size % 2 == 0 and len(match) == self.size:\n                    if len(paths) != 2:\n                        #print \"NRingPattern.check_next_match: not strong a.1\"\n                        return False\n                    for path in paths:\n                        if len(path) != len(match)//2+1:\n                            #print \"NRingPattern.check_next_match: not strong a.2\"\n                            return False\n                else:\n                    if len(paths) != 1:\n                        #print \"NRingPattern.check_next_match: not strong b.1\"\n                        return False\n                    if len(paths[0]) != (len(match)+1)//2:\n                        #print \"NRingPattern.check_next_match: not strong b.2\"\n                        return False\n            #print \"RingPattern.check_next_match: no remarks\"\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef complete(self, match, subject_graph):\n        if not CustomPattern.complete(self, match, subject_graph):\n            return False\n        if self.strong:\n            # If the ring is not strong, return False\n            if self.size % 2 == 0:\n                # even ring\n                for i in range(self.size//2):\n                    vertex1_start = match.forward[i]\n                    vertex1_stop = match.forward[(i+self.size//2)%self.size]\n                    paths = list(subject_graph.iter_shortest_paths(vertex1_start, vertex1_stop))\n                    if len(paths) != 2:\n                        #print \"Even ring must have two paths between opposite vertices\"\n                        return False\n                    for path in paths:\n                        if len(path) != self.size//2+1:\n                            #print \"Paths between opposite vertices must half the size of the ring+1\"\n                            return False\n            else:\n                # odd ring\n                for i in range(self.size//2+1):\n                    vertex1_start = match.forward[i]\n                    vertex1_stop = match.forward[(i+self.size//2)%self.size]\n                    paths = list(subject_graph.iter_shortest_paths(vertex1_start, vertex1_stop))\n                    if len(paths) > 1:\n                        return False\n                    if len(paths[0]) != self.size//2+1:\n                        return False\n                    vertex1_stop = match.forward[(i+self.size//2+1)%self.size]\n                    paths = list(subject_graph.iter_shortest_paths(vertex1_start, vertex1_stop))\n                    if len(paths) > 1:\n                        return False\n                    if len(paths[0]) != self.size//2+1:\n                        return False\n        return True", "response": "Check the completeness of the ring match"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_kind(self, value):\n        if isinstance(value, float):\n            return 'f'\n        elif isinstance(value, int):\n            return 'i'\n        else:\n            raise ValueError(\"Only integer or floating point values can be stored.\")", "response": "Return the kind of the attribute"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dump(self, f, name):\n        # print the header line\n        value = self.get()\n        kind = self.get_kind(value)\n        print(\"% 40s  kind=%s  value=%s\" % (name, kind, value), file=f)", "response": "Write the attribute to a file - like object"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the value of the attribute", "response": "def get(self, copy=False):\n        \"\"\"Return the value of the attribute\"\"\"\n        array = getattr(self.owner, self.name)\n        if copy:\n            return array.copy()\n        else:\n            return array"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite the attribute to a file - like object", "response": "def dump(self, f, name):\n        \"\"\"Write the attribute to a file-like object\"\"\"\n        array = self.get()\n        # print the header line\n        print(\"% 40s  kind=%s  shape=(%s)\" % (\n            name,\n            array.dtype.kind,\n            \",\".join([str(int(size_axis)) for size_axis in array.shape]),\n        ), file=f)\n        # print the numbers\n        counter = 0\n        for value in array.flat:\n            counter += 1\n            print(\"% 20s\" % value, end=' ', file=f)\n            if counter % 4 == 0:\n                print(file=f)\n        if counter % 4 != 0:\n            print(file=f)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the array data from a file - like object", "response": "def load(self, f, skip):\n        \"\"\"Load the array data from a file-like object\"\"\"\n        array = self.get()\n        counter = 0\n        counter_limit = array.size\n        convert = array.dtype.type\n        while counter < counter_limit:\n            line = f.readline()\n            words = line.split()\n            for word in words:\n                if counter >= counter_limit:\n                    raise FileFormatError(\"Wrong array data: too many values.\")\n                if not skip:\n                    array.flat[counter] = convert(word)\n                counter += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _register(self, name, AttrCls):\n        if not issubclass(AttrCls, StateAttr):\n            raise TypeError(\"The second argument must a StateAttr instance.\")\n        if len(name) > 40:\n            raise ValueError(\"Name can count at most 40 characters.\")\n        self._fields[name] = AttrCls(self._owner, name)", "response": "Register a new attribute to take care of with dump and load\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary object with the registered fields and their values Optional rguments subset = list of names to restrict the number of fields in the result", "response": "def get(self, subset=None):\n        \"\"\"Return a dictionary object with the registered fields and their values\n\n           Optional rgument:\n            | ``subset``  --  a list of names to restrict the number of fields\n                              in the result\n        \"\"\"\n        if subset is None:\n            return dict((name, attr.get(copy=True)) for name, attr in self._fields.items())\n        else:\n            return dict((name, attr.get(copy=True)) for name, attr in self._fields.items() if name in subset)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nassign the data to the attributes of the current object based on a dictionary with the data to be assigned to .", "response": "def set(self, new_fields, subset=None):\n        \"\"\"Assign the registered fields based on a dictionary\n\n           Argument:\n            | ``new_fields``  --  the dictionary with the data to be assigned to\n                                  the attributes\n\n           Optional argument:\n            | ``subset``  --  a list of names to restrict the fields that are\n                              effectively overwritten\n        \"\"\"\n        for name in new_fields:\n            if name not in self._fields and (subset is None or name in subset):\n                raise ValueError(\"new_fields contains an unknown field '%s'.\" % name)\n        if subset is not None:\n            for name in subset:\n                if name not in self._fields:\n                    raise ValueError(\"name '%s' in subset is not a known field in self._fields.\" % name)\n                if name not in new_fields:\n                    raise ValueError(\"name '%s' in subset is not a known field in new_fields.\" % name)\n        if subset is None:\n            if len(new_fields) != len(self._fields):\n                raise ValueError(\"new_fields contains too many fields.\")\n        for name, attr in self._fields.items():\n            if name in subset:\n                attr.set(new_fields[name])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping the registered fields to a file", "response": "def dump(self, filename):\n        \"\"\"Dump the registered fields to a file\n\n           Argument:\n            | ``filename``  --  the file to write to\n        \"\"\"\n        with open(filename, \"w\") as f:\n            for name in sorted(self._fields):\n                self._fields[name].dump(f, name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _load_bond_data(self):\n\n        def read_units(unit_names):\n            \"\"\"convert unit_names into conversion factors\"\"\"\n            tmp = {\n                \"A\": units.angstrom,\n                \"pm\": units.picometer,\n                \"nm\": units.nanometer,\n            }\n            return [tmp[unit_name] for unit_name in unit_names]\n\n        def read_length(BOND_TYPE, words, col):\n            \"\"\"Read the bondlengths from a single line in the data file\"\"\"\n            nlow = int(words[2])\n            nhigh = int(words[3])\n            for i, conversion in zip(range((len(words) - 4) // 3), conversions):\n                word = words[col + 3 + i*3]\n                if word != 'NA':\n                    self.lengths[BOND_TYPE][frozenset([nlow, nhigh])] = float(word)*conversion\n                    return\n\n        with pkg_resources.resource_stream(__name__, 'data/bonds.csv') as f:\n            for line in f:\n                words = line.decode('utf-8').split()\n                if (len(words) > 0) and (words[0][0] != \"#\"):\n                    if words[0] == \"unit\":\n                        conversions = read_units(words[1:])\n                    else:\n                        read_length(BOND_SINGLE, words, 1)\n                        read_length(BOND_DOUBLE, words, 2)\n                        read_length(BOND_TRIPLE, words, 3)", "response": "Load the bond data from the given file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _approximate_unkown_bond_lengths(self):\n        dataset = self.lengths[BOND_SINGLE]\n        for n1 in periodic.iter_numbers():\n            for n2 in periodic.iter_numbers():\n                if n1 <= n2:\n                    pair = frozenset([n1, n2])\n                    atom1 = periodic[n1]\n                    atom2 = periodic[n2]\n                    #if (pair not in dataset) and hasattr(atom1, \"covalent_radius\") and hasattr(atom2, \"covalent_radius\"):\n                    if (pair not in dataset) and (atom1.covalent_radius is not None) and (atom2.covalent_radius is not None):\n                        dataset[pair] = (atom1.covalent_radius + atom2.covalent_radius)", "response": "Completes the bond length database with approximations based on VDW radii"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the estimated bond type that is bonded between two atom numbers n1 and n2.", "response": "def bonded(self, n1, n2, distance):\n        \"\"\"Return the estimated bond type\n\n           Arguments:\n            | ``n1``  --  the atom number of the first atom in the bond\n            | ``n2``  --  the atom number of the second atom the bond\n            | ``distance``  --  the distance between the two atoms\n\n           This method checks whether for the given pair of atom numbers, the\n           given distance corresponds to a certain bond length. The best\n           matching bond type will be returned. If the distance is a factor\n           ``self.bond_tolerance`` larger than a tabulated distance, the\n           algorithm will not relate them.\n        \"\"\"\n        if distance > self.max_length * self.bond_tolerance:\n            return None\n\n        deviation = 0.0\n        pair = frozenset([n1, n2])\n        result = None\n        for bond_type in bond_types:\n            bond_length = self.lengths[bond_type].get(pair)\n            if (bond_length is not None) and \\\n               (distance < bond_length * self.bond_tolerance):\n                if result is None:\n                    result = bond_type\n                    deviation = abs(bond_length - distance)\n                else:\n                    new_deviation = abs(bond_length - distance)\n                    if deviation > new_deviation:\n                        result = bond_type\n                        deviation = new_deviation\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the length of a bond between n1 and n2.", "response": "def get_length(self, n1, n2, bond_type=BOND_SINGLE):\n        \"\"\"Return the length of a bond between n1 and n2 of type bond_type\n\n           Arguments:\n            | ``n1``  --  the atom number of the first atom in the bond\n            | ``n2``  --  the atom number of the second atom the bond\n\n           Optional argument:\n            | ``bond_type``  --  the type of bond [default=BOND_SINGLE]\n\n           This is a safe method for querying a bond_length. If no answer can be\n           found, this get_length returns None.\n        \"\"\"\n        dataset = self.lengths.get(bond_type)\n        if dataset == None:\n            return None\n        return dataset.get(frozenset([n1, n2]))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing a 3D unit cell with the given parameters.", "response": "def from_parameters3(cls, lengths, angles):\n        \"\"\"Construct a 3D unit cell with the given parameters\n\n           The a vector is always parallel with the x-axis and they point in the\n           same direction. The b vector is always in the xy plane and points\n           towards the positive y-direction. The c vector points towards the\n           positive z-direction.\n        \"\"\"\n        for length in lengths:\n            if length <= 0:\n                raise ValueError(\"The length parameters must be strictly positive.\")\n        for angle in angles:\n            if angle <= 0 or angle >= np.pi:\n                raise ValueError(\"The angle parameters must lie in the range ]0 deg, 180 deg[.\")\n        del length\n        del angle\n\n        matrix = np.zeros((3, 3), float)\n\n        # first cell vector along x-axis\n        matrix[0, 0] = lengths[0]\n\n        # second cell vector in x-y plane\n        matrix[0, 1] = np.cos(angles[2])*lengths[1]\n        matrix[1, 1] = np.sin(angles[2])*lengths[1]\n\n        # Finding the third cell vector is slightly more difficult. :-)\n        # It works like this:\n        # The dot products of a with c, b with c and c with c are known. the\n        # vector a has only an x component, b has no z component. This results\n        # in the following equations:\n        u_a = lengths[0]*lengths[2]*np.cos(angles[1])\n        u_b = lengths[1]*lengths[2]*np.cos(angles[0])\n        matrix[0, 2] = u_a/matrix[0, 0]\n        matrix[1, 2] = (u_b - matrix[0, 1]*matrix[0, 2])/matrix[1, 1]\n        u_c = lengths[2]**2 - matrix[0, 2]**2 - matrix[1, 2]**2\n        if u_c < 0:\n            raise ValueError(\"The given cell parameters do not correspond to a unit cell.\")\n        matrix[2, 2] = np.sqrt(u_c)\n\n        active = np.ones(3, bool)\n        return cls(matrix, active)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef active_inactive(self):\n        active_indices = []\n        inactive_indices = []\n        for index, active in enumerate(self.active):\n            if active:\n                active_indices.append(index)\n            else:\n                inactive_indices.append(index)\n        return active_indices, inactive_indices", "response": "The indexes of the active and inactive cell vectors"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reciprocal(self):\n        U, S, Vt = np.linalg.svd(self.matrix*self.active)\n        Sinv = np.zeros(S.shape, float)\n        for i in range(3):\n            if abs(S[i]) < self.eps:\n                Sinv[i] = 0.0\n            else:\n                Sinv[i] = 1.0/S[i]\n        return np.dot(U*Sinv, Vt)*self.active", "response": "The reciprocal of the unit cell."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the rotation matrix that aligns the unit cell with the the Cartesian axes starting with cell vector a.", "response": "def alignment_a(self):\n        \"\"\"Computes the rotation matrix that aligns the unit cell with the\n           Cartesian axes, starting with cell vector a.\n\n           * a parallel to x\n           * b in xy-plane with b_y positive\n           * c with c_z positive\n        \"\"\"\n        from molmod.transformations import Rotation\n        new_x = self.matrix[:, 0].copy()\n        new_x /= np.linalg.norm(new_x)\n        new_z = np.cross(new_x, self.matrix[:, 1])\n        new_z /= np.linalg.norm(new_z)\n        new_y = np.cross(new_z, new_x)\n        new_y /= np.linalg.norm(new_y)\n        return Rotation(np.array([new_x, new_y, new_z]))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef spacings(self):\n        result_invsq = (self.reciprocal**2).sum(axis=0)\n        result = np.zeros(3, float)\n        for i in range(3):\n            if result_invsq[i] > 0:\n                result[i] = result_invsq[i]**(-0.5)\n        return result", "response": "Computes the distances between neighboring crystal planes"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new unit cell with an additional cell vector.", "response": "def add_cell_vector(self, vector):\n        \"\"\"Returns a new unit cell with an additional cell vector\"\"\"\n        act = self.active_inactive[0]\n        if len(act) == 3:\n            raise ValueError(\"The unit cell already has three active cell vectors.\")\n        matrix = np.zeros((3, 3), float)\n        active = np.zeros(3, bool)\n        if len(act) == 0:\n            # Add the new vector\n            matrix[:, 0] = vector\n            active[0] = True\n            return UnitCell(matrix, active)\n\n        a = self.matrix[:, act[0]]\n        matrix[:, 0] = a\n        active[0] = True\n        if len(act) == 1:\n            # Add the new vector\n            matrix[:, 1] = vector\n            active[1] = True\n            return UnitCell(matrix, active)\n\n        b = self.matrix[:, act[1]]\n        matrix[:, 1] = b\n        active[1] = True\n        if len(act) == 2:\n            # Add the new vector\n            matrix[:, 2] = vector\n            active[2] = True\n            return UnitCell(matrix, active)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of indices of the interaction neighboring unit cells that have at least one point with a distance smaller than radius.", "response": "def get_radius_ranges(self, radius, mic=False):\n        \"\"\"Return ranges of indexes of the interacting neighboring unit cells\n\n           Interacting neighboring unit cells have at least one point in their\n           box volume that has a distance smaller or equal than radius to at\n           least one point in the central cell. This concept is of importance\n           when computing pair wise long-range interactions in periodic systems.\n\n           The mic (stands for minimum image convention) option can be used to\n           change the behavior of this routine such that only neighboring cells\n           are considered that have at least one point withing a distance below\n           `radius` from the center of the reference cell.\n        \"\"\"\n        result = np.zeros(3, int)\n        for i in range(3):\n            if self.spacings[i] > 0:\n                if mic:\n                    result[i] = np.ceil(radius/self.spacings[i]-0.5)\n                else:\n                    result[i] = np.ceil(radius/self.spacings[i])\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the indexes of the interaction neighboring unit cells that have at least one point in the central cell that has a distance smaller than radius to the central cell.", "response": "def get_radius_indexes(self, radius, max_ranges=None):\n        \"\"\"Return the indexes of the interacting neighboring unit cells\n\n           Interacting neighboring unit cells have at least one point in their\n           box volume that has a distance smaller or equal than radius to at\n           least one point in the central cell. This concept is of importance\n           when computing pair wise long-range interactions in periodic systems.\n\n           Argument:\n            | ``radius``  --  the radius of the interaction sphere\n\n           Optional argument:\n            | ``max_ranges``  --  numpy array with three elements: The maximum\n                                  ranges of indexes to consider. This is\n                                  practical when working with the minimum image\n                                  convention to reduce the generated bins to the\n                                  minimum image. (see binning.py) Use -1 to\n                                  avoid such limitations. The default is three\n                                  times -1.\n\n        \"\"\"\n        if max_ranges is None:\n            max_ranges = np.array([-1, -1, -1])\n        ranges = self.get_radius_ranges(radius)*2+1\n        mask = (max_ranges != -1) & (max_ranges < ranges)\n        ranges[mask] = max_ranges[mask]\n        max_size = np.product(self.get_radius_ranges(radius)*2 + 1)\n        indexes = np.zeros((max_size, 3), int)\n\n        from molmod.ext import unit_cell_get_radius_indexes\n        reciprocal = self.reciprocal*self.active\n        matrix = self.matrix*self.active\n        size = unit_cell_get_radius_indexes(\n            matrix, reciprocal, radius, max_ranges, indexes\n        )\n        return indexes[:size]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef guess_geometry(graph, unit_cell=None, verbose=False):\n\n    N = len(graph.numbers)\n    from molmod.minimizer import Minimizer, ConjugateGradient, \\\n        NewtonLineSearch, ConvergenceCondition, StopLossCondition\n\n    search_direction = ConjugateGradient()\n    line_search = NewtonLineSearch()\n    convergence = ConvergenceCondition(grad_rms=1e-6, step_rms=1e-6)\n    stop_loss = StopLossCondition(max_iter=500, fun_margin=0.1)\n\n    ff = ToyFF(graph, unit_cell)\n    x_init = np.random.normal(0, 1, N*3)\n\n    #  level 1 geometry optimization: graph based\n    ff.dm_quad = 1.0\n    minimizer = Minimizer(x_init, ff, search_direction, line_search, convergence, stop_loss, anagrad=True, verbose=verbose)\n    x_init = minimizer.x\n\n    #  level 2 geometry optimization: graph based + pauli repulsion\n    ff.dm_quad = 1.0\n    ff.dm_reci = 1.0\n    minimizer = Minimizer(x_init, ff, search_direction, line_search, convergence, stop_loss, anagrad=True, verbose=verbose)\n    x_init = minimizer.x\n\n    # Add a little noise to avoid saddle points\n    x_init += np.random.uniform(-0.01, 0.01, len(x_init))\n\n    #  level 3 geometry optimization: bond lengths + pauli\n    ff.dm_quad = 0.0\n    ff.dm_reci = 0.2\n    ff.bond_quad = 1.0\n    minimizer = Minimizer(x_init, ff, search_direction, line_search, convergence, stop_loss, anagrad=True, verbose=verbose)\n    x_init = minimizer.x\n\n    #  level 4 geometry optimization: bond lengths + bending angles + pauli\n    ff.bond_quad = 0.0\n    ff.bond_hyper = 1.0\n    ff.span_quad = 1.0\n    minimizer = Minimizer(x_init, ff, search_direction, line_search, convergence, stop_loss, anagrad=True, verbose=verbose)\n    x_init = minimizer.x\n\n    x_opt = x_init\n\n    mol = Molecule(graph.numbers, x_opt.reshape((N, 3)))\n    return mol", "response": "This routine tries to guess the molecular geometry based on a molecular graph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tune_geometry(graph, mol, unit_cell=None, verbose=False):\n\n    N = len(graph.numbers)\n    from molmod.minimizer import Minimizer, ConjugateGradient, \\\n        NewtonLineSearch, ConvergenceCondition, StopLossCondition\n\n    search_direction = ConjugateGradient()\n    line_search = NewtonLineSearch()\n    convergence = ConvergenceCondition(grad_rms=1e-6, step_rms=1e-6)\n    stop_loss = StopLossCondition(max_iter=500, fun_margin=1.0)\n\n    ff = ToyFF(graph, unit_cell)\n    x_init = mol.coordinates.ravel()\n\n    #  level 3 geometry optimization: bond lengths + pauli\n    ff.dm_reci = 0.2\n    ff.bond_quad = 1.0\n    minimizer = Minimizer(x_init, ff, search_direction, line_search, convergence, stop_loss, anagrad=True, verbose=verbose)\n    x_init = minimizer.x\n\n    #  level 4 geometry optimization: bond lengths + bending angles + pauli\n    ff.bond_quad = 0.0\n    ff.bond_hyper = 1.0\n    ff.span_quad = 1.0\n    minimizer = Minimizer(x_init, ff, search_direction, line_search, convergence, stop_loss, anagrad=True, verbose=verbose)\n    x_init = minimizer.x\n\n    x_opt = x_init\n\n    mol = Molecule(graph.numbers, x_opt.reshape((N, 3)))\n    return mol", "response": "Fine tune a molecular graph with a more accurate guess of the initial geometry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the coordinates and derived quantities of the system.", "response": "def update_coordinates(self, coordinates=None):\n        \"\"\"Update the coordinates (and derived quantities)\n\n           Argument:\n             coordinates  --  new Cartesian coordinates of the system\n        \"\"\"\n        if coordinates is not None:\n            self.coordinates = coordinates\n        self.numc = len(self.coordinates)\n        self.distances = np.zeros((self.numc, self.numc), float)\n        self.deltas = np.zeros((self.numc, self.numc, 3), float)\n        self.directions = np.zeros((self.numc, self.numc, 3), float)\n        self.dirouters = np.zeros((self.numc, self.numc, 3, 3), float)\n        for index1, coordinate1 in enumerate(self.coordinates):\n            for index2, coordinate2 in enumerate(self.coordinates):\n                delta = coordinate1 - coordinate2\n                self.deltas[index1, index2] = delta\n                distance = np.linalg.norm(delta)\n                self.distances[index1, index2] = distance\n                if index1 != index2:\n                    tmp = delta/distance\n                    self.directions[index1, index2] = tmp\n                    self.dirouters[index1, index2] = np.outer(tmp, tmp)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef energy(self):\n        result = 0.0\n        for index1 in range(self.numc):\n            for index2 in range(index1):\n                if self.scaling[index1, index2] > 0:\n                    for se, ve in self.yield_pair_energies(index1, index2):\n                        result += se*ve*self.scaling[index1, index2]\n        return result", "response": "Compute the energy of the system"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gradient_component(self, index1):\n        result = np.zeros(3, float)\n        for index2 in range(self.numc):\n            if self.scaling[index1, index2] > 0:\n                for (se, ve), (sg, vg) in zip(self.yield_pair_energies(index1, index2), self.yield_pair_gradients(index1, index2)):\n                    result += (sg*self.directions[index1, index2]*ve + se*vg)*self.scaling[index1, index2]\n        return result", "response": "Compute the gradient of the energy for one atom"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the gradient of the energy for all atoms", "response": "def gradient(self):\n        \"\"\"Compute the gradient of the energy for all atoms\"\"\"\n        result = np.zeros((self.numc, 3), float)\n        for index1 in range(self.numc):\n            result[index1] = self.gradient_component(index1)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the hessian of the energy for one atom pair", "response": "def hessian_component(self, index1, index2):\n        \"\"\"Compute the hessian of the energy for one atom pair\"\"\"\n        result = np.zeros((3, 3), float)\n        if index1 == index2:\n            for index3 in range(self.numc):\n                if self.scaling[index1, index3] > 0:\n                    d_1 = 1/self.distances[index1, index3]\n                    for (se, ve), (sg, vg), (sh, vh) in zip(\n                        self.yield_pair_energies(index1, index3),\n                        self.yield_pair_gradients(index1, index3),\n                        self.yield_pair_hessians(index1, index3)\n                    ):\n                        result += (\n                            +sh*self.dirouters[index1, index3]*ve\n                            +sg*(np.identity(3, float) - self.dirouters[index1, index3])*ve*d_1\n                            +sg*np.outer(self.directions[index1, index3],  vg)\n                            +sg*np.outer(vg, self.directions[index1, index3])\n                            +se*vh\n                        )*self.scaling[index1, index3]\n        elif self.scaling[index1, index2] > 0:\n            d_1 = 1/self.distances[index1, index2]\n            for (se, ve), (sg, vg), (sh, vh) in zip(\n                self.yield_pair_energies(index1, index2),\n                self.yield_pair_gradients(index1, index2),\n                self.yield_pair_hessians(index1, index2)\n            ):\n                result -= (\n                    +sh*self.dirouters[index1, index2]*ve\n                    +sg*(np.identity(3, float) - self.dirouters[index1, index2])*ve*d_1\n                    +sg*np.outer(self.directions[index1, index2],  vg)\n                    +sg*np.outer(vg, self.directions[index1, index2])\n                    +se*vh\n                )*self.scaling[index1, index2]\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hessian(self):\n        result = np.zeros((self.numc, 3, self.numc, 3), float)\n        for index1 in range(self.numc):\n            for index2 in range(self.numc):\n                result[index1, :, index2, :] = self.hessian_component(index1, index2)\n        return result", "response": "Compute the hessian of the energy of the user"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nyielding pairs of charges and dipoles.", "response": "def yield_pair_energies(self, index1, index2):\n        \"\"\"Yields pairs ((s(r_ij), v(bar{r}_ij))\"\"\"\n        d_1 = 1/self.distances[index1, index2]\n        if self.charges is not None:\n            c1 = self.charges[index1]\n            c2 = self.charges[index2]\n            yield c1*c2*d_1, 1\n        if self.dipoles is not None:\n            d_3 = d_1**3\n            d_5 = d_1**5\n            delta = self.deltas[index1, index2]\n            p1 = self.dipoles[index1]\n            p2 = self.dipoles[index2]\n            yield d_3*np.dot(p1, p2), 1\n            yield -3*d_5, np.dot(p1, delta)*np.dot(delta, p2)\n            if self.charges is not None:\n                yield c1*d_3, np.dot(p2, delta)\n                yield c2*d_3, np.dot(p1, -delta)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nyield pairs of gradients between two charges and dipoles.", "response": "def yield_pair_gradients(self, index1, index2):\n        \"\"\"Yields pairs ((s'(r_ij), grad_i v(bar{r}_ij))\"\"\"\n        d_2 = 1/self.distances[index1, index2]**2\n        if self.charges is not None:\n            c1 = self.charges[index1]\n            c2 = self.charges[index2]\n            yield -c1*c2*d_2, np.zeros(3)\n        if self.dipoles is not None:\n            d_4 = d_2**2\n            d_6 = d_2**3\n            delta = self.deltas[index1, index2]\n            p1 = self.dipoles[index1]\n            p2 = self.dipoles[index2]\n            yield -3*d_4*np.dot(p1, p2), np.zeros(3)\n            yield 15*d_6, p1*np.dot(p2, delta) + p2*np.dot(p1, delta)\n            if self.charges is not None:\n                yield -3*c1*d_4, p2\n                yield -3*c2*d_4, -p1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nyielding pairs of hessians.", "response": "def yield_pair_hessians(self, index1, index2):\n        \"\"\"Yields pairs ((s''(r_ij), grad_i (x) grad_i v(bar{r}_ij))\"\"\"\n        d_1 = 1/self.distances[index1, index2]\n        d_3 = d_1**3\n        if self.charges is not None:\n            c1 = self.charges[index1]\n            c2 = self.charges[index2]\n            yield 2*c1*c2*d_3, np.zeros((3, 3))\n        if self.dipoles is not None:\n            d_5 = d_1**5\n            d_7 = d_1**7\n            p1 = self.dipoles[index1]\n            p2 = self.dipoles[index2]\n            yield 12*d_5*np.dot(p1, p2), np.zeros((3, 3))\n            yield -90*d_7, np.outer(p1, p2) + np.outer(p2, p1)\n            if self.charges is not None:\n                yield 12*c1*d_5, np.zeros((3, 3))\n                yield 12*c2*d_5, np.zeros((3, 3))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef esp(self):\n        result = np.zeros(self.numc, float)\n        for index1 in range(self.numc):\n            result[index1] = self.esp_component(index1)\n        return result", "response": "Compute the electrostatic potential at each atom due to other atoms"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the electrostatic potential at each atom due to other atoms", "response": "def efield(self):\n        \"\"\"Compute the electrostatic potential at each atom due to other atoms\"\"\"\n        result = np.zeros((self.numc,3), float)\n        for index1 in range(self.numc):\n            result[index1] = self.efield_component(index1)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef yield_pair_energies(self, index1, index2):\n        strength = self.strengths[index1, index2]\n        distance = self.distances[index1, index2]\n        yield strength*distance**(-6), 1", "response": "Yields pairs of strength and distance"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields pairs of gradients", "response": "def yield_pair_gradients(self, index1, index2):\n        \"\"\"Yields pairs ((s'(r_ij), grad_i v(bar{r}_ij))\"\"\"\n        strength = self.strengths[index1, index2]\n        distance = self.distances[index1, index2]\n        yield -6*strength*distance**(-7), np.zeros(3)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nyield pairs of the energy between two sets of species.", "response": "def yield_pair_energies(self, index1, index2):\n        \"\"\"Yields pairs ((s(r_ij), v(bar{r}_ij))\"\"\"\n        A = self.As[index1, index2]\n        B = self.Bs[index1, index2]\n        distance = self.distances[index1, index2]\n        yield A*np.exp(-B*distance), 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef yield_pair_gradients(self, index1, index2):\n        A = self.As[index1, index2]\n        B = self.Bs[index1, index2]\n        distance = self.distances[index1, index2]\n        yield -B*A*np.exp(-B*distance), np.zeros(3)", "response": "Yields pairs of gradients"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the molecules from a CML file.", "response": "def load_cml(cml_filename):\n    \"\"\"Load the molecules from a CML file\n\n       Argument:\n        | ``cml_filename``  --  The filename of a CML file.\n\n       Returns a list of molecule objects with optional molecular graph\n       attribute and extra attributes.\n    \"\"\"\n    parser = make_parser()\n    parser.setFeature(feature_namespaces, 0)\n    dh = CMLMoleculeLoader()\n    parser.setContentHandler(dh)\n    parser.parse(cml_filename)\n    return dh.molecules"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _dump_cml_molecule(f, molecule):\n    extra = getattr(molecule, \"extra\", {})\n    attr_str = \" \".join(\"%s='%s'\" % (key, value) for key, value in extra.items())\n    f.write(\" <molecule id='%s' %s>\\n\" % (molecule.title, attr_str))\n    f.write(\"  <atomArray>\\n\")\n    atoms_extra = getattr(molecule, \"atoms_extra\", {})\n    for counter, number, coordinate in zip(range(molecule.size), molecule.numbers, molecule.coordinates/angstrom):\n        atom_extra = atoms_extra.get(counter, {})\n        attr_str = \" \".join(\"%s='%s'\" % (key, value) for key, value in atom_extra.items())\n        f.write(\"   <atom id='a%i' elementType='%s' x3='%s' y3='%s' z3='%s' %s />\\n\" % (\n            counter, periodic[number].symbol, coordinate[0],  coordinate[1],\n            coordinate[2], attr_str,\n        ))\n    f.write(\"  </atomArray>\\n\")\n    if molecule.graph is not None:\n        bonds_extra = getattr(molecule, \"bonds_extra\", {})\n        f.write(\"  <bondArray>\\n\")\n        for edge in molecule.graph.edges:\n            bond_extra = bonds_extra.get(edge, {})\n            attr_str = \" \".join(\"%s='%s'\" % (key, value) for key, value in bond_extra.items())\n            i1, i2 = edge\n            f.write(\"   <bond atomRefs2='a%i a%i' %s />\\n\" % (i1, i2, attr_str))\n        f.write(\"  </bondArray>\\n\")\n    f.write(\" </molecule>\\n\")", "response": "Dump a single molecule to a CML file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dump_cml(f, molecules):\n    if isinstance(f, str):\n        f = open(f, \"w\")\n        close = True\n    else:\n        close = False\n    f.write(\"<?xml version='1.0'?>\\n\")\n    f.write(\"<list xmlns='http://www.xml-cml.org/schema'>\\n\")\n    for molecule in molecules:\n        _dump_cml_molecule(f, molecule)\n    f.write(\"</list>\\n\")\n    if close:\n        f.close()", "response": "Dump a list of molecules to a CML file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the extra properties taking into account an exclude list", "response": "def _get_extra(self, attrs, exclude):\n        \"\"\"Read the extra properties, taking into account an exclude list\"\"\"\n        result = {}\n        for key in attrs.getNames():\n            if key not in exclude:\n                result[str(key)] = str(attrs[key])\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _read(self, filename, field_labels=None):\n        # if fields is None, all fields are read\n        def read_field(f):\n            \"\"\"Read a single field\"\"\"\n            datatype = None\n            while datatype is None:\n                # find a sane header line\n                line = f.readline()\n                if line == \"\":\n                    return False\n\n                label = line[:43].strip()\n                if field_labels is not None:\n                    if len(field_labels) == 0:\n                        return False\n                    elif label not in field_labels:\n                        return True\n                    else:\n                        field_labels.discard(label)\n                line = line[43:]\n                words = line.split()\n                if len(words) == 0:\n                    return True\n\n                if words[0] == 'I':\n                    datatype = int\n                    unreadable = 0\n                elif words[0] == 'R':\n                    datatype = float\n                    unreadable = np.nan\n\n            if len(words) == 2:\n                try:\n                    value = datatype(words[1])\n                except ValueError:\n                    return True\n            elif len(words) == 3:\n                if words[1] != \"N=\":\n                    raise FileFormatError(\"Unexpected line in formatted checkpoint file %s\\n%s\" % (filename, line[:-1]))\n                length = int(words[2])\n                value = np.zeros(length, datatype)\n                counter = 0\n                try:\n                    while counter < length:\n                        line = f.readline()\n                        if line == \"\":\n                            raise FileFormatError(\"Unexpected end of formatted checkpoint file %s\" % filename)\n                        for word in line.split():\n                            try:\n                                value[counter] = datatype(word)\n                            except (ValueError, OverflowError) as e:\n                                print('WARNING: could not interpret word while reading %s: %s' % (word, self.filename))\n                                if self.ignore_errors:\n                                    value[counter] = unreadable\n                                else:\n                                    raise\n                            counter += 1\n                except ValueError:\n                    return True\n            else:\n                raise FileFormatError(\"Unexpected line in formatted checkpoint file %s\\n%s\" % (filename, line[:-1]))\n\n            self.fields[label] = value\n            return True\n\n        self.fields = {}\n        with open(filename, 'r') as f:\n            self.title = f.readline()[:-1].strip()\n            words = f.readline().split()\n            if len(words) == 3:\n                self.command, self.lot, self.basis = words\n            elif len(words) == 2:\n                self.command, self.lot = words\n            else:\n                raise FileFormatError('The second line of the FCHK file should contain two or three words.')\n\n            while read_field(f):\n                pass", "response": "Read all the requested fields from a checkpoint file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a few elementary fields into a molecule object", "response": "def _analyze(self):\n        \"\"\"Convert a few elementary fields into a molecule object\"\"\"\n        if (\"Atomic numbers\" in self.fields) and (\"Current cartesian coordinates\" in self.fields):\n            self.molecule = Molecule(\n                self.fields[\"Atomic numbers\"],\n                np.reshape(self.fields[\"Current cartesian coordinates\"], (-1, 3)),\n                self.title,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the coordinates of the geometries at each point in the optimization", "response": "def get_optimization_coordinates(self):\n        \"\"\"Return the coordinates of the geometries at each point in the optimization\"\"\"\n        coor_array = self.fields.get(\"Opt point       1 Geometries\")\n        if coor_array is None:\n            return []\n        else:\n            return np.reshape(coor_array, (-1, len(self.molecule.numbers), 3))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_optimized_molecule(self):\n        opt_coor = self.get_optimization_coordinates()\n        if len(opt_coor) == 0:\n            return None\n        else:\n            return Molecule(\n                self.molecule.numbers,\n                opt_coor[-1],\n            )", "response": "Return a molecule object of the optimal geometry"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the energy gradients of all geometries during an optimization", "response": "def get_optimization_gradients(self):\n        \"\"\"Return the energy gradients of all geometries during an optimization\"\"\"\n        grad_array = self.fields.get(\"Opt point       1 Gradient at each geome\")\n        if grad_array is None:\n            return []\n        else:\n            return np.reshape(grad_array, (-1, len(self.molecule.numbers), 3))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the hessian of the current molecule", "response": "def get_hessian(self):\n        \"\"\"Return the hessian\"\"\"\n        force_const = self.fields.get(\"Cartesian Force Constants\")\n        if force_const is None:\n            return None\n        N = len(self.molecule.numbers)\n        result = np.zeros((3*N, 3*N), float)\n        counter = 0\n        for row in range(3*N):\n            result[row, :row+1] = force_const[counter:counter+row+1]\n            result[:row+1, row] = force_const[counter:counter+row+1]\n            counter += row + 1\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a copy of this object with the specified attributes changed.", "response": "def copy_with(self, **kwargs):\n        \"\"\"Return a copy with (a few) changed attributes\n\n           The keyword arguments are the attributes to be replaced by new\n           values. All other attributes are copied (or referenced) from the\n           original object. This only works if the constructor takes all\n           (read-only) attributes as arguments.\n        \"\"\"\n        attrs = {}\n        for key, descriptor in self.__class__.__dict__.items():\n            if isinstance(descriptor, ReadOnlyAttribute):\n                attrs[key] = descriptor.__get__(self)\n        for key in kwargs:\n            if key not in attrs:\n                raise TypeError(\"Unknown attribute: %s\" % key)\n        attrs.update(kwargs)\n        return self.__class__(**attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a single entry from the file.", "response": "def read(self, line, f, data):\n        \"\"\"See :meth:`PunchParser.read`\"\"\"\n        self.used = True\n        data[\"title\"] = f.readline().strip()\n        data[\"symmetry\"] = f.readline().split()[0]\n        if data[\"symmetry\"] != \"C1\":\n            raise NotImplementedError(\"Only C1 symmetry is supported.\")\n        symbols = []\n        while line != \" $END      \\n\":\n            line = f.readline()\n            if line[0] != \" \":\n                symbols.append(line.split()[0])\n        data[\"symbols\"] = symbols"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(self, line, f, data):\n        f.readline()\n        f.readline()\n        N = len(data[\"symbols\"])\n        # if the data are already read before, just overwrite them\n        numbers = data.get(\"numbers\")\n        if numbers is None:\n            numbers = np.zeros(N, int)\n            data[\"numbers\"] = numbers\n        coordinates = data.get(\"coordinates\")\n        if coordinates is None:\n            coordinates = np.zeros((N,3), float)\n            data[\"coordinates\"] = coordinates\n        for i in range(N):\n            words = f.readline().split()\n            numbers[i] = int(float(words[1]))\n            coordinates[i,0] = float(words[2])*angstrom\n            coordinates[i,1] = float(words[3])*angstrom\n            coordinates[i,2] = float(words[4])*angstrom", "response": "Read the untested version of the log file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread the energy and gradient from a Punch file.", "response": "def read(self, line, f, data):\n        \"\"\"See :meth:`PunchParser.read`\"\"\"\n        data[\"energy\"] = float(f.readline().split()[1])\n        N = len(data[\"symbols\"])\n        # if the data are already read before, just overwrite them\n        gradient = data.get(\"gradient\")\n        if gradient is None:\n            gradient = np.zeros((N,3), float)\n            data[\"gradient\"] = gradient\n        for i in range(N):\n            words = f.readline().split()\n            gradient[i,0] = float(words[2])\n            gradient[i,1] = float(words[3])\n            gradient[i,2] = float(words[4])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a single HESS or ALM.", "response": "def read(self, line, f, data):\n        \"\"\"See :meth:`PunchParser.read`\"\"\"\n        line = f.readline()\n        assert(line == \" $HESS\\n\")\n        while line != \" $END\\n\":\n            line = f.readline()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self, line, f, data):\n        assert(\"hessian\" not in data)\n        f.readline()\n        N = len(data[\"symbols\"])\n        hessian = np.zeros((3*N, 3*N), float)\n        tmp = hessian.ravel()\n        counter = 0\n        while True:\n            line = f.readline()\n            if line == \" $END\\n\":\n                break\n            line = line[5:-1]\n            for j in range(len(line)//15):\n                tmp[counter] = float(line[j*15:(j+1)*15])\n                counter += 1\n        data[\"hessian\"] = hessian", "response": "Read a single entry from the Punch file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the masses from a Punch file.", "response": "def read(self, line, f, data):\n        \"\"\"See :meth:`PunchParser.read`\"\"\"\n        N = len(data[\"symbols\"])\n        masses = np.zeros(N, float)\n        counter = 0\n        while counter < N:\n            words = f.readline().split()\n            for word in words:\n                masses[counter] = float(word)*amu\n                counter += 1\n        data[\"masses\"] = masses"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setup_hydrocarbon_ff(graph):\n    # A) Define parameters.\n    # the bond parameters:\n    bond_params = {\n        (6, 1): 310*kcalmol/angstrom**2,\n        (6, 6): 220*kcalmol/angstrom**2,\n    }\n    # for every (a, b), also add (b, a)\n    for key, val in list(bond_params.items()):\n        if key[0] != key[1]:\n            bond_params[(key[1], key[0])] = val\n    # the bend parameters\n    bend_params = {\n        (1, 6, 1): 35*kcalmol/rad**2,\n        (1, 6, 6): 30*kcalmol/rad**2,\n        (6, 6, 6): 60*kcalmol/rad**2,\n    }\n    # for every (a, b, c), also add (c, b, a)\n    for key, val in list(bend_params.items()):\n        if key[0] != key[2]:\n            bend_params[(key[2], key[1], key[0])] = val\n\n    # B) detect all internal coordinates and corresponding energy terms.\n    terms = []\n    # bonds\n    for i0, i1 in graph.edges:\n        K = bond_params[(graph.numbers[i0], graph.numbers[i1])]\n        terms.append(BondStretchTerm(K, i0, i1))\n    # bends (see b_bending_angles.py for the explanation)\n    for i1 in range(graph.num_vertices):\n        n = list(graph.neighbors[i1])\n        for index, i0 in enumerate(n):\n            for i2 in n[:index]:\n                K = bend_params[(graph.numbers[i0], graph.numbers[i1], graph.numbers[i2])]\n                terms.append(BendAngleTerm(K, i0, i1, i2))\n\n    # C) Create and return the force field\n    return ForceField(terms)", "response": "Create a simple ForceField object for hydrocarbons based on the graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd the contributions of this energy term to the Hessian.", "response": "def add_to_hessian(self, coordinates, hessian):\n        \"\"\"Add the contributions of this energy term to the Hessian\n\n           Arguments:\n            | ``coordinates`` -- A numpy array with 3N Cartesian coordinates.\n            | ``hessian`` -- A matrix for the full Hessian to which this energy\n                             term has to add its contribution.\n        \"\"\"\n        # Compute the derivatives of the bond stretch towards the two cartesian\n        # coordinates. The bond length is computed too, but not used.\n        q, g = self.icfn(coordinates[list(self.indexes)], 1)\n        # Add the contribution to the Hessian (an outer product)\n        for ja, ia in enumerate(self.indexes):\n            # ja is 0, 1, 2, ...\n            # ia is i0, i1, i2, ...\n            for jb, ib in enumerate(self.indexes):\n                contrib = 2*self.force_constant*numpy.outer(g[ja], g[jb])\n                hessian[3*ia:3*ia+3, 3*ib:3*ib+3] += contrib"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hessian(self, coordinates):\n        # N3 is 3 times the number of atoms.\n        N3 = coordinates.size\n        # Start with a zero hessian.\n        hessian = numpy.zeros((N3,N3), float)\n        # Add the contribution of each term.\n        for term in self.terms:\n            term.add_to_hessian(coordinates, hessian)\n        return hessian", "response": "Compute the force - field Hessian for the given coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_rotsym(molecule, graph, threshold=1e-3*angstrom):\n    result = 0\n    for match in graph.symmetries:\n        permutation = list(j for i,j in sorted(match.forward.items()))\n        new_coordinates = molecule.coordinates[permutation]\n        rmsd = fit_rmsd(molecule.coordinates, new_coordinates)[2]\n        if rmsd < threshold:\n            result += 1\n    return result", "response": "Compute the rotational symmetry number of the given molecule and graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef quaternion_product(quat1, quat2):\n    return np.array([\n        quat1[0]*quat2[0] - np.dot(quat1[1:], quat2[1:]),\n        quat1[0]*quat2[1] + quat2[0]*quat1[1] + quat1[2]*quat2[3] - quat1[3]*quat2[2],\n        quat1[0]*quat2[2] + quat2[0]*quat1[2] + quat1[3]*quat2[1] - quat1[1]*quat2[3],\n        quat1[0]*quat2[3] + quat2[0]*quat1[3] + quat1[1]*quat2[2] - quat1[2]*quat2[1]\n    ], float)", "response": "Return the quaternion product of the two arguments"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\napplies the rotation represented by the quaternion to the vector", "response": "def quaternion_rotation(quat, vector):\n    \"\"\"Apply the rotation represented by the quaternion to the vector\n\n       Warning: This only works correctly for normalized quaternions.\n    \"\"\"\n    dp = np.dot(quat[1:], vector)\n    cos = (2*quat[0]*quat[0] - 1)\n    return np.array([\n        2 * (quat[0] * (quat[2] * vector[2] - quat[3] * vector[1]) + quat[1] * dp) + cos * vector[0],\n        2 * (quat[0] * (quat[3] * vector[0] - quat[1] * vector[2]) + quat[2] * dp) + cos * vector[1],\n        2 * (quat[0] * (quat[1] * vector[1] - quat[2] * vector[0]) + quat[3] * dp) + cos * vector[2]\n    ], float)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rotation_matrix_to_quaternion(rotation_matrix):\n    invert = (np.linalg.det(rotation_matrix) < 0)\n    if invert:\n        factor = -1\n    else:\n        factor = 1\n    c2 = 0.25*(factor*np.trace(rotation_matrix) + 1)\n    if c2 < 0:\n        #print c2\n        c2 = 0.0\n    c = np.sqrt(c2)\n    r2 = 0.5*(1 + factor*np.diagonal(rotation_matrix)) - c2\n    #print \"check\", r2.sum()+c2\n    r = np.zeros(3, float)\n    for index, r2_comp in enumerate(r2):\n        if r2_comp < 0:\n            continue\n        else:\n            row, col = off_diagonals[index]\n            if (rotation_matrix[row, col] - rotation_matrix[col, row] < 0):\n                r[index] = -np.sqrt(r2_comp)\n            else:\n                r[index] = +np.sqrt(r2_comp)\n    return factor, np.array([c, r[0], r[1], r[2]], float)", "response": "Compute the quaternion representing the rotation given by the matrix"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the rotation matrix representated by the quaternion", "response": "def quaternion_to_rotation_matrix(quaternion):\n    \"\"\"Compute the rotation matrix representated by the quaternion\"\"\"\n    c, x, y, z = quaternion\n    return np.array([\n        [c*c + x*x - y*y - z*z, 2*x*y - 2*c*z,         2*x*z + 2*c*y        ],\n        [2*x*y + 2*c*z,         c*c - x*x + y*y - z*z, 2*y*z - 2*c*x        ],\n        [2*x*z - 2*c*y,         2*y*z + 2*c*x,         c*c - x*x - y*y + z*z]\n    ], float)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cosine(a, b):\n    result = np.dot(a, b) / np.linalg.norm(a) / np.linalg.norm(b)\n    return np.clip(result, -1, 1)", "response": "Compute the cosine between two vectors\n\nuggers"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef random_unit(size=3):\n    while True:\n        result = np.random.normal(0, 1, size)\n        length = np.linalg.norm(result)\n        if length > 1e-3:\n            return result/length", "response": "Return a random unit vector of the given dimension"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a random normalized vector orthogonal to the given vector", "response": "def random_orthonormal(normal):\n    \"\"\"Return a random normalized vector orthogonal to the given vector\"\"\"\n    u = normal_fns[np.argmin(np.fabs(normal))](normal)\n    u /= np.linalg.norm(u)\n    v = np.cross(normal, u)\n    v /= np.linalg.norm(v)\n    alpha = np.random.uniform(0.0, np.pi*2)\n    return np.cos(alpha)*u + np.sin(alpha)*v"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef triangle_normal(a, b, c):\n    normal = np.cross(a - c, b - c)\n    norm = np.linalg.norm(normal)\n    return normal/norm", "response": "Return a vector orthogonal to the given triangle"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dot(r1, r2):\n    if r1.size != r2.size:\n        raise ValueError(\"Both arguments must have the same input size.\")\n    if r1.deriv != r2.deriv:\n        raise ValueError(\"Both arguments must have the same deriv.\")\n    return r1.x*r2.x + r1.y*r2.y + r1.z*r2.z", "response": "Compute the dot product of two Vector3 objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the cross product of two Vector3 objects.", "response": "def cross(r1, r2):\n    \"\"\"Compute the cross product\n\n       Arguments:\n        | ``r1``, ``r2``  -- two :class:`Vector3` objects\n\n       (Returns a Vector3)\n    \"\"\"\n    if r1.size != r2.size:\n        raise ValueError(\"Both arguments must have the same input size.\")\n    if r1.deriv != r2.deriv:\n        raise ValueError(\"Both arguments must have the same deriv.\")\n    result = Vector3(r1.size, r1.deriv)\n    result.x = r1.y*r2.z - r1.z*r2.y\n    result.y = r1.z*r2.x - r1.x*r2.z\n    result.z = r1.x*r2.y - r1.y*r2.x\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _opbend_transform_mean(rs, fn_low, deriv=0):\n    v = 0.0\n    d = np.zeros((4,3), float)\n    dd = np.zeros((4,3,4,3), float)\n    #loop over the 3 cyclic permutations\n    for p in np.array([[0,1,2], [2,0,1], [1,2,0]]):\n        opbend = _opbend_transform([rs[p[0]], rs[p[1]], rs[p[2]], rs[3]], fn_low, deriv)\n        v += opbend[0]/3\n        index0 = np.where(p==0)[0][0] #index0 is the index of the 0th atom (rs[0])\n        index1 = np.where(p==1)[0][0]\n        index2 = np.where(p==2)[0][0]\n        index3 = 3\n        if deriv>0:\n            d[0] += opbend[1][index0]/3\n            d[1] += opbend[1][index1]/3\n            d[2] += opbend[1][index2]/3\n            d[3] += opbend[1][index3]/3\n        if deriv>1:\n            dd[0, :, 0, :] += opbend[2][index0, :, index0, :]/3\n            dd[0, :, 1, :] += opbend[2][index0, :, index1, :]/3\n            dd[0, :, 2, :] += opbend[2][index0, :, index2, :]/3\n            dd[0, :, 3, :] += opbend[2][index0, :, index3, :]/3\n\n            dd[1, :, 0, :] += opbend[2][index1, :, index0, :]/3\n            dd[1, :, 1, :] += opbend[2][index1, :, index1, :]/3\n            dd[1, :, 2, :] += opbend[2][index1, :, index2, :]/3\n            dd[1, :, 3, :] += opbend[2][index1, :, index3, :]/3\n\n            dd[2, :, 0, :] += opbend[2][index2, :, index0, :]/3\n            dd[2, :, 1, :] += opbend[2][index2, :, index1, :]/3\n            dd[2, :, 2, :] += opbend[2][index2, :, index2, :]/3\n            dd[2, :, 3, :] += opbend[2][index2, :, index3, :]/3\n\n            dd[3, :, 0, :] += opbend[2][index3, :, index0, :]/3\n            dd[3, :, 1, :] += opbend[2][index3, :, index1, :]/3\n            dd[3, :, 2, :] += opbend[2][index3, :, index2, :]/3\n            dd[3, :, 3, :] += opbend[2][index3, :, index3, :]/3\n    if deriv==0:\n        return v,\n    elif deriv==1:\n        return v, d\n    elif deriv==2:\n        return v, d, dd\n    else:\n        raise ValueError(\"deriv must be 0, 1 or 2.\")", "response": "Compute the mean of the 3 opbends\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _bond_length_low(r, deriv):\n    r = Vector3(3, deriv, r, (0, 1, 2))\n    d = r.norm()\n    return d.results()", "response": "Similar to bond_length but with a relative vector"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _bend_cos_low(a, b, deriv):\n    a = Vector3(6, deriv, a, (0, 1, 2))\n    b = Vector3(6, deriv, b, (3, 4, 5))\n    a /= a.norm()\n    b /= b.norm()\n    return dot(a, b).results()", "response": "Similar to bend_cos but with relative vectors"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _dihed_cos_low(a, b, c, deriv):\n    a = Vector3(9, deriv, a, (0, 1, 2))\n    b = Vector3(9, deriv, b, (3, 4, 5))\n    c = Vector3(9, deriv, c, (6, 7, 8))\n    b /= b.norm()\n    tmp = b.copy()\n    tmp *= dot(a, b)\n    a -= tmp\n    tmp = b.copy()\n    tmp *= dot(c, b)\n    c -= tmp\n    a /= a.norm()\n    c /= c.norm()\n    return dot(a, c).results()", "response": "Similar to dihed_cos but with relative vectors"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _dihed_angle_low(av, bv, cv, deriv):\n    a = Vector3(9, deriv, av, (0, 1, 2))\n    b = Vector3(9, deriv, bv, (3, 4, 5))\n    c = Vector3(9, deriv, cv, (6, 7, 8))\n    b /= b.norm()\n    tmp = b.copy()\n    tmp *= dot(a, b)\n    a -= tmp\n    tmp = b.copy()\n    tmp *= dot(c, b)\n    c -= tmp\n    a /= a.norm()\n    c /= c.norm()\n    result = dot(a, c).results()\n    # avoid trobles with the gradients by either using arccos or arcsin\n    if abs(result[0]) < 0.5:\n        # if the cosine is far away for -1 or +1, it is safe to take the arccos\n        # and fix the sign of the angle.\n        sign = 1-(np.linalg.det([av, bv, cv]) > 0)*2\n        return _cos_to_angle(result, deriv, sign)\n    else:\n        # if the cosine is close to -1 or +1, it is better to compute the sine,\n        # take the arcsin and fix the sign of the angle\n        d = cross(b, a)\n        side = (result[0] > 0)*2-1 # +1 means angle in range [-pi/2,pi/2]\n        result = dot(d, c).results()\n        return _sin_to_angle(result, deriv, side)", "response": "Similar to dihed_cos but with relative vectors"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _opbend_cos_low(a, b, c, deriv):\n    a = Vector3(9, deriv, a, (0, 1, 2))\n    b = Vector3(9, deriv, b, (3, 4, 5))\n    c = Vector3(9, deriv, c, (6, 7, 8))\n    n  = cross(a,b)\n    n /= n.norm()\n    c /= c.norm()\n    temp = dot(n,c)\n    result = temp.copy()\n    result.v = np.sqrt(1.0-temp.v**2)\n    if result.deriv > 0:\n        result.d *= -temp.v\n        result.d /= result.v\n    if result.deriv > 1:\n        result.dd *= -temp.v\n        result.dd /= result.v\n        temp2 = np.array([temp.d]).transpose()*temp.d\n        temp2 /= result.v**3\n        result.dd -= temp2\n    return result.results()", "response": "Similar to opbend_cos but with relative vectors"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _opbend_angle_low(a, b, c, deriv=0):\n    result = _opbend_cos_low(a, b, c, deriv)\n    sign = np.sign(np.linalg.det([a, b, c]))\n    return _cos_to_angle(result, deriv, sign)", "response": "Similar to opbend_angle but with relative vectors"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a cosine and its derivatives to an angle and its derivatives", "response": "def _cos_to_angle(result, deriv, sign=1):\n    \"\"\"Convert a cosine and its derivatives to an angle and its derivatives\"\"\"\n    v = np.arccos(np.clip(result[0], -1, 1))\n    if deriv == 0:\n        return v*sign,\n    if abs(result[0]) >= 1:\n        factor1 = 0\n    else:\n        factor1 = -1.0/np.sqrt(1-result[0]**2)\n    d = factor1*result[1]\n    if deriv == 1:\n        return v*sign, d*sign\n    factor2 = result[0]*factor1**3\n    dd = factor2*np.outer(result[1], result[1]) + factor1*result[2]\n    if deriv == 2:\n        return v*sign, d*sign, dd*sign\n    raise ValueError(\"deriv must be 0, 1 or 2.\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a sine and its derivatives to an angle and its derivatives", "response": "def _sin_to_angle(result, deriv, side=1):\n    \"\"\"Convert a sine and its derivatives to an angle and its derivatives\"\"\"\n    v = np.arcsin(np.clip(result[0], -1, 1))\n    sign = side\n    if sign == -1:\n        if v < 0:\n            offset = -np.pi\n        else:\n            offset = np.pi\n    else:\n        offset = 0.0\n    if deriv == 0:\n        return v*sign + offset,\n    if abs(result[0]) >= 1:\n        factor1 = 0\n    else:\n        factor1 = 1.0/np.sqrt(1-result[0]**2)\n    d = factor1*result[1]\n    if deriv == 1:\n        return v*sign + offset, d*sign\n    factor2 = result[0]*factor1**3\n    dd = factor2*np.outer(result[1], result[1]) + factor1*result[2]\n    if deriv == 2:\n        return v*sign + offset, d*sign, dd*sign\n    raise ValueError(\"deriv must be 0, 1 or 2.\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a deep copy of the current Scalar object", "response": "def copy(self):\n        \"\"\"Return a deep copy\"\"\"\n        result = Scalar(self.size, self.deriv)\n        result.v = self.v\n        if self.deriv > 0: result.d[:] = self.d[:]\n        if self.deriv > 1: result.dd[:] = self.dd[:]\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the value and optionally derivative and second order derivative", "response": "def results(self):\n        \"\"\"Return the value and optionally derivative and second order derivative\"\"\"\n        if self.deriv == 0:\n            return self.v,\n        if self.deriv == 1:\n            return self.v, self.d\n        if self.deriv == 2:\n            return self.v, self.d, self.dd"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copy(self):\n        result = Vector3(self.size, self.deriv)\n        result.x.v = self.x.v\n        result.y.v = self.y.v\n        result.z.v = self.z.v\n        if self.deriv > 0:\n            result.x.d[:] = self.x.d\n            result.y.d[:] = self.y.d\n            result.z.d[:] = self.z.d\n        if self.deriv > 1:\n            result.x.dd[:] = self.x.dd\n            result.y.dd[:] = self.y.dd\n            result.z.dd[:] = self.z.dd\n        return result", "response": "Return a deep copy of the current Vector3."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a Scalar object with the norm of this vector", "response": "def norm(self):\n        \"\"\"Return a Scalar object with the norm of this vector\"\"\"\n        result = Scalar(self.size, self.deriv)\n        result.v = np.sqrt(self.x.v**2 + self.y.v**2 + self.z.v**2)\n        if self.deriv > 0:\n            result.d += self.x.v*self.x.d\n            result.d += self.y.v*self.y.d\n            result.d += self.z.v*self.z.d\n            result.d /= result.v\n        if self.deriv > 1:\n            result.dd += self.x.v*self.x.dd\n            result.dd += self.y.v*self.y.dd\n            result.dd += self.z.v*self.z.dd\n            denom = result.v**2\n            result.dd += (1 - self.x.v**2/denom)*np.outer(self.x.d, self.x.d)\n            result.dd += (1 - self.y.v**2/denom)*np.outer(self.y.d, self.y.d)\n            result.dd += (1 - self.z.v**2/denom)*np.outer(self.z.d, self.z.d)\n            tmp = -self.x.v*self.y.v/denom*np.outer(self.x.d, self.y.d)\n            result.dd += tmp+tmp.transpose()\n            tmp = -self.y.v*self.z.v/denom*np.outer(self.y.d, self.z.d)\n            result.dd += tmp+tmp.transpose()\n            tmp = -self.z.v*self.x.v/denom*np.outer(self.z.d, self.x.d)\n            result.dd += tmp+tmp.transpose()\n            result.dd /= result.v\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a line of data from the file and return it.", "response": "def _get_line(self):\n        \"\"\"Get a line or raise StopIteration\"\"\"\n        line = self._f.readline()\n        if len(line) == 0:\n            raise StopIteration\n        return line"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _read_frame(self):\n        # Read the first line, ignore the title and try to get the time. The\n        # time field is optional.\n        line = self._get_line()\n        pos = line.rfind(\"t=\")\n        if pos >= 0:\n            time = float(line[pos+2:])*picosecond\n        else:\n            time = 0.0\n        # Read the second line, the number of atoms must match with the first\n        # frame.\n        num_atoms = int(self._get_line())\n        if self.num_atoms is not None and self.num_atoms != num_atoms:\n            raise ValueError(\"The number of atoms must be the same over the entire file.\")\n        # Read the atom lines\n        pos = np.zeros((num_atoms, 3), np.float32)\n        vel = np.zeros((num_atoms, 3), np.float32)\n        for i in range(num_atoms):\n            words = self._get_line()[22:].split()\n            pos[i, 0] = float(words[0])\n            pos[i, 1] = float(words[1])\n            pos[i, 2] = float(words[2])\n            vel[i, 0] = float(words[3])\n            vel[i, 1] = float(words[4])\n            vel[i, 2] = float(words[5])\n        pos *= nanometer\n        vel *= nanometer/picosecond\n        # Read the cell line\n        cell = np.zeros((3, 3), np.float32)\n        words = self._get_line().split()\n        if len(words) >= 3:\n            cell[0, 0] = float(words[0])\n            cell[1, 1] = float(words[1])\n            cell[2, 2] = float(words[2])\n        if len(words) == 9:\n            cell[1, 0] = float(words[3])\n            cell[2, 0] = float(words[4])\n            cell[0, 1] = float(words[5])\n            cell[2, 1] = float(words[6])\n            cell[0, 2] = float(words[7])\n            cell[1, 2] = float(words[8])\n        cell *= nanometer\n        return time, pos, vel, cell", "response": "Read one frame from the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup_ics(graph):\n    ics = []\n    # A) Collect all bonds.\n    for i0, i1 in graph.edges:\n        ics.append(BondLength(i0, i1))\n    # B) Collect all bends. (see b_bending_angles.py for the explanation)\n    for i1 in range(graph.num_vertices):\n        n = list(graph.neighbors[i1])\n        for index, i0 in enumerate(n):\n            for i2 in n[:index]:\n                ics.append(BendingAngle(i0, i1, i2))\n    # C) Collect all dihedrals.\n    for i1, i2 in graph.edges:\n        for i0 in graph.neighbors[i1]:\n            if i0==i2:\n                # All four indexes must be different.\n                continue\n            for i3 in graph.neighbors[i2]:\n                if i3==i1 or i3==i0:\n                    # All four indexes must be different.\n                    continue\n                ics.append(DihedralAngle(i0, i1, i2, i3))\n    return ics", "response": "This function creates a list of internal coordinates based on the graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_jacobian(ics, coordinates):\n    N3 = coordinates.size\n    jacobian = numpy.zeros((N3, len(ics)), float)\n    for j, ic in enumerate(ics):\n        # Let the ic object fill in each column of the Jacobian.\n        ic.fill_jacobian_column(jacobian[:,j], coordinates)\n    return jacobian", "response": "Construct a Jacobian matrix for the given internal and Cartesian coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fill_jacobian_column(self, jaccol, coordinates):\n        q, g = self.icfn(coordinates[list(self.indexes)], 1)\n        for i, j in enumerate(self.indexes):\n            jaccol[3*j:3*j+3] += g[i]\n        return jaccol", "response": "Fill in a column of the Jacobian."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_similarity(a, b, margin=1.0, cutoff=10.0):\n    return similarity_measure(\n        a.table_labels, a.table_distances,\n        b.table_labels, b.table_distances,\n        margin, cutoff\n    )", "response": "Compute the similarity between two molecules based on their descriptors."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_molecule(cls, molecule, labels=None):\n        if labels is None:\n            labels = molecule.numbers\n        return cls(molecule.distance_matrix, labels)", "response": "Initialize a similarity descriptor from a Molecule object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_molecular_graph(cls, molecular_graph, labels=None):\n        if labels is None:\n            labels = molecular_graph.numbers.astype(int)\n        return cls(molecular_graph.distances, labels)", "response": "Initialize a similarity descriptor from a MolecularGraph object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize a similarity descriptor from a set of coordinates and labels", "response": "def from_coordinates(cls, coordinates, labels):\n        \"\"\"Initialize a similarity descriptor\n\n           Arguments:\n             coordinates  --  a Nx3 numpy array\n             labels  --  a list with integer labels used to identify atoms of\n                         the same type\n        \"\"\"\n        from molmod.ext import molecules_distance_matrix\n        distance_matrix = molecules_distance_matrix(coordinates)\n        return cls(distance_matrix, labels)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_chk(filename):\n    '''Load a checkpoint file\n\n       Argument:\n        | filename  --  the file to load from\n\n       The return value is a dictionary whose keys are field labels and the\n       values can be None, string, integer, float, boolean or an array of\n       strings, integers, booleans or floats.\n\n       The file format is similar to the Gaussian fchk format, but has the extra\n       feature that the shapes of the arrays are also stored.\n    '''\n    with open(filename) as f:\n        result = {}\n        while True:\n            line = f.readline()\n            if line == '':\n                break\n            if len(line) < 54:\n                raise IOError('Header lines must be at least 54 characters long.')\n            key = line[:40].strip()\n            kind = line[47:52].strip()\n            value = line[53:-1] # discard newline\n            if kind == 'str':\n                result[key] = value\n            elif kind == 'int':\n                result[key] = int(value)\n            elif kind == 'bln':\n                result[key] = value.lower() in ['true', '1', 'yes']\n            elif kind == 'flt':\n                result[key] = float(value)\n            elif kind[3:5] == 'ar':\n                if kind[:3] == 'str':\n                    dtype = np.dtype('U22')\n                elif kind[:3] == 'int':\n                    dtype = int\n                elif kind[:3] == 'bln':\n                    dtype = bool\n                elif kind[:3] == 'flt':\n                    dtype = float\n                else:\n                    raise IOError('Unsupported kind: %s' % kind)\n                shape = tuple(int(i) for i in value.split(','))\n                array = np.zeros(shape, dtype)\n                if array.size > 0:\n                    work = array.ravel()\n                    counter = 0\n                    while True:\n                        short = f.readline().split()\n                        if len(short) == 0:\n                            raise IOError('Insufficient data')\n                        for s in short:\n                            if dtype == bool:\n                                work[counter] = s.lower() in ['true', '1', 'yes']\n                            elif callable(dtype):\n                                work[counter] = dtype(s)\n                            else:\n                                work[counter] = s\n                            counter += 1\n                            if counter == array.size:\n                                break\n                        if counter == array.size:\n                            break\n                result[key] = array\n            elif kind == 'none':\n                result[key] = None\n            else:\n                raise IOError('Unsupported kind: %s' % kind)\n    return result", "response": "Load a checkpoint file from a checkpoint file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dump_chk(filename, data):\n    '''Dump a checkpoint file\n\n       Argument:\n        | filename  --  the file to write to\n        | data  -- a dictionary whose keys are field labels and the values can\n                   be None, string, integer, float, boolean, an array/list of\n                   strings, integers, floats or booleans.\n\n       The file format is similar to the Gaussian fchk format, but has the extra\n       feature that the shapes of the arrays are also stored.\n    '''\n    with open(filename, 'w') as f:\n        for key, value in sorted(data.items()):\n            if not isinstance(key, str):\n                raise TypeError('The keys must be strings.')\n            if len(key) > 40:\n                raise ValueError('Key strings cannot be longer than 40 characters.')\n            if '\\n' in key:\n                raise ValueError('Key strings cannot contain newlines.')\n            if isinstance(value, str):\n                if len(value) > 256:\n                    raise ValueError('Only small strings are supported (256 chars).')\n                if '\\n' in value:\n                    raise ValueError('The string cannot contain new lines.')\n                print('%40s  kind=str   %s' % (key.ljust(40), value), file=f)\n            elif isinstance(value, bool):\n                print('%40s  kind=bln   %s' % (key.ljust(40), value), file=f)\n            elif isinstance(value, (int, np.integer)):\n                print('%40s  kind=int   %i' % (key.ljust(40), value), file=f)\n            elif isinstance(value, float):\n                print('%40s  kind=flt   %22.15e' % (key.ljust(40), value), file=f)\n            elif isinstance(value, np.ndarray) or isinstance(value, list) or \\\n                 isinstance(value, tuple):\n                if isinstance(value, list) or isinstance(value, tuple):\n                    value = np.array(value)\n                if value.dtype.fields is not None:\n                    raise TypeError('Arrays with fields are not supported.')\n                shape_str = ','.join(str(i) for i in value.shape)\n                if issubclass(value.dtype.type, (str, np.unicode, np.bytes_)):\n                    value = value.astype(np.unicode)\n                    for cell in value.flat:\n                        if len(cell) >= 22:\n                            raise ValueError('In case of string arrays, a string may contain at most 21 characters.')\n                        if ' ' in cell or '\\n' in cell:\n                            raise ValueError('In case of string arrays, a string may not contain spaces or new lines.')\n                    print('%40s  kind=strar %s' % (key.ljust(40), shape_str), file=f)\n                    format_str = '%22s'\n                elif issubclass(value.dtype.type, np.integer):\n                    print('%40s  kind=intar %s' % (key.ljust(40), shape_str), file=f)\n                    format_str = '%22i'\n                elif issubclass(value.dtype.type, np.bool_):\n                    print('%40s  kind=blnar %s' % (key.ljust(40), shape_str), file=f)\n                    format_str = '%22s'\n                elif issubclass(value.dtype.type, float):\n                    print('%40s  kind=fltar %s' % (key.ljust(40), shape_str), file=f)\n                    format_str = '%22.15e'\n                else:\n                    raise TypeError('Numpy array type %s not supported.' % value.dtype.type)\n                short_len = 4\n                short = []\n                for x in value.ravel():\n                    short.append(x)\n                    if len(short) == 4:\n                        print(' '.join(format_str  % s for s in short), file=f)\n                        short = []\n                if len(short) > 0:\n                    print(' '.join(format_str  % s for s in short), file=f)\n            elif value is None:\n                print('%40s  kind=none   None' % key.ljust(40), file=f)\n            else:\n                raise TypeError('Type %s not supported.' % type(value))", "response": "Dump a checkpoint file to a file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclear the contents of the data structure", "response": "def clear(self):\n        \"\"\"Clear the contents of the data structure\"\"\"\n        self.title = None\n        self.numbers = np.zeros(0, int)\n        self.atom_types = [] # the atom_types in the second column, used to associate ff parameters\n        self.charges = [] # ff charges\n        self.names = [] # a name that is unique for the molecule composition and connectivity\n        self.molecules = np.zeros(0, int) # a counter for each molecule\n        self.bonds = np.zeros((0, 2), int)\n        self.bends = np.zeros((0, 3), int)\n        self.dihedrals = np.zeros((0, 4), int)\n        self.impropers = np.zeros((0, 4), int)\n\n        self.name_cache = {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a PSF file into the internal dictionary.", "response": "def read_from_file(self, filename):\n        \"\"\"Load a PSF file\"\"\"\n        self.clear()\n        with open(filename) as f:\n            # A) check the first line\n            line = next(f)\n            if not line.startswith(\"PSF\"):\n                raise FileFormatError(\"Error while reading: A PSF file must start with a line 'PSF'.\")\n            # B) read in all the sections, without interpreting them\n            current_section = None\n            sections = {}\n            for line in f:\n                line = line.strip()\n                if line == \"\":\n                    continue\n                elif \"!N\" in line:\n                    words = line.split()\n                    current_section = []\n                    section_name = words[1][2:]\n                    if section_name.endswith(\":\"):\n                        section_name = section_name[:-1]\n                    sections[section_name] = current_section\n                else:\n                    current_section.append(line)\n        # C) interpret the supported sections\n        # C.1) The title\n        self.title = sections['TITLE'][0]\n        molecules = []\n        numbers = []\n        # C.2) The atoms and molecules\n        for line in sections['ATOM']:\n            words = line.split()\n            self.atom_types.append(words[5])\n            self.charges.append(float(words[6]))\n            self.names.append(words[3])\n            molecules.append(int(words[2]))\n            atom = periodic[words[4]]\n            if atom is None:\n                numbers.append(0)\n            else:\n                numbers.append(periodic[words[4]].number)\n        self.molecules = np.array(molecules)-1\n        self.numbers = np.array(numbers)\n        self.charges = np.array(self.charges)\n        # C.3) The bonds section\n        tmp = []\n        for line in sections['BOND']:\n            tmp.extend(int(word) for word in line.split())\n        self.bonds = np.reshape(np.array(tmp), (-1, 2))-1\n        # C.4) The bends section\n        tmp = []\n        for line in sections['THETA']:\n            tmp.extend(int(word) for word in line.split())\n        self.bends = np.reshape(np.array(tmp), (-1, 3))-1\n        # C.5) The dihedral section\n        tmp = []\n        for line in sections['PHI']:\n            tmp.extend(int(word) for word in line.split())\n        self.dihedrals = np.reshape(np.array(tmp), (-1, 4))-1\n        # C.6) The improper section\n        tmp = []\n        for line in sections['IMPHI']:\n            tmp.extend(int(word) for word in line.split())\n        self.impropers = np.reshape(np.array(tmp), (-1, 4))-1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a molecular graph into a unique name", "response": "def _get_name(self, graph, group=None):\n        \"\"\"Convert a molecular graph into a unique name\n\n           This method is not sensitive to the order of the atoms in the graph.\n        \"\"\"\n        if group is not None:\n            graph = graph.get_subgraph(group, normalize=True)\n\n        fingerprint = graph.fingerprint.tobytes()\n        name = self.name_cache.get(fingerprint)\n        if name is None:\n            name = \"NM%02i\" % len(self.name_cache)\n            self.name_cache[fingerprint] = name\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndump the data structure to a file - like object", "response": "def dump(self, f):\n        \"\"\"Dump the data structure to a file-like object\"\"\"\n        # header\n        print(\"PSF\", file=f)\n        print(file=f)\n\n        # title\n        print(\"      1 !NTITLE\", file=f)\n        print(self.title, file=f)\n        print(file=f)\n\n        # atoms\n        print(\"% 7i !NATOM\" % len(self.numbers), file=f)\n        if len(self.numbers) > 0:\n            for index, (number, atom_type, charge, name, molecule) in enumerate(zip(self.numbers, self.atom_types, self.charges, self.names, self.molecules)):\n                atom = periodic[number]\n                print(\"% 7i % 4s % 4i NAME % 6s % 6s % 8.4f % 12.6f 0\" % (\n                    index + 1,\n                    name,\n                    molecule + 1,\n                    atom.symbol,\n                    atom_type,\n                    charge,\n                    atom.mass/unified,\n                ), file=f)\n        print(file=f)\n\n        # bonds\n        print(\"% 7i !NBOND\" % len(self.bonds), file=f)\n        if len(self.bonds) > 0:\n            tmp = []\n            for bond in self.bonds:\n                tmp.extend(bond+1)\n                if len(tmp) >= 8:\n                    print(\" \".join(\"% 7i\" % v for v in tmp[:8]), file=f)\n                    tmp = tmp[8:]\n            if len(tmp) > 0:\n                print(\" \".join(\"% 7i\" % v for v in tmp), file=f)\n        print(file=f)\n\n        # bends\n        print(\"% 7i !NTHETA\" % len(self.bends), file=f)\n        if len(self.bends) > 0:\n            tmp = []\n            for bend in self.bends:\n                tmp.extend(bend+1)\n                if len(tmp) >= 9:\n                    print(\" \" + (\" \".join(\"% 6i\" % v for v in tmp[:9])), file=f)\n                    tmp = tmp[9:]\n            if len(tmp) > 0:\n                print(\" \" + (\" \".join(\"% 6i\" % v for v in tmp)), file=f)\n        print(file=f)\n\n        # dihedrals\n        print(\"% 7i !NPHI\" % len(self.dihedrals), file=f)\n        if len(self.dihedrals) > 0:\n            tmp = []\n            for dihedral in self.dihedrals:\n                tmp.extend(dihedral+1)\n                if len(tmp) >= 8:\n                    print(\" \" + (\" \".join(\"% 6i\" % v for v in tmp[:8])), file=f)\n                    tmp = tmp[8:]\n            if len(tmp) > 0:\n                print(\" \" + (\" \".join(\"% 6i\" % v for v in tmp)), file=f)\n        print(file=f)\n\n        # impropers\n        print(\"% 7i !NIMPHI\" % len(self.impropers), file=f)\n        if len(self.impropers) > 0:\n            tmp = []\n            for improper in self.impropers:\n                tmp.extend(improper+1)\n                if len(tmp) >= 8:\n                    print(\" \" + (\" \".join(\"% 6i\" % v for v in tmp[:8])), file=f)\n                    tmp = tmp[8:]\n            if len(tmp) > 0:\n                print(\" \" + (\" \".join(\"% 6i\" % v for v in tmp)), file=f)\n        print(file=f)\n\n        # not implemented fields\n        print(\"      0 !NDON\", file=f)\n        print(file=f)\n        print(\"      0 !NNB\", file=f)\n        print(file=f)\n        print(\"      0 !NGRP\", file=f)\n        print(file=f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds the molecular graph of the given molecule to the data structure", "response": "def add_molecule(self, molecule, atom_types=None, charges=None, split=True):\n        \"\"\"Add the graph of the molecule to the data structure\n\n           The molecular graph is estimated from the molecular geometry based on\n           interatomic distances.\n\n           Argument:\n            | ``molecule``  --  a Molecule instance\n\n           Optional arguments:\n            | ``atom_types``  --  a list with atom type strings\n            | ``charges``  --  The net atom charges\n            | ``split``  --  When True, the molecule is split into disconnected\n                             molecules [default=True]\n        \"\"\"\n        molecular_graph = MolecularGraph.from_geometry(molecule)\n        self.add_molecular_graph(molecular_graph, atom_types, charges, split, molecule)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_molecular_graph(self, molecular_graph, atom_types=None, charges=None, split=True, molecule=None):\n        # add atom numbers and molecule indices\n        new = len(molecular_graph.numbers)\n        if new == 0: return\n        prev = len(self.numbers)\n        offset = prev\n        self.numbers.resize(prev + new)\n        self.numbers[-new:] = molecular_graph.numbers\n        if atom_types is None:\n            atom_types = [periodic[number].symbol for number in molecular_graph.numbers]\n        self.atom_types.extend(atom_types)\n        if charges is None:\n            charges = [0.0]*len(molecular_graph.numbers)\n        self.charges.extend(charges)\n        self.molecules.resize(prev + new)\n\n        # add names (autogenerated)\n        if split:\n            groups = molecular_graph.independent_vertices\n            names = [self._get_name(molecular_graph, group) for group in groups]\n            group_indices = np.zeros(new, int)\n            for group_index, group in enumerate(groups):\n                for index in group:\n                    group_indices[index] = group_index\n            self.names.extend([names[group_index] for group_index in group_indices])\n            if prev == 0:\n                self.molecules[:] = group_indices\n            else:\n                self.molecules[-new:] = self.molecules[-new]+group_indices+1\n        else:\n            if prev == 0:\n                self.molecules[-new:] = 0\n            else:\n                self.molecules[-new:] = self.molecules[-new]+1\n            name = self._get_name(molecular_graph)\n            self.names.extend([name]*new)\n\n        self._add_graph_bonds(molecular_graph, offset, atom_types, molecule)\n        self._add_graph_bends(molecular_graph, offset, atom_types, molecule)\n        self._add_graph_dihedrals(molecular_graph, offset, atom_types, molecule)\n        self._add_graph_impropers(molecular_graph, offset, atom_types, molecule)", "response": "Adds the molecular graph to the data structure"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of groups of atom indexes Each atom in a group belongs to the same molecule or residue.", "response": "def get_groups(self):\n        \"\"\"Return a list of groups of atom indexes\n\n           Each atom in a group belongs to the same molecule or residue.\n        \"\"\"\n        groups = []\n        for a_index, m_index in enumerate(self.molecules):\n            if m_index >= len(groups):\n                groups.append([a_index])\n            else:\n                groups[m_index].append(a_index)\n        return groups"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter_halfs_bond(graph):\n    for atom1, atom2 in graph.edges:\n        try:\n            affected_atoms1, affected_atoms2 = graph.get_halfs(atom1, atom2)\n            yield affected_atoms1, affected_atoms2, (atom1, atom2)\n        except GraphError:\n            # just try again\n            continue", "response": "Iterate over the bonds that divides the molecule in two"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates over the bonds that divide the molecule in two", "response": "def iter_halfs_bend(graph):\n    \"\"\"Select randomly two consecutive bonds that divide the molecule in two\"\"\"\n    for atom2 in range(graph.num_vertices):\n        neighbors = list(graph.neighbors[atom2])\n        for index1, atom1 in enumerate(neighbors):\n            for atom3 in neighbors[index1+1:]:\n                try:\n                    affected_atoms = graph.get_halfs(atom2, atom1)[0]\n                    # the affected atoms never contain atom1!\n                    yield affected_atoms, (atom1, atom2, atom3)\n                    continue\n                except GraphError:\n                    pass\n                try:\n                    affected_atoms = graph.get_halfs(atom2, atom3)[0]\n                    # the affected atoms never contain atom3!\n                    yield affected_atoms, (atom3, atom2, atom1)\n                except GraphError:\n                    pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iter_halfs_double(graph):\n    edges = graph.edges\n    for index1, (atom_a1, atom_b1) in enumerate(edges):\n        for atom_a2, atom_b2 in edges[:index1]:\n            try:\n                affected_atoms1, affected_atoms2, hinge_atoms = graph.get_halfs_double(atom_a1, atom_b1, atom_a2, atom_b2)\n                yield affected_atoms1, affected_atoms2, hinge_atoms\n            except GraphError:\n                pass", "response": "Iterate over the two random non - consecutive bonds that divide the molecule in two"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_manipulations(\n    molecule, bond_stretch_factor=0.15, torsion_amplitude=np.pi,\n    bending_amplitude=0.30\n):\n    \"\"\"Generate a (complete) set of manipulations\n\n       The result can be used as input for the functions 'randomize_molecule'\n       and 'single_random_manipulation'\n\n       Arguments:\n         molecule  --  a reference geometry of the molecule, with graph\n                       attribute\n         bond_stretch_factor  --  the maximum relative change in bond length by\n                                  one bond stretch manipulatio\n         torsion_amplitude  --  the maximum change a dihdral angle\n         bending_amplitude  --  the maximum change in a bending angle\n\n       The return value is a list of RandomManipulation objects. They can be\n       used to generate different random distortions of the original molecule.\n    \"\"\"\n    do_stretch = (bond_stretch_factor > 0)\n    do_double_stretch = (bond_stretch_factor > 0)\n    do_bend = (bending_amplitude > 0)\n    do_double_bend = (bending_amplitude > 0)\n    do_torsion = (torsion_amplitude > 0)\n\n    results = []\n    # A) all manipulations that require one bond that cuts the molecule in half\n    if do_stretch or do_torsion:\n        for affected_atoms1, affected_atoms2, hinge_atoms in iter_halfs_bond(molecule.graph):\n            if do_stretch:\n                length = np.linalg.norm(\n                    molecule.coordinates[hinge_atoms[0]] -\n                    molecule.coordinates[hinge_atoms[1]]\n                )\n                results.append(RandomStretch(\n                    affected_atoms1, length*bond_stretch_factor, hinge_atoms\n                ))\n            if do_torsion and len(affected_atoms1) > 1 and len(affected_atoms2) > 1:\n                results.append(RandomTorsion(\n                    affected_atoms1, torsion_amplitude, hinge_atoms\n                ))\n    # B) all manipulations that require a bending angle that cuts the molecule\n    #    in two parts\n    if do_bend:\n        for affected_atoms, hinge_atoms in iter_halfs_bend(molecule.graph):\n            results.append(RandomBend(\n                affected_atoms, bending_amplitude, hinge_atoms\n            ))\n    # C) all manipulations that require two bonds that separate two halfs\n    if do_double_stretch or do_double_bend:\n        for affected_atoms1, affected_atoms2, hinge_atoms in iter_halfs_double(molecule.graph):\n            if do_double_stretch:\n                length1 = np.linalg.norm(\n                    molecule.coordinates[hinge_atoms[0]] -\n                    molecule.coordinates[hinge_atoms[1]]\n                )\n                length2 = np.linalg.norm(\n                    molecule.coordinates[hinge_atoms[2]] -\n                    molecule.coordinates[hinge_atoms[3]]\n                )\n                results.append(RandomDoubleStretch(\n                    affected_atoms1, 0.5*(length1+length2)*bond_stretch_factor, hinge_atoms\n                ))\n            if do_double_bend and len(affected_atoms1) > 2 and len(affected_atoms2) > 2:\n                if hinge_atoms[0] != hinge_atoms[2]:\n                    results.append(RandomTorsion(\n                        affected_atoms1, bending_amplitude, (hinge_atoms[0], hinge_atoms[2])\n                    ))\n                if hinge_atoms[1] != hinge_atoms[3]:\n                    results.append(RandomTorsion(\n                        affected_atoms2, bending_amplitude, (hinge_atoms[1], hinge_atoms[3])\n                    ))\n    # Neglect situations where three or more cuts are required.\n    return results", "response": "Generates a set of random manipulations for a single molecule."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_nonbond(molecule, thresholds):\n\n    # check that no atoms overlap\n    for atom1 in range(molecule.graph.num_vertices):\n        for atom2 in range(atom1):\n            if molecule.graph.distances[atom1, atom2] > 2:\n                distance = np.linalg.norm(molecule.coordinates[atom1] - molecule.coordinates[atom2])\n                if distance < thresholds[frozenset([molecule.numbers[atom1], molecule.numbers[atom2]])]:\n                    return False\n    return True", "response": "Checks whether all nonbonded atoms are well separated and if they are not then returns False."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a randomized copy of the molecule.", "response": "def randomize_molecule(molecule, manipulations, nonbond_thresholds, max_tries=1000):\n    \"\"\"Return a randomized copy of the molecule.\n\n       If no randomized molecule can be generated that survives the nonbond\n       check after max_tries repetitions, None is returned. In case of success,\n       the randomized molecule is returned. The original molecule is not\n       altered.\n    \"\"\"\n    for m in range(max_tries):\n        random_molecule = randomize_molecule_low(molecule, manipulations)\n        if check_nonbond(random_molecule, nonbond_thresholds):\n            return random_molecule"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef randomize_molecule_low(molecule, manipulations):\n\n    manipulations = copy.copy(manipulations)\n    shuffle(manipulations)\n    coordinates = molecule.coordinates.copy()\n    for manipulation in manipulations:\n        manipulation.apply(coordinates)\n    return molecule.copy_with(coordinates=coordinates)", "response": "Return a randomized copy of the molecule with the nonbond check applied."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying a single random manipulation.", "response": "def single_random_manipulation(molecule, manipulations, nonbond_thresholds, max_tries=1000):\n    \"\"\"Apply a single random manipulation.\n\n       If no randomized molecule can be generated that survives the nonbond\n       check after max_tries repetitions, None is returned. In case of success,\n       the randomized molecule and the corresponding transformation is returned.\n       The original molecule is not altered.\n    \"\"\"\n    for m in range(max_tries):\n        random_molecule, transformation = single_random_manipulation_low(molecule, manipulations)\n        if check_nonbond(random_molecule, nonbond_thresholds):\n            return random_molecule, transformation\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef single_random_manipulation_low(molecule, manipulations):\n\n    manipulation = sample(manipulations, 1)[0]\n    coordinates = molecule.coordinates.copy()\n    transformation = manipulation.apply(coordinates)\n    return molecule.copy_with(coordinates=coordinates), transformation", "response": "Return a randomized copy of the molecule without the nonbond check."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a random dimer that can be used to create a random molecule.", "response": "def random_dimer(molecule0, molecule1, thresholds, shoot_max):\n    \"\"\"Create a random dimer.\n\n       molecule0 and molecule1 are placed in one reference frame at random\n       relative positions. Interatomic distances are above the thresholds.\n       Initially a dimer is created where one interatomic distance approximates\n       the threshold value. Then the molecules are given an additional\n       separation in the range [0, shoot_max].\n\n       thresholds has the following format:\n       {frozenset([atom_number1, atom_number2]): distance}\n    \"\"\"\n\n    # apply a random rotation to molecule1\n    center = np.zeros(3, float)\n    angle = np.random.uniform(0, 2*np.pi)\n    axis = random_unit()\n    rotation = Complete.about_axis(center, angle, axis)\n    cor1 = np.dot(molecule1.coordinates, rotation.r)\n\n    # select a random atom in each molecule\n    atom0 = np.random.randint(len(molecule0.numbers))\n    atom1 = np.random.randint(len(molecule1.numbers))\n\n    # define a translation of molecule1 that brings both atoms in overlap\n    delta = molecule0.coordinates[atom0] - cor1[atom1]\n    cor1 += delta\n\n    # define a random direction\n    direction = random_unit()\n    cor1 += 1*direction\n\n    # move molecule1 along this direction until all intermolecular atomic\n    # distances are above the threshold values\n    threshold_mat = np.zeros((len(molecule0.numbers), len(molecule1.numbers)), float)\n    distance_mat = np.zeros((len(molecule0.numbers), len(molecule1.numbers)), float)\n    for i1, n1 in enumerate(molecule0.numbers):\n        for i2, n2 in enumerate(molecule1.numbers):\n            threshold = thresholds.get(frozenset([n1, n2]))\n            threshold_mat[i1, i2] = threshold**2\n    while True:\n        cor1 += 0.1*direction\n        distance_mat[:] = 0\n        for i in 0, 1, 2:\n            distance_mat += np.subtract.outer(molecule0.coordinates[:, i], cor1[:, i])**2\n        if (distance_mat > threshold_mat).all():\n            break\n\n    # translate over a random distance [0, shoot] along the same direction\n    # (if necessary repeat until no overlap is found)\n    while True:\n        cor1 += direction*np.random.uniform(0, shoot_max)\n        distance_mat[:] = 0\n        for i in 0, 1, 2:\n            distance_mat += np.subtract.outer(molecule0.coordinates[:, i], cor1[:, i])**2\n        if (distance_mat > threshold_mat).all():\n            break\n\n    # done\n    dimer = Molecule(\n        np.concatenate([molecule0.numbers, molecule1.numbers]),\n        np.concatenate([molecule0.coordinates, cor1])\n    )\n    dimer.direction = direction\n    dimer.atom0 = atom0\n    dimer.atom1 = atom1\n    return dimer"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_from_file(cls, filename):\n        with open(filename) as f:\n            lines = list(line for line in f if line[0] != '#')\n        r = []\n        t = []\n        for line in lines[:3]:\n            values = list(float(word) for word in line.split())\n            r.append(values[:3])\n            t.append(values[3])\n        transformation = Complete(r, t)\n        affected_atoms = set(int(word) for word in lines[3].split())\n        return cls(affected_atoms, transformation)", "response": "Construct a MolecularDistortion object from a file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying this distortion to Cartesian coordinates", "response": "def apply(self, coordinates):\n        \"\"\"Apply this distortion to Cartesian coordinates\"\"\"\n        for i in self.affected_atoms:\n            coordinates[i] = self.transformation*coordinates[i]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the object to a file", "response": "def write_to_file(self, filename):\n        \"\"\"Write the object to a file\"\"\"\n        r = self.transformation.r\n        t = self.transformation.t\n        with open(filename, \"w\") as f:\n            print(\"# A (random) transformation of a part of a molecule:\", file=f)\n            print(\"# The translation vector is in atomic units.\", file=f)\n            print(\"#     Rx             Ry             Rz              T\", file=f)\n            print(\"% 15.9e % 15.9e % 15.9e % 15.9e\" % (r[0, 0], r[0, 1], r[0, 2], t[0]), file=f)\n            print(\"% 15.9e % 15.9e % 15.9e % 15.9e\" % (r[1, 0], r[1, 1], r[1, 2], t[1]), file=f)\n            print(\"% 15.9e % 15.9e % 15.9e % 15.9e\" % (r[2, 0], r[2, 1], r[2, 2], t[2]), file=f)\n            print(\"# The indexes of the affected atoms:\", file=f)\n            print(\" \".join(str(i) for i in self.affected_atoms), file=f)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply(self, coordinates):\n        transform = self.get_transformation(coordinates)\n        result = MolecularDistortion(self.affected_atoms, transform)\n        result.apply(coordinates)\n        return result", "response": "Generate apply and return a random manipulation"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_transformation(self, coordinates):\n        atom1, atom2 = self.hinge_atoms\n        direction = coordinates[atom1] - coordinates[atom2]\n        direction /= np.linalg.norm(direction)\n        direction *= np.random.uniform(-self.max_amplitude, self.max_amplitude)\n        result = Translation(direction)\n        return result", "response": "Construct a translation object from the given coordinates"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_transformation(self, coordinates):\n        atom1, atom2 = self.hinge_atoms\n        center = coordinates[atom1]\n        axis = coordinates[atom1] - coordinates[atom2]\n        axis /= np.linalg.norm(axis)\n        angle = np.random.uniform(-self.max_amplitude, self.max_amplitude)\n        return Complete.about_axis(center, angle, axis)", "response": "Construct a transformation object from the given coordinates."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_transformation(self, coordinates):\n        atom1, atom2, atom3 = self.hinge_atoms\n        center = coordinates[atom2]\n        a = coordinates[atom1] - coordinates[atom2]\n        b = coordinates[atom3] - coordinates[atom2]\n        axis = np.cross(a, b)\n        norm = np.linalg.norm(axis)\n        if norm < 1e-5:\n            # We suppose that atom3 is part of the affected atoms\n            axis = random_orthonormal(a)\n        else:\n            axis /= np.linalg.norm(axis)\n        angle = np.random.uniform(-self.max_amplitude, self.max_amplitude)\n        return Complete.about_axis(center, angle, axis)", "response": "Construct a transformation object from the given coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct a translation object from the given coordinates", "response": "def get_transformation(self, coordinates):\n        \"\"\"Construct a transformation object\"\"\"\n        atom1, atom2, atom3, atom4 = self.hinge_atoms\n        a = coordinates[atom1] - coordinates[atom2]\n        a /= np.linalg.norm(a)\n        b = coordinates[atom3] - coordinates[atom4]\n        b /= np.linalg.norm(b)\n        direction = 0.5*(a+b)\n        direction *= np.random.uniform(-self.max_amplitude, self.max_amplitude)\n        result = Translation(direction)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate over all bins surrounding the given center key", "response": "def iter_surrounding(self, center_key):\n        \"\"\"Iterate over all bins surrounding the given bin\"\"\"\n        for shift in self.neighbor_indexes:\n            key = tuple(np.add(center_key, shift).astype(int))\n            if self.integer_cell is not None:\n                key = self.wrap_key(key)\n            bin = self._bins.get(key)\n            if bin is not None:\n                yield key, bin"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wrap_key(self, key):\n        return tuple(np.round(\n            self.integer_cell.shortest_vector(key)\n        ).astype(int))", "response": "Translate the key into the central cell\n          "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchoosing a proper grid for the binning process", "response": "def _setup_grid(self, cutoff, unit_cell, grid):\n        \"\"\"Choose a proper grid for the binning process\"\"\"\n        if grid is None:\n            # automatically choose a decent grid\n            if unit_cell is None:\n                grid = cutoff/2.9\n            else:\n                # The following would be faster, but it is not reliable\n                # enough yet.\n                #grid = unit_cell.get_optimal_subcell(cutoff/2.0)\n                divisions = np.ceil(unit_cell.spacings/cutoff)\n                divisions[divisions<1] = 1\n                grid = unit_cell/divisions\n\n        if isinstance(grid, float):\n            grid_cell = UnitCell(np.array([\n                [grid, 0, 0],\n                [0, grid, 0],\n                [0, 0, grid]\n            ]))\n        elif isinstance(grid, UnitCell):\n            grid_cell = grid\n        else:\n            raise TypeError(\"Grid must be None, a float or a UnitCell instance.\")\n\n        if unit_cell is not None:\n            # The columns of integer_matrix are the unit cell vectors in\n            # fractional coordinates of the grid cell.\n            integer_matrix = grid_cell.to_fractional(unit_cell.matrix.transpose()).transpose()\n            if abs((integer_matrix - np.round(integer_matrix))*self.unit_cell.active).max() > 1e-6:\n                raise ValueError(\"The unit cell vectors are not an integer linear combination of grid cell vectors.\")\n            integer_matrix = integer_matrix.round()\n            integer_cell = UnitCell(integer_matrix, unit_cell.active)\n        else:\n            integer_cell = None\n\n        return grid_cell, integer_cell"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_unit(expression):\n    try:\n        g = globals()\n        g.update(shorthands)\n        return float(eval(str(expression), g))\n    except:\n        raise ValueError(\"Could not interpret '%s' as a unit or a measure.\" % expression)", "response": "Evaluate a python expression string containing constants\nATTRIBS and return a float."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parents(self):\n        q = self.__parent__.parents()\n        q.put(self)\n        return q", "response": "Returns a FIFO queue with the ancestors and itself."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef url(self):\n        path = None\n        nodes = self.parents()\n        while not nodes.empty():\n            path = urljoin(path, nodes.get().path())\n        return path", "response": "Returns the whole URL from the base to this node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef auth_required(self):\n        if self._auth:\n            return self._auth, self\n        return self.__parent__.auth_required()", "response": "Returns a tuple of the authentication and the parent node if any."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_graph(self, graph):\n        if graph.num_vertices != self.size:\n            raise TypeError(\"The number of vertices in the graph does not \"\n                \"match the length of the atomic numbers array.\")\n        # In practice these are typically the same arrays using the same piece\n        # of memory. Just checking to be sure.\n        if (self.numbers != graph.numbers).any():\n            raise TypeError(\"The atomic numbers in the graph do not match the \"\n                \"atomic numbers in the molecule.\")", "response": "Check that the atomic numbers in the graph are consistent with the molecule."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_file(cls, filename):\n        # TODO: many different API's to load files. brrr...\n        if filename.endswith(\".cml\"):\n            from molmod.io import load_cml\n            return load_cml(filename)[0]\n        elif filename.endswith(\".fchk\"):\n            from molmod.io import FCHKFile\n            fchk = FCHKFile(filename, field_labels=[])\n            return fchk.molecule\n        elif filename.endswith(\".pdb\"):\n            from molmod.io import load_pdb\n            return load_pdb(filename)\n        elif filename.endswith(\".sdf\"):\n            from molmod.io import SDFReader\n            return next(SDFReader(filename))\n        elif filename.endswith(\".xyz\"):\n            from molmod.io import XYZReader\n            xyz_reader = XYZReader(filename)\n            title, coordinates = next(xyz_reader)\n            return Molecule(xyz_reader.numbers, coordinates, title, symbols=xyz_reader.symbols)\n        else:\n            raise ValueError(\"Could not determine file format for %s.\" % filename)", "response": "Construct a Molecule object from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef chemical_formula(self):\n        counts = {}\n        for number in self.numbers:\n            counts[number] = counts.get(number, 0)+1\n        items = []\n        for number, count in sorted(counts.items(), reverse=True):\n            if count == 1:\n                items.append(periodic[number].symbol)\n            else:\n                items.append(\"%s%i\" % (periodic[number].symbol, count))\n        return \"\".join(items)", "response": "the chemical formula of the molecule"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets self. masses based on self. numbers and periodic table.", "response": "def set_default_masses(self):\n        \"\"\"Set self.masses based on self.numbers and periodic table.\"\"\"\n        self.masses = np.array([periodic[n].mass for n in self.numbers])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets self. symbols based on self. numbers and the periodic table.", "response": "def set_default_symbols(self):\n        \"\"\"Set self.symbols based on self.numbers and the periodic table.\"\"\"\n        self.symbols = tuple(periodic[n].symbol for n in self.numbers)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_to_file(self, filename):\n        # TODO: give all file format writers the same API\n        if filename.endswith('.cml'):\n            from molmod.io import dump_cml\n            dump_cml(filename, [self])\n        elif filename.endswith('.xyz'):\n            from molmod.io import XYZWriter\n            symbols = []\n            for n in self.numbers:\n                atom = periodic[n]\n                if atom is None:\n                    symbols.append(\"X\")\n                else:\n                    symbols.append(atom.symbol)\n            xyz_writer = XYZWriter(filename, symbols)\n            xyz_writer.dump(self.title, self.coordinates)\n            del xyz_writer\n        else:\n            raise ValueError(\"Could not determine file format for %s.\" % filename)", "response": "Write the molecular geometry to a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the RMSD between two molecules.", "response": "def rmsd(self, other):\n        \"\"\"Compute the RMSD between two molecules.\n\n           Arguments:\n            | ``other``  --  Another molecule with the same atom numbers\n\n           Return values:\n            | ``transformation``  --  the transformation that brings 'self' into\n                                  overlap with 'other'\n            | ``other_trans``  --  the transformed coordinates of geometry 'other'\n            | ``rmsd``  --  the rmsd of the distances between corresponding atoms in\n                            'self' and 'other'\n\n           Make sure the atoms in `self` and `other` are in the same order.\n\n           Usage::\n\n             >>> print molecule1.rmsd(molecule2)[2]/angstrom\n        \"\"\"\n        if self.numbers.shape != other.numbers.shape or \\\n           (self.numbers != other.numbers).all():\n            raise ValueError(\"The other molecule does not have the same numbers as this molecule.\")\n        return fit_rmsd(self.coordinates, other.coordinates)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the rotational symmetry number.", "response": "def compute_rotsym(self, threshold=1e-3*angstrom):\n        \"\"\"Compute the rotational symmetry number.\n\n           Optional argument:\n            | ``threshold``  --  only when a rotation results in an rmsd below the given\n                                 threshold, the rotation is considered to transform the\n                                 molecule onto itself.\n        \"\"\"\n        # Generate a graph with a more permissive threshold for bond lengths:\n        # (is convenient in case of transition state geometries)\n        graph = MolecularGraph.from_geometry(self, scaling=1.5)\n        try:\n            return compute_rotsym(self, graph, threshold)\n        except ValueError:\n            raise ValueError(\"The rotational symmetry number can only be computed when the graph is fully connected.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the label from the last line read", "response": "def _get_current_label(self):\n        \"\"\"Get the label from the last line read\"\"\"\n        if len(self._last) == 0:\n            raise StopIteration\n        return self._last[:self._last.find(\":\")]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _skip_section(self):\n        self._last = self._f.readline()\n        while len(self._last) > 0 and len(self._last[0].strip()) == 0:\n            self._last = self._f.readline()", "response": "Skip a section of the log file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _read_section(self):\n        lines = [self._last[self._last.find(\":\")+1:]]\n        self._last = self._f.readline()\n        while len(self._last) > 0 and len(self._last[0].strip()) == 0:\n            lines.append(self._last)\n            self._last = self._f.readline()\n        return lines", "response": "Read and return an entire section"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_next(self, label):\n        while self._get_current_label() != label:\n            self._skip_section()\n        return self._read_section()", "response": "Get the next section with the given label"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading a single ATRJFrame from the trajectory", "response": "def _read_frame(self):\n        \"\"\"Read a single frame from the trajectory\"\"\"\n        self._secfile.get_next(\"Frame Number\")\n        frame = ATRJFrame()\n        # Read the time and energy\n        energy_lines = self._secfile.get_next(\"Time/Energy\")\n        energy_words = energy_lines[0].split()\n        frame.time = float(energy_words[0])*picosecond\n        frame.step = int(energy_words[1])\n        frame.total_energy = float(energy_words[2])*kcalmol\n        # Read the coordinates\n        coord_lines = self._secfile.get_next(\"Coordinates\")\n        frame.coordinates = np.zeros((self.num_atoms, 3), float)\n        for index, line in enumerate(coord_lines):\n            words = line.split()\n            frame.coordinates[index, 0] = float(words[1])\n            frame.coordinates[index, 1] = float(words[2])\n            frame.coordinates[index, 2] = float(words[3])\n        frame.coordinates *= angstrom\n        # Done\n        return frame"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate the Cartesian coordinates of the points in a cube file.", "response": "def get_cube_points(origin, axes, nrep):\n    '''Generate the Cartesian coordinates of the points in a cube file\n\n       *Arguemnts:*\n\n       origin\n            The cartesian coordinate for the origin of the grid.\n\n       axes\n            The 3 by 3 array with the grid spacings as rows.\n\n       nrep\n            The number of grid points along each axis.\n    '''\n    points = np.zeros((nrep[0], nrep[1], nrep[2], 3), float)\n    points[:] = origin\n    points[:] += np.outer(np.arange(nrep[0], dtype=float), axes[0]).reshape((-1,1,1,3))\n    points[:] += np.outer(np.arange(nrep[1], dtype=float), axes[1]).reshape((1,-1,1,3))\n    points[:] += np.outer(np.arange(nrep[2], dtype=float), axes[2]).reshape((1,1,-1,3))\n    return points"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_file(cls, filename):\n        '''Create a cube object by loading data from a file.\n\n           *Arguemnts:*\n\n           filename\n                The file to load. It must contain the header with the\n                description of the grid and the molecule.\n        '''\n        with open(filename) as f:\n            molecule, origin, axes, nrep, subtitle, nuclear_charges = \\\n                read_cube_header(f)\n            data = np.zeros(tuple(nrep), float)\n            tmp = data.ravel()\n            counter = 0\n            while True:\n                line = f.readline()\n                if len(line) == 0:\n                    break\n                words = line.split()\n                for word in words:\n                    tmp[counter] = float(word)\n                    counter += 1\n        return cls(molecule, origin, axes, nrep, data, subtitle, nuclear_charges)", "response": "Create a cube object by loading data from a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite the cube to a file in the Gaussian cube format.", "response": "def write_to_file(self, fn):\n        '''Write the cube to a file in the Gaussian cube format.'''\n        with open(fn, 'w') as f:\n            f.write(' {}\\n'.format(self.molecule.title))\n            f.write(' {}\\n'.format(self.subtitle))\n\n            def write_grid_line(n, v):\n                f.write('%5i % 11.6f % 11.6f % 11.6f\\n' % (n, v[0], v[1], v[2]))\n\n            write_grid_line(self.molecule.size, self.origin)\n            write_grid_line(self.data.shape[0], self.axes[0])\n            write_grid_line(self.data.shape[1], self.axes[1])\n            write_grid_line(self.data.shape[2], self.axes[2])\n\n            def write_atom_line(n, nc, v):\n                f.write('%5i % 11.6f % 11.6f % 11.6f % 11.6f\\n' % (n, nc, v[0], v[1], v[2]))\n\n            for i in range(self.molecule.size):\n                write_atom_line(self.molecule.numbers[i], self.nuclear_charges[i],\n                                self.molecule.coordinates[i])\n\n            for i0 in range(self.data.shape[0]):\n                for i1 in range(self.data.shape[1]):\n                    col = 0\n                    for i2 in range(self.data.shape[2]):\n                        value = self.data[i0, i1, i2]\n                        if col % 6 == 5:\n                            f.write(' % 12.5e\\n' % value)\n                        else:\n                            f.write(' % 12.5e' % value)\n                        col += 1\n                    if col % 6 != 5:\n                        f.write('\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy(self, newdata=None):\n        '''Return a copy of the cube with optionally new data.'''\n        if newdata is None:\n            newdata = self.data.copy()\n        return self.__class__(\n            self.molecule, self.origin.copy(), self.axes.copy(),\n            self.nrep.copy(), newdata, self.subtitle, self.nuclear_charges\n        )", "response": "Return a copy of the cube with optionally new data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck the constency between self. __index and self. order", "response": "def _consistent(self):\n        \"\"\"Checks the constency between self.__index and self.__order\"\"\"\n        if len(self.__order) != sum(len(values) for values in self.__index.values()):\n            return False\n        import copy\n        tmp = copy.copy(self.__order)\n        for key, values in self.__index.items():\n            for value in values:\n                if value.name != key:\n                    return False\n                if value in tmp:\n                    tmp.remove(value)\n                else:\n                    return False\n                if isinstance(value, CP2KSection):\n                    if not value._consistent():\n                        return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a child section or keyword to the end of the list.", "response": "def append(self, child):\n        \"\"\"Add a child section or keyword\"\"\"\n        if not (isinstance(child, CP2KSection) or isinstance(child, CP2KKeyword)):\n            raise TypeError(\"The child must be a CP2KSection or a CP2KKeyword, got: %s.\" % child)\n        l = self.__index.setdefault(child.name, [])\n        l.append(child)\n        self.__order.append(child)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump_children(self, f, indent=''):\n        for child in self.__order:\n            child.dump(f, indent+'  ')", "response": "Dump the children of the current section to a file - like object"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndump this section and its children to a file - like object", "response": "def dump(self, f, indent=''):\n        \"\"\"Dump this section and its children to a file-like object\"\"\"\n        print((\"%s&%s %s\" % (indent, self.__name, self.section_parameters)).rstrip(), file=f)\n        self.dump_children(f, indent)\n        print(\"%s&END %s\" % (indent, self.__name), file=f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef readline(self, f):\n        while True:\n            line = f.readline()\n            if len(line) == 0:\n                raise EOFError\n            line = line[:line.find('#')]\n            line = line.strip()\n            if len(line) > 0:\n                return line", "response": "A helper method that only reads uncommented lines"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the children of this section from a file - like object", "response": "def load_children(self, f):\n        \"\"\"Load the children of this section from a file-like object\"\"\"\n        while True:\n            line = self.readline(f)\n            if line[0] == '&':\n                if line[1:].startswith(\"END\"):\n                    check_name = line[4:].strip().upper()\n                    if check_name != self.__name:\n                        raise FileFormatError(\"CP2KSection end mismatch, pos=%s\", f.tell())\n                    break\n                else:\n                    section = CP2KSection()\n                    section.load(f, line)\n                    self.append(section)\n            else:\n                keyword = CP2KKeyword()\n                keyword.load(line)\n                self.append(keyword)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads this section from a file - like object", "response": "def load(self, f, line=None):\n        \"\"\"Load this section from a file-like object\"\"\"\n        if line is None:\n            # in case the file contains only a fragment of an input file,\n            # this is useful.\n            line = f.readlin()\n        words = line[1:].split()\n        self.__name = words[0].upper()\n        self.section_parameters = \" \".join(words[1:])\n        try:\n            self.load_children(f)\n        except EOFError:\n            raise FileFormatError(\"Unexpected end of file, section '%s' not ended.\" % self.__name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping this keyword to a file - like object", "response": "def dump(self, f, indent=''):\n        \"\"\"Dump this keyword to a file-like object\"\"\"\n        if self.__unit is None:\n            print((\"%s%s %s\" % (indent, self.__name, self.__value)).rstrip(), file=f)\n        else:\n            print((\"%s%s [%s] %s\" % (indent, self.__name, self.__unit, self.__value)).rstrip(), file=f)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading this keyword from a file - like object", "response": "def load(self, line):\n        \"\"\"Load this keyword from a file-like object\"\"\"\n        words = line.split()\n        try:\n            float(words[0])\n            self.__name = \"\"\n            self.__value = \" \".join(words)\n        except ValueError:\n            self.__name = words[0].upper()\n            if len(words) > 2 and words[1][0]==\"[\" and words[1][-1]==\"]\":\n                self.unit = words[1][1:-1]\n                self.__value = \" \".join(words[2:])\n            else:\n                self.__value = \" \".join(words[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_value(self, value):\n        if not isinstance(value, str):\n            raise TypeError(\"A value must be a string, got %s.\" % value)\n        self.__value = value", "response": "Set the value associated with the keyword"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_from_file(filename):\n        with open(filename) as f:\n            result = CP2KInputFile()\n            try:\n                while True:\n                    result.load_children(f)\n            except EOFError:\n                pass\n        return result", "response": "Reads a file containing the contents of the file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading and return the next time frame", "response": "def _read_frame(self):\n        \"\"\"Read and return the next time frame\"\"\"\n        pos = np.zeros((self.num_atoms, 3), float)\n        vel = np.zeros((self.num_atoms, 3), float)\n        for i in range(self.num_atoms):\n            line = next(self._f)\n            words = line.split()\n            pos[i, 0] = float(words[1])\n            pos[i, 1] = float(words[2])\n            pos[i, 2] = float(words[3])\n            vel[i, 0] = float(words[4])\n            vel[i, 1] = float(words[5])\n            vel[i, 2] = float(words[6])\n        return pos, vel"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck the sanity of the given 4x4 transformation matrix", "response": "def check_matrix(m):\n    \"\"\"Check the sanity of the given 4x4 transformation matrix\"\"\"\n    if m.shape != (4, 4):\n        raise ValueError(\"The argument must be a 4x4 array.\")\n    if max(abs(m[3, 0:3])) > eps:\n        raise ValueError(\"The given matrix does not have correct translational part\")\n    if abs(m[3, 3] - 1.0) > eps:\n        raise ValueError(\"The lower right element of the given matrix must be 1.0.\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the transformation that minimizes the RMSD between the points ras and rbs.", "response": "def superpose(ras, rbs, weights=None):\n    \"\"\"Compute the transformation that minimizes the RMSD between the points ras and rbs\n\n       Arguments:\n        | ``ras``  --  a ``np.array`` with 3D coordinates of geometry A,\n                       shape=(N,3)\n        | ``rbs``  --  a ``np.array`` with 3D coordinates of geometry B,\n                       shape=(N,3)\n\n       Optional arguments:\n        | ``weights``  --  a numpy array with fitting weights for each\n                           coordinate, shape=(N,)\n\n       Return value:\n        | ``transformation``  --  the transformation that brings geometry A into\n                                  overlap with geometry B\n\n       Each row in ras and rbs represents a 3D coordinate. Corresponding rows\n       contain the points that are brought into overlap by the fitting\n       procedure. The implementation is based on the Kabsch Algorithm:\n\n       http://dx.doi.org/10.1107%2FS0567739476001873\n    \"\"\"\n    if weights is None:\n        ma = ras.mean(axis=0)\n        mb = rbs.mean(axis=0)\n    else:\n        total_weight = weights.sum()\n        ma = np.dot(weights, ras)/total_weight\n        mb = np.dot(weights, rbs)/total_weight\n\n\n    # Kabsch\n    if weights is None:\n        A = np.dot((rbs-mb).transpose(), ras-ma)\n    else:\n        weights = weights.reshape((-1, 1))\n        A = np.dot(((rbs-mb)*weights).transpose(), (ras-ma)*weights)\n    v, s, wt = np.linalg.svd(A)\n    s[:] = 1\n    if np.linalg.det(np.dot(v, wt)) < 0:\n        s[2] = -1\n    r = np.dot(wt.T*s, v.T)\n    return Complete(r, np.dot(r, -mb) + ma)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying this translation to the given object x.", "response": "def apply_to(self, x, columns=False):\n        \"\"\"Apply this translation to the given object\n\n           The argument can be several sorts of objects:\n\n           * ``np.array`` with shape (3, )\n           * ``np.array`` with shape (N, 3)\n           * ``np.array`` with shape (3, N), use ``columns=True``\n           * ``Translation``\n           * ``Rotation``\n           * ``Complete``\n           * ``UnitCell``\n\n           In case of arrays, the 3D vectors are translated. In case of trans-\n           formations, a new transformation is returned that consists of this\n           translation applied AFTER the given translation. In case of a unit\n           cell, the original object is returned.\n\n           This method is equivalent to ``self*x``.\n        \"\"\"\n        if isinstance(x, np.ndarray) and len(x.shape) == 2 and x.shape[0] == 3 and columns:\n            return x + self.t.reshape((3,1))\n        if isinstance(x, np.ndarray) and (x.shape == (3, ) or (len(x.shape) == 2 and x.shape[1] == 3)) and not columns:\n            return x + self.t\n        elif isinstance(x, Complete):\n            return Complete(x.r, x.t + self.t)\n        elif isinstance(x, Translation):\n            return Translation(x.t + self.t)\n        elif isinstance(x, Rotation):\n            return Complete(x.r, self.t)\n        elif isinstance(x, UnitCell):\n            return x\n        else:\n            raise ValueError(\"Can not apply this translation to %s\" % x)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compare(self, other, t_threshold=1e-3):\n        return compute_rmsd(self.t, other.t) < t_threshold", "response": "Compare two translations\n\n           The RMSD of the translation vectors is computed. The return value\n           is True when the RMSD is below the threshold, i.e. when the two\n           translations are almost identical."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_r(self, r):\n        if abs(np.dot(r[:, 0], r[:, 0]) - 1) > eps or \\\n            abs(np.dot(r[:, 0], r[:, 0]) - 1) > eps or \\\n            abs(np.dot(r[:, 0], r[:, 0]) - 1) > eps or \\\n            np.dot(r[:, 0], r[:, 1]) > eps or \\\n            np.dot(r[:, 1], r[:, 2]) > eps or \\\n            np.dot(r[:, 2], r[:, 0]) > eps:\n            raise ValueError(\"The rotation matrix is significantly non-orthonormal.\")", "response": "check that the columns must orthogonal"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef random(cls):\n        axis = random_unit()\n        angle = np.random.uniform(0,2*np.pi)\n        invert = bool(np.random.randint(0,2))\n        return Rotation.from_properties(angle, axis, invert)", "response": "Return a random rotation"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing a rotation based on the properties", "response": "def from_properties(cls, angle, axis, invert):\n        \"\"\"Initialize a rotation based on the properties\"\"\"\n        norm = np.linalg.norm(axis)\n        if norm > 0:\n            x = axis[0] / norm\n            y = axis[1] / norm\n            z = axis[2] / norm\n            c = np.cos(angle)\n            s = np.sin(angle)\n            r = (1-2*invert) * np.array([\n                [x*x*(1-c)+c  , x*y*(1-c)-z*s, x*z*(1-c)+y*s],\n                [x*y*(1-c)+z*s, y*y*(1-c)+c  , y*z*(1-c)-x*s],\n                [x*z*(1-c)-y*s, y*z*(1-c)+x*s, z*z*(1-c)+c  ]\n            ])\n        else:\n            r = np.identity(3) * (1-2*invert)\n        return cls(r)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef properties(self):\n        # determine wether an inversion rotation has been applied\n        invert = (np.linalg.det(self.r) < 0)\n        factor = {True: -1, False: 1}[invert]\n        # get the rotation data\n        # trace(r) = 1+2*cos(angle)\n        cos_angle = 0.5*(factor*np.trace(self.r) - 1)\n        if cos_angle > 1: cos_angle = 1.0\n        if cos_angle < -1: cos_angle = -1.0\n        # the antisymmetric part of the non-diagonal vector tell us something\n        # about sin(angle) and n.\n        axis = 0.5*factor*np.array([-self.r[1, 2] + self.r[2, 1], self.r[0, 2] - self.r[2, 0], -self.r[0, 1] + self.r[1, 0]])\n        sin_angle = np.linalg.norm(axis)\n        # look for the best way to normalize the\n        if (sin_angle == 0.0) and (cos_angle > 0):\n            axis[2] = 1.0\n        elif abs(sin_angle) < (1-cos_angle):\n            for index in range(3):\n                axis[index] = {True: -1, False: 1}[axis[index] < 0] * np.sqrt(abs((factor*self.r[index, index] - cos_angle) / (1 - cos_angle)))\n        else:\n            axis = axis / sin_angle\n\n        # Finally calculate the angle:\n        angle = np.arctan2(sin_angle, cos_angle)\n        return angle, axis, invert", "response": "Rotation properties for the current object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef matrix(self):\n        result = np.identity(4, float)\n        result[0:3, 0:3] = self.r\n        return result", "response": "The 4x4 matrix representation of this rotation"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef inv(self):\n        result = Rotation(self.r.transpose())\n        result._cache_inv = self\n        return result", "response": "The inverse rotation of the current object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef apply_to(self, x, columns=False):\n        if isinstance(x, np.ndarray) and len(x.shape) == 2 and x.shape[0] == 3 and columns:\n            return np.dot(self.r, x)\n        if isinstance(x, np.ndarray) and (x.shape == (3, ) or (len(x.shape) == 2 and x.shape[1] == 3)) and not columns:\n            return np.dot(x, self.r.transpose())\n        elif isinstance(x, Complete):\n            return Complete(np.dot(self.r, x.r), np.dot(self.r, x.t))\n        elif isinstance(x, Translation):\n            return Complete(self.r, np.dot(self.r, x.t))\n        elif isinstance(x, Rotation):\n            return Rotation(np.dot(self.r, x.r))\n        elif isinstance(x, UnitCell):\n            return UnitCell(np.dot(self.r, x.matrix), x.active)\n        else:\n            raise ValueError(\"Can not apply this rotation to %s\" % x)", "response": "Apply this rotation to the given object x."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compare(self, other, r_threshold=1e-3):\n        return compute_rmsd(self.r, other.r) < r_threshold", "response": "Compare two rotations returning True if the RMSD of the rotation matrices is below the threshold."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_properties(cls, angle, axis, invert, translation):\n        rot = Rotation.from_properties(angle, axis, invert)\n        return Complete(rot.r, translation)", "response": "Initialize a transformation based on the properties"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cast(cls, c):\n        if isinstance(c, Complete):\n            return c\n        elif isinstance(c, Translation):\n            return Complete(np.identity(3, float), c.t)\n        elif isinstance(c, Rotation):\n            return Complete(c.r, np.zeros(3, float))", "response": "Convert the first argument into a Complete object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef about_axis(cls, center, angle, axis, invert=False):\n        return Translation(center) * \\\n               Rotation.from_properties(angle, axis, invert) * \\\n               Translation(-center)", "response": "Create transformation that represents a rotation about an axis"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compare(self, other, t_threshold=1e-3, r_threshold=1e-3):\n        return compute_rmsd(self.t, other.t) < t_threshold and compute_rmsd(self.r, other.r) < r_threshold", "response": "Compare two transformations\n\n           The RMSD values of the rotation matrices and the translation vectors\n           are computed. The return value is True when the RMSD values are below\n           the thresholds, i.e. when the two transformations are almost\n           identical."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread and return the next time frame.", "response": "def _read_frame(self):\n        \"\"\"Read and return the next time frame\"\"\"\n        # Read one frame, we assume that the current file position is at the\n        # line 'ITEM: TIMESTEP' and that this line marks the beginning of a\n        # time frame.\n        line = next(self._f)\n        if line != 'ITEM: TIMESTEP\\n':\n            raise FileFormatError(\"Expecting line 'ITEM: TIMESTEP' at the beginning of a time frame.\")\n        try:\n            line = next(self._f)\n            step = int(line)\n        except ValueError:\n            raise FileFormatError(\"Could not read the step number. Expected an integer. Got '%s'\" % line[:-1])\n\n        # Now we assume that the next section contains (again) the number of\n        # atoms.\n        line = next(self._f)\n        if line != 'ITEM: NUMBER OF ATOMS\\n':\n            raise FileFormatError(\"Expecting line 'ITEM: NUMBER OF ATOMS'.\")\n        try:\n            line = next(self._f)\n            num_atoms = int(line)\n        except ValueError:\n            raise FileFormatError(\"Could not read the number of atoms. Expected an integer. Got '%s'\" % line[:-1])\n        if num_atoms != self.num_atoms:\n            raise FileFormatError(\"A variable number of atoms is not supported.\")\n\n        # The next section contains the box boundaries. We will skip it\n        for i in range(4):\n            next(self._f)\n\n        # The next and last section contains the atom related properties\n        line = next(self._f)\n        if line != 'ITEM: ATOMS\\n':\n            raise FileFormatError(\"Expecting line 'ITEM: ATOMS'.\")\n        fields = [list() for i in range(len(self.units))]\n        for i in range(self.num_atoms):\n            line = next(self._f)\n            words = line.split()[1:]\n            for j in range(len(fields)):\n                fields[j].append(float(words[j]))\n        fields = [step] + [np.array(field)*unit for field, unit in zip(fields, self.units)]\n\n        return fields"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nskip the next time frame", "response": "def _skip_frame(self):\n        \"\"\"Skip the next time frame\"\"\"\n        for line in self._f:\n            if line == 'ITEM: ATOMS\\n':\n                break\n        for i in range(self.num_atoms):\n            next(self._f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds an atom info object to the database", "response": "def _add_atom_info(self, atom_info):\n        \"\"\"Add an atom info object to the database\"\"\"\n        self.atoms_by_number[atom_info.number] = atom_info\n        self.atoms_by_symbol[atom_info.symbol.lower()] = atom_info"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextend the current cluster with data from another cluster", "response": "def update(self, other):\n        \"\"\"Extend the current cluster with data from another cluster\"\"\"\n        Cluster.update(self, other)\n        self.rules.extend(other.rules)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_related(self, *objects):\n        master = None # this will become the common cluster of all related items\n        slaves = set([]) # set of clusters that are going to be merged in the master\n        solitaire = set([]) # set of new items that are not yet part of a cluster\n        for new in objects:\n            if isinstance(new, self.cls):\n                if master is None:\n                    master = new\n                else:\n                    slaves.add(new)\n                for item in new.items:\n                    existing = self.lookup.get(item)\n                    if existing is not None:\n                        slaves.add(existing)\n            else:\n                cluster = self.lookup.get(new)\n                if cluster is None:\n                    #print \"solitaire\", new\n                    solitaire.add(new)\n                elif master is None:\n                    #print \"starting master\", new\n                    master = cluster\n                elif master != cluster:\n                    #print \"in slave\", new\n                    slaves.add(cluster)\n                #else:\n                    ##nothing to do\n                    #print \"new in master\", new\n\n        if master is None:\n            master = self.cls([])\n\n        for slave in slaves:\n            master.update(slave)\n        for item in solitaire:\n            master.add_item(item)\n\n        for item in master.items:\n            self.lookup[item] = master", "response": "Add related items to the common cluster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a single time frame from the trajectory.", "response": "def _read_frame(self):\n        \"\"\"Read a single frame from the trajectory\"\"\"\n        # auxiliary read function\n        def read_three(msg):\n            \"\"\"Read three words as floating point numbers\"\"\"\n            line = next(self._f)\n            try:\n                return [float(line[:12]), float(line[12:24]), float(line[24:])]\n            except ValueError:\n                raise FileFormatError(msg)\n\n        frame = {}\n        # read the frame header line\n        words = next(self._f).split()\n        if len(words) != 6:\n            raise FileFormatError(\"The first line of each time frame must contain 6 words. (%i'th frame)\" % self._counter)\n        if words[0] != \"timestep\":\n            raise FileFormatError(\"The first word of the first line of each time frame must be 'timestep'. (%i'th frame)\" % self._counter)\n        try:\n            step = int(words[1])\n            frame[\"step\"] = step\n            if int(words[2]) != self.num_atoms:\n                raise FileFormatError(\"The number of atoms has changed. (%i'th frame, %i'th step)\" % (self._counter, step))\n            if int(words[3]) != self.keytrj:\n                raise FileFormatError(\"keytrj has changed. (%i'th frame, %i'th step)\" % (self._counter, step))\n            if int(words[4]) != self.imcon:\n                raise FileFormatError(\"imcon has changed. (%i'th frame, %i'th step)\" % (self._counter, step))\n            frame[\"timestep\"] = float(words[5])*self.time_unit\n            frame[\"time\"] = frame[\"timestep\"]*step # this is ugly, or wait ... dlpoly is a bit ugly. we are not to blame!\n        except ValueError:\n            raise FileFormatError(\"Could not convert all numbers on the first line of the current time frame. (%i'th frame)\" % self._counter)\n        # the three cell lines\n        cell = np.zeros((3, 3), float)\n        frame[\"cell\"] = cell\n        cell_msg = \"The cell lines must consist of three floating point values. (%i'th frame, %i'th step)\" % (self._counter, step)\n        for i in range(3):\n            cell[:, i] = read_three(cell_msg)\n        cell *= self.pos_unit\n        # the atoms\n        symbols = []\n        frame[\"symbols\"] = symbols\n        masses = np.zeros(self.num_atoms, float)\n        frame[\"masses\"] = masses\n        charges = np.zeros(self.num_atoms, float)\n        frame[\"charges\"] = charges\n        pos = np.zeros((self.num_atoms, 3), float)\n        frame[\"pos\"] = pos\n        if self.keytrj > 0:\n            vel = np.zeros((self.num_atoms, 3), float)\n            frame[\"vel\"] = vel\n        if self.keytrj > 1:\n            frc = np.zeros((self.num_atoms, 3), float)\n            frame[\"frc\"] = frc\n        for i in range(self.num_atoms):\n            # the atom header line\n            words = next(self._f).split()\n            if len(words) != 4:\n                raise FileFormatError(\"The atom header line must contain 4 words. (%i'th frame, %i'th step, %i'th atom)\" % (self._counter, step, i+1))\n            symbols.append(words[0])\n            try:\n                masses[i] = float(words[2])*self.mass_unit\n                charges[i] = float(words[3])\n            except ValueError:\n                raise FileFormatError(\"The numbers in the atom header line could not be interpreted.\")\n            # the pos line\n            pos_msg = \"The position lines must consist of three floating point values. (%i'th frame, %i'th step, %i'th atom)\" % (self._counter, step, i+1)\n            pos[i] = read_three(pos_msg)\n            if self.keytrj > 0:\n                vel_msg = \"The velocity lines must consist of three floating point values. (%i'th frame, %i'th step, %i'th atom)\" % (self._counter, step, i+1)\n                vel[i] = read_three(vel_msg)\n            if self.keytrj > 1:\n                frc_msg = \"The force lines must consist of three floating point values. (%i'th frame, %i'th step, %i'th atom)\" % (self._counter, step, i+1)\n                frc[i] = read_three(frc_msg)\n        pos *= self.pos_unit # convert to au\n        if self.keytrj > 0:\n            vel *= self.vel_unit # convert to au\n        if self.keytrj > 1:\n            frc *= self.frc_unit # convert to au\n        return frame"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef goto_next_frame(self):\n        marked = False\n        while True:\n            line = next(self._f)[:-1]\n            if marked and len(line) > 0 and not line.startswith(\" --------\"):\n                try:\n                    step = int(line[:10])\n                    return step, line\n                except ValueError:\n                    pass\n            marked = (len(line) == 131 and line == self._marker)", "response": "Continue reading until the next frame is reached"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _read_frame(self):\n        # optionally skip the equilibration\n        if self.skip_equi_period:\n            while True:\n                step, line = self.goto_next_frame()\n                self._counter += 1\n                if step >= self.equi_period:\n                    break\n            self.skip_equi_period = False\n        else:\n            step, line = self.goto_next_frame()\n\n        # read the three lines\n        try:\n            row = [step]\n            for i in range(9):\n                row.append(float(line[10+i*12:10+(i+1)*12]))\n            line = next(self._f)[:-1]\n            row.append(float(line[:10]))\n            for i in range(9):\n                row.append(float(line[10+i*12:10+(i+1)*12]))\n            line = next(self._f)[:-1]\n            row.append(float(line[:10]))\n            for i in range(9):\n                row.append(float(line[10+i*12:10+(i+1)*12]))\n        except ValueError:\n            raise FileFormatError(\"Some numbers in the output file could not be read. (expecting floating point numbers)\")\n\n        # convert all the numbers to atomic units\n        for i in range(30):\n            row[i] *= self._conv[i]\n\n        # done\n        return row", "response": "Read a single frame from the trajectory"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _read_frame(self):\n\n        size = self.read_size()\n        title = self._f.readline()[:-1]\n        if self.symbols is None:\n            symbols = []\n        coordinates = np.zeros((size, 3), float)\n        for counter in range(size):\n            line = self._f.readline()\n            if len(line) == 0:\n                raise StopIteration\n            words = line.split()\n            if len(words) < 4:\n                raise StopIteration\n            if self.symbols is None:\n                symbols.append(words[0])\n            try:\n                coordinates[counter, 0] = float(words[1])\n                coordinates[counter, 1] = float(words[2])\n                coordinates[counter, 2] = float(words[3])\n            except ValueError:\n                raise StopIteration\n        coordinates *= self.file_unit\n        if self.symbols is None:\n            self.symbols = symbols\n        return title, coordinates", "response": "Read a single frame from the XYZ file"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nskips a single frame from the trajectory", "response": "def _skip_frame(self):\n        \"\"\"Skip a single frame from the trajectory\"\"\"\n        size = self.read_size()\n        for i in range(size+1):\n            line = self._f.readline()\n            if len(line) == 0:\n                raise StopIteration"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the first molecule from the trajectory", "response": "def get_first_molecule(self):\n        \"\"\"Get the first molecule from the trajectory\n\n           This can be useful to configure your program before handeling the\n           actual trajectory.\n        \"\"\"\n        title, coordinates = self._first\n        molecule = Molecule(self.numbers, coordinates, title, symbols=self.symbols)\n        return molecule"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dump(self, title, coordinates):\n        print(\"% 8i\" % len(self.symbols), file=self._f)\n        print(str(title), file=self._f)\n        for symbol, coordinate in zip(self.symbols, coordinates):\n            print(\"% 2s % 12.9f % 12.9f % 12.9f\" % ((symbol, ) + tuple(coordinate/self.file_unit)), file=self._f)", "response": "Dump a frame to the trajectory file\n\n          "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_molecule(self, index=0):\n        return Molecule(self.numbers, self.geometries[index], self.titles[index], symbols=self.symbols)", "response": "Returns a Molecule object from the trajectory\n\n           Optional argument index = 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_to_file(self, f, file_unit=angstrom):\n        xyz_writer = XYZWriter(f, self.symbols, file_unit=file_unit)\n        for title, coordinates in zip(self.titles, self.geometries):\n            xyz_writer.dump(title, coordinates)", "response": "Write the trajectory to a file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef slice_match(sub, counter):\n\n    if sub.start is not None and counter < sub.start:\n        return False\n    if sub.stop is not None and counter >= sub.stop:\n        raise StopIteration\n    if sub.step is not None:\n        if sub.start is None:\n            if counter % sub.step != 0:\n                return False\n        else:\n            if (counter - sub.start) % sub.step != 0:\n                return False\n    return True", "response": "Efficiently test if the counter is in the sequence of objects in the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck the analytical gradient using finite differences", "response": "def check_anagrad(fun, x0, epsilon, threshold):\n    \"\"\"Check the analytical gradient using finite differences\n\n       Arguments:\n        | ``fun``  --  the function to be tested, more info below\n        | ``x0``  --  the reference point around which the function should be\n                      tested\n        | ``epsilon``  --  a small scalar used for the finite differences\n        | ``threshold``  --  the maximum acceptable difference between the\n                             analytical gradient and the gradient obtained by\n                             finite differentiation\n\n       The function ``fun`` takes a mandatory argument ``x`` and an optional\n       argument ``do_gradient``:\n        | ``x``  --  the arguments of the function to be tested\n        | ``do_gradient``  --  When False, only the function value is returned.\n                               When True, a 2-tuple with the function value and\n                               the gradient are returned [default=False]\n    \"\"\"\n    N = len(x0)\n    f0, ana_grad = fun(x0, do_gradient=True)\n    for i in range(N):\n        xh = x0.copy()\n        xh[i] += 0.5*epsilon\n        xl = x0.copy()\n        xl[i] -= 0.5*epsilon\n        num_grad_comp = (fun(xh)-fun(xl))/epsilon\n        if abs(num_grad_comp - ana_grad[i]) > threshold:\n            raise AssertionError(\"Error in the analytical gradient, component %i, got %s, should be about %s\" % (i, ana_grad[i], num_grad_comp))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck the difference between two functions using the analytical gradient.", "response": "def check_delta(fun, x, dxs, period=None):\n    \"\"\"Check the difference between two function values using the analytical gradient\n\n       Arguments:\n        | ``fun``  --  The function to be tested, more info below.\n        | ``x``  --  The argument vector.\n        | ``dxs``  --  A matrix where each row is a vector of small differences\n                       to be added to the argument vector.\n\n       Optional argument:\n        | ``period``  --  If the function value is periodic, one may provide the\n                          period such that differences are computed using\n                          periodic boundary conditions.\n\n       The function ``fun`` takes a mandatory argument ``x`` and an optional\n       argument ``do_gradient``:\n        | ``x``  --  The arguments of the function to be tested.\n        | ``do_gradient``  --  When False, only the function value is returned.\n                               When True, a 2-tuple with the function value and\n                               the gradient are returned. [default=False]\n\n       For every row in dxs, the following computation is repeated:\n\n       1) D1 = 'f(x+dx) - f(x)' is computed.\n       2) D2 = '0.5 (grad f(x+dx) + grad f(x)) . dx' is computed.\n\n       A threshold is set to the median of the D1 set. For each case where |D1|\n       is larger than the threshold, |D1 - D2|, should be smaller than the\n       threshold.\n    \"\"\"\n    dn1s = []\n    dn2s = []\n    dnds = []\n    for dx in dxs:\n        f0, grad0 = fun(x, do_gradient=True)\n        f1, grad1 = fun(x+dx, do_gradient=True)\n        grad = 0.5*(grad0+grad1)\n        d1 = f1 - f0\n        if period is not None:\n            d1 -= np.floor(d1/period + 0.5)*period\n        if hasattr(d1, '__iter__'):\n            norm = np.linalg.norm\n        else:\n            norm = abs\n        d2 = np.dot(grad, dx)\n\n        dn1s.append(norm(d1))\n        dn2s.append(norm(d2))\n        dnds.append(norm(d1-d2))\n    dn1s = np.array(dn1s)\n    dn2s = np.array(dn2s)\n    dnds = np.array(dnds)\n\n    # Get the threshold (and mask)\n    threshold = np.median(dn1s)\n    mask = dn1s > threshold\n    # Make sure that all cases for which dn1 is above the treshold, dnd is below\n    # the threshold\n    if not (dnds[mask] < threshold).all():\n        raise AssertionError((\n            'The first order approximation on the difference is too wrong. The '\n            'threshold is %.1e.\\n\\nDifferences:\\n%s\\n\\nFirst order '\n            'approximation to differences:\\n%s\\n\\nAbsolute errors:\\n%s')\n            % (threshold,\n            ' '.join('%.1e' % v for v in dn1s[mask]),\n            ' '.join('%.1e' % v for v in dn2s[mask]),\n            ' '.join('%.1e' % v for v in dnds[mask])\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the Hessian using the finite difference method.", "response": "def compute_fd_hessian(fun, x0, epsilon, anagrad=True):\n    \"\"\"Compute the Hessian using the finite difference method\n\n       Arguments:\n        | ``fun``  --  the function for which the Hessian should be computed,\n                       more info below\n        | ``x0``  --  the point at which the Hessian must be computed\n        | ``epsilon``  --  a small scalar step size used to compute the finite\n                           differences\n\n       Optional argument:\n        | ``anagrad``  --  when True, analytical gradients are used\n                           [default=True]\n\n       The function ``fun`` takes a mandatory argument ``x`` and an optional\n       argument ``do_gradient``:\n        | ``x``  --  the arguments of the function to be tested\n        | ``do_gradient``  --  When False, only the function value is returned.\n                               When True, a 2-tuple with the function value and\n                               the gradient are returned [default=False]\n    \"\"\"\n    N = len(x0)\n\n    def compute_gradient(x):\n        if anagrad:\n            return fun(x, do_gradient=True)[1]\n        else:\n            gradient = np.zeros(N, float)\n            for i in range(N):\n                xh = x.copy()\n                xh[i] += 0.5*epsilon\n                xl = x.copy()\n                xl[i] -= 0.5*epsilon\n                gradient[i] = (fun(xh)-fun(xl))/epsilon\n            return gradient\n\n    hessian = np.zeros((N,N), float)\n    for i in range(N):\n        xh = x0.copy()\n        xh[i] += 0.5*epsilon\n        xl = x0.copy()\n        xl[i] -= 0.5*epsilon\n        hessian[i] = (compute_gradient(xh) - compute_gradient(xl))/epsilon\n\n    return 0.5*(hessian + hessian.transpose())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, gradient, step):\n        do_sd = self.gradient_old is None\n        self.gradient_old = self.gradient\n        self.gradient = gradient\n        if do_sd:\n            self._update_sd()\n        else:\n            self._update_cg()", "response": "Update the search direction given the latest gradient and step"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _update_cg(self):\n        beta = self._beta()\n        # Automatic direction reset\n        if beta < 0:\n            self.direction = -self.gradient\n            self.status = \"SD\"\n        else:\n            self.direction = self.direction * beta - self.gradient\n            self.status = \"CG\"", "response": "Update the conjugate gradient"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the search direction given the latest gradient and step", "response": "def update(self, gradient, step):\n        \"\"\"Update the search direction given the latest gradient and step\"\"\"\n        self.old_gradient = self.gradient\n        self.gradient = gradient\n        N = len(self.gradient)\n        if self.inv_hessian is None:\n            # update the direction\n            self.direction = -self.gradient\n            self.status = \"SD\"\n            # new guess of the inverse hessian\n            self.inv_hessian = np.identity(N, float)\n        else:\n            # update the direction\n            self.direction = -np.dot(self.inv_hessian, self.gradient)\n            self.status = \"QN\"\n            # new guess of the inverse hessian (BFGS)\n            y = self.gradient - self.old_gradient\n            s = step\n            sy = abs(np.dot(s, y))+1e-5\n            A = np.outer(-y/sy, s)\n            A.ravel()[::N+1] += 1\n            self.inv_hessian = (\n                np.dot(np.dot(A.transpose(), self.inv_hessian), A) +\n                np.outer(s/sy, s)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef limit_step(self, step):\n        if self.qmax is None:\n            return step\n        else:\n            return np.clip(step, -self.qmax, self.qmax)", "response": "Clip the a step within the maximum allowed range"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _bracket(self, qinit, f0, fun):\n        self.num_bracket = 0\n        qa = qinit\n        fa = fun(qa)\n        counter = 0\n        if fa >= f0:\n            while True:\n                self.num_bracket += 1\n                #print \"    bracket shrink\"\n                qb, fb = qa, fa\n                qa /= 1+phi\n                fa = fun(qa)\n                if qa < self.qtol:\n                    return\n                if fa < f0:\n                    return (0, f0), (qa, fa), (qb, fb)\n                counter += 1\n                if self.max_iter is not None and counter > self.max_iter:\n                    return\n        else:\n            self.num_bracket += 1\n            #print \"    bracket grow1\"\n            qb, fb = qa, fa\n            qa *= (1+phi)\n            fa = fun(qa)\n            if fa >= fb:\n                return (0, f0), (qb, fb), (qa, fa)\n            while True:\n                self.num_bracket += 1\n                #print \"    bracket grow2\"\n                qc, fc = qb, fb\n                qb, fb = qa, fa\n                qa = qb*(1+phi) - qc\n                fa = fun(qa)\n                if fa >= fb:\n                    return (qc, fc), (qb, fb), (qa, fa)\n                counter += 1\n                if self.max_iter is not None and counter > self.max_iter:\n                    return", "response": "Find a bracket that does contain the minimum"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreduces the size of the bracket until the minimum is found", "response": "def _golden(self, triplet, fun):\n        \"\"\"Reduce the size of the bracket until the minimum is found\"\"\"\n        self.num_golden = 0\n        (qa, fa), (qb, fb), (qc, fc) = triplet\n        while True:\n            self.num_golden += 1\n            qd = qa + (qb-qa)*phi/(1+phi)\n            fd = fun(qd)\n            if fd < fb:\n                #print \"golden d\"\n                (qa, fa), (qb, fb) = (qb, fb), (qd, fd)\n            else:\n                #print \"golden b\"\n                (qa, fa), (qc, fc) = (qd, fd), (qa, fa)\n            if abs(qa-qb) < self.qtol:\n                return qc, fc"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, counter, f, x_orig, gradient_orig):\n        if counter - self.last_update > self.each:\n            grad_rms = np.sqrt((gradient_orig**2).mean())\n            if grad_rms < self.grad_rms:\n                self.last_update = counter\n                return True\n        return False", "response": "Perform an update of the linear transformation of the given object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, counter, f, x_orig, gradient_orig):\n        do_update = Preconditioner.update(self, counter, f, x_orig, gradient_orig)\n        if do_update:\n            # determine a new preconditioner\n            N = len(x_orig)\n            if self.scales is None:\n                self.scales = np.ones(N, float)\n            for i in range(N):\n                epsilon = self.epsilon/self.scales[i]\n                xh = x_orig.copy()\n                xh[i] += 0.5*epsilon\n                fh = self.fun(xh)\n                xl = x_orig.copy()\n                xl[i] -= 0.5*epsilon\n                fl = self.fun(xl)\n                curv = (fh+fl-2*f)/epsilon**2\n                self.scales[i] = np.sqrt(abs(curv))\n            if self.scales.max() <= 0:\n                self.scales = np.ones(N, float)\n            else:\n                self.scales /= self.scales.max()\n                self.scales[self.scales<self.scale_limit] = self.scale_limit\n        return do_update", "response": "Perform an update of the linear transformation of the minimizer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, counter, f, x_orig, gradient_orig):\n        if Preconditioner.update(self, counter, f, x_orig, gradient_orig):\n            # determine a new preconditioner\n            hessian = compute_fd_hessian(self.fun, x_orig, self.epsilon)\n            evals, evecs = np.linalg.eigh(hessian)\n            self.scales = np.sqrt(abs(evals))+self.epsilon\n            self.rotation = evecs\n            return True\n        return False", "response": "Perform an update of the linear transformation of the minimizer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do(self, x_orig):\n        if self.scales is None:\n            return x_orig\n        else:\n            return np.dot(self.rotation.transpose(), x_orig)*self.scales", "response": "Transform the unknowns to preconditioned coordinates\n\n           This method transforms the gradient to original coordinates\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntransforms the unknowns to original coordinates This method also transforms the gradient to preconditioned coordinates Integrity", "response": "def undo(self, x_prec):\n        \"\"\"Transform the unknowns to original coordinates\n\n           This method also transforms the gradient to preconditioned coordinates\n        \"\"\"\n        if self.scales is None:\n            return x_prec\n        else:\n            return np.dot(self.rotation, x_prec/self.scales)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_header(self):\n        result = \" \"\n        if self.step_rms is not None:\n            result += \"    Step RMS\"\n        if self.step_max is not None:\n            result += \"    Step MAX\"\n        if self.grad_rms is not None:\n            result += \"    Grad RMS\"\n        if self.grad_max is not None:\n            result += \"    Grad MAX\"\n        if self.rel_grad_rms is not None:\n            result += \"  Grad/F RMS\"\n        if self.rel_grad_max is not None:\n            result += \"  Grad/F MAX\"\n        return result", "response": "Returns the header for screen logging of the minimization"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconfigure the 1D function for a line search", "response": "def configure(self, x0, axis):\n        \"\"\"Configure the 1D function for a line search\n\n           Arguments:\n             x0  --  the reference point (q=0)\n             axis  --  a unit vector in the direction of the line search\n        \"\"\"\n        self.x0 = x0\n        self.axis = axis"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the values and normals of active constraints.", "response": "def _compute_equations(self, x, verbose=False):\n        '''Compute the values and the normals (gradients) of active constraints.\n\n           Arguments:\n            | ``x`` -- The unknowns.\n        '''\n        # compute the error and the normals.\n        normals = []\n        values = []\n        signs = []\n        error = 0.0\n        if verbose:\n            print()\n            print(' '.join('% 10.3e' % val for val in x), end=' ')\n            active_str = ''\n        for i, (sign, equation) in enumerate(self.equations):\n            value, normal = equation(x)\n            if (i < len(self.lock) and self.lock[i]) or \\\n               (sign==-1 and value > -self.threshold) or \\\n               (sign==0) or (sign==1 and value < self.threshold):\n                values.append(value)\n                normals.append(normal)\n                signs.append(sign)\n                error += value**2\n                if verbose:\n                    active_str += 'X'\n                if i < len(self.lock):\n                    self.lock[i] = True\n            elif verbose:\n                active_str += '-'\n        error = np.sqrt(error)\n        normals = np.array(normals, float)\n        values = np.array(values, float)\n        signs = np.array(signs, int)\n        if verbose:\n            print('[%s]' % active_str, end=' ')\n            if error < self.threshold:\n                print('OK')\n            else:\n                print('%.5e' % error)\n        return normals, values, error, signs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _rough_shake(self, x, normals, values, error):\n        '''Take a robust, but not very efficient step towards the constraints.\n\n           Arguments:\n            | ``x`` -- The unknowns.\n            | ``normals`` -- A numpy array with the gradients of the active\n                             constraints. Each row is one gradient.\n            | ``values`` -- A numpy array with the values of the constraint\n                            functions.\n            | ``error`` -- The square root of the constraint cost function.\n        '''\n        counter = 0\n        while error > self.threshold and counter < self.max_iter:\n            dxs = []\n            for i in range(len(normals)):\n                dx = -normals[i]*values[i]/np.dot(normals[i], normals[i])\n                dxs.append(dx)\n            dxs = np.array(dxs)\n            dx = dxs[abs(values).argmax()]\n            x = x+dx\n            self.lock[:] = False\n            normals, values, error = self._compute_equations(x)[:-1]\n            counter += 1\n        return x, normals, values, error", "response": "Take a robust but not very efficient step towards the constraints."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fast_shake(self, x, normals, values, error):\n        '''Take an efficient (not always robust) step towards the constraints.\n\n           Arguments:\n            | ``x`` -- The unknowns.\n            | ``normals`` -- A numpy array with the gradients of the active\n                             constraints. Each row is one gradient.\n            | ``values`` -- A numpy array with the values of the constraint\n                            functions.\n            | ``error`` -- The square root of the constraint cost function.\n        '''\n        # filter out the degrees of freedom that do not feel the constraints.\n        mask = (normals!=0).any(axis=0) > 0\n        normals = normals[:,mask]\n        # Take a step to lower the constraint cost function. If the step is too\n        # large, it is reduced iteratively towards a small steepest descent\n        # step. This is very similar to the Levenberg-Marquardt algorithm.\n        # Singular Value decomposition is used to make this procedure\n        # numerically more stable and efficient.\n        U, S, Vt = np.linalg.svd(normals, full_matrices=False)\n        rcond = None\n        counter = 0\n        while True:\n            if rcond is None:\n                rcond = 0.0\n            elif rcond == 0.0:\n                rcond = self.rcond1\n            else:\n                rcond *= 10\n            # perform the least-norm correction\n            Sinv = (S**2+rcond)\n            if Sinv.max() == 0.0:\n                continue\n            Sinv = S/Sinv\n            # compute the step\n            dx = -np.dot(Vt.transpose(), np.dot(U.transpose(), values)*Sinv)\n            new_x = x.copy()\n            new_x[mask] += dx\n            # try the step\n            new_normals, new_values, new_error = self._compute_equations(new_x)[:-1]\n            if new_error < 0.9*error:\n                # Only if it decreases the constraint cost sufficiently, the\n                # step is accepted. This routine is pointless of it converges\n                # slowly.\n                return new_x, new_normals, new_values, new_error\n            elif abs(dx).sum() < self.threshold:\n                # If the step becomes too small, then give up.\n                break\n            elif counter > self.max_iter:\n                raise ConstraintError('Exceeded maximum number of shake iterations.')\n            counter += 1", "response": "This routine is used to fast shake the active set of unknowns."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbring unknowns to the constraints.", "response": "def free_shake(self, x):\n        '''Brings unknowns to the constraints.\n\n           Arguments:\n            | ``x`` -- The unknowns.\n        '''\n        self.lock[:] = False\n        normals, values, error = self._compute_equations(x)[:-1]\n        counter = 0\n        while True:\n            if error <= self.threshold:\n                break\n            # try a well-behaved move to the constrains\n            result = self._fast_shake(x, normals, values, error)\n            counter += 1\n            if result is not None:\n                x, normals, values, error = result\n            else:\n                # well-behaved move is too slow.\n                # do a cumbersome move to satisfy constraints approximately.\n                x, normals, values, error = self._rough_shake(x, normals, values, error)\n                counter += 1\n            # When too many iterations are required, just give up.\n            if counter > self.max_iter:\n                raise ConstraintError('Exceeded maximum number of shake iterations.')\n        return x, counter, len(values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef safe_shake(self, x, fun, fmax):\n        '''Brings unknowns to the constraints, without increasing fun above fmax.\n\n           Arguments:\n            | ``x`` -- The unknowns.\n            | ``fun`` -- The function being minimized.\n            | ``fmax`` -- The highest allowed value of the function being\n                          minimized.\n\n           The function ``fun`` takes a mandatory argument ``x`` and an optional\n           argument ``do_gradient``:\n            | ``x``  --  the arguments of the function to be tested\n            | ``do_gradient``  --  when False, only the function value is\n                                   returned. when True, a 2-tuple with the\n                                   function value and the gradient are returned\n                                   [default=False]\n        '''\n        self.lock[:] = False\n        def extra_equation(xx):\n            f, g = fun(xx, do_gradient=True)\n            return (f-fmax)/abs(fmax), g/abs(fmax)\n        self.equations.append((-1,extra_equation))\n        x, shake_counter, constraint_couter = self.free_shake(x)\n        del self.equations[-1]\n        return x, shake_counter, constraint_couter", "response": "Brings unknowns to the constraints without increasing fun above fmax."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef project(self, x, vector):\n        '''Project a vector (gradient or direction) on the active constraints.\n\n           Arguments:\n            | ``x`` -- The unknowns.\n            | ``vector`` -- A numpy array with a direction or a gradient.\n\n           The return value is a gradient or direction, where the components\n           that point away from the constraints are projected out. In case of\n           half-open constraints, the projection is only active of the vector\n           points into the infeasible region.\n        '''\n        scale = np.linalg.norm(vector)\n        if scale == 0.0:\n            return vector\n        self.lock[:] = False\n        normals, signs = self._compute_equations(x)[::3]\n        if len(normals) == 0:\n            return vector\n\n        vector = vector/scale\n        mask = signs == 0\n        result = vector.copy()\n        changed = True\n        counter = 0\n        while changed:\n            changed = False\n            y = np.dot(normals, result)\n            for i, sign in enumerate(signs):\n                if sign != 0:\n                    if sign*y[i] < -self.threshold:\n                        mask[i] = True\n                        changed = True\n                    elif mask[i] and np.dot(normals[i], result-vector) < 0:\n                        mask[i] = False\n                        changed = True\n\n            if mask.any():\n                normals_select = normals[mask]\n                y = np.dot(normals_select, vector)\n                U, S, Vt = np.linalg.svd(normals_select, full_matrices=False)\n                if S.min() == 0.0:\n                    Sinv = S/(S**2+self.rcond1)\n                else:\n                    Sinv = 1.0/S\n                result = vector - np.dot(Vt.transpose(), np.dot(U.transpose(), y)*Sinv)\n            else:\n                result = vector.copy()\n\n            if counter > self.max_iter:\n                raise ConstraintError('Exceeded maximum number of shake iterations.')\n            counter += 1\n\n        return result*scale", "response": "Project a vector on the active constraints."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the final solution in the original coordinates", "response": "def get_final(self):\n        \"\"\"Return the final solution in the original coordinates\"\"\"\n        if self.prec is None:\n            return self.x\n        else:\n            return self.prec.undo(self.x)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _run(self):\n        success = self.initialize()\n        while success is None:\n            success = self.propagate()\n        return success", "response": "Run the iterative optimizer"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _print_header(self):\n        header = \" Iter  Dir  \"\n        if self.constraints is not None:\n            header += '  SC CC'\n        header += \"         Function\"\n        if self.convergence_condition is not None:\n            header += self.convergence_condition.get_header()\n        header += \"    Time\"\n        self._screen(\"-\"*(len(header)), newline=True)\n        self._screen(header, newline=True)\n        self._screen(\"-\"*(len(header)), newline=True)", "response": "Print the header for screen logging"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting something on screen when self. verbose == True", "response": "def _screen(self, s, newline=False):\n        \"\"\"Print something on screen when self.verbose == True\"\"\"\n        if self.verbose:\n            if newline:\n                print(s)\n            else:\n                print(s, end=' ')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _line_opt(self):\n        direction = self.search_direction.direction\n        if self.constraints is not None:\n            try:\n                direction = self.constraints.project(self.x, direction)\n            except ConstraintError:\n                self._screen(\"CONSTRAINT PROJECT FAILED\", newline=True)\n                return False\n        direction_norm = np.linalg.norm(direction)\n        if direction_norm == 0:\n            return False\n        self.line.configure(self.x, direction/direction_norm)\n\n        success, wolfe, qopt, fopt = \\\n            self.line_search(self.line, self.initial_step_size, self.epsilon)\n        if success:\n            self.step = qopt*self.line.axis\n            self.initial_step_size = np.linalg.norm(self.step)\n            self.x = self.x + self.step\n            self.f = fopt\n            if wolfe:\n                self._screen(\"W\")\n            else:\n                self._screen(\" \")\n                self.search_direction.reset()\n            return True\n        else:\n            if self.debug_line:\n                import matplotlib.pyplot as pt\n                import datetime\n                pt.clf()\n                qs = np.arange(0.0, 100.1)*(5*self.initial_step_size/100.0)\n                fs = np.array([self.line(q) for q in qs])\n                pt.plot(qs, fs)\n                pt.xlim(qs[0], qs[-1])\n                fdelta = fs.max() - fs.min()\n                if fdelta == 0.0:\n                    fdelta = fs.mean()\n                fmargin = fdelta*0.1\n                pt.ylim(fs.min() - fmargin, fs.max() + fmargin)\n                pt.title('fdelta = %.2e   fmean = %.2e' % (fdelta, fs.mean()))\n                pt.xlabel('Line coordinate, q')\n                pt.ylabel('Function value, f')\n                pt.savefig('line_failed_%s.png' % (datetime.datetime.now().isoformat()))\n            self._reset_state()\n            return False", "response": "Perform a line search along the current direction"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef neighbors(self):\n        neighbors = dict(\n            (vertex, []) for vertex\n            in range(self.num_vertices)\n        )\n        for a, b in self.edges:\n            neighbors[a].append(b)\n            neighbors[b].append(a)\n        # turn lists into frozensets\n        neighbors = dict((key, frozenset(val)) for key, val in neighbors.items())\n        return neighbors", "response": "A dictionary with neighbors of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist of vertices that are only interconnected within each list", "response": "def independent_vertices(self):\n        \"\"\"Lists of vertices that are only interconnected within each list\n\n           This means that there is no path from a vertex in one list to a\n           vertex in another list. In case of a molecular graph, this would\n           yield the atoms that belong to individual molecules.\n        \"\"\"\n        candidates = set(range(self.num_vertices))\n\n        result = []\n        while len(candidates) > 0:\n            pivot = candidates.pop()\n            group = [\n                vertex for vertex, distance\n                in self.iter_breadth_first(pivot)\n            ]\n            candidates.difference_update(group)\n\n            # this sort makes sure that the order of the vertices is respected\n            group.sort()\n            result.append(group)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef equivalent_vertices(self):\n        level1 = {}\n        for i, row in enumerate(self.vertex_fingerprints):\n            key = row.tobytes()\n            l = level1.get(key)\n            if l is None:\n                l = set([i])\n                level1[key] = l\n            else:\n                l.add(i)\n        level2 = {}\n        for key, vertices in level1.items():\n            for vertex in vertices:\n                level2[vertex] = vertices\n        return level2", "response": "A dictionary with symmetrically equivalent vertices."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngraph symmetries that map the graph onto itself.", "response": "def symmetries(self):\n        \"\"\"Graph symmetries (permutations) that map the graph onto itself.\"\"\"\n\n        symmetry_cycles = set([])\n        symmetries = set([])\n        for match in GraphSearch(EqualPattern(self))(self):\n            match.cycles = match.get_closed_cycles()\n            if match.cycles in symmetry_cycles:\n                raise RuntimeError(\"Duplicates in EqualMatch\")\n            symmetry_cycles.add(match.cycles)\n            symmetries.add(match)\n        return symmetries"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iter_breadth_first(self, start=None, do_paths=False, do_duplicates=False):\n        if start is None:\n            start = self.central_vertex\n        else:\n            try:\n                start = int(start)\n            except ValueError:\n                raise TypeError(\"First argument (start) must be an integer.\")\n            if start < 0 or start >= self.num_vertices:\n                raise ValueError(\"start must be in the range [0, %i[\" %\n                                 self.num_vertices)\n        from collections import deque\n        work = np.zeros(self.num_vertices, int)\n        work[:] = -1\n        work[start] = 0\n        if do_paths:\n            result = (start, 0, (start, ))\n        else:\n            result = (start, 0)\n        yield result\n        todo = deque([result])\n        while len(todo) > 0:\n            if do_paths:\n                parent, parent_length, parent_path = todo.popleft()\n            else:\n                parent, parent_length = todo.popleft()\n            current_length = parent_length + 1\n            for current in self.neighbors[parent]:\n                visited = work[current]\n                if visited == -1 or (do_duplicates and visited == current_length):\n                    work[current] = current_length\n                    if do_paths:\n                        current_path = parent_path + (current, )\n                        result = (current, current_length, current_path)\n                    else:\n                        result = (current, current_length)\n                    #print \"iter_breadth_first\", result\n                    yield result\n                    todo.append(result)", "response": "Iterate over the vertices with the breadth - first algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\niterating over the breadth first edges of the current node.", "response": "def iter_breadth_first_edges(self, start=None):\n        \"\"\"Iterate over the edges with the breadth first convention.\n\n           We need this for the pattern matching algorithms, but a quick look at\n           Wikipedia did not result in a known and named algorithm.\n\n           The edges are yielded one by one, together with the distance of the\n           edge from the starting vertex and a flag that indicates whether the\n           yielded edge connects two vertices that are at the same distance from\n           the starting vertex. If that flag is False, the distance from the\n           starting vertex to edge[0] is equal to the distance variable and the\n           distance from edge[1] to the starting vertex is equal to distance+1.\n           One item has the following format: ((i, j), distance, flag)\n        \"\"\"\n        if start is None:\n            start = self.central_vertex\n        else:\n            try:\n                start = int(start)\n            except ValueError:\n                raise TypeError(\"First argument (start) must be an integer.\")\n            if start < 0 or start >= self.num_vertices:\n                raise ValueError(\"start must be in the range [0, %i[\" %\n                                 self.num_vertices)\n        from collections import deque\n        work = np.zeros(self.num_vertices, int)\n        work[:] = -1\n        work[start] = 0\n        todo = deque([start])\n        while len(todo) > 0:\n            parent = todo.popleft()\n            distance = work[parent]\n            for current in self.neighbors[parent]:\n                if work[current] == -1:\n                    yield (parent, current), distance, False\n                    work[current] = distance+1\n                    todo.append(current)\n                elif work[current] == distance and current > parent:\n                    # second equation in elif avoids duplicates\n                    yield (parent, current), distance, True\n                elif work[current] == distance+1:\n                    yield (parent, current), distance, False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_subgraph(self, subvertices, normalize=False):\n        if normalize:\n            revorder = dict((j, i) for i, j in enumerate(subvertices))\n            new_edges = []\n            old_edge_indexes = []\n            for counter, (i, j) in enumerate(self.edges):\n                new_i = revorder.get(i)\n                if new_i is None:\n                    continue\n                new_j = revorder.get(j)\n                if new_j is None:\n                    continue\n                new_edges.append((new_i, new_j))\n                old_edge_indexes.append(counter)\n            # sort the edges\n            order = list(range(len(new_edges)))\n            # argsort in pure python\n            order.sort( key=(lambda i: tuple(sorted(new_edges[i]))) )\n            new_edges = [new_edges[i] for i in order]\n            old_edge_indexes = [old_edge_indexes[i] for i in order]\n\n            result = Graph(new_edges, num_vertices=len(subvertices))\n            result._old_vertex_indexes = np.array(subvertices, dtype=int)\n            #result.new_vertex_indexes = revorder\n            result._old_edge_indexes = np.array(old_edge_indexes, dtype=int)\n        else:\n            subvertices = set(subvertices)\n            old_edge_indexes = np.array([\n                i for i, edge in enumerate(self.edges)\n                if edge.issubset(subvertices)\n            ], dtype=int)\n            new_edges = tuple(self.edges[i] for i in old_edge_indexes)\n            result = Graph(new_edges, self.num_vertices)\n            result._old_edge_indexes = old_edge_indexes\n            # no need for old and new vertex_indexes because they remain the\n            # same.\n        return result", "response": "Constructs a subgraph of the current graph with the given set of subvertices."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_vertex_fingerprints(self, vertex_strings, edge_strings, num_iter=None):\n        import hashlib\n        def str2array(x):\n            \"\"\"convert a hash string to a numpy array of bytes\"\"\"\n            if len(x) == 0:\n                return np.zeros(0, np.ubyte)\n            elif sys.version_info[0] == 2:\n                return np.frombuffer(x, np.ubyte)\n            else:\n                return np.frombuffer(x.encode(), np.ubyte)\n        hashrow = lambda x: np.frombuffer(hashlib.sha1(x.data).digest(), np.ubyte)\n        # initialization\n        result = np.zeros((self.num_vertices, 20), np.ubyte)\n        for i in range(self.num_vertices):\n            result[i] = hashrow(str2array(vertex_strings[i]))\n        for i in range(self.num_edges):\n            a, b = self.edges[i]\n            tmp = hashrow(str2array(edge_strings[i]))\n            result[a] += tmp\n            result[b] += tmp\n        work = result.copy()\n        # iterations\n        if num_iter is None:\n            num_iter = self.max_distance\n        for i in range(num_iter):\n            for a, b in self.edges:\n                work[a] += result[b]\n                work[b] += result[a]\n            #for a in xrange(self.num_vertices):\n            #    for b in xrange(self.num_vertices):\n            #        work[a] += hashrow(result[b]*self.distances[a, b])\n            for a in range(self.num_vertices):\n                result[a] = hashrow(work[a])\n        return result", "response": "Return an array with fingerprints for each vertex"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_halfs(self, vertex1, vertex2):\n        def grow(origin, other):\n            frontier = set(self.neighbors[origin])\n            frontier.discard(other)\n            result = set([origin])\n            while len(frontier) > 0:\n                pivot = frontier.pop()\n                if pivot == other:\n                    raise GraphError(\"The graph can not be separated in two halfs \"\n                                     \"by disconnecting vertex1 and vertex2.\")\n                pivot_neighbors = set(self.neighbors[pivot])\n                pivot_neighbors -= result\n                frontier |= pivot_neighbors\n                result.add(pivot)\n            return result\n\n        vertex1_part = grow(vertex1, vertex2)\n        vertex2_part = grow(vertex2, vertex1)\n        return vertex1_part, vertex2_part", "response": "Split the graph in two halfs by cutting the edge vertex1 - vertex2 and return the vertices in both halfs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_part(self, vertex_in, vertices_border):\n        vertices_new = set(self.neighbors[vertex_in])\n        vertices_part = set([vertex_in])\n\n        while len(vertices_new) > 0:\n            pivot = vertices_new.pop()\n            if pivot in vertices_border:\n                continue\n            vertices_part.add(pivot)\n            pivot_neighbors = set(self.neighbors[pivot])\n            pivot_neighbors -= vertices_part\n            vertices_new |= pivot_neighbors\n\n        return vertices_part", "response": "List all vertices that are connected to vertex_in but are not covered in or behind vertices_border."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_halfs_double(self, vertex_a1, vertex_b1, vertex_a2, vertex_b2):\n        if vertex_a1 not in self.neighbors[vertex_b1]:\n            raise GraphError(\"vertex_a1 must be a neighbor of vertex_b1.\")\n        if vertex_a2 not in self.neighbors[vertex_b2]:\n            raise GraphError(\"vertex_a2 must be a neighbor of vertex_b2.\")\n\n        # find vertex_a_part (and possibly switch vertex_a2, vertex_b2)\n        vertex_a_new = set(self.neighbors[vertex_a1])\n        vertex_a_new.discard(vertex_b1)\n        if vertex_a1 == vertex_b2:\n            # we now that we have to swap vertex_a2 and vertex_b2. The algo\n            # below will fail otherwise in this 'exotic' case.\n            vertex_a2, vertex_b2 = vertex_b2, vertex_a2\n            #vertex_a_new.discard(vertex_a2) # in case there is overlap\n        if vertex_a1 == vertex_a2:\n            vertex_a_new.discard(vertex_b2) # in case there is overlap\n        vertex_a_part = set([vertex_a1])\n\n        touched = False # True if (the switched) vertex_a2 has been reached.\n        while len(vertex_a_new) > 0:\n            pivot = vertex_a_new.pop()\n            if pivot == vertex_b1:\n                raise GraphError(\"The graph can not be separated in two halfs. \"\n                                 \"vertex_b1 reached by vertex_a1.\")\n            vertex_a_part.add(pivot)\n            # create a new set that we can modify\n            pivot_neighbors = set(self.neighbors[pivot])\n            pivot_neighbors -= vertex_a_part\n            if pivot == vertex_a2 or pivot == vertex_b2:\n                if pivot == vertex_b2:\n                    if touched:\n                        raise GraphError(\"The graph can not be separated in \"\n                                         \"two halfs. vertex_b2 reached by \"\n                                         \"vertex_a1.\")\n                    else:\n                        # put them in the correct order\n                        vertex_a2, vertex_b2 = vertex_b2, vertex_a2\n                pivot_neighbors.discard(vertex_b2)\n                touched = True\n            vertex_a_new |= pivot_neighbors\n\n        if vertex_a2 not in vertex_a_part:\n            raise GraphError(\"The graph can not be separated in two halfs. \"\n                             \"vertex_a1 can not reach vertex_a2 trough \"\n                             \"vertex_a_part\")\n\n        # find vertex_b_part: easy, is just the rest ...\n        #vertex_b_part = set(xrange(self.num_vertices)) - vertex_a_part\n\n        # ... but we also want that there is a path in vertex_b_part from\n        # vertex_b1 to vertex_b2\n        if vertex_b1 == vertex_b2:\n            closed = True\n        else:\n            vertex_b_new = set(self.neighbors[vertex_b1])\n            vertex_b_new.discard(vertex_a1)\n            vertex_b_part = set([vertex_b1])\n\n            closed = False\n            while len(vertex_b_new) > 0:\n                pivot = vertex_b_new.pop()\n                if pivot == vertex_b2:\n                    closed = True\n                    break\n                pivot_neighbors = set(self.neighbors[pivot])\n                pivot_neighbors -= vertex_b_part\n                vertex_b_new |= pivot_neighbors\n                vertex_b_part.add(pivot)\n\n        if not closed:\n            raise GraphError(\"The graph can not be separated in two halfs. \"\n                             \"vertex_b1 can not reach vertex_b2 trough \"\n                             \"vertex_b_part\")\n\n        # finaly compute the real vertex_b_part, the former loop might break\n        # early for efficiency.\n        vertex_b_part = set(range(self.num_vertices)) - vertex_a_part\n\n        # done!\n        return vertex_a_part, vertex_b_part, \\\n               (vertex_a1, vertex_b1, vertex_a2, vertex_b2)", "response": "Compute the two halfs separated by vertex_a1 and vertex_b1 and vertex_b2 and return the two halfs separated by vertex_a1 and vertex_b1 and vertex_b2."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the mapping between vertex indexes in self and other.", "response": "def full_match(self, other):\n        \"\"\"Find the mapping between vertex indexes in self and other.\n\n           This also works on disconnected graphs. Derived classes should just\n           implement get_vertex_string and get_edge_string to make this method\n           aware of the different nature of certain vertices. In case molecules,\n           this would make the algorithm sensitive to atom numbers etc.\n        \"\"\"\n        # we need normalize subgraphs because these graphs are used as patterns.\n        graphs0 = [\n            self.get_subgraph(group, normalize=True)\n            for group in self.independent_vertices\n        ]\n        graphs1 = [\n            other.get_subgraph(group)\n            for group in other.independent_vertices\n        ]\n\n        if len(graphs0) != len(graphs1):\n            return\n\n        matches = []\n\n        for graph0 in graphs0:\n            pattern = EqualPattern(graph0)\n            found_match = False\n            for i, graph1 in enumerate(graphs1):\n                local_matches = list(GraphSearch(pattern)(graph1, one_match=True))\n                if len(local_matches) == 1:\n                    match = local_matches[0]\n                    # we need to restore the relation between the normalized\n                    # graph0 and its original indexes\n                    old_to_new = OneToOne((\n                        (j, i) for i, j\n                        in enumerate(graph0._old_vertex_indexes)\n                    ))\n                    matches.append(match * old_to_new)\n                    del graphs1[i]\n                    found_match = True\n                    break\n            if not found_match:\n                return\n\n        result = OneToOne()\n        for match in matches:\n            result.add_relations(match.forward.items())\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a new relation between source and destination.", "response": "def add_relation(self, source, destination):\n        \"\"\"Add new a relation to the bejection\"\"\"\n        if self.in_sources(source):\n            if self.forward[source] != destination:\n                raise ValueError(\"Source is already in use. Destination does \"\n                                 \"not match.\")\n            else:\n                raise ValueError(\"Source-Destination relation already exists.\")\n        elif self.in_destinations(destination):\n            raise ValueError(\"Destination is already in use. Source does not \"\n                             \"match.\")\n        else:\n            self.forward[source] = destination\n            self.reverse[destination] = source"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_relations(self, relations):\n        for source, destination in relations:\n            self.add_relation(source, destination)", "response": "Add multiple relations to a bijection"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inverse(self):\n        result = self.__class__()\n        result.forward = copy.copy(self.reverse)\n        result.reverse = copy.copy(self.forward)\n        return result", "response": "Returns the inverse bijection."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_new_edges(self, subject_graph):\n        result = []\n        #print \"Match.get_new_edges self.previous_ends1\", self.previous_ends1\n        for vertex in self.previous_ends1:\n            for neighbor in subject_graph.neighbors[vertex]:\n                if neighbor not in self.reverse:\n                    result.append((vertex, neighbor))\n        return result", "response": "Get new edges from the subject graph for the graph search algorithm\n\n          "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy_with_new_relations(self, new_relations):\n        result = self.__class__(self.forward.items())\n        result.add_relations(new_relations.items())\n        result.previous_ends1 = set(new_relations.values())\n        return result", "response": "Create a new match object extended with new relations"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_pattern_graph(self, pattern_graph):\n        self.pattern_graph = pattern_graph\n        self.level_edges = {}\n        self.level_constraints = {}\n        self.duplicate_checks = set([])\n        if pattern_graph is None:\n            return\n        if len(pattern_graph.independent_vertices) != 1:\n            raise ValueError(\"A pattern_graph must not be a disconnected \"\n                             \"graph.\")\n        # A) the levels for the incremental pattern matching\n        ibfe = self.pattern_graph.iter_breadth_first_edges(self.start_vertex)\n        for edge, distance, constraint in ibfe:\n            if constraint:\n                l = self.level_constraints.setdefault(distance-1, [])\n            else:\n                l = self.level_edges.setdefault(distance, [])\n            l.append(edge)\n        #print \"level_edges\", self.level_edges\n        #print \"level_constraints\", self.level_constraints\n        # B) The comparisons the should be checked when one wants to avoid\n        # symmetrically duplicate pattern matches\n        if self.criteria_sets is not None:\n            for cycles in pattern_graph.symmetry_cycles:\n                if len(cycles) > 0:\n                    self.duplicate_checks.add((cycles[0][0], cycles[0][1]))", "response": "Initialize the pattern_graph and initialize the internal state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\niterates over all valid initial relations for a match", "response": "def iter_initial_relations(self, subject_graph):\n        \"\"\"Iterate over all valid initial relations for a match\"\"\"\n        vertex0 = self.start_vertex\n        for vertex1 in range(subject_graph.num_vertices):\n            if self.compare(vertex0, vertex1, subject_graph):\n                yield vertex0, vertex1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_new_edges(self, level):\n        return (\n            self.level_edges.get(level, []),\n            self.level_constraints.get(level, [])\n        )", "response": "Get new edges from the pattern graph for the graph search algorithm\n\n          "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the next match can be a valid one.", "response": "def check_next_match(self, match, new_relations, subject_graph, one_match):\n        \"\"\"Check if the (onset for a) match can be a valid\"\"\"\n        # only returns true for ecaxtly one set of new_relations from all the\n        # ones that are symmetrically equivalent\n        if not (self.criteria_sets is None or one_match):\n            for check in self.duplicate_checks:\n                vertex_a = new_relations.get(check[0])\n                vertex_b = new_relations.get(check[1])\n                if vertex_a is None and vertex_b is None:\n                    continue # if this pair is completely absent in the new\n                    # relations, it is either completely in the match or it\n                    # is to be matched. So it is either already checked for\n                    # symmetry duplicates, or it will be check in future.\n                if vertex_a is None:\n                    # maybe vertex_a is in the match and vertex_b is the only\n                    # one in the new relations. try to get vertex_a from the\n                    # match.\n                    vertex_a = match.forward.get(check[0])\n                    if vertex_a is None:\n                        # ok, vertex_a is to be found, don't care about it right\n                        # now. it will be checked in future calls.\n                        continue\n                elif vertex_b is None:\n                    # maybe vertex_b is in the match and vertex_a is the only\n                    # one in the new relations. try to get vertex_b from the\n                    # match.\n                    vertex_b = match.forward.get(check[1])\n                    if vertex_b is None:\n                        # ok, vertex_b is to be found, don't care about it right\n                        # now. it will be checked in future calls.\n                        continue\n                if vertex_a > vertex_b:\n                    # Why does this work? The answer is not so easy to explain,\n                    # and certainly not easy to find. if vertex_a > vertex_b, it\n                    # means that there is a symmetry operation that leads to\n                    # an equivalent match where vertex_b < vertex_a. The latter\n                    # match is preferred for as much pairs (vertex_a, vertex_b)\n                    # as possible without rejecting all possible matches. The\n                    # real difficulty is to construct a proper list of\n                    # (vertex_a, vertex_b) pairs that will reject all but one\n                    # matches. I conjecture that this list contains all the\n                    # first two vertices from each normalized symmetry cycle of\n                    # the pattern graph. We need a math guy to do the proof. -- Toon\n                    return False\n            return True\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a match iterate over all related equivalent matches that fulfill one of the criteria sets.", "response": "def iter_final_matches(self, canonical_match, subject_graph, one_match):\n        \"\"\"Given a match, iterate over all related equivalent matches\n\n           When criteria sets are defined, the iterator runs over all symmetric\n           equivalent matches that fulfill one of the criteria sets. When not\n           criteria sets are defined, the iterator only yields the input match.\n        \"\"\"\n        if self.criteria_sets is None or one_match:\n            yield canonical_match\n        else:\n            for criteria_set in self.criteria_sets:\n                satisfied_match_tags = set([])\n                for symmetry in self.pattern_graph.symmetries:\n                    final_match = canonical_match * symmetry\n                    #print final_match\n                    if criteria_set.test_match(final_match, self.pattern_graph, subject_graph):\n                        match_tags = tuple(\n                            self.vertex_tags.get(symmetry.reverse[vertex0])\n                            for vertex0\n                            in range(self.pattern_graph.num_vertices)\n                        )\n                        if match_tags not in satisfied_match_tags:\n                            final_match.__dict__.update(criteria_set.info)\n                            yield final_match\n                            satisfied_match_tags.add(match_tags)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the closed cycles corresponding to this permutation.", "response": "def get_closed_cycles(self):\n        \"\"\"Return the closed cycles corresponding to this permutation\n\n           The cycle will be normalized to facilitate the elimination of\n           duplicates. The following is guaranteed:\n\n           1) If this permutation is represented by disconnected cycles, the\n              cycles will be sorted by the lowest index they contain.\n           2) Each cycle starts with its lowest index. (unique starting point)\n           3) Singletons are discarded. (because they are boring)\n        \"\"\"\n        # A) construct all the cycles\n        closed_cycles = []\n        todo = set(self.forward.keys())\n        if todo != set(self.forward.values()):\n            raise GraphError(\"The subject and pattern graph must have the same \"\n                             \"numbering.\")\n        current_vertex = None\n        while len(todo) > 0:\n            if current_vertex == None:\n                current_vertex = todo.pop()\n                current_cycle = []\n            else:\n                todo.discard(current_vertex)\n            current_cycle.append(current_vertex)\n            next_vertex = self.get_destination(current_vertex)\n            if next_vertex == current_cycle[0]:\n                if len(current_cycle) > 1:\n                    # bring the lowest element in front\n                    pivot = np.argmin(current_cycle)\n                    current_cycle = current_cycle[pivot:] + \\\n                                    current_cycle[:pivot]\n                    closed_cycles.append(current_cycle)\n                current_vertex = None\n            else:\n                current_vertex = next_vertex\n        # B) normalize the cycle representation\n        closed_cycles.sort() # a normal sort is sufficient because only the\n                             # first item of each cycle is considered\n\n        # transform the structure into a tuple of tuples\n        closed_cycles = tuple(tuple(cycle) for cycle in closed_cycles)\n        return closed_cycles"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates over all valid initial relations for a match", "response": "def iter_initial_relations(self, subject_graph):\n        \"\"\"Iterate over all valid initial relations for a match\"\"\"\n        if self.pattern_graph.num_edges != subject_graph.num_edges:\n            return # don't even try\n        for pair in CustomPattern.iter_initial_relations(self, subject_graph):\n            yield pair"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compare(self, vertex0, vertex1, subject_graph):\n        return (\n            self.pattern_graph.vertex_fingerprints[vertex0] ==\n            subject_graph.vertex_fingerprints[vertex1]\n        ).all()", "response": "Returns true when the two vertices are of the same kind"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\niterate over all valid initial relations for a match", "response": "def iter_initial_relations(self, subject_graph):\n        \"\"\"Iterate over all valid initial relations for a match\"\"\"\n        vertex0 = 0\n        for vertex1 in range(subject_graph.num_vertices):\n            yield vertex0, vertex1"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the new edges from the pattern graph for the graph search algorithm.", "response": "def get_new_edges(self, level):\n        \"\"\"Get new edges from the pattern graph for the graph search algorithm\n\n           The level argument denotes the distance of the new edges from the\n           starting vertex in the pattern graph.\n        \"\"\"\n        if level == 0:\n            edges0 = [(0, 1), (0, 2)]\n        elif level >= (self.max_size-1)//2:\n            edges0 = []\n        else:\n            l2 = level*2\n            edges0 = [(l2-1, l2+1), (l2, l2+2)]\n        return edges0, []"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_next_match(self, match, new_relations, subject_graph, one_match):\n        # avoid duplicate rings (order of traversal)\n        if len(match) == 3:\n            if match.forward[1] < match.forward[2]:\n                #print \"RingPattern.check_next_match: duplicate order\", match.forward[1], match.forward[2]\n                return False\n        # avoid duplicate rings (starting point)\n        for vertex1 in new_relations.values():\n            if vertex1 < match.forward[0]:\n                #print \"RingPattern.check_next_match: duplicate start\", vertex1, match.forward[0]\n                return False\n        # can this ever become a strong ring?\n        for vertex1 in new_relations.values():\n            paths = list(subject_graph.iter_shortest_paths(vertex1, match.forward[0]))\n            if len(paths) != 1:\n                #print \"RingPattern.check_next_match: not strong 1\"\n                return False\n            if len(paths[0]) != (len(match)+1)//2:\n                #print \"RingPattern.check_next_match: not strong 2\"\n                return False\n        return True", "response": "Check if the next match can be a valid one"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef complete(self, match, subject_graph):\n        size = len(match)\n        # check whether we have an odd strong ring\n        if match.forward[size-1] in subject_graph.neighbors[match.forward[size-2]]:\n            # we have an odd closed cycle. check if this is a strong ring\n            order = list(range(0, size, 2)) + list(range(1, size-1, 2))[::-1]\n            ok = True\n            for i in range(len(order)//2):\n                # Count the number of paths between two opposite points in the\n                # ring. Since the ring has an odd number of vertices, each\n                # vertex has two semi-opposite vertices.\n                count = len(list(subject_graph.iter_shortest_paths(\n                    match.forward[order[i]],\n                    match.forward[order[(i+size//2)%size]]\n                )))\n                if count > 1:\n                    ok = False\n                    break\n                count = len(list(subject_graph.iter_shortest_paths(\n                    match.forward[order[i]],\n                    match.forward[order[(i+size//2+1)%size]]\n                )))\n                if count > 1:\n                    ok = False\n                    break\n            if ok:\n                match.ring_vertices = tuple(match.forward[i] for i in order)\n                #print \"RingPattern.complete: found odd ring\"\n                return True\n            #print \"RingPattern.complete: no odd ring\"\n        # check whether we have an even strong ring\n        paths = list(subject_graph.iter_shortest_paths(\n            match.forward[size-1],\n            match.forward[size-2]\n        ))\n        #print \"RingPattern.complete: even paths\", paths\n        if (size > 3 and len(paths) == 1 and len(paths[0]) == 3) or \\\n           (size == 3 and len(paths) == 2 and len(paths[0]) == 3):\n            path = paths[0]\n            if size == 3 and path[1] == match.forward[0]:\n                path = paths[1]\n            # we have an even closed cycle. check if this is a strong ring\n            match.add_relation(size, path[1])\n            size += 1\n            order = list(range(0, size, 2)) + list(range(size-1, 0, -2))\n            ok = True\n            for i in range(len(order)//2):\n                count = len(list(subject_graph.iter_shortest_paths(\n                    match.forward[order[i]],\n                    match.forward[order[(i+size//2)%size]]\n                )))\n                if count != 2:\n                    ok = False\n                    break\n            if ok:\n                # also check if this does not violate the requirement for a\n                # unique origin:\n                if match.forward[size-1] < match.forward[0]:\n                    ok = False\n            if not ok:\n                vertex1 = match.forward[size-1]\n                del match.forward[size-1]\n                del match.reverse[vertex1]\n                size -= 1\n                #print \"RingPattern.complete: no even ring\"\n            else:\n                match.ring_vertices = tuple(match.forward[i] for i in order)\n                #print \"RingPattern.complete: found even ring\"\n            return ok\n        #print \"RingPattern.complete: not at all\"\n        return False", "response": "Check whether a match is complete."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_debug(self, text, indent=0):\n        if self.debug:\n            if indent > 0:\n                print(\" \"*self.debug, text)\n            self.debug += indent\n            if indent <= 0:\n                print(\" \"*self.debug, text)", "response": "Only prints debug info on screen when self. debug == True."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _iter_candidate_groups(self, init_match, edges0, edges1):\n        # collect all end vertices0 and end vertices1 that belong to the same\n        # group.\n        sources = {}\n        for start_vertex0, end_vertex0 in edges0:\n            l = sources.setdefault(start_vertex0, [])\n            l.append(end_vertex0)\n        dests = {}\n        for start_vertex1, end_vertex1 in edges1:\n            start_vertex0 = init_match.reverse[start_vertex1]\n            l = dests.setdefault(start_vertex0, [])\n            l.append(end_vertex1)\n        for start_vertex0, end_vertices0 in sources.items():\n            end_vertices1 = dests.get(start_vertex0, [])\n            yield end_vertices0, end_vertices1", "response": "Divide the edges into groups."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\niterating over all possible new relations in a subject graph.", "response": "def _iter_new_relations(self, init_match, subject_graph, edges0, constraints0, edges1):\n        \"\"\"Given an onset for a match, iterate over all possible new key-value pairs\"\"\"\n        # Count the number of unique edges0[i][1] values. This is also\n        # the number of new relations.\n        num_new_relations = len(set(j for i, j in edges0))\n\n        def combine_small(relations, num):\n            \"\"\"iterate over all compatible combinations within one set of relations\"\"\"\n            if len(relations) == 0:\n                return\n            for i, pivot in enumerate(relations):\n                if num == 1:\n                    yield (pivot, )\n                else:\n                    compatible_relations = list(\n                        item for item in relations[:i]\n                        if pivot[0]!=item[0] and pivot[1]!=item[1]\n                    )\n                    for tail in combine_small(compatible_relations, num-1):\n                        yield (pivot, ) + tail\n\n        # generate candidate relations\n        candidate_relations = []\n        icg = self._iter_candidate_groups(init_match, edges0, edges1)\n        for end_vertices0, end_vertices1 in icg:\n            if len(end_vertices0) > len(end_vertices1):\n                return # this can never work, the subject graph is 'too small'\n            elif not self.pattern.sub and \\\n                 len(end_vertices0) != len(end_vertices1):\n                return # an exact match is sought, this can never work\n            l = []\n            for end_vertex0 in end_vertices0:\n                for end_vertex1 in end_vertices1:\n                    if self.pattern.compare(end_vertex0, end_vertex1, subject_graph):\n                        l.append((end_vertex0, end_vertex1))\n            # len(end_vertices0) = the total number of relations that must be\n            # made in this group\n            if len(l) > 0:\n                # turn l into a list of sets of internally compatible candidate\n                # relations in this group\n                l = list(combine_small(l, len(end_vertices0)))\n                candidate_relations.append(l)\n        if len(candidate_relations) == 0:\n            return\n        self.print_debug(\"candidate_relations: %s\" % candidate_relations)\n\n        def combine_big(pos=0):\n            \"\"\"Iterate over all possible sets of relations\"\"\"\n            # pos is an index in candidate_relations\n            crs = candidate_relations[pos]\n            if pos == len(candidate_relations)-1:\n                for relations in crs:\n                    yield relations\n            else:\n                for tail in combine_big(pos+1):\n                    for relations in crs:\n                        yield relations + tail\n\n        # final loop\n        for new_relations in combine_big():\n            new_relations = set(new_relations)\n            self.print_debug(\"new_relations: %s\" % (new_relations, ))\n            # check the total number of new relations\n            if len(new_relations) != num_new_relations:\n                continue\n            # check sanity of relations\n            forward = dict(new_relations)\n            if len(forward) != num_new_relations:\n                continue\n            reverse = dict((j, i) for i, j in new_relations)\n            if len(reverse) != num_new_relations:\n                continue\n            # check the constraints\n            for a0, b0 in constraints0:\n                if forward[a0] not in subject_graph.neighbors[forward[b0]]:\n                    forward = None\n                    break\n            if forward is None:\n                continue\n            yield forward"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive an onset for a match, iterate over all completions of that match This iterator works recursively. At each level the match is extended with a new set of relations based on vertices in the pattern graph that are at a distances 'level' from the starting vertex", "response": "def _iter_matches(self, input_match, subject_graph, one_match, level=0):\n        \"\"\"Given an onset for a match, iterate over all completions of that match\n\n           This iterator works recursively. At each level the match is extended\n           with a new set of relations based on vertices in the pattern graph\n           that are at a distances 'level' from the starting vertex\n        \"\"\"\n        self.print_debug(\"ENTERING _ITER_MATCHES\", 1)\n        self.print_debug(\"input_match: %s\" % input_match)\n        # A) collect the new edges in the pattern graph and the subject graph\n        # to extend the match.\n        #\n        # Note that the edges are ordered. edge[0] is always in the match.\n        # edge[1] is never in the match. The constraints contain information\n        # about the end points of edges0. It is a list of two-tuples where\n        # (a, b) means that a and b must be connected.\n        #\n        # Second note: suffix 0 indicates the pattern graph and suffix 1\n        # is used for the subject graph.\n        edges0, constraints0 = self.pattern.get_new_edges(level)\n        edges1 = input_match.get_new_edges(subject_graph)\n        self.print_debug(\"edges0: %s\" % edges0)\n        self.print_debug(\"constraints0: %s\" % constraints0)\n        self.print_debug(\"edges1: %s\" % edges1)\n\n        # B) iterate over the sets of new relations: [(vertex0[i], vertex1[j]),\n        # ...] that contain all endpoints of edges0, that satisfy the\n        # constraints0 and where (vertex0[i], vertex1[j]) only occurs if these\n        # are end points of a edge0 and edge1 whose starting points are already\n        # in init_match. These conditions are implemented in an iterator as to\n        # separate concerns. This iterator also calls the routines that check\n        # whether vertex1[j] also satisfies additional conditions inherent\n        # vertex0[i].\n        inr = self._iter_new_relations(input_match, subject_graph, edges0,\n                                       constraints0, edges1)\n        for new_relations in inr:\n            # for each set of new_relations, construct a next_match and recurse\n            next_match = input_match.copy_with_new_relations(new_relations)\n            if not self.pattern.check_next_match(next_match, new_relations, subject_graph, one_match):\n                continue\n            if self.pattern.complete(next_match, subject_graph):\n                yield next_match\n            else:\n                for match in self._iter_matches(next_match, subject_graph, one_match, level+1):\n                    yield match\n        self.print_debug(\"LEAVING_ITER_MATCHES\", -1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dump_pdb(filename, molecule, atomnames=None, resnames=None, chain_ids=None, occupancies=None, betas=None):\n\n    with open(filename, \"w\") as f:\n        res_id = 1\n        old_resname = None\n\n        for i in range(molecule.size):\n            symbol = periodic[molecule.numbers[i]].symbol\n            if atomnames is None:\n                atomname = symbol\n            else:\n                atomname = atomnames[i]\n            if resnames is None:\n                resname = \"OXO\"\n            else:\n                resname = resnames[i]\n            if resname != old_resname:\n                res_id += 1\n            if chain_ids is None:\n                chain_id = \"A\"\n            else:\n                chain_id = chain_ids[i]\n            if occupancies is None:\n                occupancy = 1.0\n            else:\n                occupancy = occupancies[i]\n            if betas is None:\n                beta = 1.0\n            else:\n                beta = betas[i]\n\n            print(\"ATOM   %4i  %3s %3s %1s%4i    %8.3f%8.3f%8.3f%6.2f%6.2f          %2s  \" % (\n                i+1, atomname.ljust(3), resname.ljust(3), chain_id, res_id,\n                molecule.coordinates[i, 0]/angstrom,\n                molecule.coordinates[i, 1]/angstrom,\n                molecule.coordinates[i, 2]/angstrom,\n                occupancy, beta, symbol.ljust(2)\n            ), file=f)\n            old_resname = resname", "response": "Writes a single molecule to a PDB file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a single molecule from a pdb file.", "response": "def load_pdb(filename):\n    \"\"\"Loads a single molecule from a pdb file.\n\n       This function does support only a small fragment from the pdb specification.\n       It assumes that there is only one molecular geometry in the pdb file.\n    \"\"\"\n    with open(filename) as f:\n        numbers = []\n        coordinates = []\n        occupancies = []\n        betas = []\n        for line in f:\n            if line.startswith(\"ATOM\"):\n                symbol = line[76:78].strip()\n                numbers.append(periodic[symbol].number)\n                coordinates.append([float(line[30:38])*angstrom, float(line[38:46])*angstrom, float(line[46:54])*angstrom])\n                occupancies.append(float(line[54:60]))\n                betas.append(float(line[60:66]))\n    if len(numbers) > 0:\n        molecule = Molecule(numbers, coordinates)\n        molecule.occupancies = np.array(occupancies)\n        molecule.betas = np.array(betas)\n        return molecule\n    else:\n        raise FileFormatError(\"No molecule found in pdb file %s\" % filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a ZMatrix back to cartesian coordinates.", "response": "def zmat_to_cart(zmat):\n    \"\"\"Converts a ZMatrix back to cartesian coordinates.\"\"\"\n\n    numbers = zmat[\"number\"]\n    N = len(numbers)\n    coordinates = np.zeros((N, 3), float)\n\n    # special cases for the first coordinates\n    coordinates[1, 2] = zmat[\"distance\"][1]\n    if zmat[\"rel1\"][2] == 1:\n        sign = -1\n    else:\n        sign = 1\n    coordinates[2, 2] = zmat[\"distance\"][2]*sign*np.cos(zmat[\"angle\"][2])\n    coordinates[2, 1] = zmat[\"distance\"][2]*sign*np.sin(zmat[\"angle\"][2])\n    coordinates[2] += coordinates[2-zmat[\"rel1\"][2]]\n\n    ref0 = 3\n    for (number, distance, rel1, angle, rel2, dihed, rel3) in zmat[3:]:\n        ref1 = ref0 - rel1\n        ref2 = ref0 - rel2\n        ref3 = ref0 - rel3\n        if ref1 < 0: ref1 = 0\n        if ref2 < 0: ref2 = 0\n        if ref3 < 0: ref3 = 0\n        # define frame axes\n        origin = coordinates[ref1]\n        new_z = coordinates[ref2] - origin\n        norm_z = np.linalg.norm(new_z)\n        if norm_z < 1e-15:\n            new_z = np.array([0, 0, 1], float)\n        else:\n            new_z /= np.linalg.norm(new_z)\n        new_x = coordinates[ref3] - origin\n        new_x -= np.dot(new_x, new_z)*new_z\n        norm_x = np.linalg.norm(new_x)\n        if norm_x < 1e-15:\n            new_x = random_orthonormal(new_z)\n        else:\n            new_x /= np.linalg.norm(new_x)\n        # we must make our axes frame left handed due to the poor IUPAC\n        # definition of the sign of a dihedral angle.\n        new_y = -np.cross(new_z, new_x)\n\n        # coordinates of new atom:\n        x = distance*np.cos(dihed)*np.sin(angle)\n        y = distance*np.sin(dihed)*np.sin(angle)\n        z = distance*np.cos(angle)\n        coordinates[ref0] = origin + x*new_x + y*new_y + z*new_z\n        # loop\n        ref0 += 1\n\n    return numbers, coordinates"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_new_ref(self, existing_refs):\n        # ref0 is the atom whose position is defined by the current row in the\n        # zmatrix.\n        ref0 = existing_refs[0]\n        for ref in existing_refs:\n            # try to find a neighbor of the ref that can serve as the new ref\n            result = None\n            for n in sorted(self.graph.neighbors[ref]):\n                if self.new_index[n] > self.new_index[ref0]:\n                    # index is too high, zmatrix rows can't refer to future\n                    # atoms\n                    continue\n                if n in existing_refs:\n                    # ref is already in use\n                    continue\n                if result is None or self.graph.numbers[n] <= self.graph.numbers[result]:\n                    # acceptable ref, prefer heaviest atom\n                    result = n\n            if result is not None:\n                return result\n        raise RuntimeError(\"Could not find new reference.\")", "response": "Get a new reference atom for a row in the ZMatrix."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cart_to_zmat(self, coordinates):\n        N = len(self.graph.numbers)\n        if coordinates.shape != (N, 3):\n            raise ValueError(\"The shape of the coordinates must be (%i, 3)\" % N)\n        result = np.zeros(N, dtype=self.dtype)\n        for i in range(N):\n            ref0 = self.old_index[i]\n            rel1 = -1\n            rel2 = -1\n            rel3 = -1\n            distance = 0\n            angle = 0\n            dihed = 0\n            if i > 0:\n                ref1 = self._get_new_ref([ref0])\n                distance = np.linalg.norm(coordinates[ref0]-coordinates[ref1])\n                rel1 = i - self.new_index[ref1]\n            if i > 1:\n                ref2 = self._get_new_ref([ref0, ref1])\n                angle, = ic.bend_angle(coordinates[[ref0, ref1, ref2]])\n                rel2 = i - self.new_index[ref2]\n            if i > 2:\n                ref3 = self._get_new_ref([ref0, ref1, ref2])\n                dihed, = ic.dihed_angle(coordinates[[ref0, ref1, ref2, ref3]])\n                rel3 = i - self.new_index[ref3]\n            result[i] = (self.graph.numbers[i], distance, rel1, angle, rel2, dihed, rel3)\n        return result", "response": "Convert cartesian coordinates to ZMatrix format"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef can_map_ipa_string(self, ipa_string):\n        canonical = [(c.canonical_representation, ) for c in ipa_string]\n        split = split_using_dictionary(canonical, self, self.max_key_length, single_char_parsing=False)\n        for sub in split:\n            if not sub in self.ipa_canonical_representation_to_mapped_str:\n                return False\n        return True", "response": "Return True if the mapper can map all the IPA characters in the given IPA string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef map_ipa_string(self, ipa_string, ignore=False, return_as_list=False, return_can_map=False):\n        acc = []\n        can_map = True\n        canonical = [(c.canonical_representation, ) for c in ipa_string]\n        split = split_using_dictionary(canonical, self, self.max_key_length, single_char_parsing=False)\n        for sub in split:\n            try:\n                acc.append(self.ipa_canonical_representation_to_mapped_str[sub])\n            except KeyError:\n                if ignore:\n                    can_map = False\n                else:\n                    raise ValueError(\"The IPA string contains an IPA character that is not mapped: %s\" % sub)\n        mapped = acc if return_as_list else u\"\".join(acc)\n        if return_can_map:\n            return (can_map, mapped)\n        return mapped", "response": "Convert the given IPA string to a string containing the corresponding ASCII IPA representation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef map_unicode_string(self, unicode_string, ignore=False, single_char_parsing=False, return_as_list=False, return_can_map=False):\n        if unicode_string is None:\n            return None\n        ipa_string = IPAString(unicode_string=unicode_string, ignore=ignore, single_char_parsing=single_char_parsing)\n        return self.map_ipa_string(\n            ipa_string=ipa_string,\n            ignore=ignore,\n            return_as_list=return_as_list,\n            return_can_map=return_can_map\n        )", "response": "Convert the given Unicode string representing an IPA string and an IPA string to a string containing the corresponding mapped representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint Unicode characters that are not IPA valid.", "response": "def print_invalid_chars(invalid_chars, vargs):\n    \"\"\"\n    Print Unicode characterss that are not IPA valid,\n    if requested by the user.\n\n    :param list invalid_chars: a list (possibly empty) of invalid Unicode characters\n    :param dict vargs: the command line parameters\n    \"\"\"\n    if len(invalid_chars) > 0:\n        if vargs[\"print_invalid\"]:\n            print(u\"\".join(invalid_chars))\n        if vargs[\"unicode\"]:\n            for u_char in sorted(set(invalid_chars)):\n                print(u\"'%s'\\t%s\\t%s\" % (u_char, hex(ord(u_char)), unicodedata.name(u_char, \"UNKNOWN\")))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef command_canonize(string, vargs):\n    try:\n        ipa_string = IPAString(\n            unicode_string=string,\n            ignore=vargs[\"ignore\"],\n            single_char_parsing=vargs[\"single_char_parsing\"]\n        )\n        print(vargs[\"separator\"].join([(u\"%s\" % c) for c in ipa_string]))\n    except ValueError as exc:\n        print_error(str(exc))", "response": "Print the canonical representation of the given string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint a list of all IPA characters in the given string.", "response": "def command_chars(string, vargs):\n    \"\"\"\n    Print a list of all IPA characters in the given string.\n\n    It will print the Unicode representation, the full IPA name,\n    and the Unicode \"U+\"-prefixed hexadecimal codepoint representation\n    of each IPA character.\n\n    :param str string: the string to act upon\n    :param dict vargs: the command line arguments\n    \"\"\"\n    try:\n        ipa_string = IPAString(\n            unicode_string=string,\n            ignore=vargs[\"ignore\"],\n            single_char_parsing=vargs[\"single_char_parsing\"]\n        )\n        for c in ipa_string:\n            print(u\"'%s'\\t%s (%s)\" % (c.unicode_repr, c.name, unicode_to_hex(c.unicode_repr)))\n    except ValueError as exc:\n        print_error(str(exc))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef command_check(string, vargs):\n    is_valid = is_valid_ipa(string)\n    print(is_valid)\n    if not is_valid:\n        valid_chars, invalid_chars = remove_invalid_ipa_characters(\n            unicode_string=string,\n            return_invalid=True\n        )\n        print_invalid_chars(invalid_chars, vargs)", "response": "Check if the given string is IPA valid."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef command_clean(string, vargs):\n    valid_chars, invalid_chars = remove_invalid_ipa_characters(\n        unicode_string=string,\n        return_invalid=True,\n        single_char_parsing=vargs[\"single_char_parsing\"]\n    )\n    print(u\"\".join(valid_chars))\n    print_invalid_chars(invalid_chars, vargs)", "response": "Remove characters that are not IPA valid from the given string and print the remaining string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef command_u2a(string, vargs):\n    try:\n        l = ARPABETMapper().map_unicode_string(\n            unicode_string=string,\n            ignore=vargs[\"ignore\"],\n            single_char_parsing=vargs[\"single_char_parsing\"],\n            return_as_list=True\n        )\n        print(vargs[\"separator\"].join(l))\n    except ValueError as exc:\n        print_error(str(exc))", "response": "Print the ARPABEY ASCII string corresponding to the given Unicode IPA string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef command_u2k(string, vargs):\n    try:\n        l = KirshenbaumMapper().map_unicode_string(\n            unicode_string=string,\n            ignore=vargs[\"ignore\"],\n            single_char_parsing=vargs[\"single_char_parsing\"],\n            return_as_list=True\n        )\n        print(vargs[\"separator\"].join(l))\n    except ValueError as exc:\n        print_error(str(exc))", "response": "Print the Kirshenbaum ASCII string corresponding to the given Unicode IPA string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the list of IPAChar objects composing the IPA string", "response": "def ipa_chars(self, value):\n        \"\"\"\n        Set the list of IPAChar objects composing the IPA string\n\n        :param list value: list of IPAChar objects\n        \"\"\"\n        if value is None:\n            self.__ipa_chars = []\n        else:\n            if is_list_of_ipachars(value):\n                self.__ipa_chars = value\n            else:\n                raise TypeError(\"ipa_chars only accepts a list of IPAChar objects\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_equivalent(self, other, ignore=False):\n        def is_equivalent_to_list_of_ipachars(other):\n            \"\"\"\n            Return ``True`` if the list of IPAChar objects\n            in the canonical representation of the string\n            is the same as the given list.\n\n            :param list other: list of IPAChar objects\n            :rtype: bool\n            \"\"\"\n            my_ipa_chars = self.canonical_representation.ipa_chars\n            if len(my_ipa_chars) != len(other):\n                return False\n            for i in range(len(my_ipa_chars)):\n                if not my_ipa_chars[i].is_equivalent(other[i]):\n                    return False\n            return True\n\n        if is_unicode_string(other):\n            try:\n                return is_equivalent_to_list_of_ipachars(IPAString(unicode_string=other, ignore=ignore).ipa_chars)\n            except:\n                return False\n        if is_list_of_ipachars(other):\n            try:\n                return is_equivalent_to_list_of_ipachars(other) \n            except:\n                return False\n        if isinstance(other, IPAString):\n            return is_equivalent_to_list_of_ipachars(other.canonical_representation.ipa_chars)\n        return False", "response": "Return True if the given object is equivalent to the given object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new IPAString containing the canonical representation of the current string and the minimum number of IPAChar objects.", "response": "def canonical_representation(self):\n        \"\"\"\n        Return a new IPAString, containing the canonical representation of the current string,\n        that is, the one composed by the (prefix) minimum number of IPAChar objects.\n\n        :rtype: IPAString\n        \"\"\"\n        return IPAString(unicode_string=u\"\".join([c.__unicode__() for c in self.ipa_chars]))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter_chars(self, chars=u\"\"):\n        if chars in [u\"cns\", u\"consonants\"]:\n            return self.consonants\n        elif chars in [u\"vwl\", u\"vowels\"]:\n            return self.vowels\n        elif chars in [u\"cns_vwl\", u\"letters\"]:\n            return self.letters\n        elif chars in [u\"cns_vwl_pstr\", u\"cvp\"]:\n            return self.cns_vwl_pstr\n        elif chars in [u\"cns_vwl_pstr_long\", u\"cvpl\"]:\n            return self.cns_vwl_pstr_long\n        elif chars in [u\"cns_vwl_str\", u\"cvs\"]:\n            return self.cns_vwl_str\n        elif chars in [u\"cns_vwl_str_len\", u\"cvsl\"]:\n            return self.cns_vwl_str_len\n        elif chars in [u\"cns_vwl_str_len_wb\", u\"cvslw\"]:\n            return self.cns_vwl_str_len_wb\n        elif chars in [u\"cns_vwl_str_len_wb_sb\", u\"cvslws\"]:\n            return self.cns_vwl_str_len_wb_sb\n        return self", "response": "Returns a new IPAString containing only the characters specified by the chars string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef consonants(self):\n        return IPAString(ipa_chars=[c for c in self.ipa_chars if c.is_consonant])", "response": "Returns a new IPAString containing only the consonants in the current string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef vowels(self):\n        return IPAString(ipa_chars=[c for c in self.ipa_chars if c.is_vowel])", "response": "Returns a new string containing only the vowels in the current string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cns_vwl(self):\n        return IPAString(ipa_chars=[c for c in self.ipa_chars if c.is_letter])", "response": "Returns a new IPAString containing only the consonants and vowels in the current string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cns_vwl_pstr(self):\n        return IPAString(ipa_chars=[c for c in self.ipa_chars if (c.is_letter) or (c.is_suprasegmental and c.is_primary_stress)])", "response": "Returns a new IPAString containing only the consonants and vowels and the primary stress diacritics in the current string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new string containing only the consonants and vowels and the stress diacritics in the current string.", "response": "def cns_vwl_str(self):\n        \"\"\"\n        Return a new IPAString, containing only:\n        \n        1. the consonants,\n        2. the vowels, and\n        3. the stress diacritics\n\n        in the current string.\n\n        :rtype: IPAString\n        \"\"\"\n        return IPAString(ipa_chars=[c for c in self.ipa_chars if (c.is_letter) or (c.is_suprasegmental and c.is_stress)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new string containing only the consonants and vowels and the length diacritics and the consonants and the length diacritics.", "response": "def cns_vwl_str_len(self):\n        \"\"\"\n        Return a new IPAString, containing only:\n        \n        1. the consonants,\n        2. the vowels, and\n        3. the stress diacritics, and\n        4. the length diacritics\n\n        in the current string.\n\n        :rtype: IPAString\n        \"\"\"\n        return IPAString(ipa_chars=[c for c in self.ipa_chars if (c.is_letter) or (c.is_suprasegmental and (c.is_stress or c.is_length))])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new string containing only the consonants and vowels and the long suprasegmental characters in the current string.", "response": "def cns_vwl_pstr_long(self):\n        \"\"\"\n        Return a new IPAString, containing only:\n        \n        1. the consonants,\n        2. the vowels, and\n        3. the primary stress diacritics, and\n        4. the long suprasegmental\n\n        in the current string.\n\n        :rtype: IPAString\n        \"\"\"\n        return IPAString(ipa_chars=[c for c in self.ipa_chars if (c.is_letter) or (c.is_suprasegmental and (c.is_primary_stress or c.is_long))])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new string containing only the consonants and the length diacritics and the word breaks in the current string.", "response": "def cns_vwl_str_len_wb(self):\n        \"\"\"\n        Return a new IPAString, containing only:\n        \n        1. the consonants,\n        2. the vowels, and\n        3. the stress diacritics,\n        4. the length diacritics, and\n        5. the word breaks\n\n        in the current string.\n\n        :rtype: IPAString\n        \"\"\"\n        return IPAString(ipa_chars=[c for c in self.ipa_chars if (c.is_letter) or (c.is_suprasegmental and (c.is_stress or c.is_length or c.is_word_break))])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cns_vwl_str_len_wb_sb(self):\n        return IPAString(ipa_chars=[c for c in self.ipa_chars if (c.is_letter) or (c.is_suprasegmental and (c.is_stress or c.is_length or c.is_word_break or c.is_syllable_break))])", "response": "Return a new string containing only the characters that are not suprasegmental and length diacritics and the word breaks and the syllable breaks in the current string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_unicode_field(string):\n    values = []\n    for codepoint in [s for s in string.split(DATA_FILE_CODEPOINT_SEPARATOR) if (s != DATA_FILE_VALUE_NOT_AVAILABLE) and (len(s) > 0)]:\n        values.append(u\"\".join([hex_to_unichr(c) for c in codepoint.split(DATA_FILE_CODEPOINT_JOINER)]))\n    return values", "response": "Convert a Unicode field into a list of Unicode strings."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_ascii_field(string):\n    values = []\n    for codepoint in [s for s in string.split(DATA_FILE_CODEPOINT_SEPARATOR) if (s != DATA_FILE_VALUE_NOT_AVAILABLE) and (len(s) > 0)]:\n        #if DATA_FILE_CODEPOINT_JOINER in codepoint:\n        #    values.append(u\"\".join([hex_to_unichr(c) for c in codepoint.split(DATA_FILE_CODEPOINT_JOINER)]))\n        if (codepoint.startswith(DATA_FILE_ASCII_NUMERICAL_CODEPOINT_START)) or (codepoint.startswith(DATA_FILE_ASCII_UNICODE_CODEPOINT_START)):\n            values.append(hex_to_unichr(codepoint))\n        else:\n            values.append(codepoint)\n    return values", "response": "Convert an ASCII field into a list of Unicode strings."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a tuple of raw values according to the given line format.", "response": "def convert_raw_tuple(value_tuple, format_string):\n    \"\"\"\n    Convert a tuple of raw values, according to the given line format.\n\n    :param tuple value_tuple: the tuple of raw values\n    :param str format_string: the format of the tuple\n    :rtype: list of tuples\n    \"\"\" \n    values = []\n    for v, c in zip(value_tuple, format_string):\n        if v is None:\n            # append None\n            values.append(v)\n        elif c == u\"s\":\n            # string\n            values.append(v)\n        elif c == u\"S\":\n            # string, split using space as delimiter\n            values.append([s for s in v.split(u\" \") if len(s) > 0])\n        elif c == u\"i\":\n            # int\n            values.append(int(v))\n        elif c == u\"U\":\n            # Unicode\n            values.append(convert_unicode_field(v))\n        elif c == u\"A\":\n            # ASCII\n            values.append(convert_ascii_field(v))\n        #elif c == u\"x\":\n        #    # ignore\n        #    pass\n    return tuple(values)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_data_file(\n    file_path,\n    file_path_is_relative=False,\n    comment_string=DATA_FILE_COMMENT,\n    field_separator=DATA_FILE_FIELD_SEPARATOR,\n    line_format=None\n):\n    \"\"\"\n    Load a data file, with one record per line and\n    fields separated by ``field_separator``,\n    returning a list of tuples.\n\n    It ignores lines starting with ``comment_string`` or empty lines.\n\n    If ``values_per_line`` is not ``None``,\n    check that each line (tuple)\n    has the prescribed number of values.\n\n    :param str file_path: path of the data file to load\n    :param bool file_path_is_relative: if ``True``, ``file_path`` is relative to this source code file\n    :param str comment_string: ignore lines starting with this string\n    :param str field_separator: fields are separated by this string\n    :param str line_format: if not ``None``, parses each line according to the given format\n                            (``s`` = string, ``S`` = split string using spaces,\n                            ``i`` = int, ``x`` = ignore, ``U`` = Unicode, ``A`` = ASCII)\n    :rtype: list of tuples\n    \"\"\"\n    raw_tuples = []\n    if file_path_is_relative:\n        file_path = os.path.join(os.path.dirname(__file__), file_path)\n    with io.open(file_path, \"r\", encoding=\"utf-8\") as f:\n        for line in f:\n            line = line.strip()\n            if (len(line) > 0) and (not line.startswith(comment_string)):\n                raw_list = line.split(field_separator)\n                if len(raw_list) != len(line_format):\n                    raise ValueError(\"Data file '%s' contains a bad line: '%s'\" % (file_path, line))\n                raw_tuples.append(tuple(raw_list))\n    if (line_format is None) or (len(line_format) < 1):\n        return raw_tuples\n    return [convert_raw_tuple(t, line_format) for t in raw_tuples]", "response": "Load a data file and return a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload the IPA data from the built - in IPA database and create the IPA character objects.", "response": "def load_ipa_data():\n    \"\"\"\n    Load the IPA data from the built-in IPA database, creating the following globals:\n\n    1. ``IPA_CHARS``: list of all IPAChar objects\n    2. ``UNICODE_TO_IPA``: dict mapping a Unicode string (often, a single char) to an IPAChar\n    3. ``UNICODE_TO_IPA_MAX_KEY_LENGTH``: length of a longest key in ``UNICODE_TO_IPA``\n    4. ``IPA_TO_UNICODE``: map an IPAChar canonical representation to the corresponding Unicode string (or char)\n    \"\"\"\n    ipa_signs = []\n    unicode_to_ipa = {}\n    ipa_to_unicode = {}\n    max_key_length = 0\n    for line in load_data_file(\n        file_path=u\"ipa.dat\",\n        file_path_is_relative=True,\n        line_format=u\"sU\"\n    ):\n        # unpack data\n        i_desc, i_unicode_keys = line\n        name = re.sub(r\" [ ]*\", \" \", i_desc)\n\n        # create a suitable IPACharacter obj\n        if u\"consonant\" in i_desc:\n            obj = IPAConsonant(name=name, descriptors=i_desc)\n        elif u\"vowel\" in i_desc:\n            obj = IPAVowel(name=name, descriptors=i_desc)\n        elif u\"diacritic\" in i_desc:\n            obj = IPADiacritic(name=name, descriptors=i_desc)\n        elif u\"suprasegmental\" in i_desc:\n            obj = IPASuprasegmental(name=name, descriptors=i_desc)\n        elif u\"tone\" in i_desc:\n            obj = IPATone(name=name, descriptors=i_desc)\n        else:\n            raise ValueError(\"The IPA data file contains a bad line, defining an unknown type: '%s'\" % (line))\n        ipa_signs.append(obj)\n\n        # map Unicode codepoint to object, if the former is available\n        if len(i_unicode_keys) > 0:\n            # canonical Unicode string\n            first_key = i_unicode_keys[0]\n            ipa_to_unicode[obj.canonical_representation] = first_key\n            obj.unicode_repr = first_key\n            max_key_length = max(max_key_length, len(first_key))\n            # add all Unicode strings \n            for key in i_unicode_keys:\n                if key in unicode_to_ipa:\n                    raise ValueError(\"The IPA data file contains a bad line, redefining codepoint '%s': '%s'\" % (key, line))\n                unicode_to_ipa[key] = obj\n    return ipa_signs, unicode_to_ipa, max_key_length, ipa_to_unicode"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsplitting a string into a list of substrings of the given dictionary.", "response": "def split_using_dictionary(string, dictionary, max_key_length, single_char_parsing=False):\n    \"\"\"\n    Return a list of (non-empty) substrings of the given string,\n    where each substring is either:\n    \n    1. the longest string starting at the current index\n       that is a key in the dictionary, or\n    2. a single character that is not a key in the dictionary.\n\n    If ``single_char_parsing`` is ``False``,\n    parse the string one Unicode character at a time,\n    that is, do not perform the greedy parsing.\n\n    :param iterable string: the iterable object (\"string\") to split into atoms\n    :param dict dictionary: the dictionary mapping atoms (\"characters\") to something else\n    :param int max_key_length: the length of a longest key, in number of characters\n    :param bool single_char_parsing: if ``True``, parse one Unicode character at a time\n    \"\"\"\n    def substring(string, i, j):\n        if isinstance(string[i], tuple):\n            # transform list of tuples with one element in a tuple with all elements\n            return tuple([string[k][0] for k in range(i, j)])\n        # just return substring\n        return string[i:j]\n    \n    if string is None:\n        return None\n    if (single_char_parsing) or (max_key_length < 2):\n        return [c for c in string]\n    acc = []\n    l = len(string)\n    i = 0\n    while i < l:\n        found = False\n        for j in range(min(i + max_key_length, l), i, -1):\n            sub = substring(string, i, j)\n            if sub in dictionary:\n                found = True\n                acc.append(sub)\n                i = j\n                break\n        if not found:\n            acc.append(string[i])\n            i += 1\n    return acc"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ipa_substrings(unicode_string, single_char_parsing=False):\n    return split_using_dictionary(\n        string=unicode_string,\n        dictionary=UNICODE_TO_IPA,\n        max_key_length=UNICODE_TO_IPA_MAX_KEY_LENGTH,\n        single_char_parsing=single_char_parsing\n    )", "response": "Returns a list of substrings of the given Unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef invalid_ipa_characters(unicode_string, indices=False):\n    if unicode_string is None:\n        return None\n    if indices:\n        return [(i, unicode_string[i]) for i in range(len(unicode_string)) if unicode_string[i] not in UNICODE_TO_IPA]\n    return set([c for c in unicode_string if c not in UNICODE_TO_IPA])", "response": "Returns the list of Unicode characters that are not IPA valid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_invalid_ipa_characters(unicode_string, return_invalid=False, single_char_parsing=False):\n    if unicode_string is None:\n        return None\n    substrings = ipa_substrings(unicode_string, single_char_parsing=single_char_parsing)\n    valid = [s for s in substrings if s in UNICODE_TO_IPA]\n    if return_invalid:\n        return (valid, [s for s in substrings if s not in UNICODE_TO_IPA])\n    return valid", "response": "Removes all Unicode characters that are not IPA valid from the given string and returns a list of substrings of the given string that are not IPA valid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef variant_to_list(obj):\n    if isinstance(obj, list):\n        return obj\n    elif is_unicode_string(obj):\n        return [s for s in obj.split() if len(s) > 0]\n    elif isinstance(obj, set) or isinstance(obj, frozenset):\n        return list(obj)\n    raise TypeError(\"The given value must be a list or a set of descriptor strings, or a Unicode string.\")", "response": "Converts a given variant into a list containing the descriptors in the given object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a Variant object into a list containing the canonical string for the given object.", "response": "def variant_to_canonical_string(obj):\n    \"\"\"\n    Return a list containing the canonical string for the given object.\n\n    The ``obj`` can be a list or a set of descriptor strings, or a Unicode string.\n    \n    If ``obj`` is a Unicode string, it will be split using spaces as delimiters.\n\n    :param variant obj: the object to be parsed\n    :rtype: str \n    :raise TypeError: if the ``obj`` has a type not listed above\n    \"\"\"\n    acc = [DG_ALL_DESCRIPTORS.canonical_value(p) for p in variant_to_list(obj)]\n    acc = sorted([a for a in acc if a is not None])\n    return u\" \".join(acc)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the given object is a list of IPAChar objects.", "response": "def is_list_of_ipachars(obj):\n    \"\"\"\n    Return ``True`` if the given object is a list of IPAChar objects.\n\n    :param object obj: the object to test\n    :rtype: bool\n    \"\"\"\n    if isinstance(obj, list):\n        for e in obj:\n            if not isinstance(e, IPAChar):\n                return False\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_equivalent(self, other):\n        if (self.unicode_repr is not None) and (is_unicode_string(other)) and (self.unicode_repr == other):\n            return True\n        if isinstance(other, IPAChar):\n            return self.canonical_representation == other.canonical_representation\n        try:\n            return self.canonical_representation == IPAChar(name=None, descriptors=other).canonical_representation\n        except:\n            return False", "response": "Return True if the IPA character is equivalent to the other object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the canonical value of a character in the given descriptor group.", "response": "def dg_value(self, descriptor_group):\n        \"\"\"\n        Return the canonical value of a descriptor of the character,\n        provided it is present in the given descriptor group.\n\n        If not present, return ``None``.\n\n        :param IPADescriptorGroup descriptor_group: the descriptor group to be checked against\n        :rtype: str\n        \"\"\"\n        for p in self.descriptors:\n            if p in descriptor_group:\n                return descriptor_group.canonical_value(p)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the character has the given descriptor.", "response": "def has_descriptor(self, descriptor):\n        \"\"\"\n        Return ``True`` if the character has the given descriptor.\n\n        :param IPADescriptor descriptor: the descriptor to be checked against\n        :rtype: bool\n        \"\"\"\n        for p in self.descriptors:\n            if p in descriptor:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef voicing(self, value):\n        if (value is not None) and (not value in DG_C_VOICING):\n            raise ValueError(\"Unrecognized value for voicing: '%s'\" % value)\n        self.__voicing = value", "response": "Sets the voicing of the consonant."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef place(self, value):\n        if (value is not None) and (not value in DG_C_PLACE):\n            raise ValueError(\"Unrecognized value for place: '%s'\" % value)\n        self.__place = value", "response": "Sets the place of articulation of the consonant."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the manner of articulation of the consonant.", "response": "def manner(self, value):\n        \"\"\"\n        Set the manner of articulation of the consonant.\n\n        :param str value: the value to be set\n        \"\"\"\n        if (value is not None) and (not value in DG_C_MANNER):\n            raise ValueError(\"Unrecognized value for manner: '%s'\" % value)\n        self.__manner = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef height(self, value):\n        if (value is not None) and (not value in DG_V_HEIGHT):\n            raise ValueError(\"Unrecognized value for height: '%s'\" % value)\n        self.__height = value", "response": "Sets the height of the vowel."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef backness(self, value):\n        if (value is not None) and (not value in DG_V_BACKNESS):\n            raise ValueError(\"Unrecognized value for backness: '%s'\" % value)\n        self.__backness = value", "response": "Sets the backness of the vowel."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef roundness(self, value):\n        if (value is not None) and (not value in DG_V_ROUNDNESS):\n            raise ValueError(\"Unrecognized value for roundness: '%s'\" % value)\n        self.__roundness = value", "response": "Sets the roundness of the vowel."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the Kirshenbaum ASCII IPA data from the built - in database.", "response": "def _load_data(self):\n        \"\"\"\n        Load the Kirshenbaum ASCII IPA data from the built-in database.\n        \"\"\"\n        ipa_canonical_string_to_ascii_str = dict()\n        for line in load_data_file(\n            file_path=self.DATA_FILE_PATH,\n            file_path_is_relative=True,\n            line_format=u\"sxA\"\n        ):\n            i_desc, i_ascii = line\n            if len(i_ascii) == 0:\n                raise ValueError(\"Data file '%s' contains a bad line: '%s'\" % (self.DATA_FILE_PATH, line))\n            key = (variant_to_canonical_string(i_desc),)\n            ipa_canonical_string_to_ascii_str[key] = i_ascii[0]\n        return ipa_canonical_string_to_ascii_str"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the canonical value corresponding to the given query value.", "response": "def canonical_value(self, query):\n        \"\"\"\n        Return the canonical value corresponding to the given query value.\n\n        Return ``None`` if the query value is not present in any descriptor of the group.\n\n        :param str query: the descriptor value to be checked against\n        \"\"\"\n        for d in self.descriptors:\n            if query in d:\n                return d.canonical_label\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _load_data(self):\n        ipa_canonical_string_to_ascii_str = dict()\n        for line in load_data_file(\n            file_path=self.DATA_FILE_PATH,\n            file_path_is_relative=True,\n            line_format=u\"UA\"\n        ):\n            i_unicode, i_ascii = line\n            if (len(i_unicode) == 0) or (len(i_ascii) == 0):\n                raise ValueError(\"Data file '%s' contains a bad line: '%s'\" % (self.DATA_FILE_PATH, line))\n            i_unicode = i_unicode[0]\n            i_ascii = i_ascii[0]\n            key = tuple([UNICODE_TO_IPA[c].canonical_representation for c in i_unicode])\n            ipa_canonical_string_to_ascii_str[key] = i_ascii\n        return ipa_canonical_string_to_ascii_str", "response": "Load the ARPABET ASCII IPA data from the built - in database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_unicode_string(string):\n    if string is None:\n        return None\n    if PY2:\n        return isinstance(string, unicode)\n    return isinstance(string, str)", "response": "Checks if the given string is a Unicode string in Python 2 or str in Python 3."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a string into a Unicode string.", "response": "def to_unicode_string(string):\n    \"\"\"\n    Return a Unicode string out of the given string.\n    \n    On Python 2, it calls ``unicode`` with ``utf-8`` encoding.\n    On Python 3, it just returns the given string.\n\n    Return ``None`` if ``string`` is ``None``.\n\n    :param str string: the string to convert to Unicode\n    :rtype: (Unicode) str\n    \"\"\"\n    if string is None:\n        return None\n    if is_unicode_string(string):\n        return string\n    # if reached here, string is a byte string \n    if PY2:\n        return unicode(string, encoding=\"utf-8\")\n    return string.decode(encoding=\"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a string to a native - str.", "response": "def to_str(string):\n    \"\"\"\n    Return the given string (either byte string or Unicode string)\n    converted to native-str, that is,\n    a byte string on Python 2, or a Unicode string on Python 3.\n\n    Return ``None`` if ``string`` is ``None``.\n\n    :param str string: the string to convert to native-str\n    :rtype: native-str\n    \"\"\"\n    if string is None:\n        return None\n    if isinstance(string, str):\n        return string\n    if PY2:\n        return string.encode(\"utf-8\")\n    return string.decode(\"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a hexadecimal string to Unicode character.", "response": "def hex_to_unichr(hex_string):\n    \"\"\"\n    Return the Unicode character with the given codepoint,\n    given as an hexadecimal string.\n\n    Return ``None`` if ``hex_string`` is ``None`` or is empty.\n\n    Example::\n        \"0061\"   => a\n        \"U+0061\" => a\n\n    :param str hex_string: the Unicode codepoint of the desired character\n    :rtype: (Unicode) str\n    \"\"\"\n    if (hex_string is None) or (len(hex_string) < 1):\n        return None\n    if hex_string.startswith(\"U+\"):\n        hex_string = hex_string[2:]\n    return int_to_unichr(int(hex_string, base=16))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unicode_to_hex(unicode_string):\n    if unicode_string is None:\n        return None\n    acc = []\n    for c in unicode_string:\n        s = hex(ord(c)).replace(\"0x\", \"\").upper()\n        acc.append(\"U+\" + (\"0\" * (4 - len(s))) + s)\n    return u\" \".join(acc)", "response": "Converts a Unicode string to a Unicode hexadecimal codepoint."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_html(html):\n    body = html.strip().replace('\\x00', '').encode('utf8') or b'<html/>'\n    parser = lxml.html.HTMLParser(recover=True, encoding='utf8')\n    root = lxml.etree.fromstring(body, parser=parser)\n    if root is None:\n        root = lxml.etree.fromstring(b'<html/>', parser=parser)\n    return root", "response": "Parse a string with html."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef etree_to_text(tree,\n                  guess_punct_space=True,\n                  guess_layout=True,\n                  newline_tags=NEWLINE_TAGS,\n                  double_newline_tags=DOUBLE_NEWLINE_TAGS):\n    \"\"\"\n    Convert a html tree to text. Tree should be cleaned with\n    ``html_text.html_text.cleaner.clean_html`` before passing to this\n    function.\n\n    See html_text.extract_text docstring for description of the\n    approach and options.\n    \"\"\"\n    chunks = []\n\n    _NEWLINE = object()\n    _DOUBLE_NEWLINE = object()\n\n    class Context:\n        \"\"\" workaround for missing `nonlocal` in Python 2 \"\"\"\n        # _NEWLINE, _DOUBLE_NEWLINE or content of the previous chunk (str)\n        prev = _DOUBLE_NEWLINE\n\n    def should_add_space(text, prev):\n        \"\"\" Return True if extra whitespace should be added before text \"\"\"\n        if prev in {_NEWLINE, _DOUBLE_NEWLINE}:\n            return False\n        if not _has_trailing_whitespace(prev):\n            if _has_punct_after(text) or _has_open_bracket_before(prev):\n                return False\n        return True\n\n    def get_space_between(text, prev):\n        if not text or not guess_punct_space:\n            return ' '\n        return ' ' if should_add_space(text, prev) else ''\n\n    def add_newlines(tag, context):\n        if not guess_layout:\n            return\n        prev = context.prev\n        if prev is _DOUBLE_NEWLINE:  # don't output more than 1 blank line\n            return\n        if tag in double_newline_tags:\n            context.prev = _DOUBLE_NEWLINE\n            chunks.append('\\n' if prev is _NEWLINE else '\\n\\n')\n        elif tag in newline_tags:\n            context.prev = _NEWLINE\n            if prev is not _NEWLINE:\n                chunks.append('\\n')\n\n    def add_text(text_content, context):\n        text = _normalize_whitespace(text_content) if text_content else ''\n        if not text:\n            return\n        space = get_space_between(text, context.prev)\n        chunks.extend([space, text])\n        context.prev = text_content\n\n    def traverse_text_fragments(tree, context, handle_tail=True):\n        \"\"\" Extract text from the ``tree``: fill ``chunks`` variable \"\"\"\n        add_newlines(tree.tag, context)\n        add_text(tree.text, context)\n        for child in tree:\n            traverse_text_fragments(child, context)\n        add_newlines(tree.tag, context)\n        if handle_tail:\n            add_text(tree.tail, context)\n\n    traverse_text_fragments(tree, context=Context(), handle_tail=False)\n    return ''.join(chunks).strip()", "response": "Convert an etree to text."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a cleaned parsel. Selector to text.", "response": "def selector_to_text(sel, guess_punct_space=True, guess_layout=True):\n    \"\"\" Convert a cleaned parsel.Selector to text.\n    See html_text.extract_text docstring for description of the approach\n    and options.\n    \"\"\"\n    import parsel\n    if isinstance(sel, parsel.SelectorList):\n        # if selecting a specific xpath\n        text = []\n        for s in sel:\n            extracted = etree_to_text(\n                s.root,\n                guess_punct_space=guess_punct_space,\n                guess_layout=guess_layout)\n            if extracted:\n                text.append(extracted)\n        return ' '.join(text)\n    else:\n        return etree_to_text(\n            sel.root,\n            guess_punct_space=guess_punct_space,\n            guess_layout=guess_layout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts html to text.", "response": "def extract_text(html,\n                 guess_punct_space=True,\n                 guess_layout=True,\n                 newline_tags=NEWLINE_TAGS,\n                 double_newline_tags=DOUBLE_NEWLINE_TAGS):\n    \"\"\"\n    Convert html to text, cleaning invisible content such as styles.\n\n    Almost the same as normalize-space xpath, but this also\n    adds spaces between inline elements (like <span>) which are\n    often used as block elements in html markup, and adds appropriate\n    newlines to make output better formatted.\n\n    html should be a unicode string or an already parsed lxml.html element.\n\n    ``html_text.etree_to_text`` is a lower-level function which only accepts\n    an already parsed lxml.html Element, and is not doing html cleaning itself.\n\n    When guess_punct_space is True (default), no extra whitespace is added\n    for punctuation. This has a slight (around 10%) performance overhead\n    and is just a heuristic.\n\n    When guess_layout is True (default), a newline is added\n    before and after ``newline_tags`` and two newlines are added before\n    and after ``double_newline_tags``. This heuristic makes the extracted\n    text more similar to how it is rendered in the browser.\n\n    Default newline and double newline tags can be found in\n    `html_text.NEWLINE_TAGS` and `html_text.DOUBLE_NEWLINE_TAGS`.\n    \"\"\"\n    if html is None:\n        return ''\n    cleaned = _cleaned_html_tree(html)\n    return etree_to_text(\n        cleaned,\n        guess_punct_space=guess_punct_space,\n        guess_layout=guess_layout,\n        newline_tags=newline_tags,\n        double_newline_tags=double_newline_tags,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the JSON file from ArcGIS", "response": "def get_json(self, layer, where=\"1 = 1\", fields=[], count_only=False, srid='4326'):\n        \"\"\"\n        Gets the JSON file from ArcGIS\n        \"\"\"\n        params = {\n                'where': where,\n                'outFields': \", \".join(fields),\n                'returnGeometry': True,\n                'outSR': srid,\n                'f': \"pjson\",\n                'orderByFields': self.object_id_field,\n                'returnCountOnly': count_only\n            }\n        if self.token:\n            params['token'] = self.token\n        if self.geom_type:\n            params.update({'geometryType': self.geom_type})\n        response = requests.get(self._build_query_request(layer), params=params)\n        return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_descriptor_for_layer(self, layer):\n        if not layer in self._layer_descriptor_cache:\n            params = {'f': 'pjson'}\n            if self.token:\n                params['token'] = self.token\n            response = requests.get(self._build_request(layer), params=params)\n            self._layer_descriptor_cache[layer] = response.json()\n        return self._layer_descriptor_cache[layer]", "response": "Returns the standard JSON descriptor for the layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nenumerates all of the field names for a given layer.", "response": "def enumerate_layer_fields(self, layer):\n        \"\"\"\n        Pulls out all of the field names for a layer.\n        \"\"\"\n        descriptor = self.get_descriptor_for_layer(layer)\n        return [field['name'] for field in descriptor['fields']]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a single object from the KMZ.", "response": "def get(self, layer, where=\"1 = 1\", fields=[], count_only=False, srid='4326'):\n        \"\"\"\n        Gets a layer and returns it as honest to God GeoJSON.\n\n        WHERE 1 = 1 causes us to get everything. We use OBJECTID in the WHERE clause\n        to paginate, so don't use OBJECTID in your WHERE clause unless you're going to\n        query under 1000 objects.\n        \"\"\"\n        base_where = where\n        # By default we grab all of the fields. Technically I think\n        # we can just do \"*\" for all fields, but I found this was buggy in\n        # the KMZ mode. I'd rather be explicit.\n        fields = fields or self.enumerate_layer_fields(layer)\n\n        jsobj = self.get_json(layer, where, fields, count_only, srid)\n\n        # Sometimes you just want to know how far there is to go.\n        if count_only:\n            return jsobj.get('count')\n\n        # If there is no geometry, we default to assuming it's a Table type\n        # data format, and we dump a simple (non-geo) json of all of the data.\n        if not jsobj.get('geometryType', None):\n            return self.getTable(layer, where, fields, jsobj=jsobj)\n\n        # From what I can tell, the entire layer tends to be of the same type,\n        # so we only have to determine the parsing function once.\n        geom_parser = self._determine_geom_parser(jsobj.get('geometryType'))\n\n        features = []\n        # We always want to run once, and then break out as soon as we stop\n        # getting exceededTransferLimit.\n        while True:\n            features += [self.esri_to_geojson(feat, geom_parser) for feat in jsobj.get('features')]\n            if jsobj.get('exceededTransferLimit', False) == False:\n                break\n            # If we've hit the transfer limit we offset by the last OBJECTID\n            # returned and keep moving along.\n            where = \"%s > %s\" % (self.object_id_field, features[-1]['properties'].get(self.object_id_field))\n            if base_where != \"1 = 1\" :\n                # If we have another WHERE filter we needed to tack that back on.\n                where += \" AND %s\" % base_where\n            jsobj = self.get_json(layer, where, fields, count_only, srid)\n\n        return {\n            'type': \"FeatureCollection\",\n            'features': features\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getMultiple(self, layers, where=\"1 = 1\", fields=[], srid='4326', layer_name_field=None):\n        features = []\n        for layer in layers:\n            get_fields = fields or self.enumerate_layer_fields(layer)\n            this_layer = self.get(layer, where, get_fields, False, srid).get('features')\n            if layer_name_field:\n                descriptor = self.get_descriptor_for_layer(layer)\n                layer_name = descriptor.get('name')\n                for feature in this_layer:\n                    feature['properties'][layer_name_field] = layer_name\n            features += this_layer\n        return {\n            'type': \"FeatureCollection\",\n            'features': features\n        }", "response": "Get a bunch of layers and concatenate them together into one."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_version(extension, workflow_file):\n    '''Determines the version of a .py, .wdl, or .cwl file.'''\n    if extension == 'py' and two_seven_compatible(workflow_file):\n        return '2.7'\n    elif extension == 'cwl':\n        return yaml.load(open(workflow_file))['cwlVersion']\n    else:  # Must be a wdl file.\n        # Borrowed from https://github.com/Sage-Bionetworks/synapse-orchestrator/blob/develop/synorchestrator/util.py#L142\n        try:\n            return [l.lstrip('version') for l in workflow_file.splitlines() if 'version' in l.split(' ')][0]\n        except IndexError:\n            return 'draft-2'", "response": "Determines the version of a. py wdl or. cwl file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the version of the file and the file extension.", "response": "def wf_info(workflow_path):\n    \"\"\"\n    Returns the version of the file and the file extension.\n\n    Assumes that the file path is to the file directly ie, ends with a valid file extension.Supports checking local\n    files as well as files at http:// and https:// locations. Files at these remote locations are recreated locally to\n    enable our approach to version checking, then removed after version is extracted.\n    \"\"\"\n\n    supported_formats = ['py', 'wdl', 'cwl']\n    file_type = workflow_path.lower().split('.')[-1]  # Grab the file extension\n    workflow_path = workflow_path if ':' in workflow_path else 'file://' + workflow_path\n\n    if file_type in supported_formats:\n        if workflow_path.startswith('file://'):\n            version = get_version(file_type, workflow_path[7:])\n        elif workflow_path.startswith('https://') or workflow_path.startswith('http://'):\n            # If file not local go fetch it.\n            html = urlopen(workflow_path).read()\n            local_loc = os.path.join(os.getcwd(), 'fetchedFromRemote.' + file_type)\n            with open(local_loc, 'w') as f:\n                f.write(html.decode())\n            version = wf_info('file://' + local_loc)[0]  # Don't take the file_type here, found it above.\n            os.remove(local_loc)  # TODO: Find a way to avoid recreating file before version determination.\n        else:\n            raise NotImplementedError('Unsupported workflow file location: {}. Must be local or HTTP(S).'.format(workflow_path))\n    else:\n        raise TypeError('Unsupported workflow type: .{}. Must be {}.'.format(file_type, '.py, .cwl, or .wdl'))\n    return version, file_type.upper()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmodifies relative paths in a json / yaml file to be relative to where the json / yaml file is located.", "response": "def modify_jsonyaml_paths(jsonyaml_file):\n    \"\"\"\n    Changes relative paths in a json/yaml file to be relative\n    to where the json/yaml file is located.\n\n    :param jsonyaml_file: Path to a json/yaml file.\n    \"\"\"\n    loader = schema_salad.ref_resolver.Loader({\n        \"location\": {\"@type\": \"@id\"},\n        \"path\": {\"@type\": \"@id\"}\n    })\n    input_dict, _ = loader.resolve_ref(jsonyaml_file, checklinks=False)\n    basedir = os.path.dirname(jsonyaml_file)\n\n    def fixpaths(d):\n        \"\"\"Make sure all paths have a URI scheme.\"\"\"\n        if isinstance(d, dict):\n            if \"path\" in d:\n                if \":\" not in d[\"path\"]:\n                    local_path = os.path.normpath(os.path.join(os.getcwd(), basedir, d[\"path\"]))\n                    d[\"location\"] = pathname2url(local_path)\n                else:\n                    d[\"location\"] = d[\"path\"]\n                del d[\"path\"]\n\n    visit(input_dict, fixpaths)\n    return json.dumps(input_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding a WES request from a cwl file and a json file.", "response": "def build_wes_request(workflow_file, json_path, attachments=None):\n    \"\"\"\n    :param str workflow_file: Path to cwl/wdl file.  Can be http/https/file.\n    :param json_path: Path to accompanying json file.\n    :param attachments: Any other files needing to be uploaded to the server.\n\n    :return: A list of tuples formatted to be sent in a post to the wes-server (Swagger API).\n    \"\"\"\n    workflow_file = \"file://\" + workflow_file if \":\" not in workflow_file else workflow_file\n    wfbase = None\n    if json_path.startswith(\"file://\"):\n        wfbase = os.path.dirname(json_path[7:])\n        json_path = json_path[7:]\n        with open(json_path) as f:\n            wf_params = json.dumps(json.load(f))\n    elif json_path.startswith(\"http\"):\n        wf_params = modify_jsonyaml_paths(json_path)\n    else:\n        wf_params = json_path\n    wf_version, wf_type = wf_info(workflow_file)\n\n    parts = [(\"workflow_params\", wf_params),\n             (\"workflow_type\", wf_type),\n             (\"workflow_type_version\", wf_version)]\n\n    if workflow_file.startswith(\"file://\"):\n        if wfbase is None:\n            wfbase = os.path.dirname(workflow_file[7:])\n        parts.append((\"workflow_attachment\", (os.path.basename(workflow_file[7:]), open(workflow_file[7:], \"rb\"))))\n        parts.append((\"workflow_url\", os.path.basename(workflow_file[7:])))\n    else:\n        parts.append((\"workflow_url\", workflow_file))\n\n    if wfbase is None:\n        wfbase = os.getcwd()\n    if attachments:\n        for attachment in attachments:\n            if attachment.startswith(\"file://\"):\n                attachment = attachment[7:]\n                attach_f = open(attachment, \"rb\")\n                relpath = os.path.relpath(attachment, wfbase)\n            elif attachment.startswith(\"http\"):\n                attach_f = urlopen(attachment)\n                relpath = os.path.basename(attach_f)\n\n            parts.append((\"workflow_attachment\", (relpath, attach_f)))\n\n    return parts"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_service_info(self):\n        postresult = requests.get(\"%s://%s/ga4gh/wes/v1/service-info\" % (self.proto, self.host),\n                                  headers=self.auth)\n        return wes_reponse(postresult)", "response": "Get information about the workflow execution service."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self, wf, jsonyaml, attachments):\n        attachments = list(expand_globs(attachments))\n        parts = build_wes_request(wf, jsonyaml, attachments)\n        postresult = requests.post(\"%s://%s/ga4gh/wes/v1/runs\" % (self.proto, self.host),\n                                   files=parts,\n                                   headers=self.auth)\n        return wes_reponse(postresult)", "response": "Builds and sends a post request that signals the wes server to run a workflow."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncancels a running workflow.", "response": "def cancel(self, run_id):\n        \"\"\"\n        Cancel a running workflow.\n\n        :param run_id: String (typically a uuid) identifying the run.\n        :param str auth: String to send in the auth header.\n        :param proto: Schema where the server resides (http, https)\n        :param host: Port where the post request will be sent and the wes server listens at (default 8080)\n        :return: The body of the delete result as a dictionary.\n        \"\"\"\n        postresult = requests.post(\"%s://%s/ga4gh/wes/v1/runs/%s/cancel\" % (self.proto, self.host, run_id),\n                                   headers=self.auth)\n        return wes_reponse(postresult)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget detailed info about a running workflow.", "response": "def get_run_log(self, run_id):\n        \"\"\"\n        Get detailed info about a running workflow.\n\n        :param run_id: String (typically a uuid) identifying the run.\n        :param str auth: String to send in the auth header.\n        :param proto: Schema where the server resides (http, https)\n        :param host: Port where the post request will be sent and the wes server listens at (default 8080)\n        :return: The body of the get result as a dictionary.\n        \"\"\"\n        postresult = requests.get(\"%s://%s/ga4gh/wes/v1/runs/%s\" % (self.proto, self.host, run_id),\n                                  headers=self.auth)\n        return wes_reponse(postresult)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct a command to run a cwl/json from requests and opts, runs it, and deposits the outputs in outdir. Runner: opts.getopt(\"runner\", default=\"cwl-runner\") CWL (url): request[\"workflow_url\"] == a url to a cwl file or request[\"workflow_attachment\"] == input cwl text (written to a file and a url constructed for that file) JSON File: request[\"workflow_params\"] == input json text (to be written to a file) :param dict request: A dictionary containing the cwl/json information. :param wes_service.util.WESBackend opts: contains the user's arguments; specifically the runner and runner options :return: {\"run_id\": self.run_id, \"state\": state}", "response": "def run(self, request, tempdir, opts):\n        \"\"\"\n        Constructs a command to run a cwl/json from requests and opts,\n        runs it, and deposits the outputs in outdir.\n\n        Runner:\n        opts.getopt(\"runner\", default=\"cwl-runner\")\n\n        CWL (url):\n        request[\"workflow_url\"] == a url to a cwl file\n        or\n        request[\"workflow_attachment\"] == input cwl text (written to a file and a url constructed for that file)\n\n        JSON File:\n        request[\"workflow_params\"] == input json text (to be written to a file)\n\n        :param dict request: A dictionary containing the cwl/json information.\n        :param wes_service.util.WESBackend opts: contains the user's arguments;\n                                                 specifically the runner and runner options\n        :return: {\"run_id\": self.run_id, \"state\": state}\n        \"\"\"\n        with open(os.path.join(self.workdir, \"request.json\"), \"w\") as f:\n            json.dump(request, f)\n\n        with open(os.path.join(self.workdir, \"cwl.input.json\"), \"w\") as inputtemp:\n            json.dump(request[\"workflow_params\"], inputtemp)\n\n        workflow_url = request.get(\"workflow_url\")  # Will always be local path to descriptor cwl, or url.\n\n        output = open(os.path.join(self.workdir, \"cwl.output.json\"), \"w\")\n        stderr = open(os.path.join(self.workdir, \"stderr\"), \"w\")\n\n        runner = opts.getopt(\"runner\", default=\"cwl-runner\")\n        extra = opts.getoptlist(\"extra\")\n\n        # replace any locally specified outdir with the default\n        for e in extra:\n            if e.startswith('--outdir='):\n                extra.remove(e)\n        extra.append('--outdir=' + self.outdir)\n\n        # link the cwl and json into the tempdir/cwd\n        if workflow_url.startswith('file://'):\n            os.symlink(workflow_url[7:], os.path.join(tempdir, \"wes_workflow.cwl\"))\n            workflow_url = os.path.join(tempdir, \"wes_workflow.cwl\")\n        os.symlink(inputtemp.name, os.path.join(tempdir, \"cwl.input.json\"))\n        jsonpath = os.path.join(tempdir, \"cwl.input.json\")\n\n        # build args and run\n        command_args = [runner] + extra + [workflow_url, jsonpath]\n        proc = subprocess.Popen(command_args,\n                                stdout=output,\n                                stderr=stderr,\n                                close_fds=True,\n                                cwd=tempdir)\n        output.close()\n        stderr.close()\n        with open(os.path.join(self.workdir, \"pid\"), \"w\") as pid:\n            pid.write(str(proc.pid))\n\n        return self.getstatus()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the state of the current user s log entry.", "response": "def getstate(self):\n        \"\"\"\n        Returns RUNNING, -1\n                COMPLETE, 0\n                or\n                EXECUTOR_ERROR, 255\n        \"\"\"\n        state = \"RUNNING\"\n        exit_code = -1\n\n        exitcode_file = os.path.join(self.workdir, \"exit_code\")\n        pid_file = os.path.join(self.workdir, \"pid\")\n\n        if os.path.exists(exitcode_file):\n            with open(exitcode_file) as f:\n                exit_code = int(f.read())\n        elif os.path.exists(pid_file):\n            with open(pid_file, \"r\") as pid:\n                pid = int(pid.read())\n            try:\n                (_pid, exit_status) = os.waitpid(pid, os.WNOHANG)\n                if _pid != 0:\n                    exit_code = exit_status >> 8\n                    with open(exitcode_file, \"w\") as f:\n                        f.write(str(exit_code))\n                    os.unlink(pid_file)\n            except OSError:\n                os.unlink(pid_file)\n                exit_code = 255\n\n        if exit_code == 0:\n            state = \"COMPLETE\"\n        elif exit_code != -1:\n            state = \"EXECUTOR_ERROR\"\n\n        return state, exit_code"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a cwl wdl or python file as appropriate from the request dictionary.", "response": "def write_workflow(self, request, opts, cwd, wftype='cwl'):\n        \"\"\"Writes a cwl, wdl, or python file as appropriate from the request dictionary.\"\"\"\n\n        workflow_url = request.get(\"workflow_url\")\n\n        # link the cwl and json into the cwd\n        if workflow_url.startswith('file://'):\n            os.link(workflow_url[7:], os.path.join(cwd, \"wes_workflow.\" + wftype))\n            workflow_url = os.path.join(cwd, \"wes_workflow.\" + wftype)\n        os.link(self.input_json, os.path.join(cwd, \"wes_input.json\"))\n        self.input_json = os.path.join(cwd, \"wes_input.json\")\n\n        extra_options = self.sort_toil_options(opts.getoptlist(\"extra\"))\n        if wftype == 'cwl':\n            command_args = ['toil-cwl-runner'] + extra_options + [workflow_url, self.input_json]\n        elif wftype == 'wdl':\n            command_args = ['toil-wdl-runner'] + extra_options + [workflow_url, self.input_json]\n        elif wftype == 'py':\n            command_args = ['python'] + extra_options + [workflow_url]\n        else:\n            raise RuntimeError('workflow_type is not \"cwl\", \"wdl\", or \"py\": ' + str(wftype))\n\n        return command_args"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling a command with Popen.", "response": "def call_cmd(self, cmd, cwd):\n        \"\"\"\n        Calls a command with Popen.\n        Writes stdout, stderr, and the command to separate files.\n\n        :param cmd: A string or array of strings.\n        :param tempdir:\n        :return: The pid of the command.\n        \"\"\"\n        with open(self.cmdfile, 'w') as f:\n            f.write(str(cmd))\n        stdout = open(self.outfile, 'w')\n        stderr = open(self.errfile, 'w')\n        logging.info('Calling: ' + ' '.join(cmd))\n        process = subprocess.Popen(cmd,\n                                   stdout=stdout,\n                                   stderr=stderr,\n                                   close_fds=True,\n                                   cwd=cwd)\n        stdout.close()\n        stderr.close()\n\n        return process.pid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconstructing a command to run a cwl/json from requests and opts, runs it, and deposits the outputs in outdir. Runner: opts.getopt(\"runner\", default=\"cwl-runner\") CWL (url): request[\"workflow_url\"] == a url to a cwl file or request[\"workflow_attachment\"] == input cwl text (written to a file and a url constructed for that file) JSON File: request[\"workflow_params\"] == input json text (to be written to a file) :param dict request: A dictionary containing the cwl/json information. :param str tempdir: Folder where input files have been staged and the cwd to run at. :param wes_service.util.WESBackend opts: contains the user's arguments; specifically the runner and runner options :return: {\"run_id\": self.run_id, \"state\": state}", "response": "def run(self, request, tempdir, opts):\n        \"\"\"\n        Constructs a command to run a cwl/json from requests and opts,\n        runs it, and deposits the outputs in outdir.\n\n        Runner:\n        opts.getopt(\"runner\", default=\"cwl-runner\")\n\n        CWL (url):\n        request[\"workflow_url\"] == a url to a cwl file\n        or\n        request[\"workflow_attachment\"] == input cwl text (written to a file and a url constructed for that file)\n\n        JSON File:\n        request[\"workflow_params\"] == input json text (to be written to a file)\n\n        :param dict request: A dictionary containing the cwl/json information.\n        :param str tempdir: Folder where input files have been staged and the cwd to run at.\n        :param wes_service.util.WESBackend opts: contains the user's arguments;\n                                                 specifically the runner and runner options\n        :return: {\"run_id\": self.run_id, \"state\": state}\n        \"\"\"\n        wftype = request['workflow_type'].lower().strip()\n        version = request['workflow_type_version']\n\n        if version != 'v1.0' and wftype == 'cwl':\n            raise RuntimeError('workflow_type \"cwl\" requires '\n                               '\"workflow_type_version\" to be \"v1.0\": ' + str(version))\n        if version != '2.7' and wftype == 'py':\n            raise RuntimeError('workflow_type \"py\" requires '\n                               '\"workflow_type_version\" to be \"2.7\": ' + str(version))\n\n        logging.info('Beginning Toil Workflow ID: ' + str(self.run_id))\n\n        with open(self.starttime, 'w') as f:\n            f.write(str(time.time()))\n        with open(self.request_json, 'w') as f:\n            json.dump(request, f)\n        with open(self.input_json, \"w\") as inputtemp:\n            json.dump(request[\"workflow_params\"], inputtemp)\n\n        command_args = self.write_workflow(request, opts, tempdir, wftype=wftype)\n        pid = self.call_cmd(command_args, tempdir)\n\n        with open(self.endtime, 'w') as f:\n            f.write(str(time.time()))\n        with open(self.pidfile, 'w') as f:\n            f.write(str(pid))\n\n        return self.getstatus()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning QUEUED INITIALIZING EXECUTOR_ERROR 255", "response": "def getstate(self):\n        \"\"\"\n        Returns QUEUED,          -1\n                INITIALIZING,    -1\n                RUNNING,         -1\n                COMPLETE,         0\n                or\n                EXECUTOR_ERROR, 255\n        \"\"\"\n        # the jobstore never existed\n        if not os.path.exists(self.jobstorefile):\n            logging.info('Workflow ' + self.run_id + ': QUEUED')\n            return \"QUEUED\", -1\n\n        # completed earlier\n        if os.path.exists(self.statcompletefile):\n            logging.info('Workflow ' + self.run_id + ': COMPLETE')\n            return \"COMPLETE\", 0\n\n        # errored earlier\n        if os.path.exists(self.staterrorfile):\n            logging.info('Workflow ' + self.run_id + ': EXECUTOR_ERROR')\n            return \"EXECUTOR_ERROR\", 255\n\n        # the workflow is staged but has not run yet\n        if not os.path.exists(self.errfile):\n            logging.info('Workflow ' + self.run_id + ': INITIALIZING')\n            return \"INITIALIZING\", -1\n\n        # TODO: Query with \"toil status\"\n        completed = False\n        with open(self.errfile, 'r') as f:\n            for line in f:\n                if 'Traceback (most recent call last)' in line:\n                    logging.info('Workflow ' + self.run_id + ': EXECUTOR_ERROR')\n                    open(self.staterrorfile, 'a').close()\n                    return \"EXECUTOR_ERROR\", 255\n                # run can complete successfully but fail to upload outputs to cloud buckets\n                # so save the completed status and make sure there was no error elsewhere\n                if 'Finished toil run successfully.' in line:\n                    completed = True\n        if completed:\n            logging.info('Workflow ' + self.run_id + ': COMPLETE')\n            open(self.statcompletefile, 'a').close()\n            return \"COMPLETE\", 0\n\n        logging.info('Workflow ' + self.run_id + ': RUNNING')\n        return \"RUNNING\", -1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getopt(self, p, default=None):\n        for k, v in self.pairs:\n            if k == p:\n                return v\n        return default", "response": "Returns the first option value stored that matches p or default."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn all option values stored that match p as a list.", "response": "def getoptlist(self, p):\n        \"\"\"Returns all option values stored that match p as a list.\"\"\"\n        optlist = []\n        for k, v in self.pairs:\n            if k == p:\n                optlist.append(v)\n        return optlist"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef catch_exceptions(orig_func):\n\n    @functools.wraps(orig_func)\n    def catch_exceptions_wrapper(self, *args, **kwargs):\n        try:\n            return orig_func(self, *args, **kwargs)\n        except arvados.errors.ApiError as e:\n            logging.exception(\"Failure\")\n            return {\"msg\": e._get_reason(), \"status_code\": e.resp.status}, int(e.resp.status)\n        except subprocess.CalledProcessError as e:\n            return {\"msg\": str(e), \"status_code\": 500}, 500\n        except MissingAuthorization:\n            return {\"msg\": \"'Authorization' header is missing or empty, expecting Arvados API token\", \"status_code\": 401}, 401\n        except ValueError as e:\n            return {\"msg\": str(e), \"status_code\": 400}, 400\n        except Exception as e:\n            return {\"msg\": str(e), \"status_code\": 500}, 500\n\n    return catch_exceptions_wrapper", "response": "Catch uncaught exceptions and turn them into http errors"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the file name to ASCII and normalize the string.", "response": "def _safe_name(file_name, sep):\n    \"\"\"Convert the file name to ASCII and normalize the string.\"\"\"\n    file_name = stringify(file_name)\n    if file_name is None:\n        return\n    file_name = ascii_text(file_name)\n    file_name = category_replace(file_name, UNICODE_CATEGORIES)\n    file_name = collapse_spaces(file_name)\n    if file_name is None or not len(file_name):\n        return\n    return file_name.replace(WS, sep)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a secure filename for plain file system storage.", "response": "def safe_filename(file_name, sep='_', default=None, extension=None):\n    \"\"\"Create a secure filename for plain file system storage.\"\"\"\n    if file_name is None:\n        return decode_path(default)\n\n    file_name = decode_path(file_name)\n    file_name = os.path.basename(file_name)\n    file_name, _extension = os.path.splitext(file_name)\n    file_name = _safe_name(file_name, sep=sep)\n    if file_name is None:\n        return decode_path(default)\n    file_name = file_name[:MAX_LENGTH]\n    extension = _safe_name(extension or _extension, sep=sep)\n    if extension is not None:\n        file_name = '.'.join((file_name, extension))\n        file_name = file_name[:MAX_LENGTH]\n    return file_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stringify(value, encoding_default='utf-8', encoding=None):\n    if value is None:\n        return None\n\n    if not isinstance(value, six.text_type):\n        if isinstance(value, (date, datetime)):\n            return value.isoformat()\n        elif isinstance(value, (float, Decimal)):\n            return Decimal(value).to_eng_string()\n        elif isinstance(value, six.binary_type):\n            if encoding is None:\n                encoding = guess_encoding(value, default=encoding_default)\n            value = value.decode(encoding, 'replace')\n            value = remove_byte_order_mark(value)\n            value = remove_unsafe_chars(value)\n        else:\n            value = six.text_type(value)\n\n    # XXX: is this really a good idea?\n    value = value.strip()\n    if not len(value):\n        return None\n    return value", "response": "Brute - force convert a given object into a string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalize_encoding(encoding, default=DEFAULT_ENCODING):\n    if encoding is None:\n        return default\n    encoding = encoding.lower().strip()\n    if encoding in ['', 'ascii']:\n        return default\n    try:\n        codecs.lookup(encoding)\n        return encoding\n    except LookupError:\n        return default", "response": "Normalize the encoding name replace ASCII w / UTF - 8 w / DEFAULT_ENCODING."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninterprets a chardet result.", "response": "def normalize_result(result, default, threshold=0.2):\n    \"\"\"Interpret a chardet result.\"\"\"\n    if result is None:\n        return default\n    if result.get('confidence') is None:\n        return default\n    if result.get('confidence') < threshold:\n        return default\n    return normalize_encoding(result.get('encoding'),\n                              default=default)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef guess_encoding(text, default=DEFAULT_ENCODING):\n    result = chardet.detect(text)\n    return normalize_result(result, default=default)", "response": "Guess encoding of a piece of text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nguessing encoding from a file handle.", "response": "def guess_file_encoding(fh, default=DEFAULT_ENCODING):\n    \"\"\"Guess encoding from a file handle.\"\"\"\n    start = fh.tell()\n    detector = chardet.UniversalDetector()\n    while True:\n        data = fh.read(1024 * 10)\n        if not data:\n            detector.close()\n            break\n        detector.feed(data)\n        if detector.done:\n            break\n\n    fh.seek(start)\n    return normalize_result(detector.result, default=default)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef guess_path_encoding(file_path, default=DEFAULT_ENCODING):\n    with io.open(file_path, 'rb') as fh:\n        return guess_file_encoding(fh, default=default)", "response": "Try to guess the encoding of a file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decompose_nfkd(text):\n    if text is None:\n        return None\n    if not hasattr(decompose_nfkd, '_tr'):\n        decompose_nfkd._tr = Transliterator.createInstance('Any-NFKD')\n    return decompose_nfkd._tr.transliterate(text)", "response": "Perform unicode compatibility decomposition."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef category_replace(text, replacements=UNICODE_CATEGORIES):\n    if text is None:\n        return None\n    characters = []\n    for character in decompose_nfkd(text):\n        cat = category(character)\n        replacement = replacements.get(cat, character)\n        if replacement is not None:\n            characters.append(replacement)\n    return u''.join(characters)", "response": "Remove characters from a string based on unicode classes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_unsafe_chars(text):\n    if isinstance(text, six.string_types):\n        text = UNSAFE_RE.sub('', text)\n    return text", "response": "Remove unsafe unicode characters from a piece of text."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves newlines tabs and multiple spaces with single spaces.", "response": "def collapse_spaces(text):\n    \"\"\"Remove newlines, tabs and multiple spaces with single spaces.\"\"\"\n    if not isinstance(text, six.string_types):\n        return text\n    return COLLAPSE_RE.sub(WS, text).strip(WS)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef slugify(text, sep='-'):\n    text = stringify(text)\n    if text is None:\n        return None\n    text = text.replace(sep, WS)\n    text = normalize(text, ascii=True)\n    if text is None:\n        return None\n    return text.replace(WS, sep)", "response": "A simple slug generator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef latinize_text(text, ascii=False):\n    if text is None or not isinstance(text, six.string_types) or not len(text):\n        return text\n\n    if ascii:\n        if not hasattr(latinize_text, '_ascii'):\n            # Transform to latin, separate accents, decompose, remove\n            # symbols, compose, push to ASCII\n            latinize_text._ascii = Transliterator.createInstance('Any-Latin; NFKD; [:Symbol:] Remove; [:Nonspacing Mark:] Remove; NFKC; Accents-Any; Latin-ASCII')  # noqa\n        return latinize_text._ascii.transliterate(text)\n\n    if not hasattr(latinize_text, '_tr'):\n        latinize_text._tr = Transliterator.createInstance('Any-Latin')\n    return latinize_text._tr.transliterate(text)", "response": "Transliterate the given text to the latin script."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ascii_text(text):\n    text = latinize_text(text, ascii=True)\n    if isinstance(text, six.text_type):\n        text = text.encode('ascii', 'ignore').decode('ascii')\n    return text", "response": "Transliterate the given text and make sure it ends up as ASCII."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning default message for this element", "response": "def message(self):\n        \"\"\"Return default message for this element\n        \"\"\"\n        if self.code != 200:\n            for code in self.response_codes:\n                if code.code == self.code:\n                    return code.message\n\n            raise ValueError(\"Unknown response code \\\"%s\\\" in \\\"%s\\\".\" % (self.code, self.name))\n\n        return \"OK\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning default value for the element", "response": "def get_default_sample(self):\n        \"\"\"Return default value for the element\n        \"\"\"\n        if self.type not in Object.Types or self.type is Object.Types.type:\n            return self.type_object.get_sample()\n        else:\n            return self.get_object().get_sample()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a proper object of the specified type and version", "response": "def factory(cls, str_type, version):\n        \"\"\"Return a proper object\n        \"\"\"\n        type = Object.Types(str_type)\n\n        if type is Object.Types.object:\n            object = ObjectObject()\n        elif type is Object.Types.array:\n            object = ObjectArray()\n        elif type is Object.Types.number:\n            object = ObjectNumber()\n        elif type is Object.Types.integer:\n            object = ObjectInteger()\n        elif type is Object.Types.string:\n            object = ObjectString()\n        elif type is Object.Types.boolean:\n            object = ObjectBoolean()\n        elif type is Object.Types.reference:\n            object = ObjectReference()\n        elif type is Object.Types.type:\n            object = ObjectType()\n        elif type is Object.Types.none:\n            object = ObjectNone()\n        elif type is Object.Types.dynamic:\n            object = ObjectDynamic()\n        elif type is Object.Types.const:\n            object = ObjectConst()\n        elif type is Object.Types.enum:\n            object = ObjectEnum()\n        else:\n            object = Object()\n        object.type = type\n        object.version = version\n        return object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main():\n    configParser = FileParser()\n    logging.config.dictConfig(\n        configParser.load_from_file(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'settings', 'logging.yml'))\n    )\n    ApiDoc().main()", "response": "Main function to run command\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing the command s configuration from the command s arguments", "response": "def _init_config(self):\n        \"\"\"return command's configuration from call's arguments\n        \"\"\"\n        options = self.parser.parse_args()\n        if options.config is None and options.input is None:\n            self.parser.print_help()\n            sys.exit(2)\n\n        if options.config is not None:\n            configFactory = ConfigFactory()\n            config = configFactory.load_from_file(options.config)\n        else:\n            config = ConfigObject()\n\n        if options.input is not None:\n            config[\"input\"][\"locations\"] = [str(x) for x in options.input]\n        if options.arguments is not None:\n            config[\"input\"][\"arguments\"] = dict((x.partition(\"=\")[0], x.partition(\"=\")[2]) for x in options.arguments)\n\n        if options.output is not None:\n            config[\"output\"][\"location\"] = options.output\n\n        if options.no_validate is not None:\n            config[\"input\"][\"validate\"] = not options.no_validate\n\n        if options.dry_run is not None:\n            self.dry_run = options.dry_run\n        if options.watch is not None:\n            self.watch = options.watch\n        if options.traceback is not None:\n            self.traceback = options.traceback\n\n        if options.quiet is not None:\n            self.logger.setLevel(logging.WARNING)\n        if options.silence is not None:\n            logging.disable(logging.CRITICAL)\n\n        configService = ConfigService()\n        configService.validate(config)\n        self.config = config"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _watch_refresh_source(self, event):\n        self.logger.info(\"Sources changed...\")\n\n        try:\n            self.sources = self._get_sources()\n            self._render_template(self.sources)\n        except:\n            pass", "response": "Refresh sources and templates"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _watch_refresh_template(self, event):\n        self.logger.info(\"Template changed...\")\n\n        try:\n            self._render_template(self.sources)\n        except:\n            pass", "response": "Refreshes the template s contents"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a property to a class", "response": "def add_property(attribute, type):\n    \"\"\"Add a property to a class\n    \"\"\"\n    def decorator(cls):\n        \"\"\"Decorator\n        \"\"\"\n        private = \"_\" + attribute\n\n        def getAttr(self):\n            \"\"\"Property getter\n            \"\"\"\n            if getattr(self, private) is None:\n                setattr(self, private, type())\n            return getattr(self, private)\n\n        def setAttr(self, value):\n            \"\"\"Property setter\n            \"\"\"\n            setattr(self, private, value)\n\n        setattr(cls, attribute, property(getAttr, setAttr))\n        setattr(cls, private, None)\n        return cls\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncombining the input files to a big output file", "response": "def _merge_files(self, input_files, output_file):\n        \"\"\"Combine the input files to a big output file\"\"\"\n        # we assume that all the input files have the same charset\n        with open(output_file, mode='wb') as out:\n            for input_file in input_files:\n                out.write(open(input_file, mode='rb').read())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a populated object from a dictionary datas", "response": "def create_from_name_and_dictionary(self, name, datas):\n        \"\"\"Return a populated object Object from dictionary datas\n        \"\"\"\n        if \"type\" not in datas:\n            str_type = \"any\"\n        else:\n            str_type = str(datas[\"type\"]).lower()\n\n        if str_type not in ObjectRaw.Types:\n            type = ObjectRaw.Types(\"type\")\n        else:\n            type = ObjectRaw.Types(str_type)\n\n        if type is ObjectRaw.Types.object:\n            object = ObjectObject()\n            if \"properties\" in datas:\n                object.properties = self.create_dictionary_of_element_from_dictionary(\"properties\", datas)\n            if \"patternProperties\" in datas:\n                object.pattern_properties = self.create_dictionary_of_element_from_dictionary(\"patternProperties\", datas)\n            if \"additionalProperties\" in datas:\n                if isinstance(datas[\"additionalProperties\"], dict):\n                    object.additional_properties = self.create_from_name_and_dictionary(\"additionalProperties\", datas[\"additionalProperties\"])\n                elif not to_boolean(datas[\"additionalProperties\"]):\n                    object.additional_properties = None\n                else:\n                    raise ValueError(\"AdditionalProperties doe not allow empty value (yet)\")\n        elif type is ObjectRaw.Types.array:\n            object = ObjectArray()\n            if \"items\" in datas:\n                object.items = self.create_from_name_and_dictionary(\"items\", datas[\"items\"])\n            else:\n                object.items = ObjectObject()\n            if \"sample_count\" in datas:\n                object.sample_count = int(datas[\"sample_count\"])\n        elif type is ObjectRaw.Types.number:\n            object = ObjectNumber()\n        elif type is ObjectRaw.Types.integer:\n            object = ObjectInteger()\n        elif type is ObjectRaw.Types.string:\n            object = ObjectString()\n        elif type is ObjectRaw.Types.boolean:\n            object = ObjectBoolean()\n            if \"sample\" in datas:\n                object.sample = to_boolean(datas[\"sample\"])\n        elif type is ObjectRaw.Types.reference:\n            object = ObjectReference()\n            if \"reference\" in datas:\n                object.reference_name = str(datas[\"reference\"])\n        elif type is ObjectRaw.Types.type:\n            object = ObjectType()\n            object.type_name = str(datas[\"type\"])\n        elif type is ObjectRaw.Types.none:\n            object = ObjectNone()\n        elif type is ObjectRaw.Types.dynamic:\n            object = ObjectDynamic()\n            if \"items\" in datas:\n                object.items = self.create_from_name_and_dictionary(\"items\", datas[\"items\"])\n            if \"sample\" in datas:\n                if isinstance(datas[\"sample\"], dict):\n                    object.sample = {}\n                    for k, v in datas[\"sample\"].items():\n                        object.sample[str(k)] = str(v)\n                else:\n                    raise ValueError(\"A dictionnary is expected for dynamic\\s object in \\\"%s\\\"\" % name)\n        elif type is ObjectRaw.Types.const:\n            object = ObjectConst()\n            if \"const_type\" in datas:\n                const_type = str(datas[\"const_type\"])\n                if const_type not in ObjectConst.Types:\n                    raise ValueError(\"Const type \\\"%s\\\" unknwon\" % const_type)\n            else:\n                const_type = ObjectConst.Types.string\n            object.const_type = const_type\n            if \"value\" not in datas:\n                raise ValueError(\"Missing const value\")\n            object.value = datas[\"value\"]\n        elif type is ObjectRaw.Types.enum:\n            object = ObjectEnum()\n            if \"values\" not in datas or not isinstance(datas['values'], list):\n                raise ValueError(\"Missing enum values\")\n            object.values = [str(value) for value in datas[\"values\"]]\n            if \"descriptions\" in datas and isinstance(datas['descriptions'], dict):\n                for (value_name, value_description) in datas[\"descriptions\"].items():\n                    value = EnumValue()\n                    value.name = value_name\n                    value.description = value_description\n                    object.descriptions.append(value)\n\n            descriptions = [description.name for description in object.descriptions]\n            for value_name in [x for x in object.values if x not in descriptions]:\n                value = EnumValue()\n                value.name = value_name\n                object.descriptions.append(value)\n        else:\n            object = ObjectRaw()\n\n        self.set_common_datas(object, name, datas)\n        if isinstance(object, Constraintable):\n            self.set_constraints(object, datas)\n        object.type = type\n\n        if \"optional\" in datas:\n            object.optional = to_boolean(datas[\"optional\"])\n\n        return object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge_extends(self, target, extends, inherit_key=\"inherit\", inherit=False):\n        if isinstance(target, dict):\n            if inherit and inherit_key in target and not to_boolean(target[inherit_key]):\n                return\n            if not isinstance(extends, dict):\n                raise ValueError(\"Unable to merge: Dictionnary expected\")\n            for key in extends:\n                if key not in target:\n                    target[str(key)] = extends[key]\n                else:\n                    self.merge_extends(target[key], extends[key], inherit_key, True)\n        elif isinstance(target, list):\n            if not isinstance(extends, list):\n                raise ValueError(\"Unable to merge: List expected\")\n            target += extends", "response": "Merge extended dicts into target"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmerging sources files with new sources files", "response": "def merge_sources(self, datas):\n        \"\"\"Merge sources files\n        \"\"\"\n        datas = [data for data in datas if data is not None]\n\n        if len(datas) == 0:\n            raise ValueError(\"Data missing\")\n\n        if len(datas) == 1:\n            return datas[0]\n\n        if isinstance(datas[0], list):\n            if len([x for x in datas if not isinstance(x, list)]) > 0:\n                raise TypeError(\"Unable to merge: List expected\")\n            base = []\n            for x in datas:\n                base = base + x\n            return base\n\n        if isinstance(datas[0], dict):\n            if len([x for x in datas if not isinstance(x, dict)]) > 0:\n                raise TypeError(\"Unable to merge: Dictionnary expected\")\n            result = {}\n            for element in datas:\n                for key in element:\n                    if key in result:\n                        result[key] = self.merge_sources([result[key], element[key]])\n                    else:\n                        result[key] = element[key]\n            return result\n\n        if len([x for x in datas if isinstance(x, (dict, list))]) > 0:\n            raise TypeError(\"Unable to merge: List not expected\")\n\n        raise ValueError(\"Unable to merge: Conflict\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge_configs(self, config, datas):\n        if not isinstance(config, dict) or len([x for x in datas if not isinstance(x, dict)]) > 0:\n            raise TypeError(\"Unable to merge: Dictionnary expected\")\n\n        for key, value in config.items():\n            others = [x[key] for x in datas if key in x]\n            if len(others) > 0:\n                if isinstance(value, dict):\n                    config[key] = self.merge_configs(value, others)\n                else:\n                    config[key] = others[-1]\n        return config", "response": "Merge the configs of the datas into the config"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef factory(cls, object_raw):\n        if object_raw is None:\n            return None\n        if object_raw.type is ObjectRaw.Types.object:\n            return ObjectObject(object_raw)\n        elif object_raw.type is ObjectRaw.Types.type:\n            return ObjectType(object_raw)\n        elif object_raw.type is ObjectRaw.Types.array:\n            return ObjectArray(object_raw)\n        elif object_raw.type is ObjectRaw.Types.dynamic:\n            return ObjectDynamic(object_raw)\n        elif object_raw.type is ObjectRaw.Types.const:\n            return ObjectConst(object_raw)\n        elif object_raw.type is ObjectRaw.Types.enum:\n            return ObjectEnum(object_raw)\n        else:\n            return Object(object_raw)", "response": "Return a proper object\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render(self, sources, config, out=sys.stdout):\n        logger = logging.getLogger()\n        template = self.env.get_template(self.input)\n        output = template.render(sources=sources, layout=config[\"output\"][\"layout\"], config=config[\"output\"])\n        if self.output == \"stdout\":\n            out.write(output)\n        else:\n            dir = os.path.dirname(self.output)\n            if dir and not os.path.exists(dir):\n                try:\n                    os.makedirs(dir)\n                except IOError as ioerror:\n                    logger.error('Error on creating dir \"{}\": {}'.format(dir, str(ioerror)))\n                    return\n            if config[\"output\"][\"template\"] == \"default\":\n                if config[\"output\"][\"componants\"] == \"local\":\n                    for template_dir in self.env.loader.searchpath:\n                        files = (\n                            os.path.join(template_dir, \"resource\", \"js\", \"combined.js\"),\n                            os.path.join(template_dir, \"resource\", \"css\", \"combined.css\"),\n                            os.path.join(template_dir, \"resource\", \"font\", \"apidoc.eot\"),\n                            os.path.join(template_dir, \"resource\", \"font\", \"apidoc.woff\"),\n                            os.path.join(template_dir, \"resource\", \"font\", \"apidoc.ttf\"),\n                            os.path.join(template_dir, \"resource\", \"font\", \"source-code-pro.eot\"),\n                            os.path.join(template_dir, \"resource\", \"font\", \"source-code-pro.woff\"),\n                            os.path.join(template_dir, \"resource\", \"font\", \"source-code-pro.ttf\"),\n                        )\n\n                        for file in files:\n                            filename = os.path.basename(file)\n                            dirname = os.path.basename(os.path.dirname(file))\n\n                            if not os.path.exists(os.path.join(dir, dirname)):\n                                os.makedirs(os.path.join(dir, dirname))\n                            if os.path.exists(file):\n                                shutil.copyfile(file, os.path.join(dir, dirname, filename))\n                            else:\n                                logger.warn('Missing resource file \"%s\". If you run apidoc in virtualenv, run \"%s\"' % (filename, \"python setup.py resources\"))\n\n                if config[\"output\"][\"componants\"] == \"remote\":\n                    for template_dir in self.env.loader.searchpath:\n                        files = (\n                            os.path.join(template_dir, \"resource\", \"js\", \"combined.js\"),\n                            os.path.join(template_dir, \"resource\", \"css\", \"combined-embedded.css\"),\n                            os.path.join(template_dir, \"resource\", \"font\", \"apidoc.eot\"),\n                            os.path.join(template_dir, \"resource\", \"font\", \"apidoc.woff\"),\n                            os.path.join(template_dir, \"resource\", \"font\", \"apidoc.ttf\"),\n                            os.path.join(template_dir, \"resource\", \"font\", \"source-code-pro.eot\"),\n                            os.path.join(template_dir, \"resource\", \"font\", \"source-code-pro.woff\"),\n                            os.path.join(template_dir, \"resource\", \"font\", \"source-code-pro.ttf\"),\n                        )\n\n                        for file in files:\n                            filename = os.path.basename(file)\n                            dirname = os.path.basename(os.path.dirname(file))\n\n                            if not os.path.exists(os.path.join(dir, dirname)):\n                                os.makedirs(os.path.join(dir, dirname))\n                            if os.path.exists(file):\n                                shutil.copyfile(file, os.path.join(dir, dirname, filename))\n                            else:\n                                logger.warn('Missing resource file \"%s\". If you run apidoc in virtualenv, run \"%s\"' % (filename, \"python setup.py resources\"))\n\n            open(self.output, \"w\").write(output)", "response": "Render the documentation as defined in config"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an object Configuration from a dictionary datas", "response": "def create_from_dictionary(self, datas):\n        \"\"\"Return a populated object Configuration from dictionnary datas\n        \"\"\"\n        configuration = ObjectConfiguration()\n\n        if \"uri\" in datas:\n            configuration.uri = str(datas[\"uri\"])\n        if \"title\" in datas:\n            configuration.title = str(datas[\"title\"])\n        if \"description\" in datas:\n            configuration.description = str(datas[\"description\"])\n\n        return configuration"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_from_name_and_dictionary(self, name, datas):\n        parameter = ObjectParameter()\n        self.set_common_datas(parameter, name, datas)\n\n        if \"optional\" in datas:\n            parameter.optional = to_boolean(datas[\"optional\"])\n        if \"type\" in datas:\n            parameter.type = str(datas[\"type\"])\n        if \"generic\" in datas:\n            parameter.generic = to_boolean(datas[\"generic\"])\n\n        return parameter", "response": "Create an object Parameter from a name and dictionary datas."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate(self, sources):\n        if not isinstance(sources, Root):\n            raise Exception(\"Source object expected\")\n\n        parameters = self.get_uri_with_missing_parameters(sources)\n        for parameter in parameters:\n            logging.getLogger().warn('Missing parameter \"%s\" in uri of method \"%s\" in versions \"%s\"' % (parameter[\"name\"], parameter[\"method\"], parameter[\"version\"]))", "response": "Validate the format of sources\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating that the source file is ok .", "response": "def validate(self, config):\n        \"\"\"Validate that the source file is ok\n        \"\"\"\n        if not isinstance(config, ConfigObject):\n            raise Exception(\"Config object expected\")\n\n        if config[\"output\"][\"componants\"] not in (\"local\", \"remote\", \"embedded\", \"without\"):\n            raise ValueError(\"Unknown componant \\\"%s\\\".\" % config[\"output\"][\"componants\"])\n\n        if config[\"output\"][\"layout\"] not in (\"default\", \"content-only\"):\n            raise ValueError(\"Unknown layout \\\"%s\\\".\" % config[\"output\"][\"layout\"])\n\n        if config[\"input\"][\"locations\"] is not None:\n            unknown_locations = [x for x in config[\"input\"][\"locations\"] if not os.path.exists(x)]\n            if len(unknown_locations) > 0:\n                raise ValueError(\n                    \"Location%s \\\"%s\\\" does not exists\"\n                    % (\"s\" if len(unknown_locations) > 1 else \"\", (\"\\\" and \\\"\").join(unknown_locations))\n                )\n\n            config[\"input\"][\"locations\"] = [os.path.realpath(x) for x in config[\"input\"][\"locations\"]]\n\n        if config[\"input\"][\"arguments\"] is not None:\n            if not isinstance(config[\"input\"][\"arguments\"], dict):\n                raise ValueError(\n                    \"Sources arguments \\\"%s\\\" are not a dict\" % config[\"input\"][\"arguments\"]\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_template_from_config(self, config):\n        if config[\"output\"][\"template\"] == \"default\":\n            return os.path.join(\n                os.path.dirname(os.path.dirname(os.path.abspath(__file__))),\n                'template',\n                'default.html'\n            )\n        else:\n            return os.path.abspath(config[\"output\"][\"template\"])", "response": "Retrieve a template path from the config object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an object ResponseCode from a dictionary datas.", "response": "def create_from_dictionary(self, datas):\n        \"\"\"Return a populated object ResponseCode from dictionary datas\n        \"\"\"\n        if \"code\" not in datas:\n            raise ValueError(\"A response code must contain a code in \\\"%s\\\".\" % repr(datas))\n\n        code = ObjectResponseCode()\n        self.set_common_datas(code, str(datas[\"code\"]), datas)\n\n        code.code = int(datas[\"code\"])\n        if \"message\" in datas:\n            code.message = str(datas[\"message\"])\n        elif code.code in self.default_messages.keys():\n            code.message = self.default_messages[code.code]\n        if \"generic\" in datas:\n            code.generic = to_boolean(datas[\"generic\"])\n\n        return code"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_handler(self, path, handler):\n        self.signatures[path] = self.get_path_signature(path)\n        self.handlers[path] = handler", "response": "Add a handler to the watch queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_path_signature(self, path):\n        if not os.path.exists(path):\n            return None\n        if os.path.isdir(path):\n            merge = {}\n            for root, dirs, files in os.walk(path):\n                for name in files:\n                    full_name = os.path.join(root, name)\n                    merge[full_name] = os.stat(full_name)\n            return merge\n        else:\n            return os.stat(path)", "response": "generate a unique signature for a file contained in path"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check(self):\n        for (path, handler) in self.handlers.items():\n            current_signature = self.signatures[path]\n            new_signature = self.get_path_signature(path)\n            if new_signature != current_signature:\n                self.signatures[path] = new_signature\n                handler.on_change(Event(path))", "response": "Check if a file is changed\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_comparable_values(self):\n        return (int(self.major), int(self.minor), str(self.label), str(self.name))", "response": "Return a tupple of values representing the unicity of the object\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a tupple of values representing the unicity of the object", "response": "def get_comparable_values(self):\n        \"\"\"Return a tupple of values representing the unicity of the object\n        \"\"\"\n        return (int(self.order), str(self.label), str(self.name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_comparable_values(self):\n        return (not self.generic, str(self.name), str(self.description))", "response": "Return a tupple of values representing the unicity of the object\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a tupple of values representing the unicity of the object", "response": "def get_comparable_values_for_ordering(self):\n        \"\"\"Return a tupple of values representing the unicity of the object\n        \"\"\"\n\n        return (0 if self.position >= 0 else 1, int(self.position), str(self.name), str(self.description))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_comparable_values(self):\n        return (not self.generic, int(self.code), str(self.message), str(self.description))", "response": "Return a tupple of values representing the unicity of the object\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef factory(cls, object_source):\n        if object_source.type is ObjectRaw.Types.object:\n            return ObjectObject(object_source)\n        elif object_source.type not in ObjectRaw.Types or object_source.type is ObjectRaw.Types.type:\n            return ObjectType(object_source)\n        elif object_source.type is ObjectRaw.Types.array:\n            return ObjectArray(object_source)\n        elif object_source.type is ObjectRaw.Types.dynamic:\n            return ObjectDynamic(object_source)\n        elif object_source.type is ObjectRaw.Types.const:\n            return ObjectConst(object_source)\n        elif object_source.type is ObjectRaw.Types.enum:\n            return ObjectEnum(object_source)\n        else:\n            return Object(object_source)", "response": "Return a proper object from an object source"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_comparable_values(self):\n        return (str(self.name), str(self.description), str(self.type), bool(self.optional), str(self.constraints) if isinstance(self, Constraintable) else \"\")", "response": "Return a tupple of values representing the unicity of the object\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a tupple of values representing the unicity of the object", "response": "def get_comparable_values(self):\n        \"\"\"Return a tupple of values representing the unicity of the object\n        \"\"\"\n        return (str(self.name), str(self.description), str(self.constraints))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_from_name_and_dictionary(self, name, datas):\n        category = ObjectCategory(name)\n        self.set_common_datas(category, name, datas)\n\n        if \"order\" in datas:\n            category.order = int(datas[\"order\"])\n\n        return category", "response": "Create an object Category from a name and dictionary datas."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a config file into a dictionary", "response": "def load_from_file(self, file_path, format=None):\n        \"\"\"Return dict from a file config\n        \"\"\"\n        if format is None:\n            base_name, file_extension = os.path.splitext(file_path)\n            if file_extension in (\".yaml\", \".yml\"):\n                format = \"yaml\"\n            elif file_extension in (\".json\"):\n                format = \"json\"\n            else:\n                raise ValueError(\"Config file \\\"%s\\\" undetermined\" % file_extension)\n\n        if format == \"yaml\":\n            return yaml.load(open(file_path), Loader=yaml.CSafeLoader if yaml.__with_libyaml__ else yaml.SafeLoader)\n        elif format == \"json\":\n            return json.load(open(file_path))\n        else:\n            raise ValueError(\"Format \\\"%s\\\" unknwon\" % format)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_all_from_directory(self, directory_path):\n        datas = []\n        for root, folders, files in os.walk(directory_path):\n            for f in files:\n                datas.append(self.load_from_file(os.path.join(root, f)))\n\n        return datas", "response": "Return a list of dict from a directory containing files\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef json_repr(obj):\n\n    def serialize(obj):\n        \"\"\"Recursively walk object's hierarchy.\n        \"\"\"\n        if obj is None:\n            return None\n        if isinstance(obj, Enum):\n            return str(obj)\n        if isinstance(obj, (bool, int, float, str)):\n            return obj\n        if isinstance(obj, dict):\n            obj = obj.copy()\n            for key in sorted(obj.keys()):\n                obj[key] = serialize(obj[key])\n            return obj\n        if isinstance(obj, list):\n            return [serialize(item) for item in obj]\n        if isinstance(obj, tuple):\n            return tuple(serialize([item for item in obj]))\n        if hasattr(obj, '__dict__'):\n            return serialize(obj.__dict__)\n        return repr(obj)\n\n    return json.dumps(serialize(obj))", "response": "Represent an object as JSON."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_from_root(self, root_source):\n\n        root_dto = ObjectRoot()\n\n        root_dto.configuration = root_source.configuration\n        root_dto.versions = [Version(x) for x in root_source.versions.values()]\n\n        for version in sorted(root_source.versions.values()):\n            hydrator = Hydrator(version, root_source.versions, root_source.versions[version.name].types)\n            for method in version.methods.values():\n                hydrator.hydrate_method(root_dto, root_source, method)\n            for type in version.types.values():\n                hydrator.hydrate_type(root_dto, root_source, type)\n\n        self.define_changes_status(root_dto)\n\n        return root_dto", "response": "Create an object root from a dictionnary datas\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npopulating common data for an element from dictionnary datas", "response": "def set_common_datas(self, element, name, datas):\n        \"\"\"Populated common data for an element from dictionnary datas\n        \"\"\"\n        element.name = str(name)\n        if \"description\" in datas:\n            element.description = str(datas[\"description\"]).strip()\n\n        if isinstance(element, Sampleable) and element.sample is None and \"sample\" in datas:\n            element.sample = str(datas[\"sample\"]).strip()\n\n        if isinstance(element, Displayable):\n            if \"display\" in datas:\n                element.display = to_boolean(datas[\"display\"])\n\n            if \"label\" in datas:\n                element.label = datas[\"label\"]\n            else:\n                element.label = element.name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npopulating a dictionary of elements from a dictionary of datas", "response": "def create_dictionary_of_element_from_dictionary(self, property_name, datas):\n        \"\"\"Populate a dictionary of elements\n        \"\"\"\n        response = {}\n        if property_name in datas and datas[property_name] is not None and isinstance(datas[property_name], collections.Iterable):\n            for key, value in datas[property_name].items():\n                response[key] = self.create_from_name_and_dictionary(key, value)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npopulates a list of elements from a dictionary", "response": "def create_list_of_element_from_dictionary(self, property_name, datas):\n        \"\"\"Populate a list of elements\n        \"\"\"\n        response = []\n        if property_name in datas and datas[property_name] is not None and isinstance(datas[property_name], list):\n            for value in datas[property_name]:\n                response.append(self.create_from_dictionary(value))\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a template object from a config object", "response": "def create_from_config(self, config):\n        \"\"\"Create a template object file defined in the config object\n        \"\"\"\n\n        configService = ConfigService()\n        template = TemplateService()\n\n        template.output = config[\"output\"][\"location\"]\n\n        template_file = configService.get_template_from_config(config)\n        template.input = os.path.basename(template_file)\n        template.env = Environment(loader=FileSystemLoader(os.path.dirname(template_file)))\n\n        return template"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deploy(self, id_networkv4):\n\n        data = dict()\n        uri = 'api/networkv4/%s/equipments/' % id_networkv4\n\n        return super(ApiNetworkIPv4, self).post(uri, data=data)", "response": "Deploy network in equipments and set column active = 1 in tables redeipv4\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets IPv4 network by ID", "response": "def get_by_id(self, id_networkv4):\n        \"\"\"Get IPv4 network\n\n        :param id_networkv4: ID for NetworkIPv4\n\n        :return: IPv4 Network\n        \"\"\"\n\n        uri = 'api/networkv4/%s/' % id_networkv4\n\n        return super(ApiNetworkIPv4, self).get(uri)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list(self, environment_vip=None):\n\n        uri = 'api/networkv4/?'\n        if environment_vip:\n            uri += 'environment_vip=%s' % environment_vip\n\n        return super(ApiNetworkIPv4, self).get(uri)", "response": "List IPv4 networks with specific environment vip"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves deployment of network in equipments and set column active = 0 in tables redeipv4", "response": "def undeploy(self, id_networkv4):\n        \"\"\"Remove deployment of network in equipments and set column 'active = 0' in tables redeipv4 ]\n\n        :param id_networkv4: ID for NetworkIPv4\n\n        :return: Equipments configuration output\n        \"\"\"\n\n        uri = 'api/networkv4/%s/equipments/' % id_networkv4\n\n        return super(ApiNetworkIPv4, self).delete(uri)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck available ip in environment vip", "response": "def check_vip_ip(self, ip, environment_vip):\n        \"\"\"\n        Check available ip in environment vip\n        \"\"\"\n        uri = 'api/ipv4/ip/%s/environment-vip/%s/' % (ip, environment_vip)\n\n        return super(ApiNetworkIPv4, self).get(uri)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_ipv4(self, ipv4_id):\n        uri = 'api/ipv4/%s/' % (ipv4_id)\n\n        return super(ApiNetworkIPv4, self).delete(uri)", "response": "Method to delete ipv4"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search(self, **kwargs):\n\n        return super(ApiNetworkIPv4, self).get(self.prepare_url('api/v3/networkv4/',\n                                                                kwargs))", "response": "Method to search ipv4 s based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, ids):\n        url = build_uri_with_ids('api/v3/networkv4/%s/', ids)\n\n        return super(ApiNetworkIPv4, self).delete(url)", "response": "Method to delete network - ipv4 s by their ids\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update(self, networkipv4s):\n\n        data = {'networks': networkipv4s}\n        networkipv4s_ids = [str(networkipv4.get('id'))\n                            for networkipv4 in networkipv4s]\n\n        return super(ApiNetworkIPv4, self).put('api/v3/networkv4/%s/' %\n                                               ';'.join(networkipv4s_ids), data)", "response": "Method to update network - ipv4 s\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninserting a new Division Dc and returns its identifier.", "response": "def inserir(self, name):\n        \"\"\"Inserts a new Division Dc and returns its identifier.\n\n        :param name: Division Dc name. String with a minimum 2 and maximum of 80 characters\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {'division_dc': {'id': < id_division_dc >}}\n\n        :raise InvalidParameterError: Name is null and invalid.\n        :raise NomeDivisaoDcDuplicadoError: There is already a registered Division Dc with the value of name.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        division_dc_map = dict()\n        division_dc_map['name'] = name\n\n        code, xml = self.submit(\n            {'division_dc': division_dc_map}, 'POST', 'divisiondc/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchanging Division Dc from by the identifier.", "response": "def alterar(self, id_divisiondc, name):\n        \"\"\"Change Division Dc from by the identifier.\n\n        :param id_divisiondc: Identifier of the Division Dc. Integer value and greater than zero.\n        :param name: Division Dc name. String with a minimum 2 and maximum of 80 characters\n\n        :return: None\n\n        :raise InvalidParameterError: The identifier of Division Dc or name is null and invalid.\n        :raise NomeDivisaoDcDuplicadoError: There is already a registered Division Dc with the value of name.\n        :raise DivisaoDcNaoExisteError: Division Dc not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_divisiondc):\n            raise InvalidParameterError(\n                u'The identifier of Division Dc is invalid or was not informed.')\n\n        url = 'divisiondc/' + str(id_divisiondc) + '/'\n\n        division_dc_map = dict()\n        division_dc_map['name'] = name\n\n        code, xml = self.submit({'division_dc': division_dc_map}, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remover(self, id_divisiondc):\n\n        if not is_valid_int_param(id_divisiondc):\n            raise InvalidParameterError(\n                u'The identifier of Division Dc is invalid or was not informed.')\n\n        url = 'divisiondc/' + str(id_divisiondc) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Remove Division Dc from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search(self, **kwargs):\n\n        return super(ApiObjectType, self).get(self.prepare_url('api/v3/object-type/',\n                                                               kwargs))", "response": "Method to search object types based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind vlans in the database.", "response": "def find_vlans(\n            self,\n            number,\n            name,\n            iexact,\n            environment,\n            net_type,\n            network,\n            ip_version,\n            subnet,\n            acl,\n            pagination):\n        \"\"\"\n        Find vlans by all search parameters\n\n        :param number: Filter by vlan number column\n        :param name: Filter by vlan name column\n        :param iexact: Filter by name will be exact?\n        :param environment: Filter by environment ID related\n        :param net_type: Filter by network_type ID related\n        :param network: Filter by each octs in network\n        :param ip_version: Get only version (0:ipv4, 1:ipv6, 2:all)\n        :param subnet: Filter by octs will search by subnets?\n        :param acl: Filter by vlan acl column\n        :param pagination: Class with all data needed to paginate\n\n        :return: Following dictionary:\n\n        ::\n\n          {'vlan': {'id': < id_vlan >,\n          'nome': < nome_vlan >,\n          'num_vlan': < num_vlan >,\n          'id_ambiente': < id_ambiente >,\n          'descricao': < descricao >,\n          'acl_file_name': < acl_file_name >,\n          'acl_valida': < acl_valida >,\n          'acl_file_name_v6': < acl_file_name_v6 >,\n          'acl_valida_v6': < acl_valida_v6 >,\n          'ativada': < ativada >,\n          'ambiente_name': < divisao_dc-ambiente_logico-grupo_l3 >\n          'redeipv4': [ { all networkipv4 related } ],\n          'redeipv6': [ { all networkipv6 related } ] },\n          'total': {< total_registros >} }\n\n        :raise InvalidParameterError: Some parameter was invalid.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not isinstance(pagination, Pagination):\n            raise InvalidParameterError(\n                u\"Invalid parameter: pagination must be a class of type 'Pagination'.\")\n\n        vlan_map = dict()\n\n        vlan_map['start_record'] = pagination.start_record\n        vlan_map['end_record'] = pagination.end_record\n        vlan_map['asorting_cols'] = pagination.asorting_cols\n        vlan_map['searchable_columns'] = pagination.searchable_columns\n        vlan_map['custom_search'] = pagination.custom_search\n\n        vlan_map['numero'] = number\n        vlan_map['nome'] = name\n        vlan_map['exato'] = iexact\n        vlan_map['ambiente'] = environment\n        vlan_map['tipo_rede'] = net_type\n        vlan_map['rede'] = network\n        vlan_map['versao'] = ip_version\n        vlan_map['subrede'] = subnet\n        vlan_map['acl'] = acl\n\n        url = 'vlan/find/'\n\n        code, xml = self.submit({'vlan': vlan_map}, 'POST', url)\n\n        key = 'vlan'\n        return get_list_map(\n            self.response(\n                code, xml, [\n                    key, 'redeipv4', 'redeipv6', 'equipamentos']), key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef listar_por_ambiente(self, id_ambiente):\n        if not is_valid_int_param(id_ambiente):\n            raise InvalidParameterError(u'Environment id is none or invalid.')\n\n        url = 'vlan/ambiente/' + str(id_ambiente) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        key = 'vlan'\n        return get_list_map(self.response(code, xml, [key]), key)", "response": "List all VLANs from an environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef alocar(\n            self,\n            nome,\n            id_tipo_rede,\n            id_ambiente,\n            descricao,\n            id_ambiente_vip=None,\n            vrf=None):\n        \"\"\"Inserts a new VLAN.\n\n        :param nome: Name of Vlan. String with a maximum of 50 characters.\n        :param id_tipo_rede: Identifier of the Network Type. Integer value and greater than zero.\n        :param id_ambiente: Identifier of the Environment. Integer value and greater than zero.\n        :param descricao: Description of Vlan. String with a maximum of 200 characters.\n        :param id_ambiente_vip: Identifier of the Environment Vip. Integer value and greater than zero.\n\n        :return: Following dictionary:\n\n        ::\n\n          {'vlan': {'id': < id_vlan >,\n          'nome': < nome_vlan >,\n          'num_vlan': < num_vlan >,\n          'id_tipo_rede': < id_tipo_rede >,\n          'id_ambiente': < id_ambiente >,\n          'rede_oct1': < rede_oct1 >,\n          'rede_oct2': < rede_oct2 >,\n          'rede_oct3': < rede_oct3 >,\n          'rede_oct4': < rede_oct4 >,\n          'bloco': < bloco >,\n          'mascara_oct1': < mascara_oct1 >,\n          'mascara_oct2': < mascara_oct2 >,\n          'mascara_oct3': < mascara_oct3 >,\n          'mascara_oct4': < mascara_oct4 >,\n          'broadcast': < broadcast >,\n          'descricao': < descricao >,\n          'acl_file_name': < acl_file_name >,\n          'acl_valida': < acl_valida >,\n          'ativada': < ativada >}}\n\n        :raise VlanError: VLAN name already exists, VLAN name already exists, DC division of the environment invalid or does not exist VLAN number available.\n        :raise VlanNaoExisteError: VLAN not found.\n        :raise TipoRedeNaoExisteError: Network Type not registered.\n        :raise AmbienteNaoExisteError: Environment not registered.\n        :raise EnvironmentVipNotFoundError: Environment VIP not registered.\n        :raise InvalidParameterError: Name of Vlan and/or the identifier of the Environment is null or invalid.\n        :raise IPNaoDisponivelError: There is no network address is available to create the VLAN.\n        :raise ConfigEnvironmentInvalidError: Invalid Environment Configuration or not registered\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        vlan_map = dict()\n        vlan_map['nome'] = nome\n        vlan_map['id_tipo_rede'] = id_tipo_rede\n        vlan_map['id_ambiente'] = id_ambiente\n        vlan_map['descricao'] = descricao\n        vlan_map['id_ambiente_vip'] = id_ambiente_vip\n        vlan_map['vrf'] = vrf\n\n        code, xml = self.submit({'vlan': vlan_map}, 'POST', 'vlan/')\n\n        return self.response(code, xml)", "response": "Inserts a new VLAN in the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert a new VLAN into the database.", "response": "def insert_vlan(\n            self,\n            environment_id,\n            name,\n            number,\n            description,\n            acl_file,\n            acl_file_v6,\n            network_ipv4,\n            network_ipv6,\n            vrf=None):\n        \"\"\"Create new VLAN\n\n        :param environment_id: ID for Environment.\n        :param name: The name of VLAN.\n        :param description: Some description to VLAN.\n        :param number: Number of Vlan\n        :param acl_file: Acl IPv4 File name to VLAN.\n        :param acl_file_v6: Acl IPv6 File name to VLAN.\n        :param network_ipv4: responsible for generating a network attribute ipv4 automatically.\n        :param network_ipv6: responsible for generating a network attribute ipv6 automatically.\n\n        :return: Following dictionary:\n\n        ::\n\n          {'vlan': {'id': < id_vlan >,\n          'nome': < nome_vlan >,\n          'num_vlan': < num_vlan >,\n          'id_ambiente': < id_ambiente >,\n          'descricao': < descricao >,\n          'acl_file_name': < acl_file_name >,\n          'acl_valida': < acl_valida >,\n          'ativada': < ativada >\n          'acl_file_name_v6': < acl_file_name_v6 >,\n          'acl_valida_v6': < acl_valida_v6 >, } }\n\n        :raise VlanError: VLAN name already exists, VLAN name already exists, DC division of the environment invalid or does not exist VLAN number available.\n        :raise VlanNaoExisteError: VLAN not found.\n        :raise AmbienteNaoExisteError: Environment not registered.\n        :raise InvalidParameterError: Name of Vlan and/or the identifier of the Environment is null or invalid.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(environment_id):\n            raise InvalidParameterError(u'Environment id is none or invalid.')\n\n        if not is_valid_int_param(number):\n            raise InvalidParameterError(u'Vlan number is none or invalid')\n\n        vlan_map = dict()\n        vlan_map['environment_id'] = environment_id\n        vlan_map['name'] = name\n        vlan_map['description'] = description\n        vlan_map['acl_file'] = acl_file\n        vlan_map['acl_file_v6'] = acl_file_v6\n        vlan_map['number'] = number\n        vlan_map['network_ipv4'] = network_ipv4\n        vlan_map['network_ipv6'] = network_ipv6\n        vlan_map['vrf'] = vrf\n\n        code, xml = self.submit({'vlan': vlan_map}, 'POST', 'vlan/insert/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nedits a VLAN in the specified Environment.", "response": "def edit_vlan(\n            self,\n            environment_id,\n            name,\n            number,\n            description,\n            acl_file,\n            acl_file_v6,\n            id_vlan):\n        \"\"\"Edit a VLAN\n\n        :param id_vlan: ID for Vlan\n        :param environment_id: ID for Environment.\n        :param name: The name of VLAN.\n        :param description: Some description to VLAN.\n        :param number: Number of Vlan\n        :param acl_file: Acl IPv4 File name to VLAN.\n        :param acl_file_v6: Acl IPv6 File name to VLAN.\n\n        :return: None\n\n        :raise VlanError: VLAN name already exists, DC division of the environment invalid or there is no VLAN number available.\n        :raise VlanNaoExisteError: VLAN not found.\n        :raise AmbienteNaoExisteError: Environment not registered.\n        :raise InvalidParameterError: Name of Vlan and/or the identifier of the Environment is null or invalid.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_vlan):\n            raise InvalidParameterError(\n                u'Vlan id is invalid or was not informed.')\n\n        if not is_valid_int_param(environment_id):\n            raise InvalidParameterError(u'Environment id is none or invalid.')\n\n        if not is_valid_int_param(number):\n            raise InvalidParameterError(u'Vlan number is none or invalid')\n\n        vlan_map = dict()\n        vlan_map['vlan_id'] = id_vlan\n        vlan_map['environment_id'] = environment_id\n        vlan_map['name'] = name\n        vlan_map['description'] = description\n        vlan_map['acl_file'] = acl_file\n        vlan_map['acl_file_v6'] = acl_file_v6\n        vlan_map['number'] = number\n\n        code, xml = self.submit({'vlan': vlan_map}, 'POST', 'vlan/edit/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting column 'ativada = 1'. :param id_vlan: VLAN identifier. :return: None", "response": "def create_vlan(self, id_vlan):\n        \"\"\" Set column 'ativada = 1'.\n\n        :param id_vlan: VLAN identifier.\n\n        :return: None\n        \"\"\"\n\n        vlan_map = dict()\n\n        vlan_map['vlan_id'] = id_vlan\n\n        code, xml = self.submit({'vlan': vlan_map}, 'PUT', 'vlan/create/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef allocate_without_network(self, environment_id, name, description, vrf=None):\n        vlan_map = dict()\n        vlan_map['environment_id'] = environment_id\n        vlan_map['name'] = name\n        vlan_map['description'] = description\n        vlan_map['vrf'] = vrf\n\n        code, xml = self.submit({'vlan': vlan_map}, 'POST', 'vlan/no-network/')\n\n        return self.response(code, xml)", "response": "Create new VLAN without add NetworkIPv4."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef verificar_permissao(self, id_vlan, nome_equipamento, nome_interface):\n        if not is_valid_int_param(id_vlan):\n            raise InvalidParameterError(\n                u'Vlan id is invalid or was not informed.')\n\n        url = 'vlan/' + str(id_vlan) + '/check/'\n\n        vlan_map = dict()\n        vlan_map['nome'] = nome_equipamento\n        vlan_map['nome_interface'] = nome_interface\n\n        code, xml = self.submit({'equipamento': vlan_map}, 'PUT', url)\n\n        return self.response(code, xml)", "response": "Check if there is communication permission for VLAN to trunk."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary of all the keys that are set in the base class.", "response": "def buscar(self, id_vlan):\n        \"\"\"Get VLAN by its identifier.\n\n        :param id_vlan: VLAN identifier.\n\n        :return: Following dictionary:\n\n        ::\n\n          {'vlan': {'id': < id_vlan >,\n          'nome': < nome_vlan >,\n          'num_vlan': < num_vlan >,\n          'id_ambiente': < id_ambiente >,\n          'id_tipo_rede': < id_tipo_rede >,\n          'rede_oct1': < rede_oct1 >,\n          'rede_oct2': < rede_oct2 >,\n          'rede_oct3': < rede_oct3 >,\n          'rede_oct4': < rede_oct4 >,\n          'bloco': < bloco >,\n          'mascara_oct1': < mascara_oct1 >,\n          'mascara_oct2': < mascara_oct2 >,\n          'mascara_oct3': < mascara_oct3 >,\n          'mascara_oct4': < mascara_oct4 >,\n          'broadcast': < broadcast >,\n          'descricao': < descricao >,\n          'acl_file_name': < acl_file_name >,\n          'acl_valida': < acl_valida >,\n          'ativada': < ativada >}\n          OR {'id': < id_vlan >,\n          'nome': < nome_vlan >,\n          'num_vlan': < num_vlan >,\n          'id_tipo_rede': < id_tipo_rede >,\n          'id_ambiente': < id_ambiente >,\n          'bloco1': < bloco1 >,\n          'bloco2': < bloco2 >,\n          'bloco3': < bloco3 >,\n          'bloco4': < bloco4 >,\n          'bloco5': < bloco5 >,\n          'bloco6': < bloco6 >,\n          'bloco7': < bloco7 >,\n          'bloco8': < bloco8 >,\n          'bloco': < bloco >,\n          'mask_bloco1': < mask_bloco1 >,\n          'mask_bloco2': < mask_bloco2 >,\n          'mask_bloco3': < mask_bloco3 >,\n          'mask_bloco4': < mask_bloco4 >,\n          'mask_bloco5': < mask_bloco5 >,\n          'mask_bloco6': < mask_bloco6 >,\n          'mask_bloco7': < mask_bloco7 >,\n          'mask_bloco8': < mask_bloco8 >,\n          'broadcast': < broadcast >,\n          'descricao': < descricao >,\n          'acl_file_name': < acl_file_name >,\n          'acl_valida': < acl_valida >,\n          'acl_file_name_v6': < acl_file_name_v6 >,\n          'acl_valida_v6': < acl_valida_v6 >,\n          'ativada': < ativada >}}\n\n        :raise VlanNaoExisteError: VLAN does not exist.\n        :raise InvalidParameterError: VLAN id is none or invalid.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        if not is_valid_int_param(id_vlan):\n            raise InvalidParameterError(\n                u'Vlan id is invalid or was not informed.')\n\n        url = 'vlan/' + str(id_vlan) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a VLAN by your primary key.", "response": "def get(self, id_vlan):\n        \"\"\"Get a VLAN by your primary key.\n        Network IPv4/IPv6 related will also be fetched.\n\n        :param id_vlan: ID for VLAN.\n\n        :return: Following dictionary:\n\n        ::\n\n          {'vlan': {'id': < id_vlan >,\n          'nome': < nome_vlan >,\n          'num_vlan': < num_vlan >,\n          'id_ambiente': < id_ambiente >,\n          'descricao': < descricao >,\n          'acl_file_name': < acl_file_name >,\n          'acl_valida': < acl_valida >,\n          'acl_file_name_v6': < acl_file_name_v6 >,\n          'acl_valida_v6': < acl_valida_v6 >,\n          'ativada': < ativada >,\n          'redeipv4': [ { all networkipv4 related } ],\n          'redeipv6': [ { all networkipv6 related } ] } }\n\n        :raise InvalidParameterError: Invalid ID for VLAN.\n        :raise VlanNaoExisteError: VLAN not found.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        if not is_valid_int_param(id_vlan):\n            raise InvalidParameterError(\n                u'Parameter id_vlan is invalid. Value: ' +\n                id_vlan)\n\n        url = 'vlan/' + str(id_vlan) + '/network/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return get_list_map(\n            self.response(\n                code, xml, [\n                    'redeipv4', 'redeipv6']), 'vlan')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef listar_permissao(self, nome_equipamento, nome_interface):\n        vlan_map = dict()\n        vlan_map['nome'] = nome_equipamento\n        vlan_map['nome_interface'] = nome_interface\n\n        code, xml = self.submit({'equipamento': vlan_map}, 'PUT', 'vlan/list/')\n\n        return self.response(code, xml)", "response": "List all VLANS having communication permission to trunk from a port in switch."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_ipv4(self, id_network_ipv4):\n\n        url = 'vlan/v4/create/'\n\n        vlan_map = dict()\n        vlan_map['id_network_ip'] = id_network_ipv4\n\n        code, xml = self.submit({'vlan': vlan_map}, 'POST', url)\n\n        return self.response(code, xml)", "response": "Create a VLAN in layer 2 using script navlan."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_ipv6(self, id_network_ipv6):\n\n        url = 'vlan/v6/create/'\n\n        vlan_map = dict()\n        vlan_map['id_network_ip'] = id_network_ipv6\n\n        code, xml = self.submit({'vlan': vlan_map}, 'POST', url)\n\n        return self.response(code, xml)", "response": "Create a VLAN in layer 2 using script navlan."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply_acl(self, equipments, vlan, environment, network):\n        '''Apply the file acl in equipments\n\n        :param equipments: list of equipments\n        :param vlan: Vvlan\n        :param environment: Environment\n        :param network: v4 or v6\n\n        :raise Exception: Failed to apply acl\n\n        :return: True case Apply and sysout of script\n        '''\n\n        vlan_map = dict()\n        vlan_map['equipments'] = equipments\n        vlan_map['vlan'] = vlan\n        vlan_map['environment'] = environment\n        vlan_map['network'] = network\n\n        url = 'vlan/apply/acl/'\n\n        code, xml = self.submit({'vlan': vlan_map}, 'POST', url)\n\n        return self.response(code, xml)", "response": "Apply the file acl in equipments\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconfirm a vlan insert need to be confirmed", "response": "def confirm_vlan(self, number_net, id_environment_vlan, ip_version=None):\n        \"\"\"Checking if the vlan insert need to be confirmed\n\n        :param number_net: Filter by vlan number column\n        :param id_environment_vlan: Filter by environment ID related\n        :param ip_version: Ip version for checking\n\n        :return: True is need confirmation, False if no need\n\n        :raise AmbienteNaoExisteError: Ambiente n\u00e3o cadastrado.\n        :raise InvalidParameterError: Invalid ID for VLAN.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        url = 'vlan/confirm/' + \\\n            str(number_net) + '/' + id_environment_vlan + '/' + str(ip_version)\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_number_available(self, id_environment, num_vlan, id_vlan):\n\n        url = 'vlan/check_number_available/' + \\\n            str(id_environment) + '/' + str(num_vlan) + '/' + str(id_vlan)\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)", "response": "Check if environment has a number vlan available"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate ACL - IPv4 of VLAN from its identifier.", "response": "def validar(self, id_vlan):\n        \"\"\"Validates ACL - IPv4 of VLAN from its identifier.\n\n        Assigns 1 to 'acl_valida'.\n\n        :param id_vlan: Identifier of the Vlan. Integer value and greater than zero.\n\n        :return: None\n\n        :raise InvalidParameterError: Vlan identifier is null and invalid.\n        :raise VlanNaoExisteError: Vlan not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_vlan):\n            raise InvalidParameterError(\n                u'The identifier of Vlan is invalid or was not informed.')\n\n        url = 'vlan/' + str(id_vlan) + '/validate/' + IP_VERSION.IPv4[0] + '/'\n\n        code, xml = self.submit(None, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates ACL - IPv6 of VLAN from its identifier.", "response": "def validate_ipv6(self, id_vlan):\n        \"\"\"Validates ACL - IPv6 of VLAN from its identifier.\n\n        Assigns 1 to 'acl_valida_v6'.\n\n        :param id_vlan: Identifier of the Vlan. Integer value and greater than zero.\n\n        :return: None\n\n        :raise InvalidParameterError: Vlan identifier is null and invalid.\n        :raise VlanNaoExisteError: Vlan not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_vlan):\n            raise InvalidParameterError(\n                u'The identifier of Vlan is invalid or was not informed.')\n\n        url = 'vlan/' + str(id_vlan) + '/validate/' + IP_VERSION.IPv6[0] + '/'\n\n        code, xml = self.submit(None, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves a VLAN by your primary key.", "response": "def remove(self, id_vlan):\n        \"\"\"Remove a VLAN by your primary key.\n        Execute script to remove VLAN\n\n        :param id_vlan: ID for VLAN.\n\n        :return: Following dictionary:\n\n        ::\n\n          {\u2018sucesso\u2019: {\u2018codigo\u2019: < codigo >,\n          \u2018descricao\u2019: {'stdout':< stdout >, 'stderr':< stderr >}}}\n\n        :raise InvalidParameterError: Identifier of the VLAN is invalid.\n        :raise VlanNaoExisteError: VLAN not found.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_vlan):\n            raise InvalidParameterError(\n                u'Parameter id_vlan is invalid. Value: ' +\n                id_vlan)\n\n        url = 'vlan/' + str(id_vlan) + '/remove/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deallocate(self, id_vlan):\n\n        if not is_valid_int_param(id_vlan):\n            raise InvalidParameterError(\n                u'The identifier of Vlan is invalid or was not informed.')\n\n        url = 'vlan/' + str(id_vlan) + '/deallocate/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Deallocate all relationships between Vlan."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninsert a new VLAN in the internal cache.", "response": "def allocate_IPv6(\n            self,\n            name,\n            id_network_type,\n            id_environment,\n            description,\n            id_environment_vip=None):\n        \"\"\"Inserts a new VLAN.\n\n        :param name: Name of Vlan. String with a maximum of 50 characters.\n        :param id_network_type: Identifier of the Netwok Type. Integer value and greater than zero.\n        :param id_environment: Identifier of the Environment. Integer value and greater than zero.\n        :param description: Description of Vlan. String with a maximum of 200 characters.\n        :param id_environment_vip: Identifier of the Environment Vip. Integer value and greater than zero.\n\n        :return: Following dictionary:\n\n        ::\n\n          {'vlan': {'id': < id_vlan >,\n          'nome': < nome_vlan >,\n          'num_vlan': < num_vlan >,\n          'id_tipo_rede': < id_tipo_rede >,\n          'id_ambiente': < id_ambiente >,\n          'bloco1': < bloco1 >,\n          'bloco2': < bloco2 >,\n          'bloco3': < bloco3 >,\n          'bloco4': < bloco4 >,\n          'bloco5': < bloco5 >,\n          'bloco6': < bloco6 >,\n          'bloco7': < bloco7 >,\n          'bloco8': < bloco8 >,\n          'bloco': < bloco >,\n          'mask_bloco1': < mask_bloco1 >,\n          'mask_bloco2': < mask_bloco2 >,\n          'mask_bloco3': < mask_bloco3 >,\n          'mask_bloco4': < mask_bloco4 >,\n          'mask_bloco5': < mask_bloco5 >,\n          'mask_bloco6': < mask_bloco6 >,\n          'mask_bloco7': < mask_bloco7 >,\n          'mask_bloco8': < mask_bloco8 >,\n          'descricao': < descricao >,\n          'acl_file_name': < acl_file_name >,\n          'acl_valida': < acl_valida >,\n          'acl_file_name_v6': < acl_file_name_v6 >,\n          'acl_valida_v6': < acl_valida_v6 >,\n          'ativada': < ativada >}}\n\n        :raise VlanError: VLAN name already exists, VLAN name already exists, DC division of the environment invalid or does not exist VLAN number available.\n        :raise VlanNaoExisteError: VLAN not found.\n        :raise TipoRedeNaoExisteError: Network Type not registered.\n        :raise AmbienteNaoExisteError: Environment not registered.\n        :raise EnvironmentVipNotFoundError: Environment VIP not registered.\n        :raise InvalidParameterError: Name of Vlan and/or the identifier of the Environment is null or invalid.\n        :raise IPNaoDisponivelError: There is no network address is available to create the VLAN.\n        :raise ConfigEnvironmentInvalidError: Invalid Environment Configuration or not registered\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        vlan_map = dict()\n        vlan_map['name'] = name\n        vlan_map['id_network_type'] = id_network_type\n        vlan_map['id_environment'] = id_environment\n        vlan_map['description'] = description\n        vlan_map['id_environment_vip'] = id_environment_vip\n\n        code, xml = self.submit({'vlan': vlan_map}, 'POST', 'vlan/ipv6/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_script_acl(self, id_vlan, network_type):\n        '''Generate the script acl\n\n        :param id_vlan: Vlan Id\n        :param network_type: v4 or v6\n\n        :raise InvalidValueError: Attrs invalids.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        :raise VlanACLDuplicatedError: ACL name duplicate.\n        :raise VlanNotFoundError: Vlan not registered.\n\n        :return: Following dictionary:\n\n        ::\n\n          {'vlan': {\n          'id': < id >,\n          'nome': '< nome >',\n          'num_vlan': < num_vlan >,\n          'descricao': < descricao >\n          'acl_file_name': < acl_file_name >,\n          'ativada': < ativada >,\n          'acl_valida': < acl_valida >,\n          'acl_file_name_v6': < acl_file_name_v6 >,\n          'redeipv6': < redeipv6 >,\n          'acl_valida_v6': < acl_valida_v6 >,\n          'redeipv4': < redeipv4 >,\n          'ambiente': < ambiente >,\n          }}\n        '''\n\n        vlan_map = dict()\n        vlan_map['id_vlan'] = id_vlan\n        vlan_map['network_type'] = network_type\n\n        url = 'vlan/create/script/acl/'\n\n        code, xml = self.submit({'vlan': vlan_map}, 'POST', url)\n\n        return self.response(code, xml)", "response": "Generate the script acl for a given vlan."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a relationship between User and Group.", "response": "def inserir(self, id_user, id_group):\n        \"\"\"Create a relationship between User and Group.\n\n        :param id_user: Identifier of the User. Integer value and greater than zero.\n        :param id_group: Identifier of the Group. Integer value and greater than zero.\n\n        :return: Dictionary with the following structure:\n\n        ::\n            {'user_group': {'id': < id_user_group >}}\n\n        :raise InvalidParameterError: The identifier of User or Group is null and invalid.\n        :raise GrupoUsuarioNaoExisteError: UserGroup not registered.\n        :raise UsuarioNaoExisteError: User not registered.\n        :raise UsuarioGrupoError: User already registered in the group.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        if not is_valid_int_param(id_user):\n            raise InvalidParameterError(\n                u'The identifier of User is invalid or was not informed.')\n\n        if not is_valid_int_param(id_group):\n            raise InvalidParameterError(\n                u'The identifier of Group is invalid or was not informed.')\n\n        url = 'usergroup/user/' + \\\n            str(id_user) + '/ugroup/' + str(id_group) + '/associate/'\n\n        code, xml = self.submit(None, 'PUT', url)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dumps(map, root_name, root_attributes=None):\n    xml = ''\n    try:\n        implementation = getDOMImplementation()\n    except ImportError as i:\n        raise XMLErrorUtils(i, u'Erro ao obter o DOMImplementation')\n\n    doc = implementation.createDocument(None, root_name, None)\n\n    try:\n        root = doc.documentElement\n\n        if (root_attributes is not None):\n            for key, value in root_attributes.iteritems():\n                attribute = doc.createAttribute(key)\n                attribute.nodeValue = value\n                root.setAttributeNode(attribute)\n\n        _add_nodes_to_parent(map, root, doc)\n\n        xml = doc.toxml('UTF-8')\n    except InvalidCharacterErr as i:\n        raise InvalidNodeNameXMLError(\n            i,\n            u'Valor inv\u00e1lido para nome de uma TAG de XML: %s' %\n            root_name)\n    finally:\n        doc.unlink()\n\n    return xml", "response": "Return a string representation of a map."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef loads(xml, force_list=None):\n    if force_list is None:\n        force_list = []\n\n    try:\n        xml = remove_illegal_characters(xml)\n        doc = parseString(xml)\n    except Exception as e:\n        raise XMLErrorUtils(e, u'Falha ao realizar o parse do xml.')\n\n    root = doc.documentElement\n\n    map = dict()\n    attrs_map = dict()\n\n    if root.hasAttributes():\n        attributes = root.attributes\n        for i in range(attributes.length):\n            attr = attributes.item(i)\n            attrs_map[attr.nodeName] = attr.nodeValue\n\n    map[root.nodeName] = _create_childs_map(root, force_list)\n\n    return map", "response": "A chamada de las dicion\u00e1rio para cada n\u00f3 s do XML."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef option_vip_by_environment_vip_type(self, environment_vip_id, type_option):\n\n        uri = \"api/v3/option-vip/environment-vip/%s/type-option/%s/\" % (environment_vip_id, type_option)\n\n        return self.get(uri)", "response": "This method returns a list of vip s attributes by environment vip type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search(self, **kwargs):\n\n        return super(ApiV4Neighbor, self).get(self.prepare_url(\n            'api/v4/neighbor/', kwargs))", "response": "Method to search neighbors based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, ids):\n        url = build_uri_with_ids('api/v4/neighbor/%s/', ids)\n        return super(ApiV4Neighbor, self).delete(url)", "response": "Method to delete neighbors by their id s\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, neighbors):\n\n        data = {'neighbors': neighbors}\n        neighbors_ids = [str(env.get('id')) for env in neighbors]\n\n        return super(ApiV4Neighbor, self).put('api/v4/neighbor/%s/' %\n                                               ';'.join(neighbors_ids), data)", "response": "Method to update neighbors in cluster"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_vip(\n            self,\n            id,\n            real_name_sufixo,\n            id_vlan,\n            descricao_vlan,\n            id_vlan_real,\n            descricao_vlan_real,\n            balanceadores,\n            id_healthcheck_expect,\n            finalidade,\n            cliente,\n            ambiente,\n            cache,\n            metodo_bal,\n            persistencia,\n            healthcheck_type,\n            healthcheck,\n            timeout,\n            host,\n            maxcon,\n            dsr,\n            bal_ativo,\n            transbordos,\n            portas,\n            real_maps,\n            id_requisicao_vip,\n            areanegocio='Orquestra',\n            nome_servico='Orquestra',\n            l7_filter=None,\n            reals_prioritys=None,\n            reals_weights=None):\n        \"\"\"Adiciona um VIP na lista de VIPs para opera\u00e7\u00e3o de inserir/alterar um grupo virtual.\n\n        Os par\u00e2metros abaixo somente s\u00e3o necess\u00e1rios para a opera\u00e7\u00e3o de altera\u00e7\u00e3o:\n\n            - 'real_maps': Dever\u00e1 conter os reals atualmente criados para a requisi\u00e7\u00e3o de VIP.\n            - 'id_requisicao_vip': O identificador da requisi\u00e7\u00e3o que dever\u00e1 ser alterada.\n\n        Os par\u00e2metros abaixo somente s\u00e3o necess\u00e1rios para a opera\u00e7\u00e3o de inser\u00e7\u00e3o:\n\n            - 'id_vlan': Identificador da VLAN para criar o IP do VIP.\n            - 'descricao_vlan': Descri\u00e7\u00e3o do IP do VIP.\n            - balanceadores: Lista com os identificadores dos balanceadores que ser\u00e3o associados ao IP do VIP.\n\n        :param id: Identificador do VIP utilizado pelo sistema de orquestra\u00e7\u00e3o.\n        :param real_name_sufixo: Sufixo utilizado para criar os reals_names dos equipamentos na requisi\u00e7\u00e3o de VIP.\n        :param id_vlan: Identificador da VLAN para criar um IP para o VIP.\n        :param descricao_vlan: Descri\u00e7\u00e3o do IP que ser\u00e1 criado para o VIP.\n        :param id_vlan_real: Identificador da VLAN para criar os IPs dos equipamentos no VIP.\n        :param descricao_vlan_real: Descri\u00e7\u00e3o dos IPs que ser\u00e3o criados para os equipamentos no VIP.\n        :param balanceadores: Lista com os identificadores dos balanceadores que ser\u00e3o associados ao IP do VIP.\n        :param id_healthcheck_expect: Identificador do healthcheck_expect para criar a requisi\u00e7\u00e3o de VIP.\n        :param finalidade: Finalidade da requisi\u00e7\u00e3o de VIP.\n        :param cliente: Cliente da requisi\u00e7\u00e3o de VIP.\n        :param ambiente: Ambiente da requisi\u00e7\u00e3o de VIP.\n        :param cache: Cache da requisi\u00e7\u00e3o de VIP.\n        :param metodo_bal: M\u00e9todo de balanceamento da requisi\u00e7\u00e3o de VIP.\n        :param persistencia: Persist\u00eancia da requisi\u00e7\u00e3o de VIP.\n        :param healthcheck_type: Healthcheck_type da requisi\u00e7\u00e3o de VIP.\n        :param healthcheck: Healthcheck da requisi\u00e7\u00e3o de VIP.\n        :param timeout: Timeout da requisi\u00e7\u00e3o de VIP.\n        :param host: Host da requisi\u00e7\u00e3o de VIP.\n        :param maxcon: M\u00e1ximo n\u00famero de conex\u00e3o da requisi\u00e7\u00e3o de VIP.\n        :param dsr: DSR da requisi\u00e7\u00e3o de VIP.\n        :param bal_ativo: Balanceador ativo da requisi\u00e7\u00e3o de VIP.\n        :param transbordos: Lista com os IPs dos transbordos da requisi\u00e7\u00e3o de VIP.\n        :param portas: Lista com as portas da requisi\u00e7\u00e3o de VIP.\n        :param real_maps: Lista dos mapas com os dados dos reals da requisi\u00e7\u00e3o de VIP.\n            Cada mapa dever\u00e1 ter a estrutura: {'real_name':< real_name>, 'real_ip':< real_ip>}\n        :param id_requisicao_vip: Identificador da requisi\u00e7\u00e3o de VIP para opera\u00e7\u00e3o de alterar um\n            grupo virtual.\n        :param areanegocio: \u00c1rea de neg\u00f3cio para a requisi\u00e7\u00e3o de VIP (\u00e9 utilizado 'Orquestra' caso seja None).\n        :param nome_servico: Nome do servi\u00e7o para a requisi\u00e7\u00e3o de VIP (\u00e9 utilizado 'Orquestra' caso seja None).\n        :param l7_filter: Filtro L7 para a requisi\u00e7\u00e3o de VIP.\n        :param reals_prioritys: Lista dos dados de prioridade dos reals da requisi\u00e7\u00e3o de VIP (lista de zeros, caso seja None).\n        :param reals_weights: Lista dos dados de pesos dos reals da requisi\u00e7\u00e3o de VIP (lista de zeros, caso seja None).\n\n        :return: None\n        \"\"\"\n        vip_map = dict()\n\n        vip_map['id'] = id\n        # Causa erro na hora de validar os nomes de equipamentos (real servers)\n        #vip_map['real_name_sufixo'] = real_name_sufixo\n        vip_map['ip_real'] = {\n            'id_vlan': id_vlan_real,\n            'descricao': descricao_vlan_real}\n        vip_map['ip'] = {'id_vlan': id_vlan, 'descricao': descricao_vlan}\n        vip_map['balanceadores'] = {'id_equipamento': balanceadores}\n        vip_map['id_healthcheck_expect'] = id_healthcheck_expect\n        vip_map['finalidade'] = finalidade\n        vip_map['cliente'] = cliente\n        vip_map['ambiente'] = ambiente\n        vip_map['cache'] = cache\n        vip_map['metodo_bal'] = metodo_bal\n        vip_map['persistencia'] = persistencia\n        vip_map['healthcheck_type'] = healthcheck_type\n        vip_map['healthcheck'] = healthcheck\n        vip_map['timeout'] = timeout\n        vip_map['host'] = host\n        vip_map['maxcon'] = maxcon\n        vip_map['dsr'] = dsr\n        # Nao sao mais utilizados (bal_ativo e transbordos)\n        #vip_map['bal_ativo'] = bal_ativo\n        #vip_map['transbordos'] = {'transbordo': transbordos}\n        vip_map['portas_servicos'] = {'porta': portas}\n        vip_map['reals'] = {'real': real_maps}\n        vip_map['areanegocio'] = areanegocio\n        vip_map['nome_servico'] = nome_servico\n        vip_map['l7_filter'] = l7_filter\n\n        if reals_prioritys is not None:\n            vip_map['reals_prioritys'] = {'reals_priority': reals_prioritys}\n        else:\n            vip_map['reals_prioritys'] = None\n\n        if metodo_bal.upper() == 'WEIGHTED':\n            if reals_weights is not None:\n                vip_map['reals_weights'] = {'reals_weight': reals_weights}\n            else:\n                vip_map['reals_weights'] = None\n\n        if id_requisicao_vip is not None:\n            vip_map['requisicao_vip'] = {'id': id_requisicao_vip}\n\n        self.lista_vip.append(vip_map)", "response": "Adiciona um VIP para opera\u00e7\u00e3o de inserir um grupo virtual."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_access(self, id_access):\n\n        if not is_valid_int_param(id_access):\n            raise InvalidParameterError(u'Equipment Access ID is invalid.')\n\n        url = 'equipamentoacesso/id/' + str(id_access) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)", "response": "Get Equipment Access by id."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_by_equip(self, name):\n        equip_access_map = dict()\n        equip_access_map['name'] = name\n\n        code, xml = self.submit(\n            {\"equipamento_acesso\": equip_access_map}, 'POST', 'equipamentoacesso/name/')\n\n        key = 'equipamento_acesso'\n        return get_list_map(self.response(code, xml, [key]), key)", "response": "List all equipment access by equipment name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inserir(\n            self,\n            id_equipamento,\n            fqdn,\n            user,\n            password,\n            id_tipo_acesso,\n            enable_pass):\n        \"\"\"Add new relationship between equipment and access type and returns its id.\n\n        :param id_equipamento: Equipment identifier.\n        :param fqdn: Equipment FQDN.\n        :param user: User.\n        :param password: Password.\n        :param id_tipo_acesso: Access Type identifier.\n        :param enable_pass: Enable access.\n\n        :return: Dictionary with the following: {\u2018equipamento_acesso\u2019: {\u2018id\u2019: < id >}}\n\n        :raise EquipamentoNaoExisteError: Equipment doesn't exist.\n        :raise TipoAcessoNaoExisteError: Access Type doesn't exist.\n        :raise EquipamentoAcessoError:  Equipment and access type already associated.\n        :raise InvalidParameterError: The parameters equipment id, fqdn, user, password or\n            access type id are invalid or none.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        equipamento_acesso_map = dict()\n        equipamento_acesso_map['id_equipamento'] = id_equipamento\n        equipamento_acesso_map['fqdn'] = fqdn\n        equipamento_acesso_map['user'] = user\n        equipamento_acesso_map['pass'] = password\n        equipamento_acesso_map['id_tipo_acesso'] = id_tipo_acesso\n        equipamento_acesso_map['enable_pass'] = enable_pass\n\n        code, xml = self.submit(\n            {'equipamento_acesso': equipamento_acesso_map}, 'POST', 'equipamentoacesso/')\n\n        return self.response(code, xml)", "response": "Add new relationship between equipment and access type and returns its id."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef edit_by_id(\n            self,\n            id_equip_acesso,\n            id_tipo_acesso,\n            fqdn,\n            user,\n            password,\n            enable_pass):\n        \"\"\"Edit access type, fqdn, user, password and enable_pass of the relationship of\n        equipment and access type.\n\n        :param id_tipo_acesso: Access type identifier.\n        :param id_equip_acesso: Equipment identifier.\n        :param fqdn: Equipment FQDN.\n        :param user: User.\n        :param password: Password.\n        :param enable_pass: Enable access.\n\n        :return: None\n\n        :raise InvalidParameterError: The parameters fqdn, user, password or\n            access type id are invalid or none.\n        :raise EquipamentoAcessoNaoExisteError: Equipment access type relationship doesn't exist.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_tipo_acesso):\n            raise InvalidParameterError(\n                u'Access type id is invalid or not informed.')\n\n        equipamento_acesso_map = dict()\n        equipamento_acesso_map['fqdn'] = fqdn\n        equipamento_acesso_map['user'] = user\n        equipamento_acesso_map['pass'] = password\n        equipamento_acesso_map['enable_pass'] = enable_pass\n        equipamento_acesso_map['id_tipo_acesso'] = id_tipo_acesso\n        equipamento_acesso_map['id_equip_acesso'] = id_equip_acesso\n\n        url = 'equipamentoacesso/edit/'\n\n        code, xml = self.submit(\n            {'equipamento_acesso': equipamento_acesso_map}, 'POST', url)\n\n        return self.response(code, xml)", "response": "Edit access type by id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remover(self, id_tipo_acesso, id_equipamento):\n\n        if not is_valid_int_param(id_tipo_acesso):\n            raise InvalidParameterError(u'Access type id is invalid.')\n\n        if not is_valid_int_param(id_equipamento):\n            raise InvalidParameterError(u'Equipment id is invalid.')\n\n        url = 'equipamentoacesso/' + \\\n            str(id_equipamento) + '/' + str(id_tipo_acesso) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Removes relationship between equipment and access type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nenable or disable pool member by list", "response": "def set_poolmember_state(self, id_pools, pools):\n        \"\"\"\n        Enable/Disable pool member by list\n        \"\"\"\n\n        data = dict()\n\n        uri = \"api/v3/pool/real/%s/member/status/\" % ';'.join(id_pools)\n\n        data[\"server_pools\"] = pools\n\n        return self.put(uri, data=data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the state of the pool members.", "response": "def get_poolmember_state(self, id_pools, checkstatus=0):\n        \"\"\"\n        Enable/Disable pool member by list\n        \"\"\"\n\n        uri = \"api/v3/pool/real/%s/member/status/?checkstatus=%s\" % (';'.join(id_pools), checkstatus)\n\n        return self.get(uri)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting all pools in the specified environment", "response": "def list_all(self, environment_id, pagination):\n        \"\"\"\n            List All Pools To Populate Datatable\n\n            :param pagination: Object Pagination\n\n            :return: Following dictionary:{\n                                            \"total\" : < total >,\n                                            \"pools\" :[{\n                                                \"id\": < id >\n                                                \"default_port\": < default_port >,\n                                                \"identifier\": < identifier >,\n                                                \"healthcheck\": < healthcheck >,\n                                            }, ... too ... ]}\n\n            :raise NetworkAPIException: Falha ao acessar fonte de dados\n        \"\"\"\n\n        uri = \"api/pools/\"\n\n        data = dict()\n\n        data[\"start_record\"] = pagination.start_record\n        data[\"end_record\"] = pagination.end_record\n        data[\"asorting_cols\"] = pagination.asorting_cols\n        data[\"searchable_columns\"] = pagination.searchable_columns\n        data[\"custom_search\"] = pagination.custom_search or None\n        data[\"environment_id\"] = environment_id or None\n\n        return self.post(uri, data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_all_by_reqvip(self, id_vip, pagination):\n\n        uri = \"api/pools/pool_list_by_reqvip/\"\n\n        data = dict()\n\n        data[\"start_record\"] = pagination.start_record\n        data[\"end_record\"] = pagination.end_record\n        data[\"asorting_cols\"] = pagination.asorting_cols\n        data[\"searchable_columns\"] = pagination.searchable_columns\n        data[\"custom_search\"] = pagination.custom_search or None\n        data[\"id_vip\"] = id_vip or None\n\n        return self.post(uri, data=data)", "response": "This method returns a list of all pools in the system that are in the specified VIP."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves Pools Running Script And Update to Not Created :param ids: List of ids :return: None on success :raise ScriptRemovePoolException :raise InvalidIdPoolException :raise NetworkAPIException", "response": "def remove(self, pools):\n        \"\"\"\n            Remove Pools Running Script And Update to Not Created\n\n            :param ids: List of ids\n\n            :return: None on success\n\n            :raise ScriptRemovePoolException\n            :raise InvalidIdPoolException\n            :raise NetworkAPIException\n        \"\"\"\n\n        data = dict()\n        data[\"pools\"] = pools\n\n        uri = \"api/pools/v2/\"\n\n        return self.delete(uri, data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate Pools Running Script And Update to Created :param pools: List of pools :return: None on success :raise PoolDoesNotExistException :raise ScriptCreatePoolException :raise InvalidIdPoolException :raise NetworkAPIException", "response": "def create(self, pools):\n        \"\"\"\n            Create Pools Running Script And Update to Created\n\n            :param pools: List of pools\n\n            :return: None on success\n\n            :raise PoolDoesNotExistException\n            :raise ScriptCreatePoolException\n            :raise InvalidIdPoolException\n            :raise NetworkAPIException\n        \"\"\"\n\n        data = dict()\n        data[\"pools\"] = pools\n\n        uri = \"api/pools/v2/\"\n\n        return self.put(uri, data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef enable(self, ids):\n\n        data = dict()\n        data[\"ids\"] = ids\n\n        uri = \"api/pools/enable/\"\n\n        return self.post(uri, data)", "response": "Enable the specified pool members running script."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef disable(self, ids):\n\n        data = dict()\n        data[\"ids\"] = ids\n\n        uri = \"api/pools/disable/\"\n\n        return self.post(uri, data)", "response": "Disable the specified pool members running script."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef listar_por_grupo_usuario(self, id_grupo_usuario):\n        if not is_valid_int_param(id_grupo_usuario):\n            raise InvalidParameterError(\n                u'O identificador do grupo de usu\u00e1rio \u00e9 inv\u00e1lido ou n\u00e3o foi informado.')\n\n        url = 'direitosgrupoequipamento/ugrupo/' + str(id_grupo_usuario) + '/'\n\n        code, map = self.submit(None, 'GET', url)\n\n        key = 'direito_grupo_equipamento'\n        return get_list_map(self.response(code, map, [key]), key)", "response": "Lista todos os direitos de um grupo de usuario."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef buscar_por_id(self, id_direito):\n        if not is_valid_int_param(id_direito):\n            raise InvalidParameterError(\n                u'O identificador do direito grupo equipamento \u00e9 inv\u00e1lido ou n\u00e3o foi informado.')\n\n        url = 'direitosgrupoequipamento/' + str(id_direito) + '/'\n\n        code, map = self.submit(None, 'GET', url)\n\n        return self.response(code, map)", "response": "Buscar o id do direito grupo de usu\u00e1rio."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inserir(\n            self,\n            id_grupo_usuario,\n            id_grupo_equipamento,\n            leitura,\n            escrita,\n            alterar_config,\n            exclusao):\n        \"\"\"Cria um novo direito de um grupo de usu\u00e1rio em um grupo de equipamento e retorna o seu identificador.\n\n        :param id_grupo_usuario: Identificador do grupo de usu\u00e1rio.\n        :param id_grupo_equipamento: Identificador do grupo de equipamento.\n        :param leitura: Indica\u00e7\u00e3o de permiss\u00e3o de leitura ('0' ou '1').\n        :param escrita: Indica\u00e7\u00e3o de permiss\u00e3o de escrita ('0' ou '1').\n        :param alterar_config: Indica\u00e7\u00e3o de permiss\u00e3o de alterar_config ('0' ou '1').\n        :param exclusao: Indica\u00e7\u00e3o de permiss\u00e3o de exclus\u00e3o ('0' ou '1').\n\n        :return: Dicion\u00e1rio com a seguinte estrutura: {'direito_grupo_equipamento': {'id': < id>}}\n\n        :raise InvalidParameterError: Pelo menos um dos par\u00e2metros \u00e9 nulo ou inv\u00e1lido.\n        :raise GrupoEquipamentoNaoExisteError: Grupo de Equipamento n\u00e3o cadastrado.\n        :raise GrupoUsuarioNaoExisteError: Grupo de Usu\u00e1rio n\u00e3o cadastrado.\n        :raise ValorIndicacaoDireitoInvalidoError: Valor de leitura, escrita, alterar_config e/ou exclus\u00e3o inv\u00e1lido.\n        :raise DireitoGrupoEquipamentoDuplicadoError: J\u00e1 existe direitos cadastrados para o grupo de usu\u00e1rio e grupo\n            de equipamento informados.\n        :raise DataBaseError: Falha na networkapi ao acessar o banco de dados.\n        :raise XMLError: Falha na networkapi ao ler o XML de requisi\u00e7\u00e3o ou gerar o XML de resposta.\n        \"\"\"\n        direito_map = dict()\n        direito_map['id_grupo_usuario'] = id_grupo_usuario\n        direito_map['id_grupo_equipamento'] = id_grupo_equipamento\n        direito_map['leitura'] = leitura\n        direito_map['escrita'] = escrita\n        direito_map['alterar_config'] = alterar_config\n        direito_map['exclusao'] = exclusao\n\n        code, xml = self.submit(\n            {'direito_grupo_equipamento': direito_map}, 'POST', 'direitosgrupoequipamento/')\n\n        return self.response(code, xml)", "response": "Insere um novo direito de um grupo de usu\u00e1rio em um grupo de equipamento."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nalters os direitos de um grupo de equipamento.", "response": "def alterar(self, id_direito, leitura, escrita, alterar_config, exclusao):\n        \"\"\"Altera os direitos de um grupo de usu\u00e1rio em um grupo de equipamento a partir do seu identificador.\n\n        :param id_direito: Identificador do direito grupo equipamento.\n        :param leitura: Indica\u00e7\u00e3o de permiss\u00e3o de leitura ('0' ou '1').\n        :param escrita: Indica\u00e7\u00e3o de permiss\u00e3o de escrita ('0' ou '1').\n        :param alterar_config: Indica\u00e7\u00e3o de permiss\u00e3o de alterar_config ('0' ou '1').\n        :param exclusao: Indica\u00e7\u00e3o de permiss\u00e3o de exclus\u00e3o ('0' ou '1').\n\n        :return: None\n\n        :raise InvalidParameterError: Pelo menos um dos par\u00e2metros \u00e9 nulo ou inv\u00e1lido.\n        :raise ValorIndicacaoDireitoInvalidoError: Valor de leitura, escrita, alterar_config e/ou exclus\u00e3o inv\u00e1lido.\n        :raise DireitoGrupoEquipamentoNaoExisteError: Direito Grupo Equipamento n\u00e3o cadastrado.\n        :raise DataBaseError: Falha na networkapi ao acessar o banco de dados.\n        :raise XMLError: Falha na networkapi ao ler o XML de requisi\u00e7\u00e3o ou gerar o XML de resposta.\n        \"\"\"\n        if not is_valid_int_param(id_direito):\n            raise InvalidParameterError(\n                u'O identificador do direito grupo equipamento \u00e9 inv\u00e1lido ou n\u00e3o foi informado.')\n\n        url = 'direitosgrupoequipamento/' + str(id_direito) + '/'\n\n        direito_map = dict()\n        direito_map['leitura'] = leitura\n        direito_map['escrita'] = escrita\n        direito_map['alterar_config'] = alterar_config\n        direito_map['exclusao'] = exclusao\n\n        code, xml = self.submit(\n            {'direito_grupo_equipamento': direito_map}, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove os direitos de um grupo de equipamento a partir do seu identificador.", "response": "def remover(self, id_direito):\n        \"\"\"Remove os direitos de um grupo de usu\u00e1rio em um grupo de equipamento a partir do seu identificador.\n\n        :param id_direito: Identificador do direito grupo equipamento\n\n        :return: None\n\n        :raise DireitoGrupoEquipamentoNaoExisteError: Direito Grupo Equipamento n\u00e3o cadastrado.\n        :raise InvalidParameterError: O identificador do direito grupo equipamento \u00e9 nulo ou inv\u00e1lido.\n        :raise DataBaseError: Falha na networkapi ao acessar o banco de dados.\n        :raise XMLError: Falha na networkapi ao gerar o XML de resposta.\n        \"\"\"\n        if not is_valid_int_param(id_direito):\n            raise InvalidParameterError(\n                u'O identificador do direito grupo equipamento \u00e9 inv\u00e1lido ou n\u00e3o foi informado.')\n\n        url = 'direitosgrupoequipamento/' + str(id_direito) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef search(self, **kwargs):\n\n        return super(ApiObjectGroupPermission, self).get(self.prepare_url('api/v3/object-group-perm/',\n                                                                          kwargs))", "response": "Method to search object group permissions based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(self, ogps):\n\n        data = {'ogps': ogps}\n        return super(ApiObjectGroupPermission, self).post('api/v3/object-group-perm/', data)", "response": "Method to create object group permissions"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninserting a new Related Equipment with Script and returns its identifier", "response": "def inserir(self, id_equipment, id_script):\n        \"\"\"Inserts a new Related Equipment with Script and returns its identifier\n\n        :param id_equipment: Identifier of the Equipment. Integer value and greater than zero.\n        :param id_script: Identifier of the Script. Integer value and greater than zero.\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n          {'equipamento_roteiro': {'id': < id_equipment_script >}}\n\n        :raise InvalidParameterError: The identifier of Equipment or Script is null and invalid.\n        :raise RoteiroNaoExisteError: Script not registered.\n        :raise EquipamentoNaoExisteError: Equipment not registered.\n        :raise EquipamentoRoteiroError: Equipment is already associated with the script.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response\n        \"\"\"\n        equipment_script_map = dict()\n        equipment_script_map['id_equipment'] = id_equipment\n        equipment_script_map['id_script'] = id_script\n\n        code, xml = self.submit(\n            {'equipment_script': equipment_script_map}, 'POST', 'equipmentscript/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search(self, **kwargs):\n\n        return super(ApiVrf, self).get(self.prepare_url('api/v3/vrf/',\n                                                        kwargs))", "response": "Method to search vrf s based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self, ids):\n        url = build_uri_with_ids('api/v3/vrf/%s/', ids)\n\n        return super(ApiVrf, self).delete(url)", "response": "Method to delete vrf s by their id s\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update(self, vrfs):\n\n        data = {'vrfs': vrfs}\n        vrfs_ids = [str(vrf.get('id')) for vrf in vrfs]\n\n        return super(ApiVrf, self).put('api/v3/vrf/%s/' %\n                                       ';'.join(vrfs_ids), data)", "response": "Method to update vrf s\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inserir(self, name):\n        equipment_type_map = dict()\n        equipment_type_map['name'] = name\n\n        url = 'equipmenttype/'\n\n        code, xml = self.submit(\n            {'equipment_type': equipment_type_map}, 'POST', url)\n\n        return self.response(code, xml)", "response": "Inserts a new Equipment Type and returns its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inserir(self, id_equipment, id_environment, is_router=0):\n        equipment_environment_map = dict()\n        equipment_environment_map['id_equipamento'] = id_equipment\n        equipment_environment_map['id_ambiente'] = id_environment\n        equipment_environment_map['is_router'] = is_router\n\n        code, xml = self.submit(\n            {'equipamento_ambiente': equipment_environment_map}, 'POST', 'equipamentoambiente/')\n\n        return self.response(code, xml)", "response": "Inserts a new Related Equipment with Environment and returns its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remover(self, id_equipment, id_environment):\n\n        if not is_valid_int_param(id_equipment):\n            raise InvalidParameterError(\n                u'The identifier of Equipment is invalid or was not informed.')\n\n        if not is_valid_int_param(id_environment):\n            raise InvalidParameterError(\n                u'The identifier of Environment is invalid or was not informed.')\n\n        url = 'equipment/' + \\\n            str(id_equipment) + '/environment/' + str(id_environment) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Remove Related Equipment with Environment from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, id_equipment, id_environment, is_router):\n\n        if not is_valid_int_param(id_equipment):\n            raise InvalidParameterError(\n                u'The identifier of Equipment is invalid or was not informed.')\n\n        if not is_valid_int_param(id_environment):\n            raise InvalidParameterError(\n                u'The identifier of Environment is invalid or was not informed.')\n\n        equipment_environment_map = dict()\n        equipment_environment_map['id_equipamento'] = id_equipment\n        equipment_environment_map['id_ambiente'] = id_environment\n        equipment_environment_map['is_router'] = is_router\n\n        code, xml = self.submit(\n            {'equipamento_ambiente': equipment_environment_map}, 'PUT', 'equipamentoambiente/update/')\n\n        return self.response(code, xml)", "response": "Update related Equipment with Environment from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove a connection between two interfaces", "response": "def remove_connection(self, interface1, interface2):\n        \"\"\"Remove a connection between two interfaces\"\"\"\n\n        uri = \"api/interface/disconnect/%s/%s/\" % (interface1, interface2)\n\n        return self.delete(uri)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search(self, **kwargs):\n\n        return super(ApiInterfaceRequest, self).get(self.prepare_url('api/v3/interface/', kwargs))", "response": "Method to search interfaces based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef associate_interface_environments(self, int_env_map):\n\n        data = {'interface_environments': int_env_map}\n        return super(ApiInterfaceRequest, self).post('api/v3/interface/environments/', data)", "response": "Method to associate interfaces and environments with an interface."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connecting_interfaces(self, interfaces):\n\n        data = {'interfaces': interfaces}\n\n        url = 'api/v3/connections/' + str(interfaces[0].get('id')) + '/' + str(interfaces[1].get('id')) + '/'\n\n        return super(ApiInterfaceRequest, self).post(url, data)", "response": "Method to connecting interfaces."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_channel(self, channel):\n\n        data = {'channels': channel}\n        return super(ApiInterfaceRequest, self).post('api/v3/channel/', data)", "response": "Method to create a channel on database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inserir(self, name):\n\n        group_l3_map = dict()\n        group_l3_map['name'] = name\n\n        code, xml = self.submit({'group_l3': group_l3_map}, 'POST', 'groupl3/')\n\n        return self.response(code, xml)", "response": "Inserts a new Group L3 and returns its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchanges Group L3 from by the identifier.", "response": "def alterar(self, id_groupl3, name):\n        \"\"\"Change Group L3 from by the identifier.\n\n        :param id_groupl3: Identifier of the Group L3. Integer value and greater than zero.\n        :param name: Group L3 name. String with a minimum 2 and maximum of 80 characters\n\n        :return: None\n\n        :raise InvalidParameterError: The identifier of Group L3 or name is null and invalid.\n        :raise NomeGrupoL3DuplicadoError: There is already a registered Group L3 with the value of name.\n        :raise GrupoL3NaoExisteError: Group L3 not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_groupl3):\n            raise InvalidParameterError(\n                u'The identifier of Group L3 is invalid or was not informed.')\n\n        url = 'groupl3/' + str(id_groupl3) + '/'\n\n        group_l3_map = dict()\n        group_l3_map['name'] = name\n\n        code, xml = self.submit({'groupl3': group_l3_map}, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remover(self, id_groupl3):\n\n        if not is_valid_int_param(id_groupl3):\n            raise InvalidParameterError(\n                u'The identifier of Group L3 is invalid or was not informed.')\n\n        url = 'groupl3/' + str(id_groupl3) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Remove Group L3 from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, url, auth_map=None):\n        try:\n            LOG.debug('GET %s', url)\n            request = Request(url)\n            if auth_map is not None:\n                for key in auth_map.iterkeys():\n                    request.add_header(key, auth_map[key])\n                # request.add_header('NETWORKAPI_PASSWORD', auth_map['NETWORKAPI_PASSWORD'])\n                # request.add_header('NETWORKAPI_USERNAME', auth_map['NETWORKAPI_USERNAME'])\n            content = urlopen(request).read()\n            response_code = 200\n            LOG.debug('GET %s returns %s\\n%s', url, response_code, content)\n            return response_code, content\n        except HTTPError as e:\n            response_code = e.code\n            content = ''\n            if int(e.code) == 500:\n                content = e.read()\n            LOG.debug('GET %s returns %s\\n%s', url, response_code, content)\n            return response_code, content\n        except URLError as e:\n            raise ConnectionError(e)\n        except Exception as e:\n            raise RestError(e, e.message)", "response": "A function to get a specific entry in a URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef post_map(self, url, map, auth_map=None):\n        xml = dumps_networkapi(map)\n        response_code, content = self.post(url, xml, 'text/plain', auth_map)\n        return response_code, content", "response": "Gera um XML a partir dos dados do dicion\u00e1rio para autentica\u00e7\u00f5es para autentica\u00e7\u00e3o."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef put_map(self, url, map, auth_map=None):\n        xml = dumps_networkapi(map)\n        response_code, content = self.put(url, xml, 'text/plain', auth_map)\n        return response_code, content", "response": "Enviar um XML a partir dos dados do dicion\u00e1rio."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_map(self, url, auth_map=None):\n        response_code, content = self.get(url, auth_map)\n        return response_code, content", "response": "Envia uma requisi\u00e7\u00e3o HTTP."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_full_url(self, parsed_url):\n        full_path = parsed_url.path\n        if parsed_url.query:\n            full_path = '%s?%s' % (full_path, parsed_url.query)\n        return full_path", "response": "Returns full url path with querystring"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsubmitting a map to the network API.", "response": "def submit(self, map):\n        '''Envia a requisi\u00e7\u00e3o HTTP de acordo com os par\u00e2metros informados no construtor.\n\n        :param map: Dicion\u00e1rio com os dados do corpo da requisi\u00e7\u00e3o.\n\n        :return: Retorna uma tupla contendo:\n            (< c\u00f3digo de resposta http >, < corpo da resposta >).\n\n        :raise ConnectionError: Falha na conex\u00e3o com a networkAPI.\n        :raise RestError: Falha no acesso \u00e0 networkAPI.\n        '''\n        # print \"Requi\u00e7\u00e3o em %s %s com corpo: %s\" % (self.method, self.url,\n        # map)\n        rest = Rest()\n        if self.method == 'POST':\n            code, response = rest.post_map(self.url, map, self.auth_map)\n        elif self.method == 'PUT':\n            code, response = rest.put_map(self.url, map, self.auth_map)\n        elif self.method == 'GET':\n            code, response = rest.get_map(self.url, self.auth_map)\n        elif self.method == 'DELETE':\n            code, response = rest.delete_map(self.url, map, self.auth_map)\n\n        return code, response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search(self, **kwargs):\n\n        return super(ApiV4VirtualInterface, self).get(self.prepare_url(\n            'api/v4/virtual-interface/', kwargs))", "response": "Method to search Virtual Interfaces based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, virtual_interfaces):\n\n        data = {'virtual_interfaces': virtual_interfaces}\n        virtual_interfaces_ids = [str(env.get('id')) for env in virtual_interfaces]\n\n        return super(ApiV4VirtualInterface, self).put\\\n            ('api/v4/virtual-interface/%s/' % ';'.join(virtual_interfaces_ids), data)", "response": "Method to update Virtual Interfaces"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch Group User by its identifier.", "response": "def search(self, id_ugroup):\n        \"\"\"Search Group User by its identifier.\n\n        :param id_ugroup: Identifier of the Group User. Integer value and greater than zero.\n\n        :return: Following dictionary:\n\n        ::\n\n            {\u2018user_group\u2019: {'escrita': < escrita >,\n            'nome': < nome >,\n            'exclusao': < exclusao >,\n            'edicao': < edicao >,\n            'id': < id >,\n            'leitura': < leitura >}}\n\n        :raise InvalidParameterError: Group User identifier is none or invalid.\n        :raise GrupoUsuarioNaoExisteError: Group User not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_ugroup):\n            raise InvalidParameterError(\n                u'The identifier of Group User is invalid or was not informed.')\n\n        url = 'ugroup/get/' + str(id_ugroup) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef inserir(self, name, read, write, edit, remove):\n        ugroup_map = dict()\n        ugroup_map['nome'] = name\n        ugroup_map['leitura'] = read\n        ugroup_map['escrita'] = write\n        ugroup_map['edicao'] = edit\n        ugroup_map['exclusao'] = remove\n\n        code, xml = self.submit({'user_group': ugroup_map}, 'POST', 'ugroup/')\n\n        return self.response(code, xml)", "response": "Insert a new user group and returns its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nediting user group data from its identifier.", "response": "def alterar(self, id_user_group, name, read, write, edit, remove):\n        \"\"\"Edit user group data from its identifier.\n\n        :param id_user_group: User group id.\n        :param name: User group name.\n        :param read: If user group has read permission ('S' ou 'N').\n        :param write: If user group has write permission ('S' ou 'N').\n        :param edit: If user group has edit permission ('S' ou 'N').\n        :param remove: If user group has remove permission ('S' ou 'N').\n\n        :return: None\n\n        :raise NomeGrupoUsuarioDuplicadoError: User group name already exists.\n        :raise ValorIndicacaoPermissaoInvalidoError: Read, write, edit or remove value is invalid.\n        :raise GrupoUsuarioNaoExisteError: User Group not found.\n        :raise InvalidParameterError: At least one of the parameters is invalid or none.\n        :raise DataBaseError: Networkapi failed to access database.\n        :raise XMLError: Networkapi fails generating response XML.\n        \"\"\"\n        if not is_valid_int_param(id_user_group):\n            raise InvalidParameterError(\n                u'Invalid or inexistent user group id.')\n\n        url = 'ugroup/' + str(id_user_group) + '/'\n\n        ugroup_map = dict()\n        ugroup_map['nome'] = name\n        ugroup_map['leitura'] = read\n        ugroup_map['escrita'] = write\n        ugroup_map['edicao'] = edit\n        ugroup_map['exclusao'] = remove\n\n        code, xml = self.submit({'user_group': ugroup_map}, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving a user group by its identifier.", "response": "def remover(self, id_user_group):\n        \"\"\"Removes a user group by its id.\n\n        :param id_user_group: User Group's identifier. Valid integer greater than zero.\n\n        :return: None\n\n        :raise GrupoUsuarioNaoExisteError: User Group not found.\n        :raise InvalidParameterError: User Group id is invalid or none.\n        :raise DataBaseError: Networkapi failed to access database.\n        :raise XMLError: Networkapi fails generating response XML.\n        \"\"\"\n        if not is_valid_int_param(id_user_group):\n            raise InvalidParameterError(\n                u'Invalid or inexistent user group id.')\n\n        url = 'ugroup/' + str(id_user_group) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_environment(self, environment_ids):\n\n        uri = 'api/v3/environment/%s/' % environment_ids\n\n        return super(ApiEnvironment, self).get(uri)", "response": "Method to get environment"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_environment(self, environment):\n\n        uri = 'api/v3/environment/'\n\n        data = dict()\n        data['environments'] = list()\n        data['environments'].append(environment)\n\n        return super(ApiEnvironment, self).post(uri, data)", "response": "Method to create environment"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search(self, **kwargs):\n\n        return super(ApiEnvironment, self).get(self.prepare_url('api/v3/environment/',\n                                                                kwargs))", "response": "Method to search environments based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, ids):\n        url = build_uri_with_ids('api/v3/environment/%s/', ids)\n        return super(ApiEnvironment, self).delete(url)", "response": "Method to delete environments by their id s\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, environments):\n\n        data = {'environments': environments}\n        environments_ids = [str(env.get('id')) for env in environments]\n\n        return super(ApiEnvironment, self).put('api/v3/environment/%s/' %\n                                               ';'.join(environments_ids), data)", "response": "Method to update environments\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(self, environments):\n\n        data = {'environments': environments}\n        return super(ApiEnvironment, self).post('api/v3/environment/', data)", "response": "Method to create environments\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, ids):\n        url = build_uri_with_ids('api/v4/as/%s/', ids)\n        return super(ApiV4As, self).delete(url)", "response": "Method to delete asns by their id s\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, asns):\n\n        data = {'asns': asns}\n        asns_ids = [str(env.get('id')) for env in asns]\n\n        return super(ApiV4As, self).put('api/v4/as/%s/' %\n                                               ';'.join(asns_ids), data)", "response": "Method to update asns"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(self, asns):\n\n        data = {'asns': asns}\n        return super(ApiV4As, self).post('api/v4/as/', data)", "response": "Method to create asns\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch all logs in the database.", "response": "def find_logs(\n            self,\n            user_name,\n            first_date,\n            start_time,\n            last_date,\n            end_time,\n            action,\n            functionality,\n            parameter,\n            pagination):\n        \"\"\"\n        Search all logs, filtering by the given parameters.\n        :param user_name: Filter by user_name\n        :param first_date: Sets initial date for begin of the filter\n        :param start_time: Sets initial time\n        :param last_date: Sets final date\n        :param end_time: Sets final time and ends the filter. That defines the searching gap\n        :param action: Filter by action (Create, Update or Delete)\n        :param functionality: Filter by class\n        :param parameter: Filter by parameter\n        :param pagination: Class with all data needed to paginate\n\n        :return: Following dictionary:\n\n        ::\n\n            {'eventlog': {'id_usuario' : < id_user >,\n            'hora_evento': < hora_evento >,\n            'acao': < acao >,\n            'funcionalidade': < funcionalidade >,\n            'parametro_anterior': < parametro_anterior >,\n            'parametro_atual': < parametro_atual > }\n            'total' : {< total_registros >} }\n\n        :raise InvalidParameterError: Some parameter was invalid.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not isinstance(pagination, Pagination):\n            raise InvalidParameterError(\n                u\"Invalid parameter: pagination must be a class of type 'Pagination'.\")\n\n        eventlog_map = dict()\n\n        eventlog_map[\"start_record\"] = pagination.start_record\n        eventlog_map[\"end_record\"] = pagination.end_record\n        eventlog_map[\"asorting_cols\"] = pagination.asorting_cols\n        eventlog_map[\"searchable_columns\"] = pagination.searchable_columns\n        eventlog_map[\"custom_search\"] = pagination.custom_search\n\n        eventlog_map[\"usuario\"] = user_name\n        eventlog_map[\"data_inicial\"] = first_date\n        eventlog_map[\"hora_inicial\"] = start_time\n        eventlog_map[\"data_final\"] = last_date\n        eventlog_map[\"hora_final\"] = end_time\n        eventlog_map[\"acao\"] = action\n        eventlog_map[\"funcionalidade\"] = functionality\n        eventlog_map[\"parametro\"] = parameter\n\n        url = \"eventlog/find/\"\n\n        code, xml = self.submit({'eventlog': eventlog_map}, 'POST', url)\n\n        key = \"eventlog\"\n        return get_list_map(self.response(code, xml, key), key)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search(self, **kwargs):\n\n        return super(ApiV4Equipment, self).get(self.prepare_url(\n            'api/v4/equipment/', kwargs))", "response": "Method to search equipments based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, ids):\n        url = build_uri_with_ids('api/v4/equipment/%s/', ids)\n        return super(ApiV4Equipment, self).delete(url)", "response": "Method to delete equipments by their id s\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(self, equipments):\n\n        data = {'equipments': equipments}\n        return super(ApiV4Equipment, self).post('api/v4/equipment/', data)", "response": "Method to create a list of unique equipment entries"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsubmits a map to a c\u00f3digo.", "response": "def submit(self, map, method, postfix):\n        '''Realiza um requisi\u00e7\u00e3o HTTP para a networkAPI.\n\n        :param map: Dicion\u00e1rio com os dados para gerar o XML enviado no corpo da requisi\u00e7\u00e3o HTTP.\n        :param method: M\u00e9todo da requisi\u00e7\u00e3o HTTP ('GET', 'POST', 'PUT' ou 'DELETE').\n        :param postfix: Posfixo a ser colocado na URL b\u00e1sica de acesso \u00e0 networkAPI. Ex: /ambiente\n\n        :return: Tupla com o c\u00f3digo e o corpo da resposta HTTP:\n            (< codigo>, < descricao>)\n\n        :raise NetworkAPIClientError: Erro durante a chamada HTTP para acesso \u00e0 networkAPI.\n        '''\n        try:\n            rest_request = RestRequest(\n                self.get_url(postfix),\n                method,\n                self.user,\n                self.password,\n                self.user_ldap)\n            return rest_request.submit(map)\n        except RestError as e:\n            raise ErrorHandler.handle(None, str(e))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_error(self, xml):\n        '''Obtem do XML de resposta, o c\u00f3digo e a descri\u00e7\u00e3o do erro.\n\n        O XML corresponde ao corpo da resposta HTTP de c\u00f3digo 500.\n\n        :param xml: XML contido na resposta da requisi\u00e7\u00e3o HTTP.\n\n        :return: Tupla com o c\u00f3digo e a descri\u00e7\u00e3o do erro contido no XML:\n            (< codigo_erro>, < descricao_erro>)\n        '''\n        map = loads(xml)\n        network_map = map['networkapi']\n        error_map = network_map['erro']\n        return int(error_map['codigo']), str(error_map['descricao'])", "response": "Obtem do XML de resposta o c\u00f3digo e a descri\u00e7\u00e3o do erro."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef response(self, code, xml, force_list=None):\n        if int(code) == 200:\n            # Retorna o map\n            return loads(xml, force_list)['networkapi']\n        elif int(code) == 500:\n            code, description = self.get_error(xml)\n            return ErrorHandler.handle(code, description)\n        else:\n            return ErrorHandler.handle(code, xml)", "response": "Retorna um objeto NetworkAPIError."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inserir(self, id_script_type, script, model, description):\n        script_map = dict()\n        script_map['id_script_type'] = id_script_type\n        script_map['script'] = script\n        script_map['model'] = model\n        script_map['description'] = description\n\n        code, xml = self.submit({'script': script_map}, 'POST', 'script/')\n\n        return self.response(code, xml)", "response": "Inserts a new Script and returns its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchanging the script from by the identifier.", "response": "def alterar(self, id_script, id_script_type, script, description, model=None):\n        \"\"\"Change Script from by the identifier.\n\n        :param id_script: Identifier of the Script. Integer value and greater than zero.\n        :param id_script_type: Identifier of the Script Type. Integer value and greater than zero.\n        :param script: Script name. String with a minimum 3 and maximum of 40 characters\n        :param description: Script description. String with a minimum 3 and maximum of 100 characters\n\n        :return: None\n\n        :raise InvalidParameterError: The identifier of Script, script Type, script or description is null and invalid.\n        :raise RoteiroNaoExisteError: Script not registered.\n        :raise TipoRoteiroNaoExisteError: Script Type not registered.\n        :raise NomeRoteiroDuplicadoError: Script already registered with informed.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        if not is_valid_int_param(id_script):\n            raise InvalidParameterError(u'The identifier of Script is invalid or was not informed.')\n\n        script_map = dict()\n        script_map['id_script_type'] = id_script_type\n        script_map['script'] = script\n        script_map['model'] = model\n        script_map['description'] = description\n\n        url = 'script/edit/' + str(id_script) + '/'\n\n        code, xml = self.submit({'script': script_map}, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remover(self, id_script):\n        if not is_valid_int_param(id_script):\n            raise InvalidParameterError(\n                u'The identifier of Script is invalid or was not informed.')\n\n        url = 'script/' + str(id_script) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Remove a specific script from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist all Script by Script Type.", "response": "def listar_por_tipo(self, id_script_type):\n        \"\"\"List all Script by Script Type.\n\n        :param id_script_type: Identifier of the Script Type. Integer value and greater than zero.\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {\u2018script\u2019: [{\u2018id\u2019: < id >,\n            \u2018tipo_roteiro': < id_tipo_roteiro >,\n            \u2018nome': < nome >,\n            \u2018descricao\u2019: < descricao >}, ...more Script...]}\n\n        :raise InvalidParameterError: The identifier of Script Type is null and invalid.\n        :raise TipoRoteiroNaoExisteError: Script Type not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        if not is_valid_int_param(id_script_type):\n            raise InvalidParameterError(\n                u'The identifier of Script Type is invalid or was not informed.')\n\n        url = 'script/scripttype/' + str(id_script_type) + '/'\n\n        code, map = self.submit(None, 'GET', url)\n\n        key = 'script'\n        return get_list_map(self.response(code, map, [key]), key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists all Script related Equipment.", "response": "def listar_por_equipamento(self, id_equipment):\n        \"\"\"List all Script related Equipment.\n\n        :param id_equipment: Identifier of the Equipment. Integer value and greater than zero.\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {script': [{\u2018id\u2019: < id >,\n            \u2018nome\u2019: < nome >,\n            \u2018descricao\u2019: < descricao >,\n            \u2018id_tipo_roteiro\u2019: < id_tipo_roteiro >,\n            \u2018nome_tipo_roteiro\u2019: < nome_tipo_roteiro >,\n            \u2018descricao_tipo_roteiro\u2019: < descricao_tipo_roteiro >}, ...more Script...]}\n\n        :raise InvalidParameterError: The identifier of Equipment is null and invalid.\n        :raise EquipamentoNaoExisteError: Equipment not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        if not is_valid_int_param(id_equipment):\n            raise InvalidParameterError(\n                u'The identifier of Equipment is invalid or was not informed.')\n\n        url = 'script/equipment/' + str(id_equipment) + '/'\n\n        code, map = self.submit(None, 'GET', url)\n\n        key = 'script'\n        return get_list_map(self.response(code, map, [key]), key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_rule_by_id(self, rule_id):\n\n        url = \"rule/get_by_id/\" + str(rule_id)\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml, ['rule_contents', 'rule_blocks'])", "response": "Get a specific rule by its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new network in the specified set of VLANs.", "response": "def create_networks(self, ids, id_vlan):\n        \"\"\"Set column 'active = 1' in tables redeipv4 and redeipv6]\n\n        :param ids: ID for NetworkIPv4 and/or NetworkIPv6\n\n        :return: Nothing\n        \"\"\"\n\n        network_map = dict()\n        network_map['ids'] = ids\n        network_map['id_vlan'] = id_vlan\n\n        code, xml = self.submit(\n            {'network': network_map}, 'PUT', 'network/create/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding new network :param network: IPV4 or IPV6 (ex.: \"10.0.0.3/24\") :param id_vlan: Identifier of the Vlan. Integer value and greater than zero. :param id_network_type: Identifier of the NetworkType. Integer value and greater than zero. :param id_environment_vip: Identifier of the Environment Vip. Integer value and greater than zero. :return: Following dictionary: :: {'network':{'id': <id_network>, 'rede': <network>, 'broadcast': <broadcast> (if is IPv4), 'mask': <net_mask>, 'id_vlan': <id_vlan>, 'id_tipo_rede': <id_network_type>, 'id_ambiente_vip': <id_ambiente_vip>, 'active': <active>} } :raise TipoRedeNaoExisteError: NetworkType not found. :raise InvalidParameterError: Invalid ID for Vlan or NetworkType. :raise EnvironmentVipNotFoundError: Environment VIP not registered. :raise IPNaoDisponivelError: Network address unavailable to create a NetworkIPv4. :raise NetworkIPRangeEnvError: Other environment already have this ip range. :raise DataBaseError: Networkapi failed to access the database. :raise XMLError: Networkapi failed to generate the XML response.", "response": "def add_network(self, network, id_vlan, id_network_type,\n                    id_environment_vip=None, cluster_unit=None):\n        \"\"\"\n        Add new network\n\n        :param network: IPV4 or IPV6 (ex.: \"10.0.0.3/24\")\n        :param id_vlan: Identifier of the Vlan. Integer value and greater than zero.\n        :param id_network_type: Identifier of the NetworkType. Integer value and greater than zero.\n        :param id_environment_vip: Identifier of the Environment Vip. Integer value and greater than zero.\n\n        :return: Following dictionary:\n\n        ::\n\n          {'network':{'id': <id_network>,\n          'rede': <network>,\n          'broadcast': <broadcast> (if is IPv4),\n          'mask': <net_mask>,\n          'id_vlan': <id_vlan>,\n          'id_tipo_rede': <id_network_type>,\n          'id_ambiente_vip': <id_ambiente_vip>,\n          'active': <active>} }\n\n        :raise TipoRedeNaoExisteError: NetworkType not found.\n        :raise InvalidParameterError: Invalid ID for Vlan or NetworkType.\n        :raise EnvironmentVipNotFoundError: Environment VIP not registered.\n        :raise IPNaoDisponivelError: Network address unavailable to create a NetworkIPv4.\n        :raise NetworkIPRangeEnvError: Other environment already have this ip range.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        network_map = dict()\n        network_map['network'] = network\n        network_map['id_vlan'] = id_vlan\n        network_map['id_network_type'] = id_network_type\n        network_map['id_environment_vip'] = id_environment_vip\n        network_map['cluster_unit'] = cluster_unit\n\n        code, xml = self.submit(\n            {'network': network_map}, 'POST', 'network/add/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nedits a network in the database.", "response": "def edit_network(self, id_network, ip_type, id_net_type, id_env_vip=None, cluster_unit=None):\n        \"\"\"\n        Edit a network 4 or 6\n\n        :param id_network: Identifier of the Network. Integer value and greater than zero.\n        :param id_net_type: Identifier of the NetworkType. Integer value and greater than zero.\n        :param id_env_vip: Identifier of the Environment Vip. Integer value and greater than zero.\n        :param ip_type: Identifier of the Network IP Type: 0 = IP4 Network; 1 = IP6 Network;\n\n        :return: None\n\n        :raise TipoRedeNaoExisteError: NetworkType not found.\n        :raise InvalidParameterError: Invalid ID for Vlan or NetworkType.\n        :raise EnvironmentVipNotFoundError: Environment VIP not registered.\n        :raise IPNaoDisponivelError: Network address unavailable to create a NetworkIPv4.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        net_map = dict()\n        net_map['id_network'] = id_network\n        net_map['ip_type'] = ip_type\n        net_map['id_net_type'] = id_net_type\n        net_map['id_env_vip'] = id_env_vip\n        net_map['cluster_unit'] = cluster_unit\n\n        code, xml = self.submit({'net': net_map}, 'POST', 'network/edit/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the NetworkIpv4 from Networkapi.", "response": "def get_network_ipv4(self, id_network):\n        \"\"\"\n        Get networkipv4\n\n        :param id_network: Identifier of the Network. Integer value and greater than zero.\n        :return: Following dictionary:\n\n        ::\n\n          {'network': {'id': < id_networkIpv6 >,\n          'network_type': < id_tipo_rede >,\n          'ambiente_vip': < id_ambiente_vip >,\n          'vlan': <id_vlan>\n          'oct1': < rede_oct1 >,\n          'oct2': < rede_oct2 >,\n          'oct3': < rede_oct3 >,\n          'oct4': < rede_oct4 >\n          'blocK': < bloco >,\n          'mask_oct1': < mascara_oct1 >,\n          'mask_oct2': < mascara_oct2 >,\n          'mask_oct3': < mascara_oct3 >,\n          'mask_oct4': < mascara_oct4 >,\n          'active': < ativada >,\n          'broadcast':<'broadcast>, }}\n\n        :raise NetworkIPv4NotFoundError: NetworkIPV4 not found.\n        :raise InvalidValueError: Invalid ID for NetworkIpv4\n        :raise NetworkIPv4Error: Error in NetworkIpv4\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_network):\n            raise InvalidParameterError(\n                u'O id do rede ip4 foi informado incorretamente.')\n\n        url = 'network/ipv4/id/' + str(id_network) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_network_ipv6(self, id_network):\n\n        if not is_valid_int_param(id_network):\n            raise InvalidParameterError(\n                u'O id do rede ip6 foi informado incorretamente.')\n\n        url = 'network/ipv6/id/' + str(id_network) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)", "response": "Get the network ipv6."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deallocate_network_ipv4(self, id_network_ipv4):\n\n        if not is_valid_int_param(id_network_ipv4):\n            raise InvalidParameterError(\n                u'The identifier of NetworkIPv4 is invalid or was not informed.')\n\n        url = 'network/ipv4/' + str(id_network_ipv4) + '/deallocate/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Deallocate all relationships between NetworkIPv4."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a networkipv6 to the configuration file.", "response": "def add_network_ipv6(\n            self,\n            id_vlan,\n            id_tipo_rede,\n            id_ambiente_vip=None,\n            prefix=None):\n        \"\"\"\n        Add new networkipv6\n\n        :param id_vlan: Identifier of the Vlan. Integer value and greater than zero.\n        :param id_tipo_rede: Identifier of the NetworkType. Integer value and greater than zero.\n        :param id_ambiente_vip: Identifier of the Environment Vip. Integer value and greater than zero.\n        :param prefix: Prefix.\n\n        :return: Following dictionary:\n\n        ::\n\n          {'vlan': {'id': < id_vlan >,\n          'nome': < nome_vlan >,\n          'num_vlan': < num_vlan >,\n          'id_tipo_rede': < id_tipo_rede >,\n          'id_ambiente': < id_ambiente >,\n          'rede_oct1': < rede_oct1 >,\n          'rede_oct2': < rede_oct2 >,\n          'rede_oct3': < rede_oct3 >,\n          'rede_oct4': < rede_oct4 >,\n          'rede_oct5': < rede_oct4 >,\n          'rede_oct6': < rede_oct4 >,\n          'rede_oct7': < rede_oct4 >,\n          'rede_oct8': < rede_oct4 >,\n          'bloco': < bloco >,\n          'mascara_oct1': < mascara_oct1 >,\n          'mascara_oct2': < mascara_oct2 >,\n          'mascara_oct3': < mascara_oct3 >,\n          'mascara_oct4': < mascara_oct4 >,\n          'mascara_oct5': < mascara_oct4 >,\n          'mascara_oct6': < mascara_oct4 >,\n          'mascara_oct7': < mascara_oct4 >,\n          'mascara_oct8': < mascara_oct4 >,\n          'broadcast': < broadcast >,\n          'descricao': < descricao >,\n          'acl_file_name': < acl_file_name >,\n          'acl_valida': < acl_valida >,\n          'ativada': < ativada >}}\n\n        :raise TipoRedeNaoExisteError: NetworkType not found.\n        :raise InvalidParameterError: Invalid ID for Vlan or NetworkType.\n        :raise EnvironmentVipNotFoundError: Environment VIP not registered.\n        :raise IPNaoDisponivelError: Network address unavailable to create a NetworkIPv6.\n        :raise ConfigEnvironmentInvalidError: Invalid Environment Configuration or not registered\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        vlan_map = dict()\n        vlan_map['id_vlan'] = id_vlan\n        vlan_map['id_tipo_rede'] = id_tipo_rede\n        vlan_map['id_ambiente_vip'] = id_ambiente_vip\n        vlan_map['prefix'] = prefix\n\n        code, xml = self.submit(\n            {'vlan': vlan_map}, 'POST', 'network/ipv6/add/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_network_ipv6_hosts(\n            self,\n            id_vlan,\n            id_tipo_rede,\n            num_hosts,\n            id_ambiente_vip=None):\n        \"\"\"\n        Add new networkipv6\n\n        :param id_vlan: Identifier of the Vlan. Integer value and greater than zero.\n        :param id_tipo_rede: Identifier of the NetworkType. Integer value and greater than zero.\n        :param num_hosts: Number of hosts expected. Integer value and greater than zero.\n        :param id_ambiente_vip: Identifier of the Environment Vip. Integer value and greater than zero.\n\n        :return: Following dictionary:\n\n        ::\n\n          {'vlan': {'id': < id_vlan >,\n          'nome': < nome_vlan >,\n          'num_vlan': < num_vlan >,\n          'id_tipo_rede': < id_tipo_rede >,\n          'id_ambiente': < id_ambiente >,\n          'rede_oct1': < rede_oct1 >,\n          'rede_oct2': < rede_oct2 >,\n          'rede_oct3': < rede_oct3 >,\n          'rede_oct4': < rede_oct4 >,\n          'rede_oct5': < rede_oct4 >,\n          'rede_oct6': < rede_oct4 >,\n          'rede_oct7': < rede_oct4 >,\n          'rede_oct8': < rede_oct4 >,\n          'bloco': < bloco >,\n          'mascara_oct1': < mascara_oct1 >,\n          'mascara_oct2': < mascara_oct2 >,\n          'mascara_oct3': < mascara_oct3 >,\n          'mascara_oct4': < mascara_oct4 >,\n          'mascara_oct5': < mascara_oct4 >,\n          'mascara_oct6': < mascara_oct4 >,\n          'mascara_oct7': < mascara_oct4 >,\n          'mascara_oct8': < mascara_oct4 >,\n          'broadcast': < broadcast >,\n          'descricao': < descricao >,\n          'acl_file_name': < acl_file_name >,\n          'acl_valida': < acl_valida >,\n          'ativada': < ativada >}}\n\n        :raise TipoRedeNaoExisteError: NetworkType not found.\n        :raise InvalidParameterError: Invalid ID for Vlan or NetworkType.\n        :raise EnvironmentVipNotFoundError: Environment VIP not registered.\n        :raise IPNaoDisponivelError: Network address unavailable to create a NetworkIPv6.\n        :raise ConfigEnvironmentInvalidError: Invalid Environment Configuration or not registered\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        vlan_map = dict()\n        vlan_map['id_vlan'] = id_vlan\n        vlan_map['id_tipo_rede'] = id_tipo_rede\n        vlan_map['num_hosts'] = num_hosts\n        vlan_map['id_ambiente_vip'] = id_ambiente_vip\n\n        code, xml = self.submit({'vlan': vlan_map}, 'PUT', 'network/ipv6/add/')\n\n        return self.response(code, xml)", "response": "Adds new networkipv6 hosts to the current network."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deallocate_network_ipv6(self, id_network_ipv6):\n\n        if not is_valid_int_param(id_network_ipv6):\n            raise InvalidParameterError(\n                u'The identifier of NetworkIPv6 is invalid or was not informed.')\n\n        url = 'network/ipv6/' + str(id_network_ipv6) + '/deallocate/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Deallocate all relationships between NetworkIPv6 and return the corresponding object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves the networks with the given IDs.", "response": "def remove_networks(self, ids):\n        \"\"\"\n        Set column 'active = 0' in tables redeipv4 and redeipv6]\n\n        :param ids: ID for NetworkIPv4 and/or NetworkIPv6\n\n        :return: Nothing\n\n        :raise NetworkInactiveError: Unable to remove the network because it is inactive.\n        :raise InvalidParameterError: Invalid ID for Network or NetworkType.\n        :raise NetworkIPv4NotFoundError: NetworkIPv4 not found.\n        :raise NetworkIPv6NotFoundError: NetworkIPv6 not found.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        network_map = dict()\n        network_map['ids'] = ids\n\n        code, xml = self.submit(\n            {'network': network_map}, 'PUT', 'network/remove/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add(self, networkipv4_id, ipv4_id):\n\n        data = dict()\n\n        data['networkipv4'] = networkipv4_id\n        data['ipv4'] = dict()\n        data['ipv4']['id'] = ipv4_id\n        uri = 'api/dhcprelayv4/'\n        return self.post(uri, data=data)", "response": "List all DHCPRelayIPv4.\n\n        :param: networkipv4_id, ipv4_id\n\n        :return: Following dictionary:\n          {\n          \"networkipv4\": <networkipv4_id>,\n          \"id\": <id>,\n          \"ipv4\": {\n              \"oct4\": <oct4>,\n              \"oct2\": <oct2>,\n              \"oct3\": <oct3>,\n              \"oct1\": <oct1>,\n              \"ip_formated\": \"<string IPv4>\",\n              \"networkipv4\": <networkipv4_id>,\n              \"id\": <ipv4_id>,\n              \"descricao\": \"<string description>\"\n          }\n\n        :raise NetworkAPIException: Falha ao acessar fonte de dados"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists all DHCPRelayIPv4. :param: networkipv4: networkipv4 id - list all dhcprelay filtering by networkipv4 id ipv4: ipv4 id - list all dhcprelay filtering by ipv4 id :return: Following dictionary: [ { \"networkipv4\": <networkipv4_id>, \"id\": <id>, \"ipv4\": { \"oct4\": <oct4>, \"oct2\": <oct2>, \"oct3\": <oct3>, \"oct1\": <oct1>, \"ip_formated\": \"<string IPv4>\", \"networkipv4\": <networkipv4_id>, \"id\": <ipv4_id>, \"descricao\": \"<string description>\" }, {...} ] :raise NetworkAPIException: Falha ao acessar fonte de dados", "response": "def list(self, networkipv4=None, ipv4=None):\n        \"\"\"List all DHCPRelayIPv4.\n\n        :param: networkipv4: networkipv4 id - list all dhcprelay filtering by networkipv4 id\n          ipv4: ipv4 id - list all dhcprelay filtering by ipv4 id\n\n        :return: Following dictionary:\n          [\n            {\n            \"networkipv4\": <networkipv4_id>,\n            \"id\": <id>,\n            \"ipv4\": {\n                \"oct4\": <oct4>,\n                \"oct2\": <oct2>,\n                \"oct3\": <oct3>,\n                \"oct1\": <oct1>,\n                \"ip_formated\": \"<string IPv4>\",\n                \"networkipv4\": <networkipv4_id>,\n                \"id\": <ipv4_id>,\n                \"descricao\": \"<string description>\"\n            },\n            {...}\n          ]\n\n        :raise NetworkAPIException: Falha ao acessar fonte de dados\n        \"\"\"\n\n        uri = 'api/dhcprelayv4/?'\n        if networkipv4:\n            uri += 'networkipv4=%s&' % networkipv4\n        if ipv4:\n            uri += 'ipv4=%s' % ipv4\n\n        return self.get(uri)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist all DHCPRelayIPv4. :param: Object DHCPRelayIPv4 :return: Following dictionary: { \"networkipv6\": <networkipv4_id>, \"id\": <id>, \"ipv6\": { \"block1\": <block1>, \"block2\": <block2>, \"block3\": <block3>, \"block4\": <block4>, \"block5\": <block5>, \"block6\": <block6>, \"block7\": <block7>, \"block8\": <block8>, \"ip_formated\": \"<string IPv6>\", \"networkipv6\": <networkipv6_id>, \"id\": <ipv6_id>, \"description\": \"<string description>\" } :raise NetworkAPIException: Falha ao acessar fonte de dados", "response": "def add(self, networkipv6_id, ipv6_id):\n        \"\"\"List all DHCPRelayIPv4.\n\n        :param: Object DHCPRelayIPv4\n\n        :return: Following dictionary:\n          {\n          \"networkipv6\": <networkipv4_id>,\n          \"id\": <id>,\n          \"ipv6\": {\n              \"block1\": <block1>,\n              \"block2\": <block2>,\n              \"block3\": <block3>,\n              \"block4\": <block4>,\n              \"block5\": <block5>,\n              \"block6\": <block6>,\n              \"block7\": <block7>,\n              \"block8\": <block8>,\n              \"ip_formated\": \"<string IPv6>\",\n              \"networkipv6\": <networkipv6_id>,\n              \"id\": <ipv6_id>,\n              \"description\": \"<string description>\"\n          }\n\n        :raise NetworkAPIException: Falha ao acessar fonte de dados\n        \"\"\"\n\n        data = dict()\n\n        data['networkipv6'] = networkipv6_id\n        data['ipv6'] = dict()\n        data['ipv6']['id'] = ipv6_id\n        uri = 'api/dhcprelayv6/'\n        return self.post(uri, data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list(self, networkipv6=None, ipv6=None):\n\n        uri = 'api/dhcprelayv6/?'\n        if networkipv6:\n            uri += 'networkipv6=%s&' % networkipv6\n        if ipv6:\n            uri += 'ipv6=%s' % ipv6\n\n        return self.get(uri)", "response": "List all DHCPRelayIPv6.\n\n        :param: networkipv6: networkipv6 id - list all dhcprelay filtering by networkipv6 id\n          ipv6: ipv6 id - list all dhcprelay filtering by ipv6 id\n\n        :return: Following dictionary:\n          [\n            {\n            \"networkipv6\": <networkipv4_id>,\n            \"id\": <id>,\n            \"ipv6\": {\n                \"block1\": <block1>,\n                \"block2\": <block2>,\n                \"block3\": <block3>,\n                \"block4\": <block4>,\n                \"block5\": <block5>,\n                \"block6\": <block6>,\n                \"block7\": <block7>,\n                \"block8\": <block8>,\n                \"ip_formated\": \"<string IPv6>\",\n                \"networkipv6\": <networkipv6_id>,\n                \"id\": <ipv6_id>,\n                \"description\": \"<string description>\"\n            },\n            {...}\n          ]\n\n        :raise NetworkAPIException: Falha ao acessar fonte de dados"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, ids):\n        url = build_uri_with_ids('api/v3/ipv6/%s/', ids)\n        return super(ApiIPv6, self).delete(url)", "response": "Method to delete ipv6 s by their ids\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, ipv6s):\n\n        data = {'ips': ipv6s}\n        ipv6s_ids = [str(ipv6.get('id')) for ipv6 in ipv6s]\n\n        return super(ApiIPv6, self).put('api/v3/ipv6/%s/' %\n                                        ';'.join(ipv6s_ids), data)", "response": "Method to update ipv6 s\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search(self, **kwargs):\n\n        return super(ApiIPv4, self).get(self.prepare_url('api/v3/ipv4/',\n                                                         kwargs))", "response": "Method to search ipv4 s based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, ipv4s):\n\n        data = {'ips': ipv4s}\n        ipv4s_ids = [str(ipv4.get('id')) for ipv4 in ipv4s]\n\n        return super(ApiIPv4, self).put('api/v3/ipv4/%s/' %\n                                        ';'.join(ipv4s_ids), data)", "response": "Method to update ipv4 s\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(self, ipv4s):\n\n        data = {'ips': ipv4s}\n        return super(ApiIPv4, self).post('api/v3/ipv4/', data)", "response": "Method to create ipv4 s\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, ids):\n        url = build_uri_with_ids('api/v3/object-group-perm-general/%s/', ids)\n        return super(ApiObjectGroupPermissionGeneral, self).delete(url)", "response": "Method to delete object group permissions general by their ids\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, ogpgs):\n\n        data = {'ogpgs': ogpgs}\n        ogpgs_ids = [str(ogpg.get('id')) for ogpg in ogpgs]\n\n        return super(ApiObjectGroupPermissionGeneral, self).put('api/v3/object-group-perm-general/%s/' %\n                                                                ';'.join(ogpgs_ids), data)", "response": "Method to update object group permissions general desired"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(self, ogpgs):\n\n        data = {'ogpgs': ogpgs}\n        return super(ApiObjectGroupPermissionGeneral, self).post('api/v3/object-group-perm-general/', data)", "response": "Method to create object group permissions general"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search(self, **kwargs):\n\n        return super(ApiV4IPv6, self).get(self.prepare_url('api/v4/ipv6/',\n                                                           kwargs))", "response": "Method to search ipv6 s based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(self, ids):\n        url = build_uri_with_ids('api/v4/ipv6/%s/', ids)\n        return super(ApiV4IPv6, self).delete(url)", "response": "Method to delete ipv6 s by their ids\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, tipo_opcao, nome_opcao_txt):\n        optionvip_map = dict()\n        optionvip_map['tipo_opcao'] = tipo_opcao\n        optionvip_map['nome_opcao_txt'] = nome_opcao_txt\n\n        code, xml = self.submit(\n            {'option_vip': optionvip_map}, 'POST', 'optionvip/')\n\n        return self.response(code, xml)", "response": "Inserts a new Option VIP and returns its identifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef alter(self, id_option_vip, tipo_opcao, nome_opcao_txt):\n\n        if not is_valid_int_param(id_option_vip):\n            raise InvalidParameterError(\n                u'The identifier of Option VIP is invalid or was not informed.')\n\n        optionvip_map = dict()\n        optionvip_map['tipo_opcao'] = tipo_opcao\n        optionvip_map['nome_opcao_txt'] = nome_opcao_txt\n\n        url = 'optionvip/' + str(id_option_vip) + '/'\n\n        code, xml = self.submit({'option_vip': optionvip_map}, 'PUT', url)\n\n        return self.response(code, xml)", "response": "Change Option VIP from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove(self, id_option_vip):\n\n        if not is_valid_int_param(id_option_vip):\n            raise InvalidParameterError(\n                u'The identifier of Option VIP is invalid or was not informed.')\n\n        url = 'optionvip/' + str(id_option_vip) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Remove Option VIP from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_option_vip(self, id_environment_vip):\n\n        url = 'optionvip/environmentvip/' + str(id_environment_vip) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml, ['option_vip'])", "response": "Get all Option VIP by Environment Vip."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a relationship of OptionVip with EnvironmentVip.", "response": "def associate(self, id_option_vip, id_environment_vip):\n        \"\"\"Create a relationship of OptionVip with EnvironmentVip.\n\n        :param id_option_vip: Identifier of the Option VIP. Integer value and greater than zero.\n        :param id_environment_vip: Identifier of the Environment VIP. Integer value and greater than zero.\n\n        :return: Following dictionary\n\n        ::\n\n            {'opcoesvip_ambiente_xref': {'id': < id_opcoesvip_ambiente_xref >} }\n\n        :raise InvalidParameterError: Option VIP/Environment VIP identifier is null and/or invalid.\n        :raise OptionVipNotFoundError: Option VIP not registered.\n        :raise EnvironmentVipNotFoundError: Environment VIP not registered.\n        :raise OptionVipError: Option vip is already associated with the environment vip.\n        :raise UserNotAuthorizedError: User does not have authorization to make this association.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_option_vip):\n            raise InvalidParameterError(\n                u'The identifier of Option VIP is invalid or was not informed.')\n\n        if not is_valid_int_param(id_environment_vip):\n            raise InvalidParameterError(\n                u'The identifier of Environment VIP is invalid or was not informed.')\n\n        url = 'optionvip/' + \\\n            str(id_option_vip) + '/environmentvip/' + str(id_environment_vip) + '/'\n\n        code, xml = self.submit(None, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef buscar_rules(self, id_ambiente_vip, id_vip=''):\n\n        url = 'environment-vip/get/rules/' + \\\n            str(id_ambiente_vip) + '/' + str(id_vip)\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)", "response": "Search rules by environment vip identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching healthcheck by environment vip identifier.", "response": "def buscar_healthchecks(self, id_ambiente_vip):\n        \"\"\"Search healthcheck \u200bby environmentvip_id\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {'healthcheck_opt': [{'name': <name>, 'id': <id>},...]}\n\n        :raise InvalidParameterError: Environment VIP identifier is null and invalid.\n        :raise EnvironmentVipNotFoundError: Environment VIP not registered.\n        :raise InvalidParameterError: id_ambiente_vip is null and invalid.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        url = 'environment-vip/get/healthcheck/' + str(id_ambiente_vip)\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml, ['healthcheck_opt'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef buscar_idtrafficreturn_opcvip(self, nome_opcao_txt):\n\n        trafficreturn_map = dict()\n        trafficreturn_map['trafficreturn'] = nome_opcao_txt\n\n        url = 'optionvip/trafficreturn/search/'\n\n        code, xml = self.submit({'trafficreturn_opt':trafficreturn_map }, 'POST', url)\n\n        return self.response(code, xml)", "response": "Search id of Option VIP when tipo_opcao = Retorno de trafego"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists all Model by Brand.", "response": "def listar_por_marca(self, id_brand):\n        \"\"\"List all Model by Brand.\n\n        :param id_brand: Identifier of the Brand. Integer value and greater than zero.\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {\u2018model\u2019: [{\u2018id\u2019: < id >,\n            \u2018nome\u2019: < nome >,\n            \u2018id_marca\u2019: < id_marca >}, ... too Model ...]}\n\n        :raise InvalidParameterError: The identifier of Brand is null and invalid.\n        :raise MarcaNaoExisteError: Brand not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response\n        \"\"\"\n\n        if not is_valid_int_param(id_brand):\n            raise InvalidParameterError(\n                u'The identifier of Brand is invalid or was not informed.')\n\n        url = 'model/brand/' + str(id_brand) + '/'\n\n        code, map = self.submit(None, 'GET', url)\n\n        key = 'model'\n        return get_list_map(self.response(code, map, [key]), key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inserir(self, id_brand, name):\n        model_map = dict()\n        model_map['name'] = name\n        model_map['id_brand'] = id_brand\n\n        code, xml = self.submit({'model': model_map}, 'POST', 'model/')\n\n        return self.response(code, xml)", "response": "Inserts a new Model and returns its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef alterar(self, id_model, id_brand, name):\n\n        if not is_valid_int_param(id_model):\n            raise InvalidParameterError(\n                u'The identifier of Model is invalid or was not informed.')\n\n        model_map = dict()\n        model_map['name'] = name\n        model_map['id_brand'] = id_brand\n\n        url = 'model/' + str(id_model) + '/'\n\n        code, xml = self.submit({'model': model_map}, 'PUT', url)\n\n        return self.response(code, xml)", "response": "Change the Model from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving Model from by the identifier.", "response": "def remover(self, id_model):\n        \"\"\"Remove Model from by the identifier.\n\n        :param id_model: Identifier of the Model. Integer value and greater than zero.\n\n        :return: None\n\n        :raise InvalidParameterError: The identifier of Model is null and invalid.\n        :raise ModeloEquipamentoNaoExisteError: Model not registered.\n        :raise ModeloEquipamentoError: The Model is associated with a equipment.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response\n        \"\"\"\n\n        if not is_valid_int_param(id_model):\n            raise InvalidParameterError(\n                u'The identifier of Model is invalid or was not informed.')\n\n        url = 'model/' + str(id_model) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef listar_por_equipamento(self, id_equipamento):\n        if not is_valid_int_param(id_equipamento):\n            raise InvalidParameterError(\n                u'Equipment id is invalid or was not informed.')\n\n        url = 'interface/equipamento/' + str(id_equipamento) + '/'\n\n        code, map = self.submit(None, 'GET', url)\n\n        key = 'interface'\n        return get_list_map(self.response(code, map, [key]), key)", "response": "List all interfaces of an equipment."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets an interface by id.", "response": "def get_by_id(self, id_interface):\n        \"\"\"Get an interface by id.\n\n        :param id_interface: Interface identifier.\n\n        :return: Following dictionary:\n\n        ::\n\n            {'interface': {'id': < id >,\n            'interface': < interface >,\n            'descricao': < descricao >,\n            'protegida': < protegida >,\n            'tipo_equip': < id_tipo_equipamento >,\n            'equipamento': < id_equipamento >,\n            'equipamento_nome': < nome_equipamento >\n            'ligacao_front': < id_ligacao_front >,\n            'nome_ligacao_front': < interface_name >,\n            'nome_equip_l_front': < equipment_name >,\n            'ligacao_back': < id_ligacao_back >,\n            'nome_ligacao_back': < interface_name >,\n            'nome_equip_l_back': < equipment_name > }}\n\n        :raise InvalidParameterError: Interface identifier is invalid or none.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        if not is_valid_int_param(id_interface):\n            raise InvalidParameterError(\n                u'Interface id is invalid or was not informed.')\n\n        url = 'interface/' + str(id_interface) + '/get/'\n\n        code, map = self.submit(None, 'GET', url)\n\n        return self.response(code, map)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inserir(\n            self,\n            nome,\n            protegida,\n            descricao,\n            id_ligacao_front,\n            id_ligacao_back,\n            id_equipamento,\n            tipo=None,\n            vlan=None):\n        \"\"\"Insert new interface for an equipment.\n\n        :param nome: Interface name.\n        :param protegida: Indication of protected ('0' or '1').\n        :param descricao: Interface description.\n        :param id_ligacao_front: Front end link interface identifier.\n        :param id_ligacao_back: Back end link interface identifier.\n        :param id_equipamento: Equipment identifier.\n\n        :return: Dictionary with the following: {'interface': {'id': < id >}}\n\n        :raise EquipamentoNaoExisteError: Equipment does not exist.\n        :raise InvalidParameterError: The parameters nome, protegida and/or equipment id are none or invalid.\n        :raise NomeInterfaceDuplicadoParaEquipamentoError: There is already an interface with this name for this equipment.\n        :raise InterfaceNaoExisteError: Front link interface and/or back link interface doesn't exist.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        interface_map = dict()\n        interface_map['nome'] = nome\n        interface_map['protegida'] = protegida\n        interface_map['descricao'] = descricao\n        interface_map['id_ligacao_front'] = id_ligacao_front\n        interface_map['id_ligacao_back'] = id_ligacao_back\n        interface_map['id_equipamento'] = id_equipamento\n        interface_map['tipo'] = tipo\n        interface_map['vlan'] = vlan\n\n        code, xml = self.submit(\n            {'interface': interface_map}, 'POST', 'interface/')\n        return self.response(code, xml)", "response": "Inserts a new interface for an equipment."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nedits an interface by its identifier.", "response": "def alterar(\n            self,\n            id_interface,\n            nome,\n            protegida,\n            descricao,\n            id_ligacao_front,\n            id_ligacao_back,\n            tipo=None,\n            vlan=None):\n        \"\"\"Edit an interface by its identifier.\n\n        Equipment identifier is not changed.\n\n        :param nome: Interface name.\n        :param protegida: Indication of protected ('0' or '1').\n        :param descricao: Interface description.\n        :param id_ligacao_front: Front end link interface identifier.\n        :param id_ligacao_back: Back end link interface identifier.\n        :param id_interface: Interface identifier.\n\n        :return: None\n\n        :raise InvalidParameterError: The parameters interface id, nome and protegida are none or invalid.\n        :raise NomeInterfaceDuplicadoParaEquipamentoError: There is already an interface with this name for this equipment.\n        :raise InterfaceNaoExisteError: Front link interface and/or back link interface doesn't exist.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        if not is_valid_int_param(id_interface):\n            raise InvalidParameterError(\n                u'Interface id is invalid or was not informed.')\n\n        url = 'interface/' + str(id_interface) + '/'\n\n        interface_map = dict()\n        interface_map['nome'] = nome\n        interface_map['protegida'] = protegida\n        interface_map['descricao'] = descricao\n        interface_map['id_ligacao_front'] = id_ligacao_front\n        interface_map['id_ligacao_back'] = id_ligacao_back\n        interface_map['tipo'] = tipo\n        interface_map['vlan'] = vlan\n\n        code, xml = self.submit({'interface': interface_map}, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves an interface by its identifier.", "response": "def remover(self, id_interface):\n        \"\"\"Remove an interface by its identifier.\n\n        :param id_interface: Interface identifier.\n\n        :return: None\n\n        :raise InterfaceNaoExisteError: Interface doesn't exist.\n        :raise InterfaceError: Interface is linked to another interface.\n        :raise InvalidParameterError: The interface identifier is invalid or none.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        if not is_valid_int_param(id_interface):\n            raise InvalidParameterError(\n                u'Interface id is invalid or was not informed.')\n\n        url = 'interface/' + str(id_interface) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_connection(self, id_interface, back_or_front):\n\n        msg_err = u'Parameter %s is invalid. Value: %s.'\n\n        if not is_valid_0_1(back_or_front):\n            raise InvalidParameterError(\n                msg_err %\n                ('back_or_front', back_or_front))\n\n        if not is_valid_int_param(id_interface):\n            raise InvalidParameterError(\n                msg_err %\n                ('id_interface', id_interface))\n\n        url = 'interface/%s/%s/' % (str(id_interface), str(back_or_front))\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Remove a connection between two interfaces."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting the interfaces linked to back and front of a specified interface.", "response": "def list_connections(self, nome_interface, id_equipamento):\n        \"\"\"List interfaces linked to back and front of specified interface.\n\n        :param nome_interface: Interface name.\n        :param id_equipamento: Equipment identifier.\n\n        :return: Dictionary with the following:\n\n        ::\n\n            {'interfaces':[ {'id': < id >,\n            'interface': < nome >,\n            'descricao': < descricao >,\n            'protegida': < protegida >,\n            'equipamento': < id_equipamento >,\n            'tipo_equip': < id_tipo_equipamento >,\n            'ligacao_front': < id_ligacao_front >,\n            'nome_ligacao_front': < interface_name >,\n            'nome_equip_l_front': < equipment_name >,\n            'ligacao_back': < id_ligacao_back >,\n            'nome_ligacao_back': < interface_name >,\n            'nome_equip_l_back': < equipment_name > }, ... other interfaces ...]}\n\n        :raise InterfaceNaoExisteError: Interface doesn't exist or is not associated with this equipment.\n        :raise EquipamentoNaoExisteError: Equipment doesn't exist.\n        :raise InvalidParameterError: Interface name and/or equipment identifier are none or invalid.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        if not is_valid_int_param(id_equipamento):\n            raise InvalidParameterError(\n                u'Equipment identifier is none or was not informed.')\n\n        if (nome_interface is None) or (nome_interface == ''):\n            raise InvalidParameterError(u'Interface name was not informed.')\n\n        # Tempor\u00e1rio, remover. Fazer de outra forma.\n        nome_interface = nome_interface.replace('/', 's2it_replace')\n\n        url = 'interface/' + \\\n            urllib.quote(nome_interface) + '/equipment/' + \\\n            str(id_equipamento) + '/'\n\n        code, map = self.submit(None, 'GET', url)\n\n        key = 'interfaces'\n        return get_list_map(self.response(code, map, [key]), key)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_all(self):\n        code, map = self.submit(None, 'GET', 'perms/all/')\n\n        key = 'perms'\n        return get_list_map(self.response(code, map, [key]), key)", "response": "List all Permission.\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {'perms': [{ 'function' < function >, 'id': < id > }, ... more permissions ...]}\n\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self, ids):\n        url = build_uri_with_ids('api/v4/ipv4/%s/', ids)\n\n        return super(ApiV4IPv4, self).delete(url)", "response": "Method to delete ipv4 s by their ids\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef provisionar(self, equipamentos, vips):\n        code, map = self.submit(\n            {\n                'equipamentos': {\n                    'equipamento': equipamentos}, 'vips': {\n                    'vip': vips}}, 'POST', 'grupovirtual/')\n        return self.response(code, map, force_list=['equipamento', 'vip'])", "response": "Provisions a set of equipamentos and VIPs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remover_provisionamento(self, equipamentos, vips):\n\n        code, map = self.submit({'equipamentos': {'equipamento': equipamentos}, 'vips': {\n                                'vip': vips}}, 'DELETE', 'grupovirtual/')\n\n        return self.response(code, map)", "response": "Remove o provisionamento de um grupo virtual para o sistema de Orquestra\u00e7\u00e3o VM."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist all users and their user groups.", "response": "def list_with_usergroup(self):\n        \"\"\"List all users and their user groups.\n        is_more -If  more than 3 of groups of users or no, to control expansion Screen.\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {'usuario': [{'nome': < nome >,\n            'id': < id >,\n            'pwd': < pwd >,\n            'user': < user >,\n            'ativo': < ativo >,\n            'email': < email >,\n            'is_more': <True ou False>,\n            'grupos': [nome_grupo, ...more user groups...]}, ...more user...]}\n\n\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        url = 'usuario/get/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets user by the ldap name.", "response": "def get_by_user_ldap(self, user_name):\n        \"\"\"Get user by the ldap name.\n        is_more -If  more than 3 of groups of users or no, to control expansion Screen.\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {'usuario': [{'nome': < nome >,\n            'id': < id >,\n            'pwd': < pwd >,\n            'user': < user >,\n            'ativo': < ativo >,\n            'email': < email >,\n            'grupos': [nome_grupo, ...more user groups...],\n            'user_ldap': < user_ldap >}}\n\n\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        url = 'user/get/ldap/' + str(user_name) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inserir(self, user, pwd, name, email, user_ldap):\n        user_map = dict()\n        user_map['user'] = user\n        user_map['password'] = pwd\n        user_map['name'] = name\n        user_map['email'] = email\n        user_map['user_ldap'] = user_ldap\n\n        code, xml = self.submit({'user': user_map}, 'POST', 'user/')\n\n        return self.response(code, xml)", "response": "Inserts a new User and returns its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef alterar(self, id_user, user, password, nome, ativo, email, user_ldap):\n        if not is_valid_int_param(id_user):\n            raise InvalidParameterError(\n                u'The identifier of User is invalid or was not informed.')\n\n        url = 'user/' + str(id_user) + '/'\n\n        user_map = dict()\n        user_map['user'] = user\n        user_map['password'] = password\n        user_map['name'] = nome\n        user_map['active'] = ativo\n        user_map['email'] = email\n        user_map['user_ldap'] = user_ldap\n\n        code, xml = self.submit({'user': user_map}, 'PUT', url)\n\n        return self.response(code, xml)", "response": "Change the User from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef change_password(self, id_user, user_current_password, password):\n        if not is_valid_int_param(id_user):\n            raise InvalidParameterError(\n                u'The identifier of User is invalid or was not informed.')\n\n        if password is None or password == \"\":\n            raise InvalidParameterError(\n                u'A nova senha do usu\u00e1rio \u00e9 inv\u00e1lida ou n\u00e3o foi informada')\n\n        user_map = dict()\n        user_map['user_id'] = id_user\n        user_map['password'] = password\n\n        code, xml = self.submit(\n            {'user': user_map}, 'POST', 'user-change-pass/')\n\n        return self.response(code, xml)", "response": "Change the password of a user from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef authenticate(self, username, password, is_ldap_user):\n        user_map = dict()\n        user_map['username'] = username\n        user_map['password'] = password\n        user_map['is_ldap_user'] = is_ldap_user\n\n        code, xml = self.submit({'user': user_map}, 'POST', 'authenticate/')\n\n        return self.response(code, xml)", "response": "Authenticate a user by username and password and return a dictionary with the user s attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget user by username and password and their permissions. :param username: Username. String with a minimum 3 and maximum of 45 characters :param password: User password. String with a minimum 3 and maximum of 45 characters :return: Following dictionary: :: {'user': {'id': < id >} {'user': < user >} {'nome': < nome >} {'pwd': < pwd >} {'email': < email >} {'active': < active >} {'permission':[ {'<function>': { 'write': <value>, 'read': <value>}, ... more function ... ] } } } :raise InvalidParameterError: The value of username or password is invalid. :raise DataBaseError: Networkapi failed to access the database. :raise XMLError: Networkapi failed to generate the XML response.", "response": "def authenticate_ldap(self, username, password):\n        \"\"\"Get user by username and password and their permissions.\n\n        :param username: Username. String with a minimum 3 and maximum of 45 characters\n        :param password: User password. String with a minimum 3 and maximum of 45 characters\n\n        :return: Following dictionary:\n\n        ::\n\n            {'user': {'id': < id >}\n            {'user': < user >}\n            {'nome': < nome >}\n            {'pwd': < pwd >}\n            {'email': < email >}\n            {'active': < active >}\n            {'permission':[ {'<function>': { 'write': <value>, 'read': <value>}, ... more function ... ] } } }\n\n        :raise InvalidParameterError: The value of username or password is invalid.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        user_map = dict()\n        user_map['username'] = username\n        user_map['password'] = password\n\n        code, xml = self.submit(\n            {'user': user_map}, 'POST', 'authenticate/ldap/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist all access types.", "response": "def listar(self):\n        \"\"\"List all access types.\n\n        :return: Dictionary with structure:\n\n        ::\n\n            {\u2018tipo_acesso\u2019: [{\u2018id\u2019: < id >,\n            \u2018protocolo\u2019: < protocolo >}, ... other access types ...]}\n\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        code, map = self.submit(None, 'GET', 'tipoacesso/')\n\n        key = 'tipo_acesso'\n        return get_list_map(self.response(code, map, [key]), key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts new access type and returns its identifier.", "response": "def inserir(self, protocolo):\n        \"\"\"Insert new access type and returns its identifier.\n\n        :param protocolo: Protocol.\n\n        :return: Dictionary with structure: {\u2018tipo_acesso\u2019: {\u2018id\u2019: < id >}}\n\n        :raise ProtocoloTipoAcessoDuplicadoError: Protocol already exists.\n        :raise InvalidParameterError: Protocol value is invalid or none.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        tipo_acesso_map = dict()\n        tipo_acesso_map['protocolo'] = protocolo\n\n        code, xml = self.submit(\n            {'tipo_acesso': tipo_acesso_map}, 'POST', 'tipoacesso/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef alterar(self, id_tipo_acesso, protocolo):\n        if not is_valid_int_param(id_tipo_acesso):\n            raise InvalidParameterError(\n                u'Access type id is invalid or was not informed.')\n\n        tipo_acesso_map = dict()\n        tipo_acesso_map['protocolo'] = protocolo\n\n        url = 'tipoacesso/' + str(id_tipo_acesso) + '/'\n\n        code, xml = self.submit({'tipo_acesso': tipo_acesso_map}, 'PUT', url)\n\n        return self.response(code, xml)", "response": "Edit access type by its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remover(self, id_tipo_acesso):\n        if not is_valid_int_param(id_tipo_acesso):\n            raise InvalidParameterError(\n                u'Access type id is invalid or was not informed.')\n\n        url = 'tipoacesso/' + str(id_tipo_acesso) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Removes access type by its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef inserir(self, type, description):\n        script_type_map = dict()\n        script_type_map['type'] = type\n        script_type_map['description'] = description\n\n        code, xml = self.submit(\n            {'script_type': script_type_map}, 'POST', 'scripttype/')\n\n        return self.response(code, xml)", "response": "Inserts a new Script Type and returns its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef alterar(self, id_script_type, type, description):\n        if not is_valid_int_param(id_script_type):\n            raise InvalidParameterError(\n                u'The identifier of Script Type is invalid or was not informed.')\n\n        script_type_map = dict()\n        script_type_map['type'] = type\n        script_type_map['description'] = description\n\n        url = 'scripttype/' + str(id_script_type) + '/'\n\n        code, xml = self.submit({'script_type': script_type_map}, 'PUT', url)\n\n        return self.response(code, xml)", "response": "Change Script Type from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remover(self, id_script_type):\n        if not is_valid_int_param(id_script_type):\n            raise InvalidParameterError(\n                u'The identifier of Script Type is invalid or was not informed.')\n\n        url = 'scripttype/' + str(id_script_type) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Remove Script Type from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search(self, **kwargs):\n\n        return super(ApiPool, self).get(self.prepare_url('api/v3/pool/',\n                                                         kwargs))", "response": "Method to search pool s based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(self, pools):\n\n        data = {'server_pools': pools}\n        return super(ApiPool, self).post('api/v3/pool/', data)", "response": "Method to create pool s\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the real related VISA entries for a given equipment.", "response": "def get_real_related(self, id_equip):\n        \"\"\"\n        Find reals related with equipment\n\n        :param id_equip: Identifier of equipment\n\n        :return: Following dictionary:\n\n        ::\n\n            {'vips': [{'port_real': < port_real >,\n            'server_pool_member_id': < server_pool_member_id >,\n            'ip': < ip >,\n            'port_vip': < port_vip >,\n            'host_name': < host_name >,\n            'id_vip': < id_vip >, ...],\n            'equip_name': < equip_name > }}\n\n        :raise EquipamentoNaoExisteError: Equipment not registered.\n        :raise InvalidParameterError: Some parameter was invalid.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        url = 'equipamento/get_real_related/' + str(id_equip) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        data = self.response(code, xml)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding vlans by all search parameters.", "response": "def find_equips(\n            self,\n            name,\n            iexact,\n            environment,\n            equip_type,\n            group,\n            ip,\n            pagination):\n        \"\"\"\n        Find vlans by all search parameters\n\n        :param name: Filter by vlan name column\n        :param iexact: Filter by name will be exact?\n        :param environment: Filter by environment ID related\n        :param equip_type: Filter by equipment_type ID related\n        :param group: Filter by equipment group ID related\n        :param ip: Filter by each octs in ips related\n        :param pagination: Class with all data needed to paginate\n\n        :return: Following dictionary:\n\n        ::\n\n            {'equipamento': {'id': < id_vlan >,\n            'nome': < nome_vlan >,\n            'num_vlan': < num_vlan >,\n            'id_ambiente': < id_ambiente >,\n            'descricao': < descricao >,\n            'acl_file_name': < acl_file_name >,\n            'acl_valida': < acl_valida >,\n            'ativada': < ativada >,\n            'ambiente_name': < divisao_dc-ambiente_logico-grupo_l3 >\n            'redeipv4': [ { all networkipv4 related  } ],\n            'redeipv6': [ { all networkipv6 related } ] },\n            'total': {< total_registros >} }\n\n        :raise InvalidParameterError: Some parameter was invalid.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not isinstance(pagination, Pagination):\n            raise InvalidParameterError(\n                u\"Invalid parameter: pagination must be a class of type 'Pagination'.\")\n\n        equip_map = dict()\n\n        equip_map[\"start_record\"] = pagination.start_record\n        equip_map[\"end_record\"] = pagination.end_record\n        equip_map[\"asorting_cols\"] = pagination.asorting_cols\n        equip_map[\"searchable_columns\"] = pagination.searchable_columns\n        equip_map[\"custom_search\"] = pagination.custom_search\n\n        equip_map[\"nome\"] = name\n        equip_map[\"exato\"] = iexact\n        equip_map[\"ambiente\"] = environment\n        equip_map[\"tipo_equipamento\"] = equip_type\n        equip_map[\"grupo\"] = group\n        equip_map[\"ip\"] = ip\n\n        url = \"equipamento/find/\"\n\n        code, xml = self.submit({\"equipamento\": equip_map}, \"POST\", url)\n\n        key = \"equipamento\"\n        return get_list_map(\n            self.response(\n                code, xml, [\n                    key, \"ips\", \"grupos\"]), key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninserts a new Equipment and returns its identifier.", "response": "def inserir(self, name, id_equipment_type, id_model, id_group, maintenance=False):\n        \"\"\"Inserts a new Equipment and returns its identifier\n\n        Al\u00e9m de inserir o equipamento, a networkAPI tamb\u00e9m associa o equipamento\n        ao grupo informado.\n\n        :param name: Equipment name. String with a minimum 3 and maximum of 30 characters\n        :param id_equipment_type: Identifier of the Equipment Type. Integer value and greater than zero.\n        :param id_model: Identifier of the Model. Integer value and greater than zero.\n        :param id_group: Identifier of the Group. Integer value and greater than zero.\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {'equipamento': {'id': < id_equipamento >},\n            'equipamento_grupo': {'id': < id_grupo_equipamento >}}\n\n        :raise InvalidParameterError: The identifier of Equipment type, model, group or name  is null and invalid.\n        :raise TipoEquipamentoNaoExisteError: Equipment Type not registered.\n        :raise ModeloEquipamentoNaoExisteError: Model not registered.\n        :raise GrupoEquipamentoNaoExisteError: Group not registered.\n\n        :raise EquipamentoError: Equipamento com o nome duplicado ou\n            Equipamento do grupo \u201cEquipamentos Orquestra\u00e7\u00e3o\u201d somente poder\u00e1 ser\n            criado com tipo igual a \u201cServidor Virtual\".\n\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response\n        \"\"\"\n        equip_map = dict()\n        equip_map['id_tipo_equipamento'] = id_equipment_type\n        equip_map['id_modelo'] = id_model\n        equip_map['nome'] = name\n        equip_map['id_grupo'] = id_group\n        equip_map['maintenance'] = maintenance\n        \n        code, xml = self.submit(\n            {'equipamento': equip_map}, 'POST', 'equipamento/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchanges the Equipment from by the identifier.", "response": "def edit(self, id_equip, nome, id_tipo_equipamento, id_modelo, maintenance=None):\n        \"\"\"Change Equipment from by the identifier.\n\n        :param id_equip: Identifier of the Equipment. Integer value and greater than zero.\n        :param nome: Equipment name. String with a minimum 3 and maximum of 30 characters\n        :param id_tipo_equipamento: Identifier of the Equipment Type. Integer value and greater than zero.\n        :param id_modelo: Identifier of the Model. Integer value and greater than zero.\n\n        :return: None\n\n        :raise InvalidParameterError: The identifier of Equipment, model, equipment type or name  is null and invalid.\n        :raise EquipamentoNaoExisteError: Equipment not registered.\n        :raise TipoEquipamentoNaoExisteError: Equipment Type not registered.\n        :raise ModeloEquipamentoNaoExisteError: Model not registered.\n        :raise GrupoEquipamentoNaoExisteError: Group not registered.\n\n        :raise EquipamentoError: Equipamento com o nome duplicado ou\n            Equipamento do grupo \u201cEquipamentos Orquestra\u00e7\u00e3o\u201d somente poder\u00e1 ser\n            criado com tipo igual a \u201cServidor Virtual\".\n\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response\n\n        \"\"\"\n\n        equip_map = dict()\n        equip_map['id_equip'] = id_equip\n        equip_map['id_tipo_equipamento'] = id_tipo_equipamento\n        equip_map['id_modelo'] = id_modelo\n        equip_map['nome'] = nome\n        if maintenance is not None:\n            equip_map['maintenance'] = maintenance\n\n        url = 'equipamento/edit/' + str(id_equip) + '/'\n\n        code, xml = self.submit({'equipamento': equip_map}, 'POST', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef criar_ip(self, id_vlan, id_equipamento, descricao):\n        ip_map = dict()\n        ip_map['id_vlan'] = id_vlan\n        ip_map['descricao'] = descricao\n        ip_map['id_equipamento'] = id_equipamento\n\n        code, xml = self.submit({'ip': ip_map}, 'POST', 'ip/')\n\n        return self.response(code, xml)", "response": "Criar um IP para um a VLAN para um a novo IP para um a equipamento."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nallocate an IP on a network and associate it with an equipment.", "response": "def add_ipv4(self, id_network_ipv4, id_equipamento, descricao):\n        \"\"\"Allocate an IP on a network to an equipment.\n        Insert new IP for network and associate to the equipment\n\n        :param id_network_ipv4: ID for NetworkIPv4.\n        :param id_equipamento: ID for Equipment.\n        :param descricao: Description for IP.\n\n        :return: Following dictionary:\n\n        ::\n\n            {'ip': {'id': < id_ip >,\n            'id_network_ipv4': < id_network_ipv4 >,\n            'oct1\u2019: < oct1 >,\n            'oct2': < oct2 >,\n            'oct3': < oct3 >,\n            'oct4': < oct4 >,\n            'descricao': < descricao >}}\n\n        :raise InvalidParameterError: Invalid ID for NetworkIPv4 or Equipment.\n        :raise InvalidParameterError: The value of description is invalid.\n        :raise EquipamentoNaoExisteError: Equipment not found.\n        :raise RedeIPv4NaoExisteError: NetworkIPv4 not found.\n        :raise IPNaoDisponivelError: There is no network address is available to create the VLAN.\n        :raise ConfigEnvironmentInvalidError: Invalid Environment Configuration or not registered\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        ip_map = dict()\n        ip_map['id_network_ipv4'] = id_network_ipv4\n        ip_map['description'] = descricao\n        ip_map['id_equipment'] = id_equipamento\n\n        code, xml = self.submit({'ip': ip_map}, 'POST', 'ipv4/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nallocating an IP on a network and associate it with an equipment.", "response": "def add_ipv6(self, id_network_ipv6, id_equip, description):\n        \"\"\"Allocate an IP on a network to an equipment.\n        Insert new IP for network and associate to the equipment\n\n        :param id_network_ipv6: ID for NetworkIPv6.\n        :param id_equip: ID for Equipment.\n        :param description: Description for IP.\n\n        :return: Following dictionary:\n\n        ::\n\n            {'ip': {'id': < id_ip >,\n            'id_network_ipv6': < id_network_ipv6 >,\n            'bloco1': < bloco1 >,\n            'bloco2': < bloco2 >,\n            'bloco3': < bloco3 >,\n            'bloco4': < bloco4 >,\n            'bloco5': < bloco5 >,\n            'bloco6': < bloco6 >,\n            'bloco7': < bloco7 >,\n            'bloco8': < bloco8 >,\n            'descricao': < descricao >}}\n\n        :raise InvalidParameterError: NetworkIPv6 identifier or Equipament identifier  is null and invalid,\n        :raise InvalidParameterError: The value of description is invalid.\n        :raise EquipamentoNaoExisteError: Equipment not found.\n        :raise RedeIPv6NaoExisteError: NetworkIPv6 not found.\n        :raise IPNaoDisponivelError: There is no network address is available to create the VLAN.\n        :raise ConfigEnvironmentInvalidError: Invalid Environment Configuration or not registered\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        ip_map = dict()\n        ip_map['id_network_ipv6'] = id_network_ipv6\n        ip_map['description'] = description\n        ip_map['id_equip'] = id_equip\n\n        code, xml = self.submit({'ip': ip_map}, 'POST', 'ipv6/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remover_ip(self, id_equipamento, id_ip):\n\n        if not is_valid_int_param(id_equipamento):\n            raise InvalidParameterError(\n                u'O identificador do equipamento \u00e9 inv\u00e1lido ou n\u00e3o foi informado.')\n\n        if not is_valid_int_param(id_ip):\n            raise InvalidParameterError(\n                u'O identificador do ip \u00e9 inv\u00e1lido ou n\u00e3o foi informado.')\n\n        url = 'ip/' + str(id_ip) + '/equipamento/' + str(id_equipamento) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Removes association of IP and Equipment."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nassociates an IPv6 with an equipment.", "response": "def associate_ipv6(self, id_equip, id_ipv6):\n        \"\"\"Associates an IPv6 to a equipament.\n\n        :param id_equip: Identifier of the equipment. Integer value and greater than zero.\n        :param id_ipv6: Identifier of the ip. Integer value and greater than zero.\n\n        :return: Dictionary with the following structure:\n            {'ip_equipamento': {'id': < id_ip_do_equipamento >}}\n\n        :raise EquipamentoNaoExisteError: Equipment is not registered.\n        :raise IpNaoExisteError: IP not registered.\n        :raise IpError: IP is already associated with the equipment.\n        :raise InvalidParameterError:  Identifier of the equipment and/or IP is null or invalid.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_equip):\n            raise InvalidParameterError(\n                u'The identifier of equipment is invalid or was not informed.')\n\n        if not is_valid_int_param(id_ipv6):\n            raise InvalidParameterError(\n                u'The identifier of ip is invalid or was not informed.')\n\n        url = 'ipv6/' + str(id_ipv6) + '/equipment/' + str(id_equip) + '/'\n\n        code, xml = self.submit(None, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef listar_por_tipo_ambiente(self, id_tipo_equipamento, id_ambiente):\n\n        if not is_valid_int_param(id_tipo_equipamento):\n            raise InvalidParameterError(\n                u'O identificador do tipo do equipamento \u00e9 inv\u00e1lido ou n\u00e3o foi informado.')\n\n        if not is_valid_int_param(id_ambiente):\n            raise InvalidParameterError(\n                u'O identificador do ambiente \u00e9 inv\u00e1lido ou n\u00e3o foi informado.')\n\n        url = 'equipamento/tipoequipamento/' + \\\n            str(id_tipo_equipamento) + '/ambiente/' + str(id_ambiente) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        key = 'equipamento'\n        return get_list_map(self.response(code, xml, [key]), key)", "response": "Listar os equipamentos de um tipo do equipamento ou um ambiente."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef listar_por_nome(self, nome):\n\n        if nome == '' or nome is None:\n            raise InvalidParameterError(\n                u'O nome do equipamento n\u00e3o foi informado.')\n\n        url = 'equipamento/nome/' + urllib.quote(nome) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)", "response": "Listar o nome do equipamento."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists all the nome and modelo of a partir do seu identificador.", "response": "def listar_por_id(self, id):\n        \"\"\"Obt\u00e9m um equipamento a partir do seu identificador.\n\n        :param id: ID do equipamento.\n\n        :return: Dicion\u00e1rio com a seguinte estrutura:\n\n        ::\n\n            {'equipamento': {'id': < id_equipamento >,\n            'nome': < nome_equipamento >,\n            'id_tipo_equipamento': < id_tipo_equipamento >,\n            'nome_tipo_equipamento': < nome_tipo_equipamento >,\n            'id_modelo': < id_modelo >,\n            'nome_modelo': < nome_modelo >,\n            'id_marca': < id_marca >,\n            'nome_marca': < nome_marca >}}\n\n        :raise EquipamentoNaoExisteError: Equipamento com o\n            id informado n\u00e3o cadastrado.\n        :raise InvalidParameterError: O nome do equipamento \u00e9 nulo ou vazio.\n        :raise DataBaseError: Falha na networkapi ao acessar o banco de dados.\n        :raise XMLError: Falha na networkapi ao gerar o XML de resposta.\n        \"\"\"\n\n        if id is None:\n            raise InvalidParameterError(\n                u'O id do equipamento n\u00e3o foi informado.')\n\n        url = 'equipamento/id/' + urllib.quote(id) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting all equipments in database", "response": "def list_all(self):\n        \"\"\"Return all equipments in database\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {'equipaments': {'name' :< name_equipament >}, {... demais equipamentos ...} }\n\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        url = 'equipamento/list/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all equipments in database", "response": "def get_all(self):\n        \"\"\"Return all equipments in database\n\n        :return: Dictionary with the following structure:\n\n        ::\n            {'equipaments': {'name' :< name_equipament >}, {... demais equipamentos ...} }\n\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        url = 'equipment/all'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remover(self, id_equipamento):\n        if not is_valid_int_param(id_equipamento):\n            raise InvalidParameterError(\n                u'O identificador do equipamento \u00e9 inv\u00e1lido ou n\u00e3o foi informado.')\n\n        url = 'equipamento/' + str(id_equipamento) + '/'\n\n        code, map = self.submit(None, 'DELETE', url)\n\n        return self.response(code, map)", "response": "Remove um equipamento a partir do seu identificador."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef associar_grupo(self, id_equipamento, id_grupo_equipamento):\n\n        equip_map = dict()\n        equip_map['id_grupo'] = id_grupo_equipamento\n        equip_map['id_equipamento'] = id_equipamento\n\n        code, xml = self.submit(\n            {'equipamento_grupo': equip_map}, 'POST', 'equipamentogrupo/')\n\n        return self.response(code, xml)", "response": "Associate a grupo with a given equipment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remover_grupo(self, id_equipamento, id_grupo):\n\n        if not is_valid_int_param(id_equipamento):\n            raise InvalidParameterError(\n                u'O identificador do equipamento \u00e9 inv\u00e1lido ou n\u00e3o foi informado.')\n\n        if not is_valid_int_param(id_grupo):\n            raise InvalidParameterError(\n                u'O identificador do grupo \u00e9 inv\u00e1lido ou n\u00e3o foi informado.')\n\n        url = 'equipamentogrupo/equipamento/' + \\\n            str(id_equipamento) + '/egrupo/' + str(id_grupo) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Remove an association between a group and a equipment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch Group Equipment from by the identifier.", "response": "def list_by_group(self, id_egroup):\n        \"\"\"Search Group Equipment from by the identifier.\n\n        :param id_egroup: Identifier of the Group Equipment. Integer value and greater than zero.\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {'equipaments':\n            [{'nome': < name_equipament >, 'grupos': < id_group >,\n            'mark': {'id': < id_mark >, 'nome': < name_mark >},'modelo': < id_model >,\n            'tipo_equipamento': < id_type >,\n            'model': {'nome': , 'id': < id_model >, 'marca': < id_mark >},\n            'type': {id': < id_type >, 'tipo_equipamento': < name_type >},\n            'id': < id_equipment >}, ... ]}\n\n        :raise InvalidParameterError: Group Equipment is null and invalid.\n        :raise GrupoEquipamentoNaoExisteError: Group Equipment not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if id_egroup is None:\n            raise InvalidParameterError(\n                u'The identifier of Group Equipament is invalid or was not informed.')\n\n        url = 'equipment/group/' + str(id_egroup) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_ips_by_equipment_and_environment(self, equip_nome, id_ambiente):\n\n        if id_ambiente is None:\n            raise InvalidParameterError(\n                u'The environment id is invalid or was not informed.')\n\n        url = 'equipment/getipsbyambiente/' + str(equip_nome) + '/' + str(id_ambiente)\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)", "response": "Search Group Equipment from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, uri):\n        request = None\n\n        try:\n\n            request = requests.get(\n                self._url(uri),\n                auth=self._auth_basic(),\n                headers=self._header()\n            )\n\n            request.raise_for_status()\n\n            try:\n                return request.json()\n            except Exception:\n                return request\n\n        except HTTPError:\n            try:\n                error = request.json()\n                self.logger.error(error)\n                err = error.get('detail', '')\n            except:\n                err = request\n            raise NetworkAPIClientError(err)\n        finally:\n            self.logger.info('URI: %s', uri)\n            if request:\n                self.logger.info('Status Code: %s',\n                                 request.status_code if request else '')\n                self.logger.info('X-Request-Id: %s',\n                                 request.headers.get('x-request-id'))\n                self.logger.info('X-Request-Context: %s',\n                                 request.headers.get('x-request-context'))", "response": "Send a GET request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse(self, content):\n        if content:\n\n            stream = BytesIO(str(content))\n            data = json.loads(stream.getvalue())\n\n            return data", "response": "Parse data request from python."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert dict for URL params", "response": "def prepare_url(self, uri, kwargs):\n        \"\"\"Convert dict for URL params\n        \"\"\"\n        params = dict()\n        for key in kwargs:\n            if key in ('include', 'exclude', 'fields'):\n                params.update({\n                    key: ','.join(kwargs.get(key))\n                })\n            elif key in ('search', 'kind'):\n                params.update({\n                    key: kwargs.get(key)\n                })\n\n        if params:\n            params = urlencode(params)\n            uri = '%s?%s' % (uri, params)\n\n        return uri"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert_rack(\n            self,\n            number,\n            name,\n            mac_address_sw1,\n            mac_address_sw2,\n            mac_address_ilo,\n            id_sw1,\n            id_sw2,\n            id_ilo):\n        \"\"\"Create new Rack\n        :param number: Number of Rack\n        :return: Following dictionary:\n        ::\n          {'rack': {'id': < id_rack >,\n          'num_rack': < num_rack >,\n          'name_rack': < name_rack >,\n          'mac_sw1': < mac_sw1 >,\n          'mac_sw2': < mac_sw2 >,\n          'mac_ilo': < mac_ilo >,\n          'id_sw1': < id_sw1 >,\n          'id_sw2': < id_sw2 >,\n          'id_ilo': < id_ilo >, } }\n        :raise RacksError: Rack already registered with informed.\n        :raise NumeroRackDuplicadoError: There is already a registered Rack with the value of number.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(number):\n            raise InvalidParameterError(u'Rack number is none or invalid')\n\n        rack_map = dict()\n        rack_map['number'] = number\n        rack_map['name'] = name\n        rack_map['mac_address_sw1'] = mac_address_sw1\n        rack_map['mac_address_sw2'] = mac_address_sw2\n        rack_map['mac_address_ilo'] = mac_address_ilo\n        rack_map['id_sw1'] = id_sw1\n        rack_map['id_sw2'] = id_sw2\n        rack_map['id_ilo'] = id_ilo\n\n        code, xml = self.submit({'rack': rack_map}, 'POST', 'rack/insert/')\n\n        return self.response(code, xml)", "response": "Insert a new Rack into the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a Rack by the identifier.", "response": "def remover(self, id_rack):\n        \"\"\"Remove Rack by the identifier.\n\n        :param id_rack: Identifier of the Rack. Integer value and greater than zero.\n\n        :return: None\n\n        :raise InvalidParameterError: The identifier of Rack is null and invalid.\n        :raise RackNaoExisteError: Rack not registered.\n        :raise RackError: Rack is associated with a script.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        if not is_valid_int_param(id_rack):\n            raise InvalidParameterError(\n                u'The identifier of Rack is invalid or was not informed.')\n\n        url = 'rack/' + str(id_rack) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef buscar_healthcheck_por_id(self, id_healthcheck):\n        if not is_valid_int_param(id_healthcheck):\n            raise InvalidParameterError(\n                u'O identificador do healthcheck \u00e9 inv\u00e1lido ou n\u00e3o foi informado.')\n\n        url = 'healthcheckexpect/get/' + str(id_healthcheck) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)", "response": "Get a specific healthcheck by id."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef listar_por_equip(self, equip_id):\n\n        if equip_id is None:\n            raise InvalidParameterError(\n                u'O id do equipamento n\u00e3o foi informado.')\n\n        url = 'ambiente/equip/' + str(equip_id) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)", "response": "Lista todos os ambientes por equipamento especifico."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef listar_healthcheck_expect(self, id_ambiente):\n\n        if not is_valid_int_param(id_ambiente):\n            raise InvalidParameterError(\n                u'O identificador do ambiente \u00e9 inv\u00e1lido ou n\u00e3o foi informado.')\n\n        url = 'healthcheckexpect/ambiente/' + str(id_ambiente) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        key = 'healthcheck_expect'\n        return get_list_map(self.response(code, xml, [key]), key)", "response": "Lista os healthcheck_expects de um ambiente."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_healthcheck_expect(self, id_ambiente, expect_string, match_list):\n\n        healthcheck_map = dict()\n        healthcheck_map['id_ambiente'] = id_ambiente\n        healthcheck_map['expect_string'] = expect_string\n        healthcheck_map['match_list'] = match_list\n\n        url = 'healthcheckexpect/add/'\n\n        code, xml = self.submit({'healthcheck': healthcheck_map}, 'POST', url)\n\n        return self.response(code, xml)", "response": "Insere um novo healthckeck_expect e retorna o seu identificador."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inserir(\n            self,\n            id_grupo_l3,\n            id_ambiente_logico,\n            id_divisao,\n            link,\n            id_filter=None,\n            acl_path=None,\n            ipv4_template=None,\n            ipv6_template=None,\n            min_num_vlan_1=None,\n            max_num_vlan_1=None,\n            min_num_vlan_2=None,\n            max_num_vlan_2=None,\n            vrf=None):\n        \"\"\"Insere um novo ambiente e retorna o seu identificador.\n\n        :param id_grupo_l3: Identificador do grupo layer 3.\n        :param id_ambiente_logico: Identificador do ambiente l\u00f3gico.\n        :param id_divisao: Identificador da divis\u00e3o data center.\n        :param id_filter: Filter identifier.\n        :param link: Link\n        :param acl_path: Path where the ACL will be stored\n        :param ipv4_template: Template that will be used in Ipv6\n        :param ipv6_template: Template that will be used in Ipv4\n        :param min_num_vlan_1: Min 1 num vlan valid for this environment\n        :param max_num_vlan_1: Max 1 num vlan valid for this environment\n        :param min_num_vlan_2: Min 2 num vlan valid for this environment\n        :param max_num_vlan_2: Max 2 num vlan valid for this environment\n\n        :return: Dicion\u00e1rio com a seguinte estrutura: {'ambiente': {'id': < id >}}\n\n        :raise InvalidParameterError: O identificador do grupo l3, o identificador do ambiente l\u00f3gico, e/ou\n            o identificador da divis\u00e3o de data center s\u00e3o nulos ou inv\u00e1lidos.\n        :raise GrupoL3NaoExisteError: Grupo layer 3 n\u00e3o cadastrado.\n        :raise AmbienteLogicoNaoExisteError: Ambiente l\u00f3gico n\u00e3o cadastrado.\n        :raise DivisaoDcNaoExisteError: Divis\u00e3o datacenter n\u00e3o cadastrada.\n        :raise AmbienteDuplicadoError: Ambiente com o mesmo id_grupo_l3, id_ambiente_logico e id_divisao\n            j\u00e1 cadastrado.\n        :raise DataBaseError: Falha na networkapi ao acessar o banco de dados.\n        :raise XMLError: Falha na networkapi ao ler o XML de requisi\u00e7\u00e3o ou gerar o XML de resposta.\n        \"\"\"\n\n        ambiente_map = dict()\n        ambiente_map['id_grupo_l3'] = id_grupo_l3\n        ambiente_map['id_ambiente_logico'] = id_ambiente_logico\n        ambiente_map['id_divisao'] = id_divisao\n        ambiente_map['id_filter'] = id_filter\n        ambiente_map['link'] = link\n        ambiente_map['acl_path'] = acl_path\n        ambiente_map['ipv4_template'] = ipv4_template\n        ambiente_map['ipv6_template'] = ipv6_template\n        ambiente_map['min_num_vlan_1'] = min_num_vlan_1\n        ambiente_map['max_num_vlan_1'] = max_num_vlan_1\n        ambiente_map['min_num_vlan_2'] = min_num_vlan_2\n        ambiente_map['max_num_vlan_2'] = max_num_vlan_2\n        ambiente_map['vrf'] = vrf\n\n        code, xml = self.submit(\n            {'ambiente': ambiente_map}, 'POST', 'ambiente/')\n\n        return self.response(code, xml)", "response": "Insere um novo ambiente e retorna o seu identificador."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef insert_with_ip_range(\n            self,\n            id_l3_group,\n            id_logical_environment,\n            id_division,\n            id_ip_config,\n            link,\n            id_filter=None):\n        \"\"\"Insert new environment with ip config and returns your id.\n\n        :param id_l3_group: Layer 3 Group ID.\n        :param id_logical_environment: Logical Environment ID.\n        :param id_division: Data Center Division ID.\n        :param id_filter: Filter identifier.\n        :param id_ip_config: IP Configuration ID.\n        :param link: Link.\n\n        :return: Following dictionary: {'ambiente': {'id': < id >}}\n\n        :raise ConfigEnvironmentDuplicateError: Error saving duplicate Environment Configuration.\n        :raise InvalidParameterError: Some parameter was invalid.\n        :raise GrupoL3NaoExisteError: Layer 3 Group not found.\n        :raise AmbienteLogicoNaoExisteError: Logical Environment not found.\n        :raise DivisaoDcNaoExisteError: Data Center Division not found.\n        :raise AmbienteDuplicadoError: Environment with this parameters already exists.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        environment_map = dict()\n        environment_map['id_grupo_l3'] = id_l3_group\n        environment_map['id_ambiente_logico'] = id_logical_environment\n        environment_map['id_divisao'] = id_division\n        environment_map['id_filter'] = id_filter\n        environment_map['id_ip_config'] = id_ip_config\n        environment_map['link'] = link\n\n        code, xml = self.submit(\n            {'ambiente': environment_map}, 'POST', 'ambiente/ipconfig/')\n\n        return self.response(code, xml)", "response": "Inserts new environment with ip config and returns your id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd an environment with an ip config and returns your id.", "response": "def add_ip_range(self, id_environment, id_ip_config):\n        \"\"\"Makes relationship of environment with ip config and returns your id.\n\n        :param id_environment: Environment ID.\n        :param id_ip_config: IP Configuration ID.\n\n        :return: Following dictionary:\n\n        {'config_do_ambiente': {'id_config_do_ambiente': < id_config_do_ambiente >}}\n\n        :raise InvalidParameterError: Some parameter was invalid.\n        :raise ConfigEnvironmentDuplicateError: Error saving duplicate Environment Configuration.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        environment_map = dict()\n        environment_map['id_environment'] = id_environment\n        environment_map['id_ip_config'] = id_ip_config\n\n        code, xml = self.submit(\n            {'ambiente': environment_map}, 'POST', 'ipconfig/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninserts a new healthcheck_expect with only expect_string.", "response": "def add_expect_string_healthcheck(self, expect_string):\n        \"\"\"Inserts a new healthckeck_expect  with only expect_string.\n\n        :param expect_string: expect_string.\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {'healthcheck_expect': {'id': < id >}}\n\n        :raise InvalidParameterError: The value of expect_string is invalid.\n        :raise HealthCheckExpectJaCadastradoError: There is already a healthcheck_expect registered with the same data.\n        :raise HealthCheckExpectNaoExisteError: Healthcheck_expect not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n\n        \"\"\"\n\n        healthcheck_map = dict()\n        healthcheck_map['expect_string'] = expect_string\n\n        url = 'healthcheckexpect/add/expect_string/'\n\n        code, xml = self.submit({'healthcheck': healthcheck_map}, 'POST', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all expect_string. :return: Dictionary with the following structure: :: {'healthcheck_expect': [ 'expect_string': < expect_string >, ... demais healthcheck_expects ...]} :raise InvalidParameterError: Identifier is null and invalid. :raise DataBaseError: Networkapi failed to access the database. :raise XMLError: Networkapi failed to generate the XML response.", "response": "def listar_healtchcheck_expect_distinct(self):\n        \"\"\"Get all expect_string.\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {'healthcheck_expect': [\n             'expect_string': < expect_string >,\n             ... demais healthcheck_expects ...]}\n\n\n        :raise InvalidParameterError: Identifier is null and invalid.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        url = 'healthcheckexpect/distinct/busca/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_acl_path(self):\n\n        url = 'environment/acl_path/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)", "response": "Get all distinct acl paths."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the template value.", "response": "def set_template(self, id_environment, name, network):\n        \"\"\"Set template value. If id_environment = 0, set '' to all environments related with the template name.\n\n        :param id_environment: Environment Identifier.\n        :param name: Template Name.\n        :param network: IPv4 or IPv6.\n\n        :return: None\n\n        :raise InvalidParameterError: Invalid param.\n        :raise AmbienteNaoExisteError: Ambiente n\u00e3o cadastrado.\n        :raise DataBaseError: Falha na networkapi ao acessar o banco de dados.\n        :raise XMLError: Falha na networkapi ao ler o XML de requisi\u00e7\u00e3o ou gerar o XML de resposta.\n        \"\"\"\n\n        url = 'environment/set_template/' + str(id_environment) + '/'\n\n        environment_map = dict()\n        environment_map['name'] = name\n        environment_map['network'] = network\n\n        code, xml = self.submit({'environment': environment_map}, 'POST', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets environments by template name.", "response": "def get_environment_template(self, name, network):\n        \"\"\"Get environments by template name\n\n        :param name: Template name.\n        :param network: IPv4 or IPv6.\n\n        :return: Following dictionary:\n\n        ::\n\n            {'ambiente': [divisao_dc - ambiente_logico - grupo_l3, other envs...] }\n\n        :raise InvalidParameterError: Invalid param.\n        :raise DataBaseError: Falha na networkapi ao acessar o banco de dados.\n        :raise XMLError: Falha na networkapi ao ler o XML de requisi\u00e7\u00e3o ou gerar o XML de resposta.\n        \"\"\"\n        url = 'environment/get_env_template/'\n\n        map_dict = dict()\n        map_dict['name'] = name\n        map_dict['network'] = network\n\n        code, xml = self.submit({'map': map_dict}, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_blocks(self, id_env, blocks):\n\n        url = 'environment/save_blocks/'\n\n        map_dict = dict()\n\n        map_dict['id_env'] = id_env\n        map_dict['blocks'] = blocks\n\n        code, xml = self.submit({'map': map_dict}, 'POST', url)\n\n        return self.response(code, xml)", "response": "Save blocks from environment id_env"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_rule_by_pk(self, id_rule):\n        url = 'rule/get_by_id/' + str(id_rule)\n        code, xml = self.submit(None, 'GET', url)\n        return self.response(code, xml)", "response": "Get a rule by its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving a rule in an environment.", "response": "def save_rule(self, name, id_env, contents, blocks_id):\n        \"\"\"\n        Save an environment rule\n\n        :param name: Name of the rule\n        :param id_env: Environment id\n        :param contents: Lists of contents in order. Ex: ['content one', 'content two', ...]\n        :param blocks_id: Lists of blocks id or 0 if is as custom content. Ex: ['0', '5', '0' ...]\n\n        :return: None\n\n        :raise AmbienteNaoExisteError: Ambiente n\u00e3o cadastrado.\n        :raise InvalidValueError: Invalid parameter.\n        :raise UserNotAuthorizedError: Permiss\u00e3o negada.\n        :raise DataBaseError: Falha na networkapi ao acessar o banco de dados.\n        :raise XMLError: Falha na networkapi ao ler o XML de requisi\u00e7\u00e3o ou gerar o XML de resposta.\n        \"\"\"\n\n        url = 'rule/save/'\n\n        map_dict = dict()\n\n        map_dict['name'] = name\n        map_dict['id_env'] = id_env\n        map_dict['contents'] = contents\n        map_dict['blocks_id'] = blocks_id\n\n        code, xml = self.submit({'map': map_dict}, 'POST', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates an environment rule.", "response": "def update_rule(self, name, id_env, contents, blocks_id, id_rule):\n        \"\"\"\n        Save an environment rule\n\n        :param name: Name of the rule\n        :param id_env: Environment id\n        :param contents: Lists of contents in order. Ex: ['content one', 'content two', ...]\n        :param blocks_id: Lists of blocks id or 0 if is as custom content. Ex: ['0', '5', '0' ...]\n        :param id_rule: Rule id\n\n        :return: None\n\n        :raise AmbienteNaoExisteError: Ambiente n\u00e3o cadastrado.\n        :raise InvalidValueError: Invalid parameter.\n        :raise UserNotAuthorizedError: Permiss\u00e3o negada.\n        :raise DataBaseError: Falha na networkapi ao acessar o banco de dados.\n        :raise XMLError: Falha na networkapi ao ler o XML de requisi\u00e7\u00e3o ou gerar o XML de resposta.\n        \"\"\"\n\n        url = 'rule/update/'\n\n        map_dict = dict()\n\n        map_dict['name'] = name\n        map_dict['id_env'] = id_env\n        map_dict['contents'] = contents\n        map_dict['blocks_id'] = blocks_id\n        map_dict['id_rule'] = id_rule\n\n        try:\n            code, xml = self.submit({'map': map_dict}, 'PUT', url)\n        except Exception as e:\n            raise e\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all rules for an environment.", "response": "def get_all_rules(self, id_env):\n        \"\"\"Save an environment rule\n\n        :param id_env: Environment id\n\n        :return: Estrutura:\n\n        ::\n\n            { 'rules': [{'id': < id >,\n            'environment': < Environment Object >,\n            'content': < content >,\n            'name': < name >,\n            'custom': < custom > },... ]}\n\n        :raise AmbienteNaoExisteError: Ambiente n\u00e3o cadastrado.\n        :raise UserNotAuthorizedError: Permiss\u00e3o negada.\n        :raise DataBaseError: Falha na networkapi ao acessar o banco de dados.\n        :raise XMLError: Falha na networkapi ao ler o XML de requisi\u00e7\u00e3o ou gerar o XML de resposta.\n        \"\"\"\n\n        url = 'rule/all/' + str(id_env)\n        code, xml = self.submit(None, 'GET', url)\n        return self.response(code, xml, ['rules'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds new prefix configuration to the specified environment.", "response": "def configuration_save(\n            self,\n            id_environment,\n            network,\n            prefix,\n            ip_version,\n            network_type):\n        \"\"\"\n        Add new prefix configuration\n\n        :param id_environment: Identifier of the Environment. Integer value and greater than zero.\n        :param network: Network Ipv4 or Ipv6.\n        :param prefix: Prefix 0-32 to Ipv4 or 0-128 to Ipv6.\n        :param ip_version: v4 to IPv4 or v6 to IPv6\n        :param network_type: type network\n\n        :return: Following dictionary:\n\n        ::\n\n            {'network':{'id_environment': <id_environment>,\n            'id_vlan': <id_vlan>,\n            'network_type': <network_type>,\n            'network': <network>,\n            'prefix': <prefix>} }\n\n        :raise ConfigEnvironmentInvalidError: Invalid Environment Configuration or not registered.\n        :raise InvalidValueError: Invalid Id for environment or network or network_type or prefix.\n        :raise AmbienteNotFoundError: Environment not registered.\n        :raise DataBaseError: Failed into networkapi access data base.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        network_map = dict()\n        network_map['id_environment'] = id_environment\n        network_map['network'] = network\n        network_map['prefix'] = prefix\n        network_map['ip_version'] = ip_version\n        network_map['network_type'] = network_type\n\n        code, xml = self.submit(\n            {'ambiente': network_map}, 'POST', 'environment/configuration/save/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists all prefix configurations by environment in DB", "response": "def configuration_list_all(self, environment_id):\n        \"\"\"\n        List all prefix configurations by environment in DB\n\n        :return: Following dictionary:\n\n        ::\n\n            {'lists_configuration': [{\n            'id': <id_ipconfig>,\n            'subnet': <subnet>,\n            'type': <type>,\n            'new_prefix': <new_prefix>,\n            }, ... ]}\n\n\n        :raise InvalidValueError: Invalid ID for Environment.\n        :raise AmbienteNotFoundError: Environment not registered.\n        :raise DataBaseError: Failed into networkapi access data base.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        data = dict()\n        data[\"environment_id\"] = environment_id\n\n        url = (\"environment/configuration/list/%(environment_id)s/\" % data)\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml, force_list=['lists_configuration'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef configuration_remove(self, environment_id, configuration_id):\n\n        data = dict()\n\n        data[\"configuration_id\"] = configuration_id\n        data[\"environment_id\"] = environment_id\n\n        url = (\n            \"environment/configuration/remove/%(environment_id)s/%(configuration_id)s/\" %\n            data)\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Remove a specific configuration from an environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nassociating a news Environment on Environment VIP and returns its identifier.", "response": "def associate(self, environment_id, environment_vip_id):\n\n        \"\"\"Associate a news Environment on Environment VIP and returns its identifier.\n\n        :param environment_id: Identifier of the Environment. Integer value and greater than zero.\n        :param environment_vip_id: Identifier of the Environment VIP. Integer value and greater than zero.\n\n        :return: Following dictionary:\n\n        ::\n\n            {'environment_environment_vip': {'id': < id >}}\n\n        :raise InvalidParameterError: The value of environment_id or environment_vip_id is invalid.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        if not is_valid_int_param(environment_id):\n            raise InvalidParameterError(\n                u'The identifier of Environment VIP is invalid or was not informed.')\n\n        if not is_valid_int_param(environment_vip_id):\n            raise InvalidParameterError(\n                u'The identifier of Environment is invalid or was not informed.')\n\n        environment_environment_vip_map = dict()\n        environment_environment_vip_map['environment_id'] = environment_id\n        environment_environment_vip_map['environment_vip_id'] = environment_vip_id\n\n        url = 'environment/{}/environmentvip/{}/'.format(environment_id, environment_vip_id)\n\n        code, xml = self.submit(None, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_related_environment_list(self, environment_vip_id):\n\n        url = 'environment/environmentvip/{}/'.format(environment_vip_id)\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml, ['environment_related_list'])", "response": "Get all related Environment by Environment Vip."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning list environments related with environment vip", "response": "def get_equipment(self, **kwargs):\n        \"\"\"\n        Return list environments related with environment vip\n        \"\"\"\n\n        uri = 'api/v3/equipment/'\n        uri = self.prepare_url(uri, kwargs)\n\n        return super(ApiEquipment, self).get(uri)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search(self, **kwargs):\n\n        return super(ApiEquipment, self).get(self.prepare_url('api/v3/equipment/',\n                                                              kwargs))", "response": "Method to search equipments based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, ids):\n        url = build_uri_with_ids('api/v3/equipment/%s/', ids)\n        return super(ApiEquipment, self).delete(url)", "response": "Method to delete equipments by their id s\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(self, equipments):\n\n        data = {'equipments': equipments}\n        return super(ApiEquipment, self).post('api/v3/equipment/', data)", "response": "Method to create equipments on database"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, ids):\n        url = build_uri_with_ids('api/v3/pool/deploy/%s/', ids)\n\n        return super(ApiPoolDeploy, self).delete(url)", "response": "Method to undeploy pool s by their ids\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef edit_reals(\n            self,\n            id_vip,\n            method_bal,\n            reals,\n            reals_prioritys,\n            reals_weights,\n            alter_priority=0):\n        \"\"\"Execute the script 'gerador_vips' several times with options -real, -add and -del to adjust vip request reals.\n        :param id_vip: Identifier of the VIP. Integer value and greater than zero.\n        :param method_bal: method_bal.\n        :param reals: List of reals. Ex: [{'real_name':'Teste1', 'real_ip':'10.10.10.1'},{'real_name':'Teste2', 'real_ip':'10.10.10.2'}]\n        :param reals_prioritys: List of reals_priority. Ex: ['1','5','3'].\n        :param reals_weights: List of reals_weight. Ex: ['1','5','3'].\n        :param alter_priority: 1 if priority has changed and 0 if hasn't changed.\n        :return: None\n        :raise VipNaoExisteError: Request VIP not registered.\n        :raise InvalidParameterError: Identifier of the request is invalid or null VIP.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        :raise EnvironmentVipError: The combination of finality, client and environment is invalid.\n        :raise InvalidTimeoutValueError: The value of timeout is invalid.\n        :raise InvalidBalMethodValueError: The value of method_bal is invalid.\n        :raise InvalidCacheValueError: The value of cache is invalid.\n        :raise InvalidPersistenceValueError: The value of persistence is invalid.\n        :raise InvalidPriorityValueError: One of the priority values is invalid.\n        :raise EquipamentoNaoExisteError: The equipment associated with this Vip Request doesn't exist.\n        :raise IpEquipmentError: Association between equipment and ip of this Vip Request doesn't exist.\n        :raise IpError: IP not registered.\n        :raise RealServerPriorityError: Vip Request priority list has an error.\n        :raise RealServerWeightError: Vip Request weight list has an error.\n        :raise RealServerPortError: Vip Request port list has an error.\n        :raise RealParameterValueError: Vip Request real server parameter list has an error.\n        :raise RealServerScriptError: Vip Request real server script execution error.\n        \"\"\"\n\n        if not is_valid_int_param(id_vip):\n            raise InvalidParameterError(\n                u'The identifier of vip is invalid or was not informed.')\n\n        vip_map = dict()\n        vip_map['vip_id'] = id_vip\n        # vip_map['metodo_bal'] = method_bal\n        vip_map['reals'] = {'real': reals}\n        vip_map['reals_prioritys'] = {'reals_priority': reals_prioritys}\n        vip_map['reals_weights'] = {'reals_weight': reals_weights}\n        vip_map['alter_priority'] = alter_priority\n\n        url = 'vip/real/edit/'\n\n        code, xml = self.submit({'vip': vip_map}, 'PUT', url)\n\n        return self.response(code, xml)", "response": "Execute the script 'gerador_vips' several times with options -real, -add and -del to adjust vip request reals.\n        :param id_vip: Identifier of the VIP. Integer value and greater than zero.\n        :param method_bal: method_bal.\n        :param reals: List of reals. Ex: [{'real_name':'Teste1', 'real_ip':'10.10.10.1'},{'real_name':'Teste2', 'real_ip':'10.10.10.2'}]\n        :param reals_prioritys: List of reals_priority. Ex: ['1','5','3'].\n        :param reals_weights: List of reals_weight. Ex: ['1','5','3'].\n        :param alter_priority: 1 if priority has changed and 0 if hasn't changed.\n        :return: None\n        :raise VipNaoExisteError: Request VIP not registered.\n        :raise InvalidParameterError: Identifier of the request is invalid or null VIP.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        :raise EnvironmentVipError: The combination of finality, client and environment is invalid.\n        :raise InvalidTimeoutValueError: The value of timeout is invalid.\n        :raise InvalidBalMethodValueError: The value of method_bal is invalid.\n        :raise InvalidCacheValueError: The value of cache is invalid.\n        :raise InvalidPersistenceValueError: The value of persistence is invalid.\n        :raise InvalidPriorityValueError: One of the priority values is invalid.\n        :raise EquipamentoNaoExisteError: The equipment associated with this Vip Request doesn't exist.\n        :raise IpEquipmentError: Association between equipment and ip of this Vip Request doesn't exist.\n        :raise IpError: IP not registered.\n        :raise RealServerPriorityError: Vip Request priority list has an error.\n        :raise RealServerWeightError: Vip Request weight list has an error.\n        :raise RealServerPortError: Vip Request port list has an error.\n        :raise RealParameterValueError: Vip Request real server parameter list has an error.\n        :raise RealServerScriptError: Vip Request real server script execution error."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninserting a new Brand and returns its identifier.", "response": "def inserir(self, name):\n        \"\"\"Inserts a new Brand and returns its identifier\n\n        :param name: Brand name. String with a minimum 3 and maximum of 100 characters\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {'marca': {'id': < id_brand >}}\n\n        :raise InvalidParameterError: Name is null and invalid.\n        :raise NomeMarcaDuplicadoError: There is already a registered Brand with the value of name.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        brand_map = dict()\n        brand_map['name'] = name\n\n        code, xml = self.submit({'brand': brand_map}, 'POST', 'brand/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchanges the name of the Brand from by the identifier.", "response": "def alterar(self, id_brand, name):\n        \"\"\"Change Brand from by the identifier.\n\n        :param id_brand: Identifier of the Brand. Integer value and greater than zero.\n        :param name: Brand name. String with a minimum 3 and maximum of 100 characters\n\n        :return: None\n\n        :raise InvalidParameterError: The identifier of Brand or name is null and invalid.\n        :raise NomeMarcaDuplicadoError: There is already a registered Brand with the value of name.\n        :raise MarcaNaoExisteError: Brand not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_brand):\n            raise InvalidParameterError(\n                u'The identifier of Brand is invalid or was not informed.')\n\n        url = 'brand/' + str(id_brand) + '/'\n\n        brand_map = dict()\n        brand_map['name'] = name\n\n        code, xml = self.submit({'brand': brand_map}, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remover(self, id_brand):\n\n        if not is_valid_int_param(id_brand):\n            raise InvalidParameterError(\n                u'The identifier of Brand is invalid or was not informed.')\n\n        url = 'brand/' + str(id_brand) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Remove Brand from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef acl_remove_draft(self, id_vlan, type_acl):\n\n        parameters = dict(id_vlan=id_vlan, type_acl=type_acl)\n\n        uri = 'api/vlan/acl/remove/draft/%(id_vlan)s/%(type_acl)s/' % parameters\n\n        return super(ApiVlan, self).get(uri)", "response": "Method to remove Acl draft by type"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves Acl draft by type", "response": "def acl_save_draft(self, id_vlan, type_acl, content_draft):\n        \"\"\"\n            Save Acl draft by type\n\n            :param id_vlan: Identity of Vlan\n            :param type_acl: Acl type v4 or v6\n\n            :return: None\n\n            :raise VlanDoesNotExistException: Vlan Does Not Exist.\n            :raise InvalidIdVlanException: Invalid id for Vlan.\n            :raise NetworkAPIException: Failed to access the data source.\n        \"\"\"\n\n        parameters = dict(id_vlan=id_vlan, type_acl=type_acl)\n\n        data = dict(content_draft=content_draft)\n\n        uri = 'api/vlan/acl/save/draft/%(id_vlan)s/%(type_acl)s/' % parameters\n\n        return super(ApiVlan, self).post(uri, data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search(self, **kwargs):\n\n        return super(ApiVlan, self).get(self.prepare_url('api/v3/vlan/',\n                                                         kwargs))", "response": "Method to search vlan s based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(self, vlans):\n\n        data = {'vlans': vlans}\n        return super(ApiVlan, self).post('api/v3/vlan/', data)", "response": "Method to create vlan s\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_valid_int_param(param):\n    if param is None:\n        return False\n    try:\n        param = int(param)\n        if param < 0:\n            return False\n    except (TypeError, ValueError):\n        return False\n    return True", "response": "Verifica se o par\u00e2metro \u00e9 um valor inteiro v\u00e1lido."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_valid_version_ip(param):\n    if param is None:\n        return False\n\n    if param == IP_VERSION.IPv4[0] or param == IP_VERSION.IPv6[0]:\n        return True\n\n    return False", "response": "Checks if the parameter is a valid ip version value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef option_vip_by_environmentvip(self, environment_vip_id):\n\n        uri = 'api/v3/option-vip/environment-vip/%s/' % environment_vip_id\n\n        return super(ApiVipRequest, self).get(uri)", "response": "Method to list Option Vip by Environment Vip"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_vip_request_details(self, vip_request_id):\n        uri = 'api/v3/vip-request/details/%s/' % vip_request_id\n\n        return super(ApiVipRequest, self).get(uri)", "response": "Method to get details of vip request"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_vip_request(self, vip_request_id):\n        uri = 'api/v3/vip-request/%s/' % vip_request_id\n\n        return super(ApiVipRequest, self).get(uri)", "response": "Method to get vip request"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search_vip_request(self, search):\n        uri = 'api/v3/vip-request/?%s' % urllib.urlencode({'search': search})\n\n        return super(ApiVipRequest, self).get(uri)", "response": "Method to list vip request"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_vip_request(self, vip_request, vip_request_id):\n        uri = 'api/v3/vip-request/%s/' % vip_request_id\n\n        data = dict()\n        data['vips'] = list()\n        data['vips'].append(vip_request)\n\n        return super(ApiVipRequest, self).put(uri, data)", "response": "Method to update vip request object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search(self, **kwargs):\n\n        return super(ApiVipRequest, self).get(self.prepare_url('api/v3/vip-request/',\n                                                               kwargs))", "response": "Method to search vip s based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, tipo_opcao, nome_opcao):\n        #optionpool_map = dict()\n        #optionpool_map['type'] = tipo_opcao\n        #optionpool_map['name'] = nome_opcao\n\n        url='api/pools/options/save/'\n\n        return self.post(url, {'type': tipo_opcao, \"name\":nome_opcao })", "response": "Inserts a new Option Pool and returns its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nchange the type of an option pool from by id.", "response": "def modify(self, id_option_pool, tipo_opcao, nome_opcao):\n        \"\"\"Change Option Pool from by id.\n\n        :param id_option_pool: Identifier of the Option Pool. Integer value and greater than zero.\n        :param tipo_opcao: Type. String with a maximum of 50 characters and respect [a-zA-Z\\_-]\n        :param nome_opcao_txt: Name Option. String with a maximum of 50 characters and respect [a-zA-Z\\_-]\n\n        :return: None\n\n        :raise InvalidParameterError: Option Pool identifier is null or invalid.\n        :raise InvalidParameterError: The value of tipo_opcao or nome_opcao_txt is invalid.\n        :raise optionpoolNotFoundError: Option pool not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_option_pool):\n            raise InvalidParameterError(\n                u'The identifier of Option Pool is invalid or was not informed.')\n\n        #optionpool_map = dict()\n        #optionpool_map['type'] = tipo_opcao\n        #optionpool_map['name'] = nome_opcao_txt\n\n        url = 'api/pools/options/' + str(id_option_pool) + '/'\n\n        return self.put(url,{'type': tipo_opcao, \"name\":nome_opcao } )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving an option pool by identifier.", "response": "def remove(self, id_option_pool):\n        \"\"\"Remove Option pool  by  identifier and all Environment related .\n\n        :param id_option_pool: Identifier of the Option Pool. Integer value and greater than zero.\n\n        :return: None\n\n        :raise InvalidParameterError: Option Pool identifier is null and invalid.\n        :raise optionpoolNotFoundError: Option Pool not registered.\n        :raise optionpoolError: Option Pool associated with Pool.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_option_pool):\n            raise InvalidParameterError(\n                u'The identifier of Option Pool is invalid or was not informed.')\n\n        url = 'api/pools/options/' + str(id_option_pool) + '/'\n\n        return self.delete(url)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_option_pool(self, id_option_pool):\n\n        if not is_valid_int_param(id_option_pool):\n            raise InvalidParameterError(\n                u'The identifier of Option Pool is invalid or was not informed.')\n\n        url = 'api/pools/options/' + str(id_option_pool) + '/'\n\n        return self.get(url)", "response": "Search Option Pool by id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget all option pool.", "response": "def get_all_option_pool(self, option_type=None):\n        \"\"\"Get all Option Pool.\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {[{\u2018id\u2019: < id >,\n            \u2018type\u2019: < tipo_opcao >,\n            \u2018name\u2019: < nome_opcao_txt >}, ... other option pool ...] }\n\n        :raise optionpoolNotFoundError: Option Pool not registered.\n        :raise DataBaseError: Can't connect to networkapi database.\n        :raise XMLError: Failed to generate the XML response.\n        \"\"\"\n        if option_type:\n            url = 'api/pools/options/?type='+option_type\n        else:\n            url = 'api/pools/options/'\n\n\n        return self.get(url)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all environment option pool by environment.", "response": "def get_all_environment_option_pool(self, id_environment=None, option_id=None, option_type=None):\n        \"\"\"Get all Option VIP by Environment .\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {[{\u2018id\u2019: < id >,\n                option: {\n                    'id': <id>\n                    'type':<type>\n                    'name':<name> }\n                environment: {\n                    'id':<id>\n                    .... all environment info }\n                    etc to option pools ...] }\n\n        :raise EnvironmentVipNotFoundError: Environment Pool not registered.\n        :raise DataBaseError: Can't connect to networkapi database.\n        :raise XMLError: Failed to generate the XML response.\n        \"\"\"\n        url='api/pools/environment_options/'\n\n        if id_environment:\n            if  option_id:\n                if option_type:\n                    url = url + \"?environment_id=\" + str(id_environment)+ \"&option_id=\" + str(option_id)  + \"&option_type=\" + option_type\n                else:\n                    url = url + \"?environment_id=\" + str(id_environment)+ \"&option_id=\" + str(option_id)\n            else:\n                if option_type:\n                    url = url + \"?environment_id=\" + str(id_environment) + \"&option_type=\" + option_type\n                else:\n                    url = url + \"?environment_id=\" + str(id_environment)\n        elif option_id:\n            if option_type:\n                url = url + \"?option_id=\" + str(option_id)  + \"&option_type=\" + option_type\n            else:\n                url = url + \"?option_id=\" + str(option_id)\n        elif option_type:\n            url = url + \"?option_type=\" + option_type\n\n\n        return self.get(url)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef associate_environment_option_pool(self, id_option_pool, id_environment):\n\n        if not is_valid_int_param(id_option_pool):\n            raise InvalidParameterError(\n                u'The identifier of Option Pool is invalid or was not informed.')\n\n        if not is_valid_int_param(id_environment):\n            raise InvalidParameterError(\n                u'The identifier of Environment Pool is invalid or was not informed.')\n\n\n\n        url= 'api/pools/environment_options/save/'\n\n        return self.post(url,  {'option_id': id_option_pool,\"environment_id\":id_environment })", "response": "This method associates an option pool with an Environment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef disassociate_environment_option_pool(self, environment_option_id):\n\n        if not is_valid_int_param(environment_option_id):\n            raise InvalidParameterError(\n                u'The identifier of Option Pool is invalid or was not informed.')\n\n        if not is_valid_int_param(environment_option_id):\n            raise InvalidParameterError(\n                u'The identifier of Environment Pool is invalid or was not informed.')\n\n        url = 'api/pools/environment_options/' + str(environment_option_id) +  '/'\n\n        return self.delete(url)", "response": "Remove a relationship of an option pool with an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef modify_environment_option_pool(self, environment_option_id, id_option_pool,id_environment ):\n\n        if not is_valid_int_param(environment_option_id):\n            raise InvalidParameterError(\n                u'The identifier of Environment Option Pool is invalid or was not informed.')\n\n        #optionpool_map = dict()\n        #optionpool_map['option'] = option_id\n        #optionpool_map['environment'] = environment_id\n\n\n        url = 'api/pools/environment_options/' + str(environment_option_id) +  '/'\n\n        return self.put(url, {'option_id': id_option_pool,\"environment_id\":id_environment })", "response": "Modify an existing option pool with an Environment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add(self, name, description):\n        filter_map = dict()\n        filter_map['name'] = name\n        filter_map['description'] = description\n\n        code, xml = self.submit({'filter': filter_map}, 'POST', 'filter/')\n\n        return self.response(code, xml)", "response": "Inserts a new filter and returns its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nchange the name or description of a specific filter.", "response": "def alter(self, id_filter, name, description):\n        \"\"\"Change Filter by the identifier.\n\n        :param id_filter: Identifier of the Filter. Integer value and greater than zero.\n        :param name: Name. String with a maximum of 50 characters and respect [a-zA-Z\\_-]\n        :param description: Description. String with a maximum of 50 characters and respect [a-zA-Z\\_-]\n\n        :return: None\n\n        :raise InvalidParameterError: Filter identifier is null and invalid.\n        :raise InvalidParameterError: The value of name or description is invalid.\n        :raise FilterNotFoundError: Filter not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_filter):\n            raise InvalidParameterError(\n                u'The identifier of Filter is invalid or was not informed.')\n\n        filter_map = dict()\n        filter_map['name'] = name\n        filter_map['description'] = description\n\n        url = 'filter/' + str(id_filter) + '/'\n\n        code, xml = self.submit({'filter': filter_map}, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove(self, id_filter):\n\n        if not is_valid_int_param(id_filter):\n            raise InvalidParameterError(\n                u'The identifier of Filter is invalid or was not informed.')\n\n        url = 'filter/' + str(id_filter) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Remove a Filter by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget filter by id.", "response": "def get(self, id_filter):\n        \"\"\"Get filter by id.\n\n        :param id_filter: Identifier of the Filter. Integer value and greater than zero.\n\n        :return: Following dictionary:\n\n        ::\n\n            {\u2018filter\u2019: {\u2018id\u2019: < id >,\n            \u2018name\u2019: < name >,\n            \u2018description\u2019: < description >}}\n\n        :raise InvalidParameterError: The value of id_filter is invalid.\n        :raise FilterNotFoundError: Filter not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        url = 'filter/get/' + str(id_filter) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef associate(self, et_id, id_filter):\n\n        if not is_valid_int_param(et_id):\n            raise InvalidParameterError(\n                u'The identifier of TipoEquipamento is invalid or was not informed.')\n\n        if not is_valid_int_param(id_filter):\n            raise InvalidParameterError(\n                u'The identifier of Filter is invalid or was not informed.')\n\n        url = 'filter/' + str(id_filter) + '/equiptype/' + str(et_id) + '/'\n\n        code, xml = self.submit(None, 'PUT', url)\n\n        return self.response(code, xml)", "response": "Create a relationship between TipoEquipamento and Filter."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving relationship between Filter and TipoEquipamento.", "response": "def dissociate(self, id_filter, id_eq_type):\n        \"\"\"Removes relationship between Filter and TipoEquipamento.\n\n        :param id_filter: Identifier of Filter. Integer value and greater than zero.\n        :param id_eq_type: Identifier of TipoEquipamento. Integer value, greater than zero.\n\n        :return: None\n\n        :raise FilterNotFoundError: Filter not registered.\n        :raise TipoEquipamentoNotFoundError: TipoEquipamento not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_filter):\n            raise InvalidParameterError(\n                u'The identifier of Filter is invalid or was not informed.')\n\n        if not is_valid_int_param(id_eq_type):\n            raise InvalidParameterError(\n                u'The identifier of TipoEquipamento is invalid or was not informed.')\n\n        url = 'filter/' + \\\n            str(id_filter) + '/dissociate/' + str(id_eq_type) + '/'\n\n        code, xml = self.submit(None, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch Group Equipament from by the identifier.", "response": "def search(self, id_egroup):\n        \"\"\"Search Group Equipament from by the identifier.\n\n        :param id_egroup: Identifier of the Group Equipament. Integer value and greater than zero.\n\n        :return: Following dictionary:\n\n        ::\n\n            {\u2018group_equipament\u2019:  {\u2018id\u2019: < id_egrupo >,\n            \u2018nome\u2019: < nome >} }\n\n        :raise InvalidParameterError: Group Equipament identifier is null and invalid.\n        :raise GrupoEquipamentoNaoExisteError: Group Equipament not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_egroup):\n            raise InvalidParameterError(\n                u'The identifier of Group Equipament is invalid or was not informed.')\n\n        url = 'egroup/' + str(id_egroup) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves um grupo de equipamento a partir do seu identificador.", "response": "def remover(self, id_egrupo):\n        \"\"\"Remove um grupo de equipamento a partir do seu identificador.\n\n        :param id_egrupo: Identificador do grupo de equipamento.\n\n        :return: None\n\n        :raise GrupoEquipamentoNaoExisteError: Grupo de equipamento n\u00e3o cadastrado.\n        :raise InvalidParameterError: O identificador do grupo \u00e9 nulo ou inv\u00e1lido.\n        :raise GroupDontRemoveError:\n        :raise DataBaseError: Falha na networkapi ao acessar o banco de dados.\n        :raise XMLError: Falha na networkapi ao gerar o XML de resposta.\n        \"\"\"\n        if not is_valid_int_param(id_egrupo):\n            raise InvalidParameterError(\n                u'O identificador do grupo de equipamento \u00e9 inv\u00e1lido ou n\u00e3o foi informado.')\n\n        url = 'egrupo/' + str(id_egrupo) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nassociates a new entry in a system with a grupo.", "response": "def associa_equipamento(self, id_equip, id_grupo_equipamento):\n        \"\"\"Associa um equipamento a um grupo.\n\n        :param id_equip: Identificador do equipamento.\n        :param id_grupo_equipamento: Identificador do grupo de equipamento.\n\n        :return: Dicion\u00e1rio com a seguinte estrutura:\n            {'equipamento_grupo':{'id': < id_equip_do_grupo >}}\n\n        :raise GrupoEquipamentoNaoExisteError: Grupo de equipamento n\u00e3o cadastrado.\n        :raise InvalidParameterError: O identificador do equipamento e/ou do grupo s\u00e3o nulos ou inv\u00e1lidos.\n        :raise EquipamentoNaoExisteError: Equipamento n\u00e3o cadastrado.\n        :raise EquipamentoError: Equipamento j\u00e1 est\u00e1 associado ao grupo.\n        :raise DataBaseError: Falha na networkapi ao acessar o banco de dados.\n        :raise XMLError: Falha na networkapi ao ler o XML de requisi\u00e7\u00e3o ou gerar o XML de resposta.\n        \"\"\"\n\n        equip_map = dict()\n        equip_map['id_grupo'] = id_grupo_equipamento\n        equip_map['id_equipamento'] = id_equip\n\n        code, xml = self.submit(\n            {'equipamento_grupo': equip_map}, 'POST', 'equipamentogrupo/associa/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove(self, id_equipamento, id_egrupo):\n\n        if not is_valid_int_param(id_egrupo):\n            raise InvalidParameterError(\n                u'O identificador do grupo de equipamento \u00e9 inv\u00e1lido ou n\u00e3o foi informado.')\n\n        if not is_valid_int_param(id_equipamento):\n            raise InvalidParameterError(\n                u'O identificador do equipamento \u00e9 inv\u00e1lido ou n\u00e3o foi informado.')\n\n        url = 'egrupo/equipamento/' + \\\n            str(id_equipamento) + '/egrupo/' + str(id_egrupo) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)", "response": "Removes a associacao de um grupo de equipamento com um equipamento a partir do seu identificador."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef inserir(self, name):\n\n        logical_environment_map = dict()\n        logical_environment_map['name'] = name\n\n        code, xml = self.submit(\n            {'logical_environment': logical_environment_map}, 'POST', 'logicalenvironment/')\n\n        return self.response(code, xml)", "response": "Inserts a new Logical Environment and returns its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nchange the Logical Environment from by the identifier.", "response": "def alterar(self, id_logicalenvironment, name):\n        \"\"\"Change Logical Environment from by the identifier.\n\n        :param id_logicalenvironment: Identifier of the Logical Environment. Integer value and greater than zero.\n        :param name: Logical Environment name. String with a minimum 2 and maximum of 80 characters\n\n        :return: None\n\n        :raise InvalidParameterError: The identifier of Logical Environment or name is null and invalid.\n        :raise NomeAmbienteLogicoDuplicadoError: There is already a registered Logical Environment with the value of name.\n        :raise AmbienteLogicoNaoExisteError: Logical Environment not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_logicalenvironment):\n            raise InvalidParameterError(\n                u'The identifier of Logical Environment is invalid or was not informed.')\n\n        url = 'logicalenvironment/' + str(id_logicalenvironment) + '/'\n\n        logical_environment_map = dict()\n        logical_environment_map['name'] = name\n\n        code, xml = self.submit(\n            {'logical_environment': logical_environment_map}, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remover(self, id_logicalenvironment):\n\n        if not is_valid_int_param(id_logicalenvironment):\n            raise InvalidParameterError(\n                u'The identifier of Logical Environment is invalid or was not informed.')\n\n        url = 'logicalenvironment/' + str(id_logicalenvironment) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Remove Logical Environment from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_by_group(self, id_ugroup):\n\n        if id_ugroup is None:\n            raise InvalidParameterError(\n                u'The identifier of Group User is invalid or was not informed.')\n\n        url = 'aperms/group/' + str(id_ugroup) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)", "response": "Search Administrative Permission by Group User by identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search(self, id_perm):\n\n        if not is_valid_int_param(id_perm):\n            raise InvalidParameterError(\n                u'The identifier of Administrative Permission is invalid or was not informed.')\n\n        url = 'aperms/get/' + str(id_perm) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)", "response": "Search Administrative Permission from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inserir(self, id_permission, read, write, id_group):\n        perms_map = dict()\n        perms_map['id_permission'] = id_permission\n        perms_map['read'] = read\n        perms_map['write'] = write\n        perms_map['id_group'] = id_group\n\n        code, xml = self.submit(\n            {'administrative_permission': perms_map}, 'POST', 'aperms/')\n\n        return self.response(code, xml)", "response": "Inserts a new Administrative Permission and returns its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchanges Administrative Permission from by the identifier.", "response": "def alterar(self, id_perm, id_permission, read, write, id_group):\n        \"\"\"Change Administrative Permission from by the identifier.\n\n        :param id_perm: Identifier of the Administrative Permission. Integer value and greater than zero.\n        :param id_permission: Identifier of the Permission. Integer value and greater than zero.\n        :param read: Read. 0 or 1\n        :param write: Write. 0 or 1\n        :param id_group: Identifier of the Group of User. Integer value and greater than zero.\n\n        :return: None\n\n        :raise InvalidParameterError: The identifier of Administrative Permission, identifier of Permission, identifier of Group of User, read or  write is null and invalid.\n        :raise ValorIndicacaoPermissaoInvalidoError: The value of read or write is null and invalid.\n        :raise PermissaoAdministrativaNaoExisteError: Administrative Permission not registered.\n        :raise GrupoUsuarioNaoExisteError: Group of User not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        if not is_valid_int_param(id_perm):\n            raise InvalidParameterError(\n                u'The identifier of Administrative Permission is invalid or was not informed.')\n\n        url = 'aperms/' + str(id_perm) + '/'\n\n        perms_map = dict()\n        perms_map['id_perm'] = id_perm\n        perms_map['id_permission'] = id_permission\n        perms_map['read'] = read\n        perms_map['write'] = write\n        perms_map['id_group'] = id_group\n\n        code, xml = self.submit(\n            {'administrative_permission': perms_map}, 'PUT', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves Administrative Permission from by the identifier.", "response": "def remover(self, id_perms):\n        \"\"\"Remove Administrative Permission from by the identifier.\n\n        :param id_perms: Identifier of the Administrative Permission. Integer value and greater than zero.\n\n        :return: None\n\n        :raise InvalidParameterError: The identifier of Administrative Permission is null and invalid.\n        :raise PermissaoAdministrativaNaoExisteError: Administrative Permission not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        if not is_valid_int_param(id_perms):\n            raise InvalidParameterError(\n                u'The identifier of Administrative Permission is invalid or was not informed.')\n\n        url = 'aperms/' + str(id_perms) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting an instance of ambiente services facade.", "response": "def create_ambiente(self):\n        \"\"\"Get an instance of ambiente services facade.\"\"\"\n        return Ambiente(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_ambiente_logico(self):\n        return AmbienteLogico(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of ambiente_logico services facade."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets an instance of Api Environment Vip services facade.", "response": "def create_api_environment_vip(self):\n        \"\"\"Get an instance of Api Environment Vip services facade.\"\"\"\n        return ApiEnvironmentVip(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget an instance of Api Environment services facade.", "response": "def create_api_environment(self):\n        \"\"\"Get an instance of Api Environment services facade.\"\"\"\n        return ApiEnvironment(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_api_equipment(self):\n        return ApiEquipment(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of Api Equipment services facade."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_api_v4_equipment(self):\n        return ApiV4Equipment(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of Api V4 Equipment services facade."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets an instance of Api V4 As services facade.", "response": "def create_api_v4_as(self):\n        \"\"\"Get an instance of Api As services facade.\"\"\"\n        return ApiV4As(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_api_v4_virtual_interface(self):\n        return ApiV4VirtualInterface(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of Api Virtual Interface services facade."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget an instance of Api Neighbor services facade.", "response": "def create_api_v4_neighbor(self):\n        \"\"\"Get an instance of Api Neighbor services facade.\"\"\"\n        return ApiV4Neighbor(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting an instance of Api Interface Request services facade.", "response": "def create_api_interface_request(self):\n        \"\"\"Get an instance of Api Vip Requests services facade.\"\"\"\n\n        return ApiInterfaceRequest(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_api_ipv4(self):\n\n        return ApiIPv4(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of Api IPv4 services facade."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget an instance of Api IPv6 services facade.", "response": "def create_api_ipv6(self):\n        \"\"\"Get an instance of Api IPv6 services facade.\"\"\"\n\n        return ApiIPv6(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_api_v4_ipv4(self):\n\n        return ApiV4IPv4(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of Api V4 IPv4 services facade."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting an instance of Api V4 IPv6 services facade.", "response": "def create_api_v4_ipv6(self):\n        \"\"\"Get an instance of Api V4 IPv6 services facade.\"\"\"\n\n        return ApiV4IPv6(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_api_network_ipv4(self):\n\n        return ApiNetworkIPv4(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of Api Networkv4 services facade."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget an instance of Api Networkv6 services facade.", "response": "def create_api_network_ipv6(self):\n        \"\"\"Get an instance of Api Networkv6 services facade.\"\"\"\n\n        return ApiNetworkIPv6(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_api_option_vip(self):\n        return ApiOptionVip(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of Api Option Vip services facade."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget an instance of Api Pool services facade.", "response": "def create_api_pool(self):\n        \"\"\"Get an instance of Api Pool services facade.\"\"\"\n        return ApiPool(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_api_pool_deploy(self):\n        return ApiPoolDeploy(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of Api Pool Deploy services facade."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets an instance of Api Rack Variables services facade.", "response": "def create_apirack(self):\n        \"\"\"Get an instance of Api Rack Variables services facade.\"\"\"\n        return ApiRack(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_api_vip_request(self):\n\n        return ApiVipRequest(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap,\n            self.log_level)", "response": "Create an instance of Api Vip Requests services facade."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_api_object_type(self):\n\n        return ApiObjectType(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of Api Object Type services facade."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_api_object_group_permission(self):\n\n        return ApiObjectGroupPermission(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of Api Object Group Permission services facade."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_api_object_group_permission_general(self):\n\n        return ApiObjectGroupPermissionGeneral(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of Api Object Group Permission General services facade."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets an instance of Api Vlan services facade.", "response": "def create_api_vlan(self):\n        \"\"\"Get an instance of Api Vlan services facade.\"\"\"\n        return ApiVlan(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget an instance of Api Vrf services facade.", "response": "def create_api_vrf(self):\n        \"\"\"Get an instance of Api Vrf services facade.\"\"\"\n        return ApiVrf(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets an instance of block rule services facade.", "response": "def create_rule(self):\n        \"\"\"Get an instance of block rule services facade.\"\"\"\n        return BlockRule(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting an instance of direito_grupo_equipamento services facade.", "response": "def create_direito_grupo_equipamento(self):\n        \"\"\"Get an instance of direito_grupo_equipamento services facade.\"\"\"\n        return DireitoGrupoEquipamento(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget an instance of divisao_dc services facade.", "response": "def create_divisao_dc(self):\n        \"\"\"Get an instance of divisao_dc services facade.\"\"\"\n        return DivisaoDc(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget an instance of environment_vip services facade.", "response": "def create_environment_vip(self):\n        \"\"\"Get an instance of environment_vip services facade.\"\"\"\n        return EnvironmentVIP(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_equipamento(self):\n        return Equipamento(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of equipamento services facade."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_equipamento_acesso(self):\n        return EquipamentoAcesso(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of equipamento_acesso services facade."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets an instance of equipamento_ambiente services facade.", "response": "def create_equipamento_ambiente(self):\n        \"\"\"Get an instance of equipamento_ambiente services facade.\"\"\"\n        return EquipamentoAmbiente(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_equipamento_roteiro(self):\n        return EquipamentoRoteiro(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of equipamento_roteiro services facade."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_log(self):\n        return EventLog(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of log services facade."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_filter(self):\n        return Filter(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of filter services facade."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets an instance of grupo_equipamento services facade.", "response": "def create_grupo_equipamento(self):\n        \"\"\"Get an instance of grupo_equipamento services facade.\"\"\"\n        return GrupoEquipamento(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget an instance of grupo_l3 services facade.", "response": "def create_grupo_l3(self):\n        \"\"\"Get an instance of grupo_l3 services facade.\"\"\"\n        return GrupoL3(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets an instance of grupo_usuario services facade.", "response": "def create_grupo_usuario(self):\n        \"\"\"Get an instance of grupo_usuario services facade.\"\"\"\n        return GrupoUsuario(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_grupo_virtual(self):\n        return GrupoVirtual(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of grupo_virtual services facade."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_healthcheck(self):\n\n        return Healthcheck(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of Healthcheck services facade."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget an instance of interface services facade.", "response": "def create_interface(self):\n        \"\"\"Get an instance of interface services facade.\"\"\"\n        return Interface(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_ip(self):\n        return Ip(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of ip services facade."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_marca(self):\n        return Marca(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of marca services facade."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_modelo(self):\n        return Modelo(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of modelo services facade."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget an instance of DHCPRelayIPv4 services facade.", "response": "def create_dhcprelay_ipv4(self):\n        \"\"\"Get an instance of DHCPRelayIPv4 services facade.\"\"\"\n        return DHCPRelayIPv4(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting an instance of DHCPRelayIPv6 services facade.", "response": "def create_dhcprelay_ipv6(self):\n        \"\"\"Get an instance of DHCPRelayIPv6 services facade.\"\"\"\n        return DHCPRelayIPv6(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting an instance of vlan services facade.", "response": "def create_network(self):\n        \"\"\"Get an instance of vlan services facade.\"\"\"\n        return Network(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting an instance of option_pool services facade.", "response": "def create_option_pool(self):\n        \"\"\"Get an instance of option_pool services facade.\"\"\"\n        return OptionPool(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_option_vip(self):\n        return OptionVIP(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of option_vip services facade."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_permissao_administrativa(self):\n        return PermissaoAdministrativa(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of permissao_administrativa services facade."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_permission(self):\n        return Permission(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of permission services facade."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget an instance of Poll services facade.", "response": "def create_pool(self):\n        \"\"\"Get an instance of Poll services facade.\"\"\"\n\n        return Pool(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets an instance of rack services facade.", "response": "def create_rack(self):\n        \"\"\"Get an instance of rack services facade.\"\"\"\n        return Rack(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget an instance of rackservers services facade.", "response": "def create_rackservers(self):\n        \"\"\"Get an instance of rackservers services facade.\"\"\"\n        return RackServers(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_roteiro(self):\n        return Roteiro(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of roteiro services facade."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_system(self):\n        return System(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of Api System Variables services facade."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget an instance of tipo_acesso services facade.", "response": "def create_tipo_acesso(self):\n        \"\"\"Get an instance of tipo_acesso services facade.\"\"\"\n        return TipoAcesso(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_tipo_equipamento(self):\n        return TipoEquipamento(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of tipo_equipamento services facade."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_tipo_rede(self):\n        return TipoRede(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of tipo_rede services facade."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_tipo_roteiro(self):\n        return TipoRoteiro(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of tipo_roteiro services facade."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_usuario(self):\n        return Usuario(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of usuario services facade."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget an instance of usuario_grupo services facade.", "response": "def create_usuario_grupo(self):\n        \"\"\"Get an instance of usuario_grupo services facade.\"\"\"\n        return UsuarioGrupo(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_vip(self):\n        return Vip(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)", "response": "Get an instance of vip services facade."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget an instance of vlan services facade.", "response": "def create_vlan(self):\n        \"\"\"Get an instance of vlan services facade.\"\"\"\n        return Vlan(\n            self.networkapi_url,\n            self.user,\n            self.password,\n            self.user_ldap)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndeploy network in equipments and set column active = 1 in tables redeipv6", "response": "def deploy(self, id_networkv6):\n        \"\"\"Deploy network in equipments and set column 'active = 1' in tables redeipv6 ]\n\n        :param id_networkv6: ID for NetworkIPv6\n\n        :return: Equipments configuration output\n        \"\"\"\n\n        data = dict()\n        uri = 'api/networkv6/%s/equipments/' % id_networkv6\n\n        return super(ApiNetworkIPv6, self).post(uri, data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_by_id(self, id_networkv6):\n\n        uri = 'api/networkv4/%s/' % id_networkv6\n        return super(ApiNetworkIPv6, self).get(uri)", "response": "Get IPv6 network\n\n        by ID"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting networks in redeipv6", "response": "def list(self, environment_vip=None):\n        \"\"\"List networks redeipv6 ]\n\n        :param environment_vip: environment vip to filter\n\n        :return: IPv6 Networks\n        \"\"\"\n\n        uri = 'api/networkv6/?'\n        if environment_vip:\n            uri += 'environment_vip=%s' % environment_vip\n\n        return super(ApiNetworkIPv6, self).get(uri)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef undeploy(self, id_networkv6):\n\n        uri = 'api/networkv6/%s/equipments/' % id_networkv6\n        return super(ApiNetworkIPv6, self).delete(uri)", "response": "Remove deployment of network in equipments and set active = 0 in tables redeipv6"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck available ipv6 in environment vip", "response": "def check_vip_ip(self, ip, environment_vip):\n        \"\"\"\n        Check available ipv6 in environment vip\n        \"\"\"\n        uri = 'api/ipv6/ip/%s/environment-vip/%s/' % (ip, environment_vip)\n\n        return super(ApiNetworkIPv6, self).get(uri)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_ipv6(self, ipv6_id):\n        uri = 'api/ipv6/%s/' % (ipv6_id)\n\n        return super(ApiNetworkIPv6, self).delete(uri)", "response": "Delete IPv6 related information"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search(self, **kwargs):\n\n        return super(ApiNetworkIPv6, self).get(self.prepare_url('api/v3/networkv6/',\n                                                                kwargs))", "response": "Method to search ipv6 s based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, networkipv6s):\n\n        data = {'networks': networkipv6s}\n        networkipv6s_ids = [str(networkipv6.get('id'))\n                            for networkipv6 in networkipv6s]\n\n        return super(ApiNetworkIPv6, self).put('api/v3/networkv6/%s/' %\n                                               ';'.join(networkipv6s_ids), data)", "response": "Method to update network - ipv6 s\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_all(self):\n        url = 'environmentvip/all/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        key = 'environment_vip'\n\n        return get_list_map(self.response(code, xml, [key]), key)", "response": "List all environment vips"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_all_available(self, id_vlan):\n\n        url = 'environmentvip/search/' + str(id_vlan)\n\n        code, xml = self.submit(None, 'GET', url)\n\n        key = 'environment_vip'\n\n        return get_list_map(self.response(code, xml, [key]), key)", "response": "List all available environments vip"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, finalidade_txt, cliente_txt, ambiente_p44_txt, description):\n        environmentvip_map = dict()\n        environmentvip_map['finalidade_txt'] = finalidade_txt\n        environmentvip_map['cliente_txt'] = cliente_txt\n        environmentvip_map['ambiente_p44_txt'] = ambiente_p44_txt\n        environmentvip_map['description'] = description\n\n        code, xml = self.submit(\n            {'environment_vip': environmentvip_map}, 'POST', 'environmentvip/')\n\n        return self.response(code, xml)", "response": "Inserts a new Environment VIP and returns its identifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef alter(\n            self,\n            id_environment_vip,\n            finalidade_txt,\n            cliente_txt,\n            ambiente_p44_txt,\n            description):\n        \"\"\"Change Environment VIP from by the identifier.\n\n        :param id_environment_vip: Identifier of the Environment VIP. Integer value and greater than zero.\n        :param finalidade_txt: Finality. String with a maximum of 50 characters and respect [a-zA-Z\\_-]\n        :param cliente_txt: ID  Client. String with a maximum of 50 characters and respect [a-zA-Z\\_-]\n        :param ambiente_p44_txt: Environment P44. String with a maximum of 50 characters and respect [a-zA-Z\\_-]\n\n        :return: None\n\n        :raise InvalidParameterError: Environment VIP identifier is null and invalid.\n        :raise InvalidParameterError: The value of finalidade_txt, cliente_txt or ambiente_p44_txt is invalid.\n        :raise EnvironmentVipNotFoundError: Environment VIP not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_environment_vip):\n            raise InvalidParameterError(\n                u'The identifier of Environment VIP is invalid or was not informed.')\n\n        environmentvip_map = dict()\n        environmentvip_map['finalidade_txt'] = finalidade_txt\n        environmentvip_map['cliente_txt'] = cliente_txt\n        environmentvip_map['ambiente_p44_txt'] = ambiente_p44_txt\n        environmentvip_map['description'] = description\n\n        url = 'environmentvip/' + str(id_environment_vip) + '/'\n\n        code, xml = self.submit(\n            {'environment_vip': environmentvip_map}, 'PUT', url)\n\n        return self.response(code, xml)", "response": "Change the Environment VIP from by the identifier."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving Environment VIP from by the identifier.", "response": "def remove(self, id_environment_vip):\n        \"\"\"Remove Environment VIP from by the identifier.\n\n        :param id_environment_vip: Identifier of the Environment VIP. Integer value and greater than zero.\n\n        :return: None\n\n        :raise InvalidParameterError: Environment VIP identifier is null and invalid.\n        :raise EnvironmentVipNotFoundError: Environment VIP not registered.\n        :raise EnvironmentVipError: There networkIPv4 or networkIPv6 associated with environment vip.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_environment_vip):\n            raise InvalidParameterError(\n                u'The identifier of Environment VIP is invalid or was not informed.')\n\n        url = 'environmentvip/' + str(id_environment_vip) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching Environment VIP from by parameters.", "response": "def search(\n            self,\n            id_environment_vip=None,\n            finalidade_txt=None,\n            cliente_txt=None,\n            ambiente_p44_txt=None):\n        \"\"\"Search Environment VIP from by parameters.\n\n        Case the id parameter has been passed, the same it has priority over the other parameters.\n\n        :param id_environment_vip: Identifier of the Environment VIP. Integer value and greater than zero.\n        :param finalidade_txt: Finality. String with a maximum of 50 characters and respect [a-zA-Z\\_-]\n        :param cliente_txt: ID  Client. String with a maximum of 50 characters and respect [a-zA-Z\\_-]\n        :param ambiente_p44_txt: Environment P44. String with a maximum of 50 characters and respect [a-zA-Z\\_-]\n\n        :return: Following dictionary:\n\n        ::\n\n            {\u2018environment_vip\u2019:\n            {\u2018id\u2019: < id >,\n            \u2018finalidade_txt\u2019: < finalidade_txt >,\n            \u2018finalidade\u2019: < finalidade >,\n            \u2018cliente_txt\u2019: < cliente_txt >,\n            \u2018ambiente_p44_txt\u2019: < ambiente_p44_txt >}}\n\n        :raise InvalidParameterError: The value of id_environment_vip, finalidade_txt, cliente_txt or ambiente_p44_txt is invalid.\n        :raise EnvironmentVipNotFoundError: Environment VIP not registered.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n        environmentvip_map = dict()\n        environmentvip_map['id_environment_vip'] = id_environment_vip\n        environmentvip_map['finalidade_txt'] = finalidade_txt\n        environmentvip_map['cliente_txt'] = cliente_txt\n        environmentvip_map['ambiente_p44_txt'] = ambiente_p44_txt\n\n        code, xml = self.submit(\n            {'environment_vip': environmentvip_map}, 'POST', 'environmentvip/search/')\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef buscar_finalidade(self):\n\n        url = 'environment-vip/get/finality'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)", "response": "Search finalidade_txt environment vip"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsearches cliente_txt environment vip", "response": "def buscar_cliente_por_finalidade(self, finalidade_txt):\n        \"\"\"Search cliente_txt environment vip\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {\u2018cliente_txt\u2019:\n            \u2018finalidade\u2019: <'finalidade_txt'>,\n            'cliente_txt: <'cliente_txt'>'}\n\n        :raise InvalidParameterError: finalidade_txt is null and invalid.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        vip_map = dict()\n        vip_map['finalidade_txt'] = finalidade_txt\n\n        url = 'environment-vip/get/cliente_txt/'\n\n        code, xml = self.submit({'vip': vip_map}, 'POST', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef buscar_ambientep44_por_finalidade_cliente(\n            self,\n            finalidade_txt,\n            cliente_txt):\n        \"\"\"Search ambiente_p44_txt environment vip\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {\u2018ambiente_p44_txt\u2019:\n            'id':<'id_ambientevip'>,\n            \u2018finalidade\u2019: <'finalidade_txt'>,\n            'cliente_txt: <'cliente_txt'>',\n            'ambiente_p44: <'ambiente_p44'>',}\n\n        :raise InvalidParameterError: finalidade_txt and cliente_txt is null and invalid.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        vip_map = dict()\n        vip_map['finalidade_txt'] = finalidade_txt\n        vip_map['cliente_txt'] = cliente_txt\n\n        url = 'environment-vip/get/ambiente_p44_txt/'\n\n        code, xml = self.submit({'vip': vip_map}, 'POST', url)\n\n        return self.response(code, xml)", "response": "Search ambiente_p44_txt environment vip"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist finality, client or environment vip list. Param finality: finality of environment(optional) Param client: client of environment(optional) Param environmentp44: environmentp44(optional) Return finality list: when request has no finality and client. Return client list: when request has only finality. Return list environment vip: when request has finality and client. Return environment vip: when request has finality, client and environmentvip", "response": "def environmentvip_step(self, finality='', client='', environmentp44=''):\n        \"\"\"\n        List finality, client or environment vip list.\n        Param finality: finality of environment(optional)\n        Param client: client of environment(optional)\n        Param environmentp44: environmentp44(optional)\n        Return finality list: when request has no finality and client.\n        Return client list: when request has only finality.\n        Return list environment vip: when request has finality and client.\n        Return environment vip: when request has finality, client and environmentvip\n        \"\"\"\n\n        uri = 'api/v3/environment-vip/step/?finality=%s&client=%s&environmentp44=%s' % (\n            finality, client, environmentp44)\n\n        return super(ApiEnvironmentVip, self).get(\n            uri)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search(self, **kwargs):\n\n        return super(ApiEnvironmentVip, self).get(\n            self.prepare_url('api/v3/environment-vip/', kwargs))", "response": "Method to search environments vip based on extends search."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(self, environments):\n\n        data = {'environments_vip': environments}\n        uri = 'api/v3/environment-vip/'\n        return super(ApiEnvironmentVip, self).post(uri, data)", "response": "Method to create environments vip\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_ipv4(self, id_ip):\n\n        if not is_valid_int_param(id_ip):\n            raise InvalidParameterError(\n                u'The IPv4 identifier is invalid or was not informed.')\n\n        url = 'ip/get-ipv4/' + str(id_ip) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        key = 'ipv4'\n        return get_list_map(self.response(code, xml, [\"equipamentos\"]), key)", "response": "Get IPv4 by id."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget IPv6 by id.", "response": "def get_ipv6(self, id_ip):\n        \"\"\"Get IPv6 by id.\n\n        :param id_ip: ID of IPv6.\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {'ip': {'id': < id >,\n            'networkipv6': < networkipv6 >,\n            'block1': < block1 >,\n            'block2': < block2 >,\n            'block3': < block3 >,\n            'block4': < block4 >,\n            'block5': < block5 >,\n            'block6': < block6 >,\n            'block7': < block7 >,\n            'block8': < block8 >,\n            'description': < description >,\n            'equipamentos': [ { all name of equipments related } ] , }}\n\n        :raise IpNaoExisteError: IP is not registered.\n        :raise InvalidParameterError: IP identifier is null or invalid.\n        :raise DataBaseError: Networkapi failed to access the database.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        \"\"\"\n\n        if not is_valid_int_param(id_ip):\n            raise InvalidParameterError(\n                u'The IPv6 identifier is invalid or was not informed.')\n\n        url = 'ip/get-ipv6/' + str(id_ip) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        key = 'ipv6'\n        return get_list_map(self.response(code, xml, [\"equipamentos\"]), key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef buscar_por_ip_ambiente(self, ip, id_environment):\n\n        if not is_valid_int_param(id_environment):\n            raise InvalidParameterError(\n                u'Environment identifier is invalid or was not informed.')\n\n        if not is_valid_ip(ip):\n            raise InvalidParameterError(u'IP is invalid or was not informed.')\n\n        url = 'ip/' + str(ip) + '/ambiente/' + str(id_environment) + '/'\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)", "response": "Get an IP with an associated environment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_available_ip4(self, id_network):\n\n        if not is_valid_int_param(id_network):\n            raise InvalidParameterError(\n                u'Network identifier is invalid or was not informed.')\n\n        url = 'ip/availableip4/' + str(id_network) + \"/\"\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)", "response": "Get a available IP in the network ipv4\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a available IP in the Equipment related Environment VIP and return the result as a dictionary.", "response": "def get_ip_by_equip_and_vip(self, equip_name, id_evip):\n        \"\"\"\n        Get a available IP in the Equipment related Environment VIP\n\n        :param equip_name: Equipment Name.\n        :param id_evip: Vip environment identifier. Integer value and greater than zero.\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            { 'ipv4': [ {'id': < id >, 'ip': < ip >, 'network': { 'id': < id >, 'network': < network >, 'mask': < mask >, }} ... ],\n            'ipv6': [ {'id': < id >, 'ip': < ip >, 'network': { 'id': < id >, 'network': < network >, 'mask': < mask >, }} ... ] }\n\n        :raise InvalidParameterError: Vip environment identifier or equipment name is none or invalid.\n        :raise EquipamentoNotFoundError: Equipment not registered.\n        :raise EnvironmentVipNotFoundError: Vip environment not registered.\n        :raise UserNotAuthorizedError: User dont have permission to perform operation.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        :raise DataBaseError: Networkapi failed to access the database.\n        \"\"\"\n\n        if not is_valid_int_param(id_evip):\n            raise InvalidParameterError(\n                u'Vip environment is invalid or was not informed.')\n\n        ip_map = dict()\n        ip_map['equip_name'] = equip_name\n        ip_map['id_evip'] = id_evip\n\n        url = \"ip/getbyequipandevip/\"\n\n        code, xml = self.submit({'ip_map': ip_map}, 'POST', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ipv4_or_ipv6(self, ip):\n\n        ip_map = dict()\n        ip_map['ip'] = ip\n\n        url = \"ip/getbyoctblock/\"\n\n        code, xml = self.submit({'ip_map': ip_map}, 'POST', url)\n\n        return self.response(code, xml)", "response": "Get a Ipv4 or Ipv6 by ip"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a Ipv4 or Ipv6 for a vip", "response": "def check_vip_ip(self, ip, id_evip):\n        \"\"\"\n        Get a Ipv4 or Ipv6 for Vip request\n\n        :param ip: IPv4 or Ipv6. 'xxx.xxx.xxx.xxx or xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx'\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {'ip': {'ip': < ip - octs for ipv4, blocks for ipv6 - >,\n            'id': <id>,\n            'network4 or network6'}}.\n\n        :raise IpNaoExisteError: Ipv4 or Ipv6 not found.\n        :raise EnvironemntVipNotFoundError: Vip environment not found.\n        :raise IPNaoDisponivelError: Ip not available for Vip Environment.\n        :raise UserNotAuthorizedError: User dont have permission to perform operation.\n        :raise InvalidParameterError: Ip string or vip environment is none or invalid.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        :raise DataBaseError: Networkapi failed to access the database.\n\n        \"\"\"\n\n        ip_map = dict()\n        ip_map['ip'] = ip\n        ip_map['id_evip'] = id_evip\n\n        url = \"ip/checkvipip/\"\n\n        code, xml = self.submit({'ip_map': ip_map}, 'POST', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a available IP in Network ipv6.", "response": "def get_available_ip6(self, id_network6):\n        \"\"\"\n        Get a available IP in Network ipv6\n\n        :param id_network6: Network ipv6 identifier. Integer value and greater than zero.\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {'ip6': {'ip6': < available_ip6 >}}\n\n        :raise IpNotAvailableError: Network dont have available IP.\n        :raise NetworkIPv4NotFoundError: Network was not found.\n        :raise UserNotAuthorizedError: User dont have permission to get a available IP.\n        :raise InvalidParameterError: Network ipv6 identifier is none or invalid.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        :raise DataBaseError: Networkapi failed to access the database.\n\n        \"\"\"\n\n        if not is_valid_int_param(id_network6):\n            raise InvalidParameterError(\n                u'Network ipv6 identifier is invalid or was not informed.')\n\n        url = 'ip/availableip6/' + str(id_network6) + \"/\"\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting and save a available IP in the network ipv6 for vip environment.", "response": "def get_available_ip6_for_vip(self, id_evip, name):\n        \"\"\"\n        Get and save a available IP in the network ipv6 for vip request\n\n        :param id_evip: Vip environment identifier. Integer value and greater than zero.\n        :param name: Ip description\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {'ip': {'bloco1':<bloco1>,\n            'bloco2':<bloco2>,\n            'bloco3':<bloco3>,\n            'bloco4':<bloco4>,\n            'bloco5':<bloco5>,\n            'bloco6':<bloco6>,\n            'bloco7':<bloco7>,\n            'bloco8':<bloco8>,\n            'id':<id>,\n            'networkipv6':<networkipv6>,\n            'description':<description>}}\n\n        :raise IpNotAvailableError: Network dont have available IP for vip environment.\n        :raise EnvironmentVipNotFoundError: Vip environment not registered.\n        :raise UserNotAuthorizedError: User dont have permission to perform operation.\n        :raise InvalidParameterError: Vip environment identifier is none or invalid.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        :raise DataBaseError: Networkapi failed to access the database.\n\n        \"\"\"\n\n        if not is_valid_int_param(id_evip):\n            raise InvalidParameterError(\n                u'Vip environment identifier is invalid or was not informed.')\n\n        url = 'ip/availableip6/vip/' + str(id_evip) + \"/\"\n\n        ip_map = dict()\n        ip_map['id_evip'] = id_evip\n        ip_map['name'] = name\n\n        code, xml = self.submit({'ip_map': ip_map}, 'POST', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nedit an IP4 in a resource.", "response": "def edit_ipv4(self, ip4, descricao, id_ip):\n        \"\"\"\n        Edit a IP4\n\n        :param ip4: An IP4 available to save in format x.x.x.x.\n        :param id_ip: IP identifier. Integer value and greater than zero.\n        :param descricao: IP description.\n\n        :return: None\n        \"\"\"\n\n        if not is_valid_int_param(id_ip):\n            raise InvalidParameterError(\n                u'Ip identifier is invalid or was not informed.')\n\n        if ip4 is None or ip4 == \"\":\n            raise InvalidParameterError(\n                u'The IP4 is invalid or was not informed.')\n\n        ip_map = dict()\n        ip_map['descricao'] = descricao\n        ip_map['ip4'] = ip4\n        ip_map['id_ip'] = id_ip\n\n        url = \"ip4/edit/\"\n\n        code, xml = self.submit({'ip_map': ip_map}, 'POST', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_ipv4(self, ip4, id_equip, descricao, id_net):\n        if not is_valid_int_param(id_net):\n            raise InvalidParameterError(\n                u'Network identifier is invalid or was not informed.')\n\n        if not is_valid_int_param(id_equip):\n            raise InvalidParameterError(\n                u'Equipment identifier is invalid or was not informed.')\n\n        if ip4 is None or ip4 == \"\":\n            raise InvalidParameterError(u'IP4 is invalid or was not informed.')\n\n        ip_map = dict()\n        ip_map['id_net'] = id_net\n        ip_map['descricao'] = descricao\n        ip_map['ip4'] = ip4\n        ip_map['id_equip'] = id_equip\n\n        url = \"ipv4/save/\"\n\n        code, xml = self.submit({'ip_map': ip_map}, 'POST', url)\n\n        return self.response(code, xml)", "response": "Save a IP4 and associate with equipment and network."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef edit_ipv6(self, ip6, descricao, id_ip):\n\n        if not is_valid_int_param(id_ip):\n            raise InvalidParameterError(\n                u'Ipv6 identifier is invalid or was not informed.')\n\n        if ip6 is None or ip6 == \"\":\n            raise InvalidParameterError(u'IP6 is invalid or was not informed.')\n\n        ip_map = dict()\n        ip_map['descricao'] = descricao\n        ip_map['ip6'] = ip6\n        ip_map['id_ip'] = id_ip\n\n        url = \"ipv6/edit/\"\n\n        code, xml = self.submit({'ip_map': ip_map}, 'POST', url)\n\n        return self.response(code, xml)", "response": "Edit an IP6 in a cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_ip4_by_id(self, id_ip):\n\n        if not is_valid_int_param(id_ip):\n            raise InvalidParameterError(\n                u'Ip identifier is invalid or was not informed.')\n\n        url = 'ip/get/' + str(id_ip) + \"/\"\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)", "response": "Get an IP by ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets Ips related to an equipment by its identifier.", "response": "def find_ips_by_equip(self, id_equip):\n        \"\"\"\n        Get Ips related to equipment by its identifier\n\n        :param id_equip: Equipment identifier. Integer value and greater than zero.\n\n        :return: Dictionary with the following structure:\n\n            { ips: { ipv4:[\n            id: <id_ip4>,\n            oct1: <oct1>,\n            oct2: <oct2>,\n            oct3: <oct3>,\n            oct4: <oct4>,\n            descricao: <descricao> ]\n            ipv6:[\n            id: <id_ip6>,\n            block1: <block1>,\n            block2: <block2>,\n            block3: <block3>,\n            block4: <block4>,\n            block5: <block5>,\n            block6: <block6>,\n            block7: <block7>,\n            block8: <block8>,\n            descricao: <descricao> ] } }\n\n        :raise UserNotAuthorizedError: User dont have permission to list ips.\n        :raise InvalidParameterError: Equipment identifier is none or invalid.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        :raise DataBaseError: Networkapi failed to access the database.\n\n        \"\"\"\n        url = 'ip/getbyequip/' + str(id_equip) + \"/\"\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml, ['ipv4', 'ipv6'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets an IP6 by ID.", "response": "def find_ip6_by_id(self, id_ip):\n        \"\"\"\n        Get an IP6 by ID\n\n        :param id_ip: IP6 identifier. Integer value and greater than zero.\n\n        :return: Dictionary with the following structure:\n\n        ::\n\n            {'ip': {'id': < id >,\n            'block1': <block1>,\n            'block2': <block2>,\n            'block3': <block3>,\n            'block4': <block4>,\n            'block5': <block5>,\n            'block6': <block6>,\n            'block7': <block7>,\n            'block8': <block8>,\n            'descricao': < description >,\n            'equipamento': [ { all name equipamentos related} ], }}\n\n\n        :raise IpNotAvailableError: Network dont have available IPv6.\n        :raise NetworkIPv4NotFoundError: Network was not found.\n        :raise UserNotAuthorizedError: User dont have permission to perform operation.\n        :raise InvalidParameterError: IPv6 identifier is none or invalid.\n        :raise XMLError: Networkapi failed to generate the XML response.\n        :raise DataBaseError: Networkapi failed to access the database.\n\n        \"\"\"\n\n        if not is_valid_int_param(id_ip):\n            raise InvalidParameterError(\n                u'Ipv6 identifier is invalid or was not informed.')\n\n        url = 'ipv6/get/' + str(id_ip) + \"/\"\n\n        code, xml = self.submit(None, 'GET', url)\n\n        return self.response(code, xml)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_ipv6(self, ip6, id_equip, descricao, id_net):\n        if not is_valid_int_param(id_net):\n            raise InvalidParameterError(\n                u'Network identifier is invalid or was not informed.')\n\n        if not is_valid_int_param(id_equip):\n            raise InvalidParameterError(\n                u'Equipment identifier is invalid or was not informed.')\n\n        if ip6 is None or ip6 == \"\":\n            raise InvalidParameterError(\n                u'IPv6 is invalid or was not informed.')\n\n        ip_map = dict()\n        ip_map['id_net'] = id_net\n        ip_map['descricao'] = descricao\n        ip_map['ip6'] = ip6\n        ip_map['id_equip'] = id_equip\n\n        url = \"ipv6/save/\"\n\n        code, xml = self.submit({'ip_map': ip_map}, 'POST', url)\n\n        return self.response(code, xml)", "response": "Save an IP6 and associate with equipment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_ip4(self, id_ip):\n\n        if not is_valid_int_param(id_ip):\n            raise InvalidParameterError(u'Ipv4 identifier is invalid or was not informed.')\n\n        url = 'ip4/delete/' + str(id_ip) + \"/\"\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Delete an IP4 from the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_ip6_by_network(self, id_network):\n\n        if not is_valid_int_param(id_network):\n            raise InvalidParameterError(\n                u'Network identifier is invalid or was not informed.')\n\n        url = 'ip/id_network_ipv6/' + str(id_network) + \"/\"\n\n        code, xml = self.submit(None, 'GET', url)\n\n        key = \"ips\"\n        return get_list_map(self.response(code, xml, [key]), key)", "response": "List IPv6 from network."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search_ipv6_environment(self, ipv6, id_environment):\n\n        if not is_valid_int_param(id_environment):\n            raise InvalidParameterError(\n                u'Environment identifier is invalid or was not informed.')\n\n        ipv6_map = dict()\n        ipv6_map['ipv6'] = ipv6\n        ipv6_map['id_environment'] = id_environment\n\n        code, xml = self.submit(\n            {'ipv6_map': ipv6_map}, 'POST', 'ipv6/environment/')\n\n        return self.response(code, xml)", "response": "Search IPv6 with an associated environment."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef assoc_ipv4(self, id_ip, id_equip, id_net):\n\n        if not is_valid_int_param(id_ip):\n            raise InvalidParameterError(\n                u'Ip identifier is invalid or was not informed.')\n\n        if not is_valid_int_param(id_net):\n            raise InvalidParameterError(\n                u'Network identifier is invalid or was not informed.')\n\n        if not is_valid_int_param(id_equip):\n            raise InvalidParameterError(\n                u'Equipment identifier is invalid or was not informed.')\n\n        ip_map = dict()\n        ip_map['id_ip'] = id_ip\n        ip_map['id_net'] = id_net\n        ip_map['id_equip'] = id_equip\n\n        url = \"ipv4/assoc/\"\n\n        code, xml = self.submit({'ip_map': ip_map}, 'POST', url)\n\n        return self.response(code, xml)", "response": "Associate an IP4 with an equipment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assoc_ipv6(self, id_ip, id_equip, id_net):\n\n        if not is_valid_int_param(id_ip):\n            raise InvalidParameterError(\n                u'Ipv6 identifier is invalid or was not informed.')\n\n        if not is_valid_int_param(id_net):\n            raise InvalidParameterError(\n                u'Network identifier is invalid or was not informed.')\n\n        if not is_valid_int_param(id_equip):\n            raise InvalidParameterError(\n                u'Equipment identifier is invalid or was not informed.')\n\n        ip_map = dict()\n        ip_map['id_ip'] = id_ip\n        ip_map['id_net'] = id_net\n        ip_map['id_equip'] = id_equip\n\n        url = \"ipv6/assoc/\"\n\n        code, xml = self.submit({'ip_map': ip_map}, 'POST', url)\n\n        return self.response(code, xml)", "response": "Associate an IPv6 with an equipment."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef listar(self):\n\n        code, xml = self.submit(None, 'GET', 'net_type/')\n\n        key = 'net_type'\n        return get_list_map(self.response(code, xml, [key]), key)", "response": "List all network types."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef inserir(self, name):\n\n        net_type_map = dict()\n        net_type_map['name'] = name\n\n        code, xml = self.submit(\n            {'net_type': net_type_map}, 'POST', 'net_type/')\n\n        return self.response(code, xml)", "response": "Insert a new network type and return its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef alterar(self, id_net_type, name):\n\n        if not is_valid_int_param(id_net_type):\n            raise InvalidParameterError(\n                u'Network type is invalid or was not informed.')\n\n        url = 'net_type/' + str(id_net_type) + '/'\n\n        net_type_map = dict()\n        net_type_map['name'] = name\n\n        code, xml = self.submit({'net_type': net_type_map}, 'PUT', url)\n\n        return self.response(code, xml)", "response": "Edit network type by its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remover(self, id_net_type):\n        if not is_valid_int_param(id_net_type):\n            raise InvalidParameterError(\n                u'Network type is invalid or was not informed.')\n\n        url = 'net_type/' + str(id_net_type) + '/'\n\n        code, xml = self.submit(None, 'DELETE', url)\n\n        return self.response(code, xml)", "response": "Remove network type by its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompile rbnf source code file", "response": "def cc(filename: 'input source file',\n       output:\n       'output file name. default to be replacing input file\\'s suffix with \".py\"' = None,\n       name: 'name of language' = 'unname'):\n    \"\"\"\n    rbnf source code compiler.\n    \"\"\"\n\n    lang = Language(name)\n\n    with Path(filename).open('r') as fr:\n        build_language(fr.read(), lang, filename)\n\n    if not output:\n        base, _ = os.path.splitext(filename)\n\n        output = base + '.py'\n    lang.dump(output)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning the parser and returns a tree of all the modules that are parsed.", "response": "def run(filename: 'python file generated by `rbnf` command, or rbnf sour file',\n        opt: 'optimize switch' = False):\n    \"\"\"\n    You can apply immediate tests on your parser.\n    P.S: use `--opt` option takes longer starting time.\n    \"\"\"\n    from rbnf.easy import build_parser\n    import importlib.util\n    import traceback\n    full_path = Path(filename)\n    base, ext = os.path.splitext(str(full_path))\n    full_path_str = str(full_path)\n\n    if not ext:\n        if full_path.into('.py').exists():\n            full_path_str = base + '.py'\n        elif Path(base).into('.rbnf'):\n            full_path_str = base + '.rbnf'\n\n    if full_path_str[-3:].lower() != '.py':\n        with Path(full_path_str).open('r') as fr:\n            ze_exp = ze.compile(fr.read(), filename=full_path_str)\n            lang = ze_exp.lang\n\n    else:\n        spec = importlib.util.spec_from_file_location(\"runbnf\", full_path_str)\n\n        mod = importlib.util.module_from_spec(spec)\n        spec.loader.exec_module(mod)\n        try:\n            lang = next(each for each in mod.__dict__.values()\n                        if isinstance(each, Language))\n        except StopIteration:\n            raise NameError(\"Found no language in {}\".format(full_path_str))\n\n    parse = build_parser(lang, opt=bool(opt))\n    namespace = {}\n\n    print(Purple('type `:i` to switch between python mode and parsing mode.'))\n    print(Purple('The last result of parsing is stored as symbol `res`.'))\n    while True:\n\n        inp = input('runbnf> ')\n        if not inp.strip():\n            continue\n        elif inp.strip() == 'exit':\n            break\n\n        if inp.strip() == ':i':\n            while True:\n                inp = input('python> ')\n\n                if inp.strip() == ':i':\n                    break\n                try:\n                    try:\n                        res = eval(inp, namespace)\n                        if res is not None:\n                            print(res)\n\n                        namespace['_'] = res\n                    except SyntaxError:\n                        exec(inp, namespace)\n                except Exception:\n                    traceback.print_exc()\n        else:\n            res = namespace['res'] = parse(inp)\n            print(\n                LightBlue(\n                    'parsed result = res: ResultDescription{result, tokens, state}'\n                ))\n            print(res.result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rbnf_lexing(text: str):\n\n    cast_map: const    = _cast_map\n    lexer_table: const = _lexer_table\n    keyword: const     = _keyword\n    drop_table: const  = _DropTable\n    end: const         = _END\n    unknown: const     = _UNKNOWN\n\n    text_length = len(text)\n    colno       = 0\n    lineno      = 0\n    position    = 0\n\n    cast_const  = ConstStrPool.cast_to_const\n\n    while True:\n        if text_length <= position:\n            break\n\n        for case_name, text_match_case in lexer_table:\n            matched_text = text_match_case(text, position)\n            if not matched_text:\n                continue\n\n            case_mem_addr = id(case_name)  # memory address of case_name\n\n            if case_mem_addr not in drop_table:\n\n                if matched_text in cast_map:\n                    yield Tokenizer(keyword, cast_const(matched_text), lineno, colno)\n\n                else:\n                    yield Tokenizer(cast_const(case_name), matched_text, lineno, colno)\n\n            n = len(matched_text)\n            line_inc = matched_text.count('\\n')\n\n            if line_inc:\n\n                latest_newline_idx = matched_text.rindex('\\n')\n                colno = n - latest_newline_idx\n                lineno += line_inc\n\n                if case_name is _Space and matched_text[-1] == '\\n':\n\n                    yield Tokenizer(end, '', lineno, colno)\n\n            else:\n                colno += n\n            position += n\n            break\n\n        else:\n\n            char = text[position]\n            yield Tokenizer(unknown, char, lineno, colno)\n\n            position += 1\n\n            if char == '\\n':\n                lineno += 1\n                colno = 0\n\n            else:\n                colno += 1", "response": "Read loudly for documentation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrecovers the code string from a series of tokenizers to a series of code strings.", "response": "def recover_codes(tokens: Iterator[Tokenizer]) -> str:\n    \"\"\"\n    from a series of tokenizers to code string. (preserve the indentation)\n    \"\"\"\n\n    tokens = iter(tokens)\n\n    s = []\n\n    try:\n        head = next(tokens)\n\n    except StopIteration:\n        return s\n\n    append = s.append\n    lineno = head.lineno\n\n    start_indent = colno = head.colno\n\n    append(head.value)\n\n    colno += len(s[-1])\n\n    for each in tokens:\n        n = each.lineno - lineno\n\n        if n:\n            append('\\n' * n)\n            lineno = each.lineno\n            colno = each.colno\n\n            if colno - start_indent > 0:\n                append(' ' * colno)\n\n        else:\n            c = each.colno - colno\n            if c:\n                colno = each.colno\n                if c > 0:\n                    append(' ' * c)\n\n        append(each.value)\n\n        colno += len(s[-1])\n\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef str_lexer(mode):\n    cast_to_const = ConstStrPool.cast_to_const\n\n    def f_raw(inp_str, pos):\n        return cast_to_const(mode) if inp_str.startswith(mode, pos) else None\n\n    def f_collection(inp_str, pos):\n        for each in mode:\n            if inp_str.startswith(each, pos):\n                return cast_to_const(each)\n        return None\n\n    if isinstance(mode, str):\n        return f_raw\n\n    if len(mode) is 1:\n        mode = mode[0]\n        return f_raw\n\n    return f_collection", "response": "generate token strings cache\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dispatch(self, tree):\n        \"Dispatcher function, dispatching tree type T to method _T.\"\n        if isinstance(tree, list):\n            for t in tree:\n                self.dispatch(t)\n            return\n        meth = getattr(self, \"_\" + tree.__class__.__name__)\n        meth(tree)", "response": "Dispatcher function dispatching tree type T to method _T."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprocess a function and its ast.", "response": "def process(fn, bound_names):\n    \"\"\"\n    process automatic context variable capturing.\n    return the transformed function and its ast.\n    \"\"\"\n    if isinstance(fn, _AutoContext):\n        fn = fn.fn\n\n    # noinspection PyArgumentList,PyArgumentList\n    if isinstance(fn, _FnCodeStr):\n\n        if bound_names:\n            assign_code_str = '{syms} = map(state.ctx.get, {names})'.format(\n                syms=', '.join(bound_names) + ',', names=repr(bound_names))\n        else:\n             assign_code_str = ''\n\n        code = \"def {0}({1}):\\n{2}\".format(\n            fn.fn_name, \", \".join(fn.fn_args),\n            textwrap.indent(assign_code_str + '\\n' + fn.code, \"    \"))\n\n        module_ast = ast.parse(code, fn.filename)\n\n        bound_name_line_inc = int(bool(bound_names)) + 1\n\n        module_ast: ast.Module = ast.increment_lineno(\n            module_ast, fn.lineno - bound_name_line_inc)\n\n        fn_ast = module_ast.body[0]\n\n        if isinstance(fn_ast.body[-1], ast.Expr):\n            # auto addition of tail expr return\n            # in rbnf you don't need to write return if the last statement in the end is an expression.\n            it: ast.Expr = fn_ast.body[-1]\n\n            fn_ast.body[-1] = ast.Return(\n                lineno=it.lineno, col_offset=it.col_offset, value=it.value)\n\n        filename = fn.filename\n        name = fn.fn_name\n\n        code_object = compile(module_ast, filename, \"exec\")\n\n        local = {}\n        # TODO: using types.MethodType here to create the function object leads to various problems.\n        # Actually I don't really known why util now.\n        exec(code_object, fn.namespace, local)\n        ret = local[name]\n\n    else:\n        if not bound_names:\n            return fn, get_ast(fn)\n\n        code = fn.__code__\n        assigns = ast.parse(\"ctx = state.ctx\\n\" + \"\\n\".join(\n            \"{0} = ctx.get({0!r})\".format(name) for name in bound_names))\n\n        module_ast = get_ast(fn)\n        fn_ast: ast.FunctionDef = module_ast.body[0]\n        fn_ast.body = assigns.body + fn_ast.body\n        module_ast = ast.Module([fn_ast])\n\n        filename = code.co_filename\n        name = code.co_name\n        __defaults__ = fn.__defaults__\n        __closure__ = fn.__closure__\n        __globals__ = fn.__globals__\n\n        code_object = compile(module_ast, filename, \"exec\")\n\n        code_object = next(\n            each for each in code_object.co_consts\n            if isinstance(each, types.CodeType) and each.co_name == name)\n\n        # noinspection PyArgumentList,PyUnboundLocalVariable\n        ret = types.FunctionType(code_object, __globals__, name, __defaults__,\n                                 __closure__)\n    return ret, module_ast"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ignore(self, *ignore_lst: str):\n\n        def stream():\n            for each in ignore_lst:\n                each = ConstStrPool.cast_to_const(each)\n                yield id(each), each\n\n        self.ignore_lst.update(stream())", "response": "ignore a set of tokens with specific names\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a language from a source code.", "response": "def build_language(source_code: str, lang: Language, filename: str):\n    \"\"\"\n    lang:      language object represents your language.\n    \"\"\"\n    state = MetaState(rbnf.implementation, requires=_Wild(), filename=filename)\n    state.data = lang\n    _build_language(source_code, state)\n    lang.build()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _decode_POST_value(request, field_name, default=None):\n    if default is None:\n        value = request.POST[field_name]\n    else:\n        value = request.POST.get(field_name, default)\n\n    # it's inefficient to load this each time it gets called, but we're\n    # not anticipating incoming email being a performance bottleneck right now!\n    charsets = json.loads(request.POST.get('charsets', \"{}\"))\n    charset = charsets.get(field_name, 'utf-8')\n\n    if charset.lower() != 'utf-8':\n        logger.debug(\"Incoming email field '%s' has %s encoding.\", field_name, charset)\n\n    return smart_text(value, encoding=charset)", "response": "Helper function to decode a request field into unicode based on charsets encoding."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes a list of RFC - compliant email addresses and returns a list of strings each containing the name and email addresses.", "response": "def _get_addresses(self, address_data, retain_name=False):\n        \"\"\"\n        Takes RFC-compliant email addresses in both terse (email only)\n        and verbose (name + email) forms and returns a list of\n        email address strings\n\n        (TODO: breaking change that returns a tuple of (name, email) per string)\n        \"\"\"\n        if retain_name:\n            raise NotImplementedError(\n                \"Not yet implemented, but will need client-code changes too\"\n            )\n\n        # We trust than an email address contains an \"@\" after\n        # email.utils.getaddresses has done the hard work. If we wanted\n        # to we could use a regex to check for greater email validity\n\n        # NB: getaddresses expects a list, so ensure we feed it appropriately\n        if isinstance(address_data, str):\n            if \"[\" not in address_data:\n                # Definitely turn these into a list\n                # NB: this is pretty assumptive, but still prob OK\n                address_data = [address_data]\n\n        output = [x[1] for x in getaddresses(address_data) if \"@\" in x[1]]\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(self, request):\n        assert isinstance(request, HttpRequest), \"Invalid request type: %s\" % type(request)\n\n        try:\n            # from_email should never be a list (unless we change our API)\n            from_email = self._get_addresses([_decode_POST_value(request, 'from')])[0]\n\n            # ...but all these can and will be a list\n            to_email = self._get_addresses([_decode_POST_value(request, 'to')])\n            cc = self._get_addresses([_decode_POST_value(request, 'cc', default='')])\n            bcc = self._get_addresses([_decode_POST_value(request, 'bcc', default='')])\n\n            subject = _decode_POST_value(request, 'subject')\n            text = _decode_POST_value(request, 'text', default='')\n            html = _decode_POST_value(request, 'html', default='')\n\n        except IndexError as ex:\n            raise RequestParseError(\n                \"Inbound request lacks a valid from address: %s.\" % request.get('from')\n            )\n\n        except MultiValueDictKeyError as ex:\n            raise RequestParseError(\"Inbound request is missing required value: %s.\" % ex)\n\n        if \"@\" not in from_email:\n            # Light sanity check for potential issues related to taking just the\n            # first element of the 'from' address list\n            raise RequestParseError(\"Could not get a valid from address out of: %s.\" % request)\n\n        email = EmailMultiAlternatives(\n            subject=subject,\n            body=text,\n            from_email=from_email,\n            to=to_email,\n            cc=cc,\n            bcc=bcc,\n        )\n        if html is not None and len(html) > 0:\n            email.attach_alternative(html, \"text/html\")\n\n        # TODO: this won't cope with big files - should really read in in chunks\n        for n, f in list(request.FILES.items()):\n            if f.size > self.max_file_size:\n                logger.debug(\n                    \"File attachment %s is too large to process (%sB)\",\n                    f.name,\n                    f.size\n                )\n                raise AttachmentTooLargeError(\n                    email=email,\n                    filename=f.name,\n                    size=f.size\n                )\n            else:\n                email.attach(f.name, f.read(), f.content_type)\n        return email", "response": "Parse an incoming request and return an EmailMultiAlternatives instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing an incoming request and return an EmailMultiAlternatives instance.", "response": "def parse(self, request):\n        \"\"\"Parse incoming request and return an email instance.\n\n        Mailgun does a lot of the heavy lifting at their end - requests\n        come in from them UTF-8 encoded, and with the message reply and\n        signature stripped out for you.\n\n        Args:\n            request: an HttpRequest object, containing the forwarded email, as\n                per the SendGrid specification for inbound emails.\n\n        Returns:\n            an EmailMultiAlternatives instance, containing the parsed contents\n                of the inbound email.\n        \"\"\"\n        assert isinstance(request, HttpRequest), \"Invalid request type: %s\" % type(request)\n\n        try:\n            subject = request.POST.get('subject', '')\n            text = \"%s\\n\\n%s\" % (\n                request.POST.get('stripped-text', ''),\n                request.POST.get('stripped-signature', '')\n            )\n            html = request.POST.get('stripped-html')\n            from_email = request.POST.get('sender')\n            to_email = request.POST.get('recipient').split(',')\n            cc = request.POST.get('cc', '').split(',')\n            bcc = request.POST.get('bcc', '').split(',')\n\n        except MultiValueDictKeyError as ex:\n            raise RequestParseError(\n                \"Inbound request is missing required value: %s.\" % ex\n            )\n\n        except AttributeError as ex:\n            raise RequestParseError(\n                \"Inbound request is missing required value: %s.\" % ex\n            )\n\n        email = EmailMultiAlternatives(\n            subject=subject,\n            body=text,\n            from_email=from_email,\n            to=to_email,\n            cc=cc,\n            bcc=bcc,\n        )\n        if html is not None and len(html) > 0:\n            email.attach_alternative(html, \"text/html\")\n\n        # TODO: this won't cope with big files - should really read in in chunks\n        for n, f in list(request.FILES.items()):\n            if f.size > self.max_file_size:\n                logger.debug(\n                    \"File attachment %s is too large to process (%sB)\",\n                    f.name,\n                    f.size\n                )\n                raise AttachmentTooLargeError(\n                    email=email,\n                    filename=f.name,\n                    size=f.size\n                )\n            else:\n                email.attach(n, f.read(), f.content_type)\n\n        return email"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an iterator of objects from the array", "response": "def _get_recipients(self, array):\n        \"\"\"Returns an iterator of objects\n           in the form [\"Name <address@example.com\", ...]\n           from the array [[\"address@example.com\", \"Name\"]]\n        \"\"\"\n        for address, name in array:\n            if not name:\n                yield address\n            else:\n                yield \"\\\"%s\\\" <%s>\" % (name, address)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(self, request):\n        assert isinstance(request, HttpRequest), \"Invalid request type: %s\" % type(request)\n\n        if settings.INBOUND_MANDRILL_AUTHENTICATION_KEY:\n            _check_mandrill_signature(\n                request=request,\n                key=settings.INBOUND_MANDRILL_AUTHENTICATION_KEY,\n            )\n\n        try:\n            messages = json.loads(request.POST['mandrill_events'])\n        except (ValueError, KeyError) as ex:\n            raise RequestParseError(\"Request is not a valid json: %s\" % ex)\n\n        if not messages:\n            logger.debug(\"No messages found in mandrill request: %s\", request.body)\n            return []\n\n        emails = []\n        for message in messages:\n            if message.get('event') != 'inbound':\n                logger.debug(\"Discarding non-inbound message\")\n                continue\n\n            msg = message.get('msg')\n            try:\n                from_email = msg['from_email']\n                to = list(self._get_recipients(msg['to']))\n                cc = list(self._get_recipients(msg['cc'])) if 'cc' in msg else []\n                bcc = list(self._get_recipients(msg['bcc'])) if 'bcc' in msg else []\n\n                subject = msg.get('subject', \"\")\n\n                attachments = msg.get('attachments', {})\n                attachments.update(msg.get('images', {}))\n\n                text = msg.get('text', \"\")\n                html = msg.get('html', \"\")\n            except (KeyError, ValueError) as ex:\n                raise RequestParseError(\n                    \"Inbound request is missing or got an invalid value.: %s.\" % ex\n                )\n\n            email = EmailMultiAlternatives(\n                subject=subject,\n                body=text,\n                from_email=self._get_sender(\n                    from_email=from_email,\n                    from_name=msg.get('from_name'),\n                ),\n                to=to,\n                cc=cc,\n                bcc=bcc,\n            )\n            if html is not None and len(html) > 0:\n                email.attach_alternative(html, \"text/html\")\n\n            email = self._process_attachments(email, attachments)\n            emails.append(email)\n\n        return emails", "response": "Parse an incoming request and return an EmailMultiAlternatives instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef receive_inbound_email(request):\n    # log the request.POST and request.FILES contents\n    if log_requests is True:\n        _log_request(request)\n\n    # HEAD requests are used by some backends to validate the route\n    if request.method == 'HEAD':\n        return HttpResponse('OK')\n\n    try:\n        # clean up encodings and extract relevant fields from request.POST\n        backend = get_backend_instance()\n        emails = backend.parse(request)\n\n        # backend.parse can return either an EmailMultiAlternatives\n        # or a list of those\n        if emails:\n            if isinstance(emails, EmailMultiAlternatives):\n                emails = [emails]\n            for email in emails:\n                # fire the signal for each email\n                email_received.send(sender=backend.__class__, email=email, request=request)\n\n    except AttachmentTooLargeError as ex:\n        logger.exception(ex)\n        email_received_unacceptable.send(\n            sender=backend.__class__,\n            email=ex.email,\n            request=request,\n            exception=ex\n        )\n    except AuthenticationError as ex:\n        logger.exception(ex)\n        email_received_unacceptable.send(\n            sender=backend.__class__,\n            email=None,\n            request=request,\n            exception=ex\n        )\n\n    except RequestParseError as ex:\n        logger.exception(ex)\n        if getattr(settings, 'INBOUND_EMAIL_RESPONSE_200', True):\n            # NB even if we have a problem, always use HTTP_STATUS=200, as\n            # otherwise the email service will continue polling us with the email.\n            # This is the default behaviour.\n            status_code = 200\n        else:\n            status_code = 400\n\n        return HttpResponse(\n            \"Unable to parse inbound email: %s\" % ex,\n            status=status_code\n        )\n\n    return HttpResponse(\"Successfully parsed inbound email.\", status=200)", "response": "Receives the inbound email from SendGrid."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_backend_class():\n    # this will (intentionally) blow up if the setting does not exist\n    assert hasattr(settings, 'INBOUND_EMAIL_PARSER')\n    assert getattr(settings, 'INBOUND_EMAIL_PARSER') is not None\n\n    package, klass = settings.INBOUND_EMAIL_PARSER.rsplit('.', 1)\n    module = import_module(package)\n    return getattr(module, klass)", "response": "Return reference to the configured backed class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sorted_exists(values, x):\n    i = bisect_left(values, x)\n    j = bisect_right(values, x)\n    exists = x in values[i:j]\n    return exists, i", "response": "Returns the insert position for item x and whether the item already exists in the list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsort a list but returns the order of the index values of the list.", "response": "def sorted_list_indexes(list_to_sort, key=None, reverse=False):\n    \"\"\"\n    Sorts a list but returns the order of the index values of the list for the sort and not the values themselves.\n    For example is the list provided is ['b', 'a', 'c'] then the result will be [2, 1, 3]\n\n    :param list_to_sort: list to sort\n    :param key: if not None then a function of one argument that is used to extract a comparison key from each\n                list element\n    :param reverse: if True then the list elements are sorted as if each comparison were reversed.\n    :return: list of sorted index values\n    \"\"\"\n    if key is not None:\n        def key_func(i):\n            return key(list_to_sort.__getitem__(i))\n    else:\n        key_func = list_to_sort.__getitem__\n    return sorted(range(len(list_to_sort)), key=key_func, reverse=reverse)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef runDia(diagram):\n    ifname = '{}.dia'.format(diagram)\n    ofname = '{}.png'.format(diagram)\n    cmd = 'dia -t png-libart -e {} {}'.format(ofname, ifname)\n    print('  {}'.format(cmd))\n    subprocess.call(cmd, shell=True)\n    return True", "response": "Generate the diagrams using Dia."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing the ordered worker.", "response": "def init2(\n        self, \n        input_tube,      # Read task from the input tube.\n        output_tubes,    # Send result on all the output tubes.\n        num_workers,     # Total number of workers in the stage.\n        disable_result,  # Whether to override any result with None.\n        do_stop_task,    # Whether to call doTask() on \"stop\" request.\n        ):\n        \"\"\"Create *num_workers* worker objects with *input_tube* and \n        an iterable of *output_tubes*. The worker reads a task from *input_tube* \n        and writes the result to *output_tubes*.\"\"\"\n\n        super(OrderedWorker, self).__init__()\n        self._tube_task_input = input_tube\n        self._tubes_result_output = output_tubes\n        self._num_workers = num_workers\n\n        # Serializes reading from input tube.\n        self._lock_prev_input = None\n        self._lock_next_input = None\n\n        # Serializes writing to output tube.\n        self._lock_prev_output = None\n        self._lock_next_output = None\n\n        self._disable_result = disable_result\n        self._do_stop_task = do_stop_task"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef assemble(\n        cls, \n        args, \n        input_tube, \n        output_tubes, \n        size, \n        disable_result=False,\n        do_stop_task=False,\n        ):\n        \"\"\"Create, assemble and start workers.\n        Workers are created of class *cls*, initialized with *args*, and given\n        task/result communication channels *input_tube* and *output_tubes*.\n        The number of workers created is according to *size* parameter.\n        *do_stop_task* indicates whether doTask() will be called for \"stop\" request.\n        \"\"\"\n\n        # Create the workers.\n        workers = []\n        for ii in range(size):\n            worker = cls(**args)\n            worker.init2(\n                input_tube,\n                output_tubes,\n                size,\n                disable_result,\n                do_stop_task,\n                )\n            workers.append(worker)\n\n        # Connect the workers.\n        for ii in range(size):\n            worker_this = workers[ii]\n            worker_prev = workers[ii-1]\n            worker_prev._link(\n                worker_this, \n                next_is_first=(ii==0),  # Designate 0th worker as the first.\n                )\n\n        # Start the workers.\n        for worker in workers:\n            worker.start()", "response": "Assemble and start workers."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlinks the worker to the given next worker object.", "response": "def _link(self, next_worker, next_is_first=False):\n        \"\"\"Link the worker to the given next worker object, \n        connecting the two workers with communication tubes.\"\"\"\n\n        lock = multiprocessing.Lock()\n        next_worker._lock_prev_input = lock\n        self._lock_next_input = lock\n        lock.acquire()\n\n        lock = multiprocessing.Lock()\n        next_worker._lock_prev_output = lock\n        self._lock_next_output = lock\n        lock.acquire()\n\n        # If the next worker is the first one, trigger it now.\n        if next_is_first:\n            self._lock_next_input.release()\n            self._lock_next_output.release()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering the result by putting it on all the output tubes.", "response": "def putResult(self, result):\n        \"\"\"Register the *result* by putting it on all the output tubes.\"\"\"\n        self._lock_prev_output.acquire()\n        for tube in self._tubes_result_output:\n            tube.put((result, 0))\n        self._lock_next_output.release()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init2(\n        self, \n        input_tube,      # Read task from the input tube.\n        output_tubes,    # Send result on all the output tubes.\n        num_workers,     # Total number of workers in the stage.\n        disable_result,  # Whether to override any result with None.\n        do_stop_task,    # Whether to call doTask() on \"stop\" request.\n        ):\n        \"\"\"Create *num_workers* worker objects with *input_tube* and \n        an iterable of *output_tubes*. The worker reads a task from *input_tube* \n        and writes the result to *output_tubes*.\"\"\"\n\n        super(UnorderedWorker, self).__init__()\n        self._tube_task_input = input_tube\n        self._tubes_result_output = output_tubes\n        self._num_workers = num_workers\n        self._disable_result = disable_result\n        self._do_stop_task = do_stop_task", "response": "Initialize the unordered worker."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nassemble and start workers.", "response": "def assemble(\n        cls, \n        args, \n        input_tube, \n        output_tubes, \n        size, \n        disable_result,\n        do_stop_task,\n        ):\n        \"\"\"Create, assemble and start workers.\n        Workers are created of class *cls*, initialized with *args*, and given\n        task/result communication channels *input_tube* and *output_tubes*.\n        The number of workers created is according to *size* parameter.\n        *do_stop_task* indicates whether doTask() will be called for \"stop\" request.\n        \"\"\"\n\n        # Create the workers.\n        workers = []\n        for ii in range(size):\n            worker = cls(**args)\n            worker.init2(\n                input_tube,\n                output_tubes,\n                size,\n                disable_result,\n                do_stop_task,\n                )\n            workers.append(worker)\n\n        # Start the workers.\n        for worker in workers:\n            worker.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints the contents of the Series.", "response": "def show(self, index=True, **kwargs):\n        \"\"\"\n        Print the contents of the Series. This method uses the tabulate function from the tabulate package. Use the\n        kwargs to pass along any arguments to the tabulate function.\n\n        :param index: If True then include the indexes as a column in the output, if False ignore the index\n        :param kwargs: Parameters to pass along to the tabulate function\n        :return: output of the tabulate function\n        \"\"\"\n        print(self._make_table(index=index, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving indexes will return a sub-set of the Series. This method will direct to the specific methods based on what types are passed in for the indexes. The type of the return is determined by the types of the parameters. :param indexes: index value, list of index values, or a list of booleans. :param as_list: if True then return the values as a list, if False return a Series. :return: either Series, list, or single value. The return is a shallow copy", "response": "def get(self, indexes, as_list=False):\n        \"\"\"\n        Given indexes will return a sub-set of the Series. This method will direct to the specific methods\n        based on what types are passed in for the indexes. The type of the return is determined by the\n        types of the parameters.\n\n        :param indexes: index value, list of index values, or a list of booleans.\n        :param as_list: if True then return the values as a list, if False return a Series.\n        :return: either Series, list, or single value. The return is a shallow copy\n        \"\"\"\n        if isinstance(indexes, (list, blist)):\n            return self.get_rows(indexes, as_list)\n        else:\n            return self.get_cell(indexes)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the value of the key - value pair for a single index and return the value", "response": "def get_cell(self, index):\n        \"\"\"\n        For a single index and return the value\n\n        :param index: index value\n        :return: value\n        \"\"\"\n        i = sorted_index(self._index, index) if self._sort else self._index.index(index)\n        return self._data[i]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the rows of the table.", "response": "def get_rows(self, indexes, as_list=False):\n        \"\"\"\n        For a list of indexes return the values of the indexes in that column.\n\n        :param indexes: either a list of index values or a list of booleans with same length as all indexes\n        :param as_list: if True return a list, if False return Series\n        :return: Series if as_list if False, a list if as_list is True\n        \"\"\"\n        if all([isinstance(i, bool) for i in indexes]):  # boolean list\n            if len(indexes) != len(self._index):\n                raise ValueError('boolean index list must be same size of existing index')\n            if all(indexes):  # the entire column\n                data = self._data\n                index = self._index\n            else:\n                data = list(compress(self._data, indexes))\n                index = list(compress(self._index, indexes))\n        else:  # index values list\n            locations = [sorted_index(self._index, x) for x in indexes] if self._sort \\\n                else [self._index.index(x) for x in indexes]\n            data = [self._data[i] for i in locations]\n            index = [self._index[i] for i in locations]\n        return data if as_list else Series(data=data, index=index, data_name=self._data_name,\n                                           index_name=self._index_name, sort=self._sort)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_location(self, location):\n        return {self.index_name: self._index[location], self.data_name: self._data[location]}", "response": "Returns a dictionary of the index and value for the specified index location"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_locations(self, locations, as_list=False):\n\n        indexes = [self._index[x] for x in locations]\n        return self.get(indexes, as_list)", "response": "Get the values for a list of locations."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a slice of the data from the index.", "response": "def get_slice(self, start_index=None, stop_index=None, as_list=False):\n        \"\"\"\n        For sorted Series will return either a Series or list of all of the rows where the index is greater than\n        or equal to the start_index if provided and less than or equal to the stop_index if provided. If either the\n        start or stop index is None then will include from the first or last element, similar to standard python\n        slide of [:5] or [:5]. Both end points are considered inclusive.\n\n        :param start_index: lowest index value to include, or None to start from the first row\n        :param stop_index: highest index value to include, or None to end at the last row\n        :param as_list: if True then return a list of the indexes and values\n        :return: Series or tuple of (index list, values list)\n        \"\"\"\n        if not self._sort:\n            raise RuntimeError('Can only use get_slice on sorted Series')\n\n        start_location = bisect_left(self._index, start_index) if start_index is not None else None\n        stop_location = bisect_right(self._index, stop_index) if stop_index is not None else None\n\n        index = self._index[start_location:stop_location]\n        data = self._data[start_location:stop_location]\n\n        if as_list:\n            return index, data\n        else:\n            return Series(data=data, index=index, data_name=self._data_name, index_name=self._index_name,\n                          sort=self._sort)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dict containing the data and index names and the values are the data and index names.", "response": "def to_dict(self, index=True, ordered=False):\n        \"\"\"\n        Returns a dict where the keys are the data and index names and the values are list of the data and index.\n\n        :param index: If True then include the index in the dict with the index_name as the key\n        :param ordered: If True then return an OrderedDict() to preserve the order of the columns in the Series\n        :return: dict or OrderedDict()\n        \"\"\"\n        result = OrderedDict() if ordered else dict()\n        if index:\n            result.update({self._index_name: self._index})\n        if ordered:\n            data_dict = [(self._data_name, self._data)]\n        else:\n            data_dict = {self._data_name: self._data}\n        result.update(data_dict)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a Series of the first N rows", "response": "def head(self, rows):\n        \"\"\"\n        Return a Series of the first N rows\n\n        :param rows: number of rows\n        :return: Series\n        \"\"\"\n        rows_bool = [True] * min(rows, len(self._index))\n        rows_bool.extend([False] * max(0, len(self._index) - rows))\n        return self.get(indexes=rows_bool)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef select_index(self, compare, result='boolean'):\n        if isinstance(compare, tuple):\n            # this crazy list comprehension will match all the tuples in the list with None being an * wildcard\n            booleans = [all([(compare[i] == w if compare[i] is not None else True) for i, w in enumerate(v)])\n                        for x, v in enumerate(self._index)]\n        else:\n            booleans = [False] * len(self._index)\n            if self._sort:\n                booleans[sorted_index(self._index, compare)] = True\n            else:\n                booleans[self._index.index(compare)] = True\n        if result == 'boolean':\n            return booleans\n        elif result == 'value':\n            return list(compress(self._index, booleans))\n        else:\n            raise ValueError('only valid values for result parameter are: boolean or value.')", "response": "Select the elements in the index that match the compare parameter and returns either a list of booleans or values that match the compare parameter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of booleans on the equality of the value for the given indexes.", "response": "def equality(self, indexes=None, value=None):\n        \"\"\"\n        Math helper method. Given a column and optional indexes will return a list of booleans on the equality of the\n        value for that index in the DataFrame to the value parameter.\n\n        :param indexes: list of index values or list of booleans. If a list of booleans then the list must be the same\\\n        length as the DataFrame\n        :param value: value to compare\n        :return: list of booleans\n        \"\"\"\n        indexes = [True] * len(self._index) if indexes is None else indexes\n        compare_list = self.get_rows(indexes, as_list=True)\n        return [x == value for x in compare_list]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _pad_data(self, index_len):\n        self._data.extend([None] * (index_len - len(self._data)))", "response": "Pad the data in Series with None to ensure that data is the same length as index\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sort_index(self):\n        sort = sorted_list_indexes(self._index)\n        # sort index\n        self._index = blist([self._index[x] for x in sort]) if self._blist else [self._index[x] for x in sort]\n        # sort data\n        self._data = blist([self._data[x] for x in sort]) if self._blist else [self._data[x] for x in sort]", "response": "Sort the Series by the index. The sort modifies the Series inplace\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set(self, indexes, values=None):\n        if isinstance(indexes, (list, blist)):\n            self.set_rows(indexes, values)\n        else:\n            self.set_cell(indexes, values)", "response": "This method will set the values of the given indexes in the Series."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_row(self, index):\n        self._index.append(index)\n        self._data.append(None)", "response": "Add a new row to the Series\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _insert_row(self, i, index):\n        if i == len(self._index):\n            self._add_row(index)\n        else:\n            self._index.insert(i, index)\n            self._data.insert(i, None)", "response": "Insert a new row in the Series."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_missing_rows(self, indexes):\n        new_indexes = [x for x in indexes if x not in self._index]\n        for x in new_indexes:\n            self._add_row(x)", "response": "Given a list of indexes add missing rows to the Series."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a list of indexes find all the indexes that are not currently in the Series and insert a new row for those that are not in the index.", "response": "def _insert_missing_rows(self, indexes):\n        \"\"\"\n        Given a list of indexes, find all the indexes that are not currently in the Series and make a new row for\n        that index, inserting into the index. This requires the Series to be sorted=True\n\n        :param indexes: list of indexes\n        :return: nothing\n        \"\"\"\n        new_indexes = [x for x in indexes if x not in self._index]\n        for x in new_indexes:\n            self._insert_row(bisect_left(self._index, x), x)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_cell(self, index, value):\n        if self._sort:\n            exists, i = sorted_exists(self._index, index)\n            if not exists:\n                self._insert_row(i, index)\n        else:\n            try:\n                i = self._index.index(index)\n            except ValueError:\n                i = len(self._index)\n                self._add_row(index)\n        self._data[i] = value", "response": "Sets the value of a single cell."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the rows of the current DataFrame to a single value or list of values.", "response": "def set_rows(self, index, values=None):\n        \"\"\"\n        Set rows to a single value or list of values. If any of the index values are not in the current indexes\n        then a new row will be created.\n\n        :param index: list of index values or list of booleans. If a list of booleans then the list must be the same\\\n        length as the Series\n        :param values: either a single value or a list. The list must be the same length as the index list if the index\\\n        list is values, or the length of the True values in the index list if the index list is booleans\n        :return: nothing\n        \"\"\"\n        if all([isinstance(i, bool) for i in index]):  # boolean list\n            if not isinstance(values, (list, blist)):  # single value provided, not a list, so turn values into list\n                values = [values for x in index if x]\n            if len(index) != len(self._index):\n                raise ValueError('boolean index list must be same size of existing index')\n            if len(values) != index.count(True):\n                raise ValueError('length of values list must equal number of True entries in index list')\n            indexes = [i for i, x in enumerate(index) if x]\n            for x, i in enumerate(indexes):\n                self._data[i] = values[x]\n        else:  # list of index\n            if not isinstance(values, (list, blist)):  # single value provided, not a list, so turn values into list\n                values = [values for _ in index]\n            if len(values) != len(index):\n                raise ValueError('length of values and index must be the same.')\n            # insert or append indexes as needed\n            if self._sort:\n                exists_tuples = list(zip(*[sorted_exists(self._index, x) for x in index]))\n                exists = exists_tuples[0]\n                indexes = exists_tuples[1]\n                if not all(exists):\n                    self._insert_missing_rows(index)\n                    indexes = [sorted_index(self._index, x) for x in index]\n            else:\n                try:  # all index in current index\n                    indexes = [self._index.index(x) for x in index]\n                except ValueError:  # new rows need to be added\n                    self._add_missing_rows(index)\n                    indexes = [self._index.index(x) for x in index]\n            for x, i in enumerate(indexes):\n                self._data[i] = values[x]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_locations(self, locations, values):\n\n        indexes = [self._index[x] for x in locations]\n        self.set(indexes, values)", "response": "Set the values for a list of locations."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef append_row(self, index, value):\n        if index in self._index:\n            raise IndexError('index already in Series')\n\n        self._index.append(index)\n        self._data.append(value)", "response": "Appends a row of value to the end of the data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nappend the values to the end of the data.", "response": "def append_rows(self, indexes, values):\n        \"\"\"\n        Appends values to the end of the data. Be very careful with this function as for sort DataFrames it will not \n        enforce sort order. Use this only for speed when needed, be careful.\n\n        :param indexes: list of indexes to append\n        :param values: list of values to append\n        :return: nothing\n        \"\"\"\n\n        # check that the values data is less than or equal to the length of the indexes\n        if len(values) != len(indexes):\n            raise ValueError('length of values is not equal to length of indexes')\n\n        # check the indexes are not duplicates\n        combined_index = self._index + indexes\n        if len(set(combined_index)) != len(combined_index):\n            raise IndexError('duplicate indexes in Series')\n\n        # append index value\n        self._index.extend(indexes)\n        self._data.extend(values)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete rows from the DataFrame COOKIE table.", "response": "def delete(self, indexes):\n        \"\"\"\n        Delete rows from the DataFrame\n\n        :param indexes: either a list of values or list of booleans for the rows to delete\n        :return: nothing\n        \"\"\"\n        indexes = [indexes] if not isinstance(indexes, (list, blist)) else indexes\n        if all([isinstance(i, bool) for i in indexes]):  # boolean list\n            if len(indexes) != len(self._index):\n                raise ValueError('boolean indexes list must be same size of existing indexes')\n            indexes = [i for i, x in enumerate(indexes) if x]\n        else:\n            indexes = [sorted_index(self._index, x) for x in indexes] if self._sort \\\n                else [self._index.index(x) for x in indexes]\n        indexes = sorted(indexes, reverse=True)  # need to sort and reverse list so deleting works\n        for i in indexes:\n            del self._data[i]\n        # now remove from index\n        for i in indexes:\n            del self._index[i]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreset the index of the Series to simple integer list and the index name to index.", "response": "def reset_index(self):\n        \"\"\"\n        Resets the index of the Series to simple integer list and the index name to 'index'.\n\n        :return: nothing\n        \"\"\"\n        self.index = list(range(self.__len__()))\n        self.index_name = 'index'"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps function for get. It will return a list of values or booleans.", "response": "def value(self, indexes, int_as_index=False):\n        \"\"\"\n        Wrapper function for get. It will return a list, no index. If the indexes are integers it will be assumed\n        that they are locations unless int_as_index = True. If the indexes are locations then they will be rotated to \n        the left by offset number of locations.\n\n        :param indexes: integer location, single index, list of indexes or list of boolean\n        :param int_as_index: if True then will treat int index values as indexes and not locations\n        :return: value or list of values\n        \"\"\"\n        # single integer value\n        if isinstance(indexes, int):\n            if int_as_index:\n                return self.get(indexes, as_list=True)\n            else:\n                indexes = indexes - self._offset\n                return self._data[indexes]\n\n        # slice\n        elif isinstance(indexes, slice):\n            if isinstance(indexes.start, int) and not int_as_index:  # treat as location\n                start = indexes.start - self._offset\n                stop = indexes.stop - self._offset + 1  # to capture the last value\n                # check locations are valid and will not return empty\n                if start > stop:\n                    raise IndexError('end of slice is before start of slice')\n                if (start > 0 > stop) or (start < 0 < stop):\n                    raise IndexError('slide indexes invalid with given offset:%f' % self._offset)\n                # where end is the last element\n                if (start < 0) and stop == 0:\n                    return self._data[start:]\n                return self._data[start:stop]\n            else:  # treat as index\n                indexes = self._slice_index(indexes)\n                return self.get(indexes, as_list=True)\n\n        # list of booleans\n        elif all([isinstance(x, bool) for x in indexes]):\n            return self.get(indexes, as_list=True)\n\n        # list of values\n        elif isinstance(indexes, list):\n            if int_as_index or not isinstance(indexes[0], int):\n                return self.get(indexes, as_list=True)\n            else:\n                indexes = [x - self._offset for x in indexes]\n                return self.get_locations(indexes, as_list=True)\n\n        # just a single value\n        else:\n            return self.get(indexes)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate and return a Series from a DataFrame and specific columnname", "response": "def from_dataframe(cls, dataframe, column, offset=0):\n        \"\"\"\n        Creates and return a Series from a DataFrame and specific column\n\n        :param dataframe: raccoon DataFrame\n        :param column: column name\n        :param offset: offset value must be provided as there is no equivalent for a DataFrame\n        :return: Series\n        \"\"\"\n        return cls(data=dataframe.get_entire_column(column, as_list=True), index=dataframe.index,\n                   data_name=column, index_name=dataframe.index_name, sort=dataframe.sort, offset=offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates and return a Series from a Series", "response": "def from_series(cls, series, offset=0):\n        \"\"\"\n        Creates and return a Series from a Series\n\n        :param series: raccoon Series\n        :param offset: offset value must be provided as there is no equivalent for a DataFrame\n        :return: Series\n        \"\"\"\n        return cls(data=series.data, index=series.index, data_name=series.data_name, index_name=series.index_name,\n                   sort=series.sort, offset=offset)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, timeout=None):\n        if timeout:\n            try:\n                result = self._queue.get(True, timeout)\n            except multiprocessing.Queue.Empty:\n                return(False, None)\n            return(True, result)\n        return self._queue.get()", "response": "Get the next available item from the tube."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, timeout=None):\n        valid = False\n        result = None\n        for tube in self._output_tubes:\n            if timeout:\n                valid, result = tube.get(timeout)\n                if valid:\n                    result = result[0]\n            else:\n                result = tube.get()[0]\n        if timeout:\n            return valid, result\n        return result", "response": "Retrieve results from all the output tubes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef link(self, next_stage):\n        if next_stage is self: raise ValueError('cannot link stage to itself')\n        self._output_tubes.append(next_stage._input_tube)\n        self._next_stages.append(next_stage)\n        return self", "response": "Link this stage to the given downstream stage."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getLeaves(self):\n        result = list()\n        if not self._next_stages:\n            result.append(self)\n        else:\n            for stage in self._next_stages:\n                leaves = stage.getLeaves()\n                result += leaves\n        return result", "response": "Return the downstream leaf stages of this stage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate and start up the internal workers.", "response": "def build(self):\n        \"\"\"Create and start up the internal workers.\"\"\"\n\n        # If there's no output tube, it means that this stage\n        # is at the end of a fork (hasn't been linked to any stage downstream).\n        # Therefore, create one output tube.\n        if not self._output_tubes:\n            self._output_tubes.append(self._worker_class.getTubeClass()())\n\n        self._worker_class.assemble(\n            self._worker_args,\n            self._input_tube,\n            self._output_tubes,\n            self._size,\n            self._disable_result,\n            self._do_stop_task,\n            )\n\n        # Build all downstream stages.\n        for stage in self._next_stages:\n            stage.build()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, timeout=None):\n        if timeout:\n            # Todo: Consider locking the poll/recv block.\n            # Otherwise, this method is not thread safe.\n            if self._conn1.poll(timeout):\n                return (True, self._conn1.recv())\n            else:\n                return (False, None)\n        return self._conn1.recv()", "response": "Return the next available item from the tube."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _sort_columns(self, columns_list):\n        if not (all([x in columns_list for x in self._columns]) and all([x in self._columns for x in columns_list])):\n            raise ValueError(\n                'columns_list must be all in current columns, and all current columns must be in columns_list')\n        new_sort = [self._columns.index(x) for x in columns_list]\n        self._data = blist([self._data[x] for x in new_sort]) if self._blist else [self._data[x] for x in new_sort]\n        self._columns = blist([self._columns[x] for x in new_sort]) if self._blist \\\n            else [self._columns[x] for x in new_sort]", "response": "This function will sort the columns of the DataFrame to match the given order."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npad the data in DataFrame with [ None ] to ensure that all columns have the same length.", "response": "def _pad_data(self, max_len=None):\n        \"\"\"\n        Pad the data in DataFrame with [None} to ensure that all columns have the same length.\n\n        :param max_len: If provided will extend all columns to this length, if not then will use the longest column\n        :return: nothing\n        \"\"\"\n        if not max_len:\n            max_len = max([len(x) for x in self._data])\n        for _, col in enumerate(self._data):\n            col.extend([None] * (max_len - len(col)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, indexes=None, columns=None, as_list=False, as_dict=False):\n        if (indexes is None) and (columns is not None) and (not isinstance(columns, (list, blist))):\n            return self.get_entire_column(columns, as_list)\n\n        if indexes is None:\n            indexes = [True] * len(self._index)\n        if columns is None:\n            columns = [True] * len(self._columns)\n\n        if isinstance(indexes, (list, blist)) and isinstance(columns, (list, blist)):\n            return self.get_matrix(indexes, columns)\n        elif isinstance(indexes, (list, blist)) and (not isinstance(columns, (list, blist))):\n            return self.get_rows(indexes, columns, as_list)\n        elif (not isinstance(indexes, (list, blist))) and isinstance(columns, (list, blist)):\n            return self.get_columns(indexes, columns, as_dict)\n        else:\n            return self.get_cell(indexes, columns)", "response": "This method will return a sub - set of the DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_cell(self, index, column):\n        i = sorted_index(self._index, index) if self._sort else self._index.index(index)\n        c = self._columns.index(column)\n        return self._data[c][i]", "response": "Returns the value of the cell with the given index and column."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a DataFrame containing the values of the indexes in that column.", "response": "def get_rows(self, indexes, column, as_list=False):\n        \"\"\"\n        For a list of indexes and a single column name return the values of the indexes in that column.\n\n        :param indexes: either a list of index values or a list of booleans with same length as all indexes\n        :param column: single column name\n        :param as_list: if True return a list, if False return DataFrame\n        :return: DataFrame is as_list if False, a list if as_list is True\n        \"\"\"\n        c = self._columns.index(column)\n        if all([isinstance(i, bool) for i in indexes]):  # boolean list\n            if len(indexes) != len(self._index):\n                raise ValueError('boolean index list must be same size of existing index')\n            if all(indexes):  # the entire column\n                data = self._data[c]\n                index = self._index\n            else:\n                data = list(compress(self._data[c], indexes))\n                index = list(compress(self._index, indexes))\n        else:  # index values list\n            locations = [sorted_index(self._index, x) for x in indexes] if self._sort \\\n                else [self._index.index(x) for x in indexes]\n            data = [self._data[c][i] for i in locations]\n            index = [self._index[i] for i in locations]\n        return data if as_list else DataFrame(data={column: data}, index=index, index_name=self._index_name,\n                                              sort=self._sort)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_columns(self, index, columns=None, as_dict=False):\n        i = sorted_index(self._index, index) if self._sort else self._index.index(index)\n        return self.get_location(i, columns, as_dict)", "response": "Get the columns of a single index and list of column names"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the entire column of the data table.", "response": "def get_entire_column(self, column, as_list=False):\n        \"\"\"\n        Shortcut method to retrieve a single column all rows. Since this is a common use case this method will be\n        faster than the more general method.\n\n        :param column: single column name\n        :param as_list: if True return a list, if False return DataFrame\n        :return: DataFrame is as_list if False, a list if as_list is True\n        \"\"\"\n        c = self._columns.index(column)\n        data = self._data[c]\n        return data if as_list else DataFrame(data={column: data}, index=self._index, index_name=self._index_name,\n                                              sort=self._sort)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a DataFrame of the values for a list of indexes and columns.", "response": "def get_matrix(self, indexes, columns):\n        \"\"\"\n        For a list of indexes and list of columns return a DataFrame of the values.\n\n        :param indexes: either a list of index values or a list of booleans with same length as all indexes\n        :param columns: list of column names\n        :return: DataFrame\n        \"\"\"\n        if all([isinstance(i, bool) for i in indexes]):  # boolean list\n            is_bool_indexes = True\n            if len(indexes) != len(self._index):\n                raise ValueError('boolean index list must be same size of existing index')\n            bool_indexes = indexes\n            indexes = list(compress(self._index, indexes))\n        else:\n            is_bool_indexes = False\n            locations = [sorted_index(self._index, x) for x in indexes] if self._sort \\\n                else [self._index.index(x) for x in indexes]\n\n        if all([isinstance(i, bool) for i in columns]):  # boolean list\n            if len(columns) != len(self._columns):\n                raise ValueError('boolean column list must be same size of existing columns')\n            columns = list(compress(self._columns, columns))\n\n        col_locations = [self._columns.index(x) for x in columns]\n        data_dict = dict()\n\n        for c in col_locations:\n            data_dict[self._columns[c]] = list(compress(self._data[c], bool_indexes)) if is_bool_indexes \\\n                else [self._data[c][i] for i in locations]\n\n        return DataFrame(data=data_dict, index=indexes, columns=columns, index_name=self._index_name,\n                         sort=self._sort)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a DataFrame or dictionary of the values of the column with the given location.", "response": "def get_location(self, location, columns=None, as_dict=False, index=True):\n        \"\"\"\n        For an index location and either (1) list of columns return a DataFrame or dictionary of the values or\n        (2) single column name and return the value of that cell. This is optimized for speed because it does not need\n        to lookup the index location with a search. Also can accept relative indexing from the end of the DataFrame\n        in standard python notation [-3, -2, -1]\n        \n        :param location: index location in standard python form of positive or negative number\n        :param columns: list of columns, single column name, or None to include all columns\n        :param as_dict: if True then return a dictionary\n        :param index: if True then include the index in the dictionary if as_dict=True\n        :return: DataFrame or dictionary if columns is a list or value if columns is a single column name\n        \"\"\"\n        if columns is None:\n            columns = self._columns\n        elif not isinstance(columns, list):  # single value for columns\n            c = self._columns.index(columns)\n            return self._data[c][location]\n        elif all([isinstance(i, bool) for i in columns]):\n            if len(columns) != len(self._columns):\n                raise ValueError('boolean column list must be same size of existing columns')\n            columns = list(compress(self._columns, columns))\n        data = dict()\n        for column in columns:\n            c = self._columns.index(column)\n            data[column] = self._data[c][location]\n        index_value = self._index[location]\n        if as_dict:\n            if index:\n                data[self._index_name] = index_value\n            return data\n        else:\n            data = {k: [data[k]] for k in data}  # this makes the dict items lists\n            return DataFrame(data=data, index=[index_value], columns=columns, index_name=self._index_name,\n                             sort=self._sort)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a DataFrame or tuple of the index and data values of the entry in the table.", "response": "def get_slice(self, start_index=None, stop_index=None, columns=None, as_dict=False):\n        \"\"\"\n        For sorted DataFrames will return either a DataFrame or dict of all of the rows where the index is greater than\n        or equal to the start_index if provided and less than or equal to the stop_index if provided. If either the\n        start or stop index is None then will include from the first or last element, similar to standard python\n        slide of [:5] or [:5]. Both end points are considered inclusive.\n         \n        :param start_index: lowest index value to include, or None to start from the first row\n        :param stop_index: highest index value to include, or None to end at the last row\n        :param columns: list of column names to include, or None for all columns\n        :param as_dict: if True then return a tuple of (list of index, dict of column names: list data values)\n        :return: DataFrame or tuple\n        \"\"\"\n        if not self._sort:\n            raise RuntimeError('Can only use get_slice on sorted DataFrames')\n\n        if columns is None:\n            columns = self._columns\n        elif all([isinstance(i, bool) for i in columns]):\n            if len(columns) != len(self._columns):\n                raise ValueError('boolean column list must be same size of existing columns')\n            columns = list(compress(self._columns, columns))\n\n        start_location = bisect_left(self._index, start_index) if start_index is not None else None\n        stop_location = bisect_right(self._index, stop_index) if stop_index is not None else None\n\n        index = self._index[start_location:stop_location]\n        data = dict()\n        for column in columns:\n            c = self._columns.index(column)\n            data[column] = self._data[c][start_location:stop_location]\n\n        if as_dict:\n            return index, data\n        else:\n            data = data if data else None  # if the dict is empty, convert to None\n            return DataFrame(data=data, index=index, columns=columns, index_name=self._index_name, sort=self._sort,\n                             use_blist=self._blist)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _insert_row(self, i, index):\n        if i == len(self._index):\n            self._add_row(index)\n        else:\n            self._index.insert(i, index)\n            for c in range(len(self._columns)):\n                self._data[c].insert(i, None)", "response": "Insert a new row in the DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a new row to the DataFrame.", "response": "def _add_row(self, index):\n        \"\"\"\n        Add a new row to the DataFrame\n\n        :param index: index of the new row\n        :return: nothing\n        \"\"\"\n        self._index.append(index)\n        for c, _ in enumerate(self._columns):\n            self._data[c].append(None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new column to the DataFrame.", "response": "def _add_column(self, column):\n        \"\"\"\n        Add a new column to the DataFrame\n\n        :param column: column name\n        :return: nothing\n        \"\"\"\n        self._columns.append(column)\n        if self._blist:\n            self._data.append(blist([None] * len(self._index)))\n        else:\n            self._data.append([None] * len(self._index))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving indexes and columns will set a sub-set of the DataFrame to the values provided. This method will direct to the below methods based on what types are passed in for the indexes and columns. If the indexes or columns contains values not in the DataFrame then new rows or columns will be added. :param indexes: indexes value, list of indexes values, or a list of booleans. If None then all indexes are used :param columns: columns name, if None then all columns are used. Currently can only handle a single column or\\ all columns :param values: value or list of values to set (index, column) to. If setting just a single row, then must be a\\ dict where the keys are the column names. If a list then must be the same length as the indexes parameter, if\\ indexes=None, then must be the same and length of DataFrame :return: nothing", "response": "def set(self, indexes=None, columns=None, values=None):\n        \"\"\"\n        Given indexes and columns will set a sub-set of the DataFrame to the values provided. This method will direct\n        to the below methods based on what types are passed in for the indexes and columns. If the indexes or columns\n        contains values not in the DataFrame then new rows or columns will be added.\n\n        :param indexes: indexes value, list of indexes values, or a list of booleans. If None then all indexes are used\n        :param columns: columns name, if None then all columns are used. Currently can only handle a single column or\\\n        all columns\n        :param values: value or list of values to set (index, column) to. If setting just a single row, then must be a\\\n        dict where the keys are the column names. If a list then must be the same length as the indexes parameter, if\\\n        indexes=None, then must be the same and length of DataFrame\n        :return: nothing\n        \"\"\"\n        if (indexes is not None) and (columns is not None):\n            if isinstance(indexes, (list, blist)):\n                self.set_column(indexes, columns, values)\n            else:\n                self.set_cell(indexes, columns, values)\n        elif (indexes is not None) and (columns is None):\n            self.set_row(indexes, values)\n        elif (indexes is None) and (columns is not None):\n            self.set_column(indexes, columns, values)\n        else:\n            raise ValueError('either or both of indexes or columns must be provided')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the value of a single cell.", "response": "def set_cell(self, index, column, value):\n        \"\"\"\n        Sets the value of a single cell. If the index and/or column is not in the current index/columns then a new\n        index and/or column will be created.\n\n        :param index: index value\n        :param column: column name\n        :param value: value to set\n        :return: nothing\n        \"\"\"\n        if self._sort:\n            exists, i = sorted_exists(self._index, index)\n            if not exists:\n                self._insert_row(i, index)\n        else:\n            try:\n                i = self._index.index(index)\n            except ValueError:\n                i = len(self._index)\n                self._add_row(index)\n        try:\n            c = self._columns.index(column)\n        except ValueError:\n            c = len(self._columns)\n            self._add_column(column)\n        self._data[c][i] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_row(self, index, values):\n        if self._sort:\n            exists, i = sorted_exists(self._index, index)\n            if not exists:\n                self._insert_row(i, index)\n        else:\n            try:\n                i = self._index.index(index)\n            except ValueError:  # new row\n                i = len(self._index)\n                self._add_row(index)\n        if isinstance(values, dict):\n            if not (set(values.keys()).issubset(self._columns)):\n                raise ValueError('keys of values are not all in existing columns')\n            for c, column in enumerate(self._columns):\n                self._data[c][i] = values.get(column, self._data[c][i])\n        else:\n            raise TypeError('cannot handle values of this type.')", "response": "Sets the values of the columns in a single row."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset a column to a single value or list of values.", "response": "def set_column(self, index=None, column=None, values=None):\n        \"\"\"\n        Set a column to a single value or list of values. If any of the index values are not in the current indexes\n        then a new row will be created.\n\n        :param index: list of index values or list of booleans. If a list of booleans then the list must be the same\\\n        length as the DataFrame\n        :param column: column name\n        :param values: either a single value or a list. The list must be the same length as the index list if the index\\\n        list is values, or the length of the True values in the index list if the index list is booleans\n        :return: nothing\n        \"\"\"\n        try:\n            c = self._columns.index(column)\n        except ValueError:  # new column\n            c = len(self._columns)\n            self._add_column(column)\n        if index:  # index was provided\n            if all([isinstance(i, bool) for i in index]):  # boolean list\n                if not isinstance(values, (list, blist)):  # single value provided, not a list, so turn values into list\n                    values = [values for x in index if x]\n                if len(index) != len(self._index):\n                    raise ValueError('boolean index list must be same size of existing index')\n                if len(values) != index.count(True):\n                    raise ValueError('length of values list must equal number of True entries in index list')\n                indexes = [i for i, x in enumerate(index) if x]\n                for x, i in enumerate(indexes):\n                    self._data[c][i] = values[x]\n            else:  # list of index\n                if not isinstance(values, (list, blist)):  # single value provided, not a list, so turn values into list\n                    values = [values for _ in index]\n                if len(values) != len(index):\n                    raise ValueError('length of values and index must be the same.')\n                # insert or append indexes as needed\n                if self._sort:\n                    exists_tuples = list(zip(*[sorted_exists(self._index, x) for x in index]))\n                    exists = exists_tuples[0]\n                    indexes = exists_tuples[1]\n                    if not all(exists):\n                        self._insert_missing_rows(index)\n                        indexes = [sorted_index(self._index, x) for x in index]\n                else:\n                    try:  # all index in current index\n                        indexes = [self._index.index(x) for x in index]\n                    except ValueError:  # new rows need to be added\n                        self._add_missing_rows(index)\n                        indexes = [self._index.index(x) for x in index]\n                for x, i in enumerate(indexes):\n                    self._data[c][i] = values[x]\n        else:  # no index, only values\n            if not isinstance(values, (list, blist)):  # values not a list, turn into one of length same as index\n                values = [values for _ in self._index]\n            if len(values) != len(self._index):\n                raise ValueError('values list must be at same length as current index length.')\n            else:\n                self._data[c] = blist(values) if self._blist else values"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the values for the column values for the row at the given location.", "response": "def set_location(self, location, values, missing_to_none=False):\n        \"\"\"\n        Sets the column values, as given by the keys of the values dict, for the row at location to the values of the\n        values dict. If missing_to_none is False then columns not in the values dict will be left unchanged, if it is\n        True then they are set to None. This method does not add new columns and raises an error.\n        \n        :param location: location\n        :param values: dict of column names as keys and the value as the value to set the row for that column to \n        :param missing_to_none: if True set any column missing in the values to None, otherwise leave unchanged\n        :return: nothing\n        \"\"\"\n        if missing_to_none:\n            # populate the dict with None in any column missing\n            for column in self._columns:\n                if column not in values:\n                    values[column] = None\n\n        for column in values:\n            i = self._columns.index(column)\n            self._data[i][location] = values[column]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nappends a row of values to the end of the data.", "response": "def append_row(self, index, values, new_cols=True):\n        \"\"\"\n        Appends a row of values to the end of the data. If there are new columns in the values and new_cols is True\n        they will be added. Be very careful with this function as for sort DataFrames it will not enforce sort order. \n        Use this only for speed when needed, be careful.\n\n        :param index: value of the index\n        :param values: dictionary of values\n        :param new_cols: if True add new columns in values, if False ignore\n        :return: nothing\n        \"\"\"\n\n        if index in self._index:\n            raise IndexError('index already in DataFrame')\n\n        if new_cols:\n            for col in values:\n                if col not in self._columns:\n                    self._add_column(col)\n\n        # append index value\n        self._index.append(index)\n\n        # add data values, if not in values then use None\n        for c, col in enumerate(self._columns):\n            self._data[c].append(values.get(col, None))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nappend rows of values to the end of the data.", "response": "def append_rows(self, indexes, values, new_cols=True):\n        \"\"\"\n        Appends rows of values to the end of the data. If there are new columns in the values and new_cols is True\n        they will be added. Be very careful with this function as for sort DataFrames it will not enforce sort order. \n        Use this only for speed when needed, be careful.\n\n        :param indexes: list of indexes\n        :param values: dictionary of values where the key is the column name and the value is a list\n        :param new_cols: if True add new columns in values, if False ignore\n        :return: nothing\n        \"\"\"\n\n        # check that the values data is less than or equal to the length of the indexes\n        for column in values:\n            if len(values[column]) > len(indexes):\n                raise ValueError('length of %s column in values is longer than indexes' % column)\n\n        # check the indexes are not duplicates\n        combined_index = self._index + indexes\n        if len(set(combined_index)) != len(combined_index):\n            raise IndexError('duplicate indexes in DataFrames')\n\n        if new_cols:\n            for col in values:\n                if col not in self._columns:\n                    self._add_column(col)\n\n        # append index value\n        self._index.extend(indexes)\n\n        # add data values, if not in values then use None\n        for c, col in enumerate(self._columns):\n            self._data[c].extend(values.get(col, [None] * len(indexes)))\n        self._pad_data()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dict containing the key - value pairs of column names and the values of that column.", "response": "def to_dict(self, index=True, ordered=False):\n        \"\"\"\n        Returns a dict where the keys are the column names and the values are lists of the values for that column.\n\n        :param index: If True then include the index in the dict with the index_name as the key\n        :param ordered: If True then return an OrderedDict() to preserve the order of the columns in the DataFrame\n        :return: dict or OrderedDict()\n        \"\"\"\n        result = OrderedDict() if ordered else dict()\n        if index:\n            result.update({self._index_name: self._index})\n        if ordered:\n            data_dict = [(column, self._data[i]) for i, column in enumerate(self._columns)]\n        else:\n            data_dict = {column: self._data[i] for i, column in enumerate(self._columns)}\n        result.update(data_dict)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a JSON string of the entire DataFrame that can be reconstructed back with raccoon. from_json.", "response": "def to_json(self):\n        \"\"\"\n        Returns a JSON of the entire DataFrame that can be reconstructed back with raccoon.from_json(input). Any object\n        that cannot be serialized will be replaced with the representation of the object using repr(). In that instance\n        the DataFrame will have a string representation in place of the object and will not reconstruct exactly.\n\n        :return: json string\n        \"\"\"\n        input_dict = {'data': self.to_dict(index=False), 'index': list(self._index)}\n\n        # if blist, turn into lists\n        if self.blist:\n            input_dict['index'] = list(input_dict['index'])\n            for key in input_dict['data']:\n                input_dict['data'][key] = list(input_dict['data'][key])\n\n        meta_data = dict()\n        for key in self.__slots__:\n            if key not in ['_data', '_index']:\n                value = self.__getattribute__(key)\n                meta_data[key.lstrip('_')] = value if not isinstance(value, blist) else list(value)\n        meta_data['use_blist'] = meta_data.pop('blist')\n        input_dict['meta_data'] = meta_data\n        return json.dumps(input_dict, default=repr)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrename the columns of the table.", "response": "def rename_columns(self, rename_dict):\n        \"\"\"\n        Renames the columns\n\n        :param rename_dict: dict where the keys are the current column names and the values are the new names\n        :return: nothing\n        \"\"\"\n        if not all([x in self._columns for x in rename_dict.keys()]):\n            raise ValueError('all dictionary keys must be in current columns')\n        for current in rename_dict.keys():\n            self._columns[self._columns.index(current)] = rename_dict[current]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_all_rows(self):\n        del self._index[:]\n        for c in range(len(self._columns)):\n            del self._data[c][:]", "response": "Deletes all rows in the DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_columns(self, columns):\n        columns = [columns] if not isinstance(columns, (list, blist)) else columns\n        if not all([x in self._columns for x in columns]):\n            raise ValueError('all columns must be in current columns')\n        for column in columns:\n            c = self._columns.index(column)\n            del self._data[c]\n            del self._columns[c]\n        if not len(self._data):  # if all the columns have been deleted, remove index\n            self.index = list()", "response": "Delete columns from the DataFrame\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsorting the DataFrame by the index. The sort modifies the DataFrame inplace", "response": "def sort_index(self):\n        \"\"\"\n        Sort the DataFrame by the index. The sort modifies the DataFrame inplace\n\n        :return: nothing\n        \"\"\"\n        sort = sorted_list_indexes(self._index)\n        # sort index\n        self._index = blist([self._index[x] for x in sort]) if self._blist else [self._index[x] for x in sort]\n        # each column\n        for c in range(len(self._data)):\n            self._data[c] = blist([self._data[c][i] for i in sort]) if self._blist else [self._data[c][i] for i in sort]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sort_columns(self, column, key=None, reverse=False):\n        if isinstance(column, (list, blist)):\n            raise TypeError('Can only sort by a single column  ')\n        sort = sorted_list_indexes(self._data[self._columns.index(column)], key, reverse)\n        # sort index\n        self._index = blist([self._index[x] for x in sort]) if self._blist else [self._index[x] for x in sort]\n        # each column\n        for c in range(len(self._data)):\n            self._data[c] = blist([self._data[c][i] for i in sort]) if self._blist else [self._data[c][i] for i in sort]", "response": "Sort the DataFrame by one of the columns."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate the integrity of the DataFrame.", "response": "def validate_integrity(self):\n        \"\"\"\n        Validate the integrity of the DataFrame. This checks that the indexes, column names and internal data are not\n        corrupted. Will raise an error if there is a problem.\n\n        :return: nothing\n        \"\"\"\n        self._validate_columns(self._columns)\n        self._validate_index(self._index)\n        self._validate_data()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append(self, data_frame):\n        if len(data_frame) == 0:  # empty DataFrame, do nothing\n            return\n        data_frame_index = data_frame.index\n        combined_index = self._index + data_frame_index\n        if len(set(combined_index)) != len(combined_index):\n            raise ValueError('duplicate indexes in DataFrames')\n\n        for c, column in enumerate(data_frame.columns):\n            if PYTHON3:\n                self.set(indexes=data_frame_index, columns=column, values=data_frame.data[c].copy())\n            else:\n                self.set(indexes=data_frame_index, columns=column, values=data_frame.data[c][:])", "response": "Append another DataFrame to this DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add(self, left_column, right_column, indexes=None):\n        left_list, right_list = self._get_lists(left_column, right_column, indexes)\n        return [l + r for l, r in zip(left_list, right_list)]", "response": "This method adds element - wise two columns."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a boolean list where each element in the column is in the compare_list.", "response": "def isin(self, column, compare_list):\n        \"\"\"\n        Returns a boolean list where each elements is whether that element in the column is in the compare_list.\n\n        :param column: single column name, does not work for multiple columns\n        :param compare_list: list of items to compare to\n        :return: list of booleans\n        \"\"\"\n        return [x in compare_list for x in self._data[self._columns.index(column)]]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\niterate over DataFrame rows as dictionary of the values.", "response": "def iterrows(self, index=True):\n        \"\"\"\n        Iterates over DataFrame rows as dictionary of the values. The index will be included.\n\n        :param index: if True include the index in the results\n        :return: dictionary\n        \"\"\"\n        for i in range(len(self._index)):\n            row = {self._index_name: self._index[i]} if index else dict()\n            for c, col in enumerate(self._columns):\n                row[col] = self._data[c][i]\n            yield row"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates over DataFrame rows as tuple of the values.", "response": "def itertuples(self, index=True, name='Raccoon'):\n        \"\"\"\n        Iterates over DataFrame rows as tuple of the values.\n\n        :param index: if True then include the index\n        :param name: name of the namedtuple\n        :return: namedtuple\n        \"\"\"\n        fields = [self._index_name] if index else list()\n        fields.extend(self._columns)\n        row_tuple = namedtuple(name, fields)\n        for i in range(len(self._index)):\n            row = {self._index_name: self._index[i]} if index else dict()\n            for c, col in enumerate(self._columns):\n                row[col] = self._data[c][i]\n            yield row_tuple(**row)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reset_index(self, drop=False):\n        if not drop:\n            if isinstance(self.index_name, tuple):\n                index_data = list(map(list, zip(*self._index)))\n                for i in range(len(self.index_name)):\n                    self.set_column(column=self.index_name[i], values=index_data[i])\n            else:\n                col_name = self.index_name if self.index_name is not 'index' else 'index_0'\n                self.set_column(column=col_name, values=self._index)\n        self.index = list(range(self.__len__()))\n        self.index_name = 'index'", "response": "Resets the index of the DataFrame to simple integer list and the index name to index."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_json(cls, json_string):\n        input_dict = json.loads(json_string)\n        # convert index to tuple if required\n        if input_dict['index'] and isinstance(input_dict['index'][0], list):\n            input_dict['index'] = [tuple(x) for x in input_dict['index']]\n        # convert index_name to tuple if required\n        if isinstance(input_dict['meta_data']['index_name'], list):\n            input_dict['meta_data']['index_name'] = tuple(input_dict['meta_data']['index_name'])\n        data = input_dict['data'] if input_dict['data'] else None\n        return cls(data=data, index=input_dict['index'], **input_dict['meta_data'])", "response": "Creates and returns a DataFrame from a JSON string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef doTask(self, task):\n\n        # If we're not caching, then clear the table of last results.\n        if not self._cache_results:\n            self._last_results = dict()\n\n        # Iterate the list of pipelines, draining each one of any results.\n        # For pipelines whose current stream has less than *max_tasks* tasks \n        # remaining, feed them the current task.\n        for pipe in self._pipelines:\n\n            count = self._task_counts[pipe]\n\n            # Let's attempt to drain all (if any) results from the pipeline.\n            valid = True\n            last_result = None\n            while count and valid:\n                valid, result = pipe.get(sys.float_info.min)\n                if valid:\n                    last_result = result\n                    count -= 1\n\n            # Unless we're dropping results, save the last result (if any).\n            if not self._drop_results:\n                if last_result is not None:\n                    self._last_results[pipe] = last_result\n\n            # If there is room for the task, or if it is a \"stop\" request,\n            # put it on the pipeline.\n            if count <= self._max_tasks-1 or task is None:\n                pipe.put(task)\n                count += 1\n\n            # Update the task count for the pipeline.\n            self._task_counts[pipe] = count\n\n        # If we're only propagating the task, do so now.\n        if self._drop_results:\n            return task\n\n        # Otherwise, also propagate the assembly of pipeline results.\n        all_results = [res for res in self._last_results.values()]\n        return task, all_results", "response": "Filter input task to pipelines and return a tuple containing the task and the list of latest retrieved results from the pipelines."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assert_frame_equal(left, right, data_function=None, data_args=None):\n    if data_function:\n        data_args = {} if not data_args else data_args\n        data_function(left.data, right.data, **data_args)\n    else:\n        assert left.data == right.data\n    assert left.index == right.index\n    assert left.columns == right.columns\n    assert left.index_name == right.index_name\n    assert left.sort == right.sort\n    assert left.blist == right.blist", "response": "This function is used to assert that two DataFrames are equal."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assert_series_equal(left, right, data_function=None, data_args=None):\n    assert type(left) == type(right)\n    if data_function:\n        data_args = {} if not data_args else data_args\n        data_function(left.data, right.data, **data_args)\n    else:\n        assert left.data == right.data\n    assert left.index == right.index\n    assert left.data_name == right.data_name\n    assert left.index_name == right.index_name\n    assert left.sort == right.sort\n    if isinstance(left, rc.ViewSeries):\n        assert left.offset == right.offset\n    if isinstance(left, rc.Series):\n        assert left.blist == right.blist", "response": "This function is used to assert that two Series objects are equal."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the result from the pipeline.", "response": "def get(self, timeout=None):\n        \"\"\"Return result from the pipeline.\"\"\"\n        result = None\n        for stage in self._output_stages:\n            result = stage.get(timeout)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the lyrics from MetroLyrics.", "response": "def load(self):\n        \"\"\"Load the lyrics from MetroLyrics.\"\"\"\n        page = requests.get(self._url)\n        # Forces utf-8 to prevent character mangling\n        page.encoding = 'utf-8'\n\n        tree = html.fromstring(page.text)\n        lyric_div = tree.get_element_by_id('lyrics-body-text')\n        verses = [c.text_content() for c in lyric_div.find_class('verse')]\n        self._lyrics = '\\n\\n'.join(verses)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the list of songs.", "response": "def load(self, verbose=False):\n        \"\"\"\n        Load the list of songs.\n\n        Note that this only loads a list of songs that this artist was the main\n        artist of.  If they were only featured in the song, that song won't be\n        listed here.  There is a list on the artist page for that, I just\n        haven't added any parsing code for that, since I don't need it.\n        \"\"\"\n        self._songs = []\n        page_num = 1\n        total_pages = 1\n\n        while page_num <= total_pages:\n            if verbose:\n                print('retrieving page %d' % page_num)\n            page = requests.get(ARTIST_URL.format(artist=self.name,\n                                                  n=page_num))\n            tree = html.fromstring(page.text)\n            song_rows_xp = r'//*[@id=\"popular\"]/div/table/tbody/tr'\n            songlist_pagination_xp = r'//*[@id=\"main-content\"]/div[1]/'\\\n                                     'div[2]/p/span/a'\n\n            rows = tree.xpath(song_rows_xp)\n            for row in rows:\n                song_link = row.xpath(r'./td/a[contains(@class,\"title\")]')\n                assert len(song_link) == 1\n                self._songs.append(Song(url=song_link[0].attrib['href']))\n\n            total_pages = len(tree.xpath(songlist_pagination_xp))\n            page_num += 1\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the distance between two points on the surface of the Earth.", "response": "def distance(p0, p1, deg=True, r=r_earth_mean):\n    \"\"\"\n    Return the distance between two points on the surface of the Earth.\n\n    Parameters\n    ----------\n    p0 : point-like (or array of point-like) [longitude, latitude] objects\n    p1 : point-like (or array of point-like) [longitude, latitude] objects\n    deg : bool, optional (default True)\n        indicates if p0 and p1 are specified in degrees \n    r : float, optional (default r_earth_mean)\n        radius of the sphere \n\n    Returns\n    -------\n    d : float\n\n    Reference\n    ---------\n    http://www.movable-type.co.uk/scripts/latlong.html - Distance\n\n    Note: Spherical earth model. By default uses radius of 6371.0 km.\n\n    \"\"\"\n    single, (p0, p1) = _to_arrays((p0, 2), (p1, 2))\n    if deg:\n        p0 = np.radians(p0)\n        p1 = np.radians(p1)\n\n    lon0, lat0 = p0[:,0], p0[:,1]\n    lon1, lat1 = p1[:,0], p1[:,1]\n\n    # h_x used to denote haversine(x): sin^2(x / 2)\n    h_dlat = sin((lat1 - lat0) / 2.0) ** 2\n    h_dlon = sin((lon1 - lon0) / 2.0) ** 2\n    h_angle = h_dlat + cos(lat0) * cos(lat1) * h_dlon\n    angle = 2.0 * arcsin(sqrt(h_angle))\n    d = r * angle\n\n    if single:\n        d = d[0]\n\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the initial bearing along the great circle from p0 to p1.", "response": "def course(p0, p1, deg=True, bearing=False):\n    \"\"\"\n    Compute the initial bearing along the great circle from p0 to p1\n\n    NB: The angle returned by course() is not the traditional definition of\n    bearing. It is definted such that 0 degrees to due East increasing\n    counter-clockwise such that 90 degrees is due North. To obtain the bearing\n    (0 degrees is due North increasing clockwise so that 90 degrees is due\n    East), set the bearing flag input to True.\n\n    Parameters\n    ----------\n    p0 : point-like (or array of point-like) [lon, lat] objects\n    p1 : point-like (or array of point-like) [lon, lat] objects\n    deg : bool, optional (default True)\n        indicates if p0 and p1 are specified in degrees. The returned\n        angle is returned in the same units as the input.\n    bearing : bool, optional (default False)\n        If True, use the classical definition of bearing where 0 degrees is\n        due North increasing clockwise so that and 90 degrees is due East.\n\n    Reference\n    ---------\n    http://www.movable-type.co.uk/scripts/latlong.html - Bearing\n\n    \"\"\"\n    single, (p0, p1) = _to_arrays((p0, 2), (p1, 2))\n    if deg:\n        p0 = np.radians(p0)\n        p1 = np.radians(p1)\n\n    lon0, lat0 = p0[:,0], p0[:,1]\n    lon1, lat1 = p1[:,0], p1[:,1]\n\n    dlon = lon1 - lon0\n    a = sin(dlon) * cos(lat1)\n    b = cos(lat0) * sin(lat1) - sin(lat0) * cos(lat1) * cos(dlon)\n\n    if bearing:\n        angle = arctan2(a, b)\n    else:\n        angle = arctan2(b, a)\n\n    if deg:\n        angle = np.degrees(angle)\n\n    if single:\n        angle = angle[0]\n\n    return angle"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef propagate(p0, angle, d, deg=True, bearing=False, r=r_earth_mean):\n    single, (p0, angle, d) = _to_arrays((p0, 2), (angle, 1), (d, 1))\n    if deg:\n        p0 = np.radians(p0)\n        angle = np.radians(angle)\n\n    if not bearing:\n        angle = np.pi / 2.0 - angle\n\n    lon0, lat0 = p0[:,0], p0[:,1]\n\n    angd = d / r\n    lat1 = arcsin(sin(lat0) * cos(angd) + cos(lat0) * sin(angd) * cos(angle))\n\n    a = sin(angle) * sin(angd) * cos(lat0)\n    b = cos(angd) - sin(lat0) * sin(lat1)\n    lon1 = lon0 + arctan2(a, b)\n\n    p1 = np.column_stack([lon1, lat1])\n\n    if deg:\n        p1 = np.degrees(p1)\n\n    if single:\n        p1 = p1[0]\n\n    return p1", "response": "Given an initial point and angle move distance d along the surface\n    Returns a new object that is a copy of the base classical hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating the signature sent by weixin.", "response": "def validate(self, signature, timestamp, nonce):\n        \"\"\"Validate request signature.\n\n        :param signature: A string signature parameter sent by weixin.\n        :param timestamp: A int timestamp parameter sent by weixin.\n        :param nonce: A int nonce parameter sent by weixin.\n        \"\"\"\n        if not self.token:\n            raise RuntimeError('WEIXIN_TOKEN is missing')\n\n        if self.expires_in:\n            try:\n                timestamp = int(timestamp)\n            except (ValueError, TypeError):\n                # fake timestamp\n                return False\n\n            delta = time.time() - timestamp\n            if delta < 0:\n                # this is a fake timestamp\n                return False\n\n            if delta > self.expires_in:\n                # expired timestamp\n                return False\n\n        values = [self.token, str(timestamp), str(nonce)]\n        s = ''.join(sorted(values))\n        hsh = hashlib.sha1(s.encode('utf-8')).hexdigest()\n        return signature == hsh"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the xml body sent by weixin.", "response": "def parse(self, content):\n        \"\"\"Parse xml body sent by weixin.\n\n        :param content: A text of xml body.\n        \"\"\"\n        raw = {}\n\n        try:\n            root = etree.fromstring(content)\n        except SyntaxError as e:\n            raise ValueError(*e.args)\n\n        for child in root:\n            raw[child.tag] = child.text\n\n        formatted = self.format(raw)\n\n        msg_type = formatted['type']\n        msg_parser = getattr(self, 'parse_%s' % msg_type, None)\n        if callable(msg_parser):\n            parsed = msg_parser(raw)\n        else:\n            parsed = self.parse_invalid_type(raw)\n\n        formatted.update(parsed)\n        return formatted"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reply(self, username, type='text', sender=None, **kwargs):\n        sender = sender or self.sender\n        if not sender:\n            raise RuntimeError('WEIXIN_SENDER or sender argument is missing')\n\n        if type == 'text':\n            content = kwargs.get('content', '')\n            return text_reply(username, sender, content)\n\n        if type == 'music':\n            values = {}\n            for k in ('title', 'description', 'music_url', 'hq_music_url'):\n                values[k] = kwargs.get(k)\n            return music_reply(username, sender, **values)\n\n        if type == 'news':\n            items = kwargs.get('articles', [])\n            return news_reply(username, sender, *items)\n\n        if type == 'customer_service':\n            service_account = kwargs.get('service_account', None)\n            return transfer_customer_service_reply(username, sender,\n                                                   service_account)\n\n        if type == 'image':\n            media_id = kwargs.get('media_id', '')\n            return image_reply(username, sender, media_id)\n\n        if type == 'voice':\n            media_id = kwargs.get('media_id', '')\n            return voice_reply(username, sender, media_id)\n\n        if type == 'video':\n            values = {}\n            for k in ('media_id', 'title', 'description'):\n                values[k] = kwargs.get(k)\n            return video_reply(username, sender, **values)", "response": "Create the reply text for the user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register(self, key=None, func=None, **kwargs):\n        if func:\n            if key is None:\n                limitation = frozenset(kwargs.items())\n                self._registry_without_key.append((func, limitation))\n            else:\n                self._registry[key] = func\n            return func\n\n        return self.__call__(key, **kwargs)", "response": "Register a command helper function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef view_func(self):\n        if request is None:\n            raise RuntimeError('view_func need Flask be installed')\n\n        signature = request.args.get('signature')\n        timestamp = request.args.get('timestamp')\n        nonce = request.args.get('nonce')\n        if not self.validate(signature, timestamp, nonce):\n            return 'signature failed', 400\n\n        if request.method == 'GET':\n            echostr = request.args.get('echostr', '')\n            return echostr\n\n        try:\n            ret = self.parse(request.data)\n        except ValueError:\n            return 'invalid', 400\n\n        if 'type' not in ret:\n            # not a valid message\n            return 'invalid', 400\n\n        if ret['type'] == 'text' and ret['content'] in self._registry:\n            func = self._registry[ret['content']]\n        else:\n            ret_set = frozenset(ret.items())\n            matched_rules = (\n                _func for _func, _limitation in self._registry_without_key\n                if _limitation.issubset(ret_set))\n            func = next(matched_rules, None)  # first matched rule\n\n        if func is None:\n            if '*' in self._registry:\n                func = self._registry['*']\n            else:\n                func = 'failed'\n\n        if callable(func):\n            text = func(**ret)\n        else:\n            # plain text\n            text = self.reply(\n                username=ret['sender'],\n                sender=ret['receiver'],\n                content=func,\n            )\n\n        return Response(text, content_type='text/xml; charset=utf-8')", "response": "Default view function for Flask app."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npasses user inputs to GetGist and calls get", "response": "def run_getgist(filename, user, **kwargs):\n    \"\"\"Passes user inputs to GetGist() and calls get()\"\"\"\n    assume_yes = kwargs.get(\"yes_to_all\")\n    getgist = GetGist(user=user, filename=filename, assume_yes=assume_yes)\n    getgist.get()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npasses user inputs to GetGist and calls put", "response": "def run_putgist(filename, user, **kwargs):\n    \"\"\"Passes user inputs to GetGist() and calls put()\"\"\"\n    assume_yes = kwargs.get(\"yes_to_all\")\n    private = kwargs.get(\"private\")\n    getgist = GetGist(\n        user=user,\n        filename=filename,\n        assume_yes=assume_yes,\n        create_private=private,\n        allow_none=True,\n    )\n    getgist.put()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self):\n        if self.gist:\n            content = self.github.read_gist_file(self.gist)\n            self.local.save(content)", "response": "Reads the remote file from Gist and saves it locally"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef put(self):\n        content = self.local.read()\n        if self.gist:\n            self.github.update(self.gist, content)\n        else:\n            self.github.create(content, public=self.public)", "response": "Reads local file and updates the remote gist or creates a new one."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef oauth_only(function):\n\n    def check_for_oauth(self, *args, **kwargs):\n        \"\"\"\n        Returns False if GitHubTools instance is not authenticated, or return\n        the decorated fucntion if it is.\n        \"\"\"\n        if not self.is_authenticated:\n            self.oops(\"To use putgist you have to set your GETGIST_TOKEN\")\n            self.oops(\"(see `putgist --help` for details)\")\n            return False\n        return function(self, *args, **kwargs)\n\n    return check_for_oauth", "response": "Decorator to restrict some GitHubTools methods to run only with OAuth"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_oauth_header(self):\n        # abort if no token\n        oauth_token = self._get_token()\n        if not oauth_token:\n            return\n\n        # add oauth header & reach the api\n        self.headers[\"Authorization\"] = \"token \" + oauth_token\n        url = self._api_url(\"user\")\n        raw_resp = self.requests.get(url)\n        resp = raw_resp.json()\n\n        # abort & remove header if token is invalid\n        if resp.get(\"login\", None) != self.user:\n            self.oops(\"Invalid token for user \" + self.user)\n            self.headers.pop(\"Authorization\")\n            return\n\n        self.is_authenticated = True\n        self.yeah(\"User {} authenticated\".format(self.user))", "response": "Validate token and add the proper header for further requests."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_gists(self):\n        # fetch all gists\n        if self.is_authenticated:\n            url = self._api_url(\"gists\")\n        else:\n            url = self._api_url(\"users\", self.user, \"gists\")\n        self.output(\"Fetching \" + url)\n        raw_resp = self.requests.get(url)\n\n        # abort if user not found\n        if raw_resp.status_code != 200:\n            self.oops(\"User `{}` not found\".format(self.user))\n            return\n\n        # abort if there are no gists\n        resp = raw_resp.json()\n        if not resp:\n            self.oops(\"No gists found for user `{}`\".format(self.user))\n            return\n\n        # parse response\n        for gist in raw_resp.json():\n            yield self._parse_gist(gist)", "response": "Get all gists for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef select_gist(self, allow_none=False):\n        # pick up all macthing gists\n        matches = list()\n        for gist in self.get_gists():\n            for gist_file in gist.get(\"files\"):\n                if self.filename == gist_file.get(\"filename\"):\n                    matches.append(gist)\n\n        # abort if no match is found\n        if not matches:\n            if allow_none:\n                return None\n            else:\n                msg = \"No file named `{}` found in {}'s gists\"\n                self.oops(msg.format(self.file_path, self.user))\n                if not self.is_authenticated:\n                    self.warn(\"To access private gists set the GETGIST_TOKEN\")\n                    self.warn(\"(see `getgist --help` for details)\")\n                return False\n\n        # return if there's is only one match\n        if len(matches) == 1 or self.assume_yes:\n            return matches.pop(0)\n\n        return self._ask_which_gist(matches)", "response": "This method selects the proper gist for the given filename. If more than one gist is found it returns the proper gist ; if no gist is found it returns False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading a gist file from GitHub", "response": "def read_gist_file(self, gist):\n        \"\"\"\n        Returns the contents of file hosted inside a gist at GitHub.\n        :param gist: (dict) gist parsed by GitHubTools._parse()\n        :return: (bytes) content of a gist loaded from GitHub\n        \"\"\"\n        url = False\n        files = gist.get(\"files\")\n        for gist_file in files:\n            if gist_file.get(\"filename\") == self.filename:\n                url = gist_file.get(\"raw_url\")\n                break\n        if url:\n            self.output(\"Reading {}\".format(url))\n            response = self.requests.get(url)\n            return response.content"}
