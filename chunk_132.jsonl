{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the Twitter Bootstrap JavaScript file.", "response": "def djfrontend_twbs_js(version=None, files=None):\n    \"\"\"\n    Returns Twitter Bootstrap JavaScript file(s).\n    all returns concatenated file; full file for TEMPLATE_DEBUG, minified otherwise.\n\n    Other choice are:\n        affix,\n        alert,\n        button,\n        carousel,\n        collapse,\n        dropdown,\n        modal,\n        popover (adds tooltip if not included),\n        scrollspy,\n        tab,\n        tooltip,\n        transition.\n\n    Individual files are not minified.\n    \"\"\"\n    if version is None:\n        if not getattr(settings, 'DJFRONTEND_TWBS_JS_VERSION', False):\n            version = getattr(settings, 'DJFRONTEND_TWBS_VERSION', DJFRONTEND_TWBS_VERSION_DEFAULT)\n        else:\n            version = getattr(settings, 'DJFRONTEND_TWBS_JS_VERSION', DJFRONTEND_TWBS_VERSION_DEFAULT)\n\n    if files:\n        if files != 'all':\n            files = files.split(' ')\n    elif getattr(settings, 'DJFRONTEND_TWBS_JS_FILES', False) and settings.DJFRONTEND_TWBS_JS_FILES != 'all':\n        files = settings.DJFRONTEND_TWBS_JS_FILES.split(' ')\n    else:\n        files = 'all'\n\n    if files == 'all':\n        return format_html(\n            '<script src=\"//cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/{v}/js/bootstrap.min.js\"></script>\\n'\n            '<script>window.jQuery.fn.scrollspy || document.write(\\'<script src=\"{static}djfrontend/js/twbs/{v}/bootstrap.min.js\"><\\/script>\\')</script>',\n            v=version, static=_static_url)\n    else:\n        if 'popover' in files and 'tooltip' not in files:\n            files.append('tooltip')\n        for file in files:\n            file = ['<script src=\"%sdjfrontend/js/twbs/%s/%s.js\"></script>' %\n                    (_static_url, version, file) for file in files]\n        return mark_safe('\\n'.join(file))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef djfrontend_ga(account=None):\n    if account is None:\n        account = getattr(settings, 'DJFRONTEND_GA', False)\n\n    if account:\n        if getattr(settings, 'TEMPLATE_DEBUG', False):\n            return ''\n        else:\n            if getattr(settings, 'DJFRONTEND_GA_SETDOMAINNAME', False):\n                if getattr(settings, 'DJFRONTEND_GA_SETALLOWLINKER', False):\n                    return mark_safe(\n                        '<script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,\"script\",\"//www.google-analytics.com/analytics.js\",\"ga\");ga(\"require\", \"linker\");ga(\"linker:autoLink\", [\"%s\"]);ga(\"create\", \"%s\", \"auto\", {\"allowLinker\": true});ga(\"send\", \"pageview\");</script>' %\n                        (settings.DJFRONTEND_GA_SETDOMAINNAME, account))\n                else:\n                    return mark_safe(\n                        '<script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,\"script\",\"//www.google-analytics.com/analytics.js\",\"ga\");ga(\"create\", \"%s\", \"%s\");ga(\"send\", \"pageview\");</script>' %\n                        (account, settings.DJFRONTEND_GA_SETDOMAINNAME))\n            else:\n                return mark_safe(\n                    '<script>(function(i,s,o,g,r,a,m){i[\"GoogleAnalyticsObject\"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,\"script\",\"//www.google-analytics.com/analytics.js\",\"ga\");ga(\"create\", \"%s\", \"auto\");ga(\"send\", \"pageview\");</script>' % account)\n    else:\n        return ''", "response": "Returns a JavaScript snippet that can be used to display Google Analytics asynchronous snippet."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter_auth_hashes(user, purpose, minutes_valid):\n    now = timezone.now().replace(microsecond=0, second=0)\n    for minute in range(minutes_valid + 1):\n        yield hashlib.sha1(\n            '%s:%s:%s:%s:%s' % (\n                now - datetime.timedelta(minutes=minute),\n                user.password,\n                purpose,\n                user.pk,\n                settings.SECRET_KEY,\n            ),\n        ).hexdigest()", "response": "Generate auth token hashes for a user and purpose."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calc_expiry_time(minutes_valid):\n    return (\n        timezone.now() + datetime.timedelta(minutes=minutes_valid + 1)\n    ).replace(second=0, microsecond=0)", "response": "Calculate the time an auth_hash will expire."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns login token info for given user.", "response": "def get_user_token(user, purpose, minutes_valid):\n    \"\"\"Return login token info for given user.\"\"\"\n    token = ''.join(\n        dumps([\n            user.get_username(),\n            get_auth_hash(user, purpose),\n        ]).encode('base64').split('\\n')\n    )\n    return {\n        'id': get_meteor_id(user),\n        'token': token,\n        'tokenExpires': calc_expiry_time(minutes_valid),\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nserializing user as per Meteor accounts serialization.", "response": "def serialize(self, obj, *args, **kwargs):\n        \"\"\"Serialize user as per Meteor accounts serialization.\"\"\"\n        # use default serialization, then modify to suit our needs.\n        data = super(Users, self).serialize(obj, *args, **kwargs)\n\n        # everything that isn't handled explicitly ends up in `profile`\n        profile = data.pop('fields')\n        profile.setdefault('name', obj.get_full_name())\n        fields = data['fields'] = {\n            'username': obj.get_username(),\n            'emails': [],\n            'profile': profile,\n            'permissions': sorted(self.model.get_all_permissions(obj)),\n        }\n\n        # clear out sensitive data\n        for sensitive in [\n                'password',\n                'user_permissions_ids',\n                'is_active',\n                'is_staff',\n                'is_superuser',\n                'groups_ids',\n        ]:\n            profile.pop(sensitive, None)\n\n        # createdAt (default is django.contrib.auth.models.User.date_joined)\n        try:\n            fields['createdAt'] = profile.pop('date_joined')\n        except KeyError:\n            date_joined = getattr(\n                obj, 'get_date_joined',\n                lambda: getattr(obj, 'date_joined', None)\n            )()\n            if date_joined:\n                fields['createdAt'] = date_joined\n\n        # email (default is django.contrib.auth.models.User.email)\n        try:\n            email = profile.pop('email')\n        except KeyError:\n            email = getattr(\n                obj, 'get_email',\n                lambda: getattr(obj, 'email', None)\n            )()\n        if email:\n            fields['emails'].append({'address': email, 'verified': True})\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deserialize_profile(profile, key_prefix='', pop=False):\n        result = {}\n        if pop:\n            getter = profile.pop\n        else:\n            getter = profile.get\n\n        def prefixed(name):\n            \"\"\"Return name prefixed by `key_prefix`.\"\"\"\n            return '%s%s' % (key_prefix, name)\n\n        for key in profile.keys():\n            val = getter(key)\n            if key == prefixed('name'):\n                result['full_name'] = val\n            else:\n                raise MeteorError(400, 'Bad profile key: %r' % key)\n        return result", "response": "De - serialize user profile fields into concrete model fields."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve the current user from the database.", "response": "def user_factory(self):\n        \"\"\"Retrieve the current user (or None) from the database.\"\"\"\n        if this.user_id is None:\n            return None\n        return self.user_model.objects.get(pk=this.user_id)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating subs to send added and removed for collections with user_rel.", "response": "def update_subs(new_user_id):\n        \"\"\"Update subs to send added/removed for collections with user_rel.\"\"\"\n        for sub in Subscription.objects.filter(connection=this.ws.connection):\n            params = loads(sub.params_ejson)\n            pub = API.get_pub_by_name(sub.publication)\n\n            # calculate the querysets prior to update\n            pre = collections.OrderedDict([\n                (col, query) for col, query\n                in API.sub_unique_objects(sub, params, pub)\n            ])\n\n            # save the subscription with the updated user_id\n            sub.user_id = new_user_id\n            sub.save()\n\n            # calculate the querysets after the update\n            post = collections.OrderedDict([\n                (col, query) for col, query\n                in API.sub_unique_objects(sub, params, pub)\n            ])\n\n            # first pass, send `added` for objs unique to `post`\n            for col_post, query in post.items():\n                try:\n                    qs_pre = pre[col_post]\n                    query = query.exclude(\n                        pk__in=qs_pre.order_by().values('pk'),\n                    )\n                except KeyError:\n                    # collection not included pre-auth, everything is added.\n                    pass\n                for obj in query:\n                    this.ws.send(col_post.obj_change_as_msg(obj, ADDED))\n\n            # second pass, send `removed` for objs unique to `pre`\n            for col_pre, query in pre.items():\n                try:\n                    qs_post = post[col_pre]\n                    query = query.exclude(\n                        pk__in=qs_post.order_by().values('pk'),\n                    )\n                except KeyError:\n                    # collection not included post-auth, everything is removed.\n                    pass\n                for obj in query:\n                    this.ws.send(col_pre.obj_change_as_msg(obj, REMOVED))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validated_user(cls, token, purpose, minutes_valid):\n        try:\n            username, auth_hash = loads(token.decode('base64'))\n        except (ValueError, Error):\n            cls.auth_failed(token=token)\n        try:\n            user = cls.user_model.objects.get(**{\n                cls.user_model.USERNAME_FIELD: username,\n                'is_active': True,\n            })\n            user.backend = 'django.contrib.auth.backends.ModelBackend'\n        except cls.user_model.DoesNotExist:\n            cls.auth_failed(username=username, token=token)\n        if auth_hash not in iter_auth_hashes(user, purpose, minutes_valid):\n            cls.auth_failed(username=username, token=token)\n        return user", "response": "Resolve and validate auth token returns user object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_secure():\n        if this.request.is_secure():\n            return True  # using SSL\n        elif this.request.META['REMOTE_ADDR'] in [\n                'localhost',\n                '127.0.0.1',\n        ]:\n            return True  # localhost\n        raise MeteorError(403, 'Authentication refused without SSL.')", "response": "Check request return False if using SSL or local connection."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve username from user selector.", "response": "def get_username(self, user):\n        \"\"\"Retrieve username from user selector.\"\"\"\n        if isinstance(user, basestring):\n            return user\n        elif isinstance(user, dict) and len(user) == 1:\n            [(key, val)] = user.items()\n            if key == 'username' or (key == self.user_model.USERNAME_FIELD):\n                # username provided directly\n                return val\n            elif key in ('email', 'emails.address'):\n                email_field = getattr(self.user_model, 'EMAIL_FIELD', 'email')\n                if self.user_model.USERNAME_FIELD == email_field:\n                    return val  # email is username\n                # find username by email\n                return self.user_model.objects.values_list(\n                    self.user_model.USERNAME_FIELD, flat=True,\n                ).get(**{email_field: val})\n            elif key in ('id', 'pk'):\n                # find username by primary key (ID)\n                return self.user_model.objects.values_list(\n                    self.user_model.USERNAME_FIELD, flat=True,\n                ).get(\n                    pk=val,\n                )\n            else:\n                raise MeteorError(400, 'Invalid user lookup: %r' % key)\n        else:\n            raise MeteorError(400, 'Invalid user expression: %r' % user)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister a new user account.", "response": "def create_user(self, params):\n        \"\"\"Register a new user account.\"\"\"\n        receivers = create_user.send(\n            sender=__name__,\n            request=this.request,\n            params=params,\n        )\n        if len(receivers) == 0:\n            raise NotImplementedError(\n                'Handler for `create_user` not registered.'\n            )\n        user = receivers[0][1]\n        user = auth.authenticate(\n            username=user.get_username(), password=params['password'],\n        )\n        self.do_login(user)\n        return get_user_token(\n            user=user, purpose=HashPurpose.RESUME_LOGIN,\n            minutes_valid=HASH_MINUTES_VALID[HashPurpose.RESUME_LOGIN],\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlog a user in and update the internal state.", "response": "def do_login(self, user):\n        \"\"\"Login a user.\"\"\"\n        this.user_id = user.pk\n        this.user_ddp_id = get_meteor_id(user)\n        # silent subscription (sans sub/nosub msg) to LoggedInUser pub\n        this.user_sub_id = meteor_random_id()\n        API.do_sub(this.user_sub_id, 'LoggedInUser', silent=True)\n        self.update_subs(user.pk)\n        user_logged_in.send(\n            sender=user.__class__, request=this.request, user=user,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef login(self, params):\n        if 'password' in params:\n            return self.login_with_password(params)\n        elif 'resume' in params:\n            return self.login_with_resume_token(params)\n        else:\n            self.auth_failed(**params)", "response": "Login either with resume token or password."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef login_with_password(self, params):\n        # never allow insecure login\n        self.check_secure()\n\n        username = self.get_username(params['user'])\n        password = self.get_password(params['password'])\n\n        user = auth.authenticate(username=username, password=password)\n        if user is not None:\n            # the password verified for the user\n            if user.is_active:\n                self.do_login(user)\n                return get_user_token(\n                    user=user, purpose=HashPurpose.RESUME_LOGIN,\n                    minutes_valid=HASH_MINUTES_VALID[HashPurpose.RESUME_LOGIN],\n                )\n\n        # Call to `authenticate` couldn't verify the username and password.\n        # It will have sent the `user_login_failed` signal, no need to pass the\n        # `username` argument to auth_failed().\n        self.auth_failed()", "response": "Authenticate using credentials supplied in params."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef login_with_resume_token(self, params):\n        # never allow insecure login\n        self.check_secure()\n\n        # pull the username and auth_hash from the token\n        user = self.validated_user(\n            params['resume'], purpose=HashPurpose.RESUME_LOGIN,\n            minutes_valid=HASH_MINUTES_VALID[HashPurpose.RESUME_LOGIN],\n        )\n\n        self.do_login(user)\n        return get_user_token(\n            user=user, purpose=HashPurpose.RESUME_LOGIN,\n            minutes_valid=HASH_MINUTES_VALID[HashPurpose.RESUME_LOGIN],\n        )", "response": "Login with existing resume token."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrequesting password reset email.", "response": "def forgot_password(self, params):\n        \"\"\"Request password reset email.\"\"\"\n        username = self.get_username(params)\n        try:\n            user = self.user_model.objects.get(**{\n                self.user_model.USERNAME_FIELD: username,\n            })\n        except self.user_model.DoesNotExist:\n            self.auth_failed()\n\n        minutes_valid = HASH_MINUTES_VALID[HashPurpose.PASSWORD_RESET]\n        token = get_user_token(\n            user=user, purpose=HashPurpose.PASSWORD_RESET,\n            minutes_valid=minutes_valid,\n        )\n\n        forgot_password.send(\n            sender=__name__,\n            user=user,\n            token=token,\n            request=this.request,\n            expiry_date=calc_expiry_time(minutes_valid),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nresets password using a token received in email then logs user in.", "response": "def reset_password(self, token, new_password):\n        \"\"\"Reset password using a token received in email then logs user in.\"\"\"\n        user = self.validated_user(\n            token, purpose=HashPurpose.PASSWORD_RESET,\n            minutes_valid=HASH_MINUTES_VALID[HashPurpose.PASSWORD_RESET],\n        )\n        user.set_password(new_password)\n        user.save()\n        self.do_login(user)\n        return {\"userId\": this.user_ddp_id}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dict_merge(lft, rgt):\n    if not isinstance(rgt, dict):\n        return rgt\n    result = deepcopy(lft)\n    for key, val in rgt.iteritems():\n        if key in result and isinstance(result[key], dict):\n            result[key] = dict_merge(result[key], val)\n        else:\n            result[key] = deepcopy(val)\n    return result", "response": "Recursive dict merge.\n\n    Recursively merges dict's. not just simple lft['key'] = rgt['key'], if\n    both lft and rgt have a key who's value is a dict then dict_merge is\n    called on both values and the result stored in the returned dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread encoded contents from specified path or return default.", "response": "def read(path, default=None, encoding='utf8'):\n    \"\"\"Read encoded contents from specified path or return default.\"\"\"\n    if not path:\n        return default\n    try:\n        with io.open(path, mode='r', encoding=encoding) as contents:\n            return contents.read()\n    except IOError:\n        if default is not None:\n            return default\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns HTML or other related content for Meteor.", "response": "def get(self, request, path):\n        \"\"\"Return HTML (or other related content) for Meteor.\"\"\"\n        if path == 'meteor_runtime_config.js':\n            config = {\n                'DDP_DEFAULT_CONNECTION_URL': request.build_absolute_uri('/'),\n                'PUBLIC_SETTINGS': self.meteor_settings.get('public', {}),\n                'ROOT_URL': request.build_absolute_uri(\n                    '%s/' % (\n                        self.runtime_config.get('ROOT_URL_PATH_PREFIX', ''),\n                    ),\n                ),\n                'ROOT_URL_PATH_PREFIX': '',\n            }\n            # Use HTTPS instead of HTTP if SECURE_SSL_REDIRECT is set\n            if config['DDP_DEFAULT_CONNECTION_URL'].startswith('http:') \\\n                    and settings.SECURE_SSL_REDIRECT:\n                config['DDP_DEFAULT_CONNECTION_URL'] = 'https:%s' % (\n                    config['DDP_DEFAULT_CONNECTION_URL'].split(':', 1)[1],\n                )\n            config.update(self.runtime_config)\n            return HttpResponse(\n                '__meteor_runtime_config__ = %s;' % dumps(config),\n                content_type='text/javascript',\n            )\n        try:\n            file_path, content_type = self.url_map[path]\n            with open(file_path, 'r') as content:\n                return HttpResponse(\n                    content.read(),\n                    content_type=content_type,\n                )\n        except KeyError:\n            return HttpResponse(self.html)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an Alea ID for the given object or model.", "response": "def get_meteor_id(obj_or_model, obj_pk=None):\n    \"\"\"Return an Alea ID for the given object.\"\"\"\n    if obj_or_model is None:\n        return None\n    # Django model._meta is now public API -> pylint: disable=W0212\n    meta = obj_or_model._meta\n    model = meta.model\n    if model is ObjectMapping:\n        # this doesn't make sense - raise TypeError\n        raise TypeError(\"Can't map ObjectMapping instances through self.\")\n\n    # try getting value of AleaIdField straight from instance if possible\n    if isinstance(obj_or_model, model):\n        # obj_or_model is an instance, not a model.\n        if isinstance(meta.pk, AleaIdField):\n            return obj_or_model.pk\n        if obj_pk is None:\n            # fall back to primary key, but coerce as string type for lookup.\n            obj_pk = str(obj_or_model.pk)\n    alea_unique_fields = [\n        field\n        for field in meta.local_fields\n        if isinstance(field, AleaIdField) and field.unique\n    ]\n    if len(alea_unique_fields) == 1:\n        # found an AleaIdField with unique=True, assume it's got the value.\n        aid = alea_unique_fields[0].attname\n        if isinstance(obj_or_model, model):\n            val = getattr(obj_or_model, aid)\n        elif obj_pk is None:\n            val = None\n        else:\n            val = model.objects.values_list(aid, flat=True).get(\n                pk=obj_pk,\n            )\n        if val:\n            return val\n\n    if obj_pk is None:\n        # bail out if args are (model, pk) but pk is None.\n        return None\n\n    # fallback to using AleaIdField from ObjectMapping model.\n    content_type = ContentType.objects.get_for_model(model)\n    try:\n        return ObjectMapping.objects.values_list(\n            'meteor_id', flat=True,\n        ).get(\n            content_type=content_type,\n            object_id=obj_pk,\n        )\n    except ObjectDoesNotExist:\n        return ObjectMapping.objects.create(\n            content_type=content_type,\n            object_id=obj_pk,\n            meteor_id=meteor_random_id('/collection/%s' % meta),\n        ).meteor_id"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_meteor_ids(model, object_ids):\n    # Django model._meta is now public API -> pylint: disable=W0212\n    meta = model._meta\n    result = collections.OrderedDict(\n        (str(obj_pk), None)\n        for obj_pk\n        in object_ids\n    )\n    if isinstance(meta.pk, AleaIdField):\n        # primary_key is an AleaIdField, use it.\n        return collections.OrderedDict(\n            (obj_pk, obj_pk) for obj_pk in object_ids\n        )\n    alea_unique_fields = [\n        field\n        for field in meta.local_fields\n        if isinstance(field, AleaIdField) and field.unique and not field.null\n    ]\n    if len(alea_unique_fields) == 1:\n        aid = alea_unique_fields[0].name\n        query = model.objects.filter(\n            pk__in=object_ids,\n        ).values_list('pk', aid)\n    else:\n        content_type = ContentType.objects.get_for_model(model)\n        query = ObjectMapping.objects.filter(\n            content_type=content_type,\n            object_id__in=list(result)\n        ).values_list('object_id', 'meteor_id')\n    for obj_pk, meteor_id in query:\n        result[str(obj_pk)] = meteor_id\n    for obj_pk, meteor_id in result.items():\n        if meteor_id is None:\n            result[obj_pk] = get_meteor_id(model, obj_pk)\n    return result", "response": "Return Alea ID mapping for all given ids of specified model."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_object_id(model, meteor_id):\n    if meteor_id is None:\n        return None\n    # Django model._meta is now public API -> pylint: disable=W0212\n    meta = model._meta\n\n    if model is ObjectMapping:\n        # this doesn't make sense - raise TypeError\n        raise TypeError(\"Can't map ObjectMapping instances through self.\")\n\n    if isinstance(meta.pk, AleaIdField):\n        # meteor_id is the primary key\n        return meteor_id\n\n    alea_unique_fields = [\n        field\n        for field in meta.local_fields\n        if isinstance(field, AleaIdField) and field.unique\n    ]\n    if len(alea_unique_fields) == 1:\n        # found an AleaIdField with unique=True, assume it's got the value.\n        val = model.objects.values_list(\n            'pk', flat=True,\n        ).get(**{\n            alea_unique_fields[0].attname: meteor_id,\n        })\n        if val:\n            return val\n\n    content_type = ContentType.objects.get_for_model(model)\n    return ObjectMapping.objects.filter(\n        content_type=content_type,\n        meteor_id=meteor_id,\n    ).values_list('object_id', flat=True).get()", "response": "Return an object ID for the given meteor_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_object_ids(model, meteor_ids):\n    if model is ObjectMapping:\n        # this doesn't make sense - raise TypeError\n        raise TypeError(\"Can't map ObjectMapping instances through self.\")\n    # Django model._meta is now public API -> pylint: disable=W0212\n    meta = model._meta\n    alea_unique_fields = [\n        field\n        for field in meta.local_fields\n        if isinstance(field, AleaIdField) and field.unique and not field.null\n    ]\n    result = collections.OrderedDict(\n        (str(meteor_id), None)\n        for meteor_id\n        in meteor_ids\n    )\n    if len(alea_unique_fields) == 1:\n        aid = alea_unique_fields[0].name\n        query = model.objects.filter(**{\n            '%s__in' % aid: meteor_ids,\n        }).values_list(aid, 'pk')\n    else:\n        content_type = ContentType.objects.get_for_model(model)\n        query = ObjectMapping.objects.filter(\n                content_type=content_type,\n                meteor_id__in=meteor_ids,\n        ).values_list('meteor_id', 'object_id')\n    for meteor_id, object_id in query:\n        result[meteor_id] = object_id\n    return result", "response": "Return all object IDs for the given meteor_ids."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an object for the given meteor_id.", "response": "def get_object(model, meteor_id, *args, **kwargs):\n    \"\"\"Return an object for the given meteor_id.\"\"\"\n    # Django model._meta is now public API -> pylint: disable=W0212\n    meta = model._meta\n    if isinstance(meta.pk, AleaIdField):\n        # meteor_id is the primary key\n        return model.objects.filter(*args, **kwargs).get(pk=meteor_id)\n\n    alea_unique_fields = [\n        field\n        for field in meta.local_fields\n        if isinstance(field, AleaIdField) and field.unique and not field.null\n    ]\n    if len(alea_unique_fields) == 1:\n        return model.objects.filter(*args, **kwargs).get(**{\n            alea_unique_fields[0].name: meteor_id,\n        })\n\n    return model.objects.filter(*args, **kwargs).get(\n        pk=get_object_id(model, meteor_id),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate ID if required.", "response": "def get_pk_value_on_save(self, instance):\n        \"\"\"Generate ID if required.\"\"\"\n        value = super(AleaIdField, self).get_pk_value_on_save(instance)\n        if not value:\n            value = self.get_seeded_value(instance)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates ID if required.", "response": "def pre_save(self, model_instance, add):\n        \"\"\"Generate ID if required.\"\"\"\n        value = super(AleaIdField, self).pre_save(model_instance, add)\n        if (not value) and self.default in (meteor_random_id, NOT_PROVIDED):\n            value = self.get_seeded_value(model_instance)\n            setattr(model_instance, self.attname, value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_default_forwards(app_name, operation, apps, schema_editor):\n    model = apps.get_model(app_name, operation.model_name)\n    for obj_pk in model.objects.values_list('pk', flat=True):\n        model.objects.filter(pk=obj_pk).update(**{\n            operation.name: get_meteor_id(model, obj_pk),\n        })", "response": "Set default value for AleaIdField."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing schema_editor to apply any forward changes.", "response": "def database_forwards(self, app_label, schema_editor, from_state, to_state):\n        \"\"\"Use schema_editor to apply any forward changes.\"\"\"\n        self.truncate(app_label, schema_editor, self.truncate_forwards)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef database_backwards(self, app_label, schema_editor, from_state, to_state):\n        self.truncate(app_label, schema_editor, self.truncate_backwards)", "response": "Use schema_editor to apply any reverse changes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting command option defaults.", "response": "def initialize_options(self):\n        \"\"\"Set command option defaults.\"\"\"\n        setuptools.command.build_py.build_py.initialize_options(self)\n        self.meteor = 'meteor'\n        self.meteor_debug = False\n        self.build_lib = None\n        self.package_dir = None\n        self.meteor_builds = []\n        self.no_prune_npm = None\n        self.inplace = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef path_to_dir(*path_args):\n        return os.path.join(\n            *list(path_args[:-1]) + path_args[-1].split(posixpath.sep)\n        )", "response": "Convert a UNIX - style path into platform specific directory spec."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef seed(self, values):\n        if not values:\n            # Meteor uses epoch seconds as the seed if no args supplied, we use\n            # a much more secure seed by default to avoid hash collisions.\n            seed_ids = [int, str, random, self, values, self.__class__]\n            random.shuffle(seed_ids)\n            values = list(map(id, seed_ids)) + [time.time(), os.urandom(512)]\n\n        mash = Mash()\n        self.c = 1\n        self.s0 = mash(' ')\n        self.s1 = mash(' ')\n        self.s2 = mash(' ')\n\n        for val in values:\n            self.s0 -= mash(val)\n            if self.s0 < 0:\n                self.s0 += 1\n            self.s1 -= mash(val)\n            if self.s1 < 0:\n                self.s1 += 1\n            self.s2 -= mash(val)\n            if self.s2 < 0:\n                self.s2 += 1", "response": "Seed internal state from supplied values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef state(self):\n        return {'c': self.c, 's0': self.s0, 's1': self.s1, 's2': self.s2}", "response": "Return internal state useful for testing."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a random string of length elements chosen from alphabet.", "response": "def random_string(self, length, alphabet):\n        \"\"\"Return string of `length` elements chosen from `alphabet`.\"\"\"\n        return ''.join(\n            self.choice(alphabet) for n in range(length)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef api_endpoints(obj):\n    for name in dir(obj):\n        attr = getattr(obj, name)\n        api_path = getattr(attr, 'api_path', None)\n        if api_path:\n            yield (\n                '%s%s' % (obj.api_path_prefix, api_path),\n                attr,\n            )\n    for api_provider in obj.api_providers:\n        for api_path, attr in api_endpoints(api_provider):\n            yield (api_path, attr)", "response": "Iterator over all API endpoint names and callbacks."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef api_path_map(self):\n        if self._api_path_cache is None:\n            self._api_path_cache = {\n                api_path: func\n                for api_path, func\n                in api_endpoints(self)\n            }\n        return self._api_path_cache", "response": "Cached dict of api_path to func."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclear out cache for api_path_map.", "response": "def clear_api_path_map_cache(self):\n        \"\"\"Clear out cache for api_path_map.\"\"\"\n        self._api_path_cache = None\n        for api_provider in self.api_providers:\n            if six.get_method_self(\n                api_provider.clear_api_path_map_cache,\n            ) is not None:\n                api_provider.clear_api_path_map_cache()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls a function but NEVER raise an exception.", "response": "def safe_call(func, *args, **kwargs):\n    \"\"\"\n    Call `func(*args, **kwargs)` but NEVER raise an exception.\n\n    Useful in situations such as inside exception handlers where calls to\n    `logging.error` try to send email, but the SMTP server isn't always\n    availalbe and you don't want your exception handler blowing up.\n    \"\"\"\n    try:\n        return None, func(*args, **kwargs)\n    except Exception:  # pylint: disable=broad-except\n        # something went wrong during the call, return a stack trace that can\n        # be dealt with by the caller\n        return traceback.format_exc(), None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndebug print name and val.", "response": "def dprint(name, val):\n    \"\"\"Debug print name and val.\"\"\"\n    from pprint import pformat\n    print(\n        '% 5s: %s' % (\n            name,\n            '\\n       '.join(\n                pformat(\n                    val, indent=4, width=75,\n                ).split('\\n')\n            ),\n        ),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_kwargs(func, kwargs):\n    func_name = func.__name__\n    argspec = inspect.getargspec(func)\n    all_args = argspec.args[:]\n    defaults = list(argspec.defaults or [])\n\n    # ignore implicit 'self' argument\n    if inspect.ismethod(func) and all_args[:1] == ['self']:\n        all_args[:1] = []\n\n    # don't require arguments that have defaults\n    if defaults:\n        required = all_args[:-len(defaults)]\n    else:\n        required = all_args[:]\n\n    # translate 'foo_' to avoid reserved names like 'id'\n    trans = {\n        arg: arg.endswith('_') and arg[:-1] or arg\n        for arg\n        in all_args\n    }\n    for key in list(kwargs):\n        key_adj = '%s_' % key\n        if key_adj in all_args:\n            kwargs[key_adj] = kwargs.pop(key)\n\n    # figure out what we're missing\n    supplied = sorted(kwargs)\n    missing = [\n        trans.get(arg, arg) for arg in required\n        if arg not in supplied\n    ]\n    if missing:\n        raise MeteorError(\n            400,\n            func.err,\n            'Missing required arguments to %s: %s' % (\n                func_name,\n                ' '.join(missing),\n            ),\n        )\n\n    # figure out what is extra\n    extra = [\n        arg for arg in supplied\n        if arg not in all_args\n    ]\n    if extra:\n        raise MeteorError(\n            400,\n            func.err,\n            'Unknown arguments to %s: %s' % (func_name, ' '.join(extra)),\n        )", "response": "Validate arguments to be supplied to func."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles new websocket connection.", "response": "def on_open(self):\n        \"\"\"Handle new websocket connection.\"\"\"\n        this.request = WSGIRequest(self.ws.environ)\n        this.ws = self\n        this.send = self.send\n        this.reply = self.reply\n\n        self.logger = self.ws.logger\n        self.remote_ids = collections.defaultdict(set)\n\n        # `_tx_buffer` collects outgoing messages which must be sent in order\n        self._tx_buffer = {}\n        # track the head of the queue (buffer) and the next msg to be sent\n        self._tx_buffer_id_gen = itertools.cycle(irange(sys.maxint))\n        self._tx_next_id_gen = itertools.cycle(irange(sys.maxint))\n        # start by waiting for the very first message\n        self._tx_next_id = next(self._tx_next_id_gen)\n\n        this.remote_addr = self.remote_addr = \\\n            '{0[REMOTE_ADDR]}:{0[REMOTE_PORT]}'.format(\n                self.ws.environ,\n            )\n        this.subs = {}\n        safe_call(self.logger.info, '+ %s OPEN', self)\n        self.send('o')\n        self.send('a[\"{\\\\\"server_id\\\\\":\\\\\"0\\\\\"}\"]')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_close(self, *args, **kwargs):\n        if self.connection is not None:\n            del self.pgworker.connections[self.connection.pk]\n            self.connection.delete()\n            self.connection = None\n        signals.request_finished.send(sender=self.__class__)\n        safe_call(self.logger.info, '- %s %s', self, args or 'CLOSE')", "response": "Handle closing of websocket connection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess a message received from remote.", "response": "def on_message(self, message):\n        \"\"\"Process a message received from remote.\"\"\"\n        if self.ws.closed:\n            return None\n        try:\n            safe_call(self.logger.debug, '< %s %r', self, message)\n\n            # process individual messages\n            for data in self.ddp_frames_from_message(message):\n                self.process_ddp(data)\n                # emit request_finished signal to close DB connections\n                signals.request_finished.send(sender=self.__class__)\n        except geventwebsocket.WebSocketError:\n            self.ws.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields DDP messages from a raw WebSocket message.", "response": "def ddp_frames_from_message(self, message):\n        \"\"\"Yield DDP messages from a raw WebSocket message.\"\"\"\n        # parse message set\n        try:\n            msgs = ejson.loads(message)\n        except ValueError:\n            self.reply(\n                'error', error=400, reason='Data is not valid EJSON',\n            )\n            raise StopIteration\n        if not isinstance(msgs, list):\n            self.reply(\n                'error', error=400, reason='Invalid EJSON messages',\n            )\n            raise StopIteration\n        # process individual messages\n        while msgs:\n            # pop raw message from the list\n            raw = msgs.pop(0)\n            # parse message payload\n            try:\n                data = ejson.loads(raw)\n            except (TypeError, ValueError):\n                data = None\n            if not isinstance(data, dict):\n                self.reply(\n                    'error', error=400,\n                    reason='Invalid SockJS DDP payload',\n                    offendingMessage=raw,\n                )\n            yield data\n            if msgs:\n                # yield to other greenlets before processing next msg\n                gevent.sleep()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_ddp(self, data):\n        msg_id = data.get('id', None)\n        try:\n            msg = data.pop('msg')\n        except KeyError:\n            self.reply(\n                'error', reason='Bad request',\n                offendingMessage=data,\n            )\n            return\n        try:\n            # dispatch message\n            self.dispatch(msg, data)\n        except Exception as err:  # pylint: disable=broad-except\n            # This should be the only protocol exception handler\n            kwargs = {\n                'msg': {'method': 'result'}.get(msg, 'error'),\n            }\n            if msg_id is not None:\n                kwargs['id'] = msg_id\n            if isinstance(err, MeteorError):\n                error = err.as_dict()\n            else:\n                error = {\n                    'error': 500,\n                    'reason': 'Internal server error',\n                }\n            if kwargs['msg'] == 'error':\n                kwargs.update(error)\n            else:\n                kwargs['error'] = error\n            if not isinstance(err, MeteorError):\n                # not a client error, should always be logged.\n                stack, _ = safe_call(\n                    self.logger.error, '%r %r', msg, data, exc_info=1,\n                )\n                if stack is not None:\n                    # something went wrong while logging the error, revert to\n                    # writing a stack trace to stderr.\n                    traceback.print_exc(file=sys.stderr)\n                    sys.stderr.write(\n                        'Additionally, while handling the above error the '\n                        'following error was encountered:\\n'\n                    )\n                    sys.stderr.write(stack)\n            elif settings.DEBUG:\n                print('ERROR: %s' % err)\n                dprint('msg', msg)\n                dprint('data', data)\n                error.setdefault('details', traceback.format_exc())\n                # print stack trace for client errors when DEBUG is True.\n                print(error['details'])\n            self.reply(**kwargs)\n            if msg_id and msg == 'method':\n                self.reply('updated', methods=[msg_id])", "response": "Process a single DDP message."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndispatches msg to appropriate recv_foo handler.", "response": "def dispatch(self, msg, kwargs):\n        \"\"\"Dispatch msg to appropriate recv_foo handler.\"\"\"\n        # enforce calling 'connect' first\n        if self.connection is None and msg != 'connect':\n            self.reply('error', reason='Must connect first')\n            return\n        if msg == 'method':\n            if (\n                'method' not in kwargs\n            ) or (\n                'id' not in kwargs\n            ):\n                self.reply(\n                    'error', error=400, reason='Malformed method invocation',\n                )\n                return\n\n        # lookup method handler\n        try:\n            handler = getattr(self, 'recv_%s' % msg)\n        except (AttributeError, UnicodeEncodeError):\n            raise MeteorError(404, 'Method not found')\n\n        # validate handler arguments\n        validate_kwargs(handler, kwargs)\n\n        # dispatch to handler\n        handler(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send(self, data, tx_id=None):\n        # buffer data until we get pre-requisite data\n        if tx_id is None:\n            tx_id = self.get_tx_id()\n        self._tx_buffer[tx_id] = data\n\n        # de-queue messages from buffer\n        while self._tx_next_id in self._tx_buffer:\n            # pull next message from buffer\n            data = self._tx_buffer.pop(self._tx_next_id)\n            if self._tx_buffer:\n                safe_call(self.logger.debug, 'TX found %d', self._tx_next_id)\n            # advance next message ID\n            self._tx_next_id = next(self._tx_next_id_gen)\n            if not isinstance(data, basestring):\n                # ejson payload\n                msg = data.get('msg', None)\n                if msg in (ADDED, CHANGED, REMOVED):\n                    ids = self.remote_ids[data['collection']]\n                    meteor_id = data['id']\n                    if msg == ADDED:\n                        if meteor_id in ids:\n                            msg = data['msg'] = CHANGED\n                        else:\n                            ids.add(meteor_id)\n                    elif msg == CHANGED:\n                        if meteor_id not in ids:\n                            # object has become visible, treat as `added`.\n                            msg = data['msg'] = ADDED\n                            ids.add(meteor_id)\n                    elif msg == REMOVED:\n                        try:\n                            ids.remove(meteor_id)\n                        except KeyError:\n                            continue  # client doesn't have this, don't send.\n                data = 'a%s' % ejson.dumps([ejson.dumps(data)])\n            # send message\n            safe_call(self.logger.debug, '> %s %r', self, data)\n            try:\n                self.ws.send(data)\n            except geventwebsocket.WebSocketError:\n                self.ws.close()\n                self._tx_buffer.clear()\n                break\n        num_waiting = len(self._tx_buffer)\n        if num_waiting > 10:\n            safe_call(\n                self.logger.warn,\n                'TX received %d, waiting for %d, have %d waiting: %r.',\n                tx_id, self._tx_next_id, num_waiting, self._tx_buffer,\n            )", "response": "Send data to the client."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef recv_connect(self, version=None, support=None, session=None):\n        del session  # Meteor doesn't even use this!\n        if self.connection is not None:\n            raise MeteorError(\n                400, 'Session already established.',\n                self.connection.connection_id,\n            )\n        elif None in (version, support) or version not in self.versions:\n            self.reply('failed', version=self.versions[0])\n        elif version not in support:\n            raise MeteorError(400, 'Client version/support mismatch.')\n        else:\n            from dddp.models import Connection\n            cur = connection.cursor()\n            cur.execute('SELECT pg_backend_pid()')\n            (backend_pid,) = cur.fetchone()\n            this.version = version\n            this.support = support\n            self.connection = Connection.objects.create(\n                server_addr='%d:%s' % (\n                    backend_pid,\n                    self.ws.handler.socket.getsockname(),\n                ),\n                remote_addr=self.remote_addr,\n                version=version,\n            )\n            self.pgworker.connections[self.connection.pk] = self\n            atexit.register(self.on_close, 'Shutting down.')\n            self.reply('connected', session=self.connection.connection_id)", "response": "Receive a connection from the server."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninforms client that WebSocket service is available.", "response": "def ddpp_sockjs_info(environ, start_response):\n    \"\"\"Inform client that WebSocket service is available.\"\"\"\n    import random\n    import ejson\n\n    start_response(\n        '200 OK',\n        [\n            ('Content-Type', 'application/json; charset=UTF-8'),\n        ] + common_headers(environ),\n    )\n    yield ejson.dumps(collections.OrderedDict([\n        ('websocket', True),\n        ('origins', [\n            '*:*',\n        ]),\n        ('cookie_needed', False),\n        ('entropy', random.getrandbits(32)),\n    ]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addr(val, default_port=8000, defualt_host='localhost'):\n    import re\n    import socket\n\n    match = re.match(r'\\A(?P<host>.*?)(:(?P<port>(\\d+|\\w+)))?\\Z', val)\n    if match is None:\n        raise argparse.ArgumentTypeError(\n            '%r is not a valid host[:port] address.' % val\n        )\n    host, port = match.group('host', 'port')\n\n    if not host:\n        host = defualt_host\n\n    if not port:\n        port = default_port\n    elif port.isdigit():\n        port = int(port)\n    else:\n        port = socket.getservbyname(port)\n\n    return Addr(host, port)", "response": "Convert a string of format host[:port ] into a Addr object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serve(listen, verbosity=1, debug_port=0, **ssl_args):\n    launcher = DDPLauncher(debug=verbosity == 3, verbosity=verbosity)\n    if debug_port:\n        launcher.servers.append(\n            launcher.get_backdoor_server('localhost:%d' % debug_port)\n        )\n    launcher.add_web_servers(listen, **ssl_args)\n    # die gracefully with SIGINT or SIGQUIT\n    sigmap = {\n        val: name\n        for name, val\n        in vars(signal).items()\n        if name.startswith('SIG')\n    }\n\n    def sighandler(signum=None, frame=None):\n        \"\"\"Signal handler\"\"\"\n        launcher.logger.info(\n            'Received signal %s in frame %r',\n            sigmap.get(signum, signum),\n            frame,\n        )\n        launcher.stop()\n    for signum in [signal.SIGINT, signal.SIGQUIT]:\n        gevent.signal(signum, sighandler)\n    launcher.run()", "response": "Serve a list of web servers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n    parser = argparse.ArgumentParser(description=__doc__)\n    django = parser.add_argument_group('Django Options')\n    django.add_argument(\n        '--verbosity', '-v', metavar='VERBOSITY', dest='verbosity', type=int,\n        default=1,\n    )\n    django.add_argument(\n        '--debug-port', metavar='DEBUG_PORT', dest='debug_port', type=int,\n        default=0,\n    )\n    django.add_argument(\n        '--settings', metavar='SETTINGS', dest='settings',\n        help=\"The Python path to a settings module, e.g. \"\n        \"\\\"myproject.settings.main\\\". If this isn't provided, the \"\n        \"DJANGO_SETTINGS_MODULE environment variable will be used.\",\n    )\n    http = parser.add_argument_group('HTTP Options')\n    http.add_argument(\n        'listen', metavar='address[:port]', nargs='*', type=addr,\n        help='Listening address for HTTP(s) server.',\n    )\n    ssl = parser.add_argument_group('SSL Options')\n    ssl.add_argument('--ssl-version', metavar='SSL_VERSION', dest='ssl_version',\n                     help=\"SSL version to use (see stdlib ssl module's) [3]\",\n                     choices=['1', '2', '3'], default='3')\n    ssl.add_argument('--certfile', metavar='FILE', dest='certfile',\n                     help=\"SSL certificate file [None]\")\n    ssl.add_argument('--ciphers', metavar='CIPHERS', dest='ciphers',\n                     help=\"Ciphers to use (see stdlib ssl module's) [TLSv1]\")\n    ssl.add_argument('--ca-certs', metavar='FILE', dest='ca_certs',\n                     help=\"CA certificates file [None]\")\n    ssl.add_argument('--keyfile', metavar='FILE', dest='keyfile',\n                     help=\"SSL key file [None]\")\n    namespace = parser.parse_args()\n    if namespace.settings:\n        os.environ['DJANGO_SETTINGS_MODULE'] = namespace.settings\n    serve(\n        namespace.listen or [Addr('localhost', 8000)],\n        debug_port=namespace.debug_port,\n        keyfile=namespace.keyfile,\n        certfile=namespace.certfile,\n        verbosity=namespace.verbosity,\n    )", "response": "Entry point for dddp command."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint formatted msg if verbosity is set at 1 or above.", "response": "def print(self, msg, *args, **kwargs):\n        \"\"\"Print formatted msg if verbosity set at 1 or above.\"\"\"\n        if self.verbosity >= 1:\n            print(msg, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd WebSocketServer for each host in listen_addrs.", "response": "def add_web_servers(self, listen_addrs, debug=False, **ssl_args):\n        \"\"\"Add WebSocketServer for each (host, port) in listen_addrs.\"\"\"\n        self.servers.extend(\n            self.get_web_server(listen_addr, debug=debug, **ssl_args)\n            for listen_addr in listen_addrs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_web_server(self, listen_addr, debug=False, **ssl_args):\n        return geventwebsocket.WebSocketServer(\n            listen_addr,\n            self.resource,\n            debug=debug,\n            **{key: val for key, val in ssl_args.items() if val is not None}\n        )", "response": "Setup WebSocketServer on listen_addr."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a backdoor server.", "response": "def get_backdoor_server(self, listen_addr, **context):\n        \"\"\"Add a backdoor (debug) server.\"\"\"\n        from django.conf import settings\n        local_vars = {\n            'launcher': self,\n            'servers': self.servers,\n            'pgworker': self.pgworker,\n            'stop': self.stop,\n            'api': self.api,\n            'resource': self.resource,\n            'settings': settings,\n            'wsgi_app': self.wsgi_app,\n            'wsgi_name': self.wsgi_name,\n        }\n        local_vars.update(context)\n        return BackdoorServer(\n            listen_addr, banner='Django DDP', locals=local_vars,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstopping all green threads.", "response": "def stop(self):\n        \"\"\"Stop all green threads.\"\"\"\n        self.logger.debug('PostgresGreenlet stop')\n        self._stop_event.set()\n        # ask all threads to stop.\n        for server in self.servers + [DDPLauncher.pgworker]:\n            self.logger.debug('Stopping %s', server)\n            server.stop()\n        # wait for all threads to stop.\n        gevent.joinall(self.threads + [DDPLauncher.pgworker])\n        self.threads = []"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self):\n        self.logger.debug('PostgresGreenlet start')\n        self._stop_event.clear()\n        self.print('=> Discovering DDP endpoints...')\n        if self.verbosity > 1:\n            for api_path in sorted(self.api.api_path_map()):\n                print('    %s' % api_path)\n\n        # start greenlets\n        self.pgworker.start()\n        self.print('=> Started PostgresGreenlet.')\n        for server in self.servers:\n            thread = gevent.spawn(server.serve_forever)\n            gevent.sleep()  # yield to thread in case it can't start\n            self.threads.append(thread)\n            if thread.dead:\n                # thread died, stop everything and re-raise the exception.\n                self.stop()\n                thread.get()\n            if isinstance(server, geventwebsocket.WebSocketServer):\n                self.print(\n                    '=> App running at: %s://%s:%d/' % (\n                        'https' if server.ssl_enabled else 'http',\n                        server.server_host,\n                        server.server_port,\n                    ),\n                )\n            elif isinstance(server, gevent.backdoor.BackdoorServer):\n                self.print(\n                    '=> Debug service running at: telnet://%s:%d/' % (\n                        server.server_host,\n                        server.server_port,\n                    ),\n                )\n        self.print('=> Started your app (%s).' % self.wsgi_name)", "response": "Start the postgres greenlet and the web server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialise django - ddp.", "response": "def ready(self):\n        \"\"\"Initialisation for django-ddp (setup lookups and signal handlers).\"\"\"\n        if not settings.DATABASES:\n            raise ImproperlyConfigured('No databases configured.')\n        for (alias, conf) in settings.DATABASES.items():\n            engine = conf['ENGINE']\n            if engine not in [\n                'django.db.backends.postgresql',\n                'django.db.backends.postgresql_psycopg2',\n            ]:\n                warnings.warn(\n                    'Database %r uses unsupported %r engine.' % (\n                        alias, engine,\n                    ),\n                    UserWarning,\n                )\n        self.api = autodiscover()\n        self.api.ready()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _run(self):  # pylint: disable=method-hidden\n        conn_params = self.connection.get_connection_params()\n        # See http://initd.org/psycopg/docs/module.html#psycopg2.connect and\n        # http://www.postgresql.org/docs/current/static/libpq-connect.html\n        # section 31.1.2 (Parameter Key Words) for details on available params.\n        conn_params.update(\n            async=True,\n            application_name='{} pid={} django-ddp'.format(\n                socket.gethostname(),  # hostname\n                os.getpid(),  # PID\n            )[:64],  # 64 characters for default PostgreSQL build config\n        )\n        conn = None\n        while conn is None:\n            try:\n                conn = psycopg2.connect(**conn_params)\n            except psycopg2.OperationalError as err:\n                # Some variants of the psycopg2 driver for Django add extra\n                # params that aren't meant to be passed directly to\n                # `psycopg2.connect()` -- issue a warning and try again.\n                msg = ('%s' % err).strip()\n                msg_prefix = 'invalid connection option \"'\n                if not msg.startswith(msg_prefix):\n                    # *waves hand* this is not the errror you are looking for.\n                    raise\n                key = msg[len(msg_prefix):-1]\n                self.logger.warning(\n                    'Ignoring unknown settings.DATABASES[%r] option: %s=%r',\n                    self.connection.alias,\n                    key, conn_params.pop(key),\n                )\n        self.poll(conn)  # wait for conneciton to start\n\n        import logging\n        logging.getLogger('dddp').info('=> Started PostgresGreenlet.')\n\n        cur = conn.cursor()\n        cur.execute('LISTEN \"ddp\";')\n        while not self._stop_event.is_set():\n            try:\n                self.select_greenlet = gevent.spawn(\n                    gevent.select.select,\n                    [conn], [], [], timeout=None,\n                )\n                self.select_greenlet.get()\n            except gevent.GreenletExit:\n                self._stop_event.set()\n            finally:\n                self.select_greenlet = None\n            self.poll(conn)\n        self.poll(conn)\n        cur.close()\n        self.poll(conn)\n        conn.close()", "response": "Spawn sub tasks wait for stop signal."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stop(self):\n        self._stop_event.set()\n        if self.select_greenlet is not None:\n            self.select_greenlet.kill()\n            self.select_greenlet.get()\n            gevent.sleep()", "response": "Stop subtasks and let run() finish."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef poll(self, conn):\n        while 1:\n            state = conn.poll()\n            if state == psycopg2.extensions.POLL_OK:\n                while conn.notifies:\n                    notify = conn.notifies.pop()\n                    self.logger.info(\n                        \"Got NOTIFY (pid=%d, payload=%r)\",\n                        notify.pid, notify.payload,\n                    )\n\n                    # read the header and check seq/fin.\n                    hdr, chunk = notify.payload.split('|', 1)\n                    # print('RECEIVE: %s' % hdr)\n                    header = ejson.loads(hdr)\n                    uuid = header['uuid']\n                    size, chunks = self.chunks.setdefault(uuid, [0, {}])\n                    if header['fin']:\n                        size = self.chunks[uuid][0] = header['seq']\n\n                    # stash the chunk\n                    chunks[header['seq']] = chunk\n\n                    if len(chunks) != size:\n                        # haven't got all the chunks yet\n                        continue  # process next NOTIFY in loop\n\n                    # got the last chunk -> process it.\n                    data = ''.join(\n                        chunk for _, chunk in sorted(chunks.items())\n                    )\n                    del self.chunks[uuid]  # don't forget to cleanup!\n                    data = ejson.loads(data)\n                    sender = data.pop('_sender', None)\n                    tx_id = data.pop('_tx_id', None)\n                    for connection_id in data.pop('_connection_ids'):\n                        try:\n                            websocket = self.connections[connection_id]\n                        except KeyError:\n                            continue  # connection not in this process\n                        if connection_id == sender:\n                            websocket.send(data, tx_id=tx_id)\n                        else:\n                            websocket.send(data)\n                break\n            elif state == psycopg2.extensions.POLL_WRITE:\n                gevent.select.select([], [conn.fileno()], [])\n            elif state == psycopg2.extensions.POLL_READ:\n                gevent.select.select([conn.fileno()], [], [])\n            else:\n                self.logger.warn('POLL_ERR: %s', state)", "response": "Poll DB socket and process async tasks."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef greenify():\n    # don't greenify twice.\n    if _GREEN:\n        return\n    _GREEN[True] = True\n\n    from gevent.monkey import patch_all, saved\n    if ('threading' in sys.modules) and ('threading' not in saved):\n        import warnings\n        warnings.warn('threading module loaded before patching!')\n    patch_all()\n\n    try:\n        # Use psycopg2 by default\n        import psycopg2\n        del psycopg2\n    except ImportError:\n        # Fallback to psycopg2cffi if required (eg: pypy)\n        from psycopg2cffi import compat\n        compat.register()\n\n    from psycogreen.gevent import patch_psycopg\n    patch_psycopg()", "response": "Patch threading and psycopg2 modules for green threads."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a new ID optionally using namespace of given name.", "response": "def meteor_random_id(name=None, length=17):\n    \"\"\"Generate a new ID, optionally using namespace of given `name`.\"\"\"\n    if name is None:\n        stream = THREAD_LOCAL.alea_random\n    else:\n        stream = THREAD_LOCAL.random_streams[name]\n    return stream.random_string(length, METEOR_ID_CHARS)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef autodiscover():\n    from django.utils.module_loading import autodiscover_modules\n    from dddp.api import API\n    autodiscover_modules('ddp', register_to=API)\n    return API", "response": "Imports all dddp submodules from settings. INSTALLED_APPS and returns API object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef as_dict(self, **kwargs):\n        error, reason, details, err_kwargs = self.args\n        result = {\n            key: val\n            for key, val in {\n                'error': error, 'reason': reason, 'details': details,\n            }.items()\n            if val is not None\n        }\n        result.update(err_kwargs)\n        result.update(kwargs)\n        return result", "response": "Return an error dict for self. args and kwargs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, name, factory, *factory_args, **factory_kwargs):\n        update_thread_local = getattr(factory, 'update_thread_local', True)\n        if (not update_thread_local) or (name not in self.__dict__):\n            obj = factory(*factory_args, **factory_kwargs)\n            if update_thread_local:\n                setattr(self, name, obj)\n            return obj\n        return getattr(self, name)", "response": "Get attribute from specified factory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nemitting a formatted log record via DDP.", "response": "def emit(self, record):\n        \"\"\"Emit a formatted log record via DDP.\"\"\"\n        if getattr(this, 'subs', {}).get(LOGS_NAME, False):\n            self.format(record)\n            this.send({\n                'msg': ADDED,\n                'collection': LOGS_NAME,\n                'id': meteor_random_id('/collection/%s' % LOGS_NAME),\n                'fields': {\n                    attr: {\n                        # typecasting methods for specific attributes\n                        'args': lambda args: [repr(arg) for arg in args],\n                        'created': datetime.datetime.fromtimestamp,\n                        'exc_info': stacklines_or_none,\n                    }.get(\n                        attr,\n                        lambda val: val  # default typecasting method\n                    )(getattr(record, attr, None))\n                    for attr in (\n                        'args',\n                        'asctime',\n                        'created',\n                        'exc_info',\n                        'filename',\n                        'funcName',\n                        'levelname',\n                        'levelno',\n                        'lineno',\n                        'module',\n                        'msecs',\n                        'message',\n                        'name',\n                        'pathname',\n                        'process',\n                        'processName',\n                        'relativeCreated',\n                        'thread',\n                        'threadName',\n                    )\n                },\n            })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef select_renderer(request: web.Request, renderers: OrderedDict, force=True):\n    header = request.headers.get('ACCEPT', '*/*')\n    best_match = mimeparse.best_match(renderers.keys(), header)\n    if not best_match or best_match not in renderers:\n        if force:\n            return tuple(renderers.items())[0]\n        else:\n            raise web.HTTPNotAcceptable\n    return best_match, renderers[best_match]", "response": "Given a request a list of renderers and a force configuration\n    returns a two - tuple of media type render callable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef negotiation_middleware(\n    renderers=DEFAULTS['RENDERERS'],\n    negotiator=DEFAULTS['NEGOTIATOR'],\n    force_negotiation=DEFAULTS['FORCE_NEGOTIATION']\n):\n    \"\"\"Middleware which selects a renderer for a given request then renders\n    a handler's data to a `aiohttp.web.Response`.\n    \"\"\"\n    @asyncio.coroutine\n    def factory(app, handler):\n\n        @asyncio.coroutine\n        def middleware(request):\n            content_type, renderer = negotiator(\n                request,\n                renderers,\n                force_negotiation,\n            )\n            request['selected_media_type'] = content_type\n            response = yield from handler(request)\n\n            if getattr(response, 'data', None):\n                # Render data with the selected renderer\n                if asyncio.iscoroutinefunction(renderer):\n                    render_result = yield from renderer(request, response.data)\n                else:\n                    render_result = renderer(request, response.data)\n            else:\n                render_result = response\n\n            if isinstance(render_result, web.Response):\n                return render_result\n\n            if getattr(response, 'data', None):\n                response.body = render_result\n                response.content_type = content_type\n\n            return response\n        return middleware\n    return factory", "response": "Returns a middleware which renders a request to a response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup(\n    app: web.Application, *, negotiator: callable=DEFAULTS['NEGOTIATOR'],\n    renderers: OrderedDict=DEFAULTS['RENDERERS'],\n    force_negotiation: bool=DEFAULTS['FORCE_NEGOTIATION']\n):\n    \"\"\"Set up the negotiation middleware. Reads configuration from\n    ``app['AIOHTTP_UTILS']``.\n\n    :param app: Application to set up.\n    :param negotiator: Function that selects a renderer given a\n        request, a dict of renderers, and a ``force`` parameter (whether to return\n        a renderer even if the client passes an unsupported media type).\n    :param renderers: Mapping of mediatypes to callable renderers.\n    :param force_negotiation: Whether to return a rennderer even if the\n        client passes an unsupported media type).\n    \"\"\"\n    config = app.get(CONFIG_KEY, {})\n    middleware = negotiation_middleware(\n        renderers=config.get('RENDERERS', renderers),\n        negotiator=config.get('NEGOTIATOR', negotiator),\n        force_negotiation=config.get('FORCE_NEGOTIATION', force_negotiation)\n    )\n    app.middlewares.append(middleware)\n    return app", "response": "Setup the application for negotiation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_route_context(\n    app: web.Application, module=None, url_prefix: str=None, name_prefix: str=None\n):\n    \"\"\"Context manager which yields a function for adding multiple routes from a given module.\n\n    Example:\n\n    .. code-block:: python\n\n        # myapp/articles/views.py\n        async def list_articles(request):\n            return web.Response(b'article list...')\n\n        async def create_article(request):\n            return web.Response(b'created article...')\n\n    .. code-block:: python\n\n        # myapp/app.py\n        from myapp.articles import views\n\n        with add_route_context(app, url_prefix='/api/', name_prefix='articles') as route:\n            route('GET', '/articles/', views.list_articles)\n            route('POST', '/articles/', views.create_article)\n\n        app.router['articles.list_articles'].url()  # /api/articles/\n\n    If you prefer, you can also pass module and handler names as strings.\n\n    .. code-block:: python\n\n        with add_route_context(app, module='myapp.articles.views',\n                               url_prefix='/api/', name_prefix='articles') as route:\n            route('GET', '/articles/', 'list_articles')\n            route('POST', '/articles/', 'create_article')\n\n    :param app: Application to add routes to.\n    :param module: Import path to module (str) or module object which contains the handlers.\n    :param url_prefix: Prefix to prepend to all route paths.\n    :param name_prefix: Prefix to prepend to all route names.\n    \"\"\"\n    if isinstance(module, (str, bytes)):\n        module = importlib.import_module(module)\n\n    def add_route(method, path, handler, name=None):\n        \"\"\"\n        :param str method: HTTP method.\n        :param str path: Path for the route.\n        :param handler: A handler function or a name of a handler function contained\n            in `module`.\n        :param str name: Name for the route. If `None`, defaults to the handler's\n            function name.\n        \"\"\"\n        if isinstance(handler, (str, bytes)):\n            if not module:\n                raise ValueError(\n                    'Must pass module to add_route_context if passing handler name strings.'\n                )\n            name = name or handler\n            handler = getattr(module, handler)\n        else:\n            name = name or handler.__name__\n        path = make_path(path, url_prefix)\n        name = '.'.join((name_prefix, name)) if name_prefix else name\n        return app.router.add_route(method, path, handler, name=name)\n    yield add_route", "response": "Context manager which yields a function for adding multiple routes from a given module."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_resource_object(self, path: str, resource, methods: tuple=tuple(), names: Mapping=None):\n        names = names or {}\n        if methods:\n            method_names = methods\n        else:\n            method_names = self.HTTP_METHOD_NAMES\n        for method_name in method_names:\n            handler = getattr(resource, method_name, None)\n            if handler:\n                name = names.get(method_name, self.get_default_handler_name(resource, method_name))\n                self.add_route(method_name.upper(), path, handler, name=name)", "response": "Add routes by an object s methods."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning an gunicorn. web. Application using gunicorn. gunicorn.", "response": "def run(app: web.Application, **kwargs):\n    \"\"\"Run an `aiohttp.web.Application` using gunicorn.\n\n    :param app: The app to run.\n    :param str app_uri: Import path to `app`. Takes the form\n        ``$(MODULE_NAME):$(VARIABLE_NAME)``.\n        The module name can be a full dotted path.\n        The variable name refers to the `aiohttp.web.Application` instance.\n        This argument is required if ``reload=True``.\n    :param str host: Hostname to listen on.\n    :param int port: Port of the server.\n    :param bool reload: Whether to reload the server on a code change.\n        If not set, will take the same value as ``app.debug``.\n        **EXPERIMENTAL**.\n    :param \\*\\*kwargs: Extra configuration options to set on the\n        ``GunicornApp's`` config object.\n    \"\"\"\n    runner = Runner(app, **kwargs)\n    runner.run()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_message(self, message, **kwargs):\n\n        from ..libs.gcm import gcm_send_message\n        data = kwargs.pop(\"extra\", {})\n        if message is not None:\n            data[\"message\"] = message\n\n        return gcm_send_message(registration_id=self.registration_id,\n                data=data, **kwargs)", "response": "Sends a push notification to this device via GCM"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending an APNS notification to one or more registration_ids.", "response": "def apns_send_bulk_message(registration_ids, alert, **kwargs):\n    \"\"\"\n    Sends an APNS notification to one or more registration_ids.\n    The registration_ids argument needs to be a list.\n\n    Note that if set alert should always be a string. If it is not set,\n    it won't be included in the notification. You will need to pass None\n    to this for silent notifications.\n    \"\"\"\n    with closing(_apns_create_socket_to_push(**kwargs)) as socket:\n        for identifier, registration_id in enumerate(registration_ids):\n            _apns_send(registration_id, alert, identifier=identifier, socket=socket, **kwargs)\n        _apns_check_errors(socket)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nquery the APNS server for id s that are no longer active since", "response": "def apns_fetch_inactive_ids():\n    \"\"\"\n    Queries the APNS server for id's that are no longer active since\n    the last fetch\n    \"\"\"\n    with closing(_apns_create_socket_to_feedback()) as socket:\n        inactive_ids = []\n\n        for _, registration_id in _apns_receive_feedback(socket):\n            inactive_ids.append(codecs.encode(registration_id, 'hex_codec'))\n\n        return inactive_ids"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a message to a single gcm notification", "response": "def gcm_send_message(registration_id, data, encoding='utf-8', **kwargs):\n    \"\"\"\n    Standalone method to send a single gcm notification\n    \"\"\"\n\n    messenger = GCMMessenger(registration_id, data, encoding=encoding, **kwargs)\n    return messenger.send_plain()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a message to a list of gcm notifications", "response": "def gcm_send_bulk_message(registration_ids, data, encoding='utf-8', **kwargs):\n    \"\"\"\n    Standalone method to send bulk gcm notifications\n    \"\"\"\n\n    messenger = GCMMessenger(registration_ids, data, encoding=encoding, **kwargs)\n    return messenger.send_bulk()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_plain(self):\n\n        values = {\"registration_id\": self._registration_id}\n\n        for key, val in self._data.items():\n            values[\"data.%s\" % (key)] = val.encode(self.encoding)\n\n        for key, val in self._kwargs.items():\n            if val and isinstance(val, bool):\n                val = 1\n                values[key] = val\n\n        data = urlencode(sorted(values.items())).encode(self.encoding)\n        result = self._send(data, \"application/x-www-form-urlencoded;charset=UTF-8\")\n\n        if result.startswith(\"Error=\"):\n            if result in (\"Error=NotRegistered\", \"Error=InvalidRegistration\"):\n                ## TODO: deactivate the unregistered device\n                return result\n\n            raise GCMPushError(result)\n\n        return result", "response": "Sends a text / plain GCM message to the device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_json(self, ids=None):\n\n        items = ids or self._registration_id\n        values = {\"registration_ids\": items}\n\n        if self._data is not None:\n            values[\"data\"] = self._data\n\n        for key, val in self._kwargs.items():\n            if val:\n                values[key] = val\n\n        data = json.dumps(values, separators=(\",\", \":\"), sort_keys=True).encode(\n                self.encoding)\n\n        result = json.loads(self._send(data, \"application/json\"))\n\n        if (\"failure\" in result) and (result[\"failure\"]):\n            unregistered = []\n            throw_error = False\n\n            for index, error in enumerate(result.get(\"results\", [])):\n                error = error.get(\"error\", \"\")\n                if error in (\"NotRegistered\", \"InvalidRegistration\"):\n                    unregistered.append(items[index])\n                elif error != \"\":\n                    throw_error = True\n\n            self.deactivate_unregistered_devices(unregistered)\n            if throw_error:\n                raise GCMPushError(result)\n\n        return result", "response": "Sends a json GCM message to the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending a GCM message with the given content type", "response": "def _send(self, data, content_type):\n        \"\"\"\n        Sends a GCM message with the given content type\n        \"\"\"\n\n        headers = {\n            \"Content-Type\": content_type,\n            \"Authorization\": \"key=%s\" % (self.api_key),\n            \"Content-Length\": str(len(data))\n        }\n\n        request = Request(self.api_url, data, headers)\n        return urlopen(request).read().decode(self.encoding)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_model(module_location):\n\n    if not isinstance(module_location, (str, unicode)):\n        raise ValueError(\"The value provided should either be a string or \"\\\n                \"unicode instance. The value '%s' provided was %s \"\\\n                \"rather.\" % (module_location, type(module_location)))\n\n    try:\n        name_split = module_location.split(\".\")\n        class_name = name_split.pop(-1)\n\n        if not len(name_split):\n            raise ValueError(\"The value should provide the module location \"\\\n                    \"joined by '.' e.g. for model named 'test' in \"\n                    \"/app/module.py, The value should be 'app.module.test'\")\n\n        module_location = \".\".join(name_split)\n        module = importlib.import_module(module_location)\n        cls = getattr(module, class_name)\n\n        return cls\n\n    except AttributeError:\n        pass", "response": "Returns the class of the given module location."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplots the line power of a single case.", "response": "def plot_line_power(obj, results, hour, ax=None):\n    '''\n    obj: case or network\n    '''\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=(16, 10))\n        ax.axis('off')\n\n    case, network = _return_case_network(obj)\n\n    network.draw_buses(ax=ax)\n    network.draw_loads(ax=ax)\n    network.draw_generators(ax=ax)\n    network.draw_connections('gen_to_bus', ax=ax)\n    network.draw_connections('load_to_bus', ax=ax)\n\n    edgelist, edge_color, edge_width, edge_labels = _generate_edges(results, case, hour)\n    branches = network.draw_branches(ax=ax, edgelist=edgelist, edge_color=edge_color, width=edge_width, edge_labels=edge_labels)\n\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes('right', size='5%', pad=0.05)\n    cb = plt.colorbar(branches, cax=cax, orientation='vertical')\n    cax.yaxis.set_label_position('left')\n    cax.yaxis.set_ticks_position('left')\n    cb.set_label('Loading Factor')\n\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fast_forward_selection(scenarios, number_of_reduced_scenarios, probability=None):\n    print(\"Running fast forward selection algorithm\")\n\n    number_of_scenarios = scenarios.shape[1]\n    logger.debug(\"Input number of scenarios = %d\", number_of_scenarios)\n\n    # if probability is not defined assign equal probability to all scenarios\n    if probability is None:\n        probability = np.array([1/number_of_scenarios for i in range(0, number_of_scenarios)])\n\n    # initialize z, c and J\n    z = np.array([np.inf for i in range(0, number_of_scenarios)])\n    c = np.zeros((number_of_scenarios, number_of_scenarios))\n    J = range(0, number_of_scenarios)\n\n    # no reduction necessary\n    if number_of_reduced_scenarios >= number_of_scenarios:\n        return(scenarios, probability, J)\n\n    for scenario_k in range(0, number_of_scenarios):\n        for scenario_u in range(0, number_of_scenarios):\n            c[scenario_k, scenario_u] = distance(scenarios[:, scenario_k], scenarios[:, scenario_u])\n\n    for scenario_u in range(0, number_of_scenarios):\n        summation = 0\n        for scenario_k in range(0, number_of_scenarios):\n            if scenario_k != scenario_u:\n                summation = summation + probability[scenario_k]*c[scenario_k, scenario_u]\n\n        z[scenario_u] = summation\n\n    U = [np.argmin(z)]\n\n    for u in U:\n        J.remove(u)\n\n    for _ in range(0, number_of_scenarios - number_of_reduced_scenarios - 1):\n        print(\"Running {}\".format(_))\n\n        for scenario_u in J:\n            for scenario_k in J:\n                lowest_value = np.inf\n\n                for scenario_number in U:\n                    lowest_value = min(c[scenario_k, scenario_u], c[scenario_k, scenario_number])\n\n            c[scenario_k, scenario_u] = lowest_value\n\n        for scenario_u in J:\n            summation = 0\n            for scenario_k in J:\n                if scenario_k not in U:\n                    summation = summation + probability[scenario_k]*c[scenario_k, scenario_u]\n\n            z[scenario_u] = summation\n\n        u_i = np.argmin([item if i in J else np.inf for i, item in enumerate(z)])\n\n        J.remove(u_i)\n        U.append(u_i)\n\n    reduced_scenario_set = U\n    reduced_probability = []\n\n    reduced_probability = copy.deepcopy(probability)\n    for deleted_scenario_number in J:\n        lowest_value = np.inf\n\n        # find closest scenario_number\n        for scenario_j in reduced_scenario_set:\n            if c[deleted_scenario_number, scenario_j] < lowest_value:\n                closest_scenario_number = scenario_j\n                lowest_value = c[deleted_scenario_number, scenario_j]\n\n        reduced_probability[closest_scenario_number] = reduced_probability[closest_scenario_number] + reduced_probability[deleted_scenario_number]\n\n    reduced_scenarios = copy.deepcopy(scenarios[:, reduced_scenario_set])\n    reduced_probability = reduced_probability[reduced_scenario_set]\n\n\n\n    return reduced_scenarios, reduced_probability, reduced_scenario_set", "response": "Fast forward selection algorithm for the base scenario set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef simultaneous_backward_reduction(scenarios, number_of_reduced_scenarios, probability=None):\n\n    print(\"Running simultaneous backward reduction algorithm\")\n\n    number_of_scenarios = scenarios.shape[1]\n    logger.debug(\"Input number of scenarios = %d\", number_of_scenarios)\n    # if probability is not defined assign equal probability to all scenarios\n    if probability is None:\n        probability = np.array([1/number_of_scenarios for i in range(0, number_of_scenarios)])\n\n    # initialize z, c and J\n    z = np.array([np.inf for i in range(0, number_of_scenarios)])\n    c = np.zeros((number_of_scenarios, number_of_scenarios))\n    J = []\n\n    # no reduction necessary\n    if number_of_reduced_scenarios >= number_of_scenarios:\n        return(scenarios, probability, J)\n\n    \"\"\"compute the distance of scenario pairs\"\"\"\n\n    for scenario_k in range(0, number_of_scenarios):\n        for scenario_j in range(0, number_of_scenarios):\n            c[scenario_k, scenario_j] = distance(scenarios[:, scenario_k], scenarios[:, scenario_j])\n\n    for scenario_l in range(0, number_of_scenarios):\n        lowest_value = np.inf\n        for scenario_j in range(0, number_of_scenarios):\n            if scenario_l == scenario_j:\n                continue\n            lowest_value = min(lowest_value, c[scenario_l, scenario_j])\n\n        c[scenario_l, scenario_l] = lowest_value\n        z[scenario_l] = probability[scenario_l]*c[scenario_l, scenario_l]\n\n    J.append(np.argmin(z))\n\n    for _ in range(0, number_of_scenarios - number_of_reduced_scenarios - 1):\n\n        for scenario_l in range(0, number_of_scenarios):\n            for scenario_k in range(0, number_of_scenarios):\n                if scenario_k in J or scenario_k == scenario_l:\n                    if scenario_l not in J:\n                        lowest_value = np.inf\n                        for scenario_j in range(0, number_of_scenarios):\n                            if scenario_j not in J and scenario_j != scenario_l:\n                                lowest_value = min(lowest_value, c[scenario_k, scenario_j])\n\n                        c[scenario_k, scenario_l] = lowest_value\n\n        for scenario_l in range(0, number_of_scenarios):\n            if scenario_l not in J:\n                summation = 0\n\n                for scenario_k in range(0, number_of_scenarios):\n                    if scenario_k in J or scenario_k == scenario_l:\n                        summation = summation + probability[scenario_k]*c[scenario_k, scenario_l]\n\n                z[scenario_l] = summation\n\n        J.append(np.argmin([item if i not in J else np.inf for i, item in enumerate(z)]))\n\n    reduced_scenario_set = []\n    for scenario_number in range(0, number_of_scenarios):\n        if scenario_number not in J:\n            reduced_scenario_set.append(scenario_number)\n\n    reduced_probability = []\n\n    reduced_probability = copy.deepcopy(probability)\n    for deleted_scenario_number in J:\n        lowest_value = np.inf\n\n        # find closest scenario_number\n        for scenario_j in reduced_scenario_set:\n            if c[deleted_scenario_number, scenario_j] < lowest_value:\n                closest_scenario_number = scenario_j\n                lowest_value = c[deleted_scenario_number, scenario_j]\n\n        reduced_probability[closest_scenario_number] = reduced_probability[closest_scenario_number] + reduced_probability[deleted_scenario_number]\n\n    reduced_scenarios = copy.deepcopy(scenarios[:, reduced_scenario_set])\n    reduced_probability = reduced_probability[reduced_scenario_set]\n    return(reduced_scenarios, reduced_probability, reduced_scenario_set)", "response": "Simultaneous backward reduction algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch for a given term phrase and limit the number of results returned by the search method.", "response": "def search(term=None, phrase=None, limit=DEFAULT_SEARCH_LIMIT,\n           api_key=GIPHY_PUBLIC_KEY, strict=False, rating=None):\n    \"\"\"\n    Shorthand for creating a Giphy api wrapper with the given api key\n    and then calling the search method. Note that this will return a generator\n    \"\"\"\n    return Giphy(api_key=api_key, strict=strict).search(\n        term=term, phrase=phrase, limit=limit, rating=rating)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef translate(term=None, phrase=None, api_key=GIPHY_PUBLIC_KEY, strict=False,\n              rating=None):\n    \"\"\"\n    Shorthand for creating a Giphy api wrapper with the given api key\n    and then calling the translate method.\n    \"\"\"\n    return Giphy(api_key=api_key, strict=strict).translate(\n        term=term, phrase=phrase, rating=rating)", "response": "Returns a Giphy object for the given term phrase and rating."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a generator that returns a single object with the trending data.", "response": "def trending(limit=DEFAULT_SEARCH_LIMIT, api_key=GIPHY_PUBLIC_KEY,\n             strict=False, rating=None):\n    \"\"\"\n    Shorthand for creating a Giphy api wrapper with the given api key\n    and then calling the trending method. Note that this will return\n    a generator\n    \"\"\"\n    return Giphy(api_key=api_key, strict=strict).trending(\n        limit=limit, rating=rating)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a Giphy object for the given gif id.", "response": "def gif(gif_id, api_key=GIPHY_PUBLIC_KEY, strict=False):\n    \"\"\"\n    Shorthand for creating a Giphy api wrapper with the given api key\n    and then calling the gif method.\n    \"\"\"\n    return Giphy(api_key=api_key, strict=strict).gif(gif_id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuploads a file to Giphy.", "response": "def upload(tags, file_path, username=None, api_key=GIPHY_PUBLIC_KEY,\n           strict=False):\n    \"\"\"\n    Shorthand for creating a Giphy api wrapper with the given api key\n    and then calling the upload method.\n    \"\"\"\n    return Giphy(api_key=api_key, strict=strict).upload(\n        tags, file_path, username)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _make_images(self, images):\n        # Order matters :)\n        process = ('original',\n                   'fixed_width',\n                   'fixed_height',\n                   'fixed_width_downsampled',\n                   'fixed_width_still',\n                   'fixed_height_downsampled',\n                   'fixed_height_still',\n                   'downsized')\n\n        for key in process:\n            data = images.get(key)\n\n            # Ignore empties\n            if not data:\n                continue\n\n            parts = key.split('_')\n\n            # attr/subattr style\n            if len(parts) > 2:\n                attr, subattr = '_'.join(parts[:-1]), parts[-1]\n            else:\n                attr, subattr = '_'.join(parts), None\n\n            # Normalize data\n            img = AttrDict(self._normalized(data))\n\n            if subattr is None:\n                setattr(self, attr, img)\n            else:\n                setattr(getattr(self, attr), subattr, img)", "response": "Takes an image dict from the giphy api and converts it to attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndo a normalization of sorts on image type data so that values are integers.", "response": "def _normalized(self, data):\n        \"\"\"\n        Does a normalization of sorts on image type data so that values\n        that should be integers are converted from strings\n        \"\"\"\n        int_keys = ('frames', 'width', 'height', 'size')\n\n        for key in int_keys:\n            if key not in data:\n                continue\n\n            try:\n                data[key] = int(data[key])\n            except ValueError:\n                pass  # Ignored\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _fetch(self, endpoint_name, **params):\n        params['api_key'] = self.api_key\n\n        resp = requests.get(self._endpoint(endpoint_name), params=params)\n        resp.raise_for_status()\n\n        data = resp.json()\n        self._check_or_raise(data.get('meta', {}))\n\n        return data", "response": "Wrapper for making an api request from giphy\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching for gifs with a given term or phrase.", "response": "def search(self, term=None, phrase=None, limit=DEFAULT_SEARCH_LIMIT,\n               rating=None):\n        \"\"\"\n        Search for gifs with a given word or phrase. Punctuation is ignored.\n        By default, this will perform a `term` search. If you want to search\n        by phrase, use the `phrase` keyword argument. What's the difference\n        between `term` and `phrase` searches? Simple: a term search will\n        return results matching any words given, whereas a phrase search will\n        match all words.\n\n        Note that this method is a GiphyImage generator that\n        automatically handles api paging. Optionally accepts a limit that will\n        terminate the generation after a specified number of results have been\n        yielded. This defaults to 25 results; a None implies no limit\n\n        :param term: Search term or terms\n        :type term: string\n        :param phrase: Search phrase\n        :type phrase: string\n        :param limit: Maximum number of results to yield\n        :type limit: int\n        :param rating: limit results to those rated (y,g, pg, pg-13 or r).\n        :type rating: string\n        \"\"\"\n        assert any((term, phrase)), 'You must supply a term or phrase to search'\n\n        # Phrases should have dashes and not spaces\n        if phrase:\n            phrase = phrase.replace(' ', '-')\n\n        results_yielded = 0  # Count how many things we yield\n        page, per_page = 0, 25\n        params = {'q': (term or phrase)}\n        if rating:\n            params.update({'rating': rating})\n        fetch = partial(self._fetch, 'search', **params)\n\n        # Generate results until we 1) run out of pages 2) reach a limit\n        while True:\n            data = fetch(offset=page, limit=per_page)\n            page += per_page\n\n            # Guard for empty results\n            if not data['data']:\n                raise StopIteration\n\n            for item in data['data']:\n                results_yielded += 1\n                yield GiphyImage(item)\n\n                if limit is not None and results_yielded >= limit:\n                    raise StopIteration\n\n            # Check yieled limit and whether or not there are more items\n            if (page >= data['pagination']['total_count'] or\n                    (limit is not None and results_yielded >= limit)):\n                raise StopIteration"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch for a single entry in the database.", "response": "def search_list(self, term=None, phrase=None, limit=DEFAULT_SEARCH_LIMIT,\n                    rating=None):\n        \"\"\"\n        Suppose you expect the `search` method to just give you a list rather\n        than a generator. This method will have that effect. Equivalent to::\n\n            >>> g = Giphy()\n            >>> results = list(g.search('foo'))\n        \"\"\"\n        return list(self.search(term=term, phrase=phrase, limit=limit,\n                                rating=rating))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntranslate a term or phrase into an animated GIF.", "response": "def translate(self, term=None, phrase=None, strict=False, rating=None):\n        \"\"\"\n        Retrieve a single image that represents a transalation of a term or\n        phrase into an animated gif. Punctuation is ignored. By default, this\n        will perform a `term` translation. If you want to translate by phrase,\n        use the `phrase` keyword argument.\n\n        :param term: Search term or terms\n        :type term: string\n        :param phrase: Search phrase\n        :type phrase: string\n        :param strict: Whether an exception should be raised when no results\n        :type strict: boolean\n        :param rating: limit results to those rated (y,g, pg, pg-13 or r).\n        :type rating: string\n        \"\"\"\n        assert any((term, phrase)), 'You must supply a term or phrase to search'\n\n        # Phrases should have dashes and not spaces\n        if phrase:\n            phrase = phrase.replace(' ', '-')\n\n        params = {'s': (term or phrase)}\n        if rating:\n            params.update({'rating': rating})\n        resp = self._fetch('translate', **params)\n        if resp['data']:\n            return GiphyImage(resp['data'])\n        elif strict or self.strict:\n            raise GiphyApiException(\n                \"Term/Phrase '%s' could not be translated into a GIF\" %\n                (term or phrase))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef trending(self, rating=None, limit=DEFAULT_SEARCH_LIMIT):\n\n        results_yielded = 0  # Count how many things we yield\n        page, per_page = 0, 25\n        params = {'rating': rating} if rating else {}\n        fetch = partial(self._fetch, 'trending', **params)\n\n        # Generate results until we 1) run out of pages 2) reach a limit\n        while True:\n            data = fetch(offset=page, limit=per_page)\n            page += per_page\n\n            # Guard for empty results\n            if not data['data']:\n                raise StopIteration\n\n            for item in data['data']:\n                results_yielded += 1\n                yield GiphyImage(item)\n\n                if limit is not None and results_yielded >= limit:\n                    raise StopIteration\n\n            # Check yieled limit and whether or not there are more items\n            if (page >= data['pagination']['total_count'] or\n                    (limit is not None and results_yielded >= limit)):\n                raise StopIteration", "response": "Retrieve GIFs currently trending online. The data returned is returned mirrors\n        that used to create the Hot 100 list of GIFs on Giphy."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef trending_list(self, rating=None, limit=DEFAULT_SEARCH_LIMIT):\n        return list(self.trending(limit=limit, rating=rating))", "response": "Returns a list of all trending items for a given user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve a specifc gif from giphy based on unique id", "response": "def gif(self, gif_id, strict=False):\n        \"\"\"\n        Retrieves a specifc gif from giphy based on unique id\n\n        :param gif_id: Unique giphy gif ID\n        :type gif_id: string\n        :param strict: Whether an exception should be raised when no results\n        :type strict: boolean\n        \"\"\"\n        resp = self._fetch(gif_id)\n\n        if resp['data']:\n            return GiphyImage(resp['data'])\n        elif strict or self.strict:\n            raise GiphyApiException(\n                \"GIF with ID '%s' could not be found\" % gif_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef screensaver(self, tag=None, strict=False):\n        params = {'tag': tag} if tag else {}\n        resp = self._fetch('screensaver', **params)\n\n        if resp['data'] and resp['data']['id']:\n            return self.gif(resp['data']['id'])\n        elif strict or self.strict:\n            raise GiphyApiException(\n                \"No screensaver GIF tagged '%s' found\" % tag)", "response": "Returns a random giphy image optionally based on a search of a given tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuploads a gif from the filesystem to Giphy.", "response": "def upload(self, tags, file_path, username=None):\n        \"\"\"\n        Uploads a gif from the filesystem to Giphy.\n\n        :param tags: Tags to apply to the uploaded image\n        :type tags: list\n        :param file_path: Path at which the image can be found\n        :type file_path: string\n        :param username: Your channel username if not using public API key\n        \"\"\"\n        params = {\n            'api_key': self.api_key,\n            'tags': ','.join(tags)\n        }\n        if username is not None:\n            params['username'] = username\n\n        with open(file_path, 'rb') as f:\n            resp = requests.post(\n                GIPHY_UPLOAD_ENDPOINT, params=params, files={'file': f})\n\n        resp.raise_for_status()\n\n        data = resp.json()\n        self._check_or_raise(data.get('meta', {}))\n\n        return self.gif(data['data']['id'])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _convert(self, args):\n        '''convert '(1,1)' to 'B2' and 'B2' to '(1,1)' auto-recongnize'''\n        if args.find(\",\") > -1:\n            b, a = args.replace(\"(\", \"\").replace(\")\", \"\").split(\",\")\n            a = chr(int(a)+65)#chr(65) is \"A\" and ord(\"A\") is 65\n            b = str(int(b)+1)\n            return a+b\n        else:\n            a = str(int(args[1:2])-1)               # D1-->(0,3)   1-->0\n            b = str(ord(args[0:1].upper())-65)      # D1-->(0,3)   D-->3       ord(\"D\") is 68\n            return \"(\"+a+\",\"+b+\")\"", "response": "converts A to B and B to B and B to B1 and B2 auto - congnize"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the appropriate extension element for the given access control", "response": "def _access_control(self, access_control, my_media_group=None):\n        \"\"\"\n        Prepares the extension element for access control\n        Extension element is the optional parameter for the YouTubeVideoEntry\n        We use extension element to modify access control settings\n\n        Returns:\n            tuple of extension elements\n        \"\"\"\n        # Access control\n        extension = None\n        if access_control is AccessControl.Private:\n            # WARNING: this part of code is not tested\n            # set video as private\n            if my_media_group:\n                my_media_group.private = gdata.media.Private()\n        elif access_control is AccessControl.Unlisted:\n            # set video as unlisted\n            from gdata.media import YOUTUBE_NAMESPACE\n            from atom import ExtensionElement\n            kwargs = {\n                \"namespace\": YOUTUBE_NAMESPACE,\n                \"attributes\": {'action': 'list', 'permission': 'denied'},\n            }\n            extension = ([ExtensionElement('accessControl', **kwargs)])\n        return extension"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fetch_feed_by_username(self, username):\n        # Don't use trailing slash\n        youtube_url = 'http://gdata.youtube.com/feeds/api'\n        uri = os.sep.join([youtube_url, \"users\", username, \"uploads\"])\n        return Api.yt_service.GetYouTubeVideoFeed(uri)", "response": "Retrieve the video feed by username"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef authenticate(self, email=None, password=None, source=None):\n        from gdata.service import BadAuthentication\n\n        # Auth parameters\n        Api.yt_service.email = email if email else settings.YOUTUBE_AUTH_EMAIL\n        Api.yt_service.password = password if password else settings.YOUTUBE_AUTH_PASSWORD\n        Api.yt_service.source = source if source else settings.YOUTUBE_CLIENT_ID\n        try:\n            Api.yt_service.ProgrammaticLogin()\n            self.authenticated = True\n        except BadAuthentication:\n            raise ApiError(_(\"Incorrect username or password\"))", "response": "Authenticate the user and set the GData Auth token."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upload_direct(self, video_path, title, description=\"\", keywords=\"\", developer_tags=None, access_control=AccessControl.Public):\n        # prepare a media group object to hold our video's meta-data\n        my_media_group = gdata.media.Group(\n            title=gdata.media.Title(text=title),\n            description=gdata.media.Description(description_type='plain',\n                                                text=description),\n            keywords=gdata.media.Keywords(text=keywords),\n            category=[gdata.media.Category(\n                text='Autos',\n                scheme='http://gdata.youtube.com/schemas/2007/categories.cat',\n                label='Autos')],\n            #player = None\n        )\n\n        # Access Control\n        extension = self._access_control(access_control, my_media_group)\n\n        # create the gdata.youtube.YouTubeVideoEntry to be uploaded\n        video_entry = gdata.youtube.YouTubeVideoEntry(media=my_media_group, extension_elements=extension)\n\n        # add developer tags\n        if developer_tags:\n            video_entry.AddDeveloperTags(developer_tags)\n\n        # upload the video and create a new entry\n        new_entry = Api.yt_service.InsertVideoEntry(video_entry, video_path)\n\n        return new_entry", "response": "Direct upload method. Uploads the video directly to Youtube and creates a video\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef upload(self, title, description=\"\", keywords=\"\", developer_tags=None, access_control=AccessControl.Public):\n        # Raise ApiError if not authenticated\n        if not self.authenticated:\n            raise ApiError(_(\"Authentication is required\"))\n\n        # create media group\n        my_media_group = gdata.media.Group(\n            title=gdata.media.Title(text=title),\n            description=gdata.media.Description(description_type='plain',\n                                                text=description),\n            keywords=gdata.media.Keywords(text=keywords),\n            category=[gdata.media.Category(\n                text='Autos',\n                scheme='http://gdata.youtube.com/schemas/2007/categories.cat',\n                label='Autos')],\n            #player = None\n        )\n\n        # Access Control\n        extension = self._access_control(access_control, my_media_group)\n\n        # create video entry\n        video_entry = gdata.youtube.YouTubeVideoEntry(\n            media=my_media_group, extension_elements=extension)\n\n        # add developer tags\n        if developer_tags:\n            video_entry.AddDeveloperTags(developer_tags)\n\n        # upload meta data only\n        response = Api.yt_service.GetFormUploadToken(video_entry)\n\n        # parse response tuple and use the variables to build a form\n        post_url = response[0]\n        youtube_token = response[1]\n\n        return {'post_url': post_url, 'youtube_token': youtube_token}", "response": "Create a video entry and meta data for uploading a video."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking the video upload status and returns a dict containing upload_state and detailed_message.", "response": "def check_upload_status(self, video_id):\n        \"\"\"\n        Checks the video upload status\n        Newly uploaded videos may be in the processing state\n\n        Authentication is required\n\n        Returns:\n            True if video is available\n            otherwise a dict containes upload_state and detailed message\n            i.e. {\"upload_state\": \"processing\", \"detailed_message\": \"\"}\n        \"\"\"\n        # Raise ApiError if not authenticated\n        if not self.authenticated:\n            raise ApiError(_(\"Authentication is required\"))\n\n        entry = self.fetch_video(video_id)\n        upload_status = Api.yt_service.CheckUploadStatus(entry)\n\n        if upload_status is not None:\n            video_upload_state = upload_status[0]\n            detailed_message = upload_status[1]\n            return {\"upload_state\": video_upload_state, \"detailed_message\": detailed_message}\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_video(self, video_id, title=\"\", description=\"\", keywords=\"\", access_control=AccessControl.Unlisted):\n\n        # Raise ApiError if not authenticated\n        if not self.authenticated:\n            raise ApiError(_(\"Authentication is required\"))\n\n        entry = self.fetch_video(video_id)\n\n        # Set Access Control\n        extension = self._access_control(access_control)\n        if extension:\n            entry.extension_elements = extension\n\n        if title:\n            entry.media.title.text = title\n\n        if description:\n            entry.media.description.text = description\n\n        #if keywords:\n        #    entry.media.keywords.text = keywords\n\n        success = Api.yt_service.UpdateVideoEntry(entry)\n        return success", "response": "Update the video entry with the given title description and keywords."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_video(self, video_id):\n        # Raise ApiError if not authenticated\n        if not self.authenticated:\n            raise ApiError(_(\"Authentication is required\"))\n\n        entry = self.fetch_video(video_id)\n        response = Api.yt_service.DeleteVideoEntry(entry)\n\n        if not response:\n            raise OperationError(_(\"Cannot be deleted from Youtube\"))\n\n        return True", "response": "Delete a video entry from Youtube"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_video_availability(request, video_id):\n    # Check video availability\n    # Available states are: processing\n    api = Api()\n    api.authenticate()\n    availability = api.check_upload_status(video_id)\n\n    if availability is not True:\n        data = {'success': False}\n    else:\n        data = {'success': True}\n\n    return HttpResponse(json.dumps(data), content_type=\"application/json\")", "response": "Checks availability of a video."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef video(request, video_id):\n\n    # Check video availability\n    # Available states are: processing\n    api = Api()\n    api.authenticate()\n    availability = api.check_upload_status(video_id)\n\n    if availability is not True:\n        # Video is not available\n        video = Video.objects.filter(video_id=video_id).get()\n\n        state = availability[\"upload_state\"]\n\n        # Add additional states here. I'm not sure what states are available\n        if state == \"failed\" or state == \"rejected\":\n            return render_to_response(\n                \"django_youtube/video_failed.html\",\n                {\"video\": video, \"video_id\": video_id, \"message\":\n                    _(\"Invalid video.\"), \"availability\": availability},\n                context_instance=RequestContext(request)\n            )\n        else:\n            return render_to_response(\n                \"django_youtube/video_unavailable.html\",\n                {\"video\": video, \"video_id\": video_id,\n                 \"message\": _(\"This video is currently being processed\"), \"availability\": availability},\n                context_instance=RequestContext(request)\n            )\n\n    video_params = _video_params(request, video_id)\n\n    return render_to_response(\n        \"django_youtube/video.html\",\n        video_params,\n        context_instance=RequestContext(request)\n    )", "response": "Displays a video in an embed player"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef video_list(request, username=None):\n\n    # If user is not authenticated and username is None, raise an error\n    if username is None and not request.user.is_authenticated():\n        from django.http import Http404\n        raise Http404\n\n    from django.contrib.auth.models import User\n    user = User.objects.get(username=username) if username else request.user\n\n    # loop through the videos of the user\n    videos = Video.objects.filter(user=user).all()\n    video_params = []\n    for video in videos:\n        video_params.append(_video_params(request, video.video_id))\n\n    return render_to_response(\n        \"django_youtube/videos.html\",\n        {\"video_params\": video_params},\n        context_instance=RequestContext(request)\n    )", "response": "Displays a list of videos of a user"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndirect upload method for Youtube and return a json response.", "response": "def direct_upload(request):\n    \"\"\"\n    direct upload method\n    starts with uploading video to our server\n    then sends the video file to youtube\n\n    param:\n        (optional) `only_data`: if set, a json response is returns i.e. {'video_id':'124weg'}\n\n    return:\n        if `only_data` set, a json object.\n        otherwise redirects to the video display page\n    \"\"\"\n    if request.method == \"POST\":\n        try:\n            form = YoutubeDirectUploadForm(request.POST, request.FILES)\n            # upload the file to our server\n            if form.is_valid():\n                uploaded_video = form.save()\n\n                # send this file to youtube\n                api = Api()\n                api.authenticate()\n                video_entry = api.upload_direct(uploaded_video.file_on_server.path, \"Uploaded video from zuqqa\")\n\n                # get data from video entry\n                swf_url = video_entry.GetSwfUrl()\n                youtube_url = video_entry.id.text\n\n                # getting video_id is tricky, I can only reach the url which\n                # contains the video_id.\n                # so the only option is to parse the id element\n                # https://groups.google.com/forum/?fromgroups=#!topic/youtube-api-gdata/RRl_h4zuKDQ\n                url_parts = youtube_url.split(\"/\")\n                url_parts.reverse()\n                video_id = url_parts[0]\n\n                # save video_id to video instance\n                video = Video()\n                video.user = request.user\n                video.video_id = video_id\n                video.title = 'tmp video'\n                video.youtube_url = youtube_url\n                video.swf_url = swf_url\n                video.save()\n\n                # send a signal\n                video_created.send(sender=video, video=video)\n\n                # delete the uploaded video instance\n                uploaded_video.delete()\n\n                # return the response\n                return_only_data = request.GET.get('only_data')\n                if return_only_data:\n                    return HttpResponse(json.dumps({\"video_id\": video_id}), content_type=\"application/json\")\n                else:\n                    # Redirect to the video page or the specified page\n                    try:\n                        next_url = settings.YOUTUBE_UPLOAD_REDIRECT_URL\n                    except AttributeError:\n                        next_url = reverse(\n                            \"django_youtube.views.video\", kwargs={\"video_id\": video_id})\n\n                    return HttpResponseRedirect(next_url)\n        except:\n            import sys\n            logger.error(\"Unexpected error: %s - %s\" % (sys.exc_info()[\n                0], sys.exc_info()[1]))\n            # @todo: proper error management\n            return HttpResponse(\"error happened\")\n\n    form = YoutubeDirectUploadForm()\n\n    if return_only_data:\n        return HttpResponse(json.dumps({\"error\": 500}), content_type=\"application/json\")\n    else:\n        return render_to_response(\n            \"django_youtube/direct-upload.html\",\n            {\"form\": form},\n            context_instance=RequestContext(request)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates an upload form and returns the url and token of the uploaded video", "response": "def upload(request):\n    \"\"\"\n    Displays an upload form\n    Creates upload url and token from youtube api and uses them on the form\n    \"\"\"\n    # Get the optional parameters\n    title = request.GET.get(\"title\", \"%s's video on %s\" % (\n        request.user.username, request.get_host()))\n    description = request.GET.get(\"description\", \"\")\n    keywords = request.GET.get(\"keywords\", \"\")\n\n    # Try to create post_url and token to create an upload form\n    try:\n        api = Api()\n\n        # upload method needs authentication\n        api.authenticate()\n\n        # Customize following line to your needs, you can add description, keywords or developer_keys\n        # I prefer to update video information after upload finishes\n        data = api.upload(title, description=description, keywords=keywords,\n                          access_control=AccessControl.Unlisted)\n    except ApiError as e:\n        # An api error happened, redirect to homepage\n        messages.add_message(request, messages.ERROR, e.message)\n        return HttpResponseRedirect(\"/\")\n    except:\n        # An error happened, redirect to homepage\n        messages.add_message(request, messages.ERROR, _(\n            'An error occurred during the upload, Please try again.'))\n        return HttpResponseRedirect(\"/\")\n\n    # Create the form instance\n    form = YoutubeUploadForm(initial={\"token\": data[\"youtube_token\"]})\n\n    protocol = 'https' if request.is_secure() else 'http'\n    next_url = '%s://%s%s/' % (protocol, request.get_host(), reverse(\"django_youtube.views.upload_return\"))\n    return render_to_response(\n        \"django_youtube/upload.html\",\n        {\"form\": form, \"post_url\": data[\"post_url\"], \"next_url\": next_url},\n        context_instance=RequestContext(request)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the url of the next page after upload is finished", "response": "def upload_return(request):\n    \"\"\"\n    The upload result page\n    Youtube will redirect to this page after upload is finished\n    Saves the video data and redirects to the next page\n\n    Params:\n        status: status of the upload (200 for success)\n        id: id number of the video\n    \"\"\"\n    status = request.GET.get(\"status\")\n    video_id = request.GET.get(\"id\")\n\n    if status == \"200\" and video_id:\n        # upload is successful\n\n        # save the video entry\n        video = Video()\n        video.user = request.user\n        video.video_id = video_id\n        video.save()\n\n        # send a signal\n        video_created.send(sender=video, video=video)\n\n        # Redirect to the video page or the specified page\n        try:\n            next_url = settings.YOUTUBE_UPLOAD_REDIRECT_URL\n        except AttributeError:\n            next_url = reverse(\n                \"django_youtube.views.video\", kwargs={\"video_id\": video_id})\n\n        return HttpResponseRedirect(next_url)\n    else:\n        # upload failed, redirect to upload page\n        from django.contrib import messages\n        messages.add_message(\n            request, messages.ERROR, _('Upload failed, Please try again.'))\n        return HttpResponseRedirect(reverse(\"django_youtube.views.upload\"))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove the video from youtube and from db Requires POST Requires YOUTUBE_DELETE_REDIRECT_URL", "response": "def remove(request, video_id):\n    \"\"\"\n    Removes the video from youtube and from db\n    Requires POST\n    \"\"\"\n\n    # prepare redirection url\n    try:\n        next_url = settings.YOUTUBE_DELETE_REDIRECT_URL\n    except AttributeError:\n        next_url = reverse(\"django_youtube.views.upload\")\n\n    # Remove from db\n    try:\n        Video.objects.get(video_id=video_id).delete()\n    except:\n        from django.contrib import messages\n        messages.add_message(\n            request, messages.ERROR, _('Video could not be deleted.'))\n\n    # Return to upload page or specified page\n    return HttpResponseRedirect(next_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef entry(self):\n        api = Api()\n        api.authenticate()\n        return api.fetch_video(self.video_id)", "response": "Connects to Youtube Api and retrieves the video entry object\n        Returns a YouTubeVideoEntry object"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save(self, *args, **kwargs):\n\n        # if this is a new instance add details from api\n        if not self.id:\n            # Connect to api and get the details\n            entry = self.entry()\n\n            # Set the details\n            self.title = entry.media.title.text\n            self.description = entry.media.description.text\n            self.keywords = entry.media.keywords.text\n            self.youtube_url = entry.media.player.url\n            self.swf_url = entry.GetSwfUrl()\n            if entry.media.private:\n                self.access_control = AccessControl.Private\n            else:\n                self.access_control = AccessControl.Public\n\n            # Save the instance\n            super(Video, self).save(*args, **kwargs)\n\n            # show thumbnails\n            for thumbnail in entry.media.thumbnail:\n                t = Thumbnail()\n                t.url = thumbnail.url\n                t.video = self\n                t.save()\n        else:\n            # updating the video instance\n            # Connect to API and update video on youtube\n            api = Api()\n\n            # update method needs authentication\n            api.authenticate()\n\n            # Update the info on youtube, raise error on failure\n            api.update_video(self.video_id, self.title, self.description,\n                             self.keywords, self.access_control)\n\n        # Save the model\n        return super(Video, self).save(*args, **kwargs)", "response": "Save the video instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete the video from youtube", "response": "def delete(self, *args, **kwargs):\n        \"\"\"\n        Deletes the video from youtube\n\n        Raises:\n            OperationError\n        \"\"\"\n        api = Api()\n\n        # Authentication is required for deletion\n        api.authenticate()\n\n        # Send API request, raises OperationError on unsuccessful deletion\n        api.delete_video(self.video_id)\n\n        # Call the super method\n        return super(Video, self).delete(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist Devices from an existing Distribution.", "response": "def devices(self, **params):\n        \"\"\" Method for `List Devices from an existing Distribution <https://m2x.att.com/developer/documentation/v2/distribution#List-Devices-from-an-existing-Distribution>`_ endpoint.\n\n        :param params: Query parameters passed as keyword arguments. View M2X API Docs for listing of available parameters.\n\n        :return: List of Devices associated with this Distribution as :class:`.DistributionDevice` objects\n        :rtype: `list <https://docs.python.org/2/library/functions.html#list>`_\n\n        :raises: :class:`~requests.exceptions.HTTPError` if an error occurs when sending the HTTP request\n        \"\"\"\n        return DistributionDevice.list(self.api, distribution_id=self.id, **params)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_device(self, params):\n        return DistributionDevice.create(self.api, distribution_id=self.id, **params)", "response": "Method for adding a new Device to an existing Distribution"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting Devices from an existing Collection.", "response": "def devices(self, **params):\n        \"\"\" Method for `List Devices from an existing Collection <https://m2x.att.com/developer/documentation/v2/collections#List-Devices-from-an-existing-Collection>`_ endpoint.\n\n        :param params: Query parameters passed as keyword arguments. View M2X API Docs for listing of available parameters.\n\n        :return: List of :class:`.Device` objects\n        :rtype: `list <https://docs.python.org/2/library/functions.html#list>`_\n\n        :raises: :class:`~requests.exceptions.HTTPError` if an error occurs when sending the HTTP request\n        \"\"\"\n        return CollectionDevice.list(self.api, collection_id=self.id, **params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_stream(self, name, **params):\n        return Stream.create(self.api, self, name, **params)", "response": "Create a new stream with the given name and parameters."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an API Key for this Device.", "response": "def create_key(self, **params):\n        \"\"\" Create an API Key for this Device via the `Create Key <https://m2x.att.com/developer/documentation/v2/keys#Create-Key>`_ endpoint.\n\n        :param params: Query parameters passed as keyword arguments. View M2X API Docs for listing of available parameters.\n\n        :return: The newly created Key\n        :rtype: Key\n\n        :raises: :class:`~requests.exceptions.HTTPError` if an error occurs when sending the HTTP request\n        \"\"\"\n        return Key.create(self.api, device=self.id, **params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef location(self):\n        return self.data.get('location') or \\\n            self.api.get(self.subpath('/location')) or {}", "response": "Method for getting the most recently logged location of the Device"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post_update(self, **values):\n        return self.api.post(self.subpath('/update'), data=values)", "response": "Method for POSTing update of the current device s attributes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef values(self, **params):\n        return self.api.get(self.subpath('/values'), params=params)", "response": "Method for listing available data stream values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef values_export(self, **params):\n        self.api.get(self.subpath('/values/export.csv'), params=params)\n        return self.api.last_response", "response": "This method returns the HTTP response for the Export Values From All Data Streams of a Device <https://m2x. att. com / developer / documentation / v2. att. com > _ endpoint."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef values_search(self, **params):\n        return self.api.post(self.subpath('/values/search'), data=params)", "response": "Method for Search Values from All Data Streams of a Device <https://m2x. att. com / developer / documentation / v2 / device#Search - Values - from - all - Streams - of - a - Device > _ endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_command(self, id, **params):\n        return self.api.post(self.subpath('/commands/%s/process' % id), data=params)", "response": "Method for Device Marks a Command as Processed <https://m2x. att. com / developer / documentation / v2 / commands#Device - Marks - a - Command - as - Processed > _ endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_metadata(self, params):\n    return self.api.put(self.metadata_path(), data=params)", "response": "Update the metadata of a resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_metadata_field(self, field, value):\n    return self.api.put(self.metadata_field_path(field), data={ \"value\": value })", "response": "Update the value of a metadata field in a resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the resource s attributes.", "response": "def update(self, **attrs):\n        \"\"\" Generic method for a resource's Update endpoint.\n\n        Example endpoints:\n\n        * `Update Device Details <https://m2x.att.com/developer/documentation/v2/device#Update-Device-Details>`_\n        * `Update Distribution Details <https://m2x.att.com/developer/documentation/v2/distribution#Update-Distribution-Details>`_\n        * `Update Collection Details <https://m2x.att.com/developer/documentation/v2/collections#Update-Collection-Details>`_\n\n        :param attrs: Query parameters passed as keyword arguments. View M2X API Docs for listing of available parameters.\n\n        :return: The API response, see M2X API docs for details\n        :rtype: dict\n\n        :raises: :class:`~requests.exceptions.HTTPError` if an error occurs when sending the HTTP request\n        \"\"\"\n        self.data.update(self.item_update(self.api, self.id, **attrs))\n        return self.data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sampling(self, interval, **params):\n        params['interval'] = interval\n        return self.api.get(self.subpath('/sampling'), params=params)", "response": "Method for Data Stream Sampling <https://m2x. att. com / developer / documentation / v2 / device#Data - Stream - Sampling > _ endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_value(self, value, timestamp=None):\n        data = {'value': value}\n        if timestamp:\n            data['timestamp'] = timestamp\n        return self.api.put(self.subpath('/value'), data=data)", "response": "Method for adding a value to the updated stream value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef post_values(self, values):\n        return self.api.post(self.subpath('/values'), data={\n            'values': values\n        })", "response": "Method for POSTing data stream values to M2X."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete the values from the given time range.", "response": "def delete_values(self, start, stop):\n        \"\"\" Method for `Delete Data Stream Values <https://m2x.att.com/developer/documentation/v2/device#Delete-Data-Stream-Values>`_ endpoint.\n\n        :param start: ISO8601 timestamp for starting timerange for values to be deleted\n        :param stop: ISO8601 timestamp for ending timerange for values to be deleted\n\n        :return: The API response, see M2X API docs for details\n        :rtype: dict\n\n        :raises: :class:`~requests.exceptions.HTTPError` if an error occurs when sending the HTTP request\n        \"\"\"\n        return self.api.delete(self.subpath('/values'), data=self.to_server({\n            'from': start,\n            'end': stop\n        }))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a list of trees from a Newick formatted string.", "response": "def loads(s, strip_comments=False, **kw):\n    \"\"\"\n    Load a list of trees from a Newick formatted string.\n\n    :param s: Newick formatted string.\n    :param strip_comments: Flag signaling whether to strip comments enclosed in square \\\n    brackets.\n    :param kw: Keyword arguments are passed through to `Node.create`.\n    :return: List of Node objects.\n    \"\"\"\n    kw['strip_comments'] = strip_comments\n    return [parse_node(ss.strip(), **kw) for ss in s.split(';') if ss.strip()]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dumps(trees):\n    if isinstance(trees, Node):\n        trees = [trees]\n    return ';\\n'.join([tree.newick for tree in trees]) + ';'", "response": "Serialize a list of trees in Newick format."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load(fp, strip_comments=False, **kw):\n    kw['strip_comments'] = strip_comments\n    return loads(fp.read(), **kw)", "response": "Load a list of trees from an open Newick formatted file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read(fname, encoding='utf8', strip_comments=False, **kw):\n    kw['strip_comments'] = strip_comments\n    with io.open(fname, encoding=encoding) as fp:\n        return load(fp, **kw)", "response": "Load a list of trees from a Newick formatted file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_siblings(s, **kw):\n    bracket_level = 0\n    current = []\n\n    # trick to remove special-case of trailing chars\n    for c in (s + \",\"):\n        if c == \",\" and bracket_level == 0:\n            yield parse_node(\"\".join(current), **kw)\n            current = []\n        else:\n            if c == \"(\":\n                bracket_level += 1\n            elif c == \")\":\n                bracket_level -= 1\n            current.append(c)", "response": "Parse a string of strings and yield a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a Newick formatted string into a Node object.", "response": "def parse_node(s, strip_comments=False, **kw):\n    \"\"\"\n    Parse a Newick formatted string into a `Node` object.\n\n    :param s: Newick formatted string to parse.\n    :param strip_comments: Flag signaling whether to strip comments enclosed in square \\\n    brackets.\n    :param kw: Keyword arguments are passed through to `Node.create`.\n    :return: `Node` instance.\n    \"\"\"\n    if strip_comments:\n        s = COMMENT.sub('', s)\n    s = s.strip()\n    parts = s.split(')')\n    if len(parts) == 1:\n        descendants, label = [], s\n    else:\n        if not parts[0].startswith('('):\n            raise ValueError('unmatched braces %s' % parts[0][:100])\n        descendants = list(_parse_siblings(')'.join(parts[:-1])[1:], **kw))\n        label = parts[-1]\n    name, length = _parse_name_and_length(label)\n    return Node.create(name=name, length=length, descendants=descendants, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new node object.", "response": "def create(cls, name=None, length=None, descendants=None, **kw):\n        \"\"\"\n        Create a new `Node` object.\n\n        :param name: Node label.\n        :param length: Branch length from the new node to its parent.\n        :param descendants: list of descendants or `None`.\n        :param kw: Additonal keyword arguments are passed through to `Node.__init__`.\n        :return: `Node` instance.\n        \"\"\"\n        node = cls(name=name, length=length, **kw)\n        for descendant in descendants or []:\n            node.add_descendant(descendant)\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a unicode string representing a tree in ASCII art fashion.", "response": "def ascii_art(self, strict=False, show_internal=True):\n        \"\"\"\n        Return a unicode string representing a tree in ASCII art fashion.\n\n        :param strict: Use ASCII characters strictly (for the tree symbols).\n        :param show_internal: Show labels of internal nodes.\n        :return: unicode string\n\n        >>> node = loads('((A,B)C,((D,E)F,G,H)I)J;')[0]\n        >>> print(node.ascii_art(show_internal=False, strict=True))\n                /-A\n            /---|\n            |   \\-B\n        ----|       /-D\n            |   /---|\n            |   |   \\-E\n            \\---|\n                |-G\n                \\-H\n        \"\"\"\n        cmap = {\n            '\\u2500': '-',\n            '\\u2502': '|',\n            '\\u250c': '/',\n            '\\u2514': '\\\\',\n            '\\u251c': '|',\n            '\\u2524': '|',\n            '\\u253c': '+',\n        }\n\n        def normalize(line):\n            m = re.compile('(?<=\\u2502)(?P<s>\\s+)(?=[\\u250c\\u2514\\u2502])')\n            line = m.sub(lambda m: m.group('s')[1:], line)\n            line = re.sub('\\u2500\\u2502', '\\u2500\\u2524', line)  # -|\n            line = re.sub('\\u2502\\u2500', '\\u251c', line)  # |-\n            line = re.sub('\\u2524\\u2500', '\\u253c', line)  # -|-\n            if strict:\n                for u, a in cmap.items():\n                    line = line.replace(u, a)\n            return line\n        return '\\n'.join(\n            normalize(l) for l in self._ascii_art(show_internal=show_internal)[0]\n            if set(l) != {' ', '\\u2502'})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntraverse the tree rooted at self yielding each visited Node.", "response": "def walk(self, mode=None):\n        \"\"\"\n        Traverses the (sub)tree rooted at self, yielding each visited Node.\n\n        .. seealso:: https://en.wikipedia.org/wiki/Tree_traversal\n\n        :param mode: Specifies the algorithm to use when traversing the subtree rooted \\\n        at self. `None` for breadth-first, `'postorder'` for post-order depth-first \\\n        search.\n        :return: Generator of the visited Nodes.\n        \"\"\"\n        if mode == 'postorder':\n            for n in self._postorder():\n                yield n\n        else:  # default to a breadth-first search\n            yield self\n            for node in self.descendants:\n                for n in node.walk():\n                    yield n"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit(self, visitor, predicate=None, **kw):\n        predicate = predicate or bool\n\n        for n in self.walk(**kw):\n            if predicate(n):\n                visitor(n)", "response": "Apply a function to matching nodes in the sub - tree rooted at self.\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_node(self, label):\n        for n in self.walk():\n            if n.name == label:\n                return n", "response": "Gets the specified node by name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove all nodes in the specified list or not in the specified list.", "response": "def prune(self, leaves, inverse=False):\n        \"\"\"\n        Remove all those nodes in the specified list, or if inverse=True,\n        remove all those nodes not in the specified list.  The specified nodes\n        must be leaves and distinct from the root node.\n\n        :param nodes: A list of Node objects\n        :param inverse: Specifies whether to remove nodes in the list or not\\\n                in the list.\n        \"\"\"\n        self.visit(\n            lambda n: n.ancestor.descendants.remove(n),\n            # We won't prune the root node, even if it is a leave and requested to\n            # be pruned!\n            lambda n: ((not inverse and n in leaves) or\n                       (inverse and n.is_leaf and n not in leaves)) and n.ancestor,\n            mode=\"postorder\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform an inverse prune with leaves specified by name.", "response": "def prune_by_names(self, leaf_names, inverse=False):\n        \"\"\"\n        Perform an (inverse) prune, with leaves specified by name.\n        :param node_names: A list of leaaf Node names (strings)\n        :param inverse: Specifies whether to remove nodes in the list or not\\\n                in the list.\n        \"\"\"\n        self.prune([l for l in self.walk() if l.name in leaf_names], inverse)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving redundant nodes from the tree.", "response": "def remove_redundant_nodes(self, preserve_lengths=True):\n        \"\"\"\n        Remove all nodes which have only a single child, and attach their\n        grandchildren to their parent.  The resulting tree has the minimum\n        number of internal nodes required for the number of leaves.\n        :param preserve_lengths: If true, branch lengths of removed nodes are \\\n        added to those of their children.\n        \"\"\"\n        for n in self.walk(mode='postorder'):\n            while n.ancestor and len(n.ancestor.descendants) == 1:\n                grandfather = n.ancestor.ancestor\n                father = n.ancestor\n                if preserve_lengths:\n                    n.length += father.length\n\n                if grandfather:\n                    for i, child in enumerate(grandfather.descendants):\n                        if child is father:\n                            del grandfather.descendants[i]\n                    grandfather.add_descendant(n)\n                    father.ancestor = None\n                else:\n                    self.descendants = n.descendants\n                    if preserve_lengths:\n                        self.length = n.length"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resolve_polytomies(self):\n        def _resolve_polytomies(n):\n            new = Node(length=self._length_formatter(self._length_parser('0')))\n            while len(n.descendants) > 1:\n                new.add_descendant(n.descendants.pop())\n            n.descendants.append(new)\n\n        self.visit(_resolve_polytomies, lambda n: len(n.descendants) > 2)", "response": "Resolve polytomies in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_internal_names(self):\n        self.visit(lambda n: setattr(n, 'name', None), lambda n: not n.is_leaf)", "response": "Remove the internal names from the node names attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_leaf_names(self):\n        self.visit(lambda n: setattr(n, 'name', None), lambda n: n.is_leaf)", "response": "Remove all leaf names from the node list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclear all comments in a json string and remove them from the list.", "response": "def dispose(json_str):\n    \"\"\"Clear all comments in json_str.\n\n    Clear JS-style comments like // and /**/ in json_str.\n    Accept a str or unicode as input.\n\n    Args:\n        json_str: A json string of str or unicode to clean up comment\n\n    Returns:\n        str: The str without comments (or unicode if you pass in unicode)\n    \"\"\"\n    result_str = list(json_str)\n    escaped = False\n    normal = True\n    sl_comment = False\n    ml_comment = False\n    quoted = False\n\n    a_step_from_comment = False\n    a_step_from_comment_away = False\n\n    former_index = None\n\n    for index, char in enumerate(json_str):\n\n        if escaped:  # We have just met a '\\'\n            escaped = False\n            continue\n\n        if a_step_from_comment:  # We have just met a '/'\n            if char != '/' and char != '*':\n                a_step_from_comment = False\n                normal = True\n                continue\n\n        if a_step_from_comment_away:  # We have just met a '*'\n            if char != '/':\n                a_step_from_comment_away = False\n\n        if char == '\"':\n            if normal and not escaped:\n                # We are now in a string\n                quoted = True\n                normal = False\n            elif quoted and not escaped:\n                # We are now out of a string\n                quoted = False\n                normal = True\n\n        elif char == '\\\\':\n            # '\\' should not take effect in comment\n            if normal or quoted:\n                escaped = True\n\n        elif char == '/':\n            if a_step_from_comment:\n                # Now we are in single line comment\n                a_step_from_comment = False\n                sl_comment = True\n                normal = False\n                former_index = index - 1\n            elif a_step_from_comment_away:\n                # Now we are out of comment\n                a_step_from_comment_away = False\n                normal = True\n                ml_comment = False\n                for i in range(former_index, index + 1):\n                    result_str[i] = \"\"\n\n            elif normal:\n                # Now we are just one step away from comment\n                a_step_from_comment = True\n                normal = False\n\n        elif char == '*':\n            if a_step_from_comment:\n                # We are now in multi-line comment\n                a_step_from_comment = False\n                ml_comment = True\n                normal = False\n                former_index = index - 1\n            elif ml_comment:\n                a_step_from_comment_away = True\n        elif char == '\\n':\n            if sl_comment:\n                sl_comment = False\n                normal = True\n                for i in range(former_index, index + 1):\n                    result_str[i] = \"\"\n        elif char == ']' or char == '}':\n            if normal:\n                _remove_last_comma(result_str, index)\n\n    # Show respect to original input if we are in python2\n    return (\"\" if isinstance(json_str, str) else u\"\").join(result_str)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nraising an exception if the given app setting is not defined.", "response": "def require_setting(self, name, feature=\"this feature\"):\n        \"\"\"Raises an exception if the given app setting is not defined.\"\"\"\n        if name not in self.settings:\n            raise Exception(\"You must define the '%s' setting in your \"\n                            \"application to use %s\" % (name, feature))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the value of the argument with the given name. If the name is not found in the url or if default is provided the value is returned. If the name is not found in the url an HTTP 400 exception is raised.", "response": "def get_argument(self, name, default=_ARG_DEFAULT, strip=True):\n        \"\"\"Returns the value of the argument with the given name.\n\n        If default is not provided, the argument is considered to be\n        required, and we throw an HTTP 400 exception if it is missing.\n\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        The returned value is always unicode.\n        \"\"\"\n        args = self.get_arguments(name, strip=strip)\n        if not args:\n            if default is self._ARG_DEFAULT:\n                raise HTTPError(400, \"Missing argument %s\" % name)\n            return default\n        return args[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_arguments(self, name, strip=True):\n        values = []\n        for v in self.request.params.getall(name):\n            v = self.decode_argument(v, name=name)\n            if isinstance(v, unicode):\n                # Get rid of any weird control chars (unless decoding gave\n                # us bytes, in which case leave it alone)\n                v = re.sub(r\"[\\x00-\\x08\\x0e-\\x1f]\", \" \", v)\n            if strip:\n                v = v.strip()\n            values.append(v)\n        return values", "response": "Returns a list of the arguments with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwrapping a callback function to be used in the async function.", "response": "def async_callback(self, callback, *args, **kwargs):\n        \"\"\"Obsolete - catches exceptions from the wrapped function.\n\n        This function is unnecessary since Tornado 1.1.\n        \"\"\"\n        if callback is None:\n            return None\n        if args or kwargs:\n            callback = functools.partial(callback, *args, **kwargs)\n\n        #FIXME what about the exception wrapper?\n\n        return callback"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the value of the cookie with the given name else default.", "response": "def get_cookie(self, name, default=None):\n        \"\"\"Gets the value of the cookie with the given name, else default.\"\"\"\n        assert self.cookie_monster, 'Cookie Monster not set'\n        return self.cookie_monster.get_cookie(name, default)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the given cookie name value with the given options.", "response": "def set_cookie(self, name, value, domain=None, expires=None, path=\"/\",\n                   expires_days=None, **kwargs):\n        \"\"\"Sets the given cookie name/value with the given options.\n\n        Additional keyword arguments are set on the Cookie.Morsel\n        directly.\n        See http://docs.python.org/library/cookie.html#morsel-objects\n        for available attributes.\n        \"\"\"\n        assert self.cookie_monster, 'Cookie Monster not set'\n        #, domain=domain, path=path)\n        self.cookie_monster.set_cookie(name, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting the cookie with the given name.", "response": "def clear_cookie(self, name, path=\"/\", domain=None):\n        \"\"\"Deletes the cookie with the given name.\"\"\"\n        assert self.cookie_monster, 'Cookie Monster not set'\n        #, path=path, domain=domain)\n        self.cookie_monster.delete_cookie(name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef authenticate_redirect(\n        self, callback_uri=None, ax_attrs=[\"name\", \"email\", \"language\",\n                                           \"username\"]):\n\n        \"\"\"Returns the authentication URL for this service.\n\n        After authentication, the service will redirect back to the given\n        callback URI.\n\n        We request the given attributes for the authenticated user by\n        default (name, email, language, and username). If you don't need\n        all those attributes for your app, you can request fewer with\n        the ax_attrs keyword argument.\n        \"\"\"\n        callback_uri = callback_uri or self.request.uri\n        args = self._openid_args(callback_uri, ax_attrs=ax_attrs)\n        self.redirect(self._OPENID_ENDPOINT + \"?\" + urllib.urlencode(args))", "response": "Returns the authentication URL for this service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch the authenticated user data upon redirect.", "response": "def get_authenticated_user(self, callback):\n        \"\"\"Fetches the authenticated user data upon redirect.\n\n        This method should be called by the handler that receives the\n        redirect from the authenticate_redirect() or authorize_redirect()\n        methods.\n        \"\"\"\n        # Verify the OpenID response via direct request to the OP\n        # Recommendation @hmarrao, ref #3\n        args = dict((k, unicode(v[-1]).encode('utf-8')) for k, v in self.request.arguments.iteritems())\n        args[\"openid.mode\"] = u\"check_authentication\"\n        url = self._OPENID_ENDPOINT\n        http = httpclient.AsyncHTTPClient()\n        log.debug(\"OpenID requesting {0} at uri {1}\".format(args, url))\n        http.fetch(url, self.async_callback(\n            self._on_authentication_verified, callback),\n            method=\"POST\", body=urllib.urlencode(args))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef authorize_redirect(self, callback_uri=None, extra_params=None):\n        if callback_uri and getattr(self, \"_OAUTH_NO_CALLBACKS\", False):\n            raise Exception(\"This service does not support oauth_callback\")\n        http = httpclient.AsyncHTTPClient()\n        if getattr(self, \"_OAUTH_VERSION\", \"1.0a\") == \"1.0a\":\n            http.fetch(self._oauth_request_token_url(callback_uri=callback_uri,\n                extra_params=extra_params),\n                self.async_callback(\n                    self._on_request_token,\n                    self._OAUTH_AUTHORIZE_URL,\n                callback_uri))\n        else:\n            http.fetch(self._oauth_request_token_url(), self.async_callback(\n                self._on_request_token, self._OAUTH_AUTHORIZE_URL, callback_uri))", "response": "Redirects the user to obtain OAuth authorization for this service."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_authenticated_user(self, callback):\n        request_key = self.get_argument(\"oauth_token\")\n        oauth_verifier = self.get_argument(\"oauth_verifier\", None)\n        request_cookie = self.get_cookie(\"_oauth_request_token\")\n        if not request_cookie:\n            log.warning(\"Missing OAuth request token cookie\")\n            callback(None)\n            return\n        self.clear_cookie(\"_oauth_request_token\")\n        cookie_key, cookie_secret = [base64.b64decode(i) for i in request_cookie.split(\"|\")]\n        if cookie_key != request_key:\n            log.warning(\"Request token does not match cookie\")\n            callback(None)\n            return\n        token = dict(key=cookie_key, secret=cookie_secret)\n        if oauth_verifier:\n          token[\"verifier\"] = oauth_verifier\n        http = httpclient.AsyncHTTPClient()\n        http.fetch(self._oauth_access_token_url(token), self.async_callback(\n            self._on_access_token, callback))", "response": "Gets the OAuth authorized user and access token on callback."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the OAuth parameters as a dict for the given request.", "response": "def _oauth_request_parameters(self, url, access_token, parameters={},\n                                  method=\"GET\"):\n        \"\"\"Returns the OAuth parameters as a dict for the given request.\n\n        parameters should include all POST arguments and query string arguments\n        that will be sent with the request.\n        \"\"\"\n        consumer_token = self._oauth_consumer_token()\n        base_args = dict(\n            oauth_consumer_key=consumer_token[\"key\"],\n            oauth_token=access_token[\"key\"],\n            oauth_signature_method=\"HMAC-SHA1\",\n            oauth_timestamp=str(int(time.time())),\n            oauth_nonce=binascii.b2a_hex(uuid.uuid4().bytes),\n            oauth_version=getattr(self, \"_OAUTH_VERSION\", \"1.0a\"),\n        )\n        args = {}\n        args.update(base_args)\n        args.update(parameters)\n        if getattr(self, \"_OAUTH_VERSION\", \"1.0a\") == \"1.0a\":\n            signature = _oauth10a_signature(consumer_token, method, url, args,\n                                         access_token)\n        else:\n            signature = _oauth_signature(consumer_token, method, url, args,\n                                         access_token)\n        base_args[\"oauth_signature\"] = signature\n        return base_args"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nredirecting the user to obtain OAuth authorization for this service.", "response": "def authorize_redirect(self, redirect_uri=None, client_id=None,\n                           client_secret=None, extra_params=None ):\n        \"\"\"Redirects the user to obtain OAuth authorization for this service.\n\n        Some providers require that you register a Callback\n        URL with your application. You should call this method to log the\n        user in, and then call get_authenticated_user() in the handler\n        you registered as your Callback URL to complete the authorization\n        process.\n        \"\"\"\n        args = {\n          \"redirect_uri\": redirect_uri,\n          \"client_id\": client_id\n        }\n        if extra_params: args.update(extra_params)\n        self.redirect(\n                url_concat(self._OAUTH_AUTHORIZE_URL, args))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching the given relative API path and callback and the given arguments.", "response": "def friendfeed_request(self, path, callback, access_token=None,\n                           post_args=None, **args):\n        \"\"\"Fetches the given relative API path, e.g., \"/bret/friends\"\n\n        If the request is a POST, post_args should be provided. Query\n        string arguments should be given as keyword arguments.\n\n        All the FriendFeed methods are documented at\n        http://friendfeed.com/api/documentation.\n\n        Many methods require an OAuth access token which you can obtain\n        through authorize_redirect() and get_authenticated_user(). The\n        user returned through that process includes an 'access_token'\n        attribute that can be used to make authenticated requests via\n        this method. Example usage::\n\n            class MainHandler(tornado.web.RequestHandler,\n                              tornado.auth.FriendFeedMixin):\n                @tornado.web.authenticated\n                @tornado.web.asynchronous\n                def get(self):\n                    self.friendfeed_request(\n                        \"/entry\",\n                        post_args={\"body\": \"Testing Tornado Web Server\"},\n                        access_token=self.current_user[\"access_token\"],\n                        callback=self.async_callback(self._on_post))\n\n                def _on_post(self, new_entry):\n                    if not new_entry:\n                        # Call failed; perhaps missing permission?\n                        self.authorize_redirect()\n                        return\n                    self.finish(\"Posted a message!\")\n\n        \"\"\"\n        # Add the OAuth resource request signature if we have credentials\n        url = \"http://friendfeed-api.com/v2\" + path\n        if access_token:\n            all_args = {}\n            all_args.update(args)\n            all_args.update(post_args or {})\n            consumer_token = self._oauth_consumer_token()\n            method = \"POST\" if post_args is not None else \"GET\"\n            oauth = self._oauth_request_parameters(\n                url, access_token, all_args, method=method)\n            args.update(oauth)\n        if args: url += \"?\" + urllib.urlencode(args)\n        callback = self.async_callback(self._on_friendfeed_request, callback)\n        http = httpclient.AsyncHTTPClient()\n        if post_args is not None:\n            http.fetch(url, method=\"POST\", body=urllib.urlencode(post_args),\n                       callback=callback)\n        else:\n            http.fetch(url, callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nredirects to the Google resource authorisation URL.", "response": "def authorize_redirect(self, oauth_scope, callback_uri=None,\n                           ax_attrs=[\"name\",\"email\",\"language\",\"username\"]):\n        \"\"\"Authenticates and authorizes for the given Google resource.\n\n        Some of the available resources are:\n\n        * Gmail Contacts - http://www.google.com/m8/feeds/\n        * Calendar - http://www.google.com/calendar/feeds/\n        * Finance - http://finance.google.com/finance/feeds/\n\n        You can authorize multiple resources by separating the resource\n        URLs with a space.\n        \"\"\"\n        callback_uri = callback_uri or self.request.uri\n        args = self._openid_args(callback_uri, ax_attrs=ax_attrs,\n                                 oauth_scope=oauth_scope)\n        self.redirect(self._OPENID_ENDPOINT + \"?\" + urllib.urlencode(args))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch the authenticated user data upon redirect.", "response": "def get_authenticated_user(self, callback):\n        \"\"\"Fetches the authenticated user data upon redirect.\"\"\"\n        # Look to see if we are doing combined OpenID/OAuth\n        oauth_ns = \"\"\n        for name, values in self.request.arguments.iteritems():\n            if name.startswith(\"openid.ns.\") and \\\n               values[-1] == u\"http://specs.openid.net/extensions/oauth/1.0\":\n                oauth_ns = name[10:]\n                break\n        token = self.get_argument(\"openid.\" + oauth_ns + \".request_token\", \"\")\n        if token:\n            http = httpclient.AsyncHTTPClient()\n            token = dict(key=token, secret=\"\")\n            http.fetch(self._oauth_access_token_url(token),\n                       self.async_callback(self._on_access_token, callback))\n        else:\n            OpenIdMixin.get_authenticated_user(self, callback)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef facebook_request(self, method, callback, **args):\n        self.require_setting(\"facebook_api_key\", \"Facebook Connect\")\n        self.require_setting(\"facebook_secret\", \"Facebook Connect\")\n        if not method.startswith(\"facebook.\"):\n            method = \"facebook.\" + method\n        args[\"api_key\"] = self.settings[\"facebook_api_key\"]\n        args[\"v\"] = \"1.0\"\n        args[\"method\"] = method\n        args[\"call_id\"] = str(long(time.time() * 1e6))\n        args[\"format\"] = \"json\"\n        args[\"sig\"] = self._signature(args)\n        url = \"http://api.facebook.com/restserver.php?\" + \\\n            urllib.urlencode(args)\n        http = httpclient.AsyncHTTPClient()\n        http.fetch(url, callback=self.async_callback(\n            self._parse_response, callback))", "response": "Makes a Facebook API REST request."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_authenticated_user(self, redirect_uri, client_id, client_secret,\n                              code, callback, fields=None):\n      \"\"\"Handles the login for the Facebook user, returning a user object.\n\n      Example usage::\n\n          class FacebookGraphLoginHandler(LoginHandler, tornado.auth.FacebookGraphMixin):\n            @tornado.web.asynchronous\n            def get(self):\n                if self.get_argument(\"code\", False):\n                    self.get_authenticated_user(\n                      redirect_uri='/auth/facebookgraph/',\n                      client_id=self.settings[\"facebook_api_key\"],\n                      client_secret=self.settings[\"facebook_secret\"],\n                      code=self.get_argument(\"code\"),\n                      callback=self.async_callback(\n                        self._on_login))\n                    return\n                self.authorize_redirect(redirect_uri='/auth/facebookgraph/',\n                                        client_id=self.settings[\"facebook_api_key\"],\n                                        extra_params={\"scope\": \"read_stream,offline_access\"})\n\n            def _on_login(self, user):\n              log.error(user)\n              self.finish()\n\n      \"\"\"\n      http = httpclient.AsyncHTTPClient()\n      args = {\n        \"redirect_uri\": redirect_uri,\n        \"code\": code,\n        \"client_id\": client_id,\n        \"client_secret\": client_secret,\n      }\n\n      #fields = set(['id', 'name', 'first_name', 'last_name',\n      #              'locale', 'picture', 'link'])\n      #if extra_fields: fields.update(extra_fields)\n      if fields:\n          fields = fields.split(',')\n\n      http.fetch(self._oauth_request_token_url(**args),\n          self.async_callback(self._on_access_token, redirect_uri, client_id,\n                              client_secret, callback, fields))", "response": "Handles the login for the Facebook user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching the given relative API path and callback.", "response": "def facebook_request(self, path, callback, access_token=None,\n                           post_args=None, **args):\n        \"\"\"Fetches the given relative API path, e.g., \"/btaylor/picture\"\n\n        If the request is a POST, post_args should be provided. Query\n        string arguments should be given as keyword arguments.\n\n        An introduction to the Facebook Graph API can be found at\n        http://developers.facebook.com/docs/api\n\n        Many methods require an OAuth access token which you can obtain\n        through authorize_redirect() and get_authenticated_user(). The\n        user returned through that process includes an 'access_token'\n        attribute that can be used to make authenticated requests via\n        this method. Example usage::\n\n            class MainHandler(tornado.web.RequestHandler,\n                              tornado.auth.FacebookGraphMixin):\n                @tornado.web.authenticated\n                @tornado.web.asynchronous\n                def get(self):\n                    self.facebook_request(\n                        \"/me/feed\",\n                        post_args={\"message\": \"I am posting from my Tornado application!\"},\n                        access_token=self.current_user[\"access_token\"],\n                        callback=self.async_callback(self._on_post))\n\n                def _on_post(self, new_entry):\n                    if not new_entry:\n                        # Call failed; perhaps missing permission?\n                        self.authorize_redirect()\n                        return\n                    self.finish(\"Posted a message!\")\n\n        \"\"\"\n        url = \"https://graph.facebook.com\" + path\n        all_args = {}\n        if access_token:\n            all_args[\"access_token\"] = access_token\n            all_args.update(args)\n            all_args.update(post_args or {})\n        if all_args: url += \"?\" + urllib.urlencode(all_args)\n        callback = self.async_callback(self._on_facebook_request, callback)\n        http = httpclient.AsyncHTTPClient()\n        if post_args is not None:\n            http.fetch(url, method=\"POST\", body=urllib.urlencode(post_args),\n                       callback=callback)\n        else:\n            http.fetch(url, callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef url_concat(url, args):\n    if not args: return url\n    if url[-1] not in ('?', '&'):\n        url += '&' if ('?' in url) else '?'\n    return url + urllib.urlencode(args)", "response": "Concatenate url and argument dictionary regardless of whether\n    url has existing query parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_multipart_form_data(boundary, data, arguments, files):\n    # The standard allows for the boundary to be quoted in the header,\n    # although it's rare (it happens at least for google app engine\n    # xmpp).  I think we're also supposed to handle backslash-escapes\n    # here but I'll save that until we see a client that uses them\n    # in the wild.\n    if boundary.startswith(b('\"')) and boundary.endswith(b('\"')):\n        boundary = boundary[1:-1]\n    if data.endswith(b(\"\\r\\n\")):\n        footer_length = len(boundary) + 6\n    else:\n        footer_length = len(boundary) + 4\n    parts = data[:-footer_length].split(b(\"--\") + boundary + b(\"\\r\\n\"))\n    for part in parts:\n        if not part: continue\n        eoh = part.find(b(\"\\r\\n\\r\\n\"))\n        if eoh == -1:\n            logging.warning(\"multipart/form-data missing headers\")\n            continue\n        headers = HTTPHeaders.parse(part[:eoh].decode(\"utf-8\"))\n        disp_header = headers.get(\"Content-Disposition\", \"\")\n        disposition, disp_params = _parse_header(disp_header)\n        if disposition != \"form-data\" or not part.endswith(b(\"\\r\\n\")):\n            logging.warning(\"Invalid multipart/form-data\")\n            continue\n        value = part[eoh + 4:-2]\n        if not disp_params.get(\"name\"):\n            logging.warning(\"multipart/form-data value missing name\")\n            continue\n        name = disp_params[\"name\"]\n        if disp_params.get(\"filename\"):\n            ctype = headers.get(\"Content-Type\", \"application/unknown\")\n            files.setdefault(name, []).append(dict(\n                filename=disp_params[\"filename\"], body=value,\n                content_type=ctype))\n        else:\n            arguments.setdefault(name, []).append(value)", "response": "Parses a multipart - form - data body."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a Content - Type like header. Return the main content - type and a dictionary of options.", "response": "def _parse_header(line):\n    \"\"\"Parse a Content-type like header.\n\n    Return the main content-type and a dictionary of options.\n\n    \"\"\"\n    parts = _parseparam(';' + line)\n    key = parts.next()\n    pdict = {}\n    for p in parts:\n        i = p.find('=')\n        if i >= 0:\n            name = p[:i].strip().lower()\n            value = p[i+1:].strip()\n            if len(value) >= 2 and value[0] == value[-1] == '\"':\n                value = value[1:-1]\n                value = value.replace('\\\\\\\\', '\\\\').replace('\\\\\"', '\"')\n            pdict[name] = value\n    return key, pdict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add(self, name, value):\n        norm_name = HTTPHeaders._normalize_name(name)\n        self._last_key = norm_name\n        if norm_name in self:\n            # bypass our override of __setitem__ since it modifies _as_list\n            dict.__setitem__(self, norm_name, self[norm_name] + ',' + value)\n            self._as_list[norm_name].append(value)\n        else:\n            self[norm_name] = value", "response": "Adds a new value for the given key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning all values for the given header as a list.", "response": "def get_list(self, name):\n        \"\"\"Returns all values for the given header as a list.\"\"\"\n        norm_name = HTTPHeaders._normalize_name(name)\n        return self._as_list.get(norm_name, [])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an iterable of all ( name value ) pairs.", "response": "def get_all(self):\n        \"\"\"Returns an iterable of all (name, value) pairs.\n\n        If a header has multiple values, multiple pairs will be\n        returned with the same name.\n        \"\"\"\n        for name, list in self._as_list.iteritems():\n            for value in list:\n                yield (name, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the dictionary with a single header line.", "response": "def parse_line(self, line):\n        \"\"\"Updates the dictionary with a single header line.\n\n        >>> h = HTTPHeaders()\n        >>> h.parse_line(\"Content-Type: text/html\")\n        >>> h.get('content-type')\n        'text/html'\n        \"\"\"\n        if line[0].isspace():\n            # continuation of a multi-line header\n            new_part = ' ' + line.lstrip()\n            self._as_list[self._last_key][-1] += new_part\n            dict.__setitem__(self, self._last_key,\n                             self[self._last_key] + new_part)\n        else:\n            name, value = line.split(\":\", 1)\n            self.add(name, value.strip())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary from HTTP header text.", "response": "def parse(cls, headers):\n        \"\"\"Returns a dictionary from HTTP header text.\n\n        >>> h = HTTPHeaders.parse(\"Content-Type: text/html\\\\r\\\\nContent-Length: 42\\\\r\\\\n\")\n        >>> sorted(h.iteritems())\n        [('Content-Length', '42'), ('Content-Type', 'text/html')]\n        \"\"\"\n        h = cls()\n        for line in headers.splitlines():\n            if line:\n                h.parse_line(line)\n        return h"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _normalize_name(name):\n        try:\n            return HTTPHeaders._normalized_headers[name]\n        except KeyError:\n            if HTTPHeaders._NORMALIZED_HEADER_RE.match(name):\n                normalized = name\n            else:\n                normalized = \"-\".join([w.capitalize() for w in name.split(\"-\")])\n            HTTPHeaders._normalized_headers[name] = normalized\n            return normalized", "response": "Converts a name to Http - Header - Case."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef utf8(value):\n    if isinstance(value, _UTF8_TYPES):\n        return value\n    assert isinstance(value, unicode)\n    return value.encode(\"utf-8\")", "response": "Converts a string argument to a byte string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a string argument to a unicode string.", "response": "def to_unicode(value):\n    \"\"\"Converts a string argument to a unicode string.\n\n    If the argument is already a unicode string or None, it is returned\n    unchanged.  Otherwise it must be a byte string and is decoded as utf8.\n    \"\"\"\n    if isinstance(value, _TO_UNICODE_TYPES):\n        return value\n    assert isinstance(value, bytes)\n    return value.decode(\"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a string argument to a subclass of basestring.", "response": "def to_basestring(value):\n    \"\"\"Converts a string argument to a subclass of basestring.\n\n    In python2, byte and unicode strings are mostly interchangeable,\n    so functions that deal with a user-supplied argument in combination\n    with ascii string constants can use either and should return the type\n    the user supplied.  In python3, the two types are not interchangeable,\n    so this method is needed to convert byte strings to unicode.\n    \"\"\"\n    if isinstance(value, _BASESTRING_TYPES):\n        return value\n    assert isinstance(value, bytes)\n    return value.decode(\"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef recursive_unicode(obj):\n    if isinstance(obj, dict):\n        return dict((recursive_unicode(k), recursive_unicode(v)) for (k,v) in obj.iteritems())\n    elif isinstance(obj, list):\n        return list(recursive_unicode(i) for i in obj)\n    elif isinstance(obj, tuple):\n        return tuple(recursive_unicode(i) for i in obj)\n    elif isinstance(obj, bytes):\n        return to_unicode(obj)\n    else:\n        return obj", "response": "Walks a simple data structure converting byte strings to unicode."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes sure that other plugins don t affect the same keyword argument and check if metadata is available.", "response": "def setup(self, app):\n        \"\"\" Make sure that other installed plugins don't affect the same\n            keyword argument and check if metadata is available.\"\"\"\n        for other in app.plugins:\n            if not isinstance(other, AuthPlugin):\n                continue\n            if other.keyword == self.keyword:\n                raise bottle.PluginError(\"Found another auth plugin \"\n                                         \"with conflicting settings (\"\n                                         \"non-unique keyword).\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iter_subclasses(cls, _seen=None):\n\n\tif not isinstance(cls, type):\n\t\traise TypeError(\n\t\t\t'iter_subclasses must be called with '\n\t\t\t'new-style classes, not %.100r' % cls\n\t\t)\n\tif _seen is None:\n\t\t_seen = set()\n\ttry:\n\t\tsubs = cls.__subclasses__()\n\texcept TypeError:  # fails only when cls is type\n\t\tsubs = cls.__subclasses__(cls)\n\tfor sub in subs:\n\t\tif sub in _seen:\n\t\t\tcontinue\n\t\t_seen.add(sub)\n\t\tyield sub\n\t\tfor sub in iter_subclasses(sub, _seen):\n\t\t\tyield sub", "response": "iter_subclasses yields all subclasses of a given class in depth - first order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbasing on the matching strategy and the origin and optionally the requested method a tuple of policyname and origin to pass back is returned.", "response": "def selectPolicy(self, origin, request_method=None):\n        \"Based on the matching strategy and the origin and optionally the requested method a tuple of policyname and origin to pass back is returned.\"\n        ret_origin = None\n        policyname = None\n        if self.matchstrategy in (\"firstmatch\", \"verbmatch\"):\n            for pol in self.activepolicies:\n                policy=self.policies[pol]\n                ret_origin = None\n                policyname = policy.name\n                if policyname == \"deny\":\n                    break\n                if self.matchstrategy == \"verbmatch\":\n                    if policy.methods != \"*\" and not CORS.matchlist(request_method, policy.methods, case_sensitive=True):\n                        continue\n                if origin and policy.match:\n                    if CORS.matchlist(origin, policy.match):\n                        ret_origin = origin\n                elif policy.origin == \"copy\":\n                    ret_origin = origin\n                elif policy.origin:\n                    ret_origin = policy.origin\n                if ret_origin:\n                    break\n        return policyname, ret_origin"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef loads(data, wrapper=dict):\n    if not isinstance(data, (bytes, bytearray)):\n        raise TypeError('can only load a bytes-like object as an Appinfo but got ' + type(data).__name__)\n\n    return AppinfoDecoder(data, wrapper=wrapper).decode()", "response": "Loads an Appinfo file into a Python object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dumps(obj):\n    if not isinstance(obj, dict):\n        raise TypeError('can only dump a dictionary as an Appinfo but got ' + type(obj).__name__)\n\n    return b''.join(AppinfoEncoder(obj).iter_encode())", "response": "Serializes a dictionary into an Appinfo data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a byte - like object containing the contents of an Appinfo file into a Python dictionary.", "response": "def loads(data, wrapper=dict):\n    \"\"\"\n    Loads Manifest content into a Python object.\n    :param data: A byte-like object with the contents of an Appinfo file.\n    :param wrapper: A wrapping object for key-value pairs.\n    :return: A dictionary with Manifest data.\n    \"\"\"\n    if not isinstance(data, (bytes, bytearray)):\n        raise TypeError('can only load a bytes-like object as a Manifest but got ' + type(data).__name__)\n\n    offset = 0\n    parsed = wrapper()\n    int32 = struct.Struct('<I')\n\n    while True:\n        msg_id, = int32.unpack_from(data, offset)\n        offset += int32.size\n\n        if msg_id == MSG_EOF:\n            break\n\n        msg_size, = int32.unpack_from(data, offset)\n        offset += int32.size\n\n        msg_data = data[offset:offset + msg_size]\n        offset += msg_size\n\n        message = MessageClass[msg_id]()\n        message.ParseFromString(msg_data)\n\n        parsed[MSG_NAMES[msg_id]] = wrapper(protobuf_to_dict(message))\n\n    return parsed"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dumps(obj):\n    if not isinstance(obj, dict):\n        raise TypeError('can only dump a dictionary as a Manifest but got ' + type(obj).__name__)\n\n    data = []\n    int32 = struct.Struct('<I')\n\n    for message_name in ('payload', 'metadata', 'signature'):\n        message_data = obj[message_name]\n        message_id = MSG_IDS[message_name]\n        message_class = MessageClass[message_id]\n        message = dict_to_protobuf(message_class, message_data)\n        message_bytes = message.SerializeToString()\n        message_size = len(message_bytes)\n\n        data.append(int32.pack(message_id))\n        data.append(int32.pack(message_size))\n        data.append(message_bytes)\n\n    # MSG_EOF marks the end of messages.\n    data.append(int32.pack(MSG_EOF))\n    return b''.join(data)", "response": "Serializes a dictionary into a manifest data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload an ACF file into a Python object.", "response": "def loads(data, wrapper=dict):\n    \"\"\"\n    Loads ACF content into a Python object.\n    :param data: An UTF-8 encoded content of an ACF file.\n    :param wrapper: A wrapping object for key-value pairs.\n    :return: An Ordered Dictionary with ACF data.\n    \"\"\"\n    if not isinstance(data, str):\n        raise TypeError('can only load a str as an ACF but got ' + type(data).__name__)\n\n    parsed = wrapper()\n    current_section = parsed\n    sections = []\n\n    lines = (line.strip() for line in data.splitlines())\n\n    for line in lines:\n        try:\n            key, value = line.split(None, 1)\n            key = key.replace('\"', '').lstrip()\n            value = value.replace('\"', '').rstrip()\n        except ValueError:\n            if line == SECTION_START:\n                # Initialize the last added section.\n                current_section = _prepare_subsection(parsed, sections, wrapper)\n            elif line == SECTION_END:\n                # Remove the last section from the queue.\n                sections.pop()\n            else:\n                # Add a new section to the queue.\n                sections.append(line.replace('\"', ''))\n            continue\n\n        current_section[key] = value\n\n    return parsed"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nserializes a dictionary into an ACF data.", "response": "def dumps(obj):\n    \"\"\"\n    Serializes a dictionary into ACF data.\n    :param obj: A dictionary to serialize.\n    :return: ACF data.\n    \"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError('can only dump a dictionary as an ACF but got ' + type(obj).__name__)\n\n    return '\\n'.join(_dumps(obj, level=0)) + '\\n'"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of strings that represent the ACF data in the nested dictionary obj.", "response": "def _dumps(obj, level):\n    \"\"\"\n    Does the actual serializing of data into an ACF format.\n    :param obj: A dictionary to serialize.\n    :param level: Nesting level.\n    :return: A List of strings.\n    \"\"\"\n    lines = []\n    indent = '\\t' * level\n\n    for key, value in obj.items():\n        if isinstance(value, dict):\n            # [INDENT]\"KEY\"\n            # [INDENT]{\n            line = indent + '\"{}\"\\n'.format(key) + indent + '{'\n            lines.append(line)\n            # Increase intendation of the nested dict\n            lines.extend(_dumps(value, level+1))\n            # [INDENT]}\n            lines.append(indent + '}')\n        else:\n            # [INDENT]\"KEY\"[TAB][TAB]\"VALUE\"\n            lines.append(indent + '\"{}\"'.format(key) + '\\t\\t' + '\"{}\"'.format(value))\n\n    return lines"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _prepare_subsection(data, sections, wrapper):\n    current = data\n    for i in sections[:-1]:\n        current = current[i]\n\n    current[sections[-1]] = wrapper()\n    return current[sections[-1]]", "response": "Prepares a subsection for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a vector with the occupancy of each grid point for given array of points", "response": "def occupancy(grid, points, spacing=0.01):\n    \"\"\"Return a vector with the occupancy of each grid point for \n    given array of points\"\"\"\n    distances = ((grid[:,None,:] - points[None,:,:])**2).sum(axis=2)\n    occupied = (distances < spacing).sum(axis=1)\n    return occupied"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_gro(outfile, title, atoms, box):\n    # Print the title\n    print(title, file=outfile)\n\n    # Print the number of atoms\n    print(\"{:5d}\".format(len(atoms)), file=outfile)\n\n    # Print the atoms\n    atom_template = \"{:5d}{:<5s}{:>5s}{:5d}{:8.3f}{:8.3f}{:8.3f}\"\n    for idx, atname, resname, resid, x, y, z in atoms:\n        print(atom_template\n              .format(int(resid % 1e5), resname, atname, int(idx % 1e5),\n                      x, y, z),\n              file=outfile)\n\n    # Print the box\n    grobox = (box[0][0], box[1][1], box[2][2],\n              box[0][1], box[0][2], box[1][0],\n              box[1][2], box[2][0], box[2][1])\n    box_template = '{:10.5f}' * 9\n    print(box_template.format(*grobox), file=outfile)", "response": "Write a GRO file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_pdb(outfile, title, atoms, box):\n    # Print the title\n    print('TITLE ' + title, file=outfile)\n\n    # Print the box\n    print(pdbBoxString(box), file=outfile)\n\n    # Print the atoms\n    for idx, atname, resname, resid, x, y, z in atoms:\n        print(pdbline % (idx % 1e5, atname[:4], resname[:3], \"\",\n                         resid % 1e4, '', 10*x, 10*y, 10*z, 0, 0, ''),\n              file=outfile)", "response": "Write a PDB file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetermine molecule numbers for given total absolute and relative numbers", "response": "def determine_molecule_numbers(total, molecules, absolute, relative):\n    \"\"\"Determine molecule numbers for given total, \n    absolute and relative numbers\"\"\" \n    weight = sum(relative)\n    if not any(absolute):\n        # Only relative numbers\n        numbers = [int(total*i/weight) for i in relative]\n    elif any(relative):\n        # Absolute numbers and fill the rest with relative numbers\n        rest = total - sum(absolute)\n        numbers = [int(rest*i/weight) if i else j \n                   for i,j in zip(relative, absolute)]\n    else:\n        # Only absolute numbers\n        numbers = absolute\n    return list(zip(molecules, numbers))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resize_pbc_for_lipids(pbc, relL, relU, absL, absU,\n                          uparea, area, hole, proteins):\n    \"\"\"\n    Adapt the size of the box to accomodate the lipids.\n\n    The PBC is changed **in place**.\n    \"\"\"\n    if any(relL) and any(relU):\n        # Determine box from size\n        # If one leaflet is defined with an absolute number of lipids\n        # then the other leaflet (with relative numbers) will follow\n        # from that.\n        # box/d/x/y/z needed to define unit cell\n\n        # box is set up already...\n        # yet it may be set to 0, then there is nothing we can do.\n        if 0 in (pbc.x, pbc.y, pbc.z):\n            raise PBCException('Not enough information to set the box size.')\n    elif any(absL) or any(absU):\n        # All numbers are absolute.. determine size from number of lipids\n        # Box x/y will be set, d/dz/z is needed to set third box vector.\n        # The area is needed to determine the size of the x/y plane OR\n        # the area will be SET if a box is given.\n\n        if pbc.z == 0:\n            raise PBCException('Not enough information to set the box size.')\n\n        if 0 in (pbc.x, pbc.y):\n            # We do not know what size the box should be. \n            # Let X and Y be the same.\n            #T This does not agree with the default pbc being hexagonal...\n            pbc.x = pbc.y = 1\n        # A scaling factor is needed for the box\n        # This is the area for the given number of lipids\n        upsize = sum(absU) * uparea\n        losize = sum(absL) * area\n        # This is the size of the hole, going through both leaflets\n        holesize = np.pi * hole ** 2\n        # This is the area of the PBC xy plane\n        xysize = pbc.x * pbc.y\n        # This is the total area of the proteins per leaflet (IMPLEMENT!)\n        psize_up = sum([p.areaxy(0, 2.4) for p in proteins])\n        psize_lo = sum([p.areaxy(-2.4, 0) for p in proteins])\n        # So this is unavailable:\n        unavail_up = holesize + psize_up\n        unavail_lo = holesize + psize_lo\n        # This is the current area marked for lipids\n        # xysize_up = xysize - unavail_up\n        # xysize_lo = xysize - unavail_lo\n        # This is how much the unit cell xy needs to be scaled\n        # to accomodate the fixed amount of lipids with given area.\n        upscale = (upsize + unavail_up)/xysize\n        loscale = (losize + unavail_lo)/xysize\n        area_scale = max(upscale, loscale)\n        aspect_ratio = pbc.x / pbc.y\n        scale_x = np.sqrt(area_scale / aspect_ratio)\n        scale_y = np.sqrt(area_scale / aspect_ratio)\n        pbc.box[:2,:] *= math.sqrt(area_scale)", "response": "This function resizes the leaflet with the given lipids."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_top(outpath, molecules, title):\n    topmolecules = []\n    for i in molecules:\n        if i[0].endswith('.o'):\n            topmolecules.append(tuple([i[0][:-2]]+list(i[1:])))\n        else:\n            topmolecules.append(i)\n\n    if outpath:\n        # Write a rudimentary topology file\n        with open(outpath, \"w\") as top:\n            print('#include \"martini.itp\"\\n', file=top)\n            print('[ system ]', file=top)\n            print('; name', file=top)\n            print(title, file=top)\n            print('\\n', file=top)\n            print('[ molecules ]', file=top)\n            print('; name  number', file=top)\n            print(\"\\n\".join(\"%-10s %7d\"%i for i in topmolecules), file=top)\n    else:\n        # Here we only include molecules that have beed added by insane.\n        # This is usually concatenated at the end of an existint top file.\n        # As the existing file usually contain the proteins already, we do not\n        # include them here.\n        added_molecules = (molecule for molecule in topmolecules\n                           if molecule[0] != 'Protein')\n        print(\"\\n\".join(\"%-10s %7d\"%i for i in added_molecules), file=sys.stderr)", "response": "Write a basic TOP file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iter_resource(filename):\n    with pkg_resources.resource_stream(__name__, filename) as resource:\n        for line in resource:\n            yield line.decode('utf-8')", "response": "Iterate over a given resource file in the module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse lipid definition from string", "response": "def parse(self, string):\n        \"\"\"\n        Parse lipid definition from string:\n\n            alhead=C P, allink=A A, altail=TCC CCCC, alname=DPSM, charge=0.0\n        \"\"\"\n        fields = [i.split(\"=\") for i in string.split(', ')]\n        for what, val in fields:\n            what = what.strip()\n            val  = val.split()\n            if what.endswith(\"head\"):\n                self.head = val\n            elif what.endswith(\"link\"):\n                self.link = val\n            elif what.endswith(\"tail\"):\n                self.tail = val\n            elif what == \"charge\":\n                self.charge = float(val[0])\n            elif what.endswith(\"name\") and not self.name:\n                self.name = val[0]\n        if self.charge is None:\n            # Infer charge from head groups\n            self.charge = sum([headgroup_charges[bead] for bead in self.head])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a string for a lipid or solvent as given on the command line.", "response": "def molspec(x):\n    \"\"\"\n    Parse a string for a lipid or a solvent as given on the command line\n    (MOLECULE[=NUMBER|:NUMBER]); where `=NUMBER` sets an absolute number of the\n    molecule, and `:NUMBER` sets a relative number of it.\n    If both absolute and relative number are set False, then relative count is 1.\n    \"\"\"\n    lip = x.split(\":\")\n    abn = lip[0].split(\"=\")\n    names = abn[0]\n    if len(abn) > 1:\n        nrel = 0\n        nabs = int(abn[1])\n    else:\n        nabs = 0\n        if len(lip) > 1:\n            nrel = float(lip[1])\n        else:\n            nrel = 1\n    return abn[0], nabs, nrel"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a message to a particular user.", "response": "def message_user(user, message, level=constants.INFO):\n    \"\"\"\n    Send a message to a particular user.\n\n    :param user: User instance\n    :param message: Message to show\n    :param level: Message level\n    \"\"\"\n    # We store a list of messages in the cache so we can have multiple messages\n    # queued up for a user.\n    user_key = _user_key(user)\n    messages = cache.get(user_key) or []\n    messages.append((message, level))\n    cache.set(user_key, messages)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a message to a group of users.", "response": "def message_users(users, message, level=constants.INFO):\n    \"\"\"\n    Send a message to a group of users.\n\n    :param users: Users queryset\n    :param message: Message to show\n    :param level: Message level\n    \"\"\"\n    for user in users:\n        message_user(user, message, level)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the message for given user. Returns None if no such message exists.", "response": "def get_messages(user):\n    \"\"\"\n    Fetch messages for given user.  Returns None if no such message exists.\n\n    :param user: User instance\n    \"\"\"\n    key = _user_key(user)\n    result = cache.get(key)\n    if result:\n        cache.delete(key)\n        return result\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck for messages for this user and add them to the messages API", "response": "def process_response(self, request, response):\n        \"\"\"\n        Check for messages for this user and, if it exists,\n        call the messages API with it\n        \"\"\"\n        if hasattr(request, \"session\") and hasattr(request, \"user\") and request.user.is_authenticated():\n            msgs = get_messages(request.user)\n            if msgs:\n                for msg, level in msgs:\n                    messages.add_message(request, level, msg)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_config_file(msg):\n    with jsonconfig.Config(\"messages\", indent=4) as cfg:\n        verify_profile_name(msg, cfg)\n\n        retrieve_data_from_config(msg, cfg)\n\n        if msg._auth is None:\n            retrieve_pwd_from_config(msg, cfg)\n\n        if msg.save:\n            update_config_data(msg, cfg)\n            update_config_pwd(msg, cfg)", "response": "Checks the config. json file for default settings and auth values."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies that the profile name exists in the config. json file.", "response": "def verify_profile_name(msg, cfg):\n    \"\"\"\n    Verifies the profile name exists in the config.json file.\n\n    Args:\n        :msg: (Message class) an instance of a message class.\n        :cfg: (jsonconfig.Config) config instance.\n    \"\"\"\n    if msg.profile not in cfg.data:\n        raise UnknownProfileError(msg.profile)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates msg attrs with values from the profile configuration.", "response": "def retrieve_data_from_config(msg, cfg):\n    \"\"\"\n    Update msg attrs with values from the profile configuration if the\n    msg.attr=None, else leave it alone.\n\n    Args:\n        :msg: (Message class) an instance of a message class.\n        :cfg: (jsonconfig.Config) config instance.\n    \"\"\"\n    msg_type = msg.__class__.__name__.lower()\n    for attr in msg:\n        if getattr(msg, attr) is None and attr in cfg.data[msg.profile][msg_type]:\n            setattr(msg, attr, cfg.data[msg.profile][msg_type][attr])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef retrieve_pwd_from_config(msg, cfg):\n    msg_type = msg.__class__.__name__.lower()\n    key_fmt = msg.profile + \"_\" + msg_type\n    pwd = cfg.pwd[key_fmt].split(\" :: \")\n    if len(pwd) == 1:\n        msg.auth = pwd[0]\n    else:\n        msg.auth = tuple(pwd)", "response": "Retrieve auth from profile configuration and set in msg. auth attr."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_config_data(msg, cfg):\n    for attr in msg:\n        if attr in cfg.data[msg.profile] and attr is not \"auth\":\n            cfg.data[msg.profile][attr] = getattr(msg, attr)", "response": "Updates the config data for the current user in the message class with values set in each attr by the the\n ArcGIS user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the config. pwd dictionary with values set by the user.", "response": "def update_config_pwd(msg, cfg):\n    \"\"\"\n    Updates the profile's auth entry with values set by the user.\n    This will overwrite existing values.\n\n    Args:\n        :msg: (Message class) an instance of a message class.\n        :cfg: (jsonconfig.Config) config instance.\n    \"\"\"\n    msg_type = msg.__class__.__name__.lower()\n    key_fmt = msg.profile + \"_\" + msg_type\n    if isinstance(msg._auth, (MutableSequence, tuple)):\n        cfg.pwd[key_fmt] = \" :: \".join(msg._auth)\n    else:\n        cfg.pwd[key_fmt] = msg._auth"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new config entry for the given message type.", "response": "def create_config_profile(msg_type):\n    \"\"\"\n    Create a profile for the given message type.\n\n    Args:\n        :msg_type: (str) message type to create config entry.\n    \"\"\"\n    msg_type = msg_type.lower()\n\n    if msg_type not in CONFIG.keys():\n        raise UnsupportedMessageTypeError(msg_type)\n\n    display_required_items(msg_type)\n\n    if get_user_ack():\n        profile_name = input(\"Profile Name: \")\n        data = get_data_from_user(msg_type)\n        auth = get_auth_from_user(msg_type)\n        configure_profile(msg_type, profile_name, data, auth)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisplaying the required items needed to create a new config entry.", "response": "def display_required_items(msg_type):\n    \"\"\"\n    Display the required items needed to configure a profile for the given\n    message type.\n\n    Args:\n        :msg_type: (str) message type to create config entry.\n    \"\"\"\n    print(\"Configure a profile for: \" + msg_type)\n    print(\"You will need the following information:\")\n    for k, v in CONFIG[msg_type][\"settings\"].items():\n        print(\"   * \" + v)\n    print(\"Authorization/credentials required:\")\n    for k, v in CONFIG[msg_type][\"auth\"].items():\n        print(\"   * \" + v)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the required settings from the user and return as a dict.", "response": "def get_data_from_user(msg_type):\n    \"\"\"Get the required 'settings' from the user and return as a dict.\"\"\"\n    data = {}\n    for k, v in CONFIG[msg_type][\"settings\"].items():\n        data[k] = input(v + \": \")\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the required auth from the user and return as a dict.", "response": "def get_auth_from_user(msg_type):\n    \"\"\"Get the required 'auth' from the user and return as a dict.\"\"\"\n    auth = []\n    for k, v in CONFIG[msg_type][\"auth\"].items():\n        auth.append((k, getpass(v + \": \")))\n    return OrderedDict(auth)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef configure_profile(msg_type, profile_name, data, auth):\n    with jsonconfig.Config(\"messages\", indent=4) as cfg:\n        write_data(msg_type, profile_name, data, cfg)\n        write_auth(msg_type, profile_name, auth, cfg)\n\n    print(\"[+] Configuration entry for <\" + profile_name + \"> created.\")\n    print(\"[+] Configuration file location: \" + cfg.filename)", "response": "Create the profile entry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_data(msg_type, profile_name, data, cfg):\n    if profile_name not in cfg.data:\n        cfg.data[profile_name] = {}\n    cfg.data[profile_name][msg_type] = data", "response": "Write the settings into the data portion of the cfg."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_auth(msg_type, profile_name, auth, cfg):\n    key_fmt = profile_name + \"_\" + msg_type\n    pwd = []\n    for k, v in CONFIG[msg_type][\"auth\"].items():\n        pwd.append(auth[k])\n\n    if len(pwd) > 1:\n        cfg.pwd[key_fmt] = \" :: \".join(pwd)\n    else:\n        cfg.pwd[key_fmt] = pwd[0]", "response": "Writes the auth settings into the cfg."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding the message params.", "response": "def _construct_message(self):\n        \"\"\"Build the message params.\"\"\"\n        self.message[\"text\"] = \"\"\n        if self.from_:\n            self.message[\"text\"] += \"From: \" + self.from_ + \"\\n\"\n        if self.subject:\n            self.message[\"text\"] += \"Subject: \" + self.subject + \"\\n\"\n\n        self.message[\"text\"] += self.body\n        self._add_attachments()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending the message via HTTP POST.", "response": "def send(self, encoding=\"json\"):\n        \"\"\"Send the message via HTTP POST, default is json-encoded.\"\"\"\n        self._construct_message()\n        if self.verbose:\n            print(\n                \"Debugging info\"\n                \"\\n--------------\"\n                \"\\n{} Message created.\".format(timestamp())\n            )\n\n        if encoding == \"json\":\n            resp = requests.post(self.url, json=self.message)\n        elif encoding == \"url\":\n            resp = requests.post(self.url, data=self.message)\n\n        try:\n            resp.raise_for_status()\n            if resp.history and resp.history[0].status_code >= 300:\n                raise MessageSendError(\"HTTP Redirect: Possibly Invalid authentication\")\n            elif \"invalid_auth\" in resp.text:\n                raise MessageSendError(\"Invalid Auth: Possibly Bad Auth Token\")\n        except (requests.exceptions.HTTPError, MessageSendError) as e:\n            raise MessageSendError(e)\n\n        if self.verbose:\n            print(\n                timestamp(),\n                type(self).__name__,\n                \" info:\",\n                self.__str__(indentation=\"\\n * \"),\n                \"\\n * HTTP status code:\",\n                resp.status_code,\n            )\n\n        print(\"Message sent.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _construct_message(self):\n        self.message = {\"token\": self._auth, \"channel\": self.channel}\n        super()._construct_message()", "response": "Set the message token and channel then call the bas class constructor."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a message to the specified node.", "response": "def send(msg_type, send_async=False, *args, **kwargs):\n    \"\"\"\n    Constructs a message class and sends the message.\n    Defaults to sending synchronously.  Set send_async=True to send\n    asynchronously.\n\n    Args:\n        :msg_type: (str) the type of message to send, i.e. 'Email'\n        :send_async: (bool) default is False, set True to send asynchronously.\n        :kwargs: (dict) keywords arguments that are required for the\n            various message types.  See docstrings for each type.\n            i.e. help(messages.Email), help(messages.Twilio), etc.\n\n    Example:\n        >>> kwargs = {\n                  from_: 'me@here.com',\n                  to: 'you@there.com',\n                  auth: 'yourPassword',\n                  subject: 'Email Subject',\n                  body: 'Your message to send',\n                  attachments: ['filepath1', 'filepath2'],\n            }\n        >>> messages.send('email', **kwargs)\n        Message sent...\n    \"\"\"\n    message = message_factory(msg_type, *args, **kwargs)\n\n    try:\n        if send_async:\n            message.send_async()\n        else:\n            message.send()\n    except MessageSendError as e:\n        err_exit(\"Unable to send message: \", e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a message instance for the specified message type.", "response": "def message_factory(msg_type, msg_types=MESSAGE_TYPES, *args, **kwargs):\n    \"\"\"\n    Factory function to return the specified message instance.\n\n    Args:\n        :msg_type: (str) the type of message to send, i.e. 'Email'\n        :msg_types: (str, list, or set) the supported message types\n        :kwargs: (dict) keywords arguments that are required for the\n            various message types.  See docstrings for each type.\n            i.e. help(messages.Email), help(messages.Twilio), etc.\n    \"\"\"\n    try:\n        return msg_types[msg_type.lower()](*args, **kwargs)\n    except (UnknownProfileError, InvalidMessageInputError) as e:\n        err_exit(\"Unable to send message: \", e)\n    except KeyError:\n        raise UnsupportedMessageTypeError(msg_type, msg_types)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef credential_property(cred):\n\n    def getter(instance):\n        return \"***obfuscated***\"\n\n    def setter(instance, value):\n        private = \"_\" + cred\n        instance.__dict__[private] = value\n\n    return property(fget=getter, fset=setter)", "response": "A credential property factory for each message class that will set the credentials for obfuscated credentials when requested."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_property(attr):\n\n    def getter(instance):\n        return instance.__dict__[attr]\n\n    def setter(instance, value):\n        validate_input(instance.__class__.__name__, attr, value)\n        instance.__dict__[attr] = value\n\n    return property(fget=getter, fset=setter)", "response": "A property factory that will dispatch the to a specific validator function that will validate the user s input to ensure critical parameters are of the specific type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_input(msg_type, attr, value):\n    try:\n        valid = {\n            \"Email\": validate_email,\n            \"Twilio\": validate_twilio,\n            \"SlackWebhook\": validate_slackwebhook,\n            \"SlackPost\": validate_slackpost,\n            \"TelegramBot\": validate_telegrambot,\n            \"WhatsApp\": validate_whatsapp,\n        }[msg_type](attr, value)\n    except KeyError:\n        return 1\n    else:\n        return 0", "response": "Base function to validate input dispatched via message type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if input is valid as per .", "response": "def check_valid(msg_type, attr, value, func, exec_info):\n    \"\"\"\n    Checker function all validate_* functions below will call.\n    Raises InvalidMessageInputError if input is not valid as per\n    given func.\n    \"\"\"\n    if value is not None:\n        if isinstance(value, MutableSequence):\n            for v in value:\n                if not func(v):\n                    raise InvalidMessageInputError(msg_type, attr, value, exec_info)\n        else:\n            if not func(value):\n                raise InvalidMessageInputError(msg_type, attr, value, exec_info)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_twilio(attr, value):\n    if attr in (\"from_\", \"to\"):\n        check_valid(\"Twilio\", attr, value, validus.isphone, \"phone number\")\n    elif attr in (\"attachments\"):\n        check_valid(\"Twilio\", attr, value, validus.isurl, \"url\")", "response": "Twilio input validator function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_whatsapp(attr, value):\n    if attr in (\"from_\", \"to\"):\n        if value is not None and \"whatsapp:\" in value:\n            value = value.split(\"whatsapp:+\")[-1]\n        check_valid(\n            \"WhatsApp\",\n            attr,\n            value,\n            validus.isint,\n            \"phone number starting with the '+' symbol\",\n        )\n    elif attr in (\"attachments\"):\n        check_valid(\"WhatsApp\", attr, value, validus.isurl, \"url\")", "response": "WhatsApp input validator function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _send_coroutine():\n    with PoolExecutor() as executor:\n        while True:\n            msg = yield\n            future = executor.submit(msg.send)\n            future.add_done_callback(_exception_handler)", "response": "Creates a running coroutine to receive message instances and send them in a futures executor."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_message(self, msg):\n        try:\n            self._coro.send(msg)\n        except AttributeError:\n            raise UnsupportedMessageTypeError(msg.__class__.__name__)", "response": "Add a message to the futures executor."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_body_from_file(kwds):\n    if kwds[\"file\"] and os.path.isfile(kwds[\"file\"]):\n        kwds[\"body\"] = open(kwds[\"file\"], \"r\").read()\n        kwds[\"file\"] = None", "response": "Reads message body if specified via filepath."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting rid of args with value of None as well as select keys.", "response": "def trim_args(kwds):\n    \"\"\"Gets rid of args with value of None, as well as select keys.\"\"\"\n    reject_key = (\"type\", \"types\", \"configure\")\n    reject_val = (None, ())\n    kwargs = {\n        k: v for k, v in kwds.items() if k not in reject_key and v not in reject_val\n    }\n    for k, v in kwargs.items():\n        if k in (\"to\", \"cc\", \"bcc\", \"attachments\"):\n            kwargs[k] = list(kwargs[k])\n    return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_message(msg_type, kwds):\n    if kwds[\"file\"]:\n        get_body_from_file(kwds)\n    kwargs = trim_args(kwds)\n    send(msg_type, send_async=False, **kwargs)", "response": "Send a message to the current page."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_chat_id(self, username):\n        if username is not None:\n            chats = requests.get(self.base_url + \"/getUpdates\").json()\n            user = username.split(\"@\")[-1]\n            for chat in chats[\"result\"]:\n                if chat[\"message\"][\"from\"][\"username\"] == user:\n                    return chat[\"message\"][\"from\"][\"id\"]", "response": "Lookup chat_id of username if chat_id is unknown via API call."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _construct_message(self):\n        self.message[\"chat_id\"] = self.chat_id\n        self.message[\"text\"] = \"\"\n        if self.from_:\n            self.message[\"text\"] += \"From: \" + self.from_ + \"\\n\"\n        if self.subject:\n            self.message[\"text\"] += \"Subject: \" + self.subject + \"\\n\"\n\n        self.message[\"text\"] += self.body\n        self.message.update(self.params)", "response": "Build the message params."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _send_content(self, method=\"/sendMessage\"):\n        url = self.base_url + method\n\n        try:\n            resp = requests.post(url, json=self.message)\n            resp.raise_for_status()\n        except requests.exceptions.HTTPError as e:\n            raise MessageSendError(e)\n\n        if self.verbose:\n            if method == \"/sendMessage\":\n                content_type = \"Message body\"\n            elif method == \"/sendDocument\":\n                content_type = \"Attachment: \" + self.message[\"document\"]\n            print(timestamp(), content_type, \"sent.\")", "response": "send content via HTTP POST."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting sending the message and attachments.", "response": "def send(self):\n        \"\"\"Start sending the message and attachments.\"\"\"\n        self._construct_message()\n\n        if self.verbose:\n            print(\n                \"Debugging info\"\n                \"\\n--------------\"\n                \"\\n{} Message created.\".format(timestamp())\n            )\n\n        self._send_content(\"/sendMessage\")\n\n        if self.attachments:\n            if isinstance(self.attachments, str):\n                self.attachments = [self.attachments]\n            for a in self.attachments:\n                self.message[\"document\"] = a\n                self._send_content(method=\"/sendDocument\")\n\n        if self.verbose:\n            print(\n                timestamp(),\n                type(self).__name__ + \" info:\",\n                self.__str__(indentation=\"\\n * \"),\n            )\n\n        print(\"Message sent.\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend the SMS message.", "response": "def send(self):\n        \"\"\"\n        Send the SMS/MMS message.\n        Set self.sid to return code of message.\n        \"\"\"\n        url = (\n            \"https://api.twilio.com/2010-04-01/Accounts/\"\n            + self._auth[0]\n            + \"/Messages.json\"\n        )\n        data = {\n            \"From\": self.from_,\n            \"To\": self.to,\n            \"Body\": self.body,\n            \"MediaUrl\": self.attachments,\n        }\n\n        if self.verbose:\n            print(\n                \"Debugging info\"\n                \"\\n--------------\"\n                \"\\n{} Message created.\".format(timestamp())\n            )\n\n        try:\n            resp = requests.post(url, data=data, auth=(self._auth[0], self._auth[1]))\n            resp.raise_for_status()\n        except requests.exceptions.RequestException as e:\n            exc = \"{}\\n{}\".format(e, resp.json()[\"message\"])\n            raise MessageSendError(exc)\n\n        self.sid = resp.json()[\"sid\"]\n\n        if self.verbose:\n            print(\n                timestamp(),\n                type(self).__name__ + \" info:\",\n                self.__str__(indentation=\"\\n * \"),\n                \"\\n * HTTP status code:\",\n                resp.status_code,\n            )\n\n        print(\"Message sent.\")\n\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an SMTP servername guess from outgoing email address.", "response": "def get_server(address=None):\n        \"\"\"Return an SMTP servername guess from outgoing email address.\"\"\"\n        if address:\n            domain = address.split(\"@\")[1]\n            try:\n                return SMTP_SERVERS[domain]\n            except KeyError:\n                return (\"smtp.\" + domain, 465)\n        return (None, None)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _generate_email(self):\n        self.message = MIMEMultipart()\n        self._add_header()\n        self._add_body()\n        self._add_attachments()", "response": "Put the parts of the email together."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds email header info.", "response": "def _add_header(self):\n        \"\"\"Add email header info.\"\"\"\n        self.message[\"From\"] = self.from_\n        self.message[\"Subject\"] = self.subject\n        if self.to:\n            self.message[\"To\"] = self.list_to_string(self.to)\n        if self.cc:\n            self.message[\"Cc\"] = self.list_to_string(self.cc)\n        if self.bcc:\n            self.message[\"Bcc\"] = self.list_to_string(self.bcc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _add_body(self):\n        if self.body:\n            b = MIMEText(\"text\", \"plain\")\n            b.set_payload(self.body)\n            self.message.attach(b)", "response": "Add body content of email."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_session(self):\n        if self.port in (465, \"465\"):\n            session = self._get_ssl()\n        elif self.port in (587, \"587\"):\n            session = self._get_tls()\n\n        try:\n            session.login(self.from_, self._auth)\n        except SMTPResponseException as e:\n            raise MessageSendError(e.smtp_error.decode(\"unicode_escape\"))\n\n        return session", "response": "Start session with email server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_ssl(self):\n        return smtplib.SMTP_SSL(\n            self.server, self.port, context=ssl.create_default_context()\n        )", "response": "Get an SMTP_SSL object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets an SMTP session with TLS.", "response": "def _get_tls(self):\n        \"\"\"Get an SMTP session with TLS.\"\"\"\n        session = smtplib.SMTP(self.server, self.port)\n        session.ehlo()\n        session.starttls(context=ssl.create_default_context())\n        session.ehlo()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend the message. First, a message is constructed, then a session with the email servers is created, finally the message is sent and the session is stopped.", "response": "def send(self):\n        \"\"\"\n        Send the message.\n        First, a message is constructed, then a session with the email\n        servers is created, finally the message is sent and the session\n        is stopped.\n        \"\"\"\n        self._generate_email()\n\n        if self.verbose:\n            print(\n                \"Debugging info\"\n                \"\\n--------------\"\n                \"\\n{} Message created.\".format(timestamp())\n            )\n\n        recipients = []\n        for i in (self.to, self.cc, self.bcc):\n            if i:\n                if isinstance(i, MutableSequence):\n                    recipients += i\n                else:\n                    recipients.append(i)\n\n        session = self._get_session()\n        if self.verbose:\n            print(timestamp(), \"Login successful.\")\n\n        session.sendmail(self.from_, recipients, self.message.as_string())\n        session.quit()\n\n        if self.verbose:\n            print(timestamp(), \"Logged out.\")\n\n        if self.verbose:\n            print(\n                timestamp(),\n                type(self).__name__ + \" info:\",\n                self.__str__(indentation=\"\\n * \"),\n            )\n\n        print(\"Message sent.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, filename=None):\n\n        if self.tags is not None:\n            if filename is None:\n                filename = self.filename\n            else:\n                warnings.warn(\n                    \"delete(filename=...) is deprecated, reload the file\",\n                    DeprecationWarning)\n            return self.tags.delete(filename)", "response": "Remove tags from a file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unload(self):\n        '''Releases renderer resources associated with this image.'''\n        if self._handle != -1:\n            lib.UnloadImage(self._handle)\n        self._handle = -1", "response": "Releases renderer resources associated with this image."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_region(self, x1, y1, x2, y2):\n        '''Get an image that refers to the given rectangle within this image.  The image data is not actually\n        copied; if the image region is rendered into, it will affect this image.\n\n        :param int x1: left edge of the image region to return\n        :param int y1: top edge of the image region to return\n        :param int x2: right edge of the image region to return\n        :param int y2: bottom edge of the image region to return\n        :return: :class:`Image`\n        '''\n        handle = c_int()\n        lib.GetImageRegion(byref(handle), self._handle, x1, y1, x2, y2)\n        return Image(width = x2 - x1, height = y2 - y1, content_scale = self._content_scale, handle = handle)", "response": "Get an image that refers to the given rectangle within this image."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef  main( argv ):\n\n    global output_dir\n\n    try:\n        opts, args = getopt.getopt( sys.argv[1:], \\\n                                    \"hb\",         \\\n                                    [\"help\", \"backup\"] )\n    except getopt.GetoptError:\n        usage()\n        sys.exit( 2 )\n\n    if args == []:\n        usage()\n        sys.exit( 1 )\n\n    # process options\n    #\n    output_dir = None\n    do_backup  = None\n\n    for opt in opts:\n        if opt[0] in ( \"-h\", \"--help\" ):\n            usage()\n            sys.exit( 0 )\n\n        if opt[0] in ( \"-b\", \"--backup\" ):\n            do_backup = 1\n\n    # create context and processor\n    source_processor = SourceProcessor()\n\n    # retrieve the list of files to process\n    file_list = make_file_list( args )\n    for filename in file_list:\n        source_processor.parse_file( filename )\n\n        for block in source_processor.blocks:\n            beautify_block( block )\n\n        new_name = filename + \".new\"\n        ok       = None\n\n        try:\n            file = open( new_name, \"wt\" )\n            for block in source_processor.blocks:\n                for line in block.lines:\n                    file.write( line )\n                    file.write( \"\\n\" )\n            file.close()\n        except:\n            ok = 0", "response": "main entry point for the get_resource_file command"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connect(aws_access_key_id=None, aws_secret_access_key=None, **kwargs):\n\n    from route53.connection import Route53Connection\n    return Route53Connection(\n        aws_access_key_id,\n        aws_secret_access_key,\n        **kwargs\n    )", "response": "Creates a new connection to the Amazon s Route 53\n    API."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate(self):\n\n        # be stricter in Python 3\n        if PY3:\n            if not isinstance(self.vendor, text_type):\n                raise ValueError\n            for key, value in self:\n                if not isinstance(key, text_type):\n                    raise ValueError\n                if not isinstance(value, text_type):\n                    raise ValueError\n\n        if not isinstance(self.vendor, text_type):\n            try:\n                self.vendor.decode('utf-8')\n            except UnicodeDecodeError:\n                raise ValueError\n\n        for key, value in self._internal:\n            try:\n                if not is_valid_key(key):\n                    raise ValueError\n            except:\n                raise ValueError(\"%r is not a valid key\" % key)\n\n            if not isinstance(value, text_type):\n                try:\n                    value.decode(\"utf-8\")\n                except:\n                    raise ValueError(\"%r is not a valid value\" % value)\n        else:\n            return True", "response": "Validate keys and values."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclears all keys from the comment.", "response": "def clear(self):\n        \"\"\"Clear all keys from the comment.\"\"\"\n\n        for i in list(self._internal):\n            self._internal.remove(i)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a string representation of the data.", "response": "def write(self, framing=True):\n        \"\"\"Return a string representation of the data.\n\n        Validation is always performed, so calling this function on\n        invalid data may raise a ValueError.\n\n        Keyword arguments:\n\n        * framing -- if true, append a framing bit (see load)\n        \"\"\"\n\n        self.validate()\n\n        def _encode(value):\n            if not isinstance(value, bytes):\n                return value.encode('utf-8')\n            return value\n\n        f = BytesIO()\n        vendor = _encode(self.vendor)\n        f.write(cdata.to_uint_le(len(vendor)))\n        f.write(vendor)\n        f.write(cdata.to_uint_le(len(self)))\n        for tag, value in self._internal:\n            tag = _encode(tag)\n            value = _encode(value)\n            comment = tag + b\"=\" + value\n            f.write(cdata.to_uint_le(len(comment)))\n            f.write(comment)\n        if framing:\n            f.write(b\"\\x01\")\n        return f.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(self):\n        self.__fileobj.seek(self.data_offset)\n        self.data = self.__fileobj.read(self.data_size)", "response": "Read the chunks data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves the chunk from the file", "response": "def delete(self):\n        \"\"\"Removes the chunk from the file\"\"\"\n        delete_bytes(self.__fileobj, self.size, self.offset)\n        if self.parent_chunk is not None:\n            self.parent_chunk.resize(self.parent_chunk.data_size - self.size)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resize(self, data_size):\n        self.__fileobj.seek(self.offset + 4)\n        self.__fileobj.write(pack('>I', data_size))\n        if self.parent_chunk is not None:\n            size_diff = self.data_size - data_size\n            self.parent_chunk.resize(self.parent_chunk.data_size - size_diff)\n        self.data_size = data_size\n        self.size = data_size + self.HEADER_SIZE", "response": "Update the size of the file object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insert_chunk(self, id_):\n\n        if not isinstance(id_, text_type):\n            id_ = id_.decode('ascii')\n\n        if not is_valid_chunk_id(id_):\n            raise KeyError(\"AIFF key must be four ASCII characters.\")\n\n        self.__fileobj.seek(self.__next_offset)\n        self.__fileobj.write(pack('>4si', id_.ljust(4).encode('ascii'), 0))\n        self.__fileobj.seek(self.__next_offset)\n        chunk = IFFChunk(self.__fileobj, self[u'FORM'])\n        self[u'FORM'].resize(self[u'FORM'].data_size + chunk.size)\n\n        self.__chunks[id_] = chunk\n        self.__next_offset = chunk.offset + chunk.size", "response": "Insert a new chunk at the end of the IFF file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self, filename=None, v2_version=4, v23_sep='/'):\n\n        framedata = self._prepare_framedata(v2_version, v23_sep)\n        framesize = len(framedata)\n\n        if filename is None:\n            filename = self.filename\n\n        # Unlike the parent ID3.save method, we won't save to a blank file\n        # since we would have to construct a empty AIFF file\n        fileobj = open(filename, 'rb+')\n        iff_file = IFFFile(fileobj)\n\n        try:\n            if u'ID3' not in iff_file:\n                iff_file.insert_chunk(u'ID3')\n\n            chunk = iff_file[u'ID3']\n            fileobj.seek(chunk.data_offset)\n\n            header = fileobj.read(10)\n            header = self._prepare_id3_header(header, framesize, v2_version)\n            header, new_size, _ = header\n\n            data = header + framedata + (b'\\x00' * (new_size - framesize))\n\n            # Include ID3 header size in 'new_size' calculation\n            new_size += 10\n\n            # Expand the chunk if necessary, including pad byte\n            if new_size > chunk.size:\n                insert_at = chunk.offset + chunk.size\n                insert_size = new_size - chunk.size + new_size % 2\n                insert_bytes(fileobj, insert_size, insert_at)\n                chunk.resize(new_size)\n\n            fileobj.seek(chunk.data_offset)\n            fileobj.write(data)\n        finally:\n            fileobj.close()", "response": "Save the ID3v2 data to the AIFF file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads stream and tag information from a file.", "response": "def load(self, filename, **kwargs):\n        \"\"\"Load stream and tag information from a file.\"\"\"\n        self.filename = filename\n\n        try:\n            self.tags = _IFFID3(filename, **kwargs)\n        except ID3Error:\n            self.tags = None\n\n        try:\n            fileobj = open(filename, \"rb\")\n            self.info = AIFFInfo(fileobj)\n        finally:\n            fileobj.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef  parse_file( self, filename ):\n        self.reset()\n\n        self.filename = filename\n\n        fileinput.close()\n        self.format = None\n        self.lineno = 0\n        self.lines  = []\n\n        for line in fileinput.input( filename ):\n            # strip trailing newlines, important on Windows machines!\n            if line[-1] == '\\012':\n                line = line[0:-1]\n\n            if self.format == None:\n                self.process_normal_line( line )\n            else:\n                if self.format.end.match( line ):\n                    # that's a normal block end, add it to 'lines' and\n                    # create a new block\n                    self.lines.append( line )\n                    self.add_block_lines()\n                elif self.format.column.match( line ):\n                    # that's a normal column line, add it to 'lines'\n                    self.lines.append( line )\n                else:\n                    # humm.. this is an unexpected block end,\n                    # create a new block, but don't process the line\n                    self.add_block_lines()\n\n                    # we need to process the line again\n                    self.process_normal_line( line )\n\n        # record the last lines\n        self.add_block_lines()", "response": "parse a C source file and add its blocks to the processor s list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprocess a normal line and check whether it is the start of a new block", "response": "def  process_normal_line( self, line ):\n        \"\"\"process a normal line and check whether it is the start of a new block\"\"\"\n        for f in re_source_block_formats:\n            if f.start.match( line ):\n                self.add_block_lines()\n                self.format = f\n                self.lineno = fileinput.filelineno()\n\n        self.lines.append( line )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding the current accumulated lines and create a new block", "response": "def  add_block_lines( self ):\n        \"\"\"add the current accumulated lines and create a new block\"\"\"\n        if self.lines != []:\n            block = SourceBlock( self, self.filename, self.lineno, self.lines )\n\n            self.blocks.append( block )\n            self.format = None\n            self.lines  = []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndrawing a string with the given font.", "response": "def draw_string(font, text, x, y, width=None, height=None, align=Alignment.left, vertical_align=VerticalAlignment.baseline):\n    '''Draw a string with the given font.\n\n    :note: Text alignment and word-wrapping is not yet implemented.  The text is rendered with the left edge and\n        baseline at ``(x, y)``.\n\n    :param font: the :class:`Font` to render text with\n    :param text: a string of text to render.\n    '''\n    style = Style(font)\n    run = GlyphRun(style, text)\n    glyph_layout = GlyphLayout([run], x, y, width, height, align, vertical_align)\n    draw_glyph_layout(glyph_layout)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw_glyph_layout(glyph_layout):\n    '''Draw a prepared :class:`GlyphLayout`\n    '''\n    pushed_color = False\n\n    # Draw lines\n    for line in glyph_layout.lines:\n        x = line.x\n        y = line.y\n        \n        for run in line.runs:\n            style = run.style\n            if style.color is not None:\n                if not pushed_color:\n                    bacon.push_color()\n                    pushed_color = True\n                bacon.set_color(*style.color)\n            elif pushed_color:\n                bacon.pop_color()\n                pushed_color = False\n\n            for glyph in run.glyphs:\n                if glyph.image:\n                    bacon.draw_image(glyph.image, x + glyph.offset_x, y - glyph.offset_y)\n                x += glyph.advance\n\n    if pushed_color:\n        bacon.pop_color()", "response": "Draw a prepared glyph layout."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_iso_8601_time_str(time_str):\n    if re.search('\\.\\d{3}Z$', time_str):\n        submitted_at = datetime.datetime.strptime(time_str, \\\n            '%Y-%m-%dT%H:%M:%S.%fZ')\n    else:\n        submitted_at = datetime.datetime.strptime(time_str, \\\n            '%Y-%m-%dT%H:%M:%SZ')\n    # Parse the string, and make it explicitly UTC.\n    return submitted_at.replace(tzinfo=UTC_TIMEZONE)", "response": "Parses a standard ISO 8601 time string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a series of simple words into some HTML text", "response": "def  make_html_words( self, words ):\n        \"\"\" convert a series of simple words into some HTML text \"\"\"\n        line = \"\"\n        if words:\n            line = html_quote( words[0] )\n            for w in words[1:]:\n                line = line + \" \" + html_quote( w )\n\n        return line"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nanalyzing a simple word to detect cross - references and styling", "response": "def  make_html_word( self, word ):\n        \"\"\"analyze a simple word to detect cross-references and styling\"\"\"\n        # look for cross-references\n        m = re_crossref.match( word )\n        if m:\n            try:\n                name = m.group( 1 )\n                rest = m.group( 2 )\n                block = self.identifiers[name]\n                url   = self.make_block_url( block )\n                return '<a href=\"' + url + '\">' + name + '</a>' + rest\n            except:\n                # we detected a cross-reference to an unknown item\n                sys.stderr.write( \\\n                   \"WARNING: undefined cross reference '\" + name + \"'.\\n\" )\n                return '?' + name + '?' + rest\n\n        # look for italics and bolds\n        m = re_italic.match( word )\n        if m:\n            name = m.group( 1 )\n            rest = m.group( 3 )\n            return '<i>' + name + '</i>' + rest\n\n        m = re_bold.match( word )\n        if m:\n            name = m.group( 1 )\n            rest = m.group( 3 )\n            return '<b>' + name + '</b>' + rest\n\n        return html_quote( word )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef  make_html_para( self, words ):\n        line = \"\"\n        if words:\n            line = self.make_html_word( words[0] )\n            for word in words[1:]:\n                line = line + \" \" + self.make_html_word( word )\n            # convert `...' quotations into real left and right single quotes\n            line = re.sub( r\"(^|\\W)`(.*?)'(\\W|$)\",  \\\n                           r'\\1&lsquo;\\2&rsquo;\\3', \\\n                           line )\n            # convert tilde into non-breakable space\n            line = string.replace( line, \"~\", \"&nbsp;\" )\n\n        return para_header + line + para_footer", "response": "convert words of a paragraph into tagged HTML text"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a code sequence to HTML", "response": "def  make_html_code( self, lines ):\n        \"\"\" convert a code sequence to HTML \"\"\"\n        line = code_header + '\\n'\n        for l in lines:\n            line = line + html_quote( l ) + '\\n'\n\n        return line + code_footer"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a field s content into some valid HTML", "response": "def  make_html_items( self, items ):\n        \"\"\" convert a field's content into some valid HTML \"\"\"\n        lines = []\n        for item in items:\n            if item.lines:\n                lines.append( self.make_html_code( item.lines ) )\n            else:\n                lines.append( self.make_html_para( item.words ) )\n\n        return string.join( lines, '\\n' )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef  main( argv ):\n\n    global output_dir\n\n    try:\n        opts, args = getopt.getopt( sys.argv[1:], \\\n                                    \"ht:o:p:\",    \\\n                                    [\"help\", \"title=\", \"output=\", \"prefix=\"] )\n    except getopt.GetoptError:\n        usage()\n        sys.exit( 2 )\n\n    if args == []:\n        usage()\n        sys.exit( 1 )\n\n    # process options\n    #\n    project_title  = \"Project\"\n    project_prefix = None\n    output_dir     = None\n\n    for opt in opts:\n        if opt[0] in ( \"-h\", \"--help\" ):\n            usage()\n            sys.exit( 0 )\n\n        if opt[0] in ( \"-t\", \"--title\" ):\n            project_title = opt[1]\n\n        if opt[0] in ( \"-o\", \"--output\" ):\n            utils.output_dir = opt[1]\n\n        if opt[0] in ( \"-p\", \"--prefix\" ):\n            project_prefix = opt[1]\n\n    check_output()\n\n    # create context and processor\n    source_processor  = SourceProcessor()\n    content_processor = ContentProcessor()\n\n    # retrieve the list of files to process\n    file_list = make_file_list( args )\n    for filename in file_list:\n        source_processor.parse_file( filename )\n        content_processor.parse_sources( source_processor )\n\n    # process sections\n    content_processor.finish()\n\n    formatter = HtmlFormatter( content_processor, project_title, project_prefix )\n\n    formatter.toc_dump()\n    formatter.index_dump()\n    formatter.section_dump_all()", "response": "main function for the base class"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_hosted_zone_by_id_parser(root, connection):\n\n    e_zone = root.find('./{*}HostedZone')\n    # This pops out a HostedZone instance.\n    hosted_zone =  parse_hosted_zone(e_zone, connection)\n    # Now we'll fill in the nameservers.\n    e_delegation_set = root.find('./{*}DelegationSet')\n    # Modifies the HostedZone in place.\n    parse_delegation_set(hosted_zone, e_delegation_set)\n    return hosted_zone", "response": "Parses the API responses for the get_hosted_zone_by_id method."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves the metadata to the given filename.", "response": "def save(self, filename):\n        \"\"\"Save the metadata to the given filename.\"\"\"\n\n        values = []\n        items = sorted(self.items(), key=MP4Tags.__get_sort_stats )\n        for key, value in items:\n            info = self.__atoms.get(key[:4], (None, type(self).__render_text))\n            try:\n                values.append(info[1](self, key, value, *info[2:]))\n            except (TypeError, ValueError) as s:\n                reraise(MP4MetadataValueError, s, sys.exc_info()[2])\n        data = Atom.render(b\"ilst\", b\"\".join(values))\n\n        # Find the old atoms.\n        fileobj = open(filename, \"rb+\")\n        try:\n            atoms = Atoms(fileobj)\n            try:\n                path = atoms.path(b\"moov\", b\"udta\", b\"meta\", b\"ilst\")\n            except KeyError:\n                self.__save_new(fileobj, atoms, data)\n            else:\n                self.__save_existing(fileobj, atoms, path, data)\n        finally:\n            fileobj.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates all parent atoms with the new size.", "response": "def __update_parents(self, fileobj, path, delta):\n        \"\"\"Update all parent atoms with the new size.\"\"\"\n        for atom in path:\n            fileobj.seek(atom.offset)\n            size = cdata.uint_be(fileobj.read(4))\n            if size == 1:  # 64bit\n                # skip name (4B) and read size (8B)\n                size = cdata.ulonglong_be(fileobj.read(12)[4:])\n                fileobj.seek(atom.offset + 8)\n                fileobj.write(cdata.to_ulonglong_be(size + delta))\n            else:  # 32bit\n                fileobj.seek(atom.offset)\n                fileobj.write(cdata.to_uint_be(size + delta))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(game):\n    '''Start running the game.  The window is created and shown at this point, and then\n    the main event loop is entered.  'game.on_tick' and other event handlers are called\n    repeatedly until the game exits.\n\n    If a game is already running, this function replaces the :class:`Game` instance that\n    receives events.\n    '''\n    if bacon._current_game:\n        bacon._current_game = game\n        return\n\n    global _tick_callback_handle\n    bacon._current_game = game\n\n    # Window handler\n    window_resize_callback_handle = lib.WindowResizeEventHandler(window._window_resize_event_handler)\n    lib.SetWindowResizeEventHandler(window_resize_callback_handle)\n\n    # Key handler\n    key_callback_handle = lib.KeyEventHandler(keyboard._key_event_handler)\n    lib.SetKeyEventHandler(key_callback_handle)\n\n    # Mouse handlers\n    mouse_button_callback_handle = lib.MouseButtonEventHandler(mouse_input._mouse_button_event_handler)\n    lib.SetMouseButtonEventHandler(mouse_button_callback_handle)\n    mouse_scroll_callback_handle = lib.MouseScrollEventHandler(mouse_input._mouse_scroll_event_handler)\n    lib.SetMouseScrollEventHandler(mouse_scroll_callback_handle)\n\n    # Controller handlers\n    controller_connected_handle = lib.ControllerConnectedEventHandler(controller._controller_connected_event_handler)\n    lib.SetControllerConnectedEventHandler(controller_connected_handle)\n    controller_button_handle = lib.ControllerButtonEventHandler(controller._controller_button_event_handler)\n    lib.SetControllerButtonEventHandler(controller_button_handle)\n    controller_axis_handle = lib.ControllerAxisEventHandler(controller._controller_axis_event_handler)\n    lib.SetControllerAxisEventHandler(controller_axis_handle)\n\n    # Tick handler\n    _tick_callback_handle = lib.TickCallback(_first_tick_callback)\n    lib.SetTickCallback(_tick_callback_handle)\n\n    lib.Run()\n    bacon._current_game = None\n    _tick_callback_handle = None\n\n    lib.SetWindowResizeEventHandler(lib.WindowResizeEventHandler(0))\n    lib.SetKeyEventHandler(lib.KeyEventHandler(0))\n    lib.SetMouseButtonEventHandler(lib.MouseButtonEventHandler(0))\n    lib.SetMouseScrollEventHandler(lib.MouseScrollEventHandler(0))\n    lib.SetControllerConnectedEventHandler(lib.ControllerConnectedEventHandler(0))\n    lib.SetControllerButtonEventHandler(lib.ControllerButtonEventHandler(0))\n    lib.SetControllerAxisEventHandler(lib.ControllerAxisEventHandler(0))\n    lib.SetTickCallback(lib.TickCallback(0))", "response": "Start running the game.  The window is created and shown at this point, and then\n    the main event loop is entered.  'game.on_tick' and other event handlers are called\n    repeatedly until the game exits.\n\n    If a game is already running, this function replaces the :class:`Game` instance that\n    receives events."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register(cls, vendor_id, product_id, mapping):\n        '''Register a mapping for controllers with the given vendor and product IDs.  The mapping will\n        replace any existing mapping for these IDs for controllers not yet connected.\n\n        :param vendor_id: the vendor ID of the controller, as reported by :attr:`Controller.vendor_id`\n        :param product_id: the vendor ID of the controller, as reported by :attr:`Controller.product_id`\n        :param mapping: a :class:`ControllerMapping` to apply\n        '''\n        cls._registry[(vendor_id, product_id)] = mapping", "response": "Register a mapping for controllers with the given vendor and product IDs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the controller mapping that can apply to the given controller. Returns None if unsuccessful.", "response": "def get(cls, controller):\n        '''Find a mapping that can apply to the given controller.  Returns None if unsuccessful.\n\n        :param controller: :class:`Controller` to look up\n        :return: :class:`ControllerMapping`\n        '''\n        try:\n            return cls._registry[(controller.vendor_id, controller.product_id)]\n        except KeyError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef RegisterFreeformKey(cls, key, name, mean=b\"com.apple.iTunes\"):\n        atomid = b\"----:\" + mean + b\":\" + name\n\n        def getter(tags, key):\n            return [s.decode(\"utf-8\", \"replace\") for s in tags[atomid]]\n\n        def setter(tags, key, value):\n            tags[atomid] = [utf8(v) for v in value]\n\n        def deleter(tags, key):\n            del(tags[atomid])\n\n        cls.RegisterKey(key, getter, setter, deleter)", "response": "Register a text key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_request_headers(self):\n\n        date_header = time.asctime(time.gmtime())\n        # We sign the time string above with the user's AWS secret access key\n        # in order to authenticate our request.\n        signing_key = self._hmac_sign_string(date_header)\n\n        # Amazon's super fun auth token.\n        auth_header = \"AWS3-HTTPS AWSAccessKeyId=%s,Algorithm=HmacSHA256,Signature=%s\" % (\n            self.connection._aws_access_key_id,\n            signing_key,\n        )\n\n        return {\n            'X-Amzn-Authorization': auth_header,\n            'x-amz-date': date_header,\n            'Host': 'route53.amazonaws.com',\n        }", "response": "Determine the headers to send along with the request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_request(self, path, data, method):\n\n        headers = self.get_request_headers()\n\n        if method == 'GET':\n            return self._send_get_request(path, data, headers)\n        elif method == 'POST':\n            return self._send_post_request(path, data, headers)\n        elif method == 'DELETE':\n            return self._send_delete_request(path, headers)\n        else:\n            raise Route53Error(\"Invalid request method: %s\" % method)", "response": "This method is used to send out a request to the route53 server. It defers to the route53 HTTP method - specific methods."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a GET request to the Route53 endpoint.", "response": "def _send_get_request(self, path, params, headers):\n        \"\"\"\n        Sends the GET request to the Route53 endpoint.\n\n        :param str path: The path to tack on to the endpoint URL for\n            the query.\n        :param dict params: Key/value pairs to send.\n        :param dict headers: A dict of headers to send with the request.\n        :rtype: str\n        :returns: The body of the response.\n        \"\"\"\n\n        r = requests.get(self.endpoint + path, params=params, headers=headers)\n        r.raise_for_status()\n        return r.text"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _send_post_request(self, path, data, headers):\n\n        r = requests.post(self.endpoint + path, data=data, headers=headers)\n        return r.text", "response": "Sends a POST request to the Route53 endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _send_delete_request(self, path, headers):\n\n        r = requests.delete(self.endpoint + path, headers=headers)\n        return r.text", "response": "Sends a DELETE request to the Route53 endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload tags from a file.", "response": "def load(self, filename):\n        \"\"\"Load tags from a filename.\"\"\"\n\n        self.filename = filename\n        fileobj = open(filename, \"rb\")\n        try:\n            data = _APEv2Data(fileobj)\n        finally:\n            fileobj.close()\n        if data.tag:\n            self.clear()\n            self.__casemap.clear()\n            self.__parse_tag(data.tag, data.items)\n        else:\n            raise APENoHeaderError(\"No APE tag found\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self, filename=None):\n\n        filename = filename or self.filename\n        try:\n            fileobj = open(filename, \"r+b\")\n        except IOError:\n            fileobj = open(filename, \"w+b\")\n        data = _APEv2Data(fileobj)\n\n        if data.is_at_start:\n            delete_bytes(fileobj, data.end - data.start, data.start)\n        elif data.start is not None:\n            fileobj.seek(data.start)\n            # Delete an ID3v1 tag if present, too.\n            fileobj.truncate()\n        fileobj.seek(0, 2)\n\n        # \"APE tags items should be sorted ascending by size... This is\n        # not a MUST, but STRONGLY recommended. Actually the items should\n        # be sorted by importance/byte, but this is not feasible.\"\n        tags = sorted((v._internal(k) for k, v in self.items()), key=len)\n        num_tags = len(tags)\n        tags = b\"\".join(tags)\n\n        header = bytearray(b\"APETAGEX\")\n        # version, tag size, item count, flags\n        header += struct.pack(\"<4I\", 2000, len(tags) + 32, num_tags,\n                              HAS_HEADER | IS_HEADER)\n        header += b\"\\0\" * 8\n        fileobj.write(header)\n\n        fileobj.write(tags)\n\n        footer = bytearray(b\"APETAGEX\")\n        footer += struct.pack(\"<4I\", 2000, len(tags) + 32, num_tags,\n                              HAS_HEADER)\n        footer += b\"\\0\" * 8\n\n        fileobj.write(footer)\n        fileobj.close()", "response": "Save the current state of the APE tags to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(self, filename=None):\n\n        filename = filename or self.filename\n        fileobj = open(filename, \"r+b\")\n        try:\n            data = _APEv2Data(fileobj)\n            if data.start is not None and data.size is not None:\n                delete_bytes(fileobj, data.end - data.start, data.start)\n        finally:\n            fileobj.close()\n        self.clear()", "response": "Remove tags from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a request to the Route53 API and returns the response.", "response": "def _send_request(self, path, data, method):\n        \"\"\"\n        Uses the HTTP transport to query the Route53 API. Runs the response\n        through lxml's parser, before we hand it off for further picking\n        apart by our call-specific parsers.\n\n        :param str path: The RESTful path to tack on to the :py:attr:`endpoint`.\n        :param data: The params to send along with the request.\n        :type data: Either a dict or bytes, depending on the request type.\n        :param str method: One of 'GET', 'POST', or 'DELETE'.\n        :rtype: lxml.etree._Element\n        :returns: An lxml Element root.\n        \"\"\"\n\n        response_body = self._transport.send_request(path, data, method)\n        root = etree.fromstring(response_body)\n        #print(prettyprint_xml(root))\n        return root"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _do_autopaginating_api_call(self, path, params, method, parser_func,\n        next_marker_xpath, next_marker_param_name,\n        next_type_xpath=None, parser_kwargs=None):\n        \"\"\"\n        Given an API method, the arguments passed to it, and a function to\n        hand parsing off to, loop through the record sets in the API call\n        until all records have been yielded.\n\n\n        :param str method: The API method on the endpoint.\n        :param dict params: The kwargs from the top-level API method.\n        :param callable parser_func: A callable that is used for parsing the\n            output from the API call.\n        :param str next_marker_param_name: The XPath to the marker tag that\n            will determine whether we continue paginating.\n        :param str next_marker_param_name: The parameter name to manipulate\n            in the request data to bring up the next page on the next\n            request loop.\n        :keyword str next_type_xpath: For the\n            py:meth:`list_resource_record_sets_by_zone_id` method, there's\n            an additional paginator token. Specifying this XPath looks for it.\n        :keyword dict parser_kwargs: Optional dict of additional kwargs to pass\n            on to the parser function.\n        :rtype: generator\n        :returns: Returns a generator that may be returned by the top-level\n            API method.\n        \"\"\"\n\n        if not parser_kwargs:\n            parser_kwargs = {}\n\n        # We loop indefinitely since we have no idea how many \"pages\" of\n        # results we're going to have to go through.\n        while True:\n            # An lxml Element node.\n            root = self._send_request(path, params, method)\n\n            # Individually yield HostedZone instances after parsing/instantiating.\n            for record in parser_func(root, connection=self, **parser_kwargs):\n                yield record\n\n            # This will determine at what offset we start the next query.\n            next_marker = root.find(next_marker_xpath)\n            if next_marker is None:\n                # If the NextMarker tag is absent, we know we've hit the\n                # last page.\n                break\n\n            # if NextMarker is present, we'll adjust our API request params\n            # and query again for the next page.\n            params[next_marker_param_name] = next_marker.text\n\n            if next_type_xpath:\n                # This is a _list_resource_record_sets_by_zone_id call. Look\n                # for the given tag via XPath and adjust our type arg for\n                # the next request. Without specifying this, we loop\n                # infinitely.\n                next_type = root.find(next_type_xpath)\n                params['type'] = next_type.text", "response": "This method will loop through the resource record sets in the API call to get the next page of the next record set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting all hosted zones associated with this connection's account. Since this method returns a generator, you can pull as many or as few entries as you'd like, without having to query and receive every hosted zone you may have. :keyword int page_chunks: This API call is \"paginated\" behind-the-scenes in order to break up large result sets. This number determines the maximum number of :py:class:`HostedZone <route53.hosted_zone.HostedZone>` instances to retrieve per request. The default is fine for almost everyone. :rtype: generator :returns: A generator of :py:class:`HostedZone <route53.hosted_zone.HostedZone>` instances.", "response": "def list_hosted_zones(self, page_chunks=100):\n        \"\"\"\n        List all hosted zones associated with this connection's account. Since\n        this method returns a generator, you can pull as many or as few\n        entries as you'd like, without having to query and receive every\n        hosted zone you may have.\n\n        :keyword int page_chunks: This API call is \"paginated\" behind-the-scenes\n            in order to break up large result sets. This number determines\n            the maximum number of\n            :py:class:`HostedZone <route53.hosted_zone.HostedZone>`\n            instances to retrieve per request. The default is fine for almost\n            everyone.\n\n        :rtype: generator\n        :returns: A generator of :py:class:`HostedZone <route53.hosted_zone.HostedZone>`\n            instances.\n        \"\"\"\n\n        return  self._do_autopaginating_api_call(\n            path='hostedzone',\n            params={'maxitems': page_chunks},\n            method='GET',\n            parser_func=xml_parsers.list_hosted_zones_parser,\n            next_marker_xpath=\"./{*}NextMarker\",\n            next_marker_param_name=\"marker\",\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_hosted_zone(self, name, caller_reference=None, comment=None):\n\n        body = xml_generators.create_hosted_zone_writer(\n            connection=self,\n            name=name,\n            caller_reference=caller_reference,\n            comment=comment\n        )\n\n        root = self._send_request(\n            path='hostedzone',\n            data=body,\n            method='POST',\n        )\n\n        return xml_parsers.created_hosted_zone_parser(\n            root=root,\n            connection=self\n        )", "response": "Creates and returns a new hosted zone."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_hosted_zone_by_id(self, id):\n\n        root = self._send_request(\n            path='hostedzone/%s' % id,\n            data={},\n            method='GET',\n        )\n\n        return xml_parsers.get_hosted_zone_by_id_parser(\n            root=root,\n            connection=self,\n        )", "response": "Retrieves a hosted zone by ID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_hosted_zone_by_id(self, id):\n\n        root = self._send_request(\n            path='hostedzone/%s' % id,\n            data={},\n            method='DELETE',\n        )\n\n        return xml_parsers.delete_hosted_zone_by_id_parser(\n            root=root,\n            connection=self,\n        )", "response": "Deletes a hosted zone by ID."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _list_resource_record_sets_by_zone_id(self, id, rrset_type=None,\n                                             identifier=None, name=None,\n                                             page_chunks=100):\n        \"\"\"\n        Lists a hosted zone's resource record sets by Zone ID, if you\n        already know it.\n\n        .. tip:: For most cases, we recommend going through a\n            :py:class:`HostedZone <route53.hosted_zone.HostedZone>`\n            instance's\n            :py:meth:`HostedZone.record_sets <route53.hosted_zone.HostedZone.record_sets>`\n            property, but this saves an HTTP request if you already know the\n            zone's ID.\n\n        :param str id: The ID of the zone whose record sets we're listing.\n        :keyword str rrset_type: The type of resource record set to begin the\n            record listing from.\n        :keyword str identifier: Weighted and latency resource record sets\n            only: If results were truncated for a given DNS name and type,\n            the value of SetIdentifier for the next resource record set\n            that has the current DNS name and type.\n        :keyword str name: Not really sure what this does.\n        :keyword int page_chunks: This API call is paginated behind-the-scenes\n            by this many ResourceRecordSet instances. The default should be\n            fine for just about everybody, aside from those with tons of RRS.\n\n        :rtype: generator\n        :returns: A generator of ResourceRecordSet instances.\n        \"\"\"\n\n        params = {\n            'name': name,\n            'type': rrset_type,\n            'identifier': identifier,\n            'maxitems': page_chunks,\n        }\n\n        return  self._do_autopaginating_api_call(\n            path='hostedzone/%s/rrset' % id,\n            params=params,\n            method='GET',\n            parser_func=xml_parsers.list_resource_record_sets_by_zone_id_parser,\n            parser_kwargs={'zone_id': id},\n            next_marker_xpath=\"./{*}NextRecordName\",\n            next_marker_param_name=\"name\",\n            next_type_xpath=\"./{*}NextRecordType\"\n        )", "response": "This method returns a generator of ResourceRecordSet instances for the given hosted zone ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a ChangeSet POST it to the Route53 API and return a dict of change info.", "response": "def _change_resource_record_sets(self, change_set, comment=None):\n        \"\"\"\n        Given a ChangeSet, POST it to the Route53 API.\n\n        .. note:: You probably shouldn't be using this method directly,\n            as there are convenience methods on the ResourceRecordSet\n            sub-classes.\n\n        :param change_set.ChangeSet change_set: The ChangeSet object to create\n            the XML doc from.\n        :keyword str comment: An optional comment to go along with the request.\n        :rtype: dict\n        :returns: A dict of change info, which contains some details about\n            the request.\n        \"\"\"\n\n        body = xml_generators.change_resource_record_set_writer(\n            connection=self,\n            change_set=change_set,\n            comment=comment\n        )\n\n        root = self._send_request(\n            path='hostedzone/%s/rrset' % change_set.hosted_zone_id,\n            data=body,\n            method='POST',\n        )\n\n        #print(prettyprint_xml(root))\n\n        e_change_info = root.find('./{*}ChangeInfo')\n        if e_change_info is None:\n            error = root.find('./{*}Error').find('./{*}Message').text\n            raise Route53Error(error)\n        return parse_change_info(e_change_info)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndraw an image. The image's top-left corner is drawn at ``(x1, y1)``, and its lower-left at ``(x2, y2)``. If ``x2`` and ``y2`` are omitted, they are calculated to render the image at its native resoultion. Note that images can be flipped and scaled by providing alternative values for ``x2`` and ``y2``. :param image: an :class:`Image` to draw", "response": "def draw_image(image, x1, y1, x2 = None, y2 = None):\n    '''Draw an image.\n\n    The image's top-left corner is drawn at ``(x1, y1)``, and its lower-left at ``(x2, y2)``.  If ``x2`` and ``y2`` are omitted, they\n    are calculated to render the image at its native resoultion.\n\n    Note that images can be flipped and scaled by providing alternative values for ``x2`` and ``y2``.\n\n    :param image: an :class:`Image` to draw\n    '''\n    if x2 is None:\n        x2 = x1 + image.width\n    if y2 is None:\n        y2 = y1 + image.height\n    lib.DrawImage(image._handle, x1, y1, x2, y2)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef draw_image_region(image, x1, y1, x2, y2,\n                      ix1, iy1, ix2, iy2):\n    '''Draw a rectangular region of an image.\n\n    The part of the image contained by the rectangle in texel-space by the coordinates ``(ix1, iy1)`` to ``(ix2, iy2)`` is\n    drawn at coordinates ``(x1, y1)`` to ``(x2, y2)``.  All coordinates have the origin ``(0, 0)`` at the upper-left corner.\n\n    For example, to draw the left half of a ``100x100`` image at coordinates ``(x, y)``::\n\n        bacon.draw_image_region(image, x, y, x + 50, y + 100,\n                                0, 0, 50, 100)\n\n    :param image: an :class:`Image` to draw\n    '''\n    lib.DrawImageRegion(image._handle, x1, y1, x2, y2, ix1, iy1, ix2, iy2)", "response": "Draw a rectangular region of an image."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef size(self):\n\n        header_size = 27 # Initial header size\n        for datum in self.packets:\n            quot, rem = divmod(len(datum), 255)\n            header_size += quot + 1\n        if not self.complete and rem == 0:\n            # Packet contains a multiple of 255 bytes and is not\n            # terminated, so we don't have a \\x00 at the end.\n            header_size -= 1\n        header_size += sum(map(len, self.packets))\n        return header_size", "response": "Total size of the message."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef replace(cls, fileobj, old_pages, new_pages):\n\n        # Number the new pages starting from the first old page.\n        first = old_pages[0].sequence\n        for page, seq in zip(new_pages, range(first, first + len(new_pages))):\n            page.sequence = seq\n            page.serial = old_pages[0].serial\n\n        new_pages[0].first = old_pages[0].first\n        new_pages[0].last = old_pages[0].last\n        new_pages[0].continued = old_pages[0].continued\n\n        new_pages[-1].first = old_pages[-1].first\n        new_pages[-1].last = old_pages[-1].last\n        new_pages[-1].complete = old_pages[-1].complete\n        if not new_pages[-1].complete and len(new_pages[-1].packets) == 1:\n            new_pages[-1].position = -1\n\n        new_data = b''.join(cls.write(p) for p in new_pages)\n\n        # Make room in the file for the new data.\n        delta = len(new_data)\n        fileobj.seek(old_pages[0].offset, 0)\n        insert_bytes(fileobj, delta, old_pages[0].offset)\n        fileobj.seek(old_pages[0].offset, 0)\n        fileobj.write(new_data)\n        new_data_end = old_pages[0].offset + delta\n\n        # Go through the old pages and delete them. Since we shifted\n        # the data down the file, we need to adjust their offsets. We\n        # also need to go backwards, so we don't adjust the deltas of\n        # the other pages.\n        old_pages.reverse()\n        for old_page in old_pages:\n            adj_offset = old_page.offset + delta\n            delete_bytes(fileobj, old_page.size, adj_offset)\n\n        # Finally, if there's any discrepency in length, we need to\n        # renumber the pages for the logical stream.\n        if len(old_pages) != len(new_pages):\n            fileobj.seek(new_data_end, 0)\n            serial = new_pages[-1].serial\n            sequence = new_pages[-1].sequence + 1\n            cls.renumber(fileobj, serial, sequence)", "response": "Replace old_pages with new_pages within fileobj."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the last page of the stream serial.", "response": "def find_last(fileobj, serial):\n        \"\"\"Find the last page of the stream 'serial'.\n\n        If the file is not multiplexed this function is fast. If it is,\n        it must read the whole the stream.\n\n        This finds the last page in the actual file object, or the last\n        page in the stream (with eos set), whichever comes first.\n        \"\"\"\n\n        # For non-muxed streams, look at the last page.\n        try:\n            fileobj.seek(-256*256, 2)\n        except IOError:\n            # The file is less than 64k in length.\n            fileobj.seek(0)\n        data = fileobj.read()\n        try:\n            index = data.rindex(b\"OggS\")\n        except ValueError:\n            raise error(\"unable to find final Ogg header\")\n        bytesobj = cBytesIO(data[index:])\n        best_page = None\n        try:\n            page = OggPage(bytesobj)\n        except error:\n            pass\n        else:\n            if page.serial == serial:\n                if page.last:\n                    return page\n                else:\n                    best_page = page\n            else:\n                best_page = None\n\n        # The stream is muxed, so use the slow way.\n        fileobj.seek(0)\n        try:\n            page = OggPage(fileobj)\n            while not page.last:\n                page = OggPage(fileobj)\n                while page.serial != serial:\n                    page = OggPage(fileobj)\n                best_page = page\n            return page\n        except error:\n            return best_page\n        except EOFError:\n            return best_page"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(self, filename):\n\n        self.filename = filename\n        fileobj = open(filename, \"rb\")\n        try:\n            try:\n                self.info = self._Info(fileobj)\n                self.tags = self._Tags(fileobj, self.info)\n                self.info._post_tags(fileobj)\n            except error as e:\n                reraise(self._Error, e, sys.exc_info()[2])\n            except EOFError:\n                raise self._Error(\"no appropriate stream found\")\n        finally:\n            fileobj.close()", "response": "Load information from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves tags from a file.", "response": "def delete(self, filename=None):\n        \"\"\"Remove tags from a file.\n\n        If no filename is given, the one most recently loaded is used.\n        \"\"\"\n\n        if filename is None:\n            filename = self.filename\n\n        self.tags.clear()\n        fileobj = open(filename, \"rb+\")\n        try:\n            try:\n                self.tags._inject(fileobj)\n            except error as e:\n                reraise(self._Error, e, sys.exc_info()[2])\n            except EOFError:\n                raise self._Error(\"no appropriate stream found\")\n        finally:\n            fileobj.close()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _inject(self, fileobj):\n\n        fileobj.seek(0)\n        page = OggPage(fileobj)\n        while not page.packets[0].startswith(b\"\\x81theora\"):\n            page = OggPage(fileobj)\n\n        old_pages = [page]\n        while not (old_pages[-1].complete or len(old_pages[-1].packets) > 1):\n            page = OggPage(fileobj)\n            if page.serial == old_pages[0].serial:\n                old_pages.append(page)\n\n        packets = OggPage.to_packets(old_pages, strict=False)\n\n        packets[0] = b\"\\x81theora\" + self.write(framing=False)\n\n        new_pages = OggPage.from_packets(packets, old_pages[0].sequence)\n        OggPage.replace(fileobj, old_pages, new_pages)", "response": "Write tag data into the Theora comment packet or page."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef created_hosted_zone_parser(root, connection):\n\n    zone = root.find('./{*}HostedZone')\n    # This pops out a HostedZone instance.\n    hosted_zone = parse_hosted_zone(zone, connection)\n\n    # Now we'll fill in the nameservers.\n    e_delegation_set = root.find('./{*}DelegationSet')\n    # Modifies the HostedZone in place.\n    parse_delegation_set(hosted_zone, e_delegation_set)\n\n    # With each CreateHostedZone request, there's some details about the\n    # request's ID, status, and submission time. We'll return this in a tuple\n    # just for the sake of completeness.\n    e_change_info = root.find('./{*}ChangeInfo')\n    # Translate the ChangeInfo values to a dict.\n    change_info = parse_change_info(e_change_info)\n\n    return hosted_zone, change_info", "response": "Parses the API responses for the create_hosted_zone method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef  set_section( self, section_name ):\n        if not self.sections.has_key( section_name ):\n            section = DocSection( section_name )\n            self.sections[section_name] = section\n            self.section                = section\n        else:\n            self.section = self.sections[section_name]", "response": "set current section during parsing"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef  add_markup( self ):\n        if self.markup and self.markup_lines:\n\n            # get rid of last line of markup if it's empty\n            marks = self.markup_lines\n            if len( marks ) > 0 and not string.strip( marks[-1] ):\n                self.markup_lines = marks[:-1]\n\n            m = DocMarkup( self.markup, self.markup_lines )\n\n            self.markups.append( m )\n\n            self.markup       = None\n            self.markup_lines = []", "response": "add a new markup section"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprocess a block content and return a list of DocMarkup objects that correspond to it", "response": "def  process_content( self, content ):\n        \"\"\"process a block content and return a list of DocMarkup objects\n           corresponding to it\"\"\"\n        markup       = None\n        markup_lines = []\n        first        = 1\n\n        for line in content:\n            found = None\n            for t in re_markup_tags:\n                m = t.match( line )\n                if m:\n                    found  = string.lower( m.group( 1 ) )\n                    prefix = len( m.group( 0 ) )\n                    line   = \" \" * prefix + line[prefix:]   # remove markup from line\n                    break\n\n            # is it the start of a new markup section ?\n            if found:\n                first = 0\n                self.add_markup()  # add current markup content\n                self.markup = found\n                if len( string.strip( line ) ) > 0:\n                    self.markup_lines.append( line )\n            elif first == 0:\n                self.markup_lines.append( line )\n\n        self.add_markup()\n\n        return self.markups"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the DocMarkup corresponding to a given tag in a block", "response": "def  get_markup( self, tag_name ):\n        \"\"\"return the DocMarkup corresponding to a given tag in a block\"\"\"\n        for m in self.markups:\n            if m.tag == string.lower( tag_name ):\n                return m\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new hosted zone.", "response": "def create_hosted_zone_writer(connection, name, caller_reference, comment):\n    \"\"\"\n    Forms an XML string that we'll send to Route53 in order to create\n    a new hosted zone.\n\n    :param Route53Connection connection: The connection instance used to\n        query the API.\n    :param str name: The name of the hosted zone to create.\n    \"\"\"\n\n    if not caller_reference:\n        caller_reference = str(uuid.uuid4())\n\n    e_root = etree.Element(\n        \"CreateHostedZoneRequest\",\n        xmlns=connection._xml_namespace\n    )\n\n    e_name = etree.SubElement(e_root, \"Name\")\n    e_name.text = name\n\n    e_caller_reference = etree.SubElement(e_root, \"CallerReference\")\n    e_caller_reference.text = caller_reference\n\n    if comment:\n        e_config = etree.SubElement(e_root, \"HostedZoneConfig\")\n        e_comment = etree.SubElement(e_config, \"Comment\")\n        e_comment.text = comment\n\n    e_tree = etree.ElementTree(element=e_root)\n\n    fobj = BytesIO()\n    # This writes bytes.\n    e_tree.write(fobj, xml_declaration=True, encoding='utf-8', method=\"xml\")\n    return fobj.getvalue().decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lock(fileobj):\n\n    try:\n        import fcntl\n    except ImportError:\n        return False\n    else:\n        try:\n            fcntl.lockf(fileobj, fcntl.LOCK_EX)\n        except IOError:\n            # FIXME: There's possibly a lot of complicated\n            # logic that needs to go here in case the IOError\n            # is EACCES or EAGAIN.\n            return False\n        else:\n            return True", "response": "Lock a file object safely."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef insert_bytes(fobj, size, offset, BUFFER_SIZE=2**16):\n\n    assert 0 < size\n    assert 0 <= offset\n    locked = False\n    fobj.seek(0, 2)\n    filesize = fobj.tell()\n    movesize = filesize - offset\n    fobj.write(b'\\x00' * size)\n    fobj.flush()\n    try:\n        try:\n            import mmap\n            file_map = mmap.mmap(fobj.fileno(), filesize + size)\n            try:\n                file_map.move(offset + size, offset, movesize)\n            finally:\n                file_map.close()\n        except (ValueError, EnvironmentError, ImportError):\n            # handle broken mmap scenarios\n            locked = lock(fobj)\n            fobj.truncate(filesize)\n\n            fobj.seek(0, 2)\n            padsize = size\n            # Don't generate an enormous string if we need to pad\n            # the file out several megs.\n            while padsize:\n                addsize = min(BUFFER_SIZE, padsize)\n                fobj.write(b\"\\x00\" * addsize)\n                padsize -= addsize\n\n            fobj.seek(filesize, 0)\n            while movesize:\n                # At the start of this loop, fobj is pointing at the end\n                # of the data we need to move, which is of movesize length.\n                thismove = min(BUFFER_SIZE, movesize)\n                # Seek back however much we're going to read this frame.\n                fobj.seek(-thismove, 1)\n                nextpos = fobj.tell()\n                # Read it, so we're back at the end.\n                data = fobj.read(thismove)\n                # Seek back to where we need to write it.\n                fobj.seek(-thismove + size, 1)\n                # Write it.\n                fobj.write(data)\n                # And seek back to the end of the unmoved data.\n                fobj.seek(nextpos)\n                movesize -= thismove\n\n            fobj.flush()\n    finally:\n        if locked:\n            unlock(fobj)", "response": "Insert size bytes of empty space starting at offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_bytes(fobj, size, offset, BUFFER_SIZE=2**16):\n\n    locked = False\n    assert 0 < size\n    assert 0 <= offset\n    fobj.seek(0, 2)\n    filesize = fobj.tell()\n    movesize = filesize - offset - size\n    assert 0 <= movesize\n    try:\n        if movesize > 0:\n            fobj.flush()\n            try:\n                import mmap\n                file_map = mmap.mmap(fobj.fileno(), filesize)\n                try:\n                    file_map.move(offset, offset + size, movesize)\n                finally:\n                    file_map.close()\n            except (ValueError, EnvironmentError, ImportError):\n                # handle broken mmap scenarios\n                locked = lock(fobj)\n                fobj.seek(offset + size)\n                buf = fobj.read(BUFFER_SIZE)\n                while buf:\n                    fobj.seek(offset)\n                    fobj.write(buf)\n                    offset += len(buf)\n                    fobj.seek(offset + size)\n                    buf = fobj.read(BUFFER_SIZE)\n        fobj.truncate(filesize - size)\n        fobj.flush()\n    finally:\n        if locked:\n            unlock(fobj)", "response": "Delete size bytes of empty space starting at offset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a basestring to a valid UTF - 8 str.", "response": "def utf8(data):\n    \"\"\"Convert a basestring to a valid UTF-8 str.\"\"\"\n\n    if isinstance(data, bytes):\n        return data.decode(\"utf-8\", \"replace\").encode(\"utf-8\")\n    elif isinstance(data, text_type):\n        return data.encode(\"utf-8\")\n    else:\n        raise TypeError(\"only unicode/bytes types can be converted to UTF-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a change to this change set.", "response": "def add_change(self, action, record_set):\n        \"\"\"\n        Adds a change to this change set.\n\n        :param str action: Must be one of either 'CREATE' or 'DELETE'.\n        :param resource_record_set.ResourceRecordSet record_set: The\n            ResourceRecordSet object that was created or deleted.\n        \"\"\"\n\n        action = action.upper()\n\n        if action not in ['CREATE', 'DELETE']:\n            raise Route53Error(\"action must be one of 'CREATE' or 'DELETE'\")\n\n        change_tuple = (action, record_set)\n\n        if action == 'CREATE':\n            self.creations.append(change_tuple)\n        else:\n            self.deletions.append(change_tuple)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a ChangeInfo tag and returns a dict representation of the change info.", "response": "def parse_change_info(e_change_info):\n    \"\"\"\n    Parses a ChangeInfo tag. Seen in CreateHostedZone, DeleteHostedZone,\n    and ChangeResourceRecordSetsRequest.\n\n    :param lxml.etree._Element e_change_info: A ChangeInfo element.\n    :rtype: dict\n    :returns: A dict representation of the change info.\n    \"\"\"\n\n    if e_change_info is None:\n        return e_change_info\n\n    status = e_change_info.find('./{*}Status').text\n    submitted_at = e_change_info.find('./{*}SubmittedAt').text\n    submitted_at = parse_iso_8601_time_str(submitted_at)\n\n    return {\n        'request_id': id,\n        'request_status': status,\n        'request_submitted_at': submitted_at\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_resource_path(filename):\n    '''Get a path to the given filename to load as a resource.  All non-absolute filenames passed to\n    :class:`Image`, :class:`Font`, :class:`Sound`, etc are transformed through this function.\n\n    :param str filename: a relative path to a resource file\n    :return str: an absolute path to the file\n    '''\n    path = os.path.join(resource_dir, filename)\n    if _dll_dir and not os.path.exists(path):\n        path = os.path.join(_dll_dir, filename)\n    return path", "response": "Get a path to the given filename to load as a resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve a glyph that renders the given character.", "response": "def get_glyph(self, char):\n        '''Retrieves a :class:`Glyph` that renders the given character.\n\n        :param char: the character (a string)\n        '''\n        try:\n            return self._glyphs[char]\n        except KeyError:\n            glyph = self._font_file.get_glyph(self._size, self._content_scale, char, self._flags)\n            self._glyphs[char] = glyph\n            return glyph"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the width of the given string in this font.", "response": "def measure_string(self, str):\n        '''Calculates the width of the given string in this font.\n\n        :param str: the string to measure\n        :return float: width of the string, in pixels\n        '''\n        style = bacon.text.Style(self)\n        run = bacon.text.GlyphRun(style, str)\n        glyph_layout = bacon.text.GlyphLayout([run], 0, 0)\n        return glyph_layout.content_width"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine whether this record set has been modified since the last retrieval or save.", "response": "def is_modified(self):\n        \"\"\"\n        Determines whether this record set has been modified since the\n        last retrieval or save.\n\n        :rtype: bool\n        :returns: ``True` if the record set has been modified,\n            and ``False`` if not.\n        \"\"\"\n\n        for key, val in self._initial_vals.items():\n            if getattr(self, key) != val:\n                # One of the initial values doesn't match, we know\n                # this object has been touched.\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes this record set.", "response": "def delete(self):\n        \"\"\"\n        Deletes this record set.\n        \"\"\"\n\n        cset = ChangeSet(connection=self.connection, hosted_zone_id=self.zone_id)\n        cset.add_change('DELETE', self)\n\n        return self.connection._change_resource_record_sets(cset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self):\n\n        cset = ChangeSet(connection=self.connection, hosted_zone_id=self.zone_id)\n        # Record sets can't actually be modified. You have to delete the\n        # existing one and create a new one. Since this happens within a single\n        # change set, it appears that the values were modified, when instead\n        # the whole thing is replaced.\n        cset.add_change('DELETE', self)\n        cset.add_change('CREATE', self)\n        retval = self.connection._change_resource_record_sets(cset)\n\n        # Now copy the current attribute values on this instance to\n        # the initial_vals dict. This will re-set the modification tracking.\n        for key, val in self._initial_vals.items():\n            self._initial_vals[key] = getattr(self, key)\n\n        return retval", "response": "Saves any changes to this record set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(filename, delete_v1=True, delete_v2=True):\n\n    f = open(filename, 'rb+')\n\n    if delete_v1:\n        try:\n            f.seek(-128, 2)\n        except IOError:\n            pass\n        else:\n            if f.read(3) == b'TAG':\n                f.seek(-128, 2)\n                f.truncate()\n\n    # technically an insize=0 tag is invalid, but we delete it anyway\n    # (primarily because we used to write it)\n    if delete_v2:\n        f.seek(0, 0)\n        idata = f.read(10)\n        try:\n            id3, vmaj, vrev, flags, insize = unpack('>3sBBB4s', idata)\n        except struct.error:\n            id3, insize = b'', -1\n        insize = BitPaddedInt(insize)\n        if id3 == b'ID3' and insize >= 0:\n            delete_bytes(f, insize + 10, 0)", "response": "Delete tags from a file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ParseID3v1(data):\n\n    try:\n        data = data[data.index(b'TAG'):]\n    except ValueError:\n        return None\n    if 128 < len(data) or len(data) < 124:\n        return None\n\n    # Issue #69 - Previous versions of Mutagen, when encountering\n    # out-of-spec TDRC and TYER frames of less than four characters,\n    # wrote only the characters available - e.g. \"1\" or \"\" - into the\n    # year field. To parse those, reduce the size of the year field.\n    # Amazingly, \"0s\" works as a struct format string.\n    unpack_fmt = \"3s30s30s30s%ds29sBB\" % (len(data) - 124)\n\n    try:\n        tag, title, artist, album, year, comment, track, genre = unpack(\n            unpack_fmt, data)\n    except StructError:\n        return None\n\n    if tag != b\"TAG\":\n        return None\n\n    def fix(data):\n        return data.split(b'\\x00')[0].strip().decode('latin1')\n\n    title, artist, album, year, comment = map(\n        fix, [title, artist, album, year, comment])\n\n    frames = {}\n    if title:\n        frames['TIT2'] = TIT2(encoding=0, text=title)\n    if artist:\n        frames['TPE1'] = TPE1(encoding=0, text=[artist])\n    if album:\n        frames['TALB'] = TALB(encoding=0, text=album)\n    if year:\n        frames['TDRC'] = TDRC(encoding=0, text=year)\n    if comment:\n        frames['COMM'] = COMM(encoding=0, lang='eng', desc=\"ID3v1 Comment\",\n                              text=comment)\n\n    # Don't read a track number if it looks like the comment was\n    # padded with spaces instead of nulls (thanks, WinAmp).\n    if track and ((track != 32) or (data[-3] == b'\\x00'[0])):\n        frames['TRCK'] = TRCK(encoding=0, text=str(track))\n    if genre != 255:\n        frames['TCON'] = TCON(encoding=0, text=str(genre))\n    return frames", "response": "Parse an ID3v1 tag returning a list of ID3v2. 4 frames."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef MakeID3v1(id3):\n\n    v1 = {}\n\n    for v2id, name in {\"TIT2\": \"title\", \"TPE1\": \"artist\",\n                       \"TALB\": \"album\"}.items():\n        if v2id in id3:\n            text = id3[v2id].text[0].encode('latin1', 'replace')[:30]\n        else:\n            text = b''\n        v1[name] = text + (b'\\x00' * (30 - len(text)))\n\n    if \"COMM\" in id3:\n        cmnt = id3[\"COMM\"].text[0].encode('latin1', 'replace')[:28]\n    else:\n        cmnt = b''\n    v1['comment'] = cmnt + (b'\\x00' * (29 - len(cmnt)))\n\n    if \"TRCK\" in id3:\n        try:\n            v1[\"track\"] = chr_(+id3[\"TRCK\"])\n        except ValueError:\n            v1[\"track\"] = b'\\x00'\n    else:\n        v1[\"track\"] = b'\\x00'\n\n    if \"TCON\" in id3:\n        try:\n            genre = id3[\"TCON\"].genres[0]\n        except IndexError:\n            pass\n        else:\n            if genre in TCON.GENRES:\n                v1[\"genre\"] = chr_(TCON.GENRES.index(genre))\n    if \"genre\" not in v1:\n        v1[\"genre\"] = b\"\\xff\"\n\n    if \"TDRC\" in id3:\n        year = text_type(id3[\"TDRC\"]).encode('latin1', 'replace')\n    elif \"TYER\" in id3:\n        year = text_type(id3[\"TYER\"]).encode('latin1', 'replace')\n    else:\n        year = b''\n    v1['year'] = (year + b'\\x00\\x00\\x00\\x00')[:4]\n\n\n    return (b'TAG' +\n            v1['title'] +\n            v1['artist'] +\n            v1['album'] +\n            v1['year'] +\n            v1['comment'] +\n            v1['track'] +\n            v1['genre'])", "response": "Make an ID3v1. 1 tag string from a dict of ID3v2. 4 frames."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a certain number of bytes from the source file.", "response": "def __fullread(self, size):\n        \"\"\" Read a certain number of bytes from the source file. \"\"\"\n\n        try:\n            if size < 0:\n                raise ValueError('Requested bytes (%s) less than zero' % size)\n            if size > self.__filesize:\n                raise EOFError('Requested %#x of %#x (%s)' % (\n                    int(size), int(self.__filesize), self.filename))\n        except AttributeError:\n            pass\n        data = self._fileobj.read(size)\n        if len(data) != size:\n            raise EOFError\n        self.__readbytes += size\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(self, filename, known_frames=None, translate=True, v2_version=4):\n\n        if not v2_version in (3, 4):\n            raise ValueError(\"Only 3 and 4 possible for v2_version\")\n\n        from os.path import getsize\n\n        self.filename = filename\n        self.__known_frames = known_frames\n        self._fileobj = open(filename, 'rb')\n        self.__filesize = getsize(filename)\n        try:\n            try:\n                self._load_header()\n            except EOFError:\n                self.size = 0\n                raise ID3NoHeaderError(\"%s: too small (%d bytes)\" % (\n                    filename, self.__filesize))\n            except (ID3NoHeaderError, ID3UnsupportedVersionError) as err:\n                self.size = 0\n                import sys\n                stack = sys.exc_info()[2]\n                try:\n                    self._fileobj.seek(-128, 2)\n                except EnvironmentError:\n                    reraise(err, None, stack)\n                else:\n                    frames = ParseID3v1(self._fileobj.read(128))\n                    if frames is not None:\n                        self.version = self._V11\n                        for v in frames.values():\n                            self.add(v)\n                    else:\n                        reraise(err, None, stack)\n            else:\n                frames = self.__known_frames\n                if frames is None:\n                    if self._V23 <= self.version:\n                        frames = Frames\n                    elif self._V22 <= self.version:\n                        frames = Frames_2_2\n                data = self.__fullread(self.size - 10)\n                for frame in self.__read_frames(data, frames=frames):\n                    if isinstance(frame, Frame):\n                        self.add(frame)\n                    else:\n                        self.unknown_frames.append(frame)\n                self.__unknown_version = self.version\n        finally:\n            self._fileobj.close()\n            del self._fileobj\n            del self.__filesize\n            if translate:\n                if v2_version == 3:\n                    self.update_to_v23()\n                else:\n                    self.update_to_v24()", "response": "Load a tag from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getall(self, key):\n        if key in self:\n            return [self[key]]\n        else:\n            key = key + ':'\n            return [v for s, v in self.items() if s.startswith(key)]", "response": "Return all frames with a given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes all tags of a given kind ; see getall.", "response": "def delall(self, key):\n        \"\"\"Delete all tags of a given kind; see getall.\"\"\"\n        if key in self:\n            del(self[key])\n        else:\n            key = key + \":\"\n            for k in self.keys():\n                if k.startswith(key):\n                    del(self[k])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeprecating ; use the add method.", "response": "def loaded_frame(self, tag):\n        \"\"\"Deprecated; use the add method.\"\"\"\n        # turn 2.2 into 2.3/2.4 tags\n        if len(type(tag).__name__) == 3:\n            tag = type(tag).__base__(tag)\n        self[tag.HashKey] = tag"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self, filename=None, v1=1, v2_version=4, v23_sep='/'):\n\n        framedata = self._prepare_framedata(v2_version, v23_sep)\n        framesize = len(framedata)\n\n        if not framedata:\n            try:\n                self.delete(filename)\n            except EnvironmentError as err:\n                from errno import ENOENT\n                if err.errno != ENOENT:\n                    raise\n            return\n\n        if filename is None:\n            filename = self.filename\n        try:\n            f = open(filename, 'rb+')\n        except IOError as err:\n            from errno import ENOENT\n            if err.errno != ENOENT:\n                raise\n            f = open(filename, 'ab')  # create, then reopen\n            f = open(filename, 'rb+')\n        try:\n            idata = f.read(10)\n\n            header = self._prepare_id3_header(idata, framesize, v2_version)\n            header, outsize, insize = header\n\n            data = header + framedata + (b'\\x00' * (outsize - framesize))\n\n            if (insize < outsize):\n                insert_bytes(f, outsize-insize, insize+10)\n            f.seek(0)\n            f.write(data)\n\n            try:\n                f.seek(-128, 2)\n            except IOError as err:\n                # If the file is too small, that's OK - it just means\n                # we're certain it doesn't have a v1 tag.\n                from errno import EINVAL\n                if err.errno != EINVAL:\n                    # If we failed to see for some other reason, bail out.\n                    raise\n                # Since we're sure this isn't a v1 tag, don't read it.\n                f.seek(0, 2)\n\n            data = f.read(128)\n            try:\n                idx = data.index(b\"TAG\")\n            except ValueError:\n                offset = 0\n                has_v1 = False\n            else:\n                offset = idx - len(data)\n                has_v1 = True\n\n            f.seek(offset, 2)\n            if v1 == 1 and has_v1 or v1 == 2:\n                f.write(MakeID3v1(self))\n            else:\n                f.truncate()\n\n        finally:\n            f.close()", "response": "Save the ID3v2 tags to a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, filename=None, delete_v1=True, delete_v2=True):\n        if filename is None:\n            filename = self.filename\n        delete(filename, delete_v1, delete_v2)\n        self.clear()", "response": "Remove tags from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates done by both v23 and v24 update.", "response": "def __update_common(self):\n        \"\"\"Updates done by both v23 and v24 update\"\"\"\n\n        if \"TCON\" in self:\n            # Get rid of \"(xx)Foobr\" format.\n            self[\"TCON\"].genres = self[\"TCON\"].genres\n\n        if self.version < self._V23:\n            # ID3v2.2 PIC frames are slightly different.\n            pics = self.getall(\"APIC\")\n            mimes = {\"PNG\": \"image/png\", \"JPG\": \"image/jpeg\"}\n            self.delall(\"APIC\")\n            for pic in pics:\n                newpic = APIC(\n                    encoding=pic.encoding, mime=mimes.get(pic.mime, pic.mime),\n                    type=pic.type, desc=pic.desc, data=pic.data)\n                self.add(newpic)\n\n            # ID3v2.2 LNK frames are just way too different to upgrade.\n            self.delall(\"LINK\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_to_v24(self):\n\n        self.__update_common()\n\n        if self.__unknown_version == self._V23:\n            # convert unknown 2.3 frames (flags/size) to 2.4\n            converted = []\n            for frame in self.unknown_frames:\n                try:\n                    name, size, flags = unpack('>4sLH', frame[:10])\n                    frame = BinaryFrame.fromData(self, flags, frame[10:])\n                except (struct.error, error):\n                    continue\n                name = name.decode('ascii')\n                converted.append(self.__save_frame(frame, name=name))\n            self.unknown_frames[:] = converted\n            self.__unknown_version = self._V24\n\n        # TDAT, TYER, and TIME have been turned into TDRC.\n        try:\n            date = text_type(self.get(\"TYER\", \"\"))\n            if date.strip(u\"\\x00\"):\n                self.pop(\"TYER\")\n                dat = text_type(self.get(\"TDAT\", \"\"))\n                if dat.strip(\"\\x00\"):\n                    self.pop(\"TDAT\")\n                    date = \"%s-%s-%s\" % (date, dat[2:], dat[:2])\n                    time = text_type(self.get(\"TIME\", \"\"))\n                    if time.strip(\"\\x00\"):\n                        self.pop(\"TIME\")\n                        date += \"T%s:%s:00\" % (time[:2], time[2:])\n                if \"TDRC\" not in self:\n                    self.add(TDRC(encoding=0, text=date))\n        except UnicodeDecodeError:\n            # Old ID3 tags have *lots* of Unicode problems, so if TYER\n            # is bad, just chuck the frames.\n            pass\n\n        # TORY can be the first part of a TDOR.\n        if \"TORY\" in self:\n            f = self.pop(\"TORY\")\n            if \"TDOR\" not in self:\n                try:\n                    self.add(TDOR(encoding=0, text=str(f)))\n                except UnicodeDecodeError:\n                    pass\n\n        # IPLS is now TIPL.\n        if \"IPLS\" in self:\n            f = self.pop(\"IPLS\")\n            if \"TIPL\" not in self:\n                self.add(TIPL(encoding=f.encoding, people=f.people))\n\n        # These can't be trivially translated to any ID3v2.4 tags, or\n        # should have been removed already.\n        for key in [\"RVAD\", \"EQUA\", \"TRDA\", \"TSIZ\", \"TDAT\", \"TIME\", \"CRM\"]:\n            if key in self:\n                del(self[key])", "response": "Convert old ID3v2. 4 tags into an ID3v2. 4 tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_to_v23(self):\n\n        self.__update_common()\n\n        # we could downgrade unknown v2.4 frames here, but given that\n        # the main reason to save v2.3 is compatibility and this\n        # might increase the chance of some parser breaking.. better not\n\n        # TMCL, TIPL -> TIPL\n        if \"TIPL\" in self or \"TMCL\" in self:\n            people = []\n            if \"TIPL\" in self:\n                f = self.pop(\"TIPL\")\n                people.extend(f.people)\n            if \"TMCL\" in self:\n                f = self.pop(\"TMCL\")\n                people.extend(f.people)\n            if \"IPLS\" not in self:\n                self.add(IPLS(encoding=f.encoding, people=people))\n\n        # TDOR -> TORY\n        if \"TDOR\" in self:\n            f = self.pop(\"TDOR\")\n            if f.text:\n                d = f.text[0]\n                if d.year and \"TORY\" not in self:\n                    self.add(TORY(encoding=f.encoding, text=\"%04d\" % d.year))\n\n        # TDRC -> TYER, TDAT, TIME\n        if \"TDRC\" in self:\n            f = self.pop(\"TDRC\")\n            if f.text:\n                d = f.text[0]\n                if d.year and \"TYER\" not in self:\n                    self.add(TYER(encoding=f.encoding, text=\"%04d\" % d.year))\n                if d.month and d.day and \"TDAT\" not in self:\n                    self.add(TDAT(encoding=f.encoding,\n                                  text=\"%02d%02d\" % (d.day, d.month)))\n                if d.hour and d.minute and \"TIME\" not in self:\n                    self.add(TIME(encoding=f.encoding,\n                                  text=\"%02d%02d\" % (d.hour, d.minute)))\n\n        # New frames added in v2.4\n        v24_frames = [\n            'ASPI', 'EQU2', 'RVA2', 'SEEK', 'SIGN', 'TDEN', 'TDOR',\n            'TDRC', 'TDRL', 'TDTG', 'TIPL', 'TMCL', 'TMOO', 'TPRO',\n            'TSOA', 'TSOP', 'TSOT', 'TSST',\n        ]\n\n        for key in v24_frames:\n            if key in self:\n                del(self[key])", "response": "Convert older and newer tags into an ID3v2. 3 tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads stream and tag information from a file.", "response": "def load(self, filename, ID3=None, **kwargs):\n        \"\"\"Load stream and tag information from a file.\n\n        A custom tag reader may be used in instead of the default\n        mutagen.id3.ID3 object, e.g. an EasyID3 reader.\n        \"\"\"\n\n        if ID3 is None:\n            ID3 = self.ID3\n        else:\n            # If this was initialized with EasyID3, remember that for\n            # when tags are auto-instantiated in add_tags.\n            self.ID3 = ID3\n        self.filename = filename\n        try:\n            self.tags = ID3(filename, **kwargs)\n        except error:\n            self.tags = None\n        if self.tags is not None:\n            try:\n                offset = self.tags.size\n            except AttributeError:\n                offset = None\n        else:\n            offset = None\n        try:\n            fileobj = open(filename, \"rb\")\n            self.info = self._Info(fileobj, offset)\n        finally:\n            fileobj.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unload(self):\n        '''Release all resources associated with the sound.'''\n        if self._handle != -1:\n            lib.UnloadSound(self._handle)\n            self._handle = -1", "response": "Release all resources associated with the sound."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplaying the sound as a one - shot.", "response": "def play(self, gain=None, pan=None, pitch=None):\n        '''Play the sound as a `one-shot`.\n\n        The sound will be played to completion.  If the sound is played more than once at a time, it will mix\n        with all previous instances of itself.  If you need more control over the playback of sounds, see\n        :class:`Voice`.\n\n        :param gain: optional volume level to play the sound back at, between 0.0 and 1.0 (defaults to 1.0)\n        :param pan: optional stereo pan, between -1.0 (left) and 1.0 (right)\n        :param pitch: optional sampling rate modification, between 0.4 and 16.0, where 1.0 represents the original pitch\n        '''\n        if gain is None and pan is None and pitch is None:\n            lib.PlaySound(self._handle)\n        else:\n            voice = Voice(self)\n            if gain is not None:\n                voice.gain = gain\n            if pan is not None:\n                voice.pan = pan\n            if pitch is not None:\n                voice.pitch = pitch\n            voice.play()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_loop_points(self, start_sample=-1, end_sample=0):\n        '''Set the loop points within the sound.\n\n        The sound must have been created with ``loop=True``.  The default parameters cause the loop points to be set to\n        the entire sound duration.\n\n        :note: There is currently no API for converting sample numbers to times.\n        :param start_sample: sample number to loop back to\n        :param end_sample: sample number to loop at\n        '''\n        lib.SetVoiceLoopPoints(self._handle, start_sample, end_sample)", "response": "Set the loop points within the sound."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_hosted_zones_parser(root, connection):\n\n    # The rest of the list pagination tags are handled higher up in the stack.\n    # We'll just worry about the HostedZones tag, which has HostedZone tags\n    # nested beneath it.\n    zones = root.find('./{*}HostedZones')\n\n    for zone in zones:\n        yield parse_hosted_zone(zone, connection)", "response": "Parses the API responses for the\n    :py : meth : Route53Connection. list_hosted_zones method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the list of glyph names and their unicode values", "response": "def adobe_glyph_values():\n  \"\"\"return the list of glyph names and their unicode values\"\"\"\n\n  lines  = string.split( adobe_glyph_list, '\\n' )\n  glyphs = []\n  values = []\n\n  for line in lines:\n    if line:\n      fields = string.split( line, ';' )\n#     print fields[1] + ' - ' + fields[0]\n      subfields = string.split( fields[1], ' ' )\n      if len( subfields ) == 1:\n        glyphs.append( fields[0] )\n        values.append( fields[1] )\n\n  return glyphs, values"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filter_glyph_names( alist, filter ):\n\n  count  = 0\n  extras = []\n\n  for name in alist:\n    try:\n      filtered_index = filter.index( name )\n    except:\n      extras.append( name )\n\n  return extras", "response": "filter alist by taking out all glyph names that are in filter"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping a given encoding", "response": "def dump_encoding( file, encoding_name, encoding_list ):\n  \"\"\"dump a given encoding\"\"\"\n\n  write = file.write\n  write( \"  /* the following are indices into the SID name table */\\n\" )\n  write( \"  static const unsigned short  \" + encoding_name +\n         \"[\" + repr( len( encoding_list ) ) + \"] =\\n\" )\n  write( \"  {\\n\" )\n\n  line  = \"    \"\n  comma = \"\"\n  col   = 0\n  for value in encoding_list:\n    line += comma\n    line += \"%3d\" % value\n    comma = \",\"\n    col  += 1\n    if col == 16:\n      col = 0\n      comma = \",\\n    \"\n\n  write( line + \"\\n  };\\n\\n\\n\" )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dump_array( the_array, write, array_name ):\n\n  write( \"  static const unsigned char  \" + array_name +\n         \"[\" + repr( len( the_array ) ) + \"L] =\\n\" )\n  write( \"  {\\n\" )\n\n  line  = \"\"\n  comma = \"    \"\n  col   = 0\n\n  for value in the_array:\n    line += comma\n    line += \"%3d\" % ord( value )\n    comma = \",\"\n    col  += 1\n\n    if col == 16:\n      col   = 0\n      comma = \",\\n    \"\n\n    if len( line ) > 1024:\n      write( line )\n      line = \"\"\n\n  write( line + \"\\n  };\\n\\n\\n\" )", "response": "dumps a given encoding"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef  file_exists( pathname ):\n    result = 1\n    try:\n        file = open( pathname, \"r\" )\n        file.close()\n    except:\n        result = None\n        sys.stderr.write( pathname + \" couldn't be accessed\\n\" )\n\n    return result", "response": "checks that a given file exists"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a list of input files from command - line arguments", "response": "def  make_file_list( args = None ):\n    \"\"\"builds a list of input files from command-line arguments\"\"\"\n    file_list = []\n    # sys.stderr.write( repr( sys.argv[1 :] ) + '\\n' )\n\n    if not args:\n        args = sys.argv[1 :]\n\n    for pathname in args:\n        if string.find( pathname, '*' ) >= 0:\n            newpath = glob.glob( pathname )\n            newpath.sort()  # sort files -- this is important because\n                            # of the order of files\n        else:\n            newpath = [pathname]\n\n        file_list.extend( newpath )\n\n    if len( file_list ) == 0:\n        file_list = None\n    else:\n        # now filter the file list to remove non-existing ones\n        file_list = filter( file_exists, file_list )\n\n    return file_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a DelegationSet element and populates the zone.", "response": "def parse_delegation_set(zone, e_delegation_set):\n    \"\"\"\n    Parses a DelegationSet tag. These often accompany HostedZone tags in\n    responses like CreateHostedZone and GetHostedZone.\n\n    :param HostedZone zone: An existing HostedZone instance to populate.\n    :param lxml.etree._Element e_delegation_set: A DelegationSet element.\n    \"\"\"\n\n    e_nameservers = e_delegation_set.find('./{*}NameServers')\n\n    nameservers = []\n    for e_nameserver in e_nameservers:\n        nameservers.append(e_nameserver.text)\n\n    zone._nameservers = nameservers"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef writeblocks(blocks):\n        data = []\n        codes = [[block.code, block.write()] for block in blocks]\n        codes[-1][0] |= 128\n        for code, datum in codes:\n            byte = chr_(code)\n            if len(datum) > 2**24:\n                raise error(\"block is too long to write\")\n            length = struct.pack(\">I\", len(datum))[-3:]\n            data.append(byte + length + datum)\n        return b\"\".join(data)", "response": "Render metadata blocks as a byte string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconsolidates FLAC padding metadata blocks.", "response": "def group_padding(blocks):\n        \"\"\"Consolidate FLAC padding metadata blocks.\n\n        The overall size of the rendered blocks does not change, so\n        this adds several bytes of padding for each merged block.\n        \"\"\"\n\n        paddings = [b for b in blocks if isinstance(b, Padding)]\n        for p in paddings:\n            blocks.remove(p)\n        # total padding size is the sum of padding sizes plus 4 bytes\n        # per removed header.\n        size = sum(padding.length for padding in paddings)\n        padding = Padding()\n        padding.length = size + 4 * (len(paddings) - 1)\n        blocks.append(padding)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, filename=None):\n        if filename is None:\n            filename = self.filename\n        for s in list(self.metadata_blocks):\n            if isinstance(s, VCFLACDict):\n                self.metadata_blocks.remove(s)\n                self.tags = None\n                self.save()\n                break", "response": "Remove Vorbis comments from a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(self, filename):\n\n        self.metadata_blocks = []\n        self.tags = None\n        self.cuesheet = None\n        self.seektable = None\n        self.filename = filename\n        fileobj = StrictFileObject(open(filename, \"rb\"))\n        try:\n            self.__check_header(fileobj)\n            while self.__read_metadata_block(fileobj):\n                pass\n        finally:\n            fileobj.close()\n\n        try:\n            self.metadata_blocks[0].length\n        except (AttributeError, IndexError):\n            raise FLACNoHeaderError(\"Stream info block not found\")", "response": "Load file information from a filename."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave the metadata blocks to a file.", "response": "def save(self, filename=None, deleteid3=False):\n        \"\"\"Save metadata blocks to a file.\n\n        If no filename is given, the one most recently loaded is used.\n        \"\"\"\n\n        if filename is None:\n            filename = self.filename\n        f = open(filename, 'rb+')\n\n        try:\n            # Ensure we've got padding at the end, and only at the end.\n            # If adding makes it too large, we'll scale it down later.\n            self.metadata_blocks.append(Padding(b'\\x00' * 1020))\n            MetadataBlock.group_padding(self.metadata_blocks)\n\n            header = self.__check_header(f)\n            # \"fLaC\" and maybe ID3\n            available = self.__find_audio_offset(f) - header\n            data = MetadataBlock.writeblocks(self.metadata_blocks)\n\n            # Delete ID3v2\n            if deleteid3 and header > 4:\n                available += header - 4\n                header = 4\n\n            if len(data) > available:\n                # If we have too much data, see if we can reduce padding.\n                padding = self.metadata_blocks[-1]\n                newlength = padding.length - (len(data) - available)\n                if newlength > 0:\n                    padding.length = newlength\n                    data = MetadataBlock.writeblocks(self.metadata_blocks)\n                    assert len(data) == available\n\n            elif len(data) < available:\n                # If we have too little data, increase padding.\n                self.metadata_blocks[-1].length += (available - len(data))\n                data = MetadataBlock.writeblocks(self.metadata_blocks)\n                assert len(data) == available\n\n            if len(data) != available:\n                # We couldn't reduce the padding enough.\n                diff = (len(data) - available)\n                insert_bytes(f, diff, header)\n\n            f.seek(header - 4)\n            f.write(b\"fLaC\" + data)\n\n            # Delete ID3v1\n            if deleteid3:\n                try:\n                    f.seek(-128, 2)\n                except IOError:\n                    pass\n                else:\n                    if f.read(3) == b\"TAG\":\n                        f.seek(-128, 2)\n                        f.truncate()\n        finally:\n            f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses an Alias tag beneath a ResourceRecordSet and returns the two values .", "response": "def parse_rrset_alias(e_alias):\n    \"\"\"\n    Parses an Alias tag beneath a ResourceRecordSet, spitting out the two values\n    found within. This is specific to A records that are set to Alias.\n\n    :param lxml.etree._Element e_alias: An Alias tag beneath a ResourceRecordSet.\n    :rtype: tuple\n    :returns: A tuple in the form of ``(alias_hosted_zone_id, alias_dns_name)``.\n    \"\"\"\n\n    alias_hosted_zone_id = e_alias.find('./{*}HostedZoneId').text\n    alias_dns_name = e_alias.find('./{*}DNSName').text\n    return alias_hosted_zone_id, alias_dns_name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_rrset_record_values(e_resource_records):\n\n    records = []\n\n    for e_record in e_resource_records:\n        for e_value in e_record:\n            records.append(e_value.text)\n\n    return records", "response": "Used to parse the various Values from the ResourceRecords tags on\n    most rrset types."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the API responses for the method.", "response": "def list_resource_record_sets_by_zone_id_parser(e_root, connection, zone_id):\n    \"\"\"\n    Parses the API responses for the\n    :py:meth:`route53.connection.Route53Connection.list_resource_record_sets_by_zone_id`\n    method.\n\n    :param lxml.etree._Element e_root: The root node of the etree parsed\n        response from the API.\n    :param Route53Connection connection: The connection instance used to\n        query the API.\n    :param str zone_id: The zone ID of the HostedZone these rrsets belong to.\n    :rtype: ResourceRecordSet\n    :returns: A generator of fully formed ResourceRecordSet instances.\n    \"\"\"\n\n    # The rest of the list pagination tags are handled higher up in the stack.\n    # We'll just worry about the ResourceRecordSets tag, which has\n    # ResourceRecordSet tags nested beneath it.\n    e_rrsets = e_root.find('./{*}ResourceRecordSets')\n\n    for e_rrset in e_rrsets:\n        yield parse_rrset(e_rrset, connection, zone_id)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nameservers(self):\n\n        # If this HostedZone was instantiated by ListHostedZones, the nameservers\n        # attribute didn't get populated. If the user requests it, we'll\n        # lazy load by querying it in after the fact. It's safe to cache like\n        # this since  these nameserver values won't change.\n        if not self._nameservers:\n            # We'll just snatch the nameserver values from a fresh copy\n            # via GetHostedZone.\n            hosted_zone = self.connection.get_hosted_zone_by_id(self.id)\n            self._nameservers = hosted_zone._nameservers\n\n        return self._nameservers", "response": "Returns a list of nameserver strings for this Hosted Zone."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete this Hosted Zone.", "response": "def delete(self, force=False):\n        \"\"\"\n        Deletes this hosted zone. After this method is ran, you won't be able\n        to add records, or do anything else with the zone. You'd need to\n        re-create it, as zones are read-only after creation.\n\n        :keyword bool force: If ``True``, delete the\n            :py:class:`HostedZone <route53.hosted_zone.HostedZone>`, even if it\n            means nuking all associated record sets. If ``False``, an\n            exception is raised if this\n            :py:class:`HostedZone <route53.hosted_zone.HostedZone>`\n            has record sets.\n        :rtype: dict\n        :returns: A dict of change info, which contains some details about\n            the request.\n        \"\"\"\n\n        self._halt_if_already_deleted()\n\n        if force:\n            # Forcing deletion by cleaning up all record sets first. We'll\n            # do it all in one change set.\n            cset = ChangeSet(connection=self.connection, hosted_zone_id=self.id)\n\n            for rrset in self.record_sets:\n                # You can delete a HostedZone if there are only SOA and NS\n                # entries left. So delete everything but SOA/NS entries.\n                if rrset.rrset_type not in ['SOA', 'NS']:\n                    cset.add_change('DELETE', rrset)\n\n            if cset.deletions or cset.creations:\n                # Bombs away.\n                self.connection._change_resource_record_sets(cset)\n\n        # Now delete the HostedZone.\n        retval = self.connection.delete_hosted_zone_by_id(self.id)\n\n        # Used to protect against modifying a deleted HostedZone.\n        self._is_deleted = True\n\n        return retval"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_record(self, record_set_class, name, values, ttl=60, weight=None,\n                    region=None,set_identifier=None, alias_hosted_zone_id=None,\n                    alias_dns_name=None):\n        \"\"\"\n        Convenience method for creating ResourceRecordSets. Most of the calls\n        are basically the same, this saves on repetition.\n\n        :rtype: tuple\n        :returns: A tuple in the form of ``(rrset, change_info)``, where\n            ``rrset`` is the newly created ResourceRecordSet sub-class\n             instance.\n        \"\"\"\n\n        self._halt_if_already_deleted()\n\n        rrset_kwargs = dict(\n            connection=self.connection,\n            zone_id=self.id,\n            name=name,\n            ttl=ttl,\n            records=values,\n            weight=weight,\n            region=region,\n            set_identifier=set_identifier,\n            )\n\n        if alias_hosted_zone_id or alias_dns_name:\n            rrset_kwargs.update(dict(\n                alias_hosted_zone_id=alias_hosted_zone_id,\n                alias_dns_name=alias_dns_name\n            ))\n\n        rrset = record_set_class(**rrset_kwargs)\n\n        cset = ChangeSet(connection=self.connection, hosted_zone_id=self.id)\n        cset.add_change('CREATE', rrset)\n\n        change_info = self.connection._change_resource_record_sets(cset)\n\n        return rrset, change_info", "response": "Internal method to create a new ResourceRecordSet and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates and returns an A record.", "response": "def create_a_record(self, name, values, ttl=60, weight=None, region=None,\n                     set_identifier=None, alias_hosted_zone_id=None,\n                     alias_dns_name=None):\n        \"\"\"\n        Creates and returns an A record attached to this hosted zone.\n\n        :param str name: The fully qualified name of the record to add.\n        :param list values: A list of value strings for the record.\n        :keyword int ttl: The time-to-live of the record (in seconds).\n        :keyword int weight: *For weighted record sets only*. Among resource record\n            sets that have the same combination of DNS name and type, a value\n            that determines what portion of traffic for the current resource\n            record set is routed to the associated location. Ranges from 0-255.\n        :keyword str region: *For latency-based record sets*. The Amazon EC2 region\n            where the resource that is specified in this resource record set\n            resides.\n        :keyword str set_identifier: *For weighted and latency resource record\n            sets only*. An identifier that differentiates among multiple\n            resource record sets that have the same combination of DNS name\n            and type. 1-128 chars.\n        :keyword str alias_hosted_zone_id: Alias A records have this specified.\n            It appears to be the hosted zone ID for the ELB the Alias points at.\n        :keyword str alias_dns_name: Alias A records have this specified. It is\n            the DNS name for the ELB that the Alias points to.\n        :rtype: tuple\n        :returns: A tuple in the form of ``(rrset, change_info)``, where\n            ``rrset`` is the newly created\n            :py:class:`AResourceRecordSet <route53.resource_record_set.AResourceRecordSet>`\n            instance.\n        \"\"\"\n\n        self._halt_if_already_deleted()\n\n        # Grab the params/kwargs here for brevity's sake.\n        values = locals()\n        del values['self']\n\n        return self._add_record(AResourceRecordSet, **values)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_aaaa_record(self, name, values, ttl=60, weight=None, region=None,\n                        set_identifier=None):\n        \"\"\"\n        Creates an AAAA record attached to this hosted zone.\n\n        :param str name: The fully qualified name of the record to add.\n        :param list values: A list of value strings for the record.\n        :keyword int ttl: The time-to-live of the record (in seconds).\n        :keyword int weight: *For weighted record sets only*. Among resource record\n            sets that have the same combination of DNS name and type, a value\n            that determines what portion of traffic for the current resource\n            record set is routed to the associated location. Ranges from 0-255.\n        :keyword str region: *For latency-based record sets*. The Amazon EC2 region\n            where the resource that is specified in this resource record set\n            resides.\n        :keyword str set_identifier: *For weighted and latency resource record\n            sets only*. An identifier that differentiates among multiple\n            resource record sets that have the same combination of DNS name\n            and type. 1-128 chars.\n        :rtype: tuple\n        :returns: A tuple in the form of ``(rrset, change_info)``, where\n            ``rrset`` is the newly created AAAAResourceRecordSet instance.\n        \"\"\"\n\n        self._halt_if_already_deleted()\n\n        # Grab the params/kwargs here for brevity's sake.\n        values = locals()\n        del values['self']\n\n        return self._add_record(AAAAResourceRecordSet, **values)", "response": "Creates an AAAA record."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_cname_record(self, name, values, ttl=60, weight=None, region=None,\n                           set_identifier=None):\n        \"\"\"\n        Creates a CNAME record attached to this hosted zone.\n\n        :param str name: The fully qualified name of the record to add.\n        :param list values: A list of value strings for the record.\n        :keyword int ttl: The time-to-live of the record (in seconds).\n        :keyword int weight: *For weighted record sets only*. Among resource record\n            sets that have the same combination of DNS name and type, a value\n            that determines what portion of traffic for the current resource\n            record set is routed to the associated location. Ranges from 0-255.\n        :keyword str region: *For latency-based record sets*. The Amazon EC2 region\n            where the resource that is specified in this resource record set\n            resides.\n        :keyword str set_identifier: *For weighted and latency resource record\n            sets only*. An identifier that differentiates among multiple\n            resource record sets that have the same combination of DNS name\n            and type. 1-128 chars.\n        :rtype: tuple\n        :returns: A tuple in the form of ``(rrset, change_info)``, where\n            ``rrset`` is the newly created CNAMEResourceRecordSet instance.\n        \"\"\"\n\n        self._halt_if_already_deleted()\n\n        # Grab the params/kwargs here for brevity's sake.\n        values = locals()\n        del values['self']\n\n        return self._add_record(CNAMEResourceRecordSet, **values)", "response": "Creates a new CNAME record."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_mx_record(self, name, values, ttl=60):\n\n        self._halt_if_already_deleted()\n\n        # Grab the params/kwargs here for brevity's sake.\n        values = locals()\n        del values['self']\n\n        return self._add_record(MXResourceRecordSet, **values)", "response": "Creates a MX record attached to this hosted zone."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_ns_record(self, name, values, ttl=60):\n\n        self._halt_if_already_deleted()\n\n        # Grab the params/kwargs here for brevity's sake.\n        values = locals()\n        del values['self']\n\n        return self._add_record(NSResourceRecordSet, **values)", "response": "Creates a new NS record."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_ptr_record(self, name, values, ttl=60):\n\n        self._halt_if_already_deleted()\n\n        # Grab the params/kwargs here for brevity's sake.\n        values = locals()\n        del values['self']\n\n        return self._add_record(PTRResourceRecordSet, **values)", "response": "Creates a PTR record attached to this hosted zone."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new SPF record.", "response": "def create_spf_record(self, name, values, ttl=60):\n        \"\"\"\n        Creates a SPF record attached to this hosted zone.\n\n        :param str name: The fully qualified name of the record to add.\n        :param list values: A list of value strings for the record.\n        :keyword int ttl: The time-to-live of the record (in seconds).\n        :rtype: tuple\n        :returns: A tuple in the form of ``(rrset, change_info)``, where\n            ``rrset`` is the newly created SPFResourceRecordSet instance.\n        \"\"\"\n\n        self._halt_if_already_deleted()\n\n        # Grab the params/kwargs here for brevity's sake.\n        values = locals()\n        del values['self']\n\n        return self._add_record(SPFResourceRecordSet, **values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_srv_record(self, name, values, ttl=60):\n\n        self._halt_if_already_deleted()\n\n        # Grab the params/kwargs here for brevity's sake.\n        values = locals()\n        del values['self']\n\n        return self._add_record(SRVResourceRecordSet, **values)", "response": "Creates a SRV record attached to this hosted zone."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a TXT record for the specified hosted zone.", "response": "def create_txt_record(self, name, values, ttl=60, weight=None, region=None,\n                          set_identifier=None):\n        \"\"\"\n        Creates a TXT record attached to this hosted zone.\n\n        :param str name: The fully qualified name of the record to add.\n        :param list values: A list of value strings for the record.\n        :keyword int ttl: The time-to-live of the record (in seconds).\n        :keyword int weight: *For weighted record sets only*. Among resource record\n            sets that have the same combination of DNS name and type, a value\n            that determines what portion of traffic for the current resource\n            record set is routed to the associated location. Ranges from 0-255.\n        :keyword str region: *For latency-based record sets*. The Amazon EC2 region\n            where the resource that is specified in this resource record set\n            resides.\n        :keyword str set_identifier: *For weighted and latency resource record\n            sets only*. An identifier that differentiates among multiple\n            resource record sets that have the same combination of DNS name\n            and type. 1-128 chars.\n        :rtype: tuple\n        :returns: A tuple in the form of ``(rrset, change_info)``, where\n            ``rrset`` is the newly created TXTResourceRecordSet instance.\n        \"\"\"\n\n        self._halt_if_already_deleted()\n\n        # Grab the params/kwargs here for brevity's sake.\n        values = locals()\n        del values['self']\n\n        return self._add_record(TXTResourceRecordSet, **values)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef RegisterTXXXKey(cls, key, desc):\n        frameid = \"TXXX:\" + desc\n\n        def getter(id3, key):\n            return list(id3[frameid])\n\n        def setter(id3, key, value):\n            try:\n                frame = id3[frameid]\n            except KeyError:\n                enc = 0\n                # Store 8859-1 if we can, per MusicBrainz spec.\n                try:\n                    for v in value:\n                        v.encode('latin_1')\n                except UnicodeError:\n                    enc = 3\n\n                id3.add(mutagen.id3.TXXX(encoding=enc, text=value, desc=desc))\n            else:\n                frame.text = value\n\n        def deleter(id3, key):\n            del(id3[frameid])\n\n        cls.RegisterKey(key, getter, setter, deleter)", "response": "Register a user - defined text frame key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_change_values(change):\n\n    action, rrset = change\n\n    if action == 'CREATE':\n        # For creations, we want the current values, since they don't need to\n        # match an existing record set.\n        values = dict()\n        for key, val in rrset._initial_vals.items():\n            # Pull from the record set's attributes, which are the current\n            # values.\n            values[key] = getattr(rrset, key)\n        return values\n    else:\n        # We can look at the initial values dict for deletions, since we\n        # have to match against the values currently in Route53.\n        return rrset._initial_vals", "response": "Get the change values for the current record set."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_change(change):\n\n    action, rrset = change\n\n    change_vals = get_change_values(change)\n\n    e_change = etree.Element(\"Change\")\n\n    e_action = etree.SubElement(e_change, \"Action\")\n    e_action.text = action\n\n    e_rrset = etree.SubElement(e_change, \"ResourceRecordSet\")\n\n    e_name = etree.SubElement(e_rrset, \"Name\")\n    e_name.text = change_vals['name']\n\n    e_type = etree.SubElement(e_rrset, \"Type\")\n    e_type.text = rrset.rrset_type\n\n    if change_vals.get('set_identifier'):\n        e_set_id = etree.SubElement(e_rrset, \"SetIdentifier\")\n        e_set_id.text = change_vals['set_identifier']\n\n    if change_vals.get('weight'):\n        e_weight = etree.SubElement(e_rrset, \"Weight\")\n        e_weight.text = change_vals['weight']\n\n    if change_vals.get('alias_hosted_zone_id') or change_vals.get('alias_dns_name'):\n        e_alias_target = etree.SubElement(e_rrset, \"AliasTarget\")\n\n        e_hosted_zone_id = etree.SubElement(e_alias_target, \"HostedZoneId\")\n        e_hosted_zone_id.text = change_vals['alias_hosted_zone_id']\n        e_dns_name = etree.SubElement(e_alias_target, \"DNSName\")\n        e_dns_name.text = change_vals['alias_dns_name']\n\n    if change_vals.get('region'):\n        e_weight = etree.SubElement(e_rrset, \"Region\")\n        e_weight.text = change_vals['region']\n\n    e_ttl = etree.SubElement(e_rrset, \"TTL\")\n    e_ttl.text = str(change_vals['ttl'])\n\n    if rrset.is_alias_record_set():\n        # A record sets in Alias mode don't have any resource records.\n        return e_change\n\n    e_resource_records = etree.SubElement(e_rrset, \"ResourceRecords\")\n\n    for value in change_vals['records']:\n        e_resource_record = etree.SubElement(e_resource_records, \"ResourceRecord\")\n        e_value = etree.SubElement(e_resource_record, \"Value\")\n        e_value.text = value\n\n    return e_change", "response": "Writes a Change to the XML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef change_resource_record_set_writer(connection, change_set, comment=None):\n\n    e_root = etree.Element(\n        \"ChangeResourceRecordSetsRequest\",\n        xmlns=connection._xml_namespace\n    )\n\n    e_change_batch = etree.SubElement(e_root, \"ChangeBatch\")\n\n    if comment:\n        e_comment = etree.SubElement(e_change_batch, \"Comment\")\n        e_comment.text = comment\n\n    e_changes = etree.SubElement(e_change_batch, \"Changes\")\n\n    # Deletions need to come first in the change sets.\n    for change in change_set.deletions + change_set.creations:\n        e_changes.append(write_change(change))\n\n    e_tree = etree.ElementTree(element=e_root)\n\n    #print(prettyprint_xml(e_root))\n\n    fobj = BytesIO()\n    # This writes bytes.\n    e_tree.write(fobj, xml_declaration=True, encoding='utf-8', method=\"xml\")\n    return fobj.getvalue().decode('utf-8')", "response": "This function creates a new change resource record set request."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_integer(self, action, index, value_if_allowed, prior_value,\n                         text, validation_type, trigger_type, widget_name):\n        \"\"\"Check if text Entry is valid (number).\n\n        I have no idea what all these arguments are doing here but took this from\n        https://stackoverflow.com/questions/8959815/restricting-the-value-in-tkinter-entry-widget\n        \"\"\"\n        if(action == '1'):\n            if text in '0123456789.-+':\n                try:\n                    int(value_if_allowed)\n                    return True\n                except ValueError:\n                    return False\n            else:\n                return False\n        else:\n            return True", "response": "Check if text Entry is valid integer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef alias_item(self, alias):\n        ident = self.alias[alias]\n        return self.items[ident]", "response": "Gets an item by its alias."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfreeze dict into tuple.", "response": "def freeze_dict(dict_):\n    \"\"\"Freezes ``dict`` into ``tuple``.\n\n    A typical usage is packing ``dict`` into hashable.\n\n    e.g.::\n\n        >>> freeze_dict({'a': 1, 'b': 2})\n        (('a', 1), ('b', 2))\n    \"\"\"\n    pairs = dict_.items()\n    key_getter = operator.itemgetter(0)\n    return tuple(sorted(pairs, key=key_getter))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\njoining the map structure into HTML attributes.", "response": "def join_html_attrs(attrs):\n    \"\"\"Joins the map structure into HTML attributes.\n\n    The return value is a 2-tuple ``(template, ordered_values)``. It should be\n    passed into :class:`markupsafe.Markup` to prevent XSS attacked.\n\n    e.g.::\n\n        >>> join_html_attrs({'href': '/', 'data-active': 'true'})\n        ('data-active=\"{0}\" href=\"{1}\"', ['true', '/'])\n    \"\"\"\n    attrs = collections.OrderedDict(freeze_dict(attrs or {}))\n    template = ' '.join('%s=\"{%d}\"' % (k, i) for i, k in enumerate(attrs))\n    return template, list(attrs.values())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init_app(self, app):\n        # connects app-level signals\n        appcontext_pushed.connect(self.initialize_bars, app)\n        # integrate with jinja template\n        app.add_template_global(self, 'nav')", "response": "Initializes an app to work with this extension."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef initialize_bars(self, sender=None, **kwargs):\n        for bar in self.bars.values():\n            for initializer in bar.initializers:\n                initializer(self)", "response": "Calls the initializers of all bound navigation bars."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bind_bar(self, sender=None, **kwargs):\n        bar = kwargs.pop('bar')\n        self.bars[bar.name] = bar", "response": "Binds a navigation bar into this extension instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef url(self):\n        if self.is_internal:\n            return url_for(self.endpoint, **self.args)\n        return self._url", "response": "The final url of this navigation item."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntrues if the current request has the same endpoint with the item.", "response": "def is_current(self):\n        \"\"\"``True`` if current request has same endpoint with the item.\n\n        The property should be used in a bound request context, or the\n        :class:`RuntimeError` may be raised.\n        \"\"\"\n        if not self.is_internal:\n            return False  # always false for external url\n        has_same_endpoint = (request.endpoint == self.endpoint)\n        has_same_args = (request.view_args == self.args)\n        return has_same_endpoint and has_same_args"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef config_path(self, value):\n        self._config_path = value or ''\n        if not isinstance(self._config_path, str):\n            raise BadArgumentError(\"config_path must be string: {}\".format(\n                self._config_path))", "response": "Set the config_path of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dictionary(self, value):\n        self._dictionary = value or {}\n        if not isinstance(self._dictionary, dict):\n            raise BadArgumentError(\"dictionary must be dict: {}\".format(\n                self._dictionary))", "response": "Set the dictionary of the user s account."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef api_options(self):\n        options = 0\n        if self._ignore_uppercase:\n            options |= 1\n        if self._ignore_digits:\n            options |= 2\n        if self._ignore_urls:\n            options |= 4\n        if self._find_repeat_words:\n            options |= 8\n        if self._ignore_latin:\n            options |= 16\n        if self._flag_latin:\n            options |= 128\n        if self._by_words:\n            options |= 256\n        if self._ignore_capitalization:\n            options |= 512\n        if self._ignore_roman_numerals:\n            options |= 2048\n        return options", "response": "returns the current api options as a bitmask"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates that the metric class is valid.", "response": "def validate(metric_class):\n    \"\"\"\n    Does basic Metric option validation. \n    \"\"\"\n    if not hasattr(metric_class, 'label'):\n        raise ImproperlyConfigured(\"No 'label' attribute found for metric %s.\" % metric_class.__name__)\n    \n    if not hasattr(metric_class, 'widget'):\n        raise ImproperlyConfigured(\"No 'widget' attribute found for metric %s.\" % metric_class.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_statistic_by_name(stat_name):\n\n    if stat_name == 'ALL':\n        return get_statistic_models()\n\n    for stat in get_statistic_models():\n        if stat.__name__ == stat_name:\n            return stat\n\n    raise Exception, _(\"%(stat)s cannot be found.\") % {'stat': stat_name}", "response": "Returns a stat object based on the given class name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calculate_statistics(stat, frequencies):\n    stats = ensure_list(stat)\n    frequencies = ensure_list(frequencies)\n\n    for stat in stats:\n        for f in frequencies:\n            print \"Calculating %s (%s)...\" % (stat.__name__, settings.STATISTIC_FREQUENCY_DICT[f])\n            stat.calculate(f)", "response": "Calculates all of the metrics associated with the registered gadgets."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresetting the specified statistic s data for the given frequency / ies.", "response": "def reset_statistics(stat, frequencies, reset_cumulative, recalculate=False):\n    \"\"\"\n    Resets the specified statistic's data (deletes it) for the given\n    frequency/ies.\n    \"\"\"\n\n    stats = ensure_list(stat)\n    frequencies = ensure_list(frequencies)\n\n    for s in stats:\n        for f in frequencies:\n            if not s.cumulative or reset_cumulative:\n                print \"Resetting %s (%s)...\" % (s.__name__, settings.STATISTIC_FREQUENCY_DICT[f])\n                s.objects.filter(frequency=f).delete()\n            elif s.cumulative and not reset_cumulative:\n                print \"Skipping %s because it is cumulative.\" % s.__name__\n\n    if recalculate:\n        print \"Recalculating statistics...\"\n        calculate_statistics(stats, frequencies)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef autodiscover():\n    from django.conf import settings\n    from django.utils.importlib import import_module\n    from django.utils.module_loading import module_has_submodule\n\n    for app in settings.INSTALLED_APPS:\n        mod = import_module(app)\n        # Attempt to import the app's gadgets module.\n        try:\n            import_module('%s.gadgets' % app)\n        except:\n            # Decide whether to bubble up this error. If the app just\n            # doesn't have a gadgets module, we can ignore the error\n            # attempting to import it, otherwise we want it to bubble up.\n            if module_has_submodule(mod, 'gadgets'):\n                raise", "response": "Auto - discover INSTALLED_APPS gadgets. py modules and fail silently when there is no gadgets module."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a CSV dump of all of the specified metric s counts and cumulative counts.", "response": "def csv_dump(request, uid):\n    \"\"\"\n    Returns a CSV dump of all of the specified metric's counts\n    and cumulative counts.\n    \"\"\"\n\n    metric = Metric.objects.get(uid=uid)\n    frequency = request.GET.get('frequency', settings.STATISTIC_FREQUENCY_DAILY)\n\n    response = HttpResponse(mimetype='text/csv')\n    response['Content-Disposition'] = 'attachment; filename=%s%s.csv' % (uid, datetime.datetime.now().strftime(\"%Y%m%d-%H%M\"))\n\n    writer = csv.writer(response)\n    writer.writerow([_('Date/time'), _('Count'), _('Cumulative count')])\n    for stat in metric.statistics.filter(frequency=frequency).order_by('date_time'):\n        writer.writerow([stat.date_time.strftime(settings.CSV_DATETIME_FORMAT), stat.count, stat.cumulative_count])\n\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calculate(cls, frequency=settings.STATISTIC_FREQUENCY_DAILY, verbose=settings.STATISTIC_CALCULATION_VERBOSE):\n        if verbose:\n            print _(\"Calculating statistics for %(class)s...\") % {'class': cls.get_label()}\n\n        start_datetime = None\n        end_datetime = None\n\n        # get the latest statistic\n        latest_stat = cls.get_latest(frequency)\n\n        # work out today's date, truncated to midnight\n        today = datetime.strptime(datetime.now().strftime(\"%Y %m %d\"), \"%Y %m %d\") \n        now = datetime.now()\n\n        # if this statistic only has cumulative stats available\n        if cls.cumulative:\n            if frequency == settings.STATISTIC_FREQUENCY_HOURLY:\n                # truncate to the nearest hour\n                start_datetime = datetime.strptime(now.strftime(\"%Y %m %d %H:00:00\"), \"%Y %m %d %H:%M:%S\")\n            elif frequency == settings.STATISTIC_FREQUENCY_DAILY:\n                start_datetime = today\n            elif frequency == settings.STATISTIC_FREQUENCY_WEEKLY:\n                # truncate today to the start of this week\n                start_datetime = datetime.strptime(today.strftime(\"%Y %W 0\"), \"%Y %W %w\")\n            elif frequency == settings.STATISTIC_FREQUENCY_MONTHLY:\n                # truncate today to the start of this month\n                start_datetime = datetime.strptime(today.strftime(\"%Y %m 1\"), \"%Y %m %d\")\n\n            stat, created = cls.objects.get_or_create(date_time=start_datetime, frequency=frequency)\n            stat.cumulative_count = cls.get_cumulative()\n            stat.count = (stat.cumulative_count-latest_stat.cumulative_count) if latest_stat else stat.cumulative_count\n        else:\n            # get the date/time at which we should start calculating\n            start_datetime = cls.get_start_datetime() if latest_stat is None else latest_stat.date_time\n            # truncate the start date/time to the appropriate frequency\n            if frequency == settings.STATISTIC_FREQUENCY_HOURLY:\n                start_datetime = datetime.strptime(start_datetime.strftime(\"%Y %m %d %H:00:00\"), \"%Y %m %d %H:%M:%S\")\n                end_datetime = start_datetime+timedelta(hours=1)\n            elif frequency == settings.STATISTIC_FREQUENCY_DAILY:\n                start_datetime = datetime.strptime(start_datetime.strftime(\"%Y %m %d\"), \"%Y %m %d\")\n                end_datetime = start_datetime+timedelta(days=1)\n            elif frequency == settings.STATISTIC_FREQUENCY_WEEKLY:\n                # start at the beginning of the week of the latest stat\n                start_datetime = datetime.strptime(start_datetime.strftime(\"%Y %W 0\"), \"%Y %W %w\")-timedelta(days=7)\n                end_datetime = start_datetime+timedelta(days=7)\n            elif frequency == settings.STATISTIC_FREQUENCY_MONTHLY:\n                # start at the beginning of the month of the latest stat\n                start_datetime = datetime.strptime(start_datetime.strftime(\"%Y %m 1\"), \"%Y %m %d\")\n                end_datetime = datetime.strptime((start_datetime+timedelta(days=33)).strftime(\"%Y %m 1\"), \"%Y %m %d\")\n\n            # if we're doing the normal count\n            while start_datetime < now:\n                count = cls.get_count(start_datetime, end_datetime)\n                cumulative_count = 0\n                if isinstance(count, tuple):\n                    cumulative_count = count[1]\n                    count = count[0]\n                else:\n                    cumulative_count = (latest_stat.cumulative_count+count) if latest_stat else count\n\n                stat, created = cls.objects.get_or_create(date_time=start_datetime, frequency=frequency)\n                stat.count = count\n                stat.cumulative_count = cumulative_count\n                stat.save()\n\n                latest_stat = stat\n\n                # update the dates/time window\n                start_datetime = end_datetime\n                if frequency == settings.STATISTIC_FREQUENCY_HOURLY:\n                    end_datetime += timedelta(hours=1)\n                elif frequency == settings.STATISTIC_FREQUENCY_DAILY:\n                    end_datetime += timedelta(days=1)\n                elif frequency == settings.STATISTIC_FREQUENCY_WEEKLY:\n                    end_datetime += timedelta(days=7)\n                elif frequency == settings.STATISTIC_FREQUENCY_MONTHLY:\n                    end_datetime = datetime.strptime((start_datetime+timedelta(days=33)).strftime(\"%Y %m 1\"), \"%Y %m %d\")", "response": "Calculates the statistics for the current statistic and returns a dictionary of the statistics for the current statistic and the current date."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles the metrics command.", "response": "def handle(self, *args, **kwargs):\n        \"\"\"\n        Command handler for the \"metrics\" command.\n        \"\"\"\n\n        frequency = kwargs['frequency']\n        frequencies = settings.STATISTIC_FREQUENCY_ALL if frequency == 'a' else (frequency.split(',') if ',' in frequency else [frequency])\n\n        if kwargs['list']:\n            maintenance.list_statistics()\n\n        # if we're supposed to calculate the latest statistics\n        elif kwargs['calculate']:\n            maintenance.calculate_statistics(maintenance.get_statistic_by_name(kwargs['calculate']), frequencies)\n\n        # pure reset of statistic(s)\n        elif kwargs['reset']:\n            maintenance.reset_statistics(maintenance.get_statistic_by_name(kwargs['reset']), frequencies, kwargs['reset_cumulative'])\n\n        # recalculation of statistic(s)\n        elif kwargs['recalculate']:\n            maintenance.reset_statistics(maintenance.get_statistic_by_name(kwargs['recalculate']), frequencies, kwargs['reset_cumulative'], True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the GET array for the specified variable.", "response": "def get_GET_array(request, var_name, fail_silently=True):\n    \"\"\"\n    Returns the GET array's contents for the specified variable.\n    \"\"\"\n\n    vals = request.GET.getlist(var_name)\n    if not vals:\n        if fail_silently:\n            return []\n        else:\n            raise Exception, _(\"No array called '%(varname)s' in GET variables\") % {'varname': var_name}\n\n    return vals"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntry to extract a boolean variable from the specified request.", "response": "def get_GET_bool(request, var_name, default=True):\n    \"\"\"\n    Tries to extract a boolean variable from the specified request.\n    \"\"\"\n\n    val = request.GET.get(var_name, default)\n    if isinstance(val, str) or isinstance(val, unicode):\n        val = True if val[0] == 't' else False\n\n    return val"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_next_colour():\n\n    colour = settings.GECKOBOARD_COLOURS[get_next_colour.cur_colour]\n\n    get_next_colour.cur_colour += 1\n    if get_next_colour.cur_colour >= len(settings.GECKOBOARD_COLOURS):\n        get_next_colour.cur_colour = 0\n\n    return colour", "response": "Gets the next colour in the Geckoboard colour list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the GET parameters for a particular Geckoboard view request.", "response": "def get_gecko_params(request, uid=None, days_back=0, cumulative=True,\n    frequency=settings.STATISTIC_FREQUENCY_DAILY, min_val=0, max_val=100,\n    chart_type='standard', percentage='show', sort=False):\n    \"\"\"\n    Returns the default GET parameters for a particular Geckoboard\n    view request.\n    \"\"\"\n\n    return {\n        'days_back'  : int(request.GET.get('daysback', days_back)),\n        'uid'        : request.GET.get('uid', uid),\n        'uids'       : get_GET_array(request, 'uids[]'),\n        'cumulative' : get_GET_bool(request, 'cumulative', cumulative),\n        'frequency'  : request.GET.get('frequency', frequency),\n        'min'        : request.GET.get('min', min_val),\n        'max'        : request.GET.get('max', max_val),\n        'type'       : request.GET.get('type', chart_type),\n        'percentage' : request.GET.get('percentage', percentage),\n        'sort'       : get_GET_bool(request, 'sort', sort),\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a number widget for the specified metric s cumulative total.", "response": "def geckoboard_number_widget(request):\n    \"\"\"\n    Returns a number widget for the specified metric's cumulative total.\n    \"\"\"\n\n    params = get_gecko_params(request, days_back=7)\n    metric = Metric.objects.get(uid=params['uid'])\n    try:\n        latest_stat = metric.statistics.filter(frequency=params['frequency']).order_by('-date_time')[0]\n    except IndexError:\n        return (0, 0)\n\n    try:\n        prev_stat = metric.statistics.filter(frequency=params['frequency'],\n            date_time__lte=latest_stat.date_time-timedelta(days=params['days_back'])).order_by('-date_time')[0]\n    except IndexError:\n        # if there is no previous stat\n        return (latest_stat.cumulative_count, 0) if params['cumulative'] else (latest_stat.count, 0)\n\n    return (latest_stat.cumulative_count, prev_stat.cumulative_count) if params['cumulative'] else (latest_stat.count, prev_stat.count)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef geckoboard_rag_widget(request):\n\n    params = get_gecko_params(request)\n    print params['uids']\n    max_date = datetime.now()-timedelta(days=params['days_back'])\n\n    metrics = Metric.objects.filter(uid__in=params['uids'])\n    results = [(metric.latest_count(frequency=params['frequency'], count=not params['cumulative'],\n        cumulative=params['cumulative'], max_date=max_date), metric.title) for metric in metrics]\n    \n    return tuple(results)", "response": "Returns a tuple of the latest count of all metrics in a RAG widget."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef geckoboard_pie_chart(request):\n\n    params = get_gecko_params(request, cumulative=True)\n    from_date = datetime.now()-timedelta(days=params['days_back'])\n\n    metrics = Metric.objects.filter(uid__in=params['uids'])\n    results = [(metric.latest_count(frequency=params['frequency'], count=not params['cumulative'],\n        cumulative=params['cumulative']), metric.title, get_next_colour()) for metric in metrics]\n    \n    return tuple(results)", "response": "Displays a pie chart of the metrics in the uids[] GET variable array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the data for a line chart for the specified metric.", "response": "def geckoboard_line_chart(request):\n    \"\"\"\n    Returns the data for a line chart for the specified metric.\n    \"\"\"\n\n    params = get_gecko_params(request, cumulative=False, days_back=7)\n    metric = Metric.objects.get(uid=params['uid'])\n\n    start_date = datetime.now()-timedelta(days=params['days_back'])\n    stats = [s for s in metric.statistics.filter(frequency=params['frequency'],\n        date_time__gte=start_date).order_by('date_time')]\n\n    if len(stats) == 0:\n        raise Exception, _(\"No statistics for metric %(metric)s.\") % {'metric': params['uid']}\n\n    dates = [stats[0].date_time]\n\n    # get up to 3 dates from the stats\n    if len(stats) >= 3:\n        mid = len(stats)/2\n        if not mid:\n            mid = 1\n        dates.extend([stats[mid].date_time, stats[-1].date_time])\n    elif len(stats) == 2:\n        dates.extend([stats[-1].date_time])\n\n    return (\n        [s.count for s in stats],\n        dates,\n        metric.title,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a Geckoboard - Metrics control for the specified metric.", "response": "def geckoboard_geckometer(request):\n    \"\"\"\n    Returns a Geck-o-Meter control for the specified metric.\n    \"\"\"\n\n    params = get_gecko_params(request, cumulative=True)\n    metric = Metric.objects.get(uid=params['uid'])\n\n    return (metric.latest_count(frequency=params['frequency'], count=not params['cumulative'],\n        cumulative=params['cumulative']), params['min'], params['max'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a funnel chart for the metrics specified in the GET variables.", "response": "def geckoboard_funnel(request, frequency=settings.STATISTIC_FREQUENCY_DAILY):\n    \"\"\"\n    Returns a funnel chart for the metrics specified in the GET variables.\n    \"\"\"\n\n    # get all the parameters for this function\n    params = get_gecko_params(request, cumulative=True)\n    metrics = Metric.objects.filter(uid__in=params['uids'])\n    items = [(metric.latest_count(frequency=params['frequency'], count=not params['cumulative'],\n        cumulative=params['cumulative']), metric.title) for metric in metrics]\n    \n    return {\n        'items'     : items,\n        'type'      : params['type'],\n        'percentage': params['percentage'],\n        'sort'      : params['sort'],\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns all of the active statistics for the currently registered gadgets.", "response": "def get_active_stats(self):\n        \"\"\"\n        Returns all of the active statistics for the gadgets currently registered.\n        \"\"\"\n        stats = []\n        for gadget in self._registry.values():\n            for s in gadget.stats:\n                if s not in stats:\n                    stats.append(s)\n        return stats"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a gadget object.", "response": "def register(self, gadget):\n        \"\"\"\n        Registers a gadget object.\n        If a gadget is already registered, this will raise AlreadyRegistered.\n        \"\"\"\n        if gadget in self._registry:\n            raise AlreadyRegistered\n        else:\n            self._registry.append(gadget)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unregister(self, gadgets):\n        gadgets = maintenance.ensure_list(gadgets)\n        for gadget in gadgets:\n            while gadget in self._registry:\n                self._registry.remove(gadget)", "response": "Unregisters the specified gadgets from the registry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_context_data(self, **kwargs):\n        #max_columns, max_rows = self.get_max_dimension()\n        context = {\n            'gadgets': self._registry,\n            'columns': self.columns,\n            'rows': self.rows,\n            'column_ratio': 100 - self.columns * 2,\n            'row_ratio': 100 - self.rows * 2,\n        }\n        context.update(kwargs)\n        return context", "response": "Get the context data for this view."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_model(self, model_name):\n        klass = None\n        try:\n            module_name, class_name = model_name.rsplit('.', 1)\n            mod = __import__(module_name, fromlist=[class_name])\n            klass = getattr(mod, class_name)\n        except ImportError, e:\n            self.error('Cannot find app %s %s' % (model_name, e))\n\n        return klass", "response": "Get the class object for the given model name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef custom(self, code, message):\n        if -32000 < code or -32099 > code:\n            code = -32603\n            message = 'Internal error'\n        return JResponse(jsonrpc={\n            'id': self.rid,\n            'error': {'code': code, 'message': message},\n        })", "response": "Specific server side errors use: -32000 to -32099\n        reserved for implementation-defined server-errors"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef string_input(prompt=''):\n    v = sys.version[0]\n    if v == '3':\n        return input(prompt)\n    else:\n        return raw_input(prompt)", "response": "Python 3 input()/Python 2 raw_input()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget input from a list of choices", "response": "def choice_input(options=[], prompt='Press ENTER to continue.', \n        showopts=True, qopt=False):\n    \"\"\"Get input from a list of choices (q to quit)\"\"\"\n\n    choice = None\n    if showopts:\n        prompt = prompt + ' ' + str(options)\n    if qopt:\n        prompt = prompt + ' (q to quit)'\n    \n    while not choice:\n        try:\n            choice = string_input(prompt + ' ')\n        except SyntaxError:\n            if options == []:\n                pass\n        if choice:\n            if choice in options:\n                return choice\n            elif qopt == True and choice == 'q':\n                choice = None\n                is_sure = string_input('Are you sure you want to quit? ')\n                if is_sure in ('Y', 'y', 'yes'):\n                    exit('\\nThanks for playing. Goodbye.\\n')\n            elif options == []:\n                return 0\n            else:\n                print('Answer must be one of ' + str(options) +\n                        '. Your answer?')\n                if options:\n                    choice = None\n        elif options == []:\n            return 0\n        else:\n            print('Answer must be one of ' + str(options) + \n                    '. Your answer?')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef long_input(prompt='Multi-line input\\n' + \\\n        'Enter EOF on a blank line to end ' + \\\n        '(ctrl-D in *nix, ctrl-Z in windows)',\n        maxlines = None, maxlength = None):\n    \"\"\"Get a multi-line string as input\"\"\"\n    \n    lines = []\n    print(prompt)\n    lnum = 1\n\n    try:\n        while True:\n            \n            if maxlines:\n            \n                if lnum > maxlines:\n                    break\n                \n                else:\n                    if maxlength:\n                        lines.append(string_input('')[:maxlength])\n                    else:\n                        lines.append(string_input(''))\n                    lnum += 1\n            \n            else:\n                if maxlength:\n                    lines.append(string_input('')[:maxlength])\n                else:\n                    lines.append(string_input(''))\n\n    except EOFError:\n        pass\n    finally:\n        return '\\n'.join(lines)", "response": "Get a multi - line string as input"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a list of strings as input", "response": "def list_input(prompt='List input - enter each item on a seperate line\\n' + \\\n        'Enter EOF on a blank line to end ' + \\\n        '(ctrl-D in *nix, ctrl-Z in windows)',\n        maxitems=None, maxlength=None):\n    \"\"\"Get a list of strings as input\"\"\"\n    \n    lines = []\n    print(prompt)\n    inum = 1\n\n    try:\n\n        while True:\n        \n            if maxitems:\n            \n                if inum > maxitems:\n                    break\n                else:\n                    if maxlength:\n                        lines.append(string_input('')[:maxlength])\n                    else:\n                        lines.append(string_input(''))\n                    inum += 1\n            \n            else:\n                if maxlength:\n                    lines.append(string_input('')[:maxlength])\n                else:\n                    lines.append(string_input(''))\n\n    except EOFError:\n        pass\n    finally:\n        return lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef outfile_input(extension=None):\n    \n    fileok = False\n    \n    while not fileok:\n        filename = string_input('File name? ')\n        if extension:\n            if not filename.endswith(extension):\n                if extension.startswith('.'):\n                    filename = filename + extension\n                else:\n                    filename = filename + '.' + extension\n        if os.path.isfile(filename):\n            choice = choice_input(prompt=filename + \\\n                    ' already exists. Overwrite?',\n                    options=['y', 'n'])\n            if choice == 'y':\n                try:\n                    nowtime = time.time()\n                    with open(filename, 'a') as f:\n                        os.utime(filename, (nowtime, nowtime))\n                    fileok = True\n                except IOError:\n                    print('Write permission denied on ' + filename + \\\n                            '. Try again.')\n                except PermissionError:\n                    print('Write permission denied on ' + filename + \\\n                            '. Try again.')\n                except FileNotFoundError:\n                    print(filename + ': directory not found. Try again.')\n\n        else:\n            choice = choice_input(\n                    prompt=filename + ' does not exist. Create it?',\n                    options=['y', 'n'])\n            if choice == 'y':\n                try:\n                    nowtime = time.time()\n                    with open(filename, 'w') as f:\n                        os.utime(filename, (nowtime, nowtime))\n                    fileok = True\n                except IOError:\n                    print('Write permission denied on ' + filename + \\\n                            '. Try again.')\n                except PermissionError:\n                    print('Write permission denied on ' + filename + \\\n                            '. Try again.')\n                except FileNotFoundError:\n                    print(filename + ': directory not found. Try again.')\n\n    return filename", "response": "Get an output file name as input"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef roster(self, year):\n        doc = self.get_year_doc(year)\n        table = doc('table#roster')\n        df = sportsref.utils.parse_table(table)\n        df['years_experience'] = (df['years_experience']\n                                  .replace('R', 0).replace('', np.nan).astype(float))\n        return df", "response": "Returns the roster table for the given year."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the schedule information for a given year.", "response": "def schedule(self, year):\n        \"\"\"Gets schedule information for a team-season.\n\n        :year: The year for which we want the schedule.\n        :returns: DataFrame of schedule information.\n        \"\"\"\n        doc = self.get_year_doc('{}_games'.format(year))\n        table = doc('table#games')\n        df = sportsref.utils.parse_table(table)\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef date(self):\n        match = re.match(r'(\\d{4})(\\d{2})(\\d{2})', self.boxscore_id)\n        year, month, day = map(int, match.groups())\n        return datetime.date(year=year, month=month, day=day)", "response": "Returns the date of the game. See Python datetime. date documentation\n        for more."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef weekday(self):\n        days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday',\n                'Saturday', 'Sunday']\n        date = self.date()\n        wd = date.weekday()\n        return days[wd]", "response": "Returns the weekday of the game."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning home team ID.", "response": "def home(self):\n        \"\"\"Returns home team ID.\n        :returns: 3-character string representing home team's ID.\n        \"\"\"\n        doc = self.get_doc()\n        table = doc('table.linescore')\n        relURL = table('tr').eq(2)('a').eq(2).attr['href']\n        home = sportsref.utils.rel_url_to_id(relURL)\n        return home"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the score of the home team.", "response": "def home_score(self):\n        \"\"\"Returns score of the home team.\n        :returns: int of the home score.\n        \"\"\"\n        doc = self.get_doc()\n        table = doc('table.linescore')\n        home_score = table('tr').eq(2)('td')[-1].text_content()\n        return int(home_score)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef away_score(self):\n        doc = self.get_doc()\n        table = doc('table.linescore')\n        away_score = table('tr').eq(1)('td')[-1].text_content()\n        return int(away_score)", "response": "Returns the score of the away team."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the team ID of the winning team. Returns NaN if a tie. Returns NaN if a tie.", "response": "def winner(self):\n        \"\"\"Returns the team ID of the winning team. Returns NaN if a tie.\"\"\"\n        hmScore = self.home_score()\n        awScore = self.away_score()\n        if hmScore > awScore:\n            return self.home()\n        elif hmScore < awScore:\n            return self.away()\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef week(self):\n        doc = self.get_doc()\n        raw = doc('div#div_other_scores h2 a').attr['href']\n        match = re.match(\n            r'/years/{}/week_(\\d+)\\.htm'.format(self.season()), raw\n        )\n        if match:\n            return int(match.group(1))\n        else:\n            return 21", "response": "Returns the week in which this game took place."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the year ID of the season in which this game took place.", "response": "def season(self):\n        \"\"\"\n        Returns the year ID of the season in which this game took place.\n        Useful for week 17 January games.\n\n        :returns: An int representing the year of the season.\n        \"\"\"\n        date = self.date()\n        return date.year - 1 if date.month <= 3 else date.year"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a pandas DataFrame where each row is an entry in the starters table where each row is a dictionary of the values for the keys player_id playerName position team home and offense.", "response": "def starters(self):\n        \"\"\"Returns a DataFrame where each row is an entry in the starters table\n        from PFR.\n\n        The columns are:\n        * player_id - the PFR player ID for the player (note that this column\n        is not necessarily all unique; that is, one player can be a starter in\n        multiple positions, in theory).\n        * playerName - the listed name of the player; this too is not\n        necessarily unique.\n        * position - the position at which the player started for their team.\n        * team - the team for which the player started.\n        * home - True if the player's team was at home, False if they were away\n        * offense - True if the player is starting on an offensive position,\n        False if defense.\n\n        :returns: A pandas DataFrame. See the description for details.\n        \"\"\"\n        doc = self.get_doc()\n        a = doc('table#vis_starters')\n        h = doc('table#home_starters')\n        data = []\n        for h, table in enumerate((a, h)):\n            team = self.home() if h else self.away()\n            for i, row in enumerate(table('tbody tr').items()):\n                datum = {}\n                datum['player_id'] = sportsref.utils.rel_url_to_id(\n                    row('a')[0].attrib['href']\n                )\n                datum['playerName'] = row('th').text()\n                datum['position'] = row('td').text()\n                datum['team'] = team\n                datum['home'] = (h == 1)\n                datum['offense'] = (i <= 10)\n                data.append(datum)\n        return pd.DataFrame(data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef surface(self):\n        doc = self.get_doc()\n        table = doc('table#game_info')\n        giTable = sportsref.utils.parse_info_table(table)\n        return giTable.get('surface', np.nan)", "response": "Returns the type of the playing surface on which the game was played."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef over_under(self):\n        doc = self.get_doc()\n        table = doc('table#game_info')\n        giTable = sportsref.utils.parse_info_table(table)\n        if 'over_under' in giTable:\n            ou = giTable['over_under']\n            return float(ou.split()[0])\n        else:\n            return None", "response": "Returns the over - under for the game as a float or np. nan."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the dictionary of coin toss - related info.", "response": "def coin_toss(self):\n        \"\"\"Gets information relating to the opening coin toss.\n\n        Keys are:\n        * wonToss - contains the ID of the team that won the toss\n        * deferred - bool whether the team that won the toss deferred it\n\n        :returns: Dictionary of coin toss-related info.\n        \"\"\"\n        doc = self.get_doc()\n        table = doc('table#game_info')\n        giTable = sportsref.utils.parse_info_table(table)\n        if 'Won Toss' in giTable:\n            # TODO: finish coinToss function\n            pass\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef weather(self):\n        doc = self.get_doc()\n        table = doc('table#game_info')\n        giTable = sportsref.utils.parse_info_table(table)\n        if 'weather' in giTable:\n            regex = (\n                r'(?:(?P<temp>\\-?\\d+) degrees )?'\n                r'(?:relative humidity (?P<relHumidity>\\d+)%, )?'\n                r'(?:wind (?P<windMPH>\\d+) mph, )?'\n                r'(?:wind chill (?P<windChill>\\-?\\d+))?'\n            )\n            m = re.match(regex, giTable['weather'])\n            d = m.groupdict()\n\n            # cast values to int\n            for k in d:\n                try:\n                    d[k] = int(d[k])\n                except TypeError:\n                    pass\n\n            # one-off fixes\n            d['windChill'] = (d['windChill'] if pd.notnull(d['windChill'])\n                              else d['temp'])\n            d['windMPH'] = d['windMPH'] if pd.notnull(d['windMPH']) else 0\n            return d\n        else:\n            # no weather found, because it's a dome\n            # TODO: what's relative humidity in a dome?\n            return {\n                'temp': 70, 'windChill': 70, 'relHumidity': None, 'windMPH': 0\n            }", "response": "Returns a dictionary of weather - related info."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pbp(self):\n        doc = self.get_doc()\n        table = doc('table#pbp')\n        df = sportsref.utils.parse_table(table)\n        # make the following features conveniently available on each row\n        df['boxscore_id'] = self.boxscore_id\n        df['home'] = self.home()\n        df['away'] = self.away()\n        df['season'] = self.season()\n        df['week'] = self.week()\n        feats = sportsref.nfl.pbp.expand_details(df)\n\n        # add team and opp columns by iterating through rows\n        df = sportsref.nfl.pbp._add_team_columns(feats)\n        # add WPA column (requires diff, can't be done row-wise)\n        df['home_wpa'] = df.home_wp.diff()\n        # lag score columns, fill in 0-0 to start\n        for col in ('home_wp', 'pbp_score_hm', 'pbp_score_aw'):\n            if col in df.columns:\n                df[col] = df[col].shift(1)\n        df.loc[0, ['pbp_score_hm', 'pbp_score_aw']] = 0\n        # fill in WP NaN's\n        df.home_wp.fillna(method='ffill', inplace=True)\n        # fix first play border after diffing/shifting for WP and WPA\n        firstPlaysOfGame = df[df.secsElapsed == 0].index\n        line = self.line()\n        for i in firstPlaysOfGame:\n            initwp = sportsref.nfl.winProb.initialWinProb(line)\n            df.loc[i, 'home_wp'] = initwp\n            df.loc[i, 'home_wpa'] = df.loc[i + 1, 'home_wp'] - initwp\n        # fix last play border after diffing/shifting for WP and WPA\n        lastPlayIdx = df.index[-1]\n        lastPlayWP = df.loc[lastPlayIdx, 'home_wp']\n        # if a tie, final WP is 50%; otherwise, determined by winner\n        winner = self.winner()\n        finalWP = 50. if pd.isnull(winner) else (winner == self.home()) * 100.\n        df.loc[lastPlayIdx, 'home_wpa'] = finalWP - lastPlayWP\n        # fix WPA for timeouts and plays after timeouts\n        timeouts = df[df.isTimeout].index\n        for to in timeouts:\n            df.loc[to, 'home_wpa'] = 0.\n            if to + 2 in df.index:\n                wpa = df.loc[to + 2, 'home_wp'] - df.loc[to + 1, 'home_wp']\n            else:\n                wpa = finalWP - df.loc[to + 1, 'home_wp']\n            df.loc[to + 1, 'home_wpa'] = wpa\n        # add team-related features to DataFrame\n        df = sportsref.nfl.pbp._add_team_features(df)\n        # fill distToGoal NaN's\n        df['distToGoal'] = np.where(df.isKickoff, 65, df.distToGoal)\n        df.distToGoal.fillna(method='bfill', inplace=True)\n        df.distToGoal.fillna(method='ffill', inplace=True)  # for last play\n\n        return df", "response": "Returns a dataframe of the play - by - play data from the game."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary of ref positions and ref IDs of the refs for that game.", "response": "def ref_info(self):\n        \"\"\"Gets a dictionary of ref positions and the ref IDs of the refs for\n        that game.\n\n        :returns: A dictionary of ref positions and IDs.\n        \"\"\"\n        doc = self.get_doc()\n        table = doc('table#officials')\n        return sportsref.utils.parse_info_table(table)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef player_stats(self):\n        doc = self.get_doc()\n        tableIDs = ('player_offense', 'player_defense', 'returns', 'kicking')\n        dfs = []\n        for tID in tableIDs:\n            table = doc('table#{}'.format(tID))\n            dfs.append(sportsref.utils.parse_table(table))\n        dfs = [df for df in dfs if not df.empty]\n        df = reduce(\n            lambda x, y: pd.merge(\n                x, y, how='outer', on=list(set(x.columns) & set(y.columns))\n            ), dfs\n        ).reset_index(drop=True)\n        return df", "response": "Gets the stats for offense defense returning and kicking of\n        individual players in the game."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef snap_counts(self):\n        # TODO: combine duplicate players, see 201312150mia - ThomDa03\n        doc = self.get_doc()\n        table_ids = ('vis_snap_counts', 'home_snap_counts')\n        tms = (self.away(), self.home())\n        df = pd.concat([\n            sportsref.utils.parse_table(doc('table#{}'.format(table_id)))\n            .assign(is_home=bool(i), team=tms[i], opp=tms[i*-1+1])\n            for i, table_id in enumerate(table_ids)\n        ])\n        if df.empty:\n            return df\n        return df.set_index('player_id')", "response": "Gets the snap counts for both teams and home players and returns them in a DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn PyQuery object for the main season URL.", "response": "def get_main_doc(self):\n        \"\"\"Returns PyQuery object for the main season URL.\n        :returns: PyQuery object.\n        \"\"\"\n        url = (sportsref.nba.BASE_URL +\n               '/leagues/NBA_{}.html'.format(self.yr))\n        return pq(sportsref.utils.get_html(url))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a PyQuery object for a given subpage URL.", "response": "def get_sub_doc(self, subpage):\n        \"\"\"Returns PyQuery object for a given subpage URL.\n        :subpage: The subpage of the season, e.g. 'per_game'.\n        :returns: PyQuery object.\n        \"\"\"\n        html = sportsref.utils.get_html(self._subpage_url(subpage))\n        return pq(html)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of the team IDs for the given year.", "response": "def get_team_ids(self):\n        \"\"\"Returns a list of the team IDs for the given year.\n        :returns: List of team IDs.\n        \"\"\"\n        df = self.team_stats_per_game()\n        if not df.empty:\n            return df.index.tolist()\n        else:\n            print('ERROR: no teams found')\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef team_ids_to_names(self):\n        doc = self.get_main_doc()\n        table = doc('table#team-stats-per_game')\n        flattened = sportsref.utils.parse_table(table, flatten=True)\n        unflattened = sportsref.utils.parse_table(table, flatten=False)\n        team_ids = flattened['team_id']\n        team_names = unflattened['team_name']\n        if len(team_names) != len(team_ids):\n            raise Exception(\"team names and team IDs don't align\")\n        return dict(zip(team_ids, team_names))", "response": "Mapping from 3 - letter team IDs to full team names."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef team_names_to_ids(self):\n        d = self.team_ids_to_names()\n        return {v: k for k, v in d.items()}", "response": "Mapping from full team names to 3 - letter team IDs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a DataFrame of BoxScore IDs for every game in the season.", "response": "def schedule(self, kind='R'):\n        \"\"\"Returns a list of BoxScore IDs for every game in the season.\n        Only needs to handle 'R' or 'P' options because decorator handles 'B'.\n\n        :param kind: 'R' for regular season, 'P' for playoffs, 'B' for both.\n            Defaults to 'R'.\n        :returns: DataFrame of schedule information.\n        :rtype: pd.DataFrame\n        \"\"\"\n        kind = kind.upper()[0]\n        dfs = []\n\n        # get games from each month\n        for month in ('october', 'november', 'december', 'january', 'february',\n                      'march', 'april', 'may', 'june'):\n            try:\n                doc = self.get_sub_doc('games-{}'.format(month))\n            except ValueError:\n                continue\n            table = doc('table#schedule')\n            df = sportsref.utils.parse_table(table)\n            dfs.append(df)\n        df = pd.concat(dfs).reset_index(drop=True)\n\n        # figure out how many regular season games\n        try:\n            sportsref.utils.get_html('{}/playoffs/NBA_{}.html'.format(\n                sportsref.nba.BASE_URL, self.yr)\n            )\n            is_past_season = True\n        except ValueError:\n            is_past_season = False\n\n        if is_past_season:\n            team_per_game = self.team_stats_per_game()\n            n_reg_games = int(team_per_game.g.sum() // 2)\n        else:\n            n_reg_games = len(df)\n\n        # subset appropriately based on `kind`\n        if kind == 'P':\n            return df.iloc[n_reg_games:]\n        else:\n            return df.iloc[:n_reg_games]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef standings(self):\n        doc = self.get_sub_doc('standings')\n\n        east_table = doc('table#divs_standings_E')\n        east_df = pd.DataFrame(sportsref.utils.parse_table(east_table))\n        east_df.sort_values('wins', ascending=False, inplace=True)\n        east_df['seed'] = range(1, len(east_df) + 1)\n        east_df['conference'] = 'E'\n\n        west_table = doc('table#divs_standings_W')\n        west_df = sportsref.utils.parse_table(west_table)\n        west_df.sort_values('wins', ascending=False, inplace=True)\n        west_df['seed'] = range(1, len(west_df) + 1)\n        west_df['conference'] = 'W'\n\n        full_df = pd.concat([east_df, west_df], axis=0).reset_index(drop=True)\n        full_df['team_id'] = full_df.team_id.str.extract(r'(\\w+)\\W*\\(\\d+\\)', expand=False)\n        full_df['gb'] = [gb if isinstance(gb, int) or isinstance(gb, float) else 0\n                         for gb in full_df['gb']]\n        full_df = full_df.drop('has_class_full_table', axis=1)\n\n        expanded_table = doc('table#expanded_standings')\n        expanded_df = sportsref.utils.parse_table(expanded_table)\n\n        full_df = pd.merge(full_df, expanded_df, on='team_id')\n        return full_df", "response": "Returns a DataFrame containing the standings information."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_team_stats_table(self, selector):\n        doc = self.get_main_doc()\n        table = doc(selector)\n        df = sportsref.utils.parse_table(table)\n        df.set_index('team_id', inplace=True)\n        return df", "response": "Helper function for stats tables on season pages. Returns a Pandas DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef roy_voting(self):\n        url = '{}/awards/awards_{}.html'.format(sportsref.nba.BASE_URL, self.yr)\n        doc = pq(sportsref.utils.get_html(url))\n        table = doc('table#roy')\n        df = sportsref.utils.parse_table(table)\n        return df", "response": "Returns a DataFrame containing information about ROY voting."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef linescore(self):\n        doc = self.get_main_doc()\n        table = doc('table#line_score')\n\n        columns = [th.text() for th in table('tr.thead').items('th')]\n        columns[0] = 'team_id'\n\n        data = [\n            [sportsref.utils.flatten_links(td) for td in tr('td').items()]\n            for tr in table('tr.thead').next_all('tr').items()\n        ]\n\n        return pd.DataFrame(data, index=['away', 'home'],\n                            columns=columns, dtype='float')", "response": "Returns the linescore for the game as a DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the year ID of the game took place.", "response": "def season(self):\n        \"\"\"\n        Returns the year ID of the season in which this game took place.\n\n        :returns: An int representing the year of the season.\n        \"\"\"\n        d = self.date()\n        if d.month >= 9:\n            return d.year + 1\n        else:\n            return d.year"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_player_stats(self, table_id_fmt):\n\n        # get data\n        doc = self.get_main_doc()\n        tms = self.away(), self.home()\n        tm_ids = [table_id_fmt.format(tm) for tm in tms]\n        tables = [doc('table#{}'.format(tm_id).lower()) for tm_id in tm_ids]\n        dfs = [sportsref.utils.parse_table(table) for table in tables]\n\n        # clean data and add features\n        for i, (tm, df) in enumerate(zip(tms, dfs)):\n            no_time = df['mp'] == 0\n            stat_cols = [col for col, dtype in df.dtypes.items()\n                         if dtype != 'object']\n            df.loc[no_time, stat_cols] = 0\n            df['team_id'] = tm\n            df['is_home'] = i == 1\n            df['is_starter'] = [p < 5 for p in range(df.shape[0])]\n            df.drop_duplicates(subset='player_id', keep='first', inplace=True)\n\n        return pd.concat(dfs)", "response": "Returns a DataFrame of player stats from the game."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pbp(self, dense_lineups=False, sparse_lineups=False):\n        try:\n            doc = self.get_subpage_doc('pbp')\n        except:\n            raise ValueError(\n                'Error fetching PBP subpage for boxscore {}'\n                .format(self.boxscore_id)\n            )\n        table = doc('table#pbp')\n        trs = [\n            tr for tr in table('tr').items()\n            if (not tr.attr['class'] or  # regular data rows\n                tr.attr['id'] and tr.attr['id'].startswith('q'))  # qtr bounds\n        ]\n        rows = [tr.children('td') for tr in trs]\n        n_rows = len(trs)\n        data = []\n        cur_qtr = 0\n        bsid = self.boxscore_id\n\n        for i in range(n_rows):\n            tr = trs[i]\n            row = rows[i]\n            p = {}\n\n            # increment cur_qtr when we hit a new quarter\n            if tr.attr['id'] and tr.attr['id'].startswith('q'):\n                assert int(tr.attr['id'][1:]) == cur_qtr + 1\n                cur_qtr += 1\n                continue\n\n            # add time of play to entry\n            t_str = row.eq(0).text()\n            t_regex = r'(\\d+):(\\d+)\\.(\\d+)'\n            mins, secs, tenths = map(int, re.match(t_regex, t_str).groups())\n            endQ = (12 * 60 * min(cur_qtr, 4) +\n                    5 * 60 * (cur_qtr - 4 if cur_qtr > 4 else 0))\n            secsElapsed = endQ - (60 * mins + secs + 0.1 * tenths)\n            p['secs_elapsed'] = secsElapsed\n            p['clock_time'] = t_str\n            p['quarter'] = cur_qtr\n\n            # handle single play description\n            # ex: beginning/end of quarter, jump ball\n            if row.length == 2:\n                desc = row.eq(1)\n                # handle jump balls\n                if desc.text().lower().startswith('jump ball: '):\n                    p['is_jump_ball'] = True\n                    jb_str = sportsref.utils.flatten_links(desc)\n                    p.update(\n                        sportsref.nba.pbp.parse_play(bsid, jb_str, None)\n                    )\n                # ignore rows marking beginning/end of quarters\n                elif (\n                    desc.text().lower().startswith('start of ') or\n                    desc.text().lower().startswith('end of ')\n                ):\n                    continue\n                # if another case, log and continue\n                else:\n                    if not desc.text().lower().startswith('end of '):\n                        print(\n                            '{}, Q{}, {} other case: {}'\n                            .format(self.boxscore_id, cur_qtr,\n                                    t_str, desc.text())\n                        )\n                    continue\n\n            # handle team play description\n            # ex: shot, turnover, rebound, foul, sub, etc.\n            elif row.length == 6:\n                aw_desc, hm_desc = row.eq(1), row.eq(5)\n                is_hm_play = bool(hm_desc.text())\n                desc = hm_desc if is_hm_play else aw_desc\n                desc = sportsref.utils.flatten_links(desc)\n                # parse the play\n                new_p = sportsref.nba.pbp.parse_play(bsid, desc, is_hm_play)\n                if not new_p:\n                    continue\n                elif isinstance(new_p, list):\n                    # this happens when a row needs to be expanded to 2 rows;\n                    # ex: double personal foul -> two PF rows\n\n                    # first, update and append the first row\n                    orig_p = dict(p)\n                    p.update(new_p[0])\n                    data.append(p)\n                    # second, set up the second row to be appended below\n                    p = orig_p\n                    new_p = new_p[1]\n                elif new_p.get('is_error'):\n                    print(\"can't parse: {}, boxscore: {}\"\n                          .format(desc, self.boxscore_id))\n                    # import pdb; pdb.set_trace()\n                p.update(new_p)\n\n            # otherwise, I don't know what this was\n            else:\n                raise Exception((\"don't know how to handle row of length {}\"\n                                 .format(row.length)))\n\n            data.append(p)\n\n        # convert to DataFrame and clean columns\n        df = pd.DataFrame.from_records(data)\n        df.sort_values('secs_elapsed', inplace=True, kind='mergesort')\n        df = sportsref.nba.pbp.clean_features(df)\n\n        # add columns for home team, away team, boxscore_id, date\n        away, home = self.away(), self.home()\n        df['home'] = home\n        df['away'] = away\n        df['boxscore_id'] = self.boxscore_id\n        df['season'] = self.season()\n        date = self.date()\n        df['year'] = date.year\n        df['month'] = date.month\n        df['day'] = date.day\n\n        def _clean_rebs(df):\n            df.reset_index(drop=True, inplace=True)\n            no_reb_after = (\n                (df.fta_num < df.tot_fta) | df.is_ftm |\n                df.get('is_tech_fta', False)\n            ).shift(1).fillna(False)\n            no_reb_before = (\n                (df.fta_num == df.tot_fta)\n            ).shift(-1).fillna(False)\n            se_end_qtr = df.loc[\n                df.clock_time == '0:00.0', 'secs_elapsed'\n            ].unique()\n            no_reb_when = df.secs_elapsed.isin(se_end_qtr)\n            drop_mask = (\n                (df.rebounder == 'Team') &\n                (no_reb_after | no_reb_before | no_reb_when)\n            ).nonzero()[0]\n            df.drop(drop_mask, axis=0, inplace=True)\n            df.reset_index(drop=True, inplace=True)\n            return df\n\n        # get rid of 'rebounds' after FTM, non-final FTA, or tech FTA\n        df = _clean_rebs(df)\n\n        # track possession number for each possession\n        # TODO: see 201604130PHO, secs_elapsed == 2756\n        # things that end a poss:\n        # FGM, dreb, TO, end of Q, made last FT, lost jump ball,\n        # def goaltending, shot clock violation\n        new_poss = (df.off_team == df.home).diff().fillna(False)\n        # def rebound considered part of the new possession\n        df['poss_id'] = np.cumsum(new_poss) + df.is_dreb\n        # create poss_id with rebs -> new possessions for granular groupbys\n        poss_id_reb = np.cumsum(new_poss | df.is_reb)\n\n        # make sure plays with the same clock time are in the right order\n        # TODO: make sort_cols depend on what cols are in the play?\n        # or combine related plays, like and-1 shot and foul\n        # issues come up with FGA after timeout in 201604130LAL\n        # issues come up with PF between FGA and DREB in 201604120SAS\n        sort_cols = [col for col in\n                     ['is_reb', 'is_fga', 'is_pf', 'is_tech_foul',\n                      'is_ejection', 'is_tech_fta', 'is_timeout', 'is_pf_fta',\n                      'fta_num', 'is_viol', 'is_to', 'is_jump_ball', 'is_sub']\n                     if col in df.columns]\n        asc_true = ['fta_num']\n        ascend = [(col in asc_true) for col in sort_cols]\n        for label, group in df.groupby([df.secs_elapsed, poss_id_reb]):\n            if len(group) > 1:\n                df.loc[group.index, :] = group.sort_values(\n                    sort_cols, ascending=ascend, kind='mergesort'\n                ).values\n\n        # 2nd pass: get rid of 'rebounds' after FTM, non-final FTA, etc.\n        df = _clean_rebs(df)\n\n        # makes sure off/def and poss_id are correct for subs after rearranging\n        # some possessions above\n        df.loc[df['is_sub'], ['off_team', 'def_team', 'poss_id']] = np.nan\n        df.off_team.fillna(method='bfill', inplace=True)\n        df.def_team.fillna(method='bfill', inplace=True)\n        df.poss_id.fillna(method='bfill', inplace=True)\n        # make off_team and def_team NaN for jump balls\n        if 'is_jump_ball' in df.columns:\n            df.loc[df['is_jump_ball'], ['off_team', 'def_team']] = np.nan\n\n        # make sure 'off_team' is always the team shooting FTs, even on techs\n        # (impt for keeping track of the score)\n        if 'is_tech_fta' in df.columns:\n            tech_fta = df['is_tech_fta']\n            df.loc[tech_fta, 'off_team'] = df.loc[tech_fta, 'fta_team']\n            df.loc[tech_fta, 'def_team'] = np.where(\n                df.loc[tech_fta, 'off_team'] == home, away, home\n            )\n        df.drop('fta_team', axis=1, inplace=True)\n        # redefine poss_id_reb\n        new_poss = (df.off_team == df.home).diff().fillna(False)\n        poss_id_reb = np.cumsum(new_poss | df.is_reb)\n\n        # get rid of redundant subs\n        for (se, tm, pnum), group in df[df.is_sub].groupby(\n            [df.secs_elapsed, df.sub_team, poss_id_reb]\n        ):\n            if len(group) > 1:\n                sub_in = set()\n                sub_out = set()\n                # first, figure out who's in and who's out after subs\n                for i, row in group.iterrows():\n                    if row['sub_in'] in sub_out:\n                        sub_out.remove(row['sub_in'])\n                    else:\n                        sub_in.add(row['sub_in'])\n                    if row['sub_out'] in sub_in:\n                        sub_in.remove(row['sub_out'])\n                    else:\n                        sub_out.add(row['sub_out'])\n                assert len(sub_in) == len(sub_out)\n                # second, add those subs\n                n_subs = len(sub_in)\n                for idx, p_in, p_out in zip(\n                    group.index[:n_subs], sub_in, sub_out\n                ):\n                    assert df.loc[idx, 'is_sub']\n                    df.loc[idx, 'sub_in'] = p_in\n                    df.loc[idx, 'sub_out'] = p_out\n                    df.loc[idx, 'sub_team'] = tm\n                    df.loc[idx, 'detail'] = (\n                        '{} enters the game for {}'.format(p_in, p_out)\n                    )\n                # third, if applicable, remove old sub entries when there are\n                # redundant subs\n                n_extra = len(group) - len(sub_in)\n                if n_extra:\n                    extra_idxs = group.index[-n_extra:]\n                    df.drop(extra_idxs, axis=0, inplace=True)\n\n        df.reset_index(drop=True, inplace=True)\n\n        # add column for pts and score\n        df['pts'] = (df['is_ftm'] + 2 * df['is_fgm'] +\n                     (df['is_fgm'] & df['is_three']))\n        df['hm_pts'] = np.where(df.off_team == df.home, df.pts, 0)\n        df['aw_pts'] = np.where(df.off_team == df.away, df.pts, 0)\n        df['hm_score'] = np.cumsum(df['hm_pts'])\n        df['aw_score'] = np.cumsum(df['aw_pts'])\n\n        # more helpful columns\n        # \"play\" is differentiated from \"poss\" by counting OReb as new play\n        # \"plays\" end with non-and1 FGA, TO, last non-tech FTA, or end of qtr\n        # (or double lane viol)\n        new_qtr = df.quarter.diff().shift(-1).fillna(False).astype(bool)\n        and1 = (df.is_fgm & df.is_pf.shift(-1).fillna(False) &\n                df.is_fta.shift(-2).fillna(False) &\n                ~df.secs_elapsed.diff().shift(-1).fillna(False).astype(bool))\n        double_lane = (df.get('viol_type') == 'double lane')\n        new_play = df.eval('(is_fga & ~(@and1)) | is_to | @new_qtr |'\n                           '(is_fta & ~is_tech_fta & fta_num == tot_fta) |'\n                           '@double_lane')\n        df['play_id'] = np.cumsum(new_play).shift(1).fillna(0)\n        df['hm_off'] = df.off_team == df.home\n\n        # get lineup data\n        if dense_lineups:\n            df = pd.concat(\n                (df, sportsref.nba.pbp.get_dense_lineups(df)), axis=1\n            )\n        if sparse_lineups:\n            df = pd.concat(\n                (df, sportsref.nba.pbp.get_sparse_lineups(df)), axis=1\n            )\n\n        # TODO: add shot clock as a feature\n\n        return df", "response": "Returns a pandas DataFrame of the play - by - play data from the game."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cache(func):\n\n    CACHE_DIR = appdirs.user_cache_dir('sportsref', getpass.getuser())\n    if not os.path.isdir(CACHE_DIR):\n        os.makedirs(CACHE_DIR)\n\n    @funcutils.wraps(func)\n    def wrapper(url):\n        # hash based on the URL\n        file_hash = hashlib.md5()\n        encoded_url = url.encode(errors='replace')\n        file_hash.update(encoded_url)\n        file_hash = file_hash.hexdigest()\n        filename = '{}/{}'.format(CACHE_DIR, file_hash)\n\n        sport_id = None\n        for a_base_url, a_sport_id in sportsref.SITE_ABBREV.items():\n            if url.startswith(a_base_url):\n                sport_id = a_sport_id\n                break\n        else:\n            print('No sport ID found for {}, not able to check cache'.format(url))\n\n        # check whether cache is valid or stale\n        file_exists = os.path.isfile(filename)\n        if sport_id and file_exists:\n            cur_time = int(time.time())\n            mod_time = int(os.path.getmtime(filename))\n            days_since_mod = datetime.timedelta(seconds=(cur_time - mod_time)).days\n            days_cache_valid = globals()['_days_valid_{}'.format(sport_id)](url)\n            cache_is_valid = days_since_mod < days_cache_valid\n        else:\n            cache_is_valid = False\n\n        # if file found and cache is valid, read from file\n        allow_caching = sportsref.get_option('cache')\n        if file_exists and cache_is_valid and allow_caching:\n            with codecs.open(filename, 'r', encoding='utf-8', errors='replace') as f:\n                text = f.read()\n        # otherwise, execute function and cache results\n        else:\n            text = func(url)\n            with codecs.open(filename, 'w+', encoding='utf-8') as f:\n                f.write(text)\n        return text\n\n    return wrapper", "response": "A decorator that caches the HTML returned by the specified function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_class_instance_key(cls, args, kwargs):\n    l = [id(cls)]\n    for arg in args:\n        l.append(id(arg))\n    l.extend((k, id(v)) for k, v in kwargs.items())\n    return tuple(sorted(l))", "response": "Returns a unique identifier for a class instantiation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the age of the player on a given date.", "response": "def age(self, year, month=2, day=1):\n        \"\"\"Returns the age of the player on a given date.\n\n        :year: int representing the year.\n        :month: int representing the month (1-12).\n        :day: int representing the day within the month (1-31).\n        :returns: Age in years as a float.\n        \"\"\"\n        doc = self.get_main_doc()\n        date_string = doc('span[itemprop=\"birthDate\"]').attr('data-birth')\n        regex = r'(\\d{4})\\-(\\d{2})\\-(\\d{2})'\n        date_args = map(int, re.match(regex, date_string).groups())\n        birth_date = datetime.date(*date_args)\n        age_date = datetime.date(year=year, month=month, day=day)\n        delta = age_date - birth_date\n        age = delta.days / 365.\n        return age"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef height(self):\n        doc = self.get_main_doc()\n        raw = doc('span[itemprop=\"height\"]').text()\n        try:\n            feet, inches = map(int, raw.split('-'))\n            return feet * 12 + inches\n        except ValueError:\n            return None", "response": "Returns the player s height in inches."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the player s weight in pounds.", "response": "def weight(self):\n        \"\"\"Returns the player's weight (in pounds).\n        :returns: An int representing a player's weight in pounds.\n        \"\"\"\n        doc = self.get_main_doc()\n        raw = doc('span[itemprop=\"weight\"]').text()\n        try:\n            weight = re.match(r'(\\d+)lb', raw).group(1)\n            return int(weight)\n        except ValueError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the player s handedness.", "response": "def hand(self):\n        \"\"\"Returns the player's handedness.\n        :returns: 'L' for left-handed, 'R' for right-handed.\n        \"\"\"\n        doc = self.get_main_doc()\n        hand = re.search(r'Shoots:\\s*(L|R)', doc.text()).group(1)\n        return hand"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn when in the draft the player was picked.", "response": "def draft_pick(self):\n        \"\"\"Returns when in the draft the player was picked.\n        :returns: TODO\n        \"\"\"\n        doc = self.get_main_doc()\n        try:\n            p_tags = doc('div#meta p')\n            draft_p_tag = next(p for p in p_tags.items() if p.text().lower().startswith('draft'))\n            draft_pick = int(re.search(r'(\\d+)\\w{,3}\\s+?overall', draft_p_tag.text()).group(1))\n            return draft_pick\n        except Exception as e:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a stats table from the player page; helper function that does the work for per-game, per-100-poss, etc. stats. :table_id: the ID of the HTML table. :kind: specifies regular season, playoffs, or both. One of 'R', 'P', 'B'. Defaults to 'R'. :returns: A DataFrame of stats.", "response": "def _get_stats_table(self, table_id, kind='R', summary=False):\n        \"\"\"Gets a stats table from the player page; helper function that does\n        the work for per-game, per-100-poss, etc. stats.\n\n        :table_id: the ID of the HTML table.\n        :kind: specifies regular season, playoffs, or both. One of 'R', 'P',\n            'B'. Defaults to 'R'.\n        :returns: A DataFrame of stats.\n        \"\"\"\n        doc = self.get_main_doc()\n        table_id = 'table#{}{}'.format(\n            'playoffs_' if kind == 'P' else '', table_id)\n        table = doc(table_id)\n        df = sportsref.utils.parse_table(table, flatten=(not summary),\n                                         footer=summary)\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a DataFrame of per - game box score stats.", "response": "def stats_per_game(self, kind='R', summary=False):\n        \"\"\"Returns a DataFrame of per-game box score stats.\"\"\"\n        return self._get_stats_table('per_game', kind=kind, summary=summary)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stats_totals(self, kind='R', summary=False):\n        return self._get_stats_table('totals', kind=kind, summary=summary)", "response": "Returns a DataFrame of total box score statistics by season."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a DataFrame of per - minute stats.", "response": "def stats_per36(self, kind='R', summary=False):\n        \"\"\"Returns a DataFrame of per-36-minutes stats.\"\"\"\n        return self._get_stats_table('per_minute', kind=kind, summary=summary)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a DataFrame of per - 100 - possession stats.", "response": "def stats_per100(self, kind='R', summary=False):\n        \"\"\"Returns a DataFrame of per-100-possession stats.\"\"\"\n        return self._get_stats_table('per_poss', kind=kind, summary=summary)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a DataFrame of advanced stats.", "response": "def stats_advanced(self, kind='R', summary=False):\n        \"\"\"Returns a DataFrame of advanced stats.\"\"\"\n        return self._get_stats_table('advanced', kind=kind, summary=summary)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a DataFrame of shooting stats.", "response": "def stats_shooting(self, kind='R', summary=False):\n        \"\"\"Returns a DataFrame of shooting stats.\"\"\"\n        return self._get_stats_table('shooting', kind=kind, summary=summary)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stats_pbp(self, kind='R', summary=False):\n        return self._get_stats_table('advanced_pbp', kind=kind,\n                                     summary=summary)", "response": "Returns a DataFrame of play - by - play stats."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gamelog_basic(self, year, kind='R'):\n        doc = self.get_sub_doc('gamelog/{}'.format(year))\n        table = (doc('table#pgl_basic_playoffs')\n                 if kind == 'P' else doc('table#pgl_basic'))\n        df = sportsref.utils.parse_table(table)\n        return df", "response": "Returns a DataFrame of the player s basic game - by - game stats for a given season."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a play - by - play string describing a play.", "response": "def parse_play(boxscore_id, details, is_hm):\n    \"\"\"Parse play details from a play-by-play string describing a play.\n\n    Assuming valid input, this function returns structured data in a dictionary\n    describing the play. If the play detail string was invalid, this function\n    returns None.\n\n    :param boxscore_id: the boxscore ID of the play\n    :param details: detail string for the play\n    :param is_hm: bool indicating whether the offense is at home\n    :param returns: dictionary of play attributes or None if invalid\n    :rtype: dictionary or None\n    \"\"\"\n    # if input isn't a string, return None\n    if not details or not isinstance(details, basestring):\n        return None\n\n    bs = sportsref.nba.BoxScore(boxscore_id)\n    aw, hm = bs.away(), bs.home()\n    season = sportsref.nba.Season(bs.season())\n    hm_roster = set(bs.basic_stats().query('is_home == True').player_id.values)\n\n    p = {}\n    p['detail'] = details\n    p['home'] = hm\n    p['away'] = aw\n    p['is_home_play'] = is_hm\n\n    # parsing field goal attempts\n    shotRE = (r'(?P<shooter>{0}) (?P<is_fgm>makes|misses) '\n              '(?P<is_three>2|3)\\-pt shot').format(PLAYER_RE)\n    distRE = r' (?:from (?P<shot_dist>\\d+) ft|at rim)'\n    assistRE = r' \\(assist by (?P<assister>{0})\\)'.format(PLAYER_RE)\n    blockRE = r' \\(block by (?P<blocker>{0})\\)'.format(PLAYER_RE)\n    shotRE = r'{0}{1}(?:{2}|{3})?'.format(shotRE, distRE, assistRE, blockRE)\n    m = re.match(shotRE, details, re.IGNORECASE)\n    if m:\n        p['is_fga'] = True\n        p.update(m.groupdict())\n        p['shot_dist'] = p['shot_dist'] if p['shot_dist'] is not None else 0\n        p['shot_dist'] = int(p['shot_dist'])\n        p['is_fgm'] = p['is_fgm'] == 'makes'\n        p['is_three'] = p['is_three'] == '3'\n        p['is_assist'] = pd.notnull(p.get('assister'))\n        p['is_block'] = pd.notnull(p.get('blocker'))\n        shooter_home = p['shooter'] in hm_roster\n        p['off_team'] = hm if shooter_home else aw\n        p['def_team'] = aw if shooter_home else hm\n        return p\n\n    # parsing jump balls\n    jumpRE = ((r'Jump ball: (?P<away_jumper>{0}) vs\\. (?P<home_jumper>{0})'\n               r'(?: \\((?P<gains_poss>{0}) gains possession\\))?')\n              .format(PLAYER_RE))\n    m = re.match(jumpRE, details, re.IGNORECASE)\n    if m:\n        p['is_jump_ball'] = True\n        p.update(m.groupdict())\n        return p\n\n    # parsing rebounds\n    rebRE = (r'(?P<is_oreb>Offensive|Defensive) rebound'\n             r' by (?P<rebounder>{0}|Team)').format(PLAYER_RE)\n    m = re.match(rebRE, details, re.I)\n    if m:\n        p['is_reb'] = True\n        p.update(m.groupdict())\n        p['is_oreb'] = p['is_oreb'].lower() == 'offensive'\n        p['is_dreb'] = not p['is_oreb']\n        if p['rebounder'] == 'Team':\n            p['reb_team'], other = (hm, aw) if is_hm else (aw, hm)\n        else:\n            reb_home = p['rebounder'] in hm_roster\n            p['reb_team'], other = (hm, aw) if reb_home else (aw, hm)\n        p['off_team'] = p['reb_team'] if p['is_oreb'] else other\n        p['def_team'] = p['reb_team'] if p['is_dreb'] else other\n        return p\n\n    # parsing free throws\n    ftRE = (r'(?P<ft_shooter>{}) (?P<is_ftm>makes|misses) '\n            r'(?P<is_tech_fta>technical )?(?P<is_flag_fta>flagrant )?'\n            r'(?P<is_clearpath_fta>clear path )?free throw'\n            r'(?: (?P<fta_num>\\d+) of (?P<tot_fta>\\d+))?').format(PLAYER_RE)\n    m = re.match(ftRE, details, re.I)\n    if m:\n        p['is_fta'] = True\n        p.update(m.groupdict())\n        p['is_ftm'] = p['is_ftm'] == 'makes'\n        p['is_tech_fta'] = bool(p['is_tech_fta'])\n        p['is_flag_fta'] = bool(p['is_flag_fta'])\n        p['is_clearpath_fta'] = bool(p['is_clearpath_fta'])\n        p['is_pf_fta'] = not p['is_tech_fta']\n        if p['tot_fta']:\n            p['tot_fta'] = int(p['tot_fta'])\n        if p['fta_num']:\n            p['fta_num'] = int(p['fta_num'])\n        ft_home = p['ft_shooter'] in hm_roster\n        p['fta_team'] = hm if ft_home else aw\n        if not p['is_tech_fta']:\n            p['off_team'] = hm if ft_home else aw\n            p['def_team'] = aw if ft_home else hm\n        return p\n\n    # parsing substitutions\n    subRE = (r'(?P<sub_in>{0}) enters the game for '\n             r'(?P<sub_out>{0})').format(PLAYER_RE)\n    m = re.match(subRE, details, re.I)\n    if m:\n        p['is_sub'] = True\n        p.update(m.groupdict())\n        sub_home = p['sub_in'] in hm_roster or p['sub_out'] in hm_roster\n        p['sub_team'] = hm if sub_home else aw\n        return p\n\n    # parsing turnovers\n    toReasons = (r'(?P<to_type>[^;]+)(?:; steal by '\n                 r'(?P<stealer>{0}))?').format(PLAYER_RE)\n    toRE = (r'Turnover by (?P<to_by>{}|Team) '\n            r'\\((?:{})\\)').format(PLAYER_RE, toReasons)\n    m = re.match(toRE, details, re.I)\n    if m:\n        p['is_to'] = True\n        p.update(m.groupdict())\n        p['to_type'] = p['to_type'].lower()\n        if p['to_type'] == 'offensive foul':\n            return None\n        p['is_steal'] = pd.notnull(p['stealer'])\n        p['is_travel'] = p['to_type'] == 'traveling'\n        p['is_shot_clock_viol'] = p['to_type'] == 'shot clock'\n        p['is_oob'] = p['to_type'] == 'step out of bounds'\n        p['is_three_sec_viol'] = p['to_type'] == '3 sec'\n        p['is_backcourt_viol'] = p['to_type'] == 'back court'\n        p['is_off_goaltend'] = p['to_type'] == 'offensive goaltending'\n        p['is_double_dribble'] = p['to_type'] == 'dbl dribble'\n        p['is_discont_dribble'] = p['to_type'] == 'discontinued dribble'\n        p['is_carry'] = p['to_type'] == 'palming'\n        if p['to_by'] == 'Team':\n            p['off_team'] = hm if is_hm else aw\n            p['def_team'] = aw if is_hm else hm\n        else:\n            to_home = p['to_by'] in hm_roster\n            p['off_team'] = hm if to_home else aw\n            p['def_team'] = aw if to_home else hm\n        return p\n\n    # parsing shooting fouls\n    shotFoulRE = (r'Shooting(?P<is_block_foul> block)? foul by (?P<fouler>{0})'\n                  r'(?: \\(drawn by (?P<drew_foul>{0})\\))?').format(PLAYER_RE)\n    m = re.match(shotFoulRE, details, re.I)\n    if m:\n        p['is_pf'] = True\n        p['is_shot_foul'] = True\n        p.update(m.groupdict())\n        p['is_block_foul'] = bool(p['is_block_foul'])\n        foul_on_home = p['fouler'] in hm_roster\n        p['off_team'] = aw if foul_on_home else hm\n        p['def_team'] = hm if foul_on_home else aw\n        p['foul_team'] = p['def_team']\n        return p\n\n    # parsing offensive fouls\n    offFoulRE = (r'Offensive(?P<is_charge> charge)? foul '\n                 r'by (?P<to_by>{0})'\n                 r'(?: \\(drawn by (?P<drew_foul>{0})\\))?').format(PLAYER_RE)\n    m = re.match(offFoulRE, details, re.I)\n    if m:\n        p['is_pf'] = True\n        p['is_off_foul'] = True\n        p['is_to'] = True\n        p['to_type'] = 'offensive foul'\n        p.update(m.groupdict())\n        p['is_charge'] = bool(p['is_charge'])\n        p['fouler'] = p['to_by']\n        foul_on_home = p['fouler'] in hm_roster\n        p['off_team'] = hm if foul_on_home else aw\n        p['def_team'] = aw if foul_on_home else hm\n        p['foul_team'] = p['off_team']\n        return p\n\n    # parsing personal fouls\n    foulRE = (r'Personal (?P<is_take_foul>take )?(?P<is_block_foul>block )?'\n              r'foul by (?P<fouler>{0})(?: \\(drawn by '\n              r'(?P<drew_foul>{0})\\))?').format(PLAYER_RE)\n    m = re.match(foulRE, details, re.I)\n    if m:\n        p['is_pf'] = True\n        p.update(m.groupdict())\n        p['is_take_foul'] = bool(p['is_take_foul'])\n        p['is_block_foul'] = bool(p['is_block_foul'])\n        foul_on_home = p['fouler'] in hm_roster\n        p['off_team'] = aw if foul_on_home else hm\n        p['def_team'] = hm if foul_on_home else aw\n        p['foul_team'] = p['def_team']\n        return p\n\n    # TODO: parsing double personal fouls\n    # double_foul_re = (r'Double personal foul by (?P<fouler1>{0}) and '\n    #                   r'(?P<fouler2>{0})').format(PLAYER_RE)\n    # m = re.match(double_Foul_re, details, re.I)\n    # if m:\n    #     p['is_pf'] = True\n    #     p.update(m.groupdict())\n    #     p['off_team'] =\n\n    # parsing loose ball fouls\n    looseBallRE = (r'Loose ball foul by (?P<fouler>{0})'\n                   r'(?: \\(drawn by (?P<drew_foul>{0})\\))?').format(PLAYER_RE)\n    m = re.match(looseBallRE, details, re.I)\n    if m:\n        p['is_pf'] = True\n        p['is_loose_ball_foul'] = True\n        p.update(m.groupdict())\n        foul_home = p['fouler'] in hm_roster\n        p['foul_team'] = hm if foul_home else aw\n        return p\n\n    # parsing punching fouls\n    # TODO\n\n    # parsing away from play fouls\n    awayFromBallRE = ((r'Away from play foul by (?P<fouler>{0})'\n                       r'(?: \\(drawn by (?P<drew_foul>{0})\\))?')\n                      .format(PLAYER_RE))\n    m = re.match(awayFromBallRE, details, re.I)\n    if m:\n        p['is_pf'] = True\n        p['is_away_from_play_foul'] = True\n        p.update(m.groupdict())\n        foul_on_home = p['fouler'] in hm_roster\n        # TODO: figure out who had the ball based on previous play\n        p['foul_team'] = hm if foul_on_home else aw\n        return p\n\n    # parsing inbound fouls\n    inboundRE = (r'Inbound foul by (?P<fouler>{0})'\n                 r'(?: \\(drawn by (?P<drew_foul>{0})\\))?').format(PLAYER_RE)\n    m = re.match(inboundRE, details, re.I)\n    if m:\n        p['is_pf'] = True\n        p['is_inbound_foul'] = True\n        p.update(m.groupdict())\n        foul_on_home = p['fouler'] in hm_roster\n        p['off_team'] = aw if foul_on_home else hm\n        p['def_team'] = hm if foul_on_home else aw\n        p['foul_team'] = p['def_team']\n        return p\n\n    # parsing flagrant fouls\n    flagrantRE = (r'Flagrant foul type (?P<flag_type>1|2) by (?P<fouler>{0})'\n                  r'(?: \\(drawn by (?P<drew_foul>{0})\\))?').format(PLAYER_RE)\n    m = re.match(flagrantRE, details, re.I)\n    if m:\n        p['is_pf'] = True\n        p['is_flagrant'] = True\n        p.update(m.groupdict())\n        foul_on_home = p['fouler'] in hm_roster\n        p['foul_team'] = hm if foul_on_home else aw\n        return p\n\n    # parsing clear path fouls\n    clearPathRE = (r'Clear path foul by (?P<fouler>{0})'\n                   r'(?: \\(drawn by (?P<drew_foul>{0})\\))?').format(PLAYER_RE)\n    m = re.match(clearPathRE, details, re.I)\n    if m:\n        p['is_pf'] = True\n        p['is_clear_path_foul'] = True\n        p.update(m.groupdict())\n        foul_on_home = p['fouler'] in hm_roster\n        p['off_team'] = aw if foul_on_home else hm\n        p['def_team'] = hm if foul_on_home else aw\n        p['foul_team'] = p['def_team']\n        return p\n\n    # parsing timeouts\n    timeoutRE = r'(?P<timeout_team>.*?) (?:full )?timeout'\n    m = re.match(timeoutRE, details, re.I)\n    if m:\n        p['is_timeout'] = True\n        p.update(m.groupdict())\n        isOfficialTO = p['timeout_team'].lower() == 'official'\n        name_to_id = season.team_names_to_ids()\n        p['timeout_team'] = (\n            'Official' if isOfficialTO else\n            name_to_id.get(hm, name_to_id.get(aw, p['timeout_team']))\n        )\n        return p\n\n    # parsing technical fouls\n    techRE = (r'(?P<is_hanging>Hanging )?'\n              r'(?P<is_taunting>Taunting )?'\n              r'(?P<is_ill_def>Ill def )?'\n              r'(?P<is_delay>Delay )?'\n              r'(?P<is_unsport>Non unsport )?'\n              r'tech(?:nical)? foul by '\n              r'(?P<tech_fouler>{0}|Team)').format(PLAYER_RE)\n    m = re.match(techRE, details, re.I)\n    if m:\n        p['is_tech_foul'] = True\n        p.update(m.groupdict())\n        p['is_hanging'] = bool(p['is_hanging'])\n        p['is_taunting'] = bool(p['is_taunting'])\n        p['is_ill_def'] = bool(p['is_ill_def'])\n        p['is_delay'] = bool(p['is_delay'])\n        p['is_unsport'] = bool(p['is_unsport'])\n        foul_on_home = p['tech_fouler'] in hm_roster\n        p['foul_team'] = hm if foul_on_home else aw\n        return p\n\n    # parsing ejections\n    ejectRE = r'(?P<ejectee>{0}|Team) ejected from game'.format(PLAYER_RE)\n    m = re.match(ejectRE, details, re.I)\n    if m:\n        p['is_ejection'] = True\n        p.update(m.groupdict())\n        if p['ejectee'] == 'Team':\n            p['ejectee_team'] = hm if is_hm else aw\n        else:\n            eject_home = p['ejectee'] in hm_roster\n            p['ejectee_team'] = hm if eject_home else aw\n        return p\n\n    # parsing defensive 3 seconds techs\n    def3TechRE = (r'(?:Def 3 sec tech foul|Defensive three seconds)'\n                  r' by (?P<tech_fouler>{})').format(PLAYER_RE)\n    m = re.match(def3TechRE, details, re.I)\n    if m:\n        p['is_tech_foul'] = True\n        p['is_def_three_secs'] = True\n        p.update(m.groupdict())\n        foul_on_home = p['tech_fouler'] in hm_roster\n        p['off_team'] = aw if foul_on_home else hm\n        p['def_team'] = hm if foul_on_home else aw\n        p['foul_team'] = p['def_team']\n        return p\n\n    # parsing violations\n    violRE = (r'Violation by (?P<violator>{0}|Team) '\n              r'\\((?P<viol_type>.*)\\)').format(PLAYER_RE)\n    m = re.match(violRE, details, re.I)\n    if m:\n        p['is_viol'] = True\n        p.update(m.groupdict())\n        if p['viol_type'] == 'kicked_ball':\n            p['is_to'] = True\n            p['to_by'] = p['violator']\n        if p['violator'] == 'Team':\n            p['viol_team'] = hm if is_hm else aw\n        else:\n            viol_home = p['violator'] in hm_roster\n            p['viol_team'] = hm if viol_home else aw\n        return p\n\n    p['is_error'] = True\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfixing up columns of the passed DataFrame such as casting T/F columns to boolean and filling in NaNs for team and opp.", "response": "def clean_features(df):\n    \"\"\"Fixes up columns of the passed DataFrame, such as casting T/F columns to\n    boolean and filling in NaNs for team and opp.\n\n    :param df: DataFrame of play-by-play data.\n    :returns: Dataframe with cleaned columns.\n    \"\"\"\n    df = pd.DataFrame(df)\n\n    bool_vals = set([True, False, None, np.nan])\n    sparse_cols = sparse_lineup_cols(df)\n    for col in df:\n\n        # make indicator columns boolean type (and fill in NaNs)\n        if set(df[col].unique()[:5]) <= bool_vals:\n            df[col] = (df[col] == True)\n\n        # fill NaN's in sparse lineup columns to 0\n        elif col in sparse_cols:\n            df[col] = df[col].fillna(0)\n\n    # fix free throw columns on technicals\n    df.loc[df.is_tech_fta, ['fta_num', 'tot_fta']] = 1\n\n    # fill in NaN's/fix off_team and def_team columns\n    df.off_team.fillna(method='bfill', inplace=True)\n    df.def_team.fillna(method='bfill', inplace=True)\n    df.off_team.fillna(method='ffill', inplace=True)\n    df.def_team.fillna(method='ffill', inplace=True)\n\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of tuples containing the set of period starters for each quarter in the game.", "response": "def get_period_starters(df):\n    \"\"\"TODO\n    \"\"\"\n\n    def players_from_play(play):\n        \"\"\"Figures out what players are in the game based on the players\n        mentioned in a play. Returns away and home players as two sets.\n\n        :param play: A dictionary representing a parsed play.\n        :returns: (aw_players, hm_players)\n        :rtype: tuple of lists\n        \"\"\"\n        # if it's a tech FT from between periods, don't count this play\n        if (\n            play['clock_time'] == '12:00.0' and\n            (play.get('is_tech_foul') or play.get('is_tech_fta'))\n        ):\n            return [], []\n\n        stats = sportsref.nba.BoxScore(play['boxscore_id']).basic_stats()\n        home_grouped = stats.groupby('is_home')\n        hm_roster = set(home_grouped.player_id.get_group(True).values)\n        aw_roster = set(home_grouped.player_id.get_group(False).values)\n        player_keys = [\n            'assister', 'away_jumper', 'blocker', 'drew_foul', 'fouler',\n            'ft_shooter', 'gains_poss', 'home_jumper', 'rebounder', 'shooter',\n            'stealer', 'sub_in', 'sub_out', 'to_by'\n        ]\n        players = [p for p in play[player_keys] if pd.notnull(p)]\n\n        aw_players = [p for p in players if p in aw_roster]\n        hm_players = [p for p in players if p in hm_roster]\n        return aw_players, hm_players\n\n    # create a mapping { quarter => (away_starters, home_starters) }\n    n_periods = df.quarter.nunique()\n    period_starters = [(set(), set()) for _ in range(n_periods)]\n\n    # fill out this mapping quarter by quarter\n    for qtr, qtr_grp in df.groupby(df.quarter):\n        aw_starters, hm_starters = period_starters[qtr-1]\n        exclude = set()\n        # loop through sets of plays that happen at the \"same time\"\n        for label, time_grp in qtr_grp.groupby(qtr_grp.secs_elapsed):\n            # first, if they sub in and weren't already starters, exclude them\n            sub_ins = set(time_grp.sub_in.dropna().values)\n            exclude.update(sub_ins - aw_starters - hm_starters)\n            # second, figure out new starters from each play at this time\n            for i, row in time_grp.iterrows():\n                aw_players, hm_players = players_from_play(row)\n                # update overall sets for the quarter\n                aw_starters.update(aw_players)\n                hm_starters.update(hm_players)\n            # remove excluded (subbed-in) players\n            hm_starters -= exclude\n            aw_starters -= exclude\n            # check whether we have found all starters\n            if len(hm_starters) > 5 or len(aw_starters) > 5:\n                import ipdb\n                ipdb.set_trace()\n            if len(hm_starters) >= 5 and len(aw_starters) >= 5:\n                break\n\n        if len(hm_starters) != 5 or len(aw_starters) != 5:\n            print('WARNING: wrong number of starters for a team in Q{} of {}'\n                  .format(qtr, df.boxscore_id.iloc[0]))\n\n    return period_starters"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_sparse_lineups(df):\n\n    # get the lineup data using get_dense_lineups if necessary\n    if (set(ALL_LINEUP_COLS) - set(df.columns)):\n        lineup_df = get_dense_lineups(df)\n    else:\n        lineup_df = df[ALL_LINEUP_COLS]\n\n    # create the sparse representation\n    hm_lineups = lineup_df[HM_LINEUP_COLS].values\n    aw_lineups = lineup_df[AW_LINEUP_COLS].values\n    # +1 for home, -1 for away\n    hm_df = pd.DataFrame([\n        {'{}_in'.format(player_id): 1 for player_id in lineup}\n        for lineup in hm_lineups\n    ], dtype=int)\n    aw_df = pd.DataFrame([\n        {'{}_in'.format(player_id): -1 for player_id in lineup}\n        for lineup in aw_lineups\n    ], dtype=int)\n    sparse_df = pd.concat((hm_df, aw_df), axis=1).fillna(0)\n    return sparse_df", "response": "Get the sparse representation of the lineups."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_dense_lineups(df):\n    # TODO: add this precondition to documentation\n    assert df['boxscore_id'].nunique() == 1\n\n    def lineup_dict(aw_lineup, hm_lineup):\n        \"\"\"Returns a dictionary of lineups to be converted to columns.\n        Specifically, the columns are 'aw_player1' through 'aw_player5' and\n        'hm_player1' through 'hm_player5'.\n\n        :param aw_lineup: The away team's current lineup.\n        :param hm_lineup: The home team's current lineup.\n        :returns: A dictionary of lineups.\n        \"\"\"\n        return {\n            '{}_player{}'.format(tm, i+1): player\n            for tm, lineup in zip(['aw', 'hm'], [aw_lineup, hm_lineup])\n            for i, player in enumerate(lineup)\n        }\n\n    def handle_sub(row, aw_lineup, hm_lineup):\n        \"\"\"Modifies the aw_lineup and hm_lineup lists based on the substitution\n        that takes place in the given row.\"\"\"\n        assert row['is_sub']\n        sub_lineup = hm_lineup if row['sub_team'] == row['home'] else aw_lineup\n        try:\n            # make the sub\n            idx = sub_lineup.index(row['sub_out'])\n            sub_lineup[idx] = row['sub_in']\n        except ValueError:\n            # if the sub was double-entered and it's already been executed...\n            if (\n                row['sub_in'] in sub_lineup\n                and row['sub_out'] not in sub_lineup\n            ):\n                return aw_lineup, hm_lineup\n            # otherwise, let's print and pretend this never happened\n            print('ERROR IN SUB IN {}, Q{}, {}: {}'\n                  .format(row['boxscore_id'], row['quarter'],\n                          row['clock_time'], row['detail']))\n            raise\n        return aw_lineup, hm_lineup\n\n    per_starters = get_period_starters(df)\n    cur_qtr = 0\n    aw_lineup, hm_lineup = [], []\n    df = df.reset_index(drop=True)\n    lineups = [{} for _ in range(df.shape[0])]\n\n    # loop through select plays to determine lineups\n    sub_or_per_start = df.is_sub | df.quarter.diff().astype(bool)\n    for i, row in df.loc[sub_or_per_start].iterrows():\n        if row['quarter'] > cur_qtr:\n            # first row in a quarter\n            assert row['quarter'] == cur_qtr + 1\n            # first, finish up the last quarter's lineups\n            if cur_qtr > 0 and not df.loc[i-1, 'is_sub']:\n                lineups[i-1] = lineup_dict(aw_lineup, hm_lineup)\n            # then, move on to the quarter, and enter the starting lineups\n            cur_qtr += 1\n            aw_lineup, hm_lineup = map(list, per_starters[cur_qtr-1])\n            lineups[i] = lineup_dict(aw_lineup, hm_lineup)\n            # if the first play in the quarter is a sub, handle that\n            if row['is_sub']:\n                aw_lineup, hm_lineup = handle_sub(row, aw_lineup, hm_lineup)\n        else:\n            # during the quarter\n            # update lineups first then change lineups based on subs\n            lineups[i] = lineup_dict(aw_lineup, hm_lineup)\n            if row['is_sub']:\n                aw_lineup, hm_lineup = handle_sub(row, aw_lineup, hm_lineup)\n\n    # create and clean DataFrame\n    lineup_df = pd.DataFrame(lineups)\n    if lineup_df.iloc[-1].isnull().all():\n        lineup_df.iloc[-1] = lineup_dict(aw_lineup, hm_lineup)\n    lineup_df = lineup_df.groupby(df.quarter).fillna(method='bfill')\n\n    # fill in NaN's based on minutes played\n    bool_mat = lineup_df.isnull()\n    mask = bool_mat.any(axis=1)\n    if mask.any():\n        bs = sportsref.nba.BoxScore(df.boxscore_id[0])\n        # first, get the true minutes played from the box score\n        stats = sportsref.nba.BoxScore(df.boxscore_id.iloc[0]).basic_stats()\n        true_mp = pd.Series(\n            stats.query('mp > 0')[['player_id', 'mp']]\n            .set_index('player_id').to_dict()['mp']\n        ) * 60\n        # next, calculate minutes played based on the lineup data\n        calc_mp = pd.Series(\n            {p: (df.secs_elapsed.diff() *\n                 [p in row for row in lineup_df.values]).sum()\n             for p in stats.query('mp > 0').player_id.values})\n        # finally, figure which players are missing minutes\n        diff = true_mp - calc_mp\n        players_missing = diff.loc[diff.abs() >= 150]\n        hm_roster = bs.basic_stats().query('is_home == True').player_id.values\n        missing_df = pd.DataFrame(\n            {'secs': players_missing.values,\n             'is_home': players_missing.index.isin(hm_roster)},\n            index=players_missing.index\n        )\n\n        if missing_df.empty:\n            # TODO: log this as a warning (or error?)\n            print('There are NaNs in the lineup data, but no players were '\n                  'found to be missing significant minutes')\n        else:\n            # import ipdb\n            # ipdb.set_trace()\n            for is_home, group in missing_df.groupby('is_home'):\n                player_id = group.index.item()\n                tm_cols = (sportsref.nba.pbp.HM_LINEUP_COLS if is_home else\n                           sportsref.nba.pbp.AW_LINEUP_COLS)\n                row_mask = lineup_df[tm_cols].isnull().any(axis=1)\n                lineup_df.loc[row_mask, tm_cols] = (\n                    lineup_df.loc[row_mask, tm_cols].fillna(player_id).values\n                )\n\n    return lineup_df", "response": "Returns a DataFrame that contains the lineups for each player in the game."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding all plays in a single page.", "response": "def GamePlayFinder(**kwargs):\n    \"\"\" Docstring will be filled in by __init__.py \"\"\"\n\n    querystring = _kwargs_to_qs(**kwargs)\n    url = '{}?{}'.format(GPF_URL, querystring)\n    # if verbose, print url\n    if kwargs.get('verbose', False):\n        print(url)\n    html = utils.get_html(url)\n    doc = pq(html)\n\n    # parse\n    table = doc('table#all_plays')\n    plays = utils.parse_table(table)\n\n    # parse score column\n    if 'score' in plays.columns:\n        oScore, dScore = zip(*plays.score.apply(lambda s: s.split('-')))\n        plays['teamScore'] = oScore\n        plays['oppScore'] = dScore\n    # add parsed pbp info\n    if 'description' in plays.columns:\n        plays = pbp.expand_details(plays, detailCol='description')\n\n    return plays"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _kwargs_to_qs(**kwargs):\n    # start with defaults\n    inpOptDef = inputs_options_defaults()\n    opts = {\n        name: dct['value']\n        for name, dct in inpOptDef.items()\n    }\n\n    # clean up keys and values\n    for k, v in kwargs.items():\n        # pID, playerID => player_id\n        if k.lower() in ('pid', 'playerid'):\n            del kwargs[k]\n            kwargs['player_id'] = v\n        # player_id can accept rel URLs\n        if k == 'player_id':\n            if v.startswith('/players/'):\n                kwargs[k] = utils.rel_url_to_id(v)\n        # bool => 'Y'|'N'\n        if isinstance(v, bool):\n            kwargs[k] = 'Y' if v else 'N'\n        # tm, team => team_id\n        if k.lower() in ('tm', 'team'):\n            del kwargs[k]\n            kwargs['team_id'] = v\n        # yr_min, yr_max => year_min, year_max\n        if k.lower() in ('yr_min', 'yr_max'):\n            del kwargs[k]\n            if k.lower() == 'yr_min':\n                kwargs['year_min'] = int(v)\n            else:\n                kwargs['year_max'] = int(v)\n        # wk_min, wk_max => week_num_min, week_num_max\n        if k.lower() in ('wk_min', 'wk_max'):\n            del kwargs[k]\n            if k.lower() == 'wk_min':\n                kwargs['week_num_min'] = int(v)\n            else:\n                kwargs['week_num_max'] = int(v)\n        # yr, year, yrs, years => year_min, year_max\n        if k.lower() in ('yr', 'year', 'yrs', 'years'):\n            del kwargs[k]\n            if isinstance(v, collections.Iterable):\n                lst = list(v)\n                kwargs['year_min'] = min(lst)\n                kwargs['year_max'] = max(lst)\n            elif isinstance(v, basestring):\n                v = list(map(int, v.split(',')))\n                kwargs['year_min'] = min(v)\n                kwargs['year_max'] = max(v)\n            else:\n                kwargs['year_min'] = v\n                kwargs['year_max'] = v\n        # wk, week, wks, weeks => week_num_min, week_num_max\n        if k.lower() in ('wk', 'week', 'wks', 'weeks'):\n            del kwargs[k]\n            if isinstance(v, collections.Iterable):\n                lst = list(v)\n                kwargs['week_num_min'] = min(lst)\n                kwargs['week_num_max'] = max(lst)\n            elif isinstance(v, basestring):\n                v = list(map(int, v.split(',')))\n                kwargs['week_num_min'] = min(v)\n                kwargs['week_num_max'] = max(v)\n            else:\n                kwargs['week_num_min'] = v\n                kwargs['week_num_max'] = v\n        # if playoff_round defined, then turn on playoff flag\n        if k == 'playoff_round':\n            kwargs['game_type'] = 'P'\n        if isinstance(v, basestring):\n            v = v.split(',')\n        if not isinstance(v, collections.Iterable):\n            v = [v]\n\n    # reset values to blank for defined kwargs\n    for k in kwargs:\n        if k in opts:\n            opts[k] = []\n\n    # update based on kwargs\n    for k, v in kwargs.items():\n        # if overwriting a default, overwrite it\n        if k in opts:\n            # if multiple values separated by commas, split em\n            if isinstance(v, basestring):\n                v = v.split(',')\n            elif not isinstance(v, collections.Iterable):\n                v = [v]\n            for val in v:\n                opts[k].append(val)\n\n    opts['request'] = [1]\n\n    qs = '&'.join('{}={}'.format(name, val)\n                  for name, vals in sorted(opts.items()) for val in vals)\n\n    return qs", "response": "Converts kwargs given to GPF to a querystring."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inputs_options_defaults():\n    # set time variables\n    if os.path.isfile(GPF_CONSTANTS_FILENAME):\n        modtime = int(os.path.getmtime(GPF_CONSTANTS_FILENAME))\n        curtime = int(time.time())\n    # if file found and it's been <= a week\n    if (os.path.isfile(GPF_CONSTANTS_FILENAME)\n            and curtime - modtime <= 7 * 24 * 60 * 60):\n\n        # just read the dict from the cached file\n        with open(GPF_CONSTANTS_FILENAME, 'r') as const_f:\n            def_dict = json.load(const_f)\n\n    # otherwise, we must regenerate the dict and rewrite it\n    else:\n\n        print('Regenerating GPFConstants file')\n\n        html = utils.get_html(GPF_URL)\n        doc = pq(html)\n\n        def_dict = {}\n        # start with input elements\n        for inp in doc('form#play_finder input[name]'):\n            name = inp.attrib['name']\n            # add blank dict if not present\n            if name not in def_dict:\n                def_dict[name] = {\n                    'value': set(),\n                    'options': set(),\n                    'type': inp.type\n                }\n\n            val = inp.attrib.get('value', '')\n            # handle checkboxes and radio buttons\n            if inp.type in ('checkbox', 'radio'):\n                # deal with default value\n                if 'checked' in inp.attrib:\n                    def_dict[name]['value'].add(val)\n                # add to options\n                def_dict[name]['options'].add(val)\n            # handle other types of inputs (only other type is hidden?)\n            else:\n                def_dict[name]['value'].add(val)\n\n        # for dropdowns (select elements)\n        for sel in doc.items('form#play_finder select[name]'):\n            name = sel.attr['name']\n            # add blank dict if not present\n            if name not in def_dict:\n                def_dict[name] = {\n                    'value': set(),\n                    'options': set(),\n                    'type': 'select'\n                }\n\n            # deal with default value\n            defaultOpt = sel('option[selected]')\n            if len(defaultOpt):\n                defaultOpt = defaultOpt[0]\n                def_dict[name]['value'].add(defaultOpt.attrib.get('value', ''))\n            else:\n                def_dict[name]['value'].add(\n                    sel('option')[0].attrib.get('value', '')\n                )\n\n            # deal with options\n            def_dict[name]['options'] = {\n                opt.attrib['value'] for opt in sel('option')\n                if opt.attrib.get('value')\n            }\n\n        # ignore QB kneels by default\n        def_dict['include_kneels']['value'] = ['0']\n\n        def_dict.pop('request', None)\n        def_dict.pop('use_favorites', None)\n\n        with open(GPF_CONSTANTS_FILENAME, 'w+') as f:\n            for k in def_dict:\n                try:\n                    def_dict[k]['value'] = sorted(\n                        list(def_dict[k]['value']), key=int\n                    )\n                    def_dict[k]['options'] = sorted(\n                        list(def_dict[k]['options']), key=int\n                    )\n                except:\n                    def_dict[k]['value'] = sorted(list(def_dict[k]['value']))\n                    def_dict[k]['options'] = sorted(\n                        list(def_dict[k]['options'])\n                    )\n            json.dump(def_dict, f)\n\n    return def_dict", "response": "Handles scraping options for play finder form."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self):\n        '''\n        Please don't do this in production environments.\n        '''\n        self.write(\"Memory Session Object Demo:\")\n        if \"sv\" in self.session:\n            current_value = self.session[\"sv\"]\n            self.write(\"current sv value is %s, and system will delete this value.<br/>\" % self.session[\"sv\"])\n            self.session.delete(\"sv\")\n            if \"sv\" not in self.session:\n                self.write(\"current sv value is empty\")\n        else:\n            self.write(\"Session data not found\")", "response": "Get the current object from the session."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexpanding the details column of the given dataframe and returns the resulting DataFrame.", "response": "def expand_details(df, detailCol='detail'):\n    \"\"\"Expands the details column of the given dataframe and returns the\n    resulting DataFrame.\n\n    :df: The input DataFrame.\n    :detailCol: The detail column name.\n    :returns: Returns DataFrame with new columns from pbp parsing.\n    \"\"\"\n    df = copy.deepcopy(df)\n    df['detail'] = df[detailCol]\n    dicts = [sportsref.nfl.pbp.parse_play_details(detail) for detail in df['detail'].values]\n    # clean up unmatched details\n    cols = {c for d in dicts if d for c in d.keys()}\n    blankEntry = {c: np.nan for c in cols}\n    newDicts = [d if d else blankEntry for d in dicts]\n    # get details DataFrame and merge it with original to create main DataFrame\n    details = pd.DataFrame(newDicts)\n    df = pd.merge(df, details, left_index=True, right_index=True)\n    # add isError column\n    errors = [i for i, d in enumerate(dicts) if d is None]\n    df['isError'] = False\n    df.loc[errors, 'isError'] = True\n    # fill in some NaN's necessary for _clean_features\n    df.loc[0, 'qtr_time_remain'] = '15:00'\n    df.qtr_time_remain.fillna(method='bfill', inplace=True)\n    df.qtr_time_remain.fillna(\n        pd.Series(np.where(df.quarter == 4, '0:00', '15:00')), inplace=True\n    )\n    # use _clean_features to clean up and add columns\n    new_df = df.apply(_clean_features, axis=1)\n    return new_df"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses play - by - play string and returns structured data.", "response": "def parse_play_details(details):\n    \"\"\"Parses play details from play-by-play string and returns structured\n    data.\n\n    :details: detail string for play\n    :returns: dictionary of play attributes\n    \"\"\"\n\n    # if input isn't a string, return None\n    if not isinstance(details, basestring):\n        return None\n\n    rushOptRE = r'(?P<rushDir>{})'.format(\n        r'|'.join(RUSH_OPTS.keys())\n    )\n    passOptRE = r'(?P<passLoc>{})'.format(\n        r'|'.join(PASS_OPTS.keys())\n    )\n\n    playerRE = r\"\\S{6,8}\\d{2}\"\n\n    # initialize return dictionary - struct\n    struct = {}\n\n    # handle challenges\n    # TODO: record the play both before & after an overturned challenge\n    challengeRE = re.compile(\n        r'.+\\. (?P<challenger>.+?) challenged.*? the play was '\n        '(?P<callUpheld>upheld|overturned)\\.',\n        re.IGNORECASE\n    )\n    match = challengeRE.search(details)\n    if match:\n        struct['isChallenge'] = True\n        struct.update(match.groupdict())\n        # if overturned, only record updated play\n        if 'overturned' in details:\n            overturnedIdx = details.index('overturned.')\n            newStart = overturnedIdx + len('overturned.')\n            details = details[newStart:].strip()\n    else:\n        struct['isChallenge'] = False\n\n    # TODO: expand on laterals\n    struct['isLateral'] = details.find('lateral') != -1\n\n    # create rushing regex\n    rusherRE = r\"(?P<rusher>{0})\".format(playerRE)\n    rushOptRE = r\"(?: {})?\".format(rushOptRE)\n    rushYardsRE = r\"(?:(?:(?P<rushYds>\\-?\\d+) yards?)|(?:no gain))\"\n    # cases: tackle, fumble, td, penalty\n    tackleRE = (r\"(?: \\(tackle by (?P<tackler1>{0})\"\n                r\"(?: and (?P<tackler2>{0}))?\\))?\"\n                .format(playerRE))\n    # currently, plays with multiple fumbles record the original fumbler\n    # and the final fumble recoverer\n    fumbleRE = (\n        r\"(?:\"\n        r\"\\.? ?(?P<fumbler>{0}) fumbles\"\n        r\"(?: \\(forced by (?P<fumbForcer>{0})\\))?\"\n        r\"(?:.*, recovered by (?P<fumbRecoverer>{0}) at )?\"\n        r\"(?:, ball out of bounds at )?\"\n        r\"(?:(?P<fumbRecFieldSide>[a-z]+)?\\-?(?P<fumbRecYdLine>\\-?\\d+))?\"\n        r\"(?: and returned for (?P<fumbRetYds>\\-?\\d*) yards)?\"\n        r\")?\"\n        .format(playerRE))\n    tdSafetyRE = r\"(?:(?P<isTD>, touchdown)|(?P<isSafety>, safety))?\"\n    # TODO: offsetting penalties\n    penaltyRE = (r\"(?:.*?\"\n                 r\"\\. Penalty on (?P<penOn>{0}|): \"\n                 r\"(?P<penalty>[^\\(,]+)\"\n                 r\"(?: \\((?P<penDeclined>Declined)\\)|\"\n                 r\", (?P<penYds>\\d*) yards?)\"\n                 r\"(?: \\(no play\\))?\"\n                 r\")?\"\n                 .format(playerRE))\n\n    rushREstr = (\n        r\"{}{}(?: for {}{}{}{}{})?\"\n    ).format(rusherRE, rushOptRE, rushYardsRE, tackleRE, fumbleRE, tdSafetyRE,\n             penaltyRE)\n    rushRE = re.compile(rushREstr, re.IGNORECASE)\n\n    # create passing regex\n    # TODO: capture \"defended by X\" for defensive stats\n    passerRE = r\"(?P<passer>{0})\".format(playerRE)\n    sackRE = (r\"(?:sacked (?:by (?P<sacker1>{0})(?: and (?P<sacker2>{0}))? )?\"\n              r\"for (?P<sackYds>\\-?\\d+) yards?)\"\n              .format(playerRE))\n    # create throw RE\n    completeRE = r\"pass (?P<isComplete>(?:in)?complete)\"\n    passOptRE = r\"(?: {})?\".format(passOptRE)\n    targetedRE = r\"(?: (?:to |intended for )?(?P<target>{0}))?\".format(\n        playerRE)\n    passYardsRE = r\"(?: for (?:(?P<passYds>\\-?\\d+) yards?|no gain))\"\n    intRE = (r'(?: is intercepted by (?P<interceptor>{0}) at '.format(playerRE)\n             + r'(?:(?P<intFieldSide>[a-z]*)?\\-?(?P<intYdLine>\\-?\\d*))?'\n             + r'(?: and returned for (?P<intRetYds>\\-?\\d+) yards?\\.?)?)?')\n    throwRE = r'(?:{}{}{}(?:(?:{}|{}){})?)'.format(\n        completeRE, passOptRE, targetedRE, passYardsRE, intRE, tackleRE\n    )\n    passREstr = (\n        r\"{} (?:{}|{})(?:{}{}{})?\"\n    ).format(passerRE, sackRE, throwRE, fumbleRE, tdSafetyRE, penaltyRE)\n    passRE = re.compile(passREstr, re.IGNORECASE)\n\n    # create kickoff regex\n    koKickerRE = r'(?P<koKicker>{0})'.format(playerRE)\n    koYardsRE = (r' kicks (?:off|(?P<isOnside>onside))'\n                 r' (?:(?P<koYds>\\d+) yards?|no gain)')\n    nextREs = []\n    nextREs.append(\n        (r', (?:returned|recovered) by (?P<koReturner>{0})(?: for '\n         r'(?:(?P<koRetYds>\\-?\\d+) yards?|no gain))?').format(playerRE)\n    )\n    nextREs.append(\n        (r'(?P<isMuffedCatch>, muffed catch by )(?P<muffedBy>{0}),'\n         r'(?: recovered by (?P<muffRecoverer>{0}))?').format(playerRE) +\n        r'(?: and returned for (?:(?P<muffRetYds>\\-?\\d+) yards|no gain))?'\n    )\n    nextREs.append(\n        r', recovered by (?P<onsideRecoverer>{0})'.format(playerRE)\n    )\n    nextREs.append(r'(?P<oob>, out of bounds)')\n    nextREs.append(r'(?P<isTouchback>, touchback)')\n    # TODO: test the following line to fix a small subset of cases\n    # (ex: muff -> oob)\n    nextRE = ''.join(r'(?:{})?'.format(nre) for nre in nextREs)\n    kickoffREstr = r'{}{}{}{}{}{}{}'.format(\n        koKickerRE, koYardsRE, nextRE,\n        tackleRE, fumbleRE, tdSafetyRE, penaltyRE\n    )\n    kickoffRE = re.compile(kickoffREstr, re.IGNORECASE)\n\n    # create timeout regex\n    timeoutREstr = r'Timeout #(?P<timeoutNum>\\d) by (?P<timeoutTeam>.+)'\n    timeoutRE = re.compile(timeoutREstr, re.IGNORECASE)\n\n    # create FG regex\n    fgKickerRE = r'(?P<fgKicker>{0})'.format(playerRE)\n    fgBaseRE = (r' (?P<fgDist>\\d+) yard field goal'\n                r' (?P<fgGood>good|no good)')\n    fgBlockRE = (\n        r'(?:, (?P<isBlocked>blocked) by '\n        r'(?P<fgBlocker>{0}))?'.format(playerRE) +\n        r'(?:, recovered by (?P<fgBlockRecoverer>{0}))?'.format(playerRE) +\n        r'(?: and returned for (?:(?P<fgBlockRetYds>\\-?\\d+) yards?|no gain))?'\n    )\n    fgREstr = r'{}{}{}{}{}'.format(fgKickerRE, fgBaseRE,\n                                   fgBlockRE, tdSafetyRE, penaltyRE)\n    fgRE = re.compile(fgREstr, re.IGNORECASE)\n\n    # create punt regex\n    punterRE = r'.*?(?P<punter>{0})'.format(playerRE)\n    puntBlockRE = (\n        (r' punts, (?P<isBlocked>blocked) by (?P<puntBlocker>{0})'\n         r'(?:, recovered by (?P<puntBlockRecoverer>{0})').format(playerRE) +\n        r'(?: and returned (?:(?P<puntBlockRetYds>\\-?\\d+) yards|no gain))?)?'\n    )\n    puntYdsRE = r' punts (?P<puntYds>\\d+) yards?'\n    nextREs = []\n    nextREs.append(r', (?P<isFairCatch>fair catch) by (?P<fairCatcher>{0})'\n                   .format(playerRE))\n    nextREs.append(r', (?P<oob>out of bounds)')\n    nextREs.append(\n        (r'(?P<isMuffedCatch>, muffed catch by )(?P<muffedBy>{0}),'\n         r' recovered by (?P<muffRecoverer>{0})').format(playerRE) +\n        r' and returned for ' +\n        r'(?:(?P<muffRetYds>\\d+) yards|no gain)'\n    )\n    nextREs.append(\n        r', returned by (?P<puntReturner>{0}) for '.format(playerRE) +\n        r'(?:(?P<puntRetYds>\\-?\\d+) yards?|no gain)'\n    )\n    nextRE = r'(?:{})?'.format('|'.join(nextREs))\n    puntREstr = r'{}(?:{}|{}){}{}{}{}{}'.format(\n        punterRE, puntBlockRE, puntYdsRE, nextRE,\n        tackleRE, fumbleRE, tdSafetyRE, penaltyRE\n    )\n    puntRE = re.compile(puntREstr, re.IGNORECASE)\n\n    # create kneel regex\n    kneelREstr = (r'(?P<kneelQB>{0}) kneels for '.format(playerRE) +\n                  r'(?:(?P<kneelYds>\\-?\\d+) yards?|no gain)')\n    kneelRE = re.compile(kneelREstr, re.IGNORECASE)\n\n    # create spike regex\n    spikeREstr = r'(?P<spikeQB>{0}) spiked the ball'.format(playerRE)\n    spikeRE = re.compile(spikeREstr, re.IGNORECASE)\n\n    # create XP regex\n    extraPointREstr = (r'(?:(?P<xpKicker>{0}) kicks)? ?extra point '\n                       r'(?P<xpGood>good|no good)').format(playerRE)\n    extraPointRE = re.compile(extraPointREstr, re.IGNORECASE)\n\n    # create 2pt conversion regex\n    twoPointREstr = (\n        r'Two Point Attempt: (?P<twoPoint>.*?),?\\s+conversion\\s+'\n        r'(?P<twoPointSuccess>succeeds|fails)'\n    )\n    twoPointRE = re.compile(twoPointREstr, re.IGNORECASE)\n\n    # create penalty regex\n    psPenaltyREstr = (\n        r'^Penalty on (?P<penOn>{0}|'.format(playerRE) + r'\\w{3}): ' +\n        r'(?P<penalty>[^\\(,]+)(?: \\((?P<penDeclined>Declined)\\)|' +\n        r', (?P<penYds>\\d*) yards?|' +\n        r'.*?(?: \\(no play\\)))')\n    psPenaltyRE = re.compile(psPenaltyREstr, re.IGNORECASE)\n\n    # try parsing as a kickoff\n    match = kickoffRE.search(details)\n    if match:\n        # parse as a kickoff\n        struct['isKickoff'] = True\n        struct.update(match.groupdict())\n        return struct\n\n    # try parsing as a timeout\n    match = timeoutRE.search(details)\n    if match:\n        # parse as timeout\n        struct['isTimeout'] = True\n        struct.update(match.groupdict())\n        return struct\n\n    # try parsing as a field goal\n    match = fgRE.search(details)\n    if match:\n        # parse as a field goal\n        struct['isFieldGoal'] = True\n        struct.update(match.groupdict())\n        return struct\n\n    # try parsing as a punt\n    match = puntRE.search(details)\n    if match:\n        # parse as a punt\n        struct['isPunt'] = True\n        struct.update(match.groupdict())\n        return struct\n\n    # try parsing as a kneel\n    match = kneelRE.search(details)\n    if match:\n        # parse as a kneel\n        struct['isKneel'] = True\n        struct.update(match.groupdict())\n        return struct\n\n    # try parsing as a spike\n    match = spikeRE.search(details)\n    if match:\n        # parse as a spike\n        struct['isSpike'] = True\n        struct.update(match.groupdict())\n        return struct\n\n    # try parsing as an XP\n    match = extraPointRE.search(details)\n    if match:\n        # parse as an XP\n        struct['isXP'] = True\n        struct.update(match.groupdict())\n        return struct\n\n    # try parsing as a 2-point conversion\n    match = twoPointRE.search(details)\n    if match:\n        # parse as a 2-point conversion\n        struct['isTwoPoint'] = True\n        struct['twoPointSuccess'] = match.group('twoPointSuccess')\n        realPlay = sportsref.nfl.pbp.parse_play_details(\n            match.group('twoPoint'))\n        if realPlay:\n            struct.update(realPlay)\n        return struct\n\n    # try parsing as a pass\n    match = passRE.search(details)\n    if match:\n        # parse as a pass\n        struct['isPass'] = True\n        struct.update(match.groupdict())\n        return struct\n\n    # try parsing as a pre-snap penalty\n    match = psPenaltyRE.search(details)\n    if match:\n        # parse as a pre-snap penalty\n        struct['isPresnapPenalty'] = True\n        struct.update(match.groupdict())\n        return struct\n\n    # try parsing as a run\n    match = rushRE.search(details)\n    if match:\n        # parse as a run\n        struct['isRun'] = True\n        struct.update(match.groupdict())\n        return struct\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _clean_features(struct):\n    struct = dict(struct)\n    # First, clean up play type bools\n    ptypes = ['isKickoff', 'isTimeout', 'isFieldGoal', 'isPunt', 'isKneel',\n              'isSpike', 'isXP', 'isTwoPoint', 'isPresnapPenalty', 'isPass',\n              'isRun']\n    for pt in ptypes:\n        struct[pt] = struct[pt] if pd.notnull(struct.get(pt)) else False\n    # Second, clean up other existing variables on a one-off basis\n    struct['callUpheld'] = struct.get('callUpheld') == 'upheld'\n    struct['fgGood'] = struct.get('fgGood') == 'good'\n    struct['isBlocked'] = struct.get('isBlocked') == 'blocked'\n    struct['isComplete'] = struct.get('isComplete') == 'complete'\n    struct['isFairCatch'] = struct.get('isFairCatch') == 'fair catch'\n    struct['isMuffedCatch'] = pd.notnull(struct.get('isMuffedCatch'))\n    struct['isNoPlay'] = (\n        ' (no play)' in struct['detail'] and\n        'penalty enforced in end zone' not in struct['detail']\n        if struct.get('detail') else False)\n    struct['isOnside'] = struct.get('isOnside') == 'onside'\n    struct['isSack'] = pd.notnull(struct.get('sackYds'))\n    struct['isSafety'] = (struct.get('isSafety') == ', safety' or\n                          (struct.get('detail') and\n                           'enforced in end zone, safety' in struct['detail']))\n    struct['isTD'] = struct.get('isTD') == ', touchdown'\n    struct['isTouchback'] = struct.get('isTouchback') == ', touchback'\n    struct['oob'] = pd.notnull(struct.get('oob'))\n    struct['passLoc'] = PASS_OPTS.get(struct.get('passLoc'), np.nan)\n    if struct['isPass']:\n        pyds = struct['passYds']\n        struct['passYds'] = pyds if pd.notnull(pyds) else 0\n    if pd.notnull(struct['penalty']):\n        struct['penalty'] = struct['penalty'].strip()\n    struct['penDeclined'] = struct.get('penDeclined') == 'Declined'\n    if struct['quarter'] == 'OT':\n        struct['quarter'] = 5\n    struct['rushDir'] = RUSH_OPTS.get(struct.get('rushDir'), np.nan)\n    if struct['isRun']:\n        ryds = struct['rushYds']\n        struct['rushYds'] = ryds if pd.notnull(ryds) else 0\n    year = struct.get('season', np.nan)\n    struct['timeoutTeam'] = sportsref.nfl.teams.team_ids(year).get(\n        struct.get('timeoutTeam'), np.nan\n    )\n    struct['twoPointSuccess'] = struct.get('twoPointSuccess') == 'succeeds'\n    struct['xpGood'] = struct.get('xpGood') == 'good'\n\n    # Third, ensure types are correct\n    bool_vars = [\n        'fgGood', 'isBlocked', 'isChallenge', 'isComplete', 'isFairCatch',\n        'isFieldGoal', 'isKickoff', 'isKneel', 'isLateral', 'isNoPlay',\n        'isPass', 'isPresnapPenalty', 'isPunt', 'isRun', 'isSack', 'isSafety',\n        'isSpike', 'isTD', 'isTimeout', 'isTouchback', 'isTwoPoint', 'isXP',\n        'isMuffedCatch', 'oob', 'penDeclined', 'twoPointSuccess', 'xpGood'\n    ]\n    int_vars = [\n        'down', 'fgBlockRetYds', 'fgDist', 'fumbRecYdLine', 'fumbRetYds',\n        'intRetYds', 'intYdLine', 'koRetYds', 'koYds', 'muffRetYds',\n        'pbp_score_aw', 'pbp_score_hm', 'passYds', 'penYds', 'puntBlockRetYds',\n        'puntRetYds', 'puntYds', 'quarter', 'rushYds', 'sackYds', 'timeoutNum',\n        'ydLine', 'yds_to_go'\n    ]\n    float_vars = [\n        'exp_pts_after', 'exp_pts_before', 'home_wp'\n    ]\n    string_vars = [\n        'challenger', 'detail', 'fairCatcher', 'fgBlockRecoverer',\n        'fgBlocker', 'fgKicker', 'fieldSide', 'fumbForcer',\n        'fumbRecFieldSide', 'fumbRecoverer', 'fumbler', 'intFieldSide',\n        'interceptor', 'kneelQB', 'koKicker', 'koReturner', 'muffRecoverer',\n        'muffedBy', 'passLoc', 'passer', 'penOn', 'penalty',\n        'puntBlockRecoverer', 'puntBlocker', 'puntReturner', 'punter',\n        'qtr_time_remain', 'rushDir', 'rusher', 'sacker1', 'sacker2',\n        'spikeQB', 'tackler1', 'tackler2', 'target', 'timeoutTeam',\n        'xpKicker'\n    ]\n    for var in bool_vars:\n        struct[var] = struct.get(var) is True\n    for var in int_vars:\n        try:\n            struct[var] = int(struct.get(var))\n        except (ValueError, TypeError):\n            struct[var] = np.nan\n    for var in float_vars:\n        try:\n            struct[var] = float(struct.get(var))\n        except (ValueError, TypeError):\n            struct[var] = np.nan\n    for var in string_vars:\n        if var not in struct or pd.isnull(struct[var]) or var == '':\n            struct[var] = np.nan\n\n    # Fourth, create new helper variables based on parsed variables\n    # creating fieldSide and ydline from location\n    if struct['isXP']:\n        struct['fieldSide'] = struct['ydLine'] = np.nan\n    else:\n        fieldSide, ydline = _loc_to_features(struct.get('location'))\n        struct['fieldSide'] = fieldSide\n        struct['ydLine'] = ydline\n    # creating secsElapsed (in entire game) from qtr_time_remain and quarter\n    if pd.notnull(struct.get('qtr_time_remain')):\n        qtr = struct['quarter']\n        mins, secs = map(int, struct['qtr_time_remain'].split(':'))\n        struct['secsElapsed'] = qtr * 900 - mins * 60 - secs\n    # creating columns for turnovers\n    struct['isInt'] = pd.notnull(struct.get('interceptor'))\n    struct['isFumble'] = pd.notnull(struct.get('fumbler'))\n    # create column for isPenalty\n    struct['isPenalty'] = pd.notnull(struct.get('penalty'))\n    # create columns for EPA\n    struct['team_epa'] = struct['exp_pts_after'] - struct['exp_pts_before']\n    struct['opp_epa'] = struct['exp_pts_before'] - struct['exp_pts_after']\n    return pd.Series(struct)", "response": "Cleans up the features collected in parse_play_details."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a location string to a tuple of those values the second being an int.", "response": "def _loc_to_features(loc):\n    \"\"\"Converts a location string \"{Half}, {YardLine}\" into a tuple of those\n    values, the second being an int.\n\n    :l: The string from the play by play table representing location.\n    :returns: A tuple that separates out the values, making them missing\n    (np.nan) when necessary.\n\n    \"\"\"\n    if loc:\n        if isinstance(loc, basestring):\n            loc = loc.strip()\n            if ' ' in loc:\n                r = loc.split()\n                r[0] = r[0].lower()\n                r[1] = int(r[1])\n            else:\n                r = (np.nan, int(loc))\n        elif isinstance(loc, float):\n            return (np.nan, 50)\n    else:\n        r = (np.nan, np.nan)\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions that adds team and opp columns to the DataFrame.", "response": "def _add_team_columns(features):\n    \"\"\"Function that adds 'team' and 'opp' columns to the features by iterating\n    through the rows in order. A precondition is that the features dicts are in\n    order in a continuous game sense and that all rows are from the same game.\n\n    :features: A DataFrame with each row representing each play (in order).\n    :returns: A similar DataFrame but with 'team' and 'opp' columns added.\n    \"\"\"\n    features = features.to_dict('records')\n    curTm = curOpp = None\n    playAfterKickoff = False\n    # fill in team and opp columns\n    for row in features:\n        # if it's a kickoff or the play after a kickoff,\n        # figure out who has possession manually\n        if row['isKickoff'] or playAfterKickoff:\n            curTm, curOpp = _team_and_opp(row)\n        else:\n            curTm, curOpp = _team_and_opp(row, curTm, curOpp)\n        row['team'], row['opp'] = curTm, curOpp\n        # set playAfterKickoff\n        playAfterKickoff = row['isKickoff']\n\n    features = pd.DataFrame(features)\n    features.team.fillna(method='bfill', inplace=True)\n    features.opp.fillna(method='bfill', inplace=True)\n    # ffill for last row\n    features.team.fillna(method='ffill', inplace=True)\n    features.opp.fillna(method='ffill', inplace=True)\n    return features"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _team_and_opp(struct, curTm=None, curOpp=None):\n    # if we don't know the current team, figure it out\n    if pd.isnull(curTm):\n        if struct['isRun']:\n            pID = struct['rusher']\n        elif struct['isPass']:\n            pID = struct['passer']\n        elif struct['isFieldGoal']:\n            pID = struct['fgKicker']\n        elif struct['isPunt']:\n            pID = struct['punter']\n        elif struct['isXP']:\n            pID = struct['xpKicker']\n        elif struct['isKickoff']:\n            pID = struct['koKicker']\n        elif struct['isSpike']:\n            pID = struct['spikeQB']\n        elif struct['isKneel']:\n            pID = struct['kneelQB']\n        else:\n            pID = None\n        curTm = curOpp = np.nan\n        bs = sportsref.nfl.boxscores.BoxScore(struct['boxscore_id'])\n        if pID and len(pID) == 3:\n            curTm = pID\n            curOpp = bs.away() if bs.home() == curTm else bs.home()\n        elif pID:\n            player = sportsref.nfl.Player(pID)\n            gamelog = player.gamelog(kind='B')\n            curTm = gamelog.loc[\n                gamelog.boxscore_id == struct['boxscore_id'], 'team_id'\n            ].item()\n            curOpp = bs.home() if bs.home() != curTm else bs.away()\n\n        return curTm, curOpp\n\n    # use row's class to determine when possession changes\n    if struct['has_class_divider']:\n        return curOpp, curTm\n    else:\n        return curTm, curOpp", "response": "Given a dict representing a play and the current team with the ball and opp returns the team and opp tuples."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd extra convenience features based on teams with and without availabe possession.", "response": "def _add_team_features(df):\n    \"\"\"Adds extra convenience features based on teams with and without\n    possession, with the precondition that the there are 'team' and 'opp'\n    specified in row.\n\n    :df: A DataFrame representing a game's play-by-play data after\n        _clean_features has been called and 'team' and 'opp' have been added by\n        _add_team_columns.\n    :returns: A dict with new features in addition to previous features.\n    \"\"\"\n    assert df.team.notnull().all()\n\n    homeOnOff = df['team'] == df['home']\n    # create column for distToGoal\n    df['distToGoal'] = np.where(df['team'] != df['fieldSide'],\n                                df['ydLine'], 100 - df['ydLine'])\n    df['distToGoal'] = np.where(df['isXP'] | df['isTwoPoint'],\n                                2, df['distToGoal'])\n    # create column for each team's WP\n    df['team_wp'] = np.where(homeOnOff, df['home_wp'], 100. - df['home_wp'])\n    df['opp_wp'] = 100. - df['team_wp']\n    # create columns for each team's WPA\n    df['team_wpa'] = np.where(homeOnOff, df['home_wpa'], -df['home_wpa'])\n    df['opp_wpa'] = -df['team_wpa']\n    # create column for offense and defense scores if not already there\n    assert df['boxscore_id'].nunique() == 1\n    bs_id = df['boxscore_id'].values[0]\n    bs = sportsref.nfl.boxscores.BoxScore(bs_id)\n    df['team_score'] = np.where(df['team'] == bs.home(),\n                                df['pbp_score_hm'], df['pbp_score_aw'])\n    df['opp_score'] = np.where(df['team'] == bs.home(),\n                               df['pbp_score_aw'], df['pbp_score_hm'])\n\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_player_stats_table(self, subpage, table_id):\n        doc = self.get_sub_doc(subpage)\n        table = doc('table#{}'.format(table_id))\n        df = sportsref.utils.parse_table(table)\n        return df", "response": "Helper function for player season stats."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef initialWinProb(line):\n    line = float(line)\n    probWin = 1. - norm.cdf(0.5, -line, 13.86)\n    probTie = norm.cdf(0.5, -line, 13.86) - norm.cdf(-0.5, -line, 13.86)\n    return 100. * (probWin + 0.5 * probTie)", "response": "Gets the initial win probability of a game given its Vegas line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the career gamelog of the given player.", "response": "def gamelog(self, year=None, kind='R'):\n        \"\"\"Gets the career gamelog of the given player.\n        :kind: One of 'R', 'P', or 'B' (for regular season, playoffs, or both).\n        Case-insensitive; defaults to 'R'.\n        :year: The year for which the gamelog should be returned; if None,\n        return entire career gamelog. Defaults to None.\n        :returns: A DataFrame with the player's career gamelog.\n        \"\"\"\n        url = self._subpage_url('gamelog', None)  # year is filtered later\n        doc = pq(sportsref.utils.get_html(url))\n        table = (doc('table#stats') if kind == 'R' else\n                 doc('table#stats_playoffs'))\n        df = sportsref.utils.parse_table(table)\n        if year is not None:\n            df = df.query('year == @year').reset_index(drop=True)\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets yearly passing stats for the player.", "response": "def passing(self, kind='R'):\n        \"\"\"Gets yearly passing stats for the player.\n\n        :kind: One of 'R', 'P', or 'B'. Case-insensitive; defaults to 'R'.\n        :returns: Pandas DataFrame with passing stats.\n        \"\"\"\n        doc = self.get_doc()\n        table = (doc('table#passing') if kind == 'R' else\n                 doc('table#passing_playoffs'))\n        df = sportsref.utils.parse_table(table)\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rushing_and_receiving(self, kind='R'):\n        doc = self.get_doc()\n        table = (doc('table#rushing_and_receiving') if kind == 'R'\n                 else doc('table#rushing_and_receiving_playoffs'))\n        if not table:\n            table = (doc('table#receiving_and_rushing') if kind == 'R'\n                     else doc('table#receiving_and_rushing_playoffs'))\n        df = sportsref.utils.parse_table(table)\n        return df", "response": "Gets yearly rushing and receiving stats for the player."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a DataFrame of plays for a given year.", "response": "def _plays(self, year, play_type, expand_details):\n        \"\"\"Returns a DataFrame of plays for a given year for a given play type\n        (like rushing, receiving, or passing).\n\n        :year: The year for the season.\n        :play_type: A type of play for which there are plays (as of this\n        writing, either \"passing\", \"rushing\", or \"receiving\")\n        :expand_details: Bool for whether PBP should be parsed.\n        :returns: A DataFrame of plays, each row is a play. Returns None if\n        there were no such plays in that year.\n        \"\"\"\n        url = self._subpage_url('{}-plays'.format(play_type), year)\n        doc = pq(sportsref.utils.get_html(url))\n        table = doc('table#all_plays')\n        if table:\n            if expand_details:\n                plays = sportsref.nfl.pbp.expand_details(\n                    sportsref.utils.parse_table(table), detailCol='description'\n                )\n                return plays\n            else:\n                return sportsref.utils.parse_table(table)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a DataFrame of advanced splits data for a player - year. Note that the year is only used for the player - year.", "response": "def advanced_splits(self, year=None):\n        \"\"\"Returns a DataFrame of advanced splits data for a player-year. Note:\n            only go back to 2012.\n\n        :year: The year for the season in question. If None, returns career\n        advanced splits.\n        :returns: A DataFrame of advanced splits data.\n        \"\"\"\n        # get the table\n        url = self._subpage_url('splits', year)\n        doc = pq(sportsref.utils.get_html(url))\n        table = doc('table#advanced_splits')\n        df = sportsref.utils.parse_table(table)\n        # cleaning the data\n        if not df.empty:\n            df.split_type.fillna(method='ffill', inplace=True)\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _simple_year_award(self, award_id):\n        doc = self.get_doc()\n        table = doc('div#leaderboard_{} table'.format(award_id))\n        return list(map(int, sportsref.utils.parse_awards_table(table)))", "response": "Template for simple year award functions that simply list years for the award."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a mapping from team ID to full team name for a given season.", "response": "def team_names(year):\n    \"\"\"Returns a mapping from team ID to full team name for a given season.\n    Example of a full team name: \"New England Patriots\"\n\n    :year: The year of the season in question (as an int).\n    :returns: A dictionary with teamID keys and full team name values.\n    \"\"\"\n    doc = pq(sportsref.utils.get_html(sportsref.nfl.BASE_URL + '/teams/'))\n    active_table = doc('table#teams_active')\n    active_df = sportsref.utils.parse_table(active_table)\n    inactive_table = doc('table#teams_inactive')\n    inactive_df = sportsref.utils.parse_table(inactive_table)\n    df = pd.concat((active_df, inactive_df))\n    df = df.loc[~df['has_class_partial_table']]\n    ids = df.team_id.str[:3].values\n    names = [tr('th a') for tr in active_table('tr').items()]\n    names.extend(tr('th a') for tr in inactive_table('tr').items())\n    names = [_f for _f in names if _f]\n    names = [lst[0].text_content() for lst in names]\n    # combine IDs and team names into pandas series\n    series = pd.Series(names, index=ids)\n    # create a mask to filter to teams from the given year\n    mask = ((df.year_min <= year) & (year <= df.year_max)).values\n    # filter, convert to a dict, and return\n    return series[mask].to_dict()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef team_ids(year):\n    names = team_names(year)\n    return {v: k for k, v in names.items()}", "response": "Returns a mapping from team name to team ID for a given season. Inverse of team_names mapping of team_names. Example of a full team name : New England Patriots"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef name(self):\n        doc = self.get_main_doc()\n        headerwords = doc('div#meta h1')[0].text_content().split()\n        lastIdx = headerwords.index('Franchise')\n        teamwords = headerwords[:lastIdx]\n        return ' '.join(teamwords)", "response": "Returns the real name of the franchise given the team ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the roster table for the given year.", "response": "def roster(self, year):\n        \"\"\"Returns the roster table for the given year.\n\n        :year: The year for which we want the roster; defaults to current year.\n        :returns: A DataFrame containing roster information for that year.\n        \"\"\"\n        doc = self.get_year_doc('{}_roster'.format(year))\n        roster_table = doc('table#games_played_team')\n        df = sportsref.utils.parse_table(roster_table)\n        starter_table = doc('table#starters')\n        if not starter_table.empty:\n            start_df = sportsref.utils.parse_table(starter_table)\n            start_df = start_df.dropna(axis=0, subset=['position'])\n            starters = start_df.set_index('position').player_id\n            df['is_starter'] = df.player_id.isin(starters)\n            df['starting_pos'] = df.player_id.map(\n                lambda pid: (starters[starters == pid].index[0]\n                             if pid in starters.values else None)\n            )\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the list of BoxScore objects corresponding to the box scores from the current log entry for that year.", "response": "def boxscores(self, year):\n        \"\"\"Gets list of BoxScore objects corresponding to the box scores from\n        that year.\n\n        :year: The year for which we want the boxscores; defaults to current\n        year.\n        :returns: np.array of strings representing boxscore IDs.\n        \"\"\"\n        doc = self.get_year_doc(year)\n        table = doc('table#games')\n        df = sportsref.utils.parse_table(table)\n        if df.empty:\n            return np.array([])\n        return df.boxscore_id.values"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a PyQuery object containing the info from the meta div at the given year page with the given keyword.", "response": "def _year_info_pq(self, year, keyword):\n        \"\"\"Returns a PyQuery object containing the info from the meta div at\n        the top of the team year page with the given keyword.\n\n        :year: Int representing the season.\n        :keyword: A keyword to filter to a single p tag in the meta div.\n        :returns: A PyQuery object for the selected p element.\n        \"\"\"\n        doc = self.get_year_doc(year)\n        p_tags = doc('div#meta div:not(.logo) p')\n        texts = [p_tag.text_content().strip() for p_tag in p_tags]\n        try:\n            return next(\n                pq(p_tag) for p_tag, text in zip(p_tags, texts)\n                if keyword.lower() in text.lower()\n            )\n        except StopIteration:\n            if len(texts):\n                raise ValueError('Keyword not found in any p tag.')\n            else:\n                raise ValueError('No meta div p tags found.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the head coaches for a given year.", "response": "def head_coaches_by_game(self, year):\n        \"\"\"Returns head coach data by game.\n\n        :year: An int representing the season in question.\n        :returns: An array with an entry per game of the season that the team\n        played (including playoffs). Each entry is the head coach's ID for that\n        game in the season.\n        \"\"\"\n        coach_str = self._year_info_pq(year, 'Coach').text()\n        regex = r'(\\S+?) \\((\\d+)-(\\d+)-(\\d+)\\)'\n        coachAndTenure = []\n        m = True\n        while m:\n            m = re.search(regex, coach_str)\n            coachID, wins, losses, ties = m.groups()\n            nextIndex = m.end(4) + 1\n            coachStr = coachStr[nextIndex:]\n            tenure = int(wins) + int(losses) + int(ties)\n            coachAndTenure.append((coachID, tenure))\n\n        coachIDs = [\n            cID for cID, games in coachAndTenure for _ in range(games)\n        ]\n        return np.array(coachIDs[::-1])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the number of regular season wins a team in a year.", "response": "def wins(self, year):\n        \"\"\"Returns the # of regular season wins a team in a year.\n\n        :year: The year for the season in question.\n        :returns: The number of regular season wins.\n        \"\"\"\n        schedule = self.schedule(year)\n        if schedule.empty:\n            return np.nan\n        return schedule.query('week_num <= 17').is_win.sum()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a Pandas DataFrame with schedule information for the given year.", "response": "def schedule(self, year):\n        \"\"\"Returns a DataFrame with schedule information for the given year.\n\n        :year: The year for the season in question.\n        :returns: Pandas DataFrame with schedule information.\n        \"\"\"\n        doc = self.get_year_doc(year)\n        table = doc('table#games')\n        df = sportsref.utils.parse_table(table)\n        if df.empty:\n            return pd.DataFrame()\n        df = df.loc[df['week_num'].notnull()]\n        df['week_num'] = np.arange(len(df)) + 1\n        df['is_win'] = df['game_outcome'] == 'W'\n        df['is_loss'] = df['game_outcome'] == 'L'\n        df['is_tie'] = df['game_outcome'] == 'T'\n        df['is_bye'] = df['game_outcome'].isnull()\n        df['is_ot'] = df['overtime'].notnull()\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef srs(self, year):\n        try:\n            srs_text = self._year_info_pq(year, 'SRS').text()\n        except ValueError:\n            return None\n        m = re.match(r'SRS\\s*?:\\s*?(\\S+)', srs_text)\n        if m:\n            return float(m.group(1))\n        else:\n            return None", "response": "Returns the SRS for a team in a year."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the SOS of a team in a year based on SRS.", "response": "def sos(self, year):\n        \"\"\"Returns the SOS (Strength of Schedule) for a team in a year, based\n        on SRS.\n\n        :year: The year for the season in question.\n        :returns: A float of SOS.\n        \"\"\"\n        try:\n            sos_text = self._year_info_pq(year, 'SOS').text()\n        except ValueError:\n            return None\n        m = re.search(r'SOS\\s*:\\s*(\\S+)', sos_text)\n        if m:\n            return float(m.group(1))\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the coach ID for the team s OC in a given year.", "response": "def off_coordinator(self, year):\n        \"\"\"Returns the coach ID for the team's OC in a given year.\n\n        :year: An int representing the year.\n        :returns: A string containing the coach ID of the OC.\n        \"\"\"\n        try:\n            oc_anchor = self._year_info_pq(year, 'Offensive Coordinator')('a')\n            if oc_anchor:\n                return oc_anchor.attr['href']\n        except ValueError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the coach ID for the team s DC in a given year.", "response": "def def_coordinator(self, year):\n        \"\"\"Returns the coach ID for the team's DC in a given year.\n\n        :year: An int representing the year.\n        :returns: A string containing the coach ID of the DC.\n        \"\"\"\n        try:\n            dc_anchor = self._year_info_pq(year, 'Defensive Coordinator')('a')\n            if dc_anchor:\n                return dc_anchor.attr['href']\n        except ValueError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the ID for the stadium in which the team played in a given year.", "response": "def stadium(self, year):\n        \"\"\"Returns the ID for the stadium in which the team played in a given\n        year.\n\n        :year: The year in question.\n        :returns: A string representing the stadium ID.\n        \"\"\"\n        anchor = self._year_info_pq(year, 'Stadium')('a')\n        return sportsref.utils.rel_url_to_id(anchor.attr['href'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the name of the offensive scheme the team ran in the given year.", "response": "def off_scheme(self, year):\n        \"\"\"Returns the name of the offensive scheme the team ran in the given\n        year.\n\n        :year: Int representing the season year.\n        :returns: A string representing the offensive scheme.\n        \"\"\"\n        scheme_text = self._year_info_pq(year, 'Offensive Scheme').text()\n        m = re.search(r'Offensive Scheme[:\\s]*(.+)\\s*', scheme_text, re.I)\n        if m:\n            return m.group(1)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef def_alignment(self, year):\n        scheme_text = self._year_info_pq(year, 'Defensive Alignment').text()\n        m = re.search(r'Defensive Alignment[:\\s]*(.+)\\s*', scheme_text, re.I)\n        if m:\n            return m.group(1)\n        else:\n            return None", "response": "Returns the name of the defensive alignment the team ran in the\n        given year."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a Series of team stats from the team - season page.", "response": "def team_stats(self, year):\n        \"\"\"Returns a Series (dict-like) of team stats from the team-season\n        page.\n\n        :year: Int representing the season.\n        :returns: A Series of team stats.\n        \"\"\"\n        doc = self.get_year_doc(year)\n        table = doc('table#team_stats')\n        df = sportsref.utils.parse_table(table)\n        if df.empty:\n            return pd.Series()\n        return df.loc[df.player_id == 'Team Stats'].iloc[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a Series of team s opponent s stats from the team - season page.", "response": "def opp_stats(self, year):\n        \"\"\"Returns a Series (dict-like) of the team's opponent's stats from the\n        team-season page.\n\n        :year: Int representing the season.\n        :returns: A Series of team stats.\n        \"\"\"\n        doc = self.get_year_doc(year)\n        table = doc('table#team_stats')\n        df = sportsref.utils.parse_table(table)\n        return df.loc[df.player_id == 'Opp. Stats'].iloc[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a Pandas DataFrame of offensive team splits for a season.", "response": "def off_splits(self, year):\n        \"\"\"Returns a DataFrame of offensive team splits for a season.\n\n        :year: int representing the season.\n        :returns: Pandas DataFrame of split data.\n        \"\"\"\n        doc = self.get_year_doc('{}_splits'.format(year))\n        tables = doc('table.stats_table')\n        dfs = [sportsref.utils.parse_table(table) for table in tables.items()]\n        dfs = [\n            df.assign(split=df.columns[0])\n            .rename(columns={df.columns[0]: 'split_value'})\n            for df in dfs\n        ]\n        if not dfs:\n            return pd.DataFrame()\n        return pd.concat(dfs).reset_index(drop=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the HTML for the given URL using a GET request.", "response": "def get_html(url):\n    \"\"\"Gets the HTML for the given URL using a GET request.\n\n    :url: the absolute URL of the desired page.\n    :returns: a string of HTML.\n    \"\"\"\n    global last_request_time\n    with throttle_process_lock:\n        with throttle_thread_lock:\n            # sleep until THROTTLE_DELAY secs have passed since last request\n            wait_left = THROTTLE_DELAY - (time.time() - last_request_time.value)\n            if wait_left > 0:\n                time.sleep(wait_left)\n\n            # make request\n            response = requests.get(url)\n\n            # update last request time for throttling\n            last_request_time.value = time.time()\n\n    # raise ValueError on 4xx status code, get rid of comments, and return\n    if 400 <= response.status_code < 500:\n        raise ValueError(\n            'Status Code {} received fetching URL \"{}\"'\n            .format(response.status_code, url)\n        )\n    html = response.text\n    html = html.replace('<!--', '').replace('-->', '')\n\n    return html"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_table(table, flatten=True, footer=False):\n    if not len(table):\n        return pd.DataFrame()\n\n    # get columns\n    columns = [c.attrib['data-stat']\n               for c in table('thead tr:not([class]) th[data-stat]')]\n\n    # get data\n    rows = list(table('tbody tr' if not footer else 'tfoot tr')\n                .not_('.thead, .stat_total, .stat_average').items())\n    data = [\n        [flatten_links(td) if flatten else td.text()\n         for td in row.items('th,td')]\n        for row in rows\n    ]\n\n    # make DataFrame\n    df = pd.DataFrame(data, columns=columns, dtype='float')\n\n    # add has_class columns\n    allClasses = set(\n        cls\n        for row in rows\n        if row.attr['class']\n        for cls in row.attr['class'].split()\n    )\n    for cls in allClasses:\n        df['has_class_' + cls] = [\n            bool(row.attr['class'] and\n                 cls in row.attr['class'].split())\n            for row in rows\n        ]\n\n    # cleaning the DataFrame\n\n    df.drop(['ranker', 'Xxx', 'Yyy', 'Zzz'],\n            axis=1, inplace=True, errors='ignore')\n\n    # year_id -> year (as int)\n    if 'year_id' in df.columns:\n        df.rename(columns={'year_id': 'year'}, inplace=True)\n        if flatten:\n            df.year = df.year.fillna(method='ffill')\n            df['year'] = df.year.map(lambda s: str(s)[:4]).astype(int)\n\n    # pos -> position\n    if 'pos' in df.columns:\n        df.rename(columns={'pos': 'position'}, inplace=True)\n\n    # boxscore_word, game_date -> boxscore_id and separate into Y, M, D columns\n    for bs_id_col in ('boxscore_word', 'game_date', 'box_score_text'):\n        if bs_id_col in df.columns:\n            df.rename(columns={bs_id_col: 'boxscore_id'}, inplace=True)\n            break\n\n    # ignore *, +, and other characters used to note things\n    df.replace(re.compile(r'[\\*\\+\\u2605]', re.U), '', inplace=True)\n    for col in df.columns:\n        if hasattr(df[col], 'str'):\n            df[col] = df[col].str.strip()\n\n    # player -> player_id and/or player_name\n    if 'player' in df.columns:\n        if flatten:\n            df.rename(columns={'player': 'player_id'}, inplace=True)\n            # when flattening, keep a column for names\n            player_names = parse_table(table, flatten=False)['player_name']\n            df['player_name'] = player_names\n        else:\n            df.rename(columns={'player': 'player_name'}, inplace=True)\n\n    # team, team_name -> team_id\n    for team_col in ('team', 'team_name'):\n        if team_col in df.columns:\n            # first, get rid of faulty rows\n            df = df.loc[~df[team_col].isin(['XXX'])]\n            if flatten:\n                df.rename(columns={team_col: 'team_id'}, inplace=True)\n\n    # season -> int\n    if 'season' in df.columns and flatten:\n        df['season'] = df['season'].astype(int)\n\n    # handle date_game columns (different types)\n    if 'date_game' in df.columns and flatten:\n        date_re = r'month=(?P<month>\\d+)&day=(?P<day>\\d+)&year=(?P<year>\\d+)'\n        date_df = df['date_game'].str.extract(date_re, expand=True)\n        if date_df.notnull().all(axis=1).any():\n            df = pd.concat((df, date_df), axis=1)\n        else:\n            df.rename(columns={'date_game': 'boxscore_id'}, inplace=True)\n\n    # game_location -> is_home\n    if 'game_location' in df.columns and flatten:\n        df['game_location'] = df['game_location'].isnull()\n        df.rename(columns={'game_location': 'is_home'}, inplace=True)\n\n    # mp: (min:sec) -> float(min + sec / 60), notes -> NaN, new column\n    if 'mp' in df.columns and df.dtypes['mp'] == object and flatten:\n        mp_df = df['mp'].str.extract(\n            r'(?P<m>\\d+):(?P<s>\\d+)', expand=True).astype(float)\n        no_match = mp_df.isnull().all(axis=1)\n        if no_match.any():\n            df.loc[no_match, 'note'] = df.loc[no_match, 'mp']\n        df['mp'] = mp_df['m'] + mp_df['s'] / 60\n\n    # converts number-y things to floats\n    def convert_to_float(val):\n        # percentages: (number%) -> float(number * 0.01)\n        m = re.search(r'([-\\.\\d]+)\\%',\n                      val if isinstance(val, basestring) else str(val), re.U)\n        try:\n            if m:\n                return float(m.group(1)) / 100 if m else val\n            if m:\n                return int(m.group(1)) + int(m.group(2)) / 60\n        except ValueError:\n            return val\n        # salaries: $ABC,DEF,GHI -> float(ABCDEFGHI)\n        m = re.search(r'\\$[\\d,]+',\n                      val if isinstance(val, basestring) else str(val), re.U)\n        try:\n            if m:\n                return float(re.sub(r'\\$|,', '', val))\n        except Exception:\n            return val\n        # generally try to coerce to float, unless it's an int or bool\n        try:\n            if isinstance(val, (int, bool)):\n                return val\n            else:\n                return float(val)\n        except Exception:\n            return val\n\n    if flatten:\n        df = df.applymap(convert_to_float)\n\n    df = df.loc[df.astype(bool).any(axis=1)]\n\n    return df", "response": "Parses a table from sports - reference sites into a pandas dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing an info table like the Game Info table or the Officials table on the PFR Boxscore page.", "response": "def parse_info_table(table):\n    \"\"\"Parses an info table, like the \"Game Info\" table or the \"Officials\"\n    table on the PFR Boxscore page. Keys are lower case and have spaces/special\n    characters converted to underscores.\n\n    :table: PyQuery object representing the HTML table.\n    :returns: A dictionary representing the information.\n    \"\"\"\n    ret = {}\n    for tr in list(table('tr').not_('.thead').items()):\n        th, td = list(tr('th, td').items())\n        key = th.text().lower()\n        key = re.sub(r'\\W', '_', key)\n        val = sportsref.utils.flatten_links(td)\n        ret[key] = val\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nflattening relative URLs within text of a table cell to IDs and returns the result.", "response": "def flatten_links(td, _recurse=False):\n    \"\"\"Flattens relative URLs within text of a table cell to IDs and returns\n    the result.\n\n    :td: the PyQuery object for the HTML to convert\n    :returns: the string with the links flattened to IDs\n    \"\"\"\n\n    # helper function to flatten individual strings/links\n    def _flatten_node(c):\n        if isinstance(c, basestring):\n            return c.strip()\n        elif 'href' in c.attrib:\n            c_id = rel_url_to_id(c.attrib['href'])\n            return c_id if c_id else c.text_content().strip()\n        else:\n            return flatten_links(pq(c), _recurse=True)\n\n    # if there's no text, just return None\n    if td is None or not td.text():\n        return '' if _recurse else None\n\n    td.remove('span.note')\n    return ''.join(_flatten_node(c) for c in td.contents())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rel_url_to_id(url):\n    yearRegex = r'.*/years/(\\d{4}).*|.*/gamelog/(\\d{4}).*'\n    playerRegex = r'.*/players/(?:\\w/)?(.+?)(?:/|\\.html?)'\n    boxscoresRegex = r'.*/boxscores/(.+?)\\.html?'\n    teamRegex = r'.*/teams/(\\w{3})/.*'\n    coachRegex = r'.*/coaches/(.+?)\\.html?'\n    stadiumRegex = r'.*/stadiums/(.+?)\\.html?'\n    refRegex = r'.*/officials/(.+?r)\\.html?'\n    collegeRegex = r'.*/schools/(\\S+?)/.*|.*college=([^&]+)'\n    hsRegex = r'.*/schools/high_schools\\.cgi\\?id=([^\\&]{8})'\n    bsDateRegex = r'.*/boxscores/index\\.f?cgi\\?(month=\\d+&day=\\d+&year=\\d+)'\n    leagueRegex = r'.*/leagues/(.*_\\d{4}).*'\n    awardRegex = r'.*/awards/(.+)\\.htm'\n\n    regexes = [\n        yearRegex,\n        playerRegex,\n        boxscoresRegex,\n        teamRegex,\n        coachRegex,\n        stadiumRegex,\n        refRegex,\n        collegeRegex,\n        hsRegex,\n        bsDateRegex,\n        leagueRegex,\n        awardRegex,\n    ]\n\n    for regex in regexes:\n        match = re.match(regex, url, re.I)\n        if match:\n            return [_f for _f in match.groups() if _f][0]\n\n    # things we don't want to match but don't want to print a WARNING\n    if any(\n        url.startswith(s) for s in\n        (\n            '/play-index/',\n        )\n    ):\n        return url\n\n    print('WARNING. NO MATCH WAS FOUND FOR \"{}\"'.format(url))\n    return url", "response": "Converts a relative URL to a unique ID."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef PlayerSeasonFinder(**kwargs):\n\n    if 'offset' not in kwargs:\n        kwargs['offset'] = 0\n\n    playerSeasons = []\n    while True:\n        querystring = _kwargs_to_qs(**kwargs)\n        url = '{}?{}'.format(PSF_URL, querystring)\n        if kwargs.get('verbose', False):\n            print(url)\n        html = utils.get_html(url)\n        doc = pq(html)\n        table = doc('table#results')\n        df = utils.parse_table(table)\n        if df.empty:\n            break\n\n        thisSeason = list(zip(df.player_id, df.year))\n        playerSeasons.extend(thisSeason)\n\n        if doc('*:contains(\"Next Page\")'):\n            kwargs['offset'] += 100\n        else:\n            break\n\n    return playerSeasons", "response": "This function returns a list of all the seasons in the current language."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert kwargs given to PSF to a querystring.", "response": "def _kwargs_to_qs(**kwargs):\n    \"\"\"Converts kwargs given to PSF to a querystring.\n\n    :returns: the querystring.\n    \"\"\"\n    # start with defaults\n    inpOptDef = inputs_options_defaults()\n    opts = {\n        name: dct['value']\n        for name, dct in inpOptDef.items()\n    }\n\n    # clean up keys and values\n    for k, v in kwargs.items():\n        del kwargs[k]\n        # bool => 'Y'|'N'\n        if isinstance(v, bool):\n            kwargs[k] = 'Y' if v else 'N'\n        # tm, team => team_id\n        elif k.lower() in ('tm', 'team'):\n            kwargs['team_id'] = v\n        # yr, year, yrs, years => year_min, year_max\n        elif k.lower() in ('yr', 'year', 'yrs', 'years'):\n            if isinstance(v, collections.Iterable):\n                lst = list(v)\n                kwargs['year_min'] = min(lst)\n                kwargs['year_max'] = max(lst)\n            elif isinstance(v, basestring):\n                v = list(map(int, v.split(',')))\n                kwargs['year_min'] = min(v)\n                kwargs['year_max'] = max(v)\n            else:\n                kwargs['year_min'] = v\n                kwargs['year_max'] = v\n        # pos, position, positions => pos[]\n        elif k.lower() in ('pos', 'position', 'positions'):\n            if isinstance(v, basestring):\n                v = v.split(',')\n            elif not isinstance(v, collections.Iterable):\n                v = [v]\n            kwargs['pos[]'] = v\n        # draft_pos, ... => draft_pos[]\n        elif k.lower() in (\n            'draft_pos', 'draftpos', 'draftposition', 'draftpositions',\n            'draft_position', 'draft_positions'\n        ):\n            if isinstance(v, basestring):\n                v = v.split(',')\n            elif not isinstance(v, collections.Iterable):\n                v = [v]\n            kwargs['draft_pos[]'] = v\n        # if not one of these cases, put it back in kwargs\n        else:\n            kwargs[k] = v\n\n    # update based on kwargs\n    for k, v in kwargs.items():\n        # if overwriting a default, overwrite it (with a list so the\n        # opts -> querystring list comp works)\n        if k in opts or k in ('pos[]', 'draft_pos[]'):\n            # if multiple values separated by commas, split em\n            if isinstance(v, basestring):\n                v = v.split(',')\n            # otherwise, make sure it's a list\n            elif not isinstance(v, collections.Iterable):\n                v = [v]\n            # then, add list of values to the querystring dict *opts*\n            opts[k] = v\n        if 'draft' in k:\n            opts['draft'] = [1]\n\n    opts['request'] = [1]\n    opts['offset'] = [kwargs.get('offset', 0)]\n\n    qs = '&'.join(\n        '{}={}'.format(urllib.parse.quote_plus(name), val)\n        for name, vals in sorted(opts.items()) for val in vals\n    )\n\n    return qs"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread a node from the streamer.", "response": "def _Streamer__read_process(self, path, read_size, cbuf, stop, barrier, cyclic, offset, read_skip, sync):\n    \"\"\"\n    Main function for the processes that read from the HDF5 file.\n\n    :param self: A reference to the streamer object that created these processes.\n    :param path: The HDF5 path to the node to be read from.\n    :param read_size: The length of the block along the outer dimension to read.\n    :param cbuf: The circular buffer to place read elements into.\n    :param stop: The Event that signals the process to stop reading.\n    :param barrier: The Barrier that synchonises read cycles.\n    :param cyclic: True if the process should read cyclically.\n    :param offset: Offset into the dataset that this process should start reading at.\n    :param read_skip: How many element to skip on each iteration.\n    :param sync: GuardSynchonizer to order writes to the buffer.\n    :return: Nothing\n    \"\"\"\n    # Multi-process access to HDF5 seems to behave better there are no top level imports of PyTables.\n    import tables as tb\n    h5_file = tb.open_file(self.filename, 'r', **self.h5_kw_args)\n    ary = h5_file.get_node(path)\n\n    i = offset\n    while not stop.is_set():\n        vals = ary[i:i + read_size]\n        # If the read goes off the end of the dataset, then wrap to the start.\n        if i + read_size > len(ary):\n            vals = np.concatenate([vals, ary[0:read_size - len(vals)]])\n\n        if sync is None:\n            # If no ordering is requested, then just write to the next available space in the buffer.\n            with cbuf.put_direct() as put_ary:\n                put_ary[:] = vals\n        else:\n            # Otherwise, use the sync object to ensure that writes occur in the order provided by i.\n            # So i = 0 will write first, then i = block_size, then i = 2*block_size, etc...\n            # The sync object has two ordered barriers so that acquisition and release of the buffer spaces\n            # are synchronized in order, but the actual writing to the buffer can happen simultaneously.\n            # If only one barrier were used, writing to the buffer would be linearised.\n            with sync.do(cbuf.put_direct(), i, (i+read_size) % len(ary)) as put_ary:\n                put_ary[:] = vals\n\n        i += read_skip\n        if cyclic:\n            # If the next iteration is past the end of the dataset, wrap it around.\n            if i >= len(ary):\n                i %= len(ary)\n                barrier.wait()\n        else:\n            # But if cyclic mode is disabled, break the loop as the work is now done.\n            if i + read_size > len(ary):\n                break"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwait until all processes have reached the barrier.", "response": "def wait(self):\n        \"\"\"Wait until all processes have reached the barrier.\"\"\"\n        with self.cvar:\n            self.count.value += 1\n            self.cvar.notify_all()\n            while self.count.value < self.n_procs:\n                self.cvar.wait()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwait until all processes have reached the barrier.", "response": "def wait(self):\n        \"\"\"Wait until all processes have reached the barrier.\"\"\"\n        self.barrier_A.wait()\n        # The current barrier (barrier_A) is switched with the reserve barrier.\n        # This is because the current barrier cannot be safely reset until the reserve barrier has been passed.\n        self.barrier_A, self.barrier_B = self.barrier_B, self.barrier_A\n        self.barrier_A.reset()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wait(self, index, next_index=None):\n        return OrderedBarrier.Guard(self, index, index+1 if next_index is None else next_index)", "response": "Block until the next_index is reached."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do(self, guard, index, next_index):\n        return GuardSynchronizer.Guard(self, guard, index, next_index)", "response": "Creates a new guard that requires the resource guard to be entered and exited based on the order provided by index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef put(self, v):\n        if v is QueueClosed:\n            v = -2\n        else:\n            assert(v >= 0)\n        with self.cvar:\n            assert(self.size.value < len(self.vals))\n\n            head = (self.tail.value + self.size.value) % len(self.vals)\n            self.vals[head] = v\n            self.size.value += 1\n            self.cvar.notify()", "response": "Put an unsigned integer into the queue."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self):\n        with self.cvar:\n            while True:\n                if self.size.value > 0:\n                    rval = self.vals[self.tail.value]\n                    self.tail.value = (self.tail.value + 1) % len(self.vals)\n                    self.size.value -= 1\n                    if rval == -2:\n                        return QueueClosed\n                    assert(rval >= 0)\n                    return rval\n                self.cvar.wait()", "response": "Fetch the next item in the queue. Blocks until an item is available."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a guard object that allows direct access to the buffer element.", "response": "def put_direct(self):\n        \"\"\"\n        Allows direct access to the buffer element.\n        Blocks until there is room to write into the buffer.\n\n        :return: A guard object that returns the buffer element.\n        \"\"\"\n\n        # Once the guard is released, write_idx will be placed into read_queue.\n        return self.Guard(self.read_queue, self.arys, self.__put_idx)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_direct(self):\n\n        read_idx = self.__get_idx()\n\n        if read_idx is QueueClosed:\n            return QueueClosed\n\n        # Once the guard is released, read_idx will be placed into write_queue.\n        return self.Guard(self.write_queue, self.arys, lambda: read_idx)", "response": "Returns a direct access to the buffer element."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclose the queue signalling that no more data can be put into the queue.", "response": "def close(self):\n        \"\"\"Close the queue, signalling that no more data can be put into the queue.\"\"\"\n        self.read_queue.put(QueueClosed)\n        self.write_queue.put(QueueClosed)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __get_batch(self, path, length, last=False):\n        import tables\n        h5_file = tables.open_file(self.filename, 'r')\n        h5_node = h5_file.get_node(path)\n\n        if len(h5_node) == 0:\n            raise Exception(\"Cannot read from empty dataset.\")\n\n        # If the length isn't specified, then fall back to default values.\n        if length is None:\n            chunkshape = h5_node.chunkshape\n            # If the array isn't chunked, then try to make the block close to 128KB.\n            if chunkshape is None:\n                default_length = 128*2**10//h5_node[0].nbytes  # Divides by one row of the dataset.\n                length = min(h5_node.shape[0], default_length)\n            # If it is chunked, then use the chunkshape for best performance.\n            else:\n                length = chunkshape[0]\n\n        if last:\n            example = h5_node[length*(len(h5_node)//length):].copy()\n        else:\n            example = h5_node[:length].copy()\n\n        h5_file.close()\n        return example", "response": "Get a batch of data from the HDF5 file at path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the remainder elements from the HDF5 file at the given path.", "response": "def get_remainder(self, path, block_size):\n        \"\"\"\n        Get the remainder elements. These elements will not be read in the direct queue access cyclic=False mode.\n\n        :param path: The HDF5 path to the dataset to be read.\n        :param block_size: The block size is used to calculate which elements will remain.\n        :return: A copy of the remainder elements as a numpy array.\n        \"\"\"\n        return self.__get_batch(path, length=block_size, last=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_queue(self, path, n_procs=4, read_ahead=None, cyclic=False, block_size=None, ordered=False):\n        # Get a block_size length of elements from the dataset to serve as a template for creating the buffer.\n        # If block_size=None, then get_batch calculates an appropriate block size.\n        example = self.__get_batch(path, block_size)\n        block_size = example.shape[0]\n\n        if read_ahead is None:\n            # 2x No. of processes for writing, 1 extra for reading.\n            read_ahead = 2*n_procs + 1\n\n        cbuf = SharedCircBuf(read_ahead, example)\n        stop = multiprocessing.Event()\n        barrier = Barrier(n_procs)\n\n        # If ordering has been requested, create a synchronizer.\n        sync = GuardSynchronizer() if ordered else None\n\n        procs = []\n        for i in range(n_procs):\n            # Each process is offset in the dataset by i*block_size\n            # The skip length is set to n_procs*block_size so that no block is read by 2 processes.\n            process = multiprocessing.Process(target=_Streamer__read_process, args=(\n                self, path, block_size, cbuf, stop, barrier, cyclic,\n                i * block_size, n_procs * block_size, sync\n            ))\n            process.daemon = True\n            process.start()\n            procs.append(process)\n\n        # If the queue is not cyclic, then the cessation of reading data needs to be monitored.\n        if not cyclic:\n\n            # This closure defines a background thread that waits until all processes have finished.\n            # At this point, all data from the dataset has been read, and the buffer is closed.\n            def monitor():\n                for p in procs:\n                    p.join()\n                cbuf.close()\n\n            monitor_thread = threading.Thread(target=monitor)\n            monitor_thread.daemon = True\n            monitor_thread.start()\n\n        return Streamer.Queue(cbuf, stop, block_size)", "response": "Get a queue object that allows direct access to the internal buffer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_generator(self, path, *args, **kw_args):\n        q = self.get_queue(path=path, *args, **kw_args)\n\n        try:\n            # This generator just implements a standard access pattern for the direct access queue.\n            for guard in q.iter():\n                with guard as batch:\n                    batch_copy = batch.copy()\n\n                for row in batch_copy:\n                    yield row\n\n            last_batch = self.get_remainder(path, q.block_size)\n            for row in last_batch:\n                yield row\n\n        finally:\n            q.close()", "response": "Get a generator that yields the elements from the queue at a time at a time."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(ifp, pb_cls, **kwargs):\n    mode = 'rb'\n    if isinstance(ifp, str):\n        istream = open(ifp, mode=mode, **kwargs)\n    else:\n        istream = open(fileobj=ifp, mode=mode, **kwargs)\n    with istream:\n        for data in istream:\n            pb_obj = pb_cls()\n            pb_obj.ParseFromString(data)\n            yield pb_obj", "response": "Parse a stream.\n article."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite a list of protobuf message objects to a file - like object.", "response": "def dump(ofp, *pb_objs, **kwargs):\n    \"\"\"Write to a stream.\n\n    Args:\n        ofp (string or file-like object): output stream.\n        pb_objs (*protobuf.message.Message): list of protobuf message objects\n            to be written.\n    \"\"\"\n    mode = 'wb'\n    if isinstance(ofp, str):\n        ostream = open(ofp, mode=mode, **kwargs)\n    else:\n        ostream = open(fileobj=ofp, mode=mode, **kwargs)\n    with ostream:\n        ostream.write(*pb_objs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a varint from file and return the decoded integer.", "response": "def _read_varint(self):\n        \"\"\"Read a varint from file, parse it, and return the decoded integer.\n        \"\"\"\n        buff = self._fd.read(1)\n        if buff == b'':\n            return 0\n\n        while (bytearray(buff)[-1] & 0x80) >> 7 == 1:  # while the MSB is 1\n            new_byte = self._fd.read(1)\n            if new_byte == b'':\n                raise EOFError('unexpected EOF.')\n            buff += new_byte\n\n        varint, _ = decodeVarint(buff, 0)\n\n        return varint"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_objs(self):\n        while True:\n            count = self._read_varint()\n            if count == 0:\n                break\n            # Read a group containing `count` number of objects.\n            for _ in range(count):\n                size = self._read_varint()\n                if size == 0:\n                    raise EOFError('unexpected EOF.')\n                # Read an object from the object group.\n                yield self._fd.read(size)\n\n            if self._group_delim:\n                yield self._delimiter() if self._delimiter is not None \\\n                                        else None", "response": "A generator yielding all protobuf object data in the file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write(self, *pb2_obj):\n        base = len(self._write_buff)\n\n        for idx, obj in enumerate(pb2_obj):\n            if self._buffer_size > 0 and \\\n                    (idx + base) != 0 and \\\n                    (idx + base) % self._buffer_size == 0:\n                self.flush()\n            self._write_buff.append(obj)\n\n        if self._buffer_size == 0:\n            self.flush()", "response": "Writes a group of protobuf objects to the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites down buffer to the file.", "response": "def flush(self):\n        \"\"\"Write down buffer to the file.\"\"\"\n        if not self.is_output():\n            return\n\n        count = len(self._write_buff)\n        if count == 0:\n            return\n\n        encodeVarint(self._fd.write, count, True)\n\n        for obj in self._write_buff:\n            obj_str = obj.SerializeToString()\n            encodeVarint(self._fd.write, len(obj_str), True)\n            self._fd.write(obj_str)\n\n        self._write_buff = []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the path relative to Steamapps", "response": "def get_game_dir(self, username=False):\n        \"\"\"Returns joined game directory path relative to Steamapps\"\"\"\n        if not self.common and not username:\n            raise RuntimeError(\"Can't determine this game's directory without username\")\n        if self.common:\n            subdir = \"common\"\n        else:\n            subdir = \"username\"\n        subsubdir = self.dir\n        if WIN32 or CYGWIN:\n            subsubdir = subsubdir.lower()\n        return os.path.join(subdir, subsubdir)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the maximum a posterior i - > n_hat_best c_hat_best LL_best and n_hat_best for a given set of fluorescence traces and model parameters.", "response": "def _get_MAP_spikes(F, c_hat, theta, dt, tol=1E-6, maxiter=100, verbosity=0):\n    \"\"\"\n    Used internally by deconvolve to compute the maximum a posteriori\n    spike train for a given set of fluorescence traces and model parameters.\n\n    See the documentation for deconvolve for the meaning of the\n    arguments\n\n    Returns:    n_hat_best, c_hat_best, LL_best\n\n    \"\"\"\n    npix, nt = F.shape\n\n    sigma, alpha, beta, lamb, gamma = theta\n\n    # we project everything onto the alpha mask so that we only ever have to\n    # deal with 1D vector norms\n    alpha_ss = np.dot(alpha, alpha)\n    c = np.dot(alpha, F) - np.dot(alpha, beta)\n\n    # used for computing the LL and gradient\n    scale_var = 1. / (2 * sigma * sigma)\n    lD = lamb * dt\n\n    # used for computing the gradient (M.T.dot(lamb * dt))\n    grad_lnprior = np.zeros(nt, dtype=DTYPE)\n    grad_lnprior[1:] = lD\n    grad_lnprior[:-1] -= lD * gamma\n\n    # initialize the weight of the barrier term to 1\n    z = 1.\n\n    # initial estimate of spike probabilities\n    n_hat = c_hat[1:] - gamma * c_hat[:-1]\n    # assert not np.any(n_hat < 0), \"spike probabilities < 0\"\n\n    # (actual - predicted) fluorescence\n    res = c - alpha_ss * c_hat\n\n    # best overall posterior log-likelihood of the fluorescence\n    LL_best = _post_LL(n_hat, res, scale_var, lD, z)\n    LL_barrier = LL_best\n\n    nloop1 = 0\n    terminate_interior = False\n\n    # in the outer loop we'll progressively reduce the weight of the barrier\n    # term and check the interior point termination criteria\n    while not terminate_interior:\n\n        nloop2 = 0\n        terminate_barrier = False\n\n        # converge for this barrier weight\n        while not terminate_barrier:\n\n            # by projecting everything onto alpha, we reduce this to a 1D\n            # vector norm\n            res = c - alpha_ss * c_hat\n\n            # compute direction of newton step\n            d = _direction(n_hat, res, alpha_ss, gamma, scale_var,\n                           grad_lnprior, z)\n\n            terminate_linesearch = False\n\n            # find the largest step we can take in direction d without\n            # violating the non-negativity constraint on n_hat\n            s_upper_bnd = -n_hat / (d[1:] - gamma * d[:-1])\n\n            # we are only interested in positive step sizes\n            feasible = (s_upper_bnd > 0)\n\n            if np.any(feasible):\n                # largest allowable step size is 1.\n                s = min(1., 0.999 * np.min(s_upper_bnd[feasible]))\n            else:\n                # if there is no step size that will keep n_hat >= 0, just\n                # reduce the barrier weight and try again\n                terminate_linesearch = True\n                terminate_barrier = True\n\n                if verbosity >= 2:\n                    print(\"skipping linesearch: no positive step size will \"\n                          \"keep n_hat >= 0\")\n\n            nloop3 = 0\n\n            # backtracking line search for the largest step size that increases\n            # the posterior log-likelihood of the fluorescence\n            while not terminate_linesearch:\n\n                # update estimated calcium\n                c_hat_line = c_hat + (s * d)\n\n                # update spike probabilities\n                n_hat_line = c_hat_line[1:] - gamma * c_hat_line[:-1]\n                # assert not np.any(n_hat_line < 0), \"spike probabilities < 0\"\n\n                # (actual - predicted) fluorescence\n                res = c - alpha_ss * c_hat_line\n\n                # compute the new posterior log-likelihood\n                LL_line = _post_LL(n_hat_line, res, scale_var, lD, z)\n                # assert not np.any(np.isnan(LL1)), \"nan LL\"\n\n                if verbosity >= 2:\n                    print('spikes: iter=%3i, %3i, %3i; z=%-10.4g; s=%-10.4g;'\n                          ' LL=%-10.4g'\n                          % (nloop1, nloop2, nloop3, z, s, LL_line))\n\n                # if the step size gets too small without making any progress,\n                # we terminate the linesearch and reduce the barrier weight\n                if s < S_TOL:\n                    if verbosity >= 2:\n                        print('--> terminated linesearch: s < %.3g on %i '\n                              'iterations' % (S_TOL, nloop3))\n                    terminate_linesearch = True\n                    terminate_barrier = True\n\n                # only update c_hat & LL if LL improved\n                if LL_line > LL_barrier:\n                    LL_barrier, n_hat, c_hat = LL_line, n_hat_line, c_hat_line\n                    terminate_linesearch = True\n\n                # reduce the step size\n                else:\n                    s /= S_FAC\n\n                nloop3 += 1\n\n            # if d gets too small, reduce the barrier weight\n            if (np.linalg.norm(d) < D_TOL):\n                terminate_barrier = True\n\n            nloop2 += 1\n\n        # only test for convergence if we were actually able to enter the\n        # linesearch\n        if nloop3:\n            delta_LL = -(LL_barrier - LL_best) / LL_best\n            LL_best = LL_barrier\n\n            if (delta_LL < tol):\n                terminate_interior = True\n\n        elif z < Z_TOL:\n            if verbosity >= 2:\n                print('MAP spike train failed to converge before z < %.3g'\n                      % Z_TOL)\n            terminate_interior = True\n\n        elif nloop1 > maxiter:\n            if verbosity >= 2:\n                print('MAP spike train failed to converge within maxiter (%i)'\n                       % maxiter)\n            terminate_interior = True\n\n        # increment the outer loop counter, reduce the barrier weight\n        nloop1 += 1\n        z /= Z_FAC\n\n    return n_hat, c_hat, LL_best"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the object from a web element.", "response": "def from_web_element(self, web_element):\n        \"\"\"\n            Store reference to a WebElement instance representing the element on the DOM.\n            Use it when an instance of WebElement has already been created (e.g. as the result of find_element) and\n            you want to create a UIComponent out of it without evaluating it from the locator again.\n            Returns an instance of the class.\n        \"\"\"\n        if isinstance(web_element, WebElement) is not True:\n            raise TypeError(\"web_element parameter is not of type WebElement.\")\n        self._web_element = web_element\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef locate(self):\n        if self._web_element:\n            return self._web_element\n        else:\n            locator_type, locator_value = self.__locator\n            element = self.driver.find_element(by=locator_type, value=locator_value)\n            self._cache_web_element(element)  # cache the element if allowed\n            return element", "response": "Locates the element on the DOM."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef input_text_with_keyboard_emulation(self, text):\n        ActionChains(self.driver).key_down(text).key_up(Keys.CONTROL).perform()", "response": "Emulates keyboard emulation of the input text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_fake_movie(nframes, mask_shape=(64, 64), mask_center=None,\n                    bg_intensity=0.1, mask_sigma=10, dt=0.02, rate=1.0,\n                    tau=1., sigma=0.001, seed=None):\n    \"\"\"\n    Generate 2D fake fluorescence movie\n\n    Arguments:\n    ---------------------------------------------------------------------------\n        nframes:        number of timebins to simulate\n        mask_shape:     tuple (nrows, ncols), shape of a single movie frame\n        mask_center:    tuple (x, y), pixel coords of cell center\n        bg_intensity:   scalar, amplitude of (static) baseline fluorescence\n        mask_sigma:     scalar, standard deviation of Gaussian mask\n        dt:             timestep (s)\n        rate:           mean spike rate (Hz)\n        tau:            time constant of decay in calcium concentration (s)\n        sigma:          SD of additive noise on fluorescence\n        seed:           Seed for RNG\n\n    Returns:\n    ---------------------------------------------------------------------------\n        F:          fluorescence [npixels, nframes]\n        c:          calcium concentration [nframes,]\n        n:          spike train [nframes,]\n        theta:      tuple of true model parameters:\n                    (sigma, alpha, beta, lambda, gamma)\n\n    \"\"\"\n\n    gen = np.random.RandomState(seed)\n\n    # poisson spikes\n    n = gen.poisson(rate * dt, size=nframes)\n\n    # internal calcium dynamics\n    gamma = np.exp(-dt / tau)\n    c = signal.lfilter(np.r_[1], np.r_[1, -gamma], n, axis=0)\n\n    # pixel weights (sum == 1)\n    nr, nc = mask_shape\n    npix = nr * nc\n    if mask_center is None:\n        mask_center = (nc // 2., nr // 2.)\n    a, b = mask_center\n    y, x = np.ogrid[:nr, :nc]\n    xs = (x - a) ** 2.\n    ys = (y - b) ** 2.\n    twoss = 2. * mask_sigma ** 2.\n    alpha = np.exp(-1 * ((xs / twoss) + (ys / twoss))).ravel()\n    alpha /= alpha.sum()\n\n    # background fluorescence\n    beta = gen.randn(npix) * bg_intensity\n\n    # firing rate (spike probability per sec)\n    lamb = rate\n\n    # spatially & temporally white noise\n    epsilon = gen.randn(npix, nframes) * sigma\n\n    # simulated fluorescence\n    F = c[None, :] * alpha[:, None] + beta[:, None] + epsilon\n\n    theta = (sigma, alpha, beta, lamb, gamma)\n\n    return F, c, n, theta", "response": "Generate a 2D fake fluorescence movie."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef evaluate_traits(self):\n        return_value = []\n        for trait in self.traits:\n            if not trait.condition():\n                if not self.traits_eager_evaluation:\n                    return [trait.description]\n                else:\n                    return_value.append(trait.description)\n        return return_value", "response": "Evaluates the traits and returns a list containing the description of traits which are not true."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwaits until condition is True or returns a non - None value.", "response": "def until_condition(self, condition, condition_description):\n        \"\"\"\n        Waits until conditions is True or returns a non-None value.\n        If any of the trait is still not present after timeout, raises a TimeoutException.\n        \"\"\"\n        end_time = time.time() + self._timeout\n        count = 1\n        while True:\n            try:\n                if not hasattr(condition, '__call__'):\n                    raise TypeError(\"condition is not callable\")\n                value = condition()\n                if type(value) is bool and value is not False:\n                    return value\n                elif type(value) is not bool and value is not None:\n                    return value\n                else:\n                    logger.debug(\"#\" + str(count) + \" - wait until \" + condition_description)  # pragma: no cover\n            except self._ignored_exceptions as ex:\n                logger.debug(\"Captured {0} : {1}\".format(str(ex.__class__).replace(\"<type '\", \"\").replace(\"'>\", \"\"),\n                                                         str(ex)))  # pragma: no cover\n            time.sleep(self._poll)\n            count += 1\n            if time.time() > end_time:  # pragma: no cover\n                break\n        raise TimeoutException(\n            msg=\"condition <\" + condition_description + \"> was not true after \" + str(self._timeout) + \" seconds.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwaiting until all traits are present.", "response": "def until_traits_are_present(self, element_with_traits):\n        \"\"\"\n        Waits until all traits are present.\n        If any of the traits is still not present after timeout, raises a TimeoutException.\n        \"\"\"\n        end_time = time.time() + self._timeout\n        count = 1\n        missing_traits_descriptions = None\n        while True:\n            missing_traits_descriptions = []\n            try:\n                missing_traits_descriptions = element_with_traits.evaluate_traits()\n                if len(missing_traits_descriptions) == 0:\n                    return True\n                else:\n                    logger.debug(\"#{0} - wait until all traits are present: <{1}>\".format(str(count), '> <'.join(\n                        missing_traits_descriptions)))\n            except self._ignored_exceptions as ex:  # pragma: no cover\n                logger.debug(\"Captured {0}: {1}\".format(str(ex.__class__).replace(\"<type '\", \"\").replace(\"'>\", \"\"),\n                                                        str(ex)))  # pragma: no cover\n                pass  # pragma: no cover\n            time.sleep(self._poll)\n            count += 1\n            if time.time() > end_time:\n                break\n        raise TimeoutException(\n            msg=\"conditions \" + '<' + '> <'.join(missing_traits_descriptions) + '>' + \" not true after \" + str(\n                self._timeout) + \" seconds.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the ignored exceptions for this wait loop.", "response": "def with_ignored_exceptions(self, *ignored_exceptions):\n        \"\"\"\n        Set a list of exceptions that should be ignored inside the wait loop.\n        \"\"\"\n        for exception in ignored_exceptions:\n            self._ignored_exceptions = self._ignored_exceptions + (exception,)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef s2h(ss):\n    mm, ss = divmod(ss, 60)\n    hh, mm = divmod(mm, 60)\n    dd, hh = divmod(hh, 24)\n    tstr = \"%02i:%04.1f\" % (mm, ss)\n    if hh > 0:\n        tstr = (\"%02i:\" % hh) + tstr\n    if dd > 0:\n        tstr = (\"%id \" % dd) + tstr\n    return tstr", "response": "convert seconds to a pretty d hh : mm : ss. s format"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a command to the receiver and read the value it returns.", "response": "def exec_command(self, domain, function, operator, value=None):\n        \"\"\"\n        Write a command to the receiver and read the value it returns.\n\n        The receiver will always return a value, also when setting a value.\n        \"\"\"\n        if operator in CMDS[domain][function]['supported_operators']:\n            if operator is '=' and value is None:\n                raise ValueError('No value provided')\n\n            if value is None:\n                cmd = ''.join([CMDS[domain][function]['cmd'], operator])\n            else:\n                cmd = ''.join(\n                    [CMDS[domain][function]['cmd'], operator, str(value)])\n        else:\n            raise ValueError('Invalid operator provided %s' % operator)\n\n        if not self.ser.is_open:\n            self.ser.open()\n\n        try:\n            self.lock.acquire()\n\n            self.ser.write(''.join(['\\r', cmd, '\\r']).encode('utf-8'))\n            time.sleep(0.1)\n            # not sure why, but otherwise it is not ready yet to do the read.\n\n            msg = self.ser.read(self.ser.in_waiting)\n            \n            try:\n                msg = msg.decode()[1:-1]\n                msg = msg.split('=')[1]\n                return msg\n            except IndexError:\n                pass\n\n        finally:\n            self.lock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes Main. Volume. getIAVolume. getIAVolume", "response": "def main_volume(self, operator, value=None):\n        \"\"\"\n        Execute Main.Volume.\n\n        Returns int\n        \"\"\"\n        try:\n            res = int(self.exec_command('main', 'volume', operator, value))\n            return res\n\n        except (ValueError, TypeError):\n            pass\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute Main. Source. getIAStatusCode.", "response": "def main_source(self, operator, value=None):\n        \"\"\"\n        Execute Main.Source.\n\n        Returns int\n        \"\"\"\n        try:\n            source = int(self.exec_command('main', 'source', operator, value))\n            return source\n        except (ValueError, TypeError):\n            pass\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _send(self, message, read_reply=False):\n        sock = None\n        for tries in range(0, 3):\n            try:\n                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                sock.connect((self._host, self.PORT))\n                break\n            except (ConnectionError, BrokenPipeError):\n                if tries == 3:\n                    print(\"socket connect failed.\")\n                    return\n                sleep(0.1)\n        sock.send(codecs.decode(message, 'hex_codec'))\n        if read_reply:\n            sleep(0.1)\n            reply = ''\n            tries = 0\n            max_tries = 20\n            while len(reply) < len(message) and tries < max_tries:\n                try:\n                    reply += codecs.encode(sock.recv(self.BUFFERSIZE), 'hex')\\\n                        .decode(\"utf-8\")\n                except (ConnectionError, BrokenPipeError):\n                    pass\n                tries += 1\n            sock.close()\n            if tries >= max_tries:\n                return\n            return reply\n        sock.close()", "response": "Send a command string to the amplifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the status of the device.", "response": "def status(self):\n        \"\"\"\n        Return the status of the device.\n\n        Returns a dictionary with keys 'volume' (int 0-200) , 'power' (bool),\n         'muted' (bool) and 'source' (str).\n        \"\"\"\n        nad_reply = self._send(self.POLL_VOLUME +\n                               self.POLL_POWER +\n                               self.POLL_MUTED +\n                               self.POLL_SOURCE, read_reply=True)\n        if nad_reply is None:\n            return\n\n        # split reply into parts of 10 characters\n        num_chars = 10\n        nad_status = [nad_reply[i:i + num_chars]\n                      for i in range(0, len(nad_reply), num_chars)]\n\n        return {'volume': int(nad_status[0][-2:], 16),\n                'power': nad_status[1][-2:] == '01',\n                'muted': nad_status[2][-2:] == '01',\n                'source': self.SOURCES_REVERSED[nad_status[3][-2:]]}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npower the device off.", "response": "def power_off(self):\n        \"\"\"Power the device off.\"\"\"\n        status = self.status()\n        if status['power']:  # Setting power off when it is already off can cause hangs\n            self._send(self.CMD_POWERSAVE + self.CMD_OFF)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npower the device on.", "response": "def power_on(self):\n        \"\"\"Power the device on.\"\"\"\n        status = self.status()\n        if not status['power']:\n            self._send(self.CMD_ON, read_reply=True)\n            sleep(0.5)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_volume(self, volume):\n        if 0 <= volume <= 200:\n            volume = format(volume, \"02x\")  # Convert to hex\n            self._send(self.CMD_VOLUME + volume)", "response": "Set the volume level of the device. Accepts integer values 0 - 200."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nselecting a source from the list of sources.", "response": "def select_source(self, source):\n        \"\"\"Select a source from the list of sources.\"\"\"\n        status = self.status()\n        if status['power']:  # Changing source when off may hang NAD7050\n            if status['source'] != source:  # Setting the source to the current source will hang the NAD7050\n                if source in self.SOURCES:\n                    self._send(self.CMD_SOURCE + self.SOURCES[source], read_reply=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite a command to the receiver and read the value it returns.", "response": "def exec_command(self, domain, function, operator, value=None):\n        \"\"\"\n        Write a command to the receiver and read the value it returns.\n        \"\"\"\n        if operator in CMDS[domain][function]['supported_operators']:\n            if operator is '=' and value is None:\n                raise ValueError('No value provided')\n\n            if value is None:\n                cmd = ''.join([CMDS[domain][function]['cmd'], operator])\n            else:\n                cmd = ''.join(\n                    [CMDS[domain][function]['cmd'], operator, str(value)])\n        else:\n            raise ValueError('Invalid operator provided %s' % operator)\n\n        if self._open_connection():\n            # For telnet the first \\r / \\n is recommended only\n            self.telnet.write((''.join(['\\r', cmd, '\\n']).encode()))\n            # Could raise eg. socket.error, UnicodeError, let the client handle it\n\n            # Test 3 x buffer is completely empty\n            # With the default timeout that means a delay at\n            # about 3+ seconds\n            loop = 3\n            while loop:\n                msg = self.telnet.read_until('\\n'.encode(), self.timeout)\n                # Could raise eg. EOFError, UnicodeError, let the client handle it\n\n                if msg == \"\":\n                    # Nothing in buffer\n                    loop -= 1\n                    continue\n\n                msg = msg.decode().strip('\\r\\n')\n                # Could raise eg. UnicodeError, let the client handle it\n\n                #print(\"NAD reponded with '%s'\" % msg)\n                # Wait for the response that equals the requested domain.function\n                if msg.strip().split('=')[0].lower() == '.'.join([domain, function]).lower():\n                    # b'Main.Volume=-12\\r will return -12\n                    return msg.strip().split('=')[1]\n\n            raise RuntimeError('Failed to read response')\n\n        raise RuntimeError('Failed to open connection')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deobfuscate(request, key, juice=None):\n    try:\n        url = decrypt(str(key),\n                      settings.UNFRIENDLY_SECRET,\n                      settings.UNFRIENDLY_IV,\n                      checksum=settings.UNFRIENDLY_ENFORCE_CHECKSUM)\n    except (CheckSumError, InvalidKeyError):\n        return HttpResponseNotFound()\n\n    try:\n        url = url.decode('utf-8')\n    except UnicodeDecodeError:\n        return HttpResponseNotFound()\n\n    url_parts = urlparse(unquote(url))\n    path = url_parts.path\n    query = url_parts.query\n\n    try:\n        view, args, kwargs = resolve(path)\n    except Resolver404:\n        return HttpResponseNotFound()\n\n    # fix-up the environ object\n    environ = request.environ.copy()\n    environ['PATH_INFO'] = path[len(environ['SCRIPT_NAME']):]\n    environ['QUERY_STRING'] = query\n\n    # init a new request\n    patched_request = request.__class__(environ)\n\n    # copy over any missing request attributes - this feels hackish\n    missing_items = set(dir(request)) - set(dir(patched_request))\n    while missing_items:\n        missing_item = missing_items.pop()\n        patched_request.__setattr__(missing_item,\n                                    request.__getattribute__(missing_item))\n\n    # mark this request as obfuscated\n    patched_request.META['obfuscated'] = True\n\n    response = view(patched_request, *args, **kwargs)\n\n    # offer up a friendlier juice-powered filename if downloaded\n    if juice and not response.has_header('Content-Disposition'):\n        response['Content-Disposition'] = 'inline; filename=%s' % juice\n\n    return response", "response": "Deobfuscates the URL and returns HttpResponse from source view."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npad secret if not legal AES block size", "response": "def _lazysecret(secret, blocksize=32, padding='}'):\n    \"\"\"Pads secret if not legal AES block size (16, 24, 32)\"\"\"\n    if not len(secret) in (16, 24, 32):\n        return secret + (blocksize - len(secret)) * padding\n    return secret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates crc32. Modulo keep the value within int range.", "response": "def _crc(plaintext):\n    \"\"\"Generates crc32. Modulo keep the value within int range.\"\"\"\n    if not isinstance(plaintext, six.binary_type):\n        plaintext = six.b(plaintext)\n    return (zlib.crc32(plaintext) % 2147483647) & 0xffffffff"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nencrypting plaintext with secret", "response": "def encrypt(plaintext, secret, inital_vector, checksum=True, lazy=True):\n    \"\"\"Encrypts plaintext with secret\n    plaintext      - content to encrypt\n    secret         - secret to encrypt plaintext\n    inital_vector  - initial vector\n    lazy           - pad secret if less than legal blocksize (default: True)\n    checksum       - attach crc32 byte encoded (default: True)\n    returns ciphertext\n    \"\"\"\n    if not isinstance(plaintext, six.binary_type):\n        plaintext = six.b(plaintext)\n\n    secret = _lazysecret(secret) if lazy else secret\n    encobj = AES.new(secret, AES.MODE_CFB, inital_vector)\n\n    if checksum:\n        packed = _pack_crc(plaintext)\n        plaintext += base64.urlsafe_b64encode(packed)\n\n    encoded = base64.urlsafe_b64encode(encobj.encrypt(plaintext))\n    if isinstance(plaintext, six.binary_type):\n        encoded = encoded.decode()\n\n    return encoded.replace('=', '')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decrypt(ciphertext, secret, inital_vector, checksum=True, lazy=True):\n    secret = _lazysecret(secret) if lazy else secret\n    encobj = AES.new(secret, AES.MODE_CFB, inital_vector)\n    try:\n        padded = ciphertext + ('=' * (len(ciphertext) % 4))\n        decoded = base64.urlsafe_b64decode(str(padded))\n        plaintext = encobj.decrypt(decoded)\n    except (TypeError, binascii.Error):\n        raise InvalidKeyError(\"invalid key\")\n\n    if checksum:\n        try:\n            crc, plaintext = (base64.urlsafe_b64decode(\n                plaintext[-8:]), plaintext[:-8])\n        except (TypeError, binascii.Error):\n            raise CheckSumError(\"checksum mismatch\")\n\n        if not crc == _pack_crc(plaintext):\n            raise CheckSumError(\"checksum mismatch\")\n\n    return plaintext", "response": "Decrypts ciphertext with secret returning plaintext content"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a URL that obfuscates whatever text it is applied to.", "response": "def obfuscate(value, juice=None):\n    \"\"\"\n    Template filter that obfuscates whatever text it is applied to. The text is\n    supposed to be a URL, but it will obfuscate anything.\n\n    Usage:\n        Extremely unfriendly URL:\n        {{ \"/my-secret-path/\"|obfuscate }}\n\n        Include some SEO juice:\n        {{ \"/my-secret-path/\"|obfuscate:\"some SEO friendly text\" }}\n    \"\"\"\n    if not settings.UNFRIENDLY_ENABLE_FILTER:\n        return value\n    kwargs = {\n        'key': encrypt(value,\n                       settings.UNFRIENDLY_SECRET,\n                       settings.UNFRIENDLY_IV,\n                       checksum=settings.UNFRIENDLY_ENFORCE_CHECKSUM),\n    }\n    if juice:\n        kwargs['juice'] = slugify(juice)\n    return reverse('unfriendly-deobfuscate', kwargs=kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef missing_schema(self,html,song_name):\n\t\t'''\n\t\tIt will print the list of songs that can be downloaded\n\t\t'''\n\t\t#html=self.get_html_response(url)\n\t\tsoup=BeautifulSoup(html)\n\t\tname=' '.join(song_name)\n\t\tprint '%s not found'%name\n\t\tprint \"But you can download any of the following songs :\"\n\t\ta_list=soup.findAll('a','touch')\n\t\tfor x in xrange(len(a_list)-1):\n\t\t\tr=a_list[x]\n\t\t\tp=str(r)\n\t\t\tq=re.sub(r'<a.*/>|<span.*\">|</span>|</a>|<a.*html\">|<font.*\">|</font>','',p)\n\t\t\tprint q", "response": "This function will print the list of songs that can be downloaded from the server but can t be downloaded."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_if_song_name(self,html):\n\t\t'''\n\t\tReturns true if user entered artist or movie name\n\t\t'''\n\t\tsoup=BeautifulSoup(html)\n\t\ta_list=soup.findAll('a','touch')\n\t\t#print a_list\n\t\ttext=[str(x) for x in a_list]\n\t\ttext=''.join(text)\n\t\ttext=text.lower()\n\t\tstring1='download in 48 kbps'\n\t\tstring2='download in 128 kbps'\n\t\tstring3='download in 320 kbps'\n\n\t\thref=''\n\t\tif string3 in text:\n\t\t\t#print 'Downloading in 320 kbps'\n\t\t\thref=a_list[2].get('href')\n\t\t\t\n\t\telif string2 in text:\n\t\t\t#print 'Downloading in 128 kbps'\n\t\t\thref=a_list[1].get('href')\n\t\t\t\n\t\telif string1 in text:\n\t\t\t#print 'Downloading in 48 kbps'\t\n\t\t\thref=a_list[0].get('href')\n\t\telse:\n\t\t\treturn (True,'nothing')\t\t\n\n\t\treturn (False,href)", "response": "Check if user entered artist or movie name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the song and return the URL of the songs that can be downloaded.", "response": "def Parse(self,url,song_name,flag):\n\t\t'''\n\t\tIt will the resource URL if song is found,\n\t\tOtherwise it will return the list of songs that can be downloaded\n\t\t'''\n\t\tfile_download=FileDownload()\n\t\thtml=file_download.get_html_response(url)\n\t\tif flag == False:\n\t\t\tsoup=BeautifulSoup(html)\n\t\t\ta_list=soup.findAll('a','touch')\n\t\t\t#print a_list\n\t\t\ttext=[str(x) for x in a_list]\n\t\t\ttext=''.join(text)\n\t\t\ttext=text.lower()\n\t\t\tstring1='download in 48 kbps'\n\t\t\tstring2='download in 128 kbps'\n\t\t\tstring3='download in 320 kbps'\n\n\t\t\thref=''\n\t\t\tif string3 in text:\n\t\t\t\tprint 'Downloading in 320 kbps'\n\t\t\t\thref=a_list[2].get('href')\n\t\t\t\t\n\t\t\telif string2 in text:\n\t\t\t\tprint 'Downloading in 128 kbps'\n\t\t\t\thref=a_list[1].get('href')\n\t\t\t\t\n\t\t\telif string1 in text:\n\t\t\t\tprint 'Downloading in 48 kbps'\t\n\t\t\t\thref=a_list[0].get('href')\n\t\t\telse:\n\t\t\t\tself.missing_schema(html,song_name)\n\t\t\t\tquit()\t\t\n\n\t\t\treturn href \n\t\telse:\n\t\t\tx,href=self.check_if_song_name(html)\n\t\t\tlinks = []\n\t\t\tif x==True:\n\t\t\t\tlinks=self.list_of_all_href(html)\n\t\t\telse:\n\t\t\t\tfile_download=FileDownload()\n\t\t\t\tfile_download.file_download_cross_platform(href)\n\t\t\t\tquit()\t\n\t\t\t\n\n\t\t\treturn links"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_google(self,html):\n\t\t'''It will parse google html response\n\t\t\tand return the first url\n\t\t '''\n\t\tsoup = BeautifulSoup(html)\n\t\thref=soup.find('div','g').find('a').get('href')\n\t\thref_list=href.split('&')\n\t\tdownload_url=href_list[0]\n\t\tdownload_url=download_url.strip()\n\t\tdownload_url=download_url.replace('/url?q=','')\n\t\treturn download_url", "response": "It will parse google html response\n\t\t\tand return the first url"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_html_response(self,url):\n\t\t'''It will download the html page specified by url and return the html response '''\n\t\tprint \"Downloading page %s ..\"%url\n\t\ttry:\n\t\t\tresponse=requests.get(url,timeout=50)\n\t\texcept requests.exceptions.SSLError:\n\t\t\ttry:\n\t\t\t\tresponse=requests.get(url,verify=False,timeout=50)\n\t\t\texcept requests.exceptions.RequestException as e:\n\t\t\t\tprint e\n\t\t\t\tquit()\n\t\texcept requests.exceptions.RequestException as e:\n\t\t\tprint e\t\n\t\t\tquit()\n\n\t\treturn response.content", "response": "This method will download the html page specified by url and return the html response."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef file_download_using_wget(self,url):\n\t\t'''It will download file specified by url using wget utility of linux '''\n\t\tfile_name=url.split('/')[-1]\n\t\tprint 'Downloading file %s '%file_name\n\t\tcommand='wget -c --read-timeout=50 --tries=3 -q --show-progress --no-check-certificate '\n\t\turl='\"'+url+'\"'\n\t\tcommand=command+url\n\t\tos.system(command)", "response": "It will download file specified by url using wget utility of linux"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a bloom filter from a file.", "response": "def ReadingBloomFilter(filename, want_lock=False):\n    \"\"\"\n    Create a read-only bloom filter with an upperbound of\n    (num_elements, max_fp_prob) as a specification and using filename\n    as the backing datastore.\n    \"\"\"\n    with open('{}.desc'.format(filename), 'r') as descriptor:\n        num_elements = int(descriptor.readline())\n        max_fp_prob = float(descriptor.readline())\n        ignore_case = int(descriptor.readline())\n\n    return _hydra.BloomFilter.getFilter(\n        num_elements, max_fp_prob,\n        filename=filename, ignore_case=ignore_case,\n        read_only=True, want_lock=want_lock)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef WritingBloomFilter(num_elements, max_fp_prob, filename=None,\n                       ignore_case=False, want_lock=False,\n                       fdatasync_on_close=True):\n    \"\"\"\n    Create a read/write bloom filter with an upperbound of\n    (num_elements, max_fp_prob) as a specification and using filename\n    as the backing datastore.\n    \"\"\"\n    new_filter = _hydra.BloomFilter.getFilter(\n        num_elements, max_fp_prob,\n        filename=filename, ignore_case=ignore_case,\n        read_only=False, want_lock=want_lock,\n        fdatasync_on_close=fdatasync_on_close)\n    if filename:\n        with open('{}.desc'.format(filename), 'w') as descriptor:\n            descriptor.write(\"{}\\n\".format(num_elements))\n            descriptor.write(\"{:0.8f}\\n\".format(max_fp_prob))\n            descriptor.write(\"{:d}\\n\".format(ignore_case))\n    return new_filter", "response": "Creates a bloom filter with the specified number of elements and maximum probability."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_observation_response(json):\n    logging.debug(json)\n\n    iaqi = json['iaqi']\n    result = {\n        'idx': json['idx'],\n        'city': json.get('city', ''),\n        'aqi': json['aqi'],\n        'dominentpol': json.get(\"dominentpol\", ''),\n        'time': json['time']['s'],\n        'iaqi': [{'p': item, 'v': iaqi[item]['v']} for item in iaqi]\n    }\n\n    return result", "response": "Decode AQICN observation response JSON into python object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrequesting station data for a specific station identified by code and token.", "response": "def get_station_observation(station_code, token):\n    \"\"\"Request station data for a specific station identified by code.\n\n    A language parameter can also be specified to translate location\n    information (default: \"en\")\n    \"\"\"\n    req = requests.get(\n        API_ENDPOINT_OBS % (station_code),\n        params={\n            'token': token\n        })\n\n    if req.status_code == 200 and req.json()['status'] == \"ok\":\n        return parse_observation_response(req.json()['data'])\n    else:\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef path_without_suffix(self):\n        if self.suffix:\n            return self.path[:-len(''.join(self.suffix))]\n        return self.path", "response": "The relative path to asset without suffix."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef logical_path(self):\n        format_extension = self.format_extension or self.compiler_format_extension\n        if format_extension is None:\n            return self.path\n        return self.path_without_suffix + format_extension", "response": "The logical path to asset.\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extensions(self):\n        return re.findall(r'\\.[^.]+', os.path.basename(self.path))", "response": "The list of asset extensions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef processors(self):\n        return self.preprocessors + list(reversed(self.compilers)) + self.postprocessors", "response": "The list of all processors used to build asset."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mimetype(self):\n        return (self.environment.mimetypes.get(self.format_extension) or\n                self.compiler_mimetype or 'application/octet-stream')", "response": "MIME type of the asset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compiler_mimetype(self):\n        for compiler in reversed(self.compilers):\n            if compiler.result_mimetype:\n                return compiler.result_mimetype\n        return None", "response": "Implicit MIME type of the asset by its compilers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register(self, mimetype, processor):\n        if mimetype not in self or processor not in self[mimetype]:\n            self.setdefault(mimetype, []).append(processor)", "response": "Register passed processor for passed mimetype."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unregister(self, mimetype, processor):\n        if mimetype in self and processor in self[mimetype]:\n            self[mimetype].remove(processor)", "response": "Remove passed processor for passed MIME type."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters default Directives Processor.", "response": "def register_defaults(self):\n        \"\"\"Register :class:`~gears.processors.DirectivesProcessor` as\n        a preprocessor for `text/css` and `application/javascript` MIME types.\n        \"\"\"\n        self.register('text/css', DirectivesProcessor.as_handler())\n        self.register('application/javascript', DirectivesProcessor.as_handler())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef suffixes(self):\n        if not hasattr(self, '_suffixes'):\n            suffixes = Suffixes()\n            for extension, mimetype in self.mimetypes.items():\n                suffixes.register(extension, root=True, mimetype=mimetype)\n            for extension, compiler in self.compilers.items():\n                suffixes.register(extension, to=compiler.result_mimetype)\n            self._suffixes = suffixes\n        return self._suffixes", "response": "The registry for supported suffixes of assets."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef paths(self):\n        if not hasattr(self, '_paths'):\n            paths = []\n            for finder in self.finders:\n                if hasattr(finder, 'paths'):\n                    paths.extend(finder.paths)\n            self._paths = paths\n        return self._paths", "response": "The list of search paths for this instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_defaults(self):\n        self.mimetypes.register_defaults()\n        self.preprocessors.register_defaults()\n        self.postprocessors.register_defaults()", "response": "Register default compilers preprocessors and MIME types."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_entry_points(self, exclude=()):\n        for entry_point in iter_entry_points('gears', 'register'):\n            if entry_point.module_name not in exclude:\n                register = entry_point.load()\n                register(self)", "response": "Allow Gears plugins to inject themselves to the environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds files using the given item.", "response": "def find(self, item, logical=False):\n        \"\"\"Find files using :attr:`finders` registry. The ``item`` parameter\n        can be an instance of :class:`~gears.asset_attributes.AssetAttributes`\n        class, a path to the asset or a logical path to the asset. If ``item``\n        is a logical path, `logical` parameter must be set to ``True``.\n\n        Returns a tuple with :class:`~gears.asset_attributes.AssetAttributes`\n        instance for found file path as first item, and absolute path to this\n        file as second item.\n\n        If nothing is found, :class:`gears.exceptions.FileNotFound` exception\n        is rased.\n        \"\"\"\n        if isinstance(item, AssetAttributes):\n            for path in item.search_paths:\n                try:\n                    return self.find(path, logical)\n                except FileNotFound:\n                    continue\n            raise FileNotFound(item.path)\n        if logical:\n            asset_attributes = AssetAttributes(self, item)\n            suffixes = self.suffixes.find(asset_attributes.mimetype)\n            if not suffixes:\n                return self.find(item)\n            path = asset_attributes.path_without_suffix\n            for suffix in suffixes:\n                try:\n                    return self.find(path + suffix)\n                except FileNotFound:\n                    continue\n        else:\n            for finder in self.finders:\n                try:\n                    absolute_path = finder.find(item)\n                except FileNotFound:\n                    continue\n                return AssetAttributes(self, item), absolute_path\n        raise FileNotFound(item)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding two - tuples for all files found in the given directory given by path parameter. Result can be filtered by mimetype parameter.", "response": "def list(self, path, mimetype=None):\n        \"\"\"Yield two-tuples for all files found in the directory given by\n        ``path`` parameter. Result can be filtered by the second parameter,\n        ``mimetype``, that must be a MIME type of assets compiled source code.\n        Each tuple has :class:`~gears.asset_attributes.AssetAttributes`\n        instance for found file path as first item, and absolute path to this\n        file as second item.\n\n        Usage example::\n\n            # Yield all files from 'js/templates' directory.\n            environment.list('js/templates/*')\n\n            # Yield only files that are in 'js/templates' directory and have\n            # 'application/javascript' MIME type of compiled source code.\n            environment.list('js/templates/*', mimetype='application/javascript')\n        \"\"\"\n        basename_pattern = os.path.basename(path)\n\n        if path.endswith('**'):\n            paths = [path]\n        else:\n            paths = AssetAttributes(self, path).search_paths\n        paths = map(lambda p: p if p.endswith('*') else p + '*', paths)\n\n        results = unique(self._list_paths(paths), lambda x: x[0])\n        for logical_path, absolute_path in results:\n            asset_attributes = AssetAttributes(self, logical_path)\n            if mimetype is not None and asset_attributes.mimetype != mimetype:\n                continue\n\n            basename = os.path.basename(asset_attributes.path_without_suffix)\n            if not fnmatch(basename, basename_pattern) and basename != 'index':\n                continue\n\n            yield asset_attributes, absolute_path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving handled public assets to root directory.", "response": "def save(self):\n        \"\"\"Save handled public assets to :attr:`root` directory.\"\"\"\n        for asset_attributes, absolute_path in self.list('**'):\n            logical_path = os.path.normpath(asset_attributes.logical_path)\n            check_asset = build_asset(self, logical_path, check=True)\n            if check_asset.is_public:\n                asset = build_asset(self, logical_path)\n                source = bytes(asset)\n                self.save_file(logical_path, source, asset.gzippable)\n                if self.fingerprinting:\n                    self.save_file(asset.hexdigest_path, source, asset.gzippable)\n                    self.manifest.files[logical_path] = asset.hexdigest_path\n        self.manifest.dump()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npopulate the form with the current IDA data.", "response": "def PopulateForm(self):\r\n        \"\"\"\r\n        +-----------------------------------------------------------------------+\r\n        | +--- splitter ------------------------------------------------------+ |\r\n        | | +-- list widget--------------+  +- IdaSettingsView -------------+ | |\r\n        | | |                            |  |                               | | |\r\n        | | |  - plugin name             |  |                               | | |\r\n        | | |  - plugin name             |  |                               | | |\r\n        | | |  - plugin name             |  |                               | | |\r\n        | | |                            |  |                               | | |\r\n        | | |                            |  |                               | | |\r\n        | | |                            |  |                               | | |\r\n        | | |                            |  |                               | | |\r\n        | | |                            |  |                               | | |\r\n        | | |                            |  |                               | | |\r\n        | | |                            |  |                               | | |\r\n        | | |                            |  |                               | | |\r\n        | | |                            |  |                               | | |\r\n        | | |                            |  |                               | | |\r\n        | | |                            |  |                               | | |\r\n        | | |                            |  |                               | | |\r\n        | | |                            |  |                               | | |\r\n        | | +----------------------------+  +-------------------------------+ | |\r\n        | +-------------------------------------------------------------------+ |\r\n        +-----------------------------------------------------------------------+\r\n        \"\"\"\r\n        hbox = QtWidgets.QHBoxLayout(self.parent)\r\n\r\n        self._splitter = QtWidgets.QSplitter(QtCore.Qt.Horizontal)\r\n        self._plugin_list = QtWidgets.QListWidget()\r\n\r\n        plugin_names = set([])\r\n        for scope, fn in ((\"idb\", ida_settings.IDASettings.get_idb_plugin_names),\r\n                (\"directory\", ida_settings.IDASettings.get_directory_plugin_names),\r\n                (\"user\", ida_settings.IDASettings.get_user_plugin_names),\r\n                (\"system\", ida_settings.IDASettings.get_system_plugin_names)):\r\n            for plugin_name in fn():\r\n                plugin_names.add(plugin_name)\r\n        for plugin_name in plugin_names:\r\n            self._plugin_list.addItem(plugin_name)\r\n        self._splitter.addWidget(self._plugin_list)\r\n\r\n        hbox.addWidget(self._splitter)\r\n        self.parent.setLayout(hbox)\r\n        \r\n        self._plugin_list.currentItemChanged.connect(self._handle_plugin_changed)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef as_handler(cls, **initkwargs):\n        @wraps(cls, updated=())\n        def handler(asset, *args, **kwargs):\n            return handler.handler_class(**initkwargs)(asset, *args, **kwargs)\n        handler.handler_class = cls\n        handler.supports_check_mode = cls.supports_check_mode\n        return handler", "response": "Converts the given class into an actual handler function that can be used\n        when registering different types of processors."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self, input):\n        p = self.get_process()\n        output, errors = p.communicate(input=input.encode('utf-8'))\n        if p.returncode != 0:\n            raise AssetHandlerError(errors)\n        return output.decode('utf-8')", "response": "Runs the executable with input as stdin."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_process(self):\n        return Popen(self.get_args(), stdin=PIPE, stdout=PIPE, stderr=PIPE)", "response": "Returns a subprocess instance with args from\n        and piped stdin stdout and stderr."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef import_qtcore():\n    has_ida = False\n    try:\n        # if we're running under IDA,\n        # then we'll use IDA's Qt bindings\n        import idaapi\n        has_ida = True\n    except ImportError:\n        # not running under IDA,\n        # so use default Qt installation\n        has_ida = False\n\n    if has_ida:\n        old_path = sys.path[:]\n        try:\n            ida_python_path = os.path.dirname(idaapi.__file__)\n            sys.path.insert(0, ida_python_path)\n            if idaapi.IDA_SDK_VERSION >= 690:\n                from PyQt5 import QtCore\n                return QtCore\n            else:\n                from PySide import QtCore\n                return QtCore\n        finally:\n            sys.path = old_path\n    else:\n        try:\n            from PyQt5 import QtCore\n            return QtCore\n        except ImportError:\n            pass\n\n        try:\n            from PySide import QtCore\n            return QtCore\n        except ImportError:\n            pass\n\n        raise ImportError(\"No module named PySide or PyQt\")", "response": "Import the IDA s base Qt bindings and return the Qt core object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_meta_netnode():\n    node_name = \"$ {org:s}.{application:s}\".format(\n        org=IDA_SETTINGS_ORGANIZATION,\n        application=IDA_SETTINGS_APPLICATION)\n    return netnode.Netnode(node_name)", "response": "Get the netnode used to store settings metadata in the current IDB."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the given plugin name to the list of registered netnode plugin names in the current IDB.", "response": "def add_netnode_plugin_name(plugin_name):\n    \"\"\"\n    Add the given plugin name to the list of plugin names registered in\n      the current IDB.\n    Note that this implicitly uses the open IDB via the idc iterface.\n    \"\"\"\n    current_names = set(get_netnode_plugin_names())\n    if plugin_name in current_names:\n        return\n\n    current_names.add(plugin_name)\n\n    get_meta_netnode()[PLUGIN_NAMES_KEY] = json.dumps(list(current_names))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef del_netnode_plugin_name(plugin_name):\n    current_names = set(get_netnode_plugin_names())\n    if plugin_name not in current_names:\n        return\n\n    try:\n        current_names.remove(plugin_name)\n    except KeyError:\n        return\n\n    get_meta_netnode()[PLUGIN_NAMES_KEY] = json.dumps(list(current_names))", "response": "Removes the given plugin name from the list of registered netnode plugin names registered in\n      the current IDB."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_settings(settings, config_path):\n    other = QtCore.QSettings(config_path, QtCore.QSettings.IniFormat)\n    for k in other.allKeys():\n        settings[k] = other.value(k)", "response": "Imports settings from the given file system path to given settings instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef export_settings(settings, config_path):\n    other = QtCore.QSettings(config_path, QtCore.QSettings.IniFormat)\n    for k, v in settings.iteritems():\n        other.setValue(k, v)", "response": "Exports the given settings instance to the given file system path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef directory(self):\n        if self._config_directory is None:\n            ensure_ida_loaded()\n        return DirectoryIDASettings(self._plugin_name, directory=self._config_directory)", "response": "Fetch the IDASettings instance for the curren plugin with directory scope."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching the value of the given key from the IDB directory user or dict.", "response": "def get_value(self, key):\n        \"\"\"\n        Fetch the settings value with the highest precedence for the given\n         key, or raise KeyError.\n        Precedence:\n          - IDB scope\n          - directory scope\n          - user scope\n          - system scope\n\n        type key: basestring\n        rtype value: Union[basestring, int, float, List, Dict]\n        \"\"\"\n        try:\n            return self.idb.get_value(key)\n        except (KeyError, EnvironmentError):\n            pass\n        try:\n            return self.directory.get_value(key)\n        except (KeyError, EnvironmentError):\n            pass\n        try:\n            return self.user.get_value(key)\n        except KeyError:\n            pass\n        try:\n            return self.system.get_value(key)\n        except KeyError:\n            pass\n\n        raise KeyError(\"key not found\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nenumerates the keys found at any scope for the current plugin.", "response": "def iterkeys(self):\n        \"\"\"\n        Enumerate the keys found at any scope for the current plugin.\n\n        rtype: Generator[str]\n        \"\"\"\n        visited_keys = set()\n        try:\n            for key in self.idb.iterkeys():\n                if key not in visited_keys:\n                    yield key\n                    visited_keys.add(key)\n        except (PermissionError, EnvironmentError):\n            pass\n\n        try:\n            for key in self.directory.iterkeys():\n                if key not in visited_keys:\n                    yield key\n                    visited_keys.add(key)\n        except (PermissionError, EnvironmentError):\n            pass\n\n        try:\n            for key in self.user.iterkeys():\n                if key not in visited_keys:\n                    yield key\n                    visited_keys.add(key)\n        except (PermissionError, EnvironmentError):\n            pass\n\n        try:\n            for key in self.system.iterkeys():\n                if key not in visited_keys:\n                    yield key\n                    visited_keys.add(key)\n        except (PermissionError, EnvironmentError):\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the names of all plugins in the config directory scope.", "response": "def get_directory_plugin_names(config_directory=None):\n        \"\"\"\n        Get the names of all plugins at the directory scope.\n        Provide a config directory path to use this method outside of IDA.\n        As this is a static method, you can call the directly on IDASettings:\n\n            import ida_settings\n            print( ida_settings.IDASettings.get_directory_plugin_names(\"/tmp/ida/1/\") )\n\n        type config_directory: str\n        rtype: Sequence[str]\n        \"\"\"\n        ensure_ida_loaded()\n        return QtCore.QSettings(get_directory_config_path(directory=config_directory),\n                                QtCore.QSettings.IniFormat).childGroups()[:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef simple_error_handler(exc, *args):\n    if isinstance(exc, exceptions.APIException):\n        headers = {}\n        if getattr(exc, 'auth_header', None):\n            headers['WWW-Authenticate'] = exc.auth_header\n        if getattr(exc, 'wait', None):\n            headers['X-Throttle-Wait-Seconds'] = '%d' % exc.wait\n\n        return Response({'error': exc.detail},\n                        status=exc.status_code,\n                        headers=headers)\n\n    elif isinstance(exc, Http404):\n        return Response({'error': 'Not found'},\n                        status=status.HTTP_404_NOT_FOUND)\n\n    elif isinstance(exc, PermissionDenied):\n        return Response({'error': 'Permission denied'},\n                        status=status.HTTP_403_FORBIDDEN)\n\n    # Note: Unhandled exceptions will raise a 500 error.\n    return None", "response": "Simple error handler for all exceptions."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a given table for the given user.", "response": "def table(name, auth=None, eager=True):\n    \"\"\"Returns a given table for the given user.\"\"\"\n    auth = auth or []\n    dynamodb = boto.connect_dynamodb(*auth)\n\n    table = dynamodb.get_table(name)\n    return Table(table=table, eager=eager)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tables(auth=None, eager=True):\n    auth = auth or []\n    dynamodb = boto.connect_dynamodb(*auth)\n\n    return [table(t, auth, eager=eager) for t in dynamodb.list_tables()]", "response": "Returns a list of tables for the given user."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fetch_items(self, category, **kwargs):\n        from_date = kwargs['from_date']\n\n        if category == CATEGORY_CRATES:\n            return self.__fetch_crates(from_date)\n        else:\n            return self.__fetch_summary()", "response": "Fetch packages and summary from Crates. io\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef metadata_id(item):\n\n        if Crates.metadata_category(item) == CATEGORY_CRATES:\n            return str(item['id'])\n        else:\n            ts = item['fetched_on']\n            ts = str_to_datetime(ts)\n            return str(ts.timestamp())", "response": "Extracts the identifier from an item depending on its type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef metadata_updated_on(item):\n        if Crates.metadata_category(item) == CATEGORY_CRATES:\n            ts = item['updated_at']\n        else:\n            ts = item['fetched_on']\n\n        ts = str_to_datetime(ts)\n\n        return ts.timestamp()", "response": "Extracts the update time from an item."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing the client object.", "response": "def _init_client(self, from_archive=False):\n        \"\"\"Init client\"\"\"\n\n        return CratesClient(self.sleep_time, self.archive, from_archive)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __fetch_summary(self):\n\n        raw_summary = self.client.summary()\n        summary = json.loads(raw_summary)\n        summary['fetched_on'] = str(datetime_utcnow())\n\n        yield summary", "response": "Fetch summary from the server"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfetch all crates in a given date.", "response": "def __fetch_crates(self, from_date):\n        \"\"\"Fetch crates\"\"\"\n\n        from_date = datetime_to_utc(from_date)\n\n        crates_groups = self.client.crates()\n\n        for raw_crates in crates_groups:\n            crates = json.loads(raw_crates)\n\n            for crate_container in crates['crates']:\n\n                if str_to_datetime(crate_container['updated_at']) < from_date:\n                    continue\n\n                crate_id = crate_container['id']\n\n                crate = self.__fetch_crate_data(crate_id)\n                crate['owner_team_data'] = self.__fetch_crate_owner_team(crate_id)\n                crate['owner_user_data'] = self.__fetch_crate_owner_user(crate_id)\n                crate['version_downloads_data'] = self.__fetch_crate_version_downloads(crate_id)\n                crate['versions_data'] = self.__fetch_crate_versions(crate_id)\n\n                yield crate"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch the owner team of a crate", "response": "def __fetch_crate_owner_team(self, crate_id):\n        \"\"\"Get crate team owner\"\"\"\n\n        raw_owner_team = self.client.crate_attribute(crate_id, 'owner_team')\n\n        owner_team = json.loads(raw_owner_team)\n\n        return owner_team"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching the owner user of a crate user", "response": "def __fetch_crate_owner_user(self, crate_id):\n        \"\"\"Get crate user owners\"\"\"\n\n        raw_owner_user = self.client.crate_attribute(crate_id, 'owner_user')\n\n        owner_user = json.loads(raw_owner_user)\n\n        return owner_user"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches the crate versions data", "response": "def __fetch_crate_versions(self, crate_id):\n        \"\"\"Get crate versions data\"\"\"\n\n        raw_versions = self.client.crate_attribute(crate_id, \"versions\")\n\n        version_downloads = json.loads(raw_versions)\n\n        return version_downloads"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch the version downloads from the given crate id", "response": "def __fetch_crate_version_downloads(self, crate_id):\n        \"\"\"Get crate version downloads\"\"\"\n\n        raw_version_downloads = self.client.crate_attribute(crate_id, \"downloads\")\n\n        version_downloads = json.loads(raw_version_downloads)\n\n        return version_downloads"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch crate data from the server", "response": "def __fetch_crate_data(self, crate_id):\n        \"\"\"Get crate data\"\"\"\n\n        raw_crate = self.client.crate(crate_id)\n\n        crate = json.loads(raw_crate)\n        return crate['crate']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget Crates. io summary", "response": "def summary(self):\n        \"\"\"Get Crates.io summary\"\"\"\n\n        path = urijoin(CRATES_API_URL, CATEGORY_SUMMARY)\n        raw_content = self.fetch(path)\n\n        return raw_content"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef crates(self, from_page=1):\n\n        path = urijoin(CRATES_API_URL, CATEGORY_CRATES)\n        raw_crates = self.__fetch_items(path, from_page)\n\n        return raw_crates", "response": "Get all crates in alphabetical order"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a crate by its ID", "response": "def crate(self, crate_id):\n        \"\"\"Get a crate by its ID\"\"\"\n\n        path = urijoin(CRATES_API_URL, CATEGORY_CRATES, crate_id)\n        raw_crate = self.fetch(path)\n\n        return raw_crate"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef crate_attribute(self, crate_id, attribute):\n\n        path = urijoin(CRATES_API_URL, CATEGORY_CRATES, crate_id, attribute)\n        raw_attribute_data = self.fetch(path)\n\n        return raw_attribute_data", "response": "Get a crate attribute"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching the items from Crates. io API using pagination", "response": "def __fetch_items(self, path, page=1):\n        \"\"\"Return the items from Crates.io API using pagination\"\"\"\n\n        fetch_data = True\n        parsed_crates = 0\n        total_crates = 0\n\n        while fetch_data:\n            logger.debug(\"Fetching page: %i\", page)\n\n            try:\n                payload = {'sort': 'alphabetical', 'page': page}\n                raw_content = self.fetch(path, payload=payload)\n                content = json.loads(raw_content)\n\n                parsed_crates += len(content['crates'])\n\n                if not total_crates:\n                    total_crates = content['meta']['total']\n\n            except requests.exceptions.HTTPError as e:\n                logger.error(\"HTTP exception raised - %s\", e.response.text)\n                raise e\n\n            yield raw_content\n            page += 1\n\n            if parsed_crates >= total_crates:\n                fetch_data = False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the textual content associated to the Response object", "response": "def fetch(self, url, payload=None):\n        \"\"\"Return the textual content associated to the Response object\"\"\"\n\n        response = super().fetch(url, payload=payload)\n\n        return response.text"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fetch(self, category=CATEGORY_QUESTION, offset=DEFAULT_OFFSET):\n        if not offset:\n            offset = DEFAULT_OFFSET\n\n        kwargs = {\"offset\": offset}\n        items = super().fetch(category, **kwargs)\n\n        return items", "response": "Fetch questions from the Kitsune url."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fetch_items(self, category, **kwargs):\n        offset = kwargs['offset']\n\n        logger.info(\"Looking for questions at url '%s' using offset %s\",\n                    self.url, str(offset))\n\n        nquestions = 0  # number of questions processed\n        tquestions = 0  # number of questions from API data\n        equestions = 0  # number of questions dropped by errors\n\n        # Always get complete pages so the first item is always\n        # the first one in the page\n        page = int(offset / KitsuneClient.ITEMS_PER_PAGE)\n        page_offset = page * KitsuneClient.ITEMS_PER_PAGE\n        # drop questions from page before the offset\n        drop_questions = offset - page_offset\n        current_offset = offset\n\n        questions_page = self.client.get_questions(offset)\n\n        while True:\n            try:\n                raw_questions = next(questions_page)\n            except StopIteration:\n                break\n            except requests.exceptions.HTTPError as e:\n                # Continue with the next page if it is a 500 error\n                if e.response.status_code == 500:\n                    logger.exception(e)\n                    logger.error(\"Problem getting Kitsune questions. \"\n                                 \"Loosing %i questions. Going to the next page.\",\n                                 KitsuneClient.ITEMS_PER_PAGE)\n                    equestions += KitsuneClient.ITEMS_PER_PAGE\n                    current_offset += KitsuneClient.ITEMS_PER_PAGE\n                    questions_page = self.client.get_questions(current_offset)\n                    continue\n                else:\n                    # If it is another error just propagate the exception\n                    raise e\n\n            try:\n                questions_data = json.loads(raw_questions)\n                tquestions = questions_data['count']\n                questions = questions_data['results']\n            except (ValueError, KeyError) as ex:\n                logger.error(ex)\n                cause = (\"Bad JSON format for mozilla_questions: %s\" % (raw_questions))\n                raise ParseError(cause=cause)\n\n            for question in questions:\n                if drop_questions > 0:\n                    # Remove extra questions due to page base retrieval\n                    drop_questions -= 1\n                    continue\n                question['offset'] = current_offset\n                current_offset += 1\n                question['answers_data'] = []\n                for raw_answers in self.client.get_question_answers(question['id']):\n                    answers = json.loads(raw_answers)['results']\n                    question['answers_data'] += answers\n                yield question\n                nquestions += 1\n\n            logger.debug(\"Questions: %i/%i\", nquestions + offset, tquestions)\n\n        logger.info(\"Total number of questions: %i (%i total)\", nquestions, tquestions)\n        logger.info(\"Questions with errors dropped: %i\", equestions)", "response": "Fetch items from the Kitsune API"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves questions from older to newer updated starting offset", "response": "def get_questions(self, offset=None):\n        \"\"\"Retrieve questions from older to newer updated starting offset\"\"\"\n\n        page = KitsuneClient.FIRST_PAGE\n\n        if offset:\n            page += int(offset / KitsuneClient.ITEMS_PER_PAGE)\n\n        while True:\n            api_questions_url = urijoin(self.base_url, '/question') + '/'\n\n            params = {\n                \"page\": page,\n                \"ordering\": \"updated\"\n            }\n\n            questions = self.fetch(api_questions_url, params)\n            yield questions\n\n            questions_json = json.loads(questions)\n            next_uri = questions_json['next']\n            if not next_uri:\n                break\n            page += 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_question_answers(self, question_id):\n\n        page = KitsuneClient.FIRST_PAGE\n\n        while True:\n            api_answers_url = urijoin(self.base_url, '/answer') + '/'\n            params = {\n                \"page\": page,\n                \"question\": question_id,\n                \"ordering\": \"updated\"\n            }\n\n            answers_raw = self.fetch(api_answers_url, params)\n            yield answers_raw\n\n            answers = json.loads(answers_raw)\n            if not answers['next']:\n                break\n            page += 1", "response": "Retrieve all answers for a question from older to newer ( updated )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfetches the textual content associated to the Response object", "response": "def fetch(self, url, params):\n        \"\"\"Return the textual content associated to the Response object\"\"\"\n\n        logger.debug(\"Kitsune client calls API: %s params: %s\",\n                     url, str(params))\n\n        response = super().fetch(url, payload=params)\n\n        return response.text"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch items from the ReMo url.", "response": "def fetch(self, category=CATEGORY_EVENT, offset=REMO_DEFAULT_OFFSET):\n        \"\"\"Fetch items from the ReMo url.\n\n        The method retrieves, from a ReMo URL, the set of items\n        of the given `category`.\n\n        :param category: the category of items to fetch\n        :param offset: obtain items after offset\n        :returns: a generator of items\n        \"\"\"\n        if not offset:\n            offset = REMO_DEFAULT_OFFSET\n\n        kwargs = {\"offset\": offset}\n        items = super().fetch(category, **kwargs)\n\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches items from the backend and yield them as a generator of items", "response": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch items\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        offset = kwargs['offset']\n\n        logger.info(\"Looking for events at url '%s' of %s category and %i offset\",\n                    self.url, category, offset)\n\n        nitems = 0  # number of items processed\n        titems = 0  # number of items from API data\n\n        # Always get complete pages so the first item is always\n        # the first one in the page\n        page = int(offset / ReMoClient.ITEMS_PER_PAGE)\n        page_offset = page * ReMoClient.ITEMS_PER_PAGE\n        # drop items from page before the offset\n        drop_items = offset - page_offset\n        logger.debug(\"%i items dropped to get %i offset starting in page %i (%i page offset)\",\n                     drop_items, offset, page, page_offset)\n        current_offset = offset\n\n        for raw_items in self.client.get_items(category, offset):\n            items_data = json.loads(raw_items)\n            titems = items_data['count']\n            logger.info(\"Pending items to retrieve: %i, %i current offset\",\n                        titems - current_offset, current_offset)\n            items = items_data['results']\n            for item in items:\n                if drop_items > 0:\n                    # Remove extra items due to page base retrieval\n                    drop_items -= 1\n                    continue\n                raw_item_details = self.client.fetch(item['_url'])\n                item_details = json.loads(raw_item_details)\n                item_details['offset'] = current_offset\n                current_offset += 1\n                yield item_details\n                nitems += 1\n\n        logger.info(\"Total number of events: %i (%i total, %i offset)\", nitems, titems, offset)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef metadata_updated_on(item):\n        if 'end' in item:\n            # events updated field\n            updated = item['end']\n        elif 'date_joined_program' in item:\n            # users updated field that always appear\n            updated = item['date_joined_program']\n        elif 'report_date' in item:\n            # activities updated field\n            updated = item['report_date']\n        else:\n            raise ValueError(\"Can't find updated field for item \" + str(item))\n\n        return float(str_to_datetime(updated).timestamp())", "response": "Extracts the update time from a ReMo item."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract the category from a ReMo item.", "response": "def metadata_category(item):\n        \"\"\"Extracts the category from a ReMo item.\n\n        This backend generates items types 'event', 'activity'\n        or 'user'. To guess the type of item, the code will look\n        for unique fields.\n        \"\"\"\n        if 'estimated_attendance' in item:\n            category = CATEGORY_EVENT\n        elif 'activity' in item:\n            category = CATEGORY_ACTIVITY\n        elif 'first_name' in item:\n            category = CATEGORY_USER\n        else:\n            raise TypeError(\"Could not define the category of item \" + str(item))\n\n        return category"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves all items for a given category", "response": "def get_items(self, category=CATEGORY_EVENT, offset=REMO_DEFAULT_OFFSET):\n        \"\"\"Retrieve all items for category using pagination \"\"\"\n\n        more = True  # There are more items to be processed\n        next_uri = None  # URI for the next items page query\n        page = ReMoClient.FIRST_PAGE\n        page += int(offset / ReMoClient.ITEMS_PER_PAGE)\n\n        if category == CATEGORY_EVENT:\n            api = self.api_events_url\n        elif category == CATEGORY_ACTIVITY:\n            api = self.api_activities_url\n        elif category == CATEGORY_USER:\n            api = self.api_users_url\n        else:\n            raise ValueError(category + ' not supported in ReMo')\n\n        while more:\n            params = {\n                \"page\": page,\n                \"orderby\": \"ASC\"\n            }\n\n            logger.debug(\"ReMo client calls APIv2: %s params: %s\",\n                         api, str(params))\n\n            raw_items = self.fetch(api, payload=params)\n            yield raw_items\n\n            items_data = json.loads(raw_items)\n            next_uri = items_data['next']\n\n            if not next_uri:\n                more = False\n            else:\n                # https://reps.mozilla.org/remo/api/remo/v1/events/?orderby=ASC&page=269\n                parsed_uri = urllib.parse.urlparse(next_uri)\n                parsed_params = urllib.parse.parse_qs(parsed_uri.query)\n                page = parsed_params['page'][0]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef io_priority(self):\n        return (\n            self._iocb.aio_reqprio\n            if self._iocb.u.c.flags & libaio.IOCB_FLAG_IOPRIO else\n            None\n        )", "response": "Return the IO priority of the current instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclose the AIO context and releases all pending IO blocks.", "response": "def close(self):\n        \"\"\"\n        Cancels all pending IO blocks.\n        Waits until all non-cancellable IO blocks finish.\n        De-initialises AIO context.\n        \"\"\"\n        if self._ctx is not None:\n            # Note: same as io_destroy\n            self._io_queue_release(self._ctx)\n            del self._ctx"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsubmits the blocks in block_list to the kernel.", "response": "def submit(self, block_list):\n        \"\"\"\n        Submits transfers.\n\n        block_list (list of AIOBlock)\n            The IO blocks to hand off to kernel.\n\n        Returns the number of successfully submitted blocks.\n        \"\"\"\n        # io_submit ioctl will only return an error for issues with the first\n        # transfer block. If there are issues with a later block, it will stop\n        # submission and return the number of submitted blocks. So it is safe\n        # to only update self._submitted once io_submit returned.\n        submitted_count = libaio.io_submit(\n            self._ctx,\n            len(block_list),\n            (libaio.iocb_p * len(block_list))(*[\n                # pylint: disable=protected-access\n                pointer(x._iocb)\n                # pylint: enable=protected-access\n                for x in block_list\n            ]),\n        )\n        submitted = self._submitted\n        for block in block_list[:submitted_count]:\n            # pylint: disable=protected-access\n            submitted[addressof(block._iocb)] = (block, block._getSubmissionState())\n            # pylint: enable=protected-access\n        return submitted_count"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cancel(self, block):\n        event = libaio.io_event()\n        try:\n            # pylint: disable=protected-access\n            libaio.io_cancel(self._ctx, byref(block._iocb), byref(event))\n            # pylint: enable=protected-access\n        except OSError as exc:\n            if exc.errno == errno.EINPROGRESS:\n                return None\n            raise\n        return self._eventToPython(event)", "response": "Cancels an IO block."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cancelAll(self):\n        cancel = self.cancel\n        result = []\n        for block, _ in self._submitted.itervalues():\n            try:\n                result.append(cancel(block))\n            except OSError as exc:\n                # EINVAL should mean we requested to cancel a not-in-flight\n                # transfer - maybe it was just completed and we just did\n                # not process its completion event yet.\n                if exc.errno != errno.EINVAL:\n                    raise\n        return result", "response": "Cancel all submitted IO blocks and return a list of all cancellations."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getEvents(self, min_nr=1, nr=None, timeout=None):\n        if min_nr is None:\n            min_nr = len(self._submitted)\n        if nr is None:\n            nr = max(len(self._submitted), self._maxevents)\n        if timeout is None:\n            timeoutp = None\n        else:\n            sec = int(timeout)\n            timeout = libaio.timespec(sec, int((timeout - sec) * 1e9))\n            timeoutp = byref(timeout)\n        event_buffer = (libaio.io_event * nr)()\n        actual_nr = libaio.io_getevents(\n            self._ctx,\n            min_nr,\n            nr,\n            event_buffer,\n            timeoutp,\n        )\n        return [\n            self._eventToPython(event_buffer[x])\n            for x in xrange(actual_nr)\n        ]", "response": "Returns a list of event data from the AIOBlock s submitted IO blocks."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches events from the Mozilla Club URL.", "response": "def fetch(self, category=CATEGORY_EVENT):\n        \"\"\"Fetch events from the MozillaClub URL.\n\n        The method retrieves, from a MozillaClub URL, the\n        events. The data is a Google spreadsheet retrieved using\n        the feed API REST.\n\n        :param category: the category of items to fetch\n\n        :returns: a generator of events\n        \"\"\"\n        kwargs = {}\n        items = super().fetch(category, **kwargs)\n\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch items from the specified category", "response": "def fetch_items(self, category, **kwargs):\n        \"\"\"Fetch events\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items\n        \"\"\"\n        logger.info(\"Looking for events at url '%s'\", self.url)\n\n        nevents = 0  # number of events processed\n\n        raw_cells = self.client.get_cells()\n        parser = MozillaClubParser(raw_cells)\n\n        for event in parser.parse():\n            yield event\n            nevents += 1\n\n        logger.info(\"Total number of events: %i\", nevents)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_cells(self):\n\n        logger.info(\"Retrieving all cells spreadsheet data ...\")\n        logger.debug(\"MozillaClub client calls API: %s\", self.base_url)\n        raw_cells = self.fetch(self.base_url)\n\n        return raw_cells.text", "response": "Retrieve all cells from the spreadsheet."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse(self):\n\n        nevents_wrong = 0\n\n        feed_json = json.loads(self.feed)\n\n        if 'entry' not in feed_json['feed']:\n            return\n\n        self.cells = feed_json['feed']['entry']\n        self.ncell = 0\n\n        event_fields = self.__get_event_fields()\n\n        # Process all events reading the rows according to the event template\n        # The only way to detect the end of row is looking to the\n        # number of column. When the max number is reached (cell_cols) the next\n        # cell is from the next row.\n        while self.ncell < len(self.cells):\n            # Process the next row (event) getting all cols to build the event\n            event = self.__get_next_event(event_fields)\n\n            if event['Date of Event'] is None or event['Club Name'] is None:\n                logger.warning(\"Wrong event data: %s\", event)\n                nevents_wrong += 1\n                continue\n            yield event\n\n        logger.info(\"Total number of wrong events: %i\", nevents_wrong)", "response": "Parse the MozillaClub spreadsheet feed cells json."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __get_event_fields(self):\n\n        event_fields = {}\n        # The cells in the first row are the column names\n        # Check that the columns names are the same we have as template\n        # Create the event template from the data retrieved\n        while self.ncell < len(self.cells):\n            cell = self.cells[self.ncell]\n            row = cell['gs$cell']['row']\n            if int(row) > 1:\n                # When the row number >1 the column row is finished\n                break\n            ncol = int(cell['gs$cell']['col'])\n            name = cell['content']['$t']\n            event_fields[ncol] = name\n            if ncol in EVENT_TEMPLATE:\n                if event_fields[ncol] != EVENT_TEMPLATE[ncol]:\n                    logger.warning(\"Event template changed in spreadsheet %s vs %s\",\n                                   name, EVENT_TEMPLATE[ncol])\n            else:\n                logger.warning(\"Event template changed in spreadsheet. New column: %s\", name)\n\n            self.ncell += 1\n        return event_fields", "response": "Get the events fields from the cells received."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns data files in directory dirname", "response": "def get_data_files(dirname):\n    \"\"\"Return data files in directory *dirname*\"\"\"\n    flist = []\n    for dirpath, _dirnames, filenames in os.walk(dirname):\n        for fname in filenames:\n            flist.append(osp.join(dirpath, fname))\n    return flist"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef md5(file_path):\r\n\r\n    hasher = hashlib.md5()\r\n    with open(file_path, 'rb') as f:\r\n        while True:\r\n            buf = f.read(BLOCKSIZE)\r\n            if not buf:\r\n                break\r\n            while len(buf) > 0:\r\n                hasher.update(buf)\r\n                buf = f.read(BLOCKSIZE)\r\n    md5_hash = hasher.hexdigest().upper()\r\n    return md5_hash", "response": "Calculates the md5 - hash of the file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef size(full_path):\r\n\r\n    file_size = os.path.getsize(full_path)\r\n    str_file_size = str(file_size)\r\n    print(str_file_size, 'b')\r\n\r\n    # Show size in b, kb, mb or gb depending on the dimension\r\n    if len(str_file_size) >= 10:\r\n        print('{0:.2f}'.format(file_size / 1073741824), 'gb')\r\n    elif len(str_file_size) >= 7:\r\n        print('{0:.2f}'.format(file_size / 1048576), 'mb')\r\n    elif len(str_file_size) >= 4:\r\n        print('{0:.2f}'.format(file_size / 1024), 'kb')", "response": "Shows the size of the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the md5 of the files in the specified directory.", "response": "def calculate(directory):\r\n    \"\"\"Split the tuple (obtained from scan) to separate files.\r\n       Alternately send full paths to the files in md5 and call it.\r\n       :param directory: tuple of files in the directory.\"\"\"\r\n\r\n    # Set correct slashes for the OS\r\n    if sys.platform == 'windows':\r\n        slash = '\\\\'\r\n    elif sys.platform == 'linux':\r\n        slash = '/'\r\n    else:\r\n        print('#Error. Unknown platform.')\r\n        return\r\n\r\n    print('Files in the current directory and their md5-hashes:\\n')\r\n\r\n    for i in range(len(directory[2])):  # Go through the list of files\r\n        full_path = directory[0]+slash+directory[2][i]\r\n        print(full_path)  # Get the list of files with full paths\r\n        size(full_path)\r\n        print(md5(full_path))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scan(tree):\r\n\r\n    tree = os.path.normpath(tree)\r\n    assert os.path.exists(tree), \"#Error. The path '{}' is\" \\\r\n                                 \" invalid or doesn't exist.\".format(str(tree))\r\n\r\n    if os.path.isfile(tree):\r\n        return md5(tree)\r\n    elif os.path.isdir(tree):\r\n        tree = os.walk(tree)\r\n        for directory in tree:\r\n            print('...................')\r\n            print('Current directory:')\r\n            print(directory[0])  # Current directory\r\n            if not directory[2]:  # Empty directory check\r\n                print('An empty directory.')\r\n                continue\r\n            else:\r\n                print('List of the files in the current directory:')\r\n                print(directory[2])  # Files in the current directory\r\n                print()\r\n            calculate(directory)", "response": "Scan the directory and send the obtained tuple to calculate."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist of export formats.", "response": "def export_formats(self, pid_type):\n        \"\"\"List of export formats.\"\"\"\n        if pid_type not in self._export_formats:\n            fmts = self.app.config.get('RECORDS_UI_EXPORT_FORMATS', {}).get(\n                pid_type, {})\n            self._export_formats[pid_type] = sorted(\n                [(k, v) for k, v in fmts.items() if v],\n                key=lambda x: x[1]['order'],\n            )\n        return self._export_formats[pid_type]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads default permission factory.", "response": "def permission_factory(self):\n        \"\"\"Load default permission factory.\"\"\"\n        if self._permission_factory is None:\n            imp = self.app.config['RECORDS_UI_DEFAULT_PERMISSION_FACTORY']\n            self._permission_factory = obj_or_import_string(imp)\n        return self._permission_factory"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nflasks application initialization. :param app: The Flask application.", "response": "def init_app(self, app):\n        \"\"\"Flask application initialization.\n\n        :param app: The Flask application.\n        \"\"\"\n        self.init_config(app)\n        app.extensions['invenio-records-ui'] = _RecordUIState(app)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating Invenio - Records - UI blueprint.", "response": "def create_blueprint(endpoints):\n    \"\"\"Create Invenio-Records-UI blueprint.\n\n    The factory installs one URL route per endpoint defined, and adds an\n    error handler for rendering tombstones.\n\n    :param endpoints: Dictionary of endpoints to be installed. See usage\n        documentation for further details.\n    :returns: The initialized blueprint.\n    \"\"\"\n    blueprint = Blueprint(\n        'invenio_records_ui',\n        __name__,\n        url_prefix='',\n        template_folder='templates',\n        static_folder='static',\n    )\n\n    @blueprint.errorhandler(PIDDeletedError)\n    def tombstone_errorhandler(error):\n        return render_template(\n            current_app.config['RECORDS_UI_TOMBSTONE_TEMPLATE'],\n            pid=error.pid,\n            record=error.record or {},\n        ), 410\n\n    @blueprint.context_processor\n    def inject_export_formats():\n        return dict(\n            export_formats=(\n                current_app.extensions['invenio-records-ui'].export_formats)\n            )\n\n    for endpoint, options in (endpoints or {}).items():\n        blueprint.add_url_rule(**create_url_rule(endpoint, **options))\n\n    return blueprint"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a Werkzeug URL rule for a specific endpoint.", "response": "def create_url_rule(endpoint, route=None, pid_type=None, template=None,\n                    permission_factory_imp=None, view_imp=None,\n                    record_class=None, methods=None):\n    \"\"\"Create Werkzeug URL rule for a specific endpoint.\n\n    The method takes care of creating a persistent identifier resolver\n    for the given persistent identifier type.\n\n    :param endpoint: Name of endpoint.\n    :param route: URL route (must include ``<pid_value>`` pattern). Required.\n    :param pid_type: Persistent identifier type for endpoint. Required.\n    :param template: Template to render.\n        (Default: ``invenio_records_ui/detail.html``)\n    :param permission_factory_imp: Import path to factory that creates a\n        permission object for a given record.\n    :param view_imp: Import path to view function. (Default: ``None``)\n    :param record_class: Name of the record API class.\n    :param methods: Method allowed for the endpoint.\n    :returns: A dictionary that can be passed as keywords arguments to\n        ``Blueprint.add_url_rule``.\n    \"\"\"\n    assert route\n    assert pid_type\n\n    permission_factory = import_string(permission_factory_imp) if \\\n        permission_factory_imp else None\n    view_method = import_string(view_imp) if view_imp else default_view_method\n    record_class = import_string(record_class) if record_class else Record\n    methods = methods or ['GET']\n\n    view_func = partial(\n        record_view,\n        resolver=Resolver(pid_type=pid_type, object_type='rec',\n                          getter=record_class.get_record),\n        template=template or 'invenio_records_ui/detail.html',\n        permission_factory=permission_factory,\n        view_method=view_method)\n    # Make view well-behaved for Flask-DebugToolbar\n    view_func.__module__ = record_view.__module__\n    view_func.__name__ = record_view.__name__\n\n    return dict(\n        endpoint=endpoint,\n        rule=route,\n        view_func=view_func,\n        methods=methods,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisplaying record view. The two parameters ``resolver`` and ``template`` should not be included in the URL rule, but instead set by creating a partially evaluated function of the view. The template being rendered is passed two variables in the template context: - ``pid`` - ``record``. Procedure followed: #. PID and record are resolved. #. Permission are checked. #. ``view_method`` is called. :param pid_value: Persistent identifier value. :param resolver: An instance of a persistent identifier resolver. A persistent identifier resolver takes care of resolving persistent identifiers into internal objects. :param template: Template to render. :param permission_factory: Permission factory called to check if user has enough power to execute the action. :param view_method: Function that is called. :returns: Tuple (pid object, record object).", "response": "def record_view(pid_value=None, resolver=None, template=None,\n                permission_factory=None, view_method=None, **kwargs):\n    \"\"\"Display record view.\n\n    The two parameters ``resolver`` and ``template`` should not be included\n    in the URL rule, but instead set by creating a partially evaluated function\n    of the view.\n\n    The template being rendered is passed two variables in the template\n    context:\n\n    - ``pid``\n    - ``record``.\n\n    Procedure followed:\n\n    #. PID and record are resolved.\n\n    #. Permission are checked.\n\n    #. ``view_method`` is called.\n\n    :param pid_value: Persistent identifier value.\n    :param resolver: An instance of a persistent identifier resolver. A\n        persistent identifier resolver takes care of resolving persistent\n        identifiers into internal objects.\n    :param template: Template to render.\n    :param permission_factory: Permission factory called to check if user has\n        enough power to execute the action.\n    :param view_method: Function that is called.\n    :returns: Tuple (pid object, record object).\n    \"\"\"\n    try:\n        pid, record = resolver.resolve(pid_value)\n    except (PIDDoesNotExistError, PIDUnregistered):\n        abort(404)\n    except PIDMissingObjectError as e:\n        current_app.logger.exception(\n            \"No object assigned to {0}.\".format(e.pid),\n            extra={'pid': e.pid})\n        abort(500)\n    except PIDRedirectedError as e:\n        try:\n            return redirect(url_for(\n                '.{0}'.format(e.destination_pid.pid_type),\n                pid_value=e.destination_pid.pid_value))\n        except BuildError:\n            current_app.logger.exception(\n                \"Invalid redirect - pid_type '{0}' endpoint missing.\".format(\n                    e.destination_pid.pid_type),\n                extra={\n                    'pid': e.pid,\n                    'destination_pid': e.destination_pid,\n                })\n            abort(500)\n\n    # Check permissions\n    permission_factory = permission_factory or current_permission_factory\n    if permission_factory:\n        # Note, cannot be done in one line due to overloading of boolean\n        # operations in permission object.\n        if not permission_factory(record).can():\n            from flask_login import current_user\n            if not current_user.is_authenticated:\n                return redirect(url_for(\n                    current_app.config['RECORDS_UI_LOGIN_ENDPOINT'],\n                    next=request.url))\n            abort(403)\n\n    return view_method(pid, record, template=template, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef default_view_method(pid, record, template=None, **kwargs):\n    record_viewed.send(\n        current_app._get_current_object(),\n        pid=pid,\n        record=record,\n    )\n    return render_template(\n        template,\n        pid=pid,\n        record=record,\n    )", "response": "r Display default view."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef export(pid, record, template=None, **kwargs):\n    formats = current_app.config.get('RECORDS_UI_EXPORT_FORMATS', {}).get(\n        pid.pid_type)\n    fmt = formats.get(request.view_args.get('format'))\n\n    if fmt is False:\n        # If value is set to False, it means it was deprecated.\n        abort(410)\n    elif fmt is None:\n        abort(404)\n    else:\n        serializer = obj_or_import_string(fmt['serializer'])\n        data = serializer.serialize(pid, record)\n        if isinstance(data, six.binary_type):\n            data = data.decode('utf8')\n\n        return render_template(\n            template, pid=pid, record=record, data=data,\n            format_title=fmt['title'],\n        )", "response": "r Serializes record with given format and renders record export template."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads test data fixture.", "response": "def records():\n    \"\"\"Load test data fixture.\"\"\"\n    import uuid\n    from invenio_records.api import Record\n    from invenio_pidstore.models import PersistentIdentifier, PIDStatus\n\n    # Record 1 - Live record\n    with db.session.begin_nested():\n        pid1 = PersistentIdentifier.create(\n            'recid', '1', object_type='rec', object_uuid=rec1_uuid,\n            status=PIDStatus.REGISTERED)\n        Record.create({\n            'title': 'Registered ',\n            'authors': [\n                {'name': 'Ellis Jonathan'},\n                {'name': 'Higgs Peter'},\n            ],\n            'access': 'open',\n            'keywords': ['CERN', 'higgs'],\n        }, id_=rec1_uuid)\n\n        PersistentIdentifier.create(\n            'recid', '2', object_type='rec', object_uuid=rec2_uuid,\n            status=PIDStatus.REGISTERED)\n        Record.create({\n            'title': 'Registered ',\n            'authors': [\n                {'name': 'Ellis Jonathan'},\n                {'name': 'Higgs Peter'},\n            ],\n            'access': 'closed',\n            'keywords': ['CERN', 'higgs'],\n        }, id_=rec2_uuid)\n\n        # Record 3 - Deleted PID with record\n        rec3_uuid = uuid.uuid4()\n        pid = PersistentIdentifier.create(\n            'recid', '3', object_type='rec', object_uuid=rec3_uuid,\n            status=PIDStatus.REGISTERED)\n        pid.delete()\n        Record.create({'title': 'Live '}, id_=rec3_uuid)\n\n        # Record 4 - Deleted PID without a record\n        PersistentIdentifier.create(\n            'recid', '4', status=PIDStatus.DELETED)\n\n        # Record 5 - Registered PID without a record\n        PersistentIdentifier.create(\n            'recid', '5', status=PIDStatus.REGISTERED)\n\n        # Record 6 - Redirected PID\n        pid = PersistentIdentifier.create(\n            'recid', '6', status=PIDStatus.REGISTERED)\n        pid.redirect(pid1)\n\n        # Record 7 - Redirected non existing endpoint\n        doi = PersistentIdentifier.create(\n            'doi', '10.1234/foo', status=PIDStatus.REGISTERED)\n        pid = PersistentIdentifier.create(\n            'recid', '7', status=PIDStatus.REGISTERED)\n        pid.redirect(doi)\n\n        # Record 8 - Unregistered PID\n        PersistentIdentifier.create(\n            'recid', '8', status=PIDStatus.RESERVED)\n\n    db.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef time_callable(self, name, target, rate=None, args=(), kwargs={}):\n        # type: (str, Callable, float, Tuple, Dict) -> Chronometer\n        \"\"\"Send a Timer metric calculating duration of execution of the provided callable\"\"\"\n        assert callable(target)\n        if rate is None:\n            rate = self._rate\n        else:\n            assert_sample_rate(rate)\n        start_time = time()  # type: float\n        result = target(*args, **kwargs)\n        self.since(name, start_time, rate)\n        return result", "response": "Send a Timer metric calculating the duration of execution of the provided callable"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close(self):\n        # type: () -> None\n        \"\"\"Close the socket to free system resources.\n\n        After the socket is closed, further operations with socket\n        will fail. Multiple calls to close will have no effect.\n        \"\"\"\n\n        if self._closed:\n            return\n        self._socket.close()\n        self._closed = True", "response": "Close the socket to free system resources."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_client(self, client):\n        # type: (object) -> None\n        \"\"\"Remove the client from the users of the socket.\n\n        If there are no more clients for the socket, it\n        will close automatically.\n        \"\"\"\n\n        try:\n            self._clients.remove(id(client))\n        except ValueError:\n            pass\n\n        if len(self._clients) < 1:\n            self.close()", "response": "Removes the client from the users of the socket."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nincrement a Counter metric", "response": "def increment(self, name, count=1, rate=1):\n        # type: (str, int, float) -> None\n        \"\"\"Increment a Counter metric\"\"\"\n\n        if self._should_send_metric(name, rate):\n            self._request(\n                Counter(\n                    self._create_metric_name_for_request(name),\n                    int(count),\n                    rate\n                ).to_request()\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a Timer metric with the specified duration in milliseconds", "response": "def timing(self, name, milliseconds, rate=1):\n        # type: (str, float, float) -> None\n        \"\"\"Send a Timer metric with the specified duration in milliseconds\"\"\"\n\n        if self._should_send_metric(name, rate):\n            milliseconds = int(milliseconds)\n            self._request(\n                Timer(\n                    self._create_metric_name_for_request(name),\n                    milliseconds,\n                    rate\n                ).to_request()\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef timing_since(self, name, start_time, rate=1):\n        # type: (str, Union[float, datetime], float) -> None\n        \"\"\"Send a Timer metric calculating the duration from the start time\"\"\"\n        duration = 0  # type: float\n        if isinstance(start_time, datetime):\n            duration = (datetime.now(start_time.tzinfo) - start_time).total_seconds() * 1000\n        elif is_numeric(start_time):\n            assert start_time > 0\n            duration = (time() - start_time) * 1000\n        else:\n            raise ValueError(\"start time should be a timestamp or a datetime\")\n        self.timing(name, duration, rate)", "response": "Send a Timer metric calculating the duration from the start time"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a Gauge metric with the specified value", "response": "def gauge(self, name, value, rate=1):\n        # type: (str, float, float) -> None\n        \"\"\"Send a Gauge metric with the specified value\"\"\"\n\n        if self._should_send_metric(name, rate):\n            if not is_numeric(value):\n                value = float(value)\n            self._request(\n                Gauge(\n                    self._create_metric_name_for_request(name),\n                    value,\n                    rate\n                ).to_request()\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gauge_delta(self, name, delta, rate=1):\n        # type: (str, float, float) -> None\n        \"\"\"Send a GaugeDelta metric to change a Gauge by the specified value\"\"\"\n\n        if self._should_send_metric(name, rate):\n            if not is_numeric(delta):\n                delta = float(delta)\n            self._request(\n                GaugeDelta(\n                    self._create_metric_name_for_request(name),\n                    delta,\n                    rate\n                ).to_request()\n            )", "response": "Send a GaugeDelta metric to change a Gauge by the specified value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set(self, name, value, rate=1):\n        # type: (str, str, float) -> None\n        \"\"\"Send a Set metric with the specified unique value\"\"\"\n\n        if self._should_send_metric(name, rate):\n            value = str(value)\n            self._request(\n                Set(\n                    self._create_metric_name_for_request(name),\n                    value,\n                    rate\n                ).to_request()\n            )", "response": "Send a Set metric with the specified unique value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _request(self, data):\n        # type: (str) -> None\n        \"\"\"Override parent by buffering the metric instead of sending now\"\"\"\n\n        data = bytearray(\"{}\\n\".format(data).encode())\n        self._prepare_batches_for_storage(len(data))\n        self._batches[-1].extend(data)", "response": "Override the parent by buffering the metric instead of sending now"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a batch client with same settings of the client", "response": "def batch_client(self, size=512):\n        # type: (int) -> BatchClient\n        \"\"\"Return a batch client with same settings of the client\"\"\"\n\n        batch_client = BatchClient(self.host, self.port, self.prefix, size)\n        self._configure_client(batch_client)\n        return batch_client"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a client with same settings of the batch client", "response": "def unit_client(self):\n        # type: () -> Client\n        \"\"\"Return a client with same settings of the batch client\"\"\"\n\n        client = Client(self.host, self.port, self.prefix)\n        self._configure_client(client)\n        return client"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend buffered metrics in batch requests", "response": "def flush(self):\n        # type: () -> BatchClient\n        \"\"\"Send buffered metrics in batch requests\"\"\"\n\n        address = self.remote_address\n        while len(self._batches) > 0:\n            self._socket.sendto(self._batches[0], address)\n            self._batches.popleft()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef batch_client(self, size=512):\n        # type: (int) -> TCPBatchClient\n        \"\"\"Return a TCP batch client with same settings of the TCP client\"\"\"\n\n        batch_client = TCPBatchClient(self.host, self.port, self.prefix, size)\n        self._configure_client(batch_client)\n        return batch_client", "response": "Returns a TCP batch client with same settings of the TCP client"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef flush(self):\n        # type: () -> TCPBatchClient\n        while len(self._batches) > 0:\n            self._socket.sendall(self._batches[0])\n            self._batches.popleft()\n        return self", "response": "Send buffered metrics in batch requests over TCP"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new TCPClient with same settings of the batch TCP client", "response": "def unit_client(self):\n        # type: () -> TCPClient\n        \"\"\"Return a TCPClient with same settings of the batch TCP client\"\"\"\n\n        client = TCPClient(self.host, self.port, self.prefix)\n        self._configure_client(client)\n        return client"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef weighted_choice(choices):\r\n    total = sum([weight for (weight, _) in choices])\r\n    i = random.randint(0, total - 1)\r\n    for weight, choice in choices:\r\n        i -= weight\r\n        if i < 0: \r\n            if callable(choice):\r\n                return choice()\r\n            return choice\r\n    raise Exception('Bug')", "response": "Returns a weighted version of choice that is a list of two elements items."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn random float with min_value and max_value", "response": "def any_float(min_value=0, max_value=100, precision=2):\r\n    \"\"\"\r\n    Returns random float\r\n    \r\n    >>> result = any_float(min_value=0, max_value=100, precision=2)\r\n    >>> type(result)\r\n    <type 'float'>\r\n    >>> result >=0 and result <= 100\r\n    True\r\n\r\n    \"\"\"\r\n    return round(random.uniform(min_value, max_value), precision)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a random string with any of the given letters.", "response": "def any_string(letters = ascii_letters, min_length=3, max_length=100):\r\n    \"\"\"\r\n    Return string with random content\r\n\r\n    >>> result = any_string(letters = ascii_letters, min_length=3, max_length=100)\r\n    >>> type(result)\r\n    <type 'str'>\r\n    >>> len(result) in range(3,101)\r\n    True\r\n    >>> any([c in ascii_letters for c in result])\r\n    True\r\n    \"\"\"\r\n    \r\n    length = random.randint(min_length, max_length)\r\n    letters = [any_letter(letters=letters) for _ in range(0, length)]\r\n    return \"\".join(letters)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef any_date(from_date=date(1990, 1, 1), to_date=date.today()):\r\n    days = any_int(min_value=0, max_value=(to_date - from_date).days)\r\n\r\n    return from_date + timedelta(days=days)", "response": "Returns a random date from the [ from_date to_date )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef any_datetime(from_date=datetime(1990, 1, 1), to_date=datetime.now()):\r\n    days = any_int(min_value=0, max_value=(to_date - from_date).days-1)\r\n    time = timedelta(seconds=any_int(min_value=0, max_value=24*3600-1))\r\n\r\n    return from_date + timedelta(days=days) + time", "response": "Returns a random datetime from the [ from_date to_date )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn random decimal from the [ min_value max_value ) interval", "response": "def any_decimal(min_value=Decimal(0), max_value=Decimal('99.99'), decimal_places=2):\r\n    \"\"\"\r\n    Return random decimal from the [min_value, max_value] interval\r\n\r\n    >>> result = any_decimal(min_value=0.999, max_value=3, decimal_places=3)\r\n    >>> type(result)\r\n    <class 'decimal.Decimal'>\r\n    >>> result >= Decimal('0.999') and result <= Decimal(3)\r\n    True\r\n    \"\"\"\r\n    return Decimal(str(any_float(min_value=float(min_value),\r\n                                 max_value=float(max_value),\r\n                                 precision=decimal_places)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef any_user(password=None, permissions=[], groups=[], **kwargs):\n\n    is_active = kwargs.pop('is_active', True)\n    is_superuser = kwargs.pop('is_superuser', False)\n    is_staff = kwargs.pop('is_staff', False)\n\n    user = any_model(User, is_active = is_active, is_superuser = is_superuser,\n                     is_staff = is_staff, **kwargs)\n\n    for group_name in groups :\n        group = Group.objects.get(name=group_name)\n        user.groups.add(group)\n\n    for permission_name in permissions:\n        app_label, codename = permission_name.split('.')\n        permission = Permission.objects.get(\n            content_type__app_label=app_label,\n            codename=codename)\n        user.user_permissions.add(permission)\n\n    if password:\n        user.set_password(password)\n    \n    user.save()\n    return user", "response": "Create a User object with the specified password and permissions and groups."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef interpretAsOpenMath(x):\n    \n    if hasattr(x, \"_ishelper\") and x._ishelper:\n        # wrapped things in this class -> unwrap\n        return x._toOM()\n    \n    elif isinstance(x, om.OMAny):\n        # already OM\n        return x\n    \n    elif isinstance(x, six.integer_types):\n        # integers -> OMI\n        return om.OMInteger(x)\n    \n    elif isinstance(x, float):\n        # floats -> OMF\n        return om.OMFloat(x)\n\n    elif isinstance(x, six.string_types):\n        # strings -> OMSTR\n        return om.OMString(x)\n    \n    elif isinstance(x, WrappedHelper):\n        # wrapper -> wrapped object\n        return x.toOM()\n    \n    elif inspect.isfunction(x):\n        # function -> OMBIND(lambda,...)\n        \n        # get all the parameters of the function\n        paramMap = inspect.signature(x).parameters\n        params = [v for k, v in six.iteritems(paramMap)]\n        \n        # make sure that all of them are positional\n        posArgKinds = [inspect.Parameter.POSITIONAL_ONLY, inspect.Parameter.POSITIONAL_OR_KEYWORD]\n        if not all([p.kind in posArgKinds for p in params]):\n            raise CannotInterpretAsOpenMath(\"no sequence arguments allowed\")\n        \n        # call the function with appropriate OMVariables\n        paramsOM = [om.OMVariable(name=p.name) for p in params]\n        bodyOM = interpretAsOpenMath(x(*paramsOM))\n\n        return OMBinding(om.OMSymbol(name=\"lambda\", cd=\"python\", cdbase=\"http://python.org\"), paramsOM, bodyOM)\n    \n    else:\n        # fail\n        raise CannotInterpretAsOpenMath(\"unknown kind of object: \" + str(x))", "response": "tries to interpret a Python object into an OpenMath object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convertAsOpenMath(term, converter):\n    \n    # if we already have openmath, or have some of our magic helpers, use interpretAsOpenMath\n    if hasattr(term, \"_ishelper\") and term._ishelper or isinstance(term, om.OMAny):\n        return interpretAsOpenMath(term)\n        \n    # next try to convert using the converter\n    if converter is not None:\n        try:\n            _converted = converter.to_openmath(term)\n        except Exception as e:\n            _converted = None\n        \n        if isinstance(_converted, om.OMAny):\n            return _converted\n    \n    # fallback to the openmath helper\n    return interpretAsOpenMath(term)", "response": "Converts a term into OpenMath using either a converter or the interpretAsOpenMath method"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_python(self, omobj):\n        # general overrides\n        if omobj.__class__ in self._omclass_to_py:\n            return self._omclass_to_py[omobj.__class__](omobj)\n        # oms\n        elif isinstance(omobj, om.OMSymbol):\n            return self._lookup_to_python(omobj.cdbase, omobj.cd, omobj.name)\n        # oma\n        elif isinstance(omobj, om.OMApplication):\n            elem = self.to_python(omobj.elem)\n            arguments = [self.to_python(x) for x in omobj.arguments]\n            return elem(*arguments)\n        raise ValueError('Cannot convert object of class %s to Python.' % omobj.__class__.__name__)", "response": "Convert OpenMath object to Python object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_openmath(self, obj):\n        for cl, conv in reversed(self._conv_to_om):\n            if cl is None or isinstance(obj, cl):\n                try:\n                    return conv(obj)\n                except CannotConvertError:\n                    continue\n\n        if hasattr(obj, '__openmath__'):\n            return obj.__openmath__()\n\n        raise ValueError('Cannot convert %r to OpenMath.' % obj)", "response": "Convert a Python object to OpenMath."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_to_openmath(self, py_class, converter):\n        if py_class is not None and not isclass(py_class):\n            raise TypeError('Expected class, found %r' % py_class)\n        if not callable(converter) and not isinstance(converter, om.OMAny):\n            raise TypeError('Expected callable or openmath.OMAny object, found %r' % converter)\n        self._conv_to_om.append((py_class, converter))", "response": "Register a conversion from Python to OpenMath."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering a conversion from OpenMath to Python.", "response": "def _deprecated_register_to_python(self, cd, name, converter=None):\n        \"\"\"Register a conversion from OpenMath to Python\n\n        This function has two forms. A three-arguments one:\n\n        :param cd: A content dictionary name\n        :type cd: str\n\n        :param name: A symbol name\n        :type name: str\n\n        :param converter: A conversion function, or a Python object\n        :type: Callable, Any\n\n        Any object of type ``openmath.OMSymbol``, with content\n        dictionary equal to ``cd`` and name equal to ``name`` will be converted\n        using ``converter``. Also, any object of type ``openmath.OMApplication``\n        whose first child is an ``openmath.OMSymbol`` as above will be converted\n        using ``converter``. If ``converter`` is a callable, it will be called with the\n        OpenMath object as parameter; otherwise ``converter`` will be returned.\n\n        In the two-argument form\n\n        :param cd: A subclass of ``OMAny``\n        :type cd: type\n\n        :param name: A conversion function\n        :type name: Callable\n\n        Any object of type ``cd`` will be passed to ``name()``, and the\n        result will be returned. This forms is mainly to override default\n        conversions for basic OpenMath tags (OMInteger, OMString, etc.). It\n        is discouraged to use it for ``OMSymbol`` and ``OMApplication``.\n        \"\"\"\n        if converter is None:\n            if isclass(cd) and issubclass(cd, om.OMAny):\n                self._conv_to_py[cd] = name\n            else:\n                raise TypeError('Two-arguments form expects subclass of openmath.OMAny, found %r' % cd)\n        else:\n            if isinstance(cd, str) and isinstance(name, str):\n                self._conv_sym_to_py[(cd, name)] = converter\n            else:\n                raise TypeError('Three-arguments form expects string, found %r' % cd.__class__)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _deprecated_register(self, py_class, to_om, om_cd, om_name, to_py=None):\n        self.register_to_python(om_cd, om_name, to_py)\n        self.register_to_openmath(py_class, to_om)", "response": "This is a shorthand for:\n\n           ``self.register_to_python(om_cd, om_name, to_py)``\n           ``self.register_to_openmath(py_class, to_om)``"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_app(self, app):\n\n        app.config.setdefault('REDIS_URLS', {\n            'main': 'redis://localhost:6379/0',\n            'admin': 'redis://localhost:6379/1',\n        })\n\n        app.before_request(self.before_request)\n\n        self.app = app", "response": "Initialize the application object with the given app"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nyield the keys of the choices that are valid.", "response": "def valid_choices(choices):\n    \"\"\"\n    Return list of choices's keys\n    \"\"\"\n    for key, value in choices:\n        if isinstance(value, (list, tuple)):\n            for key, _ in value:\n                yield key\n        else:\n            yield key"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef split_model_kwargs(kw):\n    from collections import defaultdict\n    \n    model_fields = {}\n    fields_agrs = defaultdict(lambda : {})\n    \n    for key in kw.keys():\n        if '__' in key:\n            field, _, subfield = key.partition('__')\n            fields_agrs[field][subfield] = kw[key]\n        else:\n            model_fields[key] = kw[key]\n\n    return model_fields, fields_agrs", "response": "Split model keyword arguments into model fields and fields_agrs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register(self, field_type, impl=None):\n        def _wrapper(func):\n            self.registry[field_type] = func\n            return func\n\n        if impl:\n            return _wrapper(impl)\n        return _wrapper", "response": "Decorator to register a function to be used as a decorator for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a value from the registry.", "response": "def _create_value(self, *args, **kwargs):\n        \"\"\"\n        Lowest value generator.\n\n        Separated from __call__, because it seems that python\n        cache __call__ reference on module import\n        \"\"\"\n        if not len(args):\n            raise TypeError('Object instance is not provided')\n\n        if self.by_instance:\n            field_type = args[0]\n        else:\n            field_type = args[0].__class__\n\n        function = self.registry.get(field_type, self.default)\n\n        if function is None:\n            raise TypeError(\"no match %s\" % field_type)\n\n        return function(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef any_form_default(form_cls, **kwargs):\n    form_data = {}\n    form_files = {}\n\n    form_fields, fields_args = split_model_kwargs(kwargs)\n\n    for name, field in form_cls.base_fields.iteritems():\n        if name in form_fields:\n            form_data[name] = kwargs[name]\n        else:\n            form_data[name] = any_form_field(field, **fields_args[name])\n\n    return form_data, form_files", "response": "Returns tuple with form data and files for any form."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef field_required_attribute(function):\n    def _wrapper(field, **kwargs):\n        if not field.required and random.random < 0.1:\n            return None\n        return function(field, **kwargs)\n    return _wrapper", "response": "Decorator to check if a field is required by the user"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn random value for CharField", "response": "def char_field_data(field, **kwargs):\n    \"\"\"\n    Return random value for CharField\n    >>> result = any_form_field(forms.CharField(min_length=3, max_length=10))\n    >>> type(result)\n    <type 'str'>\n    \"\"\"\n    min_length = kwargs.get('min_length', 1)\n    max_length = kwargs.get('max_length', field.max_length or 255)    \n    return xunit.any_string(min_length=field.min_length or min_length, \n                            max_length=field.max_length or max_length)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn random value for DecimalField", "response": "def decimal_field_data(field, **kwargs):\n    \"\"\"\n    Return random value for DecimalField\n\n    >>> result = any_form_field(forms.DecimalField(max_value=100, min_value=11, max_digits=4, decimal_places = 2))\n    >>> type(result)\n    <type 'str'>\n    >>> from decimal import Decimal\n    >>> Decimal(result) >= 11, Decimal(result) <= Decimal('99.99')\n    (True, True)\n    \"\"\"\n    min_value = 0\n    max_value = 10\n    from django.core.validators import MinValueValidator, MaxValueValidator \n    for elem in field.validators:\n        if isinstance(elem, MinValueValidator):\n            min_value = elem.limit_value\n        if isinstance(elem, MaxValueValidator):\n            max_value = elem.limit_value\n    if (field.max_digits and field.decimal_places):\n        from decimal import Decimal\n        max_value = min(max_value,\n                        Decimal('%s.%s' % ('9'*(field.max_digits-field.decimal_places),\n                                           '9'*field.decimal_places)))\n\n    min_value = kwargs.get('min_value') or min_value\n    max_value = kwargs.get('max_value') or max_value\n\n    return str(xunit.any_decimal(min_value=min_value,\n                             max_value=max_value,\n                             decimal_places = field.decimal_places or 2))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn random value for EmailField", "response": "def email_field_data(field, **kwargs):\n    \"\"\"\n    Return random value for EmailField\n\n    >>> result = any_form_field(forms.EmailField(min_length=10, max_length=30))\n    >>> type(result)\n    <type 'str'>\n    >>> len(result) <= 30, len(result) >= 10\n    (True, True)\n    \"\"\"\n    max_length = 10\n    if field.max_length:\n        max_length = (field.max_length -5) / 2 \n    min_length = 10\n    if field.min_length:\n        min_length = (field.min_length-4) / 2\n    return \"%s@%s.%s\" % (\n        xunit.any_string(min_length=min_length, max_length=max_length),\n        xunit.any_string(min_length=min_length, max_length=max_length),\n        xunit.any_string(min_length=2, max_length=3))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef date_field_data(field, **kwargs):\n    from_date = kwargs.get('from_date', date(1990, 1, 1))\n    to_date = kwargs.get('to_date', date.today())\n    \n    date_format = random.choice(field.input_formats or formats.get_format('DATE_INPUT_FORMATS'))\n                                \n    return xunit.any_date(from_date=from_date, to_date=to_date).strftime(date_format)", "response": "Return random value for DateField"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef datetime_field_data(field, **kwargs):\n    from_date = kwargs.get('from_date', datetime(1990, 1, 1))\n    to_date = kwargs.get('to_date', datetime.today())\n    date_format = random.choice(field.input_formats or formats.get_format('DATETIME_INPUT_FORMATS'))\n    return xunit.any_datetime(from_date=from_date, to_date=to_date).strftime(date_format)", "response": "Return random value for DateTimeField"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn random value for a FloatField.", "response": "def float_field_data(field, **kwargs):\n    \"\"\"\n    Return random value for FloatField\n\n    >>> result = any_form_field(forms.FloatField(max_value=200, min_value=100))\n    >>> type(result)\n    <type 'str'>\n    >>> float(result) >=100, float(result) <=200\n    (True, True)\n    \"\"\"\n    min_value = 0\n    max_value = 100\n    from django.core.validators import MinValueValidator, MaxValueValidator\n    for elem in field.validators:\n        if isinstance(elem, MinValueValidator):\n            min_value = elem.limit_value\n        if isinstance(elem, MaxValueValidator):\n            max_value = elem.limit_value\n\n    min_value = kwargs.get('min_value', min_value)\n    max_value = kwargs.get('max_value', max_value)\n    precision = kwargs.get('precision', 3)\n\n    return str(xunit.any_float(min_value=min_value, max_value=max_value, precision=precision))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef integer_field_data(field, **kwargs):\n    min_value = 0\n    max_value = 100\n    from django.core.validators import MinValueValidator, MaxValueValidator \n    for elem in field.validators:\n        if isinstance(elem, MinValueValidator):\n            min_value = elem.limit_value\n        if isinstance(elem, MaxValueValidator):\n            max_value = elem.limit_value\n\n    min_value = kwargs.get('min_value', min_value)\n    max_value = kwargs.get('max_value', max_value)\n\n    return str(xunit.any_int(min_value=min_value, max_value=max_value))", "response": "Return random value for an integer field."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns random value for IPAddressField", "response": "def ipaddress_field_data(field, **kwargs):\n    \"\"\"\n    Return random value for IPAddressField\n    \n    >>> result = any_form_field(forms.IPAddressField())\n    >>> type(result)\n    <type 'str'>\n    >>> from django.core.validators import ipv4_re\n    >>> import re\n    >>> re.match(ipv4_re, result) is not None\n    True\n    \"\"\"\n    choices = kwargs.get('choices')\n    if choices:\n        return random.choice(choices)\n    else:\n        nums = [str(xunit.any_int(min_value=0, max_value=255)) for _ in xrange(0, 4)]\n        return \".\".join(nums)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef slug_field_data(field, **kwargs):\n    min_length = kwargs.get('min_length', 1)\n    max_length = kwargs.get('max_length', field.max_length or 20)    \n    \n    from string import ascii_letters, digits\n    letters = ascii_letters + digits + '_-' \n    return xunit.any_string(letters = letters, min_length = min_length, max_length = max_length)", "response": "Return random value for SlugField"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef time_field_data(field, **kwargs):\n    time_format = random.choice(field.input_formats or formats.get_format('TIME_INPUT_FORMATS'))\n\n    return time(xunit.any_int(min_value=0, max_value=23),\n                xunit.any_int(min_value=0, max_value=59),\n                xunit.any_int(min_value=0, max_value=59)).strftime(time_format)", "response": "Return random value for TimeField"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn random value for ChoiceField", "response": "def choice_field_data(field, **kwargs):\n    \"\"\"\n    Return random value for ChoiceField\n\n    >>> CHOICES = [('YNG', 'Child'), ('OLD', 'Parent')]\n    >>> result = any_form_field(forms.ChoiceField(choices=CHOICES))\n    >>> type(result)\n    <type 'str'>\n    >>> result in ['YNG', 'OLD']\n    True\n    >>> typed_result = any_form_field(forms.TypedChoiceField(choices=CHOICES))\n    >>> typed_result in ['YNG', 'OLD']\n    True\n    \"\"\"\n    if field.choices:\n        return str(random.choice(list(valid_choices(field.choices))))\n    return 'None'"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef multiple_choice_field_data(field, **kwargs):\n    if field.choices:\n        from django_any.functions import valid_choices \n        l = list(valid_choices(field.choices))\n        random.shuffle(l)\n        choices = []\n        count = xunit.any_int(min_value=1, max_value=len(field.choices))\n        for i in xrange(0, count):\n            choices.append(l[i])\n        return ' '.join(choices)\n    return 'None'", "response": "Return random value for MultipleChoiceField"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef model_choice_field_data(field, **kwargs):\n    data = list(field.queryset[:10])\n    if data:\n        return random.choice(data)\n    else:\n        raise TypeError('No %s available in queryset' % field.queryset.model)", "response": "Return one of first ten items for field queryset"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencodes an OpenMath object to an XML node.", "response": "def encode_xml(obj, E=None):\n    \"\"\" Encodes an OpenMath object as an XML node.\n\n    :param obj: OpenMath object (or related item) to encode as XML.\n    :type obj: OMAny\n\n    :param ns: Namespace prefix to use for\n        http://www.openmath.org/OpenMath\", or None if default namespace.\n    :type ns: str, None\n\n    :return: The XML node representing the OpenMath data structure.\n    :rtype: etree._Element\n    \"\"\"\n\n    if E is None:\n        E = default_E\n    elif isinstance(E, str):\n        E = ElementMaker(namespace=xml.openmath_ns,\n                         nsmap={ E: xml.openmath_ns })\n\n    name = \"\"\n    attr = {}\n    children = []\n\n    if isinstance(obj, om.CDBaseAttribute) and obj.cdbase is not None:\n        attr[\"cdbase\"] = obj.cdbase\n\n    if isinstance(obj, om.CommonAttributes) and obj.id is not None:\n        attr[\"id\"] = obj.id\n\n    # Wrapper object\n    if isinstance(obj, om.OMObject):\n        children.append(encode_xml(obj.omel, E))\n        attr[\"version\"] = obj.version\n\n    # Derived Objects\n    elif isinstance(obj, om.OMReference):\n        attr[\"href\"] = obj.href\n\n    # Basic Objects\n    elif isinstance(obj, om.OMInteger):\n        children.append(str(obj.integer))\n    elif isinstance(obj, om.OMFloat):\n        attr[\"dec\"] = obj.double\n    elif isinstance(obj, om.OMString):\n        if obj.string is not None:\n            children.append(str(obj.string))\n    elif isinstance(obj, om.OMBytes):\n        children.append(base64.b64encode(obj.bytes).decode('ascii'))\n    elif isinstance(obj, om.OMSymbol):\n        attr[\"name\"] = obj.name\n        attr[\"cd\"] = obj.cd\n    elif isinstance(obj, om.OMVariable):\n        attr[\"name\"] = obj.name\n\n    # Derived Elements\n    elif isinstance(obj, om.OMForeign):\n        attr[\"encoding\"] = obj.encoding\n        children.append(str(obj.obj))\n\n    # Compound Elements\n    elif isinstance(obj, om.OMApplication):\n        children = [encode_xml(obj.elem, E)]\n        children.extend(encode_xml(x, E) for x in obj.arguments)\n    elif isinstance(obj, om.OMAttribution):\n        children = [encode_xml(obj.pairs, E), encode_xml(obj.obj, E)]\n\n    elif isinstance(obj, om.OMAttributionPairs):\n        for (k, v) in obj.pairs:\n            children.append(encode_xml(k, E))\n            children.append(encode_xml(v, E))\n\n    elif isinstance(obj, om.OMBinding):\n        children = [\n            encode_xml(obj.binder, E),\n            encode_xml(obj.vars, E),\n            encode_xml(obj.obj, E)\n        ]\n    elif isinstance(obj, om.OMBindVariables):\n        children = [encode_xml(x, E) for x in obj.vars]\n    elif isinstance(obj, om.OMAttVar):\n        children = [encode_xml(obj.pairs, E), encode_xml(obj.obj, E)]\n    elif isinstance(obj, om.OMError):\n        children = [encode_xml(obj.name, E)]\n        children.extend(encode_xml(x, E) for x in obj.params)\n    else:\n        raise TypeError(\"Expected obj to be of type OMAny, found %s.\" % obj.__class__.__name__)\n\n    attr = dict((k,str(v)) for k, v in attr.items() if v is not None)\n\n    return E(xml.object_to_tag(obj), *children, **attr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nencode an OpenMath element into a byte string.", "response": "def encode_bytes(obj, nsprefix=None):\n    \"\"\" Encodes an OpenMath element into a string.\n\n    :param obj: Object to encode as string.\n    :type obj: OMAny\n\n    :rtype: bytes\n    \"\"\"\n\n    node = encode_xml(obj, nsprefix)\n    return etree.tostring(node)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decode_bytes(xml, validator=None, snippet=False):\n    return decode_stream(io.BytesIO(xml), validator, snippet)", "response": "Decodes a byte stream into an OpenMath object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecode a stream into an OpenMath object.", "response": "def decode_stream(stream, validator=None, snippet=False):\n    \"\"\" Decodes a stream into an OpenMath object.\n\n    :param stream: Stream to decode.\n    :type stream: Any\n\n    :param validator: Validator to use.\n\n    :param snippet: Is this an OpenMath snippet, or a full object?\n    :type snippet: Bool\n\n    :rtype: OMAny\n    \"\"\"\n\n    # TODO: Complete the docstring above\n\n    \n    tree = etree.parse(stream)\n    if validator is not None:\n        validator.assertValid(tree)\n\n    root = tree.getroot()\n    v = root.get(\"version\")\n    if not snippet and (not v or v != \"2.0\"):\n        raise ValueError(\"Only OpenMath 2.0 is supported\")\n\n    return decode_xml(root)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decode_xml(elem, _in_bind = False):\n\n    obj = xml.tag_to_object(elem)\n    attrs = {}\n    \n    def a2d(*props):\n        for p in props:\n            attrs[p] = elem.get(p)\n    \n    if issubclass(obj, om.CommonAttributes):\n        a2d(\"id\")\n    if issubclass(obj, om.CDBaseAttribute):\n        a2d(\"cdbase\")\n\n    # Root Object\n    if issubclass(obj, om.OMObject):\n        a2d(\"version\")\n        attrs[\"omel\"] = decode_xml(elem[0])\n\n    # Reference Objects\n    elif issubclass(obj, om.OMReference):\n        a2d(\"href\")\n\n    # Basic Objects\n    elif issubclass(obj, om.OMInteger):\n        attrs[\"integer\"] = int(elem.text)\n    elif issubclass(obj, om.OMFloat):\n        # TODO: Support Hex\n        attrs[\"double\"] = float(elem.get('dec'))\n    elif issubclass(obj, om.OMString):\n        attrs[\"string\"] = elem.text\n    elif issubclass(obj, om.OMBytes):\n        try:\n            attrs[\"bytes\"] = base64.b64decode(elem.text)\n        except TypeError:\n            attrs[\"bytes\"] = base64.b64decode(bytes(elem.text, \"ascii\"))\n    elif issubclass(obj, om.OMSymbol):\n        a2d(\"name\", \"cd\")\n    elif issubclass(obj, om.OMVariable):\n        a2d(\"name\")\n\n    # Derived Elements\n    elif issubclass(obj, om.OMForeign):\n        attrs[\"obj\"] = elem.text\n        a2d(\"encoding\")\n\n    # Compound Elements\n    elif issubclass(obj, om.OMApplication):\n        attrs[\"elem\"] = decode_xml(elem[0])\n        attrs[\"arguments\"] = list(map(decode_xml, elem[1:]))\n    elif issubclass(obj, om.OMAttribution):\n        attrs[\"pairs\"] = decode_xml(elem[0])\n        attrs[\"obj\"] = decode_xml(elem[1])\n    elif issubclass(obj, om.OMAttributionPairs):\n        if not _in_bind:\n            attrs[\"pairs\"] = [(decode_xml(k), decode_xml(v)) for k, v in zip(elem[::2], elem[1::2])]\n        else:\n            obj = om.OMAttVar\n            attrs[\"pairs\"] = decode_xml(elem[0], True)\n            attrs[\"obj\"] = decode_xml(elem[1], True)\n    elif issubclass(obj, om.OMBinding):\n        attrs[\"binder\"] = decode_xml(elem[0])\n        attrs[\"vars\"] = decode_xml(elem[1])\n        attrs[\"obj\"] = decode_xml(elem[2])\n    elif issubclass(obj, om.OMBindVariables):\n        attrs[\"vars\"] = list(map(lambda x:decode_xml(x, True), elem[:]))\n    elif issubclass(obj, om.OMError):\n        attrs[\"name\"] = decode_xml(elem[0])\n        attrs[\"params\"] = list(map(decode_xml, elem[1:]))\n        \n    else:\n        raise TypeError(\"Expected OMAny, found %s.\" % obj.__name__)\n\n    return obj(**attrs)", "response": "Decodes an XML element into an OpenMath object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef publish(msg=\"checkpoint: publish package\"):\n    test = check()\n    if test.succeeded:\n        # clean()\n        # push(msg)\n        sdist = local(\"python setup.py sdist\")\n        if sdist.succeeded:\n            build = local(\n                'python setup.py build && python setup.py bdist_egg')\n            if build.succeeded:\n                upload = local(\"twine upload dist/*\")\n                if upload.succeeded:\n                    tag()", "response": "Deploy the app to PYPI."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndeploy a version tag.", "response": "def tag(version=__version__):\n    \"\"\"Deploy a version tag.\"\"\"\n    build = local(\"git tag {0}\".format(version))\n    if build.succeeded:\n        local(\"git push --tags\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef any_field_choices(function):\r\n    def wrapper(field, **kwargs):\r\n        if field.choices:\r\n            return random.choice(list(valid_choices(field.choices)))\r\n        return function(field, **kwargs)\r\n\r\n    return wrapper", "response": "Decorator to return a random choice from field. choices"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef any_biginteger_field(field, **kwargs):\r\n    min_value = kwargs.get('min_value', 1)\r\n    max_value = kwargs.get('max_value', 10**10)\r\n    return long(xunit.any_int(min_value=min_value, max_value=max_value))", "response": "Returns random value for any biginteger field"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new xunit. AnyIntegerField that is a positive integer.", "response": "def any_positiveinteger_field(field, **kwargs):\r\n    \"\"\"\r\n    An positive integer\r\n\r\n    >>> result = any_field(models.PositiveIntegerField())\r\n    >>> type(result)\r\n    <type 'int'>\r\n    >>> result > 0\r\n    True\r\n    \"\"\"\r\n    min_value = kwargs.get('min_value', 1)\r\n    max_value = kwargs.get('max_value', 9999)\r\n    return xunit.any_int(min_value=min_value, max_value=max_value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning random value for any char field", "response": "def any_char_field(field, **kwargs):\r\n    \"\"\"\r\n    Return random value for CharField\r\n\r\n    >>> result = any_field(models.CharField(max_length=10))\r\n    >>> type(result)\r\n    <type 'str'>\r\n    \"\"\"\r\n    min_length = kwargs.get('min_length', 1)\r\n    max_length = kwargs.get('max_length', field.max_length)\r\n    return xunit.any_string(min_length=min_length, max_length=max_length)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef any_commaseparatedinteger_field(field, **kwargs):\r\n    nums_count = field.max_length/2\r\n    nums = [str(xunit.any_int(min_value=0, max_value=9)) for _ in xrange(0, nums_count)]\r\n    return \",\".join(nums)", "response": "Returns random value for any commaseparated integer field."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef any_date_field(field, **kwargs):\r\n    if field.auto_now or field.auto_now_add:\r\n        return None\r\n    from_date = kwargs.get('from_date', date(1990, 1, 1))\r\n    to_date = kwargs.get('to_date', date.today())\r\n    return xunit.any_date(from_date=from_date, to_date=to_date)", "response": "Returns random value for any date field"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef any_datetime_field(field, **kwargs):\r\n    from_date = kwargs.get('from_date', datetime(1990, 1, 1))\r\n    to_date = kwargs.get('to_date', datetime.today())\r\n    return xunit.any_datetime(from_date=from_date, to_date=to_date)", "response": "Returns random value for any datetime field"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef any_decimal_field(field, **kwargs):\r\n    min_value = kwargs.get('min_value', 0)\r\n    max_value = kwargs.get('max_value',\r\n                           Decimal('%s.%s' % ('9'*(field.max_digits-field.decimal_places),\r\n                                              '9'*field.decimal_places)))\r\n    decimal_places = kwargs.get('decimal_places', field.decimal_places)\r\n    return xunit.any_decimal(min_value=min_value, max_value=max_value,\r\n                             decimal_places = decimal_places)", "response": "Returns random value for any decimal field"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef any_email_field(field, **kwargs):\r\n    return \"%s@%s.%s\" % (xunit.any_string(max_length=10),\r\n                         xunit.any_string(max_length=10),\r\n                         xunit.any_string(min_length=2, max_length=3))", "response": "Returns random value for any email field"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef any_float_field(field, **kwargs):\r\n    min_value = kwargs.get('min_value', 1)\r\n    max_value = kwargs.get('max_value', 100)\r\n    precision = kwargs.get('precision', 3)\r\n    return xunit.any_float(min_value=min_value, max_value=max_value, precision=precision)", "response": "Returns random value for any float field"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef any_file_field(field, **kwargs):\r\n    def get_some_file(path):\r\n        subdirs, files = field.storage.listdir(path)\r\n\r\n        if files:\r\n            result_file = random.choice(files)\r\n            instance = field.storage.open(\"%s/%s\" % (path, result_file)).file\r\n            return FieldFile(instance, field, result_file)\r\n\r\n        for subdir in subdirs:\r\n            result = get_some_file(\"%s/%s\" % (path, subdir))\r\n            if result:\r\n                return result\r\n            \r\n    result = get_some_file(field.upload_to)\r\n\r\n    if result is None and not field.null:\r\n        raise TypeError(\"Can't found file in %s for non nullable FileField\" % field.upload_to)\r\n    return result", "response": "Lookup for nearest existing file in a given field."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a random filepath for any existing file in the specified FilePathField", "response": "def any_filepath_field(field, **kwargs):\r\n    \"\"\"\r\n    Lookup for nearest existing file\r\n\r\n    \"\"\"\r\n    def get_some_file(path):\r\n        subdirs, files = [], []\r\n        for entry in os.listdir(path):\r\n            entry_path = os.path.join(path, entry)\r\n            if os.path.isdir(entry_path):\r\n                subdirs.append(entry_path)\r\n            else:\r\n                if not field.match or re.match(field.match,entry):\r\n                    files.append(entry_path)\r\n\r\n        if files:\r\n            return random.choice(files)\r\n        \r\n        if field.recursive:\r\n            for subdir in subdirs:\r\n                result = get_some_file(subdir)\r\n                if result:\r\n                    return result\r\n\r\n    result = get_some_file(field.path)\r\n    if result is None and not field.null:\r\n        raise TypeError(\"Can't found file in %s for non nullable FilePathField\" % field.path)\r\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef any_ipaddress_field(field, **kwargs):\r\n    nums = [str(xunit.any_int(min_value=0, max_value=255)) for _ in xrange(0, 4)]\r\n    return \".\".join(nums)", "response": "Returns random value for any IPAddressField"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn random value for any positive small integer field", "response": "def any_positivesmallinteger_field(field, **kwargs):\r\n    \"\"\"\r\n    Return random value for PositiveSmallIntegerField\r\n    >>> result = any_field(models.PositiveSmallIntegerField())\r\n    >>> type(result)\r\n    <type 'int'>\r\n    >>> result < 256, result > 0\r\n    (True, True)\r\n    \"\"\"\r\n    min_value = kwargs.get('min_value', 1)\r\n    max_value = kwargs.get('max_value', 255)\r\n    return xunit.any_int(min_value=min_value, max_value=max_value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning random value for any slug field", "response": "def any_slug_field(field, **kwargs):\r\n    \"\"\"\r\n    Return random value for SlugField\r\n    >>> result = any_field(models.SlugField())\r\n    >>> type(result)\r\n    <type 'str'>\r\n    >>> from django.core.validators import slug_re\r\n    >>> re.match(slug_re, result) is not None\r\n    True\r\n    \"\"\"\r\n    letters = ascii_letters + digits + '_-'\r\n    return xunit.any_string(letters = letters, max_length = field.max_length)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns random value for any small integer field", "response": "def any_smallinteger_field(field, **kwargs):\r\n    \"\"\"\r\n    Return random value for SmallIntegerValue\r\n    >>> result = any_field(models.SmallIntegerField())\r\n    >>> type(result)\r\n    <type 'int'>\r\n    >>> result > -256, result < 256\r\n    (True, True)\r\n    \"\"\"\r\n    min_value = kwargs.get('min_value', -255)\r\n    max_value = kwargs.get('max_value', 255)\r\n    return xunit.any_int(min_value=min_value, max_value=max_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef any_integer_field(field, **kwargs):\r\n    min_value = kwargs.get('min_value', -10000)\r\n    max_value = kwargs.get('max_value', 10000)\r\n    return xunit.any_int(min_value=min_value, max_value=max_value)", "response": "Returns random value for any integer field"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns random value for any URLField", "response": "def any_url_field(field, **kwargs):\r\n    \"\"\"\r\n    Return random value for URLField\r\n    >>> result = any_field(models.URLField())\r\n    >>> from django.core.validators import URLValidator\r\n    >>> re.match(URLValidator.regex, result) is not None\r\n    True\r\n    \"\"\"\r\n    url = kwargs.get('url')\r\n\r\n    if not url:\r\n        verified = [validator for validator in field.validators \\\r\n                    if isinstance(validator, validators.URLValidator) and \\\r\n                    validator.verify_exists == True]\r\n        if verified:\r\n            url = choice(['http://news.yandex.ru/society.html',\r\n                          'http://video.google.com/?hl=en&tab=wv',\r\n                          'http://www.microsoft.com/en/us/default.aspx',\r\n                          'http://habrahabr.ru/company/opera/',\r\n                          'http://www.apple.com/support/hardware/',\r\n                          'http://ya.ru',\r\n                          'http://google.com',\r\n                          'http://fr.wikipedia.org/wiki/France'])\r\n        else:\r\n            url = \"http://%s.%s/%s\" % (\r\n                xunit.any_string(max_length=10),\r\n                xunit.any_string(min_length=2, max_length=3),\r\n                xunit.any_string(max_length=20))\r\n\r\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef any_time_field(field, **kwargs):\r\n    return time(\r\n        xunit.any_int(min_value=0, max_value=23),\r\n        xunit.any_int(min_value=0, max_value=59),\r\n        xunit.any_int(min_value=0, max_value=59))", "response": "Returns random value for any time field"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nevaluates an OpenMath symbol describing a global Python object and return it.", "response": "def load_python_global(module, name):\n    \"\"\"\n    Evaluate an OpenMath symbol describing a global Python object\n\n    EXAMPLES::\n\n        >>> from openmath.convert_pickle import to_python\n        >>> from openmath.convert_pickle  import load_python_global\n        >>> load_python_global('math', 'sin')\n        <built-in function sin>\n\n        >>> from openmath import openmath as om\n        >>> o = om.OMSymbol(cdbase=\"http://python.org/\", cd='math', name='sin')\n        >>> to_python(o)\n        <built-in function sin>\n    \"\"\"\n\n    # The builtin module has been renamed in python3\n    if module == '__builtin__' and six.PY3:\n        module = 'builtins'\n    module = importlib.import_module(module)\n    return getattr(module, name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new instance of the class with the given state.", "response": "def cls_build(inst, state):\n    \"\"\"\n    Apply the setstate protocol to initialize `inst` from `state`.\n\n    INPUT:\n\n    - ``inst`` -- a raw instance of a class\n    - ``state`` -- the state to restore; typically a dictionary mapping attribute names to their values\n\n    EXAMPLES::\n\n        >>> from openmath.convert_pickle import cls_build\n        >>> class A(object): pass\n        >>> inst = A.__new__(A)\n        >>> state = {\"foo\": 1, \"bar\": 4}\n        >>> inst2 = cls_build(inst,state)\n        >>> inst is inst2\n        True\n        >>> inst.foo\n        1\n        >>> inst.bar\n        4\n    \"\"\"\n    # Copied from Pickler.load_build\n    setstate = getattr(inst, \"__setstate__\", None)\n    if setstate:\n        setstate(state)\n        return inst\n    slotstate = None\n    if isinstance(state, tuple) and len(state) == 2:\n        state, slotstate = state\n    \n    if state:\n        try:\n            d = inst.__dict__\n            try:\n                for k, v in six.iteritems(state):\n                    d[six.moves.intern(k)] = v\n            # keys in state don't have to be strings\n            # don't blow up, but don't go out of our way\n            except TypeError:\n                d.update(state)\n\n        except RuntimeError:\n            # XXX In restricted execution, the instance's __dict__\n            # is not accessible.  Use the old way of unpickling\n            # the instance variables.  This is a semantic\n            # difference when unpickling in restricted\n            # vs. unrestricted modes.\n            # Note, however, that cPickle has never tried to do the\n            # .update() business, and always uses\n            #     PyObject_SetItem(inst.__dict__, key, value) in a\n            # loop over state.items().\n            for k, v in state.items():\n                setattr(inst, k, v)\n    if slotstate:\n        for k, v in slotstate.items():\n            setattr(inst, k, v)\n    return inst"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef OMList(self, l):\n        # Except for the conversion of operands, this duplicates the default\n        # implementation of python's list conversion to openmath in py_openmath\n        return om.OMApplication(elem=om.OMSymbol(cdbase=self._cdbase, cd='Python', name='list', ), arguments=l)", "response": "Convert a list of OM objects into an OM object\n            EXAMPLES::get\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a tuple of OM objects into an OM object", "response": "def OMTuple(self, l):\n        \"\"\"\n        Convert a tuple of OM objects into an OM object\n\n        EXAMPLES::\n\n            >>> from openmath import openmath as om\n            >>> from openmath.convert_pickle  import PickleConverter\n            >>> converter = PickleConverter()\n            >>> o = converter.OMTuple([om.OMInteger(2), om.OMInteger(3)]); o\n            OMApplication(elem=OMSymbol(name='tuple', cd='Python', id=None, cdbase='http://python.org/'),\n                     arguments=[OMInteger(integer=2, id=None), OMInteger(integer=3, id=None)], id=None, cdbase=None)\n            >>> converter.to_python(o)\n            (2, 3)\n        \"\"\"\n        return om.OMApplication(elem=self.OMSymbol(module='Python', name='tuple'),\n                                arguments=l)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a dictionary or list of items thereof into an OM object", "response": "def OMDict(self, items):\n        \"\"\"\n        Convert a dictionary (or list of items thereof) of OM objects into an OM object\n\n        EXAMPLES::\n\n            >>> from openmath import openmath as om\n            >>> from openmath.convert_pickle  import PickleConverter\n            >>> converter = PickleConverter()\n            >>> a = om.OMInteger(1)\n            >>> b = om.OMInteger(3)\n            >>> o = converter.OMDict([(a,b), (b,b)]); print(o)\n            OMApplication(\n              elem=OMSymbol(name='dict', cd='Python', cdbase='http://python.org/'),\n              arguments=[\n                OMApplication(\n                  elem=OMSymbol(name='tuple', cd='Python', cdbase='http://python.org/'),\n                  arguments=[\n                    OMInteger(integer=1),\n                    OMInteger(integer=3)]),\n                OMApplication(\n                  elem=OMSymbol(name='tuple', cd='Python', cdbase='http://python.org/'),\n                  arguments=[\n                    OMInteger(integer=3),\n                    OMInteger(integer=3)])])\n            >>> converter.to_python(o)\n            {1: 3, 3: 3}\n        \"\"\"\n        return om.OMApplication(elem=self.OMSymbol(module='Python', name='dict'),\n                                arguments=[self.OMTuple(item) for item in items])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decode(data):\n    data = bytearray(data) # <- python 2/3 compatibility fix\n    result = bytearray()\n    pos = 0\n    while pos < len(data):\n        header_byte = data[pos]\n        if header_byte > 127:\n            header_byte -= 256\n        pos += 1\n\n        if 0 <= header_byte <= 127:\n            result.extend(data[pos:pos+header_byte+1])\n            pos += header_byte+1\n        elif header_byte == -128:\n            pass\n        else:\n            result.extend([data[pos]] * (1 - header_byte))\n            pos += 1\n\n    return bytes(result)", "response": "Decodes a PackBit encoded data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef encode(data):\n    if len(data) == 0:\n        return data\n\n    if len(data) == 1:\n        return b'\\x00' + data\n\n    data = bytearray(data)\n\n    result = bytearray()\n    buf = bytearray()\n    pos = 0\n    repeat_count = 0\n    MAX_LENGTH = 127\n\n    # we can safely start with RAW as empty RAW sequences\n    # are handled by finish_raw()\n    state = 'RAW'\n\n    def finish_raw():\n        if len(buf) == 0:\n            return\n        result.append(len(buf)-1)\n        result.extend(buf)\n        buf[:] = bytearray()\n\n    def finish_rle():\n        result.append(256-(repeat_count - 1))\n        result.append(data[pos])\n\n    while pos < len(data)-1:\n        current_byte = data[pos]\n\n        if data[pos] == data[pos+1]:\n            if state == 'RAW':\n                # end of RAW data\n                finish_raw()\n                state = 'RLE'\n                repeat_count = 1\n            elif state == 'RLE':\n                if repeat_count == MAX_LENGTH:\n                    # restart the encoding\n                    finish_rle()\n                    repeat_count = 0\n                # move to next byte\n                repeat_count += 1\n\n        else:\n            if state == 'RLE':\n                repeat_count += 1\n                finish_rle()\n                state = 'RAW'\n                repeat_count = 0\n            elif state == 'RAW':\n                if len(buf) == MAX_LENGTH:\n                    # restart the encoding\n                    finish_raw()\n\n                buf.append(current_byte)\n\n        pos += 1\n\n    if state == 'RAW':\n        buf.append(data[pos])\n        finish_raw()\n    else:\n        repeat_count += 1\n        finish_rle()\n\n    return bytes(result)", "response": "Encodes data using PackBits encoding."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _check_currency_format(self, format=None):\n        defaults = self.settings['currency']['format']\n        if hasattr(format, '__call__'):\n            format = format()\n        if is_str(format) and re.match('%v', format):\n\n            # Create and return positive, negative and zero formats:\n            return {\n                'pos': format,\n                'neg': format.replace(\"-\", \"\").replace(\"%v\", \"-%v\"),\n                'zero': format\n            }\n        elif not format or not format['por'] or not re.match('%v',\n                                                             format['pos']):\n            self.settings['currency']['format'] = {\n                'pos': defaults,\n                'neg': defaults.replace(\"%v\", \"-%v\"),\n                'zero': defaults\n            }\n            return self.settings\n\n        return format", "response": "Check if the currency format is valid and return it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _change_precision(self, val, base=0):\n        if not isinstance(val, int):\n            raise TypeError('The first argument must be an integer.')\n        val = round(abs(val))\n        val = (lambda num: base if is_num(num) else num)(val)\n        return val", "response": "Check and normalise the value of precision."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a string and return the raw float value", "response": "def parse(self, value, decimal=None):\n        \"\"\"\n        Summary.\n\n         Takes a string/array of strings, removes all formatting/cruft and\n         returns the raw float value\n\n         Decimal must be included in the regular expression to match floats\n          (defaults to Accounting.settings.number.decimal),\n          so if the number uses a non-standard decimal\n         separator, provide it as the second argument.\n         *\n         Also matches bracketed negatives (eg. \"$ (1.99)\" => -1.99)\n\n         Doesn't throw any errors (`None`s become 0) but this may change\n\n        Args:\n            value (TYPE): Description\n            decimal (TYPE): Description\n\n        Returns:\n            name (TYPE): Description\n        \"\"\"\n        # Fails silently (need decent errors):\n        value = value or 0\n\n        # Recursively unformat arrays:\n        if check_type(value, 'list'):\n            return map(lambda val: self.parse(val, decimal))\n\n        # Return the value as-is if it's already a number:\n        if check_type(value, 'int') or check_type(value, 'float'):\n            return value\n\n        # Default decimal point comes from settings, but could be set to eg.\",\"\n        decimal = decimal or self.settings.number.decimal\n\n        # Build regex to strip out everything except digits,\n        # decimal point and minus sign\n        regex = re.compile(\"[^0-9-\" + decimal + \"]\")\n        unformatted = str(value)\n        unformatted = re.sub('/\\((.*)\\)/', \"-$1\", unformatted)\n        unformatted = re.sub(regex, '', unformatted)\n        unformatted = unformatted.replace('.', decimal)\n        formatted = (lambda val: unformatted if val else 0)(\n            is_num(unformatted))\n\n        return formatted"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats a given number with comma - separated thousands and decimal places and thousand and decimal separators", "response": "def format(self, number, **kwargs):\n        \"\"\"Format a given number.\n\n        Format a number, with comma-separated thousands and\n        custom precision/decimal places\n\n        Localise by overriding the precision and thousand / decimal separators\n        2nd parameter `precision` can be an object matching `settings.number`\n\n        Args:\n            number (TYPE): Description\n            precision (TYPE): Description\n            thousand (TYPE): Description\n            decimal (TYPE): Description\n\n        Returns:\n            name (TYPE): Description\n        \"\"\"\n        # Resursively format lists\n        if check_type(number, 'list'):\n            return map(lambda val: self.format(val, **kwargs))\n        # Clean up number\n        number = self.parse(number)\n\n        # Build options object from second param (if object) or all params,\n        # extending defaults\n        if check_type(kwargs, 'dict'):\n            options = (self.settings['number'].update(kwargs))\n\n        # Clean up precision\n        precision = self._change_precision(options['precision'])\n        negative = (lambda num: \"-\" if num < 0 else \"\")(number)\n        base = str(int(self.to_fixed(abs(number) or 0, precision)), 10)\n        mod = (lambda num: len(num) % 3 if len(num) > 3 else 0)(base)\n\n        # Format the number:\n        num = negative + (lambda num: base[0:num] if num else '')(mod)\n\n        num += re.sub('/(\\d{3})(?=\\d)/g', '$1' +\n                      options['thousand'], base[mod:])\n        num += (lambda val: options[\n            'decimal'] + self.to_fixed(abs(number), precision)\n            .split('.')[1] if val else '')(precision)\n\n        return num"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nformat a number into money.", "response": "def as_money(self, number, **options):\n        \"\"\"Format a number into currency.\n\n        Usage: accounting.formatMoney(number, symbol, precision, thousandsSep,\n                                      decimalSep, format)\n        defaults: (0, \"$\", 2, \",\", \".\", \"%s%v\")\n        Localise by overriding the symbol, precision,\n        thousand / decimal separators and format\n        Second param can be an object matching `settings.currency`\n        which is the easiest way.\n\n        Args:\n            number (TYPE): Description\n            precision (TYPE): Description\n            thousand (TYPE): Description\n            decimal (TYPE): Description\n\n        Returns:\n            name (TYPE): Description\n        \"\"\"\n        # Resursively format arrays\n        if isinstance(number, list):\n            return map(lambda val: self.as_money(val, **options))\n\n        # Clean up number\n        decimal = options.get('decimal')\n        number = self.parse(number, decimal)\n\n        # Build options object from second param (if object) or all params,\n        # extending defaults\n        if check_type(options, 'dict'):\n            options = (self.settings['currency'].update(options))\n\n        # Check format (returns object with pos, neg and zero)\n        formats = self._check_currency_format(options['format'])\n\n        # Choose which format to use for this value\n        use_format = (lambda num: formats['pos'] if num > 0 else formats[\n                      'neg'] if num < 0 else formats['zero'])(number)\n        precision = self._change_precision(number, options['precision'])\n        thousands = options['thousand']\n        decimal = options['decimal']\n        formater = self.format(abs(number), precision, thousands, decimal)\n\n        # Return with currency symbol added\n        amount = use_format.replace(\n            '%s', options['symbol']).replace('%v', formater)\n\n        return amount"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimport a blosc array into a numpy array.", "response": "def to_array(data):\n    \"\"\"\n    Import a blosc array into a numpy array.\n\n    Arguments:\n        data: A blosc packed numpy array\n\n    Returns:\n        A numpy array with data from a blosc compressed array\n    \"\"\"\n    try:\n        numpy_data = blosc.unpack_array(data)\n    except Exception as e:\n        raise ValueError(\"Could not load numpy data. {}\".format(e))\n\n    return numpy_data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexport a numpy array to a blosc compressed array.", "response": "def from_array(array):\n    \"\"\"\n    Export a numpy array to a blosc array.\n\n    Arguments:\n        array: The numpy array to compress to blosc array\n\n    Returns:\n        Bytes/String. A blosc compressed array\n    \"\"\"\n    try:\n        raw_data = blosc.pack_array(array)\n    except Exception as e:\n        raise ValueError(\"Could not compress data from array. {}\".format(e))\n\n    return raw_data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a workspace entry in user config file.", "response": "def add(self, name, path):\n        \"\"\"Add a workspace entry in user config file.\"\"\"\n        if not (os.path.exists(path)):\n            raise ValueError(\"Workspace path `%s` doesn't exists.\" % path)\n\n        if (self.exists(name)):\n            raise ValueError(\"Workspace `%s` already exists.\" % name)\n\n        self.config[\"workspaces\"][name] = {\"path\": path, \"repositories\": {}}\n        self.config.write()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove(self, name):\n        if not (self.exists(name)):\n            raise ValueError(\"Workspace `%s` doesn't exists.\" % name)\n\n        self.config[\"workspaces\"].pop(name, 0)\n        self.config.write()", "response": "Remove workspace from config file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist all available workspaces.", "response": "def list(self):\n        \"\"\"List all available workspaces.\"\"\"\n        ws_list = {}\n\n        for key, value in self.config[\"workspaces\"].items():\n            ws_list[key] = dict({\"name\": key}, **value)\n\n        return ws_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, name):\n        ws_list = self.list()\n        return ws_list[name] if name in ws_list else None", "response": "Get workspace infos from name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if workspace contains repository name.", "response": "def repository_exists(self, workspace, repo):\n        \"\"\"Return True if workspace contains repository name.\"\"\"\n        if not self.exists(workspace):\n            return False\n\n        workspaces = self.list()\n        return repo in workspaces[workspace][\"repositories\"]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsynchronise workspace s repositories.", "response": "def sync(self, ws_name):\n        \"\"\"Synchronise workspace's repositories.\"\"\"\n        path = self.config[\"workspaces\"][ws_name][\"path\"]\n        repositories = self.config[\"workspaces\"][ws_name][\"repositories\"]\n\n        logger = logging.getLogger(__name__)\n        color = Color()\n\n        for r in os.listdir(path):\n            try:\n                repo = Repository(os.path.join(path, r))\n            except RepositoryError:\n                continue\n            else:\n                repositories[r] = repo.path\n\n        for repo_name, path in repositories.items():\n            logger.info(color.colored(\n                \" - %s\" % repo_name, \"blue\"))\n\n        self.config[\"workspaces\"][ws_name][\"repositories\"]\n        self.config.write()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntell you if you have an old version of ndio.", "response": "def check_version():\n    \"\"\"\n    Tells you if you have an old version of ndio.\n    \"\"\"\n    import requests\n    r = requests.get('https://pypi.python.org/pypi/ndio/json').json()\n    r = r['info']['version']\n    if r != version:\n        print(\"A newer version of ndio is available. \" +\n              \"'pip install -U ndio' to update.\")\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_voxels(array):\n    if type(array) is not numpy.ndarray:\n        raise ValueError(\"array argument must be of type numpy.ndarray\")\n    return numpy.argwhere(array)", "response": "Converts an array to its voxel list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_voxels(voxels):\n    dimensions = len(voxels[0])\n\n    for d in range(len(dimensions)):\n        size.append(max([i[d] for i in voxels]))\n\n    result = numpy.zeros(dimensions)\n\n    for v in voxels:\n        result[v] = 1\n\n    return result", "response": "Converts a voxel list to an ndarray."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting a file handler for this log record.", "response": "def set_file_handler(self, logfile):\n        \"\"\"Set FileHandler\"\"\"\n        handler = logging.FileHandler(logfile)\n        handler.setLevel(logging.NOTSET)\n        handler.setFormatter(Formatter(FORMAT))\n\n        self.addHandler(handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute(self, command, path=None):\n        logger = logging.getLogger(__name__)\n\n        self.check_executable()\n        logger.debug(\"Executing command `%s` (cwd: %s)\" % (command, path))\n        process = subprocess.Popen(\n            command,\n            shell=True,\n            cwd=path,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE\n        )\n        stdout, stderr = process.communicate()\n        exit_code = process.wait()\n\n        if stdout:\n            logger.info(stdout.decode(\"utf-8\"))\n\n        if stderr:\n            if exit_code != 0:\n                logger.error(stderr.decode(\"utf-8\"))\n            else:\n                logger.info(stderr.decode(\"utf-8\"))\n\n        return process", "response": "Execute command with os. popen and return output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load(png_filename):\n    # Expand filename to be absolute\n    png_filename = os.path.expanduser(png_filename)\n\n    try:\n        img = Image.open(png_filename)\n    except Exception as e:\n        raise ValueError(\"Could not load file {0} for conversion.\"\n                         .format(png_filename))\n        raise\n\n    return numpy.array(img)", "response": "Imports a png file into a numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexport a numpy array to a png file.", "response": "def save(filename, numpy_data):\n    \"\"\"\n    Export a numpy array to a png file.\n\n    Arguments:\n        filename (str): A filename to which to save the png data\n        numpy_data (numpy.ndarray OR str): The numpy array to save to png.\n            OR a string: If a string is provded, it should be a binary png str\n\n    Returns:\n        str. The expanded filename that now holds the png data\n\n    Raises:\n        ValueError: If the save fails; for instance if the binary string data\n            cannot be coerced into a png, or perhaps your numpy.ndarray is\n            ill-formed?\n    \"\"\"\n    # Expand filename to be absolute\n    png_filename = os.path.expanduser(filename)\n\n    if type(numpy_data) is str:\n        fp = open(png_filename, \"wb\")\n        fp.write(numpy_data)\n        fp.close()\n        return png_filename\n\n    try:\n        if numpy_data.dtype.name != 'uint8':\n            m = 'I'\n            img = Image.fromarray(numpy_data, mode=m)\n        else:\n            img = Image.fromarray(numpy_data)\n        img.save(png_filename)\n    except Exception as e:\n        raise ValueError(\"Could not save png file {0}.\".format(png_filename))\n    return png_filename"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_collection(png_filename_base, numpy_data, start_layers_at=1):\n    file_ext = png_filename_base.split('.')[-1]\n    if file_ext in ['png']:\n        # Filename is \"name*.ext\", set file_base to \"name*\".\n        file_base = '.'.join(png_filename_base.split('.')[:-1])\n    else:\n        # Filename is \"name*\", set file_base to \"name*\".\n        # That is, extension wasn't included.\n        file_base = png_filename_base\n        file_ext = \".png\"\n\n    file_base_array = file_base.split('*')\n\n    # The array of filenames to return\n    output_files = []\n\n    # Filename 0-padding\n    i = start_layers_at\n    for layer in numpy_data:\n        layer_filename = (str(i).zfill(6)).join(file_base_array) + file_ext\n        output_files.append(save(layer_filename, layer))\n        i += 1\n\n    return output_files", "response": "Exports a numpy array to a set of png files with each Z - index as its own 2D file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_collection(png_filename_base):\n    # We expect images to be indexed by their alphabetical order.\n    files = glob.glob(png_filename_base)\n    files.sort()\n\n    numpy_data = []\n    for f in files:\n        numpy_data.append(load(f))\n\n    return numpy.concatenate(numpy_data)", "response": "Loads all PNG files matching the given filename base and returns a 3D array containing the 3D images."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the blocksize for a given token at a given resolution.", "response": "def get_block_size(self, token, resolution=None):\n        \"\"\"\n        Gets the block-size for a given token at a given resolution.\n\n        Arguments:\n            token (str): The token to inspect\n            resolution (int : None): The resolution at which to inspect data.\n                If none is specified, uses the minimum available.\n\n        Returns:\n            int[3]: The xyz blocksize.\n        \"\"\"\n        cdims = self.get_metadata(token)['dataset']['cube_dimension']\n        if resolution is None:\n            resolution = min(cdims.keys())\n        return cdims[str(resolution)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_volume(self, token, channel,\n                   x_start, x_stop,\n                   y_start, y_stop,\n                   z_start, z_stop,\n                   resolution=1,\n                   block_size=DEFAULT_BLOCK_SIZE,\n                   neariso=False):\n        \"\"\"\n        Get a RAMONVolume volumetric cutout from the neurodata server.\n\n        Arguments:\n            token (str): Token to identify data to download\n            channel (str): Channel\n            resolution (int): Resolution level\n            Q_start (int): The lower bound of dimension 'Q'\n            Q_stop (int): The upper bound of dimension 'Q'\n            block_size (int[3]): Block size of this dataset\n            neariso (bool : False): Passes the 'neariso' param to the cutout.\n                If you don't know what this means, ignore it!\n\n        Returns:\n            ndio.ramon.RAMONVolume: Downloaded data.\n        \"\"\"\n        size = (x_stop - x_start) * (y_stop - y_start) * (z_stop - z_start)\n        volume = ramon.RAMONVolume()\n        volume.xyz_offset = [x_start, y_start, z_start]\n        volume.resolution = resolution\n\n        volume.cutout = self.get_cutout(token, channel, x_start,\n                                        x_stop, y_start, y_stop,\n                                        z_start, z_stop,\n                                        resolution=resolution,\n                                        block_size=block_size,\n                                        neariso=neariso)\n        return volume", "response": "Get a RAMONVolume from the neurodata server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the volumetric cutout data from the neurodata server.", "response": "def get_cutout(self, token, channel,\n                   x_start, x_stop,\n                   y_start, y_stop,\n                   z_start, z_stop,\n                   t_start=0, t_stop=1,\n                   resolution=1,\n                   block_size=DEFAULT_BLOCK_SIZE,\n                   neariso=False):\n        \"\"\"\n        Get volumetric cutout data from the neurodata server.\n\n        Arguments:\n            token (str): Token to identify data to download\n            channel (str): Channel\n            resolution (int): Resolution level\n            Q_start (int): The lower bound of dimension 'Q'\n            Q_stop (int): The upper bound of dimension 'Q'\n            block_size (int[3]): Block size of this dataset. If not provided,\n                ndio uses the metadata of this tokenchannel to set. If you find\n                that your downloads are timing out or otherwise failing, it may\n                be wise to start off by making this smaller.\n            neariso (bool : False): Passes the 'neariso' param to the cutout.\n                If you don't know what this means, ignore it!\n\n        Returns:\n            numpy.ndarray: Downloaded data.\n        \"\"\"\n        if block_size is None:\n            # look up block size from metadata\n            block_size = self.get_block_size(token, resolution)\n\n        origin = self.get_image_offset(token, resolution)\n\n        # If z_stop - z_start is < 16, backend still pulls minimum 16 slices\n        if (z_stop - z_start) < 16:\n            z_slices = 16\n        else:\n            z_slices = z_stop - z_start\n\n        # Calculate size of the data to be downloaded.\n        size = (x_stop - x_start) * (y_stop - y_start) * z_slices * 4\n\n        # Switch which download function to use based on which libraries are\n        # available in this version of python.\n        if six.PY2:\n            dl_func = self._get_cutout_blosc_no_chunking\n        elif six.PY3:\n            dl_func = self._get_cutout_no_chunking\n        else:\n            raise ValueError(\"Invalid Python version.\")\n\n        if size < self._chunk_threshold:\n            vol = dl_func(token, channel, resolution,\n                          x_start, x_stop,\n                          y_start, y_stop,\n                          z_start, z_stop,\n                          t_start, t_stop,\n                          neariso=neariso)\n            vol = numpy.rollaxis(vol, 1)\n            vol = numpy.rollaxis(vol, 2)\n            return vol\n        else:\n            from ndio.utils.parallel import block_compute\n            blocks = block_compute(x_start, x_stop,\n                                   y_start, y_stop,\n                                   z_start, z_stop,\n                                   origin, block_size)\n\n            vol = numpy.zeros(((z_stop - z_start),\n                               (y_stop - y_start),\n                               (x_stop - x_start)))\n            for b in blocks:\n\n                data = dl_func(token, channel, resolution,\n                               b[0][0], b[0][1],\n                               b[1][0], b[1][1],\n                               b[2][0], b[2][1],\n                               0, 1,\n                               neariso=neariso)\n\n                if b == blocks[0]:  # first block\n                    vol = numpy.zeros(((z_stop - z_start),\n                                       (y_stop - y_start),\n                                       (x_stop - x_start)), dtype=data.dtype)\n\n                vol[b[2][0] - z_start: b[2][1] - z_start,\n                    b[1][0] - y_start: b[1][1] - y_start,\n                    b[0][0] - x_start: b[0][1] - x_start] = data\n\n            vol = numpy.rollaxis(vol, 1)\n            vol = numpy.rollaxis(vol, 2)\n            return vol"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nposts a cutout to the server.", "response": "def post_cutout(self, token, channel,\n                    x_start,\n                    y_start,\n                    z_start,\n                    data,\n                    resolution=0):\n        \"\"\"\n        Post a cutout to the server.\n\n        Arguments:\n            token (str)\n            channel (str)\n            x_start (int)\n            y_start (int)\n            z_start (int)\n            data (numpy.ndarray): A numpy array of data. Pass in (x, y, z)\n            resolution (int : 0): Resolution at which to insert the data\n\n        Returns:\n            bool: True on success\n\n        Raises:\n            RemoteDataUploadError: if there's an issue during upload.\n        \"\"\"\n        datatype = self.get_proj_info(token)['channels'][channel]['datatype']\n        if data.dtype.name != datatype:\n            data = data.astype(datatype)\n\n        data = numpy.rollaxis(data, 1)\n        data = numpy.rollaxis(data, 2)\n\n        if six.PY3 or data.nbytes > 1.5e9:\n            ul_func = self._post_cutout_no_chunking_npz\n        else:\n            ul_func = self._post_cutout_no_chunking_blosc\n\n        if data.size < self._chunk_threshold:\n            return ul_func(token, channel, x_start,\n                           y_start, z_start, data,\n                           resolution)\n\n        return self._post_cutout_with_chunking(token, channel,\n                                               x_start, y_start, z_start, data,\n                                               resolution, ul_func)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nposting cutout of no - chunked BLOSC data to the specified resource.", "response": "def _post_cutout_no_chunking_blosc(self, token, channel,\n                                       x_start, y_start, z_start,\n                                       data, resolution):\n        \"\"\"\n        Accepts data in zyx. !!!\n        \"\"\"\n        data = numpy.expand_dims(data, axis=0)\n        blosc_data = blosc.pack_array(data)\n        url = self.url(\"{}/{}/blosc/{}/{},{}/{},{}/{},{}/0,0/\".format(\n            token, channel,\n            resolution,\n            x_start, x_start + data.shape[3],\n            y_start, y_start + data.shape[2],\n            z_start, z_start + data.shape[1]\n        ))\n\n        req = self.remote_utils.post_url(url, data=blosc_data, headers={\n            'Content-Type': 'application/octet-stream'\n        })\n\n        if req.status_code is not 200:\n            raise RemoteDataUploadError(req.text)\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nimport a TIFF file into a numpy array.", "response": "def load(tiff_filename):\n    \"\"\"\n    Import a TIFF file into a numpy array.\n\n    Arguments:\n        tiff_filename:  A string filename of a TIFF datafile\n\n    Returns:\n        A numpy array with data from the TIFF file\n    \"\"\"\n    # Expand filename to be absolute\n    tiff_filename = os.path.expanduser(tiff_filename)\n\n    try:\n        img = tiff.imread(tiff_filename)\n    except Exception as e:\n        raise ValueError(\"Could not load file {0} for conversion.\"\n                         .format(tiff_filename))\n        raise\n\n    return numpy.array(img)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexport a numpy array to a TIFF file.", "response": "def save(tiff_filename, numpy_data):\n    \"\"\"\n    Export a numpy array to a TIFF file.\n\n    Arguments:\n        tiff_filename:  A filename to which to save the TIFF data\n        numpy_data:     The numpy array to save to TIFF\n\n    Returns:\n        String. The expanded filename that now holds the TIFF data\n    \"\"\"\n    # Expand filename to be absolute\n    tiff_filename = os.path.expanduser(tiff_filename)\n\n    if type(numpy_data) is str:\n        fp = open(png_filename, \"wb\")\n        fp.write(numpy_data)\n        fp.close()\n        return png_filename\n\n    try:\n        img = tiff.imsave(tiff_filename, numpy_data)\n    except Exception as e:\n        raise ValueError(\"Could not save TIFF file {0}.\".format(tiff_filename))\n\n    return tiff_filename"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a multipage tiff into a single variable in x y z format.", "response": "def load_tiff_multipage(tiff_filename, dtype='float32'):\n    \"\"\"\n    Load a multipage tiff into a single variable in x,y,z format.\n\n    Arguments:\n        tiff_filename:     Filename of source data\n        dtype:             data type to use for the returned tensor\n\n    Returns:\n        Array containing contents from input tiff file in xyz order\n    \"\"\"\n    if not os.path.isfile(tiff_filename):\n        raise RuntimeError('could not find file \"%s\"' % tiff_filename)\n\n    # load the data from multi-layer TIF files\n    data = tiff.imread(tiff_filename)\n\n    im = []\n\n    while True:\n\n        Xi = numpy.array(data, dtype=dtype)\n        if Xi.ndim == 2:\n            Xi = Xi[numpy.newaxis, ...]  # add slice dimension\n        im.append(Xi)\n\n        try:\n            data.seek(data.tell()+1)\n        except EOFError:\n            break  # this just means hit end of file (not really an error)\n\n    im = numpy.concatenate(im, axis=0)  # list of 2d -> tensor\n    im = numpy.rollaxis(im, 1)\n    im = numpy.rollaxis(im, 2)\n\n    return im"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites config in configuration file.", "response": "def write(self):\n        \"\"\"\n        Write config in configuration file.\n        Data must me a dict.\n        \"\"\"\n        file = open(self.config_file, \"w+\")\n        file.write(yaml.dump(dict(self), default_flow_style=False))\n        file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclone repository from url.", "response": "def clone(self, url):\n        \"\"\"Clone repository from url.\"\"\"\n        return self.execute(\"%s branch %s %s\" % (self.executable,\n                                                 url, self.path))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_version():\n    requirement = pkg_resources.Requirement.parse(\"yoda\")\n    provider = pkg_resources.get_provider(requirement)\n    return provider.version", "response": "Get version from package resources."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmix and matching positional args and keyword options.", "response": "def mix_and_match(name, greeting='Hello', yell=False):\n    '''Mixing and matching positional args and keyword options.'''\n    say = '%s, %s' % (greeting, name)\n    if yell:\n        print '%s!' % say.upper()\n    else:\n        print '%s.' % say"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nimporting a nifti file into a numpy array.", "response": "def load(nifti_filename):\n    \"\"\"\n    Import a nifti file into a numpy array. TODO:  Currently only\n    transfers raw data for compatibility with annotation and ND formats\n\n    Arguments:\n        nifti_filename (str):  A string filename of a nifti datafile\n\n    Returns:\n        A numpy array with data from the nifti file\n    \"\"\"\n    # Expand filename to be absolute\n    nifti_filename = os.path.expanduser(nifti_filename)\n\n    try:\n        data = nib.load(nifti_filename)\n        img = data.get_data()\n\n    except Exception as e:\n        raise ValueError(\"Could not load file {0} for conversion.\"\n                         .format(nifti_filename))\n        raise\n\n    return img"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(nifti_filename, numpy_data):\n    # Expand filename to be absolute\n    nifti_filename = os.path.expanduser(nifti_filename)\n\n    try:\n        nifti_img = nib.Nifti1Image(numpy_data, numpy.eye(4))\n        nib.save(nifti_img, nifti_filename)\n\n    except Exception as e:\n        raise ValueError(\"Could not save file {0}.\".format(nifti_filename))\n    return nifti_filename", "response": "Exports a numpy array to a nifti file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ping(self, suffix='public_tokens/'):\n        return self.remote_utils.ping(super(neuroRemote, self).url(), suffix)", "response": "Ping the API endpoint and return the status - code of the API."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef url(self, suffix=\"\"):\n        return super(neuroRemote,\n                     self).url('{}/'.format(self._ext) + suffix)", "response": "Returns a constructed URL appending an optional suffix to the end of the URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrequest a list of next available ID s from the server.", "response": "def reserve_ids(self, token, channel, quantity):\n        \"\"\"\n        Requests a list of next-available-IDs from the server.\n\n        Arguments:\n            quantity (int): The number of IDs to reserve\n\n        Returns:\n            int[quantity]: List of IDs you've been granted\n        \"\"\"\n        quantity = str(quantity)\n        url = self.url(\"{}/{}/reserve/{}/\".format(token, channel, quantity))\n        req = self.remote_utils.get_url(url)\n        if req.status_code is not 200:\n            raise RemoteDataNotFoundError('Invalid req: ' + req.status_code)\n        out = req.json()\n        return [out[0] + i for i in range(out[1])]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge_ids(self, token, channel, ids, delete=False):\n        url = self.url() + \"/merge/{}/\".format(','.join([str(i) for i in ids]))\n        req = self.remote_utils.get_url(url)\n        if req.status_code is not 200:\n            raise RemoteDataUploadError('Could not merge ids {}'.format(\n                                        ','.join([str(i) for i in ids])))\n        if delete:\n            self.delete_ramon(token, channel, ids[1:])\n        return True", "response": "This method merges two RAMON objects into one."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_channels(self, dataset, token, new_channels_data):\n        channels = {}\n        for channel_new in new_channels_data:\n\n            self._check_channel(channel_new.name)\n\n            if channel_new.channel_type not in ['image', 'annotation']:\n                raise ValueError('Channel type must be ' +\n                                 'neuroRemote.IMAGE or ' +\n                                 'neuroRemote.ANNOTATION.')\n\n            if channel_new.readonly * 1 not in [0, 1]:\n                raise ValueError(\"readonly must be 0 (False) or 1 (True).\")\n\n            channels[channel_new.name] = {\n                \"channel_name\": channel_new.name,\n                \"channel_type\": channel_new.channel_type,\n                \"datatype\": channel_new.dtype,\n                \"readonly\": channel_new.readonly * 1\n            }\n        req = requests.post(self.url(\"/{}/project/\".format(dataset) +\n                                     \"{}\".format(token)),\n                            json={\"channels\": {channels}}, verify=False)\n\n        if req.status_code is not 201:\n            raise RemoteDataUploadError('Could not upload {}'.format(req.text))\n        else:\n            return True", "response": "Creates channels given a dictionary in new_channels_data dataset name and token."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef propagate(self, token, channel):\n        if self.get_propagate_status(token, channel) != u'0':\n            return\n        url = self.url('sd/{}/{}/setPropagate/1/'.format(token, channel))\n        req = self.remote_utils.get_url(url)\n        if req.status_code is not 200:\n            raise RemoteDataUploadError('Propagate fail: {}'.format(req.text))\n        return True", "response": "Kick off the propagate function on the remote server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the propagate status for a token / channel pair.", "response": "def get_propagate_status(self, token, channel):\n        \"\"\"\n        Get the propagate status for a token/channel pair.\n\n        Arguments:\n            token (str): The token to check\n            channel (str): The channel to check\n\n        Returns:\n            str: The status code\n        \"\"\"\n        url = self.url('sd/{}/{}/getPropagate/'.format(token, channel))\n        req = self.remote_utils.get_url(url)\n        if req.status_code is not 200:\n            raise ValueError('Bad pair: {}/{}'.format(token, channel))\n        return req.text"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new project with the given parameters.", "response": "def create_project(self,\n                       project_name,\n                       dataset_name,\n                       hostname,\n                       is_public,\n                       s3backend=0,\n                       kvserver='localhost',\n                       kvengine='MySQL',\n                       mdengine='MySQL',\n                       description=''):\n        \"\"\"\n        Creates a project with the given parameters.\n\n        Arguments:\n            project_name (str): Project name\n            dataset_name (str): Dataset name project is based on\n            hostname (str): Hostname\n            s3backend (str): S3 region to save the data in\n            is_public (int): 1 is public. 0 is not public.\n            kvserver (str): Server to store key value pairs in\n            kvengine (str): Database to store key value pairs in\n            mdengine (str): ???\n            description (str): Description for your project\n\n        Returns:\n            bool: True if project created, false if not created.\n        \"\"\"\n        url = self.url() + \"/resource/dataset/{}\".format(\n            dataset_name) + \"/project/{}/\".format(project_name)\n\n        json = {\n            \"project_name\": project_name,\n            \"host\": hostname,\n            \"s3backend\": s3backend,\n            \"public\": is_public,\n            \"kvserver\": kvserver,\n            \"kvengine\": kvengine,\n            \"mdengine\": mdengine,\n            \"project_description\": description\n        }\n\n        req = self.remote_utils.post_url(url, json=json)\n\n        if req.status_code is not 201:\n            raise RemoteDataUploadError('Could not upload {}'.format(req))\n        if req.content == \"\" or req.content == b'':\n\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_projects(self, dataset_name):\n        url = self.url() + \"/nd/resource/dataset/{}\".format(dataset_name)\\\n            + \"/project/\"\n\n        req = self.remote_utils.get_url(url)\n\n        if req.status_code is not 200:\n            raise RemoteDataNotFoundError('Could not find {}'.format(req.text))\n        else:\n            return req.json()", "response": "Lists a set of projects related to a dataset."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_token(self,\n                     token_name,\n                     project_name,\n                     dataset_name,\n                     is_public):\n        \"\"\"\n        Creates a token with the given parameters.\n        Arguments:\n            project_name (str): Project name\n            dataset_name (str): Dataset name project is based on\n            token_name (str): Token name\n            is_public (int): 1 is public. 0 is not public\n        Returns:\n            bool: True if project created, false if not created.\n        \"\"\"\n        url = self.url() + '/nd/resource/dataset/{}'.format(\n            dataset_name) + '/project/{}'.format(project_name) + \\\n            '/token/{}/'.format(token_name)\n\n        json = {\n            \"token_name\": token_name,\n            \"public\": is_public\n        }\n\n        req = self.remote_utils.post_url(url, json=json)\n\n        if req.status_code is not 201:\n            raise RemoteDataUploadError('Cout not upload {}:'.format(req.text))\n        if req.content == \"\" or req.content == b'':\n            return True\n        else:\n            return False", "response": "Creates a token with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_token(self,\n                  token_name,\n                  project_name,\n                  dataset_name):\n        \"\"\"\n        Get a token with the given parameters.\n        Arguments:\n            project_name (str): Project name\n            dataset_name (str): Dataset name project is based on\n            token_name (str): Token name\n        Returns:\n            dict: Token info\n        \"\"\"\n        url = self.url() + \"/nd/resource/dataset/{}\".format(dataset_name)\\\n            + \"/project/{}\".format(project_name)\\\n            + \"/token/{}/\".format(token_name)\n        req = self.remote_utils.get_url(url)\n\n        if req.status_code is not 200:\n            raise RemoteDataUploadError('Could not find {}'.format(req.text))\n        else:\n            return req.json()", "response": "Get a token with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_token(self,\n                     token_name,\n                     project_name,\n                     dataset_name):\n        \"\"\"\n        Delete a token with the given parameters.\n        Arguments:\n            project_name (str): Project name\n            dataset_name (str): Dataset name project is based on\n            token_name (str): Token name\n            channel_name (str): Channel name project is based on\n        Returns:\n            bool: True if project deleted, false if not deleted.\n        \"\"\"\n        url = self.url() + \"/nd/resource/dataset/{}\".format(dataset_name)\\\n            + \"/project/{}\".format(project_name)\\\n            + \"/token/{}/\".format(token_name)\n        req = self.remote_utils.delete_url(url)\n\n        if req.status_code is not 204:\n            raise RemoteDataUploadError(\"Could not delete {}\".format(req.text))\n        if req.content == \"\" or req.content == b'':\n            return True\n        else:\n            return False", "response": "Delete a token with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of public tokens that are public in Neurodata.", "response": "def list_tokens(self):\n        \"\"\"\n        Lists a set of tokens that are public in Neurodata.\n        Arguments:\n        Returns:\n            dict: Public tokens found in Neurodata\n        \"\"\"\n        url = self.url() + \"/nd/resource/public/token/\"\n        req = self.remote_utils.get_url(url)\n\n        if req.status_code is not 200:\n            raise RemoteDataNotFoundError('Coud not find {}'.format(req.text))\n        else:\n            return req.json()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new dataset in the resource.", "response": "def create_dataset(self,\n                       name,\n                       x_img_size,\n                       y_img_size,\n                       z_img_size,\n                       x_vox_res,\n                       y_vox_res,\n                       z_vox_res,\n                       x_offset=0,\n                       y_offset=0,\n                       z_offset=0,\n                       scaling_levels=0,\n                       scaling_option=0,\n                       dataset_description=\"\",\n                       is_public=0):\n        \"\"\"\n        Creates a dataset.\n\n        Arguments:\n            name (str): Name of dataset\n            x_img_size (int): max x coordinate of image size\n            y_img_size (int): max y coordinate of image size\n            z_img_size (int): max z coordinate of image size\n            x_vox_res (float): x voxel resolution\n            y_vox_res (float): y voxel resolution\n            z_vox_res (float): z voxel resolution\n            x_offset (int): x offset amount\n            y_offset (int): y offset amount\n            z_offset (int): z offset amount\n            scaling_levels (int): Level of resolution scaling\n            scaling_option (int): Z slices is 0 or Isotropic is 1\n            dataset_description (str): Your description of the dataset\n            is_public (int): 1 'true' or 0 'false' for viewability of data set\n                in public\n\n        Returns:\n            bool: True if dataset created, False if not\n        \"\"\"\n        url = self.url() + \"/resource/dataset/{}\".format(name)\n        json = {\n            \"dataset_name\": name,\n            \"ximagesize\": x_img_size,\n            \"yimagesize\": y_img_size,\n            \"zimagesize\": z_img_size,\n            \"xvoxelres\": x_vox_res,\n            \"yvoxelres\": y_vox_res,\n            \"zvoxelres\": z_vox_res,\n            \"xoffset\": x_offset,\n            \"yoffset\": y_offset,\n            \"zoffset\": z_offset,\n            \"scalinglevels\": scaling_levels,\n            \"scalingoption\": scaling_option,\n            \"dataset_description\": dataset_description,\n            \"public\": is_public\n        }\n        req = self.remote_utils.post_url(url, json=json)\n\n        if req.status_code is not 201:\n            raise RemoteDataUploadError('Could not upload {}'.format(req.text))\n        if req.content == \"\" or req.content == b'':\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_dataset(self, name):\n        url = self.url() + \"/resource/dataset/{}\".format(name)\n        req = self.remote_utils.get_url(url)\n\n        if req.status_code is not 200:\n            raise RemoteDataNotFoundError('Could not find {}'.format(req.text))\n        else:\n            return req.json()", "response": "Returns info regarding a particular dataset."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_datasets(self, get_global_public):\n        appending = \"\"\n        if get_global_public:\n            appending = \"public\"\n        url = self.url() + \"/resource/{}dataset/\".format(appending)\n        req = self.remote_utils.get_url(url)\n\n        if req.status_code is not 200:\n            raise RemoteDataNotFoundError('Could not find {}'.format(req.text))\n        else:\n            return req.json()", "response": "Returns a list of datasets in resources."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_dataset(self, name):\n        url = self.url() + \"/resource/dataset/{}\".format(name)\n        req = self.remote_utils.delete_url(url)\n\n        if req.status_code is not 204:\n            raise RemoteDataUploadError('Could not delete {}'.format(req.text))\n        if req.content == \"\" or req.content == b'':\n            return True\n        else:\n            return False", "response": "Delete a single dataset from the remote data upload."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_channel(self,\n                       channel_name,\n                       project_name,\n                       dataset_name,\n                       channel_type,\n                       dtype,\n                       startwindow,\n                       endwindow,\n                       readonly=0,\n                       start_time=0,\n                       end_time=0,\n                       propagate=0,\n                       resolution=0,\n                       channel_description=''):\n        \"\"\"\n        Create a new channel on the Remote, using channel_data.\n\n        Arguments:\n            channel_name (str): Channel name\n            project_name (str): Project name\n            dataset_name (str): Dataset name\n            channel_type (str): Type of the channel (e.g. `neurodata.IMAGE`)\n            dtype (str): The datatype of the channel's data (e.g. `uint8`)\n            startwindow (int): Window to start in\n            endwindow (int): Window to end in\n            readonly (int): Can others write to this channel?\n            propagate (int): Allow propogation? 1 is True, 0 is False\n            resolution (int): Resolution scaling\n            channel_description (str): Your description of the channel\n\n        Returns:\n            bool: `True` if successful, `False` otherwise.\n\n        Raises:\n            ValueError: If your args were bad :(\n            RemoteDataUploadError: If the channel data is valid but upload\n                fails for some other reason.\n        \"\"\"\n        self._check_channel(channel_name)\n\n        if channel_type not in ['image', 'annotation', 'timeseries']:\n            raise ValueError('Channel type must be ' +\n                             'neurodata.IMAGE or neurodata.ANNOTATION.')\n\n        if readonly * 1 not in [0, 1]:\n            raise ValueError(\"readonly must be 0 (False) or 1 (True).\")\n\n        # Good job! You supplied very nice arguments.\n\n        url = self.url() + \"/nd/resource/dataset/{}\".format(dataset_name)\\\n            + \"/project/{}\".format(project_name) + \\\n            \"/channel/{}/\".format(channel_name)\n        json = {\n            \"channel_name\": channel_name,\n            \"channel_type\": channel_type,\n            \"channel_datatype\": dtype,\n            \"startwindow\": startwindow,\n            \"endwindow\": endwindow,\n            'starttime': start_time,\n            'endtime': end_time,\n            'readonly': readonly,\n            'propagate': propagate,\n            'resolution': resolution,\n            'channel_description': channel_description\n        }\n        req = self.remote_utils.post_url(url, json=json)\n\n        if req.status_code is not 201:\n            raise RemoteDataUploadError('Could not upload {}'.format(req.text))\n        if req.content == \"\" or req.content == b'':\n            return True\n        else:\n            return False", "response": "This method creates a new channel on the Remote."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget info about a channel given its name project name and dataset name.", "response": "def get_channel(self, channel_name, project_name, dataset_name):\n        \"\"\"\n        Gets info about a channel given its name, name of its project\n        , and name of its dataset.\n\n        Arguments:\n            channel_name (str): Channel name\n            project_name (str): Project name\n            dataset_name (str): Dataset name\n\n        Returns:\n            dict: Channel info\n        \"\"\"\n        url = self.url() + \"/nd/resource/dataset/{}\".format(dataset_name)\\\n            + \"/project/{}\".format(project_name) + \\\n            \"/channel/{}/\".format(channel_name)\n\n        req = self.remote_utils.get_url(url)\n\n        if req.status_code is not 200:\n            raise RemoteDataNotFoundError('Could not find {}'.format(req.text))\n        else:\n            return req.json()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing details for all workspaces.", "response": "def show_all(self):\n        \"\"\"Show details for all workspaces.\"\"\"\n        for ws in self.workspace.list().keys():\n            self.show_workspace(ws)\n            print(\"\\n\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the base URL of the Remote.", "response": "def url(self, endpoint=''):\n        \"\"\"\n        Get the base URL of the Remote.\n\n        Arguments:\n            None\n        Returns:\n            `str` base URL\n        \"\"\"\n        if not endpoint.startswith('/'):\n            endpoint = \"/\" + endpoint\n        return self.protocol + \"://\" + self.hostname + endpoint"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nping the server to make sure that you can access the base URL.", "response": "def ping(self, endpoint=''):\n        \"\"\"\n        Ping the server to make sure that you can access the base URL.\n\n        Arguments:\n            None\n        Returns:\n            `boolean` Successful access of server (or status code)\n        \"\"\"\n        r = requests.get(self.url() + \"/\" + endpoint)\n        return r.status_code"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef export_dae(filename, cutout, level=0):\n    if \".dae\" not in filename:\n        filename = filename + \".dae\"\n\n    vs, fs = mcubes.marching_cubes(cutout, level)\n    mcubes.export_mesh(vs, fs, filename, \"ndioexport\")", "response": "Converts a dense annotation to a DAE using Marching Cubes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef export_obj(filename, cutout, level=0):\n    if \".obj\" not in filename:\n        filename = filename + \".obj\"\n\n    vs, fs = mcubes.marching_cubes(cutout, level)\n    mcubes.export_obj(vs, fs, filename)", "response": "Converts a dense annotation to a obj using Marching Cubes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexport a dense annotation to a. PLY file.", "response": "def export_ply(filename, cutout, level=0):\n    \"\"\"\n    Converts a dense annotation to a .PLY, using Marching Cubes (PyMCubes).\n\n    Arguments:\n        filename (str): The filename to write out to\n        cutout (numpy.ndarray): The dense annotation\n        level (int): The level at which to run mcubes\n\n    Returns:\n        boolean success\n    \"\"\"\n    if \".ply\" not in filename:\n        filename = filename + \".ply\"\n\n    vs, fs = mcubes.marching_cubes(cutout, level)\n\n    with open(filename, 'w') as fh:\n        lines = [\n            \"ply\"\n            \"format ascii 1.0\",\n            \"comment generated by ndio\",\n            \"element vertex \" + str(len(vs)),\n            \"property float32 x\",\n            \"property float32 y\",\n            \"property float32 z\",\n            \"element face \" + str(len(fs)),\n            \"property list uint8 int32 vertex_index\",\n            \"end_header\"\n        ]\n        fh.writelines(lines)\n        for v in vs:\n            fh.write(\"{} {} {}\".format(v[0], v[1], v[2]))\n        for f in fs:\n            fh.write(\"3 {} {} {}\".format(f[0], f[1], f[2]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nguesses the appropriate data type from the file extension.", "response": "def _guess_format_from_extension(ext):\n    \"\"\"\n    Guess the appropriate data type from file extension.\n\n    Arguments:\n        ext:        The file extension (period optional)\n\n    Returns:\n        String. The format (without leading period),\n                or False if none was found or couldn't be guessed\n    \"\"\"\n    ext = ext.strip('.')\n\n    # We look through FILE_FORMATS for this extension.\n    # - If it appears zero times, return False. We can't guess.\n    # - If it appears once, we can simply return that format.\n    # - If it appears more than once, we can't guess (it's ambiguous,\n    #   e.g .m = RAMON or MATLAB)\n\n    formats = []\n    for fmt in FILE_FORMATS:\n        if ext in FILE_FORMATS[fmt]:\n            formats.append(fmt)\n\n    if formats == [] or len(formats) > 1:\n        return False\n\n    return formats[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread in a file from disk and returns a numpy array of the next available node.", "response": "def open(in_file, in_fmt=None):\n    \"\"\"\n    Reads in a file from disk.\n\n    Arguments:\n        in_file: The name of the file to read in\n        in_fmt: The format of in_file, if you want to be explicit\n\n    Returns:\n        numpy.ndarray\n    \"\"\"\n    fmt = in_file.split('.')[-1]\n    if in_fmt:\n        fmt = in_fmt\n    fmt = fmt.lower()\n\n    if fmt in ['png', 'jpg', 'tiff', 'tif', 'jpeg']:\n        return Image.open(in_file)\n    else:\n        raise NotImplementedError(\"Cannot open file of type {fmt}\".format(fmt))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a single file into another file.", "response": "def convert(in_file, out_file, in_fmt=\"\", out_fmt=\"\"):\n    \"\"\"\n    Converts in_file to out_file, guessing datatype in the absence of\n    in_fmt and out_fmt.\n\n    Arguments:\n        in_file:    The name of the (existing) datafile to read\n        out_file:   The name of the file to create with converted data\n        in_fmt:     Optional. The format of incoming data, if not guessable\n        out_fmt:    Optional. The format of outgoing data, if not guessable\n\n    Returns:\n        String. Output filename\n    \"\"\"\n    # First verify that in_file exists and out_file doesn't.\n    in_file = os.path.expanduser(in_file)\n    out_file = os.path.expanduser(out_file)\n\n    if not os.path.exists(in_file):\n        raise IOError(\"Input file {0} does not exist, stopping...\"\n                      .format(in_file))\n\n    # Get formats, either by explicitly naming them or by guessing.\n    # TODO: It'd be neat to check here if an explicit fmt matches the guess.\n    in_fmt = in_fmt.lower() or _guess_format_from_extension(\n        in_file.split('.')[-1].lower())\n    out_fmt = out_fmt.lower() or _guess_format_from_extension(\n        out_file.split('.')[-1].lower())\n\n    if not in_fmt or not out_fmt:\n        raise ValueError(\"Cannot determine conversion formats.\")\n        return False\n\n    if in_fmt is out_fmt:\n        # This is the case when this module (intended for LONI) is used\n        # indescriminately to 'funnel' data into one format.\n        shutil.copyfileobj(in_file, out_file)\n        return out_file\n\n    # Import\n    if in_fmt == 'hdf5':\n        from . import hdf5\n        data = hdf5.load(in_file)\n    elif in_fmt == 'tiff':\n        from . import tiff\n        data = tiff.load(in_file)\n    elif in_fmt == 'png':\n        from . import png\n        data = png.load(in_file)\n    else:\n        return _fail_pair_conversion(in_fmt, out_fmt)\n\n    # Export\n    if out_fmt == 'hdf5':\n        from . import hdf5\n        return hdf5.save(out_file, data)\n    elif out_fmt == 'tiff':\n        from . import tiff\n        return tiff.save(out_file, data)\n    elif out_fmt == 'png':\n        from . import png\n        return png.export_png(out_file, data)\n    else:\n        return _fail_pair_conversion(in_fmt, out_fmt)\n\n    return _fail_pair_conversion(in_fmt, out_fmt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_graph(self, project, site, subject, session, scan,\n                    size, email=None, invariants=Invariants.ALL,\n                    fiber_file=DEFAULT_FIBER_FILE, atlas_file=None,\n                    use_threads=False, callback=None):\n        \"\"\"\n        Builds a graph using the graph-services endpoint.\n\n        Arguments:\n            project (str): The project to use\n            site (str): The site in question\n            subject (str): The subject's identifier\n            session (str): The session (per subject)\n            scan (str): The scan identifier\n            size (str): Whether to return a big (grute.BIG) or small\n                (grute.SMALL) graph. For a better explanation, see m2g.io.\n            email (str : self.email)*: An email to notify\n            invariants (str[]: Invariants.ALL)*: An array of invariants to\n                compute. You can use the grute.Invariants class to construct a\n                list, or simply pass grute.Invariants.ALL to compute them all.\n            fiber_file (str: DEFAULT_FIBER_FILE)*: A local filename of an\n                MRI Studio .dat file\n            atlas_file (str: None)*: A local atlas file, in NIFTI .nii format.\n                If none is specified, the Desikan atlas is used by default.\n            use_threads (bool: False)*: Whether to run the download in a Python\n                thread. If set to True, the call to `build_graph` will end\n                quickly, and the `callback` will be called with the returned\n                status-code of the restful call as its only argument.\n            callback (function: None)*: The function to run upon completion of\n                the call, if using threads. (Will not be called if use_threads\n                is set to False.)\n\n        Returns:\n            HTTP Response if use_threads is False. Otherwise, None\n\n        Raises:\n            ValueError: When the supplied values are invalid (contain invalid\n                characters, bad email address supplied, etc.)\n            RemoteDataNotFoundError: When the data cannot be processed due to\n                a server error.\n        \"\"\"\n        if email is None:\n            email = self.email\n\n        if not set(invariants) <= set(Invariants.ALL):\n            raise ValueError(\"Invariants must be a subset of Invariants.ALL.\")\n\n        if use_threads and callback is not None:\n            if not hasattr(callback, '__call__'):\n                raise ValueError(\"callback must be a function.\")\n            if len(inspect.getargspec(callback).args) != 1:\n                raise ValueError(\"callback must take exactly 1 argument.\")\n\n        # Once we get here, we know the callback is\n        if size not in [self.BIG, self.SMALL]:\n            raise ValueError(\"size must be either grute.BIG or grute.SMALL.\")\n\n        url = \"buildgraph/{}/{}/{}/{}/{}/{}/{}/{}/\".format(\n            project,\n            site,\n            subject,\n            session,\n            scan,\n            size,\n            email,\n            \"/\".join(invariants)\n        )\n\n        if \" \" in url:\n            raise ValueError(\"Arguments must not contain spaces.\")\n\n        if use_threads:\n            # Run in the background.\n            download_thread = threading.Thread(\n                target=self._run_build_graph,\n                args=[url, fiber_file, atlas_file, callback]\n            )\n            download_thread.start()\n        else:\n            # Run in the foreground.\n            return self._run_build_graph(url, fiber_file, atlas_file)\n        return", "response": "Builds a graph from the graph - services endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute invariants from an existing GraphML file using the remote grute graph services. Arguments: graph_file (str): The filename of the graphml file input_format (str): One of grute.GraphFormats invariants (str[]: Invariants.ALL)*: An array of grute.Invariants to compute on the graph email (str: self.email)*: The email to notify upon completion use_threads (bool: False)*: Whether to use Python threads to run computation in the background when waiting for the server to return the invariants callback (function: None)*: The function to run upon completion of the call, if using threads. (Will not be called if use_threads is set to False.) Returns: HTTP Response if use_threads is False. Otherwise, None Raises: ValueError: If the graph file does not exist, or if there are issues with the passed arguments RemoteDataUploadError: If there is an issue packing the file RemoteError: If the server experiences difficulty computing invs", "response": "def compute_invariants(self, graph_file, input_format,\n                           invariants=Invariants.ALL, email=None,\n                           use_threads=False, callback=None):\n        \"\"\"\n        Compute invariants from an existing GraphML file using the remote\n        grute graph services.\n\n        Arguments:\n            graph_file (str): The filename of the graphml file\n            input_format (str): One of grute.GraphFormats\n            invariants (str[]: Invariants.ALL)*: An array of grute.Invariants\n                to compute on the graph\n            email (str: self.email)*: The email to notify upon completion\n            use_threads (bool: False)*: Whether to use Python threads to run\n                computation in the background when waiting for the server to\n                return the invariants\n            callback (function: None)*: The function to run upon completion of\n                the call, if using threads. (Will not be called if use_threads\n                is set to False.)\n\n        Returns:\n            HTTP Response if use_threads is False. Otherwise, None\n\n        Raises:\n            ValueError: If the graph file does not exist, or if there are\n                issues with the passed arguments\n            RemoteDataUploadError: If there is an issue packing the file\n            RemoteError: If the server experiences difficulty computing invs\n        \"\"\"\n        if email is None:\n            email = self.email\n\n        if input_format not in GraphFormats._any:\n            raise ValueError(\"Invalid input format, {}.\".format(input_format))\n\n        if not set(invariants) <= set(Invariants.ALL):\n            raise ValueError(\"Invariants must be a subset of Invariants.ALL.\")\n\n        if use_threads and callback is not None:\n            if not hasattr(callback, '__call__'):\n                raise ValueError(\"callback must be a function.\")\n            if len(inspect.getargspec(callback).args) != 1:\n                raise ValueError(\"callback must take exactly 1 argument.\")\n\n        url = \"graphupload/{}/{}/{}/\".format(\n            email,\n            input_format,\n            \"/\".join(invariants)\n        )\n\n        if \" \" in url:\n            raise ValueError(\"Arguments cannot have spaces in them.\")\n\n        if not (os.path.exists(graph_file)):\n            raise ValueError(\"File {} does not exist.\".format(graph_file))\n\n        if use_threads:\n            # Run in the background.\n            upload_thread = threading.Thread(\n                target=self._run_compute_invariants,\n                args=[url, graph_file, callback]\n            )\n            upload_thread.start()\n\n        else:\n            # Run in the foreground.\n            return self._run_compute_invariants(url, graph_file)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a graph from one GraphFormat to another.", "response": "def convert_graph(self, graph_file, input_format, output_formats,\n                      email=None, use_threads=False, callback=None):\n        \"\"\"\n        Convert a graph from one GraphFormat to another.\n\n        Arguments:\n            graph_file (str): Filename of the file to convert\n            input_format (str): A grute.GraphFormats\n            output_formats (str[]): A grute.GraphFormats\n            email (str: self.email)*: The email to notify\n            use_threads (bool: False)*: Whether to use Python threads to run\n                computation in the background when waiting for the server\n            callback (function: None)*: The function to run upon completion of\n                the call, if using threads. (Will not be called if use_threads\n                is set to False.)\n\n        Returns:\n            HTTP Response if use_threads=False. Else, no return value.\n\n        Raises:\n            RemoteDataUploadError: If there's an issue uploading the data\n            RemoteError: If there's a server-side issue\n            ValueError: If there's a problem with the supplied arguments\n        \"\"\"\n        if email is None:\n            email = self.email\n\n        if input_format not in GraphFormats._any:\n            raise ValueError(\"Invalid input format {}.\".format(input_format))\n\n        if not set(output_formats) <= set(GraphFormats._any):\n            raise ValueError(\"Output formats must be a GraphFormats.\")\n\n        if use_threads and callback is not None:\n            if not hasattr(callback, '__call__'):\n                raise ValueError(\"callback must be a function.\")\n            if len(inspect.getargspec(callback).args) != 1:\n                raise ValueError(\"callback must take exactly 1 argument.\")\n\n        if not (os.path.exists(graph_file)):\n            raise ValueError(\"No such file, {}!\".format(graph_file))\n\n        url = \"convert/{}/{}/{}/l\".format(\n            email,\n            input_format,\n            ','.join(output_formats)\n        )\n\n        if \" \" in url:\n            raise ValueError(\"Spaces are not permitted in arguments.\")\n\n        if use_threads:\n            # Run in the background.\n            convert_thread = threading.Thread(\n                target=self._run_convert_graph,\n                args=[url, graph_file, callback]\n            )\n            convert_thread.start()\n        else:\n            # Run in the foreground.\n            return self._run_convert_graph(url, graph_file)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_dict(ramons, flatten=False):\n    if type(ramons) is not list:\n        ramons = [ramons]\n\n    out_ramons = {}\n    for r in ramons:\n        out_ramons[r.id] = {\n            \"id\": r.id,\n            \"type\": _reverse_ramon_types[type(r)],\n            \"metadata\": vars(r)\n        }\n    return out_ramons", "response": "Converts a list of RAMON objects to a JSON - style dictionary. Useful for going\n    from an array of RAMON objects to a dictionary. Useful for going\n    from an array of RAMON objects to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_json(ramons, flatten=False):\n    if type(ramons) is not list:\n        ramons = [ramons]\n\n    out_ramons = {}\n    for r in ramons:\n        out_ramons[r.id] = {\n            \"id\": r.id,\n            \"type\": _reverse_ramon_types[type(r)],\n            \"metadata\": vars(r)\n        }\n\n    if flatten:\n        return jsonlib.dumps(out_ramons.values()[0])\n\n    return jsonlib.dumps(out_ramons)", "response": "Converts a list of RAMON objects into a JSON string which can be directly written out\n    to a. json file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_json(json, cutout=None):\n    if type(json) is str:\n        json = jsonlib.loads(json)\n\n    out_ramons = []\n    for (rid, rdata) in six.iteritems(json):\n        _md = rdata['metadata']\n        r = AnnotationType.RAMON(rdata['type'])(\n            id=rid,\n            author=_md['author'],\n            status=_md['status'],\n            confidence=_md['confidence'],\n            kvpairs=copy.deepcopy(_md['kvpairs'])\n        )\n\n        if rdata['type'] == 'segment':\n            r.segmentclass = _md.get('segmentclass')\n            r.neuron = _md.get('neuron')\n            if 'synapses' in _md:\n                r.synapses = _md['synapses'][:]\n            if 'organelles' in _md:\n                r.organelles = _md['organelles'][:]\n\n        elif rdata['type'] in ['neuron', 'synapse']:\n            if 'segments' in _md:\n                r.segments = _md['segments'][:]\n\n        elif rdata['type'] == 'organelle':\n            r.organelle_class = _md['organelleclass'][:]\n\n        elif rdata['type'] == 'synapse':\n            r.synapse_type = _md.get('synapse_type')\n            r.weight = _md.get('weight')\n\n        out_ramons.append(r)\n\n    return out_ramons", "response": "Converts a JSON string to a list of RAMON objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_hdf5(hdf5, anno_id=None):\n    if anno_id is None:\n        # The user just wants the first item we find, so... Yeah.\n        return from_hdf5(hdf5, list(hdf5.keys())[0])\n\n    # First, get the actual object we're going to download.\n    anno_id = str(anno_id)\n    if anno_id not in list(hdf5.keys()):\n        raise ValueError(\"ID {} is not in this file. Options are: {}\".format(\n            anno_id,\n            \", \".join(list(hdf5.keys()))\n        ))\n\n    anno = hdf5[anno_id]\n    # anno now holds just the RAMON of interest\n\n    # This is the most complicated line in here: It creates an object whose\n    # type is conditional on the ANNOTATION_TYPE of the hdf5 object.\n    try:\n        r = AnnotationType.get_class(anno['ANNOTATION_TYPE'][0])()\n    except:\n        raise InvalidRAMONError(\"This is not a valid RAMON type.\")\n\n    # All RAMON types definitely have these attributes:\n    metadata = anno['METADATA']\n    r.author = metadata['AUTHOR'][0]\n    r.confidence = metadata['CONFIDENCE'][0]\n    r.status = metadata['STATUS'][0]\n    r.id = anno_id\n\n    # These are a little tougher, some RAMON types have special attributes:\n\n    if type(r) in [RAMONNeuron, RAMONSynapse]:\n        r.segments = metadata['SEGMENTS'][()]\n\n    if 'KVPAIRS' in metadata:\n        kvs = metadata['KVPAIRS'][()][0].split()\n        if len(kvs) != 0:\n\n            for i in kvs:\n                k, v = str(i).split(',')\n                r.kvpairs[str(k)] = str(v)\n        else:\n            r.kvpairs = {}\n\n    if issubclass(type(r), RAMONVolume):\n        if 'CUTOUT' in anno:\n            r.cutout = anno['CUTOUT'][()]\n        if 'XYZOFFSET' in anno:\n            r.cutout = anno['XYZOFFSET'][()]\n        if 'RESOLUTION' in anno:\n            r.cutout = anno['RESOLUTION'][()]\n\n    if type(r) is RAMONSynapse:\n        r.synapse_type = metadata['SYNAPSE_TYPE'][0]\n        r.weight = metadata['WEIGHT'][0]\n\n    if type(r) is RAMONSegment:\n        if 'NEURON' in metadata:\n            r.neuron = metadata['NEURON'][0]\n        if 'PARENTSEED' in metadata:\n            r.parent_seed = metadata['PARENTSEED'][0]\n        if 'SEGMENTCLASS' in metadata:\n            r.segmentclass = metadata['SEGMENTCLASS'][0]\n        if 'SYNAPSES' in metadata:\n            r.synapses = metadata['SYNAPSES'][()]\n        if 'ORGANELLES' in metadata:\n            r.organelles = metadata['ORGANELLES'][()]\n\n    if type(r) is RAMONOrganelle:\n        r.organelle_class = metadata['ORGANELLECLASS'][0]\n\n    return r", "response": "Converts an hdf5 file to a RAMON object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexporting a RAMON object to an HDF5 file object.", "response": "def to_hdf5(ramon, hdf5=None):\n    \"\"\"\n    Exports a RAMON object to an HDF5 file object.\n\n    Arguments:\n        ramon (RAMON): A subclass of RAMONBase\n        hdf5 (str): Export filename\n\n    Returns:\n        hdf5.File\n\n    Raises:\n        InvalidRAMONError: if you pass a non-RAMON object\n    \"\"\"\n    if issubclass(type(ramon), RAMONBase) is False:\n        raise InvalidRAMONError(\"Invalid RAMON supplied to ramon.to_hdf5.\")\n\n    import h5py\n    import numpy\n\n    if hdf5 is None:\n        tmpfile = tempfile.NamedTemporaryFile(delete=False)\n    else:\n        tmpfile = hdf5\n\n    with h5py.File(tmpfile.name, \"a\") as hdf5:\n\n        # First we'll export things that all RAMON objects have in\n        # common, starting with the Group that encompasses each ID:\n        grp = hdf5.create_group(str(ramon.id))\n\n        grp.create_dataset(\"ANNOTATION_TYPE\", (1,),\n                           numpy.uint32,\n                           data=AnnotationType.get_int(type(ramon)))\n\n        if hasattr(ramon, 'cutout'):\n            if ramon.cutout is not None:\n                grp.create_dataset('CUTOUT', ramon.cutout.shape,\n                                   ramon.cutout.dtype, data=ramon.cutout)\n                grp.create_dataset('RESOLUTION', (1,),\n                                   numpy.uint32, data=ramon.resolution)\n                grp.create_dataset('XYZOFFSET', (3,),\n                                   numpy.uint32, data=ramon.xyz_offset)\n\n        # Next, add general metadata.\n        metadata = grp.create_group('METADATA')\n\n        metadata.create_dataset('AUTHOR', (1,),\n                                dtype=h5py.special_dtype(vlen=str),\n                                data=ramon.author)\n\n        fstring = StringIO()\n        csvw = csv.writer(fstring, delimiter=',')\n        csvw.writerows([r for r in six.iteritems(ramon.kvpairs)])\n\n        metadata.create_dataset('KVPAIRS', (1,),\n                                dtype=h5py.special_dtype(vlen=str),\n                                data=fstring.getvalue())\n        metadata.create_dataset('CONFIDENCE', (1,), numpy.float,\n                                data=ramon.confidence)\n        metadata.create_dataset('STATUS', (1,), numpy.uint32,\n                                data=ramon.status)\n\n        # Finally, add type-specific metadata:\n\n        if hasattr(ramon, 'segments'):\n            metadata.create_dataset('SEGMENTS',\n                                    data=numpy.asarray(ramon.segments,\n                                                       dtype=numpy.uint32))\n\n        if hasattr(ramon, 'synapse_type'):\n            metadata.create_dataset('SYNAPSE_TYPE', (1,), numpy.uint32,\n                                    data=ramon.synapse_type)\n\n        if hasattr(ramon, 'weight'):\n            metadata.create_dataset('WEIGHT', (1,),\n                                    numpy.float, data=ramon.weight)\n\n        if hasattr(ramon, 'neuron'):\n            metadata.create_dataset('NEURON', (1,),\n                                    numpy.uint32, data=ramon.neuron)\n\n        if hasattr(ramon, 'segmentclass'):\n            metadata.create_dataset('SEGMENTCLASS', (1,), numpy.uint32,\n                                    data=ramon.segmentclass)\n\n        if hasattr(ramon, 'synapses'):\n            metadata.create_dataset('SYNAPSES', (len(ramon.synapses),),\n                                    numpy.uint32, data=ramon.synapses)\n\n        if hasattr(ramon, 'organelles'):\n            metadata.create_dataset('ORGANELLES',\n                                    (len(ramon.organelles),),\n                                    numpy.uint32,\n                                    data=ramon.organelles)\n\n        if hasattr(ramon, 'organelle_class'):\n            metadata.create_dataset('ORGANELLECLASS', (1,),\n                                    numpy.uint32,\n                                    data=ramon.organelle_class)\n        hdf5.flush()\n        tmpfile.seek(0)\n        return tmpfile\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef RAMON(typ):\n        if six.PY2:\n            lookup = [str, unicode]\n        elif six.PY3:\n            lookup = [str]\n\n        if type(typ) is int:\n            return _ramon_types[typ]\n        elif type(typ) in lookup:\n            return _ramon_types[_types[typ]]", "response": "Returns class type of a resource in RAMON."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a binary - encoded decompressed 2d image. You should provide a token channel pair. You should provide a channel image.", "response": "def get_xy_slice(self, token, channel,\n                     x_start, x_stop,\n                     y_start, y_stop,\n                     z_index,\n                     resolution=0):\n        \"\"\"\n        Return a binary-encoded, decompressed 2d image. You should\n        specify a 'token' and 'channel' pair.  For image data, users\n        should use the channel 'image.'\n\n        Arguments:\n            token (str): Token to identify data to download\n            channel (str): Channel\n            resolution (int): Resolution level\n            Q_start (int):` The lower bound of dimension 'Q'\n            Q_stop (int): The upper bound of dimension 'Q'\n            z_index (int): The z-slice to image\n\n        Returns:\n            str: binary image data\n        \"\"\"\n        return self.data.get_xy_slice(token, channel,\n                                      x_start, x_stop,\n                                      y_start, y_stop,\n                                      z_index,\n                                      resolution)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_volume(self, token, channel,\n                   x_start, x_stop,\n                   y_start, y_stop,\n                   z_start, z_stop,\n                   resolution=1,\n                   block_size=DEFAULT_BLOCK_SIZE,\n                   neariso=False):\n        \"\"\"\n        Get a RAMONVolume volumetric cutout from the neurodata server.\n\n        Arguments:\n            token (str): Token to identify data to download\n            channel (str): Channel\n            resolution (int): Resolution level\n            Q_start (int): The lower bound of dimension 'Q'\n            Q_stop (int): The upper bound of dimension 'Q'\n            block_size (int[3]): Block size of this dataset\n            neariso (bool : False): Passes the 'neariso' param to the cutout.\n                If you don't know what this means, ignore it!\n\n        Returns:\n            ndio.ramon.RAMONVolume: Downloaded data.\n        \"\"\"\n        return self.data.get_volume(token, channel,\n                                    x_start, x_stop,\n                                    y_start, y_stop,\n                                    z_start, z_stop,\n                                    resolution, block_size, neariso)", "response": "Get a RAMONVolume from the neurodata server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting volumetric cutout data from the neurodata server.", "response": "def get_cutout(self, token, channel,\n                   x_start, x_stop,\n                   y_start, y_stop,\n                   z_start, z_stop,\n                   t_start=0, t_stop=1,\n                   resolution=1,\n                   block_size=DEFAULT_BLOCK_SIZE,\n                   neariso=False):\n        \"\"\"\n        Get volumetric cutout data from the neurodata server.\n\n        Arguments:\n            token (str): Token to identify data to download\n            channel (str): Channel\n            resolution (int): Resolution level\n            Q_start (int): The lower bound of dimension 'Q'\n            Q_stop (int): The upper bound of dimension 'Q'\n            block_size (int[3]): Block size of this dataset. If not provided,\n                ndio uses the metadata of this tokenchannel to set. If you find\n                that your downloads are timing out or otherwise failing, it may\n                be wise to start off by making this smaller.\n            neariso (bool : False): Passes the 'neariso' param to the cutout.\n                If you don't know what this means, ignore it!\n\n        Returns:\n            numpy.ndarray: Downloaded data.\n        \"\"\"\n        return self.data.get_cutout(token, channel,\n                                    x_start, x_stop,\n                                    y_start, y_stop,\n                                    z_start, z_stop,\n                                    t_start, t_stop,\n                                    resolution,\n                                    block_size,\n                                    neariso)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef post_cutout(self, token, channel,\n                    x_start,\n                    y_start,\n                    z_start,\n                    data,\n                    resolution=0):\n        \"\"\"\n        Post a cutout to the server.\n\n        Arguments:\n            token (str)\n            channel (str)\n            x_start (int)\n            y_start (int)\n            z_start (int)\n            data (numpy.ndarray): A numpy array of data. Pass in (x, y, z)\n            resolution (int : 0): Resolution at which to insert the data\n\n        Returns:\n            bool: True on success\n\n        Raises:\n            RemoteDataUploadError: if there's an issue during upload.\n        \"\"\"\n        return self.data.post_cutout(token, channel,\n                                     x_start,\n                                     y_start,\n                                     z_start,\n                                     data,\n                                     resolution)", "response": "Post a cutout to the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new project with the given parameters.", "response": "def create_project(self,\n                       project_name,\n                       dataset_name,\n                       hostname,\n                       is_public,\n                       s3backend=0,\n                       kvserver='localhost',\n                       kvengine='MySQL',\n                       mdengine='MySQL',\n                       description=''):\n        \"\"\"\n        Creates a project with the given parameters.\n\n        Arguments:\n            project_name (str): Project name\n            dataset_name (str): Dataset name project is based on\n            hostname (str): Hostname\n            s3backend (str): S3 region to save the data in\n            is_public (int): 1 is public. 0 is not public.\n            kvserver (str): Server to store key value pairs in\n            kvengine (str): Database to store key value pairs in\n            mdengine (str): ???\n            description (str): Description for your project\n\n        Returns:\n            bool: True if project created, false if not created.\n        \"\"\"\n        return self.resources.create_project(project_name,\n                                             dataset_name,\n                                             hostname,\n                                             is_public,\n                                             s3backend,\n                                             kvserver,\n                                             kvengine,\n                                             mdengine,\n                                             description)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_token(self,\n                     token_name,\n                     project_name,\n                     dataset_name,\n                     is_public):\n        \"\"\"\n        Creates a token with the given parameters.\n        Arguments:\n            project_name (str): Project name\n            dataset_name (str): Dataset name project is based on\n            token_name (str): Token name\n            is_public (int): 1 is public. 0 is not public\n        Returns:\n            bool: True if project created, false if not created.\n        \"\"\"\n        return self.resources.create_token(token_name,\n                                           project_name,\n                                           dataset_name,\n                                           is_public)", "response": "Creates a token with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a token with the given parameters.", "response": "def get_token(self,\n                  token_name,\n                  project_name,\n                  dataset_name):\n        \"\"\"\n        Get a token with the given parameters.\n        Arguments:\n            project_name (str): Project name\n            dataset_name (str): Dataset name project is based on\n            token_name (str): Token name\n        Returns:\n            dict: Token info\n        \"\"\"\n        return self.resources.get_token(token_name,\n                                        project_name,\n                                        dataset_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a token with the given parameters.", "response": "def delete_token(self,\n                     token_name,\n                     project_name,\n                     dataset_name):\n        \"\"\"\n        Delete a token with the given parameters.\n        Arguments:\n            project_name (str): Project name\n            dataset_name (str): Dataset name project is based on\n            token_name (str): Token name\n            channel_name (str): Channel name project is based on\n        Returns:\n            bool: True if project deleted, false if not deleted.\n        \"\"\"\n        return self.resources.delete_token(token_name,\n                                           project_name,\n                                           dataset_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_dataset(self,\n                       name,\n                       x_img_size,\n                       y_img_size,\n                       z_img_size,\n                       x_vox_res,\n                       y_vox_res,\n                       z_vox_res,\n                       x_offset=0,\n                       y_offset=0,\n                       z_offset=0,\n                       scaling_levels=0,\n                       scaling_option=0,\n                       dataset_description=\"\",\n                       is_public=0):\n        \"\"\"\n        Creates a dataset.\n\n        Arguments:\n            name (str): Name of dataset\n            x_img_size (int): max x coordinate of image size\n            y_img_size (int): max y coordinate of image size\n            z_img_size (int): max z coordinate of image size\n            x_vox_res (float): x voxel resolution\n            y_vox_res (float): y voxel resolution\n            z_vox_res (float): z voxel resolution\n            x_offset (int): x offset amount\n            y_offset (int): y offset amount\n            z_offset (int): z offset amount\n            scaling_levels (int): Level of resolution scaling\n            scaling_option (int): Z slices is 0 or Isotropic is 1\n            dataset_description (str): Your description of the dataset\n            is_public (int): 1 'true' or 0 'false' for viewability of data set\n                in public\n\n        Returns:\n            bool: True if dataset created, False if not\n        \"\"\"\n        return self.resources.create_dataset(name,\n                                             x_img_size,\n                                             y_img_size,\n                                             z_img_size,\n                                             x_vox_res,\n                                             y_vox_res,\n                                             z_vox_res,\n                                             x_offset,\n                                             y_offset,\n                                             z_offset,\n                                             scaling_levels,\n                                             scaling_option,\n                                             dataset_description,\n                                             is_public)", "response": "Creates a new dataset in the resource store."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_channel(self,\n                       channel_name,\n                       project_name,\n                       dataset_name,\n                       channel_type,\n                       dtype,\n                       startwindow,\n                       endwindow,\n                       readonly=0,\n                       start_time=0,\n                       end_time=0,\n                       propagate=0,\n                       resolution=0,\n                       channel_description=''):\n        \"\"\"\n        Create a new channel on the Remote, using channel_data.\n\n        Arguments:\n            channel_name (str): Channel name\n            project_name (str): Project name\n            dataset_name (str): Dataset name\n            channel_type (str): Type of the channel (e.g. `neurodata.IMAGE`)\n            dtype (str): The datatype of the channel's data (e.g. `uint8`)\n            startwindow (int): Window to start in\n            endwindow (int): Window to end in\n            readonly (int): Can others write to this channel?\n            propagate (int): Allow propogation? 1 is True, 0 is False\n            resolution (int): Resolution scaling\n            channel_description (str): Your description of the channel\n\n        Returns:\n            bool: `True` if successful, `False` otherwise.\n\n        Raises:\n            ValueError: If your args were bad :(\n            RemoteDataUploadError: If the channel data is valid but upload\n                fails for some other reason.\n        \"\"\"\n        return self.resources.create_channel(channel_name,\n                                             project_name,\n                                             dataset_name,\n                                             channel_type,\n                                             dtype,\n                                             startwindow,\n                                             endwindow,\n                                             readonly,\n                                             start_time,\n                                             end_time,\n                                             propagate,\n                                             resolution,\n                                             channel_description)", "response": "Creates a new channel on the Remote."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_channel(self, channel_name, project_name, dataset_name):\n        return self.resources.get_channel(channel_name, project_name,\n                                          dataset_name)", "response": "Gets info about a channel given its name project name and dataset name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete a channel given its name of its project and name of its dataset .", "response": "def delete_channel(self, channel_name, project_name, dataset_name):\n        \"\"\"\n        Deletes a channel given its name, name of its project\n        , and name of its dataset.\n\n        Arguments:\n            channel_name (str): Channel name\n            project_name (str): Project name\n            dataset_name (str): Dataset name\n\n        Returns:\n            bool: True if channel deleted, False if not\n        \"\"\"\n        return self.resources.delete_channel(channel_name, project_name,\n                                             dataset_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a new channel to the internal dictionary of the available do .", "response": "def add_channel(self, channel_name, datatype, channel_type,\n                    data_url, file_format, file_type, exceptions=None,\n                    resolution=None, windowrange=None, readonly=None):\n        \"\"\"\n        Arguments:\n            channel_name (str): Channel Name is the specific name of a\n                specific series of data. Standard naming convention is to do\n                ImageTypeIterationNumber or NameSubProjectName.\n            datatype (str): The data type is the storage method of data in\n                the channel. It can be uint8, uint16, uint32, uint64, or\n                float32.\n            channel_type (str): The channel type is the kind of data being\n                stored in the channel. It can be image, annotation, or\n                timeseries.\n            data_url (str): This url points to the root directory of the\n                files. Dropbox (or any data requiring authentication to\n                download such as private s3) is not an acceptable HTTP\n                Server. See additional instructions in documentation online\n                to format s3 properly so it is http accessible.\n            file_format (str): File format refers to the overarching kind\n                of data, as in slices (normal image data) or catmaid\n                (tile-based).\n            file_type (str): File type refers to the specific type of file\n                that the data is stored in, as in, tiff, png, or tif.\n            exceptions (int): Exceptions is an option to enable the\n                possibility for annotations to contradict each other (assign\n                different values to the same point). 1 corresponds to True,\n                0 corresponds to False.\n            resolution (int): Resolution is the starting resolution of the\n                data being uploaded to the channel.\n            windowrange (int, int): Window range is the maximum and minimum\n                pixel values for a particular image. This is used so that the\n                image can be displayed in a readable way for viewing through\n                RESTful calls\n            readonly (int): This option allows the user to control if,\n                after the initial data commit, the channel is read-only.\n                Generally this is suggested with data that will be publicly\n                viewable.\n\n        Returns:\n            None\n        \"\"\"\n        self.channels[channel_name] = [\n            channel_name.strip().replace(\" \", \"\"), datatype,\n            channel_type.lower(), data_url,\n            file_format, file_type, exceptions, resolution,\n            windowrange, readonly\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_project(self, project_name, token_name=None, public=None):\n        self.project = (project_name.strip().replace(\" \", \"\"),\n                        token_name.strip().replace(\" \", \"\"), public)", "response": "This method adds a project to the internal cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_dataset(self, dataset_name, imagesize, voxelres, offset=None,\n                    timerange=None, scalinglevels=None, scaling=None):\n        \"\"\"\n        Add a new dataset to the ingest.\n\n        Arguments:\n            dataset_name (str): Dataset Name is the overarching name of the\n                research effort. Standard naming convention is to do\n                LabNamePublicationYear or LeadResearcherCurrentYear.\n            imagesize (int, int, int): Image size is the pixel count\n                dimensions of the data. For example is the data is stored\n                as a series of 100 slices each 2100x2000 pixel TIFF images,\n                the X,Y,Z dimensions are (2100, 2000, 100).\n            voxelres (float, float, float): Voxel Resolution is the number\n                of voxels per unit pixel. We store X,Y,Z voxel resolution\n                separately.\n            offset (int, int, int): If your data is not well aligned and\n                there is \"excess\" image data you do not wish to examine, but\n                are present in your images, offset is how you specify where\n                your actual image starts. Offset is provided a pixel\n                coordinate offset from origin which specifies the \"actual\"\n                origin of the image. The offset is for X,Y,Z dimensions.\n            timerange (int, int): Time Range is a parameter to support\n                storage of Time Series data, so the value of the tuple is a\n                0 to X range of how many images over time were taken. It\n                takes 2 inputs timeStepStart and timeStepStop.\n            scalinglevels (int): Scaling levels is the number of levels the\n                data is scalable to (how many zoom levels are present in the\n                data). The highest resolution of the data is at scaling level\n                0, and for each level up the data is down sampled by 2x2\n                (per slice). To learn more about the sampling service used,\n                visit the the propagation service page.\n            scaling (int): Scaling is the scaling method of the data being\n                stored. 0 corresponds to a Z-slice orientation (as in a\n                collection of tiff images in which each tiff is a slice on\n                the z plane) where data will be scaled only on the xy plane,\n                not the z plane. 1 corresponds to an isotropic orientation\n                (in which each tiff is a slice on the y plane) where data\n                is scaled along all axis.\n\n        Returns:\n            None\n        \"\"\"\n        self.dataset = (dataset_name.strip().replace(\" \", \"\"), imagesize,\n                        voxelres, offset, timerange, scalinglevels, scaling)", "response": "This function is called by the base class to add a new dataset to the ingest."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nd_json(self, dataset, project, channel_list, metadata):\n        nd_dict = {}\n        nd_dict['dataset'] = self.dataset_dict(*dataset)\n        nd_dict['project'] = self.project_dict(*project)\n        nd_dict['metadata'] = metadata\n        nd_dict['channels'] = {}\n        for channel_name, value in channel_list.items():\n            nd_dict['channels'][channel_name] = self.channel_dict(*value)\n\n        return json.dumps(nd_dict, sort_keys=True, indent=4)", "response": "Genarate ND json object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating the dictionary of the dataset", "response": "def dataset_dict(\n        self, dataset_name, imagesize, voxelres,\n            offset, timerange, scalinglevels, scaling):\n        \"\"\"Generate the dataset dictionary\"\"\"\n        dataset_dict = {}\n        dataset_dict['dataset_name'] = dataset_name\n        dataset_dict['imagesize'] = imagesize\n        dataset_dict['voxelres'] = voxelres\n        if offset is not None:\n            dataset_dict['offset'] = offset\n        if timerange is not None:\n            dataset_dict['timerange'] = timerange\n        if scalinglevels is not None:\n            dataset_dict['scalinglevels'] = scalinglevels\n        if scaling is not None:\n            dataset_dict['scaling'] = scaling\n        return dataset_dict"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef channel_dict(self, channel_name, datatype, channel_type, data_url,\n                     file_format, file_type, exceptions, resolution,\n                     windowrange, readonly):\n        \"\"\"\n        Generate the project dictionary.\n        \"\"\"\n        channel_dict = {}\n        channel_dict['channel_name'] = channel_name\n        channel_dict['datatype'] = datatype\n        channel_dict['channel_type'] = channel_type\n        if exceptions is not None:\n            channel_dict['exceptions'] = exceptions\n        if resolution is not None:\n            channel_dict['resolution'] = resolution\n        if windowrange is not None:\n            channel_dict['windowrange'] = windowrange\n        if readonly is not None:\n            channel_dict['readonly'] = readonly\n        channel_dict['data_url'] = data_url\n        channel_dict['file_format'] = file_format\n        channel_dict['file_type'] = file_type\n        return channel_dict", "response": "Generate the project dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nidentify the image size using the data location and other parameters.", "response": "def identify_imagesize(self, image_type, image_path='/tmp/img.'):\n        \"\"\"\n        Identify the image size using the data location and other parameters\n        \"\"\"\n        dims = ()\n        try:\n            if (image_type.lower() == 'png'):\n                dims = np.shape(ndpng.load('{}{}'.format(\n                    image_path, image_type\n                )))\n            elif (image_type.lower() == 'tif' or image_type.lower() == 'tiff'):\n                dims = np.shape(ndtiff.load('{}{}'.format(\n                    image_path, image_type\n                )))\n            else:\n                raise ValueError(\"Unsupported image type.\")\n        except:\n            raise OSError('The file was not accessible at {}{}'.format(\n                image_path,\n                image_type\n            ))\n        return dims[::-1]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nverify the path supplied.", "response": "def verify_path(self, data, verifytype):\n        \"\"\"\n        Verify the path supplied.\n        \"\"\"\n        # Insert try and catch blocks\n        try:\n            token_name = data[\"project\"][\"token_name\"]\n        except:\n            token_name = data[\"project\"][\"project_name\"]\n\n        channel_names = list(data[\"channels\"].copy().keys())\n        imgsz = data['dataset']['imagesize']\n\n        for i in range(0, len(channel_names)):\n            channel_type = data[\"channels\"][\n                channel_names[i]][\"channel_type\"]\n            path = data[\"channels\"][channel_names[i]][\"data_url\"]\n            aws_pattern = re.compile(\"^(http:\\/\\/)(.+)(\\.s3\\.amazonaws\\.com)\")\n            file_type = data[\"channels\"][channel_names[i]][\"file_type\"]\n            if \"offset\" in data[\"dataset\"]:\n                offset = data[\"dataset\"][\"offset\"][0]\n            else:\n                offset = 0\n\n            if (aws_pattern.match(path)):\n                verifytype = VERIFY_BY_SLICE\n\n            if (channel_type == \"timeseries\"):\n                timerange = data[\"dataset\"][\"timerange\"]\n                try:\n                    assert(timerange[0] != timerange[1])\n                except AssertionError:\n                    raise ValueError('Timeseries values are the same, did you\\\nspecify the time steps?')\n                for j in range(timerange[0], timerange[1] + 1):\n                    # Test for tifs or such? Currently test for just not\n                    # empty\n                    if (verifytype == VERIFY_BY_FOLDER):\n                        work_path = \"{}/{}/{}/time{}/\".format(\n                            path, token_name, channel_names[i], (\"%04d\" % j))\n                    elif (verifytype == VERIFY_BY_SLICE):\n                        work_path = \"{}/{}/{}/time{}/{}.{}\".format(\n                            path, token_name, channel_names[i], (\"%04d\" % j),\n                            (\"%04d\" % offset), file_type)\n                    else:\n                        raise TypeError('Incorrect verify method')\n                    # Check for accessibility\n                    try:\n                        if (verifytype == VERIFY_BY_FOLDER):\n                            resp = requests.head(work_path)\n                            assert(resp.status_code == 200)\n                        elif (verifytype == VERIFY_BY_SLICE):\n                            resp = requests.get(\n                                work_path, stream=True, verify=False)\n                            with open('/tmp/img.{}'.format(file_type),\n                                      'wb') as out_file:\n                                shutil.copyfileobj(resp.raw, out_file)\n                            out_file.close()\n                            assert(resp.status_code == 200)\n                            resp.close()\n                    except AssertionError:\n                        raise OSError('Files are not http accessible: \\\n                            Error: {}, Path: {}'.format(resp.status_code,\n                                                        work_path))\n                    # Attempt to Verify imagesize here\n\n                    try:\n                        if (verifytype == VERIFY_BY_SLICE):\n                            assert(list(self.identify_imagesize(file_type)) ==\n                                   imgsz[0:2])\n                    except:\n                        raise ValueError('File image size does not match\\\nprovided image size.')\n\n            else:\n                # Test for tifs or such? Currently test for just not empty\n                if (verifytype == VERIFY_BY_FOLDER):\n                    work_path = \"{}/{}/{}/\".format(\n                        path, token_name, channel_names[i])\n                elif (verifytype == VERIFY_BY_SLICE):\n                    work_path = \"{}/{}/{}/{}.{}\".format(\n                        path, token_name, channel_names[i],\n                        (\"%04d\" % offset), file_type)\n                else:\n                    raise TypeError('Incorrect verify method')\n                # Check for accessibility\n                if (verifytype == VERIFY_BY_FOLDER):\n                    resp = requests.head(work_path)\n                elif (verifytype == VERIFY_BY_SLICE):\n                    resp = requests.get(work_path, stream=True, verify=False)\n                    with open('/tmp/img.{}'.format(file_type),\n                              'wb') as out_file:\n                        shutil.copyfileobj(resp.raw, out_file)\n                    out_file.close()\n                    resp.close()\n                if (resp.status_code >= 300):\n                    raise OSError('Files are not http accessible: \\\n                            Error: {}, Path: {}'.format(resp.status_code,\n                                                        work_path))\n                # Attempt to Verify imagesize here\n\n                try:\n                    if (verifytype == VERIFY_BY_SLICE):\n                        assert(list(self.identify_imagesize(file_type)) ==\n                               imgsz[0:2])\n                except:\n                    raise ValueError('File image size does not match\\\nprovided image size.')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to post data to the server.", "response": "def put_data(self, data):\n        \"\"\"\n        Try to post data to the server.\n        \"\"\"\n        URLPath = self.oo.url(\"autoIngest/\")\n        # URLPath = 'https://{}/ca/autoIngest/'.format(self.oo.site_host)\n        try:\n            response = requests.post(URLPath, data=json.dumps(data),\n                                     verify=False)\n            assert(response.status_code == 200)\n            print(\"From ndio: {}\".format(response.content))\n        except:\n            raise OSError(\"Error in posting JSON file {}\\\n\".format(response.status_code))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nposting data to the MICROS server.", "response": "def post_data(self, file_name=None, legacy=False,\n                  verifytype=VERIFY_BY_SLICE):\n        \"\"\"\n        Arguments:\n            file_name (str): The file name of the json file to post (optional).\n                If this is left unspecified it is assumed the data is in the\n                AutoIngest object.\n            dev (bool): If pushing to a microns dev branch server set this\n                to True, if not leave False.\n            verifytype (enum): Set http verification type, by checking the\n                first slice is accessible or by checking channel folder.\n                NOTE: If verification occurs by folder there is NO image size\n                or type verification. Enum: [Folder, Slice]\n\n        Returns:\n            None\n        \"\"\"\n        if (file_name is None):\n            complete_example = (\n                self.dataset, self.project, self.channels, self.metadata)\n            data = json.loads(self.nd_json(*complete_example))\n\n        else:\n            try:\n                with open(file_name) as data_file:\n                    data = json.load(data_file)\n            except:\n                raise OSError(\"Error opening file\")\n\n        # self.verify_path(data, verifytype)\n        # self.verify_json(data)\n        self.put_data(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef output_json(self, file_name='/tmp/ND.json'):\n        complete_example = (\n            self.dataset, self.project, self.channels, self.metadata)\n        data = json.loads(self.nd_json(*complete_example))\n\n        # self.verify_json(data)\n        self.verify_path(data, VERIFY_BY_SLICE)\n\n        f = open(file_name, 'w')\n        f.write(str(data))\n        f.close()", "response": "Outputs the json to the file_name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_path(name, config, wsonly=False):\n    workspace = Workspace(config)\n    config = config[\"workspaces\"]\n\n    path_list = {}\n\n    if name.find('/') != -1:\n        wsonly = False\n        try:\n            ws, repo = name.split('/')\n        except ValueError:\n            raise ValueError(\"There is too many / in `name` argument. \"\n                             \"Argument syntax: `workspace/repository`.\")\n        if (workspace.exists(ws)):\n            if (repo in config[ws][\"repositories\"]):\n                path_name = \"%s/%s\" % (ws, repo)\n                path_list[path_name] = config[ws][\"repositories\"][repo]\n\n    for ws_name, ws in sorted(config.items()):\n        if (name == ws_name):\n            if wsonly is True:\n                return {ws_name: ws[\"path\"]}\n            repositories = sorted(config[ws_name][\"repositories\"].items())\n            for name, path in repositories:\n                path_list[\"%s/%s\" % (ws_name, name)] = path\n            break\n\n        for repo_name, repo_path in sorted(ws[\"repositories\"].items()):\n            if (repo_name == name):\n                path_list[\"%s/%s\" % (ws_name, repo_name)] = repo_path\n\n    return path_list", "response": "Find path for given workspace and or repository."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a list of public tokens available on this server.", "response": "def get_public_tokens(self):\n        \"\"\"\n        Get a list of public tokens available on this server.\n\n        Arguments:\n            None\n\n        Returns:\n            str[]: list of public tokens\n        \"\"\"\n        r = self.remote_utils.get_url(self.url() + \"public_tokens/\")\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary that relating key to dataset to list of tokens that rely on that dataset.", "response": "def get_public_datasets_and_tokens(self):\n        \"\"\"\n        NOTE: VERY SLOW!\n        Get a dictionary relating key:dataset to value:[tokens] that rely\n        on that dataset.\n\n        Arguments:\n            None\n\n        Returns:\n            dict: relating key:dataset to value:[tokens]\n        \"\"\"\n        datasets = {}\n        tokens = self.get_public_tokens()\n        for t in tokens:\n            dataset = self.get_token_dataset(t)\n            if dataset in datasets:\n                datasets[dataset].append(t)\n            else:\n                datasets[dataset] = [t]\n        return datasets"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_proj_info(self, token):\n        r = self.remote_utils.get_url(self.url() + \"{}/info/\".format(token))\n        return r.json()", "response": "Returns the project info for a given token."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_image_size(self, token, resolution=0):\n        info = self.get_proj_info(token)\n        res = str(resolution)\n        if res not in info['dataset']['imagesize']:\n            raise RemoteDataNotFoundError(\"Resolution \" + res +\n                                          \" is not available.\")\n        return info['dataset']['imagesize'][str(resolution)]", "response": "Returns the size of the dataset image."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_metadata(self, token, data):\n        req = requests.post(self.meta_url(\"metadata/ocp/set/\" + token),\n                            json=data, verify=False)\n\n        if req.status_code != 200:\n            raise RemoteDataUploadError(\n                \"Could not upload metadata: \" + req.json()['message']\n            )\n        return req.json()", "response": "Insert new metadata into the OCP metadata database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_subvolume(self, token, channel, secret,\n                      x_start, x_stop,\n                      y_start, y_stop,\n                      z_start, z_stop,\n                      resolution, title, notes):\n        \"\"\"\n        Adds a new subvolume to a token/channel.\n\n        Arguments:\n            token (str): The token to write to in LIMS\n            channel (str): Channel to add in the subvolume. Can be `None`\n            x_start (int): Start in x dimension\n            x_stop (int): Stop in x dimension\n            y_start (int): Start in y dimension\n            y_stop (int): Stop in y dimension\n            z_start (int): Start in z dimension\n            z_stop (int): Stop in z dimension\n            resolution (int): The resolution at which this subvolume is seen\n            title (str): The title to set for the subvolume\n            notes (str): Optional extra thoughts on the subvolume\n\n        Returns:\n            boolean: success\n        \"\"\"\n        md = self.get_metadata(token)['metadata']\n        if 'subvolumes' in md:\n            subvols = md['subvolumes']\n        else:\n            subvols = []\n\n        subvols.append({\n            'token': token,\n            'channel': channel,\n            'x_start': x_start,\n            'x_stop': x_stop,\n            'y_start': y_start,\n            'y_stop': y_stop,\n            'z_start': z_start,\n            'z_stop': z_stop,\n            'resolution': resolution,\n            'title': title,\n            'notes': notes\n        })\n\n        return self.set_metadata(token, {\n            'secret': secret,\n            'subvolumes': subvols\n        })", "response": "Adds a new subvolume to a token or channel."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_url(self, url):\n        try:\n            req = requests.get(url, headers={\n                'Authorization': 'Token {}'.format(self._user_token)\n            }, verify=False)\n            if req.status_code is 403:\n                raise ValueError(\"Access Denied\")\n            else:\n                return req\n        except requests.exceptions.ConnectionError as e:\n            if str(e) == '403 Client Error: Forbidden':\n                raise ValueError('Access Denied')\n            else:\n                raise e", "response": "Get a response object for a given url."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef post_url(self, url, token='', json=None, data=None, headers=None):\n        if (token == ''):\n            token = self._user_token\n\n        if headers:\n            headers.update({'Authorization': 'Token {}'.format(token)})\n        else:\n            headers = {'Authorization': 'Token {}'.format(token)}\n\n        if json:\n            return requests.post(url,\n                                 headers=headers,\n                                 json=json,\n                                 verify=False)\n        if data:\n            return requests.post(url,\n                                 headers=headers,\n                                 data=data,\n                                 verify=False)\n\n        return requests.post(url,\n                             headers=headers,\n                             verify=False)", "response": "Returns a post request object taking in a url user token and json information."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_url(self, url, token=''):\n        if (token == ''):\n            token = self._user_token\n\n        return requests.delete(url,\n                               headers={\n                                   'Authorization': 'Token {}'.format(token)},\n                               verify=False,)", "response": "Returns a delete request object taking in a url and user token."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ping(self, url, endpoint=''):\n        r = self.get_url(url + \"/\" + endpoint)\n        return r.status_code", "response": "Ping the server to make sure that you can access the base URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nimports a HDF5 file into a numpy array.", "response": "def load(hdf5_filename):\n    \"\"\"\n    Import a HDF5 file into a numpy array.\n\n    Arguments:\n        hdf5_filename:  A string filename of a HDF5 datafile\n\n    Returns:\n        A numpy array with data from the HDF5 file\n    \"\"\"\n    # Expand filename to be absolute\n    hdf5_filename = os.path.expanduser(hdf5_filename)\n\n    try:\n        f = h5py.File(hdf5_filename, \"r\")\n        # neurodata stores data inside the 'cutout' h5 dataset\n        data_layers = f.get('image').get('CUTOUT')\n    except Exception as e:\n        raise ValueError(\"Could not load file {0} for conversion. {}\".format(\n                         hdf5_filename, e))\n        raise\n\n    return numpy.array(data_layers)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexport a numpy array to a HDF5 file.", "response": "def save(hdf5_filename, array):\n    \"\"\"\n    Export a numpy array to a HDF5 file.\n\n    Arguments:\n        hdf5_filename (str): A filename to which to save the HDF5 data\n        array (numpy.ndarray): The numpy array to save to HDF5\n\n    Returns:\n        String. The expanded filename that now holds the HDF5 data\n    \"\"\"\n    # Expand filename to be absolute\n    hdf5_filename = os.path.expanduser(hdf5_filename)\n\n    try:\n        h = h5py.File(hdf5_filename, \"w\")\n        h.create_dataset('CUTOUT', data=array)\n        h.close()\n    except Exception as e:\n        raise ValueError(\"Could not save HDF5 file {0}.\".format(hdf5_filename))\n\n    return hdf5_filename"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute the job and return the result of the task.", "response": "def run(self, job: Job) -> Future[Result]:\n        ''' return values of execute are set as result of the task\n        returned by ensure_future(), obtainable via task.result()\n        '''\n        if not self.watcher_ready:\n            self.log.error(f'child watcher unattached when executing {job}')\n            job.cancel('unattached watcher')\n        elif not self.can_execute(job):\n            self.log.error('invalid execution job: {}'.format(job))\n            job.cancel('invalid')\n        else:\n            self.log.debug('executing {}'.format(job))\n            task = asyncio.ensure_future(self._execute(job), loop=self.loop)\n            task.add_done_callback(job.finish)\n            task.add_done_callback(L(self.job_done)(job, _))\n            self.current[job.client] = job\n        return job.status"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninferring gaps in sequences at an ancestral nodes.", "response": "def infer_gaps_in_tree(df_seq, tree, id_col='id', sequence_col='sequence'):\n    \"\"\"Adds a character matrix to DendroPy tree and infers gaps using\n    Fitch's algorithm.\n\n    Infer gaps in sequences at ancestral nodes.\n    \"\"\"\n    taxa = tree.taxon_namespace\n\n    # Get alignment as fasta\n    alignment = df_seq.phylo.to_fasta(id_col=id_col, id_only=True,\n                                      sequence_col=sequence_col)\n\n    # Build a Sequence data matrix from Dendropy\n    data = dendropy.ProteinCharacterMatrix.get(\n        data=alignment,\n        schema=\"fasta\",\n        taxon_namespace=taxa)\n\n    # Construct a map object between sequence data and tree data.\n    taxon_state_sets_map = data.taxon_state_sets_map(gaps_as_missing=False)\n\n    # Fitch algorithm to determine placement of gaps\n    dendropy.model.parsimony.fitch_down_pass(tree.postorder_node_iter(),\n            taxon_state_sets_map=taxon_state_sets_map)\n    dendropy.model.parsimony.fitch_up_pass(tree.preorder_node_iter())\n    return tree"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nvim_io_recover(self, io: NvimIORecover[A]) -> NvimIO[B]:\n        '''calls `map` to shift the recover execution to flat_map_nvim_io\n        '''\n        return eval_step(self.vim)(io.map(lambda a: a))", "response": "calls map to shift the recover execution to flat_map_nvim_io\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the codeml output file and return a new object.", "response": "def read_codeml_output(\n    filename,\n    df,\n    altall_cutoff=0.2,\n    ):\n    \"\"\"Read codeml file.\n    \"\"\"\n    # Read paml output.\n    with open(filename, 'r') as f:\n        data = f.read()\n\n    # Rip all trees out of the codeml output.\n    regex = re.compile('\\([()\\w\\:. ,]+;')\n    trees = regex.findall(data)\n    anc_tree = trees[2]\n\n    # First tree in codeml file is the original input tree\n    tip_tree = dendropy.Tree.get(data=trees[0], schema='newick')\n\n    # Third tree in codeml fule is ancestor tree.\n    anc_tree = dendropy.Tree.get(data=trees[2], schema='newick')\n\n    # Main tree to return\n    tree = tip_tree\n\n    # Map ancestors onto main tree object\n    ancestors = anc_tree.internal_nodes()\n    for i, node in enumerate(tree.internal_nodes()):\n        node.label = ancestors[i].label\n\n    # Map nodes onto dataframe.\n    df['reconstruct_label'] = None\n    for node in tree.postorder_node_iter():\n\n        # Ignore parent node\n        if node.parent_node is None:\n            pass\n\n        elif node.is_leaf():\n            node_label = node.taxon.label\n            parent_label = node.parent_node.label\n            # Set node label.\n            df.loc[df.uid == node_label, 'reconstruct_label'] = node_label\n\n            # Set parent label.\n            parent_id = df.loc[df.uid == node_label, 'parent'].values[0]\n            df.loc[df.id == parent_id, 'reconstruct_label'] = node.parent_node.label\n\n        elif node.is_internal():\n            label = node.label\n            parent_id = df.loc[df.reconstruct_label == label, 'parent'].values[0]\n            df.loc[df.id == parent_id, 'reconstruct_label'] = node.parent_node.label\n\n\n    # Compile a regular expression to find blocks of data for internal nodes\n    node_regex = re.compile(\"\"\"Prob distribution at node [0-9]+, by site[-\\w():.\\s]+\\n\"\"\")\n\n    # Strip the node number from this block of data.\n    node_num_regex = re.compile(\"[0-9]+\")\n\n    # Get dataframes for all ancestors.\n    df['ml_sequence'] = None\n    df['ml_posterior'] = None\n    df['alt_sequence'] = None\n    df['alt_posterior'] = None\n\n    for node in node_regex.findall(data):\n        # Get node label\n        node_label = node_num_regex.search(node).group(0)\n\n        # Compile regex for matching site data\n        site_regex = re.compile(\"(?:\\w\\(\\w.\\w{3}\\) )+\")\n\n        # Iterate through each match for site data.\n        ml_sequence, ml_posterior, alt_sequence, alt_posterior = [], [], [], []\n\n        for site in site_regex.findall(node):\n\n            # Iterate through residues\n            scores = [float(site[i+2:i+7]) for i in range(0,len(site), 9)]\n            residues = [site[i] for i in range(0, len(site), 9)]\n\n            # Get the indices of sorted scores\n            sorted_score_index = [i[0] for i in sorted(\n                enumerate(scores),\n                key=lambda x:x[1],\n                reverse=True)]\n\n            ml_idx = sorted_score_index[0]\n            alt_idx = sorted_score_index[1]\n\n            # Should we keep alterative site.\n            ml_sequence.append(residues[ml_idx])\n            ml_posterior.append(scores[ml_idx])\n\n            if scores[alt_idx] < altall_cutoff:\n                alt_idx = ml_idx\n\n            alt_sequence.append(residues[alt_idx])\n            alt_posterior.append(scores[alt_idx])\n\n        keys = [\n            \"ml_sequence\",\n            \"ml_posterior\",\n            \"alt_sequence\",\n            \"alt_posterior\"\n        ]\n\n        vals = [\n            \"\".join(ml_sequence),\n            sum(ml_posterior) / len(ml_posterior),\n            \"\".join(alt_sequence),\n            sum(alt_posterior) / len(alt_posterior),\n        ]\n\n        df.loc[df.reconstruct_label == node_label, keys] = vals\n\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ugettext(message, context=None):\n    stripped = strip_whitespace(message)\n\n    message = add_context(context, stripped) if context else stripped\n\n    ret = django_ugettext(message)\n\n    # If the context isn't found, we need to return the string without it\n    return stripped if ret == message else ret", "response": "Always return a stripped string localized if possible"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninstall our gettext and ngettext functions into Jinja2 s environment.", "response": "def install_jinja_translations():\n    \"\"\"\n    Install our gettext and ngettext functions into Jinja2's environment.\n    \"\"\"\n    class Translation(object):\n        \"\"\"\n        We pass this object to jinja so it can find our gettext implementation.\n        If we pass the GNUTranslation object directly, it won't have our\n        context and whitespace stripping action.\n        \"\"\"\n        ugettext = staticmethod(ugettext)\n        ungettext = staticmethod(ungettext)\n\n    import jingo\n    jingo.env.install_gettext_translations(Translation)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef activate(locale):\n    if INSTALL_JINJA_TRANSLATIONS:\n        install_jinja_translations()\n\n    if django.VERSION >= (1, 3):\n        django_trans._active.value = _activate(locale)\n    else:\n        from django.utils.thread_support import currentThread\n        django_trans._active[currentThread()] = _activate(locale)", "response": "Activates the locale and returns the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tweak_message(message):\n    if isinstance(message, basestring):\n        message = strip_whitespace(message)\n    elif isinstance(message, tuple):\n        # A tuple of 2 has context, 3 is plural, 4 is plural with context\n        if len(message) == 2:\n            message = add_context(message[1], message[0])\n        elif len(message) == 3:\n            if all(isinstance(x, basestring) for x in message[:2]):\n                singular, plural, num = message\n                message = (strip_whitespace(singular),\n                           strip_whitespace(plural),\n                           num)\n        elif len(message) == 4:\n            singular, plural, num, ctxt = message\n            message = (add_context(ctxt, strip_whitespace(singular)),\n                       add_context(ctxt, strip_whitespace(plural)),\n                       num)\n    return message", "response": "Tweaks a message according to the Babel s extract_* functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _percent(data, part, total):\n    try:\n        return round(100 * float(data[part]) / float(data[total]), 1)\n    except ZeroDivisionError:\n        return 0", "response": "Calculate a percentage of a resource."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_cache_slabs(server_name=None):\n    server_info = {}\n    for svr in mc_client.get_slabs():\n        svr_info = svr[0].split(' ')\n        svr_name = svr_info[0]\n        if server_name and server_name == svr_name:\n            return svr[1]\n        server_info[svr_name] = svr[1]\n    return server_info", "response": "Get cache slabs info."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _context_data(data, request=None):\n    try:\n        return dict(site.each_context(request).items() + data.items())\n    except AttributeError:\n        return data", "response": "Add admin context data to the context data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef server_status(request):\n    data = {\n        'cache_stats': _get_cache_stats(),\n        'can_get_slabs': hasattr(mc_client, 'get_slabs'),\n    }\n    return render_to_response('memcache_admin/server_status.html', data, RequestContext(request))", "response": "Return the status of all servers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dashboard(request):\n    # mc_client will be a dict if memcached is not configured\n    if not isinstance(mc_client, dict):\n        cache_stats = _get_cache_stats()\n    else:\n        cache_stats = None\n    if cache_stats:\n        data = _context_data({\n            'title': _('Memcache Dashboard'),\n            'cache_stats': cache_stats,\n            'can_get_slabs': hasattr(mc_client, 'get_slabs'),\n            'REFRESH_RATE': SETTINGS['REFRESH_RATE'],\n        },\n            request)\n        template = 'memcache_admin/dashboard.html'\n    else:\n        data = _context_data({\n            'title': _('Memcache Dashboard - Error'),\n            'error_message': _('Unable to connect to a memcache server.'),\n        },\n            request)\n        template = 'memcache_admin/dashboard_error.html'\n    return render_to_response(template, data, RequestContext(request))", "response": "Show the memcached dashboard."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a byte value into a human - readable format.", "response": "def human_bytes(value):\n    \"\"\"\n    Convert a byte value into a human-readable format.\n    \"\"\"\n    value = float(value)\n    if value >= 1073741824:\n        gigabytes = value / 1073741824\n        size = '%.2f GB' % gigabytes\n    elif value >= 1048576:\n        megabytes = value / 1048576\n        size = '%.2f MB' % megabytes\n    elif value >= 1024:\n        kilobytes = value / 1024\n        size = '%.2f KB' % kilobytes\n    else:\n        size = '%.2f B' % value\n    return size"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding a config in our children so we can fill in variables in our other children with its data.", "response": "def find_config(self, children):\n        \"\"\"\n        Find a config in our children so we can fill in variables in our other\n        children with its data.\n        \"\"\"\n        named_config = None\n        found_config = None\n\n        # first see if we got a kwarg named 'config', as this guy is special\n        if 'config' in children:\n            if type(children['config']) == str:\n                children['config'] = ConfigFile(children['config'])\n            elif isinstance(children['config'], Config):\n                children['config'] = children['config']\n            elif type(children['config']) == dict:\n                children['config'] = Config(data=children['config'])\n            else:\n                raise TypeError(\"Don't know how to turn {} into a Config\".format(type(children['config'])))\n\n            named_config = children['config']\n\n        # next check the other kwargs\n        for k in children:\n            if isinstance(children[k], Config):\n                found_config = children[k]\n\n        # if we still don't have a config, see if there's a directory with one\n        for k in children:\n            if isinstance(children[k], Directory):\n                for j in children[k]._children:\n                    if j == 'config' and not named_config:\n                        named_config = children[k]._children[j]\n                    if isinstance(children[k]._children[j], Config):\n                        found_config = children[k]._children[j]\n\n        if named_config:\n            return named_config\n        else:\n            return found_config"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add(self, **kwargs):\n        for key in kwargs:\n            if type(kwargs[key]) == str:\n                self._children[key] = Directory(kwargs[key])\n            else:\n                self._children[key] = kwargs[key]\n            self._children[key]._env = self\n            self._children[key].apply_config(ConfigApplicator(self.config))\n            self._children[key].prepare()", "response": "Add objects to the environment."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef apply_config(self, applicator):\n        if type(self._fpath) == str:\n            self._fpath = applicator.apply(self._fpath)", "response": "Apply the config tokens to the file s path."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the path to the file relative to the parent.", "response": "def path(self):\n        \"\"\"\n        Get the path to the file relative to its parent.\n        \"\"\"\n        if self._parent:\n            return os.path.join(self._parent.path, self._fpath)\n        else:\n            return self._fpath"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self):\n        with open(self.path) as f:\n            d = f.read()\n        return d", "response": "Read and return the contents of the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, data, mode='w'):\n        with open(self.path, mode) as f:\n            f.write(data)", "response": "Write data to the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef configure(self):\n        # build a file handler for this file\n        handler = logging.FileHandler(self.path, delay=True)\n\n        # if we got a format string, create a formatter with it\n        if self._format:\n            handler.setFormatter(logging.Formatter(self._format))\n\n        # if we got a string for the formatter, assume it's the name of a\n        # formatter in the environment's config\n        if type(self._formatter) == str:\n            if self._env and self._env.config.logging.dict_config.formatters[self._formatter]:\n                d = self._env.config.logging.dict_config.formatters[self._formatter].to_dict()\n                handler.setFormatter(logging.Formatter(**d))\n        elif type(self._formatter) == dict:\n            # if it's a dict it must be the actual formatter params\n            handler.setFormatter(logging.Formatter(**self._formatter))\n\n        # add the file handler to whatever loggers were specified\n        if len(self._loggers):\n            for name in self._loggers:\n                logging.getLogger(name).addHandler(handler)\n        else:\n            # none specified, just add it to the root logger\n            logging.getLogger().addHandler(handler)", "response": "Configure the Python logging module for this file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(self):\n        if not os.path.exists(self.path):\n            open(self.path, 'a').close()\n        else:\n            raise Exception(\"File exists: {}\".format(self.path))", "response": "Create the file.\n\n        If the file already exists an exception will be raised"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying any config tokens with values from the config.", "response": "def apply_config(self, applicator):\n        \"\"\"\n        Replace any config tokens with values from the config.\n        \"\"\"\n        if type(self._path) == str:\n            self._path = applicator.apply(self._path)\n\n        for key in self._children:\n            self._children[key].apply_config(applicator)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef path(self):\n        p = ''\n\n        if self._parent and self._parent.path:\n            p = os.path.join(p, self._parent.path)\n        if self._base:\n            p = os.path.join(p, self._base)\n        if self._path:\n            p = os.path.join(p, self._path)\n\n        return p", "response": "Return the path to this directory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npreparing the Directory for use in an Environment.", "response": "def prepare(self):\n        \"\"\"\n        Prepare the Directory for use in an Environment.\n\n        This will create the directory if the create flag is set.\n        \"\"\"\n        if self._create:\n            self.create()\n        for k in self._children:\n            self._children[k]._env = self._env\n            self._children[k].prepare()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclean up the children and remove the directory.", "response": "def cleanup(self):\n        \"\"\"\n        Clean up children and remove the directory.\n\n        Directory will only be removed if the cleanup flag is set.\n        \"\"\"\n        for k in self._children:\n            self._children[k].cleanup()\n\n        if self._cleanup:\n            self.remove(True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the path to something inside this directory.", "response": "def path_to(self, path):\n        \"\"\"\n        Find the path to something inside this directory.\n        \"\"\"\n        return os.path.join(self.path, str(path))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist the contents of the directory.", "response": "def list(self):\n        \"\"\"\n        List the contents of the directory.\n        \"\"\"\n        return [File(f, parent=self) for f in os.listdir(self.path)]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write(self, filename, data, mode='w'):\n        with open(self.path_to(str(filename)), mode) as f:\n            f.write(data)", "response": "Write to a file in the directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a file from the directory.", "response": "def read(self, filename):\n        \"\"\"\n        Read a file from the directory.\n        \"\"\"\n        with open(self.path_to(str(filename))) as f:\n            d = f.read()\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds objects to the directory.", "response": "def add(self, *args, **kwargs):\n        \"\"\"\n        Add objects to the directory.\n        \"\"\"\n        for key in kwargs:\n            if isinstance(kwargs[key], str):\n                self._children[key] = File(kwargs[key])\n            else:\n                self._children[key] = kwargs[key]\n            self._children[key]._parent = self\n            self._children[key]._env = self._env\n\n        added = []\n        for arg in args:\n            if isinstance(arg, File):\n                self._children[arg.name] = arg\n                self._children[arg.name]._parent = self\n                self._children[arg.name]._env = self._env\n            elif isinstance(arg, str):\n                f = File(arg)\n                added.append(f)\n                self._children[arg] = f\n                self._children[arg]._parent = self\n                self._children[arg]._env = self._env\n            else:\n                raise TypeError(type(arg))\n\n        # if we were passed a single file/filename, return the File object for convenience\n        if len(added) == 1:\n            return added[0]\n        if len(args) == 1:\n            return args[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self):\n        with open(self.path, 'w') as f:\n            f.write(yaml.dump(dict(self.d)))", "response": "Save the state of the current object to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a saved state file.", "response": "def load(self):\n        \"\"\"\n        Load a saved state file.\n        \"\"\"\n        if os.path.exists(self.path):\n            with open(self.path, 'r') as f:\n                self.d = yaml.safe_load(f.read().replace('\\t', ' '*4))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncleans up the saved state.", "response": "def cleanup(self):\n        \"\"\"\n        Clean up the saved state.\n        \"\"\"\n        if os.path.exists(self.path):\n            os.remove(self.path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload all plugins from the specified directory.", "response": "def load_plugins(self, directory):\n        \"\"\"\n        Loads plugins from the specified directory.\n\n        `directory` is the full path to a directory containing python modules\n        which each contain a subclass of the Plugin class.\n\n        There is no criteria for a valid plugin at this level - any python\n        module found in the directory will be loaded. Only modules that\n        implement a subclass of the Plugin class above will be collected.\n\n        The directory will be traversed recursively.\n        \"\"\"\n        # walk directory\n        for filename in os.listdir(directory):\n            # path to file\n            filepath = os.path.join(directory, filename)\n\n            # if it's a file, load it\n            modname, ext = os.path.splitext(filename)\n            if os.path.isfile(filepath) and ext == '.py':\n                file, path, descr = imp.find_module(modname, [directory])\n                if file:\n                    mod = imp.load_module(modname, file, path, descr)\n\n            # if it's a directory, recurse into it\n            if os.path.isdir(filepath):\n                self.load_plugins(filepath)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_dict(target, source):\n    for k,v in source.items():\n        if isinstance(v, dict) and k in target and isinstance(source[k], dict):\n            update_dict(target[k], v)\n        else:\n            target[k] = v", "response": "Recursively merge values from a nested dictionary into another nested dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a ConfigNode object representing a child node with the specified relative path.", "response": "def _child(self, path):\n        \"\"\"\n        Return a ConfigNode object representing a child node with the specified\n        relative path.\n        \"\"\"\n        if self._path:\n            path = '{}.{}'.format(self._path, path)\n        return ConfigNode(root=self._root, path=path)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _resolve_path(self, create=False):\n        # Split up the key path\n        if type(self._path) == str:\n            key_path = self._path.split('.')\n        else:\n            key_path = [self._path]\n\n        # Start at the root node\n        node = self._root._data\n        nodes = [self._root._data]\n\n        # Traverse along key path\n        while len(key_path):\n            # Get the next key in the key path\n            key = key_path.pop(0)\n\n            # See if the test could be an int for array access, if so assume it is\n            try:\n                key = int(key)\n            except:\n                pass\n\n            # If the next level doesn't exist, create it\n            if create:\n                if type(node) == dict and key not in node:\n                    node[key] = {}\n                elif type(node) == list and type(key) == int and len(node) < key:\n                    node.append([None for i in range(key-len(node))])\n\n            # Store the last node and traverse down the hierarchy\n            nodes.append(node)\n            try:\n                node = node[key]\n            except TypeError:\n                if type(key) == int:\n                    raise IndexError(key)\n                else:\n                    raise KeyError(key)\n\n        return (nodes[-1], key)", "response": "Resolves the path to the last container in the key path and returns a tuple of a reference to the last container in the path and the last component in the key path."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the value represented by this node.", "response": "def _get_value(self):\n        \"\"\"\n        Get the value represented by this node.\n        \"\"\"\n        if self._path:\n            try:\n                container, last = self._resolve_path()\n                return container[last]\n            except KeyError:\n                return None\n            except IndexError:\n                return None\n        else:\n            return self._data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, data={}, options={}):\n        # Handle an update with a set of options like CherryPy does\n        for key in options:\n            self[key] = options[key]\n\n        # Merge in any data in `data`\n        if isinstance(data, ConfigNode):\n            data = data._get_value()\n        update_dict(self._get_value(), data)", "response": "Update the configuration with new data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load(self, reload=False):\n        if reload or not self._loaded:\n            # load defaults\n            if self._defaults_file and type(self._defaults_file) == str:\n                self._defaults_file = File(self._defaults_file, parent=self._parent)\n            defaults = {}\n            if self._defaults_file:\n                defaults = yaml.safe_load(self._defaults_file.read().replace('\\t', '    '))\n\n            # load data\n            data = {}\n            if self.exists:\n                data = yaml.safe_load(self.read().replace('\\t', '    '))\n\n            # initialise with the loaded data\n            self._defaults = defaults\n            self._data = copy.deepcopy(self._defaults)\n            self.update(data=data)\n\n            # if specified, apply environment variables\n            if self._apply_env:\n                self.update(ConfigEnv(self._env_prefix))\n\n            self._loaded = True\n\n        return self", "response": "Load the config and defaults from files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\napplying the config to a string.", "response": "def apply_to_str(self, obj):\n        \"\"\"\n        Apply the config to a string.\n        \"\"\"\n        toks = re.split('({config:|})', obj)\n        newtoks = []\n        try:\n            while len(toks):\n                tok = toks.pop(0)\n                if tok == '{config:':\n                    # pop the config variable, look it up\n                    var = toks.pop(0)\n                    val = self.config[var]\n\n                    # if we got an empty node, then it didn't exist\n                    if type(val) == ConfigNode and val == None:\n                        raise KeyError(\"No such config variable '{}'\".format(var))\n\n                    # add the value to the list\n                    newtoks.append(str(val))\n\n                    # pop the '}'\n                    toks.pop(0)\n                else:\n                    # not the start of a config block, just append it to the list\n                    newtoks.append(tok)\n            return ''.join(newtoks)\n        except IndexError:\n            pass\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nview decorator to validate requests from Twilio per http://www.twilio.com/docs/security.", "response": "def validate_twilio_signature(func=None, backend_name='twilio-backend'):\n    \"\"\"View decorator to validate requests from Twilio per http://www.twilio.com/docs/security.\"\"\"\n\n    def _dec(view_func):\n        @functools.wraps(view_func, assigned=available_attrs(view_func))\n        def _wrapped_view(request, *args, **kwargs):\n            backend = kwargs.get('backend_name', backend_name)\n            config = settings.INSTALLED_BACKENDS[backend]['config']\n            validator = RequestValidator(config['auth_token'])\n            signature = request.META.get('HTTP_X_TWILIO_SIGNATURE', '')\n            url = request.build_absolute_uri()\n            body = {}\n            if request.method == 'POST':\n                body = request.POST\n            require_validation = config.get('validate', True)\n            if validator.validate(url, body, signature) or not require_validation:\n                return view_func(request, *args, **kwargs)\n            else:\n                return HttpResponseBadRequest()\n        return _wrapped_view\n\n    if func is None:\n        return _dec\n    else:\n        return _dec(func)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds the Twilio callback url for confirming message delivery status", "response": "def build_callback_url(request, urlname, message):\n    \"\"\"\n    Build Twilio callback url for confirming message delivery status\n\n    :type message: OutgoingSMS\n    \"\"\"\n    location = reverse(urlname, kwargs={\"pk\": message.pk})\n\n    callback_domain = getattr(settings, \"TWILIO_CALLBACK_DOMAIN\", None)\n    if callback_domain:\n        url = \"{}://{}{}\".format(\n            \"https\" if getattr(settings, \"TWILIO_CALLBACK_USE_HTTPS\", False) else \"http\",\n            callback_domain,\n            location\n        )\n\n    elif request is not None:\n        url = request.build_absolute_uri(location)\n    else:\n        raise ValueError(\n            \"Unable to build callback url. Configure TWILIO_CALLBACK_DOMAIN \"\n            \"or pass request object to function call\"\n        )\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_sms(request, to_number, body, callback_urlname=\"sms_status_callback\"):\n    client = TwilioRestClient(settings.TWILIO_ACCOUNT_SID, settings.TWILIO_AUTH_TOKEN)\n    from_number = settings.TWILIO_PHONE_NUMBER\n\n    message = OutgoingSMS.objects.create(\n        from_number=from_number,\n        to_number=to_number,\n        body=body,\n    )\n\n    status_callback = None\n    if callback_urlname:\n        status_callback = build_callback_url(request, callback_urlname, message)\n\n    logger.debug(\"Sending SMS message to %s with callback url %s: %s.\",\n                 to_number, status_callback, body)\n\n    if not getattr(settings, \"TWILIO_DRY_MODE\", False):\n        sent = client.sms.messages.create(\n            to=to_number,\n            from_=from_number,\n            body=body,\n            status_callback=status_callback\n        )\n        logger.debug(\"SMS message sent: %s\", sent.__dict__)\n\n        message.sms_sid = sent.sid\n        message.account_sid = sent.account_sid\n        message.status = sent.status\n        message.to_parsed = sent.to\n        if sent.price:\n            message.price = Decimal(force_text(sent.price))\n            message.price_unit = sent.price_unit\n        message.sent_at = sent.date_created\n        message.save(update_fields=[\n            \"sms_sid\", \"account_sid\", \"status\", \"to_parsed\",\n            \"price\", \"price_unit\", \"sent_at\"\n        ])\n    else:\n        logger.info(\"SMS: from %s to %s: %s\", from_number, to_number, body)\n    return message", "response": "Send SMS message to the specified phone number."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main(port, export, css, files):\n    options = { 'css': css, 'port': port }\n    try:\n        if not export:\n            if len(files) != 1:\n                error(\"please specify just one file to preview\")\n            preview(files[0], options)\n        else:\n            export_files(files, options)\n    except KeyboardInterrupt:\n        sys.exit(0)\n    except Exception as exc:\n        die()", "response": "Main function for the main function of the main function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_input(self):\n        try:\n            pyngus.read_socket_input(self.connection, self.socket)\n        except Exception as e:\n            LOG.error(\"Exception on socket read: %s\", str(e))\n            self.connection.close_input()\n            self.connection.close()\n        self.connection.process(time.time())", "response": "Called when socket is ready to be read and process incoming data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_output(self):\n        try:\n            pyngus.write_socket_output(self.connection,\n                                       self.socket)\n        except Exception as e:\n            LOG.error(\"Exception on socket write: %s\", str(e))\n            self.connection.close_output()\n            self.connection.close()\n        self.connection.process(time.time())", "response": "Called when socket is write - ready and socket is ready to send output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess the current state of the current object.", "response": "def process(self):\n        \"\"\" Do connection-based processing (I/O and timers) \"\"\"\n        readfd = []\n        writefd = []\n        if self.connection.needs_input > 0:\n            readfd = [self.socket]\n        if self.connection.has_output > 0:\n            writefd = [self.socket]\n\n        timeout = None\n        deadline = self.connection.next_tick\n        if deadline:\n            now = time.time()\n            timeout = 0 if deadline <= now else deadline - now\n\n        LOG.debug(\"select() start (t=%s)\", str(timeout))\n        readable, writable, ignore = select.select(readfd,\n                                                   writefd,\n                                                   [],\n                                                   timeout)\n        LOG.debug(\"select() returned\")\n\n        if readable:\n            try:\n                pyngus.read_socket_input(self.connection,\n                                         self.socket)\n            except Exception as e:\n                LOG.error(\"Exception on socket read: %s\", str(e))\n                self.connection.close_input()\n                self.connection.close()\n\n        self.connection.process(time.time())\n        if writable:\n            try:\n                pyngus.write_socket_output(self.connection,\n                                           self.socket)\n            except Exception as e:\n                LOG.error(\"Exception on socket write: %s\", str(e))\n                self.connection.close_output()\n                self.connection.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new caller object and returns it.", "response": "def create_caller(self, method_map, source_addr, target_addr,\n                      receiver_properties, sender_properties):\n        \"\"\" Caller factory\n        \"\"\"\n        if self.caller:\n            self.caller.destroy()\n        self.caller = MyCaller(method_map, self, source_addr, target_addr,\n                               receiver_properties, sender_properties)\n        return self.caller"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _send_request(self):\n        msg = Message()\n        msg.subject = \"An RPC call!\"\n        msg.address = self._to\n        msg.reply_to = self._reply_to\n        msg.body = self._method\n        msg.correlation_id = 5  # whatever...\n\n        print(\"sending RPC call request: %s\" % str(self._method))\n        # @todo send timeout self._sender.send(msg, self, None, time.time() +\n        # 10)\n        self._sender.send(msg, self)", "response": "Send a message containing the RPC method call\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread from the network layer and processes all data read.", "response": "def read_socket_input(connection, socket_obj):\n    \"\"\"Read from the network layer and processes all data read.  Can\n    support both blocking and non-blocking sockets.\n    Returns the number of input bytes processed, or EOS if input processing\n    is done.  Any exceptions raised by the socket are re-raised.\n    \"\"\"\n    count = connection.needs_input\n    if count <= 0:\n        return count  # 0 or EOS\n\n    while True:\n        try:\n            sock_data = socket_obj.recv(count)\n            break\n        except socket.timeout as e:\n            LOG.debug(\"Socket timeout exception %s\", str(e))\n            raise  # caller must handle\n        except socket.error as e:\n            err = e.errno\n            if err in [errno.EAGAIN,\n                       errno.EWOULDBLOCK,\n                       errno.EINTR]:\n                # try again later\n                return 0\n            # otherwise, unrecoverable, caller must handle\n            LOG.debug(\"Socket error exception %s\", str(e))\n            raise\n        except Exception as e:  # beats me... assume fatal\n            LOG.debug(\"unknown socket exception %s\", str(e))\n            raise  # caller must handle\n\n    if len(sock_data) > 0:\n        count = connection.process_input(sock_data)\n    else:\n        LOG.debug(\"Socket closed\")\n        count = Connection.EOS\n        connection.close_input()\n        connection.close_output()\n    return count"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites data to the network layer.", "response": "def write_socket_output(connection, socket_obj):\n    \"\"\"Write data to the network layer.  Can support both blocking and\n    non-blocking sockets.\n    Returns the number of output bytes sent, or EOS if output processing\n    is done.  Any exceptions raised by the socket are re-raised.\n    \"\"\"\n    count = connection.has_output\n    if count <= 0:\n        return count  # 0 or EOS\n\n    data = connection.output_data()\n    if not data:\n        # error - has_output > 0, but no data?\n        return Connection.EOS\n\n    while True:\n        try:\n            count = socket_obj.send(data)\n            break\n        except socket.timeout as e:\n            LOG.debug(\"Socket timeout exception %s\", str(e))\n            raise  # caller must handle\n        except socket.error as e:\n            err = e.errno\n            if err in [errno.EAGAIN,\n                       errno.EWOULDBLOCK,\n                       errno.EINTR]:\n                # try again later\n                return 0\n            # else assume fatal let caller handle it:\n            LOG.debug(\"Socket error exception %s\", str(e))\n            raise\n        except Exception as e:  # beats me... assume fatal\n            LOG.debug(\"unknown socket exception %s\", str(e))\n            raise\n\n    if count > 0:\n        connection.output_written(count)\n    elif data:\n        LOG.debug(\"Socket closed\")\n        count = Connection.EOS\n        connection.close_output()\n        connection.close_input()\n    return count"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_remote_settle_modes(pn_link):\n    modes = {}\n    snd = pn_link.remote_snd_settle_mode\n    if snd == proton.Link.SND_UNSETTLED:\n        modes['snd-settle-mode'] = 'unsettled'\n    elif snd == proton.Link.SND_SETTLED:\n        modes['snd-settle-mode'] = 'settled'\n    if pn_link.remote_rcv_settle_mode == proton.Link.RCV_SECOND:\n        modes['rcv-settle-mode'] = 'second'\n    return modes", "response": "Return a map containing the settle modes as provided by the remote."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef configure(self, target_address, source_address, handler, properties):\n        self._handler = handler\n        self._properties = properties\n\n        dynamic_props = None\n        if properties:\n            dynamic_props = properties.get(\"dynamic-node-properties\")\n            mode = _dist_modes.get(properties.get(\"distribution-mode\"))\n            if mode is not None:\n                self._pn_link.source.distribution_mode = mode\n            mode = _snd_settle_modes.get(properties.get(\"snd-settle-mode\"))\n            if mode is not None:\n                self._pn_link.snd_settle_mode = mode\n            mode = _rcv_settle_modes.get(properties.get(\"rcv-settle-mode\"))\n            if mode is not None:\n                self._pn_link.rcv_settle_mode = mode\n\n        if target_address is None:\n            if not self._pn_link.is_sender:\n                raise Exception(\"Dynamic target not allowed\")\n            self._pn_link.target.dynamic = True\n            if dynamic_props:\n                self._pn_link.target.properties.clear()\n                self._pn_link.target.properties.put_dict(dynamic_props)\n        elif target_address:\n            self._pn_link.target.address = target_address\n\n        if source_address is None:\n            if not self._pn_link.is_receiver:\n                raise Exception(\"Dynamic source not allowed\")\n            self._pn_link.source.dynamic = True\n            if dynamic_props:\n                self._pn_link.source.properties.clear()\n                self._pn_link.source.properties.put_dict(dynamic_props)\n        elif source_address:\n            self._pn_link.source.address = source_address", "response": "Assign addresses properties etc."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the authorative source of the link.", "response": "def source_address(self):\n        \"\"\"Return the authorative source of the link.\"\"\"\n        # If link is a sender, source is determined by the local\n        # value, else use the remote.\n        if self._pn_link.is_sender:\n            return self._pn_link.source.address\n        else:\n            return self._pn_link.remote_source.address"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the authorative target of the link.", "response": "def target_address(self):\n        \"\"\"Return the authorative target of the link.\"\"\"\n        # If link is a receiver, target is determined by the local\n        # value, else use the remote.\n        if self._pn_link.is_receiver:\n            return self._pn_link.target.address\n        else:\n            return self._pn_link.remote_target.address"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reject(self, pn_condition=None):\n        self._pn_link.source.type = proton.Terminus.UNSPECIFIED\n        super(SenderLink, self).reject(pn_condition)", "response": "See Link Reject and AMQP1. 0 spec."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _process_delivery(self, pn_delivery):\n        if pn_delivery.tag in self._send_requests:\n            if pn_delivery.settled or pn_delivery.remote_state:\n                # remote has reached a 'terminal state'\n                outcome = pn_delivery.remote_state\n                state = SenderLink._DISPOSITION_STATE_MAP.get(outcome,\n                                                              self.UNKNOWN)\n                pn_disposition = pn_delivery.remote\n                info = {}\n                if state == SenderLink.REJECTED:\n                    if pn_disposition.condition:\n                        info[\"condition\"] = pn_disposition.condition\n                elif state == SenderLink.MODIFIED:\n                    info[\"delivery-failed\"] = pn_disposition.failed\n                    info[\"undeliverable-here\"] = pn_disposition.undeliverable\n                    annotations = pn_disposition.annotations\n                    if annotations:\n                        info[\"message-annotations\"] = annotations\n                send_req = self._send_requests.pop(pn_delivery.tag)\n                send_req.destroy(state, info)\n                pn_delivery.settle()\n            elif pn_delivery.writable:\n                # we can now send on this delivery\n                if self._pending_sends:\n                    tag = self._pending_sends.popleft()\n                    send_req = self._send_requests[tag]\n                    self._write_msg(pn_delivery, send_req)\n        else:\n            # tag no longer valid, expired or canceled send?\n            LOG.debug(\"Delivery ignored, tag=%s\", str(pn_delivery.tag))\n            pn_delivery.settle()", "response": "Check if the delivery can be processed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reject(self, pn_condition=None):\n        self._pn_link.target.type = proton.Terminus.UNSPECIFIED\n        super(ReceiverLink, self).reject(pn_condition)", "response": "See Link Reject spec."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the delivery can be processed.", "response": "def _process_delivery(self, pn_delivery):\n        \"\"\"Check if the delivery can be processed.\"\"\"\n        if pn_delivery.readable and not pn_delivery.partial:\n            data = self._pn_link.recv(pn_delivery.pending)\n            msg = proton.Message()\n            msg.decode(data)\n            self._pn_link.advance()\n\n            if self._handler:\n                handle = \"rmsg-%s:%x\" % (self._name, self._next_handle)\n                self._next_handle += 1\n                self._unsettled_deliveries[handle] = pn_delivery\n                with self._callback_lock:\n                    self._handler.message_received(self, msg, handle)\n            else:\n                # TODO(kgiusti): is it ok to assume Delivery.REJECTED?\n                pn_delivery.settle()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new sender link.", "response": "def new_sender(self, name):\n        \"\"\"Create a new sender link.\"\"\"\n        pn_link = self._pn_session.sender(name)\n        return self.request_sender(pn_link)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef request_sender(self, pn_link):\n        sl = SenderLink(self._connection, pn_link)\n        self._links.add(sl)\n        return sl", "response": "Create a link from a request for a sender."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef new_receiver(self, name):\n        pn_link = self._pn_session.receiver(name)\n        return self.request_receiver(pn_link)", "response": "Create a new receiver link."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef request_receiver(self, pn_link):\n        rl = ReceiverLink(self._connection, pn_link)\n        self._links.add(rl)\n        return rl", "response": "Create a receiver link from a request."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls when a link has been destroyed.", "response": "def link_destroyed(self, link):\n        \"\"\"Link has been destroyed.\"\"\"\n        self._links.discard(link)\n        if not self._links:\n            # no more links\n            LOG.debug(\"destroying unneeded session\")\n            self._pn_session.close()\n            self._pn_session.free()\n            self._pn_session = None\n            self._connection = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls by the peer when it has closed its end of the session.", "response": "def _ep_need_close(self):\n        \"\"\"Peer has closed its end of the session.\"\"\"\n        LOG.debug(\"Session %s close requested - closing...\",\n                  self._name)\n        links = self._links.copy()  # may modify _links\n        for link in links:\n            link._session_closed()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _process_endpoint_event(self, event):\n        state_fsm = Endpoint._FSM[self._state]\n        entry = state_fsm.get(event)\n        if not entry:\n            # protocol error: invalid event for current state\n            old_state = self._state\n            self._state = Endpoint.STATE_ERROR\n            self._ep_error(\"invalid event=%s in state=%s\" %\n                           (Endpoint.EVENT_NAMES[event],\n                            Endpoint.STATE_NAMES[old_state]))\n            return\n\n        self._state = entry[0]\n        if entry[1]:\n            entry[1](self)", "response": "Called when the Proton Engine generates an endpoint state change\n            event."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling when the receiver has closed its end of the link.", "response": "def receiver_remote_closed(self, receiver_link, pn_condition):\n        \"\"\"Peer has closed its end of the link.\"\"\"\n        LOG.debug(\"receiver_remote_closed condition=%s\", pn_condition)\n        receiver_link.close()\n        self.done = True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef receiver_failed(self, receiver_link, error):\n        LOG.warn(\"receiver_failed error=%s\", error)\n        receiver_link.close()\n        self.done = True", "response": "Callback when the receiver failed."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_host_port(server_address):\n    regex = re.compile(r\"^amqp://([a-zA-Z0-9.]+)(:([\\d]+))?$\")\n    x = regex.match(server_address)\n    if not x:\n        raise Exception(\"Bad address syntax: %s\" % server_address)\n    matches = x.groups()\n    host = matches[0]\n    port = int(matches[2]) if matches[2] else None\n    return host, port", "response": "Parse the hostname and port out of the server_address."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connect_socket(host, port, blocking=True):\n    addr = socket.getaddrinfo(host, port, socket.AF_INET, socket.SOCK_STREAM)\n    if not addr:\n        raise Exception(\"Could not translate address '%s:%s'\"\n                        % (host, str(port)))\n    my_socket = socket.socket(addr[0][0], addr[0][1], addr[0][2])\n    if not blocking:\n        my_socket.setblocking(0)\n    try:\n        my_socket.connect(addr[0][4])\n    except socket.error as e:\n        if e.errno != errno.EINPROGRESS:\n            raise\n    return my_socket", "response": "Create a TCP connection to the server."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef server_socket(host, port, backlog=10):\n    addr = socket.getaddrinfo(host, port, socket.AF_INET, socket.SOCK_STREAM)\n    if not addr:\n        raise Exception(\"Could not translate address '%s:%s'\"\n                        % (host, str(port)))\n    my_socket = socket.socket(addr[0][0], addr[0][1], addr[0][2])\n    my_socket.setblocking(0)  # 0=non-blocking\n    try:\n        my_socket.bind(addr[0][4])\n        my_socket.listen(backlog)\n    except socket.error as e:\n        if e.errno != errno.EINPROGRESS:\n            raise\n    return my_socket", "response": "Create a TCP listening socket for a server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_connection(connection, my_socket):\n    if connection.closed:\n        return False\n\n    work = False\n    readfd = []\n    writefd = []\n    if connection.needs_input > 0:\n        readfd = [my_socket]\n        work = True\n    if connection.has_output > 0:\n        writefd = [my_socket]\n        work = True\n\n    timeout = None\n    deadline = connection.next_tick\n    if deadline:\n        work = True\n        now = time.time()\n        timeout = 0 if deadline <= now else deadline - now\n\n    if not work:\n        return False\n\n    readable, writable, ignore = select.select(readfd,\n                                               writefd,\n                                               [],\n                                               timeout)\n    if readable:\n        try:\n            pyngus.read_socket_input(connection, my_socket)\n        except Exception as e:\n            # treat any socket error as\n            LOG.error(\"Socket error on read: %s\", str(e))\n            connection.close_input()\n            # make an attempt to cleanly close\n            connection.close()\n\n    connection.process(time.time())\n    if writable:\n        try:\n            pyngus.write_socket_output(connection, my_socket)\n        except Exception as e:\n            LOG.error(\"Socket error on write %s\", str(e))\n            connection.close_output()\n            # this may not help, but it won't hurt:\n            connection.close()\n    return True", "response": "Handle I / O and Timers on a single Connection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming the actual processing of the current state of the connection.", "response": "def process(self, now):\n        \"\"\"Perform connection state processing.\"\"\"\n        if self._pn_connection is None:\n            LOG.error(\"Connection.process() called on destroyed connection!\")\n            return 0\n\n        # do nothing until the connection has been opened\n        if self._pn_connection.state & proton.Endpoint.LOCAL_UNINIT:\n            return 0\n\n        if self._pn_sasl and not self._sasl_done:\n            # wait until SASL has authenticated\n            if (_PROTON_VERSION < (0, 10)):\n                if self._pn_sasl.state not in (proton.SASL.STATE_PASS,\n                                               proton.SASL.STATE_FAIL):\n                    LOG.debug(\"SASL in progress. State=%s\",\n                              str(self._pn_sasl.state))\n                    if self._handler:\n                        with self._callback_lock:\n                            self._handler.sasl_step(self, self._pn_sasl)\n                    return self._next_deadline\n\n                self._sasl_done = True\n                if self._handler:\n                    with self._callback_lock:\n                        self._handler.sasl_done(self, self._pn_sasl,\n                                                self._pn_sasl.outcome)\n            else:\n                if self._pn_sasl.outcome is not None:\n                    self._sasl_done = True\n                    if self._handler:\n                        with self._callback_lock:\n                            self._handler.sasl_done(self, self._pn_sasl,\n                                                    self._pn_sasl.outcome)\n\n        # process timer events:\n        timer_deadline = self._expire_timers(now)\n        transport_deadline = self._pn_transport.tick(now)\n        if timer_deadline and transport_deadline:\n            self._next_deadline = min(timer_deadline, transport_deadline)\n        else:\n            self._next_deadline = timer_deadline or transport_deadline\n\n        # process events from proton:\n        pn_event = self._pn_collector.peek()\n        while pn_event:\n            # LOG.debug(\"pn_event: %s received\", pn_event.type)\n            if _Link._handle_proton_event(pn_event, self):\n                pass\n            elif self._handle_proton_event(pn_event):\n                pass\n            elif _SessionProxy._handle_proton_event(pn_event, self):\n                pass\n            self._pn_collector.pop()\n            pn_event = self._pn_collector.peek()\n\n        # check for connection failure after processing all pending\n        # engine events:\n        if self._error:\n            if self._handler:\n                # nag application until connection is destroyed\n                self._next_deadline = now\n                with self._callback_lock:\n                    self._handler.connection_failed(self, self._error)\n        elif (self._endpoint_state == self._CLOSED and\n              self._read_done and self._write_done):\n            # invoke closed callback after endpoint has fully closed and\n            # all pending I/O has completed:\n            if self._handler:\n                with self._callback_lock:\n                    self._handler.connection_closed(self)\n\n        return self._next_deadline"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a buffer of data that needs to be written to the network.", "response": "def output_data(self):\n        \"\"\"Get a buffer of data that needs to be written to the network.\n        \"\"\"\n        c = self.has_output\n        if c <= 0:\n            return None\n        try:\n            buf = self._pn_transport.peek(c)\n        except Exception as e:\n            self._connection_failed(str(e))\n            return None\n        return buf"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_sender(self, source_address, target_address=None,\n                      event_handler=None, name=None, properties=None):\n        \"\"\"Factory method for Sender links.\"\"\"\n        ident = name or str(source_address)\n        if ident in self._sender_links:\n            raise KeyError(\"Sender %s already exists!\" % ident)\n\n        session = _SessionProxy(\"session-%s\" % ident, self)\n        session.open()\n        sl = session.new_sender(ident)\n        sl.configure(target_address, source_address, event_handler, properties)\n        self._sender_links[ident] = sl\n        return sl", "response": "Factory method for sender links."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrejecting the SenderLink and destroys the handle.", "response": "def reject_sender(self, link_handle, pn_condition=None):\n        \"\"\"Rejects the SenderLink, and destroys the handle.\"\"\"\n        link = self._sender_links.get(link_handle)\n        if not link:\n            raise Exception(\"Invalid link_handle: %s\" % link_handle)\n        link.reject(pn_condition)\n        # note: normally, link.destroy() cannot be called from a callback,\n        # but this link was never made available to the application so this\n        # link is only referenced by the connection\n        link.destroy()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncleans up after connection failure detected.", "response": "def _connection_failed(self, error=\"Error not specified!\"):\n        \"\"\"Clean up after connection failure detected.\"\"\"\n        if not self._error:\n            LOG.error(\"Connection failed: %s\", str(error))\n            self._error = error"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ep_active(self):\n        LOG.debug(\"Connection is up\")\n        if self._handler:\n            with self._callback_lock:\n                self._handler.connection_active(self)", "response": "Called when the connection is up."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _ep_need_close(self):\n        LOG.debug(\"Connection remotely closed\")\n        if self._handler:\n            cond = self._pn_connection.remote_condition\n            with self._callback_lock:\n                self._handler.connection_remote_closed(self, cond)", "response": "The remote endpoint has closed its end of the endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ep_error(self, error):\n        super(Connection, self)._ep_error(error)\n        self._connection_failed(\"Protocol error occurred.\")", "response": "The endpoint state machine failed due to protocol error."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_color_string(self):\r\n        s = ''\r\n        if self.color_type == 'd':\r\n            if self.name is \"black\":\r\n                s = '%.3f G' % 0\r\n            else:\r\n                s = '%.3f %.3f %.3f RG' % (\r\n                    self.red / 255.0, self.green / 255.0, self.blue / 255.0)\r\n        elif self.color_type == 'f' or self.color_type == 't':\r\n            if self.name is \"black\":\r\n                s = '%.3f g' % 0\r\n            else:\r\n                s = '%.3f %.3f %.3f rg' % (\r\n                    self.red / 255.0, self.green / 255.0, self.blue / 255.0)\r\n        return s", "response": "Return string for defining colors"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nselecting a font ; size given in points", "response": "def _set_font(self, family=None, style=None, size=None):\n        \"\"\"Select a font; size given in points\"\"\"\n        if style is not None:\n            if 'B' in style:\n                family += '_bold'\n            if 'I' in style:\n                family += '_italic'\n\n        self._set_family(family)\n        self._get_diffs()\n        self._set_style(style)\n        self._set_metrics()\n        self._set_size(size)\n        self._set_font_key()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the width of a string in the current font", "response": "def _string_width(self, s):\n        \"\"\"Get width of a string in the current font\"\"\"\n        s = str(s)\n        w = 0\n        for char in s:\n            char = ord(char)\n            w += self.character_widths[char]\n        return w * self.font_size / 1000.0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_ttf(self):\n        font_dict = {}\n        families = []\n        rootdirlist = string.split(self.search_path, os.pathsep)\n\n        #for rootdir in rootdirlist:\n        #    rootdir = os.path.expanduser(rootdir)\n        for dirName, subdirList, filelist in itertools.chain.from_iterable(os.walk(path) for path in rootdirlist):\n            for item in filelist:\n                root, ext = os.path.splitext(item)\n                if ext == '.ttf':\n                    if root[0].lower() in english:\n                        source = os.path.join(dirName, item)\n                        name = root.lower().replace('_', ' ')\n                        if ' bold' in name:\n                            name = name.replace(' bold', '_bold')\n                            if ' italic' in name:\n                                name = name.replace(' italic', '_italic')\n                        elif 'bold' in name:\n                            name = name.replace('bold', '_bold')\n                            if 'italic' in name:\n                                name = name.replace('italic', '_italic')\n                        elif ' italic' in name:\n                            name = name.replace(' italic', '_italic')\n                        elif 'italic' in name:\n                            name = name.replace('italic', '_italic')\n                        elif 'oblique' in name:\n                            name = name.replace('oblique', '_italic')\n                        else:\n                            families.append(name)\n                        font_dict[name] = source\n                    else:\n                        source = os.path.join(dirName, item)\n                        name = root.lower().replace('_', ' ')\n                        font_dict[name] = source\n                        families.append(name)\n        self.font_dict = font_dict\n        self.families = families", "response": "Given a search path find the TTF file and return a dictionary of font names and families."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_compression(self, value):\r\n        if isinstance(value, bool):\r\n            self.compression = value\r\n        else:\r\n            raise Exception(\r\n                TypeError, \"%s is not a valid option for compression\" % value)", "response": "Sets the compression option for this object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate the placeholder PDF objects for the most common PDF objects.", "response": "def _create_placeholder_objects(self):\r\n        \"\"\" PDF objects #1 through #3 are typically saved for the\r\n            Zeroth, Catalog, and Pages Objects. This program will save\r\n            the numbers, but outputs the individual Page and Content objects\r\n            first. The actual Catalog and Pages objects are calculated after.\r\n\r\n        \"\"\"\r\n        self.objects.append(\"Zeroth\")\r\n        self.objects.append(\"Catalog\")\r\n        self.objects.append(\"Pages\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_object(self, flag=None):\r\n        self.offset = len(self.buffer)\r\n        if flag is None:\r\n            objnum = len(self.objects)\r\n            obj = _PDFObject(objnum, self.offset)\r\n            self.objects.append(obj)\r\n        else:\r\n            objnum = flag\r\n            obj = _PDFObject(objnum, self.offset)\r\n            self.objects[flag] = obj\r\n        self._out(str(objnum) + ' 0 obj')\r\n        return obj", "response": "Add an object to the object array."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting the contents of the file into the buffer.", "response": "def _out(self, stream, page=None):\r\n        \"\"\" Stores the pdf code in a buffer. If it is page related,\r\n            provide the page object.\r\n\r\n        \"\"\"\r\n        if page is not None:\r\n            page.buffer += str(stream) + \"\\n\"\r\n        else:\r\n            self.buffer += str(stream) + \"\\n\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a PDF text stream", "response": "def _put_stream(self, stream):\r\n        \"\"\" Creates a PDF text stream sandwich.\r\n\r\n        \"\"\"\r\n        self._out('stream')\r\n        self._out(stream)\r\n        self._out('endstream')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_page(self, text):\r\n        save_cursor = self.parent.document.page.cursor.copy()\r\n        save_cursor.x_reset()\r\n        save_cursor.y_reset()\r\n        self.parent.document.add_page()\r\n        self.parent.document.set_cursor(save_cursor)\r\n        self.parent.document.add_text(text)", "response": "Helper function for PDFText to add a page and retry adding a large block of text."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets color scheme for the image.", "response": "def _set_color_scheme(self, draw_color=None, fill_color=None, text_color=None):\r\n        \"\"\" Default color object is black letters\r\n            & black lines.\"\"\"\r\n        if draw_color is None:\r\n            draw_color = PDFColor()\r\n            draw_color._set_type('d')\r\n        if fill_color is None:\r\n            fill_color = PDFColor()\r\n            fill_color._set_type('f')\r\n        if text_color is None:\r\n            text_color = PDFColor()\r\n            text_color._set_type('t')\r\n\r\n        self.draw_color = draw_color\r\n        self.fill_color = fill_color\r\n        self.text_color = text_color"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_default_font(self):\r\n        self.font = PDFFont(self.session)\r\n        self.font._set_index()\r\n        self.fonts.append(self.font)\r\n        self.fontkeys.append(self.font.font_key)", "response": "Internal method to set the default font. Change\r\n            is a method that returns the font object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a new PDFPage to the PDF.", "response": "def add_page(self, page=None):\r\n        \"\"\" May generate and add a PDFPage separately, or use this to generate\r\n            a default page.\"\"\"\r\n        if page is None:\r\n            self.page = PDFPage(self.orientation_default, self.layout_default, self.margins)\r\n        else:\r\n            self.page = page\r\n        self.page._set_index(len(self.pages))\r\n        self.pages.append(self.page)\r\n        currentfont = self.font\r\n        self.set_font(font=currentfont)\r\n        self.session._reset_colors()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_font(self, family=None, style='', size=None, font=None):\r\n        if font:\r\n            testfont = font\r\n        elif isinstance(family, PDFFont):\r\n            testfont = family\r\n        else:\r\n            # If size is not defined, keep the last size.\r\n            if size is None:\r\n                size = self.font.font_size\r\n\r\n            # Create a font from givens to test its key\r\n            if family in CORE_FONTS:\r\n                testfont = PDFFont(self.session, family, style, size)\r\n            else:\r\n                testfont = PDFTTFont(self.session, family, style, size)\r\n\r\n        testkey = testfont.font_key\r\n\r\n        if testkey in self.fontkeys:\r\n            index = self.fontkeys.index(testkey)\r\n            self.font = self.fonts[index]\r\n            if size != self.font.font_size:\r\n                self.font._set_size(size)\r\n            if style != self.font.style:\r\n                self.font._set_style(style)\r\n        else:\r\n            self.font = testfont\r\n            self._register_new_font(self.font)\r\n\r\n        self.font.is_set = False\r\n\r\n        if self.page.index > 0:\r\n                self.session._out('BT /F%d %.2f Tf ET' %\r\n                                  (self.font.index, self.font.font_size),\r\n                                  self.page)\r\n                self.font.is_set = True\r\n        return self.font", "response": "Set the document font object family style size and font."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_font_size(self, size):\r\n        if self.font.font_size == size:\r\n            pass\r\n        else:\r\n            self.font._set_size(size)", "response": "Convenience method for just changing font size."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninputs text short or long. Writes in order within the defined page boundaries.", "response": "def add_text(self, text, cursor=None, justification=None):\r\n        \"\"\" Input text, short or long. Writes in order, within the defined page boundaries. Sequential add_text commands will print without\r\n            additional whitespace. \"\"\"\r\n        if cursor is None:\r\n            cursor = self.page.cursor\r\n\r\n        text = re.sub(\"\\s\\s+\" , \" \", text)\r\n\r\n        if justification is None:\r\n            justification = self.justification\r\n\r\n        if '\\n' in text:\r\n            text_list = text.split('\\n')\r\n            for text in text_list:\r\n                PDFText(self.session, self.page, text, self.font, self.text_color, cursor, justification, self.double_spacing)\r\n                self.add_newline()\r\n        else:\r\n            PDFText(self.session, self.page, text, self.font, self.text_color, cursor, justification, self.double_spacing)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts over at the new line.", "response": "def add_newline(self, number=1):\r\n        \"\"\" Starts over again at the new line. If number is specified,\r\n            it will leave multiple lines.\"\"\"\r\n        if isinstance(number, int):\r\n            try:\r\n                self.page._add_newline(self.font, number, self.double_spacing)\r\n            except ValueError:\r\n                self.add_page()\r\n        else:\r\n            raise TypeError(\"Number of newlines must be an integer.\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_pie_chart(self, data, cursor, width, height, title=None, data_type=\"raw\", fill_colors=None, labels=False, background=None, legend=None):\r\n        save_draw_color = self.draw_color\r\n        save_fill_color = self.fill_color\r\n\r\n        chart = PDFPieChart(self.session, self.page, data, cursor, width, height, title, data_type, fill_colors, labels, background, legend)\r\n\r\n        self.set_draw_color(save_draw_color)\r\n        self.set_fill_color(save_fill_color)", "response": "Add a pie chart to the page."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling by the PDFLite object to prompt creating the page objects.", "response": "def _output_pages(self):\r\n        \"\"\" Called by the PDFLite object to prompt creating\r\n            the page objects.\"\"\"\r\n        if not self.orientation_changes:\r\n            self._get_orientation_changes()\r\n\r\n        # Page\r\n        for page in self.pages:\r\n            obj = self.session._add_object()\r\n            self.session._out('<</Type /Page')\r\n            self.session._out('/Parent 1 0 R')\r\n            if self.orientation_changes:\r\n                self.session._out('/MediaBox [0 0 %.2f %.2f]' % (page.width, page.height))\r\n            self.session._out('/Resources 2 0 R')\r\n            self.session._out('/Group <</Type /Group /S /Transparency /CS /DeviceRGB>>')\r\n            self.session._out('/Contents %s 0 R>>' % (obj.id + 1))\r\n            self.session._out('endobj')\r\n\r\n            # Page content\r\n            self.session._add_object()\r\n            if self.session.compression is True:\r\n                textfilter = ' /Filter /FlateDecode '\r\n                page._compress()\r\n            else:\r\n                textfilter = ''\r\n            self.session._out('<<%s/Length %s >>' % (textfilter, len(page.buffer)))\r\n            self.session._put_stream(page.buffer)\r\n            self.session._out('endobj')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of the pages that have the most recent orientation changes.", "response": "def _get_orientation_changes(self):\r\n        \"\"\" Returns a list of the pages that have\r\n            orientation changes.\"\"\"\r\n        self.orientation_changes = []\r\n        for page in self.pages:\r\n            if page.orientation_change is True:\r\n                self.orientation_changes.append(page.index)\r\n            else:\r\n                pass\r\n        return self.orientation_changes"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _output_fonts(self):\r\n        self.session._save_object_number()\r\n        self._output_encoding_diffs()\r\n        self._output_font_files()\r\n\r\n        for font in self.fonts:\r\n            obj = self.session._add_object()\r\n            font._set_number(obj.id)\r\n            font._output()", "response": "Called by the PDFLite object to output the font objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating reference images that can be drawn throughout the document.", "response": "def _output_images(self):\r\n        \"\"\" Creates reference images, that can be\r\n            drawn throughout the document.\"\"\"\r\n        for image in self.images:\r\n            obj = self.session._add_object()\r\n            image._set_number(obj.id)\r\n            image._output()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _output(self):\n        self.session._out('<</Type /XObject')\n        self.session._out('/Subtype /Image')\n        self.session._out('/Width %s' % self.width)\n        self.session._out('/Height %s' % self.height)\n\n        if self.colorspace is 'Indexed':\n            self.session._out('/ColorSpace [/Indexed /DeviceRGB %s %s 0 R' %\n                              (self.pal, self.number + 1))\n        else:\n            self.session._out('/ColorSpace /%s' % self.colorspace)\n            if self.colorspace is 'DeviceCMYK':\n                self.session._out('/Decode [1 0 1 0 1 0 1 0]')\n\n        self.session._out('/BitsPerComponent %s' % self.bits_per_component)\n\n        if self.filter:\n            self.session._out('/Filter /%s' % self.filter)\n        if self.decode:\n            self.session._out('/DecodeParms << %s >>' % self.decode)\n        if self.transparent:\n            self.session._out('/Mask [%s]' % self.transparent_string)\n        if self.soft_mask:\n            self.session._out('/SMask %s 0 R' % (self.number + 1))\n        self.session._out('/Length %s >>' % self.size)\n        self.session._put_stream(self.image_data)\n        self.session._out('endobj')\n\n        if self.colorspace is 'Indexed':\n            self.session._out('<<%s /Length %s >>' % (self.palette_filter, self.palette_length))\n            self.session._put_stream(self.palette)\n            self.session._out('endobj')\n\n        if isinstance(self.soft_mask, PDFImage):\n            obj = self.session._add_object()\n            self.soft_mask._set_number(obj.id)\n            self.soft_mask._output()", "response": "Prints the creation of image objects."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transform(self, a, b, c, d, e, f):\n        a0, b0, c0, d0, e0, f0 = self._currentMatrix\n        self._currentMatrix = (a0 * a + c0 * b, b0 * a + d0 * b,\n                               a0 * c + c0 * d, b0 * c + d0 * d,\n                               a0 * e + c0 * f + e0, b0 * e + d0 * f + f0)\n        a1, b1, c1, d1, e1, f1 = self._currentMatrix\n        self.session._out('%.2f %.2f %.2f %.2f %.2f %.2f cm' % (a1, b1, c1, d1, e1, f1), self.page)", "response": "Adjust the current transformation state of the graphics state of the current graphics state."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the absolute position of x y in user space w. r. t. default user space w. r. t. default user space w. r. t. default user space w. r. t. default user space w. r. t. default user space w. r. t. default user space w. r. t. default user space w. r. t. default user space w. r. t. default user space w. r. t. default user space", "response": "def absolute_position(self, x, y):\n        \"\"\"return the absolute position of x,y in user space w.r.t. default user space\"\"\"\n        (a, b, c, d, e, f) = self._currentMatrix\n        xp = a * x + c * y + e\n        yp = b * x + d * y + f\n        return xp, yp"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrotates the current graphic state by the angle theta.", "response": "def rotate(self, theta):\n        \"\"\"Rotate current graphic state by the angle theta (in degrees).\"\"\"\n        c = cos(theta * pi / 180)\n        s = sin(theta * pi / 180)\n        self.transform(c, s, -s, c, 0, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the style of the object.", "response": "def _set_style(self, style=None):\r\n        \"\"\" Style should be a string, containing the letters 'B' for bold,\r\n        'U' for underline, or 'I' for italic, or should be '', for no style.\r\n        Symbol will not be underlined. The underline style can further be\r\n        modified by specifying the underline thickness and position.\r\n\r\n        \"\"\"\r\n        if style is None:\r\n            self.style = ''\r\n            self.underline = False\r\n        # No syling for symbol\r\n        elif self.family == ('symbol' or 'zapfdingbats'):\r\n            self.style = ''\r\n            self.underline = False\r\n\r\n        self.style = style.upper()\r\n            # SetUnderline\r\n\r\n        if 'U' in self.style or self.style == 'U':\r\n            self.underline = True\r\n        else:\r\n            self.underline = False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nselecting a font ; size given in points", "response": "def _set_font(self, family=None, style=None, size=None):\r\n        \"\"\"Select a font; size given in points\"\"\"\r\n        self._set_family(family)\r\n        self._set_style(style)\r\n        self._set_size(size)\r\n        self._set_font_key()\r\n        self._set_name()\r\n        self._set_character_widths()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _string_width(self, s):\r\n        s = str(s)\r\n        w = 0\r\n        for i in s:\r\n            w += self.character_widths[i]\r\n        return w * self.font_size / 1000.0", "response": "Get the width of a string in the current font"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getCellVertexes(self, i, j):\n        \n        # Using unrotated centroid coordinates to avoid an extra computation\n        x,y = self._getUnrotatedCellCentroidCoords(i, j)\n        \n        return [\n            self.rotatePoint(x - self._side,       y                 ),  \n            self.rotatePoint(x - self._side / 2.0, y - self._hexPerp ), \n            self.rotatePoint(x + self._side / 2.0, y - self._hexPerp ), \n            self.rotatePoint(x + self._side,       y                 ),                 \n            self.rotatePoint(x + self._side / 2.0, y + self._hexPerp ),\n            self.rotatePoint(x - self._side / 2.0, y + self._hexPerp ), \n            ]", "response": "Returns a list of vertices of a cell in the system."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rotatePoint(self, pointX, pointY):\n        if(self.angle == 0 or self.angle == None):\n            return(pointX, pointY)\n              \n        # 1. Compute the segment length\n        length = math.sqrt((pointX - self.xll) ** 2 + (pointY - self.yll) ** 2)\n        \n        # 2. Compute beta\n        beta = math.acos((pointX - self.xll) / length) \n        if(pointY < self.yll):\n            beta = math.pi * 2 - beta\n           \n        # 3. Compute offsets\n        offsetX = math.cos(beta) * length - math.cos(self._angle_rd + beta) * length\n        offsetY = math.sin(self._angle_rd + beta) * length - math.sin(beta) * length \n        return (pointX - offsetX, pointY + offsetY)", "response": "Rotates a point relative to the origin by the angle specified in the angle property."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset information about the items in the object.", "response": "def set_information(self, title=None, subject=None, author=None, keywords=None, creator=None):\r\n        \"\"\" Convenience function to add property info, can set any attribute and leave the others blank, it won't over-write\r\n            previously set items. \"\"\"\r\n        info_dict = {\"title\": title, \"subject\": subject,\r\n                     \"author\": author, \"keywords\": keywords,\r\n                     \"creator\": creator}\r\n\r\n        for att, value in info_dict.iteritems():\r\n            if hasattr(self, att):\r\n                if value:\r\n                    setattr(self, att, value)\r\n            else:\r\n                setattr(self, att, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_display_mode(self, zoom='fullpage', layout='continuous'):\r\n        self.zoom_options = [\"fullpage\", \"fullwidth\", \"real\", \"default\"]\r\n        self.layout_options = [\"single\", \"continuous\", \"two\", \"default\"]\r\n\r\n        if zoom in self.zoom_options or (isinstance(zoom, int) and 0 < zoom <= 100):\r\n            self.zoom_mode = zoom\r\n        else:\r\n            raise Exception('Incorrect zoom display mode: ' + zoom)\r\n\r\n        if layout in self.layout_options:\r\n            self.layout_mode = layout\r\n        else:\r\n            raise Exception('Incorrect layout display mode: ' + layout)", "response": "Set the default viewing mode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef close(self):\r\n        self.document._set_page_numbers()\r\n        # Places header, pages, page content first.\r\n        self._put_header()\r\n        self._put_pages()\r\n        self._put_resources()\r\n        # Information object\r\n        self._put_information()\r\n        # Catalog object\r\n        self._put_catalog()\r\n        # Cross-reference object\r\n        #self._put_cross_reference()\r\n        # Trailer object\r\n        self._put_trailer()\r\n\r\n        if hasattr(self.destination, \"write\"):\r\n            output = self._output_to_io()\r\n        elif self.destination == 'string':\r\n            output = self._output_to_string()\r\n        else:\r\n            self._output_to_file()\r\n            output = None\r\n        return output", "response": "Prompt the objects to output pdf code and save to file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nputting the header line in the PDF file.", "response": "def _put_header(self):\r\n        \"\"\" Standard first line in a PDF. \"\"\"\r\n        self.session._out('%%PDF-%s' % self.pdf_version)\r\n        if self.session.compression:\r\n            self.session.buffer += '%' + chr(235) + chr(236) + chr(237) + chr(238) + \"\\n\""}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _put_pages(self):\r\n        self.document._get_orientation_changes()\r\n        self.document._output_pages()\r\n\r\n        # Pages Object, provides reference to page objects (Kids list).\r\n        self.session._add_object(1)\r\n        self.session._out('<</Type /Pages')\r\n        kids = '/Kids ['\r\n        for i in xrange(0, len(self.document.pages)):\r\n            kids += str(3 + 2 * i) + ' 0 R '\r\n        self.session._out(kids + ']')\r\n        self.session._out('/Count %s' % len(self.document.pages))\r\n\r\n        # Overall size of the default PDF page\r\n        self.session._out('/MediaBox [0 0 %.2f %.2f]' %\r\n                          (self.document.page.width,\r\n                           self.document.page.height))\r\n        self.session._out('>>')\r\n        self.session._out('endobj')", "response": "Create the pages object and output it."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a dictionary containing the resource names and the font numbers.", "response": "def _put_resource_dict(self):\r\n        \"\"\" Creates PDF reference to resource objects.\r\n\r\n        \"\"\"\r\n        self.session._add_object(2)\r\n        self.session._out('<<')\r\n        self.session._out('/ProcSet [/PDF /Text /ImageB /ImageC /ImageI]')\r\n        self.session._out('/Font <<')\r\n        for font in self.document.fonts:\r\n            self.session._out('/F%s %s 0 R' % (font.index, font.number))\r\n        self.session._out('>>')\r\n        if self.document.images:\r\n            self.session._out('/XObject <<')\r\n            for image in self.document.images:\r\n                self.session._out('/I%s %s 0 R' % (image.index, image.number))\r\n            self.session._out('>>')\r\n        self.session._out('>>')\r\n        self.session._out('endobj')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _put_information(self):\r\n        self.session._add_object()\r\n        self.session._out('<<')\r\n        self.session._out('/Producer ' + self._text_to_string(\r\n            'PDFLite, https://github.com/katerina7479'))\r\n        if self.title:\r\n            self.session._out('/Title ' + self._text_to_string(self.title))\r\n        if self.subject:\r\n            self.session._out('/Subject ' + self._text_to_string(self.subject))\r\n        if self.author:\r\n            self.session._out('/Author ' + self._text_to_string(self.author))\r\n        if self.keywords:\r\n            self.session._out('/Keywords ' +\r\n                              self._text_to_string(self.keywords))\r\n        if self.creator:\r\n            self.session._out('/Creator ' + self._text_to_string(self.creator))\r\n        self.session._out('/CreationDate ' + self._text_to_string(\r\n            'D:' + datetime.now().strftime('%Y%m%d%H%M%S')))\r\n        self.session._out('>>')\r\n        self.session._out('endobj')", "response": "Put the PDF Information object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _put_catalog(self):\r\n        self.session._add_object()\r\n        self.session._out('<<')\r\n\r\n        self.session._out('/Type /Catalog')\r\n        self.session._out('/Pages 1 0 R')\r\n        if self.zoom_mode == 'fullpage':\r\n            self.session._out('/OpenAction [3 0 R /Fit]')\r\n        elif self.zoom_mode == 'fullwidth':\r\n            self.session._out('/OpenAction [3 0 R /FitH null]')\r\n        elif self.zoom_mode == 'real':\r\n            self.session._out('/OpenAction [3 0 R /XYZ null null 1]')\r\n        elif not isinstance(self.zoom_mode, basestring):\r\n            self.session._out(\r\n                '/OpenAction [3 0 R /XYZ null null ' +\r\n                (self.zoom_mode / 100) + ']')\r\n\r\n        if self.layout_mode == 'single':\r\n            self.session._out('/PageLayout /SinglePage')\r\n        elif self.layout_mode == 'continuous':\r\n            self.session._out('/PageLayout /OneColumn')\r\n        elif self.layout_mode == 'two':\r\n            self.session._out('/PageLayout /TwoColumnLeft')\r\n        self.session._out('>>')\r\n        self.session._out('endobj')", "response": "Writes a catalog object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _put_cross_reference(self):\r\n        self.session._out('xref')\r\n        self.session._out('0 %s' % len(self.session.objects))\r\n        self.session._out('0000000000 65535 f ')\r\n        for obj in self.session.objects:\r\n            if isinstance(obj, basestring):\r\n                pass\r\n            else:\r\n                self.session._out('%010d 00000 n ' % obj.offset)", "response": "Put a Cross Reference Object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave the session to file.", "response": "def _output_to_file(self):\r\n        \"\"\" Save to filepath specified on\r\n            init. (Will throw an error if\r\n            the document is already open).\r\n\r\n        \"\"\"\r\n        f = open(self.filepath, 'wb')\r\n        if not f:\r\n            raise Exception('Unable to create output file: ', self.filepath)\r\n        f.write(self.session.buffer)\r\n        f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _text_to_string(self, text):\r\n        if text:\r\n            for i,j in [(\"\\\\\",\"\\\\\\\\\"),(\")\",\"\\\\)\"),(\"(\", \"\\\\(\")]:\r\n                text = text.replace(i, j)\r\n            text = \"(%s)\" % text\r\n        else:\r\n            text = 'None'\r\n        return text", "response": "Converts text to string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef floyd(seqs, f=None, start=None, key=lambda x: x):\n\n    tortise, hare = seqs\n\n    yield hare.next()\n    tortise_value = tortise.next()\n    hare_value = hare.next()\n    while hare_value != tortise_value:\n        yield hare_value\n        yield hare.next()\n        hare_value = hare.next()\n        tortise_value = tortise.next()\n\n    if f is None:\n        raise CycleDetected()\n\n    hare_value = f(hare_value)\n    first = 0\n    tortise_value = start\n    while key(tortise_value) != key(hare_value):\n        tortise_value = f(tortise_value)\n        hare_value = f(hare_value)\n        first += 1\n\n    period = 1\n    hare_value = f(tortise_value)\n    while key(tortise_value) != key(hare_value):\n        hare_value = f(hare_value)\n        period += 1\n\n    raise CycleDetected(period=period, first=first)", "response": "Floyd s Cycle Detector."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gosper(seqs, f=None, start=None, key=lambda x: x):\n\n    tab = []\n    for c, value in enumerate(seqs[0], start=1):\n        yield value\n        try:\n            e = tab.index(key(value))\n            raise CycleDetected(\n                period=c - ((((c >> e) - 1) | 1) << e))\n        except ValueError:\n            try:\n                tab[(c ^ (c - 1)).bit_length() - 1] = key(value)\n            except IndexError:\n                tab.append(value)", "response": "A generator function that yields values yielded by sequence_a if it terminates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef brent(seqs, f=None, start=None, key=lambda x: x):\n\n    power = period = 1\n    tortise, hare = seqs\n\n    yield hare.next()\n    tortise_value = tortise.next()\n    hare_value = hare.next()\n    while key(tortise_value) != key(hare_value):\n        yield hare_value\n        if power == period:\n            power *= 2\n            period = 0\n            if f:\n                tortise = f_generator(f, hare_value)\n                tortise_value = tortise.next()\n            else:\n                while tortise_value != hare_value:\n                    tortise_value = tortise.next()\n        hare_value = hare.next()\n        period += 1\n\n    if f is None:\n        raise CycleDetected()\n\n    first = 0\n    tortise_value = hare_value = start\n    for _ in xrange(period):\n        hare_value = f(hare_value)\n\n    while key(tortise_value) != key(hare_value):\n        tortise_value = f(tortise_value)\n        hare_value = f(hare_value)\n        first += 1\n    raise CycleDetected(period=period, first=first)", "response": "A generator that yields all the possible values of a given function in a sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntest to see if the line can have enough space for the given length.", "response": "def x_fit(self, test_length):\r\n        \"\"\" Test to see if the line can has enough space for the given length. \"\"\"\r\n        if (self.x + test_length) >= self.xmax:\r\n            return False\r\n        else:\r\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntest to see if the page has enough space for the given text height.", "response": "def y_fit(self, test_length):\r\n        \"\"\" Test to see if the page has enough space for the given text height. \"\"\"\r\n        if (self.y + test_length) >= self.ymax:\r\n            return False\r\n        else:\r\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef x_is_greater_than(self, test_ordinate):\r\n        self._is_coordinate(test_ordinate)\r\n        if self.x > test_ordinate.x:\r\n            return True\r\n        else:\r\n            return False", "response": "Returns True if self. x is greater than test_ordinate."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef y_is_greater_than(self, test_ordinate):\r\n        self._is_coordinate(test_ordinate)\r\n        if self.y > test_ordinate.y:\r\n            return True\r\n        else:\r\n            return False", "response": "Returns True if y is greater than or equal to the y of the other instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a copy of this cursor and return it.", "response": "def copy(self):\r\n        \"\"\" Create a copy, and return it.\"\"\"\r\n        new_cursor = self.__class__(self.x, self.y)\r\n        new_cursor.set_bounds(self.xmin, self.ymin, self.xmax, self.ymax, self.ymaxmax)\r\n        new_cursor.set_deltas(self.dx, self.dy)\r\n        return new_cursor"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef x_plus(self, dx=None):\r\n        if dx is None:\r\n            self.x += self.dx\r\n        else:\r\n            self.x = self.x + dx", "response": "Adds the x attribute to the current value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_page_size(self, layout):\r\n        self.layout = layout.lower()\r\n        if self.layout in self.layout_dict:\r\n            self.page_size = self.layout_dict[self.layout]\r\n        else:\r\n            dimensions = self.layout.split('x')\r\n            if len(dimensions) == 2:\r\n                self.page_size = (float(dimensions[0]) * 72, float(dimensions[1]) * 72)\r\n            else:\r\n                raise IndexError(\"Page is two dimensions, given: %s\" % len(dimensions))", "response": "Set page size of the related object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _draw(self):\n        self._compile()\n        self.rows[0]._advance_first_row()\n        self._set_borders()\n        self._draw_fill()\n        self._draw_borders()\n        self._draw_text()\n        self._set_final_cursor()", "response": "Don't use this, use document.draw_table"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new label and returns the response", "response": "def create(self, name, description=None, color=None):\n        \"\"\"\n        Creates a new label and returns the response\n\n        :param name: The label name\n        :type name: str\n\n        :param description: An optional description for the label. The name is\n            used if no description is provided.\n        :type description: str\n\n        :param color: The hex color for the label (ex: 'ff0000' for red). If no\n            color is provided, a random one will be assigned.\n        :type color: str\n\n        :returns: The response of your post\n        :rtype: dict\n\n        :raises: This will raise a\n            :class:`ServerException<logentries_api.exceptions.ServerException>`\n            if there is an error from Logentries\n        \"\"\"\n        data = {\n            'name': name,\n            'title': name,\n            'description': description or name,\n            'appearance': {\n                'color': color or random_color()\n            }\n        }\n        # Yes, it's confusing. the `/tags/` endpoint is used for labels\n        return self._post(\n            request=ApiActions.CREATE.value,\n            uri=ApiUri.TAGS.value,\n            params=data\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list(self):\n        return self._post(\n            request='list',\n            uri=ApiUri.TAGS.value,\n        ).get('tags')", "response": "Get all current labels in the Logentries API"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, name):\n        labels = self.list()\n        return [\n            label\n            for label\n            in labels\n            if name == label.get('name')\n        ]", "response": "Get labels by name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate a Label with the data in the format of dict.", "response": "def update(self, label):\n        \"\"\"\n        Update a Label\n\n        :param label: The data to update. Must include keys:\n\n            * id (str)\n            * appearance (dict)\n            * description (str)\n            * name (str)\n            * title (str)\n        :type label: dict\n\n        Example:\n\n        .. code-block:: python\n\n            Labels().update(\n                label={\n                    'id': 'd9d4596e-49e4-4135-b3b3-847f9e7c1f43',\n                    'appearance': {'color': '278abe'},\n                    'name': 'My Sandbox',\n                    'description': 'My Sandbox',\n                    'title': 'My Sandbox',\n                }\n            )\n\n        :return:\n        :rtype: dict\n        \"\"\"\n        data = {\n            'id': label['id'],\n            'name': label['name'],\n            'appearance': label['appearance'],\n            'description': label['description'],\n            'title': label['title'],\n        }\n        return self._post(\n            request=ApiActions.UPDATE.value,\n            uri=ApiUri.TAGS.value,\n            params=data\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete the specified label s ID", "response": "def delete(self, id):\n        \"\"\"\n        Delete the specified label\n\n        :param id: the label's ID\n        :type id: str\n\n        :raises: This will raise a\n            :class:`ServerException<logentries_api.exceptions.ServerException>`\n            if there is an error from Logentries\n        \"\"\"\n        return self._post(\n            request=ApiActions.DELETE.value,\n            uri=ApiUri.TAGS.value,\n            params={'id': id}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, label_id):\n        data = {\n            'type': 'tagit',\n            'rate_count': 0,\n            'rate_range': 'day',\n            'limit_count': 0,\n            'limit_range': 'day',\n            'schedule': [],\n            'enabled': True,\n            'args': {\n                'sn': label_id,\n                'tag_sn': label_id\n            }\n        }\n        # Yes, it's confusing. the `/actions/` endpoint is used for tags, while\n        # the /tags/ endpoint is used for labels.\n        return self._post(\n            request=ApiActions.CREATE.value,\n            uri=ApiUri.ACTIONS.value,\n            params=data\n        )", "response": "This method creates a new tag entry in the Logentries database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all current tags in the logentries", "response": "def list(self):\n        \"\"\"\n        Get all current tags\n\n        :return: All tags\n        :rtype: list of dict\n\n        :raises: This will raise a\n            :class:`ServerException<logentries_api.exceptions.ServerException>`\n            if there is an error from Logentries\n        \"\"\"\n        return list(\n            filter(\n                lambda x: x.get('type') == 'tagit',  # pragma: no cover\n                self._post(\n                    request=ApiActions.LIST.value,\n                    uri=ApiUri.ACTIONS.value,\n                ).get('actions')\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets tags by a label s sn key.", "response": "def get(self, label_sn):\n        \"\"\"\n        Get tags by a label's sn key\n\n        :param label_sn: A corresponding label's ``sn`` key.\n        :type label_sn: str or int\n\n        :return: A list of matching tags. An empty list is returned if there are\n            not any matches\n        :rtype: list of dict\n\n        :raises: This will raise a\n            :class:`ServerException<logentries_api.exceptions.ServerException>`\n            if there is an error from Logentries\n        \"\"\"\n        tags = self.list()\n        return [\n            tag\n            for tag\n            in tags\n            if str(label_sn) in tag.get('args', {}).values()\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new hook with the given name and regexes and tags.", "response": "def create(self, name, regexes, tag_ids, logs=None):\n        \"\"\"\n        Create a hook\n\n        :param name: The hook's name (should be the same as the tag)\n        :type name: str\n\n        :param regexes: The list of regular expressions that Logentries expects.\n            Ex: `['user_agent = /curl\\/[\\d.]*/']` Would match where the\n            user-agent is curl.\n        :type regexes: list of str\n\n        :param tag_id: The ids of the tags to associate the hook with.\n            (The 'id' key of the create tag response)\n        :type tag_id: list of str\n\n        :param logs: The logs to add the hook to. Comes from the 'key'\n            key in the log dict.\n        :type logs: list of str\n\n        :returns: The response of your post\n        :rtype: dict\n\n        :raises: This will raise a\n            :class:`ServerException<logentries_api.exceptions.ServerException>`\n            if there is an error from Logentries\n        \"\"\"\n        data = {\n            'name': name,\n            'triggers': regexes,\n            'sources': logs or [],\n            'groups': [],\n            'actions': tag_ids\n        }\n        return self._post(\n            request=ApiActions.CREATE.value,\n            uri=ApiUri.HOOKS.value,\n            params=data\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list(self):\n        return self._post(\n            request=ApiActions.LIST.value,\n            uri=ApiUri.HOOKS.value,\n        ).get('hooks')", "response": "Get all current hooks"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a list of matching tags.", "response": "def get(self, name_or_tag_id):\n        \"\"\"\n        Get hooks by name or tag_id.\n        :param name_or_tag_id: The hook's name or associated tag['id']\n        :type name_or_tag_id: str\n\n        :return: A list of matching tags. An empty list is returned if there are\n            not any matches\n        :rtype: list of dict\n\n        :raises: This will raise a\n            :class:`ServerException<logentries_api.exceptions.ServerException>`\n            if there is an error from Logentries\n        \"\"\"\n        hooks = self.list()\n\n        return [\n            hook\n            for hook\n            in hooks\n            if name_or_tag_id in hook.get('actions')\n            or name_or_tag_id == hook.get('name')\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate a specific hook.", "response": "def update(self, hook):\n        \"\"\"\n        Update a hook\n\n        :param hook: The data to update. Must include keys:\n\n            * id (str)\n            * name (str)\n            * triggers (list of str)\n            * sources (list of str)\n            * groups (list of str)\n            * actions (list of str)\n        :type hook: dict\n\n        Example:\n\n        .. code-block:: python\n\n            Hooks().update(\n                hook={\n                    'id': 'd9d4596e-49e4-4135-b3b3-847f9e7c1f43',\n                    'name': 'My Sandbox',\n                    'triggers': [\n                        'host = you.example.com'\n                    ],\n                    'sources': [\n                        '4d42c719-4005-4929-aa4a-994da4b95040'\n                    ],\n                    'groups': [],\n                    'actions': [\n                        '9f6adf69-37b9-4a4b-88fb-c3fc4c781a11',\n                        'ddc36d71-33cb-4f4f-be1b-8591814b1946'\n                    ],\n                }\n            )\n\n        :return:\n        :rtype: dict\n        \"\"\"\n        data = {\n            'id': hook['id'],\n            'name': hook['name'],\n            'triggers': hook['triggers'],\n            'sources': hook['sources'],\n            'groups': hook['groups'],\n            'actions': hook['actions'],\n        }\n        return self._post(\n            request=ApiActions.UPDATE.value,\n            uri=ApiUri.HOOKS.value,\n            params=data\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self,\n               alert_config,\n               occurrence_frequency_count=None,\n               occurrence_frequency_unit=None,\n               alert_frequency_count=None,\n               alert_frequency_unit=None):\n        \"\"\"\n        Create a new alert\n\n        :param alert_config: A list of AlertConfig classes (Ex:\n            ``[EmailAlertConfig('me@mydomain.com')]``)\n        :type alert_config: list of\n            :class:`PagerDutyAlertConfig<logentries_api.alerts.PagerDutyAlertConfig>`,\n            :class:`WebHookAlertConfig<logentries_api.alerts.WebHookAlertConfig>`,\n            :class:`EmailAlertConfig<logentries_api.alerts.EmailAlertConfig>`,\n            :class:`SlackAlertConfig<logentries_api.alerts.SlackAlertConfig>`, or\n            :class:`HipChatAlertConfig<logentries_api.alerts.HipChatAlertConfig>`\n\n        :param occurrence_frequency_count: How many times per\n            ``alert_frequency_unit`` for a match before issuing an alert.\n            Defaults to 1\n        :type occurrence_frequency_count: int\n\n        :param occurrence_frequency_unit: The time period to monitor for sending\n            an alert. Must be 'day', or 'hour'. Defaults to 'hour'\n        :type occurrence_frequency_unit: str\n\n        :param alert_frequency_count: How many times per\n            ``alert_frequency_unit`` to issue an alert. Defaults to 1\n        :type alert_frequency_count: int\n\n        :param alert_frequency_unit: How often to regulate sending alerts.\n            Must be 'day', or 'hour'. Defaults to 'hour'\n        :type alert_frequency_unit: str\n\n        :returns: The response of your post\n        :rtype: dict\n\n        :raises: This will raise a\n            :class:`ServerException<logentries_api.exceptions.ServerException>`\n            if there is an error from Logentries\n        \"\"\"\n        data = {\n            'rate_count': occurrence_frequency_count or 1,\n            'rate_range': occurrence_frequency_unit or 'hour',\n            'limit_count': alert_frequency_count or 1,\n            'limit_range': alert_frequency_unit or 'hour',\n            'schedule': [],\n            'enabled': True,\n        }\n        data.update(alert_config.args())\n\n        # Yes, it's confusing. the `/actions/` endpoint is used for alerts, while\n        # the /tags/ endpoint is used for labels.\n        return self._post(\n            request=ApiActions.CREATE.value,\n            uri=ApiUri.ACTIONS.value,\n            params=data\n        )", "response": "Creates a new alert in the logentries base."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting alerts that match the provided alert type and args.", "response": "def get(self, alert_type, alert_args=None):\n        \"\"\"\n        Get alerts that match the alert type and args.\n\n        :param alert_type: The type of the alert. Must be one of 'pagerduty',\n            'mailto', 'webhook', 'slack', or 'hipchat'\n        :type alert_type: str\n\n        :param alert_args: The args for the alert. The provided args must be a\n            subset of the actual alert args. If no args are provided, all\n            alerts matching the ``alert_type`` are returned. For example:\n            ``.get('mailto', alert_args={'direct': 'me@mydomain.com'})`` or\n            ``.get('slack', {'url': 'https://hooks.slack.com/services...'})``\n\n        :return: A list of matching alerts. An empty list is returned if there\n            are not any matches\n        :rtype: list of dict\n\n        :raises: This will raise a\n            :class:`ServerException<logentries_api.exceptions.ServerException>`\n            if there is an error from Logentries\n        \"\"\"\n        alert_args = alert_args or {}\n\n        alerts = self.list()\n        return [\n            alert\n            for alert\n            in alerts\n            if alert.get('type') == alert_type\n            and dict_is_subset(alert_args, alert.get('args'))\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate an alert with the data in the format that is expected by the API.", "response": "def update(self, alert):\n        \"\"\"\n        Update an alert\n\n        :param alert: The data to update. Must include keys:\n\n            * id (str)\n            * rate_count (int)\n            * rate_range (str): 'day' or 'hour'\n            * limit_count (int)\n            * limit_range (str): 'day' or 'hour'\n            * type (str)\n            * schedule (list)\n            * args (dict)\n        :type alert: dict\n\n        Example:\n\n        .. code-block:: python\n\n            Alert().update(\n                alert={\n                    'id': 'd9d4596e-49e4-4135-b3b3-847f9e7c1f43',\n                    'args': {'direct': 'you@example.com'},\n                    'rate_count': 1,\n                    'rate_range': 'hour',\n                    'limit_count': 1,\n                    'limit_range': 'hour',\n                    'schedule': [],\n                    'enabled': True,\n                    'type': 'mailto',\n                }\n            )\n\n        :return:\n        :rtype: dict\n        \"\"\"\n        data = {\n            'id': alert['id'],\n            'args': alert['args'],\n            'rate_count': alert['rate_count'],\n            'rate_range': alert['rate_range'],\n            'limit_count': alert['limit_count'],\n            'limit_range': alert['limit_range'],\n            'schedule': alert['schedule'],\n            'enabled': alert['enabled'],\n            'type': alert['type'],\n        }\n\n        return self._post(\n            request=ApiActions.UPDATE.value,\n            uri=ApiUri.ACTIONS.value,\n            params=data\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize this Sphinx extension", "response": "def setup(app):\n    \"\"\"\n    Initialize this Sphinx extension\n    \"\"\"\n    app.setup_extension('sphinx.ext.todo')\n    app.setup_extension('sphinx.ext.mathjax')\n\n    app.setup_extension(\"sphinx.ext.intersphinx\")\n    app.config.intersphinx_mapping.update({\n        'https://docs.python.org/': None\n        })\n    app.config.intersphinx_mapping.update({\n        sage_doc_url + doc + \"/\": None\n        for doc in sage_documents\n        })\n    app.config.intersphinx_mapping.update({\n        sage_doc_url + \"reference/\" + module: None\n        for module in sage_modules\n        })\n\n    app.setup_extension(\"sphinx.ext.extlinks\")\n    app.config.extlinks.update({\n        'python': ('https://docs.python.org/release/'+pythonversion+'/%s', ''),\n        # Sage trac ticket shortcuts. For example, :trac:`7549` .\n        'trac': ('https://trac.sagemath.org/%s', 'trac ticket #'),\n        'wikipedia': ('https://en.wikipedia.org/wiki/%s', 'Wikipedia article '),\n        'arxiv': ('http://arxiv.org/abs/%s', 'Arxiv '),\n        'oeis': ('https://oeis.org/%s', 'OEIS sequence '),\n        'doi': ('https://dx.doi.org/%s', 'doi:'),\n        'pari': ('http://pari.math.u-bordeaux.fr/dochtml/help/%s', 'pari:'),\n        'mathscinet': ('http://www.ams.org/mathscinet-getitem?mr=%s', 'MathSciNet ')\n        })\n\n    app.config.html_theme = 'sage'"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve the location of the themes directory from the location of this package", "response": "def themes_path():\n    \"\"\"\n    Retrieve the location of the themes directory from the location of this package\n\n    This is taken from Sphinx's theme documentation\n    \"\"\"\n    package_dir = os.path.abspath(os.path.dirname(__file__))\n    return os.path.join(package_dir, 'themes')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _post(self, request, uri, params=None):\n        request_data = {\n            'acl': self.account_key,\n            'account': self.account_key,\n            'request': request,\n        }\n\n        request_data.update(params or {})\n\n        response = requests.post(\n            url='https://api.logentries.com/v2/{}'.format(uri),\n            headers=self.headers,\n            data=json.dumps(request_data)\n        )\n\n        if not response.ok:\n            raise ServerException(\n                '{}: {}'.format(response.status_code, response.text))\n        return response.json()", "response": "A wrapper for making a POST request to the Logentries API endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list(self):\n        response = requests.get(self.base_url)\n\n        if not response.ok:\n            raise ServerException(\n                '{}: {}'.format(response.status_code, response.text))\n\n        return {\n            host.get('name'): [\n                log.get('key')\n                for log\n                in host.get('logs')]\n            for host\n            in response.json().get('list')\n        }", "response": "Get all log sets in the Logentries API."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, log_set):\n        response = requests.get(self.base_url + log_set.rstrip('/'))\n\n        if not response.ok:\n            raise ServerException(\n                '{}: {}'.format(response.status_code, response.text))\n        return response.json()", "response": "Get a specific log set or log."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_attacker_slider(dest_list, occ_bb, piece_bb, target_bb, pos,\n                             domain):\n    \"\"\" Find a slider attacker\n\n    Parameters\n    ----------\n    dest_list : list\n        To store the results.\n    occ_bb : int, bitboard\n        Occupancy bitboard.\n    piece_bb : int, bitboard\n        Bitboard with the position of the attacker piece.\n    target_bb : int, bitboard\n        Occupancy bitboard without any of the sliders in question.\n    pos : int\n        Target position.\n    pos_map : function\n        Mapping between a board position and its position in a single\n        rotated/translated rank produced with domain_trans.\n    domain_trans : function\n        Transformation from a rank/file/diagonal/anti-diagonal containing pos\n        to a single rank\n    pos_inv_map : function\n        Inverse of pos_map\n    \"\"\"\n    pos_map, domain_trans, pos_inv_map = domain\n    r = reach[pos_map(pos)][domain_trans(target_bb, pos)]\n    m = r & domain_trans(piece_bb, pos)\n    while m:\n        r = m&-m\n        rpos = r.bit_length()-1\n        if not (ray[rpos][pos_map(pos)] & domain_trans(occ_bb, pos)):\n            dest_list.append(pos_inv_map(rpos, pos))\n        m ^= r", "response": "Find a slider attacker that is in question."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef duration(self):\n        '''\n        The approximate transit duration for the general case of an eccentric orbit\n        \n        '''\n        ecc = self.ecc if not np.isnan(self.ecc) else np.sqrt(self.ecw**2 + self.esw**2)\n        esw = self.esw if not np.isnan(self.esw) else ecc * np.sin(self.w)\n        aRs = ((G * self.rhos * (1. + self.MpMs) * \n              (self.per * DAYSEC)**2.) / (3. * np.pi))**(1./3.)\n        inc = np.arccos(self.bcirc/aRs)\n        becc = self.bcirc * (1 - ecc**2)/(1 - esw)\n        tdur = self.per / 2. / np.pi * np.arcsin(((1. + self.RpRs)**2 -\n               becc**2)**0.5 / (np.sin(inc) * aRs))\n        tdur *= np.sqrt(1. - ecc**2.)/(1. - esw)\n        return tdur", "response": "Returns the approximate transit duration for the general case of an eccentric orbit\n        "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the transit keyword arguments", "response": "def update(self, **kwargs):\n    '''\n    Update the transit keyword arguments\n    \n    '''\n    \n    if kwargs.get('verify_kwargs', True):\n      valid = [y[0] for x in [TRANSIT, LIMBDARK, SETTINGS] for y in x._fields_]       # List of valid kwargs\n      valid += ['b', 'times']                                                         # These are special!\n      for k in kwargs.keys():\n        if k not in valid:\n          raise Exception(\"Invalid kwarg '%s'.\" % k)  \n  \n    if ('q1' in kwargs.keys()) and ('q2' in kwargs.keys()):\n      kwargs.update({'ldmodel': KIPPING})\n    elif ('c1' in kwargs.keys()) and ('c2' in kwargs.keys()) and \\\n         ('c3' in kwargs.keys()) and ('c4' in kwargs.keys()):\n      kwargs.update({'ldmodel': NONLINEAR})\n    \n    self.limbdark.update(**kwargs)\n    self.transit.update(**kwargs)\n    self.settings.update(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Compute(self):\n    '''\n    Computes the light curve model\n    \n    '''\n    \n    err = _Compute(self.transit, self.limbdark, self.settings, self.arrays)\n    if err != _ERR_NONE: RaiseError(err)", "response": "Computes the light curve model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbin the light curve model to the provided time array.", "response": "def Bin(self):\n    '''\n    Bins the light curve model to the provided time array\n    \n    '''\n    \n    err = _Bin(self.transit, self.limbdark, self.settings, self.arrays)\n    if err != _ERR_NONE: RaiseError(err)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfree the memory used by all of the dynamically allocated C arrays.", "response": "def Free(self):\n    '''\n    Frees the memory used by all of the dynamically allocated C arrays.\n    \n    '''\n\n    if self.arrays._calloc:\n      _dbl_free(self.arrays._time)\n      _dbl_free(self.arrays._flux)\n      _dbl_free(self.arrays._bflx)\n      _dbl_free(self.arrays._M)\n      _dbl_free(self.arrays._E)\n      _dbl_free(self.arrays._f)\n      _dbl_free(self.arrays._r)\n      _dbl_free(self.arrays._x)\n      _dbl_free(self.arrays._y)\n      _dbl_free(self.arrays._z)\n      self.arrays._calloc = 0\n    if self.arrays._balloc:  \n      _dbl_free(self.arrays._b)\n      self.arrays._balloc = 0\n    if self.arrays._ialloc:\n      _dbl_free(self.arrays._iarr)\n      self.arrays._ialloc = 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread data from the socket and writes it to the buffer.", "response": "def __recv(self, size=4096):\n        \"\"\"Reads data from the socket.\n\n        Raises:\n            NNTPError: When connection times out or read from socket fails.\n        \"\"\"\n        data = self.socket.recv(size)\n        if not data:\n            raise NNTPError(\"Failed to read from socket\")\n        self.__buffer.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __buf_gen(self, length=0):\n        while True:\n            buf = self.__buffer.read(length)\n            if not buf:\n                self.__recv()\n                continue\n            yield buf", "response": "Generator that reads a block of data from the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef status(self):\n        line = next(self.__line_gen()).rstrip()\n        parts = line.split(None, 1)\n\n        try:\n            code, message = int(parts[0]), \"\"\n        except ValueError:\n            raise NNTPProtocolError(line)\n\n        if code < 100 or code >= 600:\n            raise NNTPProtocolError(line)\n\n        if len(parts) > 1:\n            message = parts[1]\n\n        if 400 <= code <= 499:\n            raise NNTPTemporaryError(code, message)\n\n        if 500 <= code <= 599:\n            raise NNTPPermanentError(code, message)\n\n        return code, message", "response": "Reads a status line from the socket and returns it as a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __info_gzip_gen(self):\n        self.__generating = True\n\n        inflate = zlib.decompressobj(15+32)\n\n        done, buf = False, fifo.Fifo()\n        while not done:\n            try:\n                data = inflate.decompress(next(self.__buf_gen()))\n            except zlib.error:\n                raise NNTPDataError(\"Decompression failed\")\n            if data:\n                buf.write(data)\n            if inflate.unused_data:\n                buf.write(inflate.unused_data)\n            for line in buf:\n                if line == \".\\r\\n\":\n                    done = True\n                    break\n                if line.startswith(\".\"):\n                    yield line[1:]\n                yield line\n\n        self.__generating = False", "response": "Generator for the lines of a compressed info response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __info_yenczlib_gen(self):\n\n        escape = 0\n        dcrc32 = 0\n        inflate = zlib.decompressobj(-15)\n\n        # header\n        header = next(self.__info_plain_gen())\n        if not header.startswith(\"=ybegin\"):\n            raise NNTPDataError(\"Bad yEnc header\")\n\n        # data\n        buf, trailer = fifo.Fifo(), \"\"\n        for line in self.__info_plain_gen():\n            if line.startswith(\"=yend\"):\n                trailer = line\n                continue\n            data, escape, dcrc32 = yenc.decode(line, escape, dcrc32)\n            try:\n                data = inflate.decompress(data)\n            except zlib.error:\n                raise NNTPDataError(\"Decompression failed\")\n            if not data:\n                continue\n            buf.write(data)\n            for l in buf:\n                yield l\n\n        # trailer\n        if not trailer:\n            raise NNTPDataError(\"Missing yEnc trailer\")\n\n        # expected crc32\n        ecrc32 = yenc.crc32(trailer)\n        if ecrc32 is None:\n            raise NNTPDataError(\"Bad yEnc trailer\")\n\n        # check crc32\n        if ecrc32 != dcrc32 & 0xffffffff:\n            raise NNTPDataError(\"Bad yEnc CRC\")", "response": "Generator for the lines of a compressed info response."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef info_gen(self, code, message, compressed=False):\n        if \"COMPRESS=GZIP\" in message:\n            return self.__info_gzip_gen()\n        if compressed:\n            return self.__info_yenczlib_gen()\n        return self.__info_plain_gen()", "response": "This function is used to generate the info for a specific entry point."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef info(self, code, message, compressed=False):\n        return \"\".join([x for x in self.info_gen(code, message, compressed)])", "response": "Returns the complete content of an info response."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling a command on the server.", "response": "def command(self, verb, args=None):\n        \"\"\"Call a command on the server.\n\n        If the user has not authenticated then authentication will be done\n        as part of calling the command on the server.\n\n        For commands that don't return a status message the status message\n        will default to an empty string.\n\n        Args:\n            verb: The verb of the command to call.\n            args: The arguments of the command as a string (default None).\n\n        Returns:\n            A tuple of status code (as an integer) and status message.\n\n        Note:\n            You can run raw commands by supplying the full command (including\n            args) in the verb.\n\n        Note: Although it is possible you shouldn't issue more than one command\n            at a time by adding newlines to the verb as it will most likely lead\n            to undesirable results.\n        \"\"\"\n        if self.__generating:\n            raise NNTPSyncError(\"Command issued while a generator is active\")\n\n        cmd = verb\n        if args:\n            cmd += \" \" + args\n        cmd += \"\\r\\n\"\n\n        self.socket.sendall(cmd)\n\n        try:\n            code, message = self.status()\n        except NNTPTemporaryError as e:\n            if e.code() != 480:\n                raise e\n            code, message = self.command(\"AUTHINFO USER\", self.username)\n            if code == 381:\n                code, message = self.command(\"AUTHINFO PASS\", self.password)\n            if code != 281:\n                raise NNTPReplyError(code, message)\n            code, message = self.command(verb, args)\n\n        return code, message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mode_reader(self):\n        code, message = self.command(\"MODE READER\")\n        if not code in [200, 201]:\n            raise NNTPReplyError(code, message)\n\n        return code == 200", "response": "Instructs a mode - switching server to switch modes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nquit command. This command is used to close the connection.", "response": "def quit(self):\n        \"\"\"QUIT command.\n\n        Tells the server to close the connection. After the server acknowledges\n        the request to quit the connection is closed both at the server and\n        client. Only useful for graceful shutdown. If you are in a generator\n        use close() instead.\n\n        Once this method has been called, no other methods of the NNTPClient\n        object should be called.\n\n        See <http://tools.ietf.org/html/rfc3977#section-5.4>\n        \"\"\"\n        code, message = self.command(\"QUIT\")\n        if code != 205:\n            raise NNTPReplyError(code, message)\n\n        self.socket.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef date(self):\n        code, message = self.command(\"DATE\")\n        if code != 111:\n            raise NNTPReplyError(code, message)\n\n        ts = date.datetimeobj(message, fmt=\"%Y%m%d%H%M%S\")\n\n        return ts", "response": "Returns the UTC time according to the server as a datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef newnews_gen(self, pattern, timestamp):\n        if timestamp.tzinfo:\n            ts = timestamp.asttimezone(date.TZ_GMT)\n        else:\n            ts = timestamp.replace(tzinfo=date.TZ_GMT)\n\n        args = pattern\n        args += \" \" + ts.strftime(\"%Y%m%d %H%M%S %Z\")\n\n        code, message = self.command(\"NEWNEWS\", args)\n        if code != 230:\n            raise NNTPReplyError(code, message)\n\n        for line in self.info_gen(code, message):\n            yield line.strip()", "response": "Generator for the NEWNEWS command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_active_times_gen(self):\n        code, message = self.command(\"LIST ACTIVE.TIMES\")\n        if code != 215:\n            raise NNTPReplyError(code, message)\n\n        for line in self.info_gen(code, message):\n            parts = line.split()\n            try:\n                name = parts[0]\n                timestamp = date.datetimeobj_epoch(parts[1])\n                creator = parts[2]\n            except (IndexError, ValueError):\n                raise NNTPDataError(\"Invalid LIST ACTIVE.TIMES\")\n            yield name, timestamp, creator", "response": "Generator for the LIST ACTIVE. TIMES command."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_newsgroups_gen(self, pattern=None):\n        args = pattern\n\n        code, message = self.command(\"LIST NEWSGROUPS\", args)\n        if code != 215:\n            raise NNTPReplyError(code, message)\n\n        for line in self.info_gen(code, message):\n            parts = line.strip().split()\n            name, description = parts[0], \"\"\n            if len(parts) > 1:\n                description = parts[1]\n            yield name, description", "response": "Generator for the LIST NEWSGROUPS command."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list(self, keyword=None, arg=None):\n        return [x for x in self.list_gen(keyword, arg)]", "response": "A wrapper for all of the other list commands."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef next(self):\n        code, message = self.command(\"NEXT\")\n        if code != 223:\n            raise NNTPReplyError(code, message)\n\n        parts = message.split(None, 3)\n        try:\n            article = int(parts[0])\n            ident = parts[1]\n        except (IndexError, ValueError):\n            raise NNTPDataError(\"Invalid NEXT status\")\n\n        return article, ident", "response": "get the next NNTP article and identifier from the reply"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef article(self, msgid_article=None, decode=None):\n        args = None\n        if msgid_article is not None:\n            args = utils.unparse_msgid_article(msgid_article)\n\n        code, message = self.command(\"ARTICLE\", args)\n        if code != 220:\n            raise NNTPReplyError(code, message)\n\n        parts = message.split(None, 1)\n\n        try:\n            articleno = int(parts[0])\n        except ValueError:\n            raise NNTPProtocolError(message)\n\n        # headers\n        headers = utils.parse_headers(self.info_gen(code, message))\n\n        # decoding setup\n        decode = \"yEnc\" in headers.get(\"subject\", \"\")\n        escape = 0\n        crc32 = 0\n\n        # body\n        body = []\n        for line in self.info_gen(code, message):\n\n            # decode body if required\n            if decode:\n                if line.startswith(\"=y\"):\n                    continue\n                line, escape, crc32 = yenc.decode(line, escape, crc32)\n\n            body.append(line)\n\n        return articleno, headers, \"\".join(body)", "response": "get article info from NNTP"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the body of a message", "response": "def body(self, msgid_article=None, decode=False):\n        \"\"\"BODY command.\n        \"\"\"\n        args = None\n        if msgid_article is not None:\n            args = utils.unparse_msgid_article(msgid_article)\n\n        code, message = self.command(\"BODY\", args)\n        if code != 222:\n            raise NNTPReplyError(code, message)\n\n        escape = 0\n        crc32 = 0\n\n        body = []\n        for line in self.info_gen(code, message):\n\n            # decode body if required\n            if decode:\n                if line.startswith(\"=y\"):\n                    continue\n                line, escape, crc32 = yenc.decode(line, escape, crc32)\n\n            # body\n            body.append(line)\n\n        return \"\".join(body)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef xover_gen(self, range=None):\n        args = None\n        if range is not None:\n            args = utils.unparse_range(range)\n\n        code, message = self.command(\"XOVER\", args)\n        if code != 224:\n            raise NNTPReplyError(code, message)\n\n        for line in self.info_gen(code, message):\n            yield line.rstrip().split(\"\\t\")", "response": "Generator for the XOVER command."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef xfeature_compress_gzip(self, terminator=False):\n        args = \"TERMINATOR\" if terminator else None\n\n        code, message = self.command(\"XFEATURE COMPRESS GZIP\", args)\n        if code != 290:\n            raise NNTPReplyError(code, message)\n\n        return True", "response": "This command is used to compress the current NNTP session."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef post(self, headers={}, body=\"\"):\n        code, message = self.command(\"POST\")\n        if code != 340:\n            raise NNTPReplyError(code, message)\n\n        # send headers\n        hdrs = utils.unparse_headers(headers)\n        self.socket.sendall(hdrs)\n\n        if isinstance(body, basestring):\n            body = cStringIO.StringIO(body)\n\n        # send body\n        illegal = False\n        for line in body:\n            if line.startswith(\".\"):\n                line = \".\" + line\n            if line.endswith(\"\\r\\n\"):\n                line = line[:-2]\n            elif line.endswith(\"\\n\"):\n                line = line[:-1]\n            if any(c in line for c in \"\\0\\r\"):\n                illegal = True\n                break\n            self.socket.sendall(line + \"\\r\\n\")\n        self.socket.sendall(\".\\r\\n\")\n\n        # get status\n        code, message = self.status()\n\n        # check if illegal characters were detected\n        if illegal:\n            raise NNTPDataError(\"Illegal characters found\")\n\n        # check status\n        if code != 240:\n            raise NNTPReplyError(code, message)\n\n        # return message-id possible\n        message_id = message.split(None, 1)[0]\n        if message_id.startswith(\"<\") and message_id.endswith(\">\"):\n            return message_id\n\n        return True", "response": "This function sends a POST command to the NNTP server and returns the message - id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nassuming that all base classes inherit list tuple or dict have a lower method that can be used for the class", "response": "def _lower(v):\n    \"\"\"assumes that classes that inherit list, tuple or dict have a constructor\n    that is compatible with those base classes. If you are using classes that\n    don't satisfy this requirement you can subclass them and add a lower()\n    method for the class\"\"\"\n    if hasattr(v, \"lower\"):\n        return v.lower()\n    if isinstance(v, (list, tuple)):\n        return v.__class__(_lower(x) for x in v)\n    if isinstance(v, dict):\n        return v.__class__(_lower(v.items()))\n    return v"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef I(r, limbdark):\n  '''\n  The standard quadratic limb darkening law.\n  \n  :param ndarray r: The radius vector\n  :param limbdark: A :py:class:`pysyzygy.transit.LIMBDARK` instance containing \n                   the limb darkening law information\n  \n  :returns: The stellar intensity as a function of `r`\n  \n  '''\n  \n  if limbdark.ldmodel == QUADRATIC:\n    u1 = limbdark.u1\n    u2 = limbdark.u2\n    return (1-u1*(1-np.sqrt(1-r**2))-u2*(1-np.sqrt(1-r**2))**2)/(1-u1/3-u2/6)/np.pi\n  elif limbdark.ldmodel == KIPPING:\n    a = np.sqrt(limbdark.q1)\n    b = 2*limbdark.q2\n    u1 = a*b\n    u2 = a*(1 - b)\n    return (1-u1*(1-np.sqrt(1-r**2))-u2*(1-np.sqrt(1-r**2))**2)/(1-u1/3-u2/6)/np.pi\n  elif limbdark.ldmodel == NONLINEAR:\n    raise Exception('Nonlinear model not yet implemented!')                           # TODO!\n  else:\n    raise Exception('Invalid limb darkening model.')", "response": "Return the stellar intensity as a function of r"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nplots the light curve of the object.", "response": "def PlotTransit(compact = False, ldplot = True, plottitle = \"\", \n                xlim = None, binned = True, **kwargs):\n  '''\n  Plots a light curve described by `kwargs`\n  \n  :param bool compact: Display the compact version of the plot? Default `False`\n  :param bool ldplot: Displat the limb darkening inset? Default `True`\n  :param str plottitle: The title of the plot. Default `\"\"`\n  :param float xlim: The half-width of the orbit plot in stellar radii. Default is to \\\n                     auto adjust this\n  :param bool binned: Bin the light curve model to the exposure time? Default `True`\n  :param kwargs: Any keyword arguments to be passed to :py:func:`pysyzygy.transit.Transit`\n  \n  :returns fig: The :py:mod:`matplotlib` figure object\n  \n  '''\n\n  # Plotting\n  fig = pl.figure(figsize = (12,8))\n  fig.subplots_adjust(hspace=0.3)\n  ax1, ax2 = pl.subplot(211), pl.subplot(212)\n  if not compact:\n    fig.subplots_adjust(right = 0.7)\n    \n  t0 = kwargs.pop('t0', 0.)\n  trn = Transit(**kwargs)\n  try:\n    trn.Compute()\n    notransit = False\n  except Exception as e:\n    if str(e) == \"Object does not transit the star.\":\n      notransit = True\n    else: raise Exception(e)\n\n  time = trn.arrays.time + t0\n  \n  if not notransit:\n    if binned:\n      trn.Bin()\n      flux = trn.arrays.bflx\n    else:\n      flux = trn.arrays.flux\n\n    time = np.concatenate(([-1.e5], time, [1.e5]))                                    # Add baseline on each side\n    flux = np.concatenate(([1.], flux, [1.]))\n    ax1.plot(time, flux, '-', color='DarkBlue')\n    rng = np.max(flux) - np.min(flux)\n  \n    if rng > 0:\n      ax1.set_ylim(np.min(flux) - 0.1*rng, np.max(flux) + 0.1*rng)\n      left = np.argmax(flux < (1. - 1.e-8))\n      right = np.argmax(flux[left:] > (1. - 1.e-8)) + left\n      rng = time[right] - time[left]        \n      ax1.set_xlim(time[left] - rng, time[right] + rng)\n  \n  ax1.set_xlabel('Time (Days)', fontweight='bold')\n  ax1.set_ylabel('Normalized Flux', fontweight='bold')\n\n  # Adjust these for full-orbit plotting\n  maxpts = kwargs.get('maxpts', 10000); kwargs.update({'maxpts': maxpts})\n  per = kwargs.get('per', 10.); kwargs.update({'per': per})\n  kwargs.update({'fullorbit': True})\n  kwargs.update({'exppts': 30})\n  kwargs.update({'exptime': 50 * per / maxpts})\n  trn = Transit(**kwargs)\n  \n  try:\n    trn.Compute()\n  except Exception as e:\n    if str(e) == \"Object does not transit the star.\":\n      pass\n    else: raise Exception(e)\n\n  # Sky-projected motion\n  x = trn.arrays.x\n  y = trn.arrays.y\n  z = trn.arrays.z\n  inc = (np.arccos(trn.transit.bcirc/trn.transit.aRs)*180./np.pi)                     # Orbital inclination\n  \n  # Mask the star\n  for j in range(len(x)):\n    if (x[j]**2 + y[j]**2) < 1. and (z[j] > 0):\n      x[j] = np.nan\n      y[j] = np.nan\n  \n  # The star\n  r = np.linspace(0,1,100)\n  Ir = I(r,trn.limbdark)/I(0,trn.limbdark)\n  \n  for ri,Iri in zip(r[::-1],Ir[::-1]):\n    star = pl.Circle((0, 0), ri, color=str(0.95*Iri), alpha=1.)\n    ax2.add_artist(star)\n\n  # Inset: Limb darkening\n  if ldplot:\n    if compact:\n      inset1 = pl.axes([0.145, 0.32, .09, .1])\n    else:\n      inset1 = fig.add_axes([0.725,0.3,0.2,0.15])\n    inset1.plot(r,Ir,'k-')\n    pl.setp(inset1, xlim=(-0.1,1.1), ylim=(-0.1,1.1), xticks=[0,1], yticks=[0,1])\n    for tick in inset1.xaxis.get_major_ticks() + inset1.yaxis.get_major_ticks():\n      tick.label.set_fontsize(8)\n    inset1.set_ylabel(r'I/I$_0$', fontsize=8, labelpad=-8)\n    inset1.set_xlabel(r'r/R$_\\star$', fontsize=8, labelpad=-8)\n    inset1.set_title('Limb Darkening', fontweight='bold', fontsize=9)\n    \n  # Inset: Top view of orbit\n  if compact:\n    inset2 = pl.axes([0.135, 0.115, .1, .1])\n  else:\n    inset2 = fig.add_axes([0.725,0.1,0.2,0.15])\n  pl.setp(inset2, xticks=[], yticks=[])\n  trn.transit.bcirc = trn.transit.aRs                                                 # This ensures we are face-on\n  try:\n    trn.Compute()\n  except Exception as e:\n    if str(e) == \"Object does not transit the star.\":\n      pass\n    else: raise Exception(e)\n  xp = trn.arrays.x\n  yp = trn.arrays.y\n  inset2.plot(xp, yp, '-', color='DarkBlue', alpha=0.5)\n  # Draw some invisible dots at the corners to set the window size\n  xmin, xmax, ymin, ymax = np.nanmin(xp), np.nanmax(xp), np.nanmin(yp), np.nanmax(yp)\n  xrng = xmax - xmin\n  yrng = ymax - ymin\n  xmin -= 0.1*xrng; xmax += 0.1*xrng;\n  ymin -= 0.1*yrng; ymax += 0.1*yrng;\n  inset2.scatter([xmin,xmin,xmax,xmax], [ymin,ymax,ymin,ymax], alpha = 0.)\n  # Plot the star\n  for ri,Iri in zip(r[::-10],Ir[::-10]):\n    star = pl.Circle((0, 0), ri, color=str(0.95*Iri), alpha=1.)\n    inset2.add_artist(star)\n  # Plot the planet\n  ycenter = yp[np.where(np.abs(xp) == np.nanmin(np.abs(xp)))][0]\n  while ycenter > 0:\n    xp[np.where(np.abs(xp) == np.nanmin(np.abs(xp)))] = np.nan\n    ycenter = yp[np.where(np.abs(xp) == np.nanmin(np.abs(xp)))][0]\n  planet = pl.Circle((0, ycenter), trn.transit.RpRs, color='DarkBlue', alpha=1.)\n  inset2.add_artist(planet)\n  inset2.set_title('Top View', fontweight='bold', fontsize=9)\n  inset2.set_aspect('equal','datalim')\n  \n  # The orbit itself\n  with np.errstate(invalid='ignore'):\n    ax2.plot(x, y, '-', color='DarkBlue', lw = 1. if per < 30. else \n                                               max(1. - (per - 30.) / 100., 0.3) )\n\n  # The planet\n  with np.errstate(invalid = 'ignore'):\n    ycenter = y[np.where(np.abs(x) == np.nanmin(np.abs(x)))][0]\n  while ycenter > 0:\n    x[np.where(np.abs(x) == np.nanmin(np.abs(x)))] = np.nan\n    ycenter = y[np.where(np.abs(x) == np.nanmin(np.abs(x)))][0]\n  planet = pl.Circle((0, ycenter), trn.transit.RpRs, color='DarkBlue', alpha=1.)\n  ax2.add_artist(planet)\n  \n  # Force aspect\n  if xlim is None:\n    xlim = 1.1 * max(np.nanmax(x), np.nanmax(-x))\n  ax2.set_ylim(-xlim/3.2,xlim/3.2)\n  ax2.set_xlim(-xlim,xlim)\n  \n  ax2.set_xlabel(r'X (R$_\\star$)', fontweight='bold')\n  ax2.set_ylabel(r'Y (R$_\\star$)', fontweight='bold')\n  ax1.set_title(plottitle, fontsize=12)\n  \n  if not compact:\n    rect = 0.725,0.55,0.2,0.35\n    ax3 = fig.add_axes(rect)\n    ax3.xaxis.set_visible(False)\n    ax3.yaxis.set_visible(False)\n\n    # Table of parameters\n    ltable = [ r'$P:$',\n               r'$e:$',\n               r'$i:$',\n               r'$\\omega:$',\n               r'$\\rho_\\star:$',\n               r'$M_p:$',\n               r'$R_p:$',\n               r'$q_1:$',\n               r'$q_2:$']\n    rtable = [ r'$%.4f\\ \\mathrm{days}$' % trn.transit.per,\n               r'$%.5f$' % trn.transit.ecc,\n               r'$%.4f^\\circ$' % inc,\n               r'$%.3f^\\circ$' % (trn.transit.w*180./np.pi),\n               r'$%.5f\\ \\mathrm{g/cm^3}$' % trn.transit.rhos,\n               r'$%.5f\\ M_\\star$' % trn.transit.MpMs,\n               r'$%.5f\\ R_\\star$' % trn.transit.RpRs,\n               r'$%.5f$' % trn.limbdark.q1,\n               r'$%.5f$' % trn.limbdark.q2]\n    yt = 0.875\n    for l,r in zip(ltable, rtable):\n      ax3.annotate(l, xy=(0.25, yt), xycoords=\"axes fraction\", ha='right', fontsize=16)\n      ax3.annotate(r, xy=(0.35, yt), xycoords=\"axes fraction\", fontsize=16)\n      yt -= 0.1\n\n  return fig"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _offset(value):\n    o = int(value)\n    if o == 0:\n        return 0\n    a = abs(o)\n    s = a*36+(a%100)*24\n    return (o//a)*s", "response": "Parse the timezone offset in seconds."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a timestamp string to time in seconds since epoch.", "response": "def timestamp_d_b_Y_H_M_S(value):\n    \"\"\"Convert timestamp string to time in seconds since epoch.\n\n    Timestamps strings like '18 Jun 2013 12:00:00 GMT' are able to be converted\n    by this function.\n\n    Args:\n        value: A timestamp string in the format '%d %b %Y %H:%M:%S GMT'.\n\n    Returns:\n        The time in seconds since epoch as an integer.\n\n    Raises:\n        ValueError: If timestamp is invalid.\n        KeyError: If the abbrieviated month is invalid.\n\n    Note: The timezone is ignored it is simply assumed to be UTC/GMT.\n    \"\"\"\n    d, b, Y, t, Z = value.split()\n    H, M, S = t.split(\":\")\n    return int(calendar.timegm((\n        int(Y), _months[b.lower()], int(d), int(H), int(M), int(S), 0, 0, 0\n    )))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a string like 18 Jun 2013 12 : 00 GMT to a datetime object.", "response": "def datetimeobj_d_b_Y_H_M_S(value):\n    \"\"\"Convert timestamp string to a datetime object.\n\n    Timestamps strings like '18 Jun 2013 12:00:00 GMT' are able to be converted\n    by this function.\n\n    Args:\n        value: A timestamp string in the format '%d %b %Y %H:%M:%S GMT'.\n\n    Returns:\n        A datetime object.\n\n    Raises:\n        ValueError: If timestamp is invalid.\n        KeyError: If the abbrieviated month is invalid.\n\n    Note: The timezone is ignored it is simply assumed to be UTC/GMT.\n    \"\"\"\n    d, b, Y, t, Z = value.split()\n    H, M, S = t.split(\":\")\n    return datetime.datetime(\n        int(Y), _months[b.lower()], int(d), int(H), int(M), int(S), tzinfo=TZ_GMT\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a timestamp string to time in seconds since epoch.", "response": "def timestamp_a__d_b_Y_H_M_S_z(value):\n    \"\"\"Convert timestamp string to time in seconds since epoch.\n\n    Timestamps strings like 'Tue, 18 Jun 2013 22:00:00 +1000' are able to be\n    converted by this function.\n\n    Args:\n        value: A timestamp string in the format '%a, %d %b %Y %H:%M:%S %z'.\n\n    Returns:\n        The time in seconds since epoch as an integer.\n\n    Raises:\n        ValueError: If timestamp is invalid.\n        KeyError: If the abbrieviated month is invalid.\n    \"\"\"\n    a, d, b, Y, t, z = value.split()\n    H, M, S = t.split(\":\")\n    return int(calendar.timegm((\n        int(Y), _months[b.lower()], int(d), int(H), int(M), int(S), 0, 0, 0\n    ))) - _offset(z)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a timestamp string to a datetime object.", "response": "def datetimeobj_a__d_b_Y_H_M_S_z(value):\n    \"\"\"Convert timestamp string to a datetime object.\n\n    Timestamps strings like 'Tue, 18 Jun 2013 22:00:00 +1000' are able to be\n    converted by this function.\n\n    Args:\n        value: A timestamp string in the format '%a, %d %b %Y %H:%M:%S %z'.\n\n    Returns:\n        A datetime object.\n\n    Raises:\n        ValueError: If timestamp is invalid.\n        KeyError: If the abbrieviated month is invalid.\n    \"\"\"\n    a, d, b, Y, t, z = value.split()\n    H, M, S = t.split(\":\")\n    return datetime.datetime(\n        int(Y), _months[b.lower()], int(d), int(H), int(M), int(S),\n        tzinfo=dateutil.tz.tzoffset(None, _offset(z))\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a timestamp string to time in seconds since epoch.", "response": "def timestamp_YmdHMS(value):\n    \"\"\"Convert timestamp string to time in seconds since epoch.\n\n    Timestamps strings like '20130618120000' are able to be converted by this\n    function.\n\n    Args:\n        value: A timestamp string in the format '%Y%m%d%H%M%S'.\n\n    Returns:\n        The time in seconds since epoch as an integer.\n\n    Raises:\n        ValueError: If timestamp is invalid.\n\n    Note: The timezone is assumed to be UTC/GMT.\n    \"\"\"\n    i = int(value)\n    S = i\n    M = S//100\n    H = M//100\n    d = H//100\n    m = d//100\n    Y = m//100\n    return int(calendar.timegm((\n        Y % 10000, m % 100, d % 100, H % 100, M % 100, S % 100, 0, 0, 0)\n    ))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a timestamp string like 20130618120000 to a datetime object.", "response": "def datetimeobj_YmdHMS(value):\n    \"\"\"Convert timestamp string to a datetime object.\n\n    Timestamps strings like '20130618120000' are able to be converted by this\n    function.\n\n    Args:\n        value: A timestamp string in the format '%Y%m%d%H%M%S'.\n\n    Returns:\n        A datetime object.\n\n    Raises:\n        ValueError: If timestamp is invalid.\n\n    Note: The timezone is assumed to be UTC/GMT. \n    \"\"\"\n    i = int(value)\n    S = i\n    M = S//100\n    H = M//100\n    d = H//100\n    m = d//100\n    Y = m//100\n    return datetime.datetime(\n        Y % 10000, m % 100, d % 100, H % 100, M % 100, S % 100, tzinfo=TZ_GMT\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a timestamp string to a datetime object.", "response": "def datetimeobj_epoch(value):\n    \"\"\"Convert timestamp string to a datetime object.\n\n    Timestamps strings like '1383470155' are able to be converted by this\n    function.\n\n    Args:\n        value: A timestamp string as seconds since epoch.\n\n    Returns:\n        A datetime object.\n\n    Raises:\n        ValueError: If timestamp is invalid.\n    \"\"\"\n    return datetime.datetime.utcfromtimestamp(int(value)).replace(tzinfo=TZ_GMT)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a timestamp string to time in seconds since epoch.", "response": "def timestamp_fmt(value, fmt):\n    \"\"\"Convert timestamp string to time in seconds since epoch.\n\n    Wraps the datetime.datetime.strptime(). This is slow use the other\n    timestamp_*() functions if possible.\n\n    Args:\n        value: A timestamp string.\n        fmt: A timestamp format string.\n\n    Returns:\n        The time in seconds since epoch as an integer.\n    \"\"\"\n    return int(calendar.timegm(\n        datetime.datetime.strptime(value, fmt).utctimetuple()\n    ))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef timestamp_any(value):\n    return int(calendar.timegm(dateutil.parser.parse(value).utctimetuple()))", "response": "Convert a timestamp string to a time in seconds since epoch."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a datetime to a unix timestamp.", "response": "def timestamp(value, fmt=None):\n    \"\"\"Parse a datetime to a unix timestamp.\n\n    Uses fast custom parsing for common datetime formats or the slow dateutil\n    parser for other formats. This is a trade off between ease of use and speed\n    and is very useful for fast parsing of timestamp strings whose format may\n    standard but varied or unknown prior to parsing.\n\n    Common formats include:\n        1 Feb 2010 12:00:00 GMT\n        Mon, 1 Feb 2010 22:00:00 +1000\n        20100201120000\n        1383470155 (seconds since epoch)\n\n    See the other timestamp_*() functions for more details.\n\n    Args:\n        value: A string representing a datetime.\n        fmt: A timestamp format string like for time.strptime().\n\n    Returns:\n        The time in seconds since epoch as and integer for the value specified.\n    \"\"\"\n    if fmt:\n        return _timestamp_formats.get(fmt,\n            lambda v: timestamp_fmt(v, fmt)\n        )(value)\n\n    l = len(value)\n\n    if 19 <= l <= 24 and value[3] == \" \":\n        # '%d %b %Y %H:%M:%Sxxxx'\n        try:\n            return timestamp_d_b_Y_H_M_S(value)\n        except (KeyError, ValueError, OverflowError):\n            pass\n\n    if 30 <= l <= 31:\n        # '%a, %d %b %Y %H:%M:%S %z'\n        try:\n            return timestamp_a__d_b_Y_H_M_S_z(value)\n        except (KeyError, ValueError, OverflowError):\n            pass\n\n    if l == 14:\n        # '%Y%m%d%H%M%S'\n        try:\n            return timestamp_YmdHMS(value)\n        except (ValueError, OverflowError):\n            pass\n\n    # epoch timestamp\n    try:\n        return timestamp_epoch(value)\n    except ValueError:\n        pass\n\n    # slow version\n    return timestamp_any(value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef datetimeobj(value, fmt=None):\n    if fmt:\n        return _datetimeobj_formats.get(fmt,\n            lambda v: datetimeobj_fmt(v, fmt)\n        )(value)\n\n    l = len(value)\n\n    if 19 <= l <= 24 and value[3] == \" \":\n        # '%d %b %Y %H:%M:%Sxxxx'\n        try:\n            return datetimeobj_d_b_Y_H_M_S(value)\n        except (KeyError, ValueError):\n            pass\n\n    if 30 <= l <= 31:\n        # '%a, %d %b %Y %H:%M:%S %z'\n        try:\n            return datetimeobj_a__d_b_Y_H_M_S_z(value)\n        except (KeyError, ValueError):\n            pass\n\n    if l == 14:\n        # '%Y%m%d%H%M%S'\n        try:\n            return datetimeobj_YmdHMS(value)\n        except ValueError:\n            pass\n\n    # epoch timestamp\n    try:\n        return datetimeobj_epoch(value)\n    except ValueError:\n        pass\n\n    # slow version\n    return datetimeobj_any(value)", "response": "Parse a datetime to a datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fix_alert_config_dict(alert_config):\n        data = alert_config.args()\n        data['params_set'] = data.get('args')\n        del data['args']\n        return data", "response": "Fix the alert config dict for the correct key name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_login_payload(self, username, password):\n        payload = {\n            'csrfmiddlewaretoken': self._get_csrf_token(),\n            'ajax': '1',\n            'next': '/app/',\n            'username': username,\n            'password': password\n        }\n        return payload", "response": "returns the payload the login page expects\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _api_post(self, url, **kwargs):\n        response = self.session.post(\n            url=url,\n            headers=self._get_api_headers(),\n            **kwargs\n        )\n        if not response.ok:\n            raise ServerException(\n                '{0}: {1}'.format(\n                    response.status_code,\n                    response.text or response.reason\n                ))\n        return response.json()", "response": "Convenience method for posting a new object to a specific resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _api_delete(self, url, **kwargs):\n        response = self.session.delete(\n            url=url,\n            headers=self._get_api_headers(),\n            **kwargs\n        )\n        if not response.ok:\n            raise ServerException(\n                '{0}: {1}'.format(\n                    response.status_code,\n                    response.text or response.reason\n                ))\n        return response", "response": "Convenience method for deleting a resource from the API."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _login(self, username, password):\n\n        login_url = 'https://logentries.com/login/'\n        login_page_response = self.session.get(url=login_url, headers=self.default_headers)\n        if not login_page_response.ok:\n            raise ServerException(login_page_response.text)\n\n        login_headers = {\n            'Referer': login_url,\n            'X-Requested-With': 'XMLHttpRequest',\n        }\n        login_headers.update(self.default_headers)\n        login_response = self.session.post(\n            'https://logentries.com/login/ajax/',\n            headers=login_headers,\n            data=self._get_login_payload(\n                username,\n                password),\n        )\n        if not login_response.ok:\n            raise ServerException(login_response.text)\n\n        app_response = self.session.get('https://logentries.com/app/', headers=self.default_headers)\n        return app_response.url.split('/')[-1]", "response": "Login to the logentries server."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists all scheduled_queries :return: A list of all scheduled query dicts :rtype: list of dict :raises: This will raise a :class:`ServerException<logentries_api.exceptions.ServerException>` if there is an error from Logentries", "response": "def list_scheduled_queries(self):\n        \"\"\"\n        List all scheduled_queries\n\n        :return: A list of all scheduled query dicts\n        :rtype: list of dict\n\n        :raises: This will raise a\n            :class:`ServerException<logentries_api.exceptions.ServerException>`\n            if there is an error from Logentries\n        \"\"\"\n        url = 'https://logentries.com/rest/{account_id}/api/scheduled_queries/'.format(\n            account_id=self.account_id)\n        return self._api_get(url=url).get('scheduled_searches')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist all tags for the account.", "response": "def list_tags(self):\n        \"\"\"\n        List all tags for the account.\n\n        The response differs from ``Hooks().list()``, in that tag dicts for\n        anomaly alerts include a 'scheduled_query_id' key with the value being\n        the UUID for the associated scheduled query\n\n        :return: A list of all tag dicts\n        :rtype: list of dict\n\n        :raises: This will raise a\n            :class:`ServerException<logentries_api.exceptions.ServerException>`\n            if there is an error from Logentries\n        \"\"\"\n        url = 'https://logentries.com/rest/{account_id}/api/tags/'.format(\n            account_id=self.account_id)\n        return self._api_get(url=url).get('tags')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the alert by name or id.", "response": "def get(self, name_or_id):\n        \"\"\"\n        Get alert by name or id\n\n        :param name_or_id: The alert's name or id\n        :type name_or_id: str\n\n        :return: A list of matching tags. An empty list is returned if there are\n            not any matches\n        :rtype: list of dict\n\n        :raises: This will raise a\n            :class:`ServerException<logentries_api.exceptions.ServerException>`\n            if there is an error from Logentries\n        \"\"\"\n        return [\n            tag\n            for tag\n            in self.list_tags()\n            if name_or_id == tag.get('id')\n            or name_or_id == tag.get('name')\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, name, patterns, logs, trigger_config, alert_reports):\n        data = {\n            'tag': {\n                'actions': [\n                    alert_report.to_dict()\n                    for alert_report\n                    in alert_reports\n                ],\n                'name': name,\n                'patterns': patterns,\n                'sources': [\n                    {'id': log}\n                    for log\n                    in logs\n                ],\n                'sub_type': 'InactivityAlert',\n                'type': 'AlertNotify'\n            }\n        }\n        data['tag'].update(trigger_config.to_dict())\n\n        return self._api_post(\n            url=self.url_template.format(account_id=self.account_id),\n            data=json.dumps(data, sort_keys=True)\n        )", "response": "Creates an inactivity alert"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes the specified InactivityAlert", "response": "def delete(self, tag_id):\n        \"\"\"\n        Delete the specified InactivityAlert\n\n        :param tag_id: The tag ID to delete\n        :type tag_id: str\n\n        :raises: This will raise a\n            :class:`ServerException <logentries_api.exceptions.ServerException>`\n            if there is an error from Logentries\n        \"\"\"\n        tag_url = 'https://logentries.com/rest/{account_id}/api/tags/{tag_id}'\n\n        self._api_delete(\n            url=tag_url.format(\n                account_id=self.account_id,\n                tag_id=tag_id\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the scheduled query for the log entries.", "response": "def _create_scheduled_query(self, query, change, scope_unit, scope_count):\n        \"\"\"\n        Create the scheduled query\n        \"\"\"\n        query_data = {\n            'scheduled_query': {\n                'name': 'ForAnomalyReport',\n                'query': query,\n                'threshold_type': '%',\n                'threshold_value': change,\n                'time_period': scope_unit.title(),\n                'time_value': scope_count,\n            }\n        }\n\n        query_url = 'https://logentries.com/rest/{account_id}/api/scheduled_queries'\n\n        return self._api_post(\n            url=query_url.format(account_id=self.account_id),\n            data=json.dumps(query_data, sort_keys=True)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an anomaly alert. This call makes 2 requests, one to create a \"scheduled_query\", and another to create the alert. :param name: The name for the alert :type name: str :param query: The `LEQL`_ query to use for detecting anomalies. Must result in a numerical value, so it should look something like ``where(...) calculate(COUNT)`` :type query: str :param scope_count: How many ``scope_unit`` s to inspect for detecting an anomaly :type scope_count: int :param scope_unit: How far to look back in detecting an anomaly. Must be one of \"hour\", \"day\", or \"week\" :type scope_unit: str :param increase_positive: Detect a positive increase for the anomaly. A value of ``False`` results in detecting a decrease for the anomaly. :type increase_positive: bool :param percentage_change: The percentage of change to detect. Must be a number between 0 and 100 (inclusive). :type percentage_change: int :param trigger_config: A AlertTriggerConfig describing how far back to look back to compare to the anomaly scope. :type trigger_config: :class:`AlertTriggerConfig<logentries_api.special_alerts.AlertTriggerConfig>` :param logs: A list of log UUID's. (The 'key' key of a log) :type logs: list of str :param alert_reports: A list of AlertReportConfig to send alerts to :type alert_reports: list of :class:`AlertReportConfig<logentries_api.special_alerts.AlertReportConfig>` :return: The API response of the alert creation :rtype: dict :raises: This will raise a :class:`ServerException <logentries_api.exceptions.ServerException>` if there is an error from Logentries .. _Leql: https://blog.logentries.com/2015/06/introducing-leql/", "response": "def create(self,\n               name,\n               query,\n               scope_count,\n               scope_unit,\n               increase_positive,\n               percentage_change,\n               trigger_config,\n               logs,\n               alert_reports):\n        \"\"\"\n        Create an anomaly alert. This call makes 2 requests, one to create a\n        \"scheduled_query\", and another to create the alert.\n\n        :param name: The name for the alert\n        :type name: str\n\n        :param query: The `LEQL`_ query to use for detecting anomalies. Must\n            result in a numerical value, so it should look something like\n            ``where(...) calculate(COUNT)``\n        :type query: str\n\n        :param scope_count: How many ``scope_unit`` s to inspect for detecting\n            an anomaly\n        :type scope_count: int\n\n        :param scope_unit: How far to look back in detecting an anomaly. Must\n            be one of \"hour\", \"day\", or \"week\"\n        :type scope_unit: str\n\n        :param increase_positive: Detect a positive increase for the anomaly. A\n            value of ``False`` results in detecting a decrease for the anomaly.\n        :type increase_positive: bool\n\n        :param percentage_change: The percentage of change to detect. Must be a\n            number between 0 and 100 (inclusive).\n        :type percentage_change: int\n\n        :param trigger_config: A AlertTriggerConfig describing how far back to\n            look back to compare to the anomaly scope.\n        :type trigger_config: :class:`AlertTriggerConfig<logentries_api.special_alerts.AlertTriggerConfig>`\n\n        :param logs: A list of log UUID's. (The 'key' key of a log)\n        :type logs: list of str\n\n        :param alert_reports: A list of AlertReportConfig to send alerts to\n        :type alert_reports: list of\n            :class:`AlertReportConfig<logentries_api.special_alerts.AlertReportConfig>`\n\n        :return: The API response of the alert creation\n        :rtype: dict\n\n        :raises: This will raise a\n            :class:`ServerException <logentries_api.exceptions.ServerException>`\n            if there is an error from Logentries\n\n        .. _Leql: https://blog.logentries.com/2015/06/introducing-leql/\n\n        \"\"\"\n        change = '{pos}{change}'.format(\n            pos='+' if increase_positive else '-',\n            change=str(percentage_change)\n        )\n\n        query_response = self._create_scheduled_query(\n            query=query,\n            change=change,\n            scope_unit=scope_unit,\n            scope_count=scope_count,\n        )\n\n        scheduled_query_id = query_response.get('scheduled_query', {}).get('id')\n\n        tag_data = {\n            'tag': {\n                'actions': [\n                    alert_report.to_dict()\n                    for alert_report\n                    in alert_reports\n                ],\n                'name': name,\n                'scheduled_query_id': scheduled_query_id,\n                'sources': [\n                    {'id': log}\n                    for log\n                    in logs\n                ],\n                'sub_type': 'AnomalyAlert',\n                'type': 'AlertNotify'\n            }\n        }\n        tag_data['tag'].update(trigger_config.to_dict())\n\n        tag_url = 'https://logentries.com/rest/{account_id}/api/tags'.format(\n            account_id=self.account_id\n        )\n\n        return self._api_post(\n            url=tag_url,\n            data=json.dumps(tag_data, sort_keys=True),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete a specified anomaly alert tag and its scheduled query This method makes 3 requests: * One to get the associated scheduled_query_id * One to delete the alert * One to delete get scheduled query :param tag_id: The tag ID to delete :type tag_id: str :raises: This will raise a :class:`ServerException <logentries_api.exceptions.ServerException>` if there is an error from Logentries", "response": "def delete(self, tag_id):\n        \"\"\"\n        Delete a specified anomaly alert tag and its scheduled query\n\n        This method makes 3 requests:\n\n            * One to get the associated scheduled_query_id\n            * One to delete the alert\n            * One to delete get scheduled query\n\n        :param tag_id: The tag ID to delete\n        :type tag_id: str\n\n        :raises: This will raise a\n            :class:`ServerException <logentries_api.exceptions.ServerException>`\n            if there is an error from Logentries\n        \"\"\"\n        this_alert = [tag for tag in self.list_tags() if tag.get('id') == tag_id]\n\n        if len(this_alert) < 1:\n            return\n\n        query_id = this_alert[0].get('scheduled_query_id')\n\n        tag_url = 'https://logentries.com/rest/{account_id}/api/tags/{tag_id}'\n\n        self._api_delete(\n            url=tag_url.format(\n                account_id=self.account_id,\n                tag_id=tag_id\n            )\n        )\n        query_url = 'https://logentries.com/rest/{account_id}/api/scheduled_queries/{query_id}'\n\n        self._api_delete(\n            url=query_url.format(\n                account_id=self.account_id,\n                query_id=query_id\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a newsgroup info line into a tuple of group low high and status.", "response": "def parse_newsgroup(line):\n    \"\"\"Parse a newsgroup info line to python types.\n\n    Args:\n        line: An info response line containing newsgroup info.\n\n    Returns:\n        A tuple of group name, low-water as integer, high-water as integer and\n        posting status.\n\n    Raises:\n        ValueError: If the newsgroup info cannot be parsed.\n\n    Note:\n        Posting status is a character is one of (but not limited to):\n            \"y\" posting allowed\n            \"n\" posting not allowed\n            \"m\" posting is moderated\n    \"\"\"\n    parts = line.split()\n    try:\n        group = parts[0]\n        low = int(parts[1])\n        high = int(parts[2])\n        status = parts[3]\n    except (IndexError, ValueError):\n        raise ValueError(\"Invalid newsgroup info\")\n    return group, low, high, status"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_header(line):\n    if not line or line == \"\\r\\n\":\n        return None\n    if line[0] in \" \\t\":\n        return line[1:].rstrip()\n    name, value = line.split(\":\", 1)\n    return (name.strip(), value.strip())", "response": "Parse a header line."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_headers(obj):\n    if isinstance(obj, basestring):\n        obj = cStringIO.StringIO(obj)\n    hdrs = []\n    for line in obj:\n        hdr = parse_header(line)\n        if not hdr:\n            break\n        if isinstance(hdr, basestring):\n            if not hdrs:\n                raise ValueError(\"First header is a continuation\")\n            hdrs[-1] = (hdrs[-1][0], hdrs[-1][1] + hdr)\n            continue\n        hdrs.append(hdr)\n    return iodict.IODict(hdrs)", "response": "Parse a string a iterable object containing file - like objects and return a dictionary of headers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unparse_headers(hdrs):\n    return \"\".join([unparse_header(n, v) for n, v in hdrs.items()]) + \"\\r\\n\"", "response": "Parse a dictionary of headers to a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(tests=(), reporter=None, stop_after=None):\n\n    if reporter is None:\n        reporter = Counter()\n    if stop_after is not None:\n        reporter = _StopAfterWrapper(reporter=reporter, limit=stop_after)\n\n    locator = ObjectLocator()\n    cases = (\n        case\n        for test in tests\n        for loader in locator.locate_by_name(name=test)\n        for case in loader.load()\n    )\n    suite = unittest.TestSuite(cases)\n    getattr(reporter, \"startTestRun\", lambda: None)()\n    suite.run(reporter)\n    getattr(reporter, \"stopTestRun\", lambda: None)()\n    return reporter", "response": "Runs the tests that are loaded by each of the strings provided."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a docstring from a list of defaults.", "response": "def defaults_docstring(defaults, header=None, indent=None, footer=None):\n    \"\"\"Return a docstring from a list of defaults.\n    \"\"\"\n    if indent is None:\n        indent = ''\n    if header is None:\n        header = ''\n    if footer is None:\n        footer = ''\n\n    width = 60\n    #hbar = indent + width * '=' + '\\n'  # horizontal bar\n    hbar = '\\n'\n\n    s = hbar + (header) + hbar\n    for key, value, desc in defaults:\n        if isinstance(value, basestring):\n            value = \"'\" + value + \"'\"\n        if hasattr(value, '__call__'):\n            value = \"<\" + value.__name__ + \">\"\n\n        s += indent +'%-12s\\n' % (\"%s :\" % key)\n        s += indent + indent + (indent + 23 * ' ').join(desc.split('\\n'))\n        s += ' [%s]\\n\\n' % str(value)\n    s += hbar\n    s += footer\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef defaults_decorator(defaults):\n    def decorator(func):\n        \"\"\"Function that appends default kwargs to a function.\n        \"\"\"\n        kwargs = dict(header='Keyword arguments\\n-----------------\\n', \n                      indent='  ',\n                      footer='\\n')\n        doc = defaults_docstring(defaults, **kwargs)\n        if func.__doc__ is None:\n            func.__doc__ = ''\n        func.__doc__ += doc\n        return func\n\n    return decorator", "response": "Decorator to append default kwargs to a function."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads kwargs key value pairs into self. __dict__", "response": "def _load(self, **kwargs):\n        \"\"\"Load kwargs key,value pairs into __dict__\n        \"\"\"\n        defaults = dict([(d[0], d[1]) for d in self.defaults])\n        # Require kwargs are in defaults\n        for k in kwargs:\n            if k not in defaults:\n                msg = \"Unrecognized attribute of %s: %s\" % (\n                    self.__class__.__name__, k)\n                raise AttributeError(msg)\n        defaults.update(kwargs)\n\n        # This doesn't overwrite the properties\n        self.__dict__.update(defaults)\n\n        # This should now be set\n        self.check_type(self.__dict__['default'])\n\n        # This sets the underlying property values (i.e., __value__)\n        self.set(**defaults)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef defaults_docstring(cls, header=None, indent=None, footer=None):\n        return defaults_docstring(cls.defaults, header=header,\n                                  indent=indent, footer=footer)", "response": "Add the default values to the class docstring"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the value of the key to the given value.", "response": "def set_value(self, value):\n        \"\"\"Set the value\n\n        This invokes hooks for type-checking and bounds-checking that\n        may be implemented by sub-classes.\n        \"\"\"\n        self.check_bounds(value)\n        self.check_type(value)\n        self.__value__ = value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_type(self, value):\n        if self.__dict__['dtype'] is None:\n            return\n        elif value is None:\n            return\n        elif isinstance(value, self.__dict__['dtype']):\n            return\n        msg = \"Value of type %s, when %s was expected.\" % (\n            type(value), self.__dict__['dtype'])\n        raise TypeError(msg)", "response": "Hook for type - checking invoked during assignment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef value(self):\n\n        if self.__value__ is None:\n            try: \n                loader = self.__dict__['loader']\n            except KeyError:\n                raise AttributeError(\"Loader is not defined\")\n\n            # Try to run the loader.\n            # Don't catch expections here, let the Model class figure it out\n            val = loader()\n\n            # Try to set the value\n            try:\n                self.set_value(val)\n            except TypeError:\n                msg = \"Loader must return variable of type %s or None, got %s\" % (self.__dict__['dtype'], type(val))\n                raise TypeError(msg)\n        return self.__value__", "response": "Return the current value of the attribute."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_type(self, value):\n        try:\n            scalar = asscalar(value)\n        except ValueError as e:\n            raise TypeError(e)\n\n        super(Parameter, self).check_type(scalar)", "response": "Hook for type - checking invoked during assignment. Allows size 1 numpy arrays and lists. Raises TypeError if value can not be cast to a scalar."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the symmetric error estimate of the current error estimate.", "response": "def symmetric_error(self):\n        \"\"\"Return the symmertic error\n\n        Similar to above, but zero implies no error estimate,\n        and otherwise this will either be the symmetric error,\n        or the average of the low,high asymmetric errors.\n        \"\"\"\n        # ADW: Should this be `np.nan`?\n        if self.__errors__ is None:\n            return 0.\n        if np.isscalar(self.__errors__):\n            return self.__errors__\n        return 0.5 * (self.__errors__[0] + self.__errors__[1])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_errors(self, errors):\n        if errors is None:\n            self.__errors__ = None\n            return\n        self.__errors__ = [asscalar(e) for e in errors]", "response": "Set parameter error estimate"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the value bounds free errors based on corresponding kwargs", "response": "def set(self, **kwargs):\n        \"\"\"Set the value,bounds,free,errors based on corresponding kwargs\n\n        The invokes hooks for type-checking and bounds-checking that\n        may be implemented by sub-classes.\n        \"\"\"\n        # Probably want to reset bounds if set fails\n        if 'bounds' in kwargs:\n            self.set_bounds(kwargs.pop('bounds'))\n        if 'free' in kwargs:\n            self.set_free(kwargs.pop('free'))\n        if 'errors' in kwargs:\n            self.set_errors(kwargs.pop('errors'))\n        if 'value' in kwargs:\n            self.set_value(kwargs.pop('value'))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_and_parse(self):\n        f = open(self.file_path, \"r\")\n        metrics_json = f.read()\n        self.metrics = json.loads(metrics_json)", "response": "Load the metrics file from the given path\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef import_metrics(self):\n\n        self.v2Metrics = self.metricDefinitionV2(self.metrics)\n        if self.v2Metrics:\n            metrics = self.metrics\n\n        else:\n            metrics = self.metrics['result']\n\n        # Loop through the metrics and call the API\n        # to create/update\n        for m in metrics:\n            if self.v2Metrics:\n                metric = metrics[m]\n                metric['name'] = m\n            else:\n                metric = m\n            self.create_update(metric)", "response": "Import the metrics from the API and create or update definitions using API call."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_from_pytz(cls, tz_info):\n\n        zone_name = tz_info.zone\n\n        utc_transition_times_list_raw = getattr(tz_info, \n                                                '_utc_transition_times', \n                                                None)\n\n        utc_transition_times_list = [tuple(utt.timetuple()) \n                                     for utt \n                                     in utc_transition_times_list_raw] \\\n                                    if utc_transition_times_list_raw is not None \\\n                                    else None\n        \n        transition_info_list_raw = getattr(tz_info, \n                                           '_transition_info', \n                                           None)\n\n        transition_info_list = [(utcoffset_td.total_seconds(), \n                                 dst_td.total_seconds(), \n                                 tzname)\n                                for (utcoffset_td, dst_td, tzname)\n                                in transition_info_list_raw] \\\n                               if transition_info_list_raw is not None \\\n                               else None\n\n        try:\n            utcoffset_dt = tz_info._utcoffset\n        except AttributeError:\n            utcoffset = None\n        else:\n            utcoffset = utcoffset_dt.total_seconds()\n\n        tzname = getattr(tz_info, '_tzname', None)\n\n        parent_class_name = getmro(tz_info.__class__)[1].__name__\n        return cls(zone_name, parent_class_name, utc_transition_times_list, \n                   transition_info_list, utcoffset, tzname)", "response": "Create an instance of this class from a timezone info object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract required fields from an array of dict of dicts", "response": "def extract_dictionary(self, metrics):\n        \"\"\"\n        Extract required fields from an array\n        \"\"\"\n        new_metrics = {}\n        for m in metrics:\n            metric = self.extract_fields(m)\n            new_metrics[m['name']] = metric\n        return new_metrics"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter(self):\n        if self.filter_expression is not None:\n            new_metrics = []\n            metrics = self.metrics['result']\n            for m in metrics:\n                if self.filter_expression.search(m['name']):\n                    new_metrics.append(m)\n        else:\n            new_metrics = self.metrics['result']\n\n        self.metrics = self.extract_dictionary(new_metrics)", "response": "Filter out the metrics that match the criteria"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_arguments(self):\n        ApiCli.get_arguments(self)\n        if self.args.hostGroupId is not None:\n            self.hostGroupId = self.args.hostGroupId\n\n        self.path = \"v1/hostgroup/{0}\".format(str(self.hostGroupId))", "response": "This function extracts the specific arguments of this CLICli"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract the specific arguments of this CLI", "response": "def get_arguments(self):\n        \"\"\"\n        Extracts the specific arguments of this CLI\n        \"\"\"\n        ApiCli.get_arguments(self)\n\n        if self.args.tenant_id is not None:\n            self._tenant_id = self.args.tenant_id\n\n        if self.args.fingerprint_fields is not None:\n            self._fingerprint_fields = self.args.fingerprint_fields\n\n        if self.args.title is not None:\n            self._title = self.args.title\n\n        if self.args.source is not None:\n            self._source = self.args.source\n\n        if self.args.severity is not None:\n            self._severity = self.args.severity\n\n        if self.args.message is not None:\n            self._message = self.args.message\n\n        event = {}\n\n        if self._title is not None:\n            event['title'] = self._title\n\n        if self._severity is not None:\n            event['severity'] = self._severity\n\n        if self._message is not None:\n            event['message'] = self._message\n\n        if self._source is not None:\n            if 'source' not in event:\n                event['source'] = {}\n            if len(self._source) >= 1:\n                event['source']['ref'] = self._source[0]\n            if len(self._source) >= 2:\n                event['source']['type'] = self._source[1]\n\n        self._process_properties(self.args.properties)\n        if self._properties is not None:\n            event['properties'] = self._properties\n\n        if self._fingerprint_fields is not None:\n            event['fingerprintFields'] = self._fingerprint_fields\n\n        self.data = json.dumps(event, sort_keys=True)\n        self.headers = {'Content-Type': 'application/json'}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _call_api(self):\n\n        # Allocate a socket and connect to the meter\n        sockobj = socket(AF_INET, SOCK_STREAM)\n        sockobj.connect((self.rpc_host, self.rpc_port))\n        self.get_json()\n        message = [self.rpc_message.encode('utf-8')]\n\n        for line in message:\n            sockobj.send(line)\n            data = sockobj.recv(self.MAX_LINE)\n            print(data)\n            self.rpc_data.append(data)\n\n        sockobj.close()", "response": "Make a call to the meter via JSON RPC"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract the specific arguments of this CLI", "response": "def get_arguments(self):\n        \"\"\"\n        Extracts the specific arguments of this CLI\n        \"\"\"\n        HostgroupModify.get_arguments(self)\n\n        if self.args.host_group_id is not None:\n            self.host_group_id = self.args.host_group_id\n\n        self.path = \"v1/hostgroup/\" + str(self.host_group_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the identifier of the given text.", "response": "def identifier(self, text):\n    \"\"\"identifier = alpha_character | \"_\" . {alpha_character | \"_\" | digit} ;\"\"\"\n    self._attempting(text)\n    return concatenation([\n      alternation([\n        self.alpha_character,\n        \"_\"\n      ]),\n      zero_or_more(\n        alternation([\n          self.alpha_character,\n          \"_\",\n          self.digit\n        ])\n      )\n    ], ignore_whitespace=False)(text).compressed(TokenType.identifier)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef expression(self, text):\n    self._attempting(text)\n    return alternation([\n      # number , op_mult , expression\n      concatenation([\n        self.number,\n        self.op_mult,\n        self.expression\n      ], ignore_whitespace=True),\n      # expression_terminal , op_mult , number , [operator , expression]\n      concatenation([\n        self.expression_terminal,\n        self.op_mult,\n        self.number,\n        option(\n          concatenation([\n            self.operator,\n            self.expression\n          ], ignore_whitespace=True)\n        )\n      ], ignore_whitespace=True),\n      # expression_terminal , op_add , [operator , expression]\n      concatenation([\n        self.expression_terminal,\n        self.op_add,\n        option(\n          concatenation([\n            self.operator,\n            self.expression\n          ], ignore_whitespace=True)\n        )\n      ], ignore_whitespace=True),\n      # expression_terminal , [operator , expression]\n      concatenation([\n        self.expression_terminal,\n        option(\n          concatenation([\n            self.operator,\n            self.expression\n          ], ignore_whitespace=True)\n        )\n      ], ignore_whitespace=True)\n    ])(text).retyped(TokenType.expression)", "response": "Return the expression of the text."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef expression_terminal(self, text):\n    self._attempting(text)\n    return alternation([\n      self.identifier,\n      self.terminal,\n      self.option_group,\n      self.repetition_group,\n      self.grouping_group,\n      self.special_handling\n    ])(text)", "response": "Return the expression terminal of the given text."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the option group.", "response": "def option_group(self, text):\n    \"\"\"option_group = \"[\" , expression , \"]\" ;\"\"\"\n    self._attempting(text)\n    return concatenation([\n      \"[\",\n      self.expression,\n      \"]\"\n    ], ignore_whitespace=True)(text).retyped(TokenType.option_group)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new terminal string.", "response": "def terminal(self, text):\n    \"\"\"terminal = '\"' . (printable - '\"') + . '\"'\n                | \"'\" . (printable - \"'\") + . \"'\" ;\n    \"\"\"\n    self._attempting(text)\n    return alternation([\n      concatenation([\n        '\"',\n        one_or_more(\n          exclusion(self.printable, '\"')\n        ),\n        '\"'\n      ], ignore_whitespace=False),\n      concatenation([\n        \"'\",\n        one_or_more(\n          exclusion(self.printable,\"'\")\n        ),\n        \"'\"\n      ], ignore_whitespace=False)\n    ])(text).compressed(TokenType.terminal)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef operator(self, text):\n    self._attempting(text)\n    return alternation([\n      \"|\",\n      \".\",\n      \",\",\n      \"-\"\n    ])(text).retyped(TokenType.operator)", "response": "operator = |. | -"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef op_mult(self, text):\n    self._attempting(text)\n    return terminal(\"*\")(text).retyped(TokenType.op_mult)", "response": "Return an operator multiplicity."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setp(self, name, clear_derived=True, value=None,\n             bounds=None, free=None, errors=None):\n        \"\"\"\n        Set the value (and bounds) of the named parameter.\n\n        Parameters\n        ----------\n\n        name : str\n            The parameter name.\n        clear_derived : bool\n            Flag to clear derived objects in this model\n        value:\n            The value of the parameter, if None, it is not changed\n        bounds: tuple or None\n            The bounds on the parameter, if None, they are not set\n        free : bool or None\n            Flag to say if parameter is fixed or free in fitting, if None, it is not changed\n        errors : tuple or None\n            Uncertainties on the parameter, if None, they are not changed\n\n        \"\"\"\n        name = self._mapping.get(name, name)\n        try:\n            self.params[name].set(\n                value=value,\n                bounds=bounds,\n                free=free,\n                errors=errors)\n        except TypeError as msg:\n            print(msg, name)\n\n        if clear_derived:\n            self.clear_derived()\n        self._cache(name)", "response": "Set the value and bounds of a named parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_attributes(self, **kwargs):\n        self.clear_derived()\n        kwargs = dict(kwargs)\n        for name, value in kwargs.items():\n            # Raise AttributeError if param not found\n            try:\n                self.getp(name)\n            except KeyError:\n                print (\"Warning: %s does not have attribute %s\" %\n                       (type(self), name))\n            # Set attributes\n            try:\n                self.setp(name, clear_derived=False, **value)\n            except TypeError:\n                try:\n                    self.setp(name, clear_derived=False, *value)\n                except (TypeError, KeyError):\n                    try:\n                        self.setp(name, clear_derived=False, value=value)\n                    except (TypeError, KeyError):\n                        self.__setattr__(name, value)\n            # pop this attribued off the list of missing properties\n            self._missing.pop(name, None)\n        # Check to make sure we got all the required properties\n        if self._missing:\n            raise ValueError(\n                \"One or more required properties are missing \",\n                self._missing.keys())", "response": "Set attributes of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlooping through the list of Properties and extract the derived and required properties and do the necessary book - keeping", "response": "def _init_properties(self):\n        \"\"\" Loop through the list of Properties,\n        extract the derived and required properties and do the\n        appropriate book-keeping\n        \"\"\"\n        self._missing = {}\n        for k, p in self.params.items():\n            if p.required:\n                self._missing[k] = p\n            if isinstance(p, Derived):\n                if p.loader is None:\n                    # Default to using _<param_name>\n                    p.loader = self.__getattribute__(\"_%s\" % k)\n                elif isinstance(p.loader, str):\n                    p.loader = self.__getattribute__(p.loader)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_params(self, pnames=None):\n        l = []\n        if pnames is None:\n            pnames = self.params.keys()\n        for pname in pnames:\n            p = self.params[pname]\n            if isinstance(p, Parameter):\n                l.append(p)\n        return l", "response": "Return a list of Parameter objects with those names\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef param_values(self, pnames=None):\n        l = self.get_params(pnames)\n        v = [p.value for p in l]\n        return np.array(v)", "response": "Return an array with the parameter values"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an array with the parameter errors for the specified parameter names.", "response": "def param_errors(self, pnames=None):\n        \"\"\" Return an array with the parameter errors\n\n        Parameters\n        ----------\n        pname : list of string or none\n           If a list of strings, get the Parameter objects with those names\n\n           If none, get all the Parameter objects\n\n        Returns\n        -------\n        ~numpy.array of parameter errors\n\n        Note that this is a N x 2 array.\n        \"\"\"\n        l = self.get_params(pnames)\n        v = [p.errors for p in l]\n        return np.array(v)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresetting all Derived properties to None", "response": "def clear_derived(self):\n        \"\"\" Reset the value of all Derived properties to None\n\n        This is called by setp (and by extension __setattr__)\n        \"\"\"\n        for p in self.params.values():\n            if isinstance(p, Derived):\n                p.clear_value()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_arguments(self):\n        ApiCli.get_arguments(self)\n        if self.args.pluginName is not None:\n            self.pluginName = self.args.pluginName\n\n        self.path = \"v1/plugins/{0}/components\".format(self.pluginName)", "response": "This function extracts the specific arguments of this CLI\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the method of the object", "response": "def method(self, value):\n        \"\"\"\n        Before assigning the value validate that is in one of the\n        HTTP methods we implement\n        \"\"\"\n        keys = self._methods.keys()\n        if value not in keys:\n            raise AttributeError(\"Method value not in \" + str(keys))\n        else:\n            self._method = value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the configuration stored in environment variables", "response": "def _get_environment(self):\n        \"\"\"\n        Gets the configuration stored in environment variables\n        \"\"\"\n        if 'TSP_EMAIL' in os.environ:\n            self._email = os.environ['TSP_EMAIL']\n        if 'TSP_API_TOKEN' in os.environ:\n            self._api_token = os.environ['TSP_API_TOKEN']\n        if 'TSP_API_HOST' in os.environ:\n            self._api_host = os.environ['TSP_API_HOST']\n        else:\n            self._api_host = 'api.truesight.bmc.com'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a metric definition identified by name", "response": "def metric_get(self, enabled=False, custom=False):\n        \"\"\"\n        Returns a metric definition identified by name\n        :param enabled: Return only enabled metrics\n        :param custom: Return only custom metrics\n        :return Metrics:\n        \"\"\"\n        self.path = 'v1/metrics?enabled={0}&{1}'.format(enabled, custom)\n        self._call_api()\n        self._handle_results()\n        return self.metrics"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _call_api(self):\n\n        self._url = self.form_url()\n        if self._headers is not None:\n            logging.debug(self._headers)\n        if self._data is not None:\n            logging.debug(self._data)\n        if len(self._get_url_parameters()) > 0:\n            logging.debug(self._get_url_parameters())\n\n        result = self._methods[self._method]()\n\n        if not self.good_response(result.status_code):\n            logging.error(self._url)\n            logging.error(self._method)\n            if self._data is not None:\n                logging.error(self._data)\n            logging.error(result)\n        self._api_result = result", "response": "Make an API call to get the metric definition"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_arguments(self):\n        # ApiCli.get_arguments(self)\n        if self.args.file_name is not None:\n            self.file_name = self.args.file_name", "response": "Extracts the specific arguments of this CLI\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute(self):\n        # self._get_environment()\n        self.add_arguments()\n        self._parse_args()\n        self.get_arguments()\n        if self._validate_arguments():\n            self._plot_data()\n        else:\n            print(self._message)", "response": "Run the steps to execute the CLI"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the remote file exists and if it does raise exception.", "response": "def validate_sceneInfo(self):\n        \"\"\"Check scene name and whether remote file exists. Raises\n        WrongSceneNameError if the scene name is wrong.\n        \"\"\"\n        if self.sceneInfo.prefix not in self.__satellitesMap:\n            raise WrongSceneNameError('USGS Downloader: Prefix of %s (%s) is invalid'\n                                      % (self.sceneInfo.name, self.sceneInfo.prefix))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nverifies that the type product is valid.", "response": "def verify_type_product(self, satellite):\n        \"\"\"Gets satellite id \"\"\"\n        if satellite == 'L5':\n            id_satellite = '3119'\n            stations = ['GLC', 'ASA', 'KIR', 'MOR', 'KHC', 'PAC', 'KIS', 'CHM', 'LGS', 'MGR', 'COA', 'MPS']\n        elif satellite == 'L7':\n            id_satellite = '3373'\n            stations = ['EDC', 'SGS', 'AGS', 'ASN', 'SG1']\n        elif satellite == 'L8':\n            id_satellite = '4923'\n            stations = ['LGN']\n        else:\n            raise ProductInvalidError('Type product invalid. the permitted types are: L5, L7, L8. ')\n        typ_product = dict(id_satelite=id_satellite, stations=stations)\n        return typ_product"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the filesize of a remote file", "response": "def get_remote_file_size(self, url):\n        \"\"\"Gets the filesize of a remote file \"\"\"\n        try:\n            req = urllib.request.urlopen(url)\n            return int(req.getheader('Content-Length').strip())\n        except urllib.error.HTTPError as error:\n            logger.error('Error retrieving size of the remote file %s' % error)\n            print('Error retrieving size of the remote file %s' % error)\n            self.connect_earthexplorer()\n            self.get_remote_file_size(url)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading the remote. tar. bz2 file.", "response": "def download(self, bands=None, download_dir=None, metadata=False):\n        \"\"\"Download remote .tar.bz file.\"\"\"\n        if not download_dir:\n            download_dir = DOWNLOAD_DIR\n\n        if bands is None:\n            bands = list(range(1, 12)) + ['BQA']\n        else:\n            self.validate_bands(bands)\n\n        pattern = re.compile('^[^\\s]+_(.+)\\.tiff?', re.I)\n        band_list = ['B%i' % (i,) if isinstance(i, int) else i for i in bands]\n        image_list = []\n\n        # Connect Earth explore\n        self.connect_earthexplorer()\n\n        # tgz name\n        tgzname = self.sceneInfo.name + '.tgz'\n        dest_dir = check_create_folder(join(download_dir, self.sceneInfo.name))\n\n        # Download File\n        downloaded = self.download_file(self.url, dest_dir, tgzname)\n\n        # Log\n        logger.debug('Status downloaded %s' % downloaded)\n        print('\\n Status downloaded %s' % downloaded)\n\n        if downloaded['sucess']:\n\n            # Log\n            print('\\n Downloaded sucess')\n            logger.debug('Downloaded sucess of scene: %s' % self.sceneInfo.name)\n\n            try:\n\n                tar = tarfile.open(downloaded['file_path'], 'r')\n                folder_path = join(download_dir, self.sceneInfo.name)\n                tar.extractall(folder_path)\n                remove(downloaded['file_path'])\n                images_path = listdir(folder_path)\n\n                for image_path in images_path:\n                    matched = pattern.match(image_path)\n                    file_path = join(folder_path, image_path)\n                    if matched and matched.group(1) in band_list:\n                        image_list.append([file_path, getsize(file_path)])\n                    elif matched:\n                        remove(file_path)\n            except tarfile.ReadError as error:\n                print('\\nError when extracting files. %s' % error)\n                logger.error('Error when extracting files. %s' % error)\n            return image_list\n        else:\n            logger.debug('Info downloaded: %s' % downloaded)\n            print('\\n Info downloaded: %s' % downloaded)\n            return downloaded"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nestablish connection to Earth explorer with proxy", "response": "def connect_earthexplorer(self):\n        \"\"\"   Connection to Earth explorer without proxy  \"\"\"\n        logger.info(\"Establishing connection to Earthexplorer\")\n        print(\"\\n Establishing connection to Earthexplorer\")\n        try:\n            opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor())\n            urllib.request.install_opener(opener)\n            params = urllib.parse.urlencode(dict(username=self.user, password=self.password))\n            params = params.encode('utf-8')\n            f = opener.open(\"https://ers.cr.usgs.gov/login\", params)\n            data = f.read().decode('utf-8')\n            f.close()\n            if data.find(\n                    'You must sign in as a registered user to download data or place orders for USGS EROS products') > 0:\n                print(\"\\n Authentification failed\")\n                logger.error(\"Authentification failed\")\n                raise AutenticationUSGSFailed('Authentification USGS failed')\n            print('User %s connected with USGS' % self.user)\n            logger.debug('User %s connected with USGS' % self.user)\n            return\n        except Exception as e:\n            print('\\nError when trying to connect USGS: %s' % e)\n            raise logger.error('Error when trying to connect USGS: %s' % e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_file(self, url, download_dir, sceneName):\n        try:\n            # Log\n            logger.info('\\nStarting download..')\n            print('\\n Starting download..\\n')\n\n            # Request\n            req = urllib.request.urlopen(url)\n\n            try:\n                if req.info().get_content_type() == 'text/html':\n                    logger.error(\"error : the file format is html\")\n                    lines = req.read()\n                    if lines.find('Download Not Found') > 0:\n                        raise TypeError('Download USGS not found for scene: %s' % self.sceneInfo.name)\n                    else:\n                        print(lines)\n                        print(sys.exit(-1))\n            except Exception as e:\n                logger.error('Erro in USGS download for scene %s error: %s' % (self.sceneInfo.name, e))\n                raise CredentialsUsgsError('User or Password invalid ! ')\n\n            total_size = int(req.getheader('Content-Length').strip())\n\n            if total_size < 50000:\n                logger.error(\"Error: The file is too small to be a Landsat Image for scene %s\" % self.sceneInfo.name)\n                raise SmallLandsatImageError(\"Error: The file is too small to be a Landsat Image\")\n\n            total_size_fmt = sizeof_fmt(total_size)\n            downloaded = 0\n            CHUNK = 1024 * 1024 * 8\n            with open(download_dir + '/' + sceneName, 'wb') as fp:\n                start = time.clock()\n                logger.debug('Downloading {0} ({1}):'.format(self.sceneInfo.name, total_size_fmt))\n                print('Downloading {0} ({1}):'.format(self.sceneInfo.name, total_size_fmt))\n                while True:\n                    chunk = req.read(CHUNK)\n                    downloaded += len(chunk)\n                    done = int(50 * downloaded / total_size)\n                    print('\\r[{1}{2}]{0:3.0f}% {3}ps'.format(floor((float(downloaded) / total_size) * 100), '-' * done,\n                                                             ' ' * (50 - done), sizeof_fmt((downloaded //\n                                                                                          (time.clock() - start)) / 8)))\n                    if not chunk:\n                        logger.debug('Download {0} completed({1}):'.format(self.sceneInfo.name, total_size_fmt))\n                        break\n                    fp.write(chunk)\n        except urllib.error.HTTPError as e:\n            if e.code == 500:\n                logger.error(\"File doesn't exist\")\n                print(\"\\n File doesn't exist: %s \" % e)\n                raise RemoteFileDoesntExist(\"File doesn't exist\")\n            elif e.code == 403:\n                # Log celery\n                logger.error(\"HTTP Error:\", e.code, url)\n                logger.debug('\\n trying to download it again scene: %s' % self.sceneInfo.name)\n                # Log shell\n                print(\"\\n HTTP Error:\", e.code, url)\n                print('\\n trying to download it again scene: %s' % self.sceneInfo.name)\n                self.connect_earthexplorer()\n                self.download_file(url, download_dir, sceneName)\n            else:\n                logger.error(\"HTTP Error:\", e)\n                print(\"HTTP Error:\", e.code, url)\n                raise e\n        except urllib.error.URLError as e:\n            print(\"URL Error:\", e.reason, url)\n            logger.error(\"URL Error: %s in %s\" % (e, url))\n            raise e\n        except ConnectionResetError as e:\n            print('Error ConnectionResetError: %s' % e)\n            logger.error('Error ConnectionResetError: %s' % e)\n            print('\\n trying to download it again scene: %s' % self.sceneInfo.name)\n            logger.debug('trying to download it again scene: %s' % self.sceneInfo.name)\n            self.download_file(url, download_dir, sceneName)\n        except urllib.error.HTTPError as e:\n            print('\\n HttpError: %s' % e)\n            print('\\n trying to download it again scene: %s' % self.sceneInfo.name)\n            logger.error('HttpError: %s' % e)\n            logger.debug('trying to download it again scene: %s' % self.sceneInfo.name)\n            self.download_file(url, download_dir, sceneName)\n        except Exception as error:\n            logger.error('Error unknown %s in download %s at scene: %s' % (error, url, self.sceneInfo.name))\n            print('Error unknown %s in download % at scene: %s' % (error, url, self.sceneInfo.name))\n            logger.debug('trying to download it again scene: %s' % self.sceneInfo.name)\n            self.download_file(url, download_dir, sceneName)\n\n        percent = floor((float(downloaded) / total_size) * 100) or 0\n        if percent != 100:\n            logger.debug('trying to download it again scene: %s' % self.sceneInfo.name)\n            logger.error('Download interrupted in %s%%, trying to download it again scene: %s' % (\n                percent, self.sceneInfo.name))\n            print('\\n Download interrupted in %s%%, trying to download it again scene: %s' % (\n                percent, self.sceneInfo.name))\n            self.download_file(url, download_dir, sceneName)\n\n        path_item = download_dir + '/' + sceneName\n        info = {'total_size': total_size_fmt, 'scene': self.sceneInfo.name,\n                'sucess': verify_sucess(total_size, path_item), 'file_path': path_item}\n        return info", "response": "Downloads large files in pieces  "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prefixed_by(prefix):\n\n    def prefixed_by_(name, value=None):\n        return name.startswith(prefix)\n    prefixed_by_.__name__ += prefix\n    return prefixed_by_", "response": "Returns a callable returning True for names starting with the given prefix."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_arguments(self):\n        ApiCli.get_arguments(self)\n        if self.args.metric_name is not None:\n            self._metric_name = self.args.metric_name\n\n        self.path = \"v1/metrics/{0}\".format(self._metric_name)", "response": "This method extracts the specific arguments of this CLIProvide"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef timezone(zone):\n    r''' Return a datetime.tzinfo implementation for the given timezone \n\n    >>> from datetime import datetime, timedelta\n    >>> utc = timezone('UTC')\n    >>> eastern = timezone('US/Eastern')\n    >>> eastern.zone\n    'US/Eastern'\n    >>> timezone(unicode('US/Eastern')) is eastern\n    True\n    >>> utc_dt = datetime(2002, 10, 27, 6, 0, 0, tzinfo=utc)\n    >>> loc_dt = utc_dt.astimezone(eastern)\n    >>> fmt = '%Y-%m-%d %H:%M:%S %Z (%z)'\n    >>> loc_dt.strftime(fmt)\n    '2002-10-27 01:00:00 EST (-0500)'\n    >>> (loc_dt - timedelta(minutes=10)).strftime(fmt)\n    '2002-10-27 00:50:00 EST (-0500)'\n    >>> eastern.normalize(loc_dt - timedelta(minutes=10)).strftime(fmt)\n    '2002-10-27 01:50:00 EDT (-0400)'\n    >>> (loc_dt + timedelta(minutes=10)).strftime(fmt)\n    '2002-10-27 01:10:00 EST (-0500)'\n\n    Raises UnknownTimeZoneError if passed an unknown zone.\n\n    >>> try:\n    ...     timezone('Asia/Shangri-La')\n    ... except UnknownTimeZoneError:\n    ...     print('Unknown')\n    Unknown\n\n    >>> try:\n    ...     timezone(unicode('\\N{TRADE MARK SIGN}'))\n    ... except UnknownTimeZoneError:\n    ...     print('Unknown')\n    Unknown\n\n    '''\n    if zone.upper() == 'UTC':\n        return utc\n\n    try:\n        zone = ascii(zone)\n    except UnicodeEncodeError:\n        # All valid timezones are ASCII\n        raise UnknownTimeZoneError(zone)\n\n    zone = _unmunge_zone(zone)\n    if zone not in _tzinfo_cache:\n        if zone in all_timezones_set:\n#            fp = open_resource(zone)\n#            try:\n             _tzinfo_cache[zone] = build_tzinfo(zone)#, fp)\n#            finally:\n#                fp.close()\n        else:\n            raise UnknownTimeZoneError(zone)\n\n    return _tzinfo_cache[zone]", "response": "r Returns a datetime. tzinfo implementation for the given timezone."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef normalize(self, dt, is_dst=False):\n        '''Correct the timezone information on the given datetime'''\n        if dt.tzinfo is None:\n            raise ValueError('Naive time - no tzinfo set')\n        return dt.replace(tzinfo=self)", "response": "Correct the timezone information on the given datetime"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract the specific arguments of this CLI", "response": "def get_arguments(self):\n        \"\"\"\n        Extracts the specific arguments of this CLI\n        \"\"\"\n        ApiCli.get_arguments(self)\n        if self.args.hostGroupId is not None:\n            self.hostGroupId = self.args.hostGroupId\n        if self.args.force is not None:\n            self.force = self.args.force\n\n        if self.force:\n            self.url_parameters = {\"forceRemove\": True}\n\n        self.path = \"v1/hostgroup/{0}\".format(str(self.hostGroupId))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract the specific arguments of this CLI", "response": "def get_arguments(self):\n        \"\"\"\n        Extracts the specific arguments of this CLI\n        \"\"\"\n        ApiCli.get_arguments(self)\n\n        self._actions = self.args.actions if self.args.actions is not None else None\n        self._alarm_name = self.args.alarm_name if self.args.alarm_name is not None else None\n\n        self._metric = self.args.metric if self.args.metric is not None else None\n        self._aggregate = self.args.aggregate if self.args.aggregate is not None else None\n        self._operation = self.args.operation if self.args.operation is not None else None\n        self._threshold = self.args.threshold if self.args.threshold is not None else None\n        self._trigger_interval = self.args.trigger_interval if self.args.trigger_interval is not None else None\n        self._host_group_id = self.args.host_group_id if self.args.host_group_id is not None else None\n        self._note = self.args.note if self.args.note is not None else None\n        self._per_host_notify = self.args.per_host_notify if self.args.per_host_notify is not None else None\n        self._is_disabled = self.args.is_disabled if self.args.is_disabled is not None else None\n        self._notify_clear = self.args.notify_clear if self.args.notify_clear is not None else None\n        self._notify_set = self.args.notify_set if self.args.notify_set is not None else None\n        self._timeout_interval = self.args.timeout_interval if self.args.timeout_interval is not None else None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef esc_split(text, delimiter=\" \", maxsplit=-1, escape=\"\\\\\", *, ignore_empty=False):\n  is_escaped = False\n  split_count = 0\n  yval = []\n\n  for char in text:\n    if is_escaped:\n      is_escaped = False\n      yval.append(char)\n    else:\n      if char == escape:\n        is_escaped = True\n      elif char in delimiter and split_count != maxsplit:\n        if yval or not ignore_empty:\n          yield \"\".join(yval)\n          split_count += 1\n        yval = []\n      else:\n        yval.append(char)\n\n  yield \"\".join(yval)", "response": "Escape - aware text splitting :\n\n Split text on a delimiter recognizing escaped delimiters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef esc_join(iterable, delimiter=\" \", escape=\"\\\\\"):\n  rep = escape + delimiter\n  return delimiter.join(i.replace(delimiter, rep) for i in iterable)", "response": "Join an iterable by a delimiter replacing instances of delimiter in items\n with escape + delimiter."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of positions in the text where all new lines occur.", "response": "def get_newline_positions(text):\n  \"\"\"Returns a list of the positions in the text where all new lines occur. This is used by\n  get_line_and_char to efficiently find coordinates represented by offset positions.\n  \"\"\"\n  pos = []\n  for i, c in enumerate(text):\n    if c == \"\\n\":\n      pos.append(i)\n  return pos"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_line_and_char(newline_positions, position):\n  if newline_positions:\n    for line_no, nl_pos in enumerate(newline_positions):\n      if nl_pos >= position:\n        if line_no == 0:\n          return (line_no, position)\n        else:\n          return (line_no, position - newline_positions[line_no - 1] - 1)\n    return (line_no + 1, position - newline_positions[-1] - 1)\n  else:\n    return (0, position)", "response": "Given a list of newline positions and an offset from the start of the source code\n \u2013 return a 2 - tuple of line and character coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef point_to_source(source, position, fmt=(2, True, \"~~~~~\", \"^\")):\n\n  surrounding_lines, show_line_numbers, tail_body, pointer_char = fmt\n\n  line_no, char_no = position\n\n  lines = source.split(\"\\n\")\n  line = lines[line_no]\n\n  if char_no >= len(tail_body):\n    tail = \" \" * (char_no - len(tail_body)) + tail_body + pointer_char\n  else:\n    tail = \" \" * char_no + pointer_char + tail_body\n\n  if show_line_numbers:\n    line_no_width = int(math.ceil(math.log10(max(1, line_no + surrounding_lines))) + 1)\n    line_fmt = \"{0:\" + str(line_no_width) + \"}: {1}\"\n  else:\n    line_fmt = \"{1}\"\n\n  pivot = line_no + 1\n  output_lines = [(pivot, line), (\"\", tail)]\n  for i in range(surrounding_lines):\n    upper_ofst = i + 1\n    upper_idx = line_no + upper_ofst\n    lower_ofst = -upper_ofst\n    lower_idx = line_no + lower_ofst\n\n    if lower_idx >= 0:\n      output_lines.insert(0, (pivot + lower_ofst, lines[lower_idx]))\n    if upper_idx < len(lines):\n      output_lines.append((pivot + upper_ofst, lines[upper_idx]))\n\n  return \"\\n\".join(line_fmt.format(n, c) for n, c in output_lines)", "response": "Point to a position in source code."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend output in textual format", "response": "def _dump_text(self):\n        \"\"\"\n        Send output in textual format\n        \"\"\"\n        results = self._relay_output['result'];\n\n        for l in results:\n            dt = time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime(int(l[1]['ts'])))\n            print(\"{0} {1} {2} {3}\".format(l[0], dt, l[1]['type'], l[1]['msg']))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _handle_results(self):\n        # Only process if we get HTTP result of 200\n        if self._api_result.status_code == requests.codes.ok:\n            self._relay_output = json.loads(self._api_result.text)\n            if self._raw:\n                self._dump_json()\n            else:\n                self._dump_text()", "response": "Handle the results from the API call."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts the specific arguments of this CLI", "response": "def get_arguments(self):\n        \"\"\"\n        Extracts the specific arguments of this CLI\n        \"\"\"\n        PluginBase.get_arguments(self)\n        if self.args.organizationName is not None:\n            self.organizationName = self.args.organizationName\n        if self.args.repositoryName is not None:\n            self.repositoryName = self.args.repositoryName\n            \n        self.path = \"v1/plugins/private/{0}/{1}/{2}\".format(self.pluginName, self.organizationName, self.repositoryName)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract_fields(self, metric):\n        m = {}\n        if 'name' in metric:\n            m['name'] = metric['name']\n        if 'description' in metric:\n            m['description'] = metric['description']\n        if 'displayName' in metric:\n            m['displayName'] = metric['displayName']\n        if 'displayNameShort' in metric:\n            m['displayNameShort'] = metric['displayNameShort']\n        if 'unit' in metric:\n            m['unit'] = metric['unit']\n        if 'defaultAggregate' in metric:\n            m['defaultAggregate'] = metric['defaultAggregate']\n        if 'defaultResolutionMS' in metric:\n            m['defaultResolutionMS'] = metric['defaultResolutionMS']\n        if 'isDisabled' in metric:\n            m['isDisabled'] = metric['isDisabled']\n        if 'isBuiltin' in metric:\n            m['isBuiltin'] = metric['isBuiltin']\n        if 'type' in metric:\n            m['type'] = metric['type']\n        return m", "response": "Extract only the required fields for the create or update API call\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_arguments(self):\n\n        AlarmModify.get_arguments(self)\n        self._alarm_id = self.args.alarm_id if self.args.alarm_id is not None else None\n        self.get_api_parameters()", "response": "Extracts the specific arguments of this CLI\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply the criteria to filter out the output required by the user.", "response": "def _filter(self):\n        \"\"\"\n        Apply the criteria to filter out on the output required\n        \"\"\"\n        if self._metrics or self._control or self._plugins:\n            relays = self._relays['result']['relays']\n            for relay in relays:\n                if self._metrics:\n                    del relays[relay]['metrics']\n                if self._control:\n                    del relays[relay]['control']\n                if self._plugins:\n                    if 'plugins' in relays[relay]:\n                        del relays[relay]['plugins']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle the API response from the get_relation_list call.", "response": "def _handle_results(self):\n        \"\"\"\n        Call back function to be implemented by the CLI.\n        \"\"\"\n\n        # Only process if we get HTTP result of 200\n        if self._api_result.status_code == requests.codes.ok:\n            self._relays = json.loads(self._api_result.text)\n            self._filter()\n            self._dump_json()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing based on a list of fortune files", "response": "def fromlist(cls, files, equal=False, offensive=False, lang=None):\n        \"\"\"Initialize based on a list of fortune files\"\"\"\n        self = cls.__new__(cls)\n        self.files = fortunes = []\n        count = 0\n        for file in files:\n            fortune = load_fortune(file, offensive=offensive, lang=lang)\n            if fortune is None:\n                logger.warn(\"Can't load: %s\", file)\n                continue\n            count += 1 if equal else fortune.size\n            fortunes.append((fortune, count))\n        if not fortunes:\n            raise ValueError('All fortune files specified are invalid')\n        self.count = count\n        self.keys = [i[1] for i in self.files]\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_chance(cls, files, equal=False, offensive=False, lang=None): # where files are (name, chance)\n        self = cls.__new__(cls)\n        total = 0.\n        file = []\n        leftover = []\n        for name, chance in files:\n            if total >= 1:\n                break\n            fortune = load_fortune(name, offensive=offensive, lang=lang)\n            if fortune is None or not fortune.size:\n                continue\n            if chance:\n                file.append((fortune, chance))\n                total += chance\n            else:\n                leftover.append(fortune)\n        if leftover and total < 1:\n            left = 1 - total\n            if equal:\n                perfile = left / len(leftover)\n                for fortune in leftover:\n                    file.append((fortune, perfile))\n            else:\n                entries = sum(map(attrgetter('size'), leftover))\n                logger.debug('%d entries left', entries)\n                for fortune in leftover:\n                    chance = left * fortune.size / entries\n                    file.append((fortune, chance))\n        \n        # Arbitrary limit to calculate upper bound with, nice round number\n        self.count = count = 65536\n        bound = 0\n        self.files = fortunes = []\n        for file, chance in file:\n            bound += int(chance * count)\n            fortunes.append((file, bound))\n        self.keys = [i[1] for i in self.files]\n        return self", "response": "Initialize based on a list of fortunes with set chances"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(context, **kwargs):\n\n    result = run(**kwargs)\n    context.exit(not result.wasSuccessful())", "response": "Runs the virtue discovers and runs tests found in the objects given by the kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef grammar(self, text):\n    self._attempting(text)\n    return concatenation([\n      zero_or_more(\n        self.comment,\n        ignore_whitespace=True\n      ),\n      self.rule,\n      zero_or_more(\n        alternation([\n          self.comment,\n          self.rule,\n        ]),\n        ignore_whitespace=True\n      ),\n    ], ignore_whitespace=True)(text).retyped(TokenType.grammar)", "response": "Return a grammar for the given text."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef comment(self, text):\n    self._attempting(text)\n    return concatenation([\n      \"(*\",\n      zero_or_more(\n        alternation([\n          exclusion(\n            self.printable,\n            \"*\"\n          ),\n          concatenation([\n            \"*\",\n            exclusion(\n              self.printable,\n              \")\"\n            ),\n          ], ignore_whitespace=False),\n        ]),\n        ignore_whitespace=False\n      ),\n      \"*)\",\n    ], ignore_whitespace=False)(text).compressed(TokenType.comment)", "response": "comment = \"(*\" . {printable - \"*\" | \"*\" . printable - \")\"} . \"*)\" ;"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrule = identifier , \"=\" , expression , \";\" ;", "response": "def rule(self, text):\n    \"\"\"rule = identifier , \"=\" , expression , \";\" ;\"\"\"\n    self._attempting(text)\n    return concatenation([\n      self.identifier,\n      \"=\",\n      self.expression,\n      \";\",\n    ], ignore_whitespace=True)(text).retyped(TokenType.rule)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef special_handling(self, text):\n    self._attempting(text)\n    return concatenation([\n      \"?\",\n      self.identifier,\n      \"?\",\n    ], ignore_whitespace=True)(text).retyped(TokenType.special_handling)", "response": "special handling for the token."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef number(self, text):\n    self._attempting(text)\n    return concatenation([\n      exclusion(\n        self.digit,\n        \"0\"\n      ),\n      zero_or_more(\n        self.digit,\n        ignore_whitespace=False\n      ),\n    ], ignore_whitespace=False)(text).compressed(TokenType.number)", "response": "Return a number from the given text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract the specific arguments of this CLI", "response": "def get_arguments(self):\n        \"\"\"\n        Extracts the specific arguments of this CLI\n        \"\"\"\n        ApiCli.get_arguments(self)\n        if self.args.metricName is not None:\n            self.metricName = self.args.metricName\n\n        if self.args.measurement is not None:\n            self.measurement = self.args.measurement\n\n        if self.args.source is not None:\n            self.source = self.args.source\n        else:\n            self.source = socket.gethostname()\n\n        if self.args.timestamp is not None:\n            self.timestamp = int(self.args.timestamp)\n\n        m = {'metric': self.metricName,\n             'measure': self.measurement}\n\n        if self.source is not None:\n            m['source'] = self.source\n        if self.timestamp is not None:\n            m['timestamp'] = int(self.timestamp)\n\n        self._process_properties()\n\n        if self._properties is not None:\n            m['metadata'] = self._properties\n\n        self.data = json.dumps(m, sort_keys=True)\n        self.headers = {'Content-Type': 'application/json', \"Accept\": \"application/json\"}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle the API response from the get_cluster_key function.", "response": "def _handle_results(self):\n        \"\"\"\n        Call back function to be implemented by the CLI.\n        \"\"\"\n\n        # Only process if we get HTTP result of 200\n        if self._api_result.status_code == requests.codes.ok:\n            payload = json.loads(self._api_result.text)\n            out = json.dumps(payload, sort_keys=True, indent=4, separators=(',', ': '))\n            print(self.colorize_json(out))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef directives(self):\n    if self._directives is None:\n      self._directives = []\n      for comment in self.comments:\n        self._directives.extend(self.directives_from_comment(comment))\n    return self._directives", "response": "The diretives parsed from the comments."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the python source code for the generated parser.", "response": "def _compile(self):\n    \"\"\"Returns the python source code for the generated parser.\"\"\"\n    fmt = \"\"\"\\\"\\\"\\\"This parser was generated by pyebnf on {date}.\\\"\\\"\\\"\n    from enum import Enum\n\n    from pyebnf import parser_base as PB\n    from pyebnf.primitive import alternation, concatenation, exclusion, one_or_more\n    from pyebnf.primitive import option, repeated, repetition, terminal, zero_or_more\n    {imports}\n\n    {token_type_enum}\n\n\n    {class_definition}\n    \"\"\"\n\n    fmt = self._clean_fmt(fmt)\n\n    return fmt.format(date=datetime.utcnow().isoformat(),\n                      imports=self._get_imports(),\n                      token_type_enum=self._get_token_type_enum(),\n                      class_definition=self._get_class_definition())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the directives and generates source code for custom imports.", "response": "def _get_imports(self):\n    \"\"\"Reads the directives and generates source code for custom imports.\"\"\"\n    import_directives = [d for d in self.directives if d.name == \"import\"]\n    if import_directives:\n      return \"\\n\" + \"\\n\".join(d.args[\"value\"] for d in import_directives)\n    else:\n      return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_token_type_enum(self):\n    fmt = \"class TokenType(Enum):\\n\" \\\n          \"{indent}\\\"\\\"\\\"The token types for parse nodes generated by the Parser.\\\"\\\"\\\"\\n\" \\\n          \"{indent}\" + \\\n          \"\\n{indent}\".join(\"{1} = {0}\".format(num + 1, r.name) for num, r in enumerate(self.rules))\n    return fmt.format(indent=self.indent)", "response": "Builds the python source code for the Parser TokenType enum."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_class_definition(self):\n    fmt = \"\"\"class Parser({parser_base}):\n             {indent}\\\"\\\"\\\"This class contains methods for reading source code and generating a parse tree.\\\"\\\"\\\"\n             {indent}entry_point = \"{entry_point}\"\n\n             {rule_definitions}\n             \"\"\"\n    fmt = self._clean_fmt(fmt)\n    return fmt.format(parser_base=self._get_parser_base(),\n                      indent=self.indent,\n                      entry_point=self._get_entry_point(),\n                      rule_definitions=\"\\n\".join(self._get_rule_definitions()))", "response": "Builds the class definition of the parser."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_entry_point(self):\n    ep = self._find_directive(\"entry_point\")\n    if ep:\n      return ep.args[\"value\"]\n    else:\n      return self.rules[0].name", "response": "Gets the entry_point value for the parser."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_rule_definition(self, rule):\n    fmt = \"\"\"def {rule_fxn_name}(self, text):\n             {indent}\\\"\\\"\\\"{rule_source}\\\"\\\"\\\"\n             {indent}self._attempting(text)\n             {indent}return {rule_definition}(text){transform}\n          \"\"\"\n    fmt = self._clean_fmt(fmt)\n    source = self._indent(self._ast_to_code(rule.expression), skip_first_line=True)\n\n    # All the primitives will accept a string x in place of terminal(x). This is terminal shorthand.\n    # However, if a rule is only a wrapper around a single terminal, we have to actually make a\n    # terminal call. This handles that situation.\n    if self.use_terminal_shorthand and len(source) == 1 and source[0].startswith((\"'\", '\"')):\n      source = [\"terminal({})\".format(source[0])]\n\n    rule_source = fmt.format(rule_fxn_name=self._get_rule_fxn_name(rule.name),\n                             indent=self.indent,\n                             rule_source=self._get_rule_source(rule),\n                             rule_definition=\"\\n\".join(source),\n                             transform=self._get_rule_transform(rule))\n    return self._indent(rule_source, 1)", "response": "Generates the source code for a rule."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_rule_source(self, rule):\n    p = len(self.input_source) + rule.position\n    source = self.input_source[p:p + rule.consumed].rstrip()\n    return self._indent(source, depth=self.indent + \"   \", skip_first_line=True)", "response": "Gets the variable part of the source code for a rule."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_rule_transform(self, rule):\n    rd = self._find_directive(lambda d: d.name == \"rule\" and d.args.get(\"name\") == rule.name)\n\n    if rd:\n      args = rd.args\n    else:\n      args = {}\n\n    transform = args.get(\"transform\", \"retype\")\n\n    if transform == \"retype\":\n      new_name = args.get(\"to_type\", \"TokenType.{0}\".format(rule.name))\n      return \".retyped({0})\".format(new_name)\n    elif transform == \"compress\":\n      new_name = args.get(\"to_type\", \"TokenType.{0}\".format(rule.name))\n      if new_name == \"identity\":\n        return \".compressed()\"\n      else:\n        return \".compressed({0})\".format(new_name)\n    elif transform == \"identity\":\n      return \"\"", "response": "Returns the source code text for accomplishing the given rule."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _expression_to_asn(self, expression):\n    new_children = [self._node_to_asn(c) for c in expression.children]\n    return self._remove_grouping_groups(infix_to_optree(new_children))", "response": "Convert an expression to an Abstract Syntax Tree Node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _node_to_asn(self, node):\n    if node.is_type(TokenType.identifier):\n      return Identifier(node.svalue)\n\n    elif node.is_type(TokenType.terminal):\n      return Terminal(node.svalue)\n\n    elif node.is_type(TokenType.option_group):\n      expr = node.children[0]\n      return OptionGroup(self._expression_to_asn(expr))\n\n    elif node.is_type(TokenType.repetition_group):\n      expr = node.children[0]\n      return RepetitionGroup(self._expression_to_asn(expr))\n\n    elif node.is_type(TokenType.grouping_group):\n      expr = node.children[0]\n      return GroupingGroup(self._expression_to_asn(expr))\n\n    elif node.is_type(TokenType.special_handling):\n      ident = node.children[0]\n      return SpecialHandling(ident)\n\n    elif node.is_type(TokenType.number):\n      return Number(node.svalue)\n\n    elif node.is_type((TokenType.operator, TokenType.op_mult, TokenType.op_add)):\n      return OperatorNode(OPERATOR_INDEX[node.svalue], node.position)\n\n    else:\n      raise Exception(\"Unhandled parse tree node: {0}\".format(node))", "response": "Convert a parse tree node into an absract syntax tree node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nflatten a list of operands based on a pred.", "response": "def _hoist_operands(self, operands, pred):\n    \"\"\"Flattens a list of optree operands based on a pred.\n\n    This is used to convert concatenation([x, concatenation[y, ...]]) (or alternation) to\n    concatenation([x, y, ...]).\n    \"\"\"\n    hopper = list(operands)\n    new_operands = []\n    while hopper:\n      target = hopper.pop(0)\n      if pred(target):\n        hopper = list(target.operands) + hopper\n      else:\n        new_operands.append(target)\n    return new_operands"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving grouping groups from an OptreeNode.", "response": "def _remove_grouping_groups(self, optree):\n    \"\"\"Grouping groups are implied by optrees, this function hoists grouping group expressions up\n    to their parent node.\n    \"\"\"\n    new_operands = []\n    for operand in optree.operands:\n      if isinstance(operand, OptreeNode):\n        new_operands.append(self._remove_grouping_groups(operand))\n      elif isinstance(operand, GroupingGroup):\n        new_operands.append(operand.expression)\n      else:\n        new_operands.append(operand)\n\n    return OptreeNode(optree.opnode, new_operands)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ast_to_code(self, node, **kwargs):\n    if isinstance(node, OptreeNode):\n      return self._ast_optree_node_to_code(node, **kwargs)\n    elif isinstance(node, Identifier):\n      return self._ast_identifier_to_code(node, **kwargs)\n    elif isinstance(node, Terminal):\n      return self._ast_terminal_to_code(node, **kwargs)\n    elif isinstance(node, OptionGroup):\n      return self._ast_option_group_to_code(node, **kwargs)\n    elif isinstance(node, RepetitionGroup):\n      return self._ast_repetition_group_to_code(node, **kwargs)\n    elif isinstance(node, SpecialHandling):\n      return self._ast_special_handling_to_code(node, **kwargs)\n    elif isinstance(node, Number):\n      return self._ast_number_to_code(node, **kwargs)\n    else:\n      raise Exception(\"Unhandled ast node: {0}\".format(node))", "response": "Convert an abstract syntax tree to python source code."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts an abstract syntax operator tree to python source code.", "response": "def _ast_optree_node_to_code(self, node, **kwargs):\n    \"\"\"Convert an abstract syntax operator tree to python source code.\"\"\"\n    opnode = node.opnode\n    if opnode is None:\n      return self._ast_to_code(node.operands[0])\n    else:\n      operator = opnode.operator\n      if operator is OP_ALTERNATE:\n        return self._ast_op_alternate_to_code(node, **kwargs)\n      elif operator is OP_WS_CONCAT:\n        kwargs[\"ignore_whitespace\"] = False\n        return self._ast_op_concat_to_code(node, **kwargs)\n      elif operator is OP_CONCAT:\n        kwargs[\"ignore_whitespace\"] = True\n        return self._ast_op_concat_to_code(node, **kwargs)\n      elif operator is OP_EXCLUDE:\n        return self._ast_op_exclude_to_code(node, **kwargs)\n      elif operator is OP_MULTIPLY:\n        return self._ast_op_multiply_to_code(node, **kwargs)\n      elif operator is OP_REPEAT:\n        return self._ast_op_repeat_to_code(node, **kwargs)\n      else:\n        raise Exception(\"Unhandled optree node: {0}\".format(node))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _ast_terminal_to_code(self, terminal, **kwargs):\n    value = _replace(terminal.value)\n    if self.use_terminal_shorthand:\n      return [value]\n    else:\n      return [\"terminal({})\".format(value)]", "response": "Convert an AST terminal to python source code."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert an AST option group to python source code.", "response": "def _ast_option_group_to_code(self, option_group, **kwargs):\n    \"\"\"Convert an AST option group to python source code.\"\"\"\n    lines = [\"option(\"]\n    lines.extend(self._indent(self._ast_to_code(option_group.expression)))\n    lines.append(\")\")\n    return lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _ast_repetition_group_to_code(self, repetition_group, ignore_whitespace=False, **kwargs):\n    lines = [\"zero_or_more(\"]\n    lines.extend(self._indent(self._ast_to_code(repetition_group.expression)))\n    lines[-1] += \",\"\n    lines.append(self._indent(\"ignore_whitespace={}\".format(bool(ignore_whitespace))))\n    lines.append(\")\")\n    return lines", "response": "Convert an AST repetition group to python source code."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _ast_special_handling_to_code(self, special_handling, **kwargs):\n    ident = special_handling.value.svalue\n    if ident in PB_SPECIAL_HANDLING:\n      return [\"PB.{0}\".format(ident)]\n    else:\n      return [\"self.{0}\".format(ident)]", "response": "Convert an AST sepcial handling to python source code."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts an AST alternate op to python source code.", "response": "def _ast_op_alternate_to_code(self, opr, **kwargs):\n    \"\"\"Convert an AST alternate op to python source code.\"\"\"\n    hoist_target = OP_ALTERNATE\n    operands = self._hoist_operands(opr.operands, lambda t: isinstance(t, OptreeNode) and t.opnode.operator is hoist_target)\n\n    lines = [\"alternation([\"]\n    for op in operands:\n      lines.extend(self._indent(self._ast_to_code(op)))\n      lines[-1] += \",\"\n    lines.append(\"])\")\n    return lines"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _ast_op_concat_to_code(self, opr, *, ignore_whitespace, **kwargs):\n    hoist_target = OP_CONCAT if ignore_whitespace else OP_WS_CONCAT\n    operands = self._hoist_operands(opr.operands, lambda t: isinstance(t, OptreeNode) and t.opnode.operator is hoist_target)\n\n    lines = [\"concatenation([\"]\n    for op in operands:\n      lines.extend(self._indent(self._ast_to_code(op, ignore_whitespace=ignore_whitespace)))\n      lines[-1] += \",\"\n    lines.append(\"], ignore_whitespace={})\".format(bool(ignore_whitespace)))\n    return lines", "response": "Convert an AST concatenate op to python source code."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts an AST exclude op to python source code.", "response": "def _ast_op_exclude_to_code(self, opr, **kwargs):\n    \"\"\"Convert an AST exclude op to python source code.\"\"\"\n    opl, opr = opr.operands\n\n    lines = [\"exclusion(\"]\n    lines.extend(self._indent(self._ast_to_code(opl)))\n    lines[-1] += \",\"\n    lines.extend(self._indent(self._ast_to_code(opr)))\n    lines.append(\")\")\n    return lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _ast_op_multiply_to_code(self, opr, ignore_whitespace=False, **kwargs):\n    opl, opr = opr.operands\n\n    if isinstance(opl, Number):\n      times = opl.value\n      subject = self._ast_to_code(opr)\n    else:\n      times = opr.value\n      subject = self._ast_to_code(opl)\n\n    lines = [\"repeated(\"]\n    lines.extend(self._indent(subject))\n    lines[-1] += \",\"\n    lines.append(\"{0}times={1},\".format(self.indent, times))\n    lines.append(\"{0}ignore_whitespace={1}\".format(self.indent, bool(ignore_whitespace)))\n    lines.append(\")\")\n    return lines", "response": "Convert an AST multiply op to python source code."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting an AST repeat op to python source code.", "response": "def _ast_op_repeat_to_code(self, opr, ignore_whitespace=False, **kwargs):\n    \"\"\"Convert an AST repeat op to python source code.\"\"\"\n    lines = [\"one_or_more(\"]\n    lines.extend(self._indent(self._ast_to_code(opr.operands[0])))\n    lines[-1] += \",\"\n    lines.append(self._indent(\"ignore_whitespace={}\".format(bool(ignore_whitespace))))\n    lines.append(\")\")\n    return lines"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _indent(self, text, depth=1, *, skip_first_line=False, suffix=\"\"):\n    as_list = isinstance(text, list)\n\n    if as_list:\n      lines = text\n    else:\n      lines = text.split(\"\\n\")\n    new_lines = []\n\n    if isinstance(depth, int):\n      spacing = self.indent * depth\n    else:\n      spacing = depth\n\n    for i, line in enumerate(lines):\n      if skip_first_line and i == 0:\n        new_lines.append(\"{0}{1}\".format(line, suffix))\n      else:\n        new_lines.append(\"{0}{1}{2}\".format(spacing, line, suffix))\n\n    if as_list:\n      return new_lines\n    else:\n      return \"\\n\".join(new_lines)", "response": "Indent text by depth and suffix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _find_directives(self, pred):\n    if isinstance(pred, str):\n      return [d for d in self.directives if d.name == pred]\n    else:\n      return [d for d in self.directives if pred(d)]", "response": "Finds all directives with a certain name or that passes a predicate."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _flatten(child, parent):\n    return parent.is_type(TokenType.expression) and child.node_type == parent.node_type", "response": "Custom flattening method for the parse tree."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef directives_from_comment(cls, comment):\n    comment_contents = comment.value[2:-2].strip()\n    comment_lines = (l.strip() for l in comment_contents.split(\"\\n\"))\n    directives = (l[1:].strip() for l in comment_lines if l.startswith(\"!\"))\n\n    for directive_def in directives:\n      yield cls.parse_directive_def(directive_def)", "response": "A generator that yields all directives in a comment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nturning a directive definition string into a Directive object.", "response": "def parse_directive_def(cls, directive_def):\n    \"\"\"Turns a directive definition string into a directive object.\"\"\"\n    name, *kwargs = esc_split(directive_def, ignore_empty=True)\n    return Directive(name, {key: value for key, value in (esc_split(arg, \"=\") for arg in kwargs)})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_arguments(self):\n        ApiCli.get_arguments(self)\n        if self.args.hostGroupName is not None:\n            self.url_parameters = {\"name\": self.args.hostGroupName}", "response": "Extracts the specific arguments of this CLI\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract the specific arguments of this CLI", "response": "def get_arguments(self):\n        \"\"\"\n        Extracts the specific arguments of this CLI\n        \"\"\"\n        ApiCli.get_arguments(self)\n        if self.args.plugin_name is not None:\n            self.plugin_name = self.args.plugin_name\n\n        self.path = \"v1/plugins/{0}\".format(self.plugin_name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_arguments(self):\n        ApiCli.get_arguments(self)\n        self._alarm_id = self.args.alarm_id if self.args.alarm_id is not None else None", "response": "Extracts the specific arguments of this CLI\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle the results of the API call to get the current user s ID and the user s name.", "response": "def _handle_results(self):\n        \"\"\"\n        Handle the results of the API call\n        \"\"\"\n\n        # Only process if we get HTTP return code other 200.\n        if self._api_result.status_code != requests.codes.ok:\n            print(self.colorize_json(self._api_result.text))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a key to a string.", "response": "def key_to_str(modifiers, key, mods_table = mods, key_table = wx, key_prefix = 'WXK_'):\n \"\"\"\n Returns a human-readable version of numerical modifiers and key.\n \n To make the key suitable for global hotkey usage, supply:\n mods_table = global_mods, key_table = win32con, key_prefix = 'VK_'\n \"\"\"\n logger.debug('Converting (%s, %s) to string.', modifiers, key)\n if not key:\n  key_str = 'NONE'\n else:\n  key_str = None\n res = ''\n for value, name in mods_table.items():\n  if (modifiers & value):\n   res += name + '+'\n for x in dir(key_table):\n  if x.startswith(key_prefix):\n   if getattr(key_table, x) == key:\n    key_str = converts.get(x, x[len(key_prefix):])\n if not key_str:\n  key_str = chr(key)\n res += key_str\n logger.debug('Final result: %s.', res)\n return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a string like CTRL_ALT + K into a key.", "response": "def str_to_key(value, key_table = wx, accel_format = 'ACCEL_%s', key_format = 'WXK_%s', key_transpositions = {}):\n \"\"\"\n Turns a string like \"CTRL_ALT+K\" into (3, 75).\n \n To get a global hotkey, try passing:\n key_table = win32con, accel_format = 'MOD_%s', key_format = 'VK_%s', key_transpositions = {'CTRL': 'CONTROL'}\n \"\"\"\n logger.debug('Converting \"%s\" to integers.', value)\n modifiers = 0\n key = 0\n split = value.split('+')\n for v in split:\n  v = v.upper()\n  a = accel_format % key_transpositions.get(v, v)\n  logger.debug('Accelerator format = %s.', a)\n  k = key_format % key_transpositions.get(v, v)\n  logger.debug('Key format = %s.', k)\n  if hasattr(key_table, a):\n   logger.debug('Found accelerator on %r.', key_table)\n   modifiers = modifiers | getattr(key_table, a)\n  elif hasattr(key_table, k):\n   logger.debug('Found key on %r.', key_table)\n   if key:\n    raise ValueError('Multiple keys specified.')\n   else:\n    key = getattr(key_table, k)\n if not key:\n  logger.debug('No key yet, falling back to ord.')\n  key = ord(split[-1])\n logger.debug('modifiers = %d, key = %d.', modifiers, key)\n return (modifiers, key)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a new id if the provided one is None.", "response": "def get_id(id):\n \"\"\"Get a new id if the provided one is None.\"\"\"\n if id == None:\n  id = wx.NewId()\n  logger.debug('Generated new ID %s.', id)\n else:\n  logger.debug('Using provided id %s.', id)\n return id"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a key to the accelerator list.", "response": "def add_accelerator(control, key, func, id = None):\n \"\"\"\n Adds a key to the control.\n \n control: The control that the accelerator should be added to.\n key: A string like \"CTRL+F\", or \"CMD+T\" that specifies the key to use.\n func: The function that should be called when key is pressed.\n id: The id to Bind the event to. Defaults to wx.NewId().\n \"\"\"\n logger.debug('Adding key \"%s\" to control %s to call %s.', key, control, func)\n id = get_id(id)\n control.Bind(wx.EVT_MENU, func, id = id)\n t = _tables.get(control, [])\n modifiers, key_int = str_to_key(key)\n t.append((modifiers, key_int, id))\n _tables[control] = t\n update_accelerators(control)\n return id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove an accelerator from a control.", "response": "def remove_accelerator(control, key):\n \"\"\"\n Removes an accelerator from control.\n \n control: The control to affect.\n key: The key to remove.\n \"\"\"\n key = str_to_key(key)\n t = _tables.get(control, [])\n for a in t:\n  if a[:2] == key:\n   t.remove(a)\n   if t:\n    _tables[control] = t\n   else:\n    del _tables[control]\n   update_accelerators(control)\n   return True\n return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_hotkey(control, key, func, id = None):\n if win32con is None:\n  raise RuntimeError('win32con is not available.')\n logger.debug('Adding hotkey \"%s\" to control %s to call %s.', key, control, func)\n modifiers, keycode = str_to_key(key, key_table = win32con, accel_format = 'MOD_%s', key_format = 'VK_%s', key_transpositions = {'CTRL': 'CONTROL'})\n id = get_id(id)\n control.Bind(wx.EVT_HOTKEY, func, id = id)\n l = _hotkeys.get(control, [])\n l.append([key, id])\n _hotkeys[control] = l\n return control.RegisterHotKey(id, modifiers, keycode)", "response": "Add a hotkey to a control via id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving a global hotkey.", "response": "def remove_hotkey(control, key):\n \"\"\"\n Remove a global hotkey.\n \n control - The control to affect\n key - The key to remove.\n \"\"\"\n l = _hotkeys.get(control, [])\n for a in l:\n  key_str, id = a\n  if key_str == key:\n   control.Unbind(wx.EVT_HOTKEY, id = id)\n   control.UnregisterHotKey(id)\n   l.remove(a)\n   if l:\n    _hotkeys[control] = l\n   else:\n    del _hotkeys[control]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_arguments(self):\n        self.add_logging_argument()\n        self.parser.add_argument('-a', '--api-host', dest='api_host', action='store', metavar=\"api_host\",\n                                 help='{0} API host endpoint'.format(self.product_name))\n        self.parser.add_argument('-e', '--email', dest='email', action='store', metavar=\"e_mail\",\n                                 help='e-mail that has access to the {0} account'.format(self.product_name))\n        self.parser.add_argument('-t', '--api-token', dest='api_token', required=False, action='store',\n                                 metavar=\"api_token\",\n                                 help='API token for given e-mail that has access to the {0} account'.format(\n                                     self.product_name))\n        self.parser.add_argument('-z', '--curl', dest='curl', required=False, action='store_true', default=False,\n                                 help='Output the corresponding curl command line and exit')", "response": "Configure handling of command line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconfigures logging based on command line options", "response": "def _configure_logging(self):\n        \"\"\"\n        Configure logging based on command line options\n        \"\"\"\n        if self.args.logLevel is not None:\n            logging.basicConfig(level=self.levels[self.args.logLevel])\n        logging.info(\"Set logging level to {0}\".format(self.args.logLevel))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _validate_arguments(self):\n        if self._email is None:\n            self.set_error_message(\"E-mail for the account not provided\")\n            return False\n        if self._api_token is None:\n            self.set_error_message(\"API Token for the account not provided\")\n            return False\n        return True", "response": "Validate the command line arguments passed to the CLI\n            class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(self):\n\n        # Set default arguments from environment variables\n        self._get_environment()\n\n        # Call our member function to add command line arguments, child classes that override need\n        # to call the ApiCli version first to add standard arguments\n        self.add_arguments()\n\n        # Parse the command line arguments\n        self._parse_args()\n\n        # Arguments are parsed call back to the instance so that it can extract the command line\n        # arguments for its use\n        self.get_arguments()\n\n        self.get_api_parameters()\n        if self._validate_arguments():\n            if self._curl:\n                self._curl_output()\n            else:\n                self._call_api()\n                self._handle_results()\n        else:\n            print(self._message)", "response": "Run the steps to execute the CLI"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef infix_to_postfix(nodes, *, recurse_types=None):\n  output = []\n  operators = []\n\n  for node in nodes:\n    if isinstance(node, OperatorNode):\n      # Drain out all operators whose precedence is gte the node's...\n      cmp_operator = node.operator\n      while operators:\n        current_operator = operators[-1].operator\n        if current_operator.precedence > cmp_operator.precedence or \\\n           current_operator.precedence == cmp_operator.precedence and current_operator.association == Association.left:\n          output.append(operators.pop())\n        else:\n          break\n      operators.append(node)\n    else:\n      if recurse_types is not None and node.node_type in recurse_types:\n        output.extend(infix_to_postfix(node.children, recurse_types=recurse_types))\n      else:\n        output.append(node)\n\n  return output + list(reversed(operators))", "response": "Convert a list of nodes in infix order to a list of nodes in postfix order."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef postfix_to_optree(nodes):\n  while len(nodes) > 1:\n    nodes = _reduce(nodes)\n\n  if len(nodes) == 0:\n    raise OperatorError(\"Empty node list\")\n\n  node = nodes[0]\n\n  if isinstance(node, OperatorNode):\n    raise OperatorError(\"Operator without operands\")\n\n  if isinstance(node, OptreeNode):\n    return node\n\n  return OptreeNode(None, (node, ))", "response": "Convert a list of nodes in postfix order to an Optree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _reduce(nodes):\n  i = 0\n  while i < len(nodes):\n    if isinstance(nodes[i], OperatorNode):\n      break\n    else:\n      i += 1\n\n  if i == len(nodes):\n    raise OperatorError(\"No operator found\")\n\n  operator_node = nodes[i]\n  operator = operator_node.operator\n  operands_lbound = i - operator.cardinality\n\n  if operands_lbound < 0:\n    raise OperatorError(\"Insufficient operands for operator {0}\".format(operator.symbol))\n\n  return nodes[:operands_lbound] + \\\n         [OptreeNode(operator_node, tuple(nodes[operands_lbound:i]))] + \\\n         nodes[i+1:]", "response": "Reduce the list of nodes by adding the operator and operands to the OptreeNode."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_arguments(self):\n        ApiCli.get_arguments(self)\n        if self.args.pluginName is not None:\n            self.pluginName = self.args.pluginName", "response": "Extracts the specific arguments of this CLI\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _process_properties(self, properties):\n        if properties is not None:\n            self._properties = {}\n            for p in properties:\n                d = p.split('=')\n                self._properties[d[0]] = d[1]", "response": "Transforms the command line properties into python dictionary"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_arguments(self):\n        MetricCommon.add_arguments(self)\n        self.parser.add_argument('-n', '--metric-name', dest='metricName', action='store',\n                                 required=True, metavar='metric_name', help='Metric identifier')\n        self.parser.add_argument('-d', '--display-name', dest='displayName', action='store',\n                                 required=True, metavar='display_name', help='Metric display name')\n        self.parser.add_argument('-s', '--display-name-short', dest='displayNameShort', action='store',\n                                 required=True, metavar='display_short_name', help='Metric short display name')\n        self.parser.add_argument('-i', '--description', dest='description', action='store',\n                                 required=not self.update, metavar='description', help='Metric description')\n        self.parser.add_argument('-g', '--aggregate', dest='aggregate', action='store',\n                                 required=True, choices=['avg', 'max', 'min', 'sum'],\n                                 help='Metric default aggregate')\n        self.parser.add_argument('-u', '--unit', dest='unit', action='store',\n                                 required=False, choices=['percent', 'number', 'bytecount', 'duration'],\n                                 help='Metric unit')\n        self.parser.add_argument('-r', '--resolution', dest='resolution', action='store', metavar='resolution',\n                                 required=False, help='Metric default resolution')\n        self.parser.add_argument('-y', '--type', dest='type', action='store', default=None,\n                                 required=False, metavar='type', help='Sets the type metadata field')\n        self.parser.add_argument('-x', '--is-disabled', dest='isDisabled', action='store', default=None,\n                                 required=False,\n                                 choices=['true', 'false'], help='Enable or disable the metric definition')", "response": "Add the specific arguments of this CLI\n        to the parser"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract the specific arguments of this CLI from the arguments object.", "response": "def get_arguments(self):\n        \"\"\"\n        Extracts the specific arguments of this CLI\n        \"\"\"\n        MetricCommon.get_arguments(self)\n        \n        if self.args.metricName is not None:\n            self.metricName = self.args.metricName\n            \n        if self.args.displayName is not None:\n            self.displayName = self.args.displayName\n                        \n        if self.args.displayNameShort is not None:\n            self.displayNameShort = self.args.displayNameShort\n\n        if self.args.description is not None:\n            self.description = self.args.description\n                    \n        if self.args.aggregate is not None:\n            self.aggregate = self.args.aggregate\n            \n        if self.args.unit is not None:\n            self.unit = self.args.unit\n            \n        if self.args.resolution is not None:\n            self.resolution = self.args.resolution\n\n        if self.args.isDisabled is not None:\n            self.isDisabled = self.args.isDisabled\n\n        if self.args.type is not None:\n            self.type = self.args.type\n\n        data = {}\n        if self.metricName is not None:\n            data['name'] = self.metricName\n        if self.displayName is not None:\n            data['displayName'] = self.displayName\n        if self.displayNameShort is not None:\n            data['displayNameShort'] = self.displayNameShort\n        if self.description is not None:\n            data['description'] = self.description\n        if self.aggregate is not None:\n            data['defaultAggregate'] = self.aggregate\n        if self.unit is not None:\n            data['unit'] = self.unit\n        if self.resolution is not None:\n            data['defaultResolutionMS'] = self.resolution\n        if self.isDisabled is not None:\n            data['isDisabled'] = True if self.isDisabled == 'yes' else False\n        if self.type is not None:\n            data['type'] =  self.type\n\n        self.path = \"v1/metrics/{0}\".format(self.metricName)\n        self.data = json.dumps(data, sort_keys=True)\n        self.headers = {'Content-Type': 'application/json', \"Accept\": \"application/json\"}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_arguments(self):\n        ApiCli.get_arguments(self)\n        self._alarm_name = self.args.alarm_name if self.args.alarm_name is not None else None", "response": "Extracts the specific arguments of this CLI\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(self):\n        f = open(self.path, \"r\")\n        self.manifest_json = f.read()", "response": "Load the metrics file from the given path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the file and parse JSON into dictionary", "response": "def load(self):\n        \"\"\"\n        Read the file and parse JSON into dictionary\n        \"\"\"\n        manifest = PluginManifest(self.file_path)\n        manifest.get()\n        self.manifest = manifest.get_manifest()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getMetricDefinition(self, name):\n        metric = None\n        for m in self.metric_definitions:\n            if m['name'] == name:\n                metric = m\n                break\n        return metric", "response": "Look up the metric definition from the definitions of the API call that matches the given name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef printMetricsHeader(self, m, d):\n        mstr = \"Metric Name\"\n        dstr = \"Description\"\n\n        print('|{0}{1}|{2}{3}|'.format(mstr, ' ' * (m - len(mstr)), dstr, ' ' * (d - len(dstr))))\n        print('|:{0}|:{1}|'.format('-' * (m - 1), '-' * (d - 1)))", "response": "Prints out the header of the metrics table based on the size of the data in columns\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getFieldsColumnLengths(self):\n        nameLen = 0\n        descLen = 0\n        for f in self.fields:\n            nameLen = max(nameLen, len(f['title']))\n            descLen = max(descLen, len(f['description']))\n        return (nameLen, descLen)", "response": "Gets the maximum length of each column in the field table\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the maximum length of each column in the metrics table", "response": "def getMetricsColumnLengths(self):\n        \"\"\"\n        Gets the maximum length of each column\n        \"\"\"\n        displayLen = 0\n        descLen = 0\n        for m in self.metrics:\n            displayLen = max(displayLen, len(m['displayName']))\n            descLen = max(descLen, len(m['description']))\n        return (displayLen, descLen)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nescape underscores so that the markdown is correct", "response": "def escapeUnderscores(self):\n        \"\"\"\n        Escape underscores so that the markdown is correct\n        \"\"\"\n        new_metrics = []\n        for m in self.metrics:\n            m['name'] = m['name'].replace(\"_\", \"\\_\")\n            new_metrics.append(m)\n        self.metrics = new_metrics"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints out the header of the fields of the current record set.", "response": "def printFieldsHeader(self, f, d):\n        \"\"\"\n        Prints out table header based on the size of the data in columns\n        \"\"\"\n        fstr = \"Field Name\"\n        dstr = \"Description\"\n        f = max(f, len(fstr))\n        d = max(d, len(dstr))\n\n        print('|{0}{1}|{2}{3}|'.format(fstr, ' ' * (f - len(fstr)), dstr, ' ' * (d - len(dstr))))\n        print('|:{0}|:{1}|'.format('-' * (f - 1), '-' * (d - 1)))\n        return (f, d)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting out the metrics for the current locale.", "response": "def printMetrics(self, m, d):\n        \"\"\"\n        Prints out table rows based on the size of the data in columns\n        \"\"\"\n        for metric in self.metrics:\n            mstr = metric['displayName']\n            dstr = metric['description']\n            mlen = m - len(mstr)\n            dlen = d - len(dstr)\n            print(\"|{0}{1}|{2}{3}|\".format(mstr, ' ' * mlen, dstr, ' ' * dlen))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint out the fields of the current object.", "response": "def printFields(self, f, d):\n        \"\"\"\n        Prints out table rows based on the size of the data in columns\n        \"\"\"\n        for field in self.fields:\n            fstr = field[\"title\"]\n            dstr = field[\"description\"]\n            flen = f - len(fstr)\n            dlen = d - len(dstr)\n            print(\"|{0}{1}|{2}{3}|\".format(fstr, ' ' * flen, dstr, ' ' * dlen))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef outputFieldMarkdown(self):\n        f, d = self.getFieldsColumnLengths()\n\n        fc, dc = self.printFieldsHeader(f, d)\n        f = max(fc, f)\n        d = max(dc, d)\n        self.printFields(f, d)", "response": "Send the field definitions ot standard out\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef outputMetricMarkdown(self):\n        self.escapeUnderscores()\n        m, d = self.getMetricsColumnLengths()\n\n        self.printMetricsHeader(m, d)\n        self.printMetrics(m, d)", "response": "Send the markdown of the metric definitions to standard out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generateMarkdown(self):\n        self.generateMetricDefinitions()\n        self.generateFieldDefinitions()\n        self.generateDashboardDefinitions()\n        self.outputMarkdown()", "response": "Generate Markdown for all the metrics and field definitions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nattempting to parse source code.", "response": "def parse(self, text):\n    \"\"\"Attempt to parse source code.\"\"\"\n    self.original_text = text\n\n    try:\n      return getattr(self, self.entry_point)(text)\n    except (DeadEnd) as exc:\n      raise ParserError(self.most_consumed, \"Failed to parse input\") from exc\n    return tree"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _attempting(self, text):\n    consumed = len(self.original_text) - len(text)\n    self.most_consumed = max(consumed, self.most_consumed)", "response": "Keeps track of the most consumed point in the source code the parser has reached to this point."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_arguments(self):\n\n        # Call our parent to add the default arguments\n        ApiCli.add_arguments(self)\n\n        # Command specific arguments\n        self.parser.add_argument('-f', '--format', dest='format', action='store', required=False,\n                                 choices=['csv', 'json', 'raw', 'xml'], help='Output format. Default is raw')\n        self.parser.add_argument('-n', '--name', dest='metric_name', action='store', required=True,\n                                 metavar=\"metric_name\", help='Metric identifier')\n        self.parser.add_argument('-g', '--aggregate', dest='aggregate', action='store', required=False,\n                                 choices=['sum', 'avg', 'max', 'min'], help='Metric default aggregate')\n        self.parser.add_argument('-r', '--sample', dest='sample', action='store', type=int, metavar=\"sample\",\n                                 help='Down sample rate sample in seconds')\n        self.parser.add_argument('-s', '--source', dest='source', action='store', metavar=\"source\", required=True,\n                                 help='Source of measurement')\n        self.parser.add_argument('-b', '--start', dest='start', action='store', required=True, metavar=\"start\",\n                                 help='Start of time range as ISO 8601 string or epoch seconds')\n        self.parser.add_argument('-d', '--end', dest='end', action='store', metavar=\"end\", required=False,\n                                 help='End of time range as ISO 8601 string or epoch seconds')\n\n        self.parser.add_argument('-o', '--date-format', dest='date_format', action='store', metavar=\"format\",\n                                 required=False,\n                                 help='For CSV, JSON, and XML output formats dates (see Python date.strftime). ' +\n                                      'Default format is %%s')", "response": "Add command line arguments for this command   \n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting the specific arguments of this CLI", "response": "def get_arguments(self):\n        \"\"\"\n        Extracts the specific arguments of this CLI\n        \"\"\"\n        ApiCli.get_arguments(self)\n        if self.args.metric_name is not None:\n            self._metric_name = self.args.metric_name\n\n        if self.args.sample is not None:\n            self.sample = self.args.sample\n\n        if self.args.source is not None:\n            self.source = self.args.source\n        else:\n            self.source = None\n\n        if self.args.aggregate is not None:\n            self.aggregate = self.args.aggregate\n        else:\n            self.aggregate = \"avg\"\n\n        if self.args.format is not None:\n            self.format = self.args.format\n        else:\n            self.format = \"json\"\n\n        if self.args.date_format is not None:\n            self.date_format = self.args.date_format\n\n        start_time = int(self.parse_time_date(self.args.start).strftime(\"%s\"))\n\n        # If the end time is not specified then\n        # default to the current time\n        if self.args.end is None:\n            stop_time = int(self.now.strftime(\"%s\"))\n        else:\n            stop_time = int(self.parse_time_date(self.args.end).strftime(\"%s\"))\n\n        # Convert to epoch time in milli-seconds\n        start_time *= 1000\n        stop_time *= 1000\n\n        self.path = \"v1/measurements/{0}\".format(self._metric_name)\n        url_parameters = {\"start\": str(start_time),\n                          \"end\": str(stop_time),\n                          \"sample\": str(self.sample),\n                          \"agg\": self.aggregate}\n        if self.source is not None:\n            url_parameters['source'] = self.source\n        self.url_parameters = url_parameters"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nattempts to parse the passed in string into a valid datetime.", "response": "def parse_time_date(self, s):\n        \"\"\"\n        Attempt to parse the passed in string into a valid datetime.\n        If we get a parse error then assume the string is an epoch time\n        and convert to a datetime.\n        \"\"\"\n        try:\n            ret = parser.parse(str(s))\n        except ValueError:\n            try:\n                ret = datetime.fromtimestamp(int(s))\n            except TypeError:\n                ret = None\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noutput results in CSV format", "response": "def output_csv(self, text):\n        \"\"\"\n        Output results in CSV format\n        \"\"\"\n        payload = json.loads(text)\n        # Print CSV header\n        print(\"{0},{1},{2},{3},{4}\".format('timestamp', 'metric', 'aggregate', 'source', 'value'))\n        metric_name = self._metric_name\n        # Loop through the aggregates one row per timestamp, and 1 or more source/value pairs\n        for r in payload['result']['aggregates']['key']:\n            timestamp = self._format_timestamp(r[0][0])\n            # timestamp = string.strip(timestamp, ' ')\n            # timestamp = string.strip(timestamp, \"'\")\n            for s in r[1]:\n                print('{0},\"{1}\",\"{2}\",\"{3}\",{4}'.format(timestamp, metric_name, self.aggregate, s[0], s[1]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef output_json(self, text):\n        payload = json.loads(text)\n        data = []\n        metric_name = self._metric_name\n        for r in payload['result']['aggregates']['key']:\n            timestamp = self._format_timestamp(r[0][0])\n            for s in r[1]:\n                data.append({\n                    \"timestamp\": timestamp,\n                    \"metric\": metric_name,\n                    \"aggregate\": self.aggregate,\n                    \"source\": s[0],\n                    \"value\": s[1],\n                })\n        payload = {\"data\": data}\n        out = json.dumps(payload, indent=self._indent, separators=(',', ': '))\n        print(self.colorize_json(out))", "response": "Output results in structured JSON format"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\noutputs results in raw JSON format", "response": "def output_raw(self, text):\n        \"\"\"\n        Output results in raw JSON format\n        \"\"\"\n        payload = json.loads(text)\n        out = json.dumps(payload, sort_keys=True, indent=self._indent, separators=(',', ': '))\n        print(self.colorize_json(out))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noutputting the results in JSON format", "response": "def output_xml(self, text):\n        \"\"\"\n        Output results in JSON format\n        \"\"\"\n\n        # Create the main document nodes\n        document = Element('results')\n        comment = Comment('Generated by TrueSight Pulse measurement-get CLI')\n        document.append(comment)\n        aggregates = SubElement(document, 'aggregates')\n        aggregate = SubElement(aggregates, 'aggregate')\n        measurements = SubElement(aggregate, 'measurements')\n\n        # Parse the JSON result so we can translate to XML\n        payload = json.loads(text)\n\n        # Current only support a single metric, if we move to the batch API then\n        # we can handle multiple\n        metric_name = self._metric_name\n\n        # Loop through the aggregates one row per timestamp, and 1 or more source/value pairs\n        for r in payload['result']['aggregates']['key']:\n            timestamp = self._format_timestamp(r[0][0])\n            for s in r[1]:\n                # Each timestamp, metric, source, values is placed in a measure tag\n                measure_node = SubElement(measurements, 'measure')\n                source = s[0]\n                value = str(s[1])\n                ts_node = SubElement(measure_node, 'timestamp')\n                ts_node.text = str(timestamp)\n                metric_node = SubElement(measure_node, 'metric')\n                metric_node.text = metric_name\n                metric_node = SubElement(measure_node, 'aggregate')\n                metric_node.text = self.aggregate\n                source_node = SubElement(measure_node, 'source')\n                source_node.text = source\n                value_node = SubElement(measure_node, 'value')\n                value_node.text = value\n\n        rough_string = ElementTree.tostring(document, 'utf-8')\n        reparse = minidom.parseString(rough_string)\n        output = reparse.toprettyxml(indent=\" \")\n        print(self.colorize_xml(output))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle the API response from the get_iso_date API call.", "response": "def _handle_results(self):\n        \"\"\"\n        Call back function to be implemented by the CLI.\n        \"\"\"\n\n        # Only process if we get HTTP result of 200\n        if self._api_result.status_code == requests.codes.ok:\n            if self.format == \"json\":\n                self.output_json(self._api_result.text)\n            elif self.format == \"csv\":\n                self.output_csv(self._api_result.text)\n            elif self.format == \"raw\":\n                self.output_raw(self._api_result.text)\n            elif self.format == \"xml\":\n                self.output_xml(self._api_result.text)\n        else:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef trimmed_pred_default(node, parent):\n  return isinstance(node, ParseNode) and (node.is_empty or node.is_type(ParseNodeType.terminal))", "response": "The default predicate used in Node. trimmed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pprint(root, depth=0, space_unit=\"    \", *, source_len=0, file=None):\n  spacing = space_unit * depth\n\n  if isinstance(root, str):\n    print(\"{0}terminal@(?): {1}\".format(spacing, root), file=file)\n  else:\n    if root.position is None:\n      position = -1\n    elif root.position < 0:\n      position = source_len + root.position\n    else:\n      position = root.position\n\n    if root.is_value:\n      print(\"{0}{1}@({2}:{3}):\\t{4}\".format(spacing, root.node_type, position, root.consumed, root.svalue), file=file)\n    else:\n      print(\"{0}{1}@({2}:{3}):\".format(spacing, root.node_type, position, root.consumed), file=file)\n      for child in root.children:\n        pprint(child, depth + 1, source_len=source_len, file=file)", "response": "Pretting print a parse tree."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a partial of _get_repetition that accepts only a text argument.", "response": "def zero_or_more(extractor, *, ignore_whitespace=False):\n  \"\"\"Returns a partial of _get_repetition with bounds set to (0, None) that accepts only a text\n  argument.\n  \"\"\"\n  return partial(_get_repetition, extractor, bounds=(0, None), ignore_whitespace=ignore_whitespace)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef one_or_more(extractor, *, ignore_whitespace=False):\n  return partial(_get_repetition, extractor, bounds=(1, None), ignore_whitespace=ignore_whitespace)", "response": "Returns a partial of _get_repetition that accepts only a text\n argument."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef repeated(extractor, times, *, ignore_whitespace=False):\n  return partial(_get_repetition,\n                 extractor,\n                 bounds=(times, times),\n                 ignore_whitespace=ignore_whitespace)", "response": "Returns a partial of _get_repetition that accepts only a text\n argument."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a partial of _get_repetition that accepts only a text argument.", "response": "def repetition(extractor, bounds, *, ignore_whitespace=False):\n  \"\"\"Returns a partial of _get_repetition that accepts only a text argument.\"\"\"\n  return partial(_get_repetition, extractor, bounds=bounds, ignore_whitespace=ignore_whitespace)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_terminal(value, text):\n  if text and text.startswith(value):\n    return ParseNode(ParseNodeType.terminal,\n                      children=[value],\n                      consumed=len(value),\n                      position=-len(text))\n  else:\n    raise DeadEnd()", "response": "Checks the beginning of text for a value and returns a terminal ParseNode."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a concatenation of the text.", "response": "def _get_concatenation(extractors, text, *, ignore_whitespace=True):\n  \"\"\"Returns a concatenation ParseNode whose children are the nodes returned by each of the\n  methods in the extractors enumerable.\n\n  If ignore_whitespace is True, whitespace will be ignored and then attached to the child it\n  preceeded.\n  \"\"\"\n  ignored_ws, use_text = _split_ignored(text, ignore_whitespace)\n\n  extractor, *remaining = extractors\n\n  child = _call_extractor(extractor, use_text)\n  child.add_ignored(ignored_ws)\n\n  # TODO: Should I set node.position = -len(text) for the case that ignored whitespace will cause\n  #       the first child's position to not be the whitespace, and therefore the concatenation's\n  #       position will be the first non-whitespace? I think not, but I'm adding this note in\n  #       case that causes an issue I'm not seeing at the moment.\n  node = ParseNode(ParseNodeType.concatenation, children=[child])\n\n  if remaining:\n    # child.consumed will include ignored whitespace, so we base the text we pass on on text rather\n    # than use_text.\n    return node.merged(_get_concatenation(remaining,\n                                          text[child.consumed:],\n                                          ignore_whitespace=ignore_whitespace))\n  else:\n    return node"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries each extractor on the given text and returns the alternative.", "response": "def _get_alternation(extractors, text):\n  \"\"\"Tries each extractor on the given text and returns the 'best fit'.\n\n  Best fit is defined by as the extractor whose result consumed the most text. If more than one\n  extractor is the best fit, the result of the one that appeared earliest in the list is returned.\n\n  If all extractors raise a DeadEnd, this method too will raise a DeadEnd.\n  \"\"\"\n  candidates = []\n\n  for extractor in extractors:\n    try:\n      candidates.append(_call_extractor(extractor, text))\n    except DeadEnd:\n      pass\n\n  if not candidates:\n    raise DeadEnd\n\n  result, *remaining = candidates\n\n  for candidate in remaining:\n    if len(candidate) > len(result):\n      result = candidate\n\n  return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_repetition(extractor, text, *, bounds=(0, None), ignore_whitespace=False):\n  minr, maxr = bounds\n  children = []\n\n  while maxr is None or len(children) <= maxr:\n    ignored_ws, use_text = _split_ignored(text, ignore_whitespace)\n    try:\n      child = _call_extractor(extractor, use_text)\n      child.add_ignored(ignored_ws)\n    except DeadEnd:\n      break\n\n    if child.is_empty:\n      break\n\n    children.append(child)\n    text = text[child.consumed:]\n\n\n  if len(children) >= minr:\n    return ParseNode(ParseNodeType.repetition,\n                      children=children)\n  else:\n    raise DeadEnd()", "response": "Tries to pull a text node from the text until it raises DeadEnd."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning extractor s result if exclusion does not match.", "response": "def _get_exclusion(extractor, exclusion, text):\n  \"\"\"Returns extractor's result if exclusion does not match.\n\n  If exclusion raises DeadEnd (meaning it did not match) then the result of extractor(text) is\n  returned. Otherwise, if exclusion does not raise DeadEnd it means it did match, and we then\n  raise DeadEnd.\n  \"\"\"\n  try:\n    _call_extractor(exclusion, text)\n    exclusion_matches = True\n  except DeadEnd:\n    exclusion_matches = False\n\n  if exclusion_matches:\n    raise DeadEnd()\n  else:\n    return _call_extractor(extractor, text)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _split_ignored(text, ignore_whitespace=True):\n  if ignore_whitespace:\n    leading_ws_count = _count_leading_whitespace(text)\n    ignored_ws = text[:leading_ws_count]\n    use_text = text[leading_ws_count:]\n    return (ignored_ws, use_text)\n  else:\n    return (\"\", text)", "response": "Split text into leading whitespace and trailing text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _count_leading_whitespace(text):\n  idx = 0\n  for idx, char in enumerate(text):\n    if not char.isspace():\n      return idx\n  return idx + 1", "response": "Returns the number of characters at the beginning of text that are whitespace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the position of the text the ParseNode processed.", "response": "def position(self):\n    \"\"\"Gets the position of the text the ParseNode processed. If the ParseNode does not have its\n    own position, it looks to its first child for its position.\n\n    'Value Nodes' (terminals) must have their own position, otherwise this method will throw an\n    exception when it tries to get the position property of the string child.\n    \"\"\"\n    pos = self._position\n    if pos is None and self.children:\n      ch1 = self.children[0]\n      if isinstance(ch1, ParseNode):\n        pos = ch1.position\n    return pos"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_empty(self):\n    return all(isinstance(c, ParseNode) and c.is_empty for c in self.children)", "response": "Returns True if this node has no children or all of its children are empty."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_ignored(self, ignored):\n    if ignored:\n      if self.ignored:\n        self.ignored = ignored + self.ignored\n      else:\n        self.ignored = ignored\n\n    self.consumed += len(ignored)", "response": "Add ignored text to the node."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if node_type == value.", "response": "def is_type(self, value):\n    \"\"\"Returns True if node_type == value.\n\n    If value is a tuple, node_type is checked against each member and True is returned if any of\n    them match.\n    \"\"\"\n    if isinstance(value, tuple):\n      for opt in value:\n        if self.node_type == opt:\n          return True\n      return False\n    else:\n      return self.node_type == value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef flattened(self, pred=flattened_pred_default):\n    if self.is_value:\n      return self\n\n    new_children = []\n\n    for child in self.children:\n      if child.is_empty:\n        continue\n\n      new_child = child.flattened(pred)\n\n      if pred(new_child, self):\n        new_children.extend(new_child.children)\n      else:\n        new_children.append(new_child)\n\n    return ParseNode(self.node_type,\n                     children=new_children,\n                     consumed=self.consumed,\n                     position=self.position,\n                     ignored=self.ignored)", "response": "Flattens nodes by hoisting children up to ancestor nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntrims a ParseTree. A node is trimmed if pred returns True.", "response": "def trimmed(self, pred=trimmed_pred_default):\n    \"\"\"Trim a ParseTree.\n\n    A node is trimmed if pred(node) returns True.\n    \"\"\"\n    new_children = []\n\n    for child in self.children:\n      if isinstance(child, ParseNode):\n        new_child = child.trimmed(pred)\n      else:\n        new_child = child\n\n      if not pred(new_child, self):\n        new_children.append(new_child)\n\n    return ParseNode(self.node_type,\n                     children=new_children,\n                     consumed=self.consumed,\n                     position=self.position,\n                     ignored=self.ignored)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merged(self, other):\n    children = [c for c in itertools.chain(self.children, other.children) if len(c) > 0]\n    # NOTE: Only terminals should have ignored text attached to them, and terminals shouldn't be\n    #       merged (probably) so it shouldn't be necessary to copy of ignored -- it should always\n    #       be None. But, we'll go ahead and copy it over anyway, recognizing that other's\n    #       ignored text will be lost.\n    return ParseNode(self.node_type,\n                      children=children,\n                      consumed=self.consumed + other.consumed,\n                      ignored=self.ignored)", "response": "Returns a new ParseNode whose type is this node s type and whose children are all the the\n    children from this node and the other whose length is not 0."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef retyped(self, new_type):\n    return ParseNode(new_type,\n                      children=list(self.children),\n                      consumed=self.consumed,\n                      position=self.position,\n                      ignored=self.ignored)", "response": "Returns a new node with the same contents as self but with a new node_type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compressed(self, new_type=None, *, include_ignored=False):\n    values = []\n    consumed = 0\n    ignored = None\n\n    for i, child in enumerate(self.children):\n      consumed += child.consumed\n      if i == 0 and not include_ignored:\n        ignored = child.ignored\n      if child.is_value:\n        if include_ignored:\n          values.append(\"{0}{1}\".format(child.ignored or \"\", child.value))\n        else:\n          values.append(child.value)\n      else:\n        values.append(child.compressed(include_ignored=include_ignored).value)\n\n    return ParseNode(new_type or self.node_type,\n                      children=[\"\".join(values)],\n                      consumed=consumed,\n                      ignored=ignored,\n                      position=self.position)", "response": "Turns the node into a value node whose single string child is the concatenation of all its\n    children."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract the specific arguments of this CLI", "response": "def get_arguments(self):\n        \"\"\"\n        Extracts the specific arguments of this CLI\n        \"\"\"\n        ApiCli.get_arguments(self)\n\n        # Get the host group name\n        if self.args.host_group_name is not None:\n            self.host_group_name = self.args.host_group_name\n\n        # Get the list of sources separated by commas\n        if self.args.sources is not None:\n            self.sources = self.args.sources\n\n        payload = {}\n        if self.host_group_name is not None:\n            payload['name'] = self.host_group_name\n\n        if self.sources is not None:\n            source_list = str.split(self.sources, ',')\n            if 'hostnames' not in payload:\n                payload['hostnames'] = []\n\n            for s in source_list:\n                payload['hostnames'].append(s)\n        self.data = json.dumps(payload, sort_keys=True)\n        self.headers = {'Content-Type': 'application/json', \"Accept\": \"application/json\"}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_scope_list(self) -> list:\n        # by default only return scoped name\n        lstparent = [self]\n        p = self.get_parent()\n        while p is not None:\n            lstparent.append(p)\n            p = p.get_parent()\n        return lstparent", "response": "Return the list of all contained scope from global to local"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the list of all contained scope names from global to local", "response": "def get_scope_names(self) -> list:\n        \"\"\"\n        Return the list of all contained scope from global to local\n        \"\"\"\n        # allow global scope to have an None string instance\n        lscope = []\n        for scope in reversed(self.get_scope_list()):\n            if scope.name is not None:\n                # handle fun/block scope decoration\n                lscope.append(scope.name)\n        return lscope"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef position(self) -> Position:\n        return Position(self._index, self._lineno, self._col_offset)", "response": "The current position of the cursor."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef step_next_char(self):\n        self._index += 1\n        self._col_offset += 1\n        if self._index > self._maxindex:\n            self._maxindex = self._index\n            self._maxcol = self._col_offset\n            self._maxline = self._lineno", "response": "Puts the cursor on the next character."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting cursor as beginning of next line.", "response": "def step_next_line(self):\n        \"\"\"Sets cursor as beginning of next line.\"\"\"\n        self._eol.append(self.position)\n        self._lineno += 1\n        self._col_offset = 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef step_prev_line(self):\n        #TODO(bps): raise explicit error for unregistered eol\n        #assert self._eol[-1].index == self._index\n        if len(self._eol) > 0:\n            self.position = self._eol.pop()", "response": "Sets cursor as end of previous line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef last_readed_line(self) -> str:\n        mpos = self._cursor.max_readed_position\n        mindex = mpos.index\n        # search last \\n\n        prevline = mindex - 1 if mindex == self.eos_index else mindex\n        while prevline >= 0 and self._content[prevline] != '\\n':\n            prevline -= 1\n        # search next \\n\n        nextline = mindex\n        while nextline < self.eos_index and self._content[nextline] != '\\n':\n            nextline += 1\n        last_line = self._content[prevline + 1:nextline]\n        return last_line", "response": "Usefull string to compute error message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef incpos(self, length: int=1) -> int:\n        if length < 0:\n            raise ValueError(\"length must be positive\")\n        i = 0\n        while (i < length):\n            if self._cursor.index < self._len:\n                if self.peek_char == '\\n':\n                    self._cursor.step_next_line()\n                self._cursor.step_next_char()\n            i += 1\n        return self._cursor.index", "response": "Increment the cursor to the next character."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_fmt(self) -> fmt.indentable:\n    qual = \"scope\"\n    txt = fmt.sep(\" \", [qual])\n    name = self.show_name()\n    if name != \"\":\n        txt.lsdata.append(name)\n    if len(self._hsig) > 0 or len(self.mapTypeTranslate) > 0:\n        lsb = []\n        if len(self.mapTypeTranslate) > 0:\n            lsb.append(\"translate:\\n\")\n            lsb.append(fmt.end(\"\\n\", self.mapTypeTranslate.to_fmt()))\n        for k in sorted(self._hsig.keys()):\n            s = self._hsig[k]\n            lsb.append(fmt.end(\"\\n\", [s.to_fmt()]))\n        block = fmt.block(\":\\n\", \"\", fmt.tab(lsb))\n        txt.lsdata.append(block)\n    return txt", "response": "Return an Fmt representation for pretty - printing."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_fmt(self):\n    qual = \"evalctx\"\n    lseval = []\n    block = fmt.block(\":\\n\", \"\", fmt.tab(lseval))\n    txt = fmt.sep(\" \", [qual, block])\n    lseval.append(self._sig.to_fmt())\n    if len(self.resolution) > 0:\n        lsb = []\n        for k in sorted(self.resolution.keys()):\n            s = self.resolution[k]\n            if s is not None:\n                lsb.append(\n                    fmt.end(\n                        \"\\n\",\n                        [\"'%s': %s (%s)\" % (k, s, s().show_name())]\n                    )\n                )\n            else:\n                lsb.append(fmt.end(\"\\n\", [\"'%s': Unresolved\" % (k)]))\n        if self._translate_to is not None:\n            lsb.append(\"use translator:\")\n            lsb.append(self._translate_to.to_fmt())\n        if self._variadic_types is not None:\n            lsb.append(\"variadic types:\\n\")\n            arity = self._sig.arity\n            for t in self._variadic_types:\n                lsb.append(\"[%d] : %s\\n\" % (arity, t))\n                arity += 1\n        lseval.append(fmt.block(\"\\nresolution :\\n\", \"\", fmt.tab(lsb)))\n    return txt", "response": "Return an Fmt representation for pretty - printing the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a Fmt representation of this object for pretty - printing.", "response": "def to_fmt(self, with_from=False) -> fmt.indentable:\n    \"\"\"\n    Return a Fmt representation of Translator for pretty-printing\n    \"\"\"\n    txt = fmt.sep(\"\\n\", [\n        fmt.sep(\n            \" \",\n            [\n                self._type_source,\n                \"to\",\n                self._type_target,\n                '=',\n                self._fun.to_fmt()\n            ]\n        ),\n        self._notify.get_content(with_from)\n    ])\n    return txt"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_fmt(self):\n    params = \"\"\n    txt = fmt.sep(\" \", ['val'])\n    name = self.show_name()\n    if name != \"\":\n        txt.lsdata.append(name)\n    txt.lsdata.append('(%s)' % self.value)\n    txt.lsdata.append(': ' + self.tret)\n    return txt", "response": "Returns an Fmt representation for pretty - printing"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_fmt(self):\n    params = \"\"\n    txt = fmt.sep(\" \", ['fun'])\n    name = self.show_name()\n    if name != \"\":\n        txt.lsdata.append(name)\n    tparams = []\n    if self.tparams is not None:\n        tparams = list(self.tparams)\n    if self.variadic:\n        tparams.append('...')\n    params = '(' + \", \".join(tparams) + ')'\n    txt.lsdata.append(': ' + params)\n    txt.lsdata.append('-> ' + self.tret)\n    return txt", "response": "Returns an Fmt representation for pretty - printing the log entry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef walk(self, lc: state.LivingContext, user_data=None, parent=None):\n    global _cacheid\n    # root node autorefence\n    if parent is None:\n        parent = self\n    ## walk attributes\n    if hasattr(self, '__dict__') and not isinstance(self, node.ListNode):\n        for k in sorted(vars(self).keys()):\n            print(\"RECURS key %s ID %d\" % (k, id(getattr(self, k))))\n            walk(getattr(self, k), lc, user_data, self)\n            # k == ?\n            #print('test attr .%s' % k)\n            lc.checkAttr(k, self)\n            # check precond\n            lc.checkEventExpr()\n            # do sub Event (for unstrict mode)\n            lc.doSubEvent()\n    # ...as dict, walk values, match keys\n    if hasattr(self, 'keys'):\n        for k in sorted(self.keys()):\n            #print(\"RECURS ID %d\" % id(self[k]))\n            walk(self[k], lc, user_data, self)\n            # k == ?\n            #print('test key [%s]' % repr(k))\n            lc.checkKey(k, self)\n            # check precond\n            lc.checkEventExpr()\n            # do sub Event (for unstrict mode)\n            lc.doSubEvent()\n    # ...as list, walk values, match indices\n    elif not isinstance(self, str) and hasattr(self, '__iter__'):\n        idx = 0\n        for i in self:\n            #print(\"RECURS ID %d\" % id(i))\n            walk(i, lc, user_data, self)\n            # idx == ?\n            #print('test indice [%s]' % str(idx))\n            lc.checkIndice(idx, self)\n            idx += 1\n            # check precond\n            lc.checkEventExpr()\n            # do sub Event (for unstrict mode)\n            lc.doSubEvent()\n    # ...type or value\n    # type(self) == ?\n    #print(\"test type %s\" % type(self))\n    lc.checkType(type(self), self, parent)\n    # self == ?\n    #print(\"test value %s\" % str(self))\n    lc.checkValue(self)\n    ## Check EVENTS\n    # TODO: what if the event do something\n    # but don't change current state and default change it!!!\n    lc.checkEventExpr()\n    #print(\"RESULT\")\n    # check Event\n    lc.doResultEvent()\n    # check Hook\n    lc.doResultHook(self, user_data, parent)\n    # no transition, fallback to default\n    lc.doDefault()\n    # maintain the pool of LivingState\n    lc.resetLivingState()", "response": "Walks the object and returns the tree of nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_name(self, name: str):\n        self.name = name\n        # update internal names\n        lsig = self._hsig.values()\n        self._hsig = {}\n        for s in lsig:\n            self._hsig[s.internal_name()] = s", "response": "Set the name of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncounting the number of types in the database.", "response": "def count_types(self) -> int:\n        \"\"\" Count subtypes \"\"\"\n        n = 0\n        for s in self._hsig.values():\n            if type(s).__name__ == 'Type':\n                n += 1\n        return n"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncounts the number of variables defined by this scope.", "response": "def count_vars(self) -> int:\n        \"\"\" Count var define by this scope \"\"\"\n        n = 0\n        for s in self._hsig.values():\n            if hasattr(s, 'is_var') and s.is_var:\n                n += 1\n        return n"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncounting the number of functions defined by this scope.", "response": "def count_funs(self) -> int:\n        \"\"\" Count function define by this scope \"\"\"\n        n = 0\n        for s in self._hsig.values():\n            if hasattr(s, 'is_fun') and s.is_fun:\n                n += 1\n        return n"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the set with values of another Set", "response": "def update(self, sig: list or Scope) -> Scope:\n        \"\"\" Update the Set with values of another Set \"\"\"\n        values = sig\n        if hasattr(sig, 'values'):\n            values = sig.values()\n        for s in values:\n            if self.is_namespace:\n                s.set_parent(self)\n            if isinstance(s, Scope):\n                s.state = StateScope.EMBEDDED\n            self._hsig[s.internal_name()] = s\n        self.__update_count()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new set produce by the union of two sets.", "response": "def union(self, sig: Scope) -> Scope:\n        \"\"\" Create a new Set produce by the union of 2 Set \"\"\"\n        new = Scope(sig=self._hsig.values(), state=self.state)\n        new |= sig\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating this set with common values of another set.", "response": "def intersection_update(self, oset: Scope) -> Scope:\n        \"\"\" Update Set with common values of another Set \"\"\"\n        keys = list(self._hsig.keys())\n        for k in keys:\n            if k not in oset:\n                del self._hsig[k]\n            else:\n                self._hsig[k] = oset.get(k)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new set produce by the intersection of two sets", "response": "def intersection(self, sig: Scope) -> Scope:\n        \"\"\" Create a new Set produce by the intersection of 2 Set \"\"\"\n        new = Scope(sig=self._hsig.values(), state=self.state)\n        new &= sig\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef difference_update(self, oset: Scope) -> Scope:\n        keys = list(self._hsig.keys())\n        for k in keys:\n            if k in oset:\n                del self._hsig[k]\n        return self", "response": "Remove values common with another Set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef difference(self, sig: Scope) -> Scope:\n        new = Scope(sig=self._hsig.values(), state=self.state)\n        new -= sig\n        return new", "response": "Create a new Set produce by a Set subtracted by another Set"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the set with the common values from another Set and remove common values from self and update specific values from oset.", "response": "def symmetric_difference_update(self, oset: Scope) -> Scope:\n        \"\"\" Remove common values\n            and Update specific values from another Set\n        \"\"\"\n        skey = set()\n        keys = list(self._hsig.keys())\n        for k in keys:\n            if k in oset:\n                skey.add(k)\n        for k in oset._hsig.keys():\n            if k not in skey:\n                self._hsig[k] = oset.get(k)\n        for k in skey:\n            del self._hsig[k]\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef symmetric_difference(self, sig: Scope) -> Scope:\n        new = Scope(sig=self._hsig.values(), state=self.state)\n        new ^= sig\n        return new", "response": "Create a new set with values present in only one set"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a signature to the set.", "response": "def add(self, it: Signature) -> bool:\n        \"\"\" Add it to the Set \"\"\"\n        if isinstance(it, Scope):\n            it.state = StateScope.EMBEDDED\n        txt = it.internal_name()\n        it.set_parent(self)\n        if self.is_namespace:\n            txt = it.internal_name()\n        if txt == \"\":\n            txt = '_' + str(len(self._hsig))\n        if txt in self._hsig:\n            raise KeyError(\"Already exists %s\" % txt)\n        self._hsig[txt] = it\n        self.__update_count()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove(self, it: Signature) -> bool:\n        txt = it.internal_name()\n        if txt not in self._hsig:\n            raise KeyError(it.show_name() + ' not in Set')\n        sig = self._hsig[txt]\n        if isinstance(sig, Scope):\n            sig.state = StateScope.LINKED\n        del self._hsig[txt]\n        return True", "response": "Remove it but raise KeyError if not found"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving it only if it is present", "response": "def discard(self, it: Signature) -> bool:\n        \"\"\" Remove it only if present \"\"\"\n        txt = it.internal_name()\n        if txt in self._hsig:\n            sig = self._hsig[txt]\n            if isinstance(sig, Scope):\n                sig.state = StateScope.LINKED\n            del self._hsig[txt]\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef values(self) -> [Signature]:\n        if self.state == StateScope.EMBEDDED and self.parent is not None:\n            return list(self._hsig.values()) + list(self.parent().values())\n        else:\n            return self._hsig.values()", "response": "Retrieve all values of this signature."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the first Signature in the set ordered by mangling descendant", "response": "def first(self) -> Signature:\n        \"\"\" Retrieve the first Signature ordered by mangling descendant \"\"\"\n        k = sorted(self._hsig.keys())\n        return self._hsig[k[0]]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the last signature in the set", "response": "def last(self) -> Signature:\n        \"\"\" Retrieve the last Signature ordered by mangling descendant \"\"\"\n        k = sorted(self._hsig.keys())\n        return self._hsig[k[-1]]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a signature instance by its internal_name", "response": "def get(self, key: str, default=None) -> Signature:\n        \"\"\" Get a signature instance by its internal_name \"\"\"\n        item = default\n        if key in self._hsig:\n            item = self._hsig[key]\n        return item"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_by_symbol_name(self, name: str) -> Scope:\n        lst = []\n        for s in self.values():\n            if s.name == name:\n                # create an EvalCtx only when necessary\n                lst.append(EvalCtx.from_sig(s))\n        # include parent\n        # TODO: see all case of local redefinition for\n        #       global overloads\n        # possible algos... take all with different internal_name\n        if len(lst) == 0:\n            p = self.get_parent()\n            if p is not None:\n                return p.get_by_symbol_name(name)\n        rscope = Scope(sig=lst, state=StateScope.LINKED, is_namespace=False)\n        # inherit type/translation from parent\n        rscope.set_parent(self)\n        return rscope", "response": "Retrieve a Scope object by symbol name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getsig_by_symbol_name(self, name: str) -> Signature:\n        subscope = self.get_by_symbol_name(name)\n        if len(subscope) != 1:\n            raise KeyError(\"%s have multiple candidates in scope\" % name)\n        v = list(subscope.values())\n        return v[0]", "response": "Retrieve the unique Signature for a symbol name. Fails if there are multiple signatures in the scope."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve a Scope of all signatures by return type.", "response": "def get_by_return_type(self, tname: str) -> Scope:\n        \"\"\" Retrieve a Set of all signature by (return) type \"\"\"\n        lst = []\n        for s in self.values():\n            if hasattr(s, 'tret') and s.tret == tname:\n                lst.append(EvalCtx.from_sig(s))\n        rscope = Scope(sig=lst, state=StateScope.LINKED, is_namespace=False)\n        # inherit type/translation from parent\n        rscope.set_parent(self)\n        return rscope"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all_polymorphic_return(self) -> bool:\n        lst = []\n        for s in self.values():\n            if hasattr(s, 'tret') and s.tret.is_polymorphic:\n                # encapsulate s into a EvalCtx for meta-var resolution\n                lst.append(EvalCtx.from_sig(s))\n        rscope = Scope(sig=lst, state=StateScope.LINKED, is_namespace=False)\n        # inherit type/translation from parent\n        rscope.set_parent(self)\n        return rscope", "response": "Returns a Scope that contains all polymorphic return types."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving a set of all signature that match the parameter list.", "response": "def get_by_params(self, params: [Scope]) -> (Scope, [[Scope]]):\n        \"\"\" Retrieve a Set of all signature that match the parameter list.\n        Return a pair:\n\n            pair[0] the overloads for the functions\n            pair[1] the overloads for the parameters\n                (a list of candidate list of parameters)\n        \"\"\"\n        lst = []\n        scopep = []\n        # for each of our signatures\n        for s in self.values():\n            # for each params of this signature\n            if hasattr(s, 'tparams'):\n                # number of matched params\n                mcnt = 0\n                # temporary collect\n                nbparam_sig = (0 if s.tparams is None else len(s.tparams))\n                nbparam_candidates = len(params)\n                # don't treat signature too short\n                if nbparam_sig > nbparam_candidates:\n                    continue\n                # don't treat call signature too long if not variadic\n                if nbparam_candidates > nbparam_sig and not s.variadic:\n                    continue\n                tmp = [None] * nbparam_candidates\n                variadic_types = []\n                for i in range(nbparam_candidates):\n                    tmp[i] = Scope(state=StateScope.LINKED)\n                    tmp[i].set_parent(self)\n                    # match param of the expr\n                    if i < nbparam_sig:\n                        if params[i].state == StateScope.EMBEDDED:\n                            raise ValueError(\n                                (\"params[%d] of get_by_params is a StateScope.\"\n                                 + \"EMBEDDED scope... \"\n                                 + \"read the doc and try a StateScope.FREE\"\n                                 + \" or StateScope.LINKED.\") % i\n                            )\n                        m = params[i].get_by_return_type(s.tparams[i])\n                        if len(m) > 0:\n                            mcnt += 1\n                            tmp[i].update(m)\n                        else:\n                            # co/contra-variance\n                            # we just need to search a t1->t2\n                            # and add it into the tree (with/without warnings)\n                            t1 = params[i]\n                            t2 = s.tparams[i]\n                            # if exist a fun (t1) -> t2\n                            (is_convertible,\n                             signature,\n                             translator\n                             ) = t1.findTranslationTo(t2)\n                            if is_convertible:\n                                # add a translator in the EvalCtx\n                                signature.use_translator(translator)\n                                mcnt += 1\n                                nscope = Scope(\n                                    sig=[signature],\n                                    state=StateScope.LINKED,\n                                    is_namespace=False\n                                    )\n                                nscope.set_parent(self)\n                                tmp[i].update(nscope)\n                            elif s.tparams[i].is_polymorphic:\n                                # handle polymorphic parameter\n                                mcnt += 1\n                                if not isinstance(params[i], Scope):\n                                    raise Exception(\n                                        \"params[%d] must be a Scope\" % i\n                                    )\n                                tmp[i].update(params[i])\n                            else:\n                                # handle polymorphic return type\n                                m = params[i].get_all_polymorphic_return()\n                                if len(m) > 0:\n                                    mcnt += 1\n                                    tmp[i].update(m)\n                    # for variadic extra parameters\n                    else:\n                        mcnt += 1\n                        if not isinstance(params[i], Scope):\n                            raise Exception(\"params[%d] must be a Scope\" % i)\n                        variadic_types.append(params[i].first().tret)\n                        tmp[i].update(params[i])\n                # we have match all candidates\n                if mcnt == len(params):\n                    # select this signature but\n                    # box it (with EvalCtx) for type resolution\n                    lst.append(EvalCtx.from_sig(s))\n                    lastentry = lst[-1]\n                    if lastentry.variadic:\n                        lastentry.use_variadic_types(variadic_types)\n                    scopep.append(tmp)\n        rscope = Scope(sig=lst, state=StateScope.LINKED, is_namespace=False)\n        # inherit type/translation from parent\n        rscope.set_parent(self)\n        return (rscope, scopep)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef callInjector(self, old: Node, trans: Translator) -> Node:\n        if self.astTranslatorInjector is None:\n            if self.parent is not None:\n                # TODO: think if we forward for all StateScope\n                # forward to parent scope\n                return self.parent().callInjector(old, trans)\n            else:\n                raise TypeError(\"Must define an Translator Injector\")\n        return self.astTranslatorInjector(old, trans)", "response": "Call the injector from the parent if it has one."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef findTranslationTo(self, t2: str) -> (bool, Signature, Translator):\n        if not t2.is_polymorphic:\n            collect = []\n            for s in self.values():\n                t1 = s.tret\n                if t1.is_polymorphic:\n                    continue\n                if (s.tret in self.mapTypeTranslate):\n                    if (t2 in self.mapTypeTranslate[t1]):\n                        collect.append((\n                            True,\n                            s,\n                            self.mapTypeTranslate[t1][t2]\n                        ))\n            # if len > 1 too many candidates\n            if len(collect) == 1:\n                return collect[0]\n        return (False, None, None)", "response": "Find an arrow that can translate something to t2"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalize(ast: Node) -> Node:\n    res = ast\n    typemap = {DictNode, ListNode, TupleNode}\n    if type(ast) is dict:\n        res = DictNode(ast)\n    elif type(ast) is list:\n        res = ListNode(ast)\n    elif type(ast) is tuple:\n        res = TupleNode(ast)\n    # in-depth change\n    if hasattr(res, 'items'):\n        for k, v in res.items():\n            res[k] = normalize(v)\n    elif hasattr(res, '__getitem__'):\n        for idx, v in zip(range(len(res)), res):\n            res[idx] = normalize(v)\n    if type(res) not in typemap and hasattr(res, '__dict__'):\n        subattr = vars(res)\n        for k, v in subattr.items():\n            setattr(res, k, normalize(v))\n    return res", "response": "Normalize an AST nodes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check(self, ndict: dict, info=\"\") -> bool:\n        def iscycle(thing, ndict: dict, info: str) -> bool:\n            # check if not already here\n            idthing = id(thing)\n            ndict[info] = idthing\n            if idthing not in ndict:\n                # add myself\n                ndict[idthing] = \"%s:%s no cycle\" % (type(thing), info)\n                return False\n            else:\n                ndict[idthing] += \"\\n%s:%s cycle\" % (type(thing), info)\n                return True\n\n        def recurs(thing, ndict: dict, info: str) -> bool:\n            if not iscycle(thing, ndict, info):\n                res = False\n                if isinstance(thing, list):\n                    idx = 0\n                    for i in thing:\n                        res |= recurs(i, ndict, \"%s[%d]\" % (info, idx))\n                        idx += 1\n                elif isinstance(thing, Node):\n                    res |= thing.check(ndict, info)\n                elif isinstance(thing, dict):\n                    for k, v in thing.items():\n                        res |= recurs(v, ndict, \"%s[%s]\" % (info, k))\n                return res\n            return True\n        # add ME FIRST\n        if len(ndict) == 0:\n            ndict['self'] = id(self)\n            info = 'self'\n        if not iscycle(self, ndict, info):\n            res = False\n            if len(self) > 0:\n                if hasattr(self, 'keys'):\n                    keys = list(self.keys())\n                    for k in keys:\n                        ndict[\"[\" + repr(k) + \"]\"] = id(self[k])\n                        res |= recurs(self[k], ndict, \"%s[%s]\" % (info, k))\n            keys = list(vars(self).keys())\n            for k in keys:\n                ndict[\".\" + k] = id(getattr(self, k))\n                res |= recurs(getattr(self, k), ndict, \"%s.%s\" % (info, k))\n            return res\n        return True", "response": "Debug method help detect cycle and or other incoherence in a tree of Node objects"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nallowing to completly mutate the node into any subclasses of Node", "response": "def set(self, othernode):\n        \"\"\"allow to completly mutate the node into any subclasses of Node\"\"\"\n        self.__class__ = othernode.__class__\n        self.clean()\n        if len(othernode) > 0:\n            for k, v in othernode.items():\n                self[k] = v\n        for k, v in vars(othernode).items():\n            setattr(self, k, v)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef values(self):\n        tmp = self\n        while tmp is not None:\n            yield tmp.data\n            tmp = tmp.next", "response": "Yield the values in order."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the values in the order of the keys", "response": "def rvalues(self):\n        \"\"\" \n        in reversed order\n        \"\"\"\n        tmp = self\n        while tmp is not None:\n            yield tmp.data\n            tmp = tmp.prev"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _pixel_masked(hit, array):\n    ''' Checks whether a hit (column/row) is masked or not. Array is 2D array with boolean elements corresponding to pixles indicating whether a pixel is disabled or not.\n    '''\n    if array.shape[0] > hit[\"column\"] and array.shape[1] > hit[\"row\"]:\n        return array[hit[\"column\"], hit[\"row\"]]\n    else:\n        return False", "response": "Checks whether a hit is masked or not."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfinish the cluster based on the hits.", "response": "def _finish_cluster(hits, clusters, cluster_size, cluster_hit_indices, cluster_index, cluster_id, charge_correction, noisy_pixels, disabled_pixels):\n    ''' Set hit and cluster information of the cluster (e.g. number of hits in the cluster (cluster_size), total cluster charge (charge), ...).\n    '''\n    cluster_charge = 0\n    max_cluster_charge = -1\n    # necessary for charge weighted hit position\n    total_weighted_column = 0\n    total_weighted_row = 0\n\n    for i in range(cluster_size):\n        hit_index = cluster_hit_indices[i]\n        if hits[hit_index]['charge'] > max_cluster_charge:\n            seed_hit_index = hit_index\n            max_cluster_charge = hits[hit_index]['charge']\n        hits[hit_index]['is_seed'] = 0\n        hits[hit_index]['cluster_size'] = cluster_size\n        # include charge correction in sum\n        total_weighted_column += hits[hit_index]['column'] * (hits[hit_index]['charge'] + charge_correction)\n        total_weighted_row += hits[hit_index]['row'] * (hits[hit_index]['charge'] + charge_correction)\n        cluster_charge += hits[hit_index]['charge']\n        hits[hit_index]['cluster_ID'] = cluster_id\n\n    hits[seed_hit_index]['is_seed'] = 1\n\n    clusters[cluster_index][\"ID\"] = cluster_id\n    clusters[cluster_index][\"n_hits\"] = cluster_size\n    clusters[cluster_index][\"charge\"] = cluster_charge\n    clusters[cluster_index]['seed_column'] = hits[seed_hit_index]['column']\n    clusters[cluster_index]['seed_row'] = hits[seed_hit_index]['row']\n    # correct total charge value and calculate mean column and row\n    clusters[cluster_index]['mean_column'] = float(total_weighted_column) / (cluster_charge + cluster_size * charge_correction)\n    clusters[cluster_index]['mean_row'] = float(total_weighted_row) / (cluster_charge + cluster_size * charge_correction)\n\n    # Call end of cluster function hook\n    _end_of_cluster_function(\n        hits=hits,\n        clusters=clusters,\n        cluster_size=cluster_size,\n        cluster_hit_indices=cluster_hit_indices,\n        cluster_index=cluster_index,\n        cluster_id=cluster_id,\n        charge_correction=charge_correction,\n        noisy_pixels=noisy_pixels,\n        disabled_pixels=disabled_pixels,\n        seed_hit_index=seed_hit_index)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting hit and cluster information of the event (e.g. number of cluster in the event (n_cluster), ...).", "response": "def _finish_event(hits, clusters, start_event_hit_index, stop_event_hit_index, start_event_cluster_index, stop_event_cluster_index):\n    ''' Set hit and cluster information of the event (e.g. number of cluster in the event (n_cluster), ...).\n    '''\n    for hit_index in range(start_event_hit_index, stop_event_hit_index):\n        hits[hit_index]['n_cluster'] = stop_event_cluster_index - start_event_cluster_index\n\n    for cluster_index in range(start_event_cluster_index, stop_event_cluster_index):\n        clusters[cluster_index]['event_number'] = hits[start_event_hit_index]['event_number']\n\n    # Call end of event function hook\n    _end_of_event_function(\n        hits=hits,\n        clusters=clusters,\n        start_event_hit_index=start_event_hit_index,\n        stop_event_hit_index=stop_event_hit_index,\n        start_event_cluster_index=start_event_cluster_index,\n        stop_event_cluster_index=stop_event_cluster_index)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if given hit is withing the limits.", "response": "def _hit_ok(hit, min_hit_charge, max_hit_charge):\n    ''' Check if given hit is withing the limits.\n    '''\n    # Omit hits with charge < min_hit_charge\n    if hit['charge'] < min_hit_charge:\n        return False\n\n    # Omit hits with charge > max_hit_charge\n    if max_hit_charge != 0 and hit['charge'] > max_hit_charge:\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_1d_array(array, value, size=-1):\n    ''' Set array elemets to value for given number of elements (if size is negative number set all elements to value).\n    '''\n    if size >= 0:\n        for i in range(size):\n            array[i] = value\n    else:\n        for i in range(array.shape[0]):\n            array[i] = value", "response": "Set array elemets to value for given number of elements."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclusters hits into a new cluster.", "response": "def _cluster_hits(hits, clusters, assigned_hit_array, cluster_hit_indices, column_cluster_distance, row_cluster_distance, frame_cluster_distance, min_hit_charge, max_hit_charge, ignore_same_hits, noisy_pixels, disabled_pixels):\n    ''' Main precompiled function that loopes over the hits and clusters them\n    '''\n    total_hits = hits.shape[0]\n    if total_hits == 0:\n        return 0  # total clusters\n    max_cluster_hits = cluster_hit_indices.shape[0]\n\n    if total_hits != clusters.shape[0]:\n        raise ValueError(\"hits and clusters must be the same size\")\n\n    if total_hits != assigned_hit_array.shape[0]:\n        raise ValueError(\"hits and assigned_hit_array must be the same size\")\n\n    # Correction for charge weighting\n    # Some chips have non-zero charge for a charge value of zero, charge needs to be corrected to calculate cluster center correctly\n    if min_hit_charge == 0:\n        charge_correction = 1\n    else:\n        charge_correction = 0\n\n    # Temporary variables that are reset for each cluster or event\n    start_event_hit_index = 0\n    start_event_cluster_index = 0\n    cluster_size = 0\n    event_number = hits[0]['event_number']\n    event_cluster_index = 0\n\n    # Outer loop over all hits in the array (referred to as actual hit)\n    for i in range(total_hits):\n\n        # Check for new event and reset event variables\n        if _new_event(hits[i]['event_number'], event_number):\n            _finish_event(\n                hits=hits,\n                clusters=clusters,\n                start_event_hit_index=start_event_hit_index,\n                stop_event_hit_index=i,\n                start_event_cluster_index=start_event_cluster_index,\n                stop_event_cluster_index=start_event_cluster_index + event_cluster_index)\n\n            start_event_hit_index = i\n            start_event_cluster_index = start_event_cluster_index + event_cluster_index\n            event_number = hits[i]['event_number']\n            event_cluster_index = 0\n\n        if assigned_hit_array[i] > 0:  # Hit was already assigned to a cluster in the inner loop, thus skip actual hit\n            continue\n\n        if not _hit_ok(\n                hit=hits[i],\n                min_hit_charge=min_hit_charge,\n                max_hit_charge=max_hit_charge) or (disabled_pixels.shape[0] != 0 and _pixel_masked(hits[i], disabled_pixels)):\n            _set_hit_invalid(hit=hits[i], cluster_id=-1)\n            assigned_hit_array[i] = 1\n            continue\n\n        # Set/reset cluster variables for new cluster\n        # Reset temp array with hit indices of actual cluster for the next cluster\n        _set_1d_array(cluster_hit_indices, -1, cluster_size)\n        cluster_hit_indices[0] = i\n        assigned_hit_array[i] = 1\n        cluster_size = 1  # actual cluster has one hit so far\n\n        for j in cluster_hit_indices:  # Loop over all hits of the actual cluster; cluster_hit_indices is updated within the loop if new hit are found\n            if j < 0:  # There are no more cluster hits found\n                break\n\n            for k in range(cluster_hit_indices[0] + 1, total_hits):\n                # Stop event hits loop if new event is reached\n                if _new_event(hits[k]['event_number'], event_number):\n                    break\n\n                # Hit is already assigned to a cluster, thus skip actual hit\n                if assigned_hit_array[k] > 0:\n                    continue\n\n                if not _hit_ok(\n                        hit=hits[k],\n                        min_hit_charge=min_hit_charge,\n                        max_hit_charge=max_hit_charge) or (disabled_pixels.shape[0] != 0 and _pixel_masked(hits[k], disabled_pixels)):\n                    _set_hit_invalid(hit=hits[k], cluster_id=-1)\n                    assigned_hit_array[k] = 1\n                    continue\n\n                # Check if event hit belongs to actual hit and thus to the actual cluster\n                if _is_in_max_difference(hits[j]['column'], hits[k]['column'], column_cluster_distance) and _is_in_max_difference(hits[j]['row'], hits[k]['row'], row_cluster_distance) and _is_in_max_difference(hits[j]['frame'], hits[k]['frame'], frame_cluster_distance):\n                    if not ignore_same_hits or hits[j]['column'] != hits[k]['column'] or hits[j]['row'] != hits[k]['row']:\n                        cluster_size += 1\n                        if cluster_size > max_cluster_hits:\n                            raise IndexError('cluster_hit_indices is too small to contain all cluster hits')\n                        cluster_hit_indices[cluster_size - 1] = k\n                        assigned_hit_array[k] = 1\n\n                    else:\n                        _set_hit_invalid(hit=hits[k], cluster_id=-2)\n                        assigned_hit_array[k] = 1\n\n        # check for valid cluster and add it to the array\n        if cluster_size == 1 and noisy_pixels.shape[0] != 0 and _pixel_masked(hits[cluster_hit_indices[0]], noisy_pixels):\n            _set_hit_invalid(hit=hits[cluster_hit_indices[0]], cluster_id=-1)\n        else:\n            _finish_cluster(\n                hits=hits,\n                clusters=clusters,\n                cluster_size=cluster_size,\n                cluster_hit_indices=cluster_hit_indices,\n                cluster_index=start_event_cluster_index + event_cluster_index,\n                cluster_id=event_cluster_index,\n                charge_correction=charge_correction,\n                noisy_pixels=noisy_pixels,\n                disabled_pixels=disabled_pixels)\n            event_cluster_index += 1\n\n    # Last event is assumed to be finished at the end of the hit array, thus add info\n    _finish_event(\n        hits=hits,\n        clusters=clusters,\n        start_event_hit_index=start_event_hit_index,\n        stop_event_hit_index=total_hits,\n        start_event_cluster_index=start_event_cluster_index,\n        stop_event_cluster_index=start_event_cluster_index + event_cluster_index)\n\n    total_clusters = start_event_cluster_index + event_cluster_index\n    return total_clusters"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_compute_sig(self) -> Signature:\n        tret = []\n        tparams = []\n        for t in self.tret.components:\n            if t in self.resolution and self.resolution[t] is not None:\n                tret.append(self.resolution[t]().show_name())\n            else:\n                tret.append(t)\n        if hasattr(self, 'tparams'):\n            for p in self.tparams:\n                tp = []\n                for t in p.components:\n                    if t in self.resolution and self.resolution[t] is not None:\n                        tp.append(self.resolution[t]().show_name())\n                    else:\n                        tp.append(t)\n                tparams.append(\" \".join(tp))\n            if self.variadic:\n                if self._variadic_types is None:\n                    raise ValueError(\"Can't compute the sig \"\n                                     + \"with unresolved variadic argument\"\n                                     )\n                for p in self._variadic_types:\n                    tp = []\n                    for t in p.components:\n                        if (t in self.resolution\n                            and self.resolution[t] is not None\n                        ):\n                            tp.append(self.resolution[t]().show_name())\n                        else:\n                            tp.append(t)\n                    tparams.append(\" \".join(tp))\n        ret = Fun(self.name, \" \".join(tret), tparams)\n        # transform as-is into our internal Signature (Val, Var, whatever)\n        ret.__class__ = self._sig.__class__\n        return ret", "response": "Compute a signature using resolution!!!"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the parent of the object.", "response": "def set_parent(self, parent) -> object:\n        \"\"\"\n        When we add a parent (from Symbol), don't forget to resolve.\n        \"\"\"\n        ret = self\n        if parent is not None:\n            ret = self._sig.set_parent(parent)\n            self.resolve()\n        elif not hasattr(self, 'parent'):\n            # only if parent didn't exist yet\n            self.parent = None\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolve(self):\n        # collect types for resolution\n        t2resolv = []\n        if hasattr(self._sig, 'tret'):\n            t2resolv.append(self._sig.tret)\n        if hasattr(self._sig, 'tparams') and self._sig.tparams is not None:\n            for p in self._sig.tparams:\n                t2resolv.append(p)\n        if self._translate_to is not None:\n            t2resolv.append(self._translate_to.target)\n        if self._variadic_types is not None:\n            for t in self._variadic_types:\n                t2resolv.append(t)\n        for t in t2resolv:\n            for c in t.components:\n                if c not in self.resolution or self.resolution[c] is None:\n                    # try to find what is c\n                    parent = self.get_parent()\n                    if parent is not None:\n                        sc = parent.get_by_symbol_name(c)\n                        if len(sc) == 1:\n                            sc = list(sc.values())[0]\n                            # unwrap EvalCtx around Type\n                            if isinstance(sc, EvalCtx):\n                                sc = sc._sig\n                            rtyp = weakref.ref(sc)\n                            self.resolution[c] = rtyp\n                            continue\n                    # unresolved\n                    self.resolution[c] = None", "response": "Resolves the type of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_resolved_names(self, type_name: TypeName) -> list:\n        if not isinstance(type_name, TypeName):\n            raise Exception(\"Take a TypeName as parameter not a %s\"\n                            % type(type_name))\n        rnames = []\n        for name in type_name.components:\n            if name not in self.resolution:\n                raise Exception(\"Unknown type %s in a EvalCtx\" % name)\n            rname = self.resolution[name]\n            if rname is not None:\n                rname = rname().show_name()\n            else:\n                rname = name\n            rnames.append(rname)\n        return rnames", "response": "Get the names of all resolved types of a type name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the resolved name for the type.", "response": "def set_resolved_name(self, ref: dict, type_name2solve: TypeName,\n                          type_name_ref: TypeName):\n        \"\"\"\n        Warning!!! Need to rethink it when global poly type\n        \"\"\"\n        if self.resolution[type_name2solve.value] is None:\n            self.resolution[type_name2solve.value] = ref[type_name_ref.value]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an Fmt representation for pretty - printing the log entry.", "response": "def to_fmt(self) -> fmt.indentable:\n        \"\"\"\n        Return an Fmt representation for pretty-printing\n        \"\"\"\n        lsb = []\n        if len(self._lsig) > 0:\n            for s in self._lsig:\n                lsb.append(s.to_fmt())\n        block = fmt.block(\"(\", \")\", fmt.sep(', ', lsb))\n        qual = \"tuple\"\n        txt = fmt.sep(\"\", [qual, block])\n        return txt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the unique internal name of the object.", "response": "def internal_name(self):\n        \"\"\"\n        Return the unique internal name\n        \"\"\"\n        unq = super().internal_name()\n        if self.tret is not None:\n            unq += \"_\" + self.tret\n        return unq"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _delete_local(self, filename):\n\n        if os.path.exists(filename):\n            os.remove(filename)", "response": "Deletes the specified file from the local filesystem."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting the specified file from the given S3 bucket.", "response": "def _delete_s3(self, filename, bucket_name):\n        \"\"\"Deletes the specified file from the given S3 bucket.\"\"\"\n\n        conn = S3Connection(self.access_key_id, self.access_key_secret)\n        bucket = conn.get_bucket(bucket_name)\n\n        if type(filename).__name__ == 'Key':\n            filename = '/' + filename.name\n\n        path = self._get_s3_path(filename)\n        k = Key(bucket)\n        k.key = path\n\n        try:\n            bucket.delete_key(k)\n        except S3ResponseError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, filename, storage_type=None, bucket_name=None):\n\n        if not (storage_type and bucket_name):\n            self._delete_local(filename)\n        else:\n            if storage_type != 's3':\n                raise ValueError('Storage type \"%s\" is invalid, the only supported storage type (apart from default local storage) is s3.' % storage_type)\n\n            self._delete_s3(filename, bucket_name)", "response": "Deletes the specified file either locally or from S3 depending on the file s storage type and bucket name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving the specified file to the local file system.", "response": "def _save_local(self, temp_file, filename, obj):\n        \"\"\"Saves the specified file to the local file system.\"\"\"\n\n        path = self._get_path(filename)\n        if not os.path.exists(os.path.dirname(path)):\n            os.makedirs(os.path.dirname(path), self.permission | 0o111)\n\n        fd = open(path, 'wb')\n\n        # Thanks to:\n        # http://stackoverflow.com/a/3253276/2066849\n        temp_file.seek(0)\n        t = temp_file.read(1048576)\n        while t:\n            fd.write(t)\n            t = temp_file.read(1048576)\n\n        fd.close()\n\n        if self.filesize_field:\n            setattr(obj, self.filesize_field, os.path.getsize(path))\n\n        return filename"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the specified file to the configured S3 bucket.", "response": "def _save_s3(self, temp_file, filename, obj):\n        \"\"\"Saves the specified file to the configured S3 bucket.\"\"\"\n\n        conn = S3Connection(self.access_key_id, self.access_key_secret)\n        bucket = conn.get_bucket(self.bucket_name)\n\n        path = self._get_s3_path(filename)\n        k = bucket.new_key(path)\n        k.set_contents_from_string(temp_file.getvalue())\n        k.set_acl(self.acl)\n\n        if self.filesize_field:\n            setattr(obj, self.filesize_field, k.size)\n\n        return filename"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave the specified file to either S3 or the local filesystem depending on the currently enabled storage type.", "response": "def save(self, temp_file, filename, obj):\n        \"\"\"Saves the specified file to either S3 or the local filesystem, depending on the currently enabled storage type.\"\"\"\n\n        if not (self.storage_type and self.bucket_name):\n            ret = self._save_local(temp_file, filename, obj)\n        else:\n            if self.storage_type != 's3':\n                raise ValueError('Storage type \"%s\" is invalid, the only supported storage type (apart from default local storage) is s3.' % self.storage_type)\n\n            ret = self._save_s3(temp_file, filename, obj)\n\n        if self.field_name:\n            setattr(obj, self.field_name, ret)\n\n        if self.storage_type == 's3':\n            if self.storage_type_field:\n                setattr(obj, self.storage_type_field, self.storage_type)\n            if self.bucket_name_field:\n                setattr(obj, self.bucket_name_field, self.bucket_name)\n        else:\n            if self.storage_type_field:\n                setattr(obj, self.storage_type_field, '')\n            if self.bucket_name_field:\n                setattr(obj, self.bucket_name_field, '')\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind files by licking an S3 bucket s contents by prefix.", "response": "def _find_by_path_s3(self, path, bucket_name):\n        \"\"\"Finds files by licking an S3 bucket's contents by prefix.\"\"\"\n\n        conn = S3Connection(self.access_key_id, self.access_key_secret)\n        bucket = conn.get_bucket(bucket_name)\n\n        s3_path = self._get_s3_path(path)\n\n        return bucket.list(prefix=s3_path)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_by_path(self, path, storage_type=None, bucket_name=None):\n\n        if not (storage_type and bucket_name):\n            return self._find_by_path_local(path)\n        else:\n            if storage_type != 's3':\n                raise ValueError('Storage type \"%s\" is invalid, the only supported storage type (apart from default local storage) is s3.' % storage_type)\n\n            return self._find_by_path_s3(path, bucket_name)", "response": "Finds files at the specified path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding an enum statement from a sequence of parameters.", "response": "def enum(*sequential, **named):\n    \"\"\"\n    Build an enum statement\n    \"\"\"\n    #: build enums from parameter\n    enums = dict(zip(sequential, range(len(sequential))), **named)\n    enums['map'] = copy.copy(enums)\n    #: build reverse mapping\n    enums['rmap'] = {}\n    for key, value in enums.items():\n        if type(value) is int:\n            enums['rmap'][value] = key\n    return type('Enum', (), enums)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef checktypes(func):\n    sig = inspect.signature(func)\n\n    types = {}\n    for param in sig.parameters.values():\n        # Iterate through function's parameters and build the list of\n        # arguments types\n        param_type = param.annotation\n        if param_type is param.empty or not inspect.isclass(param_type):\n            # Missing annotation or not a type, skip it\n            continue\n\n        types[param.name] = param_type\n\n        # If the argument has a type specified, let's check that its\n        # default value (if present) conforms with the type.\n        if (param.default is not param.empty and\n                not isinstance(param.default, param_type)):\n            raise ValueError(\n                \"{func}: wrong type of a default value for {arg!r}\".format(\n                    func=func.__qualname__, arg=param.name)\n            )\n\n    def check_type(sig, arg_name, arg_type, arg_value):\n        # Internal function that encapsulates arguments type checking\n        if not isinstance(arg_value, arg_type):\n            raise ValueError(\"{func}: wrong type of {arg!r} argument, \"\n                             \"{exp!r} expected, got {got!r}\".\n                             format(func=func.__qualname__, arg=arg_name,\n                                    exp=arg_type.__name__,\n                                    got=type(arg_value).__name__))\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        # Let's bind the arguments\n        ba = sig.bind(*args, **kwargs)\n        for arg_name, arg in ba.arguments.items():\n            # And iterate through the bound arguments\n            try:\n                type_ = types[arg_name]\n            except KeyError:\n                continue\n            else:\n                # OK, we have a type for the argument, lets get the\n                # corresponding parameter description from the signature object\n                param = sig.parameters[arg_name]\n                if param.kind == param.VAR_POSITIONAL:\n                    # If this parameter is a variable-argument parameter,\n                    # then we need to check each of its values\n                    for value in arg:\n                        check_type(sig, arg_name, type_, value)\n                elif param.kind == param.VAR_KEYWORD:\n                    # If this parameter is a variable-keyword-argument\n                    # parameter:\n                    for subname, value in arg.items():\n                        check_type(sig, arg_name + ':' + subname, type_, value)\n                else:\n                    # And, finally, if this parameter a regular one:\n                    check_type(sig, arg_name, type_, arg)\n\n        result = func(*ba.args, **ba.kwargs)\n\n        # The last bit - let's check that the result is correct\n        return_type = sig.return_annotation\n        if (return_type is not sig.empty and\n                isinstance(return_type, type) and\n                not isinstance(result, return_type)):\n\n            raise ValueError(\n                '{func}: wrong return type, {exp} expected, got {got}'.format(\n                    func=func.__qualname__, exp=return_type.__name__,\n                    got=type(result).__name__)\n            )\n        return result\n\n    return wrapper", "response": "Decorator to verify arguments and return types."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_one(chainmap, thing_name, callobject):\n    namespaces = reversed(thing_name.split(\".\"))\n    lstname = []\n    for name in namespaces:\n        lstname.insert(0, name)\n        strname = '.'.join(lstname)\n        chainmap[strname] = callobject", "response": "Add a mapping with key thing_name for callobject in chainmap with namespace handling."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nattach a method to a class.", "response": "def add_method(cls):\n    \"\"\"Attach a method to a class.\"\"\"\n    def wrapper(f):\n        #if hasattr(cls, f.__name__):\n        #    raise AttributeError(\"{} already has a '{}' attribute\".format(\n        #        cls.__name__, f.__name__))\n        setattr(cls, f.__name__, f)\n        return f\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nattaching a method to a parsing class and register it as a parser hook.", "response": "def hook(cls, hookname=None, erase=False):\n    \"\"\"Attach a method to a parsing class and register it as a parser hook.\n\n       The method is registered with its name unless hookname is provided.\n    \"\"\"\n    if not hasattr(cls, '_hooks'):\n        raise TypeError(\n            \"%s didn't seems to be a BasicParser subsclasse\" % cls.__name__)\n    class_hook_list = cls._hooks\n    class_rule_list = cls._rules\n\n    def wrapper(f):\n        nonlocal hookname\n        add_method(cls)(f)\n        if hookname is None:\n            hookname = f.__name__\n        if not erase and (hookname in class_hook_list or hookname in class_rule_list):\n            raise TypeError(\"%s is already define has rule or hook\" % hookname)\n        if '.' not in hookname:\n            hookname = '.'.join([cls.__module__, cls.__name__, hookname])\n        set_one(class_hook_list, hookname, f)\n        return f\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rule(cls, rulename=None, erase=False):\n    if not hasattr(cls, '_rules'):\n        raise TypeError(\n            \"%s didn't seems to be a BasicParser subsclasse\" % cls.__name__)\n    class_hook_list = cls._hooks\n    class_rule_list = cls._rules\n\n    def wrapper(f):\n        nonlocal rulename\n        add_method(cls)(f)\n        if rulename is None:\n            rulename = f.__name__\n        if not erase and (rulename in class_hook_list or rulename in class_rule_list):\n            raise TypeError(\"%s is already define has rule or hook\" % rulename)\n        if '.' not in rulename:\n            rulename = cls.__module__ + '.' + cls.__name__ + '.' + rulename\n        set_one(class_rule_list, rulename, f)\n        return f\n    return wrapper", "response": "Attach a method to a parsing class and register it as a parser rule."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef directive(directname=None):\n    global _directives\n    class_dir_list = _directives\n\n    def wrapper(f):\n        nonlocal directname\n        if directname is None:\n            directname = f.__name__\n        f.ns_name = directname\n        set_one(class_dir_list, directname, f)\n        return f\n    return wrapper", "response": "Attach a class to a parsing class and register it as a parser directive."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decorator(directname=None):\n    global _decorators\n    class_deco_list = _decorators\n\n    def wrapper(f):\n        nonlocal directname\n        if directname is None:\n            directname = f.__name__\n        f.ns_name = directname\n        set_one(class_deco_list, directname, f)\n\n    return wrapper", "response": "A class decorator that registers a class as a parsing class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bind(self, dst: str, src: Node) -> bool:\n\n    for m in self.rule_nodes.maps:\n        for k, v in m.items():\n            if k == dst:\n                m[k] = src\n                return True\n    raise Exception('%s not found' % dst)", "response": "Bind a node to another name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_eol(self) -> bool:\n    if self.read_eof():\n        return False\n    self._stream.save_context()\n    self.read_char('\\r')\n    if self.read_char('\\n'):\n        return self._stream.validate_context()\n    return self._stream.restore_context()", "response": "Return True if the parser can consume an EOL byte sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a hexadecimal number of a user s authors.", "response": "def read_hex_integer(self) -> bool:\n    \"\"\"\n    read a hexadecimal number\n    Read the following BNF rule else return False::\n\n        readHexInteger = [\n            [ '0'..'9' | 'a'..'f' | 'A'..'F' ]+\n        ]\n    \"\"\"\n    if self.read_eof():\n        return False\n    self._stream.save_context()\n    c = self._stream.peek_char\n    if c.isdigit() or ('a' <= c.lower() and c.lower() <= 'f'):\n        self._stream.incpos()\n        while not self.read_eof():\n            c = self._stream.peek_char\n            if not (c.isdigit() or ('a' <= c.lower() and c.lower() <= 'f')):\n                break\n            self._stream.incpos()\n        return self._stream.validate_context()\n    return self._stream.restore_context()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_cstring(self) -> bool:\n    self._stream.save_context()\n    idx = self._stream.index\n    if self.read_char(\"\\\"\") and self.read_until(\"\\\"\", \"\\\\\"):\n        txt = self._stream[idx:self._stream.index]\n        return self._stream.validate_context()\n    return self._stream.restore_context()", "response": "Read a double quoted string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef push_rule_nodes(self) -> bool:\n        if self.rule_nodes is None:\n            self.rule_nodes = collections.ChainMap()\n            self.tag_cache = collections.ChainMap()\n            self.id_cache = collections.ChainMap()\n        else:\n            self.rule_nodes = self.rule_nodes.new_child()\n            self.tag_cache = self.tag_cache.new_child()\n            self.id_cache = self.id_cache.new_child()\n        return True", "response": "Push context variable to store rule nodes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pop_rule_nodes(self) -> bool:\n        self.rule_nodes = self.rule_nodes.parents\n        self.tag_cache = self.tag_cache.parents\n        self.id_cache = self.id_cache.parents\n        return True", "response": "Pop the context variable that store rule nodes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the text value of the node", "response": "def value(self, n: Node) -> str:\n        \"\"\"Return the text value of the node\"\"\"\n        id_n = id(n)\n        idcache = self.id_cache\n        if id_n not in idcache:\n            return \"\"\n        name = idcache[id_n]\n        tag_cache = self.tag_cache\n        if name not in tag_cache:\n            raise Exception(\"Incoherent tag cache\")\n        tag = tag_cache[name]\n        k = \"%d:%d\" % (tag._begin, tag._end)\n        valcache = self._streams[-1].value_cache\n        if k not in valcache:\n            valcache[k] = str(tag)\n        return valcache[k]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npushes a new Stream into the parser.", "response": "def parsed_stream(self, content: str, name: str=None):\n        \"\"\"Push a new Stream into the parser.\n        All subsequent called functions will parse this new stream,\n        until the 'popStream' function is called.\n        \"\"\"\n        self._streams.append(Stream(content, name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef begin_tag(self, name: str) -> Node:\n        # Check if we could attach tag cache to current rule_nodes scope\n        self.tag_cache[name] = Tag(self._stream, self._stream.index)\n        return True", "response": "Save the current index under the given name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting the string between saved and current index.", "response": "def end_tag(self, name: str) -> Node:\n        \"\"\"Extract the string between saved and current index.\"\"\"\n        self.tag_cache[name].set_end(self._stream.index)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmerging internal rules set with the given rules", "response": "def set_rules(cls, rules: dict) -> bool:\n        \"\"\"\n        Merge internal rules set with the given rules\n        \"\"\"\n        cls._rules = cls._rules.new_child()\n        for rule_name, rule_pt in rules.items():\n            if '.' not in rule_name:\n                rule_name = cls.__module__ \\\n                    + '.' + cls.__name__ \\\n                    + '.' + rule_name\n            meta.set_one(cls._rules, rule_name, rule_pt)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_hooks(cls, hooks: dict) -> bool:\n        cls._hooks = cls._hooks.new_child()\n        for hook_name, hook_pt in hooks.items():\n            if '.' not in hook_name:\n                hook_name = cls.__module__ \\\n                    + '.' + cls.__name__ \\\n                    + '.' + hook_name\n            meta.set_one(cls._hooks, hook_name, hook_pt)\n        return True", "response": "Merge internal hooks set with the given hooks."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_directives(cls, directives: dict) -> bool:\n        meta._directives = meta._directives.new_child()\n        for dir_name, dir_pt in directives.items():\n            meta.set_one(meta._directives, dir_name, dir_pt)\n            dir_pt.ns_name = dir_name\n        return True", "response": "Merge internal directives with the given directives."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nevaluating a rule by name.", "response": "def eval_rule(self, name: str) -> Node:\n        \"\"\"Evaluate a rule by name.\"\"\"\n        # context created by caller\n        n = Node()\n        id_n = id(n)\n        self.rule_nodes['_'] = n\n        self.id_cache[id_n] = '_'\n        # TODO: other behavior for  empty rules?\n        if name not in self.__class__._rules:\n            self.diagnostic.notify(\n                error.Severity.ERROR,\n                \"Unknown rule : %s\" % name,\n                error.LocationInfo.from_stream(self._stream, is_error=True)\n            )\n            raise self.diagnostic\n        self._lastRule = name\n        rule_to_eval = self.__class__._rules[name]\n        # TODO: add packrat cache here, same rule - same pos == same res\n        res = rule_to_eval(self)\n        if res:\n            res = self.rule_nodes['_']\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef eval_hook(self, name: str, ctx: list) -> Node:\n        if name not in self.__class__._hooks:\n            # TODO: don't always throw error, could have return True by default\n            self.diagnostic.notify(\n                error.Severity.ERROR,\n                \"Unknown hook : %s\" % name,\n                error.LocationInfo.from_stream(self._stream, is_error=True)\n            )\n            raise self.diagnostic\n        self._lastRule = '#' + name\n        res = self.__class__._hooks[name](self, *ctx)\n        if type(res) is not bool:\n            raise TypeError(\"Your hook %r didn't return a bool value\" % name)\n        return res", "response": "Evaluate the hook by its name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef peek_text(self, text: str) -> bool:\n        start = self._stream.index\n        stop = start + len(text)\n        if stop > self._stream.eos_index:\n            return False\n        return self._stream[self._stream.index:stop] == text", "response": "Same as readText but doesn t consume the stream."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef one_char(self) -> bool:\n        if self.read_eof():\n            return False\n        self._stream.incpos()\n        return True", "response": "Read one byte in stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_char(self, c: str) -> bool:\n        if self.read_eof():\n            return False\n        self._stream.save_context()\n        if c == self._stream.peek_char:\n            self._stream.incpos()\n            return self._stream.validate_context()\n        return self._stream.restore_context()", "response": "Consume the next character in the buffer and return True if it is valid False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_until(self, c: str, inhibitor='\\\\') -> bool:\n        if self.read_eof():\n            return False\n        self._stream.save_context()\n        while not self.read_eof():\n            if self.peek_char(inhibitor):\n                # Delete inhibitor and inhibited character\n                self.one_char()\n                self.one_char()\n            if self.peek_char(c):\n                self._stream.incpos()\n                return self._stream.validate_context()\n            self._stream.incpos()\n        return self._stream.restore_context()", "response": "Consume the stream until the specified character is read."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconsume all the stream. Same as EOF in BNF.", "response": "def read_until_eof(self) -> bool:\n        \"\"\"Consume all the stream. Same as EOF in BNF.\"\"\"\n        if self.read_eof():\n            return True\n        # TODO: read ALL\n        self._stream.save_context()\n        while not self.read_eof():\n            self._stream.incpos()\n        return self._stream.validate_context()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading a string of text from the stream.", "response": "def read_text(self, text: str) -> bool:\n        \"\"\"\n        Consume a strlen(text) text at current position in the stream\n        else return False.\n        Same as \"\" in BNF\n        ex : read_text(\"ls\");.\n        \"\"\"\n        if self.read_eof():\n            return False\n        self._stream.save_context()\n        if self.peek_text(text):\n            self._stream.incpos(len(text))\n            return self._stream.validate_context()\n        return self._stream.restore_context()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_range(self, begin: str, end: str) -> int:\n        if self.read_eof():\n            return False\n        c = self._stream.peek_char\n        if begin <= c <= end:\n            self._stream.incpos()\n            return True\n        return False", "response": "Read a range of the ISO - 8601 ISO - 8601 names."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the unique internal name of the class.", "response": "def internal_name(self):\n        \"\"\"\n        Return the unique internal name\n        \"\"\"\n        unq = 'f_' + super().internal_name()\n        if self.tparams is not None:\n            unq += \"_\" + \"_\".join(self.tparams)\n        if self.tret is not None:\n            unq += \"_\" + self.tret\n        return unq"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the hit fields for the clusterer.", "response": "def set_hit_fields(self, hit_fields):\n        ''' Tell the clusterizer the meaning of the field names.\n\n        The hit_fields parameter is a dict, e.g., {\"new field name\": \"standard field name\"}.\n\n        If None default mapping is set.\n\n        Example:\n        --------\n        Internally, the clusterizer uses the hit fields names \"column\"/\"row\". If the name of the hits fields are \"x\"/\"y\", call:\n        set_hit_fields(hit_fields={'x': 'column',\n                                   'y': 'row'})\n        '''\n        if not hit_fields:\n            hit_fields_mapping_inverse = {}\n            hit_fields_mapping = {}\n        else:\n            # Create also the inverse dictionary for faster lookup\n            hit_fields_mapping_inverse = dict((k, v) for k, v in hit_fields.items())\n            hit_fields_mapping = dict((v, k) for k, v in hit_fields.items())\n\n        for old_name, new_name in self._default_hit_fields_mapping.items():\n            if old_name not in hit_fields_mapping:\n                hit_fields_mapping[old_name] = new_name\n                hit_fields_mapping_inverse[new_name] = old_name\n\n        self._hit_fields_mapping = hit_fields_mapping\n        self._hit_fields_mapping_inverse = hit_fields_mapping_inverse"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the cluster fields for the current class.", "response": "def set_cluster_fields(self, cluster_fields):\n        ''' Tell the clusterizer the meaning of the field names.\n\n        The cluster_fields parameter is a dict, e.g., {\"new filed name\": \"standard field name\"}.\n        '''\n        if not cluster_fields:\n            cluster_fields_mapping_inverse = {}\n            cluster_fields_mapping = {}\n        else:\n            # Create also the inverse dictionary for faster lookup\n            cluster_fields_mapping_inverse = dict((k, v) for k, v in cluster_fields.items())\n            cluster_fields_mapping = dict((v, k) for k, v in cluster_fields.items())\n\n        for old_name, new_name in self._default_cluster_fields_mapping.items():\n            if old_name not in cluster_fields_mapping:\n                cluster_fields_mapping[old_name] = new_name\n                cluster_fields_mapping_inverse[new_name] = old_name\n\n        self._cluster_fields_mapping = cluster_fields_mapping\n        self._cluster_fields_mapping_inverse = cluster_fields_mapping_inverse"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the data type of the clustered hits array.", "response": "def set_hit_dtype(self, hit_dtype):\n        ''' Set the data type of the hits.\n\n        Fields that are not mentioned here are NOT copied into the clustered hits array.\n        Clusterizer has to know the hit data type to produce the clustered hit result with the same data types.\n\n        Parameters:\n        -----------\n        hit_dtype : numpy.dtype or equivalent\n            Defines the dtype of the hit array.\n\n        Example:\n        --------\n        hit_dtype = [(\"column\", np.uint16), (\"row\", np.uint16)], where\n        \"column\", \"row\" is the field name of the input hit array.\n        '''\n\n        if not hit_dtype:\n            hit_dtype = np.dtype([])\n        else:\n            hit_dtype = np.dtype(hit_dtype)\n        cluster_hits_descr = hit_dtype.descr\n\n        # Add default back to description\n        for dtype_name, dtype in self._default_cluster_hits_descr:\n            if self._hit_fields_mapping[dtype_name] not in hit_dtype.fields:\n                cluster_hits_descr.append((dtype_name, dtype))\n        self._cluster_hits_descr = cluster_hits_descr\n        self._init_arrays(size=0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the data type of the cluster array.", "response": "def set_cluster_dtype(self, cluster_dtype):\n        ''' Set the data type of the cluster.\n\n        Parameters:\n        -----------\n        cluster_dtype : numpy.dtype or equivalent\n            Defines the dtype of the cluster array.\n        '''\n        if not cluster_dtype:\n            cluster_dtype = np.dtype([])\n        else:\n            cluster_dtype = np.dtype(cluster_dtype)\n        cluster_descr = cluster_dtype.descr\n\n        for dtype_name, dtype in self._default_cluster_descr:\n            if self._cluster_fields_mapping[dtype_name] not in cluster_dtype.fields:\n                cluster_descr.append((dtype_name, dtype))\n\n        self._cluster_descr = cluster_descr\n        self._init_arrays(size=0)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_cluster_field(self, description):\n        ''' Adds a field or a list of fields to the cluster result array. Has to be defined as a numpy dtype entry, e.g.: ('parameter', '<i4') '''\n        if isinstance(description, list):\n            for item in description:\n                if len(item) != 2:\n                    raise TypeError(\"Description needs to be a list of 2-tuples of a string and a dtype.\")\n                self._cluster_descr.append(item)\n        else:\n            if len(description) != 2:\n                raise TypeError(\"Description needs to be a 2-tuple of a string and a dtype.\")\n            self._cluster_descr.append(description)\n        self._init_arrays(size=0)", "response": "Adds a field or a list of fields to the cluster result array."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_end_of_cluster_function(self, function):\n        ''' Adding function to module.\n        This is maybe the only way to make the clusterizer to work with multiprocessing.\n        '''\n        self.cluster_functions._end_of_cluster_function = self._jitted(function)\n        self._end_of_cluster_function = function", "response": "Adds function to module.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_end_of_event_function(self, function):\n        ''' Adding function to module.\n        This is maybe the only way to make the clusterizer to work with multiprocessing.\n        '''\n        self.cluster_functions._end_of_event_function = self._jitted(function)\n        self._end_of_event_function = function", "response": "Adds function to module.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cluster_hits(self, hits, noisy_pixels=None, disabled_pixels=None):\n        ''' Cluster given hit array.\n\n        The noisy_pixels and disabled_pixels parameters are iterables of column/row index pairs, e.g. [[column_1, row_1], [column_2, row_2], ...].\n        The noisy_pixels parameter allows for removing clusters that consist of a single noisy pixels. Clusters with 2 or more noisy pixels are not removed.\n        The disabled_pixels parameter allows for ignoring pixels.\n        '''\n        # Jitting a second time to workaround different bahavior of the installation methods on different platforms (pip install vs. python setup.py).\n        # In some circumstances, the Numba compiler can't compile functions that were pickled previously.\n        self.cluster_functions._end_of_cluster_function = self._jitted(self._end_of_cluster_function)\n        self.cluster_functions._end_of_event_function = self._jitted(self._end_of_event_function)\n\n        n_hits = hits.shape[0]  # Set n_hits to new size\n\n        if (n_hits < int(0.5 * self._cluster_hits.size)) or (n_hits > self._cluster_hits.size):\n            self._init_arrays(size=int(1.1 * n_hits))  # oversize buffer slightly to reduce allocations\n        else:\n            self._assigned_hit_array.fill(0)  # The hit indices of the actual cluster, 0 means not assigned\n            self._cluster_hit_indices.fill(-1)  # The hit indices of the actual cluster, -1 means not assigned\n\n        self._clusters.dtype.names = self._unmap_cluster_field_names(self._clusters.dtype.names)  # Reset the data fields from previous renaming\n        self._cluster_hits.dtype.names = self._unmap_hit_field_names(self._cluster_hits.dtype.names)  # Reset the data fields from previous renaming\n        self._check_struct_compatibility(hits)\n\n        # The hit info is extended by the cluster info; this is only possible by creating a new hit info array and copy data\n        for field_name in hits.dtype.fields:\n            if field_name in self._hit_fields_mapping_inverse:\n                cluster_hits_field_name = self._hit_fields_mapping_inverse[field_name]\n            else:\n                cluster_hits_field_name = field_name\n            if cluster_hits_field_name in self._cluster_hits.dtype.fields:\n                self._cluster_hits[cluster_hits_field_name][:n_hits] = hits[field_name]\n\n        noisy_pixels_array = np.array([]) if noisy_pixels is None else np.array(noisy_pixels)\n        if noisy_pixels_array.shape[0] != 0:\n            noisy_pixels_max_range = np.array([max(0, np.max(noisy_pixels_array[:, 0])), max(0, np.max(noisy_pixels_array[:, 1]))])\n            noisy_pixels = np.zeros(noisy_pixels_max_range + 1, dtype=np.bool)\n            noisy_pixels[noisy_pixels_array[:, 0], noisy_pixels_array[:, 1]] = 1\n        else:\n            noisy_pixels = np.zeros((0, 0), dtype=np.bool)\n\n        disabled_pixels_array = np.array([]) if disabled_pixels is None else np.array(disabled_pixels)\n        if disabled_pixels_array.shape[0] != 0:\n            disabled_pixels_max_range = np.array([np.max(disabled_pixels_array[:, 0]), np.max(disabled_pixels_array[:, 1])])\n            disabled_pixels = np.zeros(disabled_pixels_max_range + 1, dtype=np.bool)\n            disabled_pixels[disabled_pixels_array[:, 0], disabled_pixels_array[:, 1]] = 1\n        else:\n            disabled_pixels = np.zeros((0, 0), dtype=np.bool)\n\n#         col_dtype = self._cluster_hits.dtype.fields[\"column\"][0]\n#         row_dtype = self._cluster_hits.dtype.fields[\"row\"][0]\n#         mask_dtype = {\"names\": [\"column\", \"row\"],\n#                       \"formats\": [col_dtype, row_dtype]}\n#         noisy_pixels = np.recarray(noisy_pixels_array.shape[0], dtype=mask_dtype)\n#         noisy_pixels[:] = [(item[0], item[1]) for item in noisy_pixels_array]\n#         disabled_pixels = np.recarray(disabled_pixels_array.shape[0], dtype=mask_dtype)\n#         disabled_pixels[:] = [(item[0], item[1]) for item in disabled_pixels_array]\n\n        n_clusters = self.cluster_functions._cluster_hits(  # Set n_clusters to new size\n            hits=self._cluster_hits[:n_hits],\n            clusters=self._clusters[:n_hits],\n            assigned_hit_array=self._assigned_hit_array[:n_hits],\n            cluster_hit_indices=self._cluster_hit_indices[:n_hits],\n            column_cluster_distance=self._column_cluster_distance,\n            row_cluster_distance=self._row_cluster_distance,\n            frame_cluster_distance=self._frame_cluster_distance,\n            min_hit_charge=self._min_hit_charge,\n            max_hit_charge=self._max_hit_charge,\n            ignore_same_hits=self._ignore_same_hits,\n            noisy_pixels=noisy_pixels,\n            disabled_pixels=disabled_pixels)\n\n        self._cluster_hits.dtype.names = self._map_hit_field_names(self._cluster_hits.dtype.names)  # Rename the data fields for the result\n        self._clusters.dtype.names = self._map_cluster_field_names(self._clusters.dtype.names)  # Rename the data fields for the result\n\n        return self._cluster_hits[:n_hits], self._clusters[:n_clusters]", "response": "Cluster the hit array into a new array of hit indices and dtype."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_struct_compatibility(self, hits):\n        ''' Takes the hit array and checks if the important data fields have the same data type than the hit clustered array and that the field names are correct.'''\n        for key, _ in self._cluster_hits_descr:\n            if key in self._hit_fields_mapping_inverse:\n                mapped_key = self._hit_fields_mapping_inverse[key]\n            else:\n                mapped_key = key\n            # Only check hit fields that contain hit information\n            if mapped_key in ['cluster_ID', 'is_seed', 'cluster_size', 'n_cluster']:\n                continue\n            if key not in hits.dtype.names:\n                raise TypeError('Required hit field \"%s\" not found.' % key)\n            if self._cluster_hits.dtype[mapped_key] != hits.dtype[key]:\n                raise TypeError('The dtype for hit data field \"%s\" does not match. Got/expected: %s/%s.' % (key, hits.dtype[key], self._cluster_hits.dtype[mapped_key]))\n        additional_hit_fields = set(hits.dtype.names) - set([key for key, val in self._cluster_hits_descr])\n        if additional_hit_fields:\n            logging.warning('Found additional hit fields: %s' % \", \".join(additional_hit_fields))", "response": "Takes the hit array and checks if the important data fields have the same data type than the hit clustered array and that the field names are correct."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a tree. Complement LookAhead Neg Until", "response": "def add_mod(self, seq, mod):\n    \"\"\"Create a tree.{Complement, LookAhead, Neg, Until}\"\"\"\n    modstr = self.value(mod)\n    if modstr == '~':\n        seq.parser_tree = parsing.Complement(seq.parser_tree)\n    elif modstr == '!!':\n        seq.parser_tree = parsing.LookAhead(seq.parser_tree)\n    elif modstr == '!':\n        seq.parser_tree = parsing.Neg(seq.parser_tree)\n    elif modstr == '->':\n        seq.parser_tree = parsing.Until(seq.parser_tree)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_ruleclause_name(self, ns_name, rid) -> bool:\n    ns_name.parser_tree = parsing.Rule(self.value(rid))\n    return True", "response": "Add a ruleclause name to the namespace."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_rules(self, bnf, r) -> bool:\n    bnf[r.rulename] = r.parser_tree\n    return True", "response": "Attach a parser tree to the dict of rules"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding the rule name rn to the rule.", "response": "def add_rule(self, rule, rn, alts) -> bool:\n    \"\"\"Add the rule name\"\"\"\n    rule.rulename = self.value(rn)\n    rule.parser_tree = alts.parser_tree\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a sequence to the tree.", "response": "def add_sequences(self, sequences, cla) -> bool:\n    \"\"\"Create a tree.Seq\"\"\"\n    if not hasattr(sequences, 'parser_tree'):\n        # forward sublevel of sequence as is\n        sequences.parser_tree = cla.parser_tree\n    else:\n        oldnode = sequences\n        if isinstance(oldnode.parser_tree, parsing.Seq):\n            oldpt = list(oldnode.parser_tree.ptlist)\n        else:\n            oldpt = [oldnode.parser_tree]\n        oldpt.append(cla.parser_tree)\n        sequences.parser_tree = parsing.Seq(*tuple(oldpt))\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds an alternative to the list of alternatives.", "response": "def add_alt(self, alternatives, alt) -> bool:\n    \"\"\"Create a tree.Alt\"\"\"\n    if not hasattr(alternatives, 'parser_tree'):\n        # forward sublevel of alt as is\n        if hasattr(alt, 'parser_tree'):\n            alternatives.parser_tree = alt.parser_tree\n        else:\n            alternatives.parser_tree = alt\n    else:\n        oldnode = alternatives\n        if isinstance(oldnode.parser_tree, parsing.Alt):\n            oldpt = list(oldnode.parser_tree.ptlist)\n        else:\n            oldpt = [oldnode.parser_tree]\n        oldpt.append(alt.parser_tree)\n        alternatives.parser_tree = parsing.Alt(*tuple(oldpt))\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_read_sqstring(self, sequence, s):\n    v = self.value(s).strip(\"'\")\n    if len(v) > 1:\n        sequence.parser_tree = parsing.Text(v)\n        return True\n    sequence.parser_tree = parsing.Char(v)\n    return True", "response": "Add a read_char or read_text primitive from simple quote string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_range(self, sequence, begin, end):\n    sequence.parser_tree = parsing.Range(self.value(begin).strip(\"'\"),\n                                         self.value(end).strip(\"'\"))\n    return True", "response": "Add a read_range primitive"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a repeater to the previous sequence", "response": "def add_rpt(self, sequence, mod, pt):\n    \"\"\"Add a repeater to the previous sequence\"\"\"\n    modstr = self.value(mod)\n    if modstr == '!!':\n        # cursor on the REPEATER\n        self._stream.restore_context()\n        # log the error\n        self.diagnostic.notify(\n            error.Severity.ERROR,\n            \"Cannot repeat a lookahead rule\",\n            error.LocationInfo.from_stream(self._stream, is_error=True)\n        )\n        raise self.diagnostic\n    if modstr == '!':\n        # cursor on the REPEATER\n        self._stream.restore_context()\n        # log the error\n        self.diagnostic.notify(\n            error.Severity.ERROR,\n            \"Cannot repeat a negated rule\",\n            error.LocationInfo.from_stream(self._stream, is_error=True)\n        )\n        raise self.diagnostic\n    oldnode = sequence\n    sequence.parser_tree = pt.functor(oldnode.parser_tree)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a tree. Capture object for the cpt value.", "response": "def add_capture(self, sequence, cpt):\n    \"\"\"Create a tree.Capture\"\"\"\n    cpt_value = self.value(cpt)\n    sequence.parser_tree = parsing.Capture(cpt_value, sequence.parser_tree)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a tree. Bind object for the cpt value.", "response": "def add_bind(self, sequence, cpt):\n    \"\"\"Create a tree.Bind\"\"\"\n    cpt_value = self.value(cpt)\n    sequence.parser_tree = parsing.Bind(cpt_value, sequence.parser_tree)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_hook(self, sequence, h):\n    sequence.parser_tree = parsing.Hook(h.name, h.listparam)\n    return True", "response": "Create a tree. Hook"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a int in parameter list", "response": "def param_num(self, param, n):\n    \"\"\"Parse a int in parameter list\"\"\"\n    param.pair = (int(self.value(n)), int)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef param_str(self, param, s):\n    param.pair = (self.value(s).strip('\"'), str)\n    return True", "response": "Parse a str in parameter list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef param_char(self, param, c):\n    param.pair = (self.value(c).strip(\"'\"), str)\n    return True", "response": "Parse a char in parameter list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef param_id(self, param, i):\n    param.pair = (self.value(i), parsing.Node)\n    return True", "response": "Parse a node name in parameter list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a hook name", "response": "def hook_name(self, hook, n):\n    \"\"\"Parse a hook name\"\"\"\n    hook.name = self.value(n)\n    hook.listparam = []\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hook_param(self, hook, p):\n    hook.listparam.append(p.pair)\n    return True", "response": "Parse a hook parameter"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_directive2(self, sequence, d, s):\n    sequence.parser_tree = parsing.Directive2(\n        d.name,\n        d.listparam,\n        s.parser_tree\n    )\n    return True", "response": "Add a directive in the sequence"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_directive(self, sequence, d, s):\n    if d.name in meta._directives:\n        the_class = meta._directives[d.name]\n        sequence.parser_tree = parsing.Directive(the_class(), d.listparam,\n                                                 s.parser_tree)\n    elif d.name in meta._decorators:\n        the_class = meta._decorators[d.name]\n        sequence.parser_tree = parsing.Decorator(the_class, d.listparam,\n                                                 s.parser_tree)\n    else:\n        raise TypeError(\"Unkown directive or decorator %s\" % d.name)\n    return True", "response": "Add a directive in the sequence"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the DSL and provide a dictionnaries of all resulting rules.", "response": "def get_rules(self) -> parsing.Node:\n        \"\"\"\n        Parse the DSL and provide a dictionnaries of all resulting rules.\n        Call by the MetaGrammar class.\n\n        TODO: could be done in the rules property of parsing.BasicParser???\n        \"\"\"\n        res = None\n        try:\n            res = self.eval_rule('bnf_dsl')\n            if not res:\n                # we fail to parse, but error is not set\n                self.diagnostic.notify(\n                    error.Severity.ERROR,\n                    \"Parse error in '%s' in EBNF bnf\" % self._lastRule,\n                    error.LocationInfo.from_maxstream(self._stream)\n                )\n                raise self.diagnostic\n        except error.Diagnostic as d:\n            d.notify(\n                error.Severity.ERROR,\n                \"Parse error in '%s' in EBNF bnf\" % self._lastRule\n            )\n            raise d\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_yml(self):\n    pp = fmt.tab([])\n    to_yml_item(self, pp.lsdata, \"\")\n    return str(pp)", "response": "Returns a string representation of the node as YML."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconsumes comments and whitespace characters.", "response": "def ignore_cxx(self) -> bool:\n    \"\"\"Consume comments and whitespace characters.\"\"\"\n    self._stream.save_context()\n    while not self.read_eof():\n        idxref = self._stream.index\n        if self._stream.peek_char in \" \\t\\v\\f\\r\\n\":\n            while (not self.read_eof()\n                    and self._stream.peek_char in \" \\t\\v\\f\\r\\n\"):\n                self._stream.incpos()\n        if self.peek_text(\"//\"):\n            while not self.read_eof() and not self.peek_char(\"\\n\"):\n                self._stream.incpos()\n            if not self.read_char(\"\\n\") and self.read_eof():\n                return self._stream.validate_context()\n        if self.peek_text(\"/*\"):\n            while not self.read_eof() and not self.peek_text(\"*/\"):\n                self._stream.incpos()\n            if not self.read_text(\"*/\") and self.read_eof():\n                return self._stream.restore_context()\n        if idxref == self._stream.index:\n            break\n    return self._stream.validate_context()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a state to the internal state list", "response": "def add_state(self, s: State):\n        \"\"\"\n        all state in the register have a uid\n        \"\"\"\n        ids = id(s)\n        uid = len(self.states)\n        if ids not in self.states:\n            self.states[ids] = (uid, s)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a. dot representation of the register.", "response": "def to_dot(self) -> str:\n        \"\"\"\n        Provide a '.dot' representation of all State in the register.\n        \"\"\"\n        txt = \"\"\n        txt += \"digraph S%d {\\n\" % id(self)\n        if self.label is not None:\n            txt += '\\tlabel=\"%s\";\\n' % (self.label + '\\l').replace('\\n', '\\l')\n        txt += \"\\trankdir=LR;\\n\"\n        #txt += '\\tlabelloc=\"t\";\\n'\n        txt += '\\tgraph [labeljust=l, labelloc=t, nojustify=true];\\n'\n        txt += \"\\tesep=1;\\n\"\n        txt += '\\tranksep=\"equally\";\\n'\n        txt += \"\\tnode [shape = circle];\\n\"\n        txt += \"\\tsplines = ortho;\\n\"\n        for s in self.states.values():\n            txt += s[1].to_dot()\n        txt += \"}\\n\"\n        return txt"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_dot_file(self, fname: str):\n        with open(fname, 'w') as f:\n            f.write(self.to_dot())", "response": "write a. dot file.\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a. png file.", "response": "def to_png_file(self, fname: str):\n        \"\"\"\n        write a '.png' file.\n        \"\"\"\n        cmd = pipes.Template()\n        cmd.append('dot -Tpng > %s' % fname, '-.')\n        with cmd.open('pipefile', 'w') as f:\n            f.write(self.to_dot())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprovide a useful representation of the register.", "response": "def to_fmt(self) -> str:\n        \"\"\"\n        Provide a useful representation of the register.\n        \"\"\"\n        infos = fmt.end(\";\\n\", [])\n        s = fmt.sep(', ', [])\n        for ids in sorted(self.states.keys()):\n            s.lsdata.append(str(ids))\n        infos.lsdata.append(fmt.block('(', ')', [s]))\n        infos.lsdata.append(\"events:\" + repr(self.events))\n        infos.lsdata.append(\n            \"named_events:\" + repr(list(self.named_events.keys()))\n        )\n        infos.lsdata.append(\"uid_events:\" + repr(list(self.uid_events.keys())))\n        return infos"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nextstate(self, newstate, treenode=None, user_data=None):\n        if newstate is None:\n            return self\n        if isinstance(newstate, State) and id(newstate) != id(self):\n            return newstate\n        elif isinstance(newstate, StateEvent):\n            self.state_register.named_events[newstate.name] = True\n            return newstate.st\n        elif isinstance(newstate, StatePrecond):\n            return newstate.st\n        elif isinstance(newstate, StateHook):\n            # final API using PSL\n            newstate.call(treenode, user_data)\n            return newstate.st\n        return self", "response": "Return the next state in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef checkValue(self, v) -> State:\n        if self.wild_value:\n            return self.nextstate(self.values['*'])\n        elif str(v) in self.values:\n            return self.nextstate(self.values[str(v)])\n        return self", "response": "check the value of the attribute"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resetLivingState(self):\n        # TODO: add some test to control number of instanciation of LivingState\n        # clean all living state on S0\n        must_delete = []\n        l = len(self.ls)\n        for idx, ls in zip(range(l), self.ls):\n            # TODO: alive by default on False, change to True on the first match\n            ids = id(ls[1].thestate())\n            if ids == id(ls[0]) and (ls[1].have_finish or not ls[1].alive):\n                must_delete.append(idx)\n            elif ls[1].alive:\n                ls[1].alive = False\n        for delete in reversed(must_delete):\n            self.ls.pop(delete)\n        self.init_all()", "response": "Reset all the living states on the S0 of each StateRegister"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef infer_type(self, init_scope: Scope=None, diagnostic=None):\n        # create the first .infer_node\n        if not hasattr(self, 'infer_node'):\n            self.infer_node = InferNode(init_scope)\n        elif init_scope is not None:\n            # only change the root scope\n            self.infer_node.scope_node = init_scope\n        # get algo\n        type_algo = self.type_algos()\n        if diagnostic is None and hasattr(self, 'diagnostic'):\n            diagnostic = self.diagnostic\n        type_algo[0](type_algo[1], diagnostic)", "response": "Do inference of the type of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef feedback(self, diagnostic=None):\n        # get algo\n        type_algo = self.type_algos()\n        if diagnostic is None and hasattr(self, 'diagnostic'):\n            diagnostic = self.diagnostic\n        type_algo[2](diagnostic)", "response": "Write infos into diagnostic object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninfer type on the block.", "response": "def infer_block(self, body, diagnostic=None):\n        \"\"\"\n        Infer type on block is to type each of is sub-element\n        \"\"\"\n        # RootBlockStmt has his own .infer_node (created via infer_type)\n        for e in body:\n            e.infer_node = InferNode(parent=self.infer_node)\n            e.infer_type(diagnostic=diagnostic)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninferring the type of the subexpression expr.", "response": "def infer_subexpr(self, expr, diagnostic=None):\n        \"\"\"\n        Infer type on the subexpr\n        \"\"\"\n        expr.infer_node = InferNode(parent=self.infer_node)\n        expr.infer_type(diagnostic=diagnostic)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef infer_id(self, ident, diagnostic=None):\n        # check if ID is declared\n        #defined = self.type_node.get_by_symbol_name(ident)\n        defined = self.infer_node.scope_node.get_by_symbol_name(ident)\n        if len(defined) > 0:\n            # set from matchings declarations\n            #self.type_node.update(defined)\n            self.infer_node.scope_node.update(defined)\n        else:\n            diagnostic.notify(\n                Severity.ERROR,\n                \"%s never declared\" % self.value,\n                self.info\n            )", "response": "Infer type from an ID!"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninfers type from an LITERAL!", "response": "def infer_literal(self, args, diagnostic=None):\n        \"\"\"\n        Infer type from an LITERAL!\n        Type of literal depend of language.\n        We adopt a basic convention\n        \"\"\"\n        literal, t = args\n        #self.type_node.add(EvalCtx.from_sig(Val(literal, t)))\n        self.infer_node.scope_node.add(EvalCtx.from_sig(Val(literal, t)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndump the node cache. For debug.", "response": "def dump_nodes(self):\n    \"\"\"\n    Dump tag,rule,id and value cache. For debug.\n\n    example::\n\n        R = [\n            #dump_nodes\n        ]\n\n    \"\"\"\n    print(\"DUMP NODE LOCAL INFOS\")\n    try:\n        print(\"map Id->node name\")\n        for k, v in self.id_cache.items():\n            print(\"[%d]=%s\" % (k, v))\n        print(\"map tag->capture infos\")\n        for k, v in self.tag_cache.items():\n            print(\"[%s]=%s\" % (k, v))\n        print(\"map nodes->tag resolution\")\n        for k, v in self.rule_nodes.items():\n            txt = \"['%s']=%d\" % (k, id(v))\n            if k in self.tag_cache:\n                tag = self.tag_cache[k]\n                txt += \" tag <%s>\" % tag\n                k = \"%d:%d\" % (tag._begin, tag._end)\n                if k in self._stream.value_cache:\n                    txt += \" cache <%s>\" % self._stream.value_cache[k]\n            print(txt)\n    except Exception as err:\n        print(\"RECV Exception %s\" % err)\n    import sys\n    sys.stdout.flush()\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_dataset_uris(cls, base_uri, config_path):\n        uri_list = []\n\n        parse_result = generous_parse_uri(base_uri)\n        bucket_name = parse_result.netloc\n        bucket = boto3.resource('s3').Bucket(bucket_name)\n\n        for obj in bucket.objects.filter(Prefix='dtool').all():\n            uuid = obj.key.split('-', 1)[1]\n            uri = cls.generate_uri(None, uuid, base_uri)\n\n            storage_broker = cls(uri, config_path)\n            if storage_broker.has_admin_metadata():\n                uri_list.append(uri)\n\n        return uri_list", "response": "Return list containing URIs with base URI."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_item_abspath(self, identifier):\n        admin_metadata = self.get_admin_metadata()\n        uuid = admin_metadata[\"uuid\"]\n        # Create directory for the specific dataset.\n        dataset_cache_abspath = os.path.join(self._s3_cache_abspath, uuid)\n        mkdir_parents(dataset_cache_abspath)\n\n        bucket_fpath = self.data_key_prefix + identifier\n        obj = self.s3resource.Object(self.bucket, bucket_fpath)\n        relpath = obj.get()['Metadata']['handle']\n        _, ext = os.path.splitext(relpath)\n\n        local_item_abspath = os.path.join(\n            dataset_cache_abspath,\n            identifier + ext\n        )\n        if not os.path.isfile(local_item_abspath):\n\n            tmp_local_item_abspath = local_item_abspath + \".tmp\"\n            self.s3resource.Bucket(self.bucket).download_file(\n                bucket_fpath,\n                tmp_local_item_abspath\n            )\n            os.rename(tmp_local_item_abspath, local_item_abspath)\n\n        return local_item_abspath", "response": "Return absolute path at which the item content can be accessed."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_overlay_names(self):\n\n        bucket = self.s3resource.Bucket(self.bucket)\n\n        overlay_names = []\n        for obj in bucket.objects.filter(\n            Prefix=self.overlays_key_prefix\n        ).all():\n\n            overlay_file = obj.key.rsplit('/', 1)[-1]\n            overlay_name, ext = overlay_file.split('.')\n            overlay_names.append(overlay_name)\n\n        return overlay_names", "response": "Return list of overlay names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_item_metadata(self, handle, key, value):\n\n        identifier = generate_identifier(handle)\n        suffix = '{}.{}.json'.format(identifier, key)\n        bucket_fpath = self.fragments_key_prefix + suffix\n\n        self.s3resource.Object(self.bucket, bucket_fpath).put(\n            Body=json.dumps(value)\n        )", "response": "Store the given key value pair for the item associated with handle."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning iterator over item handles.", "response": "def iter_item_handles(self):\n        \"\"\"Return iterator over item handles.\"\"\"\n\n        bucket = self.s3resource.Bucket(self.bucket)\n\n        for obj in bucket.objects.filter(Prefix=self.data_key_prefix).all():\n            relpath = obj.get()['Metadata']['handle']\n\n            yield relpath"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_item_metadata(self, handle):\n\n        bucket = self.s3resource.Bucket(self.bucket)\n\n        metadata = {}\n\n        identifier = generate_identifier(handle)\n        prefix = self.fragments_key_prefix + '{}'.format(identifier)\n        for obj in bucket.objects.filter(Prefix=prefix).all():\n            metadata_key = obj.key.split('.')[-2]\n            response = obj.get()\n            value_as_string = response['Body'].read().decode('utf-8')\n            value = json.loads(value_as_string)\n\n            metadata[metadata_key] = value\n\n        return metadata", "response": "Get all the metadata associated with handle."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates code for a rule.", "response": "def parserrule_topython(parser: parsing.BasicParser,\n                        rulename: str) -> ast.FunctionDef:\n    \"\"\"Generates code for a rule.\n\n    def rulename(self):\n        <code for the rule>\n        return True\n    \"\"\"\n    visitor = RuleVisitor()\n    rule = parser._rules[rulename]\n    fn_args = ast.arguments([ast.arg('self', None)], None, None, [], None,\n                            None, [], [])\n    body = visitor._clause(rule_topython(rule))\n    body.append(ast.Return(ast.Name('True', ast.Load())))\n    return ast.FunctionDef(rulename, fn_args, body, [], None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates the appropriate scope exiting statement.", "response": "def __exit_scope(self) -> ast.stmt:\n        \"\"\"Create the appropriate scope exiting statement.\n\n        The documentation only shows one level and always uses\n        'return False' in examples.\n\n        'raise AltFalse()' within a try.\n        'break' within a loop.\n        'return False' otherwise.\n        \"\"\"\n        if self.in_optional:\n            return ast.Pass()\n        if self.in_try:\n            return ast.Raise(\n                ast.Call(ast.Name('AltFalse', ast.Load()), [], [], None, None),\n                None)\n        if self.in_loop:\n            return ast.Break()\n        return ast.Return(ast.Name('False', ast.Load()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nnormalize a test expression into a statements list.", "response": "def _clause(self, pt: parsing.ParserTree) -> [ast.stmt]:\n        \"\"\"Normalize a test expression into a statements list.\n\n        Statements list are returned as-is.\n        Expression is packaged as:\n        if not expr:\n            return False\n        \"\"\"\n        if isinstance(pt, list):\n            return pt\n        return [ast.If(ast.UnaryOp(ast.Not(), pt),\n                       [self.__exit_scope()],\n                       [])]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating python code calling the function.", "response": "def visit_Call(self, node: parsing.Call) -> ast.expr:\n        \"\"\"Generates python code calling the function.\n\n        fn(*args)\n        \"\"\"\n        return ast.Call(\n            ast.Attribute(\n                ast.Name('self', ast.Load),\n                node.callObject.__name__,\n                ast.Load()),\n            [ast.Str(param) for param in node.params],\n            [],\n            None,\n            None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef visit_CallTrue(self, node: parsing.CallTrue) -> ast.expr:\n        return ast.Lambda(\n            ast.arguments([], None, None, [], None, None, [], []),\n            ast.BoolOp(\n                ast.Or(),\n                [\n                    self.visit_Call(node),\n                    ast.Name('True', ast.Load())]))", "response": "Generates python code calling the function and returning True."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef visit_Hook(self, node: parsing.Hook) -> ast.expr:\n        return ast.Call(\n            ast.Attribute(\n                ast.Name('self', ast.Load()), 'evalHook', ast.Load()),\n            [\n                ast.Str(node.name),\n                ast.Subscript(\n                    ast.Attribute(\n                        ast.Name('self', ast.Load()), 'ruleNodes', ast.Load()),\n                    ast.Index(ast.UnaryOp(ast.USub(), ast.Num(1))),\n                    ast.Load())],\n            [],\n            None,\n            None)", "response": "Generates python code calling a hook."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates python code calling a rule. self. evalRule ( rulename", "response": "def visit_Rule(self, node: parsing.Rule) -> ast.expr:\n        \"\"\"Generates python code calling a rule.\n\n        self.evalRule('rulename')\n        \"\"\"\n        return ast.Call(\n            ast.Attribute(ast.Name('self', ast.Load()),\n                          'evalRule', ast.Load()),\n            [ast.Str(node.name)], [], None, None)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of statements that can be used to capture text consumed by a clause.", "response": "def visit_Capture(self, node: parsing.Capture) -> [ast.stmt] or ast.expr:\n        \"\"\"Generates python code to capture text consumed by a clause.\n\n        #If all clauses can be inlined\n        self.beginTag('tagname') and clause and self.endTag('tagname')\n\n        if not self.beginTag('tagname'):\n            return False\n        <code for the clause>\n        if not self.endTag('tagname'):\n            return False\n        \"\"\"\n        begintag = ast.Attribute(\n            ast.Name('self', ast.Load()), 'beginTag', ast.Load())\n        endtag = ast.Attribute(\n            ast.Name('self', ast.Load()), 'endTag', ast.Load())\n        begin = ast.Call(begintag, [ast.Str(node.tagname)], [], None, None)\n        end = ast.Call(endtag, [ast.Str(node.tagname)], [], None, None)\n        result = [begin, self.visit(node.pt), end]\n        for clause in result:\n            if not isinstance(clause, ast.expr):\n                break\n        else:\n            return ast.BoolOp(ast.And(), result)\n        res = []\n        for stmt in map(self._clause, result):\n            res.extend(stmt)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates python code for a scope.", "response": "def visit_Scope(self, node: parsing.Capture) -> [ast.stmt] or ast.expr:\n        \"\"\"Generates python code for a scope.\n\n        if not self.begin():\n            return False\n        res = self.pt()\n        if not self.end():\n            return False\n        return res\n        \"\"\"\n        return ast.Name('scope_not_implemented', ast.Load())\n        raise NotImplementedError()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef visit_Alt(self, node: parsing.Alt) -> [ast.stmt]:\n        clauses = [self.visit(clause) for clause in node.ptlist]\n        for clause in clauses:\n            if not isinstance(clause, ast.expr):\n                break\n        else:\n            return ast.BoolOp(ast.Or(), clauses)\n        res = ast.Try([], [ast.ExceptHandler(\n            ast.Name('AltTrue', ast.Load()), None, [ast.Pass()])], [], [])\n        alt_true = [ast.Raise(ast.Call(\n            ast.Name('AltTrue', ast.Load()), [], [], None, None), None)]\n        alt_false = [ast.ExceptHandler(\n            ast.Name('AltFalse', ast.Load()), None, [ast.Pass()])]\n        self.in_try += 1\n        for clause in node.ptlist:\n            res.body.append(\n                ast.Try(self._clause(self.visit(clause)) + alt_true,\n                        alt_false, [], []))\n        self.in_try -= 1\n        res.body.append(self.__exit_scope())\n        return [res]", "response": "Generates python code for alternatives."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit_Seq(self, node: parsing.Seq) -> [ast.stmt] or ast.expr:\n        exprs, stmts = [], []\n        for clause in node.ptlist:\n            clause_ast = self.visit(clause)\n            if isinstance(clause_ast, ast.expr):\n                exprs.append(clause_ast)\n            else:\n                if exprs:\n                    stmts.extend(self.combine_exprs_for_clauses(exprs))\n                    exprs = []\n                stmts.extend(self._clause(clause_ast))\n        if not stmts:\n            return ast.BoolOp(ast.And(), exprs)\n        if exprs:\n            stmts.extend(self.combine_exprs_for_clauses(exprs))\n        return stmts", "response": "Generates python code for the Seq node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visit_RepOptional(self, node: parsing.RepOptional) -> ([ast.stmt] or\n                                                               ast.expr):\n        \"\"\"Generates python code for an optional clause.\n\n        <code for the clause>\n        \"\"\"\n        cl_ast = self.visit(node.pt)\n        if isinstance(cl_ast, ast.expr):\n            return ast.BoolOp(ast.Or(), [cl_ast, ast.Name('True', ast.Load())])\n        self.in_optional += 1\n        cl_ast = self.visit(node.pt)\n        self.in_optional -= 1\n        return cl_ast", "response": "Returns the AST node for an optional clause."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef visit_Rep0N(self, node: parsing.Rep0N) -> [ast.stmt]:\n        cl_ast = self.visit(node.pt)\n        if isinstance(cl_ast, ast.expr):\n            return [ast.While(cl_ast, [ast.Pass()], [])]\n        self.in_loop += 1\n        clause = self._clause(self.visit(node.pt))\n        self.in_loop -= 1\n        return [ast.While(ast.Name('True', ast.Load()), clause, [])]", "response": "Return an ast. stmt for repeated 0 or more times."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef visit_Rep1N(self, node: parsing.Rep0N) -> [ast.stmt]:\n        clause = self.visit(node.pt)\n        if isinstance(clause, ast.expr):\n            return (self._clause(clause) + self.visit_Rep0N(node))\n        self.in_loop += 1\n        clause = self._clause(self.visit(node.pt))\n        self.in_loop -= 1\n        return self._clause(self.visit(node.pt)) + [\n            ast.While(ast.Name('True', ast.Load()), clause, [])]", "response": "Return the AST node s children as a list of statements."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of all synthese deputes in a given month.", "response": "def synthese(self, month=None):\n        \"\"\"\n        month format: YYYYMM\n        \"\"\"\n        if month is None and self.legislature == '2012-2017':\n            raise AssertionError('Global Synthesis on legislature does not work, see https://github.com/regardscitoyens/nosdeputes.fr/issues/69')\n\n        if month is None:\n            month = 'data'\n\n        url = '%s/synthese/%s/%s' % (self.base_url, month, self.format)\n\n        data = requests.get(url).json()\n        return [depute[self.ptype] for depute in data[self.ptype_plural]]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef catend(dst: str, src: str, indent) -> str:\n    res = dst\n    txtsrc = src\n    if not isinstance(src, str):\n        txtsrc = str(src)\n    for c in list(txtsrc):\n        if len(res) > 0 and res[-1] == '\\n':\n            res += (indentable.char_indent * indentable.num_indent) * \\\n                   (indent - 1) + c\n        else:\n            res += c\n    return res", "response": "cat two strings but handle \\ n for tabulation"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_set_indent(lst: list, indent: int=1):\n    for i in lst:\n        if isinstance(i, indentable):\n            i.set_indent(indent)\n        if isinstance(i, list):\n            list_set_indent(i, indent)", "response": "recurs into list for indentation"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_to_str(lst: list, content: str, indent: int=1):\n    for i in lst:\n        if isinstance(i, indentable):\n            content = i.to_str(content, indent)\n        elif isinstance(i, list):\n            content = list_to_str(i, content, indent)\n        elif isinstance(i, str):\n            content = catend(content, i, indent)\n    return content", "response": "recurs into list for string computing"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef echo_nodes(self, *rest):\n    txt = \"\"\n    for thing in rest:\n        if isinstance(thing, Node):\n            txt += self.value(thing)\n        else:\n            txt += str(thing)\n    print(txt)\n    return True", "response": "Print nodes.\n\n    example::\n\n        R = [\n            In : node #echo(\"coucou\", 12, node)\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef populate_from_sequence(seq: list, r: ref(Edge), sr: state.StateRegister):\n    base_state = r\n    # we need to detect the last state of the sequence\n    idxlast = len(seq) - 1\n    idx = 0\n    for m in seq:\n        # alternatives are represented by builtin list\n        if isinstance(m, list):\n            # so recursively connect all states of each alternative sequences.\n            for item in m:\n                populate_from_sequence(item, r, sr)\n        elif isinstance(m, MatchExpr):\n            # from the current state, have we a existing edge for this event?\n            eX = r().get_next_edge(m)\n            if eX is None:\n                sX = None\n                if idx != idxlast:\n                    sX = state.State(sr)\n                    sX.matchDefault(base_state().s)\n                else:\n                    # last state of sequence return to the base\n                    sX = base_state().s\n                eX = Edge(sX)\n                r().next_edge[id(sX)] = eX\n                m.attach(r().s, sX, sr)\n            r = ref(eX)\n        idx += 1", "response": "function that connects each other one sequence of MatchExpr into the base state."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef populate_state_register(all_seq: [list], sr: state.StateRegister) -> Edge:\n    # Basic State\n    s0 = state.State(sr)\n    # loop on himself\n    s0.matchDefault(s0)\n    # this is default\n    sr.set_default_state(s0)\n    # use Edge to store connection\n    e0 = Edge(s0)\n    for seq in all_seq:\n        r = ref(e0)\n        # merge all sequences into one tree automata\n        populate_from_sequence(seq, r, sr)\n    # return edge for debug purpose\n    return e0", "response": "function that creates a state for all instance\n        of MatchExpr in the given list and connect each others to the state register."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntest if a node set with setint or setstr equal a certain value", "response": "def pred_eq(self, n, val):\n    \"\"\"\n    Test if a node set with setint or setstr equal a certain value\n\n    example::\n\n        R = [\n            __scope__:n\n            ['a' #setint(n, 12) | 'b' #setint(n, 14)]\n            C\n            [#eq(n, 12) D]\n        ]\n\n    \"\"\"\n    v1 = n.value\n    v2 = val\n    if hasattr(val, 'value'):\n        v2 = val.value\n    if isinstance(v1, int) and not isinstance(v2, int):\n        return v1 == int(v2)\n    return v1 == v2"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_string(bnf: str, entry=None, *optional_inherit) -> Grammar:\n    inherit = [Grammar] + list(optional_inherit)\n    scope = {'grammar': bnf, 'entry': entry}\n    return build_grammar(tuple(inherit), scope)", "response": "Create a Grammar from a string"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a Grammar from a file", "response": "def from_file(fn: str, entry=None, *optional_inherit) -> Grammar:\n    \"\"\"\n    Create a Grammar from a file\n    \"\"\"\n    import os.path\n    if os.path.exists(fn):\n        f = open(fn, 'r')\n        bnf = f.read()\n        f.close()\n        inherit = [Grammar] + list(optional_inherit)\n        scope = {'grammar': bnf, 'entry': entry, 'source': fn}\n        return build_grammar(tuple(inherit), scope)\n    raise Exception(\"File not Found!\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse(self, source: str=None, entry: str=None) -> parsing.Node:\n        self.from_string = True\n        if source is not None:\n            self.parsed_stream(source)\n        if entry is None:\n            entry = self.entry\n        if entry is None:\n            raise ValueError(\"No entry rule name defined for {}\".format(\n                self.__class__.__name__))\n        return self._do_parse(entry)", "response": "Parse the source using the grammar"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a file using the grammar", "response": "def parse_file(self, filename: str, entry: str=None) -> parsing.Node:\n        \"\"\"Parse filename using the grammar\"\"\"\n        self.from_string = False\n        import os.path\n        with open(filename, 'r') as f:\n            self.parsed_stream(f.read(), os.path.abspath(filename))\n        if entry is None:\n            entry = self.entry\n        if entry is None:\n            raise ValueError(\"No entry rule name defined for {}\".format(\n                self.__class__.__name__))\n        return self._do_parse(entry)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_node(self, dst, src):\n    if not isinstance(src, Node):\n        dst.value = src\n    else:\n        dst.set(src)\n        idsrc = id(src)\n        iddst = id(dst)\n        if iddst not in self.id_cache:\n            print(\"DST: %s\" % repr(dst))\n            print(\"RULE_NODES %s\" % repr(self.rule_nodes))\n            print(\"IDCACHE %s\" % repr(self.id_cache))\n        if idsrc in self.id_cache:\n            k = self.id_cache[idsrc]\n            k2 = self.id_cache[iddst]\n            if k in self.rule_nodes:\n                self.tag_cache[k2] = self.tag_cache[k]\n    return True", "response": "Basically copy one node to another."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_node_as_int(self, dst, src):\n    dst.value = self.value(src)\n    return True", "response": "Set a node to a value captured from another node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the value of subnode in the tree", "response": "def get_subnode(self, dst, ast, expr):\n    \"\"\"\n        get the value of subnode\n\n        example::\n\n            R = [\n                __scope__:big  getsomethingbig:>big\n                #get(_, big, '.val') // copy big.val into _\n            ]\n    \"\"\"\n    dst.value = eval('ast' + expr)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef default_serializer(o):\n    defs = (\n        ((datetime.date, datetime.time),\n         lambda x: x.isoformat(), ),\n        ((datetime.datetime, ),\n         lambda x: dt2utc_timestamp(x), ),\n    )\n    for types, fun in defs:\n        if isinstance(o, types):\n            return fun(o)", "response": "Default serializer for json."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_depositions(user=None, type=None):\n    from invenio.modules.workflows.models import BibWorkflowObject, Workflow\n    from invenio.modules.deposit.models import InvalidDepositionType\n    from flask import current_app\n    from invenio.ext.sqlalchemy import db\n    from invenio.modules.deposit.models import Deposition\n    params = [\n        Workflow.module_name == 'webdeposit',\n    ]\n\n    if user:\n        params.append(BibWorkflowObject.id_user == user.get_id())\n    else:\n        params.append(BibWorkflowObject.id_user != 0)\n\n    if type:\n        params.append(Workflow.name == type.get_identifier())\n\n    objects = BibWorkflowObject.query.join(\"workflow\").options(\n        db.contains_eager('workflow')).filter(*params)\n\n    def _create_obj(o):\n        try:\n            obj = Deposition(o)\n        except InvalidDepositionType as err:\n            current_app.logger.exception(err)\n            return None\n        if type is None or obj.type == type:\n            return obj\n        return None\n\n    def mapper_filter(objs):\n        for o in objs:\n            o = _create_obj(o)\n            if o is not None:\n                yield o\n\n    return mapper_filter(objects)", "response": "Get list of depositions for a user and type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting all items in the cluster.", "response": "def get(query, from_date, limit=0, **kwargs):\n    \"\"\"Get deposits.\"\"\"\n    dep_generator = _get_depositions()\n    total_depids = 1  # Count of depositions is hard to determine\n\n    # If limit provided, serve only first n=limit items\n    if limit > 0:\n        dep_generator = islice(dep_generator, limit)\n        total_depids = limit\n    return total_depids, dep_generator"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dump(deposition, from_date, with_json=True, latest_only=False, **kwargs):\n    # Serialize the __getstate__ and fall back to default serializer\n    dep_json = json.dumps(deposition.__getstate__(),\n                          default=default_serializer)\n    dep_dict = json.loads(dep_json)\n    dep_dict['_p'] = {}\n    dep_dict['_p']['id'] = deposition.id\n    dep_dict['_p']['created'] = dt2utc_timestamp(deposition.created)\n    dep_dict['_p']['modified'] = dt2utc_timestamp(deposition.modified)\n    dep_dict['_p']['user_id'] = deposition.user_id\n    dep_dict['_p']['state'] = deposition.state\n    dep_dict['_p']['has_sip'] = deposition.has_sip()\n    dep_dict['_p']['submitted'] = deposition.submitted\n    return dep_dict", "response": "Dump the deposition object as dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_recids_invenio12(from_date):\n    from invenio.dbquery import run_sql\n    return (id[0] for id in run_sql(\n        'select id_bibrec from '\n        'bibrec_bibdoc as r join bibdoc as d on r.id_bibdoc=d.id '\n        'where d.modification_date >=%s',\n        (from_date, ), run_on_slave=True))", "response": "Get BibDocs for Invenio 1."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets BibDocs for Invenio 2.", "response": "def _get_recids_invenio2(from_date):\n    \"\"\"Get BibDocs for Invenio 2.\"\"\"\n    from invenio.legacy.dbquery import run_sql\n    return (id[0] for id in run_sql(\n        'select id_bibrec from '\n        'bibrec_bibdoc as r join bibdoc as d on r.id_bibdoc=d.id '\n        'where d.modification_date >=%s',\n        (from_date, ), run_on_slave=True))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndumping all BibDoc files in a given BibDoc ID.", "response": "def dump_bibdoc(recid, from_date, **kwargs):\n    \"\"\"Dump all BibDoc metadata.\n\n    :param docid: BibDoc ID\n    :param from_date: Dump only BibDoc revisions newer than this date.\n\n    :returns: List of version of the BibDoc formatted as a dict\n    \"\"\"\n    BibRecDocs, BibDoc = _import_bibdoc()\n\n    bibdocfile_dump = []\n\n    date = datetime.datetime.strptime(from_date, '%Y-%m-%d %H:%M:%S')\n    for bibdoc in BibRecDocs(recid).list_bibdocs():\n        for version in bibdoc.list_versions():\n            bibdoc_version = bibdoc.list_version_files(version)\n            for f in bibdoc_version:\n                if f.is_icon() or f.md < date:\n                    # Don't care about icons\n                    # Don't care about files not modified since from_date\n                    continue\n                bibdocfile_dump.append(dict(\n                    bibdocid=f.get_bibdocid(),\n                    checksum=f.get_checksum(),\n                    comment=f.get_comment(),\n                    copyright=(\n                        f.get_copyright() if hasattr(f, 'get_copyright')\n                        else None),\n                    creation_date=datetime_toutc(f.cd).isoformat(),\n                    description=f.get_description(),\n                    encoding=f.encoding,\n                    etag=f.etag,\n                    flags=f.flags,\n                    format=f.get_format(),\n                    full_name=f.get_full_name(),\n                    full_path=f.get_full_path(),\n                    hidden=f.hidden,\n                    license=(\n                        f.get_license()if hasattr(f, 'get_license') else None),\n                    modification_date=datetime_toutc(f.md).isoformat(),\n                    name=f.get_name(),\n                    mime=f.mime,\n                    path=f.get_path(),\n                    recid=f.get_recid(),\n                    recids_doctype=f.recids_doctypes,\n                    size=f.get_size(),\n                    status=f.get_status(),\n                    subformat=f.get_subformat(),\n                    superformat=f.get_superformat(),\n                    type=f.get_type(),\n                    url=f.get_url(),\n                    version=f.get_version(),\n                ))\n\n    return bibdocfile_dump"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget bibdocs to check.", "response": "def get_check():\n    \"\"\"Get bibdocs to check.\"\"\"\n    try:\n        from invenio.dbquery import run_sql\n    except ImportError:\n        from invenio.legacy.dbquery import run_sql\n\n    return (\n        run_sql('select count(id) from bibdoc', run_on_slave=True)[0][0],\n        [id[0] for id in run_sql('select id from bibdoc', run_on_slave=True)],\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndumping the oauth2server tokens.", "response": "def dump(obj, from_date, with_json=True, latest_only=False, **kwargs):\n    \"\"\"Dump the oauth2server tokens.\"\"\"\n    return dict(id=obj.id,\n                client_id=obj.client_id,\n                user_id=obj.user_id,\n                token_type=obj.token_type,\n                access_token=obj.access_token,\n                refresh_token=obj.refresh_token,\n                expires=dt2iso_or_empty(obj.expires),\n                _scopes=obj._scopes,\n                is_personal=obj.is_personal,\n                is_internal=obj.is_internal)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndump the UserEXt object to a list of dictionaries.", "response": "def dump(u, from_date, with_json=True, latest_only=False, **kwargs):\n    \"\"\"Dump the UserEXt objects as a list of dictionaries.\n\n    :param u: UserEXT to be dumped.\n    :type u: `invenio_accounts.models.UserEXT [Invenio2.x]`\n    :returns: User serialized to dictionary.\n    :rtype: dict\n    \"\"\"\n    return dict(id=u.id, method=u.method, id_user=u.id_user)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping the community featuring object as a dictionary.", "response": "def dump(fc, from_date, with_json=True, latest_only=False, **kwargs):\n    \"\"\"Dump the community object as dictionary.\n\n    :param fc: Community featuring to be dumped.\n    :type fc: `invenio_communities.models.FeaturedCommunity [Invenio2.x]`\n    :returns: Community serialized to dictionary.\n    :rtype: dict\n    \"\"\"\n    return dict(id=fc.id,\n                id_community=fc.id_community,\n                start_date=fc.start_date.isoformat())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget record ids for Invenio 1.", "response": "def _get_modified_recids_invenio12(from_date):\n    \"\"\"Get record ids for Invenio 1.\"\"\"\n    from invenio.search_engine import search_pattern\n    from invenio.dbquery import run_sql\n    return set((id[0] for id in run_sql(\n        'select id from bibrec where modification_date >= %s',\n        (from_date, ), run_on_slave=True))), search_pattern"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_modified_recids_invenio2(from_date):\n    from invenio.legacy.search_engine import search_pattern\n    from invenio.modules.records.models import Record\n\n    date = datetime.datetime.strptime(from_date, '%Y-%m-%d %H:%M:%S')\n    return set(\n        (x[0]\n         for x in Record.query.filter(Record.modification_date >= date).values(\n             Record.id))), search_pattern", "response": "Get record ids for Invenio 2."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_collection_restrictions(collection):\n    try:\n        from invenio.dbquery import run_sql\n        from invenio.access_control_firerole import compile_role_definition\n    except ImportError:\n        from invenio.modules.access.firerole import compile_role_definition\n        from invenio.legacy.dbquery import run_sql\n\n    res = run_sql(\n        'SELECT r.firerole_def_src, email '\n        'FROM accROLE as r '\n        'JOIN accROLE_accACTION_accARGUMENT ON r.id=id_accROLE '\n        'JOIN accARGUMENT AS a ON a.id=id_accARGUMENT '\n        'JOIN user_accROLE AS u ON r.id=u.id_accROLE '\n        'JOIN user ON user.id=u.id_user '\n        'WHERE a.keyword=\"collection\" AND '\n        'a.value=%s AND '\n        'id_accACTION=(select id from accACTION where name=\"viewrestrcoll\")',\n        (collection, ), run_on_slave=True\n    )\n    fireroles = set()\n    users = set()\n\n    for f, u in res:\n        fireroles.add(compile_role_definition(f))\n        users.add(u)\n\n    return {'fireroles': list(fireroles), 'users': users}", "response": "Get all restrictions for a given collection users and fireroles."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_record_collections(recid):\n    try:\n        from invenio.search_engine import (\n            get_all_collections_of_a_record,\n            get_restricted_collections_for_recid)\n    except ImportError:\n        from invenio.legacy.search_engine import (\n            get_all_collections_of_a_record,\n            get_restricted_collections_for_recid)\n\n    collections = {\n        'all':\n        get_all_collections_of_a_record(recid, recreate_cache_if_needed=False),\n    }\n    collections['restricted'] = dict(\n        (coll, _get_collection_restrictions(coll))\n        for coll in get_restricted_collections_for_recid(\n                recid, recreate_cache_if_needed=False))\n\n    return collections", "response": "Get all collections the record belong to."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dump_record_json(marcxml):\n    try:\n        from invenio.modules.records.api import Record\n        d = Record.create(marcxml, 'marc')\n        return d.dumps(clean=True)\n    except ImportError:\n        from invenio.bibfield import create_record\n        d = create_record(marcxml, master_format='marc')\n        return d.dumps()", "response": "Dump JSON of record."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting recids matching query and with changes.", "response": "def get(query, from_date, **kwargs):\n    \"\"\"Get recids matching query and with changes.\"\"\"\n    recids, search_pattern = get_modified_recids(from_date)\n    recids = recids.union(get_modified_bibdoc_recids(from_date))\n\n    if query:\n        recids = recids.intersection(\n            set(search_pattern(p=query.encode('utf-8'))))\n\n    return len(recids), recids"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dump(recid,\n         from_date,\n         with_json=False,\n         latest_only=False,\n         with_collections=False,\n         **kwargs):\n    \"\"\"Dump MARCXML and JSON representation of a record.\n\n    :param recid: Record identifier\n    :param from_date: Dump only revisions from this date onwards.\n    :param with_json: If ``True`` use old ``Record.create`` to generate the\n        JSON representation of the record.\n    :param latest_only: Dump only the last revision of the record metadata.\n    :param with_collections: If ``True`` dump the list of collections that the\n        record belongs to.\n    :returns: List of versions of the record.\n    \"\"\"\n    # Grab latest only\n    if latest_only:\n        revision_iter = [get_record_revisions(recid, from_date)[-1]]\n    else:\n        revision_iter = get_record_revisions(recid, from_date)\n\n    # Dump revisions\n    record_dump = dict(\n        record=[],\n        files=[],\n        recid=recid,\n        collections=get_record_collections(recid)\n        if with_collections else None, )\n\n    for revision_date, revision_marcxml in revision_iter:\n        marcxml = zlib.decompress(revision_marcxml)\n        record_dump['record'].append(\n            dict(\n                modification_datetime=datetime_toutc(revision_date)\n                .isoformat(),\n                marcxml=marcxml,\n                json=dump_record_json(marcxml) if with_json else None, ))\n\n    record_dump['files'] = dump_bibdoc(recid, from_date)\n\n    return record_dump", "response": "Dump a record into a dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndump the remote accounts as a list of dictionaries.", "response": "def dump(ra, from_date, with_json=True, latest_only=False, **kwargs):\n    \"\"\"Dump the remote accounts as a list of dictionaries.\n\n    :param ra: Remote account to be dumped.\n    :type ra: `invenio_oauthclient.models.RemoteAccount [Invenio2.x]`\n    :returns: Remote accounts serialized to dictionary.\n    :rtype: dict\n    \"\"\"\n    return dict(id=ra.id, user_id=ra.user_id, client_id=ra.client_id,\n                extra_data=ra.extra_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_common(model_cls, data):\n    obj = model_cls(**data)\n    db.session.add(obj)\n    db.session.commit()", "response": "Helper function for loading JSON data verbatim into model."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef collect_things_entry_points():\n    things = dict()\n    for entry_point in iter_entry_points(group='invenio_migrator.things'):\n        things[entry_point.name] = entry_point.load()\n    return things", "response": "Collect entry points and return them as a dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes app context for Invenio 2. x.", "response": "def init_app_context():\n    \"\"\"Initialize app context for Invenio 2.x.\"\"\"\n    try:\n        from invenio.base.factory import create_app\n        app = create_app()\n        app.test_request_context('/').push()\n        app.preprocess_request()\n    except ImportError:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncaches for heavy function calls.", "response": "def memoize(func):\n    \"\"\"Cache for heavy function calls.\"\"\"\n    cache = {}\n\n    @wraps(func)\n    def wrap(*args, **kwargs):\n        key = '{0}{1}'.format(args, kwargs)\n        if key not in cache:\n            cache[key] = func(*args, **kwargs)\n        return cache[key]\n    return wrap"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_connected_roles(action_id):\n    try:\n        from invenio.access_control_admin import compile_role_definition\n    except ImportError:\n        from invenio.modules.access.firerole import compile_role_definition\n\n    run_sql = _get_run_sql()\n\n    roles = {}\n    res = run_sql(\n        'select r.id, r.name, r.description, r.firerole_def_src, '\n        'a.keyword, a.value, email from accROLE as r '\n        'join accROLE_accACTION_accARGUMENT on r.id=id_accROLE '\n        'join accARGUMENT as a on  a.id=id_accARGUMENT '\n        'join user_accROLE as u on r.id=u.id_accROLE '\n        'join user on user.id=u.id_user '\n        'where id_accACTION=%s', (action_id, )\n    )\n\n    for r in res:\n        role = roles.setdefault(\n            r[0], {\n                'id': r[0],\n                'name': r[1],\n                'description': r[2],\n                'firerole_def': r[3],\n                'compiled_firerole_def': compile_role_definition(r[3]),\n                'users': set(),\n                'parameters': {}\n            }\n        )\n        param = role['parameters'].setdefault(r[4], set())\n        param.add(r[5])\n        role['users'].add(r[6])\n\n    return six.itervalues(roles)", "response": "Get the roles connected to an action."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(query, *args, **kwargs):\n    run_sql = _get_run_sql()\n\n    actions = [\n        dict(id=row[0],\n             name=row[1],\n             allowedkeywords=row[2],\n             optional=row[3])\n        for action in query.split(',') for row in run_sql(\n            'select id, name, description, allowedkeywords, optional '\n            'from accACTION where name like %s', (action, ),\n            run_on_slave=True)\n    ]\n\n    return len(actions), actions", "response": "Get action definitions to dump."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping the remote tokens to a list of dictionaries.", "response": "def dump(rt, from_date, with_json=True, latest_only=False, **kwargs):\n    \"\"\"Dump the remote tokens as a list of dictionaries.\n\n    :param ra: Remote toekn to be dumped.\n    :type ra: `invenio_oauthclient.models.RemoteToken [Invenio2.x]`\n    :returns: Remote tokens serialized to dictionary.\n    :rtype: dict\n    \"\"\"\n    return dict(id_remote_account=rt.id_remote_account,\n                token_type=rt.token_type,\n                access_token=rt.access_token,\n                secret=rt.secret)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the oauth2server token from data dump.", "response": "def load_token(data):\n    \"\"\"Load the oauth2server token from data dump.\"\"\"\n    from invenio_oauth2server.models import Token\n    data['expires'] = iso2dt_or_none(data['expires'])\n    load_common(Token, data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef import_record(data, source_type=None, latest_only=False):\n    source_type = source_type or 'marcxml'\n    assert source_type in ['marcxml', 'json']\n\n    recorddump = current_migrator.records_dump_cls(\n        data,\n        source_type=source_type,\n        pid_fetchers=current_migrator.records_pid_fetchers,\n    )\n    try:\n        current_migrator.records_dumploader_cls.create(recorddump)\n        db.session.commit()\n    except Exception:\n        db.session.rollback()\n        raise", "response": "Migrate a record from a migration dump."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimports config var import path or use default value.", "response": "def config_imp_or_default(app, config_var_imp, default):\n    \"\"\"Import config var import path or use default value.\"\"\"\n    imp = app.config.get(config_var_imp)\n    return import_string(imp) if imp else default"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init_app(self, app):\n        self.init_config(app.config)\n        state = _InvenioMigratorState(app)\n        app.extensions['invenio-migrator'] = state\n        app.cli.add_command(dumps)\n        return state", "response": "Initialize the Flask application."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump(obj, from_date, with_json=True, latest_only=False, **kwargs):\n    return dict(name=obj.name,\n                description=obj.description,\n                website=obj.website,\n                user_id=obj.user_id,\n                client_id=obj.client_id,\n                client_secret=obj.client_secret,\n                is_confidential=obj.is_confidential,\n                is_internal=obj.is_internal,\n                _redirect_uris=obj._redirect_uris,\n                _default_scopes=obj._default_scopes)", "response": "Dump the oauth2server Client object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting user accounts Invenio 1.", "response": "def _get_users_invenio12(*args, **kwargs):\n    \"\"\"Get user accounts Invenio 1.\"\"\"\n    from invenio.dbquery import run_sql, deserialize_via_marshal\n    User = namedtuple('User', [\n        'id', 'email', 'password', 'password_salt', 'note', 'full_name',\n        'settings', 'nickname', 'last_login'\n    ])\n    users = run_sql(\n        'SELECT id, email, password, note, settings, nickname, last_login'\n        ' FROM user',\n        run_on_slave=True)\n    return len(users), [\n        User(\n            id=user[0],\n            email=user[1],\n            password=user[2].decode('latin1'),\n            password_salt=user[1],\n            note=user[3],\n            full_name=user[5],\n            settings=deserialize_via_marshal(user[4]) if user[4] else {},\n            # we don't have proper nicknames on Invenio v1\n            nickname='id_{0}'.format(user[0]),\n            last_login=user[6]) for user in users\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_users_invenio2(*args, **kwargs):\n    from invenio.modules.accounts.models import User\n    q = User.query\n    return q.count(), q.all()", "response": "Get user accounts from Invenio 2."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndump the users to a list of dictionaries.", "response": "def dump(u, *args, **kwargs):\n    \"\"\"Dump the users as a list of dictionaries.\n\n    :param u: User to be dumped.\n    :type u: `invenio.modules.accounts.models.User [Invenio2.x]` or namedtuple.\n    :returns: User serialized to dictionary.\n    :rtype: dict\n    \"\"\"\n    return dict(\n        id=u.id,\n        email=u.email,\n        password=u.password,\n        password_salt=u.password_salt,\n        note=u.note,\n        full_name=u.full_name if hasattr(u, 'full_name') else '{0} {1}'.format(\n            u.given_names, u.family_name),\n        settings=u.settings,\n        nickname=u.nickname,\n        last_login=dt2iso_or_empty(u.last_login))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the raw JSON dump of the Deposition.", "response": "def load_deposit(data):\n    \"\"\"Load the raw JSON dump of the Deposition.\n\n    Uses Record API in order to bypass all Deposit-specific initialization,\n    which are to be done after the final stage of deposit migration.\n\n    :param data: Dictionary containing deposition data.\n    :type data: dict\n    \"\"\"\n    from invenio_db import db\n    deposit, dep_pid = create_record_and_pid(data)\n    deposit = create_files_and_sip(deposit, dep_pid)\n    db.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates the deposit record metadata and persistent identifier.", "response": "def create_record_and_pid(data):\n    \"\"\"Create the deposit record metadata and persistent identifier.\n\n    :param data: Raw JSON dump of the deposit.\n    :type data: dict\n    :returns: A deposit object and its pid\n    :rtype: (`invenio_records.api.Record`,\n             `invenio_pidstore.models.PersistentIdentifier`)\n    \"\"\"\n    from invenio_records.api import Record\n    from invenio_pidstore.models import PersistentIdentifier, PIDStatus, \\\n        RecordIdentifier\n\n    deposit = Record.create(data=data)\n\n    created = arrow.get(data['_p']['created']).datetime\n    deposit.model.created = created.replace(tzinfo=None)\n    depid = deposit['_p']['id']\n    pid = PersistentIdentifier.create(\n        pid_type='depid',\n        pid_value=str(depid),\n        object_type='rec',\n        object_uuid=str(deposit.id),\n        status=PIDStatus.REGISTERED\n    )\n    if RecordIdentifier.query.get(int(depid)) is None:\n        RecordIdentifier.insert(int(depid))\n    deposit.commit()\n    return deposit, pid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate deposit Bucket Files and SIPs.", "response": "def create_files_and_sip(deposit, dep_pid):\n    \"\"\"Create deposit Bucket, Files and SIPs.\"\"\"\n    from invenio_pidstore.errors import PIDDoesNotExistError\n    from invenio_pidstore.models import PersistentIdentifier, PIDStatus, \\\n        RecordIdentifier\n    from invenio_sipstore.errors import SIPUserDoesNotExist\n    from invenio_sipstore.models import SIP, RecordSIP, SIPFile\n    from invenio_files_rest.models import Bucket, FileInstance, ObjectVersion\n    from invenio_records_files.models import RecordsBuckets\n    from invenio_db import db\n    buc = Bucket.create()\n    recbuc = RecordsBuckets(record_id=deposit.id, bucket_id=buc.id)\n    db.session.add(recbuc)\n    deposit.setdefault('_deposit', dict())\n    deposit.setdefault('_buckets', dict(deposit=str(buc.id)))\n    deposit.setdefault('_files', list())\n    files = deposit.get('files', [])\n    sips = deposit.get('sips', [])\n\n    # Look for prereserved DOI (and recid)\n    if 'drafts' in deposit:\n        drafts = list(deposit['drafts'].items())\n        if len(drafts) != 1:\n            logger.exception('Deposit {dep_pid} has multiple drafts'.format(\n                dep_pid=dep_pid))\n        if len(drafts) == 1:\n            draft_type, draft = drafts[0]\n            draft_v = draft['values']\n            if 'prereserve_doi' in draft_v:\n                pre_recid = str(draft_v['prereserve_doi']['recid'])\n                pre_doi = str(draft_v['prereserve_doi']['doi'])\n\n                # If pre-reserve info available, try to reserve 'recid'\n                try:\n                    pid = PersistentIdentifier.get(pid_type='recid',\n                                                   pid_value=str(pre_recid))\n                except PIDDoesNotExistError:\n                    # Reserve recid\n                    pid = PersistentIdentifier.create(\n                        pid_type='recid',\n                        pid_value=str(pre_recid),\n                        object_type='rec',\n                        status=PIDStatus.RESERVED\n                    )\n\n                # If pre-reserve info available, try to reserve 'doi'\n                try:\n                    pid = PersistentIdentifier.get(pid_type='doi',\n                                                   pid_value=str(pre_doi))\n                except PIDDoesNotExistError:\n                    # Reserve DOI\n                    pid = PersistentIdentifier.create(\n                        pid_type='doi',\n                        pid_value=str(pre_doi),\n                        object_type='rec',\n                        status=PIDStatus.RESERVED\n                    )\n\n                if RecordIdentifier.query.get(int(pre_recid)) is None:\n                    RecordIdentifier.insert(int(pre_recid))\n\n    # Store the path -> FileInstance mappings for SIPFile creation later\n    dep_file_instances = list()\n\n    for file_ in files:\n        size = file_['size']\n        key = file_['name']\n        # Warning: Assumes all checksums are MD5!\n        checksum = 'md5:{0}'.format(file_['checksum'])\n        fi = FileInstance.create()\n        fi.set_uri(file_['path'], size, checksum)\n        ov = ObjectVersion.create(buc, key, _file_id=fi.id)\n        ext = splitext(ov.key)[1].lower()\n        if ext.startswith('.'):\n            ext = ext[1:]\n        file_meta = dict(\n            bucket=str(ov.bucket.id),\n            key=ov.key,\n            checksum=ov.file.checksum,\n            size=ov.file.size,\n            version_id=str(ov.version_id),\n            type=ext,\n        )\n        deposit['_files'].append(file_meta)\n        dep_file_instances.append((file_['path'], fi))\n\n    # Get a recid from SIP information\n    recid = None\n    if sips:\n        recids = [int(sip['metadata']['recid']) for sip in sips]\n        if len(set(recids)) > 1:\n            logger.error('Multiple recids ({recids}) found in deposit {depid}'\n                         ' does not exists.'.format(recids=recids,\n                                                    depid=dep_pid.pid_value))\n            raise DepositMultipleRecids(dep_pid.pid_value, list(set(recids)))\n        elif recids:  # If only one recid\n            recid = recids[0]\n\n    for idx, sip in enumerate(sips):\n        agent = None\n        user_id = None\n        if sip['agents']:\n            agent = dict(\n                ip_address=empty_str_if_none(\n                    sip['agents'][0].get('ip_address', \"\")),\n                email=empty_str_if_none(\n                    sip['agents'][0].get('email_address', \"\")),\n            )\n            user_id = sip['agents'][0]['user_id']\n        if user_id == 0:\n            user_id = None\n        content = sip['package']\n        sip_format = 'marcxml'\n        try:\n            sip = SIP.create(sip_format,\n                             content,\n                             user_id=user_id,\n                             agent=agent)\n        except SIPUserDoesNotExist:\n            logger.exception('User ID {user_id} referred in deposit {depid} '\n                             'does not exists.'.format(\n                                 user_id=user_id, depid=dep_pid.pid_value))\n            sip = SIP.create(sip_format,\n                             content,\n                             agent=agent)\n\n        # Attach recid to SIP\n        if recid:\n            try:\n                pid = PersistentIdentifier.get(pid_type='recid',\n                                               pid_value=str(recid))\n                record_sip = RecordSIP(sip_id=sip.id, pid_id=pid.id)\n                db.session.add(record_sip)\n            except PIDDoesNotExistError:\n                logger.exception('Record {recid} referred in '\n                                 'Deposit {depid} does not exists.'.format(\n                                     recid=recid, depid=dep_pid.pid_value))\n                if deposit['_p']['submitted'] is True:\n                    logger.exception('Pair {recid}/{depid} was submitted,'\n                                     ' (should it be unpublished?).'.format(\n                                         recid=recid, depid=dep_pid.pid_value))\n                else:\n                    msg = 'Pair {recid}/{depid} was not submitted.'.format(\n                        recid=recid, depid=dep_pid.pid_value)\n                    logger.exception(msg)\n\n                # Reserve recid\n                pid = PersistentIdentifier.create(\n                    pid_type='recid',\n                    pid_value=str(recid),\n                    object_type='rec',\n                    status=PIDStatus.RESERVED\n                )\n\n                if RecordIdentifier.query.get(int(recid)) is None:\n                    RecordIdentifier.insert(int(recid))\n        if idx == 0:\n            for fp, fi in dep_file_instances:\n                sipf = SIPFile(sip_id=sip.id, filepath=fp, file_id=fi.id)\n                db.session.add(sipf)\n    deposit.commit()\n    return deposit"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndumps the community object as a dictionary.", "response": "def dump(c, from_date, with_json=True, latest_only=False, **kwargs):\n    \"\"\"Dump the community object as dictionary.\n\n    :param c: Community to be dumped.\n    :type c: `invenio.modules.communities.models.Community`\n    :returns: Community serialized to dictionary.\n    :rtype: dict\n    \"\"\"\n    return dict(id=c.id,\n                id_user=c.id_user,\n                title=c.title,\n                description=c.description,\n                page=c.page,\n                curation_policy=c.curation_policy,\n                last_record_accepted=dt2iso_or_empty(c.last_record_accepted),\n                logo_ext=c.logo_ext,\n                logo_url=c.logo_url,\n                ranking=c.ranking,\n                fixed_points=c.fixed_points,\n                created=c.created.isoformat(),\n                last_modified=c.last_modified.isoformat(),\n                id_collection_provisional=c.id_collection_provisional,\n                id_oairepository=c.id_oairepository,\n                id_collection=c.id_collection)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a single record into the database.", "response": "def _loadrecord(record_dump, source_type, eager=False):\n    \"\"\"Load a single record into the database.\n\n    :param record_dump: Record dump.\n    :type record_dump: dict\n    :param source_type: 'json' or 'marcxml'\n    :param eager: If ``True`` execute the task synchronously.\n    \"\"\"\n    if eager:\n        import_record.s(record_dump, source_type=source_type).apply(throw=True)\n    elif current_migrator.records_post_task:\n        chain(\n            import_record.s(record_dump, source_type=source_type),\n            current_migrator.records_post_task.s()\n        )()\n    else:\n        import_record.delay(record_dump, source_type=source_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads records migration dump.", "response": "def loadrecords(sources, source_type, recid):\n    \"\"\"Load records migration dump.\"\"\"\n    # Load all record dumps up-front and find the specific JSON\n    if recid is not None:\n        for source in sources:\n            records = json.load(source)\n            for item in records:\n                if str(item['recid']) == str(recid):\n                    _loadrecord(item, source_type, eager=True)\n                    click.echo(\"Record '{recid}' loaded.\".format(recid=recid))\n                    return\n        click.echo(\"Record '{recid}' not found.\".format(recid=recid))\n    else:\n        for idx, source in enumerate(sources, 1):\n            click.echo('Loading dump {0} of {1} ({2})'.format(\n                idx, len(sources), source.name))\n            data = json.load(source)\n            with click.progressbar(data) as records:\n                for item in records:\n                    _loadrecord(item, source_type)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninspect records in a migration dump.", "response": "def inspectrecords(sources, recid, entity=None):\n    \"\"\"Inspect records in a migration dump.\"\"\"\n    for idx, source in enumerate(sources, 1):\n        click.echo('Loading dump {0} of {1} ({2})'.format(idx, len(sources),\n                                                          source.name))\n        data = json.load(source)\n\n        # Just print record identifiers if none are selected.\n        if not recid:\n            click.secho('Record identifiers', fg='green')\n            total = 0\n            for r in (d['recid'] for d in data):\n                click.echo(r)\n                total += 1\n            click.echo('{0} records found in dump.'.format(total))\n            return\n\n        data = list(filter(lambda d: d['recid'] == recid, data))\n\n        if not data:\n            click.secho(\"Record not found.\", fg='yellow')\n            return\n\n        for record in data:\n            if entity is None:\n                click.echo(json.dumps(record, indent=2))\n            if entity == 'files':\n                click.secho('Files', fg='green')\n                click.echo(\n                    json.dumps(record['files'], indent=2))\n\n            if entity == 'json':\n                click.secho('Records (JSON)', fg='green')\n                for revision in record['record']:\n                    click.secho('Revision {0}'.format(\n                        revision['modification_datetime']), fg='yellow')\n                    click.echo(json.dumps(revision['json'], indent=2))\n\n            if entity == 'marcxml':\n                click.secho('Records (MARCXML)', fg='green')\n                for revision in record['record']:\n                    click.secho(\n                        'Revision {0}'.format(revision['marcxml']),\n                        fg='yellow')\n                    click.echo(revision)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a simple object from a list of files.", "response": "def loadcommon(sources, load_task, asynchronous=True, predicate=None,\n               task_args=None, task_kwargs=None):\n    \"\"\"Common helper function for load simple objects.\n\n    .. note::\n\n      Keyword arguments ``task_args`` and ``task_kwargs`` are passed to the\n      ``load_task`` function as ``*task_args`` and ``**task_kwargs``.\n\n    .. note::\n\n      The `predicate` argument is used as a predicate function to load only\n      a *single* item from across all dumps (this CLI function will return\n      after loading the item). This is primarily used for debugging of\n      the *dirty* data within the dump. The `predicate` should be a function\n      with a signature ``f(dict) -> bool``, i.e. taking a single parameter\n      (an item from the dump) and return ``True`` if the item\n      should be loaded. See the ``loaddeposit`` for a concrete example.\n\n    :param sources: JSON source files with dumps\n    :type sources: list of str (filepaths)\n    :param load_task: Shared task which loads the dump.\n    :type load_task: function\n    :param asynchronous: Flag for serial or asynchronous execution of the task.\n    :type asynchronous: bool\n    :param predicate: Predicate for selecting only a single item from the dump.\n    :type predicate: function\n    :param task_args: positional arguments passed to the task.\n    :type task_args: tuple\n    :param task_kwargs: named arguments passed to the task.\n    :type task_kwargs: dict\n    \"\"\"\n    # resolve the defaults for task_args and task_kwargs\n    task_args = tuple() if task_args is None else task_args\n    task_kwargs = dict() if task_kwargs is None else task_kwargs\n    click.echo('Loading dumps started.')\n    for idx, source in enumerate(sources, 1):\n        click.echo('Opening dump file {0} of {1} ({2})'.format(\n            idx, len(sources), source.name))\n        data = json.load(source)\n        with click.progressbar(data) as data_bar:\n            for d in data_bar:\n                # Load a single item from the dump\n                if predicate is not None:\n                    if predicate(d):\n                        load_task.s(d, *task_args, **task_kwargs).apply(\n                            throw=True)\n                        click.echo(\"Loaded a single record.\")\n                        return\n                # Load dumps normally\n                else:\n                    if asynchronous:\n                        load_task.s(d, *task_args, **task_kwargs).apply_async()\n                    else:\n                        load_task.s(d, *task_args, **task_kwargs).apply(\n                            throw=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef loadcommunities(sources, logos_dir):\n    from invenio_migrator.tasks.communities import load_community\n    loadcommon(sources, load_community, task_args=(logos_dir, ))", "response": "Load communities from sources."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads users from sources.", "response": "def loadusers(sources):\n    \"\"\"Load users.\"\"\"\n    from .tasks.users import load_user\n    # Cannot be executed asynchronously due to duplicate emails and usernames\n    # which can create a racing condition.\n    loadcommon(sources, load_user, asynchronous=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload the deposit file for the specified depid.", "response": "def loaddeposit(sources, depid):\n    \"\"\"Load deposit.\n\n    Usage:\n        invenio dumps loaddeposit ~/data/deposit_dump_*.json\n        invenio dumps loaddeposit -d 12345 ~/data/deposit_dump_*.json\n    \"\"\"\n    from .tasks.deposit import load_deposit\n    if depid is not None:\n        def pred(dep):\n            return int(dep[\"_p\"][\"id\"]) == depid\n        loadcommon(sources, load_deposit, predicate=pred, asynchronous=False)\n    else:\n        loadcommon(sources, load_deposit)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn profiler statistics. :param str sort: dictionary key to sort by :param int|None count: the number of results to return, None returns all results. :param bool strip_dirs: if True strip the directory, otherwise return the full path", "response": "def get_profiler_statistics(sort=\"cum_time\", count=20, strip_dirs=True):\n    \"\"\"Return profiler statistics.\n\n    :param str sort: dictionary key to sort by\n    :param int|None count: the number of results to return, None returns all results.\n    :param bool strip_dirs: if True strip the directory, otherwise return the full path\n    \"\"\"\n    json_stats = []\n    pstats = yappi.convert2pstats(yappi.get_func_stats())\n    if strip_dirs:\n        pstats.strip_dirs()\n\n    for func, func_stat in pstats.stats.iteritems():\n        path, line, func_name = func\n        cc, num_calls, total_time, cum_time, callers = func_stat\n        json_stats.append({\n            \"path\": path,\n            \"line\": line,\n            \"func_name\": func_name,\n            \"num_calls\": num_calls,\n            \"total_time\": total_time,\n            \"total_time_per_call\": total_time/num_calls if total_time else 0,\n            \"cum_time\": cum_time,\n            \"cum_time_per_call\": cum_time/num_calls if cum_time else 0\n        })\n\n    return sorted(json_stats, key=itemgetter(sort), reverse=True)[:count]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main(port=8888):\n    import tornado.ioloop\n\n    routes = [] + TornadoProfiler().get_routes()\n    app = tornado.web.Application(routes)\n    app.listen(port)\n    tornado.ioloop.IOLoop.current().start()", "response": "Run as sample test server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self):\n\n        sort = self.get_argument('sort', 'cum_time')\n        count = self.get_argument('count', 20)\n        strip_dirs = self.get_argument('strip_dirs', True)\n        error = ''\n        sorts = ('num_calls', 'cum_time', 'total_time',\n                 'cum_time_per_call', 'total_time_per_call')\n        if sort not in sorts:\n            error += \"Invalid `sort` '%s', must be in %s.\" % (sort, sorts)\n        try:\n            count = int(count)\n        except (ValueError, TypeError):\n            error += \"Can't cast `count` '%s' to int.\" % count\n        if count <= 0:\n            count = None\n        strip_dirs = str(strip_dirs).lower() not in ('false', 'no', 'none',\n                                                     'null', '0', '')\n        if error:\n            self.write({'error': error})\n            self.set_status(400)\n            self.finish()\n            return\n\n        try:\n            statistics = get_profiler_statistics(sort, count, strip_dirs)\n            self.write({'statistics': statistics})\n            self.set_status(200)\n        except TypeError:\n            logger.exception('Error while retrieving profiler statistics')\n            self.write({'error': 'No stats available. Start and stop the profiler before trying to retrieve stats.'})\n            self.set_status(404)\n\n        self.finish()", "response": "Get current profiler statistics."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef post(self):\n        if is_profiler_running():\n            self.set_status(201)\n            self.finish()\n            return\n\n        start_profiling()\n        self.set_status(201)\n        self.finish()", "response": "Start a new profiler."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndumping current profiler statistics into a file.", "response": "def post(self):\n        \"\"\"Dump current profiler statistics into a file.\"\"\"\n        filename = self.get_argument('filename', 'dump.prof')\n        CProfileWrapper.profiler.dump_stats(filename)\n        self.finish()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self):\n        CProfileWrapper.profiler.print_stats()\n        s = StringIO.StringIO()\n        sortby = 'cumulative'\n        ps = pstats.Stats(CProfileWrapper.profiler, stream=s).sort_stats(sortby)\n        ps.print_stats()\n        self.set_status(200)\n        self.write(s.getvalue())\n        self.finish()", "response": "Return current profiler statistics."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef post(self):\n        CProfileWrapper.profiler = cProfile.Profile()\n        CProfileWrapper.profiler.enable()\n        self.running = True\n        self.set_status(201)\n        self.finish()", "response": "Start a new profiler."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self):\n        self.write({\"running\": self.running})\n        self.set_status(200)\n        self.finish()", "response": "Check if the profiler is running."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef disable_timestamp(method):\n    @wraps(method)\n    def wrapper(*args, **kwargs):\n        result = None\n        with correct_date():\n            result = method(*args, **kwargs)\n        return result\n    return wrapper", "response": "Disable timestamp update per method."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_user(data):\n    from invenio_accounts.models import User\n    from invenio_userprofiles.api import UserProfile\n    email = data['email'].strip()\n    if User.query.filter_by(email=email).count() > 0:\n        raise UserEmailExistsError(\n            \"User email '{email}' already exists.\".format(email=email))\n\n    last_login = None\n    if data['last_login']:\n        last_login = arrow.get(data['last_login']).datetime\n\n    confirmed_at = None\n    if data['note'] == '1':\n        confirmed_at = datetime.utcnow()\n\n    salt = data['password_salt']\n    checksum = data['password']\n    if not checksum:\n        new_password = None\n    # Test if password hash is in Modular Crypt Format\n    elif checksum.startswith('$'):\n        new_password = checksum\n    else:\n        new_password = str.join('$', ['', u'invenio-aes', salt, checksum])\n    with db.session.begin_nested():\n        obj = User(\n            id=data['id'],\n            password=new_password,\n            email=email,\n            confirmed_at=confirmed_at,\n            last_login_at=last_login,\n            active=(data['note'] != '0'),\n        )\n        db.session.add(obj)\n\n    nickname = data['nickname'].strip()\n    overwritten_username = ('username' in data and 'displayname' in data)\n    # NOTE: 'username' and 'displayname' will exist in data dump only\n    # if it was inserted there after dumping. It normally should not come from\n    # Invenio 1.x or 2.x data dumper script. In such case, those values will\n    # have precedence over the 'nickname' field.\n    if nickname or overwritten_username:\n        p = UserProfile(user=obj)\n        p.full_name = data.get('full_name', '').strip()\n\n        if overwritten_username:\n            p._username = data['username'].lower()\n            p._displayname = data['displayname']\n        elif nickname:\n            if UserProfile.query.filter(\n                    UserProfile._username == nickname.lower()).count() > 0:\n                raise UserUsernameExistsError(\n                    \"Username '{username}' already exists.\".format(\n                        username=nickname))\n            try:\n                p.username = nickname\n            except ValueError:\n                current_app.logger.warn(\n                    u'Invalid username {0} for user_id {1}'.format(\n                        nickname, data['id']))\n                p._username = nickname.lower()\n                p._displayname = nickname\n\n        db.session.add(p)\n    db.session.commit()", "response": "Load user from data dump."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calc_translations_parallel(images):\n    w = Parallel(n_jobs=_CPUS)\n    res = w(delayed(images.translation)(img) for img in images)\n\n    # save results to Image object, as Parallel is spawning another process\n    for i,translation in enumerate(res):\n        images[i].translation = translation\n\n    return np.array(res)", "response": "Calculate image translations in parallel."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstitches regular spaced images.", "response": "def stitch(images):\n    \"\"\"Stitch regular spaced images.\n\n    Parameters\n    ----------\n    images : ImageCollection or list of tuple(path, row, column)\n        Each image-tuple should contain path, row and column. Row 0,\n        column 0 is top left image.\n\n        Example:\n        >>> images = [('1.png', 0, 0), ('2.png', 0, 1)]\n\n    Returns\n    -------\n    tuple (stitched, offset)\n        Stitched image and registered offset (y, x).\n    \"\"\"\n    if type(images) != ImageCollection:\n        images = ImageCollection(images)\n    calc_translations_parallel(images)\n    _translation_warn(images)\n\n    yoffset, xoffset = images.median_translation()\n\n    if xoffset != yoffset:\n        warn('yoffset != xoffset: %s != %s' % (yoffset, xoffset))\n\n    # assume all images have the same shape\n    y, x = imread(images[0].path).shape\n    height = y*len(images.rows) + yoffset*(len(images.rows)-1)\n    width = x*len(images.cols) + xoffset*(len(images.cols)-1)\n\n    # last dimension is number of images on top of each other\n    merged = np.zeros((height, width, 2), dtype=np.int)\n    for image in images:\n        r, c = image.row, image.col\n        mask = _merge_slice(r, c, y, x, yoffset, xoffset)\n        # last dim is used for averaging the seam\n        img = _add_ones_dim(imread(image.path))\n        merged[mask] += img\n\n    # average seam, possible improvement: use gradient\n    merged[..., 0] /= merged[..., 1]\n\n    return merged[..., 0].astype(np.uint8), (yoffset, xoffset)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a dimensions with ones to array.", "response": "def _add_ones_dim(arr):\n    \"Adds a dimensions with ones to array.\"\n    arr = arr[..., np.newaxis]\n    return np.concatenate((arr, np.ones_like(arr)), axis=-1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(cls, dump):\n        # If 'record' is not present, just create the PID\n        if not dump.data.get('record'):\n            try:\n                PersistentIdentifier.get(pid_type='recid',\n                                         pid_value=dump.recid)\n            except PIDDoesNotExistError:\n                PersistentIdentifier.create(\n                    'recid', dump.recid,\n                    status=PIDStatus.RESERVED\n                )\n                db.session.commit()\n            return None\n\n        dump.prepare_revisions()\n        dump.prepare_pids()\n        dump.prepare_files()\n\n        # Create or update?\n        existing_files = []\n        if dump.record:\n            existing_files = dump.record.get('_files', [])\n            record = cls.update_record(revisions=dump.revisions,\n                                       created=dump.created,\n                                       record=dump.record)\n            pids = dump.missing_pids\n        else:\n            record = cls.create_record(dump)\n            pids = dump.pids\n\n        if pids:\n            cls.create_pids(record.id, pids)\n\n        if dump.files:\n            cls.create_files(record, dump.files, existing_files)\n\n        # Update files.\n        if dump.is_deleted(record):\n            cls.delete_record(record)\n\n        return record", "response": "Create a new record based on dump."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new record from a dump.", "response": "def create_record(cls, dump):\n        \"\"\"Create a new record from dump.\"\"\"\n        # Reserve record identifier, create record and recid pid in one\n        # operation.\n        timestamp, data = dump.latest\n        record = Record.create(data)\n        record.model.created = dump.created.replace(tzinfo=None)\n        record.model.updated = timestamp.replace(tzinfo=None)\n        RecordIdentifier.insert(dump.recid)\n        PersistentIdentifier.create(\n            pid_type='recid',\n            pid_value=str(dump.recid),\n            object_type='rec',\n            object_uuid=str(record.id),\n            status=PIDStatus.REGISTERED\n        )\n        db.session.commit()\n        return cls.update_record(revisions=dump.rest, record=record,\n                                 created=dump.created)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating an existing record.", "response": "def update_record(cls, revisions, created, record):\n        \"\"\"Update an existing record.\"\"\"\n        for timestamp, revision in revisions:\n            record.model.json = revision\n            record.model.created = created.replace(tzinfo=None)\n            record.model.updated = timestamp.replace(tzinfo=None)\n            db.session.commit()\n        return Record(record.model.json, model=record.model)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_record(cls, record):\n        record.delete()\n        PersistentIdentifier.query.filter_by(\n            object_type='rec', object_uuid=record.id,\n        ).update({PersistentIdentifier.status: PIDStatus.DELETED})\n        cls.delete_buckets(record)\n        db.session.commit()", "response": "Delete a record and its persistent identifiers."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate files. This method is currently limited to a single bucket per record.", "response": "def create_files(cls, record, files, existing_files):\n        \"\"\"Create files.\n\n        This method is currently limited to a single bucket per record.\n        \"\"\"\n        default_bucket = None\n        # Look for bucket id in existing files.\n        for f in existing_files:\n            if 'bucket' in f:\n                default_bucket = f['bucket']\n                break\n\n        # Create a bucket in default location if none is found.\n        if default_bucket is None:\n            b = Bucket.create()\n            BucketTag.create(b, 'record', str(record.id))\n            default_bucket = str(b.id)\n            db.session.commit()\n        else:\n            b = Bucket.get(default_bucket)\n\n        record['_files'] = []\n        for key, meta in files.items():\n            obj = cls.create_file(b, key, meta)\n            ext = splitext(obj.key)[1].lower()\n            if ext.startswith('.'):\n                ext = ext[1:]\n            record['_files'].append(dict(\n                bucket=str(obj.bucket.id),\n                key=obj.key,\n                version_id=str(obj.version_id),\n                size=obj.file.size,\n                checksum=obj.file.checksum,\n                type=ext,\n            ))\n        db.session.add(\n            RecordsBuckets(record_id=record.id, bucket_id=b.id)\n        )\n        record.commit()\n        db.session.commit()\n\n        return [b]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a single file with all versions.", "response": "def create_file(self, bucket, key, file_versions):\n        \"\"\"Create a single file with all versions.\"\"\"\n        objs = []\n        for file_ver in file_versions:\n            f = FileInstance.create().set_uri(\n                file_ver['full_path'],\n                file_ver['size'],\n                'md5:{0}'.format(file_ver['checksum']),\n            )\n            obj = ObjectVersion.create(bucket, key).set_file(f)\n            obj.created = arrow.get(\n                file_ver['creation_date']).datetime.replace(tzinfo=None)\n            objs.append(obj)\n\n        # Set head version\n        db.session.commit()\n        return objs[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfilters persistent identifiers that are missing.", "response": "def missing_pids(self):\n        \"\"\"Filter persistent identifiers.\"\"\"\n        missing = []\n        for p in self.pids:\n            try:\n                PersistentIdentifier.get(p.pid_type, p.pid_value)\n            except PIDDoesNotExistError:\n                missing.append(p)\n        return missing"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepare_files(self):\n        # Prepare files\n        files = {}\n        for f in self.data['files']:\n            k = f['full_name']\n            if k not in files:\n                files[k] = []\n            files[k].append(f)\n\n        # Sort versions\n        for k in files.keys():\n            files[k].sort(key=lambda x: x['version'])\n\n        self.files = files", "response": "Get files from data dump."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if record is deleted.", "response": "def is_deleted(self, record=None):\n        \"\"\"Check if record is deleted.\"\"\"\n        record = record or self.revisions[-1][1]\n        return any(\n            col == 'deleted'\n            for col in record.get('collections', [])\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_community(data, logos_dir):\n    from invenio_communities.models import Community\n    from invenio_communities.utils import save_and_validate_logo\n    logo_ext_washed = logo_ext_wash(data['logo_ext'])\n    c = Community(\n        id=data['id'],\n        id_user=data['id_user'],\n        title=data['title'],\n        description=data['description'],\n        page=data['page'],\n        curation_policy=data['curation_policy'],\n        last_record_accepted=iso2dt_or_none(data['last_record_accepted']),\n        logo_ext=logo_ext_washed,\n        ranking=data['ranking'],\n        fixed_points=data['fixed_points'],\n        created=iso2dt(data['created']),\n        updated=iso2dt(data['last_modified']),\n    )\n    logo_path = join(logos_dir, \"{0}.{1}\".format(c.id, logo_ext_washed))\n    db.session.add(c)\n    if isfile(logo_path):\n        with open(logo_path, 'rb') as fp:\n            save_and_validate_logo(fp, logo_path, c.id)\n    db.session.commit()", "response": "Load community from data dump."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_featured(data):\n    from invenio_communities.models import FeaturedCommunity\n    obj = FeaturedCommunity(id=data['id'],\n                            id_community=data['id_community'],\n                            start_date=iso2dt(data['start_date']))\n    db.session.add(obj)\n    db.session.commit()", "response": "Load community featuring from data dump."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dump(thing, query, from_date, file_prefix, chunk_size, limit, thing_flags):\n    init_app_context()\n\n    file_prefix = file_prefix if file_prefix else '{0}_dump'.format(thing)\n\n    kwargs = dict((f.strip('-').replace('-', '_'), True) for f in thing_flags)\n\n    try:\n        thing_func = collect_things_entry_points()[thing]\n    except KeyError:\n        click.Abort(\n            '{0} is not in the list of available things to migrate: '\n            '{1}'.format(thing, collect_things_entry_points()))\n\n    click.echo(\"Querying {0}...\".format(thing))\n    count, items = thing_func.get(query, from_date, limit=limit, **kwargs)\n\n    progress_i = 0  # Progress bar counter\n    click.echo(\"Dumping {0}...\".format(thing))\n    with click.progressbar(length=count) as bar:\n        for i, chunk_ids in enumerate(grouper(items, chunk_size)):\n            with open('{0}_{1}.json'.format(file_prefix, i), 'w') as fp:\n                fp.write(\"[\\n\")\n                for _id in chunk_ids:\n                    try:\n                        json.dump(\n                            thing_func.dump(_id, from_date, **kwargs),\n                            fp,\n                            default=set_serializer\n                        )\n                        fp.write(\",\")\n                    except Exception as e:\n                        click.secho(\"Failed dump {0} {1} ({2})\".format(\n                            thing, _id, e.message), fg='red')\n                    progress_i += 1\n                    bar.update(progress_i)\n\n                # Strip trailing comma.\n                fp.seek(fp.tell()-1)\n                fp.write(\"\\n]\")", "response": "Dump data from Invenio legacy."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check(thing):\n    init_app_context()\n\n    try:\n        thing_func = collect_things_entry_points()[thing]\n    except KeyError:\n        click.Abort(\n            '{0} is not in the list of available things to migrate: '\n            '{1}'.format(thing, collect_things_entry_points()))\n\n    click.echo(\"Querying {0}...\".format(thing))\n    count, items = thing_func.get_check()\n\n    i = 0\n    click.echo(\"Checking {0}...\".format(thing))\n    with click.progressbar(length=count) as bar:\n        for _id in items:\n            thing_func.check(_id)\n            i += 1\n            bar.update(i)", "response": "Check data in Invenio legacy."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef registerEventHandlers(self):\n        self.peng.registerEventHandler(\"on_mouse_press\",self.on_mouse_press)\n        self.peng.registerEventHandler(\"on_mouse_release\",self.on_mouse_release)\n        self.peng.registerEventHandler(\"on_mouse_drag\",self.on_mouse_drag)\n        self.peng.registerEventHandler(\"on_mouse_motion\",self.on_mouse_motion)\n        self.peng.registerEventHandler(\"on_resize\",self.on_resize)", "response": "Registers event handlers used by this widget."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a watchlist of the size of the current item.", "response": "def size(self):\n        \"\"\"\n        Similar to :py:attr:`pos` but for the size instead.\n        \"\"\"\n        if isinstance(self._size,list) or isinstance(self._size,tuple):\n            s = self._size\n        elif callable(self._size):\n            w,h = self.submenu.size[:]\n            s = self._size(w,h)\n        else:\n            raise TypeError(\"Invalid size type\")\n        \n        s = s[:]\n        \n        if s[0]==-1:\n            s[0]=self.getMinSize()[0]\n        if s[1]==-1:\n            s[1]=self.getMinSize()[1]\n    \n        # Prevents crashes with negative size\n        s = [max(s[0],0),max(s[1],0)]\n        return _WatchingList(s,self._wlredraw_size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(self):\n        # TODO: fix memory leak upon widget deletion\n        del self.bg.widget\n        del self.bg\n        \n        #self.clickable=False\n        \n        del self._pos\n        del self._size\n        \n        self.actions = {}\n        \n        for e_type,e_handlers in self.peng.eventHandlers.items():\n            if True or e_type in eh:\n                to_del = []\n                for e_handler in e_handlers:\n                    # Weird workaround due to implementation details of WeakMethod\n                    if isinstance(e_handler,weakref.ref): \n                        if super(weakref.WeakMethod,e_handler).__call__() is self: \n                            to_del.append(e_handler) \n                    elif e_handler is self: \n                        to_del.append(e_handler)\n                for d in to_del:\n                    try:\n                        #print(\"Deleting handler %s of type %s\"%(d,e_type))\n                        del e_handlers[e_handlers.index(d)]\n                    except Exception:\n                        #print(\"Could not delete handler %s, memory leak may occur\"%d)\n                        import traceback;traceback.print_exc()", "response": "Deletes all resources of this widget that require manual cleanup."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_redraw(self):\n        if self.bg is not None:\n            if not self.bg.initialized:\n                self.bg.init_bg()\n                self.bg.initialized=True\n            self.bg.redraw_bg()\n        super(Widget,self).on_redraw()", "response": "Called by the GUI when the color is changed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef calcSphereCoordinates(pos,radius,rot):\n    # Input angles should be in degrees, as in the rest of the game\n    # E.g. phi=inclination and theta=azimuth\n    \n    # phi is yrad\n    #      Look from above         \n    #(Z goes positive towards you) \n    #                              \n    #            Y-  Z-            \n    #            |  /              \n    #            | / \"far\"         \n    #            |/                \n    #   X- ------+-------> X+      \n    #           /| yrad |          \n    #   \"near\" / |<-----+          \n    #         /  |  \"polar angle\"  \n    #        Z+  Y+                \n    \n    # theta is xrad\n    #      Look from above         \n    #(Z goes positive towards you) \n    #                              \n    #            Y-  Z-            \n    #            |  /              \n    #            | / \"far\"         \n    #            |/                \n    #   X- ------+-------> X+      \n    #           /| xrad |          \n    #   \"near\" /<-------+          \n    #         /  |  \"azimuth angle\"\n    #        Z+  Y+                \n\n    # Based on http://stackoverflow.com/questions/39647735/calculation-of-spherical-coordinates\n    # https://en.wikipedia.org/wiki/Spherical_coordinate_system\n    # http://stackoverflow.com/questions/25404613/converting-spherical-coordinates-to-cartesian?rq=1\n    \n    phi,theta = rot\n    phi+=90 # very important, took me four days of head-scratching to figure out\n    phi,theta = math.radians(phi),math.radians(theta)\n    \n    x = pos[0]+radius * math.sin(phi) * math.cos(theta)\n    y = pos[1]+radius * math.sin(phi) * math.sin(theta)\n    z = pos[2]+radius * math.cos(phi)\n    return x,y,z", "response": "Calculates the Cartesian coordinates of the spherical coordinates of the input."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef v_magnitude(v):\n    return math.sqrt(sum(v[i]*v[i] for i in range(len(v))))", "response": "Simple vector helper function returning the length of a vector."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef v_normalize(v):\n    vmag = v_magnitude(v)\n    return [ v[i]/vmag  for i in range(len(v)) ]", "response": "Normalizes the given vector."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transformTexCoords(self,data,texcoords,dims=2):\n        assert dims==2 # TODO\n        \n        out = []\n        \n        origcoords = self.tex_coords\n        min_u,min_v = origcoords[0],origcoords[1]\n        max_u,max_v = origcoords[6],origcoords[7]\n        \n        diff_u,diff_v = max_u-min_u, max_v-min_v\n\n        itexcoords = iter(texcoords)\n        for u,v in zip(itexcoords,itexcoords): # Based on http://stackoverflow.com/a/5389547/3490549\n            out_u = min_u+(diff_u*u)\n            out_v = min_v+(diff_v*v)\n            out.extend((out_u,out_v,0))\n        \n        return out", "response": "Transforms the given texture coordinates using the internal texture coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nensure that the bone data for this entity is properly initialized.", "response": "def ensureBones(self,data):\n        \"\"\"\n        Helper method ensuring per-entity bone data has been properly initialized.\n        \n        Should be called at the start of every method accessing per-entity data.\n        \n        ``data`` is the entity to check in dictionary form.\n        \"\"\"\n        if \"_bones\" not in data:\n            data[\"_bones\"]={}\n        if self.name not in data[\"_bones\"]:\n            data[\"_bones\"][self.name]={\"rot\":self.start_rot[:],\"length\":self.blength}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setRot(self,data,rot):\n        self.ensureBones(data)\n        rot = rot[0]%360,max(-90, min(90, rot[1]))\n        data[\"_bones\"][self.name][\"rot\"]=rot", "response": "Sets the rotation of this bone on the given entity."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setLength(self,data,blength):\n        self.ensureBones(data)\n        data[\"_bones\"][self.name][\"length\"]=blength", "response": "Sets the length of this bone on the given entity."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the parent of this bone for all entities.", "response": "def setParent(self,parent):\n        \"\"\"\n        Sets the parent of this bone for all entities.\n        \n        Note that this method must be called before many other methods to ensure internal state has been initialized.\n        \n        This method also registers this bone as a child of its parent.\n        \"\"\"\n        self.parent = parent\n        self.parent.child_bones[self.name]=self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setRotate(self,data):\n        self.parent.setRotate(data)\n        glPushMatrix()\n        x,y = self.getRot(data)\n        pivot = self.getPivotPoint(data)\n        px,py,pz = pivot\n\n        #ppx,ppy,ppz = self.parent.getPivotPoint(data)\n        #rot_vec = px-ppx,py-ppy,pz-ppz\n        #print([px,py,pz],[ppx,ppy,ppz],rot_vec,[x,y],self.getLength(data))\n        #norm = v_normalize(rot_vec,self.name) if v_magnitude(rot_vec)==0 else [0,1,0] # prevents a zero divison error\n        normx = [0,1,0] # currently fixed to the up vector, should be changed in the future for proper rotation that is not along the y or z axis\n        normy = [0,0,1]\n        \n        #offset = -px,-py,-pz\n        \n        glTranslatef(px,py,pz)#-offset[0],-offset[1],-offset[2])\n        glRotatef(x-self.start_rot[0], normx[0],normx[1],normx[2])\n        glRotatef(y-self.start_rot[1], normy[0],normy[1],normy[2])\n        glTranslatef(-px,-py,-pz)#offset[0],offset[1],offset[2])", "response": "Sets the rotation of the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the point this bone pivots around on the given entity.", "response": "def getPivotPoint(self,data):\n        \"\"\"\n        Returns the point this bone pivots around on the given entity.\n        \n        This method works recursively by calling its parent and then adding its own offset.\n        \n        The resulting coordinate is relative to the entity, not the world.\n        \"\"\"\n        ppos = self.parent.getPivotPoint(data)\n        rot = self.parent.getRot(data)\n        length = self.parent.getLength(data)\n        out = calcSphereCoordinates(ppos,length,rot)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getVertices(self,data):\n        return self.bone.transformVertices(data,self.vertices,self.dims)", "response": "Returns the vertices of this region already transformed and ready - to - use."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getTexCoords(self,data):\n        return self.material.transformTexCoords(data,self.tex_coords,self.tex_dims)", "response": "Returns the texture coordinates of the region if any."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting animation on a specific actor.", "response": "def startAnimation(self,data,jumptype):\n        \"\"\"\n        Callback that is called to initialize this animation on a specific actor.\n        \n        Internally sets the ``_anidata`` key of the given dict ``data``\\ .\n        \n        ``jumptype`` is either ``jump`` or ``animate`` to define how to switch to this animation.\n        \"\"\"\n        data[\"_anidata\"]={}\n        adata = data[\"_anidata\"]\n        \n        adata[\"keyframe\"]=0\n        adata[\"last_tick\"]=time.time()\n        adata[\"jumptype\"]=jumptype\n        adata[\"phase\"]=\"transition\""}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls by the animation thread when an entity is ticked.", "response": "def tickEntity(self,data):\n        \"\"\"\n        Callback that should be called regularly to update the animation.\n        \n        It is recommended to call this method about 60 times a second for smooth animations. Irregular calling of this method will be automatically adjusted.\n        \n        This method sets all the bones in the given actor to the next state of the animation.\n        \n        Note that :py:meth:`startAnimation()` must have been called before calling this method.\n        \"\"\"\n        adata = data[\"_anidata\"]\n        \n        if adata.get(\"anitype\",self.name)!=self.name:\n            return # incorrectly called\n        \n        dt = time.time()-adata.get(\"last_tick\",time.time())\n        adata[\"last_tick\"]=time.time()\n        \n        if adata.get(\"phase\",\"transition\")==\"transition\":\n            # If transitioning to this animation\n            if adata.get(\"jumptype\",self.default_jt)==\"jump\":\n                # Jumping to the animation, e.g. set all bones to the start frame\n                for bone,dat in self.start_frame.get(\"bones\",{}).items():\n                    if \"rot\" in dat:\n                        self.bones[bone].setRot(data,dat[\"rot\"])\n                    if \"length\" in dat:\n                        self.bones[bone].setLength(data,dat[\"length\"])\n                adata[\"phase\"]=\"animation\"\n                if self.atype==\"keyframes\":\n                    adata[\"from_frame\"]=self.start_frame.get(\"frame\",0)\n            elif adata.get(\"jumptype\",self.default_jt)==\"animate\":\n                raise NotImplementedError(\"Animation update phase transition type animate not yet implemented\")\n                \n                # Not yet working\n                if \"transition_frame\" not in adata:\n                    adata[\"transition_frame\"] = 0\n                tlen = self.anidata.get(\"transition_length\",self.anidata.get(\"length\",60)/3)\n                tspeed = self.anidata.get(\"transition_speed\",self.anidata.get(\"keyframespersecond\",60))\n                \n                framediff=int(dt/(1./tspeed)) # Number of frames that have passed since the last update\n                overhang = dt-(framediff*(1./tspeed)) # time that has passed but is not enough for a full frame\n                adata[\"last_tick\"]-=overhang # causes the next frame to include the overhang from this frame\n                if framediff == 0:\n                    return # optimization that saves time \n                \n                frame1 = adata[\"transition_frame\"]\n                adata[\"transition_frame\"]+=framediff\n                if adata[\"transition_frame\"]>tlen:\n                    adata[\"phase\"]=\"animation\"\n                    if self.atype==\"keyframes\":\n                        adata[\"from_frame\"]=self.start_frame.get(\"frame\",0)\n                    return\n                frame2 = adata[\"transition_frame\"]\n                \n                if \"frombones\" not in adata:\n                    frombones = {}\n                    for bname,bone in self.bones.items():\n                        frombones[bname]={\"rot\":bone.getRot(data),\"length\":bone.getLength(data)}\n                    adata[\"frombones\"] = frombones\n                if \"tobones\" not in adata:\n                    tobones = {}\n                    for bname,bone in self.start_frame[\"bones\"].items():\n                        tobones[bname]=bone\n                    adata[\"tobones\"] = tobones\n                \n                frombones = adata[\"frombones\"]\n                tobones = adata[\"tobones\"]\n                \n                from_frame = 0\n                to_frame = tlen\n                \n                for bname,bone in self.bones.items():\n                    # rot\n                    if bname not in frombones or bname not in tobones:\n                        continue\n                    \n                    from_rot = frombones[bname][\"rot\"]\n                    to_rot = tobones[bname][\"rot\"]\n                    \n                    from_x,from_y=from_rot\n                    to_x,to_y=to_rot\n                    \n                    delta_per_frame_x = (to_x-from_x)/(to_frame-from_frame)\n                    delta_per_frame_y = (to_y-from_y)/(to_frame-from_frame)\n                    \n                    delta_x = delta_per_frame_x*(frame2-frame1)\n                    delta_y = delta_per_frame_y*(frame2-frame1)\n                    \n                    rot = bone.getRot(data)\n                    new_rot = [rot[0]+delta_x,rot[1]+delta_y]\n                    \n                    bone.setRot(data,new_rot)\n                    \n                    # length\n                    \n                    # Not yet implemented\n                \n        elif adata[\"phase\"]==\"animation\":\n            # If animating\n            if self.atype == \"static\":\n                pass # Should not need any updates as the transition will set the bones\n            elif self.atype == \"keyframes\":\n                framediff=int(dt/(1./self.kps)) # Number of frames that have passed since the last update\n                overhang = dt-(framediff*(1./self.kps)) # time that has passed but is not enough for a full frame\n                adata[\"last_tick\"]-=overhang # causes the next frame to include the overhang from this frame\n                if framediff == 0:\n                    return # optimization that saves time \n                \n                frame1 = adata[\"keyframe\"]\n                adata[\"keyframe\"]+=framediff\n                if adata[\"keyframe\"]>self.anilength:\n                    repeat = True\n                    adata[\"keyframe\"]%=self.anilength\n                else:\n                    repeat = False\n                frame2 = adata[\"keyframe\"]\n                \n                if repeat:\n                    frame1 = frame2\n                    frame2+=1\n                \n                for bname,bone in self.bones.items():\n                    # Rot\n                    if bname in self.rframes_per_bone:\n                        \n                        from_frame = None#adata[\"from_frame\"]\n                        to_frame = None\n                        for framenum,rot in self.rframes_per_bone[bname].items():\n                            if (from_frame is None or framenum>from_frame) and framenum<=frame1:\n                                # from_frame is the largest frame number that is before the starting point\n                                from_frame = framenum\n                            if (to_frame is None or framenum<to_frame) and framenum>=frame2:\n                                # to_frame is the smallest frame number that is after the end point\n                                to_frame = framenum\n                        if from_frame is None or to_frame is None:\n                            raise ValueError(\"Invalid frames for bone %s in animation %s\"%(bname,self.name))\n                        if from_frame==to_frame or repeat:\n                            if self.anidata.get(\"repeat\",\"jump\")==\"jump\":\n                                for b,dat in self.start_frame.get(\"bones\",{}).items():\n                                    if \"rot\" in dat:\n                                        self.bones[b].setRot(data,dat[\"rot\"])\n                                    if \"length\" in dat:\n                                        self.bones[b].setLength(data,dat[\"length\"])\n                            elif self.anidata.get(\"repeat\",\"jump\")==\"animate\":\n                                from_frame = adata[\"to_frame\"]\n                        adata[\"from_frame\"]=from_frame\n                        adata[\"to_frame\"]=to_frame\n                        \n                        from_rot = self.rframes_per_bone[bname][from_frame]\n                        to_rot = self.rframes_per_bone[bname][to_frame]\n                        \n                        from_x,from_y=from_rot\n                        to_x,to_y=to_rot\n                        \n                        if self.anidata.get(\"interpolation\",\"linear\") == \"linear\":\n                            delta_per_frame_x = (to_x-from_x)/(to_frame-from_frame)\n                            delta_per_frame_y = (to_y-from_y)/(to_frame-from_frame)\n                            \n                            delta_x = delta_per_frame_x*(frame2-frame1)\n                            delta_y = delta_per_frame_y*(frame2-frame1)\n                            \n                            rot = bone.getRot(data)\n                            new_rot = [rot[0]+delta_x,rot[1]+delta_y]\n                        elif self.anidata[\"interpolation\"] == \"jump\":\n                            new_rot = to_x,to_y\n                        else:\n                            raise ValueError(\"Invalid interpolation method '%s' for animation %s\"%(self.anidata[\"interpolation\"],self.name))\n                        \n                        bone.setRot(data,new_rot)\n                        \n                    # Length\n                    if bname in self.lframes_per_bone:\n                        # Not yet implemented\n                        pass\n                \n            else:\n                # Should not be possible, but still\n                raise ValueError(\"Invalid animation type %s for animation %s during tick\"%(self.atype,name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_state(self):\n        x,y,z = self.obj.pos\n        glTranslatef(x,y,z)", "response": "Sets the state of the actor."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unset_state(self):\n        x,y,z = self.obj.pos\n        glTranslatef(-x,-y,-z)", "response": "Resets the state required for this actor to the default state."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the state of the region.", "response": "def set_state(self):\n        \"\"\"\n        Sets the state required for this vertex region.\n        \n        Currently binds and enables the texture of the material of the region.\n        \"\"\"\n        glEnable(self.region.material.target)\n        glBindTexture(self.region.material.target, self.region.material.id)\n        self.region.bone.setRotate(self.data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unset_state(self):\n        glDisable(self.region.material.target)\n        self.region.bone.unsetRotate(self.data)", "response": "Resets the state required for this actor to the default state."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nensure that the given object has been initialized with this model.", "response": "def ensureModelData(self,obj):\n        \"\"\"\n        Ensures that the given ``obj`` has been initialized to be used with this model.\n        \n        If the object is found to not be initialized, it will be initialized.\n        \"\"\"\n        if not hasattr(obj,\"_modeldata\"):\n            self.create(obj,cache=True)\n        if \"_modelcache\" not in obj._modeldata:\n            # Assume all initialization is missing, simply reinitialize\n            self.create(obj,cache=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new object for the given object.", "response": "def create(self,obj,cache=False):\n        \"\"\"\n        Initializes per-actor data on the given object for this model.\n        \n        If ``cache`` is set to True, the entity will not be redrawn after initialization.\n        \n        Note that this method may set several attributes on the given object, most of them starting with underscores.\n        \n        During initialization of vertex regions, several vertex lists will be created.\n        If the given object has an attribute called ``batch3d`` it will be used, else it will be created.\n        \n        If the batch already existed, the :py:meth:`draw()` method will do nothing, else it will draw the batch.\n        \n        Memory leaks may occur if this is called more than once on the same object without calling :py:meth:`cleanup()` first.\n        \"\"\"\n        obj._modeldata = {}\n        \n        data = obj._modeldata\n        \n        data[\"_model\"]=self\n        data[\"_modelcache\"] = {}\n        moddata = data[\"_modelcache\"]\n        \n        # Model group, for pos of entity\n        moddata[\"group\"] = JSONModelGroup(self,data,obj)\n        modgroup = moddata[\"group\"]\n        \n        if not hasattr(obj,\"batch3d\"):\n            obj.batch3d = pyglet.graphics.Batch()\n            data[\"_manual_render\"]=True\n        \n        # Vlists/Regions\n        moddata[\"vlists\"] = {}\n        for name,region in self.modeldata[\"regions\"].items():\n            v = region.getVertices(data)\n            vlistlen = int(len(v)/region.dims)\n            \n            if region.enable_tex:\n                vlist = obj.batch3d.add(vlistlen,region.getGeometryType(data),JSONRegionGroup(self,data,region,modgroup),\n                        \"v3f/static\",\n                        \"t3f/static\",\n                        )\n            else:\n                vlist = obj.batch3d.add(vlistlen,region.getGeometryType(data),modgroup,\n                        \"v3f/static\",\n                        )\n            \n            moddata[\"vlists\"][name]=vlist\n        \n        self.setAnimation(obj,self.modeldata[\"default_animation\"].name,transition=\"jump\")\n        \n        self.data = data\n        \n        if not cache:\n            self.redraw(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncleaning up any left over data structures including vertex lists that reside in GPU memory.", "response": "def cleanup(self,obj):\n        \"\"\"\n        Cleans up any left over data structures, including vertex lists that reside in GPU memory.\n        \n        Behaviour is undefined if it is attempted to use this model with the same object without calling :py:meth:`create()` first.\n        \n        It is very important to call this method manually during deletion as this will delete references to data objects stored in global variables of third-party modules.\n        \"\"\"\n        if not hasattr(obj,\"_modeldata\"):\n            return # already not initialized\n        data = obj._modeldata\n        \n        if \"_modelcache\" in data:\n            moddata = data[\"_modelcache\"]\n            \n            if \"vlists\" in moddata:\n                for vlist in list(moddata[\"vlists\"].keys()):\n                    del moddata[\"vlists\"][vlist]\n                del moddata[\"vlists\"]\n        \n        if \"_bones\" in data:\n            for bone in list(data[\"_bones\"].keys()):\n                del data[\"_bones\"][bone]\n            del data[\"_bones\"]\n        \n        if \"_anidata\" in data:\n            adata = data[\"_anidata\"]\n            if \"_schedfunc\" in adata:\n                pyglet.clock.unschedule(adata[\"_schedfunc\"])\n        \n        if data.get(\"_manual_render\",False):\n            del obj.batch3d\n        \n        # Removes open vertex lists and other caches\n        \n        if \"_modelcache\" not in data:\n            return\n        moddata = data[\"_modelcache\"]\n        \n        if \"vlist\" in moddata:\n            moddata[\"vlist\"].delete() # Free up the graphics memory\n        if \"group\" in moddata:\n            del moddata[\"group\"]\n        \n        del data[\"_modelcache\"], moddata"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef redraw(self,obj):\n        self.ensureModelData(obj)\n        data = obj._modeldata\n        \n        vlists = data[\"_modelcache\"][\"vlists\"]\n        \n        for name,region in self.modeldata[\"regions\"].items():\n            vlists[name].vertices = region.getVertices(data)\n            if region.enable_tex:\n                vlists[name].tex_coords = region.getTexCoords(data)", "response": "Redraws the model of the given object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setAnimation(self,obj,animation,transition=None,force=False):\n        self.ensureModelData(obj)\n        data = obj._modeldata\n        \n        # Validity check\n        if animation not in self.modeldata[\"animations\"]:\n            raise ValueError(\"There is no animation of name '%s' for model '%s'\"%(animation,self.modelname))\n        \n        if data.get(\"_anidata\",{}).get(\"anitype\",None)==animation and not force:\n            return # animation is already running\n        \n        # Cache the obj to improve readability\n        anim = self.modeldata[\"animations\"][animation]\n        \n        # Set to default if not set\n        if transition is None:\n            transition = anim.default_jt\n        \n        # Notify the animation to allow it to initialize itself\n        anim.startAnimation(data,transition)\n        \n        # initialize animation data\n        if \"_anidata\" not in data:\n            data[\"_anidata\"]={}\n        adata = data[\"_anidata\"]\n        adata[\"anitype\"]=animation\n        \n        if \"_schedfunc\" in adata:\n            # unschedule the old animation, if any\n            # prevents clashing and crashes\n            pyglet.clock.unschedule(adata[\"_schedfunc\"])\n        \n        # Schedule the animation function\n        def schedfunc(*args):\n            # This function is defined locally to create a closure\n            # The closure stores the local variables, e.g. anim and data even after the parent function has finished\n            # Note that this may also prevent the garbage collection of any objects defined in the parent scope\n            anim.tickEntity(data)\n        \n        # register the function to pyglet\n        pyglet.clock.schedule_interval(schedfunc,1./(anim.kps if anim.atype==\"keyframes\" else 60))\n        # save it for later for de-initialization\n        adata[\"_schedfunc\"] = schedfunc", "response": "Set the animation to be used by the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setModel(self,model):\n        if self.model is not None:\n            self.model.cleanup(self)\n        self.model = model\n        model.create(self)", "response": "Sets the model this actor should use when drawing."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setAnimation(self,animation,transition=None,force=False):\n        if self.model is None:\n            raise RuntimeError(\"Can only set animation if a model is set\")\n        self.model.setAnimation(self,animation,transition,force)", "response": "Sets the animation that the actor should show."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmove the actor to the specified distance from the current rotational vector along the current trigonometry.", "response": "def move(self,dist):\n        \"\"\"\n        Moves the actor using standard trigonometry along the current rotational vector.\n        \n        :param float dist: Distance to move\n        \n        .. todo::\n           \n           Test this method, also with negative distances\n        \"\"\"\n        x, y = self._rot\n        y_angle = math.radians(y)\n        x_angle = math.radians(x)\n        m = math.cos(y_angle)\n        dy = math.sin(y_angle)\n        dy = 0.0\n        dx = math.cos(x_angle)\n        dz = math.sin(x_angle)\n        dx,dy,dz = dx*dist,dy*dist,dz*dist\n        x,y,z = self._pos\n        self.pos = x+dx,y+dy,z+dz\n        return dx,dy,dz"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_reports(self, relative_path, suite_name, reports,\n                      package_name=None):\n        \"\"\"write the collection of reports to the given path\"\"\"\n\n        dest_path = self.reserve_file(relative_path)\n        with open(dest_path, 'wb') as outf:\n            outf.write(toxml(reports, suite_name, package_name=package_name))\n        return dest_path", "response": "write the collection of reports to the given path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reserve_file(self, relative_path):\n        if os.path.isabs(relative_path):\n            raise ValueError('%s must be a relative path' % relative_path)\n\n        dest_path = os.path.join(self.root_dir, '%s.xml' % relative_path)\n\n        if os.path.exists(dest_path):\n            raise ValueError('%r must not already exist' % dest_path)\n\n        if dest_path in self.expected_xunit_files:\n            raise ValueError('%r already reserved' % dest_path)\n\n        dest_dir = os.path.dirname(dest_path)\n        if not os.path.isdir(dest_dir):\n            os.makedirs(dest_dir)\n\n        self.expected_xunit_files.append(dest_path)\n\n        return dest_path", "response": "reserve a XML file for the slice at <relative_path. xml"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert test reports into an xml file", "response": "def toxml(test_reports, suite_name,\n          hostname=gethostname(), package_name=\"tests\"):\n    \"\"\"convert test reports into an xml file\"\"\"\n\n    testsuites = et.Element(\"testsuites\")\n    testsuite = et.SubElement(testsuites, \"testsuite\")\n\n    test_count = len(test_reports)\n    if test_count < 1:\n        raise ValueError('there must be at least one test report')\n\n\n    assert test_count > 0, 'expecting at least one test'\n\n    error_count = len([r for r in test_reports if r.errors])\n    failure_count = len([r for r in test_reports if r.failures])\n    ts = test_reports[0].start_ts\n    start_timestamp = datetime.fromtimestamp(ts).isoformat()\n\n    total_duration = test_reports[-1].end_ts - test_reports[0].start_ts\n\n    def quote_attribute(value):\n        return value if value is not None else \"(null)\"\n\n\n    testsuite.attrib = dict(\n        id=\"0\",\n        errors=str(error_count),\n        failures=str(failure_count),\n        tests=str(test_count),\n        hostname=quote_attribute(hostname),\n        timestamp=quote_attribute(start_timestamp),\n        time=\"%f\" % total_duration,\n        name=quote_attribute(suite_name),\n        package=quote_attribute(package_name),\n    )\n\n    for r in test_reports:\n        test_name = r.name\n        test_duration = r.end_ts - r.start_ts\n        class_name = r.src_location\n\n        testcase = et.SubElement(testsuite, \"testcase\")\n        testcase.attrib = dict(\n            name=test_name,\n            classname=quote_attribute(class_name),\n            time=\"%f\" % test_duration,\n            )\n        if r.errors or r.failures:\n            if r.failures:\n                failure = et.SubElement(testcase, \"failure\")\n                failure.attrib = dict(\n                    type=\"exception\",\n                    message=quote_attribute('\\n'.join(['%s' % e for e in r.failures])),\n                )\n            else:\n                error = et.SubElement(testcase, \"error\")\n                error.attrib = dict(\n                    type=\"exception\",\n                    message=quote_attribute('\\n'.join(['%s' % e for e in r.errors])),\n                )\n\n    return et.tostring(testsuites, encoding=\"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup(self):\n        if self._setup:\n            return\n        self._setup = True\n        \n        # Ensures that default values are supplied\n        #self.cleanConfig()\n        \n        # Sets min/max window size, if specified\n        if self.cfg[\"graphics.min_size\"] is not None:\n            self.set_minimum_size(*self.cfg[\"graphics.min_size\"])\n        if self.cfg[\"graphics.max_size\"] is not None:\n            self.set_maximum_size(*self.cfg[\"graphics.max_size\"])\n        \n        # Sets up basic OpenGL state\n        glClearColor(*self.cfg[\"graphics.clearColor\"])\n        \n        glEnable(GL_DEPTH_TEST)\n        glEnable(GL_BLEND)\n        \n        glShadeModel(GL_SMOOTH)\n        \n        if self.cfg[\"graphics.fogSettings\"][\"enable\"]:\n            self.setupFog()\n        if self.cfg[\"graphics.lightSettings\"][\"enable\"]:\n            self.setupLight()", "response": "Sets up the OpenGL state."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setupFog(self):\n        fogcfg = self.cfg[\"graphics.fogSettings\"]\n        if not fogcfg[\"enable\"]:\n            return\n        \n        glEnable(GL_FOG)\n        \n        if fogcfg[\"color\"] is None:\n            fogcfg[\"color\"] = self.cfg[\"graphics.clearColor\"]\n        # Set the fog color.\n        glFogfv(GL_FOG_COLOR, (GLfloat * 4)(*fogcfg[\"color\"]))\n        # Set the performance hint.\n        glHint(GL_FOG_HINT, GL_DONT_CARE) # TODO: add customization, including headless support\n        # Specify the equation used to compute the blending factor.\n        glFogi(GL_FOG_MODE, GL_LINEAR)\n        # How close and far away fog starts and ends. The closer the start and end,\n        # the denser the fog in the fog range.\n        glFogf(GL_FOG_START, fogcfg[\"start\"])\n        glFogf(GL_FOG_END, fogcfg[\"end\"])", "response": "Sets the fog system up."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning the application in the current thread.", "response": "def run(self,evloop=None):\n        \"\"\"\n        Runs the application in the current thread.\n        \n        This method should not be called directly, especially when using multiple windows, use :py:meth:`Peng.run()` instead.\n        \n        Note that this method is blocking as rendering needs to happen in the main thread.\n        It is thus recommendable to run your game logic in another thread that should be started before calling this method.\n        \n        ``evloop`` may optionally be a subclass of :py:class:`pyglet.app.base.EventLoop` to replace the default event loop.\n        \"\"\"\n        self.setup()\n        if evloop is not None:\n            pyglet.app.event_loop = evloop\n        pyglet.app.run() # This currently just calls the basic pyglet main loop, maybe implement custom main loop for more control"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchanging to the given menu.", "response": "def changeMenu(self,menu):\n        \"\"\"\n        Changes to the given menu.\n        \n        ``menu`` must be a valid menu name that is currently known.\n        \n        .. versionchanged:: 1.2a1\n           \n           The push/pop handlers have been deprecated in favor of the new :py:meth:`Menu.on_enter() <peng3d.menu.Menu.on_enter>`\\ , :py:meth:`Menu.on_exit() <peng3d.menu.Menu.on_exit>`\\ , etc. events.\n        \"\"\"\n        if menu not in self.menus:\n            raise ValueError(\"Menu %s does not exist!\"%menu)\n        elif menu == self.activeMenu:\n            return # Ignore double menu activation to prevent bugs in menu initializer\n        old = self.activeMenu\n        self.activeMenu = menu\n        if old is not None:\n            self.menus[old].on_exit(menu)\n            self.menus[old].doAction(\"exit\")\n            #self.pop_handlers()\n        self.menu.on_enter(old)\n        self.menu.doAction(\"enter\")\n        self.peng.sendEvent(\"peng3d:window.menu.change\",{\"peng\":self.peng,\"window\":self,\"old\":old,\"menu\":menu})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addMenu(self,menu):\n        # If there is no menu selected currently, this menu will automatically be made active.\n        # Add the line above to the docstring if fixed\n        self.menus[menu.name]=menu\n        self.peng.sendEvent(\"peng3d:window.menu.add\",{\"peng\":self.peng,\"window\":self,\"menu\":menu})", "response": "Adds a menu to the list of menus."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dispatch_event(self,event_type,*args):\n        super(PengWindow,self).dispatch_event(event_type,*args)\n        try:\n            p = self.peng\n            m = self.menu\n        except AttributeError:\n            # To prevent early startup errors\n            if hasattr(self,\"peng\") and self.peng.cfg[\"debug.events.logerr\"]:\n                print(\"Error:\")\n                traceback.print_exc()\n            return\n        p.handleEvent(event_type,args,self)\n        self.handleEvent(event_type,args)\n        m.handleEvent(event_type,args)", "response": "Internal event handling method."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef toggle_exclusivity(self,override=None):\n        if override is not None:\n            new = override\n        else:\n            new = not self.exclusive\n        self.exclusive = new\n        self.set_exclusive_mouse(self.exclusive)\n        self.peng.sendEvent(\"peng3d:window.toggle_exclusive\",{\"peng\":self.peng,\"window\":self,\"exclusive\":self.exclusive})", "response": "Toggles mouse exclusivity via pyglet s set_exclusive_mouse method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set2d(self):\n        # Light\n        \n        glDisable(GL_LIGHTING)\n        \n        # To avoid accidental wireframe GUIs and fonts\n        glPolygonMode( GL_FRONT_AND_BACK, GL_FILL)\n        \n        width, height = self.get_size()\n        glDisable(GL_DEPTH_TEST)\n        glViewport(0, 0, width, height)\n        glMatrixMode(GL_PROJECTION)\n        glLoadIdentity()\n        glOrtho(0, width, 0, height, -1, 1)\n        glMatrixMode(GL_MODELVIEW)\n        glLoadIdentity()", "response": "Configures OpenGL to draw in 2D mode."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set3d(self,cam):\n        if not isinstance(cam,camera.Camera):\n            raise TypeError(\"cam is not of type Camera!\")\n        \n        # Light\n        \n        #glEnable(GL_LIGHTING)\n        \n        if self.cfg[\"graphics.wireframe\"]:\n            glPolygonMode(GL_FRONT_AND_BACK, GL_LINE)\n        \n        width, height = self.get_size()\n        glEnable(GL_DEPTH_TEST)\n        glViewport(0, 0, width, height)\n        glMatrixMode(GL_PROJECTION)\n        glLoadIdentity()\n        gluPerspective(self.cfg[\"graphics.fieldofview\"], width / float(height), self.cfg[\"graphics.nearclip\"], self.cfg[\"graphics.farclip\"]) # default 60\n        glMatrixMode(GL_MODELVIEW)\n        glLoadIdentity()\n        x, y = cam.rot\n        glRotatef(x, 0, 1, 0)\n        glRotatef(-y, math.cos(math.radians(x)), 0, math.sin(math.radians(x)))\n        x, y, z = cam.pos\n        glTranslatef(-x, -y, -z)", "response": "Sets the OpenGL context to draw in 3D mode."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef redraw_label(self):\n        # Convenience variables\n        sx,sy = self.size\n        x,y = self.pos\n        \n        # Label position\n        self._label.font_name = self.font_name\n        self._label.font_size = self.font_size\n        self._label.font_color = self.font_color\n        \n        self._label.x = int(x+sx/2.)\n        self._label.y = int(y+sy/2.)\n        self._label.width = self.size[0]\n        self._label.height = self.size[1]\n        self._label._update()", "response": "Re - draws the text by calculating its position."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nredrawing the label by calculating its position. Currently, the label will always be centered on the position of the label.", "response": "def redraw_label(self):\n        \"\"\"\n        Re-draws the label by calculating its position.\n        \n        Currently, the label will always be centered on the position of the label.\n        \"\"\"\n        # Convenience variables\n        sx,sy = self.size\n        x,y = self.pos\n        \n        # Label position\n        x = x+self.bg.border[0]\n        y = y+sy/2.-self._text.font_size/4.\n        w = self.size[0]\n        h = self.size[1]\n        \n        self._text.x,self._text.y = x,y\n        self._text.width,self._text.height=w,h\n        \n        self._default.x,self._default.y = x,y\n        self._default.width,self._default.height=w,h\n        \n        self._text._update() # Needed to prevent the label from drifting to the top-left after resizing by odd amounts\n        self._default._update()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nchange the active submenu", "response": "def changeSubMenu(self,submenu):\n        \"\"\"\n        Changes the submenu that is displayed.\n        \n        :raises ValueError: if the name was not previously registered\n        \"\"\"\n        if submenu not in self.submenus:\n            raise ValueError(\"Submenu %s does not exist!\"%submenu)\n        elif submenu == self.activeSubMenu:\n            return # Ignore double submenu activation to prevent bugs in submenu initializer\n        old = self.activeSubMenu\n        self.activeSubMenu = submenu\n        if old is not None:\n            self.submenus[old].on_exit(submenu)\n            self.submenus[old].doAction(\"exit\")\n        self.submenu.on_enter(old)\n        self.submenu.doAction(\"enter\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndraws the sub - menu and background.", "response": "def draw(self):\n        \"\"\"\n        Draws the submenu and its background.\n        \n        Note that this leaves the OpenGL state set to 2d drawing.\n        \"\"\"\n        # Sets the OpenGL state for 2D-Drawing\n        self.window.set2d()\n        \n        # Draws the background\n        if isinstance(self.bg,Layer):\n            self.bg._draw()\n        elif hasattr(self.bg,\"draw\") and callable(self.bg.draw):\n            self.bg.draw()\n        elif isinstance(self.bg,list) or isinstance(self.bg,tuple):\n            self.bg_vlist.draw(GL_QUADS)\n        elif callable(self.bg):\n            self.bg()\n        elif isinstance(self.bg,Background):\n            # The background will be drawn via the batch\n            if not self.bg.initialized:\n                self.bg.init_bg()\n                self.bg.redraw_bg()\n                self.bg.initialized=True\n        elif self.bg==\"blank\":\n            pass\n        else:\n            raise TypeError(\"Unknown background type\")\n        \n        # In case the background modified relevant state\n        self.window.set2d()\n        \n        # Check that all widgets that need redrawing have been redrawn\n        for widget in self.widgets.values():\n            if widget.do_redraw:\n                widget.on_redraw()\n                widget.do_redraw = False\n        \n        # Actually draw the content\n        self.batch2d.draw()\n        \n        # Call custom draw methods where needed\n        for widget in self.widgets.values():\n            widget.draw()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delWidget(self,widget):\n        # TODO: fix memory leak upon widget deletion\n        #print(\"*\"*50)\n        #print(\"Start delWidget\")\n        if isinstance(widget,BasicWidget):\n            widget = widget.name\n        \n        if widget not in self.widgets:\n            return\n        \n        w = self.widgets[widget]\n        \n        #print(\"refs: %s\"%sys.getrefcount(w))\n        \n        w.delete()\n        del self.widgets[widget]\n        del widget\n        \n        #w_wref = weakref.ref(w)\n        \n        #print(\"GC: GARBAGE\")\n        #print(gc.garbage)\n        #print(\"Widget Info\")\n        #print(w_wref())\n        #import objgraph\n        #print(\"Objgraph\")\n        #objgraph.show_refs([w], filename='./mem_widget.png')\n        #print(\"refs: %s\"%sys.getrefcount(w))\n        #w_r = gc.get_referrers(w)\n        #print(\"GC: REFS\")\n        #for w_ref in w_r:\n        #    print(repr(w_ref)[:512])\n        #print(\"GC: END\")\n        #print(\"len: %s\"%len(w_r))\n        #del w_ref,w_r\n        #print(\"after del %s\"%w_wref())\n        #print(\"refs: %s\"%sys.getrefcount(w))\n        del w", "response": "Deletes the given widget from the object graph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setBackground(self,bg):\n        self.bg = bg\n        if isinstance(bg,list) or isinstance(bg,tuple):\n            if len(bg)==3 and isinstance(bg,list):\n                bg.append(255)\n            self.bg_vlist.colors = bg*4\n        elif bg in [\"flat\",\"gradient\",\"oldshadow\",\"material\"]:\n            self.bg = ContainerButtonBackground(self,borderstyle=bg)\n            self.on_resize(self.window.width,self.window.height)", "response": "Sets the background of the submenu."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef redraw_bg(self):\n        # Convenience variables\n        sx,sy = self.widget.size\n        x,y = self.widget.pos\n        bx,by = self.border\n        \n        # Button background\n        \n        # Outer vertices\n        #    x          y\n        v1 = x,         y+sy\n        v2 = x+sx,      y+sy\n        v3 = x,         y\n        v4 = x+sx,      y\n        \n        # Inner vertices\n        #    x          y\n        v5 = x+bx,      y+sy-by\n        v6 = x+sx-bx,   y+sy-by\n        v7 = x+bx,      y+by\n        v8 = x+sx-bx,   y+by\n        \n        # 5 Quads, for edges and the center\n        qb1 = v5+v6+v2+v1\n        qb2 = v8+v4+v2+v6\n        qb3 = v3+v4+v8+v7\n        qb4 = v3+v7+v5+v1\n        qc  = v7+v8+v6+v5\n        \n        v = qb1+qb2+qb3+qb4+qc\n        \n        self.vlist.vertices = v\n        \n        bg = self.submenu.bg[:3] if isinstance(self.submenu.bg,list) or isinstance(self.submenu.bg,tuple) else [242,241,240]\n        o,i = bg, [min(bg[0]+8,255),min(bg[1]+8,255),min(bg[2]+8,255)]\n        s,h = [max(bg[0]-40,0),max(bg[1]-40,0),max(bg[2]-40,0)], [min(bg[0]+12,255),min(bg[1]+12,255),min(bg[2]+12,255)]\n        # Outer,Inner,Shadow,Highlight\n        \n        if self.borderstyle == \"flat\":\n            if self.widget.pressed:\n                i = s\n            cb1 = i+i+i+i\n            cb2 = i+i+i+i\n            cb3 = i+i+i+i\n            cb4 = i+i+i+i\n            cc  = i+i+i+i\n        elif self.borderstyle == \"gradient\":\n            if self.widget.pressed:\n                i = s\n            elif self.widget.is_hovering:\n                i = [min(i[0]+6,255),min(i[1]+6,255),min(i[2]+6,255)]\n            cb1 = i+i+o+o\n            cb2 = i+o+o+i\n            cb3 = o+o+i+i\n            cb4 = o+i+i+o\n            cc  = i+i+i+i\n        elif self.borderstyle == \"oldshadow\":\n            if self.widget.pressed:\n                i = s\n                s,h = h,s\n            elif self.widget.is_hovering:\n                i = [min(i[0]+6,255),min(i[1]+6,255),min(i[2]+6,255)]\n                s = [min(s[0]+6,255),min(s[1]+6,255),min(s[2]+6,255)]\n            cb1 = h+h+h+h\n            cb2 = s+s+s+s\n            cb3 = s+s+s+s\n            cb4 = h+h+h+h\n            cc  = i+i+i+i\n        elif self.borderstyle == \"material\":\n            if self.widget.pressed:\n                i = [max(bg[0]-20,0),max(bg[1]-20,0),max(bg[2]-20,0)]\n            elif self.widget.is_hovering:\n                i = [max(bg[0]-10,0),max(bg[1]-10,0),max(bg[2]-10,0)]\n            cb1 = s+s+o+o\n            cb2 = s+o+o+s\n            cb3 = o+o+s+s\n            cb4 = o+s+s+o\n            cc  = i+i+i+i\n        else:\n            raise ValueError(\"Invalid Border style\")\n        \n        c = cb1+cb2+cb3+cb4+cc\n        \n        self.vlist.colors = c\n        \n        # Cross\n        \n        # Old method that displayed a tick\n        \"\"\"if not self.widget.pressed:\n            self.vlist_cross.colors = 6*bg\n        else:\n            if self.borderstyle==\"flat\":\n                c = [min(bg[0]+8,255),min(bg[1]+8,255),min(bg[2]+8,255)]\n            elif self.borderstyle==\"gradient\":\n                c = h\n            elif self.borderstyle==\"oldshadow\":\n                c = h\n            elif self.borderstyle==\"material\":\n                c = s\n            self.vlist_cross.colors = 6*c\n        \n        # Convenience variables\n        sx,sy = self.widget.size\n        x,y = self.widget.pos\n        bx,by = self.border\n        \n        v1 = x+bx,      y+(sy-by*2)/2+by\n        v2 = x+sx/2,    y+(sy-by*2)/4+by\n        v3 = v6\n        v4 = x+sx,      y+sy\n        v5 = x+sx/2,    y+by\n        v6 = x+bx,      y+(sy-by*2)/4+by\n        \n        self.vlist_cross.vertices = v2+v1+v6+v5+v4+v3\"\"\"\n        \n        # TODO: add better visual indicator\n        \n        v1 = x+bx*1.5,    y+sy-by*1.5\n        v2 = x+sx-bx*1.5, y+sy-by*1.5\n        v3 = x+bx*1.5,    y+by*1.5\n        v4 = x+sx-bx*1.5, y+by*1.5\n        \n        self.vlist_check.colors = self.checkcolor*4 if self.widget.pressed else i*4\n        self.vlist_check.vertices = v3+v4+v2+v1", "response": "Redraws the background of the current entry in the current menu."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a keybind to the internal registry.", "response": "def add(self,keybind,kbname,handler,mod=True):\n        \"\"\"\n        Adds a keybind to the internal registry.\n        \n        Keybind names should be of the format ``namespace:category.subcategory.name``\\ e.g. ``peng3d:actor.player.controls.forward`` for the forward key combo for the player actor.\n        \n        :param str keybind: Keybind string, as described above\n        :param str kbname: Name of the keybind, may be used to later change the keybinding without re-registering\n        :param function handler: Function or any other callable called with the positional arguments ``(symbol,modifiers,release)`` if the keybind is pressed or released\n        :param int mod: If the keybind should respect modifiers\n        \"\"\"\n        keybind = keybind.lower()\n        if mod:\n            if keybind not in self.keybinds:\n                self.keybinds[keybind]=[]\n            self.keybinds[keybind].append(kbname)\n        else:\n            if keybind not in self.keybinds_nm:\n                self.keybinds_nm[keybind]=[]\n            self.keybinds_nm[keybind].append(kbname)\n        self.kbname[kbname]=handler\n        self.peng.sendEvent(\"peng3d:keybind.add\",{\"peng\":self.peng,\"keybind\":keybind,\"kbname\":kbname,\"handler\":handler,\"mod\":mod})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef changeKeybind(self,kbname,combo):\n        for key,value in self.keybinds.items():\n            if kbname in value:\n                del value[value.index(kbname)]\n                break\n        if combo not in self.keybinds:\n            self.keybinds[combo]=[]\n        self.keybinds[combo].append(kbname)\n        self.peng.sendEvent(\"peng3d.keybind.change\",{\"peng\":self.peng,\"kbname\":kbname,\"combo\":combo})", "response": "Changes a keybind of a specific keybindname."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mod_is_held(self,modname,modifiers):\n        modifier = MODNAME2MODIFIER[modname.lower()]\n        return modifiers&modifier", "response": "Returns a bitmask of the bits that are set in the modifiers argument."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling a key combination and dispatches associated events.", "response": "def handle_combo(self,combo,symbol,modifiers,release=False,mod=True):\n        \"\"\"\n        Handles a key combination and dispatches associated events.\n        \n        First, all keybind handlers registered via :py:meth:`add` will be handled,\n        then the pyglet event :peng3d:pgevent:`on_key_combo` with params ``(combo,symbol,modifiers,release,mod)`` is sent to the :py:class:`Peng()` instance.\n        \n        Also sends the events :peng3d:event:`peng3d:keybind.combo`\\, :peng3d:event:`peng3d:keybind.combo.press` and :peng3d:event`peng3d:keybind.combo.release`\\ .\n        \n        :params str combo: Key combination pressed\n        :params int symbol: Key pressed, passed from the same argument within pyglet\n        :params int modifiers: Modifiers held while the key was pressed\n        :params bool release: If the combo was released\n        :params bool mod: If the combo was sent without mods\n        \"\"\"\n        if self.peng.cfg[\"controls.keybinds.debug\"]:\n            print(\"combo: nm=%s %s\"%(mod,combo))\n        if mod:\n            for kbname in self.keybinds.get(combo,[]):\n                self.kbname[kbname](symbol,modifiers,release)\n        else:\n            for kbname in self.keybinds_nm.get(combo,[]):\n                self.kbname[kbname](symbol,modifiers,release)\n        self.peng.sendPygletEvent(\"on_key_combo\",(combo,symbol,modifiers,release,mod))\n        self.peng.sendEvent(\"peng3d:keybind.combo\",{\"peng\":self.peng,\"combo\":combo,\"symbol\":symbol,\"modifiers\":modifiers,\"release\":release,\"mod\":mod})\n        if release:\n            self.peng.sendEvent(\"peng3d:keybind.combo.release\",{\"peng\":self.peng,\"combo\":combo,\"symbol\":symbol,\"modifiers\":modifiers,\"release\":release,\"mod\":mod})\n        else:\n            self.peng.sendEvent(\"peng3d:keybind.combo.press\",{\"peng\":self.peng,\"combo\":combo,\"symbol\":symbol,\"modifiers\":modifiers,\"release\":release,\"mod\":mod})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef registerEventHandlers(self):\n        # Forward\n        self.peng.keybinds.add(self.peng.cfg[\"controls.controls.forward\"],\"peng3d:actor.%s.player.controls.forward\"%self.actor.uuid,self.on_fwd_down,False)\n        # Backward\n        self.peng.keybinds.add(self.peng.cfg[\"controls.controls.backward\"],\"peng3d:actor.%s.player.controls.backward\"%self.actor.uuid,self.on_bwd_down,False)\n        # Strafe Left\n        self.peng.keybinds.add(self.peng.cfg[\"controls.controls.strafeleft\"],\"peng3d:actor.%s.player.controls.strafeleft\"%self.actor.uuid,self.on_left_down,False)\n        # Strafe Right\n        self.peng.keybinds.add(self.peng.cfg[\"controls.controls.straferight\"],\"peng3d:actor.%s.player.controls.straferight\"%self.actor.uuid,self.on_right_down,False)\n        pyglet.clock.schedule_interval(self.update,1.0/60)", "response": "Registers needed keybinds and schedules the update method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the movement vector according to held buttons and the rotation.", "response": "def get_motion_vector(self):\n        \"\"\"\n        Returns the movement vector according to held buttons and the rotation.\n        \n        :return: 3-Tuple of ``(dx,dy,dz)``\n        :rtype: tuple\n        \"\"\"\n        if any(self.move):\n            x, y = self.actor._rot\n            strafe = math.degrees(math.atan2(*self.move))\n            y_angle = math.radians(y)\n            x_angle = math.radians(x + strafe)\n            dy = 0.0\n            dx = math.cos(x_angle)\n            dz = math.sin(x_angle)\n        else:\n            dy = 0.0\n            dx = 0.0\n            dz = 0.0\n        return (dx, dy, dz)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef registerEventHandlers(self):\n        self.world.registerEventHandler(\"on_mouse_motion\",self.on_mouse_motion)\n        self.world.registerEventHandler(\"on_mouse_drag\",self.on_mouse_drag)", "response": "Registers the motion and drag handlers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef registerEventHandlers(self):\n        # Crouch/fly down\n        self.peng.keybinds.add(self.peng.cfg[\"controls.controls.crouch\"],\"peng3d:actor.%s.player.controls.crouch\"%self.actor.uuid,self.on_crouch_down,False)\n        # Jump/fly up\n        self.peng.keybinds.add(self.peng.cfg[\"controls.controls.jump\"],\"peng3d:actor.%s.player.controls.jump\"%self.actor.uuid,self.on_jump_down,False)\n        pyglet.clock.schedule_interval(self.update,1.0/60)", "response": "Registers the up and down handlers."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd all widgets to the internal cache.", "response": "def add_widgets(self,**kwargs):\n        \"\"\"\n        Called by the initializer to add all widgets.\n        \n        Widgets are discovered by searching through the :py:attr:`WIDGETS` class attribute.\n        If a key in :py:attr:`WIDGETS` is also found in the keyword arguments and\n        not none, the function with the name given in the value of the key will\n        be called with its only argument being the value of the keyword argument.\n        \n        For more complex usage scenarios, it is also possible to override this method\n        in a subclass, but the original method should always be called to ensure\n        compatibility with classes relying on this feature.\n        \"\"\"\n        for name,fname in self.WIDGETS.items():\n            if name in kwargs and kwargs[name] is not None:\n                assert hasattr(self,fname)\n                assert callable(getattr(self,fname))\n                getattr(self,fname)(kwargs[name])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding the main label of the dialog.", "response": "def add_label_main(self,label_main):\n        \"\"\"\n        Adds the main label of the dialog.\n        \n        This widget can be triggered by setting the label ``label_main`` to a string.\n        \n        This widget will be centered on the screen.\n        \"\"\"\n        # Main Label\n        self.wlabel_main = text.Label(\"label_main\",self,self.window,self.peng,\n                        pos=lambda sw,sh, bw,bh: (sw/2-bw/2,sh/2-bh/2),\n                        size=[0,0],\n                        label=label_main,\n                        #multiline=True, # TODO: implement multine dialog\n                        )\n        self.wlabel_main.size = lambda sw,sh: (sw,self.wlabel_main._label.font_size)\n        self.addWidget(self.wlabel_main)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_btn_ok(self,label_ok):\n        # OK Button\n        self.wbtn_ok = button.Button(\"btn_ok\",self,self.window,self.peng,\n                        pos=lambda sw,sh, bw,bh: (sw/2-bw/2,sh/2-bh/2-bh*2),\n                        size=[0,0],\n                        label=label_ok,\n                        borderstyle=self.borderstyle\n                        )\n        self.wbtn_ok.size = lambda sw,sh: (self.wbtn_ok._label.font_size*8,self.wbtn_ok._label.font_size*2)\n        self.addWidget(self.wbtn_ok)\n        \n        def f():\n            self.doAction(\"click_ok\")\n            self.exitDialog()\n        self.wbtn_ok.addAction(\"click\",f)", "response": "Adds an ok button to allow the user to exit the dialog."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef exitDialog(self):\n        if self.prev_submenu is not None:\n            # change back to the previous submenu\n            # could in theory form a stack if one dialog opens another\n            self.menu.changeSubMenu(self.prev_submenu)\n        self.prev_submenu = None", "response": "Helper method that exits the dialog."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_btn_confirm(self,label_confirm):\n        # Confirm Button\n        self.wbtn_confirm = button.Button(\"btn_confirm\",self,self.window,self.peng,\n                        pos=lambda sw,sh, bw,bh: (sw/2-bw-4,sh/2-bh/2-bh*2),\n                        size=[0,0],\n                        label=label_confirm,\n                        borderstyle=self.borderstyle\n                        )\n        self.wbtn_confirm.size = lambda sw,sh: (self.wbtn_confirm._label.font_size*8,self.wbtn_confirm._label.font_size*2)\n        self.addWidget(self.wbtn_confirm)\n        \n        def f():\n            self.doAction(\"confirm\")\n            self.exitDialog()\n        self.wbtn_confirm.addAction(\"click\",f)", "response": "Adds a confirm button to let the user confirm whatever action they were presented with."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_btn_cancel(self,label_cancel):\n        # Cancel Button\n        self.wbtn_cancel = button.Button(\"btn_cancel\",self,self.window,self.peng,\n                        pos=lambda sw,sh, bw,bh: (sw/2+4,sh/2-bh/2-bh*2),\n                        size=[0,0],\n                        label=label_cancel,\n                        borderstyle=self.borderstyle\n                        )\n        self.wbtn_cancel.size = lambda sw,sh: (self.wbtn_cancel._label.font_size*8,self.wbtn_cancel._label.font_size*2)\n        self.addWidget(self.wbtn_cancel)\n        \n        def f():\n            self.doAction(\"cancel\")\n            self.exitDialog()\n        self.wbtn_cancel.addAction(\"click\",f)", "response": "Adds a cancel button to the dialog."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the progressbar by re - calculating the label.", "response": "def update_progressbar(self):\n        \"\"\"\n        Updates the progressbar by re-calculating the label.\n        \n        It is not required to manually call this method since setting any of the\n        properties of this class will automatically trigger a re-calculation.\n        \"\"\"\n        n,nmin,nmax = self.wprogressbar.n,self.wprogressbar.nmin,self.wprogressbar.nmax\n        if (nmax-nmin)==0:\n            percent = 0 # prevents ZeroDivisionError\n        else:\n            percent = max(min((n-nmin)/(nmax-nmin),1.),0.)*100\n        dat = {\"value\":round(n,4),\"n\":round(n,4),\"nmin\":round(nmin,4),\"nmax\":round(nmax,4),\"percent\":round(percent,4),\"p\":round(percent,4)}\n        txt = self._label_progressbar.format(**dat)\n        self.wprogresslabel.label = txt"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_progressbar(self,label_progressbar):\n        # Progressbar\n        self.wprogressbar = slider.AdvancedProgressbar(\"progressbar\",self,self.window,self.peng,\n                        pos=lambda sw,sh, bw,bh: (sw/2-bw/2,self.wlabel_main.pos[1]-bh*1.5),\n                        size=[0,0],\n                        #label=label_progressbar # TODO: add label\n                        borderstyle=self.borderstyle\n                        )\n        self.addWidget(self.wprogressbar)\n        \n        # Progress Label\n        self.wprogresslabel = text.Label(\"progresslabel\",self,self.window,self.peng,\n                        pos=lambda sw,sh, bw,bh: (sw/2-bw/2,self.wprogressbar.pos[1]+8),\n                        size=[0,0],\n                        label=\"\", # set by update_progressbar()\n                        )\n        self.wprogresslabel.size = lambda sw,sh: (sw,self.wprogresslabel._label.font_size)\n        self.addWidget(self.wprogresslabel)\n        \n        self.wprogressbar.size = lambda sw,sh: (sw*0.8,self.wprogresslabel._label.font_size+10)\n        \n        self._label_progressbar = label_progressbar\n        \n        if getattr(label_progressbar,\"_dynamic\",False):\n            def f():\n                self.label_progressbar = str(label_progressbar)\n            self.peng.i18n.addAction(\"setlang\",f)\n        \n        self.wprogressbar.addAction(\"progresschange\",self.update_progressbar)\n        \n        self.update_progressbar()", "response": "Adds a progressbar and label displaying the progress within a certain task."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef createWindow(self,cls=None,caption_t=None,*args,**kwargs):\n        if cls is None:\n            from . import window\n            cls = window.PengWindow\n        if self.window is not None:\n            raise RuntimeError(\"Window already created!\")\n        self.sendEvent(\"peng3d:window.create.pre\",{\"peng\":self,\"cls\":cls})\n        if caption_t is not None:\n            kwargs[\"caption\"] = \"Peng3d Application\"\n        self.window = cls(self,*args,**kwargs)\n        self.sendEvent(\"peng3d:window.create.post\",{\"peng\":self,\"window\":self.window})\n        if self.cfg[\"rsrc.enable\"] and self.resourceMgr is None:\n            self.sendEvent(\"peng3d:rsrc.init.pre\",{\"peng\":self,\"basepath\":self.cfg[\"rsrc.basepath\"]})\n            self.resourceMgr = resource.ResourceManager(self,self.cfg[\"rsrc.basepath\"])\n            self.rsrcMgr = self.resourceMgr\n            self.sendEvent(\"peng3d:rsrc.init.post\",{\"peng\":self,\"rsrcMgr\":self.resourceMgr})\n            if self.cfg[\"i18n.enable\"] and self.i18n is None:\n                self.sendEvent(\"peng3d:i18n.init.pre\",{\"peng\":self})\n                self.i18n = i18n.TranslationManager(self)\n                self._t = self.i18n.t\n                self._tl = self.i18n.tl\n                self.sendEvent(\"peng3d:i18n.init.post\",{\"peng\":self,\"i18n\":self.i18n})\n        if caption_t is not None:\n            self.window.set_caption(self.t(caption_t))\n            def f():\n                self.window.set_caption(self.t(caption_t))\n            self.i18n.addAction(\"setlang\",f)\n        return self.window", "response": "Creates a new window using the supplied class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self,evloop=None):\n        self.sendEvent(\"peng3d:peng.run\",{\"peng\":self,\"window\":self.window,\"evloop\":evloop})\n        self.window.run(evloop)\n        self.sendEvent(\"peng3d:peng.exit\",{\"peng\":self})", "response": "Runs the application main loop."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sendPygletEvent(self,event_type,args,window=None):\n        args = list(args)\n        \n        self.sendEvent(\"pyglet:%s\"%event_type,{\"peng\":self,\"args\":args,\"window\":window,\"src\":self,\"event_type\":event_type})\n        self.sendEvent(\"peng3d:pyglet\",{\"peng\":self,\"args\":args,\"window\":window,\"src\":self,\"event_type\":event_type})\n        \n        if event_type not in [\"on_draw\",\"on_mouse_motion\"] and self.cfg[\"debug.events.dump\"]:\n            print(\"Event %s with args %s\"%(event_type,args))\n        if event_type in self.pygletEventHandlers:\n            for whandler in self.pygletEventHandlers[event_type]:\n                # This allows for proper collection of deleted handler methods by using weak references\n                handler = whandler()\n                if handler is None:\n                    del self.pygletEventHandlers[event_type][self.pygletEventHandlers[event_type].index(whandler)]\n                handler(*args)", "response": "Sends a pyglet event to the current window."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters an event handler for the specified event type.", "response": "def addPygletListener(self,event_type,handler):\n        \"\"\"\n        Registers an event handler.\n        \n        The specified callable handler will be called every time an event with the same ``event_type`` is encountered.\n        \n        All event arguments are passed as positional arguments.\n        \n        This method should be used to listen for pyglet events.\n        For new code, it is recommended to use :py:meth:`addEventListener()` instead.\n        \n        See :py:meth:`handleEvent()` for information about tunneled pyglet events.\n        \n        For custom events, use :py:meth:`addEventListener()` instead.\n        \"\"\"\n        if self.cfg[\"debug.events.register\"]:\n            print(\"Registered Event: %s Handler: %s\"%(event_type,handler))\n        if event_type not in self.pygletEventHandlers:\n            self.pygletEventHandlers[event_type]=[]\n        # Only a weak reference is kept\n        if inspect.ismethod(handler):\n            handler = weakref.WeakMethod(handler)\n        else:\n            handler = weakref.ref(handler)\n        self.pygletEventHandlers[event_type].append(handler)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sendEvent(self,event,data=None):\n        if self.cfg[\"debug.events.dumpfile\"]!=\"\" and event not in self.event_list:\n            self.event_list.add(event)\n        if event not in self.eventHandlers:\n            if event not in self.events_ignored or self.events_ignored[event]<=self.cfg[\"events.maxignore\"]: # Prevents spamming logfile with ignored event messages\n                # TODO: write to logfile\n                # Needs a logging module first...\n                self.events_ignored[event] = self.events_ignored.get(event,0)+1\n            return\n        \n        for handler in self.eventHandlers[event]:\n            f = handler[0]\n            try:\n                f(event,data)\n            except Exception:\n                if not handler[1]:\n                    raise\n                else:\n                    # TODO: write to logfile\n                    if self.cfg[\"events.removeonerror\"]:\n                        self.delEventListener(event,f)", "response": "Sends an event to the log file with optional data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a handler to the given event.", "response": "def addEventListener(self,event,func,raiseErrors=False):\n        \"\"\"\n        Adds a handler to the given event.\n        \n        A event may have an arbitrary amount of handlers, though assigning too\n        many handlers may slow down event processing.\n        \n        For the format of ``event``\\ , see :py:meth:`sendEvent()`\\ .\n        \n        ``func`` is the handler which will be executed with two arguments, ``event_type`` and ``data``\\ , as supplied to :py:meth:`sendEvent()`\\ .\n        \n        If ``raiseErrors`` is True, exceptions caused by the handler will be re-raised.\n        Defaults to ``False``\\ .\n        \"\"\"\n        if not isinstance(event,str):\n            raise TypeError(\"Event types must always be strings\")\n        \n        if event not in self.eventHandlers:\n            self.eventHandlers[event]=[]\n        self.eventHandlers[event].append([func,raiseErrors])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delEventListener(self,event,func):\n        if event not in self.eventHandlers:\n            raise NameError(\"No handlers exist for event %s\"%event)\n        if [func,True] in self.eventHandlers[event]:\n            del self.eventHandlers[event][self.eventHandlers[event].index(func)]\n        elif [func,False] in self.eventHandler[event]:\n            del self.eventHandlers[event][self.eventHandlers[event].index(func)]\n        else:\n            raise NameError(\"This handler is not registered for event %s\"%event)\n        if self.eventHandlers[event] == []:\n            del self.eventHandlers[event]", "response": "Removes the given handler from the given event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the default language for all domains.", "response": "def setLang(self,lang):\n        \"\"\"\n        Sets the default language for all domains.\n        \n        For recommendations regarding the format of the language code, see\n        :py:class:`TranslationManager`\\ .\n        \n        Note that the ``lang`` parameter of both :py:meth:`translate()` and\n        :py:meth:`translate_lazy()` will override this setting.\n        \n        Also note that the code won't be checked for existence or plausibility.\n        This may cause the fallback strings to be displayed instead if the language\n        does not exist.\n        \n        Calling this method will cause the ``setlang`` action and the\n        :peng3d:event`peng3d:i18n.set_lang` event to be triggered. Note that both\n        action and event will be triggered even if the language did not actually change.\n        \n        This method also automatically updates the :confval:`i18n.lang` config value.\n        \"\"\"\n        self.lang = lang\n        self.peng.cfg[\"i18n.lang\"] = lang\n        \n        if lang not in self.cache:\n            self.cache[lang]={}\n        \n        self.doAction(\"setlang\")\n        self.peng.sendEvent(\"peng3d:i18n.set_lang\",{\"lang\":self.lang,\"i18n\":self})"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a list of languages based on files found on disk.", "response": "def discoverLangs(self,domain=\"*\"):\n        \"\"\"\n        Generates a list of languages based on files found on disk.\n        \n        The optional ``domain`` argument may specify a domain to use when checking\n        for files. By default, all domains are checked.\n        \n        This internally uses the :py:mod:`glob` built-in module and the\n        :confval:`i18n.lang.format` config option to find suitable filenames.\n        It then applies the regex in :confval:`i18n.discover_regex` to extract the\n        language code.\n        \"\"\"\n        rsrc = self.peng.cfg[\"i18n.lang.format\"].format(domain=domain,lang=\"*\")\n        pattern = self.peng.rsrcMgr.resourceNameToPath(rsrc,self.peng.cfg[\"i18n.lang.ext\"])\n        files = glob.iglob(pattern)\n        \n        langs = set()\n        r = re.compile(self.peng.cfg[\"i18n.discover_regex\"])\n        \n        for f in files:\n            m = r.fullmatch(f)\n            if m is not None:\n                langs.add(m.group(\"lang\"))\n        \n        return list(langs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a camera to the internal registry.", "response": "def addCamera(self,camera):\n        \"\"\"\n        Add the camera to the internal registry.\n        \n        Each camera name must be unique, or else only the most recent version will be used. This behavior should not be relied on because some objects may cache objects.\n        \n        Additionally, only instances of :py:class:`Camera() <peng3d.camera.Camera>` may be used, everything else raises a :py:exc:`TypeError`\\ .\n        \"\"\"\n        if not isinstance(camera,Camera):\n            raise TypeError(\"camera is not of type Camera!\")\n        self.cameras[camera.name]=camera"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addView(self,view):\n        if not isinstance(view,WorldView):\n            raise TypeError(\"view is not of type WorldView!\")\n        self.views[view.name]=view", "response": "Adds the supplied WorldView object to the internal registry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getView(self,name):\n        if name not in self.views:\n            raise ValueError(\"Unknown world view\")\n        return self.views[name]", "response": "Returns the view with name Raises a : py : exc : ValueError if the view does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenders the world in 3d - mode.", "response": "def render3d(self,view=None):\n        \"\"\"\n        Renders the world in 3d-mode.\n        \n        If you want to render custom terrain, you may override this method. Be careful that you still call the original method or else actors may not be rendered.\n        \"\"\"\n        for actor in self.actors.values():\n            actor.render(view)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the active camera.", "response": "def setActiveCamera(self,name):\n        \"\"\"\n        Sets the active camera.\n        \n        This method also calls the :py:meth:`Camera.on_activate() <peng3d.camera.Camera.on_activate>` event handler if the camera is not already active.\n        \"\"\"\n        if name == self.activeCamera:\n            return # Cam is already active\n        if name not in self.world.cameras:\n            raise ValueError(\"Unknown camera name\")\n        old = self.activeCamera\n        self.activeCamera = name\n        self.cam.on_activate(old)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_menu_enter(self,old):\n        super(WorldViewMouseRotatable,self).on_menu_enter(old)\n        self.world.peng.window.toggle_exclusivity(True)", "response": "Override this method to force mouse exclusivity."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\noverrides to force - disables mouse exclusivity.", "response": "def on_menu_exit(self,new):\n        \"\"\"\n        Fake event handler, same as :py:meth:`WorldView.on_menu_exit()` but force-disables mouse exclusivity.\n        \"\"\"\n        super(WorldViewMouseRotatable,self).on_menu_exit(new)\n        self.world.peng.window.toggle_exclusivity(False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_key_press(self,symbol,modifiers):\n        if symbol == key.ESCAPE:\n            self.world.peng.window.toggle_exclusivity()\n            return pyglet.event.EVENT_HANDLED", "response": "This method is called when a key is pressed."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_mouse_motion(self, x, y, dx, dy):\n        if not self.world.peng.window.exclusive:\n            return\n        m = self.world.peng.cfg[\"controls.mouse.sensitivity\"]\n        x, y = self.rot\n        x, y = x + dx * m, y + dy * m\n        y = max(-90, min(90, y))\n        x %= 360\n        newrot = (x,y)\n        self.rot= newrot", "response": "Handles mouse motion and rotates the attached camera accordingly."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstart a new step. returns a context manager which allows you to to report an error", "response": "def step(self, step_name):\n        \"\"\"Start a new step. returns a context manager which allows you to\n        report an error\"\"\"\n\n        @contextmanager\n        def step_context(step_name):\n            if self.event_receiver.current_case is not None:\n                raise Exception('cannot open a step within a step')\n\n            self.event_receiver.begin_case(step_name, self.now_seconds(), self.name)\n            try:\n                yield self.event_receiver\n            except:\n                etype, evalue, tb = sys.exc_info()\n                self.event_receiver.error('%r' % [etype, evalue, tb])\n                raise\n            finally:\n                self.event_receiver.end_case(step_name, self.now_seconds())\n\n        return step_context(step_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert the given resource name to a file path.", "response": "def resourceNameToPath(self,name,ext=\"\"):\n        \"\"\"\n        Converts the given resource name to a file path.\n        \n        A resource path is of the format ``<app>:<cat1>.<cat2>.<name>`` where cat1 and cat2 can be repeated as often as desired.\n        \n        ``ext`` is the file extension to use, e.g. ``.png`` or similar.\n        \n        As an example, the resource name ``peng3d:some.category.foo`` with the extension ``.png`` results in the path ``<basepath>/assets/peng3d/some/category/foo.png``\\ .\n        \n        This resource naming scheme is used by most other methods of this class.\n        \n        Note that it is currently not possible to define multiple base paths to search through.\n        \"\"\"\n        nsplit = name.split(\":\")[1].split(\".\")\n        return os.path.join(self.basepath,\"assets\",name.split(\":\")[0],*nsplit)+ext"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resourceExists(self,name,ext=\"\"):\n        return os.path.exists(self.resourceNameToPath(name,ext))", "response": "Returns whether or not the resource with the given name and extension exists."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a new texture category with the given name.", "response": "def addCategory(self,name):\n        \"\"\"\n        Adds a new texture category with the given name.\n        \n        If the category already exists, it will be overridden.\n        \"\"\"\n        self.categories[name]={}\n        self.categoriesTexCache[name]={}\n        self.categoriesTexBin[name]=pyglet.image.atlas.TextureBin(self.texsize,self.texsize)\n        self.peng.sendEvent(\"peng3d:rsrc.category.add\",{\"peng\":self.peng,\"category\":name})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getTex(self,name,category):\n        if category not in self.categoriesTexCache:\n            return self.getMissingTex(category)\n        if name not in self.categoriesTexCache[category]:\n            self.loadTex(name,category)\n        return self.categoriesTexCache[category][name]", "response": "Gets the texture associated with the given name and category."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef loadTex(self,name,category):\n        try:\n            img = pyglet.image.load(self.resourceNameToPath(name,\".png\"))\n        except FileNotFoundError:\n            img = self.getMissingTexture()\n        texreg = self.categoriesTexBin[category].add(img)\n        #texreg = texreg.get_transform(True,True) # Mirrors the image due to how pyglets coordinate system works\n        # Strange behavior, sometimes needed and sometimes not\n        self.categories[category][name]=texreg\n        target = texreg.target\n        texid = texreg.id\n        texcoords = texreg.tex_coords\n        # Prevents texture bleeding with texture sizes that are powers of 2, else weird lines may appear at certain angles.\n        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT)\n        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT)\n        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST)\n        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST_MIPMAP_LINEAR)\n        glGenerateMipmap(GL_TEXTURE_2D)\n        \n        out = target,texid,texcoords\n        self.categoriesTexCache[category][name]=out\n        self.peng.sendEvent(\"peng3d:rsrc.tex.load\",{\"peng\":self.peng,\"name\":name,\"category\":category})\n        return out", "response": "Loads the given texture and returns the texture id and texture coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getMissingTexture(self):\n        if self.missingTexture is None:\n            if self.resourceExists(self.missingtexturename,\".png\"):\n                self.missingTexture = pyglet.image.load(self.resourceNameToPath(self.missingtexturename,\".png\"))\n                return self.missingTexture\n            else: # Falls back to create pattern in-memory\n                self.missingTexture = pyglet.image.create(1,1,pyglet.image.SolidColorImagePattern([255,0,255,255]))\n                return self.missingTexture\n        else:\n            return self.missingTexture", "response": "Returns a missing texture for the given source distribution."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a new texture from the given image.", "response": "def addFromTex(self,name,img,category):\n        \"\"\"\n        Adds a new texture from the given image.\n        \n        ``img`` may be any object that supports Pyglet-style copying in form of the ``blit_to_texture()`` method.\n        \n        This can be used to add textures that come from non-file sources, e.g. Render-to-texture.\n        \"\"\"\n        texreg = self.categoriesTexBin[category].add(img)\n        #texreg = texreg.get_transform(True,True) # Mirrors the image due to how pyglets coordinate system works\n        # Strange behaviour, sometimes needed and sometimes not\n        \n        self.categories[category][name]=texreg\n        target = texreg.target\n        texid = texreg.id\n        texcoords = texreg.tex_coords\n        \n        # Prevents texture bleeding with texture sizes that are powers of 2, else weird lines may appear at certain angles.\n        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT)\n        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT)\n        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST)\n        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST_MIPMAP_LINEAR)\n        glGenerateMipmap(GL_TEXTURE_2D)\n        \n        out = target,texid,texcoords\n        self.categoriesTexCache[category][name]=out\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the model object by the given name.", "response": "def getModel(self,name):\n        \"\"\"\n        Gets the model object by the given name.\n        \n        If it was loaded previously, a cached version will be returned.\n        If it was not loaded, it will be loaded and inserted into the cache.\n        \"\"\"\n        if name in self.modelobjcache:\n            return self.modelobjcache[name]\n        return self.loadModel(name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef loadModel(self,name):\n        m = model.Model(self.peng,self,name)\n        self.modelobjcache[name]=m\n        self.peng.sendEvent(\"peng3d:rsrc.model.load\",{\"peng\":self.peng,\"name\":name})\n        return m", "response": "Loads the model with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getModelData(self,name):\n        if name in self.modelcache:\n            return self.modelcache[name]\n        return self.loadModelData(name)", "response": "Gets the model data associated with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the model data of the given name.", "response": "def loadModelData(self,name):\n        \"\"\"\n        Loads the model data of the given name.\n        \n        The model file must always be a .json file.\n        \"\"\"\n        path = self.resourceNameToPath(name,\".json\")\n        try:\n            data = json.load(open(path,\"r\"))\n        except Exception:\n            # Temporary\n            print(\"Exception during model load: \")\n            import traceback;traceback.print_exc()\n            return {}# will probably cause other exceptions later on, TODO\n        \n        out = {}\n        \n        if data.get(\"version\",1)==1:\n            # Currently only one version, basic future-proofing\n            # This version should get incremented with breaking changes to the structure\n            \n            # Materials\n            out[\"materials\"]={}\n            for name,matdata in data.get(\"materials\",{}).items():\n                m = model.Material(self,name,matdata)\n                out[\"materials\"][name]=m\n            out[\"default_material\"]=out[\"materials\"][data.get(\"default_material\",list(out[\"materials\"].keys())[0])]\n            \n            # Bones\n            out[\"bones\"]={\"__root__\":model.RootBone(self,\"__root__\",{\"start_rot\":[0,0],\"length\":0})}\n            for name,bonedata in data.get(\"bones\",{}).items():\n                b = model.Bone(self,name,bonedata)\n                out[\"bones\"][name]=b\n            for name,bone in out[\"bones\"].items():\n                if name == \"__root__\":\n                    continue\n                bone.setParent(out[\"bones\"][bone.bonedata[\"parent\"]])\n            \n            # Regions\n            out[\"regions\"]={}\n            for name,regdata in data.get(\"regions\",{}).items():\n                r = model.Region(self,name,regdata)\n                r.material = out[\"materials\"][regdata.get(\"material\",out[\"default_material\"])]\n                r.bone = out[\"bones\"][regdata.get(\"bone\",\"__root__\")]\n                out[\"bones\"][regdata.get(\"bone\",\"__root__\")].addRegion(r)\n                out[\"regions\"][name]=r\n            \n            # Animations\n            out[\"animations\"]={}\n            out[\"animations\"][\"static\"]=model.Animation(self,\"static\",{\"type\":\"static\",\"bones\":{}})\n            for name,anidata in data.get(\"animations\",{}).items():\n                a = model.Animation(self,name,anidata)\n                a.setBones(out[\"bones\"])\n                out[\"animations\"][name]=a\n            out[\"default_animation\"]=out[\"animations\"][data.get(\"default_animation\",out[\"animations\"][\"static\"])]\n        else:\n            raise ValueError(\"Unknown version %s of model '%s'\"%(data.get(\"version\",1),name))\n        \n        self.modelcache[name]=out\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setBackground(self,bg):\n        self.bg = bg\n        if isinstance(bg,list) or isinstance(bg,tuple):\n            if len(bg)==3 and isinstance(bg,list):\n                bg.append(255)\n            self.bg_vlist.colors = bg*4\n        elif bg in [\"flat\",\"gradient\",\"oldshadow\",\"material\"]:\n            self.bg = ContainerButtonBackground(self,borderstyle=bg,batch=self.batch2d)\n            self.redraw()", "response": "Sets the background of the Container."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addWidget(self,widget):\n        if self is widget: # Prevents being able to add the container to itself, causing a recursion loop on redraw\n            return\n        self.widgets[widget.name]=widget", "response": "Adds a widget to this container."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef draw(self):\n        if not self.visible:\n            # Simple visibility check, has to be tested to see if it works properly\n            return\n        \n        if not isinstance(self.submenu,Container):\n            glEnable(GL_SCISSOR_TEST)\n            glScissor(*self.pos+self.size)\n        \n        SubMenu.draw(self)\n        \n        if not isinstance(self.submenu,Container):\n            glDisable(GL_SCISSOR_TEST)", "response": "Draw the submenu and its background."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nredraw the background and any child widgets.", "response": "def on_redraw(self):\n        \"\"\"\n        Redraws the background and any child widgets.\n        \"\"\"\n        x,y = self.pos\n        sx,sy = self.size\n        self.bg_vlist.vertices = [x,y, x+sx,y, x+sx,y+sy, x,y+sy]\n        self.stencil_vlist.vertices = [x,y, x+sx,y, x+sx,y+sy, x,y+sy]\n        if isinstance(self.bg,Background):\n            if not self.bg.initialized:\n                self.bg.init_bg()\n                self.bg.initialized=True\n            self.bg.redraw_bg()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_redraw(self):\n        n = self._scrollbar.n\n        self.offset_y = -n # Causes the content to move in the opposite direction of the slider\n        \n        # Size of scrollbar\n        sx=24 # Currently constant, TODO: add dynamic sx of scrollbar\n        sy=self.size[1]\n        # Pos of scrollbar\n        x=self.size[0]-sx\n        y=0 # Currently constant, TODO: add dynamic y-pos of scrollbar\n        \n        # Dynamic pos/size may be added via align/lambda/etc.\n        \n        # Note that the values are written to the _* variant of the attribute to avoid 3 uneccessary redraws\n        self._scrollbar._size = sx,sy\n        self._scrollbar._pos = x,y\n        self._scrollbar._nmax = self.content_height\n        \n        super(ScrollableContainer,self).on_redraw()", "response": "Redraws the background and contents including scrollbar."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mouse_aabb(mpos,size,pos):\n    return pos[0]<=mpos[0]<=pos[0]+size[0] and pos[1]<=mpos[1]<=pos[1]+size[1]", "response": "Check if the mouse is within the bounds of the AABB."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef addCategory(self,name,nmin=0,n=0,nmax=100):\n        assert isinstance(name,basestring) # py2 compat is done at the top\n        if name in self.categories:\n            raise KeyError(\"Category with name '%s' already exists\"%name)\n        self.categories[name]=[nmin,n,nmax]\n        self.redraw()", "response": "Adds a category with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef updateCategory(self,name,nmin=None,n=None,nmax=None):\n        # smart update, only stuff that was given\n        if name not in self.categories:\n            raise KeyError(\"No Category with name '%s'\"%name)\n        if nmin is not None:\n            self.categories[name][0]=nmin\n        if n is not None:\n            self.categories[name][1]=n\n        if nmax is not None:\n            self.categories[name][2]=nmax\n        self.redraw()\n        self.doAction(\"progresschange\")", "response": "Update the category with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes the category with the given name.", "response": "def deleteCategory(self,name):\n        \"\"\"\n        Deletes the category with the given name.\n        \n        If the category does not exist, a :py:exc:`KeyError` will be thrown.\n        \"\"\"\n        if name not in self.categories:\n            raise KeyError(\"No Category with name '%s'\"%name)\n        del self.categories[name]\n        self.redraw()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the percentage of the slider.", "response": "def p(self):\n        \"\"\"\n        Helper property containing the percentage this slider is \"filled\".\n        \n        This property is read-only.\n        \"\"\"\n        return (self.n-self.nmin)/max((self.nmax-self.nmin),1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new layer to the stack optionally at the specified z - value.", "response": "def addLayer(self,layer,z=-1):\n        \"\"\"\n        Adds a new layer to the stack, optionally at the specified z-value.\n        \n        ``layer`` must be an instance of Layer or subclasses.\n        \n        ``z`` can be used to override the index of the layer in the stack. Defaults to ``-1`` for appending.\n        \"\"\"\n        # Adds a new layer to the stack, optionally at the specified z-value\n        # The z-value is the index this layer should be inserted in, or -1 for appending\n        if not isinstance(layer,Layer):\n            raise TypeError(\"layer must be an instance of Layer!\")\n        if z==-1:\n            self.layers.append(layer)\n        else:\n            self.layers.insert(z,layer)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmap a buffer region using this attribute as an accessor.", "response": "def _get_region(self, buffer, start, count):\n        '''Map a buffer region using this attribute as an accessor.\n\n        The returned region can be modified as if the buffer was a contiguous\n        array of this attribute (though it may actually be interleaved or\n        otherwise non-contiguous).\n\n        The returned region consists of a contiguous array of component\n        data elements.  For example, if this attribute uses 3 floats per\n        vertex, and the `count` parameter is 4, the number of floats mapped\n        will be ``3 * 4 = 12``.\n\n        :Parameters:\n            `buffer` : `AbstractMappable`\n                The buffer to map.\n            `start` : int\n                Offset of the first vertex to map.\n            `count` : int\n                Number of vertices to map\n\n        :rtype: `AbstractBufferRegion`\n        '''\n        byte_start = self.stride * start\n        byte_size = self.stride * count\n        array_count = self.count * count\n        if self.stride == self.size or not array_count:\n            # non-interleaved\n            ptr_type = ctypes.POINTER(self.c_type * array_count)\n            return buffer.get_region(byte_start, byte_size, ptr_type)\n        else:\n            # interleaved\n            byte_start += self.offset\n            byte_size -= self.offset\n            elem_stride = self.stride // ctypes.sizeof(self.c_type)\n            elem_offset = self.offset // ctypes.sizeof(self.c_type)\n            ptr_type = ctypes.POINTER(\n                self.c_type * int((count * elem_stride - elem_offset)))\n            region = buffer.get_region(byte_start, byte_size, ptr_type)\n            return vertexbuffer.IndirectArrayRegion(\n                region, array_count, self.count, elem_stride)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndraw vertices in the domain.", "response": "def _draw(self, mode, vertex_list=None):\n        '''Draw vertices in the domain.\n\n        If `vertex_list` is not specified, all vertices in the domain are\n        drawn.  This is the most efficient way to render primitives.\n\n        If `vertex_list` specifies a `VertexList`, only primitives in that\n        list will be drawn.\n\n        :Parameters:\n            `mode` : int\n                OpenGL drawing mode, e.g. ``GL_POINTS``, ``GL_LINES``, etc.\n            `vertex_list` : `VertexList`\n                Vertex list to draw, or ``None`` for all lists in this domain.\n\n        '''\n        glPushClientAttrib(GL_CLIENT_VERTEX_ARRAY_BIT)\n        for buffer, attributes in self.buffer_attributes:\n            buffer.bind()\n            for attribute in attributes:\n                attribute.enable()\n                attribute.set_pointer(attribute.buffer.ptr)\n        if vertexbuffer._workaround_vbo_finish:\n            glFinish()\n\n        if vertex_list is not None:\n            glDrawArrays(mode, vertex_list.start, vertex_list.count)\n        else:\n            starts, sizes = self.allocator.get_allocated_regions()\n            primcount = len(starts)\n            if primcount == 0:\n                pass\n            elif primcount == 1:\n                # Common case\n                glDrawArrays(mode, starts[0], int(sizes[0]))\n            elif gl_info.have_version(1, 4):\n                starts = (GLint * primcount)(*starts)\n                sizes = (GLsizei * primcount)(*sizes)\n                glMultiDrawArrays(mode, starts, sizes, primcount)\n            else:\n                for start, size in zip(starts, sizes):\n                    glDrawArrays(mode, start, size)\n\n        for buffer, _ in self.buffer_attributes:\n            buffer.unbind()\n        glPopClientAttrib()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef patch_float2int():\n    pyglet.graphics.vertexattribute.AbstractAttribute.get_region = _get_region\n    pyglet.graphics.vertexbuffer.MappableVertexBufferObject.bind = _bind\n    pyglet.graphics.vertexbuffer.IndirectArrayRegion.__setitem__ = _iar__setitem__\n    pyglet.graphics.vertexdomain.VertexDomain.draw = _draw", "response": "Patches the pyglet. graphics. vertexattribute. AbstractAttribute. get_region and pyglet. graphics. vertexbuffer. IndirectArrayRegion. set_item to _iar__setitem__."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_pyglet_handler(peng,func,event,raiseErrors=False):\n    peng.addEventListener(\"pyglet:%s\"%event,(lambda data:func(*data[\"args\"])),raiseErrors)", "response": "Registers a given pyglet - style event handler for the given peng."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a callback to the specified action.", "response": "def addAction(self,action,func,*args,**kwargs):\n        \"\"\"\n        Adds a callback to the specified action.\n        \n        All other positional and keyword arguments will be stored and passed to the function upon activation.\n        \"\"\"\n        if not hasattr(self,\"actions\"):\n            self.actions = {}\n        if action not in self.actions:\n            self.actions[action] = []\n        self.actions[action].append((func,args,kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef doAction(self,action):\n        if not hasattr(self,\"actions\"):\n            return\n        for f,args,kwargs in self.actions.get(action,[]):\n            f(*args,**kwargs)", "response": "Helper method that calls all callbacks registered for the given action."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef genNewID(self):\n        if self.reuse_ids:\n            i = self.start_id\n            while True:\n                if i not in self._data[\"reg\"]:\n                    assert i<=self.max_id\n                    return i # no need to change any variables\n                i+=1\n        else:\n            with self.id_lock:\n                # new id creation in lock, to avoid issues with multiple threads\n                i = self._data[\"next_id\"]\n                assert i<=self.max_id\n                self._data[\"next_id\"]+=1\n            return i", "response": "Generates a new ID for the current internal counter."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register(self,name,force_id=None):\n        with self.registry_lock:\n            if force_id is None:\n                new_id = self.genNewID()\n            else:\n                new_id = force_id\n            self._data[\"reg\"][new_id]=name\n            return new_id", "response": "Registers a name to the registry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nnormalizing an ID or string representation of a resource ID.", "response": "def normalizeID(self,in_id):\n        \"\"\"\n        Takes in an object and normalizes it to its ID/integer representation.\n        \n        Currently, only integers and strings may be passed in, else a :py:exc:`TypeError`\n        will be thrown.\n        \"\"\"\n        if isinstance(in_id,int):\n            assert in_id in self._data[\"reg\"]\n            return in_id\n        elif isinstance(in_id,str):\n            assert in_id in self._data[\"reg\"].inv\n            return self._data[\"reg\"].inv[in_id]\n        else:\n            raise TypeError(\"Only int and str can be converted to IDs\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef normalizeName(self,in_name):\n        if isinstance(in_name,str):\n            assert in_name in self._data[\"reg\"].inv\n            return in_name\n        elif isinstance(in_name,int):\n            assert in_name in self._data[\"reg\"]\n            return self._data[\"reg\"][in_name]\n        else:\n            raise TypeError(\"Only int and str can be converted to names\")", "response": "Normalizes a name to its name or string representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the view used to the specified name.", "response": "def setView(self,name):\n        \"\"\"\n        Sets the view used to the specified ``name``\\ .\n        \n        The name must be known to the world or else a :py:exc:`ValueError` is raised.\n        \"\"\"\n        if name not in self.world.views:\n            raise ValueError(\"Invalid viewname for world!\")\n        self.viewname = viewname\n        self.view = self.world.getView(self.viewname)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets up the attributes used by Layer3D and calls Layer3D. predraw", "response": "def predraw(self):\n        \"\"\"\n        Sets up the attributes used by :py:class:`Layer3D()` and calls :py:meth:`Layer3D.predraw()`\\ .\n        \"\"\"\n        self.cam = self.view.cam\n        super(LayerWorld,self).predraw()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addLayer(self,layer,z_index=None):\n        if z_index is None:\n            z_index = layer.z_index\n        i = 0\n        for l,z in self.layers:\n            if z>z_index:\n                break\n            i+=1\n        self._layers[layer.name]=layer\n        self.layers.insert(i,[layer,z_index])", "response": "Adds the given layer to the internal list of the related resources."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nredrawing the given layer.", "response": "def redraw_layer(self,name):\n        \"\"\"\n        Redraws the given layer.\n        \n        :raises ValueError: If there is no Layer with the given name.\n        \"\"\"\n        if name not in self._layers:\n            raise ValueError(\"Layer %s not part of widget, cannot redraw\")\n        self._layers[name].on_redraw()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndrawing all layers of this LayeredWidget.", "response": "def draw(self):\n        \"\"\"\n        Draws all layers of this LayeredWidget.\n        \n        This should normally be unneccessary, since it is recommended that layers use Vertex Lists instead of OpenGL Immediate Mode.\n        \"\"\"\n        super(LayeredWidget,self).draw()\n        for layer,_ in self.layers:\n            layer._draw()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes all layers within this LayeredWidget before deleting itself.", "response": "def delete(self):\n        \"\"\"\n        Deletes all layers within this LayeredWidget before deleting itself.\n        \n        Recommended to call if you are removing the widget, but not yet exiting the interpreter.\n        \"\"\"\n        for layer,_ in self.layers:\n            layer.delete()\n        self.layers = []\n        self._layers = {}\n        super(LayeredWidget,self).delete()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_redraw(self):\n        super(WidgetLayer,self).on_redraw()\n        if not self._initialized:\n            self.initialize()\n            self._initialized = True", "response": "Called when the Layer should be redrawn."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef offset(self):\n        if callable(self._offset):\n            return util.WatchingList(self._offset(*(self.widget.pos+self.widget.size)),self._wlredraw_offset)\n        else:\n            return util.WatchingList(self._offset,self._wlredraw_offset)", "response": "Returns the offset of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getPos(self):\n        # Returns sx,sy,ex,ey\n        # sx,sy are bottom-left/lowest\n        # ex,ey are top-right/highest\n        sx,sy = self.widget.pos[0]+self.border[0]+self.offset[0],                       self.widget.pos[1]+self.border[1]+self.offset[1]\n        ex,ey = self.widget.pos[0]+self.widget.size[0]-self.border[0]+self.offset[0],   self.widget.pos[1]+self.widget.size[1]-self.border[1]+self.offset[1]\n        return sx,sy,ex,ey", "response": "Returns the absolute position and size of the layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getSize(self):\n        return self.widget.size[0]-self.border[0]*2,self.widget.size[1]-self.border[1]*2", "response": "Returns the size of the layer with the border size subtracted."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addImage(self,name,rsrc):\n        self.imgs[name]=self.widget.peng.resourceMgr.getTex(*rsrc)", "response": "Adds an image to the internal registry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef switchImage(self,name):\n        if name not in self.imgs:\n            raise ValueError(\"No image of name '%s'\"%name)\n        elif self.cur_img==name:\n            return\n        \n        self.cur_img = name\n        self.on_redraw()", "response": "Switches the active image to the given name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nredrawing the label by calculating its position.", "response": "def redraw_label(self):\n        \"\"\"\n        Re-draws the text by calculating its position.\n        \n        Currently, the text will always be centered on the position of the layer.\n        \"\"\"\n        # Convenience variables\n        x,y,_,_ = self.getPos()\n        sx,sy = self.getSize()\n        \n        self._label.x = x+sx/2.\n        self._label.y = y+sy/2.\n        self._label.width = sx\n        # Height is not set, would look weird otherwise\n        #self._label.height = sx\n        self._label._update()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef redraw_label(self):\n        # Convenience variables\n        x,y,_,_ = self.getPos()\n        sx,sy = self.getSize()\n        \n        if self.font_name is not None:\n            self._label.font_name = self.font_name\n        if self.font_size is not None:\n            self._label.font_size = self.font_size\n        if self.font_color is not None:\n            self._label.color = self.font_color\n        \n        self._label.x = x+sx/2.\n        self._label.y = y+sy/2.\n        self._label.width = sx\n        # Height is not set, would look weird otherwise\n        #self._label.height = sx\n        self._label._update()", "response": "Redraws the label by calculating its position."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate the vertices used by this layer.", "response": "def genVertices(self):\n        \"\"\"\n        Called to generate the vertices used by this layer.\n        \n        The length of the output of this method should be three times the :py:attr:`n_vertices` attribute.\n        \n        See the source code of this method for more information about the order of the vertices.\n        \"\"\"\n        sx,sy,ex,ey = self.getPos()\n        b = self.bborder\n        \n        # Vertex Naming\n        # Y\n        # |1  2  3  4\n        # |5  6  7  8\n        # |9  10 11 12\n        # |13 14 15 16\n        # +------> X\n        # Border order\n        # 4 2-tuples\n        # Each marks x,y offset from the respective corner\n        # tuples are in order topleft,topright,bottomleft,bottomright\n        # indices:\n        # 0,1:topleft; 2,3:topright; 4,5:bottomleft; 6,7:bottomright\n        # For a simple border that is even, just repeat the first tuple three more times\n        \n        v1 = sx,            ey\n        v2 = sx+b[0],       ey\n        v3 = ex-b[2],       ey\n        v4 = ex,            ey\n        \n        v5 = sx,            ey-b[1]\n        v6 = sx+b[0],       ey-b[1]\n        v7 = ex-b[2],       ey-b[3]\n        v8 = ex,            ey-b[3]\n        \n        v9 = sx,            sy+b[5]\n        v10= sx+b[4],       sy+b[5]\n        v11= ex-b[6],       sy+b[7]\n        v12= ex,            sy+b[7]\n        \n        v13= sx,            sy\n        v14= sx+b[4],       sy\n        v15= ex-b[6],       sy\n        v16= ex,            sy\n        \n        # Layer is separated into 9 sections, naming:\n        # 1 2 3\n        # 4 5 6\n        # 7 8 9\n        # Within each section, vertices are given counter-clockwise, starting with the bottom-left\n        # 4 3\n        # 1 2\n        # This is important when assigning colors\n        \n        q1 = v5 +v6 +v2 +v1\n        q2 = v6 +v7 +v3 +v2\n        q3 = v7 +v8 +v4 +v3\n        q4 = v9 +v10+v6 +v5\n        q5 = v10+v11+v7 +v6\n        q6 = v11+v12+v8 +v7\n        q7 = v13+v14+v10+v9\n        q8 = v14+v15+v11+v10\n        q9 = v15+v16+v12+v11\n        \n        return q1+q2+q3+q4+q5+q6+q7+q8+q9"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_h5(hdfstore, group = \"\"):\n  m = Mesh()\n  m.elements.data = hdf[\"elements/connectivity\"]\n  m.nodes.data    = hdf[\"nodes/xyz\"]\n  for key in hdf.keys():\n    if key.startswith(\"/nodes/sets\"):\n      k = key.replace(\"/nodes/sets/\", \"\")\n      m.nodes.sets[k] = set(hdf[key])\n    if key.startswith(\"/elements/sets\"):\n      k = key.replace(\"/elements/sets/\", \"\")\n      m.elements.sets[k] = set(hdf[key])\n    if key.startswith(\"/elements/surfaces\"):\n      k = key.replace(\"/elements/surfaces/\", \"\")\n      m.elements.surfaces[k] = hdf[key]\n    if key.startswith(\"/fields/\"):\n      if key.endswith(\"/metadata\"):\n        tag = key.split(\"/\")[2]\n        f = Field()\n        f.metadata = hdf[\"fields/{0}/metadata\".format(tag)]\n        f.metadata = hdf[\"fields/{0}/data\".format(tag)]\n        f.master = m\n        m.add_field(tag, f)\n  hdf.close()  \n  return m", "response": "Reads a mesh from an HDF5 file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread a GMSH MSH file and returns a Mesh instance.", "response": "def read_msh(path):\n  \"\"\"\n  Reads a GMSH MSH file and returns a :class:`Mesh` instance. \n  \n  :arg path: path to MSH file.\n  :type path: str\n  \n  \"\"\"\n  elementMap = { 15:\"point1\",\n                 1:\"line2\",\n                 2:\"tri3\",\n                 3:\"quad4\",\n                 4:\"tetra4\",\n                 5:\"hexa8\",\n                 6:\"prism6\",\n                 7:\"pyra4\",\n                 \n               }\n  lines = np.array(open(path, \"r\").readlines())\n  locs = {}\n  nl = len(lines)\n  for i in range(nl):\n    line = lines[i].lower().strip()\n    if line.startswith(\"$\"):\n      if line.startswith(\"$end\"):\n        locs[env].append(i)\n      else:\n        env = line[1:] \n        locs[env] = [i]\n  nodes = pd.read_csv(\n          io.StringIO(\"\\n\".join(\n                   lines[locs[\"nodes\"][0]+2:locs[\"nodes\"][1]])), \n                   sep = \" \",\n                   names = [\"labels\", \"x\", \"y\", \"z\"])\n  \n  elements = {\"labels\":[], \"etype\":[], \"conn\": [], \"tags\":[], \"sets\":{}}\n  \n  for line in lines[locs[\"elements\"][0]+2:locs[\"elements\"][1]]:\n    d = np.array([int(w) for w in line.split()])\n    elements[\"labels\"].append( d[0] )\n    elements[\"etype\"].append(elementMap[d[1]] )\n    elements[\"tags\"].append( d[3: 3+d[2]] ) \n    elements[\"conn\"].append(d[3+d[2]:])\n  elements[\"labels\"] = np.array(elements[\"labels\"])\n  physicalNames = {}\n  for line in lines[locs[\"physicalnames\"][0]+2:locs[\"physicalnames\"][1]]:\n    w = line.split()\n    physicalNames[int(w[1])] = w[2].replace('\"', '')\n  sets = {}\n  tags = np.array([t[0] for t in elements[\"tags\"]])\n  for k in physicalNames.keys():\n    sets[physicalNames[k]] = np.array([t == k for t in tags])     \n  \"\"\"\n  for tag, values in sets.items():\n    elements[\"sets\"][tag] = elements[\"labels\"][values]     \n  \"\"\"\n  elements[\"sets\"] = sets\n  return Mesh(nlabels = nodes[\"labels\"], \n              coords = np.array(nodes[[\"x\", \"y\", \"z\"]]),\n              elabels = elements[\"labels\"],\n              conn = elements[\"conn\"],\n              types = elements[\"etype\"],\n              esets = elements[\"sets\"])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread Abaqus inp file", "response": "def read_inp(path):\n  \"\"\"\n  Reads Abaqus inp file\n  \"\"\"\n  \n  def lineInfo(line):\n    out =  {\"type\": \"data\"}\n    if line[0] == \"*\":\n      if line[1] == \"*\": \n        out[\"type\"] = \"comment\"\n        out[\"text\"] = line[2:]\n      else:\n        out[\"type\"] = \"command\"\n        words = line[1:].split(\",\")\n        out[\"value\"] = words[0].strip()\n        out[\"options\"] = {}\n        for word in words[1:]:\n          key, value =  [s.strip() for s in word.split(\"=\")]\n          out[\"options\"][key] = value\n    return out\n  \n  def elementMapper(inpeltype):\n    if inpeltype == \"t3d2\": return \"Line2\"\n    if inpeltype[:3] in [\"cps\", \"cpe\", \"cax\"]:\n      if inpeltype[3] == \"3\": return \"tri3\"\n      if inpeltype[3] == \"4\": return \"quad4\"\n    if inpeltype[:3] in [\"c3d\"]:\n      if inpeltype[3] == \"4\": return \"tetra4\"\n      if inpeltype[3] == \"5\": return \"pyra5\"\n      if inpeltype[3] == \"6\": return \"prism6\"\n      if inpeltype[3] == \"8\": return \"hexa8\"\n    \n  nlabels      = []\n  coords       = []\n  nsets        = {}\n  elabels      = []\n  etypes       = []\n  connectivity = []\n  esets        = {}\n  surfaces     = {}\n  \n  # File preprocessing\n  lines = np.array([l.strip().lower() for l in open(path).readlines()])\n  lines = [line for line in  lines if len(line) != 0]\n  # Data processing\n  env, setlabel = None, None\n  for line in lines: \n    d = lineInfo(line)\n    if d[\"type\"] == \"command\": \n      env = d[\"value\"]\n      # Nodes\n      if env == \"node\":\n        opt = d[\"options\"]\n        currentset = None\n        if \"nset\" in opt.keys(): \n          currentset = opt[\"nset\"]\n          nsets[currentset] = []\n           \n      # Elements\n      if env == \"element\":\n        opt = d[\"options\"]\n        eltype = elementMapper(opt[\"type\"])\n        currentset = None\n        if \"elset\" in opt.keys(): \n          currentset = opt[\"elset\"]\n          esets[currentset] = []\n          \n      # Nsets\n      if env == \"nset\":\n        opt = d[\"options\"]      \n        currentset = opt[\"nset\"]\n        nsets[currentset] = []\n        \n      # Elsets     \n      if env == \"elset\":\n        opt = d[\"options\"]      \n        currentset = opt[\"elset\"]\n        esets[currentset] = []\n      \n      # Surfaces\n      if env == \"surface\":\n        opt = d[\"options\"]\n        currentsurface = opt[\"name\"]\n        if opt[\"type\"] == \"element\":\n          surfaces[currentsurface] = []  \n                    \n             \n    if d[\"type\"] == \"data\": \n      words = line.strip().split(\",\")\n      if env == \"node\":\n        label = int(words[0]) \n        nlabels.append(label) \n        coords.append(\n            np.array([np.float64(w) for w in words[1:4]])\n                     )\n        if currentset != None: nsets[currentset].append(label)\n            \n              \n      if env == \"element\": \n        label  = int(words[0])\n        elabels.append(label)\n        connectivity.append(\n            np.array( [np.int32(w) for w in words[1:] if len(w) != 0 ])\n                           )\n        etypes.append(eltype)                   \n        if currentset != None: esets[currentset].append(label)\n      \n      if env == \"nset\":\n        nsets[currentset] += [int(w) for w in words if len(w) != 0]   \n        \n      if env == \"elset\":\n        esets[currentset] += [int(w) for w in words if len(w) != 0]  \n      \n      if env == \"surface\":\n        if opt[\"type\"] == \"element\":\n          surfaces[currentsurface].append([w.strip() for w in words])\n  \n  surfaces2 = {}        \n  for tag, surface in surfaces.items():\n    surfaces2[tag] = []\n    for sdata in surface:\n      labels = esets[sdata[0]]\n      face = int(sdata[1].split(\"s\")[1].strip())-1\n      for label in labels:\n        surfaces2[tag].append((label, face))             \n  \n  return Mesh(nlabels = nlabels,\n              coords  = coords,\n              nsets   = nsets,\n              elabels = elabels,\n              etypes  = etypes,\n              connectivity = connectivity,\n              esets = esets,)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting the mesh to an XDMF file.", "response": "def write_xdmf(mesh, path, dataformat = \"XML\"):\n  \"\"\"\n  Dumps the mesh to XDMF format.\n  \"\"\"\n  pattern = Template(open(MODPATH + \"/templates/mesh/xdmf.xdmf\").read())\n  attribute_pattern = Template(open(MODPATH + \"/templates/mesh/xdmf_attribute.xdmf\").read())\n  # MAPPINGS\n  cell_map = {\n      \"tri3\":   4,\n      \"quad4\":  5,\n      \"tetra4\": 6,\n      \"pyra5\":  7,\n      \"prism6\": 8,\n      \"hexa8\":  9}\n  # REFERENCES\n  nodes, elements = mesh.nodes.data, mesh.elements.data\n  fields = mesh.fields\n  # NUMBERS\n  Ne, Nn = len(elements), len(nodes)\n  # NODES\n  nodes_map = np.arange(nodes.index.max()+1)\n  nodes_map[nodes.index] = np.arange(len(nodes.index))\n  nodes_map[0] = -1\n  # ELEMENTS\n  cols = [\"n{0}\".format(i) for i in range(elements.shape[1]-1)]\n  connectivities  = mesh.elements.data[cols].as_matrix()\n  connectivities[np.isnan(connectivities)] = 0\n  connectivities = connectivities.astype(np.int32)\n  connectivities = nodes_map[connectivities]\n  labels          = np.array(elements.index)\n  etypes          = np.array([cell_map[t] for t in elements.etype])\n  lconn           = Ne + (connectivities != -1).sum()\n  # FIELDS\n  fields_string = \"\"\n  field_data = {}\n  for tag, field in fields.items():\n      field_data[tag] = {}\n      field.data.sort_index(inplace = True)\n      fshape = field.data.shape[1]\n      if   fshape  == 1: ftype = \"Scalar\"\n      elif fshape  == 3: ftype = \"Vector\"\n      elif fshape  == 2: \n        ftype = \"Vector\"\n        # UGLY HACK...\n        field = copy.copy(field)\n        field.data[\"v3\"] = np.zeros_like(field.data.index)\n        fields[tag] = field\n        # BACK TO NORMAL  \n      elif fshape  == 6: ftype = \"Tensor6\"\n      elif fshape  == 4: \n        ftype = \"Tensor6\"\n        # UGLY HACK...\n        field = copy.copy(field)\n        field.data[\"v13\"] = np.zeros_like(field.data.index)\n        field.data[\"v23\"] = np.zeros_like(field.data.index)\n        fields[tag] = field\n        # BACK TO NORMAL  \n      if field.metadata.position == \"Nodal\": \n        position = \"Node\"\n      if field.metadata.position == \"Element\":\n        position = \"Cell\"  \n      field_data[tag][\"TAG\"]           = tag\n      field_data[tag][\"ATTRIBUTETYPE\"] = ftype\n      field_data[tag][\"FORMAT\"]        = dataformat\n      field_data[tag][\"FIELD_DIMENSION\"] = \" \".join([str(l) for l in field.data.shape])\n      field_data[tag][\"POSITION\"]      = position                             \n  if dataformat == \"XML\":\n    #NODES\n    nodes_string = \"\\n\".join([11*\" \" + \"{0} {1} {2}\".format(\n                              n.x, \n                              n.y, \n                              n.z) \n                        for i, n in nodes.iterrows()])\n    # ELEMENTS\n    elements_string = \"\"\n    for i in range(Ne):\n      elements_string += 11*\" \" + str(etypes[i]) + \" \"\n      c = connectivities[i]\n      c = c[np.where(c != -1)]\n      elements_string += \" \".join([str(i) for i in c]) + \"\\n\"\n    elements_strings = elements_string[:-1]  \n    # FIELDS\n    for tag, field in fields.items():\n      fdata = field.data.to_csv(sep = \" \", \n                                index = False, \n                                header = False).split(\"\\n\")\n      fdata = [11 * \" \" + l for l in fdata]\n      fdata = \"\\n\".join(fdata)\n      field_data[tag][\"DATA\"] = fdata\n      fields_string += attribute_pattern.substitute(**field_data[tag])     \n  elif dataformat == \"HDF\":\n    hdf = pd.HDFStore(path + \".h5\")\n    hdf.put(\"COORDS\", mesh.nodes.data[list(\"xyz\")])\n    flatconn = np.zeros(lconn, dtype = np.int32)\n    pos = 0\n    for i in range(Ne):\n      c = connectivities[i]\n      c = c[np.where(c != -1)]\n      lc = len(c)\n      flatconn[pos] = etypes[i]\n      flatconn[pos + 1 + np.arange(lc)] = c\n      pos += 1 + lc\n    hdf.put(\"CONNECTIVITY\", pd.DataFrame(flatconn))  \n    nodes_string = 11*\" \" + \"{0}.h5:/COORDS/block0_values\".format(path)\n    elements_string = 11*\" \" + \"{0}.h5:/CONNECTIVITY/block0_values\".format(path)\n    for tag, field in fields.items():\n      fstrings[tag] = fstrings[tag].replace(\"#DATA\", \n         11*\" \" + \"{0}.h5:/FIELDS/{1}/block0_values\".format(path, tag))\n      fields_string += fstrings[tag]         \n      hdf.put(\"FIELDS/{0}\".format(tag), fields.data)\n    hdf.close()\n  \"\"\"\n  pattern = pattern.replace(\"#ELEMENT_NUMBER\", str(Ne))\n  pattern = pattern.replace(\"#CONN_DIMENSION\", str(lconn))\n  pattern = pattern.replace(\"#CONN_PATH\", elements_string)\n  pattern = pattern.replace(\"#NODE_NUMBER\", str(Nn))\n  pattern = pattern.replace(\"#NODE_PATH\", nodes_string)\n  pattern = pattern.replace(\"#DATAFORMAT\", dataformat)\n  pattern = pattern.replace(\"#ATTRIBUTES\", fields_string) \n  \"\"\"\n  fields_string = \"\\n\".join([attribute_pattern.substitute(**value) for key, value in field_data.items()])\n  pattern = pattern.substitute(\n     ELEMENT_NUMBER = str(Ne),\n     CONN_DIMENSION = str(lconn),\n     CONN_PATH      = elements_string,\n     NODE_NUMBER    = str(Nn),\n     NODE_PATH      = nodes_string,\n     DATAFORMAT     = dataformat,\n     ATTRIBUTES     = fields_string)\n  open(path + \".xdmf\", \"wb\").write(pattern)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_inp(mesh, path = None, maxwidth = 40, sections = \"solid\"):\n  def set_to_inp(sets, keyword):\n    ss = \"\"\n    for sk in sets.keys():\n      labels = sets[sk].loc[sets[sk]].index.values\n      labels = list(labels)\n      labels.sort()\n      if len(labels)!= 0:\n        ss += \"*{0}, {0}={1}\\n\".format(keyword, sk)\n        ss += argiope.utils.list_to_string(labels) + \"\\n\"\n    return ss.strip()           \n\n  # DATA\n  mesh = mesh.copy()\n\n  # NODES\n  nodes_output = (mesh.nodes.coords.to_csv(header = False).split())\n  nodes_output = (\"\\n\".join([\"  \" + s.replace(\",\", \", \") for s in nodes_output]))\n  \n  # NODE SETS\n  if \"sets\" in mesh.nodes.columns.levels[0]: \n    nsets = set_to_inp(mesh.nodes.sets, \"NSET\")\n  else:\n    nsets = \"**\"\n  \n  # SURFACES \n  surf_output = []\n  if \"surfaces\" in mesh.elements.keys():\n    sk = mesh.elements.surfaces.keys()\n    for sindex in  np.unique(sk.labels[0]):\n      slabel = sk.levels[0][sindex]\n      surface = mesh.elements.surfaces[slabel]\n      if surface.values.sum() != 0:\n        mesh.surface_to_element_sets(slabel)\n        surf_output.append( \"*SURFACE, TYPE=ELEMENT, NAME={0}\".format(slabel))\n        for findex in surface.keys():\n          if surface[findex].sum() != 0:\n            surf_output.append(\"  _SURF_{0}_FACE{1}, S{1}\".format(slabel, \n                                                                  findex[1:])) \n  else:\n    surf_output.append(\"**\")\n  \n  # ELEMENTS\n  elements_output = \"\"\n  for etype, group in mesh.elements.groupby(((\"type\", \"solver\", \"\"),)):\n    els = group.conn.replace(0, np.nan).to_csv(header = False, \n                                               float_format='%.0f').split()\n    elements_output += \"*ELEMENT, TYPE={0}\\n\".format(etype)\n    elements_output += (\"\\n\".join([\"  \" + s.strip().strip(\",\").\n                             replace(\",\", \", \") for s in els]))\n    elements_output += \"\\n\"\n  elements_output = elements_output.strip() \n  el_sets = {} \n\n  # MATERIALS\n  section_output = \"\"\n  for material, group in mesh.elements.groupby(\"materials\"):\n    slabel = \"_MAT_{0}\".format(material)\n    section_output += \"*ELSET, ELSET=_MAT_{0}\\n{1}\\n\".format(\n                 material,\n                 argiope.utils.list_to_string(group.index.values))\n    \n    \n    #mesh.elements[(\"sets\", slabel, \"\")] = False\n    #mesh.elements.loc[group.index, (\"sets\", slabel, \"\")] = True\n    if sections == \"solid\":\n      section_output += \"*SOLID SECTION, ELSET=_MAT_{0}, MATERIAL={0}\\n\".format(\n       material)\n\n  # ELEMENTS SETS\n  if \"sets\" in mesh.elements.columns.levels[0]: \n    esets = set_to_inp(mesh.elements.sets.swaplevel(1,0, axis = 1)[\"\"],\"ELSET\")\n  else:\n    esets = \"**\"\n  \"\"\"\n  ek = mesh.elements.sets.keys()\n  for esindex in  np.unique(ek.labels[0]):\n    eslabel = ek.levels[0][esindex]\n    eset = mesh.elements.sets[slabel]\n  \"\"\"\n     \n  # PATTERN\n  pattern = Template(open(MODPATH + \"/templates/mesh/inp.inp\").read())\n  pattern = pattern.substitute(\n    NODES     = nodes_output,\n    NODE_SETS = nsets,\n    ELEMENTS  = elements_output,\n    ELEMENT_SETS = esets,\n    ELEMENT_SURFACES = \"\\n\".join(surf_output),\n    SECTIONS = section_output.strip())\n  pattern = pattern.strip()\n  if path == None:            \n    return pattern\n  else:\n    open(path, \"w\").write(pattern)", "response": "Writes the INP file for the given mesh."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a Connectivity array for a given shape.", "response": "def _make_conn(shape):\n    \"\"\"\n    Connectivity builder using Numba for speed boost.\n    \"\"\"\n    shape = np.array(shape)\n    Ne = shape.prod()\n    if len(shape) == 2:\n        nx, ny = np.array(shape) +1 \n        conn = np.zeros((Ne, 4), dtype = np.int32)\n        counter = 0\n        pattern = np.array([0,1,1+nx,nx])\n        for j in range(shape[1]):\n            for i in range(shape[0]):\n                conn[counter] = pattern + 1 + i + j*nx\n                counter += 1\n        \n    if len(shape) == 3:\n        nx, ny, nz  = np.array(shape) +1 \n        conn = np.zeros((Ne, 8), dtype = np.int32)\n        counter = 0\n        pattern = np.array([0,1,1+nx,nx,nx*ny,1+nx*ny,1+(nx+1)*ny,(nx+1)*ny])\n        for k in range(shape[2]):\n            for j in range(shape[1]):\n                for i in range(shape[0]):\n                    conn[counter] = pattern + 1 + i + j*nx+ k*nx*ny\n                    counter += 1\n    return conn"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a structured mesh.", "response": "def structured_mesh(shape = (2,2,2), dim = (1.,1.,1.)):\n    \"\"\"\n    Returns a structured mesh. \n    \n    :arg shape: 2 or 3 integers (eg: shape = (10, 10, 10)).\n    :type shape: tuple\n    :arg dim: 2 or 3 floats (eg: dim = (4., 2., 1.))\n    :type dim: tuple\n    \n    .. note::\n\n       This function does not use GMSH for mesh generation.\n\n\n    \n    >>> import argiope as ag\n    >>> mesh = ag.mesh.structured_mesh(shape =(10,10,10), dim=(1.,1.,1.)))\n    \"\"\"\n    # PREPROCESSING\n    shape = np.array(shape)\n    dim   = np.array(dim) \n    Ne = shape.prod()\n    Nn = (shape + 1).prod()\n    # LABELS\n    nindex = np.arange(Nn) + 1\n    eindex = np.arange(Ne) + 1\n    # COORDINATES\n    coords = [ np.linspace(0., dim[i], shape[i] + 1) for i in range(len(shape))]\n    coords = np.array(np.meshgrid(*coords))\n    coords = np.array([c.swapaxes(0,1).flatten(\"F\") for c in coords]).T\n    if len(shape) == 2:\n        c = coords\n        coords = np.zeros((Nn, 3))\n        coords[:, :2] = c  \n    # CONNECTIVITY    \n    conn = _make_conn(shape)\n    # MESH INSTANCE\n    mesh = Mesh(nlabels = nindex,\n                coords  = coords,\n                elabels = eindex,\n                conn = conn,)\n    if len(shape) == 2: mesh.elements[(\"type\", \"argiope\")] = \"quad4\"\n    if len(shape) == 3: mesh.elements[(\"type\", \"argiope\")] = \"hexa8\"    \n    return mesh"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the elements of a single element group.", "response": "def set_elements(self, elabels = None, \n                         types = None, \n                         stypes = \"\", \n                         conn = None, \n                         esets = {}, \n                         surfaces = {}, \n                         materials = \"\",\n                         **kwargs):\n    \"\"\"\n    Sets the element data.\n    \n    :arg elabels: element labels. Items be strictly positive and int typed \n                  in 1D array-like with shape :math:`(N_e)`.\n    :type elabels: 1D uint typed array-like\n    :arg types: element types chosen among argiope specific element types. \n    :type types: str typed array-like \n    :arg stypes: element types chosen in solver (depends on the chosen solver) specific element types. \n    :type stypes: str typed array-like \n    :arg conn: connectivity table. In order to deal with non rectangular tables, :math:`0` can be used to fill missing data. \n    :type conn: uint typed array-like\n    :arg esets: element sets. Contains boolean array-like of shape :math:`(N_e)`.\n    :type esets: dict  \n    :arg surfaces: surfaces. Contains boolean array-like of shape :math:`(N_e, N_s )` with :math:`N_s` being the maximum number of faces on a single element. \n    :type surfaces: dict   \n    :arg materials: material keys. Any number a of materials can be used.\n    :type materials: str typed array-like \n     \n      \n      \n           \n    \"\"\"\n    # COLUMNS BUILDING\n    if elabels is None:\n       warnings.warn(\n       \"Since no element labels where provided, no elements where created\", \n       Warning)\n       self.elements = None\n    else:   \n      columns = pd.MultiIndex.from_tuples([(\"type\", \"argiope\", \"\")])\n      self.elements = pd.DataFrame(data = types,\n                                   columns = columns,\n                                   index = elabels)\n      self.elements.index.name = \"element\"\n      self.elements.loc[:, (\"type\", \"solver\", \"\")] = stypes\n      # Connectivity \n      c = pd.DataFrame(conn, index = elabels)\n      c.fillna(0, inplace = True)\n      c[:] = c.values.astype(np.int32)\n      c.columns = pd.MultiIndex.from_product([[\"conn\"], \n                                              [\"n{0}\".format(n) for \n                                               n in np.arange(c.shape[1])], \n                                              [\"\"]])\n      self.elements = self.elements.join(c)\n      # Sets\n      for k, v in esets.items(): self.elements[(\"sets\", k, \"\")] = v\n      self.elements[\"sets\", \"all\", \"\"] = True  \n      # Surfaces\n      for k, v in surfaces.items():\n        for fk, vv in v.items():\n          self.elements[(\"surfaces\", k, \"s{0}\".format(fk))] = vv\n      # Materials\n      self.elements[(\"materials\", \"\", \"\") ] = materials\n      self.elements.sort_index(axis = 1, inplace = True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd the fields to the list of fields.", "response": "def add_fields(self, fields = None, **kwargs):\n    \"\"\"\n    Add the fields into the list of fields.\n    \"\"\"\n    if fields != None:\n      for field in fields: \n        self.fields.append(field)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the dimension of the embedded space of each element.", "response": "def space(self):\n    \"\"\"\n    Returns the dimension of the embedded space of each element.\n    \"\"\"\n    return self.elements.type.argiope.map(\n           lambda t: ELEMENTS[t].space)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the number of vertices of the eache element according to its type", "response": "def nvert(self):\n    \"\"\"\n    Returns the number of vertices of eache element according to its type/\n    \"\"\"\n    return self.elements.type.argiope.map(\n           lambda t: ELEMENTS[t].nvert)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit the tree into a list of nodes.", "response": "def split(self, into = \"edges\", loc = None, \n            at = \"labels\", sort_index = True):\n    \"\"\"\n    Returns the decomposition of the elements.\n    \n    Inputs:\n    * into: must be in ['edges', 'faces', 'simplices', 'angles']\n    * loc: None or labels of the chosen elements.\n    * at: must be in ['labels', 'coords']\n    \"\"\"\n    if type(loc) == type(None):\n      elements = self.elements\n    else:  \n      elements = self.elements.loc[loc]\n    out = []\n    for etype, group in elements.groupby([(\"type\", \"argiope\", \"\")]):\n      try:\n        output_maps = getattr(ELEMENTS[etype], into)\n        for om in range(len(output_maps)):\n          oshape = len(output_maps[om])\n          conn = group.conn\n          columns = pd.MultiIndex.from_product([(om,), np.arange(oshape)], \n                                                names = [into, \"vertex\"])\n          data = (conn.values[:, output_maps[om]].reshape(len(conn), oshape))\n          df = pd.DataFrame(data = data, \n                            columns = columns,\n                            index = conn.index).stack((0,1))\n          out.append(df)\n      except:\n        print(\"Can not extract '{0}' from '{1}'\".format(into, etype))                           \n    if len(out) != 0:\n      out = pd.concat(out)\n      out.sort_index(inplace = True)\n      if at == \"coords\":\n        data = self.nodes.coords.loc[out.values].values\n        out = pd.DataFrame(index = out.index, data = data, \n                           columns = [\"x\", \"y\", \"z\"])\n      return out"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef centroids_and_volumes(self, sort_index = True):\n    elements = self.elements\n    out = []\n    for etype, group in self.elements.groupby([(\"type\", \"argiope\", \"\")]):\n      etype_info = ELEMENTS[etype]\n      simplices_info = etype_info.simplices\n      index = group.index\n      simplices_data = self.split(into = \"simplices\", \n                             loc = index,\n                             at = \"coords\") \n      simplices = simplices_data.values.reshape(\n                  index.size, \n                  simplices_info.shape[0], \n                  simplices_info.shape[1], \n                  3) \n      edges = simplices[:,:,1:] - simplices[:,:,:1] \n      simplices_centroids = simplices.mean(axis = 2)\n      if etype_info.space == 2:\n        simplices_volumes = np.linalg.norm(\n                  np.cross(edges[:,:,0], \n                           edges[:,:,1], \n                           axis = 2),\n                  axis = 2)/2.\n      elif etype_info.space == 3:          \n        simplices_volumes =  (np.cross(edges[:,:,0], \n                                       edges[:,:,1], axis = 2) \n                             * edges[:,:, 2]).sum(axis = 2) / 6.\n      elements_volumes = simplices_volumes.sum(axis = 1)\n      elements_centroids = ((simplices_volumes.reshape(*simplices_volumes.shape, 1) \n                          * simplices_centroids).sum(axis = 1) \n                          / elements_volumes.reshape(*elements_volumes.shape,1))\n      volumes_df = pd.DataFrame(index = index,\n                                data = elements_volumes,\n                                columns = pd.MultiIndex.from_product(\n                                [[\"volume\"], [\"\"]]))\n      centroids_df = pd.DataFrame(index = index,\n                                data = elements_centroids,\n                                columns = pd.MultiIndex.from_product(\n                                [[\"centroid\"], [\"x\", \"y\", \"z\"]]))                          \n      out.append(pd.concat([volumes_df, centroids_df], axis = 1))             \n    out = pd.concat(out)  \n    if sort_index: out.sort_index(inplace = True)\n    return out.sort_index(axis= 1)", "response": "Returns a dataframe containing the volume and centroids of all the elements."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the internal angles of all elements and the associated statistics", "response": "def angles(self, zfill = 3):\n    \"\"\"\n    Returns the internal angles of all elements and the associated statistics \n    \"\"\"\n    elements = self.elements.sort_index(axis = 1)\n    etypes = elements[(\"type\", \"argiope\")].unique()\n    out = []\n    for etype in etypes:\n      etype_info = ELEMENTS[etype]\n      angles_info = etype_info.angles\n      loc = elements[(\"type\", \"argiope\", \"\")] == etype\n      index = elements.loc[loc].index\n      angles_data = self.split(into = \"angles\", \n                             loc = loc,\n                             at = \"coords\")\n      data = angles_data.values.reshape(index.size, \n                                        angles_info.shape[0],\n                                        angles_info.shape[1],\n                                        3)        \n      edges = data[:,:,[0,2],:] - data[:,:,1:2,:]\n      edges /= np.linalg.norm(edges, axis = 3).reshape(\n               index.size, angles_info.shape[0], 2, 1)\n      angles = np.degrees(np.arccos((\n               edges[:,:,0] * edges[:,:,1]).sum(axis = 2)))\n\n      deviation = angles - etype_info.optimal_angles\n      angles_df = pd.DataFrame(index = index, \n                               data = angles, \n                               columns = pd.MultiIndex.from_product(\n      [[\"angles\"], [\"a\" + \"{0}\".format(s).zfill(zfill) \n              for s in range(angles_info.shape[0])]]))\n      deviation_df = pd.DataFrame(index = index, \n                               data = deviation, \n                               columns = pd.MultiIndex.from_product(\n      [[\"deviation\"], [\"d\" + \"{0}\".format(s).zfill(zfill) \n              for s in range(angles_info.shape[0])]]))\n      \n      df = pd.concat([angles_df, deviation_df], axis = 1).sort_index(axis = 1)\n      df[\"stats\", \"max_angle\"] = df.angles.max(axis = 1)\n      df[\"stats\", \"min_angle\"] = df.angles.min(axis = 1)\n      df[\"stats\", \"max_angular_deviation\"] = df.deviation.max(axis = 1)\n      df[\"stats\", \"min_angular_deviation\"] = df.deviation.min(axis = 1)\n      df[\"stats\", \"max_abs_angular_deviation\"] = abs(df.deviation).max(axis = 1)    \n      df = df.sort_index(axis = 1)  \n      out.append(df)\n      \n    out = pd.concat(out).sort_index(axis = 1)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the aspect ratio of all elements in the sequence.", "response": "def edges(self, zfill = 3):\n    \"\"\"\n    Returns the aspect ratio of all elements.\n    \"\"\"\n    edges = self.split(\"edges\", at = \"coords\").unstack()\n    edges[\"lx\"] = edges.x[1]-edges.x[0]\n    edges[\"ly\"] = edges.y[1]-edges.y[0]\n    edges[\"lz\"] = edges.z[1]-edges.z[0]\n    edges[\"l\"] = np.linalg.norm(edges[[\"lx\", \"ly\", \"lz\"]], axis = 1)\n    edges = (edges.l).unstack()\n    edges.columns = pd.MultiIndex.from_product([[\"length\"], \n                    [\"e\" + \"{0}\".format(s).zfill(zfill) \n                    for s in np.arange(edges.shape[1])]])\n    edges[(\"stats\", \"lmax\")] = edges.length.max(axis = 1)\n    edges[(\"stats\", \"lmin\")] = edges.length.min(axis = 1)\n    edges[(\"stats\", \"aspect_ratio\")] = edges.stats.lmax / edges.stats.lmin\n    return edges.sort_index(axis = 1)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stats(self):\n    cv = self.centroids_and_volumes()\n    angles  = self.angles()\n    edges = self.edges()\n    return pd.concat([cv , angles[[\"stats\"]], edges[[\"stats\"]] ], \n                     axis = 1).sort_index(axis = 1)", "response": "Returns a DataFrame with the stats of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes a node set from an element set.", "response": "def element_set_to_node_set(self, tag):\n    \"\"\"\n    Makes a node set from an element set.\n    \"\"\"\n    nodes, elements = self.nodes, self.elements\n    loc = (elements.conn[elements[(\"sets\", tag, \"\")]]\n           .stack().stack().unique())\n    loc = loc[loc != 0]\n    nodes[(\"sets\", tag)] = False\n    nodes.loc[loc, (\"sets\", tag) ] = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef node_set_to_surface(self, tag):\n    # Create a dummy node with label 0\n    nodes = self.nodes.copy()\n    dummy = nodes.iloc[0].copy()\n    dummy[\"coords\"] *= np.nan\n    dummy[\"sets\"] = True\n    nodes.loc[0] = dummy\n    # Getting element surfaces\n    element_surfaces= self.split(\"surfaces\").unstack()\n    # killer hack !\n    surf = pd.DataFrame(\n             nodes.sets[tag].loc[element_surfaces.values.flatten()]\n                   .values.reshape(element_surfaces.shape)\n                   .prod(axis = 1)\n                   .astype(np.bool),\n             index = element_surfaces.index).unstack().fillna(False)\n    for k in surf.keys():\n      self.elements[\"surfaces\", tag, \"f{0}\".format(k[1]+1) ] = surf.loc[:, k]", "response": "Converts a node set to surface."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating elements sets corresponding to a surface.", "response": "def surface_to_element_sets(self, tag):\n    \"\"\"\n    Creates elements sets corresponding to a surface.\n    \"\"\"\n    surface = self.elements.surfaces[tag]\n    for findex in surface.keys():\n      if surface[findex].sum() != 0:\n        self.elements[(\"sets\", \"_SURF_{0}_FACE{1}\"\n                     .format(tag, findex[1:]), \"\")] = surface[findex]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_polycollection(self, *args, **kwargs):\n    from matplotlib import collections\n    nodes, elements = self.nodes, self.elements.reset_index()\n    verts = []\n    index = []\n    for etype, group in elements.groupby([(\"type\", \"argiope\", \"\")]):\n      index += list(group.index)\n      nvert = ELEMENTS[etype].nvert\n      conn = group.conn.values[:, :nvert].flatten()\n      coords = nodes.coords[[\"x\", \"y\"]].loc[conn].values.reshape(\n                                            len(group), nvert, 2)\n      verts += list(coords)\n    verts = np.array(verts)\n    verts= verts[np.argsort(index)]\n    return collections.PolyCollection(verts, *args,**kwargs )", "response": "Returns the mesh as matplotlib polygon collection."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_triangulation(self):\n    from matplotlib.tri import Triangulation\n    conn = self.split(\"simplices\").unstack()\n    coords = self.nodes.coords.copy()\n    node_map  = pd.Series(data = np.arange(len(coords)), index = coords.index)\n    conn = node_map.loc[conn.values.flatten()].values.reshape(*conn.shape)\n    return Triangulation(coords.x.values, coords.y.values, conn)", "response": "Returns the mesh as a matplotlib. tri. Triangulation instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the fields metadata as a dataframe.", "response": "def fields_metadata(self):\n    \"\"\"\n    Returns fields metadata as a dataframe.\n    \"\"\"  \n    return (pd.concat([f.metadata() for f in self.fields], axis = 1)\n            .transpose()\n            .sort_values([\"step_num\", \"frame\", \"label\", \"position\"]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dataframe containing the metadata of the current node.", "response": "def metadata(self):\n    \"\"\"\n    Returns metadata as a dataframe.\n    \"\"\"\n    return pd.Series({\n           \"part\": self.part,\n           \"step_num\": self.step_num,\n           \"step_label\": self.step_label,\n           \"frame\": self.frame,\n           \"frame_value\": self.frame_value,\n           \"label\": self.label,\n           \"position\": self.position,                    \n    })"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_directories(self):\n    if os.path.isdir(self.workdir) == False: os.mkdir(self.workdir)", "response": "Checks if required directories exist and creates them if needed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_postproc(self):\n    t0 = time.time()\n    if self.verbose: \n      print('####\u00a0POST-PROCESSING \"{0}\" USING POST-PROCESSOR \"{1}\"'.format(self.label, \n                                               self.solver.upper()))  \n    if self.solver == \"abaqus\":\n      command = '{0} viewer noGUI={1}_abqpp.py'.format(self.solver_path, self.label)\n      process = subprocess.Popen( \n                command, \n                cwd    = self.workdir,\n                shell  = True,\n                stdout = subprocess.PIPE,\n                stderr = subprocess.STDOUT)\n      \n      for line in iter(process.stdout.readline, b''):\n         line = line.rstrip().decode('utf8')\n         print(\"    \", line)\n    t1 = time.time()\n    if self.verbose: \n      print('  => POST-PROCESSED {0}: DURATION = {1:.2f}s >'.format(self.label, \n                                                                  t1 - t0))", "response": "Runs the post - proc script."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_gmsh(self):\n    argiope.utils.run_gmsh(gmsh_path = self.gmsh_path,\n                           gmsh_space = self.gmsh_space,\n                           gmsh_options = self.gmsh_options,\n                           name = self.file_name + \".geo\",\n                           workdir = self.workdir)  \n    self.mesh = argiope.mesh.read_msh(self.workdir + self.file_name + \".msh\")", "response": "Takes the gmsh file and runs it"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a history output report.", "response": "def read_history_report(path, steps, x_name = None):\n  \"\"\"\n  Reads an history output report.\n  \"\"\"\n  data = pd.read_csv(path, delim_whitespace = True)\n  if x_name != None:\n    data[x_name] = data.X\n    del data[\"X\"]\n    \n  data[\"step\"] = 0\n  t = 0.\n  for i in range(len(steps)):\n    dt = steps[i].duration\n    loc = data[data.t == t].index\n    if len(loc) == 2:\n      data.loc[loc[1]:, \"step\"] = i\n    t += dt \n  return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_field_report(path, data_flag = \"*DATA\", meta_data_flag = \"*METADATA\"):\n  text = open(path).read()\n  mdpos = text.find(meta_data_flag)\n  dpos = text.find(data_flag)\n  mdata = io.StringIO( \"\\n\".join(text[mdpos:dpos].split(\"\\n\")[1:]))\n  data = io.StringIO( \"\\n\".join(text[dpos:].split(\"\\n\")[1:]))\n  data = pd.read_csv(data, index_col = 0)\n  data = data.groupby(data.index).mean()\n  mdata = pd.read_csv(mdata, sep = \"=\", header = None, index_col = 0)[1]\n  mdata = mdata.to_dict()\n  out = {}\n  out[\"step_num\"] = int(mdata[\"step_num\"])\n  out[\"step_label\"] = mdata[\"step_label\"]\n  out[\"frame\"] = int(mdata[\"frame\"])\n  out[\"frame_value\"] = float(mdata[\"frame_value\"])\n  out[\"part\"] = mdata[\"instance\"]\n  position_map = {\"NODAL\": \"node\", \n                  \"ELEMENT_CENTROID\": \"element\", \n                  \"WHOLE_ELEMENT\": \"element\"}\n  out[\"position\"] = position_map[mdata[\"position\"]]\n  out[\"label\"] = mdata[\"label\"]  \n  out[\"data\"] = data\n  field_class = getattr(argiope.mesh, mdata[\"argiope_class\"])\n  return field_class(**out)", "response": "Reads a field output report."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a list - like to string with given line width.", "response": "def list_to_string(l = range(200), width = 40, indent = \"  \"):\n    \"\"\"\n    Converts a list-like to string with given line width.\n    \"\"\"\n    l = [str(v) + \",\" for v in l]\n    counter = 0\n    out = \"\" + indent\n    for w in l:\n        s = len(w)\n        if counter + s > width: \n            out += \"\\n\" + indent\n            counter = 0\n        out += w\n        counter += s\n    return out.strip(\",\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _equation(nodes = (1, 2), dofs = (1, 1), coefficients = (1., 1.), \n              comment = None):\n    \"\"\"\n    Returns an Abaqus INP formated string for a given linear equation.\n    \"\"\"\n    N = len(nodes)\n    if comment == None:\n      out = \"\"\n    else:\n      out = \"**EQUATION: {0}\\n\".format(comment)  \n    out+= \"*EQUATION\\n  {0}\\n  \".format(N)\n    out += \"\\n  \".join([ \",\".join([ str(nodes[i]), \n                                  str(int(dofs[i])), \n                                  str(coefficients[i]) ]) for i in range(N)])\n    return out", "response": "Returns an Abaqus INP formated string for a given linear equation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a set as inp string with unsorted option.", "response": "def _unsorted_set(df, label, **kwargs):\n    \"\"\"\n    Returns a set as inp string with unsorted option.\n    \"\"\"\n    out = \"*NSET, NSET={0}, UNSORTED\\n\".format(label)\n    labels = df.index.values\n    return out + argiope.utils.list_to_string(labels, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_response(self, response):\n        payload = None\n        try:\n            if isinstance(response.json, collections.Callable):\n                payload = response.json()\n            else:\n                # json isn't callable in old versions of requests\n                payload = response.json\n        except ValueError:\n            # response does not have JSON content\n            payload = response.content\n\n        if not self._raise_errors:\n            return payload\n        else:\n            if response.status_code == 401:\n                raise AuthenticationError(payload['message'])\n            elif response.status_code == 500:\n                raise ServerError(payload['message'])\n            elif isinstance(payload, dict) and not payload['success']:\n                raise APIError(payload['message'])\n            else:\n                return payload", "response": "Parses the API response and raises appropriate\nAttributeNames errors if raise_errors was set to True\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding the url for the specified method and arguments and returns the response as a dictionary.", "response": "def _get(self, method, **kwargs):\n        \"\"\"Builds the url for the specified method and arguments and returns\n        the response as a dictionary.\n        \"\"\"\n\n        payload = kwargs.copy()\n        payload['api_key'] = self.api_key\n        payload['api_secret'] = self.api_secret\n\n        to = payload.pop('to', None)\n        if to:\n            if isinstance(to, basestring):\n                payload['to'] = to\n            else:\n                # Presumably it's a list or tuple\n                for num_i, fax_num in enumerate(to):\n                    payload['to[%d]' % num_i] = fax_num\n\n        files = payload.pop('files', [])\n        if not isinstance(files, (list, tuple)): files = (files,)\n\n        req_files = {}\n        for file_i, f in enumerate(files):\n            if isinstance(f, basestring):\n                req_files['filename[%d]' % file_i] = open(f, 'rb')\n            else:\n                f.seek(0)\n                req_files['filename[%d]' % file_i] = f\n\n        url = '%s/v%d/%s' % (self.BASE_URL, self.VERSION, method)\n\n        r = requests.post(url, data=payload, files=req_files)\n\n        return self.parse_response(r)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the material definition as a string in Abaqus INP format.", "response": "def write_inp(self):\n     \"\"\"\n     Returns the material definition as a string in Abaqus INP format.\n     \"\"\"\n     template = self.get_template()\n     return template.substitute({\"class\": self.__class__.__name__,\n                                 \"label\": self.label}).strip()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_inp(self):\n    template = self.get_template()\n    plastic_table = self.get_plastic_table()\n    return template.substitute({\n        \"class\": self.__class__.__name__,\n        \"label\": self.label,\n        \"young_modulus\": self.young_modulus,\n        \"poisson_ratio\": self.poisson_ratio,\n        \"plastic_table\": (self.get_plastic_table()[[\"stress\", \"plastic_strain\"]]\n                          .to_csv(header = False, \n                                  index = False,\n                                  sep = \",\").strip())}).strip()", "response": "Returns the material definition as a string in Abaqus INP format."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_plastic_table(self):\n     E = self.young_modulus\n     sy = self.yield_stress\n     n = self.hardening_exponent\n     eps_max = self.max_strain\n     Np = self.strain_data_points\n     ey = sy/E\n     s = 10.**np.linspace(0., np.log10(eps_max/ey), Np)\n     strain = ey * s\n     stress = sy * s**n\n     plastic_strain = strain - stress / E \n     return pd.DataFrame({\"strain\": strain, \n                          \"stress\": stress, \n                          \"plastic_strain\": plastic_strain})", "response": "Calculates the plastic data for a given set of data points."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the plastic data for a given set of data points.", "response": "def get_plastic_table(self):\n     \"\"\"\n     Calculates the plastic data\n     \"\"\"\n     K = self.consistency\n     sy = self.yield_stress\n     n = self.hardening_exponent\n     eps_max = self.max_strain\n     Np = self.strain_data_points\n     plastic_strain = np.linspace(0., eps_max, Np)\n     stress = sy + K * plastic_strain**n \n     return pd.DataFrame({\"stress\": stress, \n                          \"plastic_strain\": plastic_strain})"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the DNA melting temp using nearest - neighbor thermodynamics.", "response": "def temp(s, DNA_c=5000.0, Na_c=10.0, Mg_c=20.0, dNTPs_c=10.0, uncorrected=False):\n    '''\n    Returns the DNA/DNA melting temp using nearest-neighbor thermodynamics.\n\n    This function returns better results than EMBOSS DAN because it uses updated\n    thermodynamics values and takes into account initialization parameters from\n    the work of SantaLucia (1998).\n\n    Corrects for mono- and divalent cation concentrations.\n\n    Arguments:\n    - DNA_c:   DNA concentration [nM]\n    - Na_c:    Na+ concentration [mM]\n    - Mg_c:    Mg2+ concentration [mM]\n    - dNTPs_c: dNTP concentration [mM]\n    - correction: correct for cation concentration?\n    '''\n\n    R = 1.987    # Universal gas constant (cal/(K*mol))\n    s = s.upper()\n    dh, ds = _tercorr(s)\n    k = DNA_c * 1e-9\n\n    # Adapted from Table 1 in Allawi and SantaLucia (1997).\n    # delta H (kcal/mol)\n    dh_coeffs = {\"AA\": -7.9, \"TT\": -7.9,\n                 \"AT\": -7.2,\n                 \"TA\": -7.2,\n                 \"CA\": -8.5, \"TG\": -8.5,\n                 \"GT\": -8.4, \"AC\": -8.4,\n                 \"CT\": -7.8, \"AG\": -7.8,\n                 \"GA\": -8.2, \"TC\": -8.2,\n                 \"CG\": -10.6,\n                 \"GC\": -9.8,\n                 \"GG\": -8.0, \"CC\": -8.0}\n\n    # delta S (eu)\n    ds_coeffs = {\"AA\": -22.2, \"TT\": -22.2,\n                 \"AT\": -20.4,\n                 \"TA\": -21.3,\n                 \"CA\": -22.7, \"TG\": -22.7,\n                 \"GT\": -22.4, \"AC\": -22.4,\n                 \"CT\": -21.0, \"AG\": -21.0,\n                 \"GA\": -22.2, \"TC\": -22.2,\n                 \"CG\": -27.2,\n                 \"GC\": -24.4,\n                 \"GG\": -19.9, \"CC\": -19.9}\n\n    # Multiplies the number of times each nuc pair is in the sequence by the\n    # appropriate coefficient, then returns the sum of all the pairs\n    dh = dh + \\\n        sum(_overcount(s, pair) * coeff for pair, coeff in dh_coeffs.items())\n    ds = ds + \\\n        sum(_overcount(s, pair) * coeff for pair, coeff in ds_coeffs.items())\n\n    fgc = len([filter(lambda x: x == 'G' or x == 'C', s)]) / float(len(s))\n\n    # Melting temperature\n    tm = (1000 * dh) / (ds + (R * log(k)))\n\n    if uncorrected:\n        return tm - 273.15\n\n    MNa = Na_c * 1e-3\n    MMg = Mg_c * 1e-3\n    MdNTPs = dNTPs_c * 1e-3\n\n    # Free magnesium concentration\n    Ka = 3e4  # association constant in biological buffers\n    D = (Ka * MdNTPs - Ka * MMg + 1)**2 + (4 * Ka * MMg)\n    Fmg = (-(Ka * MdNTPs - Ka * MMg + 1) + sqrt(D)) / (2 * Ka)\n\n    cation_ratio = sqrt(Fmg) / MNa if MNa > 0 else 7.0\n\n    if cation_ratio < 0.22:\n        tm = 1 / (\n            (1 / tm) +\n            ((4.29 * fgc - 3.95) * log(MNa) + 0.94 * log(MNa)**2) * 1e-5)\n    else:\n        a = 3.92\n        d = 1.42\n        g = 8.31\n        Fmg = MMg\n        if cation_ratio < 6.0:\n            a = a * (0.843 - 0.352 * sqrt(MNa) * log(MNa))\n            d = d * \\\n                (1.279 - 4.03 * log(MNa) * 1e-3 - 8.03 * log(MNa)**2 * 1e-3)\n            g = g * (0.486 - 0.258 * log(MNa) + 5.25 * log(MNa)**3 * 1e-3)\n        tm = 1 / (\n            (1 / tm) +\n            (a - 0.911 * log(Fmg) + fgc * (6.26 + d * log(Fmg)) +\n             1 / (2 * (len(s) - 1)) * (-48.2 + 52.5 * log(Fmg) +\n                                       g * log(Fmg)**2)) * 1e-5)\n\n    return tm - 273.15"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting a xy_report based on xy data.", "response": "def write_xy_report(odb, path, tags, columns, steps):\n  \"\"\"\n  Writes a xy_report based on xy data.\n  \"\"\"\n  xyData = [session.XYDataFromHistory(name = columns[i], \n                    odb = odb, \n                    outputVariableName = tags[i],\n                    steps = steps) \n            for i in xrange(len(tags))]\n  session.xyReportOptions.setValues(numDigits=8, numberFormat=SCIENTIFIC)\n  session.writeXYReport(fileName=path, appendMode=OFF, xyData=xyData)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_field_report(odb, path, label, argiope_class, variable, instance, output_position, \n                       step = -1, frame = -1, sortItem='Node Label'):\n  \"\"\"\n  Writes a field report and rewrites it in a cleaner format.\n  \"\"\"\n  stepKeys = get_steps(odb)\n  step = xrange(len(stepKeys))[step]\n  frame = xrange(get_frames(odb, stepKeys[step]))[frame]\n  nf = NumberFormat(numDigits=9, \n                    precision=0, \n                    format=SCIENTIFIC)\n  session.fieldReportOptions.setValues(\n          printTotal=OFF, \n          printMinMax=OFF, \n          numberFormat=nf)\n  leaf = dgo.LeafFromPartInstance(\n          partInstanceName = instance)\n  session.viewports['Viewport: 1'].odbDisplay.displayGroup.replace(leaf=leaf)\n  session.writeFieldReport(\n          fileName       = path, \n          append         = OFF, \n          sortItem       = sortItem,\n          odb            = odb, \n          step           = step, \n          frame          = frame, \n          outputPosition = output_position, \n          variable       = variable)\n  lines = [line.strip() for line in open(path).readlines()]\n  isdata = -1\n  data = []\n  for line in lines:\n   if isdata == 1:\n     if len(line) == 0: \n       isdata -= 1\n     else:\n       data.append(line)   \n   elif isdata < 1:\n     if line.startswith(\"--\"):\n       isdata += 1\n  data = \"\\n\".join([\",\".join(line.split()) for line in data if len(line) != 0])\n  # HEADER\n  header = str(output_position).lower() + \",\" \n  header += \",\".join([v[1] for v in variable[0][2]]) + \"\\n\"\n  # METADATA\n  metadata = (\n          (\"label\", label),\n          (\"argiope_class\", argiope_class) ,\n          (\"odb\", odb.path), \n          (\"instance\", instance),\n          (\"position\", output_position),\n          (\"step_num\", step),\n          (\"step_label\", stepKeys[step]),\n          (\"frame\", frame),\n          (\"frame_value\", odb.steps[stepKeys[step]].frames[frame].frameValue)\n              )\n  out = \"*METADATA\\n{0}\\n*DATA\\n{1}\".format(\n        \"\\n\".join([\"{0}={1}\".format(k, v) for k, v in metadata]),\n        header + data)           \n  open(path, \"w\").write(out)", "response": "Writes a field report to the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start(dashboards, once, secrets):\n\n    if secrets is None:\n        secrets = os.path.join(os.path.expanduser(\"~\"), \"/.doodledashboard/secrets\")\n\n    try:\n        loaded_secrets = try_read_secrets_file(secrets)\n    except InvalidSecretsException as err:\n        click.echo(get_error_message(err, default=\"Secrets file is invalid\"), err=True)\n        raise click.Abort()\n\n    read_configs = [\"\"\"\n    dashboard:\n      display:\n        type: console\n    \"\"\"]\n    for dashboard_file in dashboards:\n        read_configs.append(read_file(dashboard_file))\n\n    dashboard_config = DashboardConfigReader(initialise_component_loader(), loaded_secrets)\n\n    try:\n        dashboard = read_dashboard_from_config(dashboard_config, read_configs)\n    except YAMLError as err:\n        click.echo(get_error_message(err, default=\"Dashboard configuration is invalid\"), err=True)\n        raise click.Abort()\n\n    try:\n        DashboardValidator().validate(dashboard)\n    except ValidationException as err:\n        click.echo(get_error_message(err, default=\"Dashboard configuration is invalid\"), err=True)\n        raise click.Abort()\n\n    explain_dashboard(dashboard)\n\n    click.echo(\"Dashboard running...\")\n\n    while True:\n        try:\n            DashboardRunner(dashboard).cycle()\n        except SecretNotFound as err:\n            click.echo(get_error_message(err, default=\"Datafeed didn't have required secret\"), err=True)\n            raise click.Abort()\n\n        if once:\n            break", "response": "Start a new dashboard from the provided dashboards."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef view(action, dashboards, secrets):\n\n    if secrets is None:\n        secrets = os.path.join(os.path.expanduser(\"~\"), \"/.doodledashboard/secrets\")\n\n    try:\n        loaded_secrets = try_read_secrets_file(secrets)\n    except InvalidSecretsException as err:\n        click.echo(get_error_message(err, default=\"Secrets file is invalid\"), err=True)\n        raise click.Abort()\n\n    dashboard_config = DashboardConfigReader(initialise_component_loader(), loaded_secrets)\n\n    read_configs = [read_file(f) for f in dashboards]\n    dashboard = read_dashboard_from_config(dashboard_config, read_configs)\n\n    try:\n        messages = DashboardRunner(dashboard).poll_datafeeds()\n    except SecretNotFound as err:\n        click.echo(get_error_message(err, default=\"Datafeed didn't have required secret\"), err=True)\n        raise click.Abort()\n\n    cli_output = {\"source-data\": messages}\n\n    if action == \"notifications\":\n        cli_output[\"notifications\"] = []\n\n        for notification in dashboard.notifications:\n            notification_output = notification.create(messages)\n\n            filtered_messages = messages\n\n            if isinstance(notification, FilteredNotification):\n                filtered_messages = notification.filter_messages(messages)\n\n            cli_output[\"notifications\"].append({\n                \"filtered-messages\": filtered_messages,\n                \"notification\": str(notification_output)\n            })\n    json_output = json.dumps(cli_output, sort_keys=True, indent=4, cls=MessageJsonEncoder)\n    click.echo(json_output)", "response": "View the output of the datafeeds and notifications used in your DASHBOARDS"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list(component_type):\n    config_loader = initialise_component_loader()\n    component_types = sorted({\n         \"displays\": lambda: config_loader.load_by_type(ComponentType.DISPLAY),\n         \"datafeeds\": lambda: config_loader.load_by_type(ComponentType.DATA_FEED),\n         \"filters\": lambda: config_loader.load_by_type(ComponentType.FILTER),\n         \"notifications\": lambda: config_loader.load_by_type(ComponentType.NOTIFICATION)\n    }.items(), key=lambda t: t[0])\n\n    def print_ids(creators):\n        ids = {c.id_key_value[1] if hasattr(c, \"id_key_value\") else c.get_id() for c in creators}\n        for i in sorted(ids):\n            click.echo(\" - %s\" % i)\n\n    for k, v in component_types:\n        if component_type == k or component_type == \"all\":\n            click.echo(\"Available %s:\" % k)\n            print_ids(v())\n\n        if component_type == \"all\":\n            click.echo(\"\")", "response": "List all available components of a given type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the section of configuration pertaining to a component", "response": "def parse(self, config):\n        \"\"\"\n            Parses the section of configuration pertaining to a component\n            :param config: dict of specific config section\n            :return:\n        \"\"\"\n\n        if \"type\" not in config:\n            raise InvalidConfigurationException(\"The dashboard configuration has not defined a 'type'. %s\" % config)\n\n        component_type = config[\"type\"]\n        component_config = self._get_config_by_id(self._component_configs, component_type)\n\n        if not component_config:\n            raise ComponentNotFoundForType(component_type)\n\n        options = config.get(\"options\", {})\n        component = self._parse_item(component_config, options, config)\n        component.name = config.get(\"name\", \"\")\n        return component"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef err_msg(self, instance, value):\n        if not hasattr(self, \"name\"):\n            # err_msg will be called by the composed descriptor\n            return \"\"\n        return (\n            \"Attempted to set the {f_type} attribute {inst}.{attr} to the \"\n            \"{val_type} value {val}, which does not satisfy the condition \"\n            \"{f_type}.\".format(\n                f_type=self.field_type,\n                inst=instance.__class__.__name__,\n                attr=self.name,\n                val_type=value.__class__.__name__,\n                val=value))", "response": "Return an error message for use in exceptions thrown by\n            subclasses."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exc_thrown_by_descriptor():\n        traceback = sys.exc_info()[2]\n        tb_locals = traceback.tb_frame.f_locals\n        # relying on naming convention to get the object that threw\n        # the exception\n        if \"self\" in tb_locals:\n            if not isinstance(tb_locals[\"self\"], Descriptor):\n                return False\n            return True\n        return False", "response": "Return True if the last exception was thrown by a\n            Descriptor instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_data(self):\n        if getattr(self, 'data', False) and not getattr(self, '_x', False) and not getattr(self, '_y', False):\n            _x = XVariable()\n            _y = YVariable()\n            _x.contribute_to_class(self, 'X', self.data)\n            _y.contribute_to_class(self, 'Y', self.data)\n            self['data'] = zip(self._x.points, self._y.points)\n        else: \n            for axis in ('_x', '_y'):\n                axis_obj = getattr(self, axis, False)\n                if not axis_obj:\n                    raise exception.MissingAxisException(\"%s missing\" % axis)\n                if not getattr(axis_obj, 'points', False):\n                    raise exception.MissingDataException()\n\n            self['data'] = zip(self._x.points, self._y.points)", "response": "This method will be called to set the data of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the graph ploting options", "response": "def _set_options(self):\n        \"sets the graph ploting options\"\n        # this is aweful\n        # FIXME: Axis options should be passed completly by a GraphOption\n        if 'xaxis' in self._options.keys():\n            self._options['xaxis'].update(\n                        {'mode' : self._get_axis_mode(XAxis._var_name)})\n        if 'yaxis' in self._options.keys():\n            self._options['yaxis'].update(\n                        {'mode' : self._get_axis_mode(YAxis._var_name)})"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an __init__ method that sets all the attributes necessary for the Descriptor to check the value.", "response": "def create_init(attrs):\n    \"\"\"Create an __init__ method that sets all the attributes\n    necessary for the function the Descriptor invokes to check the\n    value.\n\n    \"\"\"\n    args = \", \".join(attrs)\n    vals = \", \".join(['getattr(self, \"{}\")'.format(attr) for attr in attrs])\n    attr_lines = \"\\n    \".join(\n        [\"self.{attr} = {attr}\".format(attr=attr) for attr in attrs])\n    init_code = \"\"\"def _init(self, {args}):\n    super(self.__class__, self).__init__()\n    {attr_lines}\n    self.field_type += \"({{}})\".format(\n        \", \".join([str(val) for val in [{vals}]]))\n    \"\"\".format(args=args, attr_lines=attr_lines, vals=vals)\n    exec(init_code, globals())\n    return _init"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_setter(func, attrs):\n    def _set(self, instance, value, name=None):\n        args = [getattr(self, attr) for attr in attrs]\n        if not func(value, *args):\n            raise ValueError(self.err_msg(instance, value))\n    return _set", "response": "Create the __set__ method for the descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nturn a funcs list element into a class object.", "response": "def make_class(clsname, func, attrs):\n    \"\"\"Turn a funcs list element into a class object.\"\"\"\n    clsdict = {\"__set__\": create_setter(func, attrs)}\n    if len(attrs) > 0:\n        clsdict[\"__init__\"] = create_init(attrs)\n    clsobj = type(str(clsname), (Descriptor, ), clsdict)\n    clsobj.__doc__ = docstrings.get(clsname)\n    return clsobj"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cycle(self):\n        messages = self.poll_datafeeds()\n        notifications = self.process_notifications(messages)\n\n        self.draw_notifications(notifications)", "response": "Cycle through notifications with latest results from data feeds."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert value to a numeric value or raise a ValueError if that isn t possible.", "response": "def try_convert(value):\n        \"\"\"Convert value to a numeric value or raise a ValueError\n        if that isn't possible.\n\n        \"\"\"\n        convertible = ForceNumeric.is_convertible(value)\n        if not convertible or isinstance(value, bool):\n            raise ValueError\n        if isinstance(str(value), str):\n            return ForceNumeric.str_to_num(value)\n        return float(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a string value to an int or a float depending on the numeric value represented by str_value.", "response": "def str_to_num(str_value):\n        \"\"\"Convert str_value to an int or a float, depending on the\n        numeric value represented by str_value.\n\n        \"\"\"\n        str_value = str(str_value)\n        try:\n            return int(str_value)\n        except ValueError:\n            return float(str_value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nplotting a single node into a template.", "response": "def plot(parser, token):\n    \"\"\"\n    Tag to plot graphs into the template\n    \"\"\"\n\n    tokens = token.split_contents()\n    tokens.pop(0)\n    graph = tokens.pop(0)\n\n    attrs = dict([token.split(\"=\") for token in tokens])\n\n    if 'id' not in attrs.keys():\n        attrs['id'] = ''.join([chr(choice(range(65, 90))) for i in range(0, 5)])\n    else:\n        attrs['id'] = attrs['id'][1:len(attrs['id'])-1]\n\n    attr_string = ''.join([\" %s=%s\" % (k, v) for k, v in attrs.iteritems()])\n    return GraphRenderer(graph, attr_string, attrs['id'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntry to get a Unicode copy of a string.", "response": "def force_unicode(raw):\n    '''Try really really hard to get a Unicode copy of a string.\n\n    First try :class:`BeautifulSoup.UnicodeDammit` to try to force\n    to Unicode; if that fails, assume UTF-8 encoding, and ignore\n    all errors.\n\n    :param str raw: string to coerce\n    :return: Unicode approximation of `raw`\n    :returntype: :class:`unicode`\n\n    '''\n    converted = UnicodeDammit(raw, isHTML=True)\n    if not converted.unicode:\n        converted.unicode = unicode(raw, 'utf8', errors='ignore')\n\n    encoding_m = encoding_re.match(converted.unicode)\n    if encoding_m:\n        converted.unicode = \\\n            encoding_m.group('start_xml') + \\\n            encoding_m.group('remainder')\n\n    return converted.unicode"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_clean_html(raw, stream_item=None, encoding=None):\n    '''Get a clean text representation of presumed HTML.\n\n    Treat `raw` as though it is HTML, even if we have no idea what it\n    really is, and attempt to get a properly formatted HTML document\n    with all HTML-escaped characters converted to their unicode.\n\n    This is called below by the `clean_html` transform stage, which\n    interprets MIME-type.  If `character_encoding` is not provided,\n    and `stream_item` is provided, then this falles back to\n    :attr:`streamcorpus.StreamItem.body.encoding`.\n\n    :param str raw: raw text to clean up\n    :param stream_item: optional stream item with encoding metadata\n    :type stream_item: :class:`streamcorpus.StreamItem`\n    :returns: UTF-8-encoded byte string of cleaned HTML text\n    :returntype: :class:`str`\n\n    '''\n    # Fix emails by protecting the <,> from HTML\n    raw = fix_emails(raw)\n    raw_decoded = nice_decode(raw, stream_item=stream_item, encoding=encoding)\n    if raw_decoded is None:\n        # give up on decoding it... maybe this should use force_unicode\n        raw_decoded = raw\n\n    # default attempt uses vanilla lxml.html\n    try:\n        root = lxml.html.document_fromstring(raw_decoded)\n    except ValueError, exc:\n        if 'with encoding declaration' in str(exc):\n            root = lxml.html.document_fromstring(raw)\n        else:\n            raise\n\n    # While we have the document parsed as a DOM, let's strip attributes.\n    # (The HTML cleaner seems to only support whitelisting attributes.\n    # As of now, we just want to blacklist a few.)\n    lxml.etree.strip_attributes(root, 'class', 'id')\n\n    # if that worked, then we will be able to generate a\n    # valid HTML string\n    fixed_html = lxml.html.tostring(root, encoding=unicode)\n\n    # remove any ^M characters\n    fixed_html = string.replace(fixed_html, '\\r', ' ')\n\n    # We drop utf8 characters that are above 0xFFFF as\n    # Lingpipe seems to be doing the wrong thing with them.\n    fixed_html = drop_invalid_and_upper_utf8_chars(fixed_html)\n\n    # construct a Cleaner that removes any ``<script>`` tags,\n    # Javascript, like an ``onclick`` attribute, comments, style\n    # tags or attributes, ``<link>`` tags\n    cleaner = lxml.html.clean.Cleaner(\n        scripts=True, javascript=True,\n        comments=True,\n        # do not remove <html> <head> <title> etc\n        page_structure=False,\n        remove_tags=['base'],\n        style=True, links=True)\n\n    # now get the really sanitized HTML\n    _clean_html = cleaner.clean_html(fixed_html)\n\n    # generate pretty HTML in utf-8\n    _clean_html = lxml.html.tostring(\n        lxml.html.document_fromstring(_clean_html),\n        method='html', encoding='utf-8',\n        pretty_print=True,\n        # include_meta_content_type=True\n        )\n\n    return uniform_html(_clean_html)", "response": "Return a clean text representation of presumed HTML."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef uniform_html(html):\n    '''Takes a utf-8-encoded string of HTML as input and returns a new\n    HTML string with fixed quoting and close tags, which generally\n    should not break any of the offsets and makes it easier for\n    functions like\n    :func:`streamcorpus_pipeline.offsets.char_offsets_to_xpaths` to\n    operate without failures.\n\n    '''\n    doc = html5lib.parse(html.decode('utf-8'))\n    config = {\n        'omit_optional_tags': False,\n        'encoding': 'utf-8',\n        'quote_attr_values': 'always',\n    }\n    return html5lib.serializer.serialize(doc, **config)", "response": "Takes a utf - 8 - encoded string of HTML as input and returns a new\n    HTML string with fixed quoting and close tags."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_matching_mime_type(self, mime_type):\n        '''This implements the MIME-type matching logic for deciding whether\n        to run `make_clean_html`\n\n        '''\n        if len(self.include_mime_types) == 0:\n            return True\n        if mime_type is None:\n            return False\n        mime_type = mime_type.lower()\n        # NB: startswith is necessary here, because encodings are\n        # often appended to HTTP header Content-Type\n        return any(mime_type.startswith(mt) for mt in self.include_mime_types)", "response": "This implements the MIME - type matching logic for deciding whether the content - type is matching the given MIME - type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract a lower - case no - slashes domain name from a raw string that might be a URL", "response": "def domain_name_cleanse(raw_string):\n    '''extract a lower-case, no-slashes domain name from a raw string\n    that might be a URL\n    '''\n    try:\n        parts = urlparse(raw_string)\n        domain = parts.netloc.split(':')[0]\n    except:\n        domain = ''\n    if not domain:\n        domain = raw_string\n    if not domain:\n        return ''\n    domain = re.sub('\\/', '', domain.strip().lower())\n    return domain"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef domain_name_left_cuts(domain):\n    '''returns a list of strings created by splitting the domain on\n    '.' and successively cutting off the left most portion\n    '''\n    cuts = []\n    if domain:\n        parts = domain.split('.')\n        for i in range(len(parts)):\n            cuts.append( '.'.join(parts[i:]))\n    return cuts", "response": "returns a list of strings created by splitting the domain on\n   . and successively cutting off the left most portion of the domain on\n   ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_hash_kw(self, tok):\n        '''Get a Murmur hash and a normalized token.\n\n        `tok` may be a :class:`unicode` string or a UTF-8-encoded\n        byte string.  :data:`DOCUMENT_HASH_KEY`, hash value 0, is\n        reserved for the document count, and this function remaps\n        that value.\n\n        :param tok: token to hash\n        :return: pair of normalized `tok` and its hash\n\n        '''\n        if isinstance(tok, unicode):\n            tok = tok.encode('utf-8')\n        h = mmh3.hash(tok)\n        if h == DOCUMENT_HASH_KEY:\n            h = DOCUMENT_HASH_KEY_REPLACEMENT\n        return (tok, h)", "response": "Get a Murmur hash and a normalized token."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncollects all of the words to be indexed from a stream item. This scans a stream item for all of the configured tagger IDs and returns a Counter of all of the words to be indexed.", "response": "def collect_words(self, si):\n        '''Collect all of the words to be indexed from a stream item.\n\n        This scans `si` for all of the configured tagger IDs.  It\n        collects all of the token values (the\n        :attr:`streamcorpus.Token.token`) and returns a\n        :class:`collections.Counter` of them.\n\n        :param si: stream item to scan\n        :type si: :class:`streamcorpus.StreamItem`\n        :return: counter of :class:`unicode` words to index\n        :returntype: :class:`collections.Counter`\n\n        '''\n        counter = Counter()\n        for tagger_id, sentences in si.body.sentences.iteritems():\n            if ((self.keyword_tagger_ids is not None\n                 and tagger_id not in self.keyword_tagger_ids)):\n                continue\n            for sentence in sentences:\n                for token in sentence.tokens:\n                    term = token.token  # always a UTF-8 byte string\n                    term = term.decode('utf-8')\n                    term = cleanse(term)\n                    if ((self.keyword_size_limit is not None and\n                         len(term) > self.keyword_size_limit)):\n                        continue\n                    if term not in self.stop_words:\n                        counter[term] += 1\n        return counter"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef index(self, si):\n        '''Record index records for a single document.\n\n        Which indexes this creates depends on the parameters to the\n        constructor.  This records all of the requested indexes for\n        a single document.\n\n        '''\n        if not si.body.clean_visible:\n            logger.warn('stream item %s has no clean_visible part, '\n                        'skipping keyword indexing', si.stream_id)\n            return\n\n        # Count tokens in si.clean_visible\n        # We will recycle hash==0 for \"# of documents\"\n        hash_counts = defaultdict(int)\n        hash_counts[DOCUMENT_HASH_KEY] = 1\n        hash_kw = defaultdict(int)\n        words = self.collect_words(si)\n        for tok, count in words.iteritems():\n            (tok, tok_hash) = self.make_hash_kw(tok)\n            hash_counts[tok_hash] += count\n            hash_kw[tok] = tok_hash\n\n        # Convert this and write it out\n        if self.hash_docs:\n            (k1, k2) = key_for_stream_item(si)\n            kvps = [((h, k1, k2), n) for (h, n) in hash_counts.iteritems()\n                    if h != DOCUMENT_HASH_KEY]\n            self.client.put(HASH_TF_INDEX_TABLE, *kvps)\n\n        if self.hash_frequencies:\n            kvps = [((h,), 1) for h in hash_counts.iterkeys()]\n            self.client.increment(HASH_FREQUENCY_TABLE, *kvps)\n\n        if self.hash_keywords:\n            kvps = [((h, t), 1) for (t, h) in hash_kw.iteritems()]\n            self.client.increment(HASH_KEYWORD_INDEX_TABLE, *kvps)", "response": "Record index records for a single document."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef invert_hash(self, tok_hash):\n        '''Get strings that correspond to some hash.\n\n        No string will correspond to :data:`DOCUMENT_HASH_KEY`; use\n        :data:`DOCUMENT_HASH_KEY_REPLACEMENT` instead.\n\n        :param int tok_hash: Murmur hash to query\n        :return: list of :class:`unicode` strings\n\n        '''\n        return [tok_encoded.decode('utf8')\n                for (_, tok_encoded) in\n                self.client.scan_keys(HASH_KEYWORD_INDEX_TABLE,\n                                      ((tok_hash,), (tok_hash,)))]", "response": "Get strings that correspond to some hash."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the document frequencies for a list of hashes.", "response": "def document_frequencies(self, hashes):\n        '''Get document frequencies for a list of hashes.\n\n        This will return all zeros unless the index was written with\n        `hash_frequencies` set.  If :data:`DOCUMENT_HASH_KEY` is\n        included in `hashes`, that value will be returned with the\n        total number of documents indexed.  If you are looking for\n        documents with that hash, pass\n        :data:`DOCUMENT_HASH_KEY_REPLACEMENT` instead.\n\n        :param hashes: hashes to query\n        :paramtype hashes: list of :class:`int`\n        :return: map from hash to document frequency\n\n        '''\n        result = {}\n        for (k, v) in self.client.get(HASH_FREQUENCY_TABLE,\n                                      *[(h,) for h in hashes]):\n            if v is None:\n                v = 0\n            result[k[0]] = v\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lookup(self, h):\n        '''Get stream IDs for a single hash.\n\n        This yields strings that can be retrieved using\n        :func:`streamcorpus_pipeline._kvlayer.get_kvlayer_stream_item`,\n        or fed back into :mod:`coordinate` or other job queue systems.\n\n        Note that for common terms this can return a large number of\n        stream IDs!  This is a scan over a dense region of a\n        :mod:`kvlayer` table so it should be reasonably efficient,\n        but be prepared for it to return many documents in a large\n        corpus.  Blindly storing the results in a :class:`list`\n        may be inadvisable.\n\n        This will return nothing unless the index was written with\n        :attr:`hash_docs` set.  No document will correspond to\n        :data:`DOCUMENT_HASH_KEY`; use\n        :data:`DOCUMENT_HASH_KEY_REPLACEMENT` instead.\n\n        :param int h: Murmur hash to look up\n\n        '''\n        for (_, k1, k2) in self.client.scan_keys(HASH_TF_INDEX_TABLE,\n                                                 ((h,), (h,))):\n            yield kvlayer_key_to_stream_id((k1, k2))", "response": "Get stream IDs for a single hash."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lookup_tf(self, h):\n        '''Get stream IDs and term frequencies for a single hash.\n\n        This yields pairs of strings that can be retrieved using\n        :func:`streamcorpus_pipeline._kvlayer.get_kvlayer_stream_item`\n        and the corresponding term frequency.\n\n        ..see:: :meth:`lookup`\n\n\n        '''\n        for ((_, k1, k2), v) in self.client.scan(HASH_TF_INDEX_TABLE,\n                                                 ((h,), (h,))):\n            yield (kvlayer_key_to_stream_id((k1, k2)), v)", "response": "Get stream IDs and term frequencies for a single hash."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a spinn3r feed produce a sequence of valid StreamItems.", "response": "def _make_stream_items(f):\n    \"\"\"Given a spinn3r feed, produce a sequence of valid StreamItems.\n\n    Because of goopy Python interactions, you probably need to call\n    this and re-yield its results, as\n\n    >>> with open(filename, 'rb') as f:\n    ...   for si in _make_stream_items(f):\n    ...     yield si\n\n    \"\"\"\n    reader = ProtoStreamReader(f)\n    return itertools.ifilter(\n        lambda x: x is not None,\n        itertools.imap(_make_stream_item, reader))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a single spinn3r feed entry produce a single StreamItem. Returns None if a complete item can t be constructed.", "response": "def _make_stream_item(entry):\n    \"\"\"Given a single spinn3r feed entry, produce a single StreamItem.\n\n    Returns 'None' if a complete item can't be constructed.\n\n    \"\"\"\n    # get standard metadata, assuming it's present...\n    if not hasattr(entry, 'permalink_entry'):\n        return None\n    pe = entry.permalink_entry\n\n    # ...and create a streamitem...\n    si = streamcorpus.make_stream_item(\n        pe.date_found[:-1] + '.0Z',\n        pe.canonical_link.href.encode('utf8'))\n    if not si.stream_time:\n        logger.debug('failed to generate stream_time from {0!r}'\n                     .format(pe.date_found))\n        return None\n    if not si.abs_url:\n        logger.debug('failed to generate abs_url from {0!r}'\n                     .format(pe.canonical_link.href))\n        return None\n\n    # ...filling in the actual data\n    si.body = _make_content_item(\n        pe.content,\n        alternate_data=entry.feed_entry.content.data)\n    if not si.body:\n        return None\n    if not si.body.raw:\n        return None\n\n    if pe.content_extract.data:\n        si.other_content['extract'] = _make_content_item(pe.content_extract)\n    si.other_content['title'] = streamcorpus.ContentItem(\n        raw=pe.title.encode('utf8'),\n        media_type=pe.content_extract.mime_type,\n        encoding='UTF-8')\n    si.other_content['feed_entry_title'] = streamcorpus.ContentItem(\n        raw=entry.feed_entry.title.encode('utf8'),\n        media_type=entry.feed_entry.content.mime_type,\n        encoding='UTF-8')\n    if entry.feed_entry.content.data:\n        si.other_content['feed_entry'] = _make_content_item(\n            entry.feed_entry.content)\n    si.source_metadata['lang'] = pe.lang[0].code\n    si.source_metadata['author'] = json.dumps(\n        dict(\n            name=pe.author[0].name,\n            email=pe.author[0].email,\n            link=pe.author[0].link[0].href,\n        )\n    )\n    si.source = entry.source.publisher_type\n    return si"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a ContentItem from a node in the spinn3r protobuf data tree.", "response": "def _make_content_item(node, mime_type=None, alternate_data=None):\n    \"\"\"Create a ContentItem from a node in the spinn3r data tree.\n\n    The ContentItem is created with raw data set to ``node.data``,\n    decompressed if the node's encoding is 'zlib', and UTF-8\n    normalized, with a MIME type from ``node.mime_type``.\n\n    ``node``\n      the actual node from the spinn3r protobuf data\n    ``mime_type``\n      string MIME type to use (defaults to ``node.mime_type``)\n    ``alternate_data``\n      alternate (compressed) data to use, if ``node.data`` is missing\n      or can't be decompressed\n\n    \"\"\"\n    raw = node.data\n    if getattr(node, 'encoding', None) == 'zlib':\n        try:\n            raw = zlib.decompress(node.data)\n        except Exception, exc:\n            if alternate_data is not None:\n                try:\n                    raw = zlib.decompress(alternate_data)\n                except Exception:\n                    raise exc  # the original exception\n                else:\n                    raise\n    if mime_type is None:\n        mime_type = node.mime_type\n    raw = raw.decode('utf8').encode('utf8')\n    return streamcorpus.ContentItem(raw=raw, media_type=mime_type)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read(self, n):\n        if n <= len(self._prefix):\n            # the read can be fulfilled entirely from the prefix\n            result = self._prefix[:n]\n            self._prefix = self._prefix[n:]\n            return result\n        # otherwise we need to read some\n        n -= len(self._prefix)\n        result = self._prefix + self.f.read(n)\n        self._prefix = \"\"\n        return result", "response": "Read up to n bytes from the underlying file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads exactly a varint out of the underlying file.", "response": "def _read_varint(self):\n        \"\"\"Read exactly a varint out of the underlying file.\"\"\"\n        buf = self._read(8)\n        (n, l) = _DecodeVarint(buf, 0)\n        self._unread(buf[l:])\n        return n"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _read_a(self, cls):\n        o = cls()\n        o.ParseFromString(self._read_block())\n        return o", "response": "Read some protobuf - encoded object out of the file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_keys_and_ranges(i_str, keyfunc, rangefunc):\n    '''Parse the :class:`from_kvlayer` input string.\n\n    This accepts two formats.  In the textual format, it accepts any\n    number of stream IDs in timestamp-docid format, separated by ``,``\n    or ``;``, and processes those as individual stream IDs.  In the\n    binary format, it accepts 20-byte key blobs (16 bytes md5 hash, 4\n    bytes timestamp) split by ``;`` or ``<``; e.g., ``a<f;x`` loads\n    scans keys `a` through `f` and loads singly key `x`.\n\n    `keyfunc` and `rangefunc` are run as generators and their yields\n    are yielded from this function.\n\n    '''\n    while i_str:\n        m = _STREAM_ID_RE.match(i_str)\n        if m:\n            # old style text stream_id\n            for retval in keyfunc(stream_id_to_kvlayer_key(m.group())):\n                yield retval\n            i_str = i_str[m.end():]\n            while i_str and ((i_str[0] == ',') or (i_str[0] == ';')):\n                i_str = i_str[1:]\n            continue\n\n        if len(i_str) == SI_KEY_LENGTH:\n            # one key, get it.\n            key = parse_si_key(i_str)\n            for retval in keyfunc(key):\n                yield retval\n            return\n\n        keya = i_str[:SI_KEY_LENGTH]\n        splitc = i_str[SI_KEY_LENGTH]\n        if splitc == '<':\n            # range\n            keyb = i_str[SI_KEY_LENGTH+1:SI_KEY_LENGTH+1+SI_KEY_LENGTH]\n            i_str = i_str[SI_KEY_LENGTH+1+SI_KEY_LENGTH:]\n            keya = parse_si_key(keya)\n            keyb = parse_si_key(keyb)\n            for retval in rangefunc(keya, keyb):\n                yield retval\n        elif splitc == ';':\n            # keya is single key to load\n            keya = parse_si_key(keya)\n            for retval in keyfunc(keya):\n                yield retval\n            i_str = i_str[SI_KEY_LENGTH+1+1:]\n        else:\n            logger.error('bogus key splitter %s, %r', splitc, i_str)\n            return", "response": "Parse the : class from_kvlayer input string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve a : class : streamcorpus. StreamItem from the kvlayer database.", "response": "def get_kvlayer_stream_item(client, stream_id):\n    '''Retrieve a :class:`streamcorpus.StreamItem` from :mod:`kvlayer`.\n\n    This function requires that `client` already be set up properly::\n\n        client = kvlayer.client()\n        client.setup_namespace(STREAM_ITEM_TABLE_DEFS,\n                               STREAM_ITEM_VALUE_DEFS)\n        si = get_kvlayer_stream_item(client, stream_id)\n\n    `stream_id` is in the form of\n    :data:`streamcorpus.StreamItem.stream_id` and contains the\n    ``epoch_ticks``, a hyphen, and the ``doc_id``.\n\n    :param client: kvlayer client object\n    :type client: :class:`kvlayer.AbstractStorage`\n    :param str stream_id: stream Id to retrieve\n    :return: corresponding :class:`streamcorpus.StreamItem`\n    :raise exceptions.KeyError: if `stream_id` is malformed or does\n      not correspond to anything in the database\n\n    '''\n    if client is None:\n        client = kvlayer.client()\n        client.setup_namespace(STREAM_ITEM_TABLE_DEFS,\n                               STREAM_ITEM_VALUE_DEFS)\n    key = stream_id_to_kvlayer_key(stream_id)\n    for k, v in client.get(STREAM_ITEMS_TABLE, key):\n        if v is not None:\n            errors, bytestr = streamcorpus.decrypt_and_uncompress(v)\n            return streamcorpus.deserialize(bytestr)\n    raise KeyError(stream_id)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_doc_id_range(doc_id):\n    '''Construct a tuple(begin, end) of one-tuple kvlayer keys from a\n    hexdigest doc_id.\n\n    '''\n    assert len(doc_id) == 32, 'expecting 32 hex string, not: %r' % doc_id\n    bin_docid = base64.b16decode(doc_id.upper())\n    doc_id_range = ((bin_docid,), (bin_docid,))\n    return doc_id_range", "response": "Construct a tuple of begin end of one - tuple kvlayer keys from a\n    hexdigest doc_id."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_kvlayer_stream_item_by_doc_id(client, doc_id):\n    '''Retrieve :class:`streamcorpus.StreamItem`s from :mod:`kvlayer`.\n\n    Namely, it returns an iterator over all documents with the given\n    docid. The docid should be an md5 hash of the document's abs_url.\n\n    :param client: kvlayer client object\n    :type client: :class:`kvlayer.AbstractStorage`\n    :param str doc_id: doc id of documents to retrieve\n    :return: generator of :class:`streamcorpus.StreamItem`\n    '''\n    if client is None:\n        client = kvlayer.client()\n        client.setup_namespace(STREAM_ITEM_TABLE_DEFS,\n                               STREAM_ITEM_VALUE_DEFS)\n    doc_id_range = make_doc_id_range(doc_id)\n    for k, v in client.scan(STREAM_ITEMS_TABLE, doc_id_range):\n        if v is not None:\n            errors, bytestr = streamcorpus.decrypt_and_uncompress(v)\n            yield streamcorpus.deserialize(bytestr)", "response": "Retrieve all stream items with the given doc_id from the given kvlayer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving stream ids from kvlayer.", "response": "def get_kvlayer_stream_ids_by_doc_id(client, doc_id):\n    '''Retrieve stream ids from :mod:`kvlayer`.\n\n    Namely, it returns an iterator over all stream ids with the given\n    docid. The docid should be an md5 hash of the document's abs_url.\n\n    :param client: kvlayer client object\n    :type client: :class:`kvlayer.AbstractStorage`\n    :param str doc_id: doc id of documents to retrieve\n    :return: generator of str\n    '''\n    if client is None:\n        client = kvlayer.client()\n        client.setup_namespace(STREAM_ITEM_TABLE_DEFS,\n                               STREAM_ITEM_VALUE_DEFS)\n    doc_id_range = make_doc_id_range(doc_id)\n    for k in client.scan_keys(STREAM_ITEMS_TABLE, doc_id_range):\n        yield kvlayer_key_to_stream_id(k)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nserialize a StreamItem kvlayer key.", "response": "def serialize_si_key(si_key):\n    '''\n    Return packed bytes representation of StreamItem kvlayer key.\n    The result is 20 bytes, 16 of md5 hash, 4 of int timestamp.\n    '''\n    if len(si_key[0]) != 16:\n        raise ValueError('bad StreamItem key, expected 16 byte '\n                         'md5 hash binary digest, got: {0!r}'.format(si_key))\n    return struct.pack('>16si', si_key[0], si_key[1])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef streamitem_to_key_data(si):\n    '''\n    extract the parts of a StreamItem that go into a kvlayer key,\n    convert StreamItem to blob for storage.\n\n    return (kvlayer key tuple), data blob\n    '''\n    key = key_for_stream_item(si)\n    data = streamcorpus.serialize(si)\n    errors, data = streamcorpus.compress_and_encrypt(data)\n    assert not errors, errors\n    return key, data", "response": "Convert a StreamItem into a kvlayer key tuple and data blob for storage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nchange the working directory and restore the previous on exit", "response": "def working_directory(path):\n    \"\"\"Change working directory and restore the previous on exit\"\"\"\n    prev_dir = os.getcwd()\n    os.chdir(str(path))\n    try:\n        yield\n    finally:\n        os.chdir(prev_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef strip_prefix(s, prefix, strict=False):\n    if s.startswith(prefix):\n        return s[len(prefix) :]\n    elif strict:\n        raise WimpyError(\"string doesn't start with prefix\")\n    return s", "response": "Removes the prefix from the input string if it s there otherwise returns input string unchanged."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving the suffix from the input string if it s present otherwise returns input string unchanged.", "response": "def strip_suffix(s, suffix, strict=False):\n    \"\"\"Removes the suffix, if it's there, otherwise returns input string unchanged.\n    If strict is True, also ensures the suffix was present\"\"\"\n    if s.endswith(suffix):\n        return s[: len(s) - len(suffix)]\n    elif strict:\n        raise WimpyError(\"string doesn't end with suffix\")\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nam the element of needle contained in haystack?", "response": "def is_subsequence(needle, haystack):\n    \"\"\"Are all the elements of needle contained in haystack, and in the same order?\n    There may be other elements interspersed throughout\"\"\"\n    it = iter(haystack)\n    for element in needle:\n        if element not in it:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new Ice application with a default home page.", "response": "def cube():\n    \"\"\"Return an Ice application with a default home page.\n\n    Create :class:`Ice` object, add a route to return the default page\n    when a client requests the server root, i.e. /, using HTTP GET\n    method, add an error handler to return HTTP error pages when an\n    error occurs and return this object. The returned object can be used\n    as a WSGI application.\n\n    Returns:\n      Ice: WSGI application.\n    \"\"\"\n    app = Ice()\n\n    @app.get('/')\n    def default_home_page():\n        \"\"\"Return a default home page.\"\"\"\n        return simple_html('It works!',\n                           '<h1>It works!</h1>\\n'\n                           '<p>This is the default ice web page.</p>')\n\n    @app.error()\n    def generic_error_page():\n        \"\"\"Return a simple and generic error page.\"\"\"\n        return simple_html(app.response.status_line,\n                           '<h1>{title}</h1>\\n'\n                           '<p>{description}</p>\\n'\n                           '<hr>\\n'\n                           '<address>Ice/{version}</address>'.format(\n                           title=app.response.status_line,\n                           description=app.response.status_detail,\n                           version=__version__))\n\n    def simple_html(title, body):\n        \"\"\"Return a simple HTML page.\"\"\"\n        return (\n            '<!DOCTYPE html>\\n'\n            '<html>\\n<head><title>{title}</title></head>\\n'\n            '<body>\\n{body}\\n</body>\\n</html>\\n'\n        ).format(title=title, body=body)\n\n    return app"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self, host='127.0.0.1', port=8080):\n        from wsgiref import simple_server\n        self._server = simple_server.make_server(host, port, self)\n        self._server.serve_forever()", "response": "Run the application using a simple WSGI server."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef exit(self):\n        if self._server is not None:\n            self._server.shutdown()\n            self._server.server_close()\n            self._server = None", "response": "Stop the simple WSGI server running the appliation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef route(self, method, pattern):\n        def decorator(callback):\n            self._router.add(method, pattern, callback)\n            return callback\n        return decorator", "response": "Decorator to add a route for a request with any HTTP method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending content of a static file as response.", "response": "def static(self, root, path, media_type=None, charset='UTF-8'):\n        \"\"\"Send content of a static file as response.\n\n        The path to the document root directory should be specified as\n        the root argument. This is very important to prevent directory\n        traversal attack. This method guarantees that only files within\n        the document root directory are served and no files outside this\n        directory can be accessed by a client.\n\n        The path to the actual file to be returned should be specified\n        as the path argument. This path must be relative to the document\n        directory.\n\n        The *media_type* and *charset* arguments are used to set the\n        Content-Type header of the HTTP response. If *media_type*\n        is not specified or specified as ``None`` (the default), then it\n        is guessed from the filename of the file to be returned.\n\n        Arguments:\n          root (str): Path to document root directory.\n          path (str): Path to file relative to document root directory.\n          media_type (str, optional): Media type of file.\n          charset (str, optional): Character set of file.\n\n        Returns:\n          bytes: Content of file to be returned in the HTTP response.\n        \"\"\"\n        root = os.path.abspath(os.path.join(root, ''))\n        path = os.path.abspath(os.path.join(root, path.lstrip('/\\\\')))\n\n        # Save the filename from the path in the response state, so that\n        # a following download() call can default to this filename for\n        # downloadable file when filename is not explicitly specified.\n        self.response.state['filename'] = os.path.basename(path)\n\n        if not path.startswith(root):\n            return 403\n        elif not os.path.isfile(path):\n            return 404\n\n        if media_type is not None:\n            self.response.media_type = media_type\n        else:\n            self.response.media_type = mimetypes.guess_type(path)[0]\n        self.response.charset = charset\n\n        with open(path, 'rb') as f:\n            return f.read()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef download(self, content, filename=None,\n                 media_type=None, charset='UTF-8'):\n        \"\"\"Send content as attachment (downloadable file).\n\n        The *content* is sent after setting Content-Disposition header\n        such that the client prompts the user to save the content\n        locally as a file. An HTTP response status code may be specified\n        as *content*. If the status code is not ``200``, then this\n        method does nothing and returns the status code.\n\n        The filename used for the download is determined according to\n        the following rules. The rules are followed in the specified\n        order.\n\n          1. If *filename* is specified, then the base name from this\n             argument, i.e. ``os.path.basename(filename)``, is used as the\n             filename for the download.\n          2. If *filename* is not specified or specified as ``None``\n             (the default), then the base name from the file path\n             specified to a previous :meth:`static` call made while\n             handling the current request is used.\n          3. If *filename* is not specified and there was no\n             :meth:`static` call made previously for the current\n             request, then the base name from the current HTTP request\n             path is used.\n          4. As a result of the above steps, if the resultant *filename*\n             turns out to be empty, then :exc:`ice.LogicError` is raised.\n\n        The *media_type* and *charset* arguments are used in the same\n        manner as they are used in :meth:`static`.\n\n        Arguments:\n          content (str, bytes or int): Content to be sent as download or\n            HTTP status code of the response to be returned.\n          filename (str): Filename to use for saving the content\n          media_type (str, optional): Media type of file.\n          charset (str, optional): Character set of file.\n\n        Returns:\n          content, i.e. the first argument passed to this method.\n\n        Raises:\n          LogicError: When filename cannot be determined.\n        \"\"\"\n        if isinstance(content, int) and content != 200:\n            return content\n        if filename is not None:\n            filename = os.path.basename(filename)\n        elif 'filename' in self.response.state:\n            filename = self.response.state['filename']\n        else:\n            filename = os.path.basename(self.request.path)\n\n        if filename == '':\n            raise LogicError('Cannot determine filename for download')\n\n        if media_type is not None:\n            self.response.media_type = media_type\n        else:\n            self.response.media_type = mimetypes.guess_type(filename)[0]\n        self.response.charset = charset\n        self.response.add_header('Content-Disposition', 'attachment; '\n                                 'filename=\"{}\"'.format(filename))\n        return content", "response": "Send content as attachment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_error_page_callback(self):\n        if self.response.status in self._error_handlers:\n            return self._error_handlers[self.response.status]\n        elif None in self._error_handlers:\n            return self._error_handlers[None]\n        else:\n            # Rudimentary error handler if no error handler was found\n            self.response.media_type = 'text/plain'\n            return lambda: self.response.status_line", "response": "Return an error page callback for the current response status."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a route to the routing table.", "response": "def add(self, method, pattern, callback):\n        \"\"\"Add a route.\n\n        Arguments:\n          method (str): HTTP method, e.g. GET, POST, etc.\n          pattern (str): Pattern that request paths must match.\n          callback (str): Route handler that is invoked when a request\n            path matches the *pattern*.\n        \"\"\"\n        pat_type, pat = self._normalize_pattern(pattern)\n        if pat_type == 'literal':\n            self._literal[method][pat] = callback\n        elif pat_type == 'wildcard':\n            self._wildcard[method].append(WildcardRoute(pat, callback))\n        else:\n            self._regex[method].append(RegexRoute(pat, callback))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if there is at least one handler for method.", "response": "def contains_method(self, method):\n        \"\"\"Check if there is at least one handler for *method*.\n\n        Arguments:\n          method (str): HTTP method name, e.g. GET, POST, etc.\n\n        Returns:\n          ``True`` if there is at least one route defined for *method*,\n          ``False`` otherwise\n        \"\"\"\n        return method in itertools.chain(self._literal, self._wildcard,\n                                         self._regex)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresolves a request to a route handler.", "response": "def resolve(self, method, path):\n        \"\"\"Resolve a request to a route handler.\n\n        Arguments:\n          method (str): HTTP method, e.g. GET, POST, etc. (type: str)\n          path (str): Request path\n\n        Returns:\n          tuple or None: A tuple of three items:\n\n            1. Route handler (callable)\n            2. Positional arguments (list)\n            3. Keyword arguments (dict)\n\n          ``None`` if no route matches the request.\n        \"\"\"\n        if method in self._literal and path in self._literal[method]:\n            return self._literal[method][path], [], {}\n        else:\n            return self._resolve_non_literal_route(method, path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nresolve a request to a wildcard or regex route handler.", "response": "def _resolve_non_literal_route(self, method, path):\n        \"\"\"Resolve a request to a wildcard or regex route handler.\n\n        Arguments:\n          method (str): HTTP method name, e.g. GET, POST, etc.\n          path (str): Request path\n\n        Returns:\n          tuple or None: A tuple of three items:\n\n            1. Route handler (callable)\n            2. Positional arguments (list)\n            3. Keyword arguments (dict)\n\n          ``None`` if no route matches the request.\n        \"\"\"\n        for route_dict in (self._wildcard, self._regex):\n            if method in route_dict:\n                for route in reversed(route_dict[method]):\n                    callback_data = route.match(path)\n                    if callback_data is not None:\n                        return callback_data\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a normalized form of the pattern.", "response": "def _normalize_pattern(pattern):\n        \"\"\"Return a normalized form of the pattern.\n\n        Normalize the pattern by removing pattern type prefix if it\n        exists in the pattern. Then return the pattern type and the\n        pattern as a tuple of two strings.\n\n        Arguments:\n          pattern (str): Route pattern to match request paths\n\n        Returns:\n          tuple: Ruple of pattern type (str) and pattern (str)\n        \"\"\"\n        if pattern.startswith('regex:'):\n            pattern_type = 'regex'\n            pattern = pattern[len('regex:'):]\n        elif pattern.startswith('wildcard:'):\n            pattern_type = 'wildcard'\n            pattern = pattern[len('wildcard:'):]\n        elif pattern.startswith('literal:'):\n            pattern_type = 'literal'\n            pattern = pattern[len('literal:'):]\n        elif RegexRoute.like(pattern):\n            pattern_type = 'regex'\n        elif WildcardRoute.like(pattern):\n            pattern_type = 'wildcard'\n        else:\n            pattern_type = 'literal'\n        return pattern_type, pattern"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef match(self, path):\n        match = self._re.search(path)\n        if match is None:\n            return None\n        args = []\n        kwargs = {}\n        for i, wildcard in enumerate(self._wildcards):\n            if wildcard.name == '!':\n                continue\n            value = wildcard.value(match.groups()[i])\n            if not wildcard.name:\n                args.append(value)\n            else:\n                kwargs[wildcard.name] = value\n        return self._callback, args, kwargs", "response": "Return route handler with arguments if path matches this route."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning route handler with arguments if path matches this route.", "response": "def match(self, path):\n        \"\"\"Return route handler with arguments if path matches this route.\n\n        Arguments:\n          path (str): Request path\n\n        Returns:\n          tuple or None: A tuple of three items:\n\n            1. Route handler (callable)\n            2. Positional arguments (list)\n            3. Keyword arguments (dict)\n\n          ``None`` if the route does not match the path.\n        \"\"\"\n        match = self._re.search(path)\n        if match is None:\n            return None\n        kwargs_indexes = match.re.groupindex.values()\n        args_indexes = [i for i in range(1, match.re.groups + 1)\n                          if i not in kwargs_indexes]\n        args = [match.group(i) for i in args_indexes]\n        kwargs = {}\n        for name, index in match.re.groupindex.items():\n            kwargs[name] = match.group(index)\n        return self._callback, args, kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef response(self):\n        if isinstance(self.body, bytes):\n            out = self.body\n        elif isinstance(self.body, str):\n            out = self.body.encode(self.charset)\n        else:\n            out = b''\n        self.add_header('Content-Type', self.content_type)\n        self.add_header('Content-Length', str(len(out)))\n\n        self.start(self.status_line, self._headers)\n        return [out]", "response": "Return the HTTP response body as a sequence of bytes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_header(self, name, value):\n        if value is not None:\n            self._headers.append((name, value))", "response": "Add an HTTP header to the response object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a Set - Cookie header to the response object.", "response": "def set_cookie(self, name, value, attrs={}):\n        \"\"\"Add a Set-Cookie header to response object.\n\n        For a description about cookie attribute values, see\n        https://docs.python.org/3/library/http.cookies.html#http.cookies.Morsel.\n\n        Arguments:\n          name (str): Name of the cookie\n          value (str): Value of the cookie\n          attrs (dict): Dicitionary with cookie attribute keys and\n                        values.\n        \"\"\"\n        cookie = http.cookies.SimpleCookie()\n        cookie[name] = value\n        for key, value in attrs.items():\n            cookie[name][key] = value\n        self.add_header('Set-Cookie', cookie[name].OutputString())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef status_line(self):\n        return (str(self.status) + ' ' +\n                Response._responses[self.status].phrase)", "response": "Return the HTTP status line."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef content_type(self):\n        if (self.media_type is not None and\n            self.media_type.startswith('text/') and\n            self.charset is not None):\n            return self.media_type + '; charset=' + self.charset\n        else:\n            return self.media_type", "response": "Return the value of the Content - Type header field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the list of all values for the specified key.", "response": "def getall(self, key, default=[]):\n        \"\"\"Return the list of all values for the specified key.\n\n        Arguments:\n          key (object): Key\n          default (list): Default value to return if the key does not\n            exist, defaults to ``[]``, i.e. an empty list.\n\n        Returns:\n          list: List of all values for the specified key if the key\n          exists, ``default`` otherwise.\n        \"\"\"\n        return self.data[key] if key in self.data else default"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rmtree(path, use_shutil=True, followlinks=False, retries=10):\n    '''remove all files and directories below path, including path\n    itself; works even when shutil.rmtree fails because of read-only\n    files in NFS and Windows.  Follows symlinks.\n\n    `use_shutil` defaults to True; useful for testing\n\n    `followlinks` defaults to False; if set to True, shutil.rmtree is\n    not used.\n    '''\n    if use_shutil and not followlinks:\n        try:\n            shutil.rmtree(path)\n            return\n        except Exception, exc:\n            logger.info('shutil.rmtree(%s) failed, so resorting to recursive delete', path)\n            logger.debug('\\ntrapped:\\n%s', traceback.format_exc(exc))\n\n    if not os.path.isdir(path):\n        os.remove(path)\n        return\n\n    ## bottom up traversal removing files and then removing directories\n    for root, dir_names, file_names in os.walk(path, topdown=False, followlinks=followlinks):\n        for fname in file_names:\n            fpath = os.path.join(root, fname)\n            tries = 0\n            while tries < retries:\n                tries += 1\n                try:\n                    os.remove(fpath)\n                    break\n                except Exception, exc:\n                    time.sleep(0.1)\n            if os.path.exists(fpath):\n                logger.critical('os.remove(%s) failed, so leaving data behind!!!', fpath)\n                logger.critical('\\ntrapped:\\n%s', traceback.format_exc(exc))\n                #logger.critical(get_open_fds())\n        for dname in dir_names:\n            full_path = os.path.join(root, dname)\n            if os.path.islink(full_path):\n                real_path = os.path.realpath(full_path)\n                os.remove(full_path)\n                full_path = real_path\n            os.rmdir(full_path)\n\n    if os.path.exists(path):\n        os.rmdir(path)", "response": "Recursively delete all files and directories below path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a rejester. WorkUnit with KBA s3 path fetch it and save it some counts about it.", "response": "def rejester_run(work_unit):\n     '''get a rejester.WorkUnit with KBA s3 path, fetch it, and save\n     some counts about it.\n     '''\n     #fname = 'verify-chunks-%d-%d' % (os.getpid(), time.time())\n     fname = work_unit.key.strip().split('/')[-1]\n     \n     output_dir_path = work_unit.data.get('output_dir_path', '/mnt')\n     u = uuid.uuid3(uuid.UUID(int=0), work_unit.key.strip())\n     path1 = u.hex[0]\n     path2 = u.hex[1]\n     fpath = os.path.join(output_dir_path, path1, path2, fname)\n     if not os.path.exists(os.path.dirname(fpath)):\n          os.makedirs(os.path.dirname(fpath))\n\n     output = gzip.open(fpath + '-out.gz', 'wb')\n\n     expected_si_count = int(fname.split('-')[1])\n\n     max_tries = 20\n     tries = 0\n     while tries < max_tries:\n          try:\n               exc, si_count, serif_count, clean_visible_bytes, clean_visible_count, stream_ids = \\\n                   attempt_fetch(work_unit, fpath)\n               if si_count != expected_si_count:\n                    print 'retrying because si_count = %d != %d expected_si_count' % (si_count, expected_si_count)\n                    sys.stdout.flush()\n                    tries += 1\n                    continue\n               else:\n                    print 'succeeded in reading si_count = %d' % (si_count,)\n                    sys.stdout.flush()\n               output.write( '%s\\t%d\\t%d\\t%d\\t%d\\t%s\\t%s\\n' % (\n                         exc, si_count, serif_count, clean_visible_bytes, clean_visible_count, \n                         work_unit.key.strip(), ','.join(['%s|%s' % tup for tup in stream_ids])) )\n               break\n          except Exception, exc:\n               print 'broken?'\n               print traceback.format_exc(exc)\n               sys.stdout.flush()\n               tries += 1\n               output.write(traceback.format_exc(exc))\n\n     output.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef attempt_fetch(work_unit, fpath):\n     '''attempt a fetch and iteration over a work_unit.key path in s3\n     '''\n     url = 'http://s3.amazonaws.com/aws-publicdatasets/' + work_unit.key.strip()\n\n     ## cheapest way to iterate over the corpus is a few stages of\n     ## streamed child processes.  Note that stderr needs to go\n     ## separately to a file so that reading the stdin doesn't get\n     ## blocked:\n     cmd = '(wget -O - %s | gpg --no-permission-warning --trust-model always --output - --decrypt - | xz --decompress) 2> %s-err' % (url, fpath)\n     print cmd\n     child = Popen(cmd, stdout=PIPE, shell=True)\n     print 'child launched'\n     sys.stdout.flush()\n\n     si_count = 0\n     serif_count = 0\n     exc = ''\n     stream_ids = list()\n     clean_visible_bytes = 0\n     clean_visible_count = 0\n     try:\n         for si in Chunk(file_obj=child.stdout):\n             print si.stream_id, si.abs_url\n             if si.body.language:\n                 lang = si.body.language.code\n             else:\n                 lang = ''\n             stream_ids.append((lang, si.stream_id))\n             if si.body.clean_visible:\n                 clean_visible_count += 1\n                 clean_visible_bytes += len(si.body.clean_visible)\n             si_count += 1\n             if 'serif' in si.body.sentences:\n                 serif_count += 1\n     except Exception, exc:\n         exc = re.sub('\\s+', ' ', str(exc)).strip()\n\n     child.terminate()\n     child.wait()\n     child.stdout.close()\n     return exc, si_count, serif_count, clean_visible_bytes, clean_visible_count, stream_ids", "response": "attempt a fetch and iteration over a work_unit. key path in s3\n    "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_file_lines(file_name):\n    file_path = path.join(path.dirname(path.abspath(__file__)), file_name)\n    with open(file_path) as file_obj:\n        return [line for line in file_obj.read().splitlines() if line]", "response": "Return a list of non - empty lines from file_path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_describers():\n    adjectives = map(lambda x: (x, 'prefix'), get_file_lines('adjectives.txt'))\n    animal_nouns = map(lambda x: (x, 'suffix'), get_file_lines('nouns.txt'))\n    return list(chain(adjectives, animal_nouns))", "response": "Return a list of describer tuples in the form name position"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an ordered 2 - tuple containing a species and a describer.", "response": "def _random_adjspecies_pair():\n    \"\"\"Return an ordered 2-tuple containing a species and a describer.\"\"\"\n    describer, desc_position = random_describer()\n    if desc_position == 'prefix':\n        return (describer, random_species())\n    elif desc_position == 'suffix':\n        return (random_species(), describer)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef random_adjspecies_pair(maxlen=None, prevent_stutter=True):\n    while True:\n        pair = _random_adjspecies_pair()\n        if maxlen and len(''.join(pair)) > maxlen:\n            continue\n        if prevent_stutter and pair[0][-1] == pair[1][0]:\n            continue\n        return pair", "response": "Returns a random set of species and describer pairs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a random adjective or species separated by sep.", "response": "def random_adjspecies(sep='', maxlen=8, prevent_stutter=True):\n    \"\"\"\n    Return a random adjective/species, separated by `sep`. The keyword\n    arguments `maxlen` and `prevent_stutter` are the same as for\n    `random_adjspecies_pair`, but note that the maximum length argument is\n    not affected by the separator.\n    \"\"\"\n    pair = random_adjspecies_pair(maxlen, prevent_stutter)\n    return pair[0] + sep + pair[1]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef morph(ctx, app_id, sentence_file, json_flag,\n          sentence, info_filter, pos_filter, request_id):\n    # type: (Context, unicode, Optional[IO], bool, unicode, unicode, unicode, unicode) -> None  # NOQA\n    \"\"\" Morphological analysis for Japanese.\"\"\"\n\n    app_id = clean_app_id(app_id)\n    sentence = clean_sentence(sentence, sentence_file)\n\n    if info_filter:\n        info_filter = info_filter.replace(',', '|')\n\n    if pos_filter:\n        pos_filter = pos_filter.replace(',', '|')\n\n    api = GoolabsAPI(app_id)\n    ret = api.morph(\n        sentence=sentence,\n        info_filter=info_filter,\n        pos_filter=pos_filter,\n        request_id=request_id,\n    )\n\n    if json_flag:\n        click.echo(format_json(api.response.json()))\n        return\n\n    for words in ret['word_list']:\n        for word in words:\n            click.echo(','.join(word))", "response": "Morph the words in a sentence into a new node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets similarity of two words.", "response": "def similarity(ctx, app_id, json_flag, query_pair, request_id):\n    # type: (Context, unicode, bool, List[unicode], unicode) -> None\n    \"\"\" Scoring the similarity of two words. \"\"\"\n\n    app_id = clean_app_id(app_id)\n\n    api = GoolabsAPI(app_id)\n    ret = api.similarity(\n        query_pair=query_pair,\n        request_id=request_id\n    )\n\n    if json_flag:\n        click.echo(format_json(api.response.json()))\n        return\n\n    click.echo('{0:.16f}'.format(ret['score']))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hiragana(ctx, app_id, sentence_file,\n             json_flag, sentence, output_type, request_id):\n    # type: (Context, unicode, Optional[IO], bool, unicode, unicode, unicode) -> None # NOQA\n    \"\"\" Convert the Japanese to Hiragana or Katakana. \"\"\"\n\n    app_id = clean_app_id(app_id)\n    sentence = clean_sentence(sentence, sentence_file)\n\n    api = GoolabsAPI(app_id)\n    ret = api.hiragana(\n        sentence=sentence,\n        output_type=output_type,\n        request_id=request_id\n    )\n\n    if json_flag:\n        click.echo(format_json(api.response.json()))\n        return\n\n    click.echo(ret['converted'])", "response": "Convert Japanese to Hiragana or Katakana."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef entity(ctx, app_id, sentence_file,\n           json_flag, sentence, class_filter, request_id):\n    # type: (Context, unicode, Optional[IO], bool, unicode, unicode, unicode) -> None # NOQA\n    \"\"\" Extract unique representation from sentence. \"\"\"\n\n    app_id = clean_app_id(app_id)\n    sentence = clean_sentence(sentence, sentence_file)\n\n    if class_filter:\n        class_filter = class_filter.replace(',', '|')\n\n    api = GoolabsAPI(app_id)\n    ret = api.entity(\n        sentence=sentence,\n        class_filter=class_filter,\n        request_id=request_id\n    )\n\n    if json_flag:\n        click.echo(format_json(api.response.json()))\n        return\n\n    for ne in ret['ne_list']:\n        click.echo(','.join(ne))", "response": "Extract unique representation of a sentence."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef shortsum(ctx, app_id, review_file,\n             json_flag, review, length, request_id):\n    # type: (Context, unicode, Optional[IO], bool, unicode, unicode, unicode) -> None # NOQA\n    \"\"\"Summarize reviews into a short summary.\"\"\"\n\n    app_id = clean_app_id(app_id)\n    review_list = clean_review(review, review_file)\n    length_int = clean_length(length)  # type: Optional[int]\n\n    api = GoolabsAPI(app_id)\n    ret = api.shortsum(\n        review_list=review_list,\n        length=length_int,\n        request_id=request_id,\n    )\n\n    if json_flag:\n        click.echo(format_json(api.response.json()))\n        return\n\n    click.echo(ret['summary'])", "response": "Summarize reviews into a short summary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef keyword(ctx, app_id, body_file, json_flag,\n            title, body, max_num, forcus, request_id):\n    # type: (Context, unicode, Optional[IO], bool, unicode, unicode, int, unicode, unicode) -> None # NOQA\n    \"\"\"Extract \"keywords\" from an input document. \"\"\"\n\n    app_id = clean_app_id(app_id)\n    body = clean_body(body, body_file)\n\n    api = GoolabsAPI(app_id)\n    ret = api.keyword(\n        title=title,\n        body=body,\n        max_num=max_num,\n        forcus=forcus,\n        request_id=request_id,\n    )\n\n    if json_flag:\n        click.echo(format_json(api.response.json()))\n        return\n\n    for k in ret['keywords']:\n        k = dict((key.encode('utf-8'), k[key]) for key in k.keys())\n        for keyword, score in six.iteritems(k):\n            click.echo(u'{0},{1}'.format(text(keyword), score))", "response": "Extract keywords from an input document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef chrono(ctx, app_id, sentence_file,\n           json_flag, sentence, doc_time, request_id):\n    # type: (Context, unicode, Optional[IO], bool, unicode, unicode, unicode) -> None  # NOQA\n    \"\"\"Extract expression expressing date and time and normalize its value \"\"\"\n\n    app_id = clean_app_id(app_id)\n    sentence = clean_sentence(sentence, sentence_file)\n\n    api = GoolabsAPI(app_id)\n    ret = api.chrono(\n        sentence=sentence,\n        doc_time=doc_time,\n        request_id=request_id,\n    )\n\n    if json_flag:\n        click.echo(format_json(api.response.json()))\n        return\n\n    for pair in ret['datetime_list']:\n        click.echo(u'{0}: {1}'.format(text(pair[0]), pair[1]))", "response": "Extract expression expressing date and time and normalize its value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(self, stage, scp_config, config=None):\n        '''Create a pipeline stage.\n\n        Instantiates `stage` with `config`.  This essentially\n        translates to ``stage(config)``, except that two keys from\n        `scp_config` are injected into the configuration:\n        ``tmp_dir_path`` is an execution-specific directory from\n        combining the top-level ``tmp_dir_path`` configuration with\n        :attr:`tmp_dir_suffix`; and ``third_dir_path`` is the same\n        path from the top-level configuration.  `stage` may be either\n        a callable returning the stage (e.g. its class), or its name\n        in the configuration.\n\n        `scp_config` is the configuration for the pipeline as a\n        whole, and is required.  `config` is the configuration for\n        the stage; if it is :const:`None` then it is extracted\n        from `scp_config`.\n\n        If you already have a fully formed configuration block\n        and want to create a stage, you can call\n\n        .. code-block:: python\n\n            factory.registry[stage](stage_config)\n\n        In most cases if you have a stage class object and want to\n        instantiate it with its defaults you can call\n\n        .. code-block:: python\n\n            stage = stage_cls(stage_cls.default_config)\n\n        .. note:: This mirrors\n                  :meth:`yakonfig.factory.AutoFactory.create`, with\n                  some thought that this factory class might migrate\n                  to using that as a base in the future.\n\n        :param stage: pipeline stage class, or its name in the registry\n        :param dict scp_config: configuration block for the pipeline\n        :param dict config: configuration block for the stage, or\n          :const:`None` to get it from `scp_config`\n\n        '''\n        # Figure out what we have for a stage and its name\n        if isinstance(stage, basestring):\n            stage_name = stage\n            stage_obj = self.registry[stage_name]\n        else:\n            stage_name = getattr(stage, 'config_name', stage.__name__)\n            stage_obj = stage\n\n        # Find the configuration; get a copy we can mutate\n        if config is None:\n            config = scp_config.get(stage_name, None)\n        if config is None:\n            config = getattr(stage_obj, 'default_config', {})\n        config = dict(config)\n\n        # Fill in more values\n        if self.tmp_dir_suffix is None:\n            config['tmp_dir_path'] = scp_config['tmp_dir_path']\n        else:\n            config['tmp_dir_path'] = os.path.join(scp_config['tmp_dir_path'],\n                                                  self.tmp_dir_suffix)\n        config['third_dir_path'] = scp_config['third_dir_path']\n\n        return stage_obj(config)", "response": "Create a pipeline stage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a list of indirect stages.", "response": "def _init_stages(self, config, name):\n        '''Create a list of indirect stages.\n\n        `name` should be the name of a config item that holds a list\n        of names of stages, for instance, ``writers``.  This looks up\n        the names of those stages, then creates and returns the\n        corresponding list of stage objects.  For instance, if the\n        config says\n\n        .. code-block:: yaml\n\n            incremental_transforms: [clean_html, clean_visible]\n\n        then calling ``self._init_stages(scp_config,\n        'incremental_transforms')`` will return a list of the two\n        named stage instances.\n\n        :param dict config: `streamcorpus_pipeline` configuration block\n        :param str name: name of the stage name list entry\n        :return: list of new stage instances\n\n        '''\n        if name not in config:\n            return []\n        return [self.create(stage, config) for stage in config[name]]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _init_all_stages(self, config):\n        '''Create stages that are used for the pipeline.\n\n        :param dict config: `streamcorpus_pipeline` configuration\n        :return: tuple of (reader, incremental transforms, batch\n          transforms, post-batch incremental transforms, writers,\n          temporary directory)\n\n        '''\n        reader = self._init_stage(config, 'reader')\n        incremental_transforms = self._init_stages(\n            config, 'incremental_transforms')\n        batch_transforms = self._init_stages(config, 'batch_transforms')\n        post_batch_incremental_transforms = self._init_stages(\n            config, 'post_batch_incremental_transforms')\n        writers = self._init_stages(config, 'writers')\n        tmp_dir_path = os.path.join(config['tmp_dir_path'],\n                                    self.tmp_dir_suffix)\n        return (reader, incremental_transforms, batch_transforms,\n                post_batch_incremental_transforms, writers, tmp_dir_path)", "response": "Create stages that are used for the pipeline."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprocess a : class : coordinate. WorkUnit.", "response": "def _process_task(self, work_unit):\n        '''Process a :class:`coordinate.WorkUnit`.\n\n        The work unit's key is taken as the input file name.  The\n        data should have ``start_count`` and ``start_chunk_time``\n        values, which are passed on to :meth:`run`.\n\n        :param work_unit: work unit to process\n        :paramtype work_unit: :class:`coordinate.WorkUnit`\n        :return: number of stream items processed\n\n        '''\n        self.work_unit = work_unit\n        i_str = work_unit.key\n        start_count = work_unit.data['start_count']\n        start_chunk_time = work_unit.data['start_chunk_time']\n        self.run(i_str, start_count, start_chunk_time)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the pipeline. This runs all of the steps described in the pipeline constructor, reading from some input and writing to some output. :param str i_str: name of the input file, or other reader-specific description of where to get input :param int start_count: index of the first stream item :param int start_chunk_time: timestamp for the first stream item", "response": "def run(self, i_str, start_count=0, start_chunk_time=None):\n        '''Run the pipeline.\n\n        This runs all of the steps described in the pipeline constructor,\n        reading from some input and writing to some output.\n\n        :param str i_str: name of the input file, or other reader-specific\n          description of where to get input\n        :param int start_count: index of the first stream item\n        :param int start_chunk_time: timestamp for the first stream item\n\n        '''\n        try:\n            if not os.path.exists(self.tmp_dir_path):\n                os.makedirs(self.tmp_dir_path)\n\n            if start_chunk_time is None:\n                start_chunk_time = time.time()\n\n            ## the reader returns generators of StreamItems\n            i_chunk = self.reader(i_str)\n\n            ## t_path points to the currently in-progress temp chunk\n            t_path = None\n\n            ## loop over all docs in the chunk processing and cutting\n            ## smaller chunks if needed\n\n            len_clean_visible = 0\n            sources = set()\n            next_idx = 0\n\n            ## how many have we input and actually done processing on?\n            input_item_count = 0\n\n            for si in i_chunk:\n                # TODO: break out a _process_stream_item function?\n                next_idx += 1\n\n                ## yield to the gevent hub to allow other things to run\n                if gevent:\n                    gevent.sleep(0)\n\n                ## skip forward until we reach start_count\n                if next_idx <= start_count:\n                    continue\n\n                if next_idx % self.rate_log_interval == 0:\n                    ## indexing is zero-based, so next_idx corresponds\n                    ## to length of list of SIs processed so far\n                    elapsed = time.time() - start_chunk_time\n                    if elapsed > 0:\n                        rate = float(next_idx) / elapsed\n                        logger.info('%d in %.1f --> %.1f per sec on '\n                                    '(pre-partial_commit) %s',\n                                    next_idx - start_count, elapsed, rate,\n                                    i_str)\n\n                if not self.t_chunk:\n                    ## make a temporary chunk at a temporary path\n                    # (Lazy allocation after we've read an item that might get processed out to the new chunk file)\n                    # TODO: make this EVEN LAZIER by not opening the t_chunk until inside _run_incremental_transforms whe the first output si is ready\n                    t_path = os.path.join(self.tmp_dir_path,\n                                          't_chunk-%s' % uuid.uuid4().hex)\n                    self.t_chunk = streamcorpus.Chunk(path=t_path, mode='wb')\n                    assert self.t_chunk.message == streamcorpus.StreamItem_v0_3_0, self.t_chunk.message\n\n                # TODO: a set of incremental transforms is equivalent\n                # to a batch transform.  Make the pipeline explicitly\n                # configurable as such:\n                #\n                # batch_transforms: [[incr set 1], batch op, [incr set 2], ...]\n                #\n                # OR: for some list of transforms (mixed incremental\n                # and batch) pipeline can detect and batchify as needed\n\n                ## incremental transforms populate t_chunk\n                ## let the incremental transforms destroy the si by\n                ## returning None\n                si = self._run_incremental_transforms(\n                    si, self.incremental_transforms)\n\n                ## insist that every chunk has only one source string\n                if si:\n                    sources.add(si.source)\n                    if self.assert_single_source and len(sources) != 1:\n                        raise InvalidStreamItem(\n                            'stream item %r had source %r, not %r '\n                            '(set assert_single_source: false to suppress)' %\n                            (si.stream_id, si.source, sources))\n\n                if si and si.body and si.body.clean_visible:\n                    len_clean_visible += len(si.body.clean_visible)\n                    ## log binned clean_visible lengths, for quick stats estimates\n                    #logger.debug('len(si.body.clean_visible)=%d' % int(10 * int(math.floor(float(len(si.body.clean_visible)) / 2**10)/10)))\n                    #logger.debug('len(si.body.clean_visible)=%d' % len(si.body.clean_visible))\n\n                if ((self.output_chunk_max_count is not None and\n                     len(self.t_chunk) == self.output_chunk_max_count)):\n                    logger.info('reached output_chunk_max_count (%d) at: %d',\n                                len(self.t_chunk), next_idx)\n                    self._process_output_chunk(\n                        start_count, next_idx, sources, i_str, t_path)\n                    start_count = next_idx\n\n                elif (self.output_max_clean_visible_bytes is not None and\n                      len_clean_visible >=\n                      self.output_chunk_max_clean_visible_bytes):\n                    logger.info(\n                        'reached output_chunk_max_clean_visible_bytes '\n                        '(%d) at: %d',\n                        self.output_chunk_max_clean_visible_bytes,\n                        len_clean_visible)\n                    len_clean_visible = 0\n                    self._process_output_chunk(\n                        start_count, next_idx, sources, i_str, t_path)\n                    start_count = next_idx\n\n                input_item_count += 1\n                if (((self.input_item_limit is not None) and\n                     (input_item_count > self.input_item_limit))):\n                    break\n\n            if self.t_chunk is not None:\n                self._process_output_chunk(\n                    start_count, next_idx, sources, i_str, t_path)\n\n            ## return how many stream items we processed\n            return next_idx\n\n        finally:\n            if self.t_chunk is not None:\n                self.t_chunk.close()\n            for transform in self.batch_transforms:\n                transform.shutdown()\n            if self.cleanup_tmp_files:\n                rmtree(self.tmp_dir_path)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _run_writers(self, start_count, next_idx, sources, i_str, t_path):\n        '''Run all of the writers over some intermediate chunk.\n\n        :param int start_count: index of the first item\n        :param int next_idx: index of the next item (after the last\n          item in this chunk)\n        :param list sources: source strings included in this chunk\n          (usually only one source)\n        :param str i_str: name of input file or other input\n        :param str t_path: location of intermediate chunk on disk\n        :return: list of output file paths or other outputs\n\n        '''\n        # writers put the chunk somewhere, and could delete it\n        name_info = dict(\n            first=start_count,\n            # num and md5 computed in each writers\n            source=sources.pop(),\n            )\n\n        all_o_paths = []\n        for writer in self.writers:\n            logger.debug('running %r on %r: %r', writer, i_str, name_info)\n            o_paths = writer(t_path, name_info, i_str)\n            logger.debug('loaded (%d, %d) of %r into %r',\n                         start_count, next_idx - 1, i_str, o_paths)\n            all_o_paths += o_paths\n        return all_o_paths", "response": "Run all of the writers over some intermediate chunk."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _run_incremental_transforms(self, si, transforms):\n        '''\n        Run transforms on stream item.\n        Item may be discarded by some transform.\n        Writes successful items out to current self.t_chunk\n        Returns transformed item or None.\n        '''\n        ## operate each transform on this one StreamItem\n        for transform in transforms:\n            try:\n                stream_id = si.stream_id\n                si_new = transform(si, context=self.context)\n\n                if si_new is None:\n                    logger.warn('transform %r deleted %s abs_url=%r',\n                                 transform, stream_id, si and si.abs_url)\n                    return None\n                si = si_new\n\n            except TransformGivingUp:\n                ## do nothing\n                logger.info('transform %r giving up on %r',\n                            transform, si.stream_id)\n\n            except Exception, exc:\n                logger.critical(\n                    'transform %r failed on %r from i_str=%r abs_url=%r',\n                    transform, si and si.stream_id, self.context.get('i_str'),\n                    si and si.abs_url, exc_info=True)\n\n        assert si is not None\n\n        ## expect to always have a stream_time\n        if not si.stream_time:\n            raise InvalidStreamItem('empty stream_time: %s' % si)\n\n        if si.stream_id is None:\n            raise InvalidStreamItem('empty stream_id: %r' % si)\n\n        ## put the StreamItem into the output\n        if type(si) != streamcorpus.StreamItem_v0_3_0:\n            raise InvalidStreamItem('incorrect stream item object %r' %\n                                    type(si))\n        self.t_chunk.add(si)\n        return si", "response": "Run the incremental transforms on a stream item."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dict that contains the date_hour md5 num_now date_hour md5 num_now date_hour time_now date_now date_", "response": "def get_name_info(chunk_path, assert_one_date_hour=False, i_str=None,\n                  chunk_type=Chunk):\n    '''\n    takes a chunk blob and obtains the date_hour, md5, num\n\n    makes fields:\n    i_str\n    input_fname\n    input_md5 - parsed from input filename if it contains '-%(md5)s-'\n    md5\n    num\n    epoch_ticks\n    target_names\n    doc_ids_8\n    date_hour\n    rand8\n    date_now\n    time_now\n    date_time_now\n    '''\n    assert i_str is not None, 'must provide i_str as keyword arg'\n\n    name_info = dict()\n    if i_str:\n        name_info['i_str'] = i_str\n    else:\n        name_info['i_str'] = ''\n\n    i_fname = i_str.split('/')[-1]\n    i_fname = i_fname.split('.')[0]  ## strip off .sc[.xz[.gpg]]\n    name_info['input_fname'] = i_fname \n\n    input_md5s = []\n    for part in i_fname.split('-'):\n        if len(part) == 32 and is_hex_32.match(part):\n            input_md5s.append(part)\n    name_info['input_md5'] = '-'.join(input_md5s)\n\n    # TODO: return a dict-like object that does the expensive\n    # calculation lazily, the name format might not even need that\n    # value.\n    ch = chunk_type(path=chunk_path, mode='rb')\n    date_hours = set()\n    target_names = set()\n    doc_ids = set()\n    epoch_ticks = None\n    count = 0\n    try:\n        for si in ch:\n            if chunk_type is Chunk:\n                if epoch_ticks is None:\n                    epoch_ticks = si.stream_time.epoch_ticks\n                date_hours.add( si.stream_time.zulu_timestamp[:13] )\n                doc_ids.add( si.doc_id )\n                for annotator_id, ratings in si.ratings.items():\n                    for rating in ratings:\n                        target_name = rating.target.target_id.split('/')[-1]\n                        target_names.add( target_name )\n            count += 1\n    except Exception, exc:\n        logger.critical('failed to iter over chunk', exc_info=True)\n        \n\n    ## create the md5 property, so we can use it in the filename\n    if hasattr(ch, 'md5_hexdigest'):\n        name_info['md5'] = ch.md5_hexdigest\n    else:\n        try:\n            data = open(chunk_path).read()\n            name_info['md5'] = hashlib.md5(data).hexdigest()\n        except Exception, exc:\n            logger.critical('failed to compute md5', exc_info=True)\n            name_info['md5'] = 'broken'\n    name_info['num'] = count\n    name_info['epoch_ticks'] = epoch_ticks\n\n    name_info['target_names'] = '-'.join( target_names )\n    name_info['doc_ids_8'] = '-'.join( [di[:8] for di in doc_ids] )\n\n    if chunk_type is Chunk:\n        if assert_one_date_hour:\n            assert len(date_hours) == 1, \\\n                'got a chunk with other than one data_hour! ' + \\\n                repr(date_hours)\n\n        if len(date_hours) > 0:\n            date_hour = list(date_hours)[0]\n            date_hour = date_hour.replace('T', '-')\n        else:\n            assert count == 0, (date_hours, count)\n            date_hour = None\n        name_info['date_hour'] = date_hour\n    else:\n        name_info['date_hour'] = 'NO-DATE-HOUR-FOR-FC'\n\n    # TODO: in future lazy evaluation world, rand8 should return a\n    # different value every time it is accessed so that a format could\n    # be 'foo-{rand8}{rand8}'\n    name_info['rand8'] = '%08x' % (random.randint(0, 0x7fffffff),)\n\n    name_info['date_now'] = datetime.datetime.utcnow().strftime('%Y-%m-%d')\n    name_info['time_now'] = datetime.datetime.utcnow().strftime('%H-%M-%S')\n    name_info['date_time_now'] = datetime.datetime.utcnow().strftime('%Y-%m-%d-%H-%M-%S')\n\n    return name_info"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplaces the top - level pipeline configurable object.", "response": "def replace_config(config, name):\n    '''Replace the top-level pipeline configurable object.\n\n    This investigates a number of sources, including\n    `external_stages_path` and `external_stages_modules` configuration\n    and `streamcorpus_pipeline.stages` entry points, and uses these to\n    find the actual :data:`sub_modules` for\n    :mod:`streamcorpus_pipeline`.\n\n    '''\n    global static_stages\n    if static_stages is None:\n        static_stages = PipelineStages()\n        stages = static_stages\n        if 'external_stages_path' in config:\n            path = config['external_stages_path']\n            if not os.path.isabs(path) and config.get('root_path'):\n                path = os.path.join(config['root_path'], path)\n            try:\n                stages.load_external_stages(config['external_stages_path'])\n            except IOError:\n                return streamcorpus_pipeline  # let check_config re-raise this\n        if 'external_stages_modules' in config:\n            for mod in config['external_stages_modules']:\n                try:\n                    stages.load_module_stages(mod)\n                except ImportError:\n                    return streamcorpus_pipeline  # let check_config re-raise this\n    else:\n        stages = static_stages\n\n    new_sub_modules = set(stage\n                          for stage in stages.itervalues()\n                          if hasattr(stage, 'config_name'))\n    return NewSubModules(streamcorpus_pipeline, new_sub_modules)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_app():\n    env = Environment()\n    # STDIN is ignored because HTTPony runs a server that doesn't care.\n    # Additionally, it is needed or else pytest blows up.\n    args = parser.parse_args(args=['/', '--ignore-stdin'], env=env)\n    args.output_options = 'HB'  # Output only requests.\n    server = 'HTTPony/{0}'.format(__version__)\n\n    def application(environ, start_response):\n        # The WSGI server puts content length and type in the environment\n        # even when not provided with the request. Drop them if they are empty.\n        if environ.get('CONTENT_LENGTH') == '':\n            del environ['CONTENT_LENGTH']\n        if environ.get('CONTENT_TYPE') == '':\n            del environ['CONTENT_TYPE']\n\n        wrequest = WerkzeugRequest(environ)\n        data = wrequest.get_data()\n        request = Request(\n            method=wrequest.method,\n            url=wrequest.url,\n            headers=wrequest.headers,\n            data=data,\n        )\n        prepared = request.prepare()\n\n        stream = streams.build_output_stream(\n            args, env, prepared, response=None,\n            output_options=args.output_options)\n        streams.write_stream(stream, env.stdout, env.stdout_isatty)\n\n        # When there is data in the request, give the next one breathing room.\n        if data:\n            print(\"\\n\", file=env.stdout)\n\n        # Make dreams come true.\n        response = Response(headers={'Server': server})\n        return response(environ, start_response)\n\n    return application", "response": "Make a WSGI application that has all the HTTPie pieces baked in."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_chains_with_names(sentences):\n    '''\n    assemble in-doc coref chains by mapping equiv_id to tokens and\n    their cleansed name strings\n\n    :param sentences: iterator over token generators\n    :returns dict:\n        keys are equiv_ids,\n        values are tuple(concatentated name string, list of tokens)\n    '''\n    ## if an equiv_id is -1, then the token is classified into some\n    ## entity_type but has not other tokens in its chain.  We don't\n    ## want these all lumped together, so we give them distinct \"fake\"\n    ## equiv_id other than -1 -- counting negatively to avoid\n    ## collisions with \"real\" equiv_ids\n    fake_equiv_ids = -2\n\n    ## use a default dictionary\n    equiv_ids = collections.defaultdict(lambda: (set(), set()))\n\n    for tagger_id, sents in sentences.items():\n        for sent in sents:\n            for tok in sent.tokens:\n                if tok.entity_type is not None:\n\n                    ## get an appropriate equiv_id\n                    if tok.equiv_id == -1:\n                        eqid = fake_equiv_ids\n                        fake_equiv_ids -= 1\n                    else:\n                        eqid = tok.equiv_id\n\n                    ## store the name parts initially as a set\n                    equiv_ids[eqid][0].add(cleanse(tok.token.decode('utf8')))\n                    ## carry a *reference* to the entire Token object\n                    equiv_ids[eqid][1].add(tok)\n\n    return equiv_ids", "response": "assemble in - doc coref chains by mapping equiv_id to tokens and their cleansed name strings"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ALL_mentions(target_mentions, chain_mentions):\n    '''\n    For each name string in the target_mentions list, searches through\n    all chain_mentions looking for any cleansed Token.token that\n    contains the name.  Returns True only if all of the target_mention\n    strings appeared as substrings of at least one cleansed\n    Token.token.  Otherwise, returns False.\n\n    :type target_mentions: list of basestring\n    :type chain_mentions: list of basestring\n\n    :returns bool:\n    '''\n    found_all = True\n    for name in target_mentions:\n        found_one = False\n        for chain_ment in chain_mentions:\n            if name in chain_ment:\n                found_one = True\n                break\n        if not found_one:\n            found_all = False\n            break\n    return found_all", "response": "Returns True if all of the target_mentions in chain_mentions are contained in at least one cleansed\n    Token. token."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if any of the target_mentions are in chain_mentions False otherwise.", "response": "def ANY_MULTI_TOKEN_mentions(multi_token_target_mentions, chain_mentions):\n    '''\n    For each name string (potentially consisting of multiple tokens) in the\n    target_mentions list, searches through all chain_mentions looking for any\n    cleansed Token.token that contains all the tokens in the name.  Returns\n    True only if all of the target_mention strings appeared as substrings of at\n    least one cleansed Token.token.  Otherwise, returns False.\n\n    :type target_mentions: list of basestring\n    :type chain_mentions: list of basestring\n\n    :returns bool:\n    '''\n    for multi_token_name in multi_token_target_mentions:\n        if ALL_mentions(multi_token_name.split(), chain_mentions):\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ANY_mentions(target_mentions, chain_mentions):\n    '''\n    For each name string in the target_mentions list, searches through\n    all chain_mentions looking for any cleansed Token.token that\n    contains the name.  Returns True if any of the target_mention\n    strings appeared as substrings of any cleansed Token.token.\n    Otherwise, returns False.\n\n    :type target_mentions: list of basestring\n    :type chain_mentions: list of basestring\n\n    :returns bool:\n    '''\n    for name in target_mentions:\n        for chain_ment in chain_mentions:\n            if name in chain_ment:\n                return True\n    return False", "response": "Returns True if any of the target_mentions in chain_mentions are contained in any of the chain_mentions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef names_in_chains(stream_item, aligner_data):\n    '''\n    Convert doc-level Rating object into a Label, and add that Label\n    to all Token in all coref chains identified by\n    aligner_data[\"chain_selector\"]\n\n    :param stream_item: document that has a doc-level Rating to translate into token-level Labels.\n    :param aligner_data: dict containing:\n      chain_selector: ALL or ANY\n      annotator_id: string to find at stream_item.Ratings[i].annotator.annotator_id\n\n    If chain_selector==ALL, then only apply Label to chains in which\n    all of the Rating.mentions strings appear as substrings within at\n    least one of the Token.token strings.\n\n    If chain_selector==ANY, then apply Label to chains in which any of\n    the Rating.mentions strings appear as a substring within at least\n    one of the Token.token strings.\n\n    If chain_selector==ANY_MULTI_TOKEN, then apply Label to chains in which all\n    the names in any of the Rating.mentions strings appear as a substring within at least\n    one of the Token.token strings.\n    '''\n    chain_selector = aligner_data.get('chain_selector', '')\n    assert chain_selector in _CHAIN_SELECTORS, \\\n        'chain_selector: %r not in %r' % (chain_selector, _CHAIN_SELECTORS.keys())\n\n    ## convert chain_selector to a function\n    chain_selector = _CHAIN_SELECTORS[chain_selector]\n\n    ## make inverted index equiv_id --> (names, tokens)\n    equiv_ids = make_chains_with_names( stream_item.body.sentences )\n\n    required_annotator_id = aligner_data.get('annotator_id')\n\n    for annotator_id, ratings in stream_item.ratings.items():\n        if (required_annotator_id is not None) and (annotator_id != required_annotator_id):\n            continue\n        else:\n            for rating in ratings:\n                label = Label(annotator=rating.annotator,\n                              target=rating.target)\n\n                for eqid, (chain_mentions, chain_tokens) in equiv_ids.items():\n                    if chain_selector(rating.mentions, chain_mentions):\n                        ## apply the label\n                        for tok in chain_tokens:\n                            add_annotation(tok, label)", "response": "Convert a stream item Rating object into a list of Token - level Label objects and add that Label to all Token in all Coref chains identified by the stream item s Rating."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\niterate through all tokens looking for matches of cleansed tokens or token regexes skipping any tokens left empty by cleansing and yielding a list of tokens that match. Yields all tokens that match.", "response": "def look_ahead_match(rating, tokens):\n    '''iterate through all tokens looking for matches of cleansed tokens\n    or token regexes, skipping tokens left empty by cleansing and\n    coping with Token objects that produce multiple space-separated\n    strings when cleansed.  Yields tokens that match.\n\n    '''\n    ## this ensures that all cleansed tokens are non-zero length\n    all_mregexes = []\n    for m in rating.mentions:\n        mregexes = []\n        mpatterns = m.decode('utf8').split(' ')\n        for mpat in mpatterns:\n            if mpat.startswith('ur\"^') and mpat.endswith('$\"'): # is not regex\n                ## chop out the meat of the regex so we can reconstitute it below\n                mpat = mpat[4:-2]\n            else:\n                mpat = cleanse(mpat)\n            if mpat:\n                ## make a unicode raw string\n                ## https://docs.python.org/2/reference/lexical_analysis.html#string-literals\n                mpat = ur'^%s$' % mpat\n                logger.debug('look_ahead_match compiling regex: %s', mpat)\n                mregexes.append(re.compile(mpat, re.UNICODE | re.IGNORECASE))\n\n        if not mregexes:\n            logger.warn('got empty cleansed mention: %r\\nrating=%r' % (m, rating))\n\n        all_mregexes.append(mregexes)\n\n    ## now that we have all_mregexes, go through all the tokens\n    for i in range(len(tokens)):\n        for mregexes in all_mregexes:\n            if mregexes[0].match(tokens[i][0][0]):\n                ## found the start of a possible match, so iterate\n                ## through the tuples of cleansed strings for each\n                ## Token while stepping through the cleansed strings\n                ## for this mention.\n                m_j = 1\n                i_j = 0\n                last_token_matched = 0\n                matched = True\n                while m_j < len(mregexes):\n                    i_j += 1\n                    if i_j == len(tokens[i + last_token_matched][0]):\n                        i_j = 0\n                        last_token_matched += 1\n                        if i + last_token_matched == len(tokens):\n                            matched = False\n                            break\n                    target_token = tokens[i + last_token_matched][0][i_j]\n                    ## this next line is the actual string comparison\n                    if mregexes[m_j].match(target_token):\n                        m_j += 1\n                    elif target_token == '':\n                        continue\n                    else:\n                        matched = False\n                        break\n                if matched:\n                    ## yield each matched token only once\n                    toks = set()\n                    for j in xrange(last_token_matched + 1):\n                        toks.add(tokens[i + j][1])\n                    for tok in toks:\n                        yield tok"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates through tokens looking for near - exact matches to strings in si. ratings... mentions in si. content. sentences... returns the list of tokens that match the given aligner data.", "response": "def multi_token_match(stream_item, aligner_data):\n    '''\n    iterate through tokens looking for near-exact matches to strings\n    in si.ratings...mentions\n    '''    \n    tagger_id = _get_tagger_id(stream_item, aligner_data)\n    sentences = stream_item.body.sentences.get(tagger_id)\n    if not sentences:\n        return\n    ## construct a list of tuples, where the first part of each tuple\n    ## is a tuple of cleansed strings, and the second part is the\n    ## Token object from which it came.\n    tokens = map(lambda tok: (cleanse(tok.token.decode('utf8')).split(' '), tok), \n                 itertools.chain(*[sent.tokens for sent in sentences]))    \n    required_annotator_id = aligner_data['annotator_id']\n    for annotator_id, ratings in stream_item.ratings.items():\n        if (required_annotator_id is None) or (annotator_id == required_annotator_id):\n            for rating in ratings:\n                label = Label(annotator=rating.annotator,\n                              target=rating.target)\n                \n                num_tokens_matched = 0\n                for tok in look_ahead_match(rating, tokens):\n                    if aligner_data.get('update_labels'):\n                        tok.labels.pop(annotator_id, None)\n                    add_annotation(tok, label)\n                    num_tokens_matched += 1\n\n                if num_tokens_matched == 0:\n                    logger.warning('multi_token_match didn\\'t actually match '\n                                   'entity %r in stream_id %r',\n                                   rating.target.target_id,\n                                   stream_item.stream_id)\n                else:\n                    logger.debug('matched %d tokens for %r in %r',\n                                 num_tokens_matched, rating.target.target_id,\n                                 stream_item.stream_id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun a child process to get XML output", "response": "def make_ner_file(self, clean_visible_path, ner_xml_path):\n        '''run tagger a child process to get XML output'''\n        if self.template is None:\n            raise exceptions.NotImplementedError('''\nSubclasses must specify a class property \"template\" that provides\ncommand string format for running a tagger.  It should take\n%(tagger_root_path)s as the path from the config file,\n%(clean_visible_path)s as the input XML file, and %(ner_xml_path)s as\nthe output path to create.\n''')\n        tagger_config = dict(\n            tagger_root_path=self.config['tagger_root_path'],\n            clean_visible_path=clean_visible_path,\n            ner_xml_path=ner_xml_path)\n        ## get a java_heap_size or default to 1GB\n        tagger_config['java_heap_size'] = self.config.get('java_heap_size', '')\n        cmd = self.template % tagger_config\n        start_time = time.time()\n        ## make sure we are using as little memory as possible\n        gc.collect()\n        try:\n            self._child = subprocess.Popen(cmd, stderr=subprocess.PIPE, shell=True)\n        except OSError, exc:\n            msg = traceback.format_exc(exc)\n            msg += make_memory_info_msg(clean_visible_path, ner_xml_path)\n            raise PipelineOutOfMemory(msg)\n\n        s_out, errors = self._child.communicate()\n\n        if not self._child.returncode == 0:\n            if 'java.lang.OutOfMemoryError' in errors:\n                msg = errors + make_memory_info_msg(clean_visible_path, ner_xml_path)\n                raise PipelineOutOfMemory(msg)\n            elif self._child.returncode == 137:\n                msg = 'tagger returncode = 137\\n' + errors\n                msg += make_memory_info_msg(clean_visible_path, ner_xml_path)\n                # maybe get a tail of /var/log/messages\n                raise PipelineOutOfMemory(msg)\n            elif 'Exception' in errors:\n                raise PipelineBaseException(errors)\n            else:\n                raise PipelineBaseException('tagger exited with %r' % self._child.returncode)\n\n        elapsed = time.time() - start_time\n        logger.info('finished tagging in %.1f seconds' % elapsed)\n        return elapsed"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef align_chunk_with_ner(self, ner_xml_path, i_chunk, o_chunk):\n        ''' iterate through ner_xml_path to fuse with i_chunk into o_chunk '''\n        ## prepare to iterate over the input chunk\n        input_iter = i_chunk.__iter__()\n\n        all_ner = xml.dom.minidom.parse(open(ner_xml_path))\n\n        ## this converts our UTF-8 data into unicode strings, so when\n        ## we want to compute byte offsets or construct tokens, we\n        ## must .encode('utf8')\n        for ner_dom in all_ner.getElementsByTagName('FILENAME'):\n        #for stream_id, raw_ner in files(open(ner_xml_path).read().decode('utf8')):\n\n            stream_item = input_iter.next()\n\n            ## get stream_id out of the XML\n            stream_id = ner_dom.attributes.get('stream_id').value\n            if stream_item.stream_id is None:\n                assert not stream_id, 'out of sync: None != %r' % stream_id\n                logger.critical('si.stream_id is None... ignoring')\n                continue\n            assert stream_id and stream_id == stream_item.stream_id, \\\n                '%s != %s' % (stream_id, stream_item.stream_id)\n\n            if not stream_item.body:\n                ## the XML better have had an empty clean_visible too...\n                #assert not ner_dom....something\n                continue\n\n            tagging = Tagging()\n            tagging.tagger_id = self.tagger_id  # pylint: disable=E1101\n\n            '''\n            ## get this one file out of its FILENAME tags\n            tagged_doc_parts = list(files(ner_dom.toxml()))\n            if not tagged_doc_parts:\n                continue\n\n            tagged_doc = tagged_doc_parts[0][1]\n\n            ## hack\n            hope_original = make_clean_visible(tagged_doc, '')\n            open(ner_xml_path + '-clean', 'wb').write(hope_original.encode('utf-8'))\n            print ner_xml_path + '-clean'\n            '''\n\n            #tagging.raw_tagging = tagged_doc\n            tagging.generation_time = streamcorpus.make_stream_time()\n            stream_item.body.taggings[self.tagger_id] = tagging       # pylint: disable=E1101\n\n            ## could consume lots of memory here by instantiating everything\n            sentences, relations, attributes = self.get_sentences(ner_dom)\n            stream_item.body.sentences[self.tagger_id] = sentences    # pylint: disable=E1101\n            stream_item.body.relations[self.tagger_id] = relations    # pylint: disable=E1101\n            stream_item.body.attributes[self.tagger_id] = attributes  # pylint: disable=E1101\n\n            logger.debug('finished aligning tokens %s' % stream_item.stream_id)\n\n            '''\n            for num, sent in enumerate(sentences):\n                for tok in sent.tokens:\n                    print '%d\\t%d\\t%s' % (num, tok.offsets[OffsetType.LINES].first, repr(tok.token))\n            '''\n\n            if 'align_labels_by' in self.config and self.config['align_labels_by']:\n                assert 'aligner_data' in self.config, 'config missing \"aligner_data\"'\n                aligner = AlignmentStrategies[ self.config['align_labels_by'] ]\n                aligner( stream_item, self.config['aligner_data'] )\n\n            ## forcibly collect dereferenced objects\n            gc.collect()\n\n            try:\n                o_chunk.add(stream_item)\n            except MemoryError, exc:\n                msg = traceback.format_exc(exc)\n                msg += make_memory_info_msg()\n                logger.critical(msg)\n                raise PipelineOutOfMemory(msg)\n\n        ## all done, so close the o_chunk\n        try:\n            o_chunk.close()\n            logger.info('finished chunk for %r' % ner_xml_path)\n        except MemoryError, exc:\n            msg = traceback.format_exc(exc)\n            msg += make_memory_info_msg()\n            logger.critical(msg)\n            raise PipelineOutOfMemory(msg)", "response": "aligns a chunk with a ner xml file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a Pattern that matches exactly n repetitions of p.", "response": "def mult(p, n):\n    \"\"\"Returns a Pattern that matches exactly n repetitions of Pattern p.\n    \"\"\"\n    np = P()\n    while n >= 1:\n        if n % 2:\n            np = np + p\n        p = p + p\n        n = n // 2\n    return np"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fix_emails(text):\n    '''Replace all angle bracket emails with a unique key.'''\n    emails = bracket_emails.findall(text)\n\n    keys = []\n    for email in emails:\n\t_email = email.replace(\"<\",\"&lt;\").replace(\">\",\"&gt;\")\n        text = text.replace(email, _email)\n\n    return text", "response": "Replace all angle bracket emails with a unique key."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates strings identified as sentences", "response": "def _sentences(self, clean_visible):\n        'generate strings identified as sentences'\n        previous_end = 0\n        clean_visible = clean_visible.decode('utf8')\n        for start, end in self.sentence_tokenizer.span_tokenize(clean_visible):\n            # no need to check start, because the first byte of text\n            # is always first byte of first sentence, and we will\n            # have already made the previous sentence longer on the\n            # end if there was an overlap.\n            if start < previous_end:\n                start = previous_end\n                if start > end:\n                    # skip this sentence... because it was eaten by\n                    # an earlier sentence with a label\n                    continue\n            try:\n                label = self.label_index.find_le(end)\n            except ValueError:\n                label = None\n            if label:\n                ## avoid splitting a label\n                off = label.offsets[OffsetType.CHARS]\n                end = max(off.first + off.length, end)\n            previous_end = end\n            sent_str = clean_visible[start:end]\n            yield start, end, sent_str"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_label_index(self, stream_item):\n        'make a sortedcollection on body.labels'\n        labels = stream_item.body.labels.get(self.annotator_id)\n        if not labels:\n            labels = []\n\n        self.label_index = SortedCollection(\n            [l for l in labels if OffsetType.CHARS in l.offsets],\n            key=lambda label: label.offsets[OffsetType.CHARS].first)", "response": "make a sortedcollection on body. labels"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nassembling Sentence and Token objects", "response": "def make_sentences(self, stream_item):\n        'assemble Sentence and Token objects'\n        self.make_label_index(stream_item)\n        sentences = []\n        token_num = 0\n        new_mention_id = 0\n        for sent_start, sent_end, sent_str in self._sentences(\n                stream_item.body.clean_visible):\n            assert isinstance(sent_str, unicode)\n            sent = Sentence()\n            sentence_pos = 0\n            for start, end in self.word_tokenizer.span_tokenize(sent_str):\n                token_str = sent_str[start:end].encode('utf8')\n                tok = Token(\n                    token_num=token_num,\n                    token=token_str,\n                    sentence_pos=sentence_pos,\n                )\n                tok.offsets[OffsetType.CHARS] = Offset(\n                    type=OffsetType.CHARS,\n                    first=sent_start + start,\n                    length=end - start,\n                )\n                # whitespace tokenizer will never get a token\n                # boundary in the middle of an 'author' label\n                try:\n                    label = self.label_index.find_le(sent_start + start)\n                except ValueError:\n                    label = None\n                if label:\n                    off = label.offsets[OffsetType.CHARS]\n                    if off.first + off.length > sent_start + start:\n                        streamcorpus.add_annotation(tok, label)\n                        logger.debug('adding label to tok: %r has %r',\n                                     tok.token, label.target.target_id)\n\n                        if label in self.label_to_mention_id:\n                            mention_id = self.label_to_mention_id[label]\n                        else:\n                            mention_id = new_mention_id\n                            new_mention_id += 1\n                            self.label_to_mention_id[label] = mention_id\n\n                        tok.mention_id = mention_id\n\n                token_num += 1\n                sentence_pos += 1\n                sent.tokens.append(tok)\n            sentences.append(sent)\n        return sentences"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert any HTML XML or numeric entities in the attribute values into unicode.", "response": "def html_entities_to_unicode(text, space_padding=False, safe_only=False):\n    '''\n    Convert any HTML, XML, or numeric entities in the attribute values.\n    For example '&amp;' becomes '&'.\n\n    This is adapted from BeautifulSoup, which should be able to do the\n    same thing when called like this --- but this fails to convert\n    everything for some bug.\n\n    text = unicode(BeautifulStoneSoup(text, convertEntities=BeautifulStoneSoup.XML_ENTITIES))\n    '''\n    def convert_entities(match):\n        '''\n        comes from BeautifulSoup.Tag._convertEntities\n        '''\n        x = match.group(1)\n\n        if safe_only and x not in ENTITIES_THAT_ARE_SAFE_TO_STRING_PAD:\n            return u'&%s;' % x\n\n        if x in name2codepoint:\n            ## handles most cases\n            return unichr(name2codepoint[x])\n\n        elif x in XML_ENTITIES_TO_SPECIAL_CHARS:\n            return XML_ENTITIES_TO_SPECIAL_CHARS[x]\n\n        elif len(x) > 0 and x[0] == '#':\n            # Handle numeric entities\n            if len(x) > 1 and x[1] == 'x':\n                return unichr(int(x[2:], 16))\n            else:\n                return unichr(int(x[1:]))\n        else:\n            ## uh oh, failed to anything\n            return u'&%s;' % x\n\n    def convert_to_padded_entitites(match):\n        converted_string = convert_entities(match)\n        num_spaces_needed = len(match.group(0)) - len(converted_string)\n        assert num_spaces_needed >= 0, \\\n            'len(%r) !<= len(%r)' % (converted_string, match.group(0))\n        ## Where to put the spaces?  Before, after, symmetric?\n        # Let's do symmetric.\n        ## cast to int in prep for python3\n        num_left = int(num_spaces_needed / 2)\n        num_right = num_spaces_needed - num_left\n        return (' ' * num_left) + converted_string + (' ' * num_right)\n\n    ## brute force regex through all the characters...\n    if space_padding:\n        return tags.sub(\n                      convert_to_padded_entitites,\n                      text)\n    else:\n        return tags.sub(\n                      convert_entities,\n                      text)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tps(text, min_token_len=2, quant_rate=0.01):\n    '''\n    :param text: tag-free UTF-8 string of free text\n    :returns string: 32-character md5 hash in hexadecimal\n\n    Python implementation of the TextProfileSignature provided in\n    SOLR.  Unlike most other locality sensitive hashes, a TPS can be\n    indexed as a searchable property of each document that does not\n    require n^2 comparisons to find duplicates.\n\n    http://wiki.apache.org/solr/TextProfileSignature\n    '''\n    \n    counts = Counter(\n        ifilter(lambda x: len(x) >= min_token_len, \n                imap(cleanse, text.split())))\n\n    max_freq = counts.most_common(1)[0][1]\n    if max_freq <= 1:\n        quant = 1\n    else:\n        quant = max(2, round(max_freq * quant_rate))\n\n    to_hash = []\n    for word, count in counts.most_common():\n        if count <= quant:\n            break\n        to_hash += [word, str(int(math.floor(count / quant)))]\n\n    to_hash = u' '.join(to_hash)\n    return hashlib.md5(to_hash.encode('utf8')).hexdigest()", "response": "Return 32 - character md5 hash of text in a tag - free UTF - 8 string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake a temp file of cleansed text", "response": "def make_cleansed_file(i_chunk, tmp_cleansed_path):\n    '''make a temp file of cleansed text'''\n    tmp_cleansed = open(tmp_cleansed_path, 'wb')\n    for idx, si in enumerate(i_chunk):\n        tmp_cleansed.write('<FILENAME docid=\"%s\">\\n' % si.stream_id)\n        tmp_cleansed.write(si.body.cleansed)\n        ## how to deal with other_content?\n        tmp_cleansed.write('</FILENAME>\\n')\n    tmp_cleansed.close()\n    ## replace this with log.info()\n    print 'created %s' % tmp_cleansed_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_ner_file(tagger_id, tmp_cleansed_path, tmp_ner_path, pipeline_root):\n    '''run child process to get OWPL output'''\n    params = dict(INPUT_FILE=tmp_cleansed_path,\n                  #RAW_OUTPUT_FILE=tmp_ner_raw_path,\n                  OUTPUT_FILE=tmp_ner_path,\n                  PIPELINE_ROOT=pipeline_root)\n    \n    pipeline_cmd = pipeline_cmd_templates[tagger_id] % params\n\n    print pipeline_cmd\n\n    ## replace this with log.info()\n    print 'creating %s' % tmp_ner_path\n    start_time = time.time()\n    gpg_child = subprocess.Popen(\n        pipeline_cmd,\n        stderr=subprocess.PIPE, shell=True)\n    s_out, errors = gpg_child.communicate()\n    assert gpg_child.returncode == 0 and 'Exception' not in errors, errors\n    elapsed = time.time() - start_time\n    ## replace this with log.info()\n    print 'created %s in %.1f sec' % (tmp_ner_path, elapsed)\n\n    '''\n    postproc_cmd = postproc_cmd_templates[tagger_id] % params\n\n    print postproc_cmd\n\n    ## replace this with log.info()\n    print 'creating %s' % tmp_ner_raw_path\n    start_time = time.time()\n    gpg_child = subprocess.Popen(\n        postproc_cmd,\n        stderr=subprocess.PIPE, shell=True)\n    s_out, errors = gpg_child.communicate()\n    assert gpg_child.returncode == 0 and 'Exception' not in errors, errors\n    elapsed = time.time() - start_time\n\n    ## replace this with log.info()\n    print 'created %s in %.1f sec' % (tmp_ner_path, elapsed)\n    '''", "response": "run child process to get OWPL output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a string of text into a lowercase string with no punctuation and only spaces for whitespace.", "response": "def cleanse(span):\n    '''Convert a string of text into a lowercase string with no\n    punctuation and only spaces for whitespace.\n\n    :param span: string\n    '''\n    try:\n        ## attempt to force it to utf8, which might fail\n        span = span.encode('utf8', 'ignore')\n    except:\n        pass\n    ## lowercase, strip punctuation, and shrink all whitespace\n    span = span.lower()\n    span = span.translate(strip_punctuation)\n    span = whitespace.sub(' ', span)\n    ## trim any leading or trailing whitespace\n    return span.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nalign a chunk with the ner file", "response": "def align_chunk_with_ner(tmp_ner_path, i_chunk, tmp_done_path):\n    '''\n    iterate through the i_chunk and tmp_ner_path to generate a new\n    Chunk with body.ner\n    '''\n    o_chunk = Chunk()\n    input_iter = i_chunk.__iter__()\n    ner = ''\n    stream_id = None\n\n    all_ner = xml.dom.minidom.parse(open(tmp_ner_path))\n\n    for raw_ner in all_ner.getElementsByTagName('FILENAME'):\n        \n        stream_item = input_iter.next()\n        ## get stream_id out of the XML\n        stream_id = raw_ner.attributes.get('docid').value\n        assert stream_id and stream_id == stream_item.stream_id, \\\n            '%s != %s\\nner=%r' % (stream_id, stream_item.stream_id, ner)\n\n        tagger_id = 'lingpipe'\n        tagging = Tagging()\n        tagging.tagger_id = tagger_id\n        ## get this one file out of its FILENAME tags\n        tagged_doc = list(lingpipe.files(raw_ner.toxml()))[0][1]\n        tagging.raw_tagging = tagged_doc\n        tagging.generation_time = streamcorpus.make_stream_time()\n        stream_item.body.taggings[tagger_id] = tagging\n\n        sentences = list(lingpipe.sentences(tagged_doc))\n\n        ## make JS labels on individual tokens\n        assert stream_item.ratings[0].mentions, stream_item.stream_id\n        john_smith_label = Label()\n        john_smith_label.annotator = stream_item.ratings[0].annotator\n        john_smith_label.target_id = stream_item.ratings[0].target_id\n\n        # first map all corefchains to their words\n        equiv_ids = collections.defaultdict(lambda: set())\n        for sent in sentences:\n            for tok in sent.tokens:\n                if tok.entity_type is not None:\n                    equiv_ids[tok.equiv_id].add(cleanse(tok.token))\n\n        ## find all the chains that are John Smith\n        johnsmiths = set()\n        for equiv_id, names in equiv_ids.items():\n            ## detect 'smith' in 'smithye'\n            _names = cleanse(' '.join(names))\n            if 'john' in _names and 'smith' in _names:\n                johnsmiths.add(equiv_id)\n\n        print len(johnsmiths)\n        ## now apply the label\n        for sent in sentences:\n            for tok in sent.tokens:\n                if tok.equiv_id in johnsmiths:\n                    tok.labels = [john_smith_label]                \n\n        stream_item.body.sentences[tagger_id] = sentences\n        \n        o_chunk.add(stream_item)\n\n    ## put the o_chunk bytes into the specified file\n    open(tmp_done_path, 'wb').write(str(o_chunk))\n    ## replace this with log.info()\n    print 'created %s' % tmp_done_path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a config dict with streamcorpus_pipeline as a key find all the keys under the streamcorpus_pipeline that end with _path and convert it to an absolute path using the value provided by root_path", "response": "def make_absolute_paths(config):\n    '''given a config dict with streamcorpus_pipeline as a key, find all\n    keys under streamcorpus_pipeline that end with \"_path\" and if the\n    value of that key is a relative path, convert it to an absolute\n    path using the value provided by root_path\n    '''\n    if not 'streamcorpus_pipeline' in config:\n        logger.critical('bad config: %r', config)\n        raise ConfigurationError('missing \"streamcorpus_pipeline\" from config')\n    ## remove the root_path, so it does not get extended itself\n    root_path = config['streamcorpus_pipeline'].pop('root_path', None)\n    if not root_path:\n        root_path = os.getcwd()\n\n    if not root_path.startswith('/'):\n        root_path = os.path.join( os.getcwd(), root_path )\n\n    def recursive_abs_path( sub_config, root_path ):\n        for key, val in sub_config.items():\n            if isinstance(val, basestring):\n                if key.endswith('path'):\n                    ## ignore URLs in *_path parameters\n                    if re.match('^http.?://', val): continue\n                    ## we have a path... is it already absolute?\n                    if not val.startswith('/'):\n                        ## make the path absolute\n                        sub_config[key] = os.path.join(root_path, val)\n\n            elif isinstance(val, dict):\n                recursive_abs_path( val, root_path )\n\n    recursive_abs_path( config, root_path )\n\n    ## put the root_path back\n    config['root_path'] = root_path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_hash(obj):\n    '''\n    Makes a hash from a dictionary, list, tuple or set to any level,\n    that contains only other hashable types (including any lists,\n    tuples, sets, and dictionaries).  See second answer (not the\n    accepted answer):\n    http://stackoverflow.com/questions/5884066/hashing-a-python-dictionary\n    '''\n    if isinstance(obj, (set, tuple, list)):\n        return tuple([make_hash(e) for e in obj])\n    elif not isinstance(obj, dict):\n        return hash(obj)\n\n    new_obj = copy.deepcopy(obj)\n    for k, v in new_obj.items():\n        ## call self recursively\n        new_obj[k] = make_hash(v)\n\n    return hash(tuple(frozenset(new_obj.items())))", "response": "Makes a hash from a dictionary list tuple or set to any level\n    that contains only other hashable types."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_john_smith_chunk(path_to_original):\n    '''\n    This _looks_ like a Chunk only in that it generates StreamItem\n    instances when iterated upon.\n    '''\n    ## Every StreamItem has a stream_time property.  It usually comes\n    ## from the document creation time.  Here, we assume the JS corpus\n    ## was created at one moment at the end of 1998:\n    creation_time = '1998-12-31T23:59:59.999999Z'\n    correct_time = 915148799\n\n    if not os.path.isabs(path_to_original):\n        path_to_original = os.path.join(os.getcwd(), path_to_original)\n\n    ## iterate over the files in the 35 input directories\n    for label_id in range(35):\n\n        dir_path = os.path.join(path_to_original, str(label_id))\n        fnames = os.listdir(dir_path)\n        fnames.sort()\n        for fname in fnames:\n\n            stream_item = streamcorpus.make_stream_item(\n                creation_time, \n                ## make up an abs_url\n                os.path.join(\n                    'john-smith-corpus', str(label_id), fname))\n\n            if int(stream_item.stream_time.epoch_ticks) != correct_time:\n                raise PipelineBaseException('wrong stream_time construction: %r-->%r != %r'\\\n                                            % (creation_time, stream_item.stream_time.epoch_ticks,\n                                               correct_time))\n\n            ## These docs came from the authors of the paper cited above.\n            stream_item.source = 'bagga-and-baldwin'\n\n            ## build a ContentItem for the body\n            body = streamcorpus.ContentItem()\n            raw_string = open(os.path.join(dir_path, fname)).read()\n            ## We know that this is already clean and has nothing\n            ## tricky in it, because we manually cleansed it.  To\n            ## illustrate how we stick all strings into thrift, we\n            ## convert this to unicode (which introduces no changes)\n            ## and then encode it as utf-8, which also introduces no\n            ## changes.  Thrift stores strings as 8-bit character\n            ## strings.\n            # http://www.mail-archive.com/thrift-user@incubator.apache.org/msg00210.html\n            body.clean_visible = unicode(raw_string).encode('utf8')\n\n            ## attach the content_item to the stream_item\n            stream_item.body = body\n\n            stream_item.body.language = streamcorpus.Language(code='en', name='ENGLISH')\n\n            ## The authors also annotated the corpus\n            anno = streamcorpus.Annotator()\n            anno.annotator_id = 'bagga-and-baldwin'\n            anno.annotation_time = stream_item.stream_time\n\n            ## build a Label for the doc-level label:\n            rating = streamcorpus.Rating()\n            rating.annotator = anno\n            rating.target = streamcorpus.Target(target_id = str(label_id)) # must be string\n            rating.contains_mention = True\n            rating.mentions = ['john', 'smith']\n\n            ## put this one label in the array of labels\n            streamcorpus.add_annotation(stream_item, rating)\n\n            ## provide this stream_item to the pipeline\n            yield stream_item", "response": "This function generates a John SMith Chunk from a file in the John Smod."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntaking an HTML - like binary string as input and returns a binary tree of the same length with all tags replaced by whitespace.", "response": "def re_based_make_clean_visible(html):\n    '''\n    Takes an HTML-like binary string as input and returns a binary\n    string of the same length with all tags replaced by whitespace.\n    This also detects script and style tags, and replaces the text\n    between them with whitespace.\n\n    Pre-existing whitespace of any kind (newlines, tabs) is converted\n    to single spaces ' ', which has the same byte length (and\n    character length).\n\n    Note: this does not change any characters like &rsquo; and &nbsp;,\n    so taggers operating on this text must cope with such symbols.\n    Converting them to some other character would change their byte\n    length, even if equivalent from a character perspective.\n\n    This is regex based, which can occassionally just hang...\n    '''\n    text = ''\n    # Fix emails\n    html = fix_emails(html)\n\n    for m in invisible.finditer(html):\n        text += m.group('before')\n        text += ' ' * len(m.group('invisible'))\n\n    # text better be >= original\n    assert len(html) >= len(text), '%d !>= %d' % (len(html), len(text))\n\n    # capture any characters after the last tag... such as newlines\n    tail = len(html) - len(text)\n    text += html[-tail:]\n\n    # now they must be equal\n    assert len(html) == len(text), '%d != %d' % (len(html), len(text))\n\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking an HTML - like Unicode string as input and returns a UTF - 8 encoded string with all tags replaced by whitespace.", "response": "def make_clean_visible(_html, tag_replacement_char=' '):\n    '''\n    Takes an HTML-like Unicode string as input and returns a UTF-8\n    encoded string with all tags replaced by whitespace. In particular,\n    all Unicode characters inside HTML are replaced with a single\n    whitespace character.\n\n    This does not detect comments, style, script, link.  It also does\n    do anything with HTML-escaped characters.  All of these are\n    handled by the clean_html pre-cursor step.\n\n    Pre-existing whitespace of any kind (newlines, tabs) is converted\n    to single spaces ' ', which has the same byte length (and\n    character length).\n\n    This is a simple state machine iterator without regexes\n    '''\n    def non_tag_chars(html):\n        n = 0\n        while n < len(html):\n            angle = html.find('<', n)\n            if angle == -1:\n                yield html[n:]\n                n = len(html)\n                break\n            yield html[n:angle]\n            n = angle\n\n            while n < len(html):\n                nl = html.find('\\n', n)\n                angle = html.find('>', n)\n                if angle == -1:\n                    yield ' ' * (len(html) - n)\n                    n = len(html)\n                    break\n                elif nl == -1 or angle < nl:\n                    yield ' ' * (angle + 1 - n)\n                    n = angle + 1\n                    break\n                else:\n                    yield ' ' * (nl - n) + '\\n'\n                    n = nl + 1\n                    # do not break\n\n    if not isinstance(_html, unicode):\n        _html = unicode(_html, 'utf-8')\n\n    # Protect emails by substituting with unique key\n    _html = fix_emails(_html)\n\n    #Strip tags with previous logic\n    non_tag = ''.join(non_tag_chars(_html))\n\n    return non_tag.encode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef non_tag_chars_from_raw(html):\n    '''generator that yields clean visible as it transitions through\n    states in the raw `html`\n\n    '''\n    n = 0\n    while n < len(html):\n        # find start of tag\n        angle = html.find('<', n)\n        if angle == -1:\n            yield html[n:]\n            n = len(html)\n            break\n        yield html[n:angle]\n        n = angle\n\n        # find the end of the tag string\n        space = html.find(' ',  n, n + longest_extended_tag + 2)\n        angle = html.find('>',  n, n + longest_extended_tag + 2)\n        nl    = html.find('\\n', n, n + longest_extended_tag + 2)\n        tab   = html.find('\\t', n, n + longest_extended_tag + 2)\n        ends = filter(lambda end: end > -1, [tab, nl, space, angle])\n        if ends:\n            tag = html[n + 1 : min(ends)]\n            if tag == '!--':\n                # whiteout comment except newlines\n                end = html.find('-->', n)\n                while n < end:\n                    nl = html.find('\\n', n, end)\n                    if nl != -1:\n                        yield ' ' * (nl - n) + '\\n'\n                        n = nl + 1\n                    else:\n                        yield ' ' * (end - n + 3)\n                        break\n                n = end + 3\n                continue\n            is_extended = tag.lower() in extended_tags\n        else:\n            is_extended = False\n\n        # find end of tag even if on a lower line\n        while n < len(html):\n            squote = html.find(\"'\", n)\n            dquote = html.find('\"', n)\n            nl = html.find('\\n', n)\n            angle = html.find('>', n)\n            if angle == -1:\n                # hits end of doc before end of tag\n                yield ' ' * (len(html) - n)\n                n = len(html)\n                break\n            elif -1 < squote < angle or -1 < dquote < angle:\n                if squote != -1 and dquote != -1:\n                    if squote < dquote: \n                        open_quote = squote\n                        quote = \"'\"\n                    else:\n                        open_quote = dquote\n                        quote = '\"'\n                elif dquote != -1:\n                    open_quote = dquote\n                    quote = '\"'\n                else:\n                    open_quote = squote\n                    quote = \"'\"\n                close_quote = html.find(quote, open_quote + 1)\n                while n < close_quote:\n                    nl = html.find('\\n', n, close_quote)\n                    if nl == -1: break\n                    yield ' ' * (nl - n) + '\\n'\n                    n = nl + 1\n                yield ' ' * (close_quote + 1 - n)\n                n = close_quote + 1\n                continue\n\n            elif nl == -1 or angle < nl:\n                # found close before either newline or end of doc\n                yield ' ' * (angle + 1 - n)\n                n = angle + 1\n                if is_extended and html[angle - 1] != '/':\n                    # find matching closing tag. JavaScript can\n                    # include HTML *strings* within it, and in\n                    # principle, that HTML could contain a closing\n                    # script tag in it; ignoring for now.\n                    while n < len(html):\n                        nl = html.find('\\n', n)\n                        close = html.find('</', n)\n                        close2 = html.find('</', close + 2)\n                        angle = html.find('>', close + 2)\n                        if nl != -1 and nl < close:\n                            yield ' ' * (nl - n) + '\\n'\n                            n = nl + 1\n                        elif close == -1 or angle == -1:\n                            # end of doc before matching close tag\n                            yield ' ' * (len(html) - n)\n                            n = len(html)\n                            break\n                        elif close2 != -1 and close2 < angle:\n                            # broken tag inside current tag\n                            yield ' ' * (close + 2 - n)\n                            n = close + 2\n                        elif html[close + 2:angle].lower() == tag.lower():\n                            yield ' ' * (angle + 1 - n)\n                            n = angle + 1\n                            break\n                        else:\n                            yield ' ' * (angle + 1 - n)\n                            n = angle + 1\n                            # do not break\n                # finished with tag\n                break\n            else:\n                # found a newline within the current tag\n                yield ' ' * (nl - n) + '\\n'\n                n = nl + 1", "response": "generator that yields clean visible as it transitions through\n    states in the raw html"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking an HTML - like Unicode string as input and returns a Unicode string with all tags replaced by whitespace.", "response": "def make_clean_visible_from_raw(_html, tag_replacement_char=' '):\n    '''Takes an HTML-like Unicode (or UTF-8 encoded) string as input and\n    returns a Unicode string with all tags replaced by whitespace. In\n    particular, all Unicode characters inside HTML are replaced with a\n    single whitespace character.\n\n    This *does* detect comments, style, script, link tags and replaces\n    them with whitespace.  This is subtle because these tags can be\n    self-closing or not.\n\n    It does do anything with HTML-escaped characters.\n\n    Pre-existing whitespace of any kind *except* newlines (\\n) and\n    linefeeds (\\r\\n) is converted to single spaces ' ', which has the\n    same byte length (and character length).  Newlines and linefeeds\n    are left unchanged.\n\n    This is a simple state machine iterator without regexes\n\n    '''\n    if not isinstance(_html, unicode):\n        _html = unicode(_html, 'utf-8')\n\n    #Strip tags with logic above\n    non_tag = ''.join(non_tag_chars_from_raw(_html))\n\n    return non_tag.encode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_clean_visible_file(i_chunk, clean_visible_path):\n    '''make a temp file of clean_visible text'''\n    _clean = open(clean_visible_path, 'wb')\n    _clean.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>')\n    _clean.write('<root>')\n    for idx, si in enumerate(i_chunk):\n        if si.stream_id is None:\n            # create the FILENAME element anyway, so the ordering\n            # remains the same as the i_chunk and can be aligned.\n            stream_id = ''\n        else:\n            stream_id = si.stream_id\n        doc = lxml.etree.Element(\"FILENAME\", stream_id=stream_id)\n        if si.body and si.body.clean_visible:\n            try:\n                # is UTF-8, and etree wants .text to be unicode\n                doc.text = si.body.clean_visible.decode('utf8')\n            except ValueError:\n                doc.text = drop_invalid_and_upper_utf8_chars(\n                    si.body.clean_visible.decode('utf8'))\n            except Exception, exc:\n                # this should never ever fail, because if it does,\n                # then it means that clean_visible (or more likely\n                # clean_html) is not what it is supposed to be.\n                # Therefore, do not take it lightly:\n                logger.critical(traceback.format_exc(exc))\n                logger.critical('failed on stream_id=%s to follow:',\n                                si.stream_id)\n                logger.critical(repr(si.body.clean_visible))\n                logger.critical('above was stream_id=%s', si.stream_id)\n                # [I don't know who calls this, but note that this\n                # will *always* fail if clean_visible isn't valid UTF-8.]\n                raise\n        else:\n            doc.text = ''\n        _clean.write(lxml.etree.tostring(doc, encoding='UTF-8'))\n    _clean.write('</root>')\n    _clean.close()\n    logger.info(clean_visible_path)\n\n    '''\n    ## hack to capture html for inspection\n    _html = open(clean_visible_path + '-html', 'wb')\n    for idx, si in enumerate(i_chunk):\n        _html.write('<FILENAME docid=\"%s\">' % si.stream_id)\n        if si.body and si.body.clean_html:\n            _html.write(si.body.clean_html)\n        _html.write('</FILENAME>\\n')\n    _html.close()\n    ## replace this with log.info()\n    print clean_visible_path + '-html'\n    '''", "response": "make a temp file of clean_visible text"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a unicode string into a lowercase string with no punctuation and only spaces for whitespace.", "response": "def cleanse(span, lower=True):\n    '''Convert a unicode string into a lowercase string with no\npunctuation and only spaces for whitespace.\n\nReplace PennTreebank escaped brackets with ' ':\n-LRB- -RRB- -RSB- -RSB- -LCB- -RCB-\n(The acronyms stand for (Left|Right) (Round|Square|Curly) Bracket.)\nhttp://www.cis.upenn.edu/~treebank/tokenization.html\n\n:param span: string\n    '''\n    assert isinstance(span, unicode), \\\n        'got non-unicode string %r' % span\n    # lowercase, strip punctuation, and shrink all whitespace\n    span = penn_treebank_brackets.sub(' ', span)\n    if lower:\n        span = span.lower()\n    span = span.translate(strip_punctuation)\n    span = whitespace.sub(' ', span)\n    # trim any leading or trailing whitespace\n    return span.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to load a stage into self ignoring errors.", "response": "def tryload_stage(self, moduleName, functionName, name=None):\n        '''Try to load a stage into self, ignoring errors.\n\n        If loading a module fails because of some subordinate load\n        failure, just give a warning and move on.  On success the\n        stage is added to the stage dictionary.\n\n        :param str moduleName: name of the Python module\n        :param str functionName: name of the stage constructor\n        :param str name: name of the stage, defaults to `functionName`\n\n        '''\n        if name is None:\n            name = functionName\n        try:\n            mod = __import__(moduleName, globals(), locals(), [functionName])\n        except ImportError, exc:\n            logger.warn('cannot load stage {0}: cannot load module {1}'\n                        .format(name, moduleName), exc_info=exc)\n            return\n\n        if not hasattr(mod, functionName):\n            logger.warn('cannot load stage {0}: module {1} missing {2}'\n                        .format(name, moduleName, functionName))\n            return\n\n        self[name] = getattr(mod, functionName)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_external_stages(self, path):\n        '''Add external stages from the Python module in `path`.\n\n        `path` must be a path to a Python module source that contains\n        a `Stages` dictionary, which is a map from stage name to callable.\n\n        :param str path: path to the module file\n        '''\n        mod = imp.load_source('', path)\n        self.update(mod.Stages)", "response": "Load external stages from the Python module in path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_module_stages(self, mod):\n        '''Add external stages from the Python module `mod`.\n\n        If `mod` is a string, then it will be interpreted as the name\n        of a module; otherwise it is an actual module object.  The\n        module should exist somewhere in :data:`sys.path`.  The module\n        must contain a `Stages` dictionary, which is a map from stage\n        name to callable.\n\n        :param mod: name of the module or the module itself\n        :raise exceptions.ImportError: if `mod` cannot be loaded or does\n          not contain ``Stages``\n\n        '''\n        if isinstance(mod, basestring):\n            mod = __import__(mod, globals=globals(), locals=locals(),\n                             fromlist=['Stages'], level=0)\n        if not hasattr(mod, 'Stages'):\n            raise ImportError(mod)\n        self.update(mod.Stages)", "response": "Load external stages from the Python module mod."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct and configure a stage from known stages.", "response": "def init_stage(self, name, config):\n\n        '''Construct and configure a stage from known stages.\n\n        `name` must be the name of one of the stages in this.  `config`\n        is the configuration dictionary of the containing object, and its `name`\n        member will be passed into the stage constructor.\n\n        :param str name: name of the stage\n        :param dict config: parent object configuration\n        :return: callable stage\n        :raise exceptions.KeyError: if `name` is not a known stage\n\n        '''\n        subconfig = config.get(name, {})\n        ctor = self[name]\n        return ctor(subconfig)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread from idx_bytes until a byte in stop_bytes or a byte in run_bytes is found.", "response": "def read_to( idx_bytes, stop_bytes=None, run_bytes=None ):\n    '''\n    iterates through idx_bytes until a byte in stop_bytes or a byte\n    not in run_bytes.\n\n    :rtype (int, string): idx of last byte and all of bytes including\n    the terminal byte from stop_bytes or not in run_bytes\n    '''\n    idx = None\n    vals = []\n    next_b = None\n    while 1:\n        try:\n            idx, next_b = idx_bytes.next()\n        except StopIteration:\n            ## maybe something going wrong?\n            idx = None\n            next_b = None\n            break\n        ## stop when we see any byte in stop_bytes\n        if stop_bytes and next_b in stop_bytes:\n            break\n        ## stop when we see any byte not in run_bytes\n        if run_bytes and next_b not in run_bytes:\n            break\n        ## assemble the ret_val\n        vals.append( next_b )\n\n    ## return whatever we have assembled\n    return idx, b''.join(vals), next_b"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef iter_attrs( idx_bytes ):\n    '''\n    called when idx_chars is just past \"<a \" inside an HTML anchor tag\n    \n    generates tuple(end_idx, attr_name, attr_value)\n    '''\n    ## read to the end of the \"A\" tag\n    while 1:\n        idx, attr_name, next_b = read_to(idx_bytes, ['=', '>'])\n        attr_vals = []\n\n        ## stop if we hit the end of the tag, or end of idx_bytes\n        if next_b is None or next_b == '>':\n            return\n        \n        idx, space, quote = read_to(idx_bytes, run_bytes = [' ', '\\t', '\\n', '\\r'])\n        if quote not in ['\"', \"'\"]:\n            ## caught start of the property value\n            attr_vals = [quote]\n            quote = ' '\n        \n        idx, attr_val, next_b = read_to(idx_bytes, [quote, '>'])\n        ## next_b had better either balance the start quote, end the\n        ## tag, or end idx_bytes\n        assert next_b in [quote, '>', None], attr_val\n        attr_vals.append( attr_val )\n\n        yield idx, attr_name.strip(), b''.join(attr_vals).strip()", "response": "Iterate over the attributes of the tag tree."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef href_filter(self, href):\n        '''\n        Test whether an href string meets criteria specified by\n        configuration parameters 'require_abs_url', which means \"does\n        it look like it is probably an absolute URL?\" and\n        'domain_substrings'.  It searches for each of the\n        domain_substrings in the href individually, and if any match,\n        then returns True.\n\n        :param: href string\n        :returns bool:\n        '''\n        if self.config['require_abs_url']:\n            if not href.lower().startswith(('http://', 'https://')):\n                return False\n        if self.config['all_domains']:\n            ## blanket accept all domains as labels\n            return True\n\n        if self.config['domain_substrings']:\n            parts = href.split('/')\n            if len(parts) < 3:\n                return False\n            domain = parts[2].lower()\n            for substring in self.config['domain_substrings']:\n                try:\n                    if substring in domain:\n                        return True\n                except Exception, exc:\n                    logger.warn('%r in %r raised', substring, domain, exc_info=True)\n                    return False", "response": "Test whether an href string meets criteria specified by the configuration parameters require_abs_url which means it is probably an absolute URL? and domain_substrings."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef line_href_anchors(self):\n        '''\n        simple, regex-based extractor of anchor tags, so we can\n        compute LINE offsets for anchor texts and associate them with\n        their href.\n        \n        Generates tuple(href_string, first_byte, byte_length, anchor_text)\n\n        Also, this mangles the body.clean_html so that LINE offsets\n        uniquely identify tokens in anchor tags -- quite a kludge.\n        '''\n        idx = 0\n        new_clean_html = ''\n        newlines_added = 0\n        ## split doc up into pieces that end on an anchor tag\n        parts = self.clean_html.split('</a>')\n        assert len('</a>'.join(parts) ) == len(self.clean_html)\n        for i in range(len(parts)):\n            part = parts[i]\n\n            ## try to get an A tag out:\n            m = anchors_re.match(part)\n\n            ## if not, then just keep going\n            if not m:\n                new_clean_html += part\n                if i < len(parts) - 1:\n                    new_clean_html += '</a>'\n                continue\n\n            before = m.group('before')\n            ahref = m.group('ahref')\n\n            ## construct a text containing bytes up to the anchor text\n            pre_anchor_increment = before + ahref\n\n            ## increment the index to get line number for the anchor\n            idx += len( pre_anchor_increment.splitlines() )\n            first = idx\n\n            ## usually this will be one, but it could be more than\n            ## that when an anchor text contains newlines\n            length = len(m.group('anchor').split('\\n'))\n\n            ## construct new clean_html with these newlines inserted\n            new_clean_html += pre_anchor_increment + '\\n' + m.group('anchor') + '\\n</a>'\n\n            newlines_added += 2\n\n            ## update the index for the next loop\n            idx += length - 1\n\n            yield m.group('href'), first, length, m.group('anchor')\n\n        ## replace clean_html with our new one that has newlines inserted\n        assert len(self.clean_html) == len(new_clean_html) - newlines_added\n        self.clean_html = new_clean_html", "response": "Generate a generator that yields the line - href - text pairs for anchor tags."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef byte_href_anchors(self, chars=False):\n        '''\n        simple, regex-based extractor of anchor tags, so we can\n        compute BYTE offsets for anchor texts and associate them with\n        their href.\n        \n        Generates tuple(href_string, first_byte, byte_length, anchor_text)\n        '''\n        input_buffer = self.clean_html\n        if chars:\n            input_buffer = input_buffer.decode('utf8')\n        idx = 0\n        ## split doc up into pieces that end on an anchor tag\n        parts = input_buffer.split('</a>')\n        assert len('</a>'.join(parts) ) == len(input_buffer)\n        for part in parts:\n            ## try to get an A tag out:\n            m = anchors_re.match(part)\n\n            if not m:\n                idx += len(part) + 4\n                continue\n\n            before = m.group('before')\n            ahref = m.group('ahref')\n\n            ## increment the index to get line number for the anchor\n            idx += len(before) + len(ahref)\n            first = idx\n\n            length = len(m.group('anchor'))\n\n            ## update the index for the next loop\n            # include anchor plus the </a>\n            idx += length + 4\n\n            if chars:\n                yield m.group('href').encode('utf8'), first, length, m.group('anchor').encode('utf8')\n            else:\n                yield m.group('href'), first, length, m.group('anchor')\n\n        assert idx - 4 == len(input_buffer)", "response": "Generate a generator that yields the href_string first_byte length and anchor_text for each anchor tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_labels(self, clean_html, clean_visible=None):\n        '''\n        Make a list of Labels for 'author' and the filtered hrefs &\n        anchors\n        '''\n        if   self.offset_type == OffsetType.BYTES:\n            parser = self.byte_href_anchors\n\n        elif self.offset_type == OffsetType.CHARS:\n            parser = self.char_href_anchors\n\n        elif self.offset_type == OffsetType.LINES:\n            parser = self.line_href_anchors\n\n        labels = []\n        ## make clean_html accessible as a class property so we can \n        self.clean_html = clean_html\n        for href, first, length, value in parser():\n            if self.href_filter(href):\n                '''\n                if clean_visible:\n                    _check_html = self.clean_html.splitlines()[first-10:10+first+length]\n                    _check_visi =   clean_visible.splitlines()[first:first+length]\n                    if not make_clean_visible(_check_html) == _check_visi:\n                        print len(self.clean_html.splitlines())\n                        print len(clean_visible.splitlines())\n\n                        print href\n                        print '\\t html: %r' % _check_html\n                        print '\\t visi: %r' % _check_visi\n                '''\n                ## add a label for every href\n                label = Label(\n                    annotator = Annotator(annotator_id = 'author'),\n                    target = Target(target_id = href),\n                    )\n                ## the offset type is specified by the config\n                label.offsets[self.offset_type] = Offset(\n                    first=first, length=length, \n                    value=value,\n                    ## the string name of the content field, not the\n                    ## content itself :-)\n                    content_form='clean_html')\n                labels.append(label)\n\n        return labels", "response": "Make a list of Labels for author and the filtered hrefs & Anchors."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef paths(input_dir):\n    'yield all file paths under input_dir'\n    for root, dirs, fnames in os.walk(input_dir):\n        for i_fname in fnames:\n            i_path = os.path.join(root, i_fname)\n            yield i_path", "response": "yield all file paths under input_dir"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a column family of the given name and sets any of the bytes_columns to have the BYTES_TYPE.", "response": "def _create_column_family(self, family, bytes_columns=[], \n                              key_validation_class=TIME_UUID_TYPE):\n        '''\n        Creates a column family of the name 'family' and sets any of\n        the names in the bytes_column list to have the BYTES_TYPE.\n\n        key_validation_class defaults to TIME_UUID_TYPE and could also\n        be ASCII_TYPE for md5 hash keys, like we use for 'inbound'\n        '''\n        sm = SystemManager(random.choice(self.server_list))\n        # sys.create_column_family(self.namespace, family, super=False)\n        sm.create_column_family(self.namespace, family, super=False,\n                key_validation_class = key_validation_class, \n                default_validation_class  = TIME_UUID_TYPE,\n                column_name_class = ASCII_TYPE)\n        for column in bytes_columns:\n            sm.alter_column(self.namespace, family, column, BYTES_TYPE)\n        sm.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_counter_column_family(self, family, counter_columns=[],\n                              key_validation_class=UTF8Type):\n        '''\n        Creates a column family of the name 'family' and sets any of\n        the names in the bytes_column list to have the BYTES_TYPE.\n\n        key_validation_class defaults to TIME_UUID_TYPE and could also\n        be ASCII_TYPE for md5 hash keys, like we use for 'inbound'\n        '''\n        sm = SystemManager(random.choice(self.server_list))\n        # sys.create_column_family(self.namespace, family, super=False)\n        sm.create_column_family(self.namespace, family, super=False,\n                key_validation_class = key_validation_class, \n                default_validation_class=\"CounterColumnType\",\n                column_name_class = ASCII_TYPE)\n        for column in counter_columns:\n            sm.alter_column(self.namespace, family, column, COUNTER_COLUMN_TYPE)\n        sm.close()", "response": "Creates a column family of the given name family and sets any of the bytes_column list to have the BYTES_TYPE."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating the data objects for every task in the table", "response": "def tasks(self, key_prefix=''):\n        '''\n        generate the data objects for every task\n        '''\n        for row in self._tasks.get_range():\n            logger.debug(row)\n            if not row[0].startswith(key_prefix):\n                continue\n            data = json.loads(row[1]['task_data'])\n            data['task_key'] = row[0]\n            yield data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a random key out of the first max_iter rows", "response": "def get_random_available(self, max_iter=10000):\n        '''\n        get a random key out of the first max_iter rows\n        '''\n        c = 1\n        keeper = None\n        ## note the ConsistencyLevel here.  If we do not do this, and\n        ## get all slick with things like column_count=0 and filter\n        ## empty False, then we can get keys that were recently\n        ## deleted... EVEN if the default consistency would seem to\n        ## rule that out!\n\n        ## note the random start key, so that we do not always hit the\n        ## same place in the key range with all workers\n        #random_key = hashlib.md5(str(random.random())).hexdigest()\n        #random_key = '0' * 32\n        #logger.debug('available.get_range(%r)' % random_key)\n        ## scratch that idea: turns out that using a random start key\n        ## OR using row_count=1 can cause get_range to hang for hours\n\n        ## why we need ConsistencyLevel.ALL on a single node is not\n        ## clear, but experience indicates it is needed.\n\n        ## note that putting a finite row_count is problematic in two\n        ## ways:\n        # 1) if there are more workers than max_iter, some will not\n        # get tasks\n        #\n        # 2) if there are more than max_iter records, then all workers\n        # have to wade through all of these just to get a task!  What\n        # we really want is a \"pick random row\" function, and that is\n        # probably best implemented using CQL3 token function via the\n        # cql python module instead of pycassa...\n        for row in self._available.get_range(row_count=max_iter, read_consistency_level=pycassa.ConsistencyLevel.ALL):\n        #for row in self._available.get_range(row_count=100):\n            logger.debug('considering %r' % (row,))\n            if random.random() < 1 / c:\n                keeper = row[0]\n            if c == max_iter:\n                break\n            c += 1\n        return keeper"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef files(text):\n    '''\n    Iterate over <FILENAME> XML-like tags and tokenize with nltk\n    '''\n    for f_match in filename_re.finditer(text):\n        yield f_match.group('stream_id'), f_match.group('tagged_doc')", "response": "Iterate over FILENAME tags and tokenize with nltk\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sentences(self):\n        '''\n        Iterate over <s> XML-like tags and tokenize with nltk\n        '''\n        for sentence_id, node in enumerate(self.ner_dom.childNodes):\n            ## increment the char index with any text before the <s>\n            ## tag.  Crucial assumption here is that the LingPipe XML\n            ## tags are inserted into the original byte array without\n            ## modifying the portions that are not inside the\n            ## LingPipe-added tags themselves.\n            if node.nodeType == node.TEXT_NODE:\n                ## we expect to only see TEXT_NODE instances with whitespace\n                assert only_whitespace.match(node.data), repr(node.data)\n\n                ## must convert back to utf-8 to have expected byte offsets\n                self.byte_idx += len(node.data.encode('utf-8'))\n\n                ## count full lines, i.e. only those that end with a \\n\n                # 'True' here means keep the trailing newlines\n                for line in node.data.splitlines(True):\n                    if line.endswith('\\n'):\n                        self.line_idx += 1\n            else:\n                logger.debug('getting tokens for sentence_id=%d' % sentence_id)\n                more_sentence_remains = True\n                while more_sentence_remains:\n                    ## always a sentence\n                    sent = Sentence()\n\n                    ## this \"node\" came from for loop above, and it's\n                    ## childNodes list might have been popped by a\n                    ## previous pass through this while loop\n                    tokens = iter( self.tokens( node ) )\n\n                    while 1:\n                        try:\n                            tok = tokens.next()\n                            sent.tokens.append(tok)\n                            #logger.debug('got token: %r  %d %d' % (tok.token, tok.mention_id, tok.sentence_pos))\n\n                        except StopIteration:\n                            yield sent\n                            more_sentence_remains = False\n                            break", "response": "Iterate over XML - like tags and tokenize with nltk\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_token(self, start, end):\n        '''\n        Instantiates a Token from self._input_string[start:end]\n        '''\n        ## all thfift strings must be encoded first\n        tok_string = self._input_string[start:end].encode('utf-8')\n        if only_whitespace.match(tok_string):\n            ## drop any tokens with only whitespace\n            return None\n        tok = Token()\n        tok.token = tok_string\n        tok.token_num = self.tok_num\n        if 'BYTES' in self.config['offset_types']:\n            tok.offsets[OffsetType.BYTES] = Offset(\n                type =  OffsetType.BYTES,\n                first=self.byte_idx + len(self._input_string[:start].encode('utf-8')),\n                length=len(tok_string),\n                value=self.config['offset_debugging'] and tok_string or None,\n                )\n        if 'LINES' in self.config['offset_types']:\n            tok.offsets[OffsetType.LINES] = Offset(\n                type =  OffsetType.LINES,\n                first=self.line_idx,\n                length=1,\n                value=self.config['offset_debugging'] and tok_string or None,\n                )\n        self.tok_num += 1\n        ## keep track of position within a sentence\n        tok.sentence_pos = self.sent_pos\n        self.sent_pos += 1\n        return tok", "response": "Makes a Token from self. _input_string [ start end )."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tokens(self, sentence_dom):\n        '''\n        Tokenize all the words and preserve NER labels from ENAMEX tags\n        '''\n        ## keep track of sentence position, which is reset for each\n        ## sentence, and used above in _make_token\n        self.sent_pos = 0\n    \n        ## keep track of mention_id, so we can distinguish adjacent\n        ## multi-token mentions within the same coref chain\n        mention_id = 0\n\n        while len(sentence_dom.childNodes) > 0:\n            ## shrink the sentence_dom's child nodes.  In v0_2_0 this\n            ## was required to cope with HitMaxi16.  Now it is just to\n            ## save memory.\n            node = sentence_dom.childNodes.pop(0)\n\n            if node.nodeType == node.TEXT_NODE:\n                ## process portion before an ENAMEX tag\n                for line in node.data.splitlines(True):\n                    self._input_string = line\n                    for start, end in self.word_tokenizer.span_tokenize(line):\n                        tok = self._make_token(start, end)\n                        if tok:\n                            yield tok\n\n                    if line.endswith('\\n'):\n                        ## maintain the index to the current line\n                        self.line_idx += 1\n\n                    ## increment index pasat the 'before' portion\n                    self.byte_idx += len(line.encode('utf-8'))\n\n            else:\n                ## process text inside an ENAMEX tag\n                assert node.nodeName == 'ENAMEX', node.nodeName\n                chain_id = node.attributes.get('ID').value\n                entity_type = node.attributes.get('TYPE').value\n                for node in node.childNodes:\n                    assert node.nodeType == node.TEXT_NODE, node.nodeType\n                    for line in node.data.splitlines(True):\n                        self._input_string = line\n                        for start, end in self.word_tokenizer.span_tokenize(line):\n                            tok = self._make_token(start, end)\n                            if tok:\n                                if entity_type in _PRONOUNS:\n                                    tok.mention_type = MentionType.PRO\n                                    tok.entity_type = _ENTITY_TYPES[entity_type]\n                                    \n                                    ## create an attribute\n                                    attr = Attribute(\n                                        attribute_type=AttributeType.PER_GENDER,\n                                        value=str(_PRONOUNS[entity_type])\n                                        )\n                                    self.attributes.append(attr)\n\n                                else:\n                                    ## regular entity_type\n                                    tok.mention_type = MentionType.NAME\n                                    tok.entity_type = _ENTITY_TYPES[entity_type]\n\n                                tok.equiv_id = int(chain_id)\n                                tok.mention_id = mention_id\n                                yield tok\n\n                        if line.endswith('\\n'):\n                            ## maintain the index to the current line\n                            self.line_idx += 1\n\n                        ## increment index pasat the 'before' portion\n                        self.byte_idx += len(line.encode('utf-8'))\n\n                ## increment mention_id within this sentence\n                mention_id += 1", "response": "Tokenize all the words and preserve NER labels from ENAMEX tags and yield tokens."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_sentences(self, ner_dom):\n        '''parse the sentences and tokens out of the XML'''\n        lp_parser = LingPipeParser(self.config)\n        lp_parser.set(ner_dom)\n        sentences = list( lp_parser.sentences() )\n        return sentences, lp_parser.relations, lp_parser.attributes", "response": "parse the sentences and tokens out of the XML"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef recursive_glob_with_tree(new_base, old_base, treeroot, pattern):\n    '''generate a list of tuples(new_base, list(paths to put there)\n    where the files are found inside of old_base/treeroot.\n    '''\n    results = []\n    old_cwd = os.getcwd()\n    os.chdir(old_base)\n    for rel_base, dirs, files in os.walk(treeroot):\n        goodfiles = fnmatch.filter(files, pattern)\n        one_dir_results = []\n        for f in goodfiles:\n            one_dir_results.append(os.path.join(old_base, rel_base, f))\n        results.append((os.path.join(new_base, rel_base), one_dir_results))\n    os.chdir(old_cwd)\n    return results", "response": "recursive_glob_with_tree - recursively finds all files in treeroot and returns a list of tuples new_base list ( paths to put there )\n    where the files are found inside of old_base."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _retry(func):\n    '''\n    Decorator for methods that need many retries, because of\n    intermittent failures, such as AWS calls via boto, which has a\n    non-back-off retry.\n    '''\n    def retry_func(self, *args, **kwargs):\n        tries = 1\n        while True:\n            # If a handler allows execution to continue, then\n            # fall through and do a back-off retry.\n            try:\n                return func(self, *args, **kwargs)\n                break\n            except OSError as exc:\n                ## OSError: [Errno 24] Too many open files\n                logger.error('assuming OSError unrecoverable')\n                raise\n            except FailedExtraction as exc:\n                ## pass through exc to caller\n                logger.error('FAIL(%d)', tries, exc_info=True)\n                raise\n            except FailedVerification as exc:\n                logger.warn('FAIL(%d)', tries, exc_info=True)\n                if tries >= self.config['tries']:\n                    if self.config.get('suppress_failures'):\n                        logger.warn('suppressing failure and breaking out of this loop; data may be corrupt, downstream will have to cope')\n                        break\n                    else:\n                        raise\n            except Exception as exc:\n                logger.warn('FAIL(%d): having I/O trouble with S3', tries, exc_info=True)\n                if tries >= self.config['tries']:\n                    raise\n\n            logger.warn('RETRYING (%d left)', self.config['tries'] - tries)\n            time.sleep(3 * tries)\n            tries += 1\n\n    return retry_func", "response": "Decorator for methods that need many retries."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if okay raise Exception if not", "response": "def verify_md5(md5_expected, data, other_errors=None):\n    \"return True if okay, raise Exception if not\"  # O_o ?\n    md5_recv = hashlib.md5(data).hexdigest()\n    if md5_expected != md5_recv:\n        if other_errors is not None:\n            logger.critical('\\n'.join(other_errors))\n        raise FailedVerification('original md5 = %r != %r = received md5' \\\n                                 % (md5_expected, md5_recv))\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_bucket(config, bucket_name=None):\n    '''This function is mostly about managing configuration, and then\n    finally returns a boto.Bucket object.\n\n    AWS credentials come first from config keys\n    aws_access_key_id_path, aws_secret_access_key_path (paths to one\n    line files); secondly from environment variables\n    AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY; also from $HOME/.aws/credentials\n    or the magic Amazon http://169.254.169.254/ service.  If credentials\n    are not set in the config then behavior is the same as other AWS-based\n    command-line tools.\n\n    '''\n    if not bucket_name:\n        if 'bucket' not in config:\n            raise ConfigurationError(\n                'The \"bucket\" parameter is required for the s3 stages.')\n        bucket_name = config['bucket']\n\n    # get AWS credentials. first, from config; else, from env vars.\n    # (boto will read environment variables and other normal places.)\n    aws_access_key_id_path = config.get('aws_access_key_id_path')\n    aws_secret_access_key_path = config.get('aws_secret_access_key_path')\n\n    params = ()\n    if aws_access_key_id_path and aws_secret_access_key_path:\n        try:\n            access = open(aws_access_key_id_path).read().strip()\n            secret = open(aws_secret_access_key_path).read().strip()\n            params = (access, secret)\n        except:\n            logger.error('failed reading aws credentials from configured file', exc_info=True)\n            raise\n\n    conn = S3Connection(*params)\n    bucket = conn.get_bucket(bucket_name)\n    return bucket", "response": "This function is mostly about managing configuration and then returns a boto. Bucket object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _decode(self, data):\n        '''\n        Given the raw data from s3, return a generator for the items\n        contained in that data. A generator is necessary to support\n        chunk files, but non-chunk files can be provided by a generator\n        that yields exactly one item.\n\n        Decoding works by case analysis on the config option\n        ``input_format``. If an invalid ``input_format`` is given, then\n        a ``ConfigurationError`` is raised.\n        '''\n        informat = self.config['input_format'].lower()\n        if informat == 'spinn3r':\n            return _generate_stream_items(data)\n        elif informat == 'streamitem':\n            ver = self.config['streamcorpus_version']\n            if ver not in _message_versions:\n                raise ConfigurationError(\n                    'Not a valid streamcorpus version: %s '\n                    '(choose from: %s)'\n                    % (ver, ', '.join(_message_versions.keys())))\n\n            message = _message_versions[ver]\n            return streamcorpus.Chunk(data=data, message=message)\n        elif informat == 'featurecollection' and FCChunk is not None:\n            return FCChunk(data=data)\n        else:\n            raise ConfigurationError(\n                'from_s3_chunks unknown input_format = %r'\n                % informat)", "response": "Decode the raw data from s3 into a generator for the items\n        contained in that data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_chunk(self, bucket_name, key_path):\n        '''return Chunk object full of records\n        bucket_name may be None'''\n        bucket = get_bucket(self.config, bucket_name=bucket_name)\n        key = bucket.get_key(key_path)\n        if key is None:\n            raise FailedExtraction('Key \"%s\" does not exist.' % key_path)\n\n        fh = StringIO()\n        key.get_contents_to_file(fh)\n        data = fh.getvalue()\n        if not data:\n            raise FailedExtraction('%s: no data (does the key exist?)'\n                                   % key.key)\n\n        chunk_type, compression, encryption = parse_file_extensions(key_path)\n        if encryption == 'gpg':\n            if not self.gpg_decryption_key_path:\n                raise FailedExtraction('%s ends with \".gpg\" but gpg_decryption_key_path=%s'\n                                       % (key.key, self.gpg_decryption_key_path))\n\n        _errors = []\n        if compression or encryption:\n            _errors, data = decrypt_and_uncompress(\n                data, \n                self.gpg_decryption_key_path,\n                tmp_dir=self.config.get('tmp_dir_path'),\n                compression=compression,\n                )\n            if not data:\n                msg = 'decrypt_and_uncompress got no data for {0!r}, from {1} bytes' \\\n                    + ' downloaded, errors: {2}' \\\n                        .format(key_path, len(data), '\\n'.join(_errors))\n                logger.error(msg)\n                raise FailedExtraction(msg)\n            logger.info( '\\n'.join(_errors) )\n\n        if not self.config['compare_md5_in_file_name']:\n            logger.warn('not checking md5 in file name, consider setting '\n                        'from_s3_chunks:compare_md5_in_file_name')\n        else:\n            logger.info('Verifying md5 for \"%s\"...' % key.key)\n\n            # The regex hammer.\n            m = re.search('([a-z0-9]{32})(?:\\.|$)', key.key)\n            if m is None:\n                raise FailedExtraction(\n                    'Could not extract md5 from key \"%s\". '\n                    'Perhaps you should disable compare_md5_in_file_name?'\n                    % key.key)\n\n            i_content_md5 = m.group(1)\n            #import pdb; pdb.set_trace()\n            verify_md5(i_content_md5, data, other_errors=_errors)\n        return self._decode(data)", "response": "return a Chunk object full of records"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stream_id_to_kvlayer_key(stream_id):\n    '''Convert a text stream ID to a kvlayer key.\n\n    The return tuple can be used directly as a key in the\n    :data:`STREAM_ITEMS_TABLE` table.\n\n    :param str stream_id: stream ID to convert\n    :return: :mod:`kvlayer` key tuple\n    :raise exceptions.KeyError: if `stream_id` is malformed\n\n    '''\n    # Reminder: stream_id is 1234567890-123456789abcdef...0\n    # where the first part is the (decimal) epoch_ticks and the second\n    # part is the (hex) doc_id\n    parts = stream_id.split('-')\n    if len(parts) != 2:\n        raise KeyError('invalid stream_id ' + stream_id)\n    epoch_ticks_s = parts[0]\n    doc_id_s = parts[1]\n    if not epoch_ticks_s.isdigit():\n        raise KeyError('invalid stream_id ' + stream_id)\n    if doc_id_s.lstrip(string.hexdigits) != '':\n        raise KeyError('invalid stream_id ' + stream_id)\n    return (base64.b16decode(doc_id_s.upper()), int(epoch_ticks_s))", "response": "Convert a text stream ID to a kvlayer key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef kvlayer_key_to_stream_id(k):\n    '''Convert a kvlayer key to a text stream ID.\n\n    `k` should be of the same form produced by\n    :func:`stream_id_to_kvlayer_key`.\n\n    :param k: :mod:`kvlayer` key tuple\n    :return: converted stream ID\n    :returntype str:\n\n    '''\n    abs_url_hash, epoch_ticks = k\n    return '{0}-{1}'.format(epoch_ticks,\n                            base64.b16encode(abs_url_hash).lower())", "response": "Convert a kvlayer key to a text stream ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef key_for_stream_item(si):\n    '''Get a kvlayer key from a stream item.\n\n    The return tuple can be used directly as a key in the\n    :data:`STREAM_ITEMS_TABLE` table.  Note that this recalculates the\n    stream ID, and if the internal data on the stream item is inconsistent\n    then this could return a different result from\n    :func:`stream_id_to_kvlayer_key`.\n\n    :param si: stream item to get key for\n    :return: :mod:`kvlayer` key tuple\n\n    '''\n    # get binary 16 byte digest\n    urlhash = hashlib.md5(si.abs_url).digest()\n    return (urlhash, int(si.stream_time.epoch_ticks))", "response": "Get a kvlayer key from a stream item."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserving up some ponies.", "response": "def main(argv=sys.argv):\n    args = parse(argv)\n    \"\"\"Serve up some ponies.\"\"\"\n    hostname = args.listen\n    port = args.port\n    print(\n        \"Making all your dreams for a pony come true on http://{0}:{1}.\\n\"\n        \"Press Ctrl+C to quit.\\n\".format(hostname, port))\n\n    # Hush, werkzeug.\n    logging.getLogger('werkzeug').setLevel(logging.CRITICAL)\n\n    plugin_manager.load_installed_plugins()\n    app = make_app()\n    run_simple(hostname, port, app)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds the parser that will have all available commands and options.", "response": "def build_parser():\n    \"\"\"Build the parser that will have all available commands and options.\"\"\"\n    description = (\n        'HTTPony (pronounced aych-tee-tee-pony) is a simple HTTP '\n        'server that pretty prints HTTP requests to a terminal. It '\n        'is a useful aide for developing clients that send HTTP '\n        'requests. HTTPony acts as a sink for a client so that a '\n        'developer can understand what the client is sending.')\n    parser = argparse.ArgumentParser(description=description)\n    parser.add_argument(\n        '-l', '--listen', help='set the IP address or hostname',\n        default='localhost')\n    parser.add_argument(\n        '-p', '--port', help='set the port', default=8000, type=int)\n\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts stream item sentences to character tokens.", "response": "def sentences_to_char_tokens(si_sentences):\n    '''Convert stream item sentences to character ``Offset``s.'''\n    for sentence in si_sentences:\n        for token in sentence.tokens:\n            if OffsetType.CHARS in token.offsets:\n                yield token"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts character Offsets to character ranges.", "response": "def char_tokens_to_char_offsets(si_tokens):\n    '''Convert character ``Offset``s to character ranges.'''\n    for token in si_tokens:\n        offset = token.offsets[OffsetType.CHARS]\n        yield offset.first, offset.first + offset.length"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert HTML and a sequence of char offsets to xpath offsets.", "response": "def char_offsets_to_xpaths(html, char_offsets):\n    '''Converts HTML and a sequence of char offsets to xpath offsets.\n\n    Returns a generator of :class:`streamcorpus.XpathRange` objects\n    in correspondences with the sequence of ``char_offsets`` given.\n    Namely, each ``XpathRange`` should address precisely the same text\n    as that ``char_offsets`` (sans the HTML).\n\n    Depending on how ``char_offsets`` was tokenized, it's possible that\n    some tokens cannot have their xpaths generated reliably. In this\n    case, a ``None`` value is yielded instead of a ``XpathRange``.\n\n    ``char_offsets`` must be a sorted and non-overlapping sequence of\n    character ranges. They do not have to be contiguous.\n    '''\n    html = uni(html)\n    parser = XpathTextCollector()\n    prev_end = 0\n    prev_progress = True\n    for start, end in char_offsets:\n        if start == end:\n            # Zero length tokens shall have no quarter!\n            # Note that this is a special case. If we let zero-length tokens\n            # be handled normally, then it will be recorded as if the parser\n            # did not make any progress. But of course, there is no progress\n            # to be had!\n            yield None\n            continue\n        # If we didn't make any progress on the previous token, then we'll\n        # need to try and make progress before we can start tracking offsets\n        # again. Otherwise the parser will report incorrect offset info.\n        #\n        # (The parser can fail to make progress when tokens are split at\n        # weird boundaries, e.g., `&amp` followed by `;`. The parser won't\n        # make progress after `&amp` but will once `;` is given.)\n        #\n        # Here, we feed the parser one character at a time between where the\n        # last token ended and where the next token will start. In most cases,\n        # this will be enough to nudge the parser along. Once done, we can pick\n        # up where we left off and start handing out offsets again.\n        #\n        # If this still doesn't let us make progress, then we'll have to skip\n        # this token too.\n        if not prev_progress:\n            for i in xrange(prev_end, start):\n                parser.feed(html[i])\n                prev_end += 1\n                if parser.made_progress:\n                    break\n            if not parser.made_progress:\n                yield None\n                continue\n        # Hand the parser everything from the end of the last token to the\n        # start of this one. Then ask for the Xpath, which should be at the\n        # start of `char_offsets`.\n        if prev_end < start:\n            parser.feed(html[prev_end:start])\n            if not parser.made_progress:\n                parser.feed(html[start:end])\n                prev_progress = parser.made_progress\n                prev_end = end\n                yield None\n                continue\n        xstart = parser.xpath_offset()\n        # print('START', xstart)\n        # Hand it the actual token and ask for the ending offset.\n        parser.feed(html[start:end])\n        xend = parser.xpath_offset()\n        # print('END', xend)\n        prev_end = end\n\n        # If we couldn't make progress then the xpaths generated are probably\n        # incorrect. (If the parser doesn't make progress, then we can't rely\n        # on the callbacks to have been called, which means we may not have\n        # captured all state correctly.)\n        #\n        # Therefore, we simply give up and claim this token is not addressable.\n        if not parser.made_progress:\n            prev_progress = False\n            yield None\n        else:\n            prev_progress = True\n            yield XpathRange(xstart[0], xstart[1], xend[0], xend[1])\n    parser.feed(html[prev_end:])\n    parser.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stream_item_roundtrip_xpaths(si, quick=False):\n    '''Roundtrip all Xpath offsets in the given stream item.\n\n    For every token that has both ``CHARS`` and ``XPATH_CHARS``\n    offsets, slice the ``clean_html`` with the ``XPATH_CHARS`` offset\n    and check that it matches slicing ``clean_visible`` with the\n    ``CHARS`` offset.\n\n    If this passes without triggering an assertion, then we're\n    guaranteed that all ``XPATH_CHARS`` offsets in the stream item are\n    correct. (Note that does not check for completeness. On occasion, a\n    token's ``XPATH_CHARS`` offset cannot be computed.)\n\n    There is copious debugging output to help make potential bugs\n    easier to track down.\n\n    This is used in tests in addition to the actual transform. It's\n    expensive to run, but not running it means silent and hard to\n    debug bugs.\n    '''\n    def debug(s):\n        logger.warning(s)\n\n    def print_window(token, size=200):\n        coffset = token.offsets[OffsetType.CHARS]\n        start = max(0, coffset.first - size)\n        end = min(len(html), coffset.first + coffset.length + size)\n        debug('-' * 49)\n        debug(coffset)\n        debug('window size: %d' % size)\n        debug(html[start:end])\n        debug('-' * 49)\n\n    def debug_all(token, xprange, expected, err=None, got=None):\n        debug('-' * 79)\n        if err is not None:\n            debug(err)\n        debug(xprange)\n        debug('expected: \"%s\"' % expected)\n        if got is not None:\n            debug('got: \"%s\"' % got)\n        debug('token value: \"%s\"' % unicode(token.token, 'utf-8'))\n        print_window(token, size=10)\n        print_window(token, size=30)\n        print_window(token, size=100)\n        print_window(token, size=200)\n        debug('-' * 79)\n\n    def slice_clean_visible(token):\n        coffset = token.offsets[OffsetType.CHARS]\n        return cleanvis[coffset.first:coffset.first + coffset.length]\n\n    def test_token(token):\n        coffset = token.offsets.get(OffsetType.CHARS)\n        if coffset is None:\n            return False\n        xoffset = token.offsets.get(OffsetType.XPATH_CHARS)\n        if xoffset is None:\n            return False\n        crange = (coffset.first, coffset.first + coffset.length)\n        xprange = XpathRange.from_offset(xoffset)\n        expected = slice_clean_visible(token)\n        if expected != unicode(token.token, 'utf-8'):\n            # Yeah, apparently this can happen. Maybe it's a bug\n            # in Basis? I'm trying to hustle, and this only happens\n            # in two instances for the `random` document, so I'm not\n            # going to try to reproduce a minimal counter-example.\n            # ---AG\n            return False\n        try:\n            got = xprange.slice_node(html_root)\n        except InvalidXpathError as err:\n            debug_all(token, xprange, expected, err=err)\n            raise XpathMismatchError(html, cleanvis, xprange, crange)\n        if expected != got:\n            debug_all(token, xprange, expected, got=got)\n            raise XpathMismatchError(html, cleanvis, xprange, crange)\n        return True\n\n    cleanvis = unicode(si.body.clean_visible, 'utf-8')\n    html = unicode(si.body.clean_html, 'utf-8')\n    html_root = XpathRange.html_node(html)\n    total, has_valid_xpath = 0, 0\n    for sentences in si.body.sentences.itervalues():\n        for sentence in sentences:\n            if quick:\n                for i in xrange(len(sentence.tokens) - 1, -1, -1):\n                    if test_token(sentence.tokens[i]):\n                        break\n            else:\n                # Exhaustive test.\n                for token in sentence.tokens:\n                    total += 1\n                    if test_token(token):\n                        has_valid_xpath += 1\n    if not quick:\n        # This is nonsense if we have quick checking enabled.\n        logger.info('stream item %s: %d/%d tokens with valid xpaths',\n                    si.stream_id, has_valid_xpath, total)", "response": "Roundtrip all XPATH offsets in the given stream item."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding an element to the tree.", "response": "def add_element(self, tag):\n        '''Record that `tag` has been seen at this depth.\n\n        If `tag` is :class:`TextElement`, it records a text node.\n\n        '''\n        # Collapse adjacent text nodes\n        if tag is TextElement and self.last_tag is TextElement:\n            return\n        self.last_tag = tag\n        if tag not in self.tags:\n            self.tags[tag] = 1\n        else:\n            self.tags[tag] += 1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef xpath_piece(self):\n        '''Get an XPath fragment for this location.\n\n        It is of the form ``tag[n]`` where `tag` is the most recent\n        element added and n is its position.\n\n        '''\n        if self.last_tag is TextElement:\n            return 'text()[{count}]'.format(count=self.text_index())\n        else:\n            return '{tag}[{count}]'.format(tag=self.last_tag,\n                                           count=self.tags[self.last_tag])", "response": "Get an XPath fragment for this location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the one - based index of the current text node.", "response": "def text_index(self):\n        '''Returns the one-based index of the current text node.'''\n        # This is the number of text nodes we've seen so far.\n        # If we are currently in a text node, great; if not then add\n        # one for the text node that's about to begin.\n        i = self.tags.get(TextElement, 0)\n        if self.last_tag is not TextElement:\n            i += 1\n        return i"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a tuple of xpath and character offset.", "response": "def xpath_offset(self):\n        '''Returns a tuple of ``(xpath, character offset)``.\n\n        The ``xpath`` returned *uniquely* identifies the end of the\n        text node most recently inserted. The character offsets\n        indicates where the text inside the node ends. (When the text\n        node is empty, the offset returned is `0`.)\n        '''\n        datai = self.depth_stack[-1].text_index()\n        xpath = (u'/' +\n                 u'/'.join(dse.xpath_piece()\n                           for dse in self.depth_stack[:-1]) +\n                 (u'/text()[%d]' % datai))\n        return (xpath, self.data_start)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef descendants(elem):\n    '''\n    Yields all the elements descendant of elem in document order\n    '''\n    for child in elem.xml_children:\n        if isinstance(child, element):\n            yield child\n            yield from descendants(child)", "response": "Yields all the elements descendant of elem in document order\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select_elements(source):\n    '''\n    Yields all the elements from the source\n    source - if an element, yields all child elements in order; if any other iterator yields the elements from that iterator\n    '''\n    if isinstance(source, element):\n        source = source.xml_children\n    return filter(lambda x: isinstance(x, element), source)", "response": "Yields all the elements from the source\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef select_name(source, name):\n    '''\n    Yields all the elements with the given name\n    source - if an element, starts with all child elements in order; can also be any other iterator\n    name - will yield only elements with this name\n    '''\n    return filter(lambda x: x.xml_name == name, select_elements(source))", "response": "Yields all the elements with the given name"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef select_name_pattern(source, pat):\n    '''\n    Yields elements from the source whose name matches the given regular expression pattern\n    source - if an element, starts with all child elements in order; can also be any other iterator\n    pat - re.pattern object\n    '''\n    return filter(lambda x: pat.match(x.xml_name) is not None, select_elements(source))", "response": "Yields elements from the source whose name matches the given regular expression pattern\n    source - source containing the elements that start with all child elements in order of name"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nyields elements from the source with the given value", "response": "def select_value(source, val):\n    '''\n    Yields elements from the source with the given value (accumulated child text)\n    source - if an element, starts with all child elements in order; can also be any other iterator\n    val - string value to match\n    '''\n    if isinstance(source, element):\n        source = source.xml_children\n    return filter(lambda x: x.xml_value == val, source)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nyielding elements from the source having the given attrivute and value.", "response": "def select_attribute(source, name, val=None):\n    '''\n    Yields elements from the source having the given attrivute, optionally with the given attribute value\n    source - if an element, starts with all child elements in order; can also be any other iterator\n    name - attribute name to check\n    val - if None check only for the existence of the attribute, otherwise compare the given value as well\n    '''\n    def check(x):\n        if val is None:\n            return name in x.xml_attributes\n        else:\n            return name in x.xml_attributes and x.xml_attributes[name] == val\n    return filter(check, select_elements(source))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield elements and text which have the same parent as elem but come afterward in document order", "response": "def following_siblings(elem):\n    '''\n    Yields elements and text which have the same parent as elem, but come afterward in document order\n    '''\n    it = itertools.dropwhile(lambda x: x != elem, elem.xml_parent.xml_children)\n    next(it) #Skip the element itself\n    return it"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields descendant nodes matching the given pattern specification.", "response": "def select_pattern(node, pattern, state=None):\n    '''\n    Yield descendant nodes matching the given pattern specification\n    pattern - tuple of steps, each of which matches an element by name, with \"*\" acting like a wildcard, descending the tree in tuple order\n                sort of like a subset of XPath in Python tuple form\n    state - for internal use only\n\n    pattern examples:\n\n    (\"a\", \"b\", \"c\") - all c elements whose parent is a b element whose parent is an a element whose parent is node\n    (\"*\", \"*\") - any \"grandchild\" of node\n    (\"*\", \"*\", \"*\") - any \"great grandchild\" of node\n    (\"**\", \"a\") - any a descendant of node\n\n    >>> from amara3.uxml import tree\n    >>> from amara3.uxml.treeutil import *\n    >>>\n    >>> tb = tree.treebuilder()\n    >>> DOC = '<a xmlns=\"urn:namespaces:suck\"><b><x>1</x></b><c><x>2</x><d><x>3</x></d></c><x>4</x><y>5</y></a>'\n    >>> root = tb.parse(DOC)\n    >>> results = [ e.xml_value for e in select_pattern(root, ('**', 'x')) ]\n    >>> results\n    ['1', '2', '3', '4']\n    '''\n    if state is None:\n        state = _prep_pattern(pattern)\n    #for child in select_elements(elem):\n    if isinstance(node, element):\n        for child in node.xml_children:\n            new_state = state(child)\n            if new_state == MATCHED_STATE:\n                yield child\n            elif new_state is not None:\n                yield from select_pattern(child, None, state=new_state)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_pretty(elem, depth=0, indent='  '):\n    '''\n    Add text nodes as possible to all descendants of an element for spacing & indentation\n    to make the MicroXML as printed easier for people to read. Will not modify the\n    value of any text node which is not already entirely whitespace.\n\n    Warning: even though this operaton avoids molesting text nodes which already have\n    whitespace, it still makes changes which alter the text. Not all whitespace in XML is\n    ignorable. In XML cues from the DTD indicate which whitespace can be ignored.\n    No such cues are available for MicroXML, so use this function with care. That said,\n    in many real world applications of XML and MicroXML, this function causes no problems.\n\n    elem - target element whose descendant nodes are to be modified.\n    returns - the same element, which has been updated in place\n\n    >>> from amara3.uxml import tree\n    >>> from amara3.uxml.treeutil import *\n    >>> DOC = '<a><b><x>1</x></b><c><x>2</x><d><x>3</x></d></c><x>4</x><y>5</y></a>'\n    >>> tb = tree.treebuilder()\n    >>> root = tb.parse(DOC)\n    >>> len(root.xml_children)\n    4\n    >>> make_pretty(root)\n    <uxml.element (8763373718343) \"a\" with 9 children>\n    >>> len(root.xml_children)\n    9\n    >>> root.xml_encode()\n    '<a>\\n  <b>\\n    <x>1</x>\\n  </b>\\n  <c>\\n    <x>2</x>\\n    <d>\\n      <x>3</x>\\n    </d>\\n  </c>\\n  <x>4</x>\\n  <y>5</y>\\n</a>'\n    '''\n    depth += 1\n    updated_child_list = []\n    updated_child_ix = 0\n    for child in elem.xml_children:\n        if isinstance(child, element):\n            if updated_child_ix % 2:\n                updated_child_list.append(child)\n                updated_child_ix += 1\n            else:\n                #It's the turn for text, but we have an element\n                new_text = text('\\n' + indent*depth, elem)\n                updated_child_list.append(new_text)\n                updated_child_list.append(child)\n                updated_child_ix += 2\n            make_pretty(child, depth)\n        else:\n            if child.xml_value.strip():\n                #More to it than whitespace, so leave alone\n                #Note: if only whitespace entities are used, will still be left alone\n                updated_child_list.append(child)\n                updated_child_ix += 1\n            else:\n                #Only whitespace, so replace with proper indentation\n                new_text = text('\\n' + indent*depth, elem)\n                updated_child_list.append(new_text)\n                updated_child_ix += 1\n    #Trailing indentation might be needed\n    if not(updated_child_ix % 2):\n        new_text = text('\\n' + indent*(depth-1), elem)\n        updated_child_list.append(new_text)\n        #updated_child_ix += 1 #About to be done, so not really needed\n    elem.xml_children = updated_child_list\n    return elem", "response": "Creates a new node in the order that the element is printed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef call_inkscape(args_strings, inkscape_binpath=None):\n    log.debug('Looking for the binary file for inkscape.')\n\n    if inkscape_binpath is None:\n        inkscape_binpath = get_inkscape_binpath()\n\n    if inkscape_binpath is None or not os.path.exists(inkscape_binpath):\n        raise IOError(\n            'Inkscape binary has not been found. Please check configuration.'\n        )\n\n    return call_command(inkscape_binpath, args_strings)", "response": "Call inkscape command CLI with arguments and returns its return value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling Inkscape to export the input_file to output_file using the inkscape_binpath argument.", "response": "def inkscape_export(input_file, output_file, export_flag=\"-A\", dpi=90, inkscape_binpath=None):\n    \"\"\" Call Inkscape to export the input_file to output_file using the\n    specific export argument flag for the output file type.\n\n    Parameters\n    ----------\n\n    input_file: str\n        Path to the input file\n\n    output_file: str\n        Path to the output file\n\n    export_flag: str\n        Inkscape CLI flag to indicate the type of the output file\n\n    Returns\n    -------\n    return_value\n        Command call return value\n\n    \"\"\"\n    if not os.path.exists(input_file):\n        log.error('File {} not found.'.format(input_file))\n        raise IOError((0, 'File not found.', input_file))\n\n    if '=' not in export_flag:\n        export_flag += ' '\n\n    arg_strings = []\n    arg_strings += ['--without-gui']\n    arg_strings += ['--export-text-to-path']\n    arg_strings += ['{}\"{}\"'.format(export_flag, output_file)]\n    arg_strings += ['--export-dpi={}'.format(dpi)]\n    arg_strings += ['\"{}\"'.format(input_file)]\n\n    return call_inkscape(arg_strings, inkscape_binpath=inkscape_binpath)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransforms SVG file to PDF file", "response": "def svg2pdf(svg_file_path, pdf_file_path, dpi=150, command_binpath=None, support_unicode=False):\n    \"\"\" Transform SVG file to PDF file\n    \"\"\"\n\n    if support_unicode:\n        return rsvg_export(svg_file_path, pdf_file_path, dpi=dpi, rsvg_binpath=command_binpath)\n\n    return inkscape_export(svg_file_path, pdf_file_path, export_flag=\"-A\",\n                           dpi=dpi, inkscape_binpath=command_binpath)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef svg2png(svg_file_path, png_file_path, dpi=150, inkscape_binpath=None):\n    return inkscape_export(svg_file_path, png_file_path, export_flag=\"-e\",\n                           dpi=dpi, inkscape_binpath=inkscape_binpath)", "response": "Transform SVG file to PNG file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_environment_for(file_path):\n    work_dir = os.path.dirname(os.path.abspath(file_path))\n\n    if not os.path.exists(work_dir):\n        raise IOError('Could not find folder for dirname of file {}.'.format(file_path))\n\n    try:\n        jinja_env = Environment(loader=FileSystemLoader(work_dir))\n    except:\n        raise\n    else:\n        return jinja_env", "response": "Returns a Jinja2. Environment object for where file_path is."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfill the content of the document with the template information.", "response": "def fill(self, doc_contents):\n        \"\"\" Fill the content of the document with the information in doc_contents.\n\n        Parameters\n        ----------\n        doc_contents: dict\n            Set of values to set the template document.\n\n        Returns\n        -------\n        filled_doc: str\n            The content of the document with the template information filled.\n        \"\"\"\n        try:\n            filled_doc = self.template.render(**doc_contents)\n        except:\n            log.exception('Error rendering Document '\n                          'for {}.'.format(doc_contents))\n            raise\n        else:\n            self.file_content_ = filled_doc\n            return filled_doc"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_content(self, file_path, encoding='utf-8'):\n        if self.file_content_ is None:\n            msg = 'Template content has not been updated. \\\n                   Please fill the template before rendering it.'\n            log.exception(msg)\n            raise ValueError(msg)\n\n        try:\n            write_to_file(file_path, content=self.file_content_,\n                          encoding=encoding)\n        except Exception as exc:\n            msg = 'Document of type {} got an error when \\\n                   writing content.'.format(self.__class__)\n            log.exception(msg)\n            raise Exception(msg) from exc", "response": "Save the content of the. txt file in a text file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfills the content of the SVG document with the information in doc_contents.", "response": "def fill(self, doc_contents):\n        \"\"\" Fill the content of the document with the information in doc_contents.\n        This is different from the TextDocument fill function, because this will\n        check for symbools in the values of `doc_content` and replace them\n        to good XML codes before filling the template.\n\n        Parameters\n        ----------\n        doc_contents: dict\n            Set of values to set the template document.\n\n        Returns\n        -------\n        filled_doc: str\n            The content of the document with the template information filled.\n        \"\"\"\n        for key, content in doc_contents.items():\n            doc_contents[key] = replace_chars_for_svg_code(content)\n\n        return super(SVGDocument, self).fill(doc_contents=doc_contents)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render(self, file_path, **kwargs):\n        temp = get_tempfile(suffix='.svg')\n        self.save_content(temp.name)\n\n        file_type = kwargs.get('file_type', 'pdf')\n        dpi = kwargs.get('dpi', 150)\n        support_unicode = kwargs.get('support_unicode', False)\n        try:\n            if file_type == 'svg':\n                shutil.copyfile(temp.name, file_path)\n            elif file_type == 'png':\n                svg2png(temp.name, file_path, dpi=dpi)\n            elif file_type == 'pdf':\n                svg2pdf(temp.name, file_path, dpi=dpi, support_unicode=support_unicode)\n        except:\n            log.exception(\n                'Error exporting file {} to {}'.format(file_path, file_type)\n            )\n            raise", "response": "Render the content of the. svg file to the chosen format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render(self, file_path, **kwargs):\n        temp = get_tempfile(suffix='.tex')\n        self.save_content(temp.name)\n\n        try:\n            self._render_function(temp.name, file_path, output_format='pdf')\n        except:\n            log.exception('Error exporting file {} to PDF.'.format(file_path))\n            raise", "response": "Render the. text file in the PDF."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts XML 1. 0 to MicroXML source - source of XML 1. 0 input handler - handler of events", "response": "def parse(source, handler):\n    '''\n    Convert XML 1.0 to MicroXML\n\n    source - XML 1.0 input\n    handler - MicroXML events handler\n\n    Returns uxml, extras\n\n    uxml - MicroXML element extracted from the source\n    extras - information to be preserved but not part of MicroXML, e.g. namespaces\n    '''\n    h = expat_callbacks(handler)\n    p = xml.parsers.expat.ParserCreate(namespace_separator=' ')\n\n    p.StartElementHandler = h.start_element\n    p.EndElementHandler = h.end_element\n    p.CharacterDataHandler = h.char_data\n    p.StartNamespaceDeclHandler = h.start_namespace\n    p.EndNamespaceDeclHandler = h.end_namespace\n    p.Parse(source)\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstart the optimisation / search using the supplied optimisation othewise method with the supplied inputs for the supplied function.", "response": "def search(self):\n        '''Start the optimisation/search using the supplied optimisation\n        method with the supplied inputs for the supplied function'''\n        search = self._method(inputs=self._inputs, function=self._function,\n                              state=self._state)\n        search.run()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse an input source with HTML text into an Amara 3 tree", "response": "def parse(source, prefixes=None, model=None, encoding=None, use_xhtml_ns=False):\n    '''\n    Parse an input source with HTML text into an Amara 3 tree\n\n    >>> from amara3.uxml import html5\n    >>> import urllib.request\n    >>> with urllib.request.urlopen('http://uche.ogbuji.net/') as response:\n    ...     html5.parse(response)\n\n\n    #Warning: if you pass a string, you must make sure it's a byte string, not a Unicode object.  You might also want to wrap it with amara.lib.inputsource.text if it's not obviously XML or HTML (for example it could be confused with a file name)\n    '''\n    def get_tree_instance(namespaceHTMLElements, use_xhtml_ns=use_xhtml_ns):\n        #use_xhtml_ns is a boolean, whether or not to use http://www.w3.org/1999/xhtml\n        return treebuilder(use_xhtml_ns)\n    parser = html5lib.HTMLParser(tree=get_tree_instance)\n    #doc = parser.parse(inputsource(source, None).stream, encoding=encoding)\n    #doc = parser.parse(source, encoding=encoding)\n    doc = parser.parse(source)\n    first_element = next((e for e in doc.root_nodes if isinstance(e, element)), None)\n    return first_element"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef markup_fragment(source, encoding=None):\n    '''\n    Parse a fragment if markup in HTML mode, and return a bindery node\n\n    Warning: if you pass a string, you must make sure it's a byte string, not a Unicode object.  You might also want to wrap it with amara.lib.inputsource.text if it's not obviously XML or HTML (for example it could be confused with a file name)\n\n    from amara.lib import inputsource\n    from amara.bindery import html\n    doc = html.markup_fragment(inputsource.text('XXX<html><body onload=\"\" color=\"white\"><p>Spam!<p>Eggs!</body></html>YYY'))\n\n    See also: http://wiki.xml3k.org/Amara2/Tagsoup\n    '''\n    doc = parse(source, encoding=encoding)\n    frag = doc.html.body\n    return frag", "response": "Parse a fragment if markup in HTML mode and return a bindery node containing the markup."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef insertText(self, data, insertBefore=None):\n        if insertBefore:\n            self.insertBefore(tree.text(data), insertBefore)\n        else:\n            self.xml_append(tree.text(data))", "response": "Insert data as text in the current node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insertBefore(self, node, refNode):\n        offset = self.xml_children.index(refNode)\n        self.xml_insert(node, offset)", "response": "Insert node as a child of the current node before refNode. Raises ValueError if refNode is not a child of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cloneNode(self):\n        attrs = self.xml_attributes.copy()\n        return element(self.xml_name, attrs=attrs)", "response": "Return a shallow copy of the current node i. e. a node with the same name and attributes but no parent or child nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute(option):\n    '''A script that melody calls with each valid set of options. This\n    script runs the required code and returns the results.'''\n\n    namelist_option = []\n    makefile_option = []\n    flags = \"\"\n    for entry in option:\n        key = entry.keys()[0]\n        if key == \"Problem Size\":\n            namelist_option.append({\"SIZE\": entry[key]})\n        elif key == \"F90\":\n            makefile_option.append(entry)\n        else:\n            flags += entry[key] + \" \"\n    makefile_option.append({\"F90FLAGS\": flags})\n\n    namelist = create_input(namelist_option, \"namelist\",\n                            template_location=\"templates\")\n\n    makefile_include = create_input(makefile_option, \"Makefile.include\",\n                                    template_location=\"templates\")\n\n    benchmark_base = \"shallow\"\n\n    # save the input files in the appropriate place\n    location = benchmark_base + \"/original/namelist\"\n    my_file = open(location, 'w')\n    my_file.write(namelist)\n    my_file.flush()\n\n    location = benchmark_base + \"/common/Makefile.include\"\n    my_file = open(location, 'w')\n    my_file.write(makefile_include)\n    my_file.flush()\n\n    # compile shallow if required\n    base_path = benchmark_base + \"/original\"\n    import subprocess\n    make_process = subprocess.Popen([\"make\", \"clean\"], cwd=base_path,\n                                    stderr=subprocess.PIPE,\n                                    stdout=subprocess.PIPE)\n    if make_process.wait() != 0:\n        return False, []\n\n    make_process = subprocess.Popen([\"make\"], cwd=base_path,\n                                    stderr=subprocess.PIPE,\n                                    stdout=subprocess.PIPE)\n    if make_process.wait() != 0:\n        return False, []\n\n    # run shallow\n    make_process = subprocess.Popen([\"./shallow_base\"], cwd=base_path,\n                                    stderr=subprocess.PIPE,\n                                    stdout=subprocess.PIPE)\n    if make_process.wait() != 0:\n        return False, []\n    # _ = make_process.stderr.read()\n    stdout = make_process.stdout.read()\n\n    # determine if the results are correct. We will need to look at\n    # the results from stdout but for the moment we assume they are\n    # correct\n\n    # extract the required outputs\n    for line in stdout.split(\"\\n\"):\n        if \"Time-stepping\" in line:\n            total_time = line.split()[2]\n\n    return True, total_time", "response": "A script that melody calls with each valid set of options. This script runs the required code and returns the results."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a vCard3. 0 string with the given parameters.", "response": "def create_vcard3_str(name, surname, displayname, email='', org='', title='', url='', note=''):\n    \"\"\" Create a vCard3.0 string with the given parameters.\n    Reference: http://www.evenx.com/vcard-3-0-format-specification\n    \"\"\"\n    vcard = []\n    vcard += ['BEGIN:VCARD']\n    vcard += ['VERSION:3.0']\n\n    if name and surname:\n        name = name.strip()\n        vcard += ['N:{};{};;;'.format(name, surname)]\n\n    if not displayname:\n        displayname = '{} {}'.format(name, surname)\n\n    vcard += ['FN:{}'.format(displayname)]\n\n    if email:\n        vcard += ['EMAIL:{}'.format(email)]\n\n    if org:\n        vcard += ['ORG:{}'.format(org)]\n\n    if title:\n        vcard += ['TITLE:{}'.format(title)]\n\n    if url:\n        vcard += ['URL:{}'.format(url)]\n\n    if note:\n        vcard += ['NOTE:{}'.format(note)]\n\n    vcard += ['END:VCARD']\n\n    return '\\n'.join([field.strip() for field in vcard])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef strval(node, outermost=True):\n    '''\n    XPath-like string value of node\n    '''\n    if not isinstance(node, element):\n        return node.xml_value if outermost else [node.xml_value]\n    accumulator = []\n    for child in node.xml_children:\n        if isinstance(child, text):\n            accumulator.append(child.xml_value)\n        elif isinstance(child, element):\n            accumulator.extend(strval(child, outermost=False))\n    if outermost: accumulator = ''.join(accumulator)\n    return accumulator", "response": "XPath - like string value of node"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_config(options):\n\n    if os.path.exists(options.config):\n        config = ConfigParser.ConfigParser()\n        try:\n            config.read(options.config)\n        except Exception, err:\n            if not options.quiet:\n                sys.stderr.write(\"ERROR: Config file read {config} error. {err}\".format(config=options.config, err=err))\n            sys.exit(-1)\n\n        try:\n            configdata = {\n                \"secrets\": config.get(\"GOOGLE\", \"secrets\"),\n                \"credentials\": config.get(\"nagios-notification-google-calendar\", \"credentials\"),\n                \"start\": config.get(\"nagios-notification-google-calendar\", \"start\"),\n                \"end\": config.get(\"nagios-notification-google-calendar\", \"end\"),\n                \"message\": config.get(\"nagios-notification-google-calendar\", \"message\"),\n            }\n        except ConfigParser.NoOptionError, err:\n            if not options.quiet:\n                sys.stderr.write(\"ERROR: Config file missing option error. {err}\\n\".format(err=err))\n            sys.exit(-1)\n\n        # check mandatory config options supplied\n        mandatories = [\"secrets\", \"credentials\", \"start\", \"end\", \"message\", ]\n        if not all(configdata[mandatory] for mandatory in mandatories):\n            if not options.quiet:\n                sys.stdout.write(\"Mandatory config option missing\\n\")\n            sys.exit(0)\n\n        return configdata\n    else:\n        if not options.quiet:\n            sys.stderr.write(\"ERROR: Config file {config} does not exist\\n\".format(config=options.config))\n        sys.exit(0)", "response": "Parse config file and return dictionary of settings."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_google_credentials(options, config):\n\n    try:\n        if options.get_google_credentials:\n            flow = flow_from_clientsecrets(config[\"secrets\"], scope=SCOPE, redirect_uri=\"oob\")\n            sys.stdout.write(\"Follow this URL: {url} and grant access to calendar.\\n\".format(url=flow.step1_get_authorize_url()))\n            token = raw_input(\"Enter token:\")\n            credentials = flow.step2_exchange(token)\n            storage = Storage(os.path.join(config[\"credentials\"], \"{username}.json\".format(username=options.username)))\n            storage.put(credentials)\n            credentials.set_store(storage)\n        else:\n            storage = Storage(os.path.join(config[\"credentials\"], \"{username}.json\".format(username=options.username)))\n            credentials = storage.get()\n    except Exception, err:\n        if not options.quiet:\n            sys.stderr.write(\"ERROR: Getting google API credentials error. {err}\\n\".format(err=err))\n        sys.exit(-1)\n\n    return credentials", "response": "Get Google API credentials for user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_event_datetimes(options, config):\n\n    now = datetime.datetime.now()\n\n    return {\n        \"start\": {\n            \"dateTime\": (now + datetime.timedelta(minutes=int(config[\"start\"]))).strftime(DT_FORMAT),\n            \"timeZone\": options.timezone,\n        },\n        \"end\": {\n            \"dateTime\": (now + datetime.timedelta(minutes=int(config[\"end\"]))).strftime(DT_FORMAT),\n            \"timeZone\": options.timezone,\n        },\n    }", "response": "Create event start and end datetimes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate event in calendar with sms reminder.", "response": "def create_event(options, config, credentials):\n    \"\"\"\n    Create event in calendar with sms reminder.\n    \"\"\"\n\n    try:\n        http = credentials.authorize(httplib2.Http())\n        service = build(\"calendar\", \"v3\", http=http)\n\n        event = {\n            \"summary\": options.message,\n            \"location\": \"\",\n            \"reminders\": {\n                \"useDefault\": False,\n                \"overrides\": [\n                    {\n                        \"method\": \"sms\",\n                        \"minutes\": config[\"message\"],\n                    },\n                ],\n            }\n        }\n        event.update(create_event_datetimes(options, config))\n\n        service.events().insert(calendarId=options.calendar, sendNotifications=True, body=event).execute()\n    except Exception, err:\n        if not options.quiet:\n            sys.stderr.write(\"ERROR: Creating google calendar event error. {err}\\n\".format(err=err))\n        sys.exit(-1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n\n    # getting info for creating event\n    options = parse_options()\n    config = parse_config(options)\n    credentials = get_google_credentials(options, config)\n\n    if not options.get_google_credentials:\n        create_event(options, config, credentials)", "response": "Main function for processing notification call main function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new document from a CSV file.", "response": "def create(input, template, field, outdir, prefix, otype, command, index,\n           dpi, verbose, unicode_support):\n    \"\"\"Use docstamp to create documents from the content of a CSV file or\n    a Google Spreadsheet.\n\n    Examples: \\n\n    docstamp create -i badge.csv -t badge_template.svg -o badges\n    docstamp create -i badge.csv -t badge_template.svg -o ./badges -d pdf\n    \"\"\"\n    logging.basicConfig(level=LOGGING_LVL)\n    log = logging.getLogger(__name__)\n\n    # setup verbose mode\n    verbose_switch(verbose)\n\n    input_file = input\n    fields = field\n\n    # init set of template contents\n    log.debug('Reading CSV elements from {}.'.format(input_file))\n    items, fieldnames = get_items_from_csv(input_file)\n\n    # check if got any item\n    if len(items) == 0:\n        click.echo('Quiting because found 0 items.')\n        exit(-1)\n\n    if not fields:\n        # set the number of zeros that the files will have\n        n_zeros = int(math.floor(math.log10(len(items))) + 1)\n    else:\n        # check that fields has all valid fields\n        for field_name in fields:\n            if field_name not in fieldnames:\n                raise ValueError('Field name {} not found in input file '\n                                 ' header.'.format(field_name))\n\n    # filter the items if index\n    if index:\n        myitems = {int(idx): items[int(idx)] for idx in index}\n        items = myitems\n        log.debug('Using the elements with index {} of the input '\n                  'file.'.format(index))\n\n    # make output folder\n    if not os.path.exists(outdir):\n        os.mkdir(outdir)\n\n    # create template document model\n    log.debug('Creating the template object using the file {}.'.format(template))\n    template_doc = TextDocument.from_template_file(template, command)\n    log.debug('Created an object of type {}.'.format(type(template_doc)))\n\n    # let's stamp them!\n    for idx in items:\n        item = items[idx]\n\n        if not len(fields):\n            file_name = str(idx).zfill(n_zeros)\n        else:\n            field_values = []\n            try:\n                for field_name in fields:\n                    field_values.append(item[field_name].replace(' ', ''))\n            except:\n                log.exception('Could not get field {} value from'\n                              ' {}'.format(field_name, item))\n                exit(-1)\n            else:\n                file_name = '_'.join(field_values)\n\n        log.debug('Filling template {} with values of item {}.'.format(file_name, idx))\n        try:\n            template_doc.fill(item)\n        except:\n            log.exception('Error filling document for {}th item'.format(idx))\n            continue\n\n        # set output file path\n        file_extension = get_extension(template)\n        if prefix is None:\n            basename = os.path.basename(template).replace(file_extension, '')\n\n        file_name = basename + '_' + file_name\n        file_path = os.path.join(outdir, file_name + '.' + otype)\n\n        kwargs = {'file_type': otype,\n                  'dpi': dpi,\n                  'support_unicode': unicode_support}\n\n        log.debug('Rendering file {}.'.format(file_path))\n        try:\n            template_doc.render(file_path, **kwargs)\n        except:\n            log.exception('Error creating {} for {}.'.format(file_path, item))\n            exit(-1)\n        else:\n            log.debug('Successfully rendered {}.'.format(file_path))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the extension of the file.", "response": "def get_extension(filepath, check_if_exists=False):\n    \"\"\"Return the extension of fpath.\n\n    Parameters\n    ----------\n    fpath: string\n    File name or path\n\n    check_if_exists: bool\n\n    Returns\n    -------\n    str\n    The extension of the file name or path\n    \"\"\"\n    if check_if_exists:\n        if not os.path.exists(filepath):\n            err = 'File not found: ' + filepath\n            log.error(err)\n            raise IOError(err)\n\n    try:\n        rest, ext = os.path.splitext(filepath)\n    except:\n        raise\n    else:\n        return ext"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding the extension ext to fpath if it doesn t already exist.", "response": "def add_extension_if_needed(filepath, ext, check_if_exists=False):\n    \"\"\"Add the extension ext to fpath if it doesn't have it.\n\n    Parameters\n    ----------\n    filepath: str\n    File name or path\n\n    ext: str\n    File extension\n\n    check_if_exists: bool\n\n    Returns\n    -------\n    File name or path with extension added, if needed.\n    \"\"\"\n    if not filepath.endswith(ext):\n        filepath += ext\n\n    if check_if_exists:\n        if not os.path.exists(filepath):\n            err = 'File not found: ' + filepath\n            log.error(err)\n            raise IOError(err)\n\n    return filepath"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_tempfile(suffix='.txt', dirpath=None):\n    if dirpath is None:\n        dirpath = get_temp_dir()\n\n    return tempfile.NamedTemporaryFile(suffix=suffix, dir=dirpath)", "response": "Returns a tempfile object with the given suffix within dirpath."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the files in workdir that have the given extension.", "response": "def cleanup(workdir, extension):\n    \"\"\" Remove the files in workdir that have the given extension.\n\n    Parameters\n    ----------\n    workdir:\n        Folder path from where to clean the files.\n\n    extension: str\n        File extension without the dot, e.g., 'txt'\n    \"\"\"\n    [os.remove(f) for f in glob(os.path.join(workdir, '*.' + extension))]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef csv_to_json(csv_filepath, json_filepath, fieldnames, ignore_first_line=True):\n    import csv\n    import json\n\n    csvfile = open(csv_filepath, 'r')\n    jsonfile = open(json_filepath, 'w')\n\n    reader = csv.DictReader(csvfile, fieldnames)\n    rows = []\n    if ignore_first_line:\n        next(reader)\n\n    for row in reader:\n        rows.append(row)\n\n    json.dump(rows, jsonfile)\n    jsonfile.close()\n    csvfile.close()", "response": "Convert a CSV file in csv_filepath into a JSON file in json_filepath."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting content inside the file in file_path with the given encoding.", "response": "def write_to_file(file_path, content, encoding=None):\n    \"\"\" Write `content` inside the file in `file_path` with the given encoding.\n    Parameters\n    ----------\n    file_path: str\n        Path to the output file. Will be overwritten if exists.\n\n    content: str\n        The content you want in the file.\n\n    encoding: str\n        The name of the encoding.\n    \"\"\"\n    try:\n        # TODO: check if in Python2 this should be this way\n        # it's possible that we have to make this function more complex\n        # to check type(content) and depending on that set 'w' without enconde\n        # or 'wb' with encode.\n        with open(file_path, \"wb\") as f:\n            f.write(content.encode(encoding))\n    except:\n        log.exception('Error writing to file in {}'.format(file_path))\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef replace_file_content(filepath, old, new, max=1):\n    with open(filepath, 'r') as f:\n        content = f.read()\n\n    content = content.replace(old, new, max)\n    with open(filepath, 'w') as f:\n        f.write(content)", "response": "Modify the content of filepath replacing old for new."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cleanup_docstamp_output(output_dir=''):\n    suffixes = ['aux', 'out', 'log']\n    files = [f for suf in suffixes for f in glob(os.path.join(output_dir, 'tmp*.{}'.format(suf)))]\n    [os.remove(file) for file in files]", "response": "Remove the tmp*.aux output and tmp*.out and tmp*.log files in output_dir."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse(self):\n        for tag in self.soup.findAll('span'):\n            self.create_italic(tag)\n            self.create_strong(tag)\n            self.create_underline(tag)\n            self.unwrap_span(tag)\n\n        for tag in self.soup.findAll('a'):\n            self.remove_comments(tag)\n            self.check_next(tag)\n\n        if self.soup.body:\n            for tag in self.soup.body.findAll():\n                self.remove_empty(tag)\n                self.remove_inline_comment(tag)\n                self.parse_attrs(tag)\n                for token, target in self.tokens:\n                    self.find_token(tag, token, target)\n\n                self.remove_blacklisted_tags(tag)", "response": "Run all parsing functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_next(self, tag):\n        if (type(tag.next_sibling) == element.Tag and\n                tag.next_sibling.name == 'a'):\n\n            next_tag = tag.next_sibling\n            if tag.get('href') and next_tag.get('href'):\n                href = self._parse_href(tag.get('href'))\n                next_href = self._parse_href(next_tag.get('href'))\n\n                if href == next_href:\n                    next_text = next_tag.get_text()\n                    tag.append(next_text)\n                    self.tags_blacklist.append(next_tag)", "response": "Check if next tag is link with same href combine them."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsees if span tag has italic style and wrap with em tag.", "response": "def create_italic(self, tag):\n        \"\"\"\n        See if span tag has italic style and wrap with em tag.\n        \"\"\"\n        style = tag.get('style')\n        if style and 'font-style:italic' in style:\n            tag.wrap(self.soup.new_tag('em'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsee if span tag has bold style and wrap with strong tag.", "response": "def create_strong(self, tag):\n        \"\"\"\n        See if span tag has bold style and wrap with strong tag.\n        \"\"\"\n        style = tag.get('style')\n        if (style and\n                ('font-weight:bold' in style or 'font-weight:700' in style)):\n            tag.wrap(self.soup.new_tag('strong'))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsee if span tag has underline style and wrap with u tag.", "response": "def create_underline(self, tag):\n        \"\"\"\n        See if span tag has underline style and wrap with u tag.\n        \"\"\"\n        style = tag.get('style')\n        if style and 'text-decoration:underline' in style:\n            tag.wrap(self.soup.new_tag('u'))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the attributes of a tag.", "response": "def parse_attrs(self, tag):\n        \"\"\"\n        Reject attributes not defined in ATTR_WHITELIST.\n        \"\"\"\n        if tag.name in ATTR_WHITELIST.keys():\n            attrs = copy(tag.attrs)\n            for attr, value in attrs.items():\n                if attr in ATTR_WHITELIST[tag.name]:\n                    tag.attrs[attr] = self._parse_attr(tag.name, attr, value)\n                else:\n                    del tag.attrs[attr]\n        else:\n            tag.attrs = {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_empty(self, tag):\n        has_children = len(tag.contents)\n        has_text = len(list(tag.stripped_strings))\n        if not has_children and not has_text and not tag.is_empty_element:\n            tag.extract()", "response": "Removes empty tags from the tag."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget unicode string without any other content transformation.", "response": "def clean_linebreaks(self, tag):\n        \"\"\"\n        get unicode string without any other content transformation.\n        and clean extra spaces\n        \"\"\"\n        stripped = tag.decode(formatter=None)\n        stripped = re.sub('\\s+', ' ', stripped)\n        stripped = re.sub('\\n', '', stripped)\n        return stripped"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_href(self, href):\n        params = parse_qs(urlsplit(href).query)\n        return params.get('q')", "response": "Extract real URL from Google redirected url by getting querystring parameter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndelegating to href parser for hrefs otherwise return value.", "response": "def _parse_attr(self, tagname, attr, value):\n        \"\"\"\n        Parse attribute. Delegate to href parser for hrefs, otherwise return\n        value.\n        \"\"\"\n        if tagname == 'a' and attr == 'href':\n            return self._parse_href(value)\n        else:\n            return value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntranslating keys in adict to ones in translations.", "response": "def translate_key_values(adict, translations, default=''):\n    \"\"\"Modify the keys in adict to the ones in translations.\n    Be careful, this will modify your input dictionary.\n    The keys not present in translations will be left intact.\n\n    Parameters\n    ----------\n    adict: a dictionary\n\n    translations: iterable of 2-tuples\n    Each 2-tuple must have the following format:\n    (<adict existing key>, <desired key name for the existing key>)\n\n    Returns\n    -------\n    Translated adict\n    \"\"\"\n    for src_key, dst_key in translations:\n        adict[dst_key] = adict.pop(src_key, default)\n    return adict"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts data to json string representation.", "response": "def to_json_str(self):\n        \"\"\"Convert data to json string representation.\n\n        Returns:\n          json representation as string.\n        \"\"\"\n        adict = dict(vars(self), sort_keys=True)\n        adict['type'] = self.__class__.__name__\n        return json.dumps(adict)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns absolute paths of files that match the regex within folder_path and all its children folders.", "response": "def find_file_match(folder_path, regex=''):\n    \"\"\"\n    Returns absolute paths of files that match the regex within folder_path and\n    all its children folders.\n\n    Note: The regex matching is done using the match function\n    of the re module.\n\n    Parameters\n    ----------\n    folder_path: string\n\n    regex: string\n\n    Returns\n    -------\n    A list of strings.\n\n    \"\"\"\n    outlist = []\n    for root, dirs, files in os.walk(folder_path):\n        outlist.extend([os.path.join(root, f) for f in files\n                        if re.match(regex, f)])\n\n    return outlist"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef qquery(xml_thing, xpath_thing, vars=None, funcs=None):\n    '''\n    Quick query. Convenience for using the MicroXPath engine.\n    Give it some XML and an expression and it will yield the results. No fuss.\n    \n    xml_thing - bytes or string, or amara3.xml.tree node\n    xpath_thing - string or parsed XPath expression\n    vars - optional mapping of variables, name to value\n    funcs - optional mapping of functions, name to function object\n    \n    >>> from amara3.uxml.uxpath import qquery\n    >>> results = qquery(b'<a>1<b>2</b>3</a>', 'a/text()'))\n    >>> next(results).xml_value\n    '1'\n    >>> next(results).xml_value\n    '3'\n    '''\n    root = None\n    if isinstance(xml_thing, nodetype):\n        root = xml_thing\n    elif isinstance(xml_thing, str):\n        tb = tree.treebuilder()\n        root = tb.parse(xml_thing)\n    elif isinstance(xml_thing, bytes):\n        tb = tree.treebuilder()\n        #Force UTF-8\n        root = tb.parse(xml_thing.decode('utf-8'))\n    if not root: return\n    if isinstance(xpath_thing, str):\n        parsed_expr = parse(xpath_thing)\n    ctx = context(root, variables=vars, functions=funcs)\n    result = parsed_expr.compute(ctx)\n    yield from result", "response": "Quick query for a single tree node or a MicroXPath expression."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_function_call(p):\n    #Hacking around the ambiguity between node type test & function call\n    if p[1] in ('node', 'text'):\n        p[0] = ast.NodeType(p[1])\n    else:\n        p[0] = ast.FunctionCall(p[1], p[2])", "response": "A function call is a node type test or function call."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nyields one string a node name or the empty string operating on the first item in the provided obj.", "response": "def name(ctx, obj=None):\n    '''\n    Yields one string a node name or the empty string, operating on the first item in the provided obj, or the current item if obj is omitted\n    If this item is a node, yield its node name (generic identifier), otherwise yield ''\n    If obj is provided, but empty, yield ''\n    '''\n    if obj is None:\n        item = ctx.item\n    elif hasattr(obj, 'compute'):\n        item = next(obj.compute(ctx), None)\n    else:\n        item = obj\n    if isinstance(item, node):\n        yield item.xml_name\n    else:\n        yield ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nyields one string derived from the argument sequence.", "response": "def string_(ctx, seq=None):\n    '''\n    Yields one string, derived from the argument literal (or the first item in the argument sequence, unless empty in which case yield '') as follows:\n\n    * If a node, yield its string-value\n    * If NaN, yield 'NaN'\n    * If +0 or -0, yield '0'\n    * If positive infinity, yield 'Infinity'\n    * If negative infinity, yield '-Infinity'\n    * If an integer, no decimal point and no leading zeros\n    * If a non-integer number, at least one digit before the decimal point and at least one digit after\n    * If boolean, either 'true' or 'false'\n    '''\n    if seq is None:\n        item = ctx.item\n    elif hasattr(seq, 'compute'):\n        item = next(seq.compute(ctx), '')\n    else:\n        item = seq\n    yield next(to_string(item), '')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef concat(ctx, *strings):\n    '''\n    Yields one string, concatenation of argument strings\n    '''\n    strings = flatten([ (s.compute(ctx) if callable(s) else s) for s in strings ])\n    strings = (next(string_arg(ctx, s), '') for s in strings)\n    #assert(all(map(lambda x: isinstance(x, str), strings)))\n    #FIXME: Check arg types\n    yield ''.join(strings)", "response": "Yields one string concatenation of argument strings\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nyields one boolean whether the first string starts with the second string.", "response": "def starts_with(ctx, full, part):\n    '''\n    Yields one boolean, whether the first string starts with the second\n    '''\n    full = next(string_arg(ctx, full), '')\n    part = next(string_arg(ctx, part), '')\n    yield full.startswith(part)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nyields one boolean whether the first string contains the second string", "response": "def contains(ctx, full, part):\n    '''\n    Yields one boolean, whether the first string contains the second\n    '''\n    full = next(string_arg(ctx, full), '')\n    part = next(string_arg(ctx, part), '')\n    yield part in full"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nyields one string that is part before full.", "response": "def substring_before(ctx, full, part):\n    '''\n    Yields one string\n    '''\n    full = next(string_arg(ctx, full), '')\n    part = next(string_arg(ctx, part), '')\n    yield full.partition(part)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef substring_after(ctx, full, part):\n    '''\n    Yields one string\n    '''\n    full = next(string_arg(ctx, full), '')\n    part = next(string_arg(ctx, part), '')\n    yield full.partition(part)[-1]", "response": "Yields one string after part."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding a substring of a string.", "response": "def substring(ctx, full, start, length):\n    '''\n    Yields one string\n    '''\n    full = next(string_arg(ctx, full), '')\n    start = int(next(to_number(start)))\n    length = int(next(to_number(length)))\n    yield full[start-1:start-1+length]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef boolean(ctx, obj):\n    '''\n    Yields one boolean, false if the argument sequence is empty, otherwise\n\n    * false if the first item is a boolean and false\n    * false if the first item is a number and positive or negative zero or NaN\n    * false if the first item is a string and ''\n    * true in all other cases\n    '''\n    if hasattr(obj, 'compute'):\n        obj = next(seq.compute(ctx), '')\n    else:\n        obj = seq\n    yield next(to_boolean(obj), '')", "response": "Yields one boolean if the argument sequence is empty otherwise\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef number(ctx, seq=None):\n    '''\n    Yields one float, derived from the first item in the argument sequence (unless empty in which case yield NaN) as follows:\n\n    * If string with optional whitespace followed by an optional minus sign followed by a Number followed by whitespace, converte to the IEEE 754 number that is nearest (according to the IEEE 754 round-to-nearest rule) to the mathematical value represented by the string; in case of any other string yield NaN\n    * If boolean true yield 1; if boolean false yield 0\n    * If a node convert to string as if by a call to string(); yield the same value as if passed that string argument to number()\n    '''\n    if hasattr(obj, 'compute'):\n        obj = next(seq.compute(ctx), '')\n    else:\n        obj = seq\n    yield next(to_number(obj), '')", "response": "Yields one float derived from the first item in the argument sequence unless empty and yield NaN."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef foreach_(ctx, seq, expr):\n    '''\n    Yields the result of applying an expression to each item in the input sequence.\n\n    * seq: input sequence\n    * expr: expression to be converted to string, then dynamically evaluated for each item on the sequence to produce the result\n    '''\n    from . import context, parse as uxpathparse\n\n    if hasattr(seq, 'compute'):\n        seq = seq.compute(ctx)\n\n    expr = next(string_arg(ctx, expr), '')\n\n    pexpr = uxpathparse(expr)\n    for item in seq:\n        innerctx = ctx.copy(item=item)\n        yield from pexpr.compute(innerctx)", "response": "Yields the result of applying an expression to each item in the input sequence."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nyielding a sequence of a single value from the tables provided in the context", "response": "def lookup_(ctx, tableid, key):\n    '''\n    Yields a sequence of a single value, the result of looking up a value from the tables provided in the context, or an empty sequence if lookup is unsuccessful\n\n    * tableid: id of the lookup table to use\n    * expr: expression to be converted to string, then dynamically evaluated for each item on the sequence to produce the result\n    '''\n    tableid = next(string_arg(ctx, tableid), '')\n    key = next(string_arg(ctx, key), '')\n    #value = ctx.\n    for item in seq:\n        innerctx = ctx.copy(item=item)\n        yield from pexpr.compute(innerctx)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_chars_for_svg_code(svg_content):\n    result = svg_content\n    svg_char = [\n        ('&', '&amp;'),\n        ('>', '&gt;'),\n        ('<', '&lt;'),\n        ('\"', '&quot;'),\n    ]\n\n    for c, entity in svg_char:\n        result = result.replace(c, entity)\n\n    return result", "response": "Replace known special characters to SVG code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntry to read a. svg file and return the object.", "response": "def _check_svg_file(svg_file):\n    \"\"\" Try to read a SVG file if `svg_file` is a string.\n    Raise an exception in case of error or return the svg object.\n\n    If `svg_file` is a svgutils svg object, will just return it.\n\n    Parameters\n    ----------\n    svg_file: str or svgutils.transform.SVGFigure object\n        If a `str`: path to a '.svg' file,\n        otherwise a svgutils svg object is expected.\n\n    Returns\n    -------\n    svgutils svg object\n\n    Raises\n    ------\n    Exception if any error happens.\n    \"\"\"\n    if isinstance(svg_file, str):\n        try:\n            svg = sg.fromfile(svg_file)\n        except Exception as exc:\n            raise Exception('Error reading svg file {}.'.format(svg_file)) from exc\n        else:\n            return svg\n\n    if isinstance(svg_file, sg.SVGFigure):\n        return svg_file\n\n    raise ValueError('Expected `svg_file` to be `str` or `svgutils.SVG`, got {}.'.format(type(svg_file)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef merge_svg_files(svg_file1, svg_file2, x_coord, y_coord, scale=1):\n    svg1 = _check_svg_file(svg_file1)\n    svg2 = _check_svg_file(svg_file2)\n\n    svg2_root = svg2.getroot()\n    svg1.append([svg2_root])\n\n    svg2_root.moveto(x_coord, y_coord, scale=scale)\n\n    return svg1", "response": "Merge SVG files in the given positions x_coord y_coord and scale."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rsvg_export(input_file, output_file, dpi=90, rsvg_binpath=None):\n    if not os.path.exists(input_file):\n        log.error('File {} not found.'.format(input_file))\n        raise IOError((0, 'File not found.', input_file))\n\n    if rsvg_binpath is None:\n        rsvg_binpath = which('rsvg-convert')\n        check_command(rsvg_binpath)\n\n    args_strings = []\n    args_strings += [\"-f pdf\"]\n    args_strings += [\"-o {}\".format(output_file)]\n    args_strings += [\"--dpi-x {}\".format(dpi)]\n    args_strings += [\"--dpi-y {}\".format(dpi)]\n    args_strings += [input_file]\n\n    return call_command(rsvg_binpath, args_strings)", "response": "Convert a SVG to a PDF."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmerging all the PDF files in pdf_filepaths into a new PDF file.", "response": "def merge_pdfs(pdf_filepaths, out_filepath):\n    \"\"\" Merge all the PDF files in `pdf_filepaths` in a new PDF file `out_filepath`.\n\n    Parameters\n    ----------\n    pdf_filepaths: list of str\n        Paths to PDF files.\n\n    out_filepath: str\n        Path to the result PDF file.\n\n    Returns\n    -------\n    path: str\n        The output file path.\n    \"\"\"\n    merger = PdfFileMerger()\n    for pdf in pdf_filepaths:\n        merger.append(PdfFileReader(open(pdf, 'rb')))\n\n    merger.write(out_filepath)\n\n    return out_filepath"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _embed_font_to_svg(filepath, font_files):\n    with open(filepath, 'r') as svgf:\n        tree = etree.parse(svgf)\n\n    if not font_files:\n        return tree\n\n    fontfaces = FontFaceGroup()\n    for font_file in font_files:\n        fontfaces.append(FontFace(font_file))\n\n    for element in tree.iter():\n        if element.tag.split(\"}\")[1] == 'svg':\n            break\n\n    element.insert(0, fontfaces.xml_elem)\n\n    return tree", "response": "Return the ElementTree of the SVG content in filepath with the font content embedded."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting ttf and otf font content from font_files to outfile.", "response": "def embed_font_to_svg(filepath, outfile, font_files):\n    \"\"\" Write ttf and otf font content from `font_files`\n    in the svg file in `filepath` and write the result in\n    `outfile`.\n\n    Parameters\n    ----------\n    filepath: str\n        The SVG file whose content must be modified.\n\n    outfile: str\n        The file path where the result will be written.\n\n    font_files: iterable of str\n        List of paths to .ttf or .otf files.\n    \"\"\"\n    tree = _embed_font_to_svg(filepath, font_files)\n    tree.write(outfile, encoding='utf-8', pretty_print=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_inputs(self):\n        ''' make some basic checks on the inputs to make sure they are valid'''\n        try:\n            _ = self._inputs[0]\n        except TypeError:\n            raise RuntimeError(\n                \"inputs should be iterable but found type='{0}', value=\"\n                \"'{1}'\".format(type(self._inputs), str(self._inputs)))\n        from melody.inputs import Input\n        for check_input in self._inputs:\n            if not isinstance(check_input, Input):\n                raise RuntimeError(\n                    \"input should be a subclass of the Input class but \"\n                    \"found type='{0}', value='{1}'\".format(type(check_input),\n                                                           str(check_input)))", "response": "make some basic checks on the inputs to make sure they are valid"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake some basic checks on the function to make sure it is valid", "response": "def _check_function(self):\n        ''' make some basic checks on the function to make sure it is valid'''\n        # note, callable is valid for Python 2 and Python 3.2 onwards but\n        # not inbetween\n        if not callable(self._function):\n            raise RuntimeError(\n                \"provided function '{0}' is not callable\".\n                format(str(self._function)))\n        from inspect import getargspec\n        arg_info = getargspec(self._function)\n        if len(arg_info.args) != 1:\n            print str(arg_info)\n            raise RuntimeError(\n                \"provided function should have one argument but found \"\n                \"{0}\".format(len(arg_info.args)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _recurse(self, inputs, output):\n        '''internal recursion routine called by the run method that generates\n        all input combinations'''\n        if inputs:\n            my_input = inputs[0]\n            name = my_input.name\n            if my_input.state:\n                my_options = my_input.options(self.state)\n            else:\n                my_options = my_input.options\n            for option in my_options:\n                my_output = list(output)\n                my_output.append({name: option})\n                self._recurse(inputs[1:], my_output)\n        else:\n            try:\n                valid, result = self._function(output)\n            except ValueError:\n                raise RuntimeError(\"function must return 2 values\")\n            print output, valid, result", "response": "internal method that generates\n            all input combinations"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_input(option, template_name, template_location=\"template\"):\n\n    '''create an input file using jinja2 by filling a template\n    with the values from the option variable passed in.'''\n\n    # restructure option list into jinja2 input format\n    jinja2_input = {}\n    for item in option:\n        try:\n            jinja2_input.update(item)\n        except ValueError:\n            raise RuntimeError(\n                (\"inputs.py, create_input : format of item '{0}' is not \"\n                 \"supported. Expecting a dictionary.\".format(str(item))))\n\n    # load the template and fill it with the option variable contents\n    import jinja2\n    try:\n        template_loader = jinja2.FileSystemLoader(searchpath=template_location)\n        template_env = jinja2.Environment(loader=template_loader)\n        template = template_env.get_template(template_name)\n        output_text = template.render(jinja2_input)\n    except jinja2.TemplateNotFound:\n        raise RuntimeError(\"template '{0}' not found\".format(template_name))\n    # return the particular input file as a string\n    return output_text", "response": "create an input file using jinja2 by filling a template\n    with the values from the option variable passed in."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_string(obj):\n    '''\n    Cast an arbitrary object or sequence to a string type\n    '''\n    if isinstance(obj, LiteralWrapper):\n        val = obj.obj\n    elif isinstance(obj, Iterable) and not isinstance(obj, str):\n        val = next(obj, None)\n    else:\n        val = obj\n    if val is None:\n        yield ''\n    elif isinstance(val, str):\n        yield val\n    elif isinstance(val, node):\n        yield strval(val)\n    elif isinstance(val, int) or isinstance(val, float):\n        yield str(val)\n    elif isinstance(item, bool):\n        yield 'true' if item else 'false'\n    else:\n        raise RuntimeError('Unknown type for string conversion: {}'.format(val))", "response": "Cast an arbitrary object or sequence to a string type\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncast an arbitrary object or sequence to a number type", "response": "def to_number(obj):\n    '''\n    Cast an arbitrary object or sequence to a number type\n    '''\n    if isinstance(obj, LiteralWrapper):\n        val = obj.obj\n    elif isinstance(obj, Iterable) and not isinstance(obj, str):\n        val = next(obj, None)\n    else:\n        val = obj\n    if val is None:\n        #FIXME: Should be NaN, not 0\n        yield 0\n    elif isinstance(val, str):\n        yield float(val)\n    elif isinstance(val, node):\n        yield float(strval(val))\n    elif isinstance(val, int) or isinstance(val, float):\n        yield val\n    else:\n        raise RuntimeError('Unknown type for number conversion: {}'.format(val))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_boolean(obj):\n    '''\n    Cast an arbitrary sequence to a boolean type\n    '''\n    #if hasattr(obj, '__iter__'):\n    if isinstance(obj, LiteralWrapper):\n        val = obj.obj\n    elif isinstance(obj, Iterable) and not isinstance(obj, str):\n        val = next(obj, None)\n    else:\n        val = obj\n    if val is None:\n        yield False\n    elif isinstance(val, bool):\n        yield val\n    elif isinstance(val, str):\n        yield bool(str)\n    elif isinstance(val, node):\n        yield True\n    elif isinstance(val, float) or isinstance(val, int):\n        yield bool(val)\n    else:\n        raise RuntimeError('Unknown type for boolean conversion: {}'.format(val))", "response": "Cast an arbitrary sequence to a boolean type\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating token strings which when joined together form a valid XPath serialization of the AST.", "response": "def _serialize(xp_ast):\n    '''Generate token strings which, when joined together, form a valid\n    XPath serialization of the AST.'''\n\n    if hasattr(xp_ast, '_serialize'):\n        for tok in xp_ast._serialize():\n            yield(tok)\n    elif isinstance(xp_ast, str):\n        yield(repr(xp_ast))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef change_xml_encoding(filepath, src_enc, dst_enc='utf-8'):\n    enc_attr = \"encoding='{}'\"\n    replace_file_content(filepath, enc_attr.format(src_enc), enc_attr.format(dst_enc), 1)", "response": "Modify the encoding entry in the XML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves text into a QR code svg image file.", "response": "def save_into_qrcode(text, out_filepath, color='', box_size=10, pixel_size=1850):\n    \"\"\" Save `text` in a qrcode svg image file.\n\n    Parameters\n    ----------\n    text: str\n        The string to be codified in the QR image.\n\n    out_filepath: str\n        Path to the output file\n\n    color: str\n        A RGB color expressed in 6 hexadecimal values.\n\n    box_size: scalar\n        Size of the QR code boxes.\n    \"\"\"\n    try:\n        qr = qrcode.QRCode(version=1, error_correction=qrcode.constants.ERROR_CORRECT_L,\n                           box_size=box_size, border=0, )\n        qr.add_data(text)\n        qr.make(fit=True)\n    except Exception as exc:\n        raise Exception('Error trying to generate QR code '\n                        ' from `vcard_string`: {}'.format(text)) from exc\n    else:\n        img = qr.make_image(image_factory=qrcode.image.svg.SvgPathImage)\n\n    _ = _qrcode_to_file(img, out_filepath)\n\n    if color:\n        replace_file_content(out_filepath, 'fill:#000000', 'fill:#{}'.format(color))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _qrcode_to_file(qrcode, out_filepath):\n    try:\n        qrcode.save(out_filepath)\n    except Exception as exc:\n        raise IOError('Error trying to save QR code file {}.'.format(out_filepath)) from exc\n    else:\n        return qrcode", "response": "Save a QR code object into out_filepath."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_cdata(pos, window, charpat, stopchars):\n    '''\n    Return (result, new_position) tuple.\n    Result is cdata string if possible and None if more input is needed\n    Or of course bad syntax can raise a RuntimeError\n    '''\n    cdata = ''\n    cursor = start = pos\n\n    try:\n        while True:\n            while charpat.match(window[cursor]):\n                cursor += 1\n            addchars = window[start:cursor]\n            cdata += addchars\n            #if window[pos] != openattr:\n            #    raise RuntimeError('Mismatch in attribute quotes')\n            if window[cursor] in stopchars:\n                return cdata, cursor\n            #Check for charref\n            elif window[cursor] == '&':\n                start = cursor = cursor + 1\n                if window[cursor] == '#' and window[cursor + 1] == 'x':\n                    #Numerical charref\n                    start = cursor = cursor + 2\n                    while True:\n                        if HEXCHARENTOK.match(window[cursor]):\n                            cursor += 1\n                        elif window[cursor] == ';':\n                            c = chr(int(window[start:cursor], 16))\n                            if not CHARACTER.match(c):\n                                raise RuntimeError('Character reference gives an illegal character: {0}'.format('&' + window[start:cursor] + ';'))\n                            cdata += c\n                            break\n                        else:\n                            raise RuntimeError('Illegal in character entity: {0}'.format(window[cursor]))\n                else:\n                    #Named charref\n                    while True:\n                        if NAMEDCHARENTOK.match(window[cursor]):\n                            cursor += 1\n                        elif window[cursor] == ';':\n                            for cn, c in CHARNAMES:\n                                if window[start:cursor] == cn:\n                                    cdata += c\n                                    #cursor += 1 #Skip ;\n                                    break\n                            else:\n                                raise RuntimeError('Unknown named character reference: {0}'.format(repr(window[start:cursor])))\n                            break\n                        else:\n                            raise RuntimeError('Illegal in character reference: {0} (around {1})'.format(window[cursor]), error_context(window, start, cursor))\n            #print(start, cursor, cdata, window[cursor])\n            cursor += 1\n            start = cursor\n    except IndexError:\n        return None, cursor", "response": "Handle a cdata character at the given position."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef launch(option):\n    '''Set the gromacs input data using the supplied input options, run\n    gromacs and extract and return the required outputs.'''\n\n    from melody.inputs import create_input\n    _ = create_input(option, template_name=\"input.mdp\")\n\n    # save the input file in the appropriate place and launch gromacs using\n    # longbow ...\n\n    # determine if the run was successful\n    success = True\n\n    results = None\n    if success:\n        # extract the required outputs\n        results = {\"rate\": {\"value\": 35, \"units\": \"ns/day\"}, }\n\n    return success, results", "response": "Launch the gromacs using the supplied input options run\n    gromacs and extract and return the required outputs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall a command with arguments and returns its return value.", "response": "def call_command(cmd_name, args_strings):\n    \"\"\"Call CLI command with arguments and returns its return value.\n\n    Parameters\n    ----------\n    cmd_name: str\n        Command name or full path to the binary file.\n\n    arg_strings: str\n        Argument strings list.\n\n    Returns\n    -------\n    return_value\n        Command return value.\n    \"\"\"\n    if not os.path.isabs(cmd_name):\n        cmd_fullpath = which(cmd_name)\n    else:\n        cmd_fullpath = cmd_name\n\n    try:\n        cmd_line = [cmd_fullpath] + args_strings\n        log.debug('Calling: `{}`.'.format(' '.join(cmd_line)))\n        # retval = subprocess.check_call(cmd_line)\n        retval = subprocess.call(' '.join(cmd_line), shell=True)\n    except CalledProcessError as ce:\n        log.exception(\n            \"Error calling command with arguments: \"\n            \"{} \\n With return code: {}\".format(cmd_line, ce.returncode)\n        )\n        raise\n    else:\n        return retval"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getCSV(self):\n        import getpass\n        import gspread\n\n        user = raw_input(\"Insert Google username:\")\n        password = getpass.getpass(prompt=\"Insert password:\")\n        name = raw_input(\"SpreadSheet filename on Drive:\")\n        sheet = raw_input(\"Sheet name (first sheet is default):\")\n\n        cl = gspread.login(user, password)\n        sh = cl.open(name)\n\n        if not (sheet.strip()):\n            ws = sh.sheet1\n            sheet = \"1\"\n        else:\n            ws = sh.worksheet(sheet)\n\n        filename = name + '-worksheet_' + sheet + '.csv'\n        with open(filename, 'wb') as f:\n            writer = UnicodeWriter(f)\n            writer.writerows(ws.get_all_values())\n\n        return filename", "response": "Returns the name of the CSV file for the current object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting a MicroXML element node to a MicroXML writer", "response": "def write(elem, a_writer):\n    '''\n    Write a MicroXML element node (yes, even one representign a whole document)\n    elem - Amara MicroXML element node to be written out\n    writer - instance of amara3.uxml.writer to implement the writing process\n    '''\n    a_writer.start_element(elem.xml_name, attribs=elem.xml_attributes)\n    for node in elem.xml_children:\n        if isinstance(node, tree.element):\n            write(node, a_writer)\n        elif isinstance(node, tree.text):\n            a_writer.text(node)\n    a_writer.end_element(elem.xml_name)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting TeX files to PDF.", "response": "def tex2pdf(tex_file, output_file=None, output_format='pdf'):\n    \"\"\" Call PDFLatex to convert TeX files to PDF.\n\n    Parameters\n    ----------\n    tex_file: str\n        Path to the input LateX file.\n\n    output_file: str\n        Path to the output PDF file.\n        If None, will use the same output directory as the tex_file.\n\n    output_format: str\n        Output file format. Choices: 'pdf' or 'dvi'. Default: 'pdf'\n\n    Returns\n    -------\n    return_value\n        PDFLatex command call return value.\n    \"\"\"\n    if not os.path.exists(tex_file):\n        raise IOError('Could not find file {}.'.format(tex_file))\n\n    if output_format != 'pdf' and output_format != 'dvi':\n        raise ValueError(\"Invalid output format given {}. Can only accept 'pdf' or 'dvi'.\".format(output_format))\n\n    cmd_name = 'pdflatex'\n    check_command(cmd_name)\n\n    args_strings = [cmd_name]\n    if output_file is not None:\n        args_strings += ['-output-directory=\"{}\" '.format(os.path.abspath(os.path.dirname(output_file)))]\n\n    result_dir = os.path.dirname(output_file) if output_file else os.path.dirname(tex_file)\n\n    args_strings += ['-output-format=\"{}\"'.format(output_format)]\n    args_strings += ['\"' + tex_file + '\"']\n\n    log.debug('Calling command {} with args: {}.'.format(cmd_name, args_strings))\n    ret = simple_call(args_strings)\n\n    result_file = os.path.join(result_dir, remove_ext(os.path.basename(tex_file)) + '.' + output_format)\n    if os.path.exists(result_file):\n        shutil.move(result_file, output_file)\n    else:\n        raise IOError('Could not find PDFLatex result file.')\n\n    log.debug('Cleaning *.aux and *.log files from folder {}.'.format(result_dir))\n    cleanup(result_dir, 'aux')\n    cleanup(result_dir, 'log')\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn all potential loop fusion options for the psy object provided", "response": "def options(self, my_psy):\n        '''Returns all potential loop fusion options for the psy object\n        provided'''\n        # compute options dynamically here as they may depend on previous\n        # changes to the psy tree\n        my_options = []\n        invokes = my_psy.invokes.invoke_list\n        #print \"there are {0} invokes\".format(len(invokes))\n        if self._dependent_invokes:\n            raise RuntimeError(\n                \"dependent invokes assumes fusion in one invoke might \"\n                \"affect fusion in another invoke. This is not yet \"\n                \"implemented\")\n        else:\n            # treat each invoke separately\n            for idx, invoke in enumerate(invokes):\n                print \"invoke {0}\".format(idx)\n                # iterate through each outer loop\n                for loop in invoke.schedule.loops():\n                    if loop.loop_type == \"outer\":\n                        siblings = loop.parent.children\n                        my_index = siblings.index(loop)\n                        option = []\n                        self._recurse(siblings, my_index, option, my_options,\n                                      invoke)\n\n        return my_options"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transform(geom, to_sref):\n    # If we have an envelope, assume it's in the target sref.\n    try:\n        geom = getattr(geom, 'polygon', Envelope(geom).polygon)\n    except (TypeError, ValueError):\n        pass\n    else:\n        geom.AssignSpatialReference(to_sref)\n    try:\n        geom_sref = geom.GetSpatialReference()\n    except AttributeError:\n        return transform(Geometry(geom), to_sref)\n    if geom_sref is None:\n        raise Exception('Cannot transform from unknown spatial reference')\n    # Reproject geom if necessary\n    if not geom_sref.IsSame(to_sref):\n        geom = geom.Clone()\n        geom.TransformTo(to_sref)\n    return geom", "response": "Returns a transformed Geometry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an ogr. Geometry instance optionally created from a geojson str or dict.", "response": "def Geometry(*args, **kwargs):\n    \"\"\"Returns an ogr.Geometry instance optionally created from a geojson str\n    or dict. The spatial reference may also be provided.\n    \"\"\"\n    # Look for geojson as a positional or keyword arg.\n    arg = kwargs.pop('geojson', None) or len(args) and args[0]\n    try:\n        srs = kwargs.pop('srs', None) or arg.srs.wkt\n    except AttributeError:\n        srs = SpatialReference(4326)\n    if hasattr(arg, 'keys'):\n        geom = ogr.CreateGeometryFromJson(json.dumps(arg))\n    elif hasattr(arg, 'startswith'):\n        # WKB as hexadecimal string.\n        char = arg[0] if arg else ' '\n        i = char if isinstance(char, int) else ord(char)\n        if i in (0, 1):\n            geom = ogr.CreateGeometryFromWkb(arg)\n        elif arg.startswith('{'):\n            geom = ogr.CreateGeometryFromJson(arg)\n        elif arg.startswith('<gml'):\n            geom = ogr.CreateGeometryFromGML(arg)\n        else:\n            raise ValueError('Invalid geometry value: %s' % arg)\n    elif hasattr(arg, 'wkb'):\n        geom = ogr.CreateGeometryFromWkb(bytes(arg.wkb))\n    else:\n        geom = ogr.Geometry(*args, **kwargs)\n    if geom:\n        if not isinstance(srs, SpatialReference):\n            srs = SpatialReference(srs)\n        geom.AssignSpatialReference(srs)\n    return geom"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef centroid(self):\n        return self.min_x + self.width * 0.5, self.min_y + self.height * 0.5", "response": "Returns the envelope centroid as a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexpanding this Envelope by the given Envelope or tuple.", "response": "def expand(self, other):\n        \"\"\"Expands this envelope by the given Envelope or tuple.\n\n        Arguments:\n        other -- Envelope, two-tuple, or four-tuple\n        \"\"\"\n        if len(other) == 2:\n            other += other\n        mid = len(other) // 2\n        self.ll = map(min, self.ll, other[:mid])\n        self.ur = map(max, self.ur, other[mid:])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef intersect(self, other):\n        inter = Envelope(tuple(self))\n        if inter.intersects(other):\n            mid = len(other) // 2\n            inter.ll = map(max, inter.ll, other[:mid])\n            inter.ur = map(min, inter.ur, other[mid:])\n        else:\n            inter.ll = (0, 0)\n            inter.ur = (0, 0)\n        return inter", "response": "Returns the intersection of this Envelope and other Envelope."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef intersects(self, other):\n        try:\n            return (self.min_x <= other.max_x and\n                    self.max_x >= other.min_x and\n                    self.min_y <= other.max_y and\n                    self.max_y >= other.min_y)\n        except AttributeError:\n            return self.intersects(Envelope(other))", "response": "Returns true if this envelope intersects another."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new Envelope rescaled from center by the given factor ( s ).", "response": "def scale(self, xfactor, yfactor=None):\n        \"\"\"Returns a new envelope rescaled from center by the given factor(s).\n\n        Arguments:\n        xfactor -- int or float X scaling factor\n        yfactor -- int or float Y scaling factor\n        \"\"\"\n        yfactor = xfactor if yfactor is None else yfactor\n        x, y = self.centroid\n        xshift = self.width * xfactor * 0.5\n        yshift = self.height * yfactor * 0.5\n        return Envelope(x - xshift, y - yshift, x + xshift, y + yshift)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef polygon(self):\n        ring = ogr.Geometry(ogr.wkbLinearRing)\n        for coord in self.ll, self.lr, self.ur, self.ul, self.ll:\n            ring.AddPoint_2D(*coord)\n        polyg = ogr.Geometry(ogr.wkbPolygon)\n        polyg.AddGeometryDirectly(ring)\n        return polyg", "response": "Returns an OGR Geometry for this envelope."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nimport a mass table from a file", "response": "def from_name(cls, name):\n        \"Imports a mass table from a file\"\n        filename = os.path.join(package_dir, 'data', name + '.txt')\n        return cls.from_file(filename, name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimport a mass table from a file", "response": "def from_file(cls, filename, name=''):\n        \"Imports a mass table from a file\"\n        df = pd.read_csv(filename, header=0, delim_whitespace=True, index_col=[0, 1])['M']\n        df.name = name\n        return cls(df=df, name=name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_ZNM(cls, Z, N, M, name=''):\n        df = pd.DataFrame.from_dict({'Z': Z, 'N': N, 'M': M}).set_index(['Z', 'N'])['M']\n        df.name = name\n        return cls(df=df, name=name)", "response": "Creates a new object from arrays Z N and M."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexport the contents of the AME2012 table to a file as comma separated values.", "response": "def to_file(self, path):\n        \"\"\"Export the contents to a file as comma separated values.\n\n        Parameters\n        ----------\n        path : string\n            File path where the data should be saved to\n\n        Example\n        -------\n        Export the last ten elements of AME2012 to a new file:\n\n        >>> Table('AME2012').tail(10).to_file('last_ten.txt')\n        \"\"\"\n        with open(path, 'w') as f:\n            f.write('Z   N   M\\n')\n        self.df.to_csv(path, sep='\\t', mode='a')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new Table instance with the nuclei corresponding to a condition on Z N or M.", "response": "def select(self, condition, name=''):\n        \"\"\"\n        Selects nuclei according to a condition on Z,N or M\n\n        Parameters\n        ----------\n        condition : function,\n            Can have one of the signatures f(M), f(Z,N) or f(Z, N, M)\n            must return a boolean value\n        name: string, optional name for the resulting Table\n\n        Example:\n        --------\n        Select all nuclei with A > 160:\n\n        >>> A_gt_160 = lambda Z,N: Z + N > 160\n        >>> Table('AME2003').select(A_gt_160)\n        \"\"\"\n        if condition.func_code.co_argcount == 1:\n            idx = [(Z, N) for (Z, N), M in self if condition(M)]\n        if condition.func_code.co_argcount == 2:\n            idx = [(Z, N) for (Z, N) in self.index if condition(Z, N)]\n        if condition.func_code.co_argcount == 3:\n            idx = [(Z, N) for (Z, N), M in self if condition(Z, N, M)]\n        index = pd.MultiIndex.from_tuples(idx, names=['Z', 'N'])\n        return Table(df=self.df.ix[index], name=name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a selection of the Table at positions given by nuclei", "response": "def at(self, nuclei):\n        \"\"\"Return a selection of the Table at positions given by ``nuclei``\n\n        Parameters\n        ----------\n        nuclei: list of tuples\n            A list where each element is tuple of the form (Z,N)\n\n        Example\n        -------\n        Return binding energies at magic nuclei:\n\n        >>> magic_nuclei = [(20,28), (50,50), (50,82), (82,126)]\n        >>> Table('AME2012').binding_energy.at(magic_nuclei)\n        Z   N\n        20  28      416.014215\n        50  50      825.325172\n            82     1102.876416\n        82  126    1636.486450\n        \"\"\"\n        index = pd.MultiIndex.from_tuples(nuclei, names=['Z', 'N'])\n        return Table(df=self.df.ix[index], name=self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef intersection(self, table):\n        idx = self.df.index & table.df.index\n        return Table(df=self.df[idx], name=self.name)", "response": "Returns a new Table with the nuclei which also belong to the given table."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef not_in(self, table):\n        idx = self.df.index - table.df.index\n        return Table(df=self.df[idx], name=self.name)", "response": "Returns a new Table object where the nuclei is not in table"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nselecting odd - odd nuclei from the table FRDM95.", "response": "def odd_odd(self):\n        \"\"\"Selects odd-odd nuclei from the table:\n\n        >>> Table('FRDM95').odd_odd\n        Out[13]:\n        Z   N\n        9   9       1.21\n            11      0.10\n            13      3.08\n            15      9.32\n        ...\n        \"\"\"\n        return self.select(lambda Z, N: (Z % 2) and (N % 2), name=self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new table with odd - even nuclei.", "response": "def odd_even(self):\n        \"\"\"\n        Selects odd-even nuclei from the table\n        \"\"\"\n        return self.select(lambda Z, N: (Z % 2) and not(N % 2), name=self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new table with even - odd nuclei.", "response": "def even_odd(self):\n        \"\"\"\n        Selects even-odd nuclei from the table\n        \"\"\"\n        return self.select(lambda Z, N: not(Z % 2) and (N % 2), name=self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef even_even(self):\n        return self.select(lambda Z, N: not(Z % 2) and not(N % 2), name=self.name)", "response": "Returns a new table with only even - even nuclei."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef error(self, relative_to='AME2003'):\n        df = self.df - Table(relative_to).df\n        return Table(df=df)", "response": "Calculate error difference between the mass table and the current one."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating root mean squared error of a mass table.", "response": "def rmse(self, relative_to='AME2003'):\n        \"\"\"Calculate root mean squared error\n\n        Parameters\n        ----------\n        relative_to : string,\n            a valid mass table name.\n\n        Example:\n        ----------\n        >>> template = '{0:10}|{1:^6.2f}|{2:^6.2f}|{3:^6.2f}'\n        >>> print 'Model      ', 'AME95 ', 'AME03 ', 'AME12 '  #  Table header\n        ... for name in Table.names:\n        ...     print template.format(name, Table(name).rmse(relative_to='AME1995'),\n        ...                             Table(name).rmse(relative_to='AME2003'),\n        ...                             Table(name).rmse(relative_to='AME2012'))\n        Model       AME95  AME03  AME12\n        AME2003   | 0.13 | 0.00 | 0.13\n        AME2003all| 0.42 | 0.40 | 0.71\n        AME2012   | 0.16 | 0.13 | 0.00\n        AME2012all| 0.43 | 0.43 | 0.69\n        AME1995   | 0.00 | 0.13 | 0.16\n        AME1995all| 0.00 | 0.17 | 0.21\n        DUZU      | 0.52 | 0.52 | 0.76\n        FRDM95    | 0.79 | 0.78 | 0.95\n        KTUY05    | 0.78 | 0.77 | 1.03\n        ETFSI12   | 0.84 | 0.84 | 1.04\n        HFB14     | 0.84 | 0.83 | 1.02\n        \"\"\"\n\n        error = self.error(relative_to=relative_to)\n        return math.sqrt((error.df ** 2).mean())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns binding energies instead of mass excesses", "response": "def binding_energy(self):\n        \"\"\"\n        Return binding energies instead of mass excesses\n        \"\"\"\n        M_P = 938.2723\n        # MeV\n        M_E = 0.5110\n        # MeV\n        M_N = 939.5656\n        # MeV\n        AMU = 931.494028\n        # MeV\n        df = self.Z * (M_P + M_E) + (self.A - self.Z) * M_N - (self.df + self.A * AMU)\n        return Table(df=df, name='BE' + '(' + self.name + ')')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns Q_alpha of the MeV", "response": "def q_alpha(self):\n        \"\"\"Return Q_alpha\"\"\"\n        M_ALPHA = 2.4249156         # He4 mass excess in MeV\n        f = lambda parent, daugther: parent - daugther - M_ALPHA\n        return self.derived('Q_alpha', (-2, -2), f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns Q_beta of the current object", "response": "def q_beta(self):\n        \"\"\"Return Q_beta\"\"\"\n        f = lambda parent, daugther: parent - daugther\n        return self.derived('Q_beta', (1, -1), f)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn 2 neutron separation energy", "response": "def s2n(self):\n        \"\"\"Return 2 neutron separation energy\"\"\"\n        M_N = 8.0713171         # neutron mass excess in MeV\n        f = lambda parent, daugther: -parent + daugther + 2 * M_N\n        return self.derived('s2n', (0, -2), f)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef s1n(self):\n        M_N = 8.0713171         # neutron mass excess in MeV\n        f = lambda parent, daugther: -parent + daugther + M_N\n        return self.derived('s1n', (0, -1), f)", "response": "Return 1 neutron separation energy"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn 2 proton separation energy", "response": "def s2p(self):\n        \"\"\"Return 2 proton separation energy\"\"\"\n        M_P = 7.28897050         # proton mass excess in MeV\n        f = lambda parent, daugther: -parent + daugther + 2 * M_P\n        return self.derived('s2p', (-2, 0), f)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef s1p(self):\n        M_P = 7.28897050         # proton mass excess in MeV\n        f = lambda parent, daugther: -parent + daugther + M_P\n        return self.derived('s1p', (-1, 0), f)", "response": "Return 1 proton separation energy"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef derived(self, name, relative_coords, formula):\n        relZ, relN = relative_coords\n        daughter_idx = [(x[0] + relZ, x[1] + relN) for x in self.df.index]\n        values = formula(self.df.values, self.df.loc[daughter_idx].values)\n        return Table(df=pd.Series(values, index=self.df.index, name=name + '(' + self.name + ')'))", "response": "Helper function for derived quantities"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ds2n(self):\n        idx = [(x[0] + 0, x[1] + 2) for x in self.df.index]\n        values = self.s2n.values - self.s2n.loc[idx].values\n        return Table(df=pd.Series(values, index=self.df.index, name='ds2n' + '(' + self.name + ')'))", "response": "Calculates the derivative of the neutron separation energies"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ds2p(self):\n        idx = [(x[0] + 2, x[1]) for x in self.df.index]\n        values = self.s2p.values - self.s2p.loc[idx].values\n        return Table(df=pd.Series(values, index=self.df.index, name='ds2p' + '(' + self.name + ')'))", "response": "Calculates the derivative of the neutron separation energies"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots a nuclear chart with theoretical deviation for the M\u00f6ller s model.", "response": "def chart_plot(self, ax=None, cmap='RdBu',\n               xlabel='N', ylabel='Z', grid_on=True, colorbar=True):\n        \"\"\"Plot a nuclear chart with (N,Z) as axis and the values\n        of the Table as a color scale\n\n        Parameters\n        ----------\n        ax: optional matplotlib axes\n                defaults to current axes\n        cmap: a matplotlib colormap\n                default: 'RdBu'\n        xlabel: string representing the label of the x axis\n            default: 'N'\n        ylabel: string, default: 'Z'\n            the label of the x axis\n        grid_on: boolean, default: True,\n            whether to draw the axes grid or not\n        colorbar: boolean, default: True\n            whether to draw a colorbar or not\n\n        Returns\n        -------\n        ax: a matplotlib axes object\n\n        Example\n        -------\n        Plot the theoretical deviation for the M\u00f6ller's model::\n\n        >>> Table('FRDM95').error().chart_plot()\n\n        \"\"\"\n        from matplotlib.mlab import griddata\n        from numpy import linspace, meshgrid\n        import matplotlib.pyplot as plt\n\n        # extract the 1D arrays to be plotted\n        x = self.dropna().N\n        y = self.dropna().Z\n        z = self.dropna().values\n\n        #convert to matplotlibs grid format\n        xi = linspace(min(x), max(x), max(x) - min(x) + 1)\n        yi = linspace(min(y), max(y), max(y) - min(y) + 1)\n        Z = griddata(x, y, z, xi, yi)\n        X, Y = meshgrid(xi, yi)\n\n        # create and customize plot\n        if ax is None:\n            ax = plt.gca()\n        chart = ax.pcolormesh(X, Y, Z, cmap=cmap)\n        ax.set_xlabel(xlabel)\n        ax.set_ylabel(ylabel)\n        ax.grid(grid_on)\n        ax.set_aspect('equal')\n        if colorbar:\n            plt.colorbar(chart)\n\n        return ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _uses_db(func, self, *args, **kwargs):\n    if not self.session:\n        _logger.debug('Creating new db session')\n        self._init_db_session()\n    try:\n        ret = func(self, *args, **kwargs)\n        self.session.commit()\n    except:\n        self.session.rollback()\n        tb = traceback.format_exc()\n        _logger.debug(tb)\n        raise\n    finally:\n        _logger.debug('Closing db session')\n        self.session.close()\n    return ret", "response": "Use as a decorator for operations on the database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef derive_key(self, master_password):\n        encoder = encoding.Encoder(self.charset)\n\n        bytes = ('%s:%s' % (master_password, self.name)).encode('utf8')\n\n        start_time = time.clock()\n        # we fix the scrypt parameters in case the defaults change\n        digest = scrypt.hash(bytes, self.salt, N=1<<14, r=8, p=1)\n\n        key = encoder.encode(digest, self.key_length)\n        derivation_time_in_s = time.clock() - start_time\n\n        _logger.debug('Key derivation took %.2fms', derivation_time_in_s*1000)\n        return key", "response": "Derives the key from the salt and master password."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bootstrap(self, path_or_uri):\n        _logger.debug(\"Bootstrapping new database: %s\", path_or_uri)\n        self.database_uri = _urify_db(path_or_uri)\n        db = sa.create_engine(self.database_uri)\n        Base.metadata.create_all(db)", "response": "Initialize a database.\n\n        :param database_path: The absolute path to the database to initialize."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef search(self, query):\n        results = self.session.query(Domain).filter(Domain.name.ilike('%%%s%%' % query)).all()\n        return results", "response": "Search the database for the given query. Will find partial matches."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_domain(self, domain_name):\n        protocol = self.database_uri.split(':', 1)[0]\n        if protocol in ('https', 'http'):\n            return self._get_domain_from_rest_api(domain_name)\n        else:\n            domain = self._get_domain_from_db(domain_name)\n            if domain:\n                return domain\n            else:\n                raise NoSuchDomainException", "response": "Returns the object with the given name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef modify_domain(self, domain_name, new_salt=False, username=None):\n        domain = self._get_domain_from_db(domain_name)\n        if domain is None:\n            raise NoSuchDomainException\n        if new_salt:\n            _logger.info(\"Generating new salt..\")\n            domain.new_salt()\n        if username is not None:\n            domain.username = username\n        return domain", "response": "Modify an existing domain."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new domain entry in the database.", "response": "def create_domain(self, domain_name, username=None, alphabet=Domain.DEFAULT_ALPHABET,\n            length=Domain.DEFAULT_KEY_LENGTH):\n        \"\"\" Create a new domain entry in the database.\n\n        :param username: The username to associate with this domain.\n        :param alphabet: A character set restriction to impose on keys generated for this domain.\n        :param length: The length of the generated key, in case of restrictions on the site.\n        \"\"\"\n        # Wrap the actual implementation to do some error handling\n        try:\n            return self._create_domain(domain_name, username, alphabet, length)\n        except Exception as ex:\n            _logger.warn(\"Inserting new domain failed: %s\", ex)\n            raise DuplicateDomainException"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nyield tile coordinates for a bounding box and zoom levels.", "response": "def from_bbox(bbox, zlevs):\n    \"\"\"Yields tile (x, y, z) tuples for a bounding box and zoom levels.\n\n    Arguments:\n    bbox - bounding box as a 4-length sequence\n    zlevs - sequence of tile zoom levels\n    \"\"\"\n    env = Envelope(bbox)\n    for z in zlevs:\n        corners = [to_tile(*coord + (z,)) for coord in (env.ul, env.lr)]\n        xs, ys = [range(p1, p2 + 1) for p1, p2 in zip(*corners)]\n        for coord in itertools.product(xs, ys, (z,)):\n            yield coord"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_lonlat(xtile, ytile, zoom):\n    n = 2.0 ** zoom\n    lon = xtile / n * 360.0 - 180.0\n    # Caculate latitude in radians and convert to degrees constrained from -90\n    # to 90. Values too big for tile coordinate pairs are invalid and could\n    # overflow.\n    try:\n        lat_rad = math.atan(math.sinh(math.pi * (1 - 2 * ytile / n)))\n    except OverflowError:\n        raise ValueError('Invalid tile coordinate for zoom level %d' % zoom)\n    lat = math.degrees(lat_rad)\n    return lon, lat", "response": "Converts a map tile xyz coordinate to a longitude and latitude tuple."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a longitude and latitude coordinate to a tile.", "response": "def to_tile(lon, lat, zoom):\n    \"\"\"Returns a tuple of (xtile, ytile) from a (longitude, latitude) coordinate.\n\n    See http://wiki.openstreetmap.org/wiki/Slippy_map_tilenames\n\n    Arguments:\n    lon - longitude as int or float\n    lat - latitude as int or float\n    zoom - zoom level as int or float\n    \"\"\"\n    lat_rad = math.radians(lat)\n    n = 2.0 ** zoom\n    xtile = int((lon + 180.0) / 360.0 * n)\n    ytile = int((1.0 - math.log(math.tan(lat_rad) +\n                (1 / math.cos(lat_rad))) / math.pi) / 2.0 * n)\n    return xtile, ytile"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract messages from Handlebars templates.", "response": "def extract_hbs(fileobj, keywords, comment_tags, options):\n    \"\"\"Extract messages from Handlebars templates.\n\n    It returns an iterator yielding tuples in the following form ``(lineno,\n    funcname, message, comments)``.\n\n    TODO: Things to improve:\n    --- Return comments\n    \"\"\"\n\n    server = get_pipeserver()\n    server.sendline(COMMAND+u'PARSE FILE:'+fileobj.name)\n    server.expect(RESPONSE+'SENDING OUTPUT')\n    server.expect(RESPONSE+'OUTPUT END')\n    trans_strings = server.before\n\n    for item in json.loads(trans_strings):\n        messages = [item['content']]\n        if item['funcname'] == 'ngettext':\n            messages.append(item['alt_content'])\n        yield item['line_number'],item['funcname'],tuple(messages),[]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a GDAL virtual filesystem prefixed path.", "response": "def vsiprefix(path):\n    \"\"\"Returns a GDAL virtual filesystem prefixed path.\n\n    Arguments:\n    path -- file path as str\n    \"\"\"\n    vpath = path.lower()\n    scheme = VSI_SCHEMES.get(urlparse(vpath).scheme, '')\n    for ext in VSI_TYPES:\n        if ext in vpath:\n            filesys = VSI_TYPES[ext]\n            break\n    else:\n        filesys = ''\n    if filesys and scheme:\n        filesys = filesys[:-1]\n    return ''.join((filesys, scheme, path))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the EPSG ID as int if it exists.", "response": "def srid(self):\n        \"\"\"Returns the EPSG ID as int if it exists.\"\"\"\n        epsg_id = (self.GetAuthorityCode('PROJCS') or\n                   self.GetAuthorityCode('GEOGCS'))\n        try:\n            return int(epsg_id)\n        except TypeError:\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n    args = get_args()\n    ret_code = args.target(args)\n    _logger.debug('Exiting with code %d', ret_code)\n    sys.exit(ret_code)", "response": "Entry point for the CLI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the content of a single file.", "response": "def update_file(url, filename):\n    \"\"\"Update the content of a single file.\"\"\"\n    resp = urlopen(url)\n    if resp.code != 200:\n        raise Exception('GET {} failed.'.format(url))\n    with open(_get_package_path(filename), 'w') as fp:\n        for l in resp:\n            if not l.startswith(b'#'):\n                fp.write(l.decode('utf8'))\n    print('Updated {}'.format(filename))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef available_drivers():\n    drivers = {}\n    for i in range(gdal.GetDriverCount()):\n        d = gdal.GetDriver(i)\n        drivers[d.ShortName] = d.GetMetadata()\n    return drivers", "response": "Returns a dictionary of GDAL Driver metadata keyed by the\n    ShortName attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef driver_for_path(path, drivers=None):\n    ext = (os.path.splitext(path)[1][1:] or path).lower()\n    drivers = drivers or ImageDriver.registry if ext else {}\n    for name, meta in drivers.items():\n        if ext == meta.get('DMD_EXTENSION', '').lower():\n            return ImageDriver(name)\n    return None", "response": "Returns the gdal. Driver for a path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef geom_to_array(geom, size, affine):\n    driver = ImageDriver('MEM')\n    rast = driver.raster(driver.ShortName, size)\n    rast.affine = affine\n    rast.sref = geom.GetSpatialReference()\n    with MemoryLayer.from_records([(1, geom)]) as ml:\n        status = gdal.RasterizeLayer(rast.ds, (1,), ml.layer, burn_values=(1,))\n    arr = rast.array()\n    rast.close()\n    return arr", "response": "Converts an OGR polygon to a 2D NumPy array."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rasterize(layer, rast):\n    driver = ImageDriver('MEM')\n    r2 = driver.raster(driver.ShortName, rast.size)\n    r2.affine = rast.affine\n    sref = rast.sref\n    if not sref.srid:\n        sref = SpatialReference(4326)\n    r2.sref = sref\n    ml = MemoryLayer(sref, layer.GetGeomType())\n    ml.load(layer)\n    status = gdal.RasterizeLayer(\n        r2.ds, (1,), ml.layer, options=['ATTRIBUTE=%s' % ml.id])\n    ml.close()\n    return r2", "response": "Returns a Raster from a Layer features."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open(path, mode=gdalconst.GA_ReadOnly):\n    path = getattr(path, 'name', path)\n    try:\n        return Raster(vsiprefix(path), mode)\n    except AttributeError:\n        try:\n            imgdata = path.read()\n        except AttributeError:\n            raise TypeError('Not a file-like object providing read()')\n        else:\n            imgio = MemFileIO(delete=False)\n            gdal.FileFromMemBuffer(imgio.name, imgdata)\n            return Raster(imgio, mode)\n    raise ValueError('Failed to open raster from \"%r\"' % path)", "response": "Returns a Raster instance from a local or remote path as str or file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef frombytes(data, size, bandtype=gdal.GDT_Byte):\n    r = ImageDriver('MEM').raster('', size, bandtype)\n    r.frombytes(data)\n    return r", "response": "Returns an in - memory raster initialized from a byte buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts image pixel coordinates to georeferenced x / y", "response": "def project(self, coords):\n        \"\"\"Convert image pixel/line coordinates to georeferenced x/y, return a\n        generator of two-tuples.\n\n        Arguments:\n        coords -- input coordinates as iterable containing two-tuples/lists\n        such as ((0, 0), (10, 10))\n        \"\"\"\n        geotransform = self.tuple\n        for x, y in coords:\n            geo_x = geotransform[0] + geotransform[1] * x + geotransform[2] * y\n            geo_y = geotransform[3] + geotransform[4] * x + geotransform[5] * y\n            # Move the coordinate to the center of the pixel.\n            geo_x += geotransform[1] / 2.0\n            geo_y += geotransform[5] / 2.0\n            yield geo_x, geo_y"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transform(self, coords):\n        # Use local vars for better performance here.\n        origin_x, origin_y = self.origin\n        sx, sy = self.scale\n        return [(int(math.floor((x - origin_x) / sx)),\n                 int(math.floor((y - origin_y) / sy)))\n                for x, y in coords]", "response": "Transform from projection coordinates ( Xp Yp ) space to pixel / line raster space based on the provided geotransformation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncopy a source Raster instance to a destination Raster instance.", "response": "def copy(self, source, dest):\n        \"\"\"Returns a copied Raster instance.\n\n        Arguments:\n        source -- the source Raster instance or filepath as str\n        dest -- destination filepath as str\n        \"\"\"\n        if not self.copyable:\n            raise IOError('Driver does not support raster copying')\n        if not isinstance(source, Raster):\n            source = Raster(source)\n            should_close = True\n        else:\n            should_close = False\n        if source.name == dest:\n            raise ValueError(\n                'Input and output are the same location: %s' % source.name)\n        settings = driverdict_tolist(self.settings)\n        ds = self.CreateCopy(dest, source.ds, self.strictmode,\n                             options=settings)\n        if should_close:\n            source.close()\n        return Raster(ds)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling Driver. Create with optionally provided creation options as dict falls back to driver specific defaults.", "response": "def Create(self, *args, **kwargs):\n        \"\"\"Calls Driver.Create() with optionally provided creation options as\n        dict, or falls back to driver specific defaults.\n        \"\"\"\n        if not self.writable:\n            raise IOError('Driver does not support raster creation')\n        options = kwargs.pop('options', {})\n        kwargs['options'] = driverdict_tolist(options or self.settings)\n        return self._driver.Create(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a dict of driver specific raster creation options.", "response": "def options(self):\n        \"\"\"Returns a dict of driver specific raster creation options.\n\n        See GDAL format docs at http://www.gdal.org/formats_list.html\n        \"\"\"\n        if self._options is None:\n            try:\n                elem = ET.fromstring(\n                    self.info.get('DMD_CREATIONOPTIONLIST', ''))\n            except ET.ParseError:\n                elem = []\n            opts = {}\n            for child in elem:\n                choices = [val.text for val in child]\n                if choices:\n                    child.attrib.update(choices=choices)\n                opts[child.attrib.pop('name')] = child.attrib\n            self._options = opts\n        return self._options"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new raster file.", "response": "def raster(self, path, size, bandtype=gdal.GDT_Byte):\n        \"\"\"Returns a new Raster instance.\n\n        gdal.Driver.Create() does not support all formats.\n\n        Arguments:\n        path -- file object or path as str\n        size -- two or three-tuple of (xsize, ysize, bandcount)\n        bandtype -- GDAL pixel data type\n        \"\"\"\n        path = getattr(path, 'name', path)\n        try:\n            is_multiband = len(size) > 2\n            nx, ny, nbands = size if is_multiband else size + (1,)\n        except (TypeError, ValueError) as exc:\n            exc.args = ('Size must be 2 or 3-item sequence',)\n            raise\n        if nx < 1 or ny < 1:\n            raise ValueError('Invalid raster size %s' % (size,))\n        # Do not write to a non-empty file.\n        if not self._is_empty(path):\n            raise IOError('%s already exists, open with Raster()' % path)\n        ds = self.Create(path, nx, ny, nbands, bandtype)\n        if not ds:\n            raise ValueError(\n                'Could not create %s using %s' % (path, str(self)))\n        return Raster(ds)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the affine transformation.", "response": "def SetGeoTransform(self, affine):\n        \"\"\"Sets the affine transformation.\n\n        Intercepts the gdal.Dataset call to ensure use as a property setter.\n\n        Arguments:\n        affine -- AffineTransform or six-tuple of geotransformation values\n        \"\"\"\n        if isinstance(affine, collections.Sequence):\n            affine = AffineTransform(*affine)\n        self._affine = affine\n        self.ds.SetGeoTransform(affine)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef array(self, envelope=()):\n        args = ()\n        if envelope:\n            args = self.get_offset(envelope)\n        return self.ds.ReadAsArray(*args)", "response": "Returns an NDArray optionally subset by spatial envelope."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the minimum bounding rectangle as a tuple of min X max Y min X max Y.", "response": "def envelope(self):\n        \"\"\"Returns the minimum bounding rectangle as a tuple of min X, min Y,\n        max X, max Y.\n        \"\"\"\n        if self._envelope is None:\n            origin = self.affine.origin\n            ur_x = origin[0] + self.ds.RasterXSize * self.affine.scale[0]\n            ll_y = origin[1] + self.ds.RasterYSize * self.affine.scale[1]\n            self._envelope = Envelope(origin[0], ll_y, ur_x, origin[1])\n        return self._envelope"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_offset(self, envelope):\n        if isinstance(envelope, collections.Sequence):\n            envelope = Envelope(envelope)\n        if not (self.envelope.contains(envelope) or\n                self.envelope.intersects(envelope)):\n            raise ValueError('Envelope does not intersect with this extent')\n        coords = self.affine.transform((envelope.ul, envelope.lr))\n        nxy = [(min(dest, size) - origin) or 1\n               for size, origin, dest in zip(self.size, *coords)]\n        return coords[0] + tuple(nxy)", "response": "Returns a 4 - tuple pixel window offset tuple or Envelope."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the underlying ImageDriver instance.", "response": "def driver(self):\n        \"\"\"Returns the underlying ImageDriver instance.\"\"\"\n        if self._driver is None:\n            self._driver = ImageDriver(self.ds.GetDriver())\n        return self._driver"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nderiving new Raster instances.", "response": "def new(self, size=(), affine=None):\n        \"\"\"Derive new Raster instances.\n\n        Keyword args:\n        size -- tuple of image size (width, height)\n        affine -- AffineTransform or six-tuple of geotransformation values\n        \"\"\"\n        size = size or self.size + (len(self),)\n        band = self.ds.GetRasterBand(1)\n        driver = ImageDriver('MEM')\n        rcopy = driver.raster(driver.ShortName, size, band.DataType)\n        rcopy.sref = self.GetProjection()\n        rcopy.affine = affine or tuple(self.affine)\n        colors = band.GetColorTable()\n        for outband in rcopy:\n            if self.nodata is not None:\n                outband.SetNoDataValue(self.nodata)\n            if colors:\n                outband.SetColorTable(colors)\n        return rcopy"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a MaskedArray using nodata values.", "response": "def masked_array(self, geometry=None):\n        \"\"\"Returns a MaskedArray using nodata values.\n\n        Keyword args:\n        geometry -- any geometry, envelope, or coordinate extent tuple\n        \"\"\"\n        if geometry is None:\n            return self._masked_array()\n        geom = transform(geometry, self.sref)\n        env = Envelope.from_geom(geom).intersect(self.envelope)\n        arr = self._masked_array(env)\n        if geom.GetGeometryType() != ogr.wkbPoint:\n            dims = self.get_offset(env)[2:]\n            affine = AffineTransform(*tuple(self.affine))\n            affine.origin = env.ul\n            mask = ~np.ma.make_mask(geom_to_array(geom, dims, affine))\n            arr.mask = arr.mask | mask\n        return arr"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nodata(self):\n        if self._nodata is None:\n            self._nodata = self[0].GetNoDataValue()\n        return self._nodata", "response": "Returns read only property for band nodata value assuming single\n        band rasters for now."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ReadRaster(self, *args, **kwargs):\n        args = args or (0, 0, self.ds.RasterXSize, self.ds.RasterYSize)\n        return self.ds.ReadRaster(*args, **kwargs)", "response": "Reads a raster from the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resample(self, size, interpolation=gdalconst.GRA_NearestNeighbour):\n        # Find the scaling factor for pixel size.\n        factors = (size[0] / float(self.RasterXSize),\n                   size[1] / float(self.RasterYSize))\n        affine = AffineTransform(*tuple(self.affine))\n        affine.scale = (affine.scale[0] / factors[0],\n                        affine.scale[1] / factors[1])\n        dest = self.new(size, affine)\n        # Uses self and dest projection when set to None\n        gdal.ReprojectImage(self.ds, dest.ds, None, None, interpolation)\n        return dest", "response": "Resample the image to the specified size."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves this instance to the path and format provided.", "response": "def save(self, to, driver=None):\n        \"\"\"Save this instance to the path and format provided.\n\n        Arguments:\n        to -- output path as str, file, or MemFileIO instance\n        Keyword args:\n        driver -- GDAL driver name as string or ImageDriver\n        \"\"\"\n        path = getattr(to, 'name', to)\n        if not driver and hasattr(path, 'encode'):\n            driver = driver_for_path(path, self.driver.filter_copyable())\n        elif hasattr(driver, 'encode'):\n            driver = ImageDriver(driver)\n        if driver is None or not driver.copyable:\n            raise ValueError('Copy supporting driver not found for %s' % path)\n        driver.copy(self, path).close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef SetProjection(self, sref):\n        if not hasattr(sref, 'ExportToWkt'):\n            sref = SpatialReference(sref)\n        self._sref = sref\n        self.ds.SetProjection(sref.ExportToWkt())", "response": "Sets the spatial reference to use as a property setter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shape(self):\n        shp = (self.ds.RasterYSize, self.ds.RasterXSize, self.ds.RasterCount)\n        return shp[:2] if shp[2] <= 1 else shp", "response": "Returns a tuple of row column band count if multidimensional."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef warp(self, to_sref, dest=None, interpolation=gdalconst.GRA_NearestNeighbour):\n        if not hasattr(to_sref, 'ExportToWkt'):\n            to_sref = SpatialReference(to_sref)\n        dest_wkt = to_sref.ExportToWkt()\n        dtype = self[0].DataType\n        err_thresh = 0.125\n        # Determine new values for destination raster dimensions and\n        # geotransform.\n        vrt = gdal.AutoCreateWarpedVRT(self.ds, None, dest_wkt,\n                                       interpolation, err_thresh)\n        if vrt is None:\n            raise ValueError('Could not warp %s to %s' % (self, dest_wkt))\n        warpsize = (vrt.RasterXSize, vrt.RasterYSize, len(self))\n        warptrans = vrt.GetGeoTransform()\n        vrt = None\n        if dest is None:\n            imgio = MemFileIO()\n            rwarp = self.driver.raster(imgio, warpsize, dtype)\n            imgio.close()\n        else:\n            rwarp = self.driver.raster(dest, warpsize, dtype)\n        rwarp.SetGeoTransform(warptrans)\n        rwarp.SetProjection(to_sref)\n        if self.nodata is not None:\n            for band in rwarp:\n                band.SetNoDataValue(self.nodata)\n                band = None\n        # Uses self and rwarp projection when set to None\n        gdal.ReprojectImage(self.ds, rwarp.ds, None, None, interpolation)\n        return rwarp", "response": "Warp the image to a new location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the ideal conversion ratio for the given alphabet.", "response": "def calc_chunklen(alph_len):\n    '''\n    computes the ideal conversion ratio for the given alphabet.\n    A ratio is considered ideal when the number of bits in one output\n    encoding chunk that don't add up to one input encoding chunk is minimal.\n    '''\n    binlen, enclen = min([\n                          (i, i*8 / math.log(alph_len, 2))\n                          for i in range(1, 7)\n                         ], key=lambda k: k[1] % 1)\n\n    return binlen, int(enclen)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lookup_alphabet(charset):\n    '''\n    retrieves a named charset or treats the input as a custom alphabet and use that\n    '''\n    if charset in PRESETS:\n        return PRESETS[charset]\n    if len(charset) < 16:\n        _logger.warning('very small alphabet in use, possibly a failed lookup?')\n    return charset", "response": "Returns a named alphabet or treats the input as a custom alphabet and use that alphabet if it is not already there."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _encode_chunk(self, data, index):\n        '''\n        gets a chunk from the input data, converts it to a number and\n        encodes that number\n        '''\n        chunk = self._get_chunk(data, index)\n        return self._encode_long(self._chunk_to_long(chunk))", "response": "Encodes a single chunk from the input data converts it to a number and returns that number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _encode_long(self, val):\n        '''\n        encodes an integer of 8*self.chunklen[0] bits using the specified\n        alphabet\n        '''\n        return ''.join([\n                self.alphabet[(val//len(self.alphabet)**i) % len(self.alphabet)]\n                for i in reversed(range(self.chunklen[1]))\n            ])", "response": "Encodes an integer of 8 * self. chunklen [ 0 ] bits using the specified\n clf alphabet"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a chunk of bytes to integer using big - endian representation", "response": "def _chunk_to_long(self, chunk):\n        '''\n        parses a chunk of bytes to integer using big-endian representation\n        '''\n        return sum([\n                256**(self.chunklen[0]-1-i) * ord_byte(chunk[i])\n                for i in range(self.chunklen[0])\n            ])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_chunk(self, data, index):\n        '''\n        partition the data into chunks and retrieve the chunk at the given index\n        '''\n        return data[index*self.chunklen[0]:(index+1)*self.chunklen[0]]", "response": "partition the data into chunks and retrieve the chunk at the given index"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef memoize(func):\n    cache = {}\n\n    @wraps(func)\n    def inner(filename):\n        if filename not in cache:\n            cache[filename] = func(filename)\n        return cache[filename]\n    return inner", "response": "Cache result of function call."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a list of patterns from a file and make a regular expression.", "response": "def _regexp(filename):\n    \"\"\"Get a list of patterns from a file and make a regular expression.\"\"\"\n    lines = _get_resource_content(filename).decode('utf-8').splitlines()\n    return re.compile('|'.join(lines))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nnormalize the given date format.", "response": "def normalize_date_format(date):\n    '''\n    Dates can be defined in many ways, but zipline use\n    aware datetime objects only. Plus, the software work\n    with utc timezone so we convert it.\n    '''\n    if isinstance(date, int):\n        # This is probably epoch time\n        date = time.strftime('%Y-%m-%d %H:%M:%S',\n                             time.localtime(date))\n\n    # assert isinstance(date, str) or isinstance(date, unicode)\n    if isinstance(date, str) or isinstance(date, unicode):\n        date = dateutil.parser.parse(date)\n    if not date.tzinfo:\n        local_tz = pytz.timezone(_detect_timezone())\n        local_dt = local_tz.localize(date, is_dst=None)\n        # TODO I'm not sure why and when I need to add a date to make it right\n        date = local_dt.astimezone(pytz.utc) + pd.datetools.day\n\n    return date"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetect timezone as set by the system", "response": "def _detect_timezone():\n    '''\n    Get timezone as set by the system\n    '''\n    default_timezone = 'America/New_York'\n    locale_code = locale.getdefaultlocale()\n    return default_timezone if not locale_code[0] else \\\n        str(pytz.country_timezones[locale_code[0][-2:]][0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the full url for the given resource.", "response": "def api_url(full_version, resource):\n    '''\n    >>> # Harmonize api endpoints\n    >>> # __version__ should be like major.minor.fix\n    >>> from my_app import __version__\n    >>> api_url(__version__, '/some/endpoint')\n    /v0/some/endpoint\n    '''\n    return '/v{}/{}'.format(dna.utils.Version(full_version).major, resource)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap api endpoints with more details", "response": "def api_doc(full_version, resource, method='GET', **kwargs):\n    '''\n    >>> # Wrap api endpoints with more details\n    >>> api_doc('/resource', secure=True, key='value')\n    GET /resource?secure=true&key=value\n    '''\n    doc = '{} {}'.format(method, api_url(full_version, resource))\n    params = '&'.join(['{}={}'.format(k, v) for k, v in kwargs.iteritems()])\n    if params:\n        doc = '?'.join([doc, params])\n    return doc"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the model properties as a dict", "response": "def to_dict(self):\n        \"\"\"\n        Returns the model properties as a dict\n        \"\"\"\n        result = {}\n\n        for attr, _ in iteritems(self.swagger_types):\n            value = getattr(self, attr)\n            if isinstance(value, list):\n                result[attr] = list(map(\n                    lambda x: x.to_dict() if hasattr(x, \"to_dict\") else x,\n                    value\n                ))\n            elif hasattr(value, \"to_dict\"):\n                result[attr] = value.to_dict()\n            else:\n                result[attr] = value\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef activate_pdb_hook():\n    ''' Catch exceptions with a prompt for post-mortem analyzis'''\n    def debug_exception(type_exception, value, tb):\n        import pdb\n        pdb.post_mortem(tb)\n\n    import sys\n    sys.excepthook = debug_exception", "response": "Activate the exception hook in sys. excepthook."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef listcoins(self):\n        '''\n        Use this function to list all coins with their data which are available on cryptocoincharts.\n        Usage: http://api.cryptocoincharts.info/listCoins\n        '''\n        url = self.API_PATH + 'listCoins'\n        \n        json_data = json.loads(self._getdata(url))\n        \n        coins = []\n        for entry in json_data:\n            coin = Coin()\n            coin.id = entry['id']\n            coin.name = entry['name']\n            coin.website = entry['website']\n            coin.price_btc = entry['price_btc']\n            coin.volume_btc = entry['volume_btc']\n            coins.append(coin)\n        \n        return coins", "response": "This function returns a list of all coins with their data which are available on cryptocoincharts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nuse this function to query price and volume data for ONE trading pair. A list with all coin currencies can be found by using the listcoins method. A example pair: currency1_currency2 = \"doge_btc\" Usage: http://api.cryptocoincharts.info/tradingPair/[currency1_currency2]", "response": "def tradingpair(self, pair):\n        '''\n        Use this function to query price and volume data for ONE trading pair.\n        A list with all coin currencies can be found by using the listcoins method.\n        A example pair: currency1_currency2 = \"doge_btc\" \n        Usage: http://api.cryptocoincharts.info/tradingPair/[currency1_currency2]\n        '''\n        url = self.API_PATH + 'tradingPair/' + pair\n        \n        json_data = json.loads(self._getdata(url))\n        \n        tradingpair = TradingPair()\n        tradingpair.id = json_data['id']\n        tradingpair.price = json_data['price']\n        tradingpair.price_before_24h = json_data['price_before_24h']\n        tradingpair.volume_first = json_data['volume_first']\n        tradingpair.volume_second = json_data['volume_second']\n        tradingpair.volume_btc = json_data['volume_btc']\n        tradingpair.best_market = json_data['best_market']\n        tradingpair.latest_trade = json_data['latest_trade']\n\n        return tradingpair"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuses this function to query price and volume data for MANY trading pairs. Usage: http://api.cryptocoincharts.info/tradingPairs/[currency1_currency2,currency2_currency3,...] A example pair: currency1_currency2 = \"doge_btc\" currency2_currency3 = \"btc_eur\" http://api.cryptocoincharts.info/tradingPairs/\"doge_btc,btc_eur\"", "response": "def tradingpairs(self, pairs):\n        '''\n        Use this function to query price and volume data for MANY trading pairs.\n        Usage: http://api.cryptocoincharts.info/tradingPairs/[currency1_currency2,currency2_currency3,...]\n               A example pair: currency1_currency2 = \"doge_btc\"\n                               currency2_currency3 = \"btc_eur\"\n               http://api.cryptocoincharts.info/tradingPairs/\"doge_btc,btc_eur\"            \n        '''\n        url = self.API_PATH + 'tradingPairs/'\n        data = { 'pairs':pairs }\n        \n        json_data = json.loads(self._getdata(url, data))\n        \n        tradingpairs = []\n        for entry in json_data:\n            tradingpair = TradingPair()\n            tradingpair.id = entry['id']\n            tradingpair.price = entry['price']\n            tradingpair.price_before_24h = entry['price_before_24h']\n            tradingpair.volume_first = entry['volume_first']\n            tradingpair.volume_second = entry['volume_second']\n            tradingpair.volume_btc = entry['volume_btc']\n            tradingpair.best_market = entry['best_market']\n            tradingpair.latest_trade = entry['latest_trade']\n            tradingpairs.append(tradingpair)\n        \n        return tradingpairs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _getdata(self, url, data = \"\"):\n        '''\n        Wrapper method\n        '''\n        request = Request(url)\n        \n        if data != \"\":\n            request = Request(url, urlencode(data))\n            \n        try:\n            response = urlopen(request)\n        except HTTPError as e:\n            print('The Server couldn\\'t fulfill the request.')\n            print('Error code: ', e.code)\n        except URLError as e:\n            print('We failed to reach a server.')\n            print('Reason: ', e.code)\n        else:\n            # Everything is fine.\n            return response.read()", "response": "Wrapper method for getdata"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling the jobs from the master and executes them and returns a response.", "response": "async def handle_jobs(job_handler, host, port, *, loop):\n    \"\"\"\n    Connects to the remote master and continuously receives calls, executes\n    them, then returns a response until interrupted.\n    \"\"\"\n\n    try:\n\n        try:\n            reader, writer = await asyncio.open_connection(host, port, loop=loop)\n        except OSError:\n            logging.error(\"worker could not connect to server\")\n            return\n\n        while True:\n\n            try:\n                call_encoded = await reader.readuntil(b\"\\n\")\n            except (asyncio.IncompleteReadError, ConnectionResetError):\n                break\n            logging.debug(\"worker got call\")\n            call_json = call_encoded.decode(\"utf-8\")\n            call = json.loads(call_json)\n\n            response = job_handler(call)\n\n            response_json = json.dumps(response) + \"\\n\"\n            response_encoded = response_json.encode(\"utf-8\")\n            writer.write(response_encoded)\n            logging.debug(\"worker returned response\")\n\n    except KeyboardInterrupt:\n\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart an asyncio event loop to connect to the master and run jobs.", "response": "def worker_main(job_handler, host, port):\n    \"\"\"\n    Starts an asyncio event loop to connect to the master and run jobs.\n    \"\"\"\n\n    loop = asyncio.new_event_loop()\n    asyncio.set_event_loop(None)\n    loop.run_until_complete(handle_jobs(job_handler, host, port, loop=loop))\n    loop.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_worker_pool(job_handler, host=\"localhost\", port=48484,\n                      *, max_workers=None):\n    \"\"\"\n    Runs a pool of workers which connect to a remote HighFive master and begin\n    executing calls.\n    \"\"\"\n\n    if max_workers is None:\n        max_workers = multiprocessing.cpu_count()\n\n    processes = []\n    for _ in range(max_workers):\n        p = multiprocessing.Process(target=worker_main,\n                args=(job_handler, host, port))\n        p.start()\n        processes.append(p)\n\n    logger.debug(\"workers started\")\n\n    for p in processes:\n        p.join()\n\n    logger.debug(\"all workers completed\")", "response": "Runs a pool of workers which connect to a remote HighFive master and begin executing calls."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the classification of this CompanyDetailCompany.", "response": "def classification(self, classification):\n        \"\"\"\n        Sets the classification of this CompanyDetailCompany.\n        Classification of Company\n\n        :param classification: The classification of this CompanyDetailCompany.\n        :type: str\n        \"\"\"\n        allowed_values = [\"Public Limited Indian Non-Government Company\", \"Private Limited Indian Non-Government Company\", \"One Person Company\", \"Private Limited Foreign Company Incorporated in India\", \"Public Limited Foreign Company Incorporated in India\", \"Union Government Company\", \"State Government Company\", \"Guarantee & Association Public\", \"Guarantee & Association Private\", \"Not For Profit Company\", \"Unlimited Liabilities Public\", \"Unlimited Liabilities Private\", \"Undefined\"]\n        if classification not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `classification`, must be one of {0}\"\n                .format(allowed_values)\n            )\n        self._classification = classification"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _send_message(self, msg):\n        LWLink.the_queue.put_nowait(msg)\n        if LWLink.thread is None or not LWLink.thread.isAlive():\n            LWLink.thread = Thread(target=self._send_queue)\n            LWLink.thread.start()", "response": "Add a message to the queue and start processing the queue."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nturning on the light.", "response": "def turn_on_light(self, device_id, name):\n        \"\"\"Create the message to turn light on.\"\"\"\n        msg = \"!%sFdP32|Turn On|%s\" % (device_id, name)\n        self._send_message(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef turn_on_switch(self, device_id, name):\n        msg = \"!%sF1|Turn On|%s\" % (device_id, name)\n        self._send_message(msg)", "response": "Turn on switch on."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nturning on with the given brightness.", "response": "def turn_on_with_brightness(self, device_id, name, brightness):\n        \"\"\"Scale brightness from 0..255 to 1..32.\"\"\"\n        brightness_value = round((brightness * 31) / 255) + 1\n        # F1 = Light on and F0 = light off. FdP[0..32] is brightness. 32 is\n        # full. We want that when turning the light on.\n        msg = \"!%sFdP%d|Lights %d|%s\" % (\n            device_id, brightness_value, brightness_value, name)\n        self._send_message(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nturns light or switch off.", "response": "def turn_off(self, device_id, name):\n        \"\"\"Create the message to turn light or switch off.\"\"\"\n        msg = \"!%sF0|Turn Off|%s\" % (device_id, name)\n        self._send_message(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _send_queue(self):\n        while not LWLink.the_queue.empty():\n            self._send_reliable_message(LWLink.the_queue.get_nowait())", "response": "Process the queue and send the messages."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _send_reliable_message(self, msg):\n        result = False\n        max_retries = 15\n        trans_id = next(LWLink.transaction_id)\n        msg = \"%d,%s\" % (trans_id, msg)\n        try:\n            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) \\\n                    as write_sock, \\\n                    socket.socket(socket.AF_INET, socket.SOCK_DGRAM) \\\n                    as read_sock:\n                write_sock.setsockopt(\n                    socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n                read_sock.setsockopt(socket.SOL_SOCKET,\n                                     socket.SO_BROADCAST, 1)\n                read_sock.settimeout(self.SOCKET_TIMEOUT)\n                read_sock.bind(('0.0.0.0', self.RX_PORT))\n                while max_retries:\n                    max_retries -= 1\n                    write_sock.sendto(msg.encode(\n                        'UTF-8'), (LWLink.link_ip, self.TX_PORT))\n                    result = False\n                    while True:\n                        response, dummy = read_sock.recvfrom(1024)\n                        response = response.decode('UTF-8')\n                        if \"Not yet registered.\" in response:\n                            _LOGGER.error(\"Not yet registered\")\n                            self.register()\n                            result = True\n                            break\n\n                        if response.startswith(\"%d,OK\" % trans_id):\n                            result = True\n                            break\n                        if response.startswith(\"%d,ERR\" % trans_id):\n                            _LOGGER.error(response)\n                            break\n\n                        _LOGGER.info(response)\n\n                    if result:\n                        break\n\n                    time.sleep(0.25)\n\n        except socket.timeout:\n            _LOGGER.error(\"LW broker timeout!\")\n            return result\n\n        except Exception as ex:\n            _LOGGER.error(ex)\n            raise\n\n        if result:\n            _LOGGER.info(\"LW broker OK!\")\n        else:\n            _LOGGER.error(\"LW broker fail!\")\n        return result", "response": "Send a message to LightwaveRF hub."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a CMPH capable adapter for the given object.", "response": "def create_adapter(cmph, ffi, obj):\n    \"\"\" Generates a wrapped adapter for the given object\n\n    Parameters\n    ----------\n    obj : list, buffer, array, or file\n\n    Raises\n    ------\n    ValueError\n        If presented with an object that cannot be adapted\n\n    Returns\n    -------\n    CMPH capable adapter\n    \"\"\"\n\n    # if arraylike and fixed unit size\n    # if file\n    # if buffer\n\n    if is_file_location(obj):\n        # The FP is captured for GC reasons inside the dtor closure\n        # pylint: disable=invalid-name\n        fd = open(obj)\n        adapter = cmph.cmph_io_nlfile_adapter(fd)\n\n        def dtor():\n            cmph.cmph_io_nlfile_adapter_destroy(adapter)\n            fd.close()\n\n        # pylint: enable=invalid-name\n        return _AdapterCxt(adapter, dtor)\n    elif is_file(obj):\n        adapter = cmph.cmph_io_nlfile_adapter(obj)\n        dtor = lambda: cmph.cmph_io_nlfile_adapter_destroy(adapter)\n        return _AdapterCxt(adapter, dtor)\n    elif isinstance(obj, Sequence):\n        if len(obj) == 0:\n            raise ValueError(\"An empty sequence is already a perfect hash!\")\n        return _create_pyobj_adapter(cmph, ffi, obj)\n    else:\n        raise ValueError(\"data cannot have a cmph wrapper generated\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nature(self, nature):\n        allowed_values = [\"STANDALONE\"]\n        if nature not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `nature`, must be one of {0}\"\n                .format(allowed_values)\n            )\n        self._nature = nature", "response": "Sets the nature of this YearlyFinancials."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef computed_displaywidth():\n    '''Figure out a reasonable default with. Use os.environ['COLUMNS'] if possible,\n    and failing that use 80.\n    '''\n    try:\n        width = int(os.environ['COLUMNS'])\n    except (KeyError, ValueError):\n        width = get_terminal_size().columns\n\n    return width or 80", "response": "Figure out a reasonable default with. Use os. environ. COLUMNS or get_terminal_size. columns otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef columnize(array, displaywidth=80, colsep = '  ',\n              arrange_vertical=True, ljust=True, lineprefix='',\n              opts={}):\n    \"\"\"Return a list of strings as a compact set of columns arranged\n    horizontally or vertically.\n\n    For example, for a line width of 4 characters (arranged vertically):\n        ['1', '2,', '3', '4'] => '1  3\\n2  4\\n'\n\n    or arranged horizontally:\n        ['1', '2,', '3', '4'] => '1  2\\n3  4\\n'\n\n    Each column is only as wide as necessary.  By default, columns are\n    separated by two spaces - one was not legible enough. Set \"colsep\"\n    to adjust the string separate columns. Set `displaywidth' to set\n    the line width.\n\n    Normally, consecutive items go down from the top to bottom from\n    the left-most column to the right-most. If \"arrange_vertical\" is\n    set false, consecutive items will go across, left to right, top to\n    bottom.\"\"\"\n    if not isinstance(array, (list, tuple)):\n        raise TypeError((\n            'array needs to be an instance of a list or a tuple'))\n\n    o = {}\n    if len(opts.keys()) > 0:\n        for key in default_opts.keys():\n            o[key] = get_option(key, opts)\n            pass\n        if o['arrange_array']:\n            o['array_prefix'] = '['\n            o['lineprefix']   = ' '\n            o['linesuffix']   = \",\\n\"\n            o['array_suffix'] = \"]\\n\"\n            o['colsep']       = ', '\n            o['arrange_vertical'] = False\n            pass\n\n    else:\n        o = default_opts.copy()\n        o['displaywidth']     = displaywidth\n        o['colsep']           = colsep\n        o['arrange_vertical'] = arrange_vertical\n        o['ljust']            = ljust\n        o['lineprefix']       = lineprefix\n        pass\n\n    # if o['ljust'] is None:\n    #     o['ljust'] = !(list.all?{|datum| datum.kind_of?(Numeric)})\n    #     pass\n\n    if o['colfmt']:\n        array = [(o['colfmt'] % i) for i in array]\n    else:\n        array = [str(i) for i in array]\n        pass\n\n    # Some degenerate cases\n    size = len(array)\n    if 0 == size:\n        return \"<empty>\\n\"\n    elif size == 1:\n        return '%s%s%s\\n' % (o['array_prefix'], str(array[0]),\n                             o['array_suffix'])\n\n    o['displaywidth'] = max(4, o['displaywidth'] - len(o['lineprefix']))\n    if o['arrange_vertical']:\n        array_index = lambda nrows, row, col: nrows*col + row\n        # Try every row count from 1 upwards\n        for nrows in range(1, size+1):\n            ncols = (size+nrows-1) // nrows\n            colwidths = []\n            totwidth = -len(o['colsep'])\n            for col in range(ncols):\n                # get max column width for this column\n                colwidth = 0\n                for row in range(nrows):\n                    i = array_index(nrows, row, col)\n                    if i >= size: break\n                    x = array[i]\n                    colwidth = max(colwidth, len(x))\n                    pass\n                colwidths.append(colwidth)\n                totwidth += colwidth + len(o['colsep'])\n                if totwidth > o['displaywidth']:\n                    break\n                pass\n            if totwidth <= o['displaywidth']:\n                break\n            pass\n        # The smallest number of rows computed and the\n        # max widths for each column has been obtained.\n        # Now we just have to format each of the\n        # rows.\n        s = ''\n        for row in range(nrows):\n            texts = []\n            for col in range(ncols):\n                i = row + nrows*col\n                if i >= size:\n                    x = \"\"\n                else:\n                    x = array[i]\n                texts.append(x)\n            while texts and not texts[-1]:\n                del texts[-1]\n            for col in range(len(texts)):\n                if o['ljust']:\n                    texts[col] = texts[col].ljust(colwidths[col])\n                else:\n                    texts[col] = texts[col].rjust(colwidths[col])\n                    pass\n                pass\n            s += \"%s%s%s\" % (o['lineprefix'], str(o['colsep'].join(texts)),\n                             o['linesuffix'])\n            pass\n        return s\n    else:\n        array_index = lambda ncols, row, col: ncols*(row-1) + col\n        # Try every column count from size downwards\n        colwidths = []\n        for ncols in range(size, 0, -1):\n            # Try every row count from 1 upwards\n            min_rows = (size+ncols-1) // ncols\n            nrows = min_rows -1\n            while nrows < size:\n                nrows += 1\n                rounded_size = nrows * ncols\n                colwidths = []\n                totwidth  = -len(o['colsep'])\n                for col in range(ncols):\n                    # get max column width for this column\n                    colwidth  = 0\n                    for row in range(1, nrows+1):\n                        i = array_index(ncols, row, col)\n                        if i >= rounded_size: break\n                        elif i < size:\n                            x = array[i]\n                            colwidth = max(colwidth, len(x))\n                            pass\n                        pass\n                    colwidths.append(colwidth)\n                    totwidth += colwidth + len(o['colsep'])\n                    if totwidth >= o['displaywidth']:\n                        break\n                    pass\n                if totwidth <= o['displaywidth'] and i >= rounded_size-1:\n                    # Found the right nrows and ncols\n                    # print \"right nrows and ncols\"\n                    nrows  = row\n                    break\n                elif totwidth >= o['displaywidth']:\n                    # print \"reduce ncols\", ncols\n                    # Need to reduce ncols\n                    break\n                pass\n            if totwidth <= o['displaywidth'] and i >= rounded_size-1:\n                break\n            pass\n        # The smallest number of rows computed and the\n        # max widths for each column has been obtained.\n        # Now we just have to format each of the\n        # rows.\n        s = ''\n        if len(o['array_prefix']) != 0:\n            prefix = o['array_prefix']\n        else:\n            prefix = o['lineprefix']\n            pass\n        for row in range(1, nrows+1):\n            texts = []\n            for col in range(ncols):\n                i = array_index(ncols, row, col)\n                if i >= size:\n                    break\n                else: x = array[i]\n                texts.append(x)\n                pass\n            for col in range(len(texts)):\n                if o['ljust']:\n                    texts[col] = texts[col].ljust(colwidths[col])\n                else:\n                    texts[col] = texts[col].rjust(colwidths[col])\n                    pass\n                pass\n            s += \"%s%s%s\" % (prefix, str(o['colsep'].join(texts)),\n                             o['linesuffix'])\n            prefix = o['lineprefix']\n            pass\n        if o['arrange_array']:\n            colsep = o['colsep'].rstrip()\n            colsep_pos = -(len(colsep)+1)\n            if s[colsep_pos:] == colsep + \"\\n\":\n                s = s[:colsep_pos] + o['array_suffix'] + \"\\n\"\n                pass\n            pass\n        else:\n            s += o['array_suffix']\n            pass\n        return s\n    pass", "response": "Return a list of strings as a compact set of columns."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a new Minimal Perfect Hash (MPH) Parameters ---------- data : list, array-like, file-like The input that is used to generate the minimal perfect hash. Be aware, in most cases the input is expected to be distinct, and many of the algorithms benefit from the input being sorted. algorithm : string, optional {chd_ph (default), chd, bmz, bmz8, chm, brz, fch, bdz, bdz_ph} The algorithm to use in generating MPH's, choice of: chd / chd_ph - Compress Hash and Displace (default) (http://cmph.sourceforge.net/chd.html) - It is the fastest algorithm to build PHFs and MPHFs in linear time. - It generates the most compact PHFs and MPHFs we know of. - It can generate PHFs with a load factor up to 99 %. - It can be used to generate t-perfect hash functions. A t-perfect hash function allows at most t collisions in a given bin. It is a well-known fact that modern memories are organized as blocks which constitute transfer unit. Example of such blocks are cache lines for internal memory or sectors for hard disks. Thus, it can be very useful for devices that carry out I/O operations in blocks. - It is a two level scheme. It uses a first level hash function to split the key set in buckets of average size determined by a parameter b in the range [1,32]. In the second level it uses displacement values to resolve the collisions that have given rise to the buckets. - It can generate MPHFs that can be stored in approximately 2.07 bits per key. - For a load factor equal to the maximum one that is achieved by the BDZ algorithm (81 %), the resulting PHFs are stored in approximately 1.40 bits per key. bdz - BDZ / BPZ algorithm (http://cmph.sourceforge.net/bdz.html) - It is very simple and efficient. It outperforms all others except CHD. - It constructs both PHFs and MPHFs in linear time. - The maximum load factor one can achieve for a PHF is 1/1.23. - It is based on acyclic random 3-graphs. A 3-graph is a generalization of a graph where each edge connects 3 vertices instead of only 2. - The resulting MPHFs are not order preserving. - The resulting MPHFs can be stored in only (2 + x)cn bits, where c should be larger than or equal to 1.23 and x is a constant larger than 0 (actually, x = 1/b and b is a parameter that should be larger than 2). For c = 1.23 and b = 8, the resulting functions are stored in approximately 2.6 bits per key. - For its maximum load factor (81 %), the resulting PHFs are stored in approximately 1.95 bits per key. bmz - Botelho, Menoti and Ziviani algorithm: (http://cmph.sourceforge.net/bdz.html) - Constructs MPHFs in linear time. - It is based on cyclic random graphs. This makes it faster than the CHM algorithm. - The resulting MPHFs are not order preserving. - The resulting MPHFs are more compact than the ones generated by the CHM algorithm and can be stored in 4cn bytes, where c is in the range [0.93,1.15]. brz - BRZ algorithm: (http://cmph.sourceforge.net/brz.html) - A very fast external memory based algorithm for constructing minimal perfect hash functions for sets in the order of billions of keys. - It works in linear time. - The resulting MPHFs are not order preserving. - The resulting MPHFs can be stored using less than 8.0 bits per key. chm - Czech, Havas and Majewski algorithm: (http://cmph.sourceforge.net/chm.html) - Construct minimal MPHFs in linear time. - It is based on acyclic random graphs - The resulting MPHFs are order preserving. - The resulting MPHFs are stored in 4cn bytes, where c is greater than 2. fch - Fox, Chen and Heath algorithm: (http://cmph.sourceforge.net/chm.html) - Construct minimal perfect hash functions that require less than 4 bits per key to be stored. - The resulting MPHFs are very compact and very efficient at evaluation time - The algorithm is only efficient for small sets. - It is used as internal algorithm in the BRZ algorithm to efficiently solve larger problems and even so to generate MPHFs that require approximately 4.1 bits per key to be stored. For that, you just need to set the parameters -a to brz and -c to a value larger than or equal to 2.6. hash_fns : list {jenkins (default), count} optional Internal hash functions to use inside MPH generation functions, can be multiple fns as a list. chd_keys_per_bin : int [1 to 128], optional Set the number of keys per bin for a t-perfect hashing function. A t-perfect hash function allows at most t collisions in a given bin. This parameter applies only to the `chd` and `chd_ph` algorithms. Its value should be an integer in the range [1, 128]. Default is 1 chd_load_factor : float, optional The load factor used in the `chd_ph` algorithm fch_bits_per_key : int, optional The number of bits per key required in the FCH algorithm num_graph_vertices : int, optional The number of vertices in the graph for the algorithms BMZ and CHM brz_memory_size : int (default 8), optional Main memory availability (in MB) used in BRZ algorithm Default is 8Mb brz_temp_dir : string, optional Temporary directory used in BRZ algorithm brz_max_keys_per_bucket : int [64 to 175] (default 128), optional Used to make the maximal number of keys in a bucket lower than 256. In this case its value should be an integer in the range [64,175]. Default is 128. bdz_precomputed_rank : int [3 to 10] (default 7), optional For BDZ it is used to determine the size of some precomputed rank information and its value should be an integer in the range [3,10]. Default is 7. The larger is this value, the more compact are the resulting functions and the slower are them at evaluation time. chd_avg_keys_per_bucket : int [1 to 32] (default 4), optional For CHD and CHD_PH it is used to set the average number of keys per bucket and its value should be an integer in the range [1,32]. Default is 4. The larger is this value, the slower is the construction of the functions. Returns ------- MPH A wrapper object that represents a minimal perfect hash in memory Raises ------ ValueError If arguments presented are incomplete, or incompatable RuntimeError If the MPH generation fails", "response": "def generate_hash(data, algorithm='chd_ph', hash_fns=(), chd_keys_per_bin=1,\n                  chd_load_factor=None, fch_bits_per_key=None,\n                  num_graph_vertices=None, brz_memory_size=8,\n                  brz_temp_dir=None, brz_max_keys_per_bucket=128,\n                  bdz_precomputed_rank=7, chd_avg_keys_per_bucket=4):\n    \"\"\"\n    Generates a new Minimal Perfect Hash (MPH)\n\n    Parameters\n    ----------\n    data : list, array-like, file-like\n        The input that is used to generate the minimal perfect hash.\n\n        Be aware, in most cases the input is expected to be distinct, and\n        many of the algorithms benefit from the input being sorted.\n\n    algorithm : string, optional\n        {chd_ph (default), chd, bmz, bmz8, chm, brz, fch, bdz, bdz_ph}\n        The algorithm to use in generating MPH's, choice of:\n\n        chd / chd_ph - Compress Hash and Displace (default)\n            (http://cmph.sourceforge.net/chd.html)\n            - It is the fastest algorithm to build PHFs and MPHFs in linear\n            time.\n            - It generates the most compact PHFs and MPHFs we know of.\n            - It can generate PHFs with a load factor up to 99 %.\n            - It can be used to generate t-perfect hash functions. A\n            t-perfect hash function allows at most t collisions in a given\n            bin. It is a well-known fact that modern memories are\n            organized as blocks which constitute transfer unit. Example of\n            such blocks are cache lines for internal memory or sectors for\n            hard disks. Thus, it can be very useful for devices that\n            carry out I/O operations in blocks.\n            - It is a two level scheme. It uses a first level hash function\n            to split the key set in buckets of average size determined by\n            a parameter b in the range [1,32]. In the second level it uses\n            displacement values to resolve the collisions that have given\n            rise to the buckets.\n            - It can generate MPHFs that can be stored in approximately 2.07\n            bits per key.\n            - For a load factor equal to the maximum one that is achieved by\n            the BDZ algorithm (81 %), the resulting PHFs are stored in\n            approximately 1.40 bits per key.\n\n        bdz - BDZ / BPZ algorithm\n            (http://cmph.sourceforge.net/bdz.html)\n            - It is very simple and efficient. It outperforms all others\n            except CHD.\n            - It constructs both PHFs and MPHFs in linear time.\n            - The maximum load factor one can achieve for a PHF is 1/1.23.\n            - It is based on acyclic random 3-graphs. A 3-graph is a\n            generalization of a graph where each edge connects 3 vertices\n            instead of only 2.\n            - The resulting MPHFs are not order preserving.\n            - The resulting MPHFs can be stored in only (2 + x)cn bits,\n            where c should be larger than or equal to 1.23 and x is a\n            constant larger than 0 (actually, x = 1/b and b is a parameter\n            that should be larger than 2). For c = 1.23 and b = 8, the\n            resulting functions are stored in approximately 2.6 bits per\n            key.\n            - For its maximum load factor (81 %), the resulting PHFs are\n            stored in approximately 1.95 bits per key.\n\n        bmz - Botelho, Menoti and Ziviani algorithm:\n            (http://cmph.sourceforge.net/bdz.html)\n            - Constructs MPHFs in linear time.\n            - It is based on cyclic random graphs. This makes it faster than\n            the CHM algorithm.\n            - The resulting MPHFs are not order preserving.\n            - The resulting MPHFs are more compact than the ones generated by\n            the CHM algorithm and can be stored in 4cn bytes, where c is in\n            the range [0.93,1.15].\n\n        brz - BRZ algorithm:\n            (http://cmph.sourceforge.net/brz.html)\n            - A very fast external memory based algorithm for constructing\n            minimal perfect hash functions for sets in the order of\n            billions of keys.\n            - It works in linear time.\n            - The resulting MPHFs are not order preserving.\n            - The resulting MPHFs can be stored using less than 8.0 bits per\n            key.\n\n        chm - Czech, Havas and Majewski algorithm:\n            (http://cmph.sourceforge.net/chm.html)\n            - Construct minimal MPHFs in linear time.\n            - It is based on acyclic random graphs\n            - The resulting MPHFs are order preserving.\n            - The resulting MPHFs are stored in 4cn bytes, where c is greater\n            than 2.\n\n        fch - Fox, Chen and Heath algorithm:\n            (http://cmph.sourceforge.net/chm.html)\n            - Construct minimal perfect hash functions that require less than\n            4 bits per key to be stored.\n            - The resulting MPHFs are very compact and very efficient at\n            evaluation time\n            - The algorithm is only efficient for small sets.\n            - It is used as internal algorithm in the BRZ algorithm to\n            efficiently solve larger problems and even so to generate MPHFs\n            that require approximately 4.1 bits per key to be stored. For\n            that, you just need to set the parameters -a to brz and -c to a\n            value larger than or equal to 2.6.\n\n    hash_fns : list {jenkins (default), count} optional\n        Internal hash functions to use inside MPH generation functions,\n        can be multiple fns as a list.\n\n    chd_keys_per_bin : int [1 to 128], optional\n        Set the number of keys per bin for a t-perfect hashing function. A\n        t-perfect hash function allows at most t collisions in a given bin.\n        This parameter applies only to the `chd` and `chd_ph` algorithms.\n        Its value should be an integer in the range [1, 128].\n\n        Default is 1\n\n    chd_load_factor : float, optional\n        The load factor used in the `chd_ph` algorithm\n\n    fch_bits_per_key : int, optional\n        The number of bits per key required in the FCH algorithm\n\n    num_graph_vertices : int, optional\n        The number of vertices in the graph for the algorithms BMZ and CHM\n\n    brz_memory_size : int (default 8), optional\n        Main memory availability (in MB) used in BRZ algorithm\n\n        Default is 8Mb\n\n    brz_temp_dir : string, optional\n        Temporary directory used in BRZ algorithm\n\n    brz_max_keys_per_bucket : int [64 to 175] (default 128), optional\n        Used to make the maximal number of keys in a bucket lower than 256.\n        In this case its value should be an integer in the range [64,175].\n        Default is 128.\n\n    bdz_precomputed_rank : int [3 to 10] (default 7), optional\n        For BDZ it is used to determine the size of some precomputed rank\n        information and its value should be an integer in the range [3,10].\n\n        Default is 7.\n\n        The larger is this value, the more compact are the resulting\n        functions and the slower are them at evaluation time.\n\n    chd_avg_keys_per_bucket : int [1 to 32] (default 4), optional\n        For CHD and CHD_PH it is used to set the average number of keys per\n        bucket and its value should be an integer in the range [1,32].\n\n        Default is 4.\n\n        The larger is this value, the slower is the construction of the\n        functions.\n\n    Returns\n    -------\n    MPH\n        A wrapper object that represents a minimal perfect hash in memory\n\n    Raises\n    ------\n    ValueError\n        If arguments presented are incomplete, or incompatable\n    RuntimeError\n        If the MPH generation fails\n    \"\"\"\n\n    cfg = _cfg(algorithm, hash_fns, chd_keys_per_bin, chd_load_factor,\n               fch_bits_per_key, num_graph_vertices, brz_memory_size,\n               brz_temp_dir, brz_max_keys_per_bucket, bdz_precomputed_rank,\n               chd_avg_keys_per_bucket)\n\n    with create_adapter(_cmph, ffi, data) as source:\n        with _create_config(source, cfg) as config:\n            _mph = _cmph.cmph_new(config)\n            if not _mph:\n                raise RuntimeError(\"MPH generation failed\")\n            return MPH(_mph)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_hash(existing_mph):\n    if is_file_location(existing_mph):\n        with open(abspath(existing_mph)) as hash_table:\n            _mph = _cmph.cmph_load(hash_table)\n    elif is_file(existing_mph):\n        _mph = _cmph.cmph_load(existing_mph)\n\n    if not _mph:\n        raise IOError(\"Unable to load an MPH from the given source\")\n\n    return MPH(_mph)", "response": "Loads a minimal perfect hash from an existing MPH file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save(self, output):\n        assert self._mph, \"There is no MPH ?\"\n        if isinstance(output, six.string_types):\n            with open(abspath(output), 'w') as out:\n                _cmph.cmph_dump(self._mph, out)\n        else:\n            _cmph.cmph_dump(self._mph, output)", "response": "Saves the MPH to a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lookup(self, key):\n        assert self._mph\n        key = convert_to_bytes(key)\n        box = ffi.new('char[]', key)\n        try:\n            result = _cmph.cmph_search(self._mph, box, len(key))\n            return result\n        finally:\n            del box", "response": "Returns the hash code for the given item in the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate values of configuration section with dict.", "response": "def update_(self, sct_dict, conf_arg=True):\n        \"\"\"Update values of configuration section with dict.\n\n        Args:\n            sct_dict (dict): dict indexed with option names. Undefined\n                options are discarded.\n            conf_arg (bool): if True, only options that can be set in a config\n                file are updated.\n        \"\"\"\n        for opt, val in sct_dict.items():\n            if opt not in self.def_:\n                continue\n            if not conf_arg or self.def_[opt].conf_arg:\n                self[opt] = val"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrestore default values of options in this section.", "response": "def reset_(self):\n        \"\"\"Restore default values of options in this section.\"\"\"\n        for opt, meta in self.defaults_():\n            self[opt] = meta.default"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_dict_(cls, conf_dict):\n        return cls(**{name: Section(**opts)\n                      for name, opts in conf_dict.items()})", "response": "Use a dictionary to create a ConfigurationManager."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_config_files_(self, *config_files):\n        self._config_files = tuple(pathlib.Path(path) for path in config_files)", "response": "Set the list of config files."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef opt_vals_(self):\n        for sct, opt in self.options_():\n            yield sct, opt, self[sct][opt]", "response": "Iterator over sections option names and option values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef defaults_(self):\n        for sct, opt in self.options_():\n            yield sct, opt, self[sct].def_[opt]", "response": "Iterator over sections option names and option metadata."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating config file in self. config_files_ [ index ].", "response": "def create_config_(self, index=0, update=False):\n        \"\"\"Create config file.\n\n        Create config file in :attr:`config_files_[index]`.\n\n        Parameters:\n            index(int): index of config file.\n            update (bool): if set to True and :attr:`config_files_` already\n                exists, its content is read and all the options it sets are\n                kept in the produced config file.\n        \"\"\"\n        if not self.config_files_[index:]:\n            return\n        path = self.config_files_[index]\n        if not path.parent.exists():\n            path.parent.mkdir(parents=True)\n        conf_dict = {}\n        for section in self.sections_():\n            conf_opts = [o for o, m in self[section].defaults_() if m.conf_arg]\n            if not conf_opts:\n                continue\n            conf_dict[section] = {}\n            for opt in conf_opts:\n                conf_dict[section][opt] = (self[section][opt] if update else\n                                           self[section].def_[opt].default)\n        with path.open('w') as cfile:\n            toml.dump(conf_dict, cfile)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating values of configuration options with dict.", "response": "def update_(self, conf_dict, conf_arg=True):\n        \"\"\"Update values of configuration options with dict.\n\n        Args:\n            conf_dict (dict): dict of dict indexed with section and option\n                names.\n            conf_arg (bool): if True, only options that can be set in a config\n                file are updated.\n        \"\"\"\n        for section, secdict in conf_dict.items():\n            self[section].update_(secdict, conf_arg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_config_(self, cfile):\n        if not cfile.exists():\n            return {}\n        try:\n            conf_dict = toml.load(str(cfile))\n        except toml.TomlDecodeError:\n            return None\n        self.update_(conf_dict)\n        return conf_dict", "response": "Read a config file and set config values accordingly."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads config files and set config values accordingly.", "response": "def read_configs_(self):\n        \"\"\"Read config files and set config values accordingly.\n\n        Returns:\n            (dict, list, list): respectively content of files, list of\n            missing/empty files and list of files for which a parsing error\n            arised.\n        \"\"\"\n        if not self.config_files_:\n            return {}, [], []\n        content = {section: {} for section in self}\n        empty_files = []\n        faulty_files = []\n        for cfile in self.config_files_:\n            conf_dict = self.read_config_(cfile)\n            if conf_dict is None:\n                faulty_files.append(cfile)\n                continue\n            elif not conf_dict:\n                empty_files.append(cfile)\n                continue\n            for section, secdict in conf_dict.items():\n                content[section].update(secdict)\n        return content, empty_files, faulty_files"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting of cli strings for a given option.", "response": "def _names(section, option):\n    \"\"\"List of cli strings for a given option.\"\"\"\n    meta = section.def_[option]\n    action = meta.cmd_kwargs.get('action')\n    if action is internal.Switch:\n        names = ['-{}'.format(option), '+{}'.format(option)]\n        if meta.shortname is not None:\n            names.append('-{}'.format(meta.shortname))\n            names.append('+{}'.format(meta.shortname))\n    else:\n        names = ['--{}'.format(option)]\n        if meta.shortname is not None:\n            names.append('-{}'.format(meta.shortname))\n    return names"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sections_list(self, cmd=None):\n        sections = list(self.common.sections)\n        if not cmd:\n            if self.bare is not None:\n                sections.extend(self.bare.sections)\n                return sections\n            return []\n        sections.extend(self.subcmds[cmd].sections)\n        if cmd in self._conf:\n            sections.append(cmd)\n        return sections", "response": "Returns a list of config sections used by a command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _cmd_opts_solver(self, cmd_name):\n        sections = self.sections_list(cmd_name)\n        cmd_dict = self._opt_cmds[cmd_name] if cmd_name else self._opt_bare\n        for sct in reversed(sections):\n            for opt, opt_meta in self._conf[sct].def_.items():\n                if not opt_meta.cmd_arg:\n                    continue\n                if opt not in cmd_dict:\n                    cmd_dict[opt] = sct\n                else:\n                    warnings.warn(\n                        'Command <{0}>: {1}.{2} shadowed by {3}.{2}'.format(\n                            cmd_name, sct, opt, cmd_dict[opt]),\n                        error.LoamWarning, stacklevel=4)", "response": "Scan options related to one command and enrich _opt_cmds."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds options to a parser.", "response": "def _add_options_to_parser(self, opts_dict, parser):\n        \"\"\"Add options to a parser.\"\"\"\n        store_bool = ('store_true', 'store_false')\n        for opt, sct in opts_dict.items():\n            meta = self._conf[sct].def_[opt]\n            kwargs = copy.deepcopy(meta.cmd_kwargs)\n            action = kwargs.get('action')\n            if action is internal.Switch:\n                kwargs.update(nargs=0)\n            elif meta.default is not None and action not in store_bool:\n                kwargs.setdefault('type', type(meta.default))\n            kwargs.update(help=meta.help)\n            kwargs.setdefault('default', self._conf[sct][opt])\n            parser.add_argument(*_names(self._conf[sct], opt), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding command line argument parser.", "response": "def _build_parser(self):\n        \"\"\"Build command line argument parser.\n\n        Returns:\n            :class:`argparse.ArgumentParser`: the command line argument parser.\n            You probably won't need to use it directly. To parse command line\n            arguments and update the :class:`ConfigurationManager` instance\n            accordingly, use the :meth:`parse_args` method.\n        \"\"\"\n        main_parser = argparse.ArgumentParser(description=self.common.help,\n                                              prefix_chars='-+')\n\n        self._add_options_to_parser(self._opt_bare, main_parser)\n        main_parser.set_defaults(**self.common.defaults)\n        if self.bare is not None:\n            main_parser.set_defaults(**self.bare.defaults)\n\n        subparsers = main_parser.add_subparsers(dest='loam_sub_name')\n        for cmd_name, meta in self.subcmds.items():\n            kwargs = {'prefix_chars': '+-', 'help': meta.help}\n            dummy_parser = subparsers.add_parser(cmd_name, **kwargs)\n            self._add_options_to_parser(self._opt_cmds[cmd_name], dummy_parser)\n            dummy_parser.set_defaults(**meta.defaults)\n\n        return main_parser"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_args(self, arglist=None):\n        args = self._parser.parse_args(args=arglist)\n        sub_cmd = args.loam_sub_name\n        if sub_cmd is None:\n            for opt, sct in self._opt_bare.items():\n                self._conf[sct][opt] = getattr(args, opt, None)\n        else:\n            for opt, sct in self._opt_cmds[sub_cmd].items():\n                self._conf[sct][opt] = getattr(args, opt, None)\n        return args", "response": "Parse arguments and update options accordingly."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite zsh command for a given command.", "response": "def _zsh_comp_command(self, zcf, cmd, grouping, add_help=True):\n        \"\"\"Write zsh _arguments compdef for a given command.\n\n        Args:\n            zcf (file): zsh compdef file.\n            cmd (str): command name, set to None or '' for bare command.\n            grouping (bool): group options (zsh>=5.4).\n            add_help (bool): add an help option.\n        \"\"\"\n        if add_help:\n            if grouping:\n                print(\"+ '(help)'\", end=BLK, file=zcf)\n            print(\"'--help[show help message]'\", end=BLK, file=zcf)\n            print(\"'-h[show help message]'\", end=BLK, file=zcf)\n        # could deal with duplicate by iterating in reverse and keep set of\n        # already defined opts.\n        no_comp = ('store_true', 'store_false')\n        cmd_dict = self._opt_cmds[cmd] if cmd else self._opt_bare\n        for opt, sct in cmd_dict.items():\n            meta = self._conf[sct].def_[opt]\n            if meta.cmd_kwargs.get('action') == 'append':\n                grpfmt, optfmt = \"+ '{}'\", \"'*{}[{}]{}'\"\n                if meta.comprule is None:\n                    meta.comprule = ''\n            else:\n                grpfmt, optfmt = \"+ '({})'\", \"'{}[{}]{}'\"\n            if meta.cmd_kwargs.get('action') in no_comp \\\n               or meta.cmd_kwargs.get('nargs') == 0:\n                meta.comprule = None\n            if meta.comprule is None:\n                compstr = ''\n            elif meta.comprule == '':\n                optfmt = optfmt.split('[')\n                optfmt = optfmt[0] + '=[' + optfmt[1]\n                compstr = ': :( )'\n            else:\n                optfmt = optfmt.split('[')\n                optfmt = optfmt[0] + '=[' + optfmt[1]\n                compstr = ': :{}'.format(meta.comprule)\n            if grouping:\n                print(grpfmt.format(opt), end=BLK, file=zcf)\n            for name in _names(self._conf[sct], opt):\n                print(optfmt.format(name, meta.help.replace(\"'\", \"'\\\"'\\\"'\"),\n                                    compstr), end=BLK, file=zcf)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef zsh_complete(self, path, cmd, *cmds, sourceable=False):\n        grouping = internal.zsh_version() >= (5, 4)\n        path = pathlib.Path(path)\n        firstline = ['#compdef', cmd]\n        firstline.extend(cmds)\n        subcmds = list(self.subcmds.keys())\n        with path.open('w') as zcf:\n            print(*firstline, end='\\n\\n', file=zcf)\n            # main function\n            print('function _{} {{'.format(cmd), file=zcf)\n            print('local line', file=zcf)\n            print('_arguments -C', end=BLK, file=zcf)\n            if subcmds:\n                # list of subcommands and their description\n                substrs = [\"{}\\\\:'{}'\".format(sub, self.subcmds[sub].help)\n                           for sub in subcmds]\n                print('\"1:Commands:(({}))\"'.format(' '.join(substrs)),\n                      end=BLK, file=zcf)\n            self._zsh_comp_command(zcf, None, grouping)\n            if subcmds:\n                print(\"'*::arg:->args'\", file=zcf)\n                print('case $line[1] in', file=zcf)\n                for sub in subcmds:\n                    print('{sub}) _{cmd}_{sub} ;;'.format(sub=sub, cmd=cmd),\n                          file=zcf)\n                print('esac', file=zcf)\n            print('}', file=zcf)\n            # all subcommand completion handlers\n            for sub in subcmds:\n                print('\\nfunction _{}_{} {{'.format(cmd, sub), file=zcf)\n                print('_arguments', end=BLK, file=zcf)\n                self._zsh_comp_command(zcf, sub, grouping)\n                print('}', file=zcf)\n            if sourceable:\n                print('\\ncompdef _{0} {0}'.format(cmd), *cmds, file=zcf)", "response": "Write a zsh compdef script."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a list of all CLI options for a given command.", "response": "def _bash_comp_command(self, cmd, add_help=True):\n        \"\"\"Build a list of all options for a given command.\n\n        Args:\n            cmd (str): command name, set to None or '' for bare command.\n            add_help (bool): add an help option.\n\n        Returns:\n            list of str: list of CLI options strings.\n        \"\"\"\n        out = ['-h', '--help'] if add_help else []\n        cmd_dict = self._opt_cmds[cmd] if cmd else self._opt_bare\n        for opt, sct in cmd_dict:\n            out.extend(_names(self._conf[sct], opt))\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bash_complete(self, path, cmd, *cmds):\n        path = pathlib.Path(path)\n        subcmds = list(self.subcmds.keys())\n        with path.open('w') as bcf:\n            # main function\n            print('_{}() {{'.format(cmd), file=bcf)\n            print('COMPREPLY=()', file=bcf)\n            print(r'local cur=${COMP_WORDS[COMP_CWORD]}', end='\\n\\n', file=bcf)\n            optstr = ' '.join(self._bash_comp_command(None))\n            print(r'local options=\"{}\"'.format(optstr), end='\\n\\n', file=bcf)\n            if subcmds:\n                print('local commands=\"{}\"'.format(' '.join(subcmds)),\n                      file=bcf)\n                print('declare -A suboptions', file=bcf)\n            for sub in subcmds:\n                optstr = ' '.join(self._bash_comp_command(sub))\n                print('suboptions[{}]=\"{}\"'.format(sub, optstr), file=bcf)\n            condstr = 'if'\n            for sub in subcmds:\n                print(condstr, r'[[ \"${COMP_LINE}\" == *\"', sub, '\"* ]] ; then',\n                      file=bcf)\n                print(r'COMPREPLY=( `compgen -W \"${suboptions[', sub,\n                      r']}\" -- ${cur}` )', sep='', file=bcf)\n                condstr = 'elif'\n            print(condstr, r'[[ ${cur} == -* ]] ; then', file=bcf)\n            print(r'COMPREPLY=( `compgen -W \"${options}\" -- ${cur}`)',\n                  file=bcf)\n            if subcmds:\n                print(r'else', file=bcf)\n                print(r'COMPREPLY=( `compgen -W \"${commands}\" -- ${cur}`)',\n                      file=bcf)\n            print('fi', file=bcf)\n            print('}', end='\\n\\n', file=bcf)\n            print('complete -F _{0} {0}'.format(cmd), *cmds, file=bcf)", "response": "Write bash complete script."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to guess zsh version return tuple of 0 on failure", "response": "def zsh_version():\n    \"\"\"Try to guess zsh version, return (0, 0) on failure.\"\"\"\n    try:\n        out = subprocess.check_output(shlex.split('zsh --version'))\n    except (FileNotFoundError, subprocess.CalledProcessError):\n        return (0, 0)\n    match = re.search(br'[0-9]+\\.[0-9]+', out)\n    return tuple(map(int, match.group(0).split(b'.'))) if match else (0, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts a new HighFive master at the given host and port and returns it.", "response": "async def start_master(host=\"\", port=48484, *, loop=None):\n    \"\"\"\n    Starts a new HighFive master at the given host and port, and returns it.\n    \"\"\"\n\n    loop = loop if loop is not None else asyncio.get_event_loop()\n\n    manager = jobs.JobManager(loop=loop)\n    workers = set()\n    server = await loop.create_server(\n            lambda: WorkerProtocol(manager, workers), host, port)\n    return Master(server, manager, workers, loop=loop)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling when a new connection is made.", "response": "def connection_made(self, transport):\n        \"\"\"\n        Called when a remote worker connection has been found. Finishes setting\n        up the protocol object.\n        \"\"\"\n\n        if self._manager.is_closed():\n            logger.debug(\"worker tried to connect while manager was closed\")\n            return\n\n        logger.debug(\"new worker connected\")\n\n        self._transport = transport\n        self._buffer = bytearray()\n        self._worker = Worker(self._transport, self._manager)\n        self._workers.add(self._worker)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall when a chunk of data is received from the remote worker.", "response": "def data_received(self, data):\n        \"\"\"\n        Called when a chunk of data is received from the remote worker. These\n        chunks are stored in a buffer. When a complete line is found in the\n        buffer, it removed and sent to line_received().\n        \"\"\"\n\n        self._buffer.extend(data)\n        while True:\n            i = self._buffer.find(b\"\\n\")\n            if i == -1:\n                break\n            line = self._buffer[:i+1]\n            self._buffer = self._buffer[i+1:]\n            self.line_received(line)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall when a complete line is found from the remote worker.", "response": "def line_received(self, line):\n        \"\"\"\n        Called when a complete line is found from the remote worker. Decodes\n        a response object from the line, then passes it to the worker object.\n        \"\"\"\n\n        response = json.loads(line.decode(\"utf-8\"))\n        self._worker.response_received(response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls when the connection to the remote worker is lost. Closes the worker and removes the worker from the list of available workers.", "response": "def connection_lost(self, exc):\n        \"\"\"\n        Called when the connection to the remote worker is broken. Closes the\n        worker.\n        \"\"\"\n\n        logger.debug(\"worker connection lost\")\n\n        self._worker.close()\n        self._workers.remove(self._worker)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _job_loaded(self, job):\n\n        logger.debug(\"worker {} found a job\".format(id(self)))\n\n        if self._closed:\n            self._manager.return_job(job)\n            return\n\n        self._job = job\n        call_obj = self._job.get_call()\n        call = (json.dumps(call_obj) + \"\\n\").encode(\"utf-8\")\n        self._transport.write(call)", "response": "Called when a job has been loaded. Sends the job s\n        RPC to the remote worker."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef response_received(self, response):\n\n        if self._closed:\n            return\n\n        assert self._job is not None\n\n        logger.debug(\"worker {} got response\".format(id(self)))\n        result = self._job.get_result(response)\n        self._manager.add_result(self._job, result)\n\n        self._load_job()", "response": "Called when a response to a job RPC has been received. Decodes the response and reports the result to the job manager."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclosing the worker. No more jobs will be handled by the worker, and any running job is immediately returned to the job manager.", "response": "def close(self):\n        \"\"\"\n        Closes the worker. No more jobs will be handled by the worker, and any\n        running job is immediately returned to the job manager.\n        \"\"\"\n\n        if self._closed:\n            return\n\n        self._closed = True\n\n        if self._job is not None:\n            self._manager.return_job(self._job)\n            self._job = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self, job_list):\n\n        if self._closed:\n            raise RuntimeError(\"master is closed\")\n\n        return self._manager.add_job_set(job_list)", "response": "Runs a job set which consists of the jobs in an iterable job list."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncloses the HighFive master.", "response": "def close(self):\n        \"\"\"\n        Starts closing the HighFive master. The server will be closed and\n        all queued job sets will be cancelled.\n        \"\"\"\n\n        if self._closed:\n            return\n\n        self._closed = True\n\n        self._server.close()\n        self._manager.close()\n        for worker in self._workers:\n            worker.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall when a state change has occurred.", "response": "def _change(self):\n        \"\"\"\n        Called when a state change has occurred. Waiters are notified that a\n        change has occurred.\n        \"\"\"\n\n        for waiter in self._waiters:\n            if not waiter.done():\n                waiter.set_result(None)\n        self._waiters = []"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(self, result):\n\n        assert not self._complete\n\n        self._results.append(result)\n        self._change()", "response": "Adds a new result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def wait_changed(self):\n\n        if not self.is_complete():\n            waiter = self._loop.create_future()\n            self._waiters.append(waiter)\n            await waiter", "response": "Waits until the result set has changed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the next available job from the job iterator and increments the active job count.", "response": "def _load_job(self):\n        \"\"\"\n        If there is still a job in the job iterator, loads it and increments\n        the active job count.\n        \"\"\"\n\n        try:\n            next_job = next(self._jobs)\n        except StopIteration:\n            self._on_deck = None\n        else:\n            if not isinstance(next_job, Job):\n                next_job = DefaultJob(next_job)\n            self._on_deck = next_job\n            self._active_jobs += 1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _done(self):\n\n        self._results.complete()\n        waiters = self._waiters\n        for waiter in waiters:\n            waiter.set_result(None)\n        self._manager.job_set_done(self)", "response": "Mark the job set as complete and notifies all waiting tasks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a job from the job set if one is available.", "response": "def get_job(self):\n        \"\"\"\n        Gets a job from the job set if one is queued. The jobs_available()\n        method should be consulted first to determine if a job can be obtained\n        from a call to this method. If no jobs are available, an IndexError is\n        raised.\n        \"\"\"\n\n        if len(self._return_queue) > 0:\n            return self._return_queue.popleft()\n        elif self._on_deck is not None:\n            job = self._on_deck\n            self._load_job()\n            return job\n        else:\n            raise IndexError(\"no jobs available\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_result(self, result):\n\n        if self._active_jobs == 0:\n            return\n\n        self._results.add(result)\n        self._active_jobs -= 1\n        if self._active_jobs == 0:\n            self._done()", "response": "Adds the result of a completed job to the result list and then decrements the active job count."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cancel(self):\n\n        if self._active_jobs == 0:\n            return\n\n        self._jobs = iter(())\n        self._on_deck = None\n        self._return_queue.clear()\n        self._active_jobs = 0\n\n        self._done()", "response": "Cancels the job set."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwaits until all jobs in the job set are finished. Returns immediately if the job set is already finished.", "response": "async def wait_done(self):\n        \"\"\"\n        Waits until the job set is finished. Returns immediately if the job set\n        is already finished.\n        \"\"\"\n        \n        if self._active_jobs > 0:\n            future = self._loop.create_future()\n            self._waiters.append(future)\n            await future"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndistributes jobs from the active job set to any waiting get_job callbacks.", "response": "def _distribute_jobs(self):\n        \"\"\"\n        Distributes jobs from the active job set to any waiting get_job\n        callbacks.\n        \"\"\"\n\n        while (self._active_js.job_available()\n                and len(self._ready_callbacks) > 0):\n            job = self._active_js.get_job()\n            self._job_sources[job] = self._active_js\n            callback = self._ready_callbacks.popleft()\n            callback(job)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a job set to the manager s queue.", "response": "def add_job_set(self, job_list):\n        \"\"\"\n        Adds a job set to the manager's queue. If there is no job set running,\n        it is activated immediately. A new job set handle is returned.\n        \"\"\"\n\n        assert not self._closed\n\n        results = Results(loop=self._loop)\n        js = JobSet(job_list, results, self, loop=self._loop)\n        if not js.is_done():\n            if self._active_js is None:\n                self._active_js = js\n                logger.debug(\"activated job set\")\n                self._distribute_jobs()\n            else:\n                self._js_queue.append(js)\n        else:\n            logger.debug(\"new job set has no jobs\")\n        return JobSetHandle(js, results)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_job(self, callback):\n\n        assert not self._closed\n\n        if self._active_js is None or not self._active_js.job_available():\n            self._ready_callbacks.append(callback)\n        else:\n            job = self._active_js.get_job()\n            self._job_sources[job] = self._active_js\n            callback(job)", "response": "Calls the given callback function when a job becomes available."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef return_job(self, job):\n\n        if self._closed:\n            return\n\n        js = self._job_sources[job]\n        if len(self._ready_callbacks) > 0:\n            callback = self._ready_callbacks.popleft()\n            callback(job)\n        else:\n            del self._job_sources[job]\n            js.return_job(job)", "response": "Returns a job to its source job set to be run later."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds the result of a job to the results list of the job s source job set.", "response": "def add_result(self, job, result):\n        \"\"\"\n        Adds the result of a job to the results list of the job's source job\n        set.\n        \"\"\"\n\n        if self._closed:\n            return\n\n        js = self._job_sources[job]\n        del self._job_sources[job]\n        js.add_result(result)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef job_set_done(self, js):\n\n        if self._closed:\n            return\n\n        if self._active_js != js:\n            return\n\n        try:\n            while self._active_js.is_done():\n                logger.debug(\"job set done\")\n                self._active_js = self._js_queue.popleft()\n                logger.debug(\"activated job set\")\n        except IndexError:\n            self._active_js = None\n        else:\n            self._distribute_jobs()", "response": "Called when a job set has been completed or cancelled."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef close(self):\n\n        if self._closed:\n            return\n\n        self._closed = True\n        if self._active_js is not None:\n            self._active_js.cancel()\n        for js in self._js_queue:\n            js.cancel()", "response": "Closes the job manager."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _uniquify(_list):\n    seen = set()\n    result = []\n    for x in _list:\n        if x not in seen:\n            result.append(x)\n            seen.add(x)\n    return result", "response": "Remove duplicates in a list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if the regex matches the object.", "response": "def _match_regex(regex, obj):\n    \"\"\"\n    Returns true if the regex matches the object, or a string in the object\n    if it is some sort of container.\n\n    :param regex: A regex.\n    :type regex: ``regex``\n    :param obj: An arbitrary object.\n    :type object: ``object``\n\n    :rtype: ``bool``\n    \"\"\"\n    if isinstance(obj, six.string_types):\n        return len(regex.findall(obj)) > 0\n    elif isinstance(obj, dict):\n        return _match_regex(regex, obj.values())\n    elif hasattr(obj, '__iter__'):\n        # Object is a list or some other iterable.\n        return any(_match_regex(regex, s)\n                   for s in obj if isinstance(s, six.string_types))\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of host entries that match the given filters and exclude.", "response": "def get_entries(latest, filters, exclude, limit=None):\n    \"\"\"\n    Lists all available instances.\n\n    :param latest: If true, ignores the cache and grabs the latest list.\n    :type latest: ``bool``\n    :param filters: Filters to apply to results. A result will only be shown\n                    if it includes all text in all filters.\n    :type filters: [``str``]\n    :param exclude: The opposite of filters. Results will be rejected if they\n                    include any of these strings.\n    :type exclude: [``str``]\n    :param limit: Maximum number of entries to show (default no maximum).\n    :type limit: ``int`` or ``NoneType``\n\n    :return: A list of host entries.\n    :rtype: ``list`` of :py:class:`HostEntry`\n    \"\"\"\n    entry_list = _list_all_latest() if latest is True or not _is_valid_cache()\\\n                 else _list_all_cached()\n    filtered = filter_entries(entry_list, filters, exclude)\n    if limit is not None:\n        return filtered[:limit]\n    else:\n        return filtered"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse the environment variable to get the current region", "response": "def get_region():\n    \"\"\"Use the environment to get the current region\"\"\"\n    global _REGION\n    if _REGION is None:\n        region_name = os.getenv(\"AWS_DEFAULT_REGION\") or \"us-east-1\"\n        region_dict = {r.name: r for r in boto.regioninfo.get_regions(\"ec2\")}\n        if region_name not in region_dict:\n            raise ValueError(\"No such EC2 region: {}. Check AWS_DEFAULT_REGION \"\n                             \"environment variable\".format(region_name))\n        _REGION = region_dict[region_name]\n    return _REGION"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning if the cache is valid.", "response": "def _is_valid_cache():\n    \"\"\"\n    Returns if the cache is valid (exists and modified within the interval).\n    :return: Whether the cache is valid.\n    :rtype: ``bool``\n    \"\"\"\n    if not os.path.exists(get_cache_location()):\n        return False\n    modified = os.path.getmtime(get_cache_location())\n    modified = time.ctime(modified)\n    modified = datetime.strptime(modified, '%a %b %d %H:%M:%S %Y')\n    return datetime.now() - modified <= CACHE_EXPIRATION_INTERVAL"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _list_all_cached():\n    with open(get_cache_location()) as f:\n        contents = f.read()\n        objects = json.loads(contents)\n        return [HostEntry.from_dict(obj) for obj in objects]", "response": "Reads the description cache and returns each instance s information."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_entries(entries, filters, exclude):\n    filtered = [entry\n                for entry in entries\n                if all(entry.matches(f) for f in filters)\n                and not any(entry.matches(e) for e in exclude)]\n    return filtered", "response": "Filters a list of host entries according to the given filters."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the public dns name of name if it exists.", "response": "def get_host(name):\n    \"\"\"\n    Prints the public dns name of `name`, if it exists.\n\n    :param name: The instance name.\n    :type name: ``str``\n    \"\"\"\n    f = {'instance-state-name': 'running', 'tag:Name': name}\n    ec2 = boto.connect_ec2(region=get_region())\n    rs = ec2.get_all_instances(filters=f)\n    if len(rs) == 0:\n        raise Exception('Host \"%s\" not found' % name)\n    print(rs[0].instances[0].public_dns_name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_dict(cls, entry_dict):\n        return cls(\n            name=entry_dict[\"name\"],\n            instance_type=entry_dict[\"instance_type\"],\n            hostname=entry_dict[\"hostname\"],\n            private_ip=entry_dict[\"private_ip\"],\n            public_ip=entry_dict[\"public_ip\"],\n            stack_name=entry_dict[\"stack_name\"],\n            stack_id=entry_dict[\"stack_id\"],\n            logical_id=entry_dict[\"logical_id\"],\n            security_groups=entry_dict[\"security_groups\"],\n            tags=entry_dict[\"tags\"],\n            ami_id=entry_dict[\"ami_id\"],\n            launch_time=entry_dict[\"launch_time\"],\n            instance_id=entry_dict[\"instance_id\"]\n        )", "response": "Deserialize a HostEntry object from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive an attribute name, looks it up on the entry. Names that start with ``tags.`` are looked up in the ``tags`` dictionary. :param attr: Name of attribute to look up. :type attr: ``str`` :param convert_to_str: Convert result to a string. :type convert_to_str: ``bool`` :rtype: ``object``", "response": "def _get_attrib(self, attr, convert_to_str=False):\n        \"\"\"\n        Given an attribute name, looks it up on the entry. Names that\n        start with ``tags.`` are looked up in the ``tags`` dictionary.\n\n        :param attr: Name of attribute to look up.\n        :type attr: ``str``\n        :param convert_to_str: Convert result to a string.\n        :type convert_to_str: ``bool``\n\n        :rtype: ``object``\n        \"\"\"\n        if attr.startswith('tags.'):\n            tag = attr[len('tags.'):]\n            if tag in self.tags and self.tags[tag] != '':\n                return self.tags[tag]\n            elif convert_to_str is True:\n                return '<not set>'\n            else:\n                return self.tags.get(tag)\n        elif not hasattr(self, attr):\n            raise AttributeError('Invalid attribute: {0}. Perhaps you meant '\n                                 '{1}?'.format(red(attr),\n                                               green('tags.' + attr)))\n        else:\n            result = getattr(self, attr)\n            if convert_to_str is True and not result:\n                return '<none>'\n            elif convert_to_str is True and isinstance(result, list):\n                return ', '.join(result)\n            elif convert_to_str is True:\n                return str(result)\n            else:\n                return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting all of the attributes that are found on an instance of this class.", "response": "def list_attributes(cls):\n        \"\"\"\n        Lists all of the attributes to be found on an instance of this class.\n        It creates a \"fake instance\" by passing in `None` to all of the\n        ``__init__`` arguments, then returns all of the attributes of that\n        instance.\n\n        :return: A list of instance attributes of this class.\n        :rtype: ``list`` of ``str``\n        \"\"\"\n        fake_args = [None for _ in inspect.getargspec(cls.__init__).args[1:]]\n        fake_instance = cls(*fake_args)\n        return vars(fake_instance).keys()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsort a list of entries by the given attribute.", "response": "def sort_by(cls, entries, attribute):\n        \"\"\"\n        Sorts a list of entries by the given attribute.\n        \"\"\"\n        def key(entry):\n            return entry._get_attrib(attribute, convert_to_str=True)\n        return sorted(entries, key=key)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef repr_as_line(self, additional_columns=None, only_show=None, sep=','):\n        additional_columns = additional_columns or []\n        if only_show is not None:\n            columns = _uniquify(only_show)\n        else:\n            columns = _uniquify(self.DEFAULT_COLUMNS + additional_columns)\n        to_display = [self._get_attrib(c, convert_to_str=True) for c in columns]\n        return sep.join(to_display)", "response": "Returns a string representation of the host as a single line."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads a HostEntry from a boto instance.", "response": "def from_boto_instance(cls, instance):\n        \"\"\"\n        Loads a ``HostEntry`` from a boto instance.\n\n        :param instance: A boto instance object.\n        :type instance: :py:class:`boto.ec2.instanceInstance`\n\n        :rtype: :py:class:`HostEntry`\n        \"\"\"\n        return cls(\n            name=instance.tags.get('Name'),\n            private_ip=instance.private_ip_address,\n            public_ip=instance.ip_address,\n            instance_type=instance.instance_type,\n            instance_id=instance.id,\n            hostname=instance.dns_name,\n            stack_id=instance.tags.get('aws:cloudformation:stack-id'),\n            stack_name=instance.tags.get('aws:cloudformation:stack-name'),\n            logical_id=instance.tags.get('aws:cloudformation:logical-id'),\n            security_groups=[g.name for g in instance.groups],\n            launch_time=instance.launch_time,\n            ami_id=instance.image_id,\n            tags={k.lower(): v for k, v in six.iteritems(instance.tags)}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef matches(self, _filter):\n        within_attrib = re.match(r'^([a-z_.]+):(.*)', _filter)\n        having_attrib = re.match(r'^([a-z_.]+)\\?$', _filter)\n        if within_attrib is not None:\n            # Then we're matching against a specific attribute.\n            val = self._get_attrib(within_attrib.group(1))\n            sub_regex = within_attrib.group(2)\n            if len(sub_regex) > 0:\n                sub_regex = re.compile(sub_regex, re.IGNORECASE)\n                return _match_regex(sub_regex, val)\n            else:\n                # Then we are matching on the value being empty.\n                return val == '' or val is None or val == []\n        elif having_attrib is not None:\n            # Then we're searching for anything that has a specific attribute.\n            val = self._get_attrib(having_attrib.group(1))\n            return val != '' and val is not None and val != []\n        else:\n            regex = re.compile(_filter, re.IGNORECASE)\n            return _match_regex(regex, vars(self))", "response": "Returns True if the entry matches the given filter text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the best name to display for this host. Uses the instance name if available otherwise just the public IP.", "response": "def display(self):\n        \"\"\"\n        Returns the best name to display for this host. Uses the instance\n        name if available; else just the public IP.\n\n        :rtype: ``str``\n        \"\"\"\n        if isinstance(self.name, six.string_types) and len(self.name) > 0:\n            return '{0} ({1})'.format(self.name, self.public_ip)\n        else:\n            return self.public_ip"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prettyname(cls, attrib_name):\n        if attrib_name.startswith('tags.'):\n            tagname = attrib_name[len('tags.'):]\n            return '{} (tag)'.format(tagname)\n        elif attrib_name in cls.COLUMN_NAMES:\n            return cls.COLUMN_NAMES[attrib_name]\n        else:\n            return attrib_name", "response": "Returns the pretty name of an attribute by its name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a string containing 0 or more variables and formats itacute. txt and returns the formatted string according to this instance s attributes.", "response": "def format_string(self, fmat_string):\n        \"\"\"\n        Takes a string containing 0 or more {variables} and formats it\n        according to this instance's attributes.\n\n        :param fmat_string: A string, e.g. '{name}-foo.txt'\n        :type fmat_string: ``str``\n\n        :return: The string formatted according to this instance. E.g.\n                 'production-runtime-foo.txt'\n        :rtype: ``str``\n        \"\"\"\n        try:\n            return fmat_string.format(**vars(self))\n        except KeyError as e:\n            raise ValueError('Invalid format string: {0}. Instance has no '\n                             'attribute {1}.'.format(repr(fmat_string),\n                                                     repr(e)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nattach the event time as unix epoch", "response": "def add_timestamp(logger_class, log_method, event_dict):\n    ''' Attach the event time, as unix epoch '''\n    event_dict['timestamp'] = calendar.timegm(time.gmtime())\n    return event_dict"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef logger(name=__name__, output=None, uuid=False, timestamp=False):\n    ''' Configure and return a new logger for hivy modules '''\n    processors = []\n    if output == 'json':\n        processors.append(structlog.processors.JSONRenderer())\n\n    if uuid:\n        processors.append(add_unique_id)\n    if uuid:\n        processors.append(add_timestamp)\n    return structlog.wrap_logger(\n        logbook.Logger(name),\n        processors=processors\n    )", "response": "Configure and return a new logger for hivy modules"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimplement celery workers using json and redis", "response": "def setup(title, output='json', timezone=None):\n    ''' Implement celery workers using json and redis '''\n    timezone = timezone or dna.time_utils._detect_timezone()\n\n    broker_url = 'redis://{}:{}/{}'.format(\n        os.environ.get('BROKER_HOST', 'localhost'),\n        os.environ.get('BROKER_PORT', 6379),\n        0\n    )\n\n    app = Celery(title, broker=broker_url)\n\n    app.conf.update(\n        CELERY_TASK_SERIALIZER=output,\n        CELERY_ACCEPT_CONTENT=[output],  # Ignore other content\n        CELERY_RESULT_SERIALIZER=output,\n        CELERY_RESULT_BACKEND=broker_url,\n        CELERY_TIMEZONE=timezone,\n        CELERYD_FORCE_EXECV=True,\n        CELERY_ENABLE_UTC=True,\n        CELERY_IGNORE_RESULT=False\n    )\n\n    return app"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, worker_id):\n        ''' Stop and remove a worker '''\n        code = 200\n\n        if worker_id in self.jobs:\n            # NOTE pop it if done ?\n            self.jobs[worker_id]['worker'].revoke(terminate=True)\n            report = {\n                'id': worker_id,\n                'revoked': True\n                # FIXME Unable to serialize self.jobs[worker_id]\n                # 'session': self.jobs.pop(worker_id)\n            }\n            self.jobs.pop(worker_id)\n        else:\n            report = {'error': 'job {} unknown'.format(worker_id)}\n            code = 404\n\n        return flask.jsonify(report), code", "response": "Stop and remove a worker"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(fw_name, args=None, items=None):\n\n    global DEBUG_LEVEL\n    global FRAMEWORK_NAME\n\n    debug_name = \"%s_DEBUG_LEVEL\" % fw_name.upper()\n    if debug_name in os.environ:\n        try:\n            DEBUG_LEVEL = int(os.environ.get(debug_name))\n        except ValueError:\n            DEBUG_LEVEL = 10  # Assume poorly formatted means \"debug\"\n    FRAMEWORK_NAME = fw_name\n\n    if args is None:\n        args = sys.argv[1:]\n\n    if items is None:\n        items = list(globals().items())\n\n    yaclifw_parser, sub_parsers = parsers()\n\n    for name, MyCommand in sorted(items):\n        if not isinstance(MyCommand, type):\n            continue\n        if not issubclass(MyCommand, Command):\n            continue\n        if MyCommand.NAME == \"abstract\":\n            continue\n        MyCommand(sub_parsers)\n\n    ns = yaclifw_parser.parse_args(args)\n    ns.func(ns)\n    if hasattr(ns, 'callback'):\n        if callable(ns.callback):\n            ns.callback()\n        else:\n            raise Stop(3, \"Callback not callable\")", "response": "Entry point for the YACLIFW CLI."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndefines a switchable ConfOpt.", "response": "def switch_opt(default, shortname, help_msg):\n    \"\"\"Define a switchable ConfOpt.\n\n    This creates a boolean option. If you use it in your CLI, it can be\n    switched on and off by prepending + or - to its name: +opt / -opt.\n\n    Args:\n        default (bool): the default value of the swith option.\n        shortname (str): short name of the option, no shortname will be used if\n            it is set to None.\n        help_msg (str): short description of the option.\n\n    Returns:\n        :class:`~loam.manager.ConfOpt`: a configuration option with the given\n        properties.\n    \"\"\"\n    return ConfOpt(bool(default), True, shortname,\n                   dict(action=internal.Switch), True, help_msg, None)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef config_conf_section():\n    config_dict = OrderedDict((\n        ('create',\n            ConfOpt(None, True, None, {'action': 'store_true'},\n                    False, 'create most global config file')),\n        ('create_local',\n            ConfOpt(None, True, None, {'action': 'store_true'},\n                    False, 'create most local config file')),\n        ('update',\n            ConfOpt(None, True, None, {'action': 'store_true'},\n                    False, 'add missing entries to config file')),\n        ('edit',\n            ConfOpt(None, True, None, {'action': 'store_true'},\n                    False, 'open config file in a text editor')),\n        ('editor',\n            ConfOpt('vim', False, None, {}, True, 'text editor')),\n    ))\n    return config_dict", "response": "Define a configuration section handling config file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets options from a list of section. option = value string.", "response": "def set_conf_str(conf, optstrs):\n    \"\"\"Set options from a list of section.option=value string.\n\n    Args:\n        conf (:class:`~loam.manager.ConfigurationManager`): the conf to update.\n        optstrs (list of str): the list of 'section.option=value' formatted\n            string.\n    \"\"\"\n    falsy = ['0', 'no', 'n', 'off', 'false', 'f']\n    bool_actions = ['store_true', 'store_false', internal.Switch]\n    for optstr in optstrs:\n        opt, val = optstr.split('=', 1)\n        sec, opt = opt.split('.', 1)\n        if sec not in conf:\n            raise error.SectionError(sec)\n        if opt not in conf[sec]:\n            raise error.OptionError(opt)\n        meta = conf[sec].def_[opt]\n        if meta.default is None:\n            if 'type' in meta.cmd_kwargs:\n                cast = meta.cmd_kwargs['type']\n            else:\n                act = meta.cmd_kwargs.get('action')\n                cast = bool if act in bool_actions else str\n        else:\n            cast = type(meta.default)\n        if cast is bool and val.lower() in falsy:\n            val = ''\n        conf[sec][opt] = cast(val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimplements the behavior of a subcmd using config_conf_section ArcGIS", "response": "def config_cmd_handler(conf, config='config'):\n    \"\"\"Implement the behavior of a subcmd using config_conf_section\n\n    Args:\n        conf (:class:`~loam.manager.ConfigurationManager`): it should contain a\n            section created with :func:`config_conf_section` function.\n        config (str): name of the configuration section created with\n            :func:`config_conf_section` function.\n    \"\"\"\n    if conf[config].create or conf[config].update:\n        conf.create_config_(update=conf[config].update)\n    if conf[config].create_local:\n        conf.create_config_(index=-1, update=conf[config].update)\n    if conf[config].edit:\n        if not conf.config_files_[0].is_file():\n            conf.create_config_(update=conf[config].update)\n        subprocess.call(shlex.split('{} {}'.format(conf[config].editor,\n                                                   conf.config_files_[0])))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates completion files for zsh and bash.", "response": "def create_complete_files(climan, path, cmd, *cmds, zsh_sourceable=False):\n    \"\"\"Create completion files for bash and zsh.\n\n    Args:\n        climan (:class:`~loam.cli.CLIManager`): CLI manager.\n        path (path-like): directory in which the config files should be\n            created. It is created if it doesn't exist.\n        cmd (str): command name that should be completed.\n        cmds (str): extra command names that should be completed.\n        zsh_sourceable (bool): if True, the generated file will contain an\n            explicit call to ``compdef``, which means it can be sourced\n            to activate CLI completion.\n    \"\"\"\n    path = pathlib.Path(path)\n    zsh_dir = path / 'zsh'\n    if not zsh_dir.exists():\n        zsh_dir.mkdir(parents=True)\n    zsh_file = zsh_dir / '_{}.sh'.format(cmd)\n    bash_dir = path / 'bash'\n    if not bash_dir.exists():\n        bash_dir.mkdir(parents=True)\n    bash_file = bash_dir / '{}.sh'.format(cmd)\n    climan.zsh_complete(zsh_file, cmd, *cmds, sourceable=zsh_sourceable)\n    climan.bash_complete(bash_file, cmd, *cmds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_columns(columns, write_borders=True, column_colors=None):\n    if column_colors is not None and len(column_colors) != len(columns):\n        raise ValueError('Wrong number of column colors')\n    widths = [max(len(cell) for cell in column) for column in columns]\n    max_column_length = max(len(column) for column in columns)\n    result = '\\n'.join(render_row(i, columns, widths, column_colors)\n                       for i in range(max_column_length))\n    if write_borders:\n        border = '+%s+' % '|'.join('-' * (w + 2) for w in widths)\n        return '%s\\n%s\\n%s' % (border, result, border)\n    else:\n        return result", "response": "Renders a list of columns."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_row(num, columns, widths, column_colors=None):\n    row_str = '|'\n    cell_strs = []\n    for i, column in enumerate(columns):\n        try:\n            cell = column[num]\n            # We choose the number of spaces before we color the string, so\n            # that the coloring codes don't affect the length.\n            spaces = ' ' * (widths[i] - len(cell))\n            if column_colors is not None and column_colors[i] is not None:\n                cell = column_colors[i](cell)\n            cell_strs.append(' %s%s ' % (cell, spaces))\n        except IndexError:\n            # If the index is out of range, just print an empty cell.\n            cell_strs.append(' ' * (widths[i] + 2))\n    return '|%s|' % '|'.join(cell_strs)", "response": "Render the numth row of each column in columns."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render_table(table, write_borders=True, column_colors=None):\n    prepare_rows(table)\n    columns = transpose_table(table)\n    return render_columns(columns, write_borders, column_colors)", "response": "Renders a table. A table is a list of rows, each of which is a list\n    of arbitrary objects. The `.str` method will be called on each element\n    of the row. Jagged tables are ok; in this case, each row will be expanded\n    to the maximum row length.\n\n    :param table: A list of rows, as described above.\n    :type table: [[``object``]]\n    :param write_borders: Whether there should be a border on the top and\n                          bottom. Defaults to ``True``.\n    :type write_borders: ``bool``\n    :param column_colors: An optional list of coloring *functions* to be\n                          applied to each cell in each column. If provided,\n                          the list's length must be equal to the maximum\n                          number of columns. ``None`` can be mixed in to this\n                          list so that a selection of columns can be colored.\n    :type column_colors: [``str`` -> ``str``] or ``NoneType``\n\n    :return: The rendered table.\n    :rtype: ``str``"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransposes a table into rows and columns.", "response": "def transpose_table(table):\n    \"\"\"\n    Transposes a table, turning rows into columns.\n    :param table: A 2D string grid.\n    :type table: [[``str``]]\n\n    :return: The same table, with rows and columns flipped.\n    :rtype: [[``str``]]\n    \"\"\"\n    if len(table) == 0:\n        return table\n    else:\n        num_columns = len(table[0])\n        return [[row[i] for row in table] for i in range(num_columns)]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npreparing the rows so they re all strings and all the same length.", "response": "def prepare_rows(table):\n    \"\"\"\n    Prepare the rows so they're all strings, and all the same length.\n\n    :param table: A 2D grid of anything.\n    :type table: [[``object``]]\n\n    :return: A table of strings, where every row is the same length.\n    :rtype: [[``str``]]\n    \"\"\"\n    num_columns = max(len(row) for row in table)\n    for row in table:\n        while len(row) < num_columns:\n            row.append('')\n        for i in range(num_columns):\n            row[i] = str(row[i]) if row[i] is not None else ''\n    return table"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_table_width(table):\n    columns = transpose_table(prepare_rows(table))\n    widths = [max(len(cell) for cell in column) for column in columns]\n    return len('+' + '|'.join('-' * (w + 2) for w in widths) + '+')", "response": "Returns the width of the table that would be printed."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef color(number):\n    if supports_256():\n        template = \"\\033[38;5;{number}m{text}\\033[0m\"\n    else:\n        template = \"\\033[{number}m{text}\\033[0m\"\n    def _color(text):\n        if not all([sys.stdout.isatty(), sys.stderr.isatty()]):\n            return text\n        else:\n            return template.format(number=number, text=text)\n    return _color", "response": "Color function that colors a string with a number from 0 to 255."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_color_hash(string, _min=MIN_COLOR_BRIGHT, _max=MAX_COLOR_BRIGHT):\n    hash_num = int(hashlib.sha1(string.encode('utf-8')).hexdigest()[:6], 16)\n    _range = _max - _min\n    num_in_range = hash_num % _range\n    return color(_min + num_in_range)", "response": "Get a color from a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a random color between min and max.", "response": "def random_color(_min=MIN_COLOR, _max=MAX_COLOR):\n    \"\"\"Returns a random color between min and max.\"\"\"\n    return color(random.randint(_min, _max))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads stdin returns a string if possible.", "response": "def get_input(prompt, default=None, exit_msg='bye!'):\n    \"\"\"\n    Reads stdin, exits with a message if interrupted, EOF, or a quit message.\n\n    :return: The entered input. Converts to an integer if possible.\n    :rtype: ``str`` or ``int``\n    \"\"\"\n    try:\n        response = six.moves.input(prompt)\n    except (KeyboardInterrupt, EOFError):\n        print()\n        print(exit_msg)\n        exit()\n    try:\n        return int(response)\n    except ValueError:\n        if response.strip() == \"\" and default is not None:\n            return default\n        else:\n            return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nverifies basic http authentification", "response": "def check_credentials(username, password):\n    ''' Verify basic http authentification '''\n    user = models.User.objects(\n        username=username,\n        password=password\n    ).first()\n    return user or None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nverifies http header token authentification", "response": "def check_token(token):\n    ''' Verify http header token authentification '''\n    user = models.User.objects(api_key=token).first()\n    return user or None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_running(process):\n    ''' `pgrep` returns an error code if no process was found '''\n    try:\n        pgrep = sh.Command('/usr/bin/pgrep')\n        pgrep(process)\n        flag = True\n    except sh.ErrorReturnCode_1:\n        flag = False\n    return flag", "response": "Returns True if the process is running."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntakes a string and return the corresponding module", "response": "def dynamic_import(mod_path, obj_name=None):\n    ''' Take a string and return the corresponding module '''\n    try:\n        module = __import__(mod_path, fromlist=['whatever'])\n    except ImportError, error:\n        raise errors.DynamicImportFailed(\n            module='.'.join([mod_path, obj_name]), reason=error)\n    # Make sure we're up-to-date\n    reload(module)\n\n    if obj_name is None:\n        obj = module\n    elif hasattr(module, obj_name):\n        obj = getattr(module, obj_name)\n    else:\n        raise errors.DynamicImportFailed(\n            module='.'.join([mod_path, obj_name]),\n            reason='module {} has no attribute {}'.\n                   format(module.__name__, obj_name))\n        return None\n\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes the HTTP request using the RESTClient.", "response": "def request(self, method, url, query_params=None, headers=None,\n                post_params=None, body=None):\n        \"\"\"\n        Makes the HTTP request using RESTClient.\n        \"\"\"\n        if method == \"GET\":\n            return self.rest_client.GET(url,\n                                        query_params=query_params,\n                                        headers=headers)\n        elif method == \"HEAD\":\n            return self.rest_client.HEAD(url,\n                                         query_params=query_params,\n                                         headers=headers)\n        elif method == \"OPTIONS\":\n            return self.rest_client.OPTIONS(url,\n                                            query_params=query_params,\n                                            headers=headers,\n                                            post_params=post_params,\n                                            body=body)\n        elif method == \"POST\":\n            return self.rest_client.POST(url,\n                                         query_params=query_params,\n                                         headers=headers,\n                                         post_params=post_params,\n                                         body=body)\n        elif method == \"PUT\":\n            return self.rest_client.PUT(url,\n                                        query_params=query_params,\n                                        headers=headers,\n                                        post_params=post_params,\n                                        body=body)\n        elif method == \"PATCH\":\n            return self.rest_client.PATCH(url,\n                                          query_params=query_params,\n                                          headers=headers,\n                                          post_params=post_params,\n                                          body=body)\n        elif method == \"DELETE\":\n            return self.rest_client.DELETE(url,\n                                           query_params=query_params,\n                                           headers=headers)\n        else:\n            raise ValueError(\n                \"http method must be `GET`, `HEAD`,\"\n                \" `POST`, `PATCH`, `PUT` or `DELETE`.\"\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepare_post_parameters(self, post_params=None, files=None):\n        params = {}\n\n        if post_params:\n            params.update(post_params)\n\n        if files:\n            for k, v in iteritems(files):\n                if not v:\n                    continue\n\n                with open(v, 'rb') as f:\n                    filename = os.path.basename(f.name)\n                    filedata = f.read()\n                    mimetype = mimetypes.\\\n                        guess_type(filename)[0] or 'application/octet-stream'\n                    params[k] = tuple([filename, filedata, mimetype])\n\n        return params", "response": "Prepare form parameters for post processing."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serve(self, app_docopt=DEFAULT_DOC, description=''):\n        ''' Configure from cli and run the server '''\n\n        exit_status = 0\n        if isinstance(app_docopt, str):\n            args = docopt(app_docopt, version=description)\n        elif isinstance(app_docopt, dict):\n            args = app_docopt\n        else:\n            raise ValueError('unknown configuration object ({})'\n                             .format(type(app_docopt)))\n        log_level = args.get('--log', 'debug')\n        is_debug = args.get('--debug', False)\n        # TODO More serious default\n        log_output = 'stdout' if is_debug else 'apy.log'\n        safe_bind = args.get('--bind', '127.0.0.1')\n        safe_port = int(args.get('--port', 5000))\n        log_setup = dna.logging.setup(level=log_level, output=log_output)\n\n        with log_setup.applicationbound():\n            try:\n                log.info('server ready',\n                         version=description,\n                         log=log_level,\n                         debug=is_debug,\n                         bind='{}:{}'.format(safe_bind, safe_port))\n\n                self.app.run(host=safe_bind,\n                             port=safe_port,\n                             debug=is_debug)\n\n            except Exception as error:\n                if is_debug:\n                    raise\n                log.error('{}: {}'.format(type(error).__name__, str(error)))\n                exit_status = 1\n\n            finally:\n                log.info('session ended with status {}'.format(exit_status))\n\n        return exit_status", "response": "Configure from cli and run the server"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nincluding a hidden input to stored the serialized upload value.", "response": "def render(self, name, value, attrs=None):\n        \"\"\"Include a hidden input to stored the serialized upload value.\"\"\"\n        context = attrs or {}\n        context.update({'name': name, 'value': value, })\n        return render_to_string(self.template_name, context)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns a bash command and returns a list of lines.", "response": "def stream_command(command, formatter=None, write_stdin=None, ignore_empty=False):\n    \"\"\"\n    Starts `command` in a subprocess. Prints every line the command prints,\n    prefaced with `description`.\n\n    :param command: The bash command to run. Must use fully-qualified paths.\n    :type command: ``str``\n    :param formatter: An optional formatting function to apply to each line.\n    :type formatter: ``function`` or ``NoneType``\n    :param write_stdin: An optional string to write to the process' stdin.\n    :type write_stdin: ``str`` or ``NoneType``\n    :param ignore_empty: If true, empty or whitespace-only lines will be skipped.\n    :type ignore_empty: ``bool``\n    \"\"\"\n    command_list = shlex.split(command)\n    try:\n        proc = subprocess.Popen(command_list, stdout=subprocess.PIPE,\n                                stderr=subprocess.STDOUT, stdin=subprocess.PIPE)\n    except Exception as e:\n        raise IOError('Encountered error: {0} when running command {1}'\n                      .format(e.message, ' '.join(command_list)))\n    if write_stdin is not None:\n        proc.stdin.write(write_stdin)\n        proc.stdin.flush()\n\n    while proc.poll() is None:\n        try:\n            line = proc.stdout.readline()\n        except KeyboardInterrupt:\n            sys.exit('Keyboard interrupt while running {}'.format(command))\n        if len(line.strip()) == 0 and ignore_empty is True:\n            continue\n        elif 'killed by signal 1' in decode(line).lower():\n            continue\n        elif 'to the list of known hosts' in decode(line).lower():\n            continue\n        if formatter is not None:\n            line = formatter(line)\n        sys.stdout.write(line)\n    result = proc.poll()\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stream_command_dicts(commands, parallel=False):\n    if parallel is True:\n        threads = []\n        for command in commands:\n            target = lambda: stream_command(**command)\n            thread = Thread(target=target)\n            thread.start()\n            threads.append(thread)\n        for t in threads:\n            t.join()\n    else:\n        for command in commands:\n            stream_command(**command)", "response": "Takes a list of dictionaries with keys corresponding to stream_command arguments and runs all of them in parallel."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stream_commands(commands, hash_colors=True, parallel=False):\n    def _get_color(string):\n        if hash_colors is True:\n            return get_color_hash(string)\n        else:\n            return DEFAULT_COLOR\n    fixed_commands = []\n    for command in commands:\n        cmd_text = command['command']\n        description = command.get('description')\n        color = _get_color(description or '')\n        write_stdin = command.get('write_stdin')\n        description = color(description) if color is not None else description\n        formatter = _format_with_description(description)\n        fixed_commands.append({\n            'command': cmd_text,\n            'formatter': formatter,\n            'write_stdin': write_stdin,\n            'ignore_empty': True\n        })\n    stream_command_dicts(fixed_commands, parallel=parallel)", "response": "Runs multiple commands optionally in parallel."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef networkdays(from_date, to_date, locale='en-US'):\n    holidays = locales[locale]\n    return workdays.networkdays(from_date, to_date, holidays)", "response": "Return the net work days according to RH s calendar."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge(dicto, other):\n    if not isinstance(dicto, Dicto):\n        dicto = Dicto(dicto)\n\n    if not isinstance(other, Dicto):\n        other = Dicto(other)\n\n    for k, v in other.__dict__.items():\n        if k in dicto and isinstance(dicto[k], Dicto) and isinstance(other[k], Dicto):\n            dicto[k] = merge(dicto[k], other[k])\n        else:\n            dicto[k] = other[k]\n    \n    return dicto", "response": "Recursive dict merge. Inspired by dict. update."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _run_ssh(entries, username, idfile, no_prompt=False, command=None,\n             show=None, only=None, sort_by=None, limit=None, tunnel=None,\n             num=None, random=False):\n    \"\"\"\n    Lets the user choose which instance to SSH into.\n\n    :param entries: The list of host entries.\n    :type entries: [:py:class:`HostEntry`]\n    :param username: The SSH username to use. Defaults to current user.\n    :type username: ``str`` or ``NoneType``\n    :param idfile: The identity file to use. Optional.\n    :type idfile: ``str`` or ``NoneType``\n    :param no_prompt: Whether to disable confirmation for SSH command.\n    :type no_prompt: ``bool``\n    :param command: SSH command to run on matching instances.\n    :type command: ``str`` or ``NoneType``\n    :param show: Instance attributes to show in addition to defaults.\n    :type show: ``NoneType`` or ``list`` of ``str``\n    :param only: If not ``None``, will *only* show these attributes.\n    :type only: ``NoneType`` or ``list`` of ``str``\n    :param sort_by: What to sort columns by. By default, sort by 'name'.\n    :type sort_by: ``str``\n    :param limit: At most how many results to show.\n    :type limit: ``int`` or ``NoneType``\n    :param num: If not None, choose the given entry from within filters.\n    :type num: ``int`` or ``NoneType``\n    :param random: If true, choose a random entry from within filters.\n    :type random: ``bool``\n    \"\"\"\n    _print_entries = num is None\n    _print_help = False\n    if len(entries) == 0:\n        exit('No entries matched the filters.')\n    if no_prompt is True and command is not None:\n        return _run_ssh_command(entries, username, idfile, command, tunnel)\n    elif len(entries) == 1 or random is True:\n        entry = py_random.choice(entries)\n        if command is None:\n            return _connect_ssh(entry, username, idfile, tunnel)\n        else:\n            return _run_ssh_command([entry], username, idfile, command, tunnel)\n    elif command is not None:\n        print(HostEntry.render_entries(entries,\n                                       additional_columns=show,\n                                       only_show=only, numbers=True))\n        if no_prompt is False:\n            get_input(\"Press enter to run command {} on the {} \"\n                      \"above machines (Ctrl-C to cancel)\"\n                      .format(cyan(command), len(entries)))\n        return _run_ssh_command(entries, username, idfile, command, tunnel)\n    else:\n        while True:\n            if sort_by is not None:\n                entries = HostEntry.sort_by(entries, sort_by)\n            if limit is not None:\n                entries = entries[:limit]\n            if _print_entries is True:\n                print(HostEntry.render_entries(entries,\n                                               additional_columns=show,\n                                               only_show=only, numbers=True))\n                print('%s matching entries.' % len(entries))\n                _print_entries = False\n            if _print_help is True:\n                cmd_str = green(command) if command is not None else 'none set'\n                msg = COMMANDS_STRING.format(username=username or 'none set',\n                                             idfile=idfile or 'none set',\n                                             cur_cmd=cmd_str)\n                print(msg)\n                _print_help = False\n            elif command is not None:\n                print('Set to run ssh command: %s' % cyan(command))\n            msg = 'Enter command (%s for help, %s to quit): ' % (cyan('h'),\n                                                                 cyan('q'))\n            if num is not None:\n                choice = num\n            else:\n                choice = get_input(msg)\n            if isinstance(choice, int):\n                if 0 <= choice <= len(entries):\n                    break\n                else:\n                    if num is not None:\n                        exit(\"Invalid number {}: must be between 0 and {}\"\n                             .format(num, len(entries) - 1))\n                    else:\n                        msg = \"Invalid number: must be between 0 and %s\"\n                        print(msg % (len(entries) - 1))\n            elif choice == 'x':\n                if command is None:\n                    print('No command has been set. Set command with `c`')\n                else:\n                    return _run_ssh_command(entries, username, idfile,\n                                            command, tunnel)\n            elif choice == 'h':\n                _print_help = True\n            elif choice in ['q', 'quit', 'exit']:\n                print('bye!')\n                return\n            else:\n                # All of these commands take one or more arguments, so the\n                # split length must be at least 2.\n                commands = choice.split()\n                if len(commands) < 2:\n                    print(yellow('Unknown command \"%s\".' % choice))\n                else:\n                    cmd = commands[0]\n                    if cmd in ['u', 'i', 'p']:\n                        if cmd == 'u':\n                            username = commands[1]\n                        elif cmd == 'i':\n                            _idfile = commands[1]\n                            if not os.path.exists(_idfile):\n                                print(yellow('No such file: %s' % _idfile))\n                                continue\n                            idfile = _idfile\n                        elif cmd == 'p':\n                            p = commands[1]\n                            try:\n                                profile = LsiProfile.load(p)\n                                _username = profile.username\n                                _idfile = expanduser(profile.identity_file)\n                            except LsiProfile.LoadError:\n                                print(yellow('No such profile: %s' % repr(p)))\n                                continue\n                            username = _username\n                            idfile = _idfile\n                        print('username: %s' % green(repr(username)))\n                        print('identity file: %s' % green(repr(idfile)))\n                    elif cmd == 'f':\n                        entries = filter_entries(entries, commands[1:], [])\n                        _print_entries = True\n                    elif cmd == 'e':\n                        entries = filter_entries(entries, [], commands[1:])\n                        _print_entries = True\n                    elif cmd == 'c':\n                        command = ' '.join(commands[1:])\n                    elif cmd == 'limit':\n                        try:\n                            limit = int(commands[1])\n                            _print_entries = True\n                        except ValueError:\n                            print(yellow('Invalid limit (must be an integer)'))\n                    elif cmd == 'sort':\n                        sort_by = commands[1]\n                        if sort_by not in show:\n                            show.append(sort_by)\n                        _print_entries = True\n                    elif cmd == 'show':\n                        if show is None:\n                            show = commands[1:]\n                        else:\n                            show.extend(commands[1:])\n                        _print_entries = True\n                    else:\n                        print(yellow('Unknown command \"%s\".' % cmd))\n        return _connect_ssh(entries[choice], username, idfile, tunnel)", "response": "Run a command on a list of host entries on the SSH server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_path(cmd):\n    if cmd in _PATHS:\n        return _PATHS[cmd]\n    out = subprocess.check_output('which {}'.format(cmd), shell=True)\n    _PATHS[cmd] = out.decode(\"utf-8\").strip()\n    return _PATHS[cmd]", "response": "Queries bash to find the path to a commmand on the system."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _build_ssh_command(hostname, username, idfile, ssh_command, tunnel):\n    command = [_get_path('ssh'),\n               '-o', 'StrictHostKeyChecking=no',\n               '-o', 'ConnectTimeout=5']\n    if idfile is not None:\n        command.extend(['-i', idfile])\n    if tunnel is not None:\n        # If there's a tunnel, run the ssh command on the tunneled host.\n        command.extend(['-A', '-t', tunnel, 'ssh', '-A', '-t'])\n    if username is not None:\n        command.append('{}@{}'.format(username, hostname))\n    else:\n        command.append(hostname)\n    if ssh_command is not None:\n        command.append(repr(ssh_command))\n    return(' '.join(command))", "response": "Builds an SSH command string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a SCP command.", "response": "def _build_scp_command(hostname, username, idfile, is_get,\n                       local_path, remote_path):\n    \"\"\"\n    Uses hostname and other info to construct an SCP command.\n\n    :param hostname: The hostname of the remote machine.\n    :type hostname: ``str``\n    :param username: The username to use on the remote machine.\n    :type username: ``str``\n    :param idfile: A path to the identity file to use.\n    :type idfile: ``str``\n    :param is_get: If true, we are getting a file rather than putting a file.\n    :type is_get: ``bool``\n    :param local_path: The path on the local file system.\n    :type local_path: ``str``\n    :param remote_path: The path on the remote file system.\n    :type remote_path: ``str``\n    \"\"\"\n    if hostname.strip() == '' or hostname is None:\n        raise ValueError('Empty hostname')\n    command = [_get_path('scp'),\n               '-o', 'StrictHostKeyChecking=no',\n               '-o', 'ConnectTimeout=5',\n               '-o', 'UserKnownHostsFile={}'.format(_KNOWN_HOSTS_FILE)]\n    if idfile is not None:\n        command.extend(['-i', idfile])\n    if username is not None:\n        hostname = '%s@%s' % (username, hostname)\n    remote_path = '{}:{}'.format(hostname, remote_path)\n    if is_get:\n        command.extend([remote_path, local_path])\n    else:\n        command.extend([local_path, remote_path])\n    return ' '.join(command)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncopies the given list of host entries to the given local path on the remote machine.", "response": "def _copy_to(entries, remote_path, local_path, profile):\n    \"\"\"\n    Performs an SCP command where the remote_path is the target and the\n    local_path is the source.\n\n    :param entries: A list of entries.\n    :type entries: ``list`` of :py:class:`HostEntry`\n    :param remote_path: The target path on the remote machine(s).\n    :type remote_path: ``str``\n    :param local_path: The source path on the local machine.\n    :type local_path: ``str``\n    :param profile: The profile, holding username/idfile info, etc.\n    :type profile: :py:class:`Profile`\n    \"\"\"\n    commands = []\n    for entry in entries:\n        hname = entry.hostname or entry.public_ip\n        cmd = _build_scp_command(hname, profile.username,\n                                 profile.identity_file,\n                                 is_get=False,\n                                 local_path=local_path,\n                                 remote_path=remote_path)\n        print('Command:', cmd)\n        commands.append({\n            'command': cmd,\n            'description': entry.display()\n        })\n    stream_commands(commands)\n    print(green('Finished copying'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncopies a list of host entries from the remote machine to the local machine.", "response": "def _copy_from(entries, remote_path, local_path, profile):\n    \"\"\"\n    Performs an SCP command where the remote_path is the source and the\n    local_path is a format string, formatted individually for each host\n    being copied from so as to create one or more distinct paths on the\n    local system.\n\n    :param entries: A list of entries.\n    :type entries: ``list`` of :py:class:`HostEntry`\n    :param remote_path: The source path on the remote machine(s).\n    :type remote_path: ``str``\n    :param local_path: A format string for the path on the local machine.\n    :type local_path: ``str``\n    :param profile: The profile, holding username/idfile info, etc.\n    :type profile: :py:class:`Profile`\n    \"\"\"\n    commands = []\n    paths = set()\n    for entry in entries:\n        hname = entry.hostname or entry.public_ip\n        _local_path = entry.format_string(local_path)\n        if _local_path in paths:\n            raise ValueError('Duplicate local paths: one or more paths '\n                             'had value {} after formatting.'\n                             .format(local_path))\n        paths.add(_local_path)\n        # If the path references a folder, create the folder if it doesn't\n        # exist.\n        _folder = os.path.split(_local_path)[0]\n        if len(_folder) > 0:\n            if not os.path.exists(_folder):\n                print('Creating directory ' + _folder)\n                os.makedirs(_folder)\n        cmd = _build_scp_command(hname, profile.username,\n                                 profile.identity_file,\n                                 is_get=True,\n                                 local_path=_local_path,\n                                 remote_path=remote_path)\n        print('Command:', cmd)\n        commands.append({\n            'command': cmd,\n            'description': entry.display()\n        })\n    stream_commands(commands)\n    print(green('Finished copying'))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun a given command on all hosts in entries.", "response": "def _run_ssh_command(entries, username, idfile, command, tunnel,\n                     parallel=False):\n    \"\"\"\n    Runs the given command over SSH in parallel on all hosts in `entries`.\n\n    :param entries: The host entries the hostnames from.\n    :type entries: ``list`` of :py:class:`HostEntry`\n    :param username: To use a specific username.\n    :type username: ``str`` or ``NoneType``\n    :param idfile: The SSH identity file to use, or none.\n    :type idfile: ``str`` or ``NoneType``\n    :param command: The command to run.\n    :type command: ``str``\n    :param parallel: If true, commands will be run in parallel.\n    :type parallel: ``bool``\n    \"\"\"\n    if len(entries) == 0:\n        print('(No hosts to run command on)')\n        return 1\n    if command.strip() == '' or command is None:\n        raise ValueError('No command given')\n    print('Running command {0} on {1} matching hosts'\n          .format(green(repr(command)), len(entries)))\n    shell_cmds = []\n    for entry in entries:\n        hname = entry.hostname or entry.public_ip\n        cmd = _build_ssh_command(hname, username, idfile, command, tunnel)\n        shell_cmds.append({\n            'command': cmd,\n            'description': entry.display()\n        })\n    stream_commands(shell_cmds, parallel=parallel)\n    print(green('All commands finished'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconnect to a host entry via SSH.", "response": "def _connect_ssh(entry, username, idfile, tunnel=None):\n    \"\"\"\n    SSH into to a host.\n\n    :param entry: The host entry to pull the hostname from.\n    :type entry: :py:class:`HostEntry`\n    :param username: To use a specific username.\n    :type username: ``str`` or ``NoneType``\n    :param idfile: The SSH identity file to use, if supplying a username.\n    :type idfile: ``str`` or ``NoneType``\n    :param tunnel: Host to tunnel SSH command through.\n    :type tunnel: ``str`` or ``NoneType``\n\n    :return: An exit status code.\n    :rtype: ``int``\n    \"\"\"\n    if entry.hostname != \"\" and entry.hostname is not None:\n        _host = entry.hostname\n    elif entry.public_ip != \"\" and entry.public_ip is not None:\n        _host = entry.public_ip\n    elif entry.private_ip != \"\" and entry.private_ip is not None:\n        if tunnel is None:\n            raise ValueError(\"Entry does not have a hostname or public IP. \"\n                             \"You can connect via private IP if you use a \"\n                             \"tunnel.\")\n        _host = entry.private_ip\n    else:\n        raise ValueError(\"No hostname, public IP or private IP information \"\n                         \"found on host entry. I don't know how to connect.\")\n    command = _build_ssh_command(_host, username, idfile, None, tunnel)\n    print('Connecting to %s...' % cyan(entry.display()))\n    print('SSH command: %s' % green(command))\n    proc = subprocess.Popen(command, shell=True)\n    return proc.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses command - line arguments.", "response": "def _get_args():\n    \"\"\"Parse command-line arguments.\"\"\"\n    parser = argparse.ArgumentParser(description='List EC2 instances')\n    parser.add_argument('-l', '--latest', action='store_true', default=False,\n                        help='Query AWS for latest instances')\n    parser.add_argument('--version', action='store_true', default=False,\n                        help='Print version and exit')\n    parser.add_argument('--refresh-only', action='store_true', default=False,\n                        help='Refresh cache and exit')\n    parser.add_argument('--host', help='Specific host to list',\n                        default=None)\n    parser.add_argument('-s', '--ssh', action='store_true',\n                        help='SSH to instance', default=False)\n    parser.add_argument('-i', '--identity-file', help='SSH identify file',\n                        default=None)\n    parser.add_argument('-u', '--username', default=None,\n                        help='Log in as this user')\n    parser.add_argument('filters', nargs='*',\n                        help='Text filters for output lines')\n    parser.add_argument('-v', '--exclude', nargs='+',\n                        help='Exclude results that match these')\n    parser.add_argument('-c', '--command', type=str,\n                        help='Command to run on matching instance(s)')\n    parser.add_argument('-y', '--no-prompt', action='store_true', default=False,\n                        help=\"Don't ask for confirmation before running a \"\n                             \"command\")\n    parser.add_argument('-p', '--profile', type=str,\n                        help='Profile to use (defined in ~/.lsi)')\n    parser.add_argument('--show', nargs='+', default=None,\n                        help='Instance attributes to show')\n    parser.add_argument('--only', nargs='+', default=None,\n                        help='Show ONLY these instance attributes')\n    parser.add_argument('--sep', type=str, default=None,\n                        help='Simple output with given separator')\n    parser.add_argument('--sort-by', type=str, default=\"name\",\n                        help='What to sort list by')\n    parser.add_argument('-L', '--limit', type=int, default=None,\n                        help='Show at most this many entries')\n    parser.add_argument('--attributes', action='store_true',\n                        help='Show all available attributes')\n    parser.add_argument('--get', nargs=2, default=None,\n                        help='Get files from matching instances, must be '\n                             'followed by the source and destination filenames')\n    parser.add_argument('--put', nargs=2, default=None,\n                        help='Put a local file on matching instances, must be '\n                             'followed by the source and destination filenames')\n    parser.add_argument('-t', '--tunnel', default=None,\n                        help='Connect via the tunneled host.')\n    parser.add_argument(\"-r\", \"--random\", action=\"store_true\", default=False,\n                        help=\"Choose a random instance from within results.\")\n    parser.add_argument(\"-n\", \"--num\", type=int, default=None,\n                        help=\"Choose the given number from within results.\")\n    args = parser.parse_args()\n    if args.exclude is None:\n        args.exclude = []\n    # Presumably, if someone is sorting by something, they want to show that\n    # thing...\n    if args.sort_by is not None:\n        args.show = (args.show or []) + [args.sort_by]\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(cls, profile_name=None):\n        lsi_location = os.path.expanduser('~/.lsi')\n        if not os.path.exists(lsi_location):\n            return LsiProfile()\n        cfg_parser = ConfigParser()\n        cfg_parser.read(lsi_location)\n        if profile_name is None:\n            # Load the default profile if one exists; otherwise return empty.\n            if cfg_parser.has_section('default'):\n                profile_name = 'default'\n            else:\n                return cls()\n        elif not cfg_parser.has_section(profile_name):\n            raise cls.LoadError('No such profile {}'.format(profile_name))\n        def _get(option, alt=None):\n            \"\"\"Gets an option if it exists; else returns `alt`.\"\"\"\n            if cfg_parser.has_option(profile_name, option):\n                return cfg_parser.get(profile_name, option)\n            else:\n                return alt\n        if cfg_parser.has_option(profile_name, 'inherit'):\n            profile = cls.load(cfg_parser.get(profile_name, 'inherit'))\n        else:\n            profile = cls()\n        profile.override('username', _get('username'))\n        profile.override('identity_file', _get('identity file'))\n        profile.override('command', _get('command'))\n        filters = [s for s in _get('filters', '').split(',') if len(s) > 0]\n        exclude = [s for s in _get('exclude', '').split(',') if len(s) > 0]\n        profile.filters.extend(filters)\n        profile.exclude.extend(exclude)\n        return profile", "response": "Loads the user s LSI profile or provides a default."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_args(args):\n        # If the args specify a username explicitly, don't load from file.\n        if args.username is not None or args.identity_file is not None:\n            profile = LsiProfile()\n        else:\n            profile = LsiProfile.load(args.profile)\n        profile.override('username', args.username)\n        profile.override('identity_file', args.identity_file)\n        profile.override('command', args.command)\n        profile.no_prompt = args.no_prompt\n        profile.filters.extend(args.filters)\n        profile.exclude.extend(args.exclude)\n        if profile.identity_file is not None:\n            profile.identity_file = os.path.expanduser(profile.identity_file)\n        return profile", "response": "Takes arguments parsed from argparse and returns a profile."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrelate this package component to the supplied part.", "response": "def relate(self, part, id=None):\n\t\t\"\"\"Relate this package component to the supplied part.\"\"\"\n\t\tassert part.name.startswith(self.base)\n\t\tname = part.name[len(self.base):].lstrip('/')\n\t\trel = Relationship(self, name, part.rel_type, id=id)\n\t\tself.relationships.add(rel)\n\t\treturn rel"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of parts related to this one via reltype.", "response": "def related(self, reltype):\n\t\t\"\"\"Return a list of parts related to this one via reltype.\"\"\"\n\t\tparts = []\n\t\tpackage = getattr(self, 'package', None) or self\n\t\tfor rel in self.relationships.types.get(reltype, []):\n\t\t\tparts.append(package[posixpath.join(self.base, rel.target)])\n\t\treturn parts"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads relationships from source XML.", "response": "def _load_rels(self, source):\n\t\t\"\"\"Load relationships from source XML.\"\"\"\n\t\t# don't get confused here - the original source is string data;\n\t\t#  the parameter source below is a Part object\n\t\tself.relationships.load(source=self, data=source)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a part to the package.", "response": "def add(self, part, override=True):\n\t\t\"\"\"Add a part to the package.\n\n\t\tIt will also add a content-type - by default an override.  If\n\t\toverride is False then it will add a content-type for the extension\n\t\tif one isn't already present.\n\t\t\"\"\"\n\t\tct_add_method = [\n\t\t\tself.content_types.add_default,\n\t\t\tself.content_types.add_override,\n                ][override]\n\t\tself[part.name] = part\n\t\tct_add_method(part)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_part(self, rel_type, name, data):\n\t\tif self.content_types.find_for(name) is None:\n\t\t\tlog.warning('no content type found for part %(name)s' % vars())\n\t\t\treturn\n\t\tcls = Part.classes_by_rel_type[rel_type]\n\t\tpart = cls(self, name)\n\t\tpart.load(data)\n\t\tself[name] = part\n\t\treturn part", "response": "Load a part into this package based on its relationship type and data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_parts_by_class(self, cls):\n\t\treturn (part for part in self.parts.values() if isinstance(part, cls))", "response": "Return all parts of this package that are instances of cls."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the correct content type for a given name", "response": "def find_for(self, name):\n\t\t\"\"\"\n\t\tGet the correct content type for a given name\n\t\t\"\"\"\n\t\tmap = self.items\n\t\t# first search the overrides (by name)\n\t\t# then fall back to the defaults (by extension)\n\t\t# finally, return None if unmatched\n\t\treturn map.get(name, None) or map.get(get_ext(name) or None, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives an element parse out the proper ContentType", "response": "def from_element(cls, element):\n\t\t\"given an element, parse out the proper ContentType\"\n\t\t# disambiguate the subclass\n\t\tns, class_name = parse_tag(element.tag)\n\t\tclass_ = getattr(ContentType, class_name)\n\t\tif not class_:\n\t\t\tmsg = 'Invalid Types child element: %(class_name)s' % vars()\n\t\t\traise ValueError(msg)\n\t\t# construct the subclass\n\t\tkey = element.get(class_.key_name)\n\t\tname = element.get('ContentType')\n\t\treturn class_(name, key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the given DSL string and returns parsed results.", "response": "def parse(input_string, prefix=''):\n  \"\"\"Parses the given DSL string and returns parsed results.\n\n  Args:\n    input_string (str): DSL string\n    prefix (str): Optional prefix to add to every element name, useful to namespace things\n\n  Returns:\n    dict: Parsed content\n\n  \"\"\"\n\n  tree = parser.parse(input_string)\n  visitor = ChatlVisitor(prefix)\n\n  visit_parse_tree(tree, visitor)\n\n  return visitor.parsed"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a final copy of the token using the given secret key.", "response": "def build(self, secret_key):\n        \"\"\"Builds a final copy of the token using the given secret key.\n\n        :param secret_key(string): The secret key that corresponds to this builder's access key.\n        \"\"\"\n        key = jwk.JWK(\n            kty='oct',\n            k=base64url_encode(uuid.UUID(secret_key).bytes),\n        )\n\n        header = {\n            'alg': 'dir',\n            'enc': 'A128GCM',\n            'zip': 'DEF',\n            'cty': 'JWT',\n            'kid': self._access_key,\n        }\n\n        now = int(time.time())\n\n        payload = {\n            'iat': now,\n            'nbf': now,\n        }\n\n        if self._expiration is not None:\n            payload['exp'] = int(calendar.timegm(self._expiration.utctimetuple()))\n\n        if len(self._view_identifiers) > 0:\n            payload[VIEW_IDENTIFIERS_CLAIM_NAME] = self._view_identifiers\n\n        if len(self._parameters) > 0:\n            parameters = []\n            for parameter in self._parameters:\n                serialized = {\n                    'field': parameter.field,\n                    'op': parameter.op,\n                }\n\n                if hasattr(parameter, '__iter__'):\n                    serialized['any'] = list(parameter.value)\n                else:\n                    serialized['value'] = parameter.value\n\n                parameters.append(serialized)\n\n            payload[PARAMETERS_CLAIM_NAME] = parameters\n\n        if len(self._attributes) > 0:\n            payload[ATTRIBUTES_CLAIM_NAME] = self._attributes\n\n        tok = jwe.JWE(json_encode(payload), protected=header)\n        tok.add_recipient(key)\n\n        return tok.serialize(compact=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nassigning force field parameters to Atoms in the AMPAL object.", "response": "def assign_force_field(ampal_obj, ff):\n    \"\"\"Assigns force field parameters to Atoms in the AMPAL object.\n\n    Parameters\n    ----------\n    ampal_obj : AMPAL Object\n        Any AMPAL object with a `get_atoms` method.\n    ff: BuffForceField\n        The force field to be used for scoring.\n    \"\"\"\n    if hasattr(ampal_obj, 'ligands'):\n        atoms = ampal_obj.get_atoms(ligands=True, inc_alt_states=True)\n    else:\n        atoms = ampal_obj.get_atoms(inc_alt_states=True)\n    for atom in atoms:\n        w_str = None\n        a_ff_id = None\n        if atom.element == 'H':\n            continue\n        elif atom.parent.mol_code.upper() in ff:\n            if atom.res_label.upper() in ff[atom.parent.mol_code]:\n                a_ff_id = (atom.parent.mol_code.upper(),\n                           atom.res_label.upper())\n            elif atom.res_label.upper() in ff['WLD']:\n                a_ff_id = ('WLD', atom.res_label.upper())\n            else:\n                w_str = ('{} atom is not parameterised in the selected '\n                         'force field for {} residues, this will be '\n                         'ignored.').format(\n                             atom.res_label, atom.parent.mol_code)\n        elif atom.res_label.upper() in ff['WLD']:\n            a_ff_id = ('WLD', atom.res_label.upper())\n        else:\n            w_str = ('{} ({}) atom is not parameterised in the selected'\n                     ' residue force field.').format(\n                         atom.res_label, atom.parent.mol_code)\n        if w_str:\n            warnings.warn(w_str, NotParameterisedWarning)\n        atom.tags['_buff_ff_id'] = a_ff_id\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_max_rad_npnp(self):\n        max_rad = 0\n        max_npnp = 0\n        for res, _ in self.items():\n            if res != 'KEY':\n                for _, ff_params in self[res].items():\n                    if max_rad < ff_params[1]:\n                        max_rad = ff_params[1]\n                    if max_npnp < ff_params[4]:\n                        max_npnp = ff_params[4]\n        return max_rad, max_npnp", "response": "Finds the maximum radius and npnp in the loaded force field."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_ff_params_dict(self):\n        try:\n            ff_params_struct_dict = {}\n            for res in self.keys():\n                if res == 'KEY':\n                    continue\n                if res not in ff_params_struct_dict:\n                    ff_params_struct_dict[res] = {}\n                for atom, params in self[res].items():\n                    ff_params_struct_dict[res][atom] = PyAtomData(\n                        atom.encode(), params[0].encode(), *params[1:])\n        except TypeError:\n            raise ForceFieldParameterError(\n                'Badly formatted force field parameters: {}'.format(params))\n        return ff_params_struct_dict", "response": "Makes a dictionary containing PyAtomData structs for each atom in the force field."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self, target=None):\n\t\ttarget = target or getattr(self, 'filename', None)\n\t\tif isinstance(target, six.string_types):\n\t\t\tself.filename = target\n\t\t\ttarget = open(target, 'wb')\n\t\tif target is None:\n\t\t\tmsg = (\n\t\t\t\t\"Target filename required if %s was not opened from a file\"\n\t\t\t\t% self.__class__.__name__\n\t\t\t)\n\t\t\traise ValueError(msg)\n\t\tself._store(target)", "response": "Save this package to target."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_stream(self):\n\t\tstream = io.BytesIO()\n\t\tself._store(stream)\n\t\tstream.seek(0)\n\t\treturn stream", "response": "Return a zipped package as a readable stream"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_matching_segments(self, zf, name):\n\t\tfor n in zf.namelist():\n\t\t\tif n.startswith(name):\n\t\t\t\tyield zf.read(n)", "response": "Returns a generator yielding each of the segments who s names\n\tmatch name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy_dir(bucket_name, src_path, dest_path,\n             aws_access_key_id=None, aws_secret_access_key=None,\n             aws_profile=None,\n             surrogate_key=None, cache_control=None,\n             surrogate_control=None,\n             create_directory_redirect_object=True):\n    \"\"\"Copy objects from one directory in a bucket to another directory in\n    the same bucket.\n\n    Object metadata is preserved while copying, with the following exceptions:\n\n    - If a new surrogate key is provided it will replace the original one.\n    - If ``cache_control`` and ``surrogate_control`` values are provided they\n      will replace the old one.\n\n    Parameters\n    ----------\n    bucket_name : `str`\n        Name of an S3 bucket.\n    src_path : `str`\n        Source directory in the S3 bucket. The ``src_path`` should ideally end\n        in a trailing `'/'`. E.g. `'dir/dir2/'`.\n    dest_path : `str`\n        Destination directory in the S3 bucket. The ``dest_path`` should\n        ideally end in a trailing `'/'`. E.g. `'dir/dir2/'`. The destination\n        path cannot contain the source path.\n    aws_access_key_id : `str`\n        The access key for your AWS account. Also set\n        ``aws_secret_access_key``.\n    aws_secret_access_key : `str`\n        The secret key for your AWS account.\n    aws_profile : `str`, optional\n        Name of AWS profile in :file:`~/.aws/credentials`. Use this instead\n        of ``aws_access_key_id`` and ``aws_secret_access_key`` for file-based\n        credentials.\n    surrogate_key : `str`, optional\n        The surrogate key to insert in the header of all objects in the\n        ``x-amz-meta-surrogate-key`` field. This key is used to purge\n        builds from the Fastly CDN when Editions change.\n        If `None` then no header will be set.\n        If the object already has a ``x-amz-meta-surrogate-key`` header then\n        it will be replaced.\n    cache_control : `str`, optional\n        This sets (and overrides) the ``Cache-Control`` header on the copied\n        files. The ``Cache-Control`` header specifically dictates how content\n        is cached by the browser (if ``surrogate_control`` is also set).\n    surrogate_control : `str`, optional\n        This sets (and overrides) the ``x-amz-meta-surrogate-control`` header\n        on the copied files. The ``Surrogate-Control``\n        or ``x-amz-meta-surrogate-control`` header is used in priority by\n        Fastly to givern it's caching. This caching policy is *not* passed\n        to the browser.\n    create_directory_redirect_object : `bool`, optional\n        Create a directory redirect object for the root directory. The\n        directory redirect object is an empty S3 object named after the\n        directory (without a trailing slash) that contains a\n        ``x-amz-meta-dir-redirect=true`` HTTP header. LSST the Docs' Fastly\n        VCL is configured to redirect requests for a directory path to the\n        directory's ``index.html`` (known as *courtesy redirects*).\n\n    Raises\n    ------\n    ltdconveyor.s3.S3Error\n        Thrown by any unexpected faults from the S3 API.\n    RuntimeError\n        Thrown when the source and destination directories are the same.\n    \"\"\"\n    if not src_path.endswith('/'):\n        src_path += '/'\n    if not dest_path.endswith('/'):\n        dest_path += '/'\n\n    # Ensure the src_path and dest_path don't contain each other\n    common_prefix = os.path.commonprefix([src_path, dest_path])\n    if common_prefix == src_path:\n        msg = 'Common prefix {0} is same as source dir {1}'.format(\n            common_prefix, src_path)\n        raise RuntimeError(msg)\n    if common_prefix == dest_path:\n        msg = 'Common prefix {0} is same as dest dir {1}'.format(\n            common_prefix, dest_path)\n        raise RuntimeError(msg)\n\n    # Delete any existing objects in the destination\n    delete_dir(bucket_name, dest_path,\n               aws_access_key_id, aws_secret_access_key)\n\n    session = boto3.session.Session(\n        aws_access_key_id=aws_access_key_id,\n        aws_secret_access_key=aws_secret_access_key,\n        profile_name=aws_profile)\n    s3 = session.resource('s3')\n    bucket = s3.Bucket(bucket_name)\n\n    # Copy each object from source to destination\n    for src_obj in bucket.objects.filter(Prefix=src_path):\n        src_rel_path = os.path.relpath(src_obj.key, start=src_path)\n        dest_key_path = os.path.join(dest_path, src_rel_path)\n\n        # the src_obj (ObjectSummary) doesn't include headers afaik\n        head = s3.meta.client.head_object(Bucket=bucket_name,\n                                          Key=src_obj.key)\n        metadata = head['Metadata']\n        content_type = head['ContentType']\n\n        # try to use original Cache-Control header if new one is not set\n        if cache_control is None and 'CacheControl' in head:\n            cache_control = head['CacheControl']\n\n        if surrogate_control is not None:\n            metadata['surrogate-control'] = surrogate_control\n\n        if surrogate_key is not None:\n            metadata['surrogate-key'] = surrogate_key\n\n        s3.meta.client.copy_object(\n            Bucket=bucket_name,\n            Key=dest_key_path,\n            CopySource={'Bucket': bucket_name, 'Key': src_obj.key},\n            MetadataDirective='REPLACE',\n            Metadata=metadata,\n            ACL='public-read',\n            CacheControl=cache_control,\n            ContentType=content_type)\n\n    if create_directory_redirect_object:\n        dest_dirname = dest_path.rstrip('/')\n        obj = bucket.Object(dest_dirname)\n        metadata = {'dir-redirect': 'true'}\n        obj.put(Body='',\n                ACL='public-read',\n                Metadata=metadata,\n                CacheControl=cache_control)", "response": "Copy a directory from one S3 path to another S3 path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef open_bucket(bucket_name,\n                aws_access_key_id=None, aws_secret_access_key=None,\n                aws_profile=None):\n    \"\"\"Open an S3 Bucket resource.\n\n    Parameters\n    ----------\n    bucket_name : `str`\n        Name of the S3 bucket.\n    aws_access_key_id : `str`, optional\n        The access key for your AWS account. Also set\n        ``aws_secret_access_key``.\n    aws_secret_access_key : `str`, optional\n        The secret key for your AWS account.\n    aws_profile : `str`, optional\n        Name of AWS profile in :file:`~/.aws/credentials`. Use this instead\n        of ``aws_access_key_id`` and ``aws_secret_access_key`` for file-based\n        credentials.\n\n    Returns\n    -------\n    bucket : Boto3 S3 Bucket instance\n        The S3 bucket as a Boto3 instance.\n    \"\"\"\n    session = boto3.session.Session(\n        profile_name=aws_profile,\n        aws_access_key_id=aws_access_key_id,\n        aws_secret_access_key=aws_secret_access_key)\n    s3 = session.resource('s3')\n    bucket = s3.Bucket(bucket_name)\n    return bucket", "response": "Open an S3 Bucket resource."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef upload_dir(bucket_name, path_prefix, source_dir,\n               upload_dir_redirect_objects=True,\n               surrogate_key=None,\n               surrogate_control=None, cache_control=None,\n               acl=None,\n               aws_access_key_id=None, aws_secret_access_key=None,\n               aws_profile=None):\n    \"\"\"Upload a directory of files to S3.\n\n    This function places the contents of the Sphinx HTML build directory\n    into the ``/path_prefix/`` directory of an *existing* S3 bucket.\n    Existing files on S3 are overwritten; files that no longer exist in the\n    ``source_dir`` are deleted from S3.\n\n    Parameters\n    ----------\n    bucket_name : `str`\n        Name of the S3 bucket where documentation is uploaded.\n    path_prefix : `str`\n        The root directory in the bucket where documentation is stored.\n    source_dir : `str`\n        Path of the Sphinx HTML build directory on the local file system.\n        The contents of this directory are uploaded into the ``/path_prefix/``\n        directory of the S3 bucket.\n    upload_dir_redirect_objects : `bool`, optional\n        A feature flag to enable uploading objects to S3 for every directory.\n        These objects contain ``x-amz-meta-dir-redirect=true`` HTTP headers\n        that tell Fastly to issue a 301 redirect from the directory object to\n        the `index.html`` in that directory.\n    surrogate_key : `str`, optional\n        The surrogate key to insert in the header of all objects\n        in the ``x-amz-meta-surrogate-key`` field. This key is used to purge\n        builds from the Fastly CDN when Editions change.\n        If `None` then no header will be set.\n    cache_control : `str`, optional\n        This sets the ``Cache-Control`` header on the uploaded\n        files. The ``Cache-Control`` header specifically dictates how content\n        is cached by the browser (if ``surrogate_control`` is also set).\n    surrogate_control : `str`, optional\n        This sets the ``x-amz-meta-surrogate-control`` header\n        on the uploaded files. The ``Surrogate-Control``\n        or ``x-amz-meta-surrogate-control`` header is used in priority by\n        Fastly to givern it's caching. This caching policy is *not* passed\n        to the browser.\n    acl : `str`, optional\n        The pre-canned AWS access control list to apply to this upload.\n        Can be ``'public-read'``, which allow files to be downloaded\n        over HTTP by the public. See\n        https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl\n        for an overview of S3's pre-canned ACL lists. Note that ACL settings\n        are not validated locally. Default is `None`, meaning that no ACL\n        is applied to an individual object. In this case, use ACLs applied\n        to the bucket itself.\n    aws_access_key_id : `str`, optional\n        The access key for your AWS account. Also set\n        ``aws_secret_access_key``.\n    aws_secret_access_key : `str`, optional\n        The secret key for your AWS account.\n    aws_profile : `str`, optional\n        Name of AWS profile in :file:`~/.aws/credentials`. Use this instead\n        of ``aws_access_key_id`` and ``aws_secret_access_key`` for file-based\n        credentials.\n\n    Notes\n    -----\n    ``cache_control`` and  ``surrogate_control`` can be used together.\n    ``surrogate_control`` takes priority in setting Fastly's POP caching,\n    while ``cache_control`` then sets the browser's caching. For example:\n\n    - ``cache_control='no-cache'``\n    - ``surrogate_control='max-age=31536000'``\n\n    together will ensure that the browser always does an ETAG server query,\n    but that Fastly will cache the content for one year (or until purged).\n    This configuration is good for files that are frequently changed in place.\n\n    For immutable uploads simply using ``cache_control`` is more efficient\n    since it allows the browser to also locally cache content.\n\n    .. seelso:\n\n       - `Fastly: Cache control tutorial\n         <https://docs.fastly.com/guides/tutorials/cache-control-tutorial>`_.\n       - `Google: HTTP caching <http://ls.st/39v>`_.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n\n    logger.debug('s3upload.upload({0}, {1}, {2})'.format(\n        bucket_name, path_prefix, source_dir))\n\n    session = boto3.session.Session(\n        profile_name=aws_profile,\n        aws_access_key_id=aws_access_key_id,\n        aws_secret_access_key=aws_secret_access_key)\n    s3 = session.resource('s3')\n    bucket = s3.Bucket(bucket_name)\n\n    metadata = {}\n    if surrogate_key is not None:\n        metadata['surrogate-key'] = surrogate_key\n    if surrogate_control is not None:\n        metadata['surrogate-control'] = surrogate_control\n\n    manager = ObjectManager(session, bucket_name, path_prefix)\n\n    for (rootdir, dirnames, filenames) in os.walk(source_dir):\n        # name of root directory on S3 bucket\n        bucket_root = os.path.relpath(rootdir, start=source_dir)\n        if bucket_root in ('.', '/'):\n            bucket_root = ''\n\n        # Delete bucket directories that no longer exist in source\n        bucket_dirnames = manager.list_dirnames_in_directory(bucket_root)\n        for bucket_dirname in bucket_dirnames:\n            if bucket_dirname not in dirnames:\n                logger.debug(('Deleting bucket directory {0}'.format(\n                    bucket_dirname)))\n                manager.delete_directory(bucket_dirname)\n\n        # Delete files that no longer exist in source\n        bucket_filenames = manager.list_filenames_in_directory(bucket_root)\n        for bucket_filename in bucket_filenames:\n            if bucket_filename not in filenames:\n                bucket_filename = os.path.join(bucket_root, bucket_filename)\n                logger.debug(\n                    'Deleting bucket file {0}'.format(bucket_filename))\n                manager.delete_file(bucket_filename)\n\n        # Upload files in directory\n        for filename in filenames:\n            local_path = os.path.join(rootdir, filename)\n            bucket_path = os.path.join(path_prefix, bucket_root, filename)\n            logger.debug('Uploading to {0}'.format(bucket_path))\n            upload_file(local_path, bucket_path, bucket,\n                        metadata=metadata, acl=acl,\n                        cache_control=cache_control)\n\n        # Upload a directory redirect object\n        if upload_dir_redirect_objects is True:\n            bucket_dir_path = os.path.join(path_prefix, bucket_root)\n            create_dir_redirect_object(\n                bucket_dir_path,\n                bucket,\n                metadata=metadata,\n                acl=acl,\n                cache_control=cache_control)", "response": "This function uploads a directory of files to S3."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupload a file to the S3 bucket.", "response": "def upload_file(local_path, bucket_path, bucket,\n                metadata=None, acl=None, cache_control=None):\n    \"\"\"Upload a file to the S3 bucket.\n\n    This function uses the mimetypes module to guess and then set the\n    Content-Type and Encoding-Type headers.\n\n    Parameters\n    ----------\n    local_path : `str`\n        Full path to a file on the local file system.\n    bucket_path : `str`\n        Destination path (also known as the key name) of the file in the\n        S3 bucket.\n    bucket : boto3 Bucket instance\n        S3 bucket.\n    metadata : `dict`, optional\n        Header metadata values. These keys will appear in headers as\n        ``x-amz-meta-*``.\n    acl : `str`, optional\n        A pre-canned access control list. See\n        https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl\n        Default is `None`, mean that no ACL is applied to the object.\n    cache_control : `str`, optional\n        The cache-control header value. For example, ``'max-age=31536000'``.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n\n    extra_args = {}\n    if acl is not None:\n        extra_args['ACL'] = acl\n    if metadata is not None and len(metadata) > 0:  # avoid empty Metadata\n        extra_args['Metadata'] = metadata\n    if cache_control is not None:\n        extra_args['CacheControl'] = cache_control\n\n    # guess_type returns None if it cannot detect a type\n    content_type, content_encoding = mimetypes.guess_type(local_path,\n                                                          strict=False)\n    if content_type is not None:\n        extra_args['ContentType'] = content_type\n\n    logger.debug(str(extra_args))\n\n    obj = bucket.Object(bucket_path)\n    # no return status from the upload_file api\n    obj.upload_file(local_path, ExtraArgs=extra_args)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupload an arbitrary object to an S3 bucket.", "response": "def upload_object(bucket_path, bucket, content='',\n                  metadata=None, acl=None, cache_control=None,\n                  content_type=None):\n    \"\"\"Upload an arbitrary object to an S3 bucket.\n\n    Parameters\n    ----------\n    bucket_path : `str`\n        Destination path (also known as the key name) of the file in the\n        S3 bucket.\n    content : `str` or `bytes`, optional\n        Object content.\n    bucket : boto3 Bucket instance\n        S3 bucket.\n    metadata : `dict`, optional\n        Header metadata values. These keys will appear in headers as\n        ``x-amz-meta-*``.\n    acl : `str`, optional\n        A pre-canned access control list. See\n        https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl\n        Default is `None`, meaning that no ACL is applied to the object.\n    cache_control : `str`, optional\n        The cache-control header value. For example, ``'max-age=31536000'``.\n    content_type : `str`, optional\n        The object's content type (such as ``text/html``). If left unset,\n        no MIME type is passed to boto3 (which defaults to\n        ``binary/octet-stream``).\n    \"\"\"\n    obj = bucket.Object(bucket_path)\n\n    # Object.put seems to be sensitive to None-type kwargs, so we filter first\n    args = {}\n    if metadata is not None and len(metadata) > 0:  # avoid empty Metadata\n        args['Metadata'] = metadata\n    if acl is not None:\n        args['ACL'] = acl\n    if cache_control is not None:\n        args['CacheControl'] = cache_control\n    if content_type is not None:\n        args['ContentType'] = content_type\n\n    obj.put(Body=content, **args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_dir_redirect_object(bucket_dir_path, bucket, metadata=None,\n                               acl=None, cache_control=None):\n    \"\"\"Create an S3 object representing a directory that's designed to\n    redirect a browser (via Fastly) to the ``index.html`` contained inside\n    that directory.\n\n    Parameters\n    ----------\n    bucket_dir_path : `str`\n        Full name of the object in the S3, which is equivalent to a POSIX\n        directory path, like ``dir1/dir2``.\n    bucket : boto3 Bucket instance\n        S3 bucket.\n    metadata : `dict`, optional\n        Header metadata values. These keys will appear in headers as\n        ``x-amz-meta-*``.\n    acl : `str`, optional\n        A pre-canned access control list. See\n        https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl\n        Default is None, meaning that no ACL is applied to the object.\n    cache_control : `str`, optional\n        The cache-control header value. For example, ``'max-age=31536000'``.\n    \"\"\"\n    # Just the name of the 'directory' itself\n    bucket_dir_path = bucket_dir_path.rstrip('/')\n\n    # create a copy of metadata\n    if metadata is not None:\n        metadata = dict(metadata)\n    else:\n        metadata = {}\n\n    # header used by LTD's Fastly Varnish config to create a 301 redirect\n    metadata['dir-redirect'] = 'true'\n\n    upload_object(bucket_dir_path,\n                  content='',\n                  bucket=bucket,\n                  metadata=metadata,\n                  acl=acl,\n                  cache_control=cache_control)", "response": "Create an S3 object representing a directory that s designed to be redirected to the index. html contained inside the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_filenames_in_directory(self, dirname):\n        prefix = self._create_prefix(dirname)\n        filenames = []\n        for obj in self._bucket.objects.filter(Prefix=prefix):\n            if obj.key.endswith('/'):\n                # a directory redirect object, not a file\n                continue\n            obj_dirname = os.path.dirname(obj.key)\n            if obj_dirname == prefix:\n                # object is at root of directory\n                filenames.append(os.path.relpath(obj.key,\n                                                 start=prefix))\n        return filenames", "response": "List all file - type object names that exist at the root of the given directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist all names of directories that exist at the root of the specified directory.", "response": "def list_dirnames_in_directory(self, dirname):\n        \"\"\"List all names of directories that exist at the root of this\n        bucket directory.\n\n        Note that *directories* don't exist in S3; rather directories are\n        inferred from path names.\n\n        Parameters\n        ----------\n        dirname : `str`\n            Directory name in the bucket relative to ``bucket_root``.\n\n        Returns\n        -------\n        dirnames : `list`\n            List of directory names (`str`), relative to ``bucket_root/``,\n            that exist at the root of ``dirname``.\n        \"\"\"\n        prefix = self._create_prefix(dirname)\n        dirnames = []\n        for obj in self._bucket.objects.filter(Prefix=prefix):\n            # get directory name of every object under this path prefix\n            dirname = os.path.dirname(obj.key)\n\n            # dirname is empty if the object happens to be the directory\n            # redirect object object for the prefix directory (directory\n            # redirect objects are named after directories and have metadata\n            # that tells Fastly to redirect the browser to the index.html\n            # contained in the directory).\n            if dirname == '':\n                dirname = obj.key + '/'\n\n            # Strip out the path prefix from the directory name\n            rel_dirname = os.path.relpath(dirname, start=prefix)\n\n            # If there's only one part then this directory is at the root\n            # relative to the prefix. We want this.\n            dir_parts = rel_dirname.split('/')\n            if len(dir_parts) == 1:\n                dirnames.append(dir_parts[0])\n\n        # Above algorithm finds root directories for all *files* in sub\n        # subdirectories; trim down to the unique set.\n        dirnames = list(set(dirnames))\n\n        # Remove posix-like relative directory names that can appear\n        # in the bucket listing.\n        for filtered_dir in ('.', '..'):\n            if filtered_dir in dirnames:\n                dirnames.remove(filtered_dir)\n\n        return dirnames"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_prefix(self, dirname):\n        if dirname in ('.', '/'):\n            dirname = ''\n        # Strips trailing slash from dir prefix for comparisons\n        # os.path.dirname() returns directory names without a trailing /\n        prefix = os.path.join(self._bucket_root, dirname)\n        prefix = prefix.rstrip('/')\n        return prefix", "response": "Create a prefix for the given dirname."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_file(self, filename):\n        key = os.path.join(self._bucket_root, filename)\n        objects = list(self._bucket.objects.filter(Prefix=key))\n        for obj in objects:\n            obj.delete()", "response": "Delete a file from the bucket."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes a directory from the bucket.", "response": "def delete_directory(self, dirname):\n        \"\"\"Delete a directory (and contents) from the bucket.\n\n        Parameters\n        ----------\n        dirname : `str`\n            Name of the directory, relative to ``bucket_root/``.\n\n        Raises\n        ------\n        RuntimeError\n            Raised when there are no objects to delete (directory\n            does not exist).\n        \"\"\"\n        key = os.path.join(self._bucket_root, dirname)\n        if not key.endswith('/'):\n            key += '/'\n\n        key_objects = [{'Key': obj.key}\n                       for obj in self._bucket.objects.filter(Prefix=key)]\n        if len(key_objects) == 0:\n            msg = 'No objects in bucket directory {}'.format(dirname)\n            raise RuntimeError(msg)\n        delete_keys = {'Objects': key_objects}\n        # based on http://stackoverflow.com/a/34888103\n        s3 = self._session.resource('s3')\n        r = s3.meta.client.delete_objects(Bucket=self._bucket.name,\n                                          Delete=delete_keys)\n        self._logger.debug(r)\n        if 'Errors' in r:\n            raise S3Error('S3 could not delete {0}'.format(key))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nensures a token is in the Click context object or obtain it from LTD Keeper.", "response": "def ensure_login(ctx):\n    \"\"\"Ensure a token is in the Click context object or authenticate and obtain\n    the token from LTD Keeper.\n\n    Parameters\n    ----------\n    ctx : `click.Context`\n        The Click context. ``ctx.obj`` must be a `dict` that contains keys:\n        ``keeper_hostname``, ``username``, ``password``, ``token``. This\n        context object is prepared by the main Click group,\n        `ltdconveyor.cli.main.main`.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    logger.info('utils name %r', __name__)\n\n    if ctx.obj['token'] is None:\n        if ctx.obj['username'] is None or ctx.obj['password'] is None:\n            raise click.UsageError(\n                'Use `ltd -u <username> -p <password> COMMAND` to '\n                'authenticate to the LTD Keeper server.')\n            sys.exit(1)\n\n        logger.debug(\n            'About to get token for user %s at %s',\n            ctx.obj['username'],\n            ctx.obj['keeper_hostname'])\n\n        token = get_keeper_token(\n            ctx.obj['keeper_hostname'],\n            ctx.obj['username'],\n            ctx.obj['password'])\n        ctx.obj['token'] = token\n\n        logger.debug(\n            'Got token for user %s at %s',\n            ctx.obj['username'],\n            ctx.obj['keeper_hostname'])\n\n    else:\n        logger.debug(\n            'Token already exists.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef loud(self, lang='englist'):\n        lang_method = getattr(self, lang, None)\n        if lang_method:\n            return lang_method().upper()\n        else:\n            return self.english().upper()", "response": "Speak loudly! FIVE! Use upper case!"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rotate(self, word):\n        before = string.printable[:62]\n        after = ''.join([i[5:] + i[:5] for i in [string.digits,\n                                                 string.ascii_lowercase,\n                                                 string.ascii_uppercase]])\n        table = dict(zip(before, after))\n        processed_word = [table[i] if i in before else i for i in word]\n        return ''.join(processed_word)", "response": "Rotate the word by a letter 5 right shift."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_dir(bucket_name, root_path,\n               aws_access_key_id=None, aws_secret_access_key=None,\n               aws_profile=None):\n    \"\"\"Delete all objects in the S3 bucket named ``bucket_name`` that are\n    found in the ``root_path`` directory.\n\n    Parameters\n    ----------\n    bucket_name : `str`\n        Name of an S3 bucket.\n    root_path : `str`\n        Directory in the S3 bucket that will be deleted.\n    aws_access_key_id : `str`\n        The access key for your AWS account. Also set\n        ``aws_secret_access_key``.\n    aws_secret_access_key : `str`\n        The secret key for your AWS account.\n    aws_profile : `str`, optional\n        Name of AWS profile in :file:`~/.aws/credentials`. Use this instead\n        of ``aws_access_key_id`` and ``aws_secret_access_key`` for file-based\n        credentials.\n\n    Raises\n    ------\n    ltdconveyor.s3.S3Error\n        Thrown by any unexpected faults from the S3 API.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n\n    session = boto3.session.Session(\n        aws_access_key_id=aws_access_key_id,\n        aws_secret_access_key=aws_secret_access_key)\n    s3 = session.resource('s3')\n    client = s3.meta.client\n\n    # Normalize directory path for searching patch prefixes of objects\n    if not root_path.endswith('/'):\n        root_path.rstrip('/')\n\n    paginator = client.get_paginator('list_objects_v2')\n    pages = paginator.paginate(Bucket=bucket_name, Prefix=root_path)\n\n    keys = dict(Objects=[])\n    for item in pages.search('Contents'):\n        try:\n            keys['Objects'].append({'Key': item['Key']})\n        except TypeError:  # item is None; nothing to delete\n            continue\n        # Delete immediately when 1000 objects are listed\n        # the delete_objects method can only take a maximum of 1000 keys\n        if len(keys['Objects']) >= 1000:\n            try:\n                client.delete_objects(Bucket=bucket_name, Delete=keys)\n            except Exception:\n                message = 'Error deleting objects from %r' % root_path\n                logger.exception(message)\n                raise S3Error(message)\n            keys = dict(Objects=[])\n\n    # Delete remaining keys\n    if len(keys['Objects']) > 0:\n        try:\n            client.delete_objects(Bucket=bucket_name, Delete=keys)\n        except Exception:\n            message = 'Error deleting objects from %r' % root_path\n            logger.exception(message)\n            raise S3Error(message)", "response": "Delete all objects in the S3 bucket named bucket_name under root_path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget project s home URL based on settings. PROJECT_HOME_NAMESPACE.", "response": "def home_url():\n    \"\"\"Get project's home URL based on settings.PROJECT_HOME_NAMESPACE.\n\n    Returns None if PROJECT_HOME_NAMESPACE is not defined in settings.\n    \"\"\"\n    try:\n        return reverse(home_namespace)\n    except Exception:\n        url = home_namespace\n        try:\n            validate_url = URLValidator()\n            if '://' not in url:\n                url = 'http://' + url\n            validate_url(url)\n            return(url)\n        except ValidationError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef silence_without_namespace(f):\n    @wraps(f)\n    def wrapped(label=None):\n        if not home_namespace:\n            return ''\n        if label:\n            return f(label)\n        else:\n            return f(home_label)\n    return wrapped", "response": "Decorator to silence template tags if PROJECT_HOME_NAMESPACE is not defined in settings. is\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef project_home_breadcrumb_bs4(label):\n    url = home_url()\n    if url:\n        return format_html(\n            '<li class=\"breadcrumb-item\" aria-label=\"breadcrumb\"><a href=\"{}\">{}</a></li>',\n            url, label)\n    else:\n        return format_html(\n            '<li class=\"breadcrumb-item\" aria-label=\"breadcrumb\">{}</li>',\n            label)", "response": "A template tag to return the project s home URL and label as a Bootstrap 4 breadcrumb."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pm(client, event, channel, nick, rest):\n    'Arggh matey'\n    if rest:\n        rest = rest.strip()\n        Karma.store.change(rest, 2)\n        rcpt = rest\n    else:\n        rcpt = channel\n\n    if random.random() > 0.95:\n        return f\"Arrggh ye be doin' great, grand work, {rcpt}!\"\n    return f\"Arrggh ye be doin' good work, {rcpt}!\"", "response": "Arrggh ye be doin garma grand work"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lm(client, event, channel, nick, rest):\n    'Rico Suave'\n    if rest:\n        rest = rest.strip()\n        Karma.store.change(rest, 2)\n        rcpt = rest\n    else:\n        rcpt = channel\n    return f'\u00a1Est\u00e1s haciendo un buen trabajo, {rcpt}!'", "response": "Haciendo un buen trabajo."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef zorsupas(client, event, channel, nick, rest):\n    'Zor supas! \u2014 !\u0632\u06c6\u0631 \u0633\u0648\u067e\u0627\u0633'\n    if rest:\n        rest = rest.strip()\n        Karma.store.change(rest, 1)\n        rcpt = rest\n    else:\n        rcpt = channel\n    return (\n        f'Zor supas {rcpt}, to zor zor barezi! \u2014'\n        ' \u0632\u06c6\u0631 \u0633\u0648\u067e\u0627\u0633\u060c \u062a\u06c6 \u0632\u06c6\u0631 \u0632\u06c6\u0631 \u0628\u0647\u200c\u0631\u0647\u200c\u0632\u06cc'\n    )", "response": "Zor supas! \u2014! \u0632\u06c6\u0631 \u0633\u0648\u067e\u0627\u0633 \u062a\u06c6 \u0632\u06c6\u0631 \u0633\u0648\u067e\u0627\u0633 \u062a\u06c6 \u0632\u06c6\u0631 \u0633\u0648\u067e\u0627\u0633 \u062a\u06c6 \u0632\u06c6 \u0633\u0648\u067e\u0627\u0633 \u062a"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_interaction_energy(ampal_objs, ff=None, assign_ff=True):\n    if ff is None:\n        ff = FORCE_FIELDS['bude_2016v1']\n    if assign_ff:\n        for ampal_obj in ampal_objs:\n            assign_force_field(ampal_obj, ff)\n    interactions = find_inter_ampal(ampal_objs, ff.distance_cutoff)\n    buff_score = score_interactions(interactions, ff)\n    return buff_score", "response": "Calculates the interaction energy between the AMPAL objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_internal_energy(ampal_obj, ff=None, assign_ff=True):\n    if ff is None:\n        ff = FORCE_FIELDS['bude_2016v1']\n    if assign_ff:\n        assign_force_field(ampal_obj, ff)\n    interactions = find_intra_ampal(ampal_obj, ff.distance_cutoff)\n    buff_score = score_interactions(interactions, ff)\n    return buff_score", "response": "Calculates the internal energy of the AMPAL object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting sample counts by file and root thread function.", "response": "def rooted_samples_by_file(self):\n        '''\n        Get sample counts by file, and root thread function.\n        (Useful for answering quesitons like \"what modules are hot?\")\n        '''\n        rooted_leaf_samples, _ = self.live_data_copy()\n        rooted_file_samples = {}\n        for root, counts in rooted_leaf_samples.items():\n            cur = {}\n            for key, count in counts.items():\n                code, lineno = key\n                cur.setdefault(code.co_filename, 0)\n                cur[code.co_filename] += count\n            rooted_file_samples[root] = cur\n        return rooted_file_samples"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rooted_samples_by_line(self, filename):\n        '''\n        Get sample counts by line, and root thread function.\n        (For one file, specified as a parameter.)\n        This is useful for generating \"side-by-side\" views of\n        source code and samples.\n        '''\n        rooted_leaf_samples, _ = self.live_data_copy()\n        rooted_line_samples = {}\n        for root, counts in rooted_leaf_samples.items():\n            cur = {}\n            for key, count in counts.items():\n                code, lineno = key\n                if code.co_filename != filename:\n                    continue\n                cur[lineno] = count\n            rooted_line_samples[root] = cur\n        return rooted_line_samples", "response": "Get sample counts by line and root thread function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hotspots(self):\n        '''\n        Get lines sampled accross all threads, in order\n        from most to least sampled.\n        '''\n        rooted_leaf_samples, _ = self.live_data_copy()\n        line_samples = {}\n        for _, counts in rooted_leaf_samples.items():\n            for key, count in counts.items():\n                line_samples.setdefault(key, 0)\n                line_samples[key] += count\n        return sorted(\n            line_samples.items(), key=lambda v: v[1], reverse=True)", "response": "Get lines sampled accross all threads in order\n        from most to least sampled."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary of all the stacks in form suitable for inclusion in a flame graph", "response": "def flame_map(self):\n        '''\n        return sampled stacks in form suitable for inclusion in a\n        flame graph (https://github.com/brendangregg/FlameGraph)\n        '''\n        flame_map = {}\n        _, stack_counts = self.live_data_copy()\n        for stack, count in stack_counts.items():\n            root = stack[-2].co_name\n            stack_elements = []\n            for i in range(len(stack)):\n                if type(stack[i]) in (int, long):\n                    continue\n                code = stack[i]\n                stack_elements.append(\"{0}`{1}`{2}\".format(\n                    root, code.co_filename, code.co_name))\n            flame_key = ';'.join(stack_elements)\n            flame_map.setdefault(flame_key, 0)\n            flame_map[flame_key] += count\n        return flame_map"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_keeper_token(host, username, password):\n    token_endpoint = urljoin(host, '/token')\n    r = requests.get(token_endpoint, auth=(username, password))\n    if r.status_code != 200:\n        raise KeeperError('Could not authenticate to {0}: error {1:d}\\n{2}'.\n                          format(host, r.status_code, r.json()))\n    return r.json()['token']", "response": "Get a temporary auth token from LTD Keeper API."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupload a new site build to LSST the Docs.", "response": "def upload(ctx, product, git_ref, dirname, aws_id, aws_secret, ci_env,\n           on_travis_push, on_travis_pr, on_travis_api, on_travis_cron,\n           skip_upload):\n    \"\"\"Upload a new site build to LSST the Docs.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n\n    if skip_upload:\n        click.echo('Skipping ltd upload.')\n        sys.exit(0)\n\n    logger.debug('CI environment: %s', ci_env)\n    logger.debug('Travis events settings. '\n                 'On Push: %r, PR: %r, API: %r, Cron: %r',\n                 on_travis_push, on_travis_pr, on_travis_api, on_travis_cron)\n\n    # Abort upload on Travis CI under certain events\n    if ci_env == 'travis' and \\\n            _should_skip_travis_event(\n                on_travis_push, on_travis_pr, on_travis_api, on_travis_cron):\n        sys.exit(0)\n\n    # Authenticate to LTD Keeper host\n    ensure_login(ctx)\n\n    # Detect git refs\n    git_refs = _get_git_refs(ci_env, git_ref)\n\n    build_resource = register_build(\n        ctx.obj['keeper_hostname'],\n        ctx.obj['token'],\n        product,\n        git_refs\n    )\n    logger.debug('Created build resource %r', build_resource)\n\n    # Do the upload.\n    # This cache_control is appropriate for builds since they're immutable.\n    # The LTD Keeper server changes the cache settings when copying the build\n    # over to be a mutable edition.\n    upload_dir(\n        build_resource['bucket_name'],\n        build_resource['bucket_root_dir'],\n        dirname,\n        aws_access_key_id=aws_id,\n        aws_secret_access_key=aws_secret,\n        surrogate_key=build_resource['surrogate_key'],\n        cache_control='max-age=31536000',\n        surrogate_control=None,\n        upload_dir_redirect_objects=True)\n    logger.debug('Upload complete for %r', build_resource['self_url'])\n\n    # Confirm upload\n    confirm_build(\n        build_resource['self_url'],\n        ctx.obj['token']\n    )\n    logger.debug('Build %r complete', build_resource['self_url'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _should_skip_travis_event(on_travis_push, on_travis_pr, on_travis_api,\n                              on_travis_cron):\n    \"\"\"Detect if the upload should be skipped based on the\n    ``TRAVIS_EVENT_TYPE`` environment variable.\n\n    Returns\n    -------\n    should_skip : `bool`\n        True if the upload should be skipped based on the combination of\n        ``TRAVIS_EVENT_TYPE`` and user settings.\n    \"\"\"\n    travis_event = os.getenv('TRAVIS_EVENT_TYPE')\n    if travis_event is None:\n        raise click.UsageError(\n            'Using --travis but the TRAVIS_EVENT_TYPE '\n            'environment variable is not detected.')\n\n    if travis_event == 'push' and on_travis_push is False:\n        click.echo('Skipping upload on Travis push event.')\n        return True\n    elif travis_event == 'pull_request' and on_travis_pr is False:\n        click.echo('Skipping upload on Travis pull request event.')\n        return True\n    elif travis_event == 'api' and on_travis_api is False:\n        click.echo('Skipping upload on Travis pull request event.')\n        return True\n    elif travis_event == 'cron' and on_travis_cron is False:\n        click.echo('Skipping upload on Travis cron event.')\n        return True\n    else:\n        return False", "response": "Detects if the upload should be skipped based on the TRAVIS_EVENT_TYPE environment variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_build(host, keeper_token, product, git_refs):\n    data = {\n        'git_refs': git_refs\n    }\n\n    endpoint_url = uritemplate.expand(\n        urljoin(host, '/products/{p}/builds/'),\n        p=product)\n\n    r = requests.post(\n        endpoint_url,\n        auth=(keeper_token, ''),\n        json=data)\n\n    if r.status_code != 201:\n        raise KeeperError(r.json())\n    build_info = r.json()\n    return build_info", "response": "Register a new build for a product on LSST the Docs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef confirm_build(build_url, keeper_token):\n    data = {\n        'uploaded': True\n    }\n\n    r = requests.patch(\n        build_url,\n        auth=(keeper_token, ''),\n        json=data)\n    if r.status_code != 200:\n        raise KeeperError(r)", "response": "Confirm a build upload is complete."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deep_update(d, u):\n\n  for k, v in u.items():\n    if isinstance(v, Mapping):\n      d[k] = deep_update(d.get(k, {}), v)\n    elif isinstance(v, list):\n      existing_elements = d.get(k, [])\n      d[k] = existing_elements + [ele for ele in v if ele not in existing_elements]\n    else:\n      d[k] = v\n\n  return d", "response": "Deeply updates a dictionary. List values are concatenated."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef part_edit_cmd():\n\t'Edit a part from an OOXML Package without unzipping it'\n\tparser = argparse.ArgumentParser(description=inspect.getdoc(part_edit_cmd))\n\tparser.add_argument(\n\t\t'path',\n\t\thelp='Path to part (including path to zip file, i.e. ./file.zipx/part)',\n\t)\n\tparser.add_argument(\n\t\t'--reformat-xml',\n\t\taction='store_true',\n\t\thelp=(\n\t\t\t'run the content through an XML pretty-printer '\n\t\t\t'first for improved editability'\n\t\t),\n\t)\n\targs = parser.parse_args()\n\tpart_edit(args.path, args.reformat_xml)", "response": "Edit a part from an OOXML Package without unzipping it"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist the contents of a subdirectory of a zipfile", "response": "def pack_dir_cmd():\n\t'List the contents of a subdirectory of a zipfile'\n\tparser = argparse.ArgumentParser(description=inspect.getdoc(part_edit_cmd))\n\tparser.add_argument(\n\t\t'path',\n\t\thelp=(\n\t\t\t'Path to list (including path to zip file, '\n\t\t\t'i.e. ./file.zipx or ./file.zipx/subdir)'\n\t\t),\n\t)\n\targs = parser.parse_args()\n\tfor item, is_file in sorted(list_contents(args.path)):\n\t\tprefix = 'd ' if not is_file else '  '\n\t\tmsg = prefix + item\n\t\tprint(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds a file in a zip file and return a path to the file and the path to the part.", "response": "def find_file(path):\n\t\"\"\"\n\tGiven a path to a part in a zip file, return a path to the file and\n\tthe path to the part.\n\n\tAssuming /foo.zipx exists as a file,\n\n\t>>> find_file('/foo.zipx/dir/part') # doctest: +SKIP\n\t('/foo.zipx', '/dir/part')\n\n\t>>> find_file('/foo.zipx') # doctest: +SKIP\n\t('/foo.zipx', '')\n\t\"\"\"\n\tpath_components = split_all(path)\n\n\tdef get_assemblies():\n\t\t\"\"\"\n\t\tEnumerate the various combinations of file paths and part paths\n\t\t\"\"\"\n\t\tfor n in range(len(path_components), 0, -1):\n\t\t\tfile_c = path_components[:n]\n\t\t\tpart_c = path_components[n:] or ['']\n\t\t\tyield (os.path.join(*file_c), posixpath.join(*part_c))\n\tfor file_path, part_path in get_assemblies():\n\t\tif os.path.isfile(file_path):\n\t\t\treturn file_path, part_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the XML_EDITOR or EDITOR defined in the environment.", "response": "def get_editor(filepath):\n\t\t\"\"\"\n\t\tGive preference to an XML_EDITOR or EDITOR defined in the\n\t\tenvironment. Otherwise use notepad on Windows and edit on other\n\t\tplatforms.\n\t\t\"\"\"\n\t\tdefault_editor = ['edit', 'notepad'][sys.platform.startswith('win32')]\n\t\treturn os.environ.get(\n\t\t\t'XML_EDITOR',\n\t\t\tos.environ.get('EDITOR', default_editor),\n\t\t)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef permission_check(apikey, endpoint):\n        try:\n            ak = APIKeys.objects.get(apikey=apikey)\n            apitree = cPickle.loads(ak.apitree.encode(\"ascii\"))\n            if apitree.match(endpoint):\n                return ak.user if ak.user else AnonymousUser(), ak.seckey\n        except APIKeys.DoesNotExist:\n            pass\n        return None, None", "response": "Check if user is in allowed entry point list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_module(self, node):\n        if self.config.file_header:\n            if sys.version_info[0] < 3:\n                pattern = re.compile(\n                    '\\A' + self.config.file_header, re.LOCALE | re.MULTILINE)\n            else:\n                # The use of re.LOCALE is discouraged in python 3\n                pattern = re.compile(\n                    '\\A' + self.config.file_header, re.MULTILINE)\n\n            content = None\n            with node.stream() as stream:\n                # Explicit decoding required by python 3\n                content = stream.read().decode('utf-8')\n\n            matches = pattern.findall(content)\n\n            if len(matches) != 1:\n                self.add_message('invalid-file-header', 1,\n                                 args=self.config.file_header)", "response": "Process the astroid node stream."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gen(self, slug, name, dataobj, xfield, yfield, time_unit=None,\n            chart_type=\"line\", width=800,\n            height=300, color=Color(), size=Size(),\n            scale=Scale(zero=False), shape=Shape(), filepath=None,\n            html_before=\"\", html_after=\"\"):\n        \"\"\"\n        Generates an html chart from either a pandas dataframe, a dictionnary,\n        a list or an Altair Data object and optionally write it to a file\n        \"\"\"\n        chart_obj = self.serialize(dataobj, xfield, yfield, time_unit,\n                                   chart_type, width, height, color, size, scale, shape)\n        html = self.html(slug, name, chart_obj, filepath,\n                         html_before, html_after)\n        return html", "response": "Generates an html chart from a pandas dataframe a list or Altair Data object and optionally writes it to a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef html(self, slug, name, chart_obj, filepath=None,\n             html_before=\"\", html_after=\"\"):\n        \"\"\"\n        Generate html from an Altair chart object and optionally write it to a file\n        \"\"\"\n        try:\n            html = \"\"\n            if name:\n                html = \"<h3>\" + name + \"</h3>\"\n            json_data = chart_obj.to_json()\n            json_data = self._patch_json(json_data)\n            html = html_before + html +\\\n                self._json_to_html(slug, json_data) + html_after\n        except Exception as e:\n            tr.new(e)\n            tr.check()\n        # generate file\n        if filepath is not None:\n            self._write_file(slug, filepath, html)\n            return None\n        else:\n            return html", "response": "Generate html from an Altair chart object and optionally write it to a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef serialize(self, dataobj, xfield, yfield, time_unit=None,\n                  chart_type=\"line\", width=800,\n                  height=300, color=None, size=None,\n                  scale=Scale(zero=False), shape=None, options={}):\n        \"\"\"\n        Serialize to an Altair chart object from either a pandas dataframe, a dictionnary,\n        a list or an Altair Data object\n        \"\"\"\n        dataset = dataobj\n        if self._is_dict(dataobj) is True:\n            dataset = self._dict_to_df(dataobj, xfield, yfield)\n        elif isinstance(dataobj, list):\n            dataset = Data(values=dataobj)\n        xencode, yencode = self._encode_fields(\n            xfield, yfield, time_unit)\n        opts = dict(x=xencode, y=yencode)\n        if color is not None:\n            opts[\"color\"] = color\n        if size is not None:\n            opts[\"size\"] = size\n        if shape is not None:\n            opts[\"shape\"] = shape\n        chart = self._chart_class(dataset, chart_type, **options).encode(\n            **opts\n        ).configure_cell(\n            width=width,\n            height=height,\n        )\n        return chart", "response": "Serialize to an Altair chart object from a pandas dataframe a list or a Data object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _patch_json(self, json_data):\n        json_data = json.loads(json_data)\n        # add schema\n        json_data[\"$schema\"] = \"https://vega.github.io/schema/vega-lite/2.0.0-beta.15.json\"\n        # add top level width and height\n        json_data[\"width\"] = json_data[\"config\"][\"cell\"][\"width\"]\n        json_data[\"height\"] = json_data[\"config\"][\"cell\"][\"height\"]\n        del(json_data[\"config\"][\"cell\"])\n        return json.dumps(json_data)", "response": "Patch the Altair generated json to the newest Vega Lite spec\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates html from json data", "response": "def _json_to_html(self, slug, json_data):\n        \"\"\"\n        Generates html from Vega lite data\n        \"\"\"\n        html = '<div id=\"chart-' + slug + '\"></div>'\n        html += '<script>'\n        html += 'var s' + slug + ' = ' + json_data + ';'\n        html += 'vega.embed(\"#chart-' + slug + '\", s' + slug + ');'\n        #html += 'console.log(JSON.stringify(s{id}, null, 2));'\n        html += '</script>'\n        return html"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _dict_to_df(self, dictobj, xfield, yfield):\n        x = []\n        y = []\n        for datapoint in dictobj:\n            x.append(datapoint)\n            y.append(dictobj[datapoint])\n        df = pd.DataFrame({xfield[0]: x, yfield[0]: y})\n        return df", "response": "Converts a dictionary to a pandas dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _write_file(self, slug, folderpath, html):\n        # check directories\n\n        if not os.path.isdir(folderpath):\n            try:\n                os.makedirs(folderpath)\n            except Exception as e:\n                tr.err(e)\n        # construct file path\n        filepath = folderpath + \"/\" + slug + \".html\"\n        #~ write the file\n        try:\n            filex = open(filepath, \"w\")\n            filex.write(html)\n            filex.close()\n        except Exception as e:\n            tr.err(e)", "response": "Writes a chart s html to a file"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the right chart class from a string", "response": "def _chart_class(self, df, chart_type, **kwargs):\n        \"\"\"\n        Get the right chart class from a string\n        \"\"\"\n        if chart_type == \"bar\":\n            return Chart(df).mark_bar(**kwargs)\n        elif chart_type == \"circle\":\n            return Chart(df).mark_circle(**kwargs)\n        elif chart_type == \"line\":\n            return Chart(df).mark_line(**kwargs)\n        elif chart_type == \"point\":\n            return Chart(df).mark_point(**kwargs)\n        elif chart_type == \"area\":\n            return Chart(df).mark_area(**kwargs)\n        elif chart_type == \"tick\":\n            return Chart(df).mark_tick(**kwargs)\n        elif chart_type == \"text\":\n            return Chart(df).mark_text(**kwargs)\n        elif chart_type == \"square\":\n            return Chart(df).mark_square(**kwargs)\n        elif chart_type == \"rule\":\n            return Chart(df).mark_rule(**kwargs)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nencoding the fields in Altair format", "response": "def _encode_fields(self, xfield, yfield, time_unit=None,\n                       scale=Scale(zero=False)):\n        \"\"\"\n        Encode the fields in Altair format\n        \"\"\"\n        if scale is None:\n            scale = Scale()\n        xfieldtype = xfield[1]\n        yfieldtype = yfield[1]\n        x_options = None\n        if len(xfield) > 2:\n            x_options = xfield[2]\n        y_options = None\n        if len(yfield) > 2:\n            y_options = yfield[2]\n        if time_unit is not None:\n            if x_options is None:\n                xencode = X(xfieldtype, timeUnit=time_unit)\n            else:\n                xencode = X(\n                    xfieldtype,\n                    axis=Axis(**x_options),\n                    timeUnit=time_unit,\n                    scale=scale\n                )\n        else:\n            if x_options is None:\n                xencode = X(xfieldtype)\n            else:\n                xencode = X(\n                    xfieldtype,\n                    axis=Axis(**x_options),\n                    scale=scale\n                )\n        if y_options is None:\n            yencode = Y(yfieldtype, scale=scale)\n        else:\n            yencode = Y(\n                yfieldtype,\n                axis=Axis(**y_options),\n                scale=scale\n            )\n        return xencode, yencode"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlink to a GitHub user.", "response": "def ghuser_role(name, rawtext, text, lineno, inliner, options={}, content=[]):\n    \"\"\"Link to a GitHub user.\n\n    Returns 2 part tuple containing list of nodes to insert into the\n    document and a list of system messages.  Both are allowed to be\n    empty.\n\n    :param name: The role name used in the document.\n    :param rawtext: The entire markup snippet, with role.\n    :param text: The text marked with the role.\n    :param lineno: The line number where rawtext appears in the input.\n    :param inliner: The inliner instance that called us.\n    :param options: Directive options for customization.\n    :param content: The directive content for customization.\n    \"\"\"\n    # app = inliner.document.settings.env.app\n    #app.info('user link %r' % text)\n    ref = 'https://www.github.com/' + text\n    node = nodes.reference(rawtext, text, refuri=ref, **options)\n    return [node], []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _infer_tarball_url():\n    try:\n        with click.open_file('app.json', 'r') as f:\n            contents = f.read()\n\n        app_json = json.loads(contents)\n    except IOError:\n        return None\n\n    repository = app_json.get('repository')\n\n    if not repository:\n        return None\n    else:\n        return app_json.get('repository') + '/tarball/master/'", "response": "Returns the tarball URL inferred from an app. json file if present."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef up(tarball_url, auth_token, env, app_name):\n    tarball_url = tarball_url or _infer_tarball_url()\n\n    if not tarball_url:\n        click.echo('No tarball URL found.')\n        sys.exit(1)\n\n    if env:\n        # Split [\"KEY=value\", ...] into {\"KEY\": \"value\", ...}\n        env = {\n            arg.split('=')[0]: arg.split('=')[1]\n            for arg in env\n        }\n\n    happy = Happy(auth_token=auth_token)\n\n    click.echo('Creating app... ', nl=False)\n\n    build_id, app_name = happy.create(\n        tarball_url=tarball_url,\n        env=env,\n        app_name=app_name,\n    )\n\n    click.echo(app_name)\n\n    click.echo('Building... ', nl=False)\n\n    happy.wait(build_id)\n\n    _write_app_name(app_name)\n\n    click.echo('done')\n    click.echo(\"It's up! :) https://%s.herokuapp.com\" % app_name)", "response": "Bring up a Heroku app."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef down(auth_token, force, app_name):\n    if not app_name:\n        click.echo(\n            'WARNING: Inferring the app name when deleting is deprecated. '\n            'Starting with happy 2.0, the app_name parameter will be required.'\n        )\n\n    app_name = app_name or _read_app_name()\n\n    if not app_name:\n        click.echo('No app name given.')\n        sys.exit(1)\n\n    if not force:\n        click.confirm(\n            'Are you sure you want to delete %s?' % app_name,\n            abort=True,\n        )\n\n    happy = Happy(auth_token=auth_token)\n\n    click.echo('Destroying app %s... ' % app_name, nl=False)\n\n    happy.delete(app_name=app_name)\n\n    _delete_app_name_file()\n\n    click.echo('done')\n    click.echo(\"It's down. :(\")", "response": "Brings down a Heroku app."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iter_attribute(iterable_name) -> Union[Iterable, Callable]:\n\n    def create_new_class(decorated_class) -> Union[Iterable, Callable]:\n        \"\"\"Class extender implementing __next__ and __iter__ methods.\n\n        :param decorated_class: class to be extended with iterator interface\n        :return: new class\n        \"\"\"\n        assert inspect.isclass(decorated_class), 'You can only decorate class objects!'\n        assert isinstance(iterable_name, str), 'Please provide attribute name string'\n\n        decorated_class.iterator_attr_index = 0\n\n        def __iter__(instance) -> Iterable:\n            \"\"\"Implement __iter__ method\n\n            :param instance: __iter__ uses instance of class which is being extended\n            :return: instance of decorated_class\n            \"\"\"\n            return instance\n\n        def __next__(instance) -> Any:\n            \"\"\"Implement __next__ method\n\n            :param instance: __next__ uses instance of class which is being extended\n            :return: instance of decorated_class\n            \"\"\"\n            assert hasattr(instance, iterable_name), \\\n                'Decorated object does not have attribute named {}'.format(iterable_name)\n            assert isinstance(getattr(instance, iterable_name), collections.Iterable), \\\n                '{} of object {} is not iterable'.format(iterable_name, instance.__class__.__name__)\n            ind = instance.iterator_attr_index\n            while ind < len(getattr(instance, iterable_name)):\n                val = getattr(instance, iterable_name)[ind]\n                instance.iterator_attr_index += 1\n                return val\n            instance.iterator_attr_index = 0\n            raise StopIteration\n\n        dct = dict(decorated_class.__dict__)\n        dct['__iter__'] = __iter__\n        dct['__next__'] = __next__\n        dct['iterator_attr_index'] = decorated_class.iterator_attr_index\n        return type(decorated_class.__name__, (collections.Iterable,), dct)\n\n    return create_new_class", "response": "Decorator that returns an iterable of objects with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking 1, timestamp in reasonable range 2, api key exists 3, entry point allowed for this api key 4, signature correctness effect: - add user object in request if the api key is binding with an user", "response": "def api_auth(function=None):\n    \"\"\"\n    check:\n    1, timestamp in reasonable range\n    2, api key exists\n    3, entry point allowed for this api key\n    4, signature correctness\n\n    effect:\n    - add user object in request if the api key is binding with an user\n    \"\"\"\n    def real_decorator(func):\n        def wrapped(request, *args, **kwargs):\n            try:\n                user = _auth_url(request.get_full_path(), request.body)\n                request.user = user  # put user object in request\n            except Exception as e:\n                return JsonResponse({\"error\": str(e)}, status=403)\n            return func(request, *args, **kwargs)\n        setattr(wrapped, '__djapiauth__', True)\n        return wrapped\n    return real_decorator if not function else real_decorator(function)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef text(length, choices=string.ascii_letters):\n    return ''.join(choice(choices) for x in range(length))", "response": "returns a random string of given length"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a random string.", "response": "def rtext(maxlength, minlength=1, choices=string.ascii_letters):\n    \"\"\" returns a random (variable length) string.\n\n        :param maxlength: maximum string length\n        :param minlength: minimum string length\n        :param choices: string containing all the chars can be used to build the string\n\n        .. seealso::\n           :py:func:`text`\n        \"\"\"\n    return ''.join(choice(choices) for x in range(randint(minlength, maxlength)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef binary(length):\n    num = randint(1, 999999)\n    mask = '0' * length\n    return (mask + ''.join([str(num >> i & 1) for i in range(7, -1, -1)]))[-length:]", "response": "Returns a random string that represent a binary representation of the given number of bits."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a random ip address", "response": "def ipaddress(not_valid=None):\n    \"\"\"\n        returns a string representing a random ip address\n\n    :param not_valid: if passed must be a list of integers representing valid class A netoworks that must be ignored\n    \"\"\"\n    not_valid_class_A = not_valid or []\n\n    class_a = [r for r in range(1, 256) if r not in not_valid_class_A]\n    shuffle(class_a)\n    first = class_a.pop()\n\n    return \".\".join([str(first), str(randrange(1, 256)),\n                     str(randrange(1, 256)), str(randrange(1, 256))])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ip(private=True, public=True, max_attempts=10000):\n    if not (private or public):\n        raise ValueError('Cannot disable both `private` and `public` network')\n\n    if private != public:\n        if private:\n            is_valid = lambda address: address.is_private()\n            not_valid = [n for n in range(1, 255) if n not in NOT_NET]\n        else:\n            is_valid = lambda address: not address.is_private()\n            not_valid = NOT_NET\n\n        attempt = 0\n        while attempt < max_attempts:\n            attempt += 1\n            ip = IPAddress(ipaddress(not_valid))\n            if is_valid(ip):\n                return ip\n    else:\n        return IPAddress(ipaddress())", "response": "Returns a random IP object with a random value for private and public networks."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef date(start, end):\n\n    stime = date_to_timestamp(start)\n    etime = date_to_timestamp(end)\n\n    ptime = stime + random.random() * (etime - stime)\n\n    return datetime.date.fromtimestamp(ptime)", "response": "Get a random date between two dates"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a prepared Session instance.", "response": "def _get_session(self):\n        \"\"\"Returns a prepared ``Session`` instance.\"\"\"\n        session = Session()\n\n        session.headers = {\n            'Content-type': 'application/json',\n            'Accept': 'application/vnd.heroku+json; version=3',\n        }\n\n        if self._auth_token:\n            session.trust_env = False  # Effectively disable netrc auth\n            session.headers['Authorization'] = 'Bearer %s' % self._auth_token\n\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef api_request(self, method, endpoint, data=None, *args, **kwargs):\n        session = self._get_session()\n\n        api_root = 'https://api.heroku.com'\n        url = api_root + endpoint\n\n        if data:\n            data = json.dumps(data)\n\n        response = session.request(method, url, data=data, *args, **kwargs)\n\n        if not response.ok:\n            try:\n                message = response.json().get('message')\n            except ValueError:\n                message = response.content\n\n            raise APIError(message)\n\n        return response.json()", "response": "Sends an API request to Heroku."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_build(self, tarball_url, env=None, app_name=None):\n        data = {\n            'source_blob': {\n                'url': tarball_url\n            }\n        }\n\n        if env:\n            data['overrides'] = {'env': env}\n\n        if app_name:\n            data['app'] = {'name': app_name}\n\n        return self.api_request('POST', '/app-setups', data=data)", "response": "Creates an app - setups build."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks the status of an app - setups build.", "response": "def check_build_status(self, build_id):\n        \"\"\"Checks the status of an app-setups build.\n\n        :param build_id: ID of the build to check.\n        :returns: ``True`` if succeeded, ``False`` if pending.\n        \"\"\"\n        data = self.api_request('GET', '/app-setups/%s' % build_id)\n\n        status = data.get('status')\n\n        if status == 'pending':\n            return False\n        elif status == 'succeeded':\n            return True\n        else:\n            raise BuildError(str(data))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sequence(prefix, cache=None):\n    if cache is None:\n        cache = _sequence_counters\n    if cache == -1:\n        cache = {}\n\n    if prefix not in cache:\n        cache[prefix] = infinite()\n\n    while cache[prefix]:\n        yield \"{0}-{1}\".format(prefix, next(cache[prefix]))", "response": "generator that returns an unique string"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_memoized_value(func, args, kwargs):\n    key = (repr(args), repr(kwargs))\n\n    if not key in func._cache_dict:\n        ret = func(*args, **kwargs)\n        func._cache_dict[key] = ret\n\n    return func._cache_dict[key]", "response": "Used internally by memoize decorator to get and store function results"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unique(func, num_args=0, max_attempts=100, cache=None):\n    if cache is None:\n        cache = _cache_unique\n\n    @wraps(func)\n    def wrapper(*args):\n        key = \"%s_%s\" % (str(func.__name__), str(args[:num_args]))\n        attempt = 0\n        while attempt < max_attempts:\n            attempt += 1\n            drawn = cache.get(key, [])\n            result = func(*args)\n            if result not in drawn:\n                drawn.append(result)\n                cache[key] = drawn\n                return result\n\n        raise MaxAttemptException()\n\n    return wrapper", "response": "A decorator that creates a random object and returns a unique version of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds any sub commands to the argument parser.", "response": "def register_sub_commands(self, parser):\n        \"\"\"\n        Add any sub commands to the argument parser.\n\n        :param parser: The argument parser object\n        \"\"\"\n        sub_commands = self.get_sub_commands()\n        if sub_commands:\n            sub_parsers = parser.add_subparsers(dest=self.sub_parser_dest_name)\n\n            for name, cls in sub_commands.items():\n                cmd = cls(name)\n\n                sub_parser = sub_parsers.add_parser(name, help=name, description=cmd.get_help(), formatter_class=cmd.get_formatter_class())\n\n                cmd.add_args(sub_parser)\n                cmd.register_sub_commands(sub_parser)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_root_argparser(self):\n        return self.arg_parse_class(description=self.get_help(), formatter_class=self.get_formatter_class())", "response": "Gets the root argument parser object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_description(self):\n        if self.description:\n            return self.description\n        elif self.__doc__ and self.__doc__.strip():\n            return self.__doc__.strip().split('.')[0] + '.'\n        else:\n            return ''", "response": "Gets the description of the command."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_help(self):\n        if self.help:\n            return self.help\n        elif self.__doc__ and self.__doc__.strip():\n            return self.__doc__.strip()\n        else:\n            return ''", "response": "Gets the help text for the command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the command passing in the parsed arguments.", "response": "def run(self, args=None):\n        \"\"\"\n        Runs the command passing in the parsed arguments.\n\n        :param args: The arguments to run the command with. If ``None`` the arguments\n            are gathered from the argument parser. This is automatically set when calling\n            sub commands and in most cases should not be set for the root command.\n\n        :return: The status code of the action (0 on success)\n        \"\"\"\n        args = args or self.parse_args()\n\n        sub_command_name = getattr(args, self.sub_parser_dest_name, None)\n        if sub_command_name:\n            sub_commands = self.get_sub_commands()\n            cmd_cls = sub_commands[sub_command_name]\n            return cmd_cls(sub_command_name).run(args)\n\n        return self.action(args) or 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a model form that can be used to bind an api key with a user.", "response": "def get_api_key_form(userfilter={}):\n    \"\"\"\n    userfileter: when binding api key with user, filter some users if necessary\n    \"\"\"\n    class APIKeyForm(ModelForm):\n        class Meta:\n            model = APIKeys\n            exclude = (\"apitree\",)\n        user = forms.ModelChoiceField(queryset=get_user_model().objects.filter(**userfilter),\n                                      required=True,)\n    return APIKeyForm"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encode(self,  *args, **kwargs):\n        if isinstance(args[0], str):\n            return self.encode([args[0]],**kwargs)\n        elif isinstance(args[0], int) or isinstance(args[0], float):\n            return self.encode([[args[0]]],**kwargs)\n        if len(args)>1:\n            dataset = args\n        else:\n            dataset = args[0]\n        typemap = list(map(type,dataset))\n        code = self.encoding[0]\n        if type('') in typemap:\n            data = ','.join(map(str,dataset))\n        elif type([]) in typemap or type(()) in typemap:\n            data = self.codeset['char'].join(map(self.encodedata, dataset))\n        elif len(dataset) == 1 and hasattr(dataset[0], '__iter__'):\n            data = self.encodedata(dataset[0])\n        else:\n            try:\n                data = self.encodedata(dataset)\n            except ValueError:\n                data = self.encodedata(','.join(map(unicode,dataset)))\n        if not '.' in data and code == 't':\n            code = 'e'\n        return '%s%s:%s'%(code,self.series,data)", "response": "Encode a dataset with maximum value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all available athletes", "response": "def get_athletes(self):\n        \"\"\"Get all available athletes\n        This method is cached to prevent unnecessary calls to GC.\n        \"\"\"\n        response = self._get_request(self.host)\n        response_buffer = StringIO(response.text)\n        \n        return pd.read_csv(response_buffer)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_last_activities(self, n):\n        filenames = self.get_activity_list().iloc[-n:].filename.tolist()\n        last_activities = [self.get_activity(f) for f in filenames]\n        return last_activities", "response": "Get the last n activities"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _athlete_endpoint(self, athlete):\n        return '{host}{athlete}'.format(\n            host=self.host,\n            athlete=quote_plus(athlete)\n        )", "response": "Construct athlete endpoint from host and athlete name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct the endpoint for the activity request.", "response": "def _activity_endpoint(self, athlete, filename):\n        \"\"\"Construct activity endpoint from host, athlete name and filename\n\n        Keyword arguments:\n        athlete -- Full athlete name\n        filename -- filename of request activity (e.g. \\'2015_04_29_09_03_16.json\\')\n        \"\"\"\n        return '{host}{athlete}/activity/{filename}'.format(\n            host=self.host,\n            athlete=quote_plus(athlete),\n            filename=filename\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_request(self, endpoint):\n        try:\n            response = requests.get(endpoint)\n        except requests.exceptions.RequestException:\n            raise GoldenCheetahNotAvailable(endpoint)\n        \n        if response.text.startswith('unknown athlete'):\n            match = re.match(\n                pattern='unknown athlete (?P<athlete>.+)',\n                string=response.text)\n            raise AthleteDoesNotExist(\n                athlete=match.groupdict()['athlete'])\n\n        elif response.text == 'file not found':\n            match = re.match(\n                pattern='.+/activity/(?P<filename>.+)',\n                string=endpoint)\n            raise ActivityDoesNotExist(\n                filename=match.groupdict()['filename'])\n\n        return response", "response": "Perform a GET request to the specified endpoint and return the response."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_version():\n    with open(os.path.join(os.path.dirname(__file__), 'argparsetree', '__init__.py')) as init_py:\n        return re.search('__version__ = [\\'\"]([^\\'\"]+)[\\'\"]', init_py.read()).group(1)", "response": "Return package version as listed in __version__ in init. py."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self, tarball_url, env=None, app_name=None):\n        data = self._api.create_build(\n            tarball_url=tarball_url,\n            env=env,\n            app_name=app_name,\n        )\n\n        return (data['id'], data['app']['name'])", "response": "Creates a Heroku app - setup build."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef url_with_auth(regex, view, kwargs=None, name=None, prefix=''):\n    from djapiauth.auth import api_auth\n    if isinstance(view, six.string_types):  # view is a string, must be full path\n        return url(regex, api_auth(import_by_path(prefix + \".\" + view if prefix else view)))\n    elif isinstance(view, (list, tuple)):  # include\n        return url(regex, view, name, prefix, **kwargs)\n    else:  # view is an object\n        return url(regex, api_auth(view))", "response": "Returns a url with auth"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntraverse all urls in the urlpattern and all sub urls in the urlpattern", "response": "def traverse_urls(urlpattern, prefixre=[], prefixname=[], patternFunc=None, resolverFunc=None):\n    \"\"\"\n    urlpattern: urlpattern object\n\n    prefix?? : for multiple level urls defined in different urls.py files\n    prefixre: compiled regex object\n    prefixnames: regex text\n\n    patternFunc: function to process RegexURLPattern\n    resolverFunc: function to process RegexURLResolver\n    \"\"\"\n    for u in urlpattern:\n        if isinstance(u, RegexURLResolver):  # inspect sub urls\n            if resolverFunc:\n                resolverFunc(u, prefixre, prefixname)\n\n            traverse_urls(u.url_patterns,\n                          prefixre + [u.regex, ],\n                          prefixname + [u._regex, ],\n                          patternFunc,\n                          resolverFunc)\n        else:\n            if patternFunc:\n                patternFunc(u, prefixre, prefixname)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a random title of the available languages and genders.", "response": "def title(languages=None, genders=None):\n    \"\"\"\n    returns a random title\n\n    .. code-block:: python\n\n        >>> d.title()\n        u'Mrs.'\n        >>> d.title(['es'])\n        u'El Sr.'\n        >>> d.title(None, [GENDER_FEMALE])\n        u'Mrs.'\n\n    :param languages: list of allowed languages. ['en'] if None\n    :param genders: list of allowed genders. (GENDER_FEMALE, GENDER_MALE) if None\n    \"\"\"\n    languages = languages or ['en']\n    genders = genders or (GENDER_FEMALE, GENDER_MALE)\n\n    choices = _get_titles(languages)\n    gender = {'m':0, 'f':1}[random.choice(genders)]\n\n    return random.choice(choices)[gender]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef person(languages=None, genders=None):\n    languages = languages or ['en']\n    genders = genders or (GENDER_FEMALE, GENDER_MALE)\n\n\n    lang = random.choice(languages)\n    g = random.choice(genders)\n    t = title([lang], [g])\n    return first_name([lang], [g]), last_name([lang]), t, g", "response": "Returns a random tuple representing person information."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef first_name(languages=None, genders=None):\n    choices = []\n    languages = languages or ['en']\n    genders = genders or [GENDER_MALE, GENDER_FEMALE]\n    for lang in languages:\n        for gender in genders:\n            samples = _get_firstnames(lang, gender)\n            choices.extend(samples)\n    return random.choice(choices).title()", "response": "Get a random first name of a given languages and genders."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a random last name for the given languages", "response": "def last_name(languages=None):\n    \"\"\"\n        return a random last name\n\n    >>> from mock import patch\n    >>> with patch('%s._get_lastnames' % __name__, lambda *args: ['aaa']):\n    ...     last_name()\n    'Aaa'\n    >>> with patch('%s.get_lastnames' % __name__, lambda lang: ['%s_lastname'% lang]):\n    ...     last_name(['it'])\n    'It_Lastname'\n    \"\"\"\n    choices = []\n    languages = languages or ['en']\n    for lang in languages:\n        samples = _get_lastnames(lang)\n        choices.extend(samples)\n    return random.choice(choices).title()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the hex color for any valid css color name", "response": "def lookup_color(color):\n    \"\"\"\n    Returns the hex color for any valid css color name\n    \n    >>> lookup_color('aliceblue')\n    'F0F8FF'\n    \"\"\"\n    if color is None: return\n    color = color.lower()\n    if color in COLOR_MAP:\n        return COLOR_MAP[color]\n    return color"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef color_args(args, *indexes):\n    for i,arg in enumerate(args):\n        if i in indexes:\n            yield lookup_color(arg)\n        else:\n            yield arg", "response": "Color a list of arguments on particular indexes"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding tick marks to the data.", "response": "def tick(self, index, length):\n        \"\"\"\n        Add tick marks in order of axes by width\n        APIPARAM: chxtc     <axis index>,<length of tick mark>\n        \"\"\"\n        assert int(length) <= 25, 'Width cannot be more than 25'\n        self.data['ticks'].append('%s,%d'%(index,length))\n        return self.parent"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef type(self, atype):\n        for char in atype:\n            assert char in 'xtyr', 'Invalid axes type: %s'%char\n        if not ',' in atype:\n            atype = ','.join(atype)\n        self['chxt'] = atype\n        return self.parent", "response": "Define the type of axes you wish to use"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef label(self, index, *args):\n        self.data['labels'].append(\n            str('%s:|%s'%(index, '|'.join(map(str,args)) )).replace('None','')\n        )\n        return self.parent", "response": "Add a label to the data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the range of each axis one at a time", "response": "def range(self, index, *args):\n        \"\"\"\n        Set the range of each axis, one at a time\n        args are of the form <start of range>,<end of range>,<interval>\n        APIPARAM: chxr\n        \"\"\"\n        self.data['ranges'].append('%s,%s'%(index,\n                                    ','.join(map(smart_str, args))))\n        return self.parent"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef style(self, index, *args):\n        args = color_args(args, 0)\n        self.data['styles'].append(\n            ','.join([str(index)]+list(map(str,args)))\n        )\n        return self.parent", "response": "Add style to your axis one at a time\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrendering the axes data into the dict data", "response": "def render(self):\n        \"\"\"Render the axes data into the dict data\"\"\"\n        for opt,values in self.data.items():\n            if opt == 'ticks':\n                self['chxtc'] = '|'.join(values)\n            else:\n                self['chx%s'%opt[0]] = '|'.join(values)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fromurl(cls, qs):\n        if isinstance(qs, dict):\n            return cls(**qs)\n        return cls(**dict(parse_qsl(qs[qs.index('?')+1:])))", "response": "Reverse a chart URL or dict into a GChart instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the geography and country codes for this chart", "response": "def map(self, geo, country_codes):\n        \"\"\"\n        Creates a map of the defined geography with the given country/state codes\n        Geography choices are africa, asia, europe, middle_east, south_america, and world\n        ISO country codes can be found at http://code.google.com/apis/chart/isocodes.html\n        US state codes can be found at http://code.google.com/apis/chart/statecodes.html\n        APIPARAMS: chtm & chld\n        \"\"\"\n        assert geo in GEO, 'Geograpic area %s not recognized'%geo\n        self._geo = geo\n        self._ld = country_codes\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the data scale down to the given size", "response": "def scale(self, *args):\n        \"\"\"\n        Scales the data down to the given size\n        args must be of the form::\n            <data set 1 minimum value>,\n            <data set 1 maximum value>,\n            <data set n minimum value>,\n            <data set n maximum value>\n        will only work with text encoding!\n        APIPARAM: chds\n        \"\"\"\n        self._scale =  [','.join(map(smart_str, args))]\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the chart s dataset", "response": "def dataset(self, data, series=''):\n        \"\"\"\n        Update the chart's dataset, can be two dimensional or contain string data\n        \"\"\"\n        self._dataset = data\n        self._series = series\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef marker(self, *args):\n        if len(args[0]) == 1:\n            assert args[0] in MARKERS, 'Invalid marker type: %s'%args[0]\n        assert len(args) <= 6, 'Incorrect arguments %s'%str(args)\n        args = color_args(args, 1)\n        self.markers.append(','.join(map(str,args)) )\n        return self", "response": "Adds a marker to the set of markers that can be used to display a single node in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting margins for chart area", "response": "def margin(self, left, right, top, bottom, lwidth=0, lheight=0):\n        \"\"\"\n        Set margins for chart area\n        args are of the form::\n            <left margin>,\n            <right margin>,\n            <top margin>,\n            <bottom margin>|\n            <legend width>,\n            <legend height>\n        \n        APIPARAM: chma\n        \"\"\"\n        self['chma'] = '%d,%d,%d,%d'  % (left, right, top, bottom)\n        if lwidth or lheight:\n            self['chma'] += '|%d,%d' % (lwidth, lheight)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a line to the list of line segments for each dataset in the set", "response": "def line(self, *args):\n        \"\"\"\n        Called one at a time for each dataset\n        args are of the form::\n            <data set n line thickness>,\n            <length of line segment>,\n            <length of blank segment>\n        APIPARAM: chls\n        \"\"\"\n        self.lines.append(','.join(['%.1f'%x for x in map(float,args)]))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying a solid fill to your chart", "response": "def fill(self, *args):\n        \"\"\"\n        Apply a solid fill to your chart\n        args are of the form <fill type>,<fill style>,...\n        fill type must be one of c,bg,a\n        fill style must be one of s,lg,ls\n        the rest of the args refer to the particular style\n        APIPARAM: chf\n        \"\"\"\n        a,b = args[:2]\n        assert a in ('c','bg','a'), 'Fill type must be bg/c/a not %s'%a\n        assert b in ('s','lg','ls'), 'Fill style must be s/lg/ls not %s'%b\n        if len(args) == 3:\n            args = color_args(args, 2)\n        else:\n            args = color_args(args, 3,5)\n        self.fills.append(','.join(map(str,args)))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply a grid to your chart", "response": "def grid(self, *args):\n        \"\"\"\n        Apply a grid to your chart\n        args are of the form::\n            <x axis step size>,\n            <y axis step size>,\n            <length of line segment>,\n            <length of blank segment>\n            <x offset>,\n            <y offset>\n        APIPARAM: chg\n        \"\"\"\n        grids =  map(str,map(float,args))\n        self['chg'] = ','.join(grids).replace('None','')\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef color(self, *args):\n        args = color_args(args, *range(len(args)))\n        self['chco'] = ','.join(args)\n        return self", "response": "Add a color for each dataset\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef label(self, *args):\n        if self['cht'] == 'qr':\n            self['chl'] = ''.join(map(str,args))\n        else:\n            self['chl'] = '|'.join(map(str,args))\n        return self", "response": "Add a simple label to your chart\n        call each time for each dataset\n        APIPARAM chl\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef legend_pos(self, pos):\n        assert pos in LEGEND_POSITIONS, 'Unknown legend position: %s'%pos\n        self['chdlp'] = str(pos)\n        return self", "response": "Set the legend position"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef title(self, title, *args):\n        self['chtt'] = title\n        if args:\n            args = color_args(args, 0)\n            self['chts'] = ','.join(map(str,args))\n        return self", "response": "Add a title to your chart\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the size of the chart", "response": "def size(self,*args):\n        \"\"\"\n        Set the size of the chart, args are width,height and can be tuple\n        APIPARAM: chs\n        \"\"\"\n        if len(args) == 2:\n            x,y = map(int,args)\n        else:\n            x,y = map(int,args[0])\n        self.check_size(x,y)\n        self['chs'] = '%dx%d'%(x,y)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render(self):\n        self.update(self.axes.render())\n        encoder = Encoder(self._encoding, None, self._series)\n        if not 'chs' in self:\n            self['chs'] = '300x150'\n        else:\n            size = self['chs'].split('x')\n            assert len(size) == 2, 'Invalid size, must be in the format WxH'\n            self.check_size(*map(int,size))\n        assert 'cht' in self, 'No chart type defined, use type method'\n        self['cht'] = self.check_type(self['cht'])\n        if ('any' in dir(self._dataset) and self._dataset.any()) or self._dataset:\n            self['chd'] = encoder.encode(self._dataset)\n        elif not 'choe' in self:\n            assert 'chd' in self, 'You must have a dataset, or use chd'\n        if self._scale:\n            assert self['chd'].startswith('t'),\\\n                'You must use text encoding with chds'\n            self['chds'] = ','.join(self._scale)\n        if self._geo and self._ld:\n            self['chtm'] = self._geo\n            self['chld'] = self._ld\n        if self.lines:\n            self['chls'] = '|'.join(self.lines)\n        if self.markers:\n            self['chm'] = '|'.join(self.markers)\n        if self.fills:\n            self['chf'] = '|'.join(self.fills)", "response": "Render the chart context and axes into the dict data\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef url(self):\n        self.render()        \n        return self._apiurl + '&'.join(self._parts()).replace(' ','+')", "response": "Returns the rendered URL of the chart\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshow the chart URL in a webbrowser", "response": "def show(self, *args, **kwargs):\n        \"\"\"\n        Shows the chart URL in a webbrowser\n\n        Other arguments passed to webbrowser.open\n        \"\"\"\n        from webbrowser import open as webopen\n        return webopen(str(self), *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload the chart from the URL into a PNG file", "response": "def save(self, fname=None):\n        \"\"\"\n        Download the chart from the URL into a filename as a PNG\n\n        The filename defaults to the chart title (chtt) if any\n        \"\"\"\n        if not fname:\n            fname = self.getname()\n        assert fname != None, 'You must specify a filename to save to'\n        if not fname.endswith('.png'):\n            fname += '.png'\n        try:\n            urlretrieve(self.url, fname)\n        except Exception:\n            raise IOError('Problem saving %s to file'%fname)\n        return fname"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an XHTML img tag of the chart", "response": "def img(self, **kwargs):\n        \"\"\" \n        Returns an XHTML <img/> tag of the chart\n\n        kwargs can be other img tag attributes, which are strictly enforced\n        uses strict escaping on the url, necessary for proper XHTML\n        \"\"\"       \n        safe = 'src=\"%s\" ' % self.url.replace('&','&amp;').replace('<', '&lt;')\\\n            .replace('>', '&gt;').replace('\"', '&quot;').replace( \"'\", '&#39;')\n        for item in kwargs.items():\n            if not item[0] in IMGATTRS:\n                raise AttributeError('Invalid img tag attribute: %s'%item[0])\n            safe += '%s=\"%s\" '%item\n        return '<img %s/>'%safe"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef urlopen(self):\n        req = Request(str(self))\n        try:\n            return urlopen(req)\n        except HTTPError:\n            _print('The server couldn\\'t fulfill the request.')\n        except URLError:\n            _print('We failed to reach a server.')", "response": "A URL - like object that returns a file pointer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef image(self):\n        try:\n            try:\n                import Image\n            except ImportError:\n                from PIL import Image\n        except ImportError:\n            raise ImportError('You must install PIL to fetch image objects')\n        try:\n            from cStringIO import StringIO\n        except ImportError:\n            from StringIO import StringIO\n        return Image.open(StringIO(self.urlopen().read()))", "response": "Returns a PIL Image instance of the chart\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write(self, fp):\n        urlfp = self.urlopen().fp\n        while 1:\n            try:\n                fp.write(urlfp.next())\n            except StopIteration:\n                return", "response": "Writes out PNG image data in chunks to file pointer fp must support w or wb\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the SHA1 hexdigest of the chart URL param parts", "response": "def checksum(self):\n        \"\"\"\n        Returns the unique SHA1 hexdigest of the chart URL param parts\n\n        good for unittesting...\n        \"\"\"\n        self.render()\n        return new_sha(''.join(sorted(self._parts()))).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets ISO 3166 - 1 ISO 3166 - 1 countryInfo. txt file.", "response": "def get_codes():\n    \"\"\"\n    >> get_codes()\n    ISO\tISO3\tISO-Numeric\tfips\tCountry\tCapital\tArea(in sq km)\tPopulation\tContinent\ttld\tCurrencyCode\tCurrencyName\tPhone\tPostal Code Format\tPostal Code Regex\tLanguages\tgeonameid\tneighbours\tEquivalentFipsCode\n    \"\"\"\n    cache_filename = os.path.join(os.path.dirname(__file__), 'data', 'countryInfo.txt')\n    data = []\n    for line in open(cache_filename, 'r'):\n        if not line.startswith('#'):\n            data.append(line.split('\\t'))\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef amount(min=1, max=sys.maxsize, decimal_places=2):\n    q = '.%s1' % '0' * (decimal_places - 1)\n    return decimal.Decimal(uniform(min, max)).quantize(decimal.Decimal(q))", "response": "return a random floating number"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nassign an entity name based on the class immediately inhering from Base. This is needed because we don't want entity names to come from any class that simply inherits our classes, just the ones in our module. For example, if you create a class Project2 that exists outside of kalibro_client and inherits from Project, it's entity name should still be Project.", "response": "def entity_name_decorator(top_cls):\n    \"\"\"\n    Assign an entity name based on the class immediately inhering from Base.\n\n    This is needed because we don't want\n    entity names to come from any class that simply inherits our classes,\n    just the ones in our module.\n\n    For example, if you create a class Project2 that exists outside of\n    kalibro_client and inherits from Project, it's entity name should still\n    be Project.\n    \"\"\"\n    class_name = inflection.underscore(top_cls.__name__).lower()\n\n    def entity_name(cls):\n        return class_name\n\n    top_cls.entity_name = classmethod(entity_name)\n\n    return top_cls"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef eval(self, orig):\n        _le = {}\n        _err = []\n        for k, v in self.sup_items():\n            if k in DoNotCompare:\n                continue\n            if k in orig:\n                if is_lesser(orig[k], v):\n                    _le[k] = orig[k]\n                else:\n                    _err.append({'claim': k, 'policy': orig[k], 'err': v,\n                                 'signer': self.iss})\n            else:\n                _le[k] = v\n\n        for k, v in orig.items():\n            if k in DoNotCompare:\n                continue\n            if k not in _le:\n                _le[k] = v\n\n        self.le = _le\n        self.err = _err", "response": "Apply the less or equal algorithm on the ordered list of metadata available at this time."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of unprotected and protected claims.", "response": "def unprotected_and_protected_claims(self):\n        \"\"\"\n        This is both verified and self asserted information. As expected \n        verified information beats self-asserted so if there is both \n        self-asserted and verified values for a claim then only the verified\n        will be returned.\n        \"\"\"\n        if self.sup:\n            res = {}\n            for k, v in self.le.items():\n                if k not in self.sup.le:\n                    res[k] = v\n                else:\n                    res[k] = self.sup.le[k]\n            return res\n        else:\n            return self.le"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a JWKS dictionary from the signing keys belonging to the self signer", "response": "def signing_keys_as_jwks(self):\n        \"\"\"\n        Build a JWKS from the signing keys belonging to the self signer\n\n        :return: Dictionary\n        \"\"\"\n        _l = [x.serialize() for x in self.self_signer.keyjar.get_signing_key()]\n        if not _l:\n            _l = [x.serialize() for x in\n                  self.self_signer.keyjar.get_signing_key(owner=self.iss)]\n        return {'keys': _l}"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nunpacks a dictionary of metadata into a single object.", "response": "def _unpack(self, ms_dict, keyjar, cls, jwt_ms=None, liss=None):\n        \"\"\"\n        \n        :param ms_dict: Metadata statement as a dictionary\n        :param keyjar: A keyjar with the necessary FO keys\n        :param cls: What class to map the metadata into\n        :param jwt_ms: Metadata statement as a JWS \n        :param liss: List of FO issuer IDs\n        :return: ParseInfo instance\n        \"\"\"\n        if liss is None:\n            liss = []\n\n        _pr = ParseInfo()\n        _pr.input = ms_dict\n        ms_flag = False\n        if 'metadata_statements' in ms_dict:\n            ms_flag = True\n            for iss, _ms in ms_dict['metadata_statements'].items():\n                if liss and iss not in liss:\n                    continue\n                _pr = self._ums(_pr, _ms, keyjar)\n\n        if 'metadata_statement_uris' in ms_dict:\n            ms_flag = True\n            if self.httpcli:\n                for iss, url in ms_dict['metadata_statement_uris'].items():\n                    if liss and iss not in liss:\n                        continue\n                    rsp = self.httpcli(method='GET', url=url,\n                                       verify=self.verify_ssl)\n                    if rsp.status_code == 200:\n                        _pr = self._ums(_pr, rsp.text, keyjar)\n                    else:\n                        raise ParseError(\n                            'Could not fetch jws from {}'.format(url))\n\n        for _ms in _pr.parsed_statement:\n            if _ms:  # can be None\n                loaded = False\n                try:\n                    keyjar.import_jwks_as_json(_ms['signing_keys'],\n                                               ms_dict['iss'])\n                except KeyError:\n                    pass\n                except TypeError:\n                    try:\n                        keyjar.import_jwks(_ms['signing_keys'], ms_dict['iss'])\n                    except Exception as err:\n                        logger.error(err)\n                        raise\n                    else:\n                        loaded = True\n                else:\n                    loaded = True\n\n                if loaded:\n                    logger.debug(\n                        'Loaded signing keys belonging to {} into the '\n                        'keyjar'.format(ms_dict['iss']))\n\n        if ms_flag is True and not _pr.parsed_statement:\n            return _pr\n\n        if jwt_ms:\n            logger.debug(\"verifying signed JWT: {}\".format(jwt_ms))\n            try:\n                _pr.result = cls().from_jwt(jwt_ms, keyjar=keyjar)\n            except MissingSigningKey:\n                if 'signing_keys' in ms_dict:\n                    try:\n                        _pr.result = self.self_signed(ms_dict, jwt_ms, cls)\n                    except MissingSigningKey as err:\n                        logger.error('Encountered: {}'.format(err))\n                        _pr.error[jwt_ms] = err\n            except (JWSException, BadSignature, KeyError) as err:\n                logger.error('Encountered: {}'.format(err))\n                _pr.error[jwt_ms] = err\n        else:\n            _pr.result = ms_dict\n\n        if _pr.result and _pr.parsed_statement:\n            _prr = _pr.result\n\n            _res = {}\n            for x in _pr.parsed_statement:\n                if x:\n                    _res[get_fo(x)] = x\n\n            _msg = Message(**_res)\n            logger.debug('Resulting metadata statement: {}'.format(_msg))\n            _pr.result['metadata_statements'] = _msg\n        return _pr"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unpack_metadata_statement(self, ms_dict=None, jwt_ms='', keyjar=None,\n                                  cls=ClientMetadataStatement, liss=None):\n        \"\"\"\n        Starting with a signed JWT or a JSON document unpack and verify all\n        the separate metadata statements.\n\n        :param ms_dict: Metadata statement as a dictionary\n        :param jwt_ms: Metadata statement as JWT\n        :param keyjar: Keys that should be used to verify the signature of the\n            document\n        :param cls: What type (Class) of metadata statement this is\n        :param liss: list of FO identifiers that matters. The rest will be \n            ignored\n        :return: A ParseInfo instance\n        \"\"\"\n\n        if not keyjar:\n            if self.jwks_bundle:\n                keyjar = self.jwks_bundle.as_keyjar()\n            else:\n                keyjar = KeyJar()\n\n        if jwt_ms:\n            try:\n                ms_dict = unfurl(jwt_ms)\n            except JWSException as err:\n                logger.error('Could not unfurl jwt_ms due to {}'.format(err))\n                raise\n\n        if ms_dict:\n            return self._unpack(ms_dict, keyjar, cls, jwt_ms, liss)\n        else:\n            raise AttributeError('Need one of ms_dict or jwt_ms')", "response": "Unpacks a single metadata statement into a ParseInfo instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pack_metadata_statement(self, metadata, receiver='', iss='', lifetime=0,\n                                sign_alg=''):\n        \"\"\"\n        Given a MetadataStatement instance create a signed JWT.\n\n        :param metadata: Original metadata statement as a MetadataStatement\n            instance\n        :param receiver: Receiver (audience) of the JWT\n        :param iss: Issuer ID if different from default\n        :param lifetime: jWT signature life time\n        :param sign_alg: JWT signature algorithm\n        :return: A JWT\n        \"\"\"\n\n        return self.self_signer.sign(metadata, receiver=receiver, iss=iss,\n                                     lifetime=lifetime, sign_alg=sign_alg)", "response": "Packs a MetadataStatement instance into a JWT."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef evaluate_metadata_statement(self, metadata, keyjar=None):\n\n        # start from the innermost metadata statement and work outwards\n\n        res = dict([(k, v) for k, v in metadata.items() if k not in IgnoreKeys])\n\n        les = []\n\n        if 'metadata_statements' in metadata:\n            for fo, ms in metadata['metadata_statements'].items():\n                if isinstance(ms, str):\n                    ms = json.loads(ms)\n                for _le in self.evaluate_metadata_statement(ms):\n                    if isinstance(ms, Message):\n                        le = LessOrEqual(sup=_le, **ms.to_dict())\n                    else:  # Must be a dict\n                        le = LessOrEqual(sup=_le, **ms)\n\n                    if le.is_expired():\n                        logger.error(\n                            'This metadata statement has expired: {}'.format(ms)\n                        )\n                        logger.info('My time: {}'.format(utc_time_sans_frac()))\n                        continue\n                    le.eval(res)\n                    les.append(le)\n            return les\n        else:  # this is the innermost\n            try:\n                _iss = metadata['iss']\n            except:\n                le = LessOrEqual()\n                le.eval(res)\n            else:\n                le = LessOrEqual(iss=_iss, exp=metadata['exp'])\n                le.eval(res)\n            les.append(le)\n            return les", "response": "Evaluate the compounded metadata statement and return a list of LessOrEqual instances."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef correct_usage(self, metadata, federation_usage):\n\n        if 'metadata_statements' in metadata:\n            _msl = {}\n            for fo, ms in metadata['metadata_statements'].items():\n                if not isinstance(ms, Message):\n                    ms = json.loads(ms)\n\n                if self.correct_usage(ms, federation_usage=federation_usage):\n                    _msl[fo] = ms\n            if _msl:\n                metadata['metadata_statements'] = Message(**_msl)\n                return metadata\n            else:\n                return None\n        else:  # this is the innermost\n            try:\n                assert federation_usage == metadata['federation_usage']\n            except KeyError:\n                pass\n            except AssertionError:\n                return None\n            return metadata", "response": "This method is used to remove MS paths that are not used for another context."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extend_with_ms(self, req, sms_dict):\n        _ms_uri = {}\n        _ms = {}\n        for fo, sms in sms_dict.items():\n            if sms.startswith('http://') or sms.startswith('https://'):\n                _ms_uri[fo] = sms\n            else:\n                _ms[fo] = sms\n\n        if _ms:\n            req['metadata_statements'] = Message(**_ms)\n        if _ms_uri:\n            req['metadata_statement_uris'] = Message(**_ms_uri)\n        return req", "response": "Extend a request with signed metadata statements."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses command line args using argparse library", "response": "def parse_args():\n    \"\"\"\n    Parses command line args using argparse library\n    \"\"\"\n    usage = \"Usage: create_concordance <infile> [<outfile>]\"\n    description = \"Simple Concordance Generator\"\n    argparser = argparse.ArgumentParser(\n        usage=usage, description=description)\n\n    argparser.add_argument(\n        'infile', type=argparse.FileType('r'),\n        help=\"File read in to create concordance\")\n\n    argparser.add_argument(\n        'outfile', nargs='?', type=argparse.FileType('w'),\n        default=sys.stdout, help=\"File to write concordance to.  \"\n        \"Default is stdout\")\n\n    argparser.add_argument(\n        '--word', nargs=\"?\", const=str, help=\"Display a word in concordance\")\n    args = argparser.parse_args()\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef addCommandLineArgs(arg_parser):\n    arg_parser.register(\"action\", \"log_levels\", LogLevelAction)\n    arg_parser.register(\"action\", \"log_files\", LogFileAction)\n    arg_parser.register(\"action\", \"log_help\", LogHelpAction)\n\n    group = arg_parser.add_argument_group(\"Logging options\")\n    group.add_argument(\n        \"-l\", \"--log-level\", dest=\"log_levels\",\n        action=\"log_levels\", metavar=\"LOGGER:LEVEL\", default=[],\n        help=\"Set log levels for individual loggers. See --help-logging for \"\n             \"complete details.\")\n\n    group.add_argument(\n        \"-L\", \"--log-file\", dest=\"log_files\",\n        action=\"log_files\", metavar=\"LOGGER:FILE\", default=[],\n        help=\"Set log the output file for individual loggers. \"\n             \" See --help-logging for complete details.\")\n\n    group.add_argument(\"--help-logging\", action=\"log_help\",\n                       help=argparse.SUPPRESS)", "response": "Add logging option to an ArgumentParser."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef applyLoggingOpts(log_levels, log_files):\n    for l, lvl in log_levels:\n        l.setLevel(lvl)\n    for l, hdl in log_files:\n        for h in l.handlers:\n            l.removeHandler(h)\n        l.addHandler(hdl)", "response": "Apply logging options produced by LogLevelAction and LogFileAction."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verbose(self, msg, *args, **kwargs):\n        self.log(logging.VERBOSE, msg, *args, **kwargs)", "response": "Log msg at verbose level debug < verbose < info"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a valid data for post", "response": "def _aodata(echo, columns, xnxq=None, final_exam=False):\n        \"\"\"\n        \u751f\u6210\u7528\u4e8epost\u7684\u6570\u636e\n\n        :param echo: a int to check is response is write\n        :type echo: int\n        :param columns: \u6240\u6709columns\u5217\u540d\u7ec4\u6210\u7684list\n        :type columns: list\n        :param xnxq: str\n        :type xnxq: string\n        :param final_exam: \u662f\u5426\u671f\u672b\u8003\u8bd5\n        :rtype: bool\n        :return: a valid data for post to get data\n        \"\"\"\n        ao_data = [{\"name\": \"sEcho\", \"value\": echo},\n                   {\"name\": \"iColumns\", \"value\": len(columns)},\n                   {\"name\": \"sColumns\", \"value\": \"\"},\n                   {\"name\": \"iDisplayStart\", \"value\": 0},\n                   {\"name\": \"iDisplayLength\", \"value\": -1},\n                   ]\n        if xnxq:\n            if final_exam:\n                ao_data.append(\n                    {\"name\": \"ksrwid\", \"value\": \"000000005bf6cb6f015bfac609410d4b\"})\n            ao_data.append({\"name\": \"xnxq\", \"value\": xnxq})\n\n        for index, value in enumerate(columns):\n            ao_data.append(\n                {\"name\": \"mDataProp_{}\".format(index), \"value\": value})\n            ao_data.append(\n                {\"name\": \"bSortable_{}\".format(index), \"value\": False})\n\n        return urlencode({\"aoData\": ao_data})"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlogin to the Akolekhov", "response": "def login(self):\n        \"\"\"\n        \u767b\u9646\u7cfb\u7edf,\u8fd4\u56de\u4e00\u4e2arequests\u7684session\u5bf9\u8c61\n\n        :return: session with login cookies\n        :rtype: requests.sessions.Session\n        \"\"\"\n        if not hasattr(self, 'session'):\n            self.last_connect = time.time()\n            s = requests.session()\n            s.get('http://bkjws.sdu.edu.cn')\n\n            data = {\n                'j_username': self.student_id,\n                'j_password': self.password_md5\n            }\n            r6 = s.post('http://bkjws.sdu.edu.cn/b/ajaxLogin', headers={\n                'user-agent': self._ua},\n                data=data)\n            if r6.text == '\"success\"':\n                return s\n            else:\n                s.close()\n                raise AuthFailure(r6.text)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_lesson(self):\n        html = self._get('http://bkjws.sdu.edu.cn/f/xk/xs/bxqkb')\n        soup = BeautifulSoup(html, \"html.parser\")\n        s = soup.find('table',\n                      attrs={\"class\": \"table table-striped table-bordered table-hover\",\n                             \"id\": \"ysjddDataTableId\"})\n        tr_box = s.find_all('tr')\n        c = list()\n\n        for les in tr_box[1:]:\n            td_box = les.find_all('td')\n            c.append({\"lesson_num_long\": td_box[1].text,\n                      \"lesson_name\": td_box[2].text,\n                      \"lesson_num_short\": td_box[3].text,\n                      \"credit\": td_box[4].text,\n                      \"school\": td_box[6].text,\n                      \"teacher\": td_box[7].text,\n                      \"weeks\": td_box[8].text,\n                      \"days\": td_box[9].text,\n                      \"times\": td_box[10].text,\n                      \"place\": td_box[11].text})\n        self._lessons = c\n        return c", "response": "\u83b7\u53d6\u8bfe\u8868,\u8fd4\u56de\u4e00\u4e2a\u5217\u8868,\u5305\u542b\u6240\u6709\u8bfe\u8868\u5bf9\u8c61\n\n        :return: list of lessons\n        :rtype: list[dict]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_detail(self):\n        response = self._post(\"http://bkjws.sdu.edu.cn/b/grxx/xs/xjxx/detail\",\n                              data=None)\n        if response['result'] == 'success':\n            self._detail = response['object']\n            return self._detail\n        else:\n            self._unexpected(response)", "response": "get the student s detail"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the raw response of past score", "response": "def get_raw_past_score(self):\n        \"\"\"\n        \u5386\u5e74\u6210\u7ee9\u67e5\u8be2\u7684\u539f\u59cb\u8fd4\u56de\u503c,\u8bf7\u4f7f\u7528get_past_score()\n        :return: dict of the raw response of past score\n        :rtype: dict\n        \"\"\"\n        echo = self._echo\n\n        response = self._post(\"http://bkjws.sdu.edu.cn/b/cj/cjcx/xs/lscx\",\n\n                              data=self._aodata(echo,\n                                                columns=[\"xnxq\", \"kcm\", \"kxh\", \"xf\", \"kssj\",\n                                                         \"kscjView\", \"wfzjd\",\n                                                         \"wfzdj\",\n                                                         \"kcsx\"]))\n        if self._check_response(response, echo):\n            self._raw_past_score = response\n            return self._raw_past_score\n        else:\n            self._unexpected(response)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget comment lesson info.", "response": "def get_comment_lesson_info(self):  # \u83b7\u53d6\u8bfe\u7a0b\u5e8f\u5217\n        \"\"\"\n        \u83b7\u53d6\u6559\u5b66\u8bc4\u4f30\u5185\u6240\u6709\u9700\u8981\u8bfe\u7a0b\n\n        :return: \u8fd4\u56de\u6240\u4ee5\u6709\u9700\u8981\u8fdb\u884c\u6559\u5b66\u8bc4\u4f30\u7684\u8bfe\u7a0b\n        :rtype: list\n        \"\"\"\n        echo = self._echo\n        response = self._post('http://bkjws.sdu.edu.cn/b/pg/xs/list',\n                              data=self._aodata(echo, ['kch', 'kcm', 'jsm', 'function', 'function']), )\n        if self._check_response(response, echo=echo):\n            return response['object']['aaData']\n        else:\n            self._unexpected(response)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _letter_map(word):\n\n    lmap = {}\n    for letter in word:\n        try:\n            lmap[letter] += 1\n        except KeyError:\n            lmap[letter] = 1\n    return lmap", "response": "Creates a dictionary of the number of letters used in a word."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef anagrams_in_word(word, sowpods=False, start=\"\", end=\"\"):\n\n    input_letters, blanks, questions = blank_tiles(word)\n\n    for tile in start + end:\n        input_letters.append(tile)\n\n    for word in word_list(sowpods, start, end):\n        lmap = _letter_map(input_letters)\n        used_blanks = 0\n        for letter in word:\n            if letter in lmap:\n                lmap[letter] -= 1\n                if lmap[letter] < 0:\n                    used_blanks += 1\n                    if used_blanks > (blanks + questions):\n                        break\n            else:\n                used_blanks += 1\n                if used_blanks > (blanks + questions):\n                    break\n        else:\n            yield (word, word_score(word, input_letters, questions))", "response": "Finds anagrams in a word."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the exception s name in an AMP Command friendly format.", "response": "def asAMP(cls):\n        \"\"\"\n        Returns the exception's name in an AMP Command friendly format.\n\n        For example, given a class named ``ExampleExceptionClass``, returns\n        ``\"EXAMPLE_EXCEPTION_CLASS\"``.\n        \"\"\"\n        parts = groupByUpperCase(cls.__name__)\n        return cls, \"_\".join(part.upper() for part in parts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransforms a Go Metrics API metric result into a list of neccesary values for a given window period.", "response": "def transform_timeseries_data(timeseries, start, end=None):\n    \"\"\"Transforms a Go Metrics API metric result into a list of\n    values for a given window period.\n\n    start and end are expected to be Unix timestamps in microseconds.\n    \"\"\"\n    data = []\n    include = False\n    for metric, points in timeseries.items():\n        for point in points:\n            if point['x'] == start:\n                include = True\n            if include:\n                data.append(point['y'])\n            if end is not None and point['x'] == end:\n                return data\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_last_value_from_timeseries(timeseries):\n    if not timeseries:\n        return 0\n    for metric, points in timeseries.items():\n        return next((p['y'] for p in reversed(points) if p['y'] > 0), 0)", "response": "Gets the last non - zero value for a. last metric or zero if empty."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating the given 1 - based page number.", "response": "def validate_page_number(number):\n    \"\"\"Validate the given 1-based page number.\"\"\"\n    try:\n        number = int(number)\n    except (TypeError, ValueError):\n        raise PageNotAnInteger('That page number is not an integer')\n    if number < 1:\n        raise EmptyPage('That page number is less than 1')\n    return number"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_page_of_iterator(iterator, page_size, page_number):\n    try:\n        page_number = validate_page_number(page_number)\n    except (PageNotAnInteger, EmptyPage):\n        page_number = 1\n\n    start = (page_number - 1) * page_size\n    # End 1 more than we need, so that we can see if there's another page\n    end = (page_number * page_size) + 1\n    skipped_items = list(islice(iterator, start))\n    items = list(islice(iterator, end))\n\n    if len(items) == 0 and page_number != 1:\n        items = skipped_items\n        page_number = 1\n\n    has_next = len(items) > page_size\n    items = items[:page_size]\n\n    return NoCountPage(items, page_number, page_size, has_next)", "response": "Get a page from an iterator handling invalid input from the page number\n    by defaulting to the first page."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes the given command and returns a 2 - tuple with returncode and output", "response": "def sh(cmd, escape=True):\n    \"\"\" Executes the given command.\n    returns a 2-tuple with returncode (integer) and OUTPUT (string)\n    \"\"\"\n\n    if escape:\n        cmd = quote(cmd)\n\n    process = Popen(cmd, stdout=PIPE, stderr=STDOUT, shell=True)\n    output, unused_err = process.communicate()\n    retcode = process.poll()\n\n    return (retcode, output)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gzip(filename):\n\n    ## run gzip\n    retcode, output = sh('gzip %s' % filename)\n    new_filename = filename+'.gz'\n\n    return (retcode, output, new_filename)", "response": "gzip a file\n    returns a 3 - tuple with returncode and terminal output and the new filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tar(filename, dirs=[], gzip=False):\n    if gzip:\n        cmd = 'tar czvf %s ' % filename\n    else:\n        cmd = 'tar cvf %s ' % filename\n\n    if type(dirs) != 'list':\n        dirs = [dirs]\n\n    cmd += ' '.join(str(x) for x in dirs)\n\n    retcode, output = sh(cmd)\n\n    return (retcode, output, filename)", "response": "Create a tar - file or a tar. gz at location filename."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef chown(path, uid, guid, recursive=True):\n\n    if recursive:\n        cmd = 'chown -R %s:%s %s' % (uid, guid, path)\n    else:\n        cmd = 'chown %s:%s %s' % (uid, guid, path)\n\n    return sh(cmd)", "response": "wrapper around os. chown."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle_exception(self, exc_info=None, state=None, tags=None, return_feedback_urls=False,\n                         dry_run=False):\n        \"\"\"\n        Call this method from within a try/except clause to generate a call to Stack Sentinel.\n\n        :param exc_info: Return value of sys.exc_info(). If you pass None, handle_exception will call sys.exc_info() itself\n        :param state: Dictionary of state information associated with the error. This could be form data, cookie data, whatnot. NOTE: sys and machine are added to this dictionary if they are not already included.\n        :param tags: Any string tags you want associated with the exception report.\n        :param return_feedback_urls: If True, Stack Sentinel will return feedback URLs you can present to the user for extra debugging information.\n        :param dry_run: If True, method will not actively send in error information to API. Instead, it will return a request object and payload. Used in unittests.\n\n        \"\"\"\n        if not exc_info:\n            exc_info = sys.exc_info()\n        if exc_info is None:\n            raise StackSentinelError(\"handle_exception called outside of exception handler\")\n\n        (etype, value, tb) = exc_info\n        try:\n            msg = value.args[0]\n        except:\n            msg = repr(value)\n\n        if not isinstance(tags, list):\n            tags = [tags]\n\n        limit = None\n\n        new_tb = []\n        n = 0\n\n        while tb is not None and (limit is None or n < limit):\n            f = tb.tb_frame\n            lineno = tb.tb_lineno\n            co = f.f_code\n            filename = co.co_filename\n            name = co.co_name\n            tb = tb.tb_next\n            n = n + 1\n\n            new_tb.append({'line': lineno, 'module': filename, 'method': name})\n\n        if state is None:\n            state = {}\n\n        if 'sys' not in state:\n            try:\n                state['sys'] = self._get_sys_info()\n            except Exception as e:\n                state['sys'] = '<Unable to get sys: %r>' % e\n        if 'machine' not in state:\n            try:\n                state['machine'] = self._get_machine_info()\n            except Exception as e:\n                state['machine'] = '<Unable to get machine: %e>' % e\n\n        if tags is None:\n            tags = []\n\n        # The joy of Unicode\n        if sys.version_info.major > 2:\n            error_type = str(etype.__name__)\n            error_message = str(value)\n        else:\n            error_type = unicode(etype.__name__)\n            error_message = unicode(value)\n\n        send_error_args = dict(error_type=error_type,\n                               error_message=error_message,\n                               traceback=new_tb,\n                               environment=self.environment,\n                               state=state,\n                               tags=self.tags + tags,\n                               return_feedback_urls=return_feedback_urls)\n        if dry_run:\n            return send_error_args\n        else:\n            return self.send_error(**send_error_args)", "response": "This method is called by the exception handler method to generate a stack - Sentinel exception report."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend an error to Stack Sentinel API.", "response": "def send_error(self, error_type, error_message, traceback, environment, state, tags=None,\n                   return_feedback_urls=False):\n        \"\"\"\n        Sends error payload to Stack Sentinel API, returning a parsed JSON response. (Parsed as in,\n        converted into Python dict/list objects)\n\n        :param error_type: Type of error generated. (Eg, \"TypeError\")\n        :param error_message: Message of error generated (Eg, \"cannot concatenate 'str' and 'int' objects\")\n        :param traceback: List of dictionaries. Each dictionary should contain, \"line\", \"method\", and \"module\" keys.\n        :param environment: Environment the error occurred in (eg, \"devel\")_\n        :param state: State of the application when the error happened. Could contain form data, cookies, etc.\n        :param tags: Arbitrary tags you want associated with the error. list.\n        :param return_feedback_urls: If True, return payload will offer URLs to send users to collect additional feedback for debugging.\n        :return: Parsed return value from Stack Sentinel API\n        \"\"\"\n\n        (request, payload) = self._generate_request(environment, error_message, error_type, return_feedback_urls,\n                                                    state, tags, traceback)\n        try:\n            response = urlopen(request)\n        except HTTPError as e:\n            if e.code == 400:\n                raise StackSentinelError(e.read())\n            else:\n                raise\n\n        if sys.version_info.major > 2:\n            text_response = response.read().decode(response.headers.get_content_charset() or 'utf8')\n        else:\n            encoding = response.headers.get('content-type', '').split('charset=')[-1].strip()\n            if encoding:\n                text_response = response.read().decode('utf8', 'replace')\n            else:\n                text_response = response.read().decode(encoding)\n\n        return json.loads(text_response)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_internal_signing_service(config, entity_id):\n\n    _args = dict([(k, v) for k, v in config.items() if k in KJ_SPECS])\n    _kj = init_key_jar(**_args)\n\n    return InternalSigningService(entity_id, _kj)", "response": "Given a configuration initiate an InternalSigningService instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a configuration initiate a SigningService instance", "response": "def make_signing_service(config, entity_id):\n    \"\"\"\n    Given configuration initiate a SigningService instance\n\n    :param config: The signing service configuration\n    :param entity_id: The entity identifier\n    :return: A SigningService instance\n    \"\"\"\n\n    _args = dict([(k, v) for k, v in config.items() if k in KJ_SPECS])\n    _kj = init_key_jar(**_args)\n\n    if config['type'] == 'internal':\n        signer = InternalSigningService(entity_id, _kj)\n    elif config['type'] == 'web':\n        _kj.issuer_keys[config['iss']] = _kj.issuer_keys['']\n        del _kj.issuer_keys['']\n        signer = WebSigningServiceClient(config['iss'], config['url'],\n                                         entity_id, _kj)\n    else:\n        raise ValueError('Unknown signer type: {}'.format(config['type']))\n\n    return signer"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sign(self, req, receiver='', iss='', lifetime=0, sign_alg='', aud=None):\n        if not sign_alg:\n            for key_type, s_alg in [('RSA', 'RS256'), ('EC', 'ES256')]:\n                if self.keyjar.get_signing_key(key_type=key_type):\n                    sign_alg = s_alg\n                    break\n\n        if not sign_alg:\n            raise NoSigningKeys('Could not find any signing keys')\n\n        return self.pack(req=req, receiver=receiver, iss=iss, lifetime=lifetime,\n                         sign=True, encrypt=False, sign_alg=sign_alg)", "response": "Creates a signed JWT using the given request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse POST to send a first metadata statement signing request to a signing service.", "response": "def create(self, req, **kwargs):\n        \"\"\"\n        Uses POST to send a first metadata statement signing request to\n        a signing service.\n\n        :param req: The metadata statement that the entity wants signed\n        :return: returns a dictionary with 'sms' and 'loc' as keys.\n        \"\"\"\n\n        response = requests.post(self.url, json=req, **self.req_args())\n        return self.parse_response(response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_metadata_statement(self, location, req):\n        response = requests.put(location, json=req, **self.req_args())\n        return self.parse_response(response)", "response": "Uses PUT to update an earlier accepted and signed metadata statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_signature(self, location):\n        response = requests.get(location, **self.req_args())\n        return self.parse_response(response)", "response": "Uses GET to get a newly signed metadata statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nyields bundle contents from the given dict.", "response": "def _yield_bundle_contents(self, data):\n        \"\"\"Yield bundle contents from the given dict.\n\n        Each item yielded will be either a string representing a file path\n        or a bundle.\"\"\"\n        if isinstance(data, list):\n            contents = data\n        else:\n            contents = data.get('contents', [])\n            if isinstance(contents, six.string_types):\n                contents = contents,\n        for content in contents:\n            if isinstance(content, dict):\n                content = self._create_bundle(content)\n            yield content"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a bundle from the given dict.", "response": "def _create_bundle(self, data):\n        \"\"\"Return a bundle initialised by the given dict.\"\"\"\n        kwargs = {}\n        filters = None\n        if isinstance(data, dict):\n            kwargs.update(\n                filters=data.get('filters', None),\n                output=data.get('output', None),\n                debug=data.get('debug', None),\n                extra=data.get('extra', {}),\n                config=data.get('config', {}),\n                depends=data.get('depends', None))\n        bundle = Bundle(*list(self._yield_bundle_contents(data)), **kwargs)\n        return self._auto_filter_bundle(bundle)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef urls_for(self, asset_type, *args, **kwargs):\n        return self.urls_for_depends(asset_type, *args, **kwargs) + \\\n               self.urls_for_self(asset_type, *args, **kwargs)", "response": "Returns the urls needed to include all assets of asset_type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef html_tags_for(self, asset_type, *args, **kwargs):\n        html = []\n        for ref in self.depends:\n            html.append(self._ref(ref).html_tags_for(asset_type, *args, **kwargs))\n        if asset_type in self.typed_bundles:\n            html.append(render_asset_html_tags(asset_type, self.urls_for_self(asset_type, *args, **kwargs)))\n        return \"\\n\".join(html)", "response": "Return html tags for the given asset type"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef html_tags(self, *args, **kwargs):\n        html = []\n        for asset_type in list_asset_types():\n            html.append(self.html_tags_for(asset_type.name, *args, **kwargs))\n        return \"\\n\".join(html)", "response": "Return all html tags for all asset types"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_version(filename):\n\n    with io.open(filename, encoding=\"utf-8\") as version_file:\n        version_match = re.search(r'^__version__ = [\\'\"]([^\\'\"]*)[\\'\"]',\n                                  version_file.read(), re.M)\n    if version_match:\n        return version_match.group(1)\n    return \"0.0-version-unknown\"", "response": "Uses re to pull out the assigned value to __version__ in filename."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a URL check to see if there is an assocaited protocol and return the protocolised URL", "response": "def protocolise(url):\n    \"\"\"\n    Given a URL, check to see if there is an assocaited protocol.\n\n    If not, set the protocol to HTTP and return the protocolised URL\n    \"\"\"\n    # Use the regex to match http//localhost/something\n    protore = re.compile(r'https?:{0,1}/{1,2}')\n    parsed = urlparse.urlparse(url)\n    if not parsed.scheme and not protore.search(url):\n        url = 'http://{0}'.format(url)\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds the href destinations of all links at URL url", "response": "def find_links(url):\n    \"\"\"\n    Find the href destinations of all links at  URL\n\n    Arguments:\n    - `url`:\n\n    Return: list[str]\n    Exceptions: None\n    \"\"\"\n    url = protocolise(url)\n    content = requests.get(url).content\n    flike = StringIO(content)\n    root = html.parse(flike).getroot()\n    atags = root.cssselect('a')\n    hrefs = [a.attrib['href'] for a in atags]\n    # !!! This does the wrong thing for bbc.co.uk/index.html\n    hrefs = [h if h.startswith('http') else '/'.join([url, h]) for h in hrefs ]\n    return hrefs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _connected(client):\n    log.msg(\"Connected to AMP server, starting to listen locally...\")\n    localFactory = multiplexing.ProxyingFactory(client, \"hello\")\n    return listeningEndpoint.listen(localFactory)", "response": "Called when the client is connected to the AMP server."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the [ section option values as a list.", "response": "def getlist(self, section, option, *, raw=False, vars=None,\n                fallback=None):\n        \"\"\"Return the [section] option values as a list.\n        The list items must be delimited with commas and/or newlines.\n        \"\"\"\n        val = self.get(section, option, raw=raw, vars=vars, fallback=fallback)\n        values = []\n        if val:\n            for line in val.split(\"\\n\"):\n                values += [s.strip() for s in line.split(\",\")]\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_modules(self):\n        if not self.project_abspath:\n            raise TypeError(\"project_abspath can not be empty.\")\n        packages_abspath = self.get_package_abspath()\n        for package_abspath in packages_abspath:\n            self.get_module_name(package_abspath)\n\n        return self._modules", "response": "Get all modules in the project_abspath and packages_scan."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef import_modules(self):\n        modules = self.get_modules()\n        log.info(\"import service modules: \" + str(modules))\n        try:\n            for module in modules:\n                __import__(module)\n        except ImportError as error:\n            raise ImportModulesError(error.msg)", "response": "Import customer s service modules."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_dates(param):\n    pos = param.find('-')\n    lower, upper = (None, None)\n    if pos == -1:\n        # no seperator given\n        lower, upper = (param, param)\n    else:\n        lower, upper = param.split('-')\n    ret = (expand_date_param(lower, 'lower'), expand_date_param(upper, 'upper'))\n    return ret", "response": "This function takes a date string in various formats and converts it to a normalized and validated date range."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexpands a possibly incomplete date string to either the lowest possible contained date or the highest possible contained date and returns a datetime. datetime object for that string.", "response": "def expand_date_param(param, lower_upper):\n    \"\"\"\n    Expands a (possibly) incomplete date string to either the lowest\n    or highest possible contained date and returns\n    datetime.datetime for that string.\n\n    0753 (lower) => 0753-01-01\n    2012 (upper) => 2012-12-31\n    2012 (lower) => 2012-01-01\n    201208 (upper) => 2012-08-31\n    etc.\n    \"\"\"\n    year = datetime.MINYEAR\n    month = 1\n    day = 1\n    hour = 0\n    minute = 0\n    second = 0\n    if lower_upper == 'upper':\n        year = datetime.MAXYEAR\n        month = 12\n        day = 31\n        hour = 23\n        minute = 59\n        second = 59\n    if len(param) == 0:\n        # leave defaults\n        pass\n    elif len(param) == 4:\n        year = int(param)\n        if lower_upper == 'lower':\n            month = 1\n            day = 1\n            hour = 0\n            minute = 0\n            second = 0\n        else:\n            month = 12\n            day = 31\n            hour = 23\n            minute = 59\n            second = 59\n    elif len(param) == 6:\n        year = int(param[0:4])\n        month = int(param[4:6])\n        if lower_upper == 'lower':\n            day = 1\n        else:\n            (firstday, dayspermonth) = monthrange(year, month)\n            day = dayspermonth\n    elif len(param) == 8:\n        year = int(param[0:4])\n        month = int(param[4:6])\n        day = int(param[6:8])\n    elif len(param) == 10:\n        year = int(param[0:4])\n        month = int(param[4:6])\n        day = int(param[6:8])\n        hour = int(param[8:10])\n    elif len(param) == 12:\n        year = int(param[0:4])\n        month = int(param[4:6])\n        day = int(param[6:8])\n        hour = int(param[8:10])\n        minute = int(param[10:12])\n    elif len(param) == 14:\n        year = int(param[0:4])\n        month = int(param[4:6])\n        day = int(param[6:8])\n        hour = int(param[8:10])\n        minute = int(param[10:12])\n        second = int(param[12:14])\n    else:\n        # wrong input length\n        raise ValueError('Bad date string provided. Use YYYY, YYYYMM or YYYYMMDD.')\n    # force numbers into valid ranges\n    #print (param, lower_upper), [year, month, day, hour, minute, second]\n    year = min(datetime.MAXYEAR, max(datetime.MINYEAR, year))\n    return datetime.datetime(year=year, month=month, day=day,\n        hour=hour, minute=minute, second=second)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef select_fields(doc, field_list):\n        '''\n        Take 'doc' and create a new doc using only keys from the 'fields' list.\n        Supports referencing fields using dotted notation \"a.b.c\" so we can parse\n        nested fields the way MongoDB does. The nested field class is a hack. It should\n        be a sub-class of dict.\n        '''\n\n        if field_list is None or len(field_list) == 0:\n            return doc\n\n        newDoc = Nested_Dict({})\n        oldDoc = Nested_Dict(doc)\n\n        for i in field_list:\n            if oldDoc.has_key(i):\n                # print( \"doc: %s\" % doc )\n                # print( \"i: %s\" %i )\n                newDoc.set_value(i, oldDoc.get_value(i))\n        return newDoc.dict_value()", "response": "Take a doc and create a new doc using only keys from the fields list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef date_map(doc, datemap_list, time_format=None):\n        '''\n        For all the datetime fields in \"datemap\" find that key in doc and map the datetime object to\n        a strftime string. This pprint and others will print out readable datetimes.\n        '''\n        if datemap_list:\n            for i in datemap_list:\n                if isinstance(i, datetime):\n                    doc=CursorFormatter.date_map_field(doc, i, time_format=time_format)\n        return doc", "response": "Given a doc and a list of datetime objects find the key in the document and map it to a strftime string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef printCursor(self, fieldnames=None, datemap=None, time_format=None):\n        '''\n        Output a cursor to a filename or stdout if filename is \"-\".\n        fmt defines whether we output CSV or JSON.\n        '''\n\n        if self._format == 'csv':\n            count = self.printCSVCursor(fieldnames, datemap, time_format)\n        else:\n            count = self.printJSONCursor( fieldnames, datemap, time_format)\n\n        return count", "response": "Output a cursor to a filename or stdout."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef output(self, fieldNames=None, datemap=None, time_format=None):\n        '''\n        Output all fields using the fieldNames list. for fields in the list datemap indicates the field must\n        be date\n        '''\n\n        count = self.printCursor(self._cursor, fieldNames, datemap, time_format)", "response": "Output all the fields using the fieldNames list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_tasks(do_tasks, dep_graph):\n\n    #XXX: Is it important that if a task has \"foo\" before \"bar\" as a dep,\n    #     that foo executes before bar? Why? ATM this may not happen.\n\n    #Each task that the user has specified gets its own execution graph\n    task_graphs = []\n\n    for task in do_tasks:\n        exgraph = DiGraph()\n        exgraph.add_node(task)\n        _get_deps(task, exgraph, dep_graph)\n\n        task_graphs.append(exgraph)\n\n    return flatten(reversed(topological_sort(g)) for g in task_graphs)", "response": "Given a list of tasks to perform and a dependency graph return the tasks that must be performed in the correct order."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrotate a file. moves original file.ext to targetdir/file-YYYY-MM-DD-THH:MM:SS.ext deletes all older files matching the same pattern in targetdir that exceed the amount of max_versions. if versions = None, no old versions are deleted. if archive_dir is set, old versions are not deleted but moved to archive_dir", "response": "def rotate(filename, targetdir, max_versions=None, archive_dir=None):\n    \"\"\" Rotates a file.\n        moves original file.ext to targetdir/file-YYYY-MM-DD-THH:MM:SS.ext\n\n        deletes all older files matching the same pattern in targetdir that \n        exceed the amount of max_versions.\n        if versions = None, no old versions are deleted.\n\n        if archive_dir is set, old versions are not deleted but moved to\n        archive_dir\n\n    \"\"\"\n    dtimeformat = '%Y-%m-%d-%H:%M:%S'\n\n    now = datetime.now().strftime(dtimeformat)\n    old_path, old_filename = os.path.split(filename)\n    fileroot, ext = old_filename.split(os.extsep, 1)\n\n    new_filename = fileroot + '-' + now + '.' + ext\n    new_filepath = os.path.join(targetdir, new_filename)\n\n    if max_versions:\n        # find all files with same pattern that already exist in targetdir\n        old_files = {}\n        for file in os.listdir(targetdir):\n            pattern = re.compile(\n                '^%s-(?P<date>\\d{4}-\\d{2}-\\d{2}-\\d{2}:\\d{2}:\\d{2}).%s'\n                % (fileroot, ext))\n            if pattern.match(file):\n                d = re.search(pattern, file).group('date')\n                old_files[d] = file\n\n        delkeys = old_files.keys()\n        # sort delkeys by date, newest first\n        delkeys.sort(key=lambda x: datetime.strptime(x, dtimeformat),\n            reverse=True)\n        \n        # delete all keys, that should not be deleted\n        del delkeys[0 : max_versions -1]\n        \n        # delete all not needed files\n        for k in delkeys:\n            fname = old_files[k]\n            fpath = os.path.join(targetdir, fname)\n\n            if archive_dir:\n                shutil.move(fpath, os.path.join(archive_dir, fname))\n            else:\n                os.remove(fpath)\n\n\n        shutil.move(filename, new_filepath)\n\n        pass\n    else:\n        shutil.move(filename, new_filepath)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef api_request(methods=None, require_token=True):\n    def decorator(view_func):\n        @wraps(view_func, assigned=available_attrs(view_func))\n        def _wrapped_view(request, *args, **kwargs):\n            ApiToken = apps.get_model('api', 'ApiToken')\n            m = methods if methods is not None else DEFAULT_API_METHODS\n            if request.method not in m:\n                response = ApiResponse(False, 'Method not supported', status=405)\n                response['Allow'] = ', '.join(methods)\n                return response\n\n            try:\n                data = json.loads(request.body.decode('utf-8')) if request.body else {}\n                if require_token:\n                    token_string = request.GET['token'] if request.method == 'GET' else data['token']\n                    try:\n                        token = ApiToken.objects.get(token=token_string)\n                        token.save()  # Update the last_seen field\n                        data['token'] = token\n\n                    except ApiToken.DoesNotExist:\n                        logger.exception('Valid token required, \"{0}\" supplied'.format(token_string))\n                        return ApiResponse(False, 'Valid token required', status=403)\n\n                return ApiResponse(data=view_func(request, data=data, *args, **kwargs))\n\n            except Exception as e:\n                if e.__class__.__name__ == 'DoesNotExist':\n                    logger.exception('Not found while handling ajax request')\n                    return ApiResponse(False, 'Exception: {0}'.format(e), status=404)\n                else:\n                    logger.exception('Error handling ajax request')\n                    return ApiResponse(False, 'Exception: {0}'.format(e), status=500)\n\n        return _wrapped_view\n    return decorator", "response": "Decorator that handles JSON based API requests and responses consistently."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd or create the default departments for the given project", "response": "def add_default_deps(project):\n    \"\"\"Add or create the default departments for the given project\n\n    :param project: the project that needs default departments\n    :type project: :class:`muke.models.Project`\n    :returns: None\n    :rtype: None\n    :raises: None\n    \"\"\"\n    # create deps for project\n    for name, short, order, af in DEFAULT_DEPARTMENTS:\n        dep, created = Department.objects.get_or_create(name=name, short=short, ordervalue=order, assetflag=af)\n        dep.projects.add(project)\n        dep.full_clean()\n        dep.save()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd or create the default assettypes for the given project", "response": "def add_default_atypes(project):\n    \"\"\"Add or create the default assettypes for the given project\n\n    :param project: the project that needs default assettypes\n    :type project: :class:`muke.models.Project`\n    :returns: None\n    :rtype: None\n    :raises: None\n    \"\"\"\n    # create assettypes for project\n    for name, desc in DEFAULT_ASSETTYPES:\n        at, created = Atype.objects.get_or_create(name=name, defaults={'description': desc})\n        at.projects.add(project)\n        at.full_clean()\n        at.save()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd or create the default sequences for the given project", "response": "def add_default_sequences(project):\n    \"\"\"Add or create the default sequences for the given project\n\n    :param project: the project that needs default sequences\n    :type project: :class:`muke.models.Project`\n    :returns: None\n    :rtype: None\n    :raises: None\n    \"\"\"\n    # create sequences for project\n    seqs = [(GLOBAL_NAME, 'global sequence for project %s' % project.name),\n            (RNDSEQ_NAME, 'research and development sequence for project %s' % project.name)]\n    for name, desc in seqs:\n        seq, created = Sequence.objects.get_or_create(name=name, project=project, defaults={'description': desc})"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_userrnd_shot(project):\n    rndseq = project.sequence_set.get(name=RNDSEQ_NAME)\n    users = [u for u in project.users.all()]\n    for user in users:\n        shot, created = Shot.objects.get_or_create(name=user.username,\n                                                   project=project,\n                                                   sequence=rndseq,\n                                                   defaults={'description': 'rnd shot for user %s' % user.username})\n        for t in shot.tasks.all():\n            t.users.add(user)\n            t.full_clean()\n            t.save()", "response": "Adds a rnd shot for every user in the project"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nposting save receiver for when a Project is saved. Creates a rnd shot for every user. On creations does: 1. create all default departments 2. create all default assettypes 3. create all default sequences :param sender: the project class :type sender: :class:`muke.models.Project` :returns: None :raises: None", "response": "def prj_post_save_handler(sender, **kwargs):\n    \"\"\" Post save receiver for when a Project is saved.\n\n    Creates a rnd shot for every user.\n\n    On creations does:\n\n       1. create all default departments\n       2. create all default assettypes\n       3. create all default sequences\n\n    :param sender: the project class\n    :type sender: :class:`muke.models.Project`\n    :returns:  None\n    :raises: None\n\n    \"\"\"\n    prj = kwargs['instance']\n    if not kwargs['created']:\n        add_userrnd_shot(prj)\n        return\n\n    add_default_deps(prj)\n    add_default_atypes(prj)\n    add_default_sequences(prj)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npost save receiver for when a sequence is saved. creates a global shot. :param sender: the sequence class :type sender: :class:`muke.models.Sequence` :returns: None :raises: None", "response": "def seq_post_save_handler(sender, **kwargs):\n    \"\"\" Post save receiver for when a sequence is saved.\n\n    creates a global shot.\n\n    :param sender: the sequence class\n    :type sender: :class:`muke.models.Sequence`\n    :returns:  None\n    :raises: None\n\n    \"\"\"\n    if not kwargs['created']:\n        return\n    seq = kwargs['instance']\n    if seq.name == RNDSEQ_NAME:\n        return\n\n    prj = seq.project\n    name = GLOBAL_NAME\n    desc = \"Global shot for sequence %s\" % seq.name\n    Shot.objects.create(name=name, project=prj, sequence=seq, description=desc)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_all_tasks(element):\n    prj = element.project\n    if isinstance(element, Asset):\n        flag=True\n    else:\n        flag=False\n    deps = prj.department_set.filter(assetflag=flag)\n    for d in deps:\n        t = Task(project=prj, department=d, element=element)\n        t.full_clean()\n        t.save()", "response": "Create all tasks for the element"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef path(self):\n        p = os.path.normpath(self._path)\n        if p.endswith(':'):\n            p = p + os.path.sep\n        return p", "response": "Return the path of the cache file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef path(self, value):\n        prepval = value.replace('\\\\', '/')\n        self._path = posixpath.normpath(prepval)\n        if self._path.endswith(':'):\n            self._path = self._path + posixpath.sep", "response": "Set the path of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clean(self, ):\n        if self.startframe > self.endframe:\n            raise ValidationError(\"Shot starts before it ends: Framerange(%s - %s)\" % (self.startframe, self.endframe))", "response": "Reimplemented from models. Model. Check if startframe is before endframe."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the path of the object.", "response": "def path(self, value):\n        \"\"\"Set path\n\n        :param value: The value for path\n        :type value: str\n        :raises: None\n        \"\"\"\n        prepval = value.replace('\\\\', '/')\n        self._path = posixpath.normpath(prepval)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a type name so that it can be used to send and receive packages.", "response": "def register_type(self, typename):\n        \"\"\"\n        Registers a type name so that it may be used to send and receive packages.\n        \n        :param typename: Name of the packet type. A method with the same name and a\n            \"on_\" prefix should be added to handle incomming packets.\n            \n        :raises ValueError: If there is a hash code collision.\n        \"\"\" \n        \n        # this is to check for collisions only\n        self._dummy_protocol.register_type(typename)\n        \n        self._typenames.add(typename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening the port and return a Deferred that fires when we are ready to receive a packet.", "response": "def open(self, packet_received):\n        \"\"\"\n        Opens the port.\n        \n        :param packet_received: Callback which is invoked when we received a packet.\n          Is passed the peer, typename, and data.\n\n        :returns: Deferred that callbacks when we are ready to receive.\n        \"\"\"\n        def port_open(listeningport):\n            self._listeningport = listeningport\n            self.ownid = self.ownid_factory(listeningport)\n            logger.debug(\"Port opened. Own-ID:%s\" % self.ownid)\n            return None\n        \n        logger.debug(\"Opening connection pool\")\n        \n        self.packet_received = packet_received\n        d = self.stream_server_endpoint.listen(PoolFactory(self, self._typenames))\n        d.addCallback(port_open)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pre_connect(self, peer):\n        if peer in self._connections:\n            return defer.succeed(peer)\n        else:\n            d = self._connect(peer, exact_peer=False)\n            def connected(p):\n                return p.peer\n            d.addCallback(connected)\n            return d", "response": "Establishes a connection to the given peer and returns the ID of the peer that we have opened to."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send(self, peer, typename, data):\n\n\n        def attempt_to_send(_):\n            if peer not in self._connections:\n                d = self._connect(peer)\n                d.addCallback(attempt_to_send)\n                return d\n            else:\n                conn = self._connections[peer][0]\n                conn.send_packet(typename, data)            \n                return defer.succeed(None)\n        \n        d = attempt_to_send(None)\n        \n        self._ongoing_sends.add(d)\n        \n        def send_completed(result):\n            if d in self._ongoing_sends:\n                self._ongoing_sends.remove(d)\n            return result\n        \n        d.addBoth(send_completed)\n        return d", "response": "Sends a packet to a peer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nclosing all open connections and close all open connections.", "response": "def close(self):\n        \"\"\"\n        Stop listing for new connections and close all open connections.\n        \n        :returns: Deferred that calls back once everything is closed.\n        \"\"\"\n        \n        def cancel_sends(_):\n            logger.debug(\"Closed port. Cancelling all on-going send operations...\")\n            while self._ongoing_sends:\n                d = self._ongoing_sends.pop()\n                d.cancel()\n\n        def close_connections(_):\n            all_connections = [c for conns in self._connections.itervalues() for c in conns]\n            \n            logger.debug(\"Closing all connections (there are %s)...\" % len(all_connections))\n            for c in all_connections:\n                c.transport.loseConnection()\n            ds = [c.wait_for_close() for c in all_connections]\n            d = defer.DeferredList(ds, fireOnOneErrback=True)\n            \n            def allclosed(_):\n                logger.debug(\"All connections closed.\")\n            d.addCallback(allclosed)\n            return d\n        \n        logger.debug(\"Closing connection pool...\")\n        \n        d = defer.maybeDeferred(self._listeningport.stopListening)\n        d.addCallback(cancel_sends)\n        d.addCallback(close_connections)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads customer s config value by section and key.", "response": "def get_config_value(self, section, key, return_type: type):\n        \"\"\"Read customer's config value by section and key.\n\n        :param section: config file's section. i.e [default]\n        :param key: config file's key under section. i.e packages_scan\n        :param return_type: return value type, str | int | bool.\n        \"\"\"\n        try:\n            value = self.method_mapping[return_type](section, key)\n        except NoSectionError as e:\n            raise ConfigError(e.message)\n        except NoOptionError as e:\n            raise ConfigError(e.message)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nova(*arg):\n    check_event_type(Openstack.Nova, *arg)\n    event_type = arg[0]\n\n    def decorator(func):\n        if event_type.find(\"*\") != -1:\n            event_type_pattern = pre_compile(event_type)\n            nova_customer_process_wildcard[event_type_pattern] = func\n        else:\n            nova_customer_process[event_type] = func\n        log.info(\"add function {0} to process event_type:{1}\".format(func.__name__, event_type))\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator", "response": "Nova annotation for adding function to process nova notification."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef neutron(*arg):\n    check_event_type(Openstack.Neutron, *arg)\n    event_type = arg[0]\n\n    def decorator(func):\n        if event_type.find(\"*\") != -1:\n            event_type_pattern = pre_compile(event_type)\n            neutron_customer_process_wildcard[event_type_pattern] = func\n        else:\n            neutron_customer_process[event_type] = func\n        log.info(\"add function {0} to process event_type:{1}\".format(func.__name__, event_type))\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator", "response": "Neutron annotation for adding function to process neutron notification."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nglancing annotation for adding function to process glance notification. if event_type include wildcard, will put {pattern: function} into process_wildcard dict else will put {event_type: function} into process dict :param arg: event_type of notification", "response": "def glance(*arg):\n    \"\"\"\n    Glance annotation for adding function to process glance notification.\n\n    if event_type include wildcard, will put {pattern: function} into process_wildcard dict\n    else will put {event_type: function} into process dict\n\n    :param arg: event_type of notification\n    \"\"\"\n    check_event_type(Openstack.Glance, *arg)\n    event_type = arg[0]\n\n    def decorator(func):\n        if event_type.find(\"*\") != -1:\n            event_type_pattern = pre_compile(event_type)\n            glance_customer_process_wildcard[event_type_pattern] = func\n        else:\n            glance_customer_process[event_type] = func\n        log.info(\"add function {0} to process event_type:{1}\".format(func.__name__, event_type))\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef swift(*arg):\n    check_event_type(Openstack.Swift, *arg)\n    event_type = arg[0]\n\n    def decorator(func):\n        if event_type.find(\"*\") != -1:\n            event_type_pattern = pre_compile(event_type)\n            swift_customer_process_wildcard[event_type_pattern] = func\n        else:\n            swift_customer_process[event_type] = func\n        log.info(\"add function {0} to process event_type:{1}\".format(func.__name__, event_type))\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator", "response": "Swift annotation for adding function to process swift notification."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nheating annotation for adding function to process heat notification. if event_type include wildcard, will put {pattern: function} into process_wildcard dict else will put {event_type: function} into process dict :param arg: event_type of notification", "response": "def heat(*arg):\n    \"\"\"\n    Heat annotation for adding function to process heat notification.\n\n    if event_type include wildcard, will put {pattern: function} into process_wildcard dict\n    else will put {event_type: function} into process dict\n\n    :param arg: event_type of notification\n    \"\"\"\n    check_event_type(Openstack.Heat, *arg)\n    event_type = arg[0]\n\n    def decorator(func):\n        if event_type.find(\"*\") != -1:\n            event_type_pattern = pre_compile(event_type)\n            heat_customer_process_wildcard[event_type_pattern] = func\n        else:\n            heat_customer_process[event_type] = func\n        log.info(\"add function {0} to process event_type:{1}\".format(func.__name__, event_type))\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a factory. After calling this method, remote clients will be able to connect to it. This will call ``factory.doStart``.", "response": "def addFactory(self, identifier, factory):\n        \"\"\"Adds a factory.\n\n        After calling this method, remote clients will be able to\n        connect to it.\n\n        This will call ``factory.doStart``.\n\n        \"\"\"\n        factory.doStart()\n        self._factories[identifier] = factory"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves a factory from the pool.", "response": "def removeFactory(self, identifier):\n        \"\"\"Removes a factory.\n\n        After calling this method, remote clients will no longer be\n        able to connect to it.\n\n        This will call the factory's ``doStop`` method.\n\n        \"\"\"\n        factory = self._factories.pop(identifier)\n        factory.doStop()\n        return factory"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nattempts to connect using a given factory.", "response": "def connect(self, factory):\n        \"\"\"Attempts to connect using a given factory.\n\n        This will find the requested factory and use it to build a\n        protocol as if the AMP protocol's peer was making the\n        connection. It will create a transport for the protocol and\n        connect it immediately. It will then store the protocol under\n        a unique identifier, and return that identifier.\n\n        \"\"\"\n        try:\n            factory = self._factories[factory]\n        except KeyError:\n            raise NoSuchFactory()\n\n        remote = self.getProtocol()\n        addr = remote.transport.getPeer()\n        proto = factory.buildProtocol(addr)\n        if proto is None:\n            raise ConnectionRefused()\n\n        identifier = uuid4().hex\n        transport = MultiplexedTransport(identifier, remote)\n        proto.makeConnection(transport)\n\n        self._protocols[identifier] = proto\n        return {\"connection\": identifier}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef receiveData(self, connection, data):\n        try:\n            protocol = self._protocols[connection]\n        except KeyError:\n            raise NoSuchConnection()\n\n        protocol.dataReceived(data)\n        return {}", "response": "Receives some data for the given protocol."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisconnecting the given protocol from the protocol list.", "response": "def disconnect(self, connection):\n        \"\"\"\n        Disconnects the given protocol.\n        \"\"\"\n        proto = self._protocols.pop(connection)\n        proto.transport = None\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a multiplexed stream connection.", "response": "def connectionMade(self):\n        \"\"\"Create a multiplexed stream connection.\n\n        Connect to the AMP server's multiplexed factory using the\n        identifier (defined by this class' factory). When done, stores\n        the connection reference and causes buffered data to be sent.\n\n        \"\"\"\n        log.msg(\"Creating multiplexed AMP connection...\")\n        remoteFactoryIdentifier = self.factory.remoteFactoryIdentifier\n        d = self._callRemote(Connect, factory=remoteFactoryIdentifier)\n        d.addCallback(self._multiplexedConnectionMade)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstore a reference to the connection registers this protocol as one related to a multiplexed AMP connection registers this protocol as one related to a multiplexed AMP connection registers the protocol on registers the buffer and sends buffered data to the factory.", "response": "def _multiplexedConnectionMade(self, response):\n        \"\"\"Stores a reference to the connection, registers this protocol on\n        the factory as one related to a multiplexed AMP connection,\n        and sends currently buffered data. Gets rid of the buffer\n        afterwards.\n\n        \"\"\"\n        self.connection = conn = response[\"connection\"]\n        self.factory.protocols[conn] = self\n\n        log.msg(\"Multiplexed AMP connection ({!r}) made!\".format(conn))\n\n        data, self._buffer = self._buffer.getvalue(), None\n        if data:\n            log.msg(\"Sending {} bytes of buffered data...\".format(len(data)))\n            self._sendData(data)\n        else:\n            log.msg(\"No buffered data to send!\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dataReceived(self, data):\n        log.msg(\"{} bytes of data received locally\".format(len(data)))\n        if self.connection is None:\n            # we haven't finished connecting yet\n            log.msg(\"Connection not made yet, buffering...\")\n            self._buffer.write(data)\n        else:\n            log.msg(\"Sending data...\")\n            self._sendData(data)", "response": "This method is called when some data is received from the local side."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling when the connection is lost.", "response": "def connectionLost(self, reason):\n        \"\"\"If we already have an AMP connection registered on the factory,\n        get rid of it.\n\n        \"\"\"\n        if self.connection is not None:\n            del self.factory.protocols[self.connection]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getLocalProtocol(self, connectionIdentifier):\n        for factory in self.localFactories:\n            try:\n                return factory.protocols[connectionIdentifier]\n            except KeyError:\n                continue\n\n        raise NoSuchConnection()", "response": "Attempts to get a local protocol by connection identifier."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall when data was received from the remote end.", "response": "def remoteDataReceived(self, connection, data):\n        \"\"\"Some data was received from the remote end. Find the matching\n        protocol and replay it.\n\n        \"\"\"\n        proto = self.getLocalProtocol(connection)\n        proto.transport.write(data)\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisconnects from the other side.", "response": "def disconnect(self, connection):\n        \"\"\"The other side has asked us to disconnect.\n\n        \"\"\"\n        proto = self.getLocalProtocol(connection)\n        proto.transport.loseConnection()\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nappend s to the queue.", "response": "def enqueue(self, s):\n        \"\"\"\n        Append `s` to the queue.\n        \n        Equivalent to::\n        \n            queue += s\n            \n        if `queue` where a regular string.\n        \"\"\"\n        self._parts.append(s)\n        self._len += len(s)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dequeue(self, n):\n        if self._len < n:\n            raise ValueError(\"Not enough bytes in the queue\")\n        self._len -= n\n        \n        def part_generator(n):\n            \"\"\"\n            Returns the requested bytes in parts\n            \"\"\"\n            remaining = n\n            while remaining:\n                part = self._parts.popleft()\n                if len(part) <= remaining:\n                    yield part\n                    remaining -= len(part)\n                else:\n                    yield part[:remaining]\n                    self._parts.appendleft(part[remaining:])\n                    remaining = 0\n                    \n        return \"\".join(part_generator(n))", "response": "Returns the first n characters from the queue."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef drop(self, n):\n        if self._len < n:\n            raise ValueError(\"Not enough bytes in the queue\")\n        self._len -= n\n        \n\n        remaining = n\n        while remaining:\n            part = self._parts.popleft()\n            if len(part) <= remaining:\n                remaining -= len(part)\n            else:\n                self._parts.appendleft(part[remaining:])\n                remaining = 0", "response": "Removes n bytes from the beginning of the queue."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef peek(self, n):\n        if self._len < n:\n            raise ValueError(\"Not enough bytes in the queue\")\n        \n        def part_generator(n):\n            \"\"\"\n            Returns the requested bytes in parts\n            \"\"\"\n            \n            remaining = n\n            \n            for part in self._parts:\n                if len(part) <= remaining:\n                    yield part\n                    remaining -= len(part)\n                else:\n                    yield part[:remaining]\n                    remaining = 0 \n                if remaining == 0:\n                    break\n                    \n        return \"\".join(part_generator(n))", "response": "Returns the first n characters from the queue without removing them."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef centered(mystring, linewidth=None, fill=\" \"):\n    '''Takes a string, centres it, and pads it on both sides'''\n    if linewidth is None:\n        linewidth = get_terminal_size().columns - 1\n    sides = (linewidth - length_no_ansi(mystring))//2\n    extra = (linewidth - length_no_ansi(mystring)) % 2\n    fill = fill[:1]\n    sidestring = fill*sides\n    extrastring = fill*extra\n    newstring = sidestring + mystring + sidestring + extrastring\n    return newstring", "response": "Takes a string centres it and pads it on both sides"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clock_on_right(mystring):\n    '''Takes a string, and prints it with the time right aligned'''\n    taken = length_no_ansi(mystring)\n    padding = (get_terminal_size().columns - 1) - taken - 5\n    clock = time.strftime(\"%I:%M\", time.localtime())\n    print(mystring + \" \"*padding + clock)", "response": "Takes a string and prints it with the time right aligned"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query_yes_no(question, default=\"yes\"):\n    '''Ask a yes/no question via raw_input() and return their answer.\n\n    \"question\" is a string that is presented to the user.\n    \"default\" is the presumed answer if the user just hits <Enter>.\n        It must be \"yes\" (the default), \"no\" or None (meaning\n        an answer is required of the user).\n\n    The return value is one of Answers.YES or Answers.NO.\n\n    Copied (and modified) from\n    http://stackoverflow.com/questions/3041986/python-command-line-yes-no-input\n    '''\n    valid = {\"yes\": Answers.YES, \"y\": Answers.YES,  \"ye\": Answers.YES,\n             \"no\": Answers.NO,   \"n\": Answers.NO}\n    if default is None:\n        prompt = \" [y/n] \"\n    elif default == \"yes\":\n        prompt = \" [Y/n] \"\n    elif default == \"no\":\n        prompt = \" [y/N] \"\n    else:\n        raise ValueError(\"invalid default answer: '%s'\" % default)\n\n    while True:\n        sys.stdout.write(question + prompt)\n        choice = input().lower()\n        if default is not None and choice == '':\n            return valid[default]\n        elif choice in valid:\n            return valid[choice]\n        else:\n            sys.stdout.write(\"Please respond with 'yes' or 'no' \"\n                             \"(or 'y' or 'n').\\n\")", "response": "Ask a yes or no question via raw_input and return their answer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query_yes_quit(question, default=\"quit\"):\n    '''Ask a yes/quit question via raw_input() and return their answer.\n\n    \"question\" is a string that is presented to the user.\n    \"default\" is the presumed answer if the user just hits <Enter>.\n        It must be \"yes\" (the default), \"quit\" or None (meaning\n        an answer is required of the user).\n\n    The \"answer\" return value is one of \"yes\" or \"quit\".\n\n    Modified from\n    http://stackoverflow.com/questions/3041986/python-command-line-yes-no-input\n    '''\n    valid = {\"yes\": Answers.YES,   \"y\": Answers.YES,  \"ye\": Answers.YES,\n             \"quit\": Answers.QUIT, \"q\": Answers.QUIT}\n    if default is None:\n        prompt = \" [y/q] \"\n    elif default == \"yes\":\n        prompt = \" [Y/q] \"\n    elif default == \"quit\":\n        prompt = \" [y/Q] \"\n    else:\n        raise ValueError(\"invalid default answer: '%s'\" % default)\n\n    while True:\n        sys.stdout.write(question + prompt)\n        choice = input().lower()\n        if default is not None and choice == '':\n            return valid[default]\n        elif choice in valid:\n            return valid[choice]\n        else:\n            sys.stdout.write(\"Please respond with 'yes' or 'quit' \"\n                             \"(or 'y' or 'q').\\n\")", "response": "Ask a yes or quit question via raw_input and return their answer."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef version_number_str(major, minor=0, patch=0, prerelease=None, build=None):\n    version = str(major) + '.' + str(minor) + '.' + str(patch)\n    if prerelease:\n        if prerelease.startswith('-'):\n            version = version + prerelease\n        else:\n            version = version + \"-\" + str(prerelease)\n    if build:\n        if build.startswith('+'):\n            version = version + build\n        else:\n            version = version + \"+\" + str(build)\n    return(version)", "response": "Takes the parts of a semantic version number and returns a nicely\n    formatted string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_terminal_size():\n    try:\n        # shutil.get_terminal_size was added to the standard\n        # library in Python 3.3\n        try:\n            from shutil import get_terminal_size as _get_terminal_size  # pylint: disable=no-name-in-module\n        except ImportError:\n            from backports.shutil_get_terminal_size import get_terminal_size as _get_terminal_size  # pylint: disable=import-error\n\n        sz = _get_terminal_size()\n    except ValueError:\n        \"\"\"\n        This can result from the 'underlying buffer being detached', which\n        occurs during running the unittest on Windows (but not on Linux?)\n        \"\"\"\n        terminal_size = namedtuple('Terminal_Size', 'columns lines')\n        sz = terminal_size(80, 24)\n\n    return sz", "response": "Returns the terminal dimensions of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef identify_unit_framework(target_unit):\n\n    if HAS_ASTROPY:\n\n        from astropy.units import UnitBase\n\n        if isinstance(target_unit, UnitBase):\n\n            return ASTROPY\n\n    if HAS_PINT:\n\n        from pint.unit import UnitsContainer\n\n        if hasattr(target_unit, 'dimensionality') and isinstance(target_unit.dimensionality, UnitsContainer):\n\n            return PINT\n\n    if HAS_QUANTITIES:\n\n        from quantities.unitquantity import IrreducibleUnit\n        from quantities import Quantity\n\n        if isinstance(target_unit, IrreducibleUnit) or isinstance(target_unit, Quantity):\n\n            return QUANTITIES\n\n    raise TraitError(\"Could not identify unit framework for target unit of type {0}\".format(type(target_unit).__name__))", "response": "Identify whether the user is requesting unit validation against a specific unit."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck that a value is in the correct units.", "response": "def assert_unit_convertability(name, value, target_unit, unit_framework):\n    \"\"\"\n    Check that a value has physical type consistent with user-specified units\n\n    Note that this does not convert the value, only check that the units have\n    the right physical dimensionality.\n\n    Parameters\n    ----------\n    name : str\n        The name of the value to check (used for error messages).\n    value : `numpy.ndarray` or instance of `numpy.ndarray` subclass\n        The value to check.\n    target_unit : unit\n        The unit that the value should be convertible to.\n    unit_framework : str\n        The unit framework to use\n    \"\"\"\n\n    if unit_framework == ASTROPY:\n\n        from astropy.units import Quantity\n\n        if not isinstance(value, Quantity):\n            raise TraitError(\"{0} should be given as an Astropy Quantity instance\".format(name))\n\n        if not target_unit.is_equivalent(value.unit):\n            raise TraitError(\"{0} should be in units convertible to {1}\".format(name, target_unit))\n\n    elif unit_framework == PINT:\n\n        from pint.unit import UnitsContainer\n\n        if not (hasattr(value, 'dimensionality') and isinstance(value.dimensionality, UnitsContainer)):\n            raise TraitError(\"{0} should be given as a Pint Quantity instance\".format(name))\n\n        if value.dimensionality != target_unit.dimensionality:\n            raise TraitError(\"{0} should be in units convertible to {1}\".format(name, target_unit))\n\n    elif unit_framework == QUANTITIES:\n\n        from quantities import Quantity\n\n        if not isinstance(value, Quantity):\n            raise TraitError(\"{0} should be given as a quantities Quantity instance\".format(name))\n\n        if value.dimensionality.simplified != target_unit.dimensionality.simplified:\n            raise TraitError(\"{0} should be in units convertible to {1}\".format(name, target_unit.dimensionality.string))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npadding the data to the specified block size.", "response": "def pad(data_to_pad, block_size, style='pkcs7'):\n    \"\"\"Apply standard padding.\n\n    :Parameters:\n      data_to_pad : byte string\n        The data that needs to be padded.\n      block_size : integer\n        The block boundary to use for padding. The output length is guaranteed\n        to be a multiple of ``block_size``.\n      style : string\n        Padding algorithm. It can be *'pkcs7'* (default), *'iso7816'* or *'x923'*.\n    :Return:\n      The original data with the appropriate padding added at the end.\n    \"\"\"\n\n    padding_len = block_size-len(data_to_pad)%block_size\n    if style == 'pkcs7':\n        padding = bchr(padding_len)*padding_len\n    elif style == 'x923':\n        padding = bchr(0)*(padding_len-1) + bchr(padding_len)\n    elif style == 'iso7816':\n        padding = bchr(128) + bchr(0)*(padding_len-1)\n    else:\n        raise ValueError(\"Unknown padding style\")\n    return data_to_pad + padding"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove standard padding from the data.", "response": "def unpad(padded_data, block_size, style='pkcs7'):\n    \"\"\"Remove standard padding.\n\n    :Parameters:\n      padded_data : byte string\n        A piece of data with padding that needs to be stripped.\n      block_size : integer\n        The block boundary to use for padding. The input length\n        must be a multiple of ``block_size``.\n      style : string\n        Padding algorithm. It can be *'pkcs7'* (default), *'iso7816'* or *'x923'*.\n    :Return:\n        Data without padding.\n    :Raises ValueError:\n        if the padding is incorrect.\n    \"\"\"\n\n    pdata_len = len(padded_data)\n    if pdata_len % block_size:\n        raise ValueError(\"Input data is not padded\")\n    if style in ('pkcs7', 'x923'):\n        padding_len = bord(padded_data[-1])\n        if padding_len<1 or padding_len>min(block_size, pdata_len):\n            raise ValueError(\"Padding is incorrect.\")\n        if style == 'pkcs7':\n            if padded_data[-padding_len:]!=bchr(padding_len)*padding_len:\n                raise ValueError(\"PKCS#7 padding is incorrect.\")\n        else:\n            if padded_data[-padding_len:-1]!=bchr(0)*(padding_len-1):\n                raise ValueError(\"ANSI X.923 padding is incorrect.\")\n    elif style == 'iso7816':\n        padding_len = pdata_len - padded_data.rfind(bchr(128))\n        if padding_len<1 or padding_len>min(block_size, pdata_len):\n            raise ValueError(\"Padding is incorrect.\")\n        if padding_len>1 and padded_data[1-padding_len:]!=bchr(0)*(padding_len-1):\n            raise ValueError(\"ISO 7816-4 padding is incorrect.\")\n    else:\n        raise ValueError(\"Unknown padding style\")\n    return padded_data[:-padding_len]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_federation_entity(config, eid='', httpcli=None, verify_ssl=True):\n    args = {}\n\n    if not eid:\n        try:\n            eid = config['entity_id']\n        except KeyError:\n            pass\n\n    if 'self_signer' in config:\n        self_signer = make_internal_signing_service(config['self_signer'],\n                                                    eid)\n        args['self_signer'] = self_signer\n\n    try:\n        bundle_cnf = config['fo_bundle']\n    except KeyError:\n        pass\n    else:\n        _args = dict([(k, v) for k, v in bundle_cnf.items() if k in KJ_SPECS])\n        if _args:\n            _kj = init_key_jar(**_args)\n        else:\n            _kj = None\n\n        if 'dir' in bundle_cnf:\n            jb = FSJWKSBundle(eid, _kj, bundle_cnf['dir'],\n                              key_conv={'to': quote_plus, 'from': unquote_plus})\n        else:\n            jb = JWKSBundle(eid, _kj)\n        args['fo_bundle'] = jb\n\n    for item in ['context', 'entity_id', 'fo_priority', 'mds_owner']:\n        try:\n            args[item] = config[item]\n        except KeyError:\n            pass\n\n    if 'entity_id' not in args:\n        args['entity_id'] = eid\n\n    # These are mutually exclusive\n    if 'sms_dir' in config:\n        args['sms_dir'] = config['sms_dir']\n        return FederationEntityOOB(httpcli, iss=eid, **args)\n    elif 'mds_service' in config:\n        args['verify_ssl'] = verify_ssl\n        args['mds_service'] = config['mds_service']\n        return FederationEntityAMS(httpcli, iss=eid, **args)\n    elif 'mdss_endpoint' in config:\n        args['verify_ssl'] = verify_ssl\n        # These are mandatory for this type of entity\n        for key in ['mdss_endpoint', 'mdss_owner', 'mdss_keys']:\n            args[key] = config[key]\n        return FederationEntitySwamid(httpcli, iss=eid, **args)", "response": "Constructs a FederationEntity instance based on given configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pick_signed_metadata_statements_regex(self, pattern, context):\n        comp_pat = re.compile(pattern)\n        sms_dict = self.signer.metadata_statements[context]\n        res = []\n        for iss, vals in sms_dict.items():\n            if comp_pat.search(iss):\n                res.extend((iss, vals))\n        return res", "response": "Pick signed metadata statements based on ISS pattern matching\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npicks signed metadata statements based on ISS pattern matching", "response": "def pick_signed_metadata_statements(self, fo, context):\n        \"\"\"\n        Pick signed metadata statements based on ISS pattern matching\n        \n        :param fo: Federation operators ID\n        :param context: In connect with which operation (one of the values in \n            :py:data:`fedoidc.CONTEXTS`). \n        :return: list of tuples (FO ID, signed metadata statement)\n        \"\"\"\n        sms_dict = self.signer.metadata_statements[context]\n        res = []\n        for iss, vals in sms_dict.items():\n            if iss == fo:\n                res.extend((iss, vals))\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nunpacking and evaluate a compound metadata statement.", "response": "def get_metadata_statement(self, input, cls=MetadataStatement,\n                               context=''):\n        \"\"\"\n        Unpack and evaluate a compound metadata statement. Goes through the\n        necessary three steps.\n        * unpack the metadata statement\n        * verify that the given statements are expected to be used in this context\n        * evaluate the metadata statements (= flatten)\n\n        :param input: The metadata statement as a JSON document or a\n            dictionary\n        :param cls: The class the response should be typed into\n        :param context: In which context the metadata statement should be used.\n        :return: A list of :py:class:`fedoidc.operator.LessOrEqual` instances\n        \"\"\"\n        logger.debug('Incoming metadata statement: {}'.format(input))\n\n        if isinstance(input, dict):\n            data = input\n        else:\n            if isinstance(input, Message):\n                data = input.to_dict()\n            else:\n                data = json.loads(input)\n\n        _pi = self.unpack_metadata_statement(ms_dict=data, cls=cls)\n        if not _pi.result:\n            return []\n\n        logger.debug('Managed to unpack the metadata statement')\n\n        if context:\n            _cms = self.correct_usage(_pi.result, context)\n        else:\n            _cms = _pi.result\n\n        logger.debug('After filtering for correct usage: {}'.format(_cms))\n\n        if _cms:\n            return self.evaluate_metadata_statement(_cms)\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsigning the extended request.", "response": "def self_sign(self, req, receiver='', aud=None):\n        \"\"\"\n        Sign the extended request.\n\n        :param req: Request, a :py:class:`fedoidcmsg.MetadataStatement' instance\n        :param receiver: The intended user of this metadata statement\n        :param aud: The audience, a list of receivers.\n        :return: An augmented set of request arguments\n        \"\"\"\n        if self.entity_id:\n            _iss = self.entity_id\n        else:\n            _iss = self.iss\n\n        creq = req.copy()\n        if not 'metadata_statement_uris' in creq and not \\\n                'metadata_statements' in creq:\n            _copy = creq.copy()\n            _jws = self.self_signer.sign(_copy, receiver=receiver, iss=_iss,\n                                         aud=aud)\n            sms_spec = {'metadata_statements': {self.iss: _jws}}\n        else:\n            for ref in ['metadata_statement_uris', 'metadata_statements']:\n                try:\n                    del creq[ref]\n                except KeyError:\n                    pass\n\n            sms_spec = {'metadata_statements': Message()}\n\n            for ref in ['metadata_statement_uris', 'metadata_statements']:\n                if ref not in req:\n                    continue\n\n                for foid, value in req[ref].items():\n                    _copy = creq.copy()\n                    _copy[ref] = Message()\n                    _copy[ref][foid] = value\n                    _jws = self.self_signer.sign(_copy, receiver=receiver,\n                                                 iss=_iss, aud=aud)\n                    sms_spec['metadata_statements'][foid] = _jws\n\n        creq.update(sms_spec)\n        return creq"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the metadata statement with the given receiver and context.", "response": "def update_metadata_statement(self, metadata_statement, receiver='',\n                                  federation=None, context=''):\n        \"\"\"\n        Update a metadata statement by:\n         * adding signed metadata statements or uris pointing to signed\n           metadata statements.\n         * adding the entities signing keys\n         * create metadata statements one per signed metadata statement or uri\n           sign these and add them to the metadata statement\n\n        :param metadata_statement: A :py:class:`fedoidcmsg.MetadataStatement`\n            instance\n        :param receiver: The intended receiver of the metadata statement\n        :param federation:\n        :param context:\n        :return: An augmented metadata statement\n        \"\"\"\n        self.add_sms_spec_to_request(metadata_statement, federation=federation,\n                                     context=context)\n        self.add_signing_keys(metadata_statement)\n        metadata_statement = self.self_sign(metadata_statement, receiver)\n        # These are unprotected here so can as well be removed\n        del metadata_statement['signing_keys']\n        return metadata_statement"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a SMS spec to a request.", "response": "def add_sms_spec_to_request(self, req, federation='', loes=None,\n                                context=''):\n        \"\"\"\n        Update a request with signed metadata statements.\n        \n        :param req: The request \n        :param federation: Federation Operator ID\n        :param loes: List of :py:class:`fedoidc.operator.LessOrEqual` instances\n        :param context:\n        :return: The updated request\n        \"\"\"\n        if federation:  # A specific federation or list of federations\n            if isinstance(federation, list):\n                req.update(self.gather_metadata_statements(federation,\n                                                           context=context))\n            else:\n                req.update(self.gather_metadata_statements([federation],\n                                                           context=context))\n        else:  # All federations I belong to\n            if loes:\n                _fos = list([r.fo for r in loes])\n                req.update(self.gather_metadata_statements(_fos,\n                                                           context=context))\n            else:\n                req.update(self.gather_metadata_statements(context=context))\n\n        return req"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngathering signed metadata statements and return them.", "response": "def gather_metadata_statements(self, fos=None, context=''):\n        \"\"\"\n        Only gathers metadata statements and returns them.\n\n        :param fos: Signed metadata statements from these Federation Operators\n            should be added.\n        :param context: context of the metadata exchange\n        :return: Dictionary with signed Metadata Statements as values\n        \"\"\"\n\n        if not context:\n            context = self.context\n\n        _res = {}\n        if self.metadata_statements:\n            try:\n                cms = self.metadata_statements[context]\n            except KeyError:\n                if self.metadata_statements == {\n                    'register': {},\n                    'discovery': {},\n                    'response': {}\n                }:\n                    # No superior so an FO then. Nothing to add ..\n                    pass\n                else:\n                    logger.error(\n                        'No metadata statements for this context: {}'.format(\n                            context))\n                    raise ValueError('Wrong context \"{}\"'.format(context))\n            else:\n                if cms != {}:\n                    if fos is None:\n                        fos = list(cms.keys())\n\n                    for f in fos:\n                        try:\n                            val = cms[f]\n                        except KeyError:\n                            continue\n\n                        if val.startswith('http'):\n                            value_type = 'metadata_statement_uris'\n                        else:\n                            value_type = 'metadata_statements'\n\n                        try:\n                            _res[value_type][f] = val\n                        except KeyError:\n                            _res[value_type] = Message()\n                            _res[value_type][f] = val\n\n        return _res"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds signed metadata statements to the request so far.", "response": "def add_sms_spec_to_request(self, req, federation='', loes=None,\n                                context='', url=''):\n        \"\"\"\n        Add signed metadata statements to the request\n\n        :param req: The request so far\n        :param federation: If only signed metadata statements from a specific\n            set of federations should be included this is the set.\n        :param loes: - not used -\n        :param context: What kind of request/response it is: 'registration',\n            'discovery' or 'response'. The later being registration response.\n        :param url: Just for testing !!\n        :return: A possibly augmented request.\n        \"\"\"\n        # fetch the signed metadata statement collection\n\n        if federation:\n            if not isinstance(federation, list):\n                federation = [federation]\n\n        if not url:\n            url = \"{}/getms/{}/{}\".format(self.mds_service, context,\n                                          quote_plus(self.entity_id))\n\n        http_resp = self.httpcli(method='GET', url=url, verify=self.verify_ssl)\n\n        if http_resp.status_code >= 400:\n            raise ConnectionError('HTTP Error: {}'.format(http_resp.text))\n\n        # verify signature on response\n        msg = JsonWebToken().from_jwt(http_resp.text,\n                                      keyjar=self.jwks_bundle[self.mds_owner])\n\n        if msg['iss'] != self.mds_owner:\n            raise KeyError('Wrong iss')\n\n        if federation:\n            _ms = dict(\n                [(fo, _ms) for fo, _ms in msg.items() if fo in federation])\n        else:\n            _ms = msg.extra()\n            try:\n                del _ms['kid']\n            except KeyError:\n                pass\n\n        _sms = {}\n        _smsu = {}\n        for fo, item in _ms.items():\n            if item.startswith('https://') or item.startswith('http://'):\n                _smsu[fo] = item\n            else:\n                _sms[fo] = item\n\n        if _sms:\n            req.update({'metadata_statements': _sms})\n        if _smsu:\n            req.update({'metadata_statement_uris': _smsu})\n\n        return req"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_sms_spec_to_request(self, req, federation='', loes=None,\n                                context='', url=''):\n        \"\"\"\n        Add signed metadata statements to the request\n\n        :param req: The request so far\n        :param federation: If only signed metadata statements from a specific\n            set of federations should be included this is the set.\n        :param loes: - not used -\n        :param context: What kind of request/response it is: 'registration',\n            'discovery' or 'response'. The later being registration response.\n        :param url: Just for testing !!\n        :return: A possibly augmented request.\n        \"\"\"\n        # fetch the signed metadata statement collection\n\n        if federation:\n            if not isinstance(federation, list):\n                federation = [federation]\n\n        if not url:\n            url = \"{}/getsmscol/{}/{}\".format(self.mdss_endpoint, context,\n                                              quote_plus(self.entity_id))\n\n        http_resp = self.httpcli(method='GET', url=url, verify=self.verify_ssl)\n\n        if http_resp.status_code >= 400:\n            raise ConnectionError('HTTP Error: {}'.format(http_resp.text))\n\n        msg = JsonWebToken().from_jwt(http_resp.text, keyjar=self.mdss_keys)\n\n        if msg['iss'] != self.mdss_owner:\n            raise KeyError('Wrong iss')\n\n        if federation:\n            _sms = dict(\n                [(fo, _ms) for fo, _ms in msg.items() if fo in federation])\n        else:\n            _sms = msg.extra()\n            try:\n                del _sms['kid']\n            except KeyError:\n                pass\n\n        req.update({'metadata_statement_uris': _sms})\n        return req", "response": "Add signed metadata statements to a request so far."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pretty_print(input_word, anagrams, by_length=False):\n\n    scores = {}\n    if by_length:\n        noun = \"tiles\"\n        for word, score in anagrams:\n            try:\n                scores[len(word)].append(\"{0} ({1:d})\".format(word, score))\n            except KeyError:\n                scores[len(word)] = [\"{0} ({1:d})\".format(word, score)]\n    else:\n        noun = \"points\"\n        for word, score in anagrams:\n            try:\n                scores[score].append(word)\n            except KeyError:\n                scores[score] = [word]\n\n    print(\"Anagrams for {0}{1}:\".format(input_word, \" (score)\" * by_length))\n\n    if not valid_scrabble_word(input_word):\n        print(\"{0} is not possible in Scrabble.\".format(input_word))\n\n    for key, value in sorted(scores.items(), reverse=True):\n        print(\"{0:d} {1}: {2}\".format(key, noun, \", \".join(value)))", "response": "Prints the results of anagrams in anagrams_in_word\n        to stdout."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_type(self, typename):\n        typekey = typehash(typename)\n        if typekey in self._type_register:\n            raise ValueError(\"Type name collision. Type %s has the same hash.\" % repr(self._type_register[typekey]))\n        self._type_register[typekey] = typename", "response": "Registers a type name so that it can be used to send and receive packages."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndo not overwrite this method. Instead implement `on_...` methods for the registered typenames to handle incomming packets.", "response": "def dataReceived(self, data):\n        \"\"\"\n        Do not overwrite this method. Instead implement `on_...` methods for the\n        registered typenames to handle incomming packets.\n        \"\"\"\n        \n        self._unprocessed_data.enqueue(data)\n        \n        \n        while True:\n            if len(self._unprocessed_data) < self._header.size:\n                return # not yet enough data\n            \n            hdr_data = self._unprocessed_data.peek(self._header.size)\n            packet_length, typekey = self._header.unpack(hdr_data)\n            total_length = self._header.size + packet_length\n            \n            if len(self._unprocessed_data) < total_length:\n                return # not yet enough data\n            \n            self._unprocessed_data.drop(self._header.size)\n            packet = self._unprocessed_data.dequeue(packet_length)\n            \n            self._start_receive = None\n            \n            typename = self._type_register.get(typekey, None)\n            if typename is None:\n                self.on_unregistered_type(typekey, packet)\n            else:\n                self.packet_received(typename, packet)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_packet(self, typename, packet):\n        typekey = typehash(typename)\n        if typename != self._type_register.get(typekey, None):\n            raise ValueError(\"Cannot send packet with unregistered type %s.\" % repr(typename))\n        \n        hdr = self._header.pack(len(packet), typekey)\n        self.transport.writeSequence([hdr, packet])", "response": "Send a packet.\n        \n        :param typename: A previously registered typename.\n        \n        :param packet: String with the content of the packet."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_unregistered_type(self, typekey, packet):\n        log.msg(\"Missing handler for typekey %s in %s. Closing connection.\" % (typekey, type(self).__name__))\n        self.transport.loseConnection()", "response": "Called when a packet with an unregistered typekey is received."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a TCP based RPC system.", "response": "def create_tcp_rpc_system(hostname=None, port_range=(0,), ping_interval=1, ping_timeout=0.5):\n    \"\"\"\n    Creates a TCP based :class:`RPCSystem`.\n    \n    :param port_range: List of ports to try. If `[0]`, an arbitrary free\n        port will be used.\n    \"\"\"\n    \n    def ownid_factory(listeningport):\n        port = listeningport.getHost().port\n        return \"%s:%s\" %(hostname, port)\n\n    def make_client_endpoint(peer):\n        host, port = peer.split(\":\")\n        if host == socket.getfqdn():\n            host = \"localhost\"\n        return endpoints.TCP4ClientEndpoint(reactor, host, int(port), timeout=5)\n    \n    if hostname is None:\n        hostname = socket.getfqdn()\n\n    server_endpointA = TCP4ServerRangeEndpoint(reactor, port_range)\n    pool = connectionpool.ConnectionPool(server_endpointA, make_client_endpoint, ownid_factory)\n    return RPCSystem(pool, ping_interval=ping_interval, ping_timeout=ping_timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen the port and returns a Deferred that will be called when we are ready to make and receive calls.", "response": "def open(self):\n        \"\"\"\n        Opens the port.\n        \n        :returns: Deferred that callbacks when we are ready to make and receive calls.\n        \"\"\"\n        logging.debug(\"Opening rpc system\")\n        d = self._connectionpool.open(self._packet_received)\n        \n        def opened(_):\n            logging.debug(\"RPC system is open\")\n            self._opened = True\n            logging.debug(\"Starting ping loop\")\n            self._ping_loop.start(self._ping_interval, now=False)\n        \n        d.addCallback(opened)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstopping listing for new connections and close all open connections.", "response": "def close(self):\n        \"\"\"\n        Stop listing for new connections and close all open connections.\n        \n        :returns: Deferred that calls back once everything is closed.\n        \"\"\"\n        assert self._opened, \"RPC System is not opened\"\n        logger.debug(\"Closing rpc system. Stopping ping loop\")\n        self._ping_loop.stop()\n        if self._ping_current_iteration:\n            self._ping_current_iteration.cancel()\n        return self._connectionpool.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_function_url(self, function):\n        assert self._opened, \"RPC System is not opened\"\n        logging.debug(\"get_function_url(%s)\" % repr(function))\n        if function in ~self._functions:\n            functionid = self._functions[:function]\n        else:\n            functionid = uuid.uuid1()\n            self._functions[functionid] = function\n        return \"anycall://%s/functions/%s\" % (self._connectionpool.ownid, functionid.hex)", "response": "Returns the URL that can be used to invoke the given function from the remote system."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_function_stub(self, url):\n        assert self._opened, \"RPC System is not opened\"\n        logging.debug(\"create_function_stub(%s)\" % repr(url))\n        parseresult = urlparse.urlparse(url)\n        scheme = parseresult.scheme\n        path = parseresult.path.split(\"/\")\n        if scheme != \"anycall\":\n            raise ValueError(\"Not an anycall URL: %s\" % repr(url))\n        if len(path) != 3 or path[0] != \"\" or path[1] != \"functions\":\n            raise ValueError(\"Not an URL for a remote function: %s\" % repr(url))\n        try:\n            functionid = uuid.UUID(path[2])\n        except ValueError:\n            raise ValueError(\"Not a valid URL for a remote function: %s\" % repr(url))\n        \n        return _RPCFunctionStub(parseresult.netloc, functionid, self)", "response": "Create a callable that will invoke the given remote function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ping_loop_iteration(self):\n        \n        deferredList = []\n        \n        for peerid, callid in list(self._local_to_remote):\n            \n            if (peerid, callid) not in self._local_to_remote:\n                continue # call finished in the meantime\n            \n            logger.debug(\"sending ping\")\n            d = self._invoke_function(peerid, self._PING, (self._connectionpool.ownid, callid), {})\n            #twistit.timeout_deferred(d, self._ping_timeout, \"Lost communication to peer during call.\")\n            \n            def failed(failure):\n                if (peerid, callid) in self._local_to_remote:\n                    d = self._local_to_remote.pop((peerid, callid))\n                    d.errback(failure)\n                    \n            def success(value):\n                logger.debug(\"received pong\")\n                return value\n                    \n            d.addCallbacks(success, failed)\n            deferredList.append(d)\n   \n        d = defer.DeferredList(deferredList)\n            \n        def done(_):\n            self._ping_current_iteration = None\n        self._ping_current_iteration = d\n        d.addBoth(done)\n        return d", "response": "Called every ping_interval seconds. Returns a Deferred that resolves when the ping is complete."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall from remote to ask if a call made to here is still in progress.", "response": "def _ping(self, peerid, callid):\n        \"\"\"\n        Called from remote to ask if a call made to here is still in progress.\n        \"\"\"\n        if not (peerid, callid) in self._remote_to_local:\n            logger.warn(\"No remote call %s from %s. Might just be unfoutunate timing.\" % (callid, peerid))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap a WSGI app and handles uncaught exceptions and defined exception and outputs a the exception in a structured format. Parameters: - wsgi_app is the app.wsgi_app of flask, - app_name should in correct format e.g. APP_NAME_1, - app_logger is the logger object", "response": "def register_app_for_error_handling(wsgi_app, app_name, app_logger, custom_logging_service=None):\n    \"\"\"Wraps a WSGI app and handles uncaught exceptions and defined exception and outputs a the exception in a\n    structured format.\n    Parameters:\n    - wsgi_app is the app.wsgi_app of flask,\n    - app_name should in correct format e.g. APP_NAME_1,\n    - app_logger is the logger object\"\"\"\n\n    logging_service = LoggingService(app_logger) if custom_logging_service is None else custom_logging_service\n    exception_manager = ExceptionHandler(app_name, logging_service)\n\n    def wrapper(environ, start_response):\n        try:\n            return wsgi_app(environ, start_response)\n        except RootException as e:\n            app_request = Request(environ)\n            stack_trace = traceback.format_exc().splitlines()[-1]\n            exception_manager.update_with_exception_data(e, app_request, stack_trace)\n        except Exception:\n            app_request = Request(environ)\n            stack_trace = traceback.format_exc()\n            e = RootException(\"FATAL_000\", {}, {}, {}, status_code=500)\n            e.error_message = \"Unknown System Error\"\n            exception_manager.update_with_exception_data(e, app_request, stack_trace)\n\n        error_details = exception_manager.construct_error_details()\n        http_status_code = exception_manager.get_http_status_code()\n        response = Response(json.dumps(error_details), status=http_status_code, content_type='application/json')\n\n        return response(environ, start_response)\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget command regex string and completer dict.", "response": "def _cmdRegex(self, cmd_grp=None):\n        \"\"\"Get command regex string and completer dict.\"\"\"\n        cmd_grp = cmd_grp or \"cmd\"\n        help_opts = (\"-h\", \"--help\")\n\n        cmd = self.name()\n        names = \"|\".join([re.escape(cmd)] +\n                         [re.escape(a) for a in self.aliases()])\n\n        opts = []\n        for action in self.parser._actions:\n            opts += [a for a in action.option_strings\n                        if a not in help_opts]\n\n        opts_re = \"|\".join([re.escape(o) for o in opts])\n        if opts_re:\n            opts_re = rf\"(\\s+(?P<{cmd_grp}_opts>{opts_re}))*\"\n\n        help_re = \"|\".join([re.escape(o) for o in help_opts])\n        help_re = rf\"(\\s+(?P<HELP_OPTS>{help_re}))*\"\n\n        completers = {}\n        if opts_re:\n            completers[f\"{cmd_grp}_opts\"] = WordCompleter(opts)\n        # Singe Help completer added elsewhere\n\n        return tuple([\n            rf\"\"\"(?P<{cmd_grp}>{names}){opts_re}{help_re}\"\"\",\n            completers\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fromStringProto(self, inString, proto):\n        value, = amp.AmpList.fromStringProto(self, inString, proto)\n        return value", "response": "Converts a string representation of a protocol buffer to an AMP list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef toStringProto(self, inObject, proto):\n        return amp.AmpList.toStringProto(self, [inObject], proto)", "response": "Returns the string representation of the object in the given protocol."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unfurl(jwt):\n\n    _rp_jwt = factory(jwt)\n    return json.loads(_rp_jwt.jwt.part[1].decode('utf8'))", "response": "Return the body of a signed JWT without verifying the signature."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef keyjar_from_metadata_statements(iss, msl):\n    keyjar = KeyJar()\n    for ms in msl:\n        keyjar.import_jwks(ms['signing_keys'], iss)\n    return keyjar", "response": "Builds a keyJar instance based on the information in the signing_keys field of the metadata statements."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a file containing a JWKS and populates a with the JWKS data.", "response": "def read_jwks_file(jwks_file):\n    \"\"\"\n    Reads a file containing a JWKS and populates a\n    :py:class:`oidcmsg.key_jar.KeyJar` from it.\n\n    :param jwks_file: file name of the JWKS file \n    :return: A :py:class:`oidcmsg.key_jar.KeyJar` instance\n    \"\"\"\n    _jwks = open(jwks_file, 'r').read()\n    _kj = KeyJar()\n    _kj.import_jwks(json.loads(_jwks), '')\n    return _kj"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies that an item a is < then an item b.", "response": "def is_lesser(a, b):\n    \"\"\"\n    Verify that an item *a* is <= then an item *b*\n    \n    :param a: An item\n    :param b: Another item\n    :return: True or False\n    \"\"\"\n\n    if type(a) != type(b):\n        return False\n\n    if isinstance(a, str) and isinstance(b, str):\n        return a == b\n    elif isinstance(a, bool) and isinstance(b, bool):\n        return a == b\n    elif isinstance(a, list) and isinstance(b, list):\n        for element in a:\n            flag = 0\n            for e in b:\n                if is_lesser(element, e):\n                    flag = 1\n                    break\n            if not flag:\n                return False\n        return True\n    elif isinstance(a, dict) and isinstance(b, dict):\n        if is_lesser(list(a.keys()), list(b.keys())):\n            for key, val in a.items():\n                if not is_lesser(val, b[key]):\n                    return False\n            return True\n        return False\n    elif isinstance(a, int) and isinstance(b, int):\n        return a <= b\n    elif isinstance(a, float) and isinstance(b, float):\n        return a <= b\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verify(self, **kwargs):\n        super(MetadataStatement, self).verify(**kwargs)\n        if \"signing_keys\" in self:\n            if 'signing_keys_uri' in self:\n                raise VerificationError(\n                    'You can only have one of \"signing_keys\" and '\n                    '\"signing_keys_uri\" in a metadata statement')\n            else:\n                # signing_keys MUST be a JWKS\n                kj = KeyJar()\n                try:\n                    kj.import_jwks(self['signing_keys'], '')\n                except Exception:\n                    raise VerificationError('\"signing_keys\" not a proper JWKS')\n\n        if \"metadata_statements\" in self and \"metadata_statement_uris\" in self:\n            s = set(self['metadata_statements'].keys())\n            t = set(self['metadata_statement_uris'].keys())\n            if s.intersection(t):\n                raise VerificationError(\n                    'You should not have the same key in \"metadata_statements\" '\n                    'and in \"metadata_statement_uris\"')\n\n        return True", "response": "Verifies that an instance of this class adheres to the given set of keyword arguments."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the remote response from the remote endpoint and return the JSON or None.", "response": "def _parse_remote_response(self, response):\n        \"\"\"\n        Parse simple JWKS or signed JWKS from the HTTP response.\n\n        :param response: HTTP response from the 'jwks_uri' or 'signed_jwks_uri'\n            endpoint\n        :return: response parsed as JSON or None\n        \"\"\"\n        # Check if the content type is the right one.\n        try:\n            if response.headers[\"Content-Type\"] == 'application/json':\n                logger.debug(\n                    \"Loaded JWKS: %s from %s\" % (response.text, self.source))\n                try:\n                    return json.loads(response.text)\n                except ValueError:\n                    return None\n            elif response.headers[\"Content-Type\"] == 'application/jwt':\n                logger.debug(\n                    \"Signed JWKS: %s from %s\" % (response.text, self.source))\n                _jws = factory(response.text)\n                _resp = _jws.verify_compact(\n                    response.text, keys=self.verify_keys.get_signing_key())\n                return _resp\n            else:\n                logger.error('Wrong content type: {}'.format(\n                    response.headers['Content-Type']))\n                raise ValueError('Content-type mismatch')\n        except KeyError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndumps a single file into a backup file.", "response": "def dump(filename, dbname, username=None, password=None, host=None,\n    port=None, tempdir='/tmp', pg_dump_path='pg_dump', format='p'):\n    \"\"\"Performs a pg_dump backup.\n\n    It runs with the current systemuser's privileges, unless you specify\n    username and password.\n\n    By default pg_dump connects to the value given in the PGHOST environment\n    variable.\n    You can either specify \"hostname\" and \"port\" or a socket path.\n\n    pg_dump expects the pg_dump-utility to be on $PATCH.\n    Should that not be case you are allowed to specify a custom location with\n    \"pg_dump_path\"\n\n    Format is p (plain / default), c = custom, d = directory, t=tar\n\n    returns statuscode and shelloutput\n\n    \"\"\"\n\n    filepath = os.path.join(tempdir, filename)\n\n    cmd = pg_dump_path\n    cmd += ' --format %s' % format\n    cmd += ' --file ' + os.path.join(tempdir, filename)\n\n    if username:\n        cmd += ' --username %s' % username\n    if host:\n        cmd += ' --host %s' % host\n    if port:\n        cmd += ' --port %s' % port\n\n    cmd += ' ' + dbname\n\n    ## export pgpasswd\n    if password:\n        os.environ[\"PGPASSWORD\"] = password\n\n    ## run pgdump\n    return sh(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _connection(username=None, password=None, host=None, port=None, db=None):\n    \"returns a connected cursor to the database-server.\"\n\n    c_opts = {}\n\n    if username: c_opts['user'] = username\n    if password: c_opts['password'] = password\n    if host: c_opts['host'] = host\n    if port: c_opts['port'] = port\n    if db: c_opts['database'] = db\n\n    dbc = psycopg2.connect(**c_opts)\n    dbc.autocommit = True\n    return dbc", "response": "returns a connected cursor to the database - server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef db_list(username=None, password=None, host=None, port=None,\n        maintain_db='postgres'):\n    \"returns a list of all databases on this server\"\n\n    conn = _connection(username=username, password=password, host=host,\n        port=port, db=maintain_db)\n\n    cur = conn.cursor()\n\n    cur.execute('SELECT DATNAME from pg_database')\n    rows = cur.fetchall()\n\n    conn.close()\n\n    result = []\n    for row in rows:\n        result.append(row[0])\n\n    return result", "response": "returns a list of all databases on this server"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_local_files(self, path):\n        if not path:\n            raise ValueError(\"No path specified\")\n        files = defaultdict(lambda: None)\n        path_len = len(path) + 1\n        for root, dirs, filenames in os.walk(path):\n            for name in filenames:\n                full_path = join(root, name)\n                files[full_path[path_len:]] = compute_md5(full_path) \n        return files", "response": "Returns a dictionary of all the files under a path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sync_folder(self, path, bucket):\n        bucket = self.conn.get_bucket(bucket)\n        local_files = self._get_local_files(path)\n        s3_files = self._get_s3_files(bucket)\n        for filename, hash in local_files.iteritems():\n            s3_key = s3_files[filename]\n            if s3_key is None:\n                s3_key = Key(bucket)\n                s3_key.key = filename\n                s3_key.etag = '\"!\"'\n            \n            if s3_key.etag[1:-1] != hash[0]:\n                s3_key.set_contents_from_filename(join(path, filename), md5=hash)", "response": "Syncs a local directory with an S3 bucket."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sync(self, folders):\n        if not folders:\n            raise ValueError(\"No folders to sync given\")\n        for folder in folders:\n            self.sync_folder(*folder)", "response": "Syncs a list of folders to their assicated buckets."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef login_required(function=None, redirect_field_name=REDIRECT_FIELD_NAME,\n                   login_url=None):\n    \"\"\"\n    Decorator for views that checks that the user is logged in, redirecting\n    to the log-in page if necessary.\n    \"\"\"\n    actual_decorator = request_passes_test(\n        lambda r: r.session.get('user_token'),\n        login_url=login_url,\n        redirect_field_name=redirect_field_name\n    )\n    if function:\n        return actual_decorator(function)\n    return actual_decorator", "response": "Decorator for views that checks that the user is logged in."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tokens_required(service_list):\n    def decorator(func):\n        @wraps(func)\n        def inner(request, *args, **kwargs):\n            for service in service_list:\n                if service not in request.session[\"user_tokens\"]:\n                    return redirect('denied')\n            return func(request, *args, **kwargs)\n        return inner\n    return decorator", "response": "Decorator that ensures the user has the necessary tokens for the specified services."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef login(request, template_name='ci/login.html',\n          redirect_field_name=REDIRECT_FIELD_NAME,\n          authentication_form=AuthenticationForm):\n    \"\"\"\n    Displays the login form and handles the login action.\n    \"\"\"\n    redirect_to = request.POST.get(redirect_field_name,\n                                   request.GET.get(redirect_field_name, ''))\n\n    if request.method == \"POST\":\n        form = authentication_form(request, data=request.POST)\n        if form.is_valid():\n\n            # Ensure the user-originating redirection url is safe.\n            if not is_safe_url(url=redirect_to, host=request.get_host()):\n                redirect_to = resolve_url(settings.LOGIN_REDIRECT_URL)\n\n            # Okay, security check complete. Get the user object from auth api.\n            user = form.get_user()\n            request.session['user_token'] = user[\"token\"]\n            request.session['user_email'] = user[\"email\"]\n            request.session['user_permissions'] = user[\"permissions\"]\n            request.session['user_id'] = user[\"id\"]\n            request.session['user_list'] = user[\"user_list\"]\n\n            if not settings.HIDE_DASHBOARDS:\n                # Set user dashboards because they are slow to change\n                dashboards = ciApi.get_user_dashboards(user[\"id\"])\n                dashboard_list = list(dashboards['results'])\n                if len(dashboard_list) > 0:\n                    request.session['user_dashboards'] = \\\n                        dashboard_list[0][\"dashboards\"]\n                    request.session['user_default_dashboard'] = \\\n                        dashboard_list[0][\"default_dashboard\"][\"id\"]\n                else:\n                    request.session['user_dashboards'] = []\n                    request.session['user_default_dashboard'] = None\n\n            # Get the user access tokens too and format for easy access\n            tokens = ciApi.get_user_service_tokens(\n                params={\"user_id\": user[\"id\"]})\n            token_list = list(tokens['results'])\n            user_tokens = {}\n            if len(token_list) > 0:\n                for token in token_list:\n                    user_tokens[token[\"service\"][\"name\"]] = {\n                        \"token\": token[\"token\"],\n                        \"url\": token[\"service\"][\"url\"] + \"/api/v1\"\n                    }\n            request.session['user_tokens'] = user_tokens\n\n            return HttpResponseRedirect(redirect_to)\n    else:\n        form = authentication_form(request)\n\n    current_site = get_current_site(request)\n\n    context = {\n        'form': form,\n        redirect_field_name: redirect_to,\n        'site': current_site,\n        'site_name': current_site.name,\n    }\n\n    return TemplateResponse(request, template_name, context)", "response": "Handles the login action."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding the CLI dynamically based on the package structure.", "response": "def build(cli, path, package):\n    \"\"\"Build CLI dynamically based on the package structure.\n    \"\"\"\n    for _, name, ispkg in iter_modules(path):\n        module = import_module(f'.{name}', package)\n        if ispkg:\n            build(cli.group(name)(module.group),\n                  module.__path__,\n                  module.__package__)\n        else:\n            cli.command(name)(module.command)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef readonly(cls, *args, **kwargs):\n        fridge = cls(*args, **kwargs)\n        fridge.close()\n        return fridge", "response": "Returns an already closed read - only Fridge instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load(self):\n        self._check_open()\n        try:\n            data = json.load(self.file, **self.load_args)\n        except ValueError:\n            data = {}\n        if not isinstance(data, dict):\n            raise ValueError('Root JSON type must be dictionary')\n        self.clear()\n        self.update(data)", "response": "Load the in - memory dictionary from the file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self):\n        self._check_open()\n        self.file.truncate(0)\n        self.file.seek(0)\n        json.dump(self, self.file, **self.dump_args)", "response": "Saves the current dictionary to the file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef close(self):\n        if not self.closed:\n            self.save()\n            if self.close_file:\n                self.file.close()\n        self.closed = True", "response": "Closes the fridge object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef self_sign_jwks(keyjar, iss, kid='', lifetime=3600):\n\n    # _json = json.dumps(jwks)\n    _jwt = JWT(keyjar, iss=iss, lifetime=lifetime)\n\n    jwks = keyjar.export_jwks(issuer=iss)\n\n    return _jwt.pack(payload={'jwks': jwks}, owner=iss, kid=kid)", "response": "Create a signed JWT containing a JWKS."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef verify_self_signed_jwks(sjwt):\n\n    _jws = factory(sjwt)\n    _json = _jws.jwt.part[1]\n    _body = json.loads(as_unicode(_json))\n    iss = _body['iss']\n    _jwks = _body['jwks']\n\n    _kj = jwks_to_keyjar(_jwks, iss)\n\n    try:\n        _kid = _jws.jwt.headers['kid']\n    except KeyError:\n        _keys = _kj.get_signing_key(owner=iss)\n    else:\n        _keys = _kj.get_signing_key(owner=iss, kid=_kid)\n\n    _ver = _jws.verify_compact(sjwt, _keys)\n    return {'jwks': _ver['jwks'], 'iss': iss}", "response": "Verify the signature of a signed JWT containing a JWKS."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef request_signed_by_signing_keys(keyjar, msreq, iss, lifetime, kid=''):\n\n    try:\n        jwks_to_keyjar(msreq['signing_keys'], iss)\n    except KeyError:\n        jwks = keyjar.export_jwks(issuer=iss)\n        msreq['signing_keys'] = jwks\n\n    _jwt = JWT(keyjar, iss=iss, lifetime=lifetime)\n\n    return _jwt.pack(owner=iss, kid=kid, payload=msreq.to_dict())", "response": "Create a signed JWT from a metadata statement signing request."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies that a signed request is signed by the signing keys.", "response": "def verify_request_signed_by_signing_keys(smsreq):\n    \"\"\"\n    Verify that a JWT is signed with a key that is inside the JWT.\n    \n    :param smsreq: Signed Metadata Statement signing request\n    :return: Dictionary containing 'ms' (the signed request) and 'iss' (the\n        issuer of the JWT).\n    \"\"\"\n\n    _jws = factory(smsreq)\n    _json = _jws.jwt.part[1]\n    _body = json.loads(as_unicode(_json))\n    iss = _body['iss']\n    _jwks = _body['signing_keys']\n\n    _kj = jwks_to_keyjar(_jwks, iss)\n\n    try:\n        _kid = _jws.jwt.headers['kid']\n    except KeyError:\n        _keys = _kj.get_signing_key(owner=iss)\n    else:\n        _keys = _kj.get_signing_key(owner=iss, kid=_kid)\n\n    _ver = _jws.verify_compact(smsreq, _keys)\n    # remove the JWT specific claims\n    for k in JsonWebToken.c_param.keys():\n        try:\n            del _ver[k]\n        except KeyError:\n            pass\n    try:\n        del _ver['kid']\n    except KeyError:\n        pass\n\n    return {'ms': MetadataStatement(**_ver), 'iss': iss}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef card(func):\n    @wraps(func)\n    def wrapped(*args, **kwargs):\n        \"\"\"Transparent wrapper.\"\"\"\n        return func(*args, **kwargs)\n    TESTS.append(wrapped)\n    return wrapped", "response": "A decorator for providing a unittesting function that will be called every time a card in the librarian card library database is called."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef descovery(testdir):\n    from os.path import join, exists, isdir, splitext, basename, sep\n    if not testdir or not exists(testdir) or not isdir(testdir):\n        return None\n\n    from os import walk\n    import fnmatch\n    import imp\n\n    for root, _, filenames in walk(testdir):\n        for filename in fnmatch.filter(filenames, '*.py'):\n            path = join(root, filename)\n            modulepath = splitext(root)[0].replace(sep, '.')\n            imp.load_source(modulepath, path)", "response": "Descover and load greencard tests."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncommanding line entry point.", "response": "def main(clargs=None):\n    \"\"\"Command line entry point.\"\"\"\n    from argparse import ArgumentParser\n    from librarian.library import Library\n    import sys\n\n    parser = ArgumentParser(\n        description=\"A test runner for each card in a librarian library.\")\n    parser.add_argument(\"library\", help=\"Library database\")\n    parser.add_argument(\"-t\", \"--tests\", default=\"test/\",\n                        help=\"Test directory\")\n    args = parser.parse_args(clargs)\n\n    descovery(args.tests)\n\n    library = Library(args.library)\n    cardcount, passes, failures = execute_tests(library)\n    print(RESULTS.format(len(SINGLES), len(TESTS), cardcount, passes,\n                         failures))\n    sys.exit(failures)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the Scrabble score of a single character string.", "response": "def letter_score(letter):\n    \"\"\"Returns the Scrabble score of a letter.\n\n    Args:\n        letter: a single character string\n\n    Raises:\n        TypeError if a non-Scrabble character is supplied\n    \"\"\"\n\n    score_map = {\n        1: [\"a\", \"e\", \"i\", \"o\", \"u\", \"l\", \"n\", \"r\", \"s\", \"t\"],\n        2: [\"d\", \"g\"],\n        3: [\"b\", \"c\", \"m\", \"p\"],\n        4: [\"f\", \"h\", \"v\", \"w\", \"y\"],\n        5: [\"k\"],\n        8: [\"j\", \"x\"],\n        10: [\"q\", \"z\"],\n    }\n\n    for score, letters in score_map.items():\n        if letter.lower() in letters:\n            return score\n    else:\n        raise TypeError(\"Invalid letter: %s\", letter)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef word_score(word, input_letters, questions=0):\n\n    score = 0\n    bingo = 0\n    filled_by_blanks = []\n    rack = list(input_letters)  # make a copy to speed up find_anagrams()\n    for letter in word:\n        if letter in rack:\n            bingo += 1\n            score += letter_score(letter)\n            rack.remove(letter)\n        else:\n            filled_by_blanks.append(letter_score(letter))\n\n    # we can have both ?'s and _'s in the word. this will apply the ?s to the\n    # highest scrabble score value letters and leave the blanks for low points.\n    for blank_score in sorted(filled_by_blanks, reverse=True):\n        if questions > 0:\n            score += blank_score\n            questions -= 1\n\n    # 50 bonus points for using all the tiles in your rack\n    if bingo > 6:\n        score += 50\n\n    return score", "response": "Calculates the Scrabble score of a single word."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch a string for blank tiles.", "response": "def blank_tiles(input_word):\n    \"\"\"Searches a string for blank tile characters (\"?\" and \"_\").\n\n    Args:\n        input_word: the user supplied string to search through\n\n    Returns:\n        a tuple of:\n            input_word without blanks\n            integer number of blanks (no points)\n            integer number of questions (points)\n    \"\"\"\n\n    blanks = 0\n    questions = 0\n    input_letters = []\n    for letter in input_word:\n        if letter == \"_\":\n            blanks += 1\n        elif letter == \"?\":\n            questions += 1\n        else:\n            input_letters.append(letter)\n    return input_letters, blanks, questions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an iterable of words in the available word lists.", "response": "def word_list(sowpods=False, start=\"\", end=\"\"):\n    \"\"\"Opens the word list file.\n\n    Args:\n        sowpods: a boolean to declare using the sowpods list or TWL (default)\n        start: a string of starting characters to find anagrams based on\n        end: a string of ending characters to find anagrams based on\n\n    Yeilds:\n        a word at a time out of 178691 words for TWL, 267751 for sowpods. Much\n        less if either start or end are used (filtering is applied here)\n    \"\"\"\n\n    location = os.path.join(\n        os.path.dirname(os.path.realpath(__file__)),\n        \"wordlists\",\n    )\n\n    if sowpods:\n        filename = \"sowpods.txt\"\n    else:\n        filename = \"twl.txt\"\n\n    filepath = os.path.join(location, filename)\n\n    with open(filepath) as wordfile:\n        for word in wordfile.readlines():\n            word = word.strip()\n            if start and end and word.startswith(start) and word.endswith(end):\n                yield word\n            elif start and word.startswith(start) and not end:\n                yield word\n            elif end and word.endswith(end) and not start:\n                yield word\n            elif not start and not end:\n                yield word"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the input word could be played with a full bag of tiles. Returns True or False.", "response": "def valid_scrabble_word(word):\n    \"\"\"Checks if the input word could be played with a full bag of tiles.\n\n    Returns:\n        True or false\n    \"\"\"\n\n    letters_in_bag = {\n        \"a\": 9,\n        \"b\": 2,\n        \"c\": 2,\n        \"d\": 4,\n        \"e\": 12,\n        \"f\": 2,\n        \"g\": 3,\n        \"h\": 2,\n        \"i\": 9,\n        \"j\": 1,\n        \"k\": 1,\n        \"l\": 4,\n        \"m\": 2,\n        \"n\": 6,\n        \"o\": 8,\n        \"p\": 2,\n        \"q\": 1,\n        \"r\": 6,\n        \"s\": 4,\n        \"t\": 6,\n        \"u\": 4,\n        \"v\": 2,\n        \"w\": 2,\n        \"x\": 1,\n        \"y\": 2,\n        \"z\": 1,\n        \"_\": 2,\n    }\n\n    for letter in word:\n        if letter == \"?\":\n            continue\n        try:\n            letters_in_bag[letter] -= 1\n        except KeyError:\n            return False\n        if letters_in_bag[letter] < 0:\n            letters_in_bag[\"_\"] -= 1\n            if letters_in_bag[\"_\"] < 0:\n                return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stringReceived(self, string):\n        request = loads(string)\n\n        identifier = request.pop(\"_ask\")\n        commandName = request.pop(\"_command\")\n        command, responder = self._getCommandAndResponder(commandName)\n\n        self._parseRequestValues(request, command)\n        d = self._runResponder(responder, request, command, identifier)\n        d.addCallback(self._writeResponse)", "response": "Handle a JSON AMP dialect request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the command class and matching responder function for the given command name.", "response": "def _getCommandAndResponder(self, commandName):\n        \"\"\"Gets the command class and matching responder function for the\n        given command name.\n\n        \"\"\"\n        # DISGUSTING IMPLEMENTATION DETAIL EXPLOITING HACK\n        locator = self._remote.boxReceiver.locator\n        responder = locator.locateResponder(commandName)\n        responderFunction = responder.func_closure[1].cell_contents\n        command = responder.func_closure[2].cell_contents\n        return command, responderFunction"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parseRequestValues(self, request, command):\n        for key, ampType in command.arguments:\n            ampClass = ampType.__class__\n\n            if ampClass is exposed.ExposedResponderLocator:\n                request[key] = self._remote\n                continue\n\n            decoder = _decoders.get(ampClass)\n            if decoder is not None:\n                value = request.get(key)\n                request[key] = decoder(value, self)", "response": "Parses all the values in the request that are in a form specific\n        to the JSON AMP dialect."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns the responder function.", "response": "def _runResponder(self, responder, request, command, identifier):\n        \"\"\"Run the responser function. If it succeeds, add the _answer key.\n        If it fails with an error known to the command, serialize the\n        error.\n\n        \"\"\"\n        d = defer.maybeDeferred(responder, **request)\n\n        def _addIdentifier(response):\n            \"\"\"Return the response with an ``_answer`` key.\n\n            \"\"\"\n            response[\"_answer\"] = identifier\n            return response\n\n        def _serializeFailure(failure):\n            \"\"\"\n            If the failure is serializable by this AMP command, serialize it.\n            \"\"\"\n            key = failure.trap(*command.allErrors)\n            response = {\n                \"_error_code\": command.allErrors[key],\n                \"_error_description\": str(failure.value),\n                \"_error\": identifier\n            }\n            return response\n\n        d.addCallbacks(_addIdentifier, _serializeFailure)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _writeResponse(self, response):\n        encoded = dumps(response, default=_default)\n        self.transport.write(encoded)", "response": "Serializes the response to JSON and writes it to the transport."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls by the remote thread when the connection to the remote thread is lost.", "response": "def connectionLost(self, reason):\n        \"\"\"\n        Tells the box receiver to stop receiving boxes.\n        \"\"\"\n        self._remote.boxReceiver.stopReceivingBoxes(reason)\n        return basic.NetstringReceiver.connectionLost(self, reason)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a bridge and associates it with an AMP protocol instance.", "response": "def buildProtocol(self, addr):\n        \"\"\"\n        Builds a bridge and associates it with an AMP protocol instance.\n        \"\"\"\n        proto = self._factory.buildProtocol(addr)\n        return JSONAMPDialectReceiver(proto)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_bundle(iss, ver_keys, bundle_file):\n    fp = open(bundle_file, 'r')\n    signed_bundle = fp.read()\n    fp.close()\n    return JWKSBundle(iss, None).upload_signed_bundle(signed_bundle, ver_keys)", "response": "Read a JWKS bundle from disc verify the signature and upload it to the server"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_signing_keys(eid, keydef, key_file):\n    if os.path.isfile(key_file):\n        kj = KeyJar()\n        kj.import_jwks(json.loads(open(key_file, 'r').read()), eid)\n    else:\n        kj = build_keyjar(keydef)[1]\n        # make it know under both names\n        fp = open(key_file, 'w')\n        fp.write(json.dumps(kj.export_jwks()))\n        fp.close()\n        kj.issuer_keys[eid] = kj.issuer_keys['']\n\n    return kj", "response": "Get the keys for the given entity and keydef."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef jwks_to_keyjar(jwks, iss=''):\n    if not isinstance(jwks, dict):\n        try:\n            jwks = json.loads(jwks)\n        except json.JSONDecodeError:\n            raise ValueError('No proper JSON')\n\n    kj = KeyJar()\n    kj.import_jwks(jwks, issuer=iss)\n    return kj", "response": "Converts a JWKS to a KeyJar instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a signed JWT containing a dictionary with Issuer IDs as keys and JWKSs as values.", "response": "def create_signed_bundle(self, sign_alg='RS256', iss_list=None):\n        \"\"\"\n        Create a signed JWT containing a dictionary with Issuer IDs as keys\n        and JWKSs as values. If iss_list is empty then all available issuers are\n        included.\n        \n        :param sign_alg: Which algorithm to use when signing the JWT\n        :param iss_list: A list of issuer IDs who's keys should be included in \n            the signed bundle.\n        :return: A signed JWT\n        \"\"\"\n        data = self.dict(iss_list)\n        _jwt = JWT(self.sign_keys, iss=self.iss, sign_alg=sign_alg)\n        return _jwt.pack({'bundle':data})"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nuploading a bundle from an unsigned JSON document or a dictionary.", "response": "def loads(self, jstr):\n        \"\"\"\n        Upload a bundle from an unsigned JSON document\n\n        :param jstr: A bundle as a dictionary or a JSON document\n        \"\"\"\n        if isinstance(jstr, dict):\n            _info = jstr\n        else:\n            _info = json.loads(jstr)\n\n        for iss, jwks in _info.items():\n            kj = KeyJar()\n            if isinstance(jwks, dict):\n                kj.import_jwks(jwks, issuer=iss)\n            else:\n                kj.import_jwks_as_json(jwks, issuer=iss)\n            self.bundle[iss] = kj\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dict(self, iss_list=None):\n        _int = {}\n        for iss, kj in self.bundle.items():\n            if iss_list is None or iss in iss_list:\n                try:\n                    _int[iss] = kj.export_jwks_as_json(issuer=iss)\n                except KeyError:\n                    _int[iss] = kj.export_jwks_as_json()\n        return _int", "response": "Return the bundle of keys as a dictionary with the issuer IDs as keys and the key sets represented as JWKS instances."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninput is a signed JWT with a JSON document representing the key bundle as body. This method verifies the signature and the updates the instance bundle with whatever was in the received package. Note, that as with dictionary update if an Issuer ID already exists in the instance bundle that will be overwritten with the new information. :param sign_bundle: A signed JWT :param ver_keys: Keys that can be used to verify the JWT signature.", "response": "def upload_signed_bundle(self, sign_bundle, ver_keys):\n        \"\"\"\n        Input is a signed JWT with a JSON document representing the key bundle \n        as body. This method verifies the signature and the updates the instance\n        bundle with whatever was in the received package. Note, that as with \n        dictionary update if an Issuer ID already exists in the instance bundle\n        that will be overwritten with the new information.\n        \n        :param sign_bundle: A signed JWT\n        :param ver_keys: Keys that can be used to verify the JWT signature.\n        \"\"\"\n        jwt = verify_signed_bundle(sign_bundle, ver_keys)\n        self.loads(jwt['bundle'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a key bundle into a KeyJar instance.", "response": "def as_keyjar(self):\n        \"\"\"\n        Convert a key bundle into a KeyJar instance.\n        \n        :return: An :py:class:`oidcmsg.key_jar.KeyJar` instance \n        \"\"\"\n        kj = KeyJar()\n        for iss, k in self.bundle.items():\n            try:\n                kj.issuer_keys[iss] = k.issuer_keys[iss]\n            except KeyError:\n                kj.issuer_keys[iss] = k.issuer_keys['']\n        return kj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_shortcut(cmd):\n    def _(cmd_arguments, *args, **kwargs):\n        return run(\"%s %s\" % (cmd, cmd_arguments), *args, **kwargs)\n    return _", "response": "return a function which runs the given cmd\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nova_process(body, message):\n    event_type = body['event_type']\n    process = nova_customer_process.get(event_type)\n    if process is not None:\n        process(body, message)\n    else:\n        matched = False\n        process_wildcard = None\n        for pattern in nova_customer_process_wildcard.keys():\n            if pattern.match(event_type):\n                process_wildcard = nova_customer_process_wildcard.get(pattern)\n                matched = True\n                break\n        if matched:\n            process_wildcard(body, message)\n        else:\n            default_process(body, message)\n    message.ack()", "response": "This function deal with the nova notification."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cinder_process(body, message):\n    event_type = body['event_type']\n    process = cinder_customer_process.get(event_type)\n    if process is not None:\n        process(body, message)\n    else:\n        matched = False\n        process_wildcard = None\n        for pattern in cinder_customer_process_wildcard.keys():\n            if pattern.match(event_type):\n                process_wildcard = cinder_customer_process_wildcard.get(pattern)\n                matched = True\n                break\n        if matched:\n            process_wildcard(body, message)\n        else:\n            default_process(body, message)\n    message.ack()", "response": "This function deal with the cinder notification."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef neutron_process(body, message):\n    event_type = body['event_type']\n    process = neutron_customer_process.get(event_type)\n    if process is not None:\n        process(body, message)\n    else:\n        matched = False\n        process_wildcard = None\n        for pattern in neutron_customer_process_wildcard.keys():\n            if pattern.match(event_type):\n                process_wildcard = neutron_customer_process_wildcard.get(pattern)\n                matched = True\n                break\n        if matched:\n            process_wildcard(body, message)\n        else:\n            default_process(body, message)\n    message.ack()", "response": "This function deal with the neutron notification."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef glance_process(body, message):\n    event_type = body['event_type']\n    process = glance_customer_process.get(event_type)\n    if process is not None:\n        process(body, message)\n    else:\n        matched = False\n        process_wildcard = None\n        for pattern in glance_customer_process_wildcard.keys():\n            if pattern.match(event_type):\n                process_wildcard = glance_customer_process_wildcard.get(pattern)\n                matched = True\n                break\n        if matched:\n            process_wildcard(body, message)\n        else:\n            default_process(body, message)\n    message.ack()", "response": "This function deal with the glance notification."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef keystone_process(body, message):\n    event_type = body['event_type']\n    process = keystone_customer_process.get(event_type)\n    if process is not None:\n        process(body, message)\n    else:\n        matched = False\n        process_wildcard = None\n        for pattern in keystone_customer_process_wildcard.keys():\n            if pattern.match(event_type):\n                process_wildcard = keystone_customer_process_wildcard.get(pattern)\n                matched = True\n                break\n        if matched:\n            process_wildcard(body, message)\n        else:\n            default_process(body, message)\n    message.ack()", "response": "This function deal with the keystone notification."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serve(self, server=None):\n        if server is None:\n            from wsgiref.simple_server import make_server\n            server = lambda app: make_server('', 8000, app).serve_forever()\n            print('Listening on 0.0.0.0:8000')\n        try:\n            server(self)\n        finally:\n            server.socket.close()", "response": "Serve app using wsgiref or provided server."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint msg to stdout and option log at info level.", "response": "def pout(msg, log=None):\n    \"\"\"Print 'msg' to stdout, and option 'log' at info level.\"\"\"\n    _print(msg, sys.stdout, log_func=log.info if log else None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting msg to stderr and option log at info level.", "response": "def perr(msg, log=None):\n    \"\"\"Print 'msg' to stderr, and option 'log' at info level.\"\"\"\n    _print(msg, sys.stderr, log_func=log.error if log else None)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef loadCommandMap(Class, subparsers=None, instantiate=True, **cmd_kwargs):\n        if not Class._registered_commands:\n            raise ValueError(\"No commands have been registered with {}\"\n                             .format(Class))\n\n        all = {}\n        for Cmd in set(Class._registered_commands[Class].values()):\n            cmd = Cmd(subparsers=subparsers, **cmd_kwargs) \\\n                        if instantiate else Cmd\n            for name in [Cmd.name()] + Cmd.aliases():\n                all[name] = cmd\n        return all", "response": "Instantiate each registered command to a dict mapping name to unique toical class instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef toString(self, value):\n        self._checkConstraints(value)\n        return self.baseArgument.toString(value)", "response": "Returns the string representation of the AMP argument."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting the string to a value using the composed AMP argument then checks all the constraints against that value.", "response": "def fromString(self, string):\n        \"\"\"\n        Converts the string to a value using the composed AMP argument, then\n        checks all the constraints against that value.\n        \"\"\"\n        value = self.baseArgument.fromString(string)\n        self._checkConstraints(value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the completers dictionary with the values from cdict.", "response": "def _updateCompleterDict(completers, cdict, regex=None):\n        \"\"\"Merges ``cdict`` into ``completers``. In the event that a key\n        in cdict already exists in the completers dict a ValueError is raised\n        iff ``regex`` false'y. If a regex str is provided it and the duplicate\n        key are updated to be unique, and the updated regex is returned.\n        \"\"\"\n        for key in cdict:\n            if key in completers and not regex:\n                raise ValueError(f\"Duplicate completion key: {key}\")\n\n            if key in completers:\n                uniq = \"_\".join([key, str(uuid.uuid4()).replace(\"-\", \"\")])\n                regex = regex.replace(f\"P<{key}>\", f\"P<{uniq}>\")\n                completers[uniq] = cdict[key]\n            else:\n                completers[key] = cdict[key]\n\n        return regex"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_completions(self, document, complete_event):\n        # Get word/text before cursor.\n        if self.sentence:\n            word_before_cursor = document.text_before_cursor\n        else:\n            word_before_cursor = document.get_word_before_cursor(WORD=self.WORD)\n\n        if self.ignore_case:\n            word_before_cursor = word_before_cursor.lower()\n\n        def word_matches(word):\n            \"\"\" True when the word before the cursor matches. \"\"\"\n            if self.ignore_case:\n                word = word.lower()\n\n            if self.match_middle:\n                return word_before_cursor in word\n            else:\n                return word.startswith(word_before_cursor)\n\n        '''\n        log.debug(\"------------------------------------------------------\")\n        log.debug(f\"** WORD {self.WORD}\")\n        log.debug(f\"** words {self.words}\")\n        log.debug(f\"** word_before_cursor {word_before_cursor}\")\n        '''\n        words = self._words_callable() if self._words_callable else self.words\n\n        for a in words:\n            if word_matches(a):\n                display_meta = self.meta_dict.get(a, '')\n                log.debug(f\"MATCH: {a}, {-len(word_before_cursor)},\"\n                          f\" meta: {display_meta}\")\n                yield Completion(self.quote(a), -len(word_before_cursor),\n                                 display_meta=display_meta)", "response": "Yields completions for the words in the document."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts ternya work. First, import customer's service modules. Second, init openstack mq. Third, keep a ternya connection that can auto-reconnect.", "response": "def work(self):\n        \"\"\"\n        Start ternya work.\n\n        First, import customer's service modules.\n        Second, init openstack mq.\n        Third, keep a ternya connection that can auto-reconnect.\n        \"\"\"\n        self.init_modules()\n        connection = self.init_mq()\n        TernyaConnection(self, connection).connect()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_modules(self):\n        if not self.config:\n            raise ValueError(\"please read your config file.\")\n\n        log.debug(\"begin to import customer's service modules.\")\n        modules = ServiceModules(self.config)\n        modules.import_modules()\n        log.debug(\"end to import customer's service modules.\")", "response": "Import customer s service modules."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init_cinder_consumer(self, mq):\n        if not self.enable_component_notification(Openstack.Cinder):\n            log.debug(\"disable listening cinder notification\")\n            return\n\n        for i in range(self.config.cinder_mq_consumer_count):\n            mq.create_consumer(self.config.cinder_mq_exchange,\n                               self.config.cinder_mq_queue,\n                               ProcessFactory.process(Openstack.Cinder))\n\n        log.debug(\"enable listening openstack cinder notification.\")", "response": "Init openstack cinder consumer"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_neutron_consumer(self, mq):\n        if not self.enable_component_notification(Openstack.Neutron):\n            log.debug(\"disable listening neutron notification\")\n            return\n\n        for i in range(self.config.neutron_mq_consumer_count):\n            mq.create_consumer(self.config.neutron_mq_exchange,\n                               self.config.neutron_mq_queue,\n                               ProcessFactory.process(Openstack.Neutron))\n\n        log.debug(\"enable listening openstack neutron notification.\")", "response": "Init openstack neutron consumer"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_glance_consumer(self, mq):\n        if not self.enable_component_notification(Openstack.Glance):\n            log.debug(\"disable listening glance notification\")\n            return\n\n        for i in range(self.config.glance_mq_consumer_count):\n            mq.create_consumer(self.config.glance_mq_exchange,\n                               self.config.glance_mq_queue,\n                               ProcessFactory.process(Openstack.Glance))\n\n        log.debug(\"enable listening openstack glance notification.\")", "response": "Init openstack glance consumer"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_swift_consumer(self, mq):\n        if not self.enable_component_notification(Openstack.Swift):\n            log.debug(\"disable listening swift notification\")\n            return\n\n        for i in range(self.config.swift_mq_consumer_count):\n            mq.create_consumer(self.config.swift_mq_exchange,\n                               self.config.swift_mq_queue,\n                               ProcessFactory.process(Openstack.Swift))\n\n        log.debug(\"enable listening openstack swift notification.\")", "response": "Init openstack swift consumer"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef init_heat_consumer(self, mq):\n        if not self.enable_component_notification(Openstack.Heat):\n            log.debug(\"disable listening heat notification\")\n            return\n\n        for i in range(self.config.heat_mq_consumer_count):\n            mq.create_consumer(self.config.heat_mq_exchange,\n                               self.config.heat_mq_queue,\n                               ProcessFactory.process(Openstack.Heat))\n\n        log.debug(\"enable listening openstack heat notification.\")", "response": "Init openstack heat consumer"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef enable_component_notification(self, openstack_component):\n        openstack_component_mapping = {\n            Openstack.Nova: self.config.listen_nova_notification,\n            Openstack.Cinder: self.config.listen_cinder_notification,\n            Openstack.Neutron: self.config.listen_neutron_notification,\n            Openstack.Glance: self.config.listen_glance_notification,\n            Openstack.Swift: self.config.listen_swift_notification,\n            Openstack.Keystone: self.config.listen_keystone_notification,\n            Openstack.Heat: self.config.listen_heat_notification\n        }\n        return openstack_component_mapping[openstack_component]", "response": "Check if customer enable openstack component notification."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget music info from baidu music api", "response": "def music_info(songid):\n    \"\"\"\n    Get music info from baidu music api\n    \"\"\"\n    if isinstance(songid, list):\n        songid = ','.join(songid)\n    data = {\n        \"hq\": 1,\n        \"songIds\": songid\n    }\n    res = requests.post(MUSIC_INFO_URL, data=data)\n    info = res.json()\n    music_data = info[\"data\"]\n\n    songs = []\n    for song in music_data[\"songList\"]:\n        song_link, size = _song_link(song, music_data[\"xcode\"])\n        songs.append({\n            \"name\": song[\"songName\"],\n            \"singer\": song[\"artistName\"],\n            \"lrc_link\": song[\"lrcLink\"],\n            \"song_link\": song_link,\n            \"size\": size\n        })\n    return songs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_music(song, thread_num=4):\n    filename = \"{}.mp3\".format(song[\"name\"])\n\n    if os.path.exists(filename):\n        os.remove(filename)\n\n    part = int(song[\"size\"] / thread_num)\n    if part <= 1024:\n        thread_num = 1\n\n    _id = uuid.uuid4().hex\n\n    logger.info(\"downloading '{}'...\".format(song[\"name\"]))\n\n    threads = []\n    for i in range(thread_num):\n        if i == thread_num - 1:\n            end = ''\n        else:\n            end = (i + 1) * part - 1\n        thread = Worker((i * part, end), song, _id)\n        thread.start()\n        threads.append(thread)\n\n    for t in threads:\n        t.join()\n\n    fileParts = glob.glob(\"part-{}-*\".format(_id))\n    fileParts.sort(key=lambda e: e.split('-')[-1])\n\n    logger.info(\"'{}' combine parts...\".format(song[\"name\"]))\n    with open(filename, \"ab\") as f:\n        for part in fileParts:\n            with open(part, \"rb\") as d:\n                shutil.copyfileobj(d, f)\n            os.remove(part)\n    logger.info(\"'{}' finished\".format(song[\"name\"]))", "response": "downloads a song with multiple threads"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes a python code object containing the key value pairs.", "response": "def execute(self, globals_=None, _locals=None):\n        \"\"\"\n        Execute a code object\n        \n        The inputs and behavior of this function should match those of\n        eval_ and exec_.\n\n        .. _eval: https://docs.python.org/3/library/functions.html?highlight=eval#eval\n        .. _exec: https://docs.python.org/3/library/functions.html?highlight=exec#exec\n\n        .. note:: Need to figure out how the internals of this function must change for\n           ``eval`` or ``exec``.\n\n        :param code: a python code object\n        :param globals_: optional globals dictionary\n        :param _locals: optional locals dictionary\n        \"\"\"\n        if globals_ is None:\n            globals_ = globals()\n        if _locals is None:\n            self._locals = globals_\n        else:\n            self._locals = _locals\n       \n        self.globals_ = globals_\n\n        if self.contains_op(\"YIELD_VALUE\"):\n            return self.iterate_instructions()\n        else:\n            return self.execute_instructions()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npop the top n items from the stack and return them as a list.", "response": "def pop(self, n):\n        \"\"\"\n        Pop the **n** topmost items from the stack and return them as a ``list``.\n        \"\"\"\n        poped = self.__stack[len(self.__stack) - n:]\n        del self.__stack[len(self.__stack) - n:]\n        return poped"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimplements builtins. __build_class__ and return a new class object.", "response": "def build_class(self, callable_, args):\n        \"\"\"\n        Implement ``builtins.__build_class__``.\n        We must wrap all class member functions using :py:func:`function_wrapper`.\n        This requires using a :py:class:`Machine` to execute the class source code\n        and then recreating the class source code using an :py:class:`Assembler`.\n\n        .. note: We might be able to bypass the call to ``builtins.__build_class__``\n           entirely and manually construct a class object.\n\n           https://github.com/python/cpython/blob/master/Python/bltinmodule.c\n        \"\"\"\n        self._print('build_class')\n        self._print(callable_)\n        self._print('args=',args)\n        \n        if isinstance(args[0], FunctionType):\n            c = args[0].get_code()\n        else:\n            c = args[0].__closure__[0].cell_contents.__code__\n        \n        # execute the original class source code\n        print('execute original class source code')\n        machine = MachineClassSource(c, self.verbose)\n        l = dict()\n        machine.execute(self.globals_, l)\n\n        # construct new code for class source\n        a = Assembler()\n        for name, value in l.items():\n            a.load_const(value)\n            a.store_name(name)\n        a.load_const(None)\n        a.return_value()\n       \n        print('new code for class source')\n        dis.dis(a.code())\n\n        #machine = Machine(self.verbose)\n\n        f = types.FunctionType(a.code(), self.globals_, args[1])\n\n        args = (f, *args[1:])\n\n        self.call_callbacks('CALL_FUNCTION', callable_, *args)\n                 \n        return callable_(*args)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef call_function(self, c, i):\n\n        callable_ = self.__stack[-1-i.arg]\n        \n        args = tuple(self.__stack[len(self.__stack) - i.arg:])\n \n        self._print('call function')\n        self._print('\\tfunction ', callable_)\n        self._print('\\ti.arg    ', i.arg)\n        self._print('\\targs     ', args)\n\n        self.call_callbacks('CALL_FUNCTION', callable_, *args)\n   \n        if isinstance(callable_, FunctionType):\n            ret = callable_(*args)\n\n        elif callable_ is builtins.__build_class__:\n            ret = self.build_class(callable_, args)\n\n        elif callable_ is builtins.globals:\n            ret = self.builtins_globals()\n\n        else:\n            ret = callable_(*args)\n        \n        self.pop(1 + i.arg)\n        self.__stack.append(ret)", "response": "Implement the CALL_FUNCTION_ operation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a connected cursor to the database - server.", "response": "def _connection(username=None, password=None, host=None, port=None):\n    \"returns a connected cursor to the database-server.\"\n\n    c_opts = {}\n\n    if username: c_opts['user'] = username\n    if password: c_opts['passwd'] = password\n    if host: c_opts['host'] = host\n    if port: c_opts['port'] = port\n\n    dbc = MySQLdb.connect(**c_opts)\n    dbc.autocommit(True)\n    return dbc"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrenders a ditaa code into a PNG output file.", "response": "def render_ditaa(self, code, options, prefix='ditaa'):\n    \"\"\"Render ditaa code into a PNG output file.\"\"\"\n    hashkey = code.encode('utf-8') + str(options) + \\\n              str(self.builder.config.ditaa) + \\\n              str(self.builder.config.ditaa_args)\n    infname = '%s-%s.%s' % (prefix, sha(hashkey).hexdigest(), \"ditaa\")\n    outfname = '%s-%s.%s' % (prefix, sha(hashkey).hexdigest(), \"png\")\n\n    inrelfn = posixpath.join(self.builder.imgpath, infname)\n    infullfn = path.join(self.builder.outdir, '_images', infname)\n    outrelfn = posixpath.join(self.builder.imgpath, outfname)\n    outfullfn = path.join(self.builder.outdir, '_images', outfname)\n\n    if path.isfile(outfullfn):\n        return outrelfn, outfullfn\n\n    ensuredir(path.dirname(outfullfn))\n\n    # ditaa expects UTF-8 by default\n    if isinstance(code, unicode):\n        code = code.encode('utf-8')\n\n    ditaa_args = [self.builder.config.ditaa]\n    ditaa_args.extend(self.builder.config.ditaa_args)\n    ditaa_args.extend(options)\n    ditaa_args.extend( [infullfn] )\n    ditaa_args.extend( [outfullfn] )\n\n    f = open(infullfn, 'w')\n    f.write(code)\n    f.close()\n\n    try:\n        self.builder.warn(ditaa_args)\n        p = Popen(ditaa_args, stdout=PIPE, stdin=PIPE, stderr=PIPE)\n    except OSError, err:\n        if err.errno != ENOENT:   # No such file or directory\n            raise\n        self.builder.warn('ditaa command %r cannot be run (needed for ditaa '\n                          'output), check the ditaa setting' %\n                          self.builder.config.ditaa)\n        self.builder._ditaa_warned_dot = True\n        return None, None\n    wentWrong = False\n    try:\n        # Ditaa may close standard input when an error occurs,\n        # resulting in a broken pipe on communicate()\n        stdout, stderr = p.communicate(code)\n    except OSError, err:\n        if err.errno != EPIPE:\n            raise\n        wentWrong = True\n    except IOError, err:\n        if err.errno != EINVAL:\n            raise\n        wentWrong = True\n    if wentWrong:\n        # in this case, read the standard output and standard error streams\n        # directly, to get the error message(s)\n        stdout, stderr = p.stdout.read(), p.stderr.read()\n        p.wait()\n    if p.returncode != 0:\n        raise DitaaError('ditaa exited with error:\\n[stderr]\\n%s\\n'\n                            '[stdout]\\n%s' % (stderr, stdout))\n    return outrelfn, outfullfn"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _atexit(self):\n        self.log.debug(\"Application._atexit\")\n        if self._atexit_func:\n            self._atexit_func(self)", "response": "Invoked in the finally block of Application. run."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the application and exits with the return value.", "response": "def run(self, args_list=None):\n        \"\"\"Run Application.main and exits with the return value.\"\"\"\n        self.log.debug(\"Application.run: {args_list}\".format(**locals()))\n        retval = None\n        try:\n            retval = self._run(args_list=args_list)\n        except KeyboardInterrupt:\n            self.log.verbose(\"Interrupted\")                    # pragma: nocover\n        except SystemExit as exit:\n            self.log.verbose(\"Exited\")\n            retval = exit.code\n        except Exception:\n            print(\"Uncaught exception\", file=sys.stderr)\n            traceback.print_exc()\n            if \"debug_pdb\" in self.args and self.args.debug_pdb:\n                debugger()\n            retval = Application.UNCAUGHT_EXCEPTION_EXIT\n            raise\n        finally:\n            try:\n                self._atexit()\n            finally:\n                sys.stderr.flush()\n                sys.stdout.flush()\n                sys.exit(retval)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cd(path):\n    old_path = os.getcwd()\n    os.chdir(path)\n    try:\n        yield\n    finally:\n        os.chdir(old_path)", "response": "Context manager that changes to directory path and return to CWD\n    when exited."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copytree(src, dst, symlinks=True):\n    from shutil import copy2, Error, copystat\n\n    names = os.listdir(src)\n\n    if not Path(dst).exists():\n        os.makedirs(dst)\n\n    errors = []\n    for name in names:\n        srcname = os.path.join(src, name)\n        dstname = os.path.join(dst, name)\n        try:\n            if symlinks and os.path.islink(srcname):\n                linkto = os.readlink(srcname)\n                os.symlink(linkto, dstname)\n            elif os.path.isdir(srcname):\n                copytree(srcname, dstname, symlinks)\n            else:\n                copy2(srcname, dstname)\n            # XXX What about devices, sockets etc.?\n        except OSError as why:\n            errors.append((srcname, dstname, str(why)))\n        # catch the Error from the recursive copytree so that we can\n        # continue with other files\n        except Error as err:\n            errors.extend(err.args[0])\n    try:\n        copystat(src, dst)\n    except OSError as why:\n        # can't copy file access times on Windows\n        if why.winerror is None:\n            errors.extend((src, dst, str(why)))\n    if errors:\n        raise Error(errors)", "response": "Modified from shutil. copytree docs code sample merges files rather than dst to not exist."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef debugger():\n    e, m, tb = sys.exc_info()\n    if tb is not None:\n        _debugger.post_mortem(tb)\n    else:\n        _debugger.set_trace()", "response": "Call post_mortem if called in the context of an exception. If called in the context of an exception calls set_trace."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a generator of all the keys in the cache.", "response": "def keys(self):\n        \"\"\"\n        Implements the dict.keys() method\n        \"\"\"\n        self.sync()\n        for k in self.db.keys():\n            try:\n                yield self.key_conv['from'](k)\n            except KeyError:\n                yield k"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_mtime(fname):\n        try:\n            mtime = os.stat(fname).st_mtime_ns\n        except OSError:\n            # The file might be right in the middle of being written\n            # so sleep\n            time.sleep(1)\n            mtime = os.stat(fname).st_mtime_ns\n\n        return mtime", "response": "Find the time this file was last modified."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_changed(self, item):\n        fname = os.path.join(self.fdir, item)\n        if os.path.isfile(fname):\n            mtime = self.get_mtime(fname)\n\n            try:\n                _ftime = self.fmtime[item]\n            except KeyError:  # Never been seen before\n                self.fmtime[item] = mtime\n                return True\n\n            if mtime > _ftime:  # has changed\n                self.fmtime[item] = mtime\n                return True\n            else:\n                return False\n        else:\n            logger.error('Could not access {}'.format(fname))\n            raise KeyError(item)", "response": "Find out if this item has been modified since last\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sync(self):\n        if not os.path.isdir(self.fdir):\n            os.makedirs(self.fdir)\n\n        for f in os.listdir(self.fdir):\n            fname = os.path.join(self.fdir, f)\n            if not os.path.isfile(fname):\n                continue\n            if f in self.fmtime:\n                if self.is_changed(f):\n                    self.db[f] = self._read_info(fname)\n            else:\n                mtime = self.get_mtime(fname)\n                self.db[f] = self._read_info(fname)\n                self.fmtime[f] = mtime", "response": "Goes through the directory and builds a local cache based on the content of the directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimplement the dict. items method.", "response": "def items(self):\n        \"\"\"\n        Implements the dict.items() method\n        \"\"\"\n        self.sync()\n        for k, v in self.db.items():\n            try:\n                yield self.key_conv['from'](k), v\n            except KeyError:\n                yield k, v"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear(self):\n        if not os.path.isdir(self.fdir):\n            os.makedirs(self.fdir, exist_ok=True)\n            return\n\n        for f in os.listdir(self.fdir):\n            del self[f]", "response": "Completely resets the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, ava):\n        for key, val in ava.items():\n            self[key] = val", "response": "Implements the dict. update method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a byte string of length 1 or 256.", "response": "def chr(x):\n    '''\n    x-->int / byte\n    Returns-->BYTE (not str in python3)\n        Behaves like PY2 chr() in PY2 or PY3\n    if x is str of length > 1 or int > 256\n        raises ValueError/TypeError is not SUPPRESS_ERRORS\n    '''\n    global _chr\n    if isinstance(x, int):\n        if x > 256:\n            if SUPPRESS_ERRORS:\n                x = x % 256\n        return toBytes(_chr(x))\n    elif isinstance(x, bytes):\n        x = fromBytes(x)\n        if len(x) > 1:\n            if not SUPPRESS_ERRORS:\n                raise TypeError('chr() found string of length > 2')\n            x = x[0]\n        return toBytes(x)\n    elif isinstance(x, str):\n        if len(x) > 1:\n            if not SUPPRESS_ERRORS:\n                raise TypeError('chr() found string of length > 2')\n            x = x[0]\n        return toBytes(x)\n    else:\n        raise TypeError('Unknown type passed to chr: %s', str(type(x)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the ord of the base64 - encoded version of the passed in object.", "response": "def ord(x):\n    '''\n    x-->char (str of length 1)\n    Returns-->int\n        Behaves like PY2 ord() in PY2 or PY3\n    if x is str of length > 1 or int > 256\n        raises ValueError/TypeError is not SUPPRESS_ERRORS\n    '''\n    global _ord\n    if isinstance(x, int):\n        if x > 256:\n            if not SUPPRESS_ERRORS:\n                raise ValueError('ord() arg not in range(256)')\n        return x % 256\n    elif isinstance(x, bytes):\n        x = fromBytes(x)\n        if len(x) > 1:\n            if SUPPRESS_ERRORS:\n                x = x[0]\n        return _ord(x)\n    elif isinstance(x, str):\n        if len(x) > 1:\n            if SUPPRESS_ERRORS:\n                x = x[0]\n        return _ord(x)\n    else:\n        raise TypeError('Unknown type passed to ord: %s', str(type(x)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hex(x):\n    '''\n    x-->bytes | bytearray\n    Returns-->bytes: hex-encoded\n    '''\n    if isinstance(x, bytearray):\n        x = bytes(x)\n    return encode(x, 'hex')", "response": "Returns a hex - encoded version of the input."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fromBytes(x):\n    '''\n    x-->unicode string | bytearray | bytes\n    Returns-->unicode string, with encoding=latin1\n    '''\n    if isinstance(x, unicode):\n        return x\n    if isinstance(x, bytearray):\n        x = bytes(x)\n    elif isinstance(x, bytes):\n        pass\n    else:\n        return x  # unchanged (int etc)\n    return decode(x, DEF_ENCODING)", "response": "Convert bytes to unicode string with encoding = latin1\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a byte string of the given object x.", "response": "def toBytes(x):\n    '''\n    x-->unicode string | bytearray | bytes\n    Returns-->bytes\n    If x is unicode, MUST have encoding=latin1\n    '''\n    if isinstance(x, bytes):\n        return x\n    elif isinstance(x, bytearray):\n        return bytes(x)\n    elif isinstance(x, unicode):\n        pass\n    else:\n        return x  # unchanged (int etc)\n    # ASSUMES latin1 encoding - Could raise an exception\n    return encode(x, DEF_ENCODING)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_rand_int(encoding='latin1', avoid=[]):\n    '''\n    encoding-->str: one of ENCODINGS\n    avoid-->list of int: to void (unprintable chars etc)\n    Returns-->int that can be converted to requested encoding\n              which is NOT in avoid\n    '''\n    UNICODE_LIMIT = 0x10ffff\n    # See: https://en.wikipedia.org/wiki/UTF-8#Invalid_code_points\n    SURROGATE_RANGE = (0xD800, 0xDFFF)\n    if encoding not in ENCODINGS:\n        raise ValueError('Unsupported encoding: ' + str(encoding))\n\n    if encoding == 'ascii':\n        maxord = 2 ** 7\n    elif encoding == 'latin1':\n        maxord = 2 ** 8\n    elif encoding == 'utf16':\n        maxord = 2 ** 16\n    elif encoding == 'utf8':\n        maxord = 2 ** 32\n    elif encoding == 'utf32':\n        maxord = 2 ** 32\n\n    rndint = random.randrange(0, min(maxord, UNICODE_LIMIT))\n    while (\n        (rndint in avoid) or\n        (SURROGATE_RANGE[0] <= rndint <= SURROGATE_RANGE[1])\n    ):\n        rndint = random.randrange(0, min(maxord, UNICODE_LIMIT))\n    return rndint", "response": "Get a random int from the set of available charset"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a random unicode string of the requested encoding", "response": "def get_rand_str(encoding='latin1', l=64, avoid=[]):\n    '''\n    encoding-->str: one of ENCODINGS\n    l-->int: length of returned str\n    avoid-->list of int: to void (unprintable chars etc)\n    Returns-->unicode str of the requested encoding\n    '''\n    ret = unicode('')\n    while len(ret) < l:\n        rndint = get_rand_int(encoding=encoding, avoid=avoid)\n        ret += unichr(rndint)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a random bytes from the current charset", "response": "def get_rand_bytes(encoding='latin1', l=64, avoid=[]):\n    '''\n    encoding-->str: one of ENCODINGS\n    l-->int: length of unicode str\n    avoid-->list of int: to void (unprintable chars etc)\n    Returns-->bytes representing unicode str of the requested encoding\n    '''\n    return encode(\n        get_rand_str(encoding=encoding, l=l, avoid=avoid),\n        encoding=encoding\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse argv for options and arguments, and start schema generation.", "response": "def main():\n    '''\n    Parse argv for options and arguments, and start schema generation.\n    '''\n    parser = optparse.OptionParser(usage=\"%prog [options] <model_path> [another_model_path...]\",\n                                   formatter=optparse.TitledHelpFormatter())\n                                   \n    parser.set_description(__doc__.strip())\n    \n    parser.add_option(\"-f\", \"--function\", dest=\"function\", metavar=\"NAME\",\n                      help=\"append integrity checking actions to functions named NAME (required)\",\n                      action=\"store\", default=None)\n    \n    parser.add_option(\"-o\", \"--output\", dest='output', metavar=\"PATH\",\n                      help=\"save sql model instances to PATH (required)\",\n                      action=\"store\", default=None)\n    \n    parser.add_option(\"-v\", \"--verbosity\", dest='verbosity', action=\"count\",\n                      help=\"increase debug logging level\", default=2)\n\n    \n    (opts, args) = parser.parse_args()\n    if len(args) == 0 or None in [opts.output, opts.function]:\n        parser.print_help()\n        sys.exit(1)\n\n    levels = {\n              0: logging.ERROR,\n              1: logging.WARNING,\n              2: logging.INFO,\n              3: logging.DEBUG,\n    }\n    logging.basicConfig(level=levels.get(opts.verbosity, logging.DEBUG))\n\n    m = ooaofooa.load_metamodel(args)\n    for c_c in m.select_many('C_C'):\n\n        filt = lambda sel: ooaofooa.is_contained_in(sel, c_c) and sel.Name == opts.function\n        s_sync = m.select_any('S_SYNC', filt)\n        if not s_sync:\n            s_sync = m.new('S_SYNC', Name=opts.function)\n            pe_pe = m.new('PE_PE')\n            s_dt = m.select_any('S_DT', where(Name='boolean'))\n            \n            relate(pe_pe, s_sync, 8001)\n            relate(s_dt, s_sync, 25)\n\n        generate_actions(m, c_c, s_sync)\n    \n    xtuml.persist_instances(m, opts.output)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrip the events from a given rss feed normalize the data and store the results in the ipdb database", "response": "def scrape(ctx, url):\n    \"\"\"\n    Rip the events from a given rss feed, normalize the data and store.\n    \"\"\"\n    data = load_feed(url)\n\n    feed = data['feed']\n    entries = data['entries']\n\n    # THIS IS SPECIFIC TO # http://konfery.cz/rss/\n\n    _type = 'community'\n    country = 'Czech Republic'\n    # title, title_detail, links, link, published, summary, tags\n    # unused: summary_detail, guidislink, published_parsed\n    for entry in entries:\n        _id = sluggify(entry['id'])\n        city = entry['tags'][0]['term']\n        landing = entry['link']\n        start_time = dt_normalize(entry['published_parsed'], local_tz=True)\n        title = entry['title']\n        summary = entry['summary']\n        link = entry['link']\n\n        ipdb.set_trace()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload the image and return the local path to the image file.", "response": "def download_image(self):\n        \"\"\"\n        Download the image and return the\n        local path to the image file.\n        \"\"\"\n        split = urlsplit(self.url)\n        filename = split.path.split(\"/\")[-1]\n\n        # Ensure the directory to store the image cache exists\n        if not os.path.exists(self.cache_directory):\n            os.makedirs(self.cache_directory)\n\n        filepath = os.path.join(self.cache_directory, filename)\n\n        data = urllib_request.urlopen(self.url)\n        with open(filepath, \"wb\") as image:\n            image.write(data.read())\n\n        return filepath"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_changed(self):\n        request = urllib_request.Request(self.url)\n        request.get_method = lambda: 'HEAD'\n\n        response = urllib_request.urlopen(request)\n        information = response.info()\n\n        if 'Last-Modified' in information:\n            last_modified = information['Last-Modified']\n\n            # Return False if the image has not been modified\n            if last_modified == self.image_last_modified:\n                return False\n\n        self.image_last_modified = last_modified\n\n        # Return True if the image has been modified\n        # or if the image has no last-modified header\n        return True", "response": "Check if an image has changed since it last downloaded."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def api_bikes(request):\n    postcode: Optional[str] = request.match_info.get('postcode', None)\n\n    try:\n        radius = int(request.match_info.get('radius', 10))\n    except ValueError:\n        raise web.HTTPBadRequest(text=\"Invalid Radius\")\n\n    try:\n        postcode = (await get_postcode_random()) if postcode == \"random\" else postcode\n        bikes = await get_bikes(postcode, radius)\n    except CachingError as e:\n        raise web.HTTPInternalServerError(text=e.status)\n    else:\n        if bikes is None:\n            raise web.HTTPNotFound(text=\"Post code does not exist.\")\n        else:\n            return str_json_response([bike.serialize() for bike in bikes])", "response": "Get stolen bikes within a given radius of a given postcode."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fancy_tag_compiler(params, defaults, takes_var_args, takes_var_kwargs, takes_context, name, node_class, parser, token):\n    \"Returns a template.Node subclass.\"\n    bits = token.split_contents()[1:]\n\n    if takes_context:\n        if 'context' in params[:1]:\n            params = params[1:]\n        else:\n            raise TemplateSyntaxError(\n                \"Any tag function decorated with takes_context=True \"\n                \"must have a first argument of 'context'\")\n\n    # Split args and kwargs\n    args = []\n    kwargs = {}\n    kwarg_found = False\n    unhandled_params = list(params)\n    handled_params = []\n    if len(bits) > 1 and bits[-2] == 'as':\n        output_var = bits[-1]\n        if len(set(output_var) - set(ALLOWED_VARIABLE_CHARS)) > 0:\n            raise TemplateSyntaxError(\"%s got output var name with forbidden chars: '%s'\" % (name, output_var))\n        bits = bits[:-2]\n    else:\n        output_var = None\n    for bit in bits:\n        kwarg_match = kwarg_re.match(bit)\n        if kwarg_match:\n            kw, var = kwarg_match.groups()\n            if kw not in params and not takes_var_kwargs:\n                raise TemplateSyntaxError(\"%s got unknown keyword argument '%s'\" % (name, kw))\n            elif kw in handled_params:\n                raise TemplateSyntaxError(\"%s got multiple values for keyword argument '%s'\" % (name, kw))\n            else:\n                kwargs[str(kw)] = var\n                kwarg_found = True\n                handled_params.append(kw)\n        else:\n            if kwarg_found:\n                raise TemplateSyntaxError(\"%s got non-keyword arg after keyword arg\" % name)\n            else:\n                args.append(bit)\n                try:\n                    handled_params.append(unhandled_params.pop(0))\n                except IndexError:\n                    if not takes_var_args:\n                        raise TemplateSyntaxError(\"%s got too many arguments\" % name)\n    # Consider the last n params handled, where n is the number of defaults.\n    if defaults is not None:\n        unhandled_params = unhandled_params[:-len(defaults)]\n    if len(unhandled_params) == 1:\n        raise TemplateSyntaxError(\"%s didn't get a value for argument '%s'\" % (name, unhandled_params[0]))\n    elif len(unhandled_params) > 1:\n        raise TemplateSyntaxError(\"%s didn't get values for arguments: %s\" % (\n                name, ', '.join([\"'%s'\" % p for p in unhandled_params])))\n\n    return node_class(args, kwargs, output_var, takes_context)", "response": "Returns a template. Node subclass."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup_file_logging(log_filename, log_file_level=\"DEBUG\", str_format=None,\n                       date_format=None, log_restart=False, log_history=False,\n                       formatter=None, silence_modules=None, log_filter=None):\n    \"\"\"\n    This will setup logging for a single file but can be called more than once\n    LOG LEVELS are \"CRITICAL\", \"ERROR\", \"INFO\", \"DEBUG\"\n    :param log_filename:    str of the file location\n    :param log_file_level   str of the log level to use on this file\n    :param str_format:      str of the logging format\n    :param date_format:     str of the date format\n    :param log_restart:     bool if True the log file will be deleted first\n    :param log_history:     bool if True will save another log file in a folder\n                            called history with the datetime\n    :param formatter:       logging.Format instance to use\n    :param log_filter:      logging.filter instance to add to handler\n    :param silence_modules  list of str of modules to silence\n    :return:                None\n    \"\"\"\n    from seaborn_timestamp.timestamp import datetime_to_str\n    if os.path.exists(log_filename) and log_restart:\n        os.remove(log_filename)\n\n    add_file_handler(log_file_level, log_filename, str_format=str_format,\n                     date_format=date_format, formatter=formatter,\n                     log_filter=log_filter)\n\n    if log_history:\n        base_name = os.path.basename(log_filename).split('.')[0] + \\\n                    '_%s' % datetime_to_str(str_format='%Y-%m-%d_%H-%M-%S')\n        history_log = os.path.join(os.path.dirname(log_filename),\n                                   'history', base_name + '.log')\n        add_file_handler(log_file_level, history_log, str_format=str_format,\n                         date_format=date_format, log_filter=log_filter)\n\n    silence_module_logging(silence_modules)", "response": "This function will setup logging for a single file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a handler to the Seaborn log file", "response": "def add_file_handler(log_file_level, log_filename, str_format=None,\n                     date_format=None, formatter=None, log_filter=None):\n    \"\"\"\n    :param log_filename:\n    :param log_file_level   str of the log level to use on this file\n    :param str_format:      str of the logging format\n    :param date_format:     str of the date format\n    :param log_restart:     bool if True the log file will be deleted first\n    :param log_history:     bool if True will save another log file in a folder\n                            called history with the datetime\n    :param formatter:       logging.Format instance to use\n    :param log_filter:      logging.filter instance to add to handler\n    :return:                None\n    \"\"\"\n    formatter = formatter or SeabornFormatter(str_format=str_format,\n                                              date_format=date_format)\n    mkdir_for_file(log_filename)\n\n    handler = logging.FileHandler(log_filename)\n    add_handler(log_file_level, handler, formatter, log_filter=log_filter)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_handler(log_handler_level, handler, formatter=None, log_filter=None):\n    handler.setLevel(log_handler_level)\n    if formatter is not None:\n        handler.setFormatter(formatter)\n    if log_filter is not None:\n        handler.addFilter(log_filter)\n    log.addHandler(handler)", "response": "Adds a handler to the log."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_module_log_level(modules=None, log_level=logging.WARNING):\n    modules = modules or []\n    if not isinstance(modules, list):\n        modules = [modules]\n    for module in modules:\n        logging.getLogger(module).setLevel(logging.WARNING)", "response": "This function will raise the log level for the given modules"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the caller so that we can note the source file name line number and function name.", "response": "def findCaller(self, stack_info=False):\n        \"\"\"\n        Find the stack frame of the caller so that we can note the source\n        file name, line number and function name.\n        \"\"\"\n        f = logging.currentframe()\n        # On some versions of IronPython, currentframe() returns None if\n        # IronPython isn't run with -X:Frames.\n        if f is not None:\n            f = f.f_back\n        rv = \"(unknown file)\", 0, \"(unknown function)\"\n        while hasattr(f, \"f_code\"):\n            co = f.f_code\n            filename = os.path.normcase(co.co_filename)\n            if filename == logging._srcfile or filename == self._srcfile:\n                f = f.f_back\n                continue\n            rv = (co.co_filename, f.f_lineno, co.co_name)\n            if stack_info:\n                sio = io.StringIO()\n                sio.write('Stack (most recent call last):\\n')\n                traceback.print_stack(f, file=sio)\n                sinfo = sio.getvalue()\n                if sinfo[-1] == '\\n':\n                    sinfo = sinfo[:-1]\n                sio.close()\n            break\n        return rv"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the C_C in which pe_pe is defined", "response": "def get_defining_component(pe_pe):\n    '''\n    get the C_C in which pe_pe is defined\n    '''\n    if pe_pe is None:\n        return None\n    \n    if pe_pe.__class__.__name__ != 'PE_PE':\n        pe_pe = xtuml.navigate_one(pe_pe).PE_PE[8001]()\n    \n    \n    ep_pkg = xtuml.navigate_one(pe_pe).EP_PKG[8000]()\n    if ep_pkg:\n        return get_defining_component(ep_pkg)\n    \n    return xtuml.navigate_one(pe_pe).C_C[8003]()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransform textual OAL actions of an instance to instances in the ooaofooa subsystems Value and Body.", "response": "def prebuild_action(instance):\n    '''\n    Transform textual OAL actions of an *instance* to instances in the ooaofooa\n    subsystems Value and Body. The provided *instance* must be an instance of \n    one of the following classes:\n    \n    - S_SYNC\n    - S_BRG\n    - O_TFR\n    - O_DBATTR\n    - SM_ACT\n    - SPR_RO\n    - SPR_RS\n    - SPR_PO\n    - SPR_PS\n    '''\n    walker_map = {\n        'S_SYNC': FunctionPrebuilder,\n        'S_BRG': BridgePrebuilder,\n        'O_TFR': OperationPrebuilder,\n        'O_DBATTR': DerivedAttributePrebuilder,\n        'SM_ACT': TransitionPrebuilder,\n        'SPR_RO': RequiredOperationPrebuilder,\n        'SPR_RS': RequiredSignalPrebuilder,\n        'SPR_PO': ProvidedOperationPrebuilder,\n        'SPR_PS': ProvidedSignalPrebuilder\n    }\n    metaclass = xtuml.get_metaclass(instance)\n    walker = walker_map[metaclass.kind](metaclass.metamodel, instance)\n    logger.info('processing action %s' % walker.label)\n    # walker.visitors.append(xtuml.tools.NodePrintVisitor())\n    root = oal.parse(instance.Action_Semantics_internal)\n    return walker.accept(root)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransforming textual OAL actions in a ooaofooa *metamodel* to instances in the subsystems Value and Body. Instances of the following classes are supported: - S_SYNC - S_BRG - O_TFR - O_DBATTR - SM_ACT - SPR_RO - SPR_RS - SPR_PO - SPR_PS", "response": "def prebuild_model(metamodel):\n    '''\n    Transform textual OAL actions in a ooaofooa *metamodel* to instances in the\n    subsystems Value and Body. Instances of the following classes are supported:\n    \n    - S_SYNC\n    - S_BRG\n    - O_TFR\n    - O_DBATTR\n    - SM_ACT\n    - SPR_RO\n    - SPR_RS\n    - SPR_PO\n    - SPR_PS\n    '''\n    for kind in ['S_SYNC','S_BRG','O_TFR', 'O_DBATTR', 'SM_ACT', 'SPR_RO',\n                 'SPR_RS', 'SPR_PO', 'SPR_PS']:\n        for inst in metamodel.select_many(kind):\n            if inst.Suc_Pars:\n                prebuild_action(inst)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses command line options and launch the prebuilder.", "response": "def main():\n    '''\n    Parse command line options and launch the prebuilder.\n    '''\n    parser = optparse.OptionParser(usage=\"%prog [options] <model_path> [another_model_path..]\",\n                                   version=xtuml.version.complete_string,\n                                   formatter=optparse.TitledHelpFormatter())\n\n    parser.add_option(\"-v\", \"--verbosity\", dest='verbosity',\n                                           action=\"count\",\n                                           help=\"increase debug logging level\",\n                                           default=1)\n    \n    parser.add_option(\"-o\", \"--output\", dest=\"output\", metavar=\"PATH\",\n                                        help=\"set output to PATH\",\n                                        action=\"store\",\n                                        default=None)\n    \n    (opts, args) = parser.parse_args()\n    if len(args) == 0 or opts.output is None:\n        parser.print_help()\n        sys.exit(1)\n        \n    levels = {\n              0: logging.ERROR,\n              1: logging.WARNING,\n              2: logging.INFO,\n              3: logging.DEBUG,\n    }\n    logging.basicConfig(level=levels.get(opts.verbosity, logging.DEBUG))\n    \n    m = ooaofooa.load_metamodel(args)\n    prebuild_model(m)\n    \n    xtuml.persist_instances(m, opts.output)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind a symbol in the symbol table by name and kind.", "response": "def find_symbol(self, name=None, kind=None):\n        '''\n        Find a symbol in the symbol table by name, kind, or both.\n        '''\n        for s in reversed(self.stack):\n                        \n            for symbol_name, handle in s.symbols.items():\n                symbol_kind = handle.__class__.__name__\n                \n                if name == symbol_name and kind == symbol_kind:\n                    return handle\n                \n                elif name is None and kind == handle.__class__.__name__:\n                    return handle\n                \n                elif name == symbol_name and kind is None:\n                    return handle\n            \n            if name is None and kind == s.handle.__class__.__name__:\n                return s.handle"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_membership(self, contact, group):\n        '''\n        input: gdata ContactEntry and GroupEntry objects\n        '''\n        if not contact:\n            log.debug('Not updating membership for EMPTY contact.')\n            return None\n        _uid = contact.email[0].address\n        _gtitle = group.title.text\n\n        for contact_group in contact.group_membership_info:\n            if contact_group.href == group.get_id():\n                log.warn(\n                    ' ... {} already a member of {}.'.format(_uid, _gtitle))\n                return contact\n\n        log.debug('Adding {} to group {}'.format(_uid, _gtitle))\n        membership = self.api.contacts.data.GroupMembershipInfo(\n            href=group.id.text)\n        contact.group_membership_info.append(membership)\n        contact = self.api.update(contact)\n        return contact", "response": "update membership of a group"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_contained_in(pe_pe, root):\n    '''\n    Determine if a PE_PE is contained within a EP_PKG or a C_C.\n    '''\n    if not pe_pe:\n        return False\n    \n    if type(pe_pe).__name__ != 'PE_PE':\n        pe_pe = one(pe_pe).PE_PE[8001]()\n    \n    ep_pkg = one(pe_pe).EP_PKG[8000]()\n    c_c = one(pe_pe).C_C[8003]()\n    \n    if root in [ep_pkg, c_c]:\n        return True\n    \n    elif is_contained_in(ep_pkg, root):\n        return True\n    \n    elif is_contained_in(c_c, root):\n        return True\n    \n    else:\n        return False", "response": "Determines if a PE_PE is contained within a EP_PKG or a C_C."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_global(pe_pe):\n    '''\n    Check if a PE_PE is globally defined, i.e. not inside a C_C\n    '''\n    if type(pe_pe).__name__ != 'PE_PE':\n        pe_pe = one(pe_pe).PE_PE[8001]()\n    \n    if one(pe_pe).C_C[8003]():\n        return False\n    \n    pe_pe = one(pe_pe).EP_PKG[8000].PE_PE[8001]()\n    if not pe_pe:\n        return True\n    \n    return is_global(pe_pe)", "response": "Check if a PE_PE is globally defined i. e. not inside a C_C\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the BridgePoint component that defines the packeable element *pe_pe*.", "response": "def get_defining_component(pe_pe):\n    '''\n    Get the BridgePoint component (C_C) that defines the packeable element\n    *pe_pe*.\n    '''\n    if pe_pe is None:\n        return None\n    \n    if type(pe_pe).__name__ != 'PE_PE':\n        pe_pe = one(pe_pe).PE_PE[8001]()\n    \n    ep_pkg = one(pe_pe).EP_PKG[8000]()\n    if ep_pkg:\n        return get_defining_component(ep_pkg)\n    \n    return one(pe_pe).C_C[8003]()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the base data type associated with a BridgePoint attribute.", "response": "def get_attribute_type(o_attr):\n    '''\n    Get the base data type (S_DT) associated with a BridgePoint attribute.\n    '''\n    ref_o_attr = one(o_attr).O_RATTR[106].O_BATTR[113].O_ATTR[106]()\n    if ref_o_attr:\n        return get_attribute_type(ref_o_attr)\n    else:\n        return one(o_attr).S_DT[114]()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a BridgePoint data type to a pyxtuml meta model type.", "response": "def _get_data_type_name(s_dt):\n    '''\n    Convert a BridgePoint data type to a pyxtuml meta model type.\n    '''\n    s_cdt = one(s_dt).S_CDT[17]()\n    if s_cdt and s_cdt.Core_Typ in range(1, 6):\n        return s_dt.Name.upper()\n    \n    if one(s_dt).S_EDT[17]():\n        return 'INTEGER'\n    \n    s_dt = one(s_dt).S_UDT[17].S_DT[18]()\n    if s_dt:\n        return _get_data_type_name(s_dt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_related_attributes(r_rgo, r_rto):\n    '''\n    The two lists of attributes which relates two classes in an association.\n    '''\n    l1 = list()\n    l2 = list()\n    \n    ref_filter = lambda ref: ref.OIR_ID == r_rgo.OIR_ID\n    for o_ref in many(r_rto).O_RTIDA[110].O_REF[111](ref_filter):\n        o_attr = one(o_ref).O_RATTR[108].O_ATTR[106]()\n        l1.append(o_attr.Name)\n        \n        o_attr = one(o_ref).O_RTIDA[111].O_OIDA[110].O_ATTR[105]()\n        l2.append(o_attr.Name)\n        \n    return l1, l2", "response": "Returns two lists of attributes which relates two classes in an association."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a named tuple from a BridgePoint enumeration.", "response": "def mk_enum(s_edt):\n    '''\n    Create a named tuple from a BridgePoint enumeration.\n    '''\n    s_dt = one(s_edt).S_DT[17]()\n    enums = list()\n    kwlist =['False', 'None', 'True'] + keyword.kwlist\n    for enum in many(s_edt).S_ENUM[27]():\n        if enum.Name in kwlist:\n            enums.append(enum.Name + '_')\n        else:\n            enums.append(enum.Name)\n            \n    Enum = collections.namedtuple(s_dt.Name, enums)\n    return Enum(*range(len(enums)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a python function from a BridgePoint bridge.", "response": "def mk_bridge(metamodel, s_brg):\n    '''\n    Create a python function from a BridgePoint bridge.\n    '''\n    action = s_brg.Action_Semantics_internal\n    label = s_brg.Name\n    return lambda **kwargs: interpret.run_function(metamodel, label, \n                                                   action, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mk_external_entity(metamodel, s_ee):\n    '''\n    Create a python object from a BridgePoint external entity with bridges\n    realized as python member functions.\n    '''\n    bridges = many(s_ee).S_BRG[19]()\n    names = [brg.Name for brg in bridges]\n    EE = collections.namedtuple(s_ee.Key_Lett, names)\n\n    funcs = list()\n    for s_brg in many(s_ee).S_BRG[19]():\n        fn = mk_bridge(metamodel, s_brg)\n        funcs.append(fn)\n\n    return EE(*funcs)", "response": "Create a python object from a BridgePoint external entity with bridges\n    realized as python member functions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mk_function(metamodel, s_sync):\n    '''\n    Create a python function from a BridgePoint function.\n    '''\n    action = s_sync.Action_Semantics_internal\n    label = s_sync.Name\n    return lambda **kwargs: interpret.run_function(metamodel, label, \n                                                   action, kwargs)", "response": "Create a python function from a BridgePoint function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a python value from a BridgePoint constant.", "response": "def mk_constant(cnst_syc):\n    '''\n    Create a python value from a BridgePoint constant.\n    '''\n    s_dt = one(cnst_syc).S_DT[1500]()\n    cnst_lsc = one(cnst_syc).CNST_LFSC[1502].CNST_LSC[1503]()\n    \n    if s_dt.Name == 'boolean':\n        return cnst_lsc.Value.lower() == 'true'\n    \n    if s_dt.Name == 'integer':\n        return int(cnst_lsc.Value)\n    \n    if s_dt.Name == 'real':\n        return float(cnst_lsc.Value)\n    \n    if s_dt.Name == 'string':\n        return str(cnst_lsc.Value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a python function that interprets that action of a BridgePoint class operation.", "response": "def mk_operation(metaclass, o_tfr):\n    '''\n    Create a python function that interprets that action of a BridgePoint class\n    operation.\n    '''\n    o_obj = one(o_tfr).O_OBJ[115]()\n    action = o_tfr.Action_Semantics_internal\n    label = '%s::%s' % (o_obj.Name, o_tfr.Name)\n    run = interpret.run_operation\n    \n    if o_tfr.Instance_Based:\n        return lambda self, **kwargs: run(metaclass, label, action, kwargs, self)\n    else:\n        fn = lambda cls, **kwargs: run(metaclass, label, action, kwargs, None)\n        return classmethod(fn)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a python property that interprets that action of a BridgePoint derived attribute.", "response": "def mk_derived_attribute(metaclass, o_dbattr):\n    '''\n    Create a python property that interprets that action of a BridgePoint derived\n    attribute.\n    '''\n    o_attr = one(o_dbattr).O_BATTR[107].O_ATTR[106]()\n    o_obj = one(o_attr).O_OBJ[102]()\n    action = o_dbattr.Action_Semantics_internal\n    label = '%s::%s' % (o_obj.Name, o_attr.Name)\n    fget = functools.partial(interpret.run_derived_attribute, metaclass, \n                             label, action, o_attr.Name)\n    return property(fget)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a pyxtuml class from a BridgePoint class.", "response": "def mk_class(m, o_obj, derived_attributes=False):\n    '''\n    Create a pyxtuml class from a BridgePoint class.\n    '''\n    first_filter = lambda selected: not one(selected).O_ATTR[103, 'succeeds']()\n    o_attr = one(o_obj).O_ATTR[102](first_filter)\n    attributes = list()\n        \n    while o_attr:\n        s_dt = get_attribute_type(o_attr)\n        ty = _get_data_type_name(s_dt)\n        if not derived_attributes and one(o_attr).O_BATTR[106].O_DBATTR[107]():\n            pass\n#            logger.warning('Omitting derived attribute %s.%s ' %\n#                           (o_obj.Key_Lett, o_attr.Name))\n        elif not ty:\n            logger.warning('Omitting unsupported attribute %s.%s ' %\n                           (o_obj.Key_Lett, o_attr.Name))\n        else:\n            attributes.append((o_attr.Name, ty))\n        \n        o_attr = one(o_attr).O_ATTR[103, 'precedes']()\n            \n    metaclass = m.define_class(o_obj.Key_Lett, list(attributes), o_obj.Descrip)\n\n    for o_id in many(o_obj).O_ID[104]():\n        o_oida = many(o_id).O_OIDA[105]()\n        o_attrs = many(o_oida).O_ATTR[105]()\n        if not derived_attributes and one(o_attrs).O_BATTR[106].O_DBATTR[107]():\n            logger.warning('Omitting unique identifier %s.I%d' %\n                           (o_obj.Key_Lett, o_id.Oid_ID + 1))\n            continue\n        \n        names = [o_attr.Name for o_attr in o_attrs]\n        m.define_unique_identifier(o_obj.Key_Lett, o_id.Oid_ID + 1, *names)\n    \n    for o_tfr in many(o_obj).O_TFR[115]():\n        fn = mk_operation(metaclass, o_tfr)\n        setattr(metaclass.clazz, o_tfr.Name, fn)\n        \n    for o_dbattr in many(o_obj).O_ATTR[102].O_BATTR[106].O_DBATTR[107]():\n        o_attr = one(o_dbattr).O_BATTR[107].O_ATTR[106]()\n        fn = mk_derived_attribute(metaclass, o_dbattr)\n        setattr(metaclass.clazz, o_attr.Name, fn)\n            \n    return metaclass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a pyxtuml association from a simple association in BridgePoint.", "response": "def mk_simple_association(m, r_simp):\n    '''\n    Create a pyxtuml association from a simple association in BridgePoint.\n    '''\n    r_rel = one(r_simp).R_REL[206]()\n\n    r_form = one(r_simp).R_FORM[208]()\n    r_part = one(r_simp).R_PART[207]()\n    \n    r_rgo = one(r_form).R_RGO[205]()\n    r_rto = one(r_part).R_RTO[204]()\n    \n    if not r_form:\n        logger.info('unformalized association R%s' % (r_rel.Numb))\n        r_form = one(r_simp).R_PART[207](lambda sel: sel != r_part)\n        r_rgo = one(r_form).R_RTO[204]()\n        \n    source_o_obj = one(r_rgo).R_OIR[203].O_OBJ[201]()\n    target_o_obj = one(r_rto).R_OIR[203].O_OBJ[201]()\n    source_ids, target_ids = _get_related_attributes(r_rgo, r_rto)\n\n    if source_o_obj.Obj_ID != target_o_obj.Obj_ID:\n        source_phrase = target_phrase = ''\n    else:\n        source_phrase = r_part.Txt_Phrs\n        target_phrase = r_form.Txt_Phrs\n            \n    m.define_association(rel_id=r_rel.Numb, \n                         source_kind=source_o_obj.Key_Lett,\n                         target_kind=target_o_obj.Key_Lett,\n                         source_keys=source_ids,\n                         target_keys=target_ids,\n                         source_conditional=r_form.Cond,\n                         target_conditional=r_part.Cond,\n                         source_phrase=source_phrase,\n                         target_phrase=target_phrase,\n                         source_many=r_form.Mult,\n                         target_many=r_part.Mult)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating pyxtuml associations from a linked association in BridgePoint.", "response": "def mk_linked_association(m, r_assoc):\n    '''\n    Create pyxtuml associations from a linked association in BridgePoint.\n    '''\n    r_rel = one(r_assoc).R_REL[206]()\n    r_rgo = one(r_assoc).R_ASSR[211].R_RGO[205]()\n    source_o_obj = one(r_rgo).R_OIR[203].O_OBJ[201]()\n    \n    def _mk_assoc(side1, side2):\n        r_rto = one(side1).R_RTO[204]()\n\n        target_o_obj = one(r_rto).R_OIR[203].O_OBJ[201]()\n        source_ids, target_ids = _get_related_attributes(r_rgo, r_rto)\n        if side1.Obj_ID != side2.Obj_ID:\n            source_phrase = target_phrase = ''\n        else:\n            source_phrase = side1.Txt_Phrs\n            target_phrase = side2.Txt_Phrs\n            \n        m.define_association(rel_id=r_rel.Numb, \n                             source_kind=source_o_obj.Key_Lett,\n                             target_kind=target_o_obj.Key_Lett,\n                             source_keys=source_ids,\n                             target_keys=target_ids,\n                             source_conditional=side2.Cond,\n                             target_conditional=False,\n                             source_phrase=source_phrase,\n                             target_phrase=target_phrase,\n                             source_many=side2.Mult,\n                             target_many=False)\n        \n    r_aone = one(r_assoc).R_AONE[209]()\n    r_aoth = one(r_assoc).R_AOTH[210]()\n    \n    _mk_assoc(r_aone, r_aoth)\n    _mk_assoc(r_aoth, r_aone)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mk_subsuper_association(m, r_subsup):\n    '''\n    Create pyxtuml associations from a sub/super association in BridgePoint.\n    '''\n    r_rel = one(r_subsup).R_REL[206]()\n    r_rto = one(r_subsup).R_SUPER[212].R_RTO[204]()\n    target_o_obj = one(r_rto).R_OIR[203].O_OBJ[201]()\n    \n    for r_sub in many(r_subsup).R_SUB[213]():\n        r_rgo = one(r_sub).R_RGO[205]()\n\n        source_o_obj = one(r_rgo).R_OIR[203].O_OBJ[201]()\n        source_ids, target_ids = _get_related_attributes(r_rgo, r_rto)\n        m.define_association(rel_id=r_rel.Numb, \n                             source_kind=source_o_obj.Key_Lett,\n                             target_kind=target_o_obj.Key_Lett,\n                             source_keys=source_ids,\n                             target_keys=target_ids,\n                             source_conditional=True,\n                             target_conditional=False,\n                             source_phrase='',\n                             target_phrase='',\n                             source_many=False,\n                             target_many=False)", "response": "Create pyxtuml associations from a sub - super association in BridgePoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mk_association(m, r_rel):\n    '''\n    Create a pyxtuml association from a R_REL in ooaofooa.\n    '''\n    handler = {\n        'R_SIMP': mk_simple_association,\n        'R_ASSOC': mk_linked_association,\n        'R_SUBSUP': mk_subsuper_association,\n        'R_COMP': mk_derived_association,\n    }\n    inst = subtype(r_rel, 206)\n    fn = handler.get(type(inst).__name__)\n    return fn(m, inst)", "response": "Create a pyxtuml association from a R_REL in ooaofooa.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mk_component(bp_model, c_c=None, derived_attributes=False):\n    '''\n    Create a pyxtuml meta model from a BridgePoint model. \n    Optionally, restrict to classes and associations contained in the\n    component c_c.\n    '''\n    target = Domain()\n\n    c_c_filt = lambda sel: c_c is None or is_contained_in(sel, c_c)\n    \n    for o_obj in bp_model.select_many('O_OBJ', c_c_filt):\n        mk_class(target, o_obj, derived_attributes)\n        \n    for r_rel in bp_model.select_many('R_REL', c_c_filt):\n        mk_association(target, r_rel)\n        \n    for s_sync in bp_model.select_many('S_SYNC', c_c_filt):\n        fn = mk_function(target, s_sync)\n        target.add_symbol(s_sync.Name, fn)\n    \n    for s_dt in bp_model.select_many('S_DT', c_c_filt):\n        s_edt = one(s_dt).S_EDT[17]()\n        if s_edt:\n            enum = mk_enum(s_edt)\n            target.add_symbol(s_dt.Name, enum)\n        \n    for cnst_csp in bp_model.select_many('CNST_CSP', c_c_filt):\n        for cnst_syc in many(cnst_csp).CNST_SYC[1504]():\n            value = mk_constant(cnst_syc)\n            target.add_symbol(cnst_syc.Name, value)\n        \n    for ass in target.associations:\n        ass.formalize()\n    \n    for s_ee in bp_model.select_many('S_EE', c_c_filt):\n        if s_ee.Key_Lett in ['LOG', 'ARCH', 'TIM', 'NVS', 'PERSIST']:\n            target.add_symbol(s_ee.Key_Lett, getattr(builtin_ee, s_ee.Key_Lett))\n                              \n        else:\n            ee = mk_external_entity(target, s_ee)\n            target.add_symbol(s_ee.Key_Lett, ee)\n    \n    return target", "response": "Create a pyxtuml meta model from a BridgePoint model."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_metamodel(resource=None, load_globals=True):\n    '''\n    Load and return a metamodel expressed in ooaofooa from a *resource*.\n    The resource may be either a filename, a path, or a list of filenames\n    and/or paths.\n    '''\n    loader = _mk_loader(resource, load_globals)\n    return loader.build_metamodel()", "response": "Load and return a metamodel expressed in ooaofooa from a resource."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_component(resource, name=None, load_globals=True):\n    '''\n    Load and return a model from a *resource*. The resource may be either a\n    filename, a path, or a list of filenames and/or paths.\n    '''\n    loader = _mk_loader(resource, load_globals)\n    return loader.build_component()", "response": "Load and return a model from a resource."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove global instances from the core data type integer.", "response": "def delete_globals(m, disconnect=False):\n    '''\n    Remove global instances, e.g. the core data type integer.\n    '''\n    filt = lambda sel: (247728914420827907967735776184937480192 <= \n                        sel.DT_ID <= \n                        247728914420827907967735776184937480208)\n\n    for s_dt in m.select_many('S_DT', filt):\n        xtuml.delete(one(s_dt).PE_PE[8001](), disconnect)\n        xtuml.delete(subtype(s_dt, 17), disconnect)\n        xtuml.delete(s_dt, disconnect)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nopening and read input from a path or filename and parse its content.", "response": "def filename_input(self, path_or_filename):\n        '''\n        Open and read input from a *path or filename*, and parse its content.\n        \n        If the filename is a directory, files that ends with .xtuml located\n        somewhere in the directory or sub directories will be loaded as well.\n        '''\n        if os.path.isdir(path_or_filename):\n            for path, _, files in os.walk(path_or_filename):\n                for name in files:\n                    if name.endswith('.xtuml'):\n                        xtuml.ModelLoader.filename_input(self, os.path.join(path, name))\n        else:\n            xtuml.ModelLoader.filename_input(self, path_or_filename)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef default_malformed_message_handler(worker, exc_info, message_parts):\n    exc_type, exc, tb = exc_info\n    exc_strs = traceback.format_exception_only(exc_type, exc)\n    exc_str = exc_strs[0].strip()\n    if len(exc_strs) > 1:\n        exc_str += '...'\n    warn('<%s> occurred by %r' % (exc_str, message_parts), MalformedMessage)", "response": "The default malformed message handler for Worker."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall a function and sends results to the collector.", "response": "def work(self, socket, call, args, kwargs, topics=()):\n        \"\"\"Calls a function and send results to the collector.  It supports\n        all of function actions.  A function could return, yield, raise any\n        packable objects.\n        \"\"\"\n        task_id = uuid4_bytes()\n        reply_socket, topics = self.replier(socket, topics, call.reply_to)\n        if reply_socket:\n            channel = (call.call_id, task_id, topics)\n        else:\n            channel = (None, None, None)\n        f, rpc_spec = self.find_call_target(call)\n        if rpc_spec.reject_if.__get__(self.app)(call, topics):\n            reply_socket and self.reject(reply_socket, call.call_id, topics)\n            return\n        reply_socket and self.accept(reply_socket, channel)\n        success = False\n        with self.catch_exceptions():\n            try:\n                val = self.call(call, args, kwargs, f, rpc_spec)\n            except:\n                exc_info = sys.exc_info()\n                self.raise_(reply_socket, channel, exc_info)\n                reraise(*exc_info)\n            success = True\n        if not success:\n            # catch_exceptions() hides exceptions.\n            return\n        if isinstance(val, Iterator):\n            vals = val\n            with self.catch_exceptions():\n                try:\n                    try:\n                        val = next(vals)\n                    except StopIteration:\n                        pass\n                    else:\n                        self.send_reply(reply_socket, YIELD, val, *channel)\n                        for val in vals:\n                            self.send_reply(reply_socket, YIELD, val, *channel)\n                    self.send_reply(reply_socket, BREAK, None, *channel)\n                except:\n                    exc_info = sys.exc_info()\n                    self.raise_(reply_socket, channel, exc_info)\n                    reraise(*exc_info)\n        else:\n            self.send_reply(reply_socket, RETURN, val, *channel)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef accept(self, reply_socket, channel):\n        info = self.info or b''\n        self.send_raw(reply_socket, ACCEPT, info, *channel)", "response": "Sends an ACCEPT reply."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends an exception reply.", "response": "def raise_(self, reply_socket, channel, exc_info=None):\n        \"\"\"Sends RAISE reply.\"\"\"\n        if not reply_socket:\n            return\n        if exc_info is None:\n            exc_info = sys.exc_info()\n        exc_type, exc, tb = exc_info\n        while tb.tb_next is not None:\n            tb = tb.tb_next\n        if issubclass(exc_type, RemoteException):\n            exc_type = exc_type.exc_type\n        filename, lineno = tb.tb_frame.f_code.co_filename, tb.tb_lineno\n        val = (exc_type, str(exc), filename, lineno)\n        try:\n            state = exc.__getstate__()\n        except AttributeError:\n            pass\n        else:\n            val += (state,)\n        self.send_reply(reply_socket, RAISE, val, *channel)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _call_wait(self, hints, name, args, kwargs, topics=(), raw=False,\n                   limit=None, retry=False, max_retries=None):\n        \"\"\"Allocates a call id and emit.\"\"\"\n        col = self.collector\n        if not col.is_running():\n            col.start()\n        call_id = uuid4_bytes()\n        reply_to = (DUPLEX if self.socket is col.socket else col.topic)\n        # Normal tuple is faster than namedtuple.\n        header = self._make_header(name, call_id, reply_to, hints)\n        payload = self._pack(args, kwargs, raw)\n        # Use short names.\n        def send_call():\n            try:\n                safe(send, self.socket, header, payload, topics, zmq.NOBLOCK)\n            except zmq.Again:\n                raise Undelivered('emission was not delivered')\n        col.prepare(call_id, self, name, args, kwargs)\n        send_call()\n        return col.establish(call_id, self.timeout, limit,\n                             send_call if retry else None,\n                             max_retries=max_retries)", "response": "Allocates a call id and emit it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef establish(self, call_id, timeout, limit=None,\n                  retry=None, max_retries=None):\n        \"\"\"Waits for the call is accepted by workers and starts to collect the\n        results.\n        \"\"\"\n        rejected = 0\n        retried = 0\n        results = []\n        result_queue = self.result_queues[call_id]\n        try:\n            with Timeout(timeout, False):\n                while True:\n                    result = result_queue.get()\n                    if result is None:\n                        rejected += 1\n                        if retry is not None:\n                            if retried == max_retries:\n                                break\n                            retry()\n                            retried += 1\n                        continue\n                    results.append(result)\n                    if len(results) == limit:\n                        break\n        finally:\n            del result_queue\n            self.remove_result_queue(call_id)\n        if not results:\n            if rejected:\n                raise Rejected('%d workers rejected' % rejected\n                               if rejected != 1 else\n                               'A worker rejected')\n            else:\n                raise WorkerNotFound('failed to find worker')\n        return results", "response": "Establishes a call to the worker and returns the list of results."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dispatch_reply(self, reply, value):\n        method = reply.method\n        call_id = reply.call_id\n        task_id = reply.task_id\n        if method & ACK:\n            try:\n                result_queue = self.result_queues[call_id]\n            except KeyError:\n                raise KeyError('already established or unprepared call')\n            if method == ACCEPT:\n                worker_info = value\n                result = RemoteResult(self, call_id, task_id, worker_info)\n                self.results[call_id][task_id] = result\n                result_queue.put_nowait(result)\n            elif method == REJECT:\n                result_queue.put_nowait(None)\n        else:\n            result = self.results[call_id][task_id]\n            result.set_reply(reply.method, value)", "response": "Dispatches the reply to the proper queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nguesses the type name of a serialized value.", "response": "def guess_type_name(value):\n    '''\n    Guess the type name of a serialized value.\n    '''\n    value = str(value)\n    \n    if value.upper() in ['TRUE', 'FALSE']:\n        return 'BOOLEAN'\n    \n    elif re.match(r'(-)?(\\d+)(\\.\\d+)', value):\n        return 'REAL'\n    \n    elif re.match(r'(-)?(\\d+)', value):\n        return 'INTEGER'\n    \n    elif re.match(r'\\'((\\'\\')|[^\\'])*\\'', value):\n        return 'STRING'\n    \n    elif re.match(r'\\\"([^\\\\\\n]|(\\\\.))*?\\\"', value):\n        return 'UNIQUE_ID'"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deserialize_value(ty, value):\n    '''\n    Deserialize a value of some type\n    '''\n    uty = ty.upper()\n    \n    if uty == 'BOOLEAN':\n        if value.isdigit():\n            return bool(int(value))\n        elif value.upper() == 'FALSE':\n            return False\n        elif value.upper() == 'TRUE':\n            return True\n        else:\n            return None\n    \n    elif uty == 'INTEGER': \n        if '\"' in value:\n            return uuid.UUID(value[1:-1]).int\n        else:\n            return int(value)\n    \n    elif uty == 'REAL': \n        return float(value)\n    \n    elif uty == 'STRING': \n        return value[1:-1].replace(\"''\", \"'\")\n    \n    elif uty == 'UNIQUE_ID': \n        if '\"' in value:\n            return uuid.UUID(value[1:-1]).int\n        else:\n            return int(value)", "response": "Deserialize a value of some type returning a value of some type"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading and return a metamodel from a file or list of filenames.", "response": "def load_metamodel(resource):\n    '''\n    Load and return a metamodel from a *resource*. The *resource* may be either\n    a filename, or a list of filenames.\n    \n    Usage example:\n    \n    >>> metamodel = xtuml.load_metamodel(['schema.sql', 'data.sql'])\n    '''\n    if isinstance(resource, str):\n        resource = [resource]\n        \n    loader = ModelLoader()\n    for filename in resource:\n        loader.filename_input(filename)\n    \n    return loader.build_metamodel()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef input(self, data, name='<string>'):\n        '''\n        Parse *data* directly from a string. The *name* is used when reporting\n        positional information if the parser encounter syntax errors.\n        '''\n        lexer = lex.lex(debuglog=logger,\n                        errorlog=logger,\n                        optimize=1,\n                        module=self,\n                        outputdir=os.path.dirname(__file__),\n                        lextab=\"xtuml.__xtuml_lextab\")\n        lexer.filename = name\n        logger.debug('parsing %s' % name)\n        s = self.parser.parse(lexer=lexer, input=data, tracking=1)\n        self.statements.extend(s)", "response": "Parse data directly from a string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef file_input(self, file_object):\n        '''\n        Read and parse data from a *file object*, i.e. the type of object \n        returned by the builtin python function *open()*.\n        '''\n        return self.input(file_object.read(), name=file_object.name)", "response": "Read and parse data from a file object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef populate_classes(self, metamodel):\n        '''\n        Populate a *metamodel* with classes previously encountered from input.\n        '''\n        for stmt in self.statements:\n            if isinstance(stmt, CreateClassStmt):\n                metamodel.define_class(stmt.kind, stmt.attributes)", "response": "Populate a metamodel with classes previously encountered from input."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef populate_associations(self, metamodel):\n        '''\n        Populate a *metamodel* with associations previously encountered from\n        input.\n        '''\n        for stmt in self.statements:\n            if not isinstance(stmt, CreateAssociationStmt):\n                continue\n            \n            ass = metamodel.define_association(stmt.rel_id,\n                                         stmt.source_kind,\n                                         stmt.source_keys,\n                                         'M' in stmt.source_cardinality,\n                                         'C' in stmt.source_cardinality,\n                                         stmt.source_phrase,\n                                         stmt.target_kind,\n                                         stmt.target_keys,\n                                         'M' in stmt.target_cardinality,\n                                         'C' in stmt.target_cardinality,\n                                         stmt.target_phrase)\n            ass.formalize()", "response": "Populate a metamodel with associations previously encountered from the input."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef populate_unique_identifiers(self, metamodel):\n        '''\n        Populate a *metamodel* with class unique identifiers previously\n        encountered from input.\n        '''\n        for stmt in self.statements:\n            if isinstance(stmt, CreateUniqueStmt):\n                metamodel.define_unique_identifier(stmt.kind, stmt.name, \n                                                   *stmt.attributes)", "response": "Populate a metamodel with class unique identifiers previously acquired from input."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npopulate a metamodel with a class that matches the given insert statement*.", "response": "def _populate_matching_class(metamodel, kind, names, values):\n        '''\n        Populate a *metamodel* with a class that matches the given *insert\n        statement*.\n        '''\n        attributes = list()\n        for name, value in zip(names, values):\n            ty = guess_type_name(value)\n            attr = (name, ty)\n            attributes.append(attr)\n                \n        return metamodel.define_class(kind, attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npopulating a metamodel with an instance previously encountered from input that was defined using positional arguments.", "response": "def _populate_instance_with_positional_arguments(metamodel, stmt):\n        '''\n        Populate a *metamodel* with an instance previously encountered from \n        input that was defined using positional arguments.\n        '''\n        if stmt.kind.upper() not in metamodel.metaclasses:\n            names = ['_%s' % idx for idx in range(len(stmt.values))]\n            ModelLoader._populate_matching_class(metamodel, stmt.kind, \n                                                 names, stmt.values)\n            \n        metaclass = metamodel.find_metaclass(stmt.kind)\n        if len(metaclass.attributes) != len(stmt.values):\n            logger.warn('%s:%d:schema mismatch' % (stmt.filename, stmt.lineno))\n                \n        inst = metamodel.new(stmt.kind)\n        for attr, value in zip(metaclass.attributes, stmt.values):\n            name, ty = attr\n            py_value = deserialize_value(ty, value)\n            if py_value is None:\n                raise ParsingException(\"%s:%d:unable to deserialize \"\\\n                                       \"%s to a %s\" % (stmt.filename,\n                                                       stmt.lineno,\n                                                       value,\n                                                       ty))\n\n            inst.__dict__[name] = py_value\n        \n        return inst"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npopulates a metamodel with an instance previously encountered from input that was defined using named arguments.", "response": "def _populate_instance_with_named_arguments(metamodel, stmt):\n        '''\n        Populate a *metamodel* with an instance previously encountered from \n        input that was defined using named arguments.\n        '''\n        if stmt.kind.upper() not in metamodel.metaclasses:\n            ModelLoader._populate_matching_class(metamodel, stmt.kind, \n                                                 stmt.names, stmt.values)\n            \n        metaclass = metamodel.find_metaclass(stmt.kind)\n            \n        schema_unames = [name.upper() for name in metaclass.attribute_names]\n        inst_unames = [name.upper() for name in stmt.names]\n        \n        if set(inst_unames) - set(schema_unames):\n            logger.warn('%s:%d:schema mismatch' % (stmt.filename, stmt.lineno))\n            \n        inst = metamodel.new(stmt.kind)\n        for name, ty in metaclass.attributes:\n            uname = name.upper()\n            if uname in inst_unames:\n                idx = inst_unames.index(uname)\n                value = deserialize_value(ty, stmt.values[idx])\n                if value is None:\n                    raise ParsingException(\"%s:%d:unable to deserialize \"\\\n                                           \"%s to a %s\" % (stmt.filename,\n                                                           stmt.lineno,\n                                                           value,\n                                                           ty))\n            else:\n                value = None\n            \n            inst.__dict__[name] = value\n\n        return inst"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npopulating a metamodel with instances previously encountered from input.", "response": "def populate_instances(self, metamodel):\n        '''\n        Populate a *metamodel* with instances previously encountered from\n        input.\n        '''\n        for stmt in self.statements:\n            if not isinstance(stmt, CreateInstanceStmt):\n                continue\n            \n            if stmt.names:\n                fn = self._populate_instance_with_named_arguments\n            else:\n                fn = self._populate_instance_with_positional_arguments\n            \n            fn(metamodel, stmt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef populate_connections(self, metamodel):\n        '''\n        Populate links in a *metamodel* with connections between them.\n        '''\n        storage = dict()\n        for ass in metamodel.associations:\n            source_class = ass.source_link.to_metaclass\n            target_class = ass.target_link.to_metaclass\n\n            if target_class not in storage:\n                storage[target_class] = dict()\n            \n            link_key = frozenset(ass.source_link.key_map.values())\n            if link_key not in storage[target_class]:\n                storage[target_class][link_key] = dict()\n                for other_inst in target_class.storage:\n                    inst_key = ass.source_link.compute_index_key(other_inst)\n                    if inst_key is None:\n                        continue\n                    \n                    if inst_key not in storage[target_class][link_key]:\n                        storage[target_class][link_key][inst_key] = xtuml.OrderedSet()\n\n                    storage[target_class][link_key][inst_key].add(other_inst)\n\n            for inst in source_class.storage:\n                inst_key = ass.source_link.compute_lookup_key(inst)\n                if inst_key is None:\n                    continue\n                \n                if inst_key not in storage[target_class][link_key]:\n                    continue\n                \n                for other_inst in storage[target_class][link_key][inst_key]:\n                    ass.source_link.connect(other_inst, inst, check=False)\n                    ass.target_link.connect(inst, other_inst, check=False)\n\n        for inst in metamodel.instances:\n            metaclass = xtuml.get_metaclass(inst)\n            for attr in metaclass.referential_attributes:\n                if attr in inst.__dict__:\n                    delattr(inst, attr)", "response": "Populate links in a metamodel with connections between them."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npopulates a given metamodel with entities previously encountered from input.", "response": "def populate(self, metamodel):\n        '''\n        Populate a *metamodel* with entities previously encountered from input.\n        '''\n        self.populate_classes(metamodel)\n        self.populate_unique_identifiers(metamodel)\n        self.populate_associations(metamodel)\n        self.populate_instances(metamodel)\n        self.populate_connections(metamodel)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild and return a *xtuml. MetaModel* containing previously loaded input.", "response": "def build_metamodel(self, id_generator=None):\n        '''\n        Build and return a *xtuml.MetaModel* containing previously loaded input.\n        '''\n        m = xtuml.MetaModel(id_generator)\n        \n        self.populate(m)\n        \n        return m"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef t_LPAREN(self, t):\n        r'\\('\n        t.endlexpos = t.lexpos + len(t.value)\n        return t", "response": "t_LPAREN is used to mark the end of the tag as being a list of names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef t_RPAREN(self, t):\n        r'\\)'\n        t.endlexpos = t.lexpos + len(t.value)\n        return t", "response": "t_RPAREN is used to mark the end of the tag name as being used"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef t_SEMICOLON(self, t):\n        r';'\n        t.endlexpos = t.lexpos + len(t.value)\n        return t", "response": "r Trailing semicolon is a no - op"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the SEMICOLONCOOKIECOOKIE statement.", "response": "def p_statement(self, p):\n        '''\n        statement : create_table_statement SEMICOLON\n                  | insert_into_statement SEMICOLON\n                  | create_rop_statement SEMICOLON\n                  | create_index_statement SEMICOLON\n        '''\n        p[0] = p[1]\n        p[0].offset = p.lexpos(1)\n        p[0].lineno = p.lineno(1)\n        p[0].filename = p.lexer.filename"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses CREATE ROP REF_ID RELID FROM association_end TO association_end", "response": "def p_create_rop_statement(self, p):\n        '''create_rop_statement : CREATE ROP REF_ID RELID FROM association_end TO association_end'''\n        args = [p[4]]\n        args.extend(p[6])\n        args.extend(p[8])\n        p[0] = CreateAssociationStmt(*args)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a cardinality 1", "response": "def p_cardinality_1(self, p):\n        '''cardinality : NUMBER'''\n        if p[1] != '1':\n            raise ParsingException(\"illegal cardinality (%s) at %s:%d\" % (p[1],\n                                   p.lexer.filename, p.lineno(1)))\n        p[0] = p[1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_cardinality_many(self, p):\n        '''cardinality : ID'''\n        if p[1] not in ['M', 'MC']:\n            raise ParsingException(\"illegal cardinality (%s) at %s:%d\" % (p[1],\n                                   p.lexer.filename, p.lineno(1)))\n        p[0] = p[1]", "response": "Parse a cardinality many."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef append_known_secrets(self):  # type: () -> None\n        for file_name in self.files:\n            if \"~\" in file_name:\n                file_name = os.path.expanduser(file_name)\n            if not os.path.isfile(file_name):\n                print(\n                    \"Don't have \"\n                    + Back.BLACK\n                    + Fore.YELLOW\n                    + file_name\n                    + \", won't use.\"\n                )\n                continue\n            with open(os.path.expanduser(file_name), \"r\") as file:\n                for line in file:\n                    if line and \"=\" in line:\n                        possible = line.split(\"=\")[1].strip(\" \\\"'\\n\")\n                        if len(possible) > 4 and possible not in self.false_positives:\n                            self.secrets.append(possible)", "response": "Read key - value pair files with secrets. For example. conf and. ini files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching a path for known secrets outputing text and file when found is True", "response": "def search_known_secrets(self):  # type: () -> None\n        \"\"\"\n        Search a path for known secrets, outputing text and file when found\n        :return:\n        \"\"\"\n        count = 0\n        here = os.path.abspath(self.source)\n        # python 3 only!\n        # for file in glob.glob(here + \"/\" + \"**/*.*\", recursive=True):\n\n        # py 2\n        matches = []\n        for root, dirnames, filenames in os.walk(here + \"/\"):\n            for filename in filenames:\n                matches.append(os.path.join(root, filename))\n\n        for file in matches:\n            if os.path.isdir(file):\n                continue\n            with open(file) as f:\n                try:\n                    contents = f.read()\n                except UnicodeDecodeError:\n                    continue\n                except Exception as e:\n                    print(e)\n                    print(file)\n                    raise\n            for secret in self.secrets:\n                if secret in contents:\n                    for line in contents.split(\"\\n\"):\n                        if secret in line:\n                            self.found.setdefault(file, []).append(\n                                (\n                                    secret,\n                                    line.replace(\n                                        secret,\n                                        Fore.RED\n                                        + Back.YELLOW\n                                        + secret\n                                        + Style.RESET_ALL,\n                                    ),\n                                )\n                            )\n                            count += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef eid(s):\n    '''Encode id (bytes) as a Unicode string.\n\n    The encoding is done such that lexicographic order is\n    preserved. No concern is given to wasting space.\n\n    The inverse of ``eid`` is ``did``.\n    '''\n    if isinstance(s, unicode):\n        s = s.encode('utf-8')\n    return u''.join('{:02x}'.format(ord(b)) for b in s)", "response": "Encode id bytes as a Unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef did(s):\n    '''Decode id (Unicode string) as a bytes.\n\n    The inverse of ``did`` is ``eid``.\n    '''\n    return ''.join(chr(int(s[i:i+2], base=16)) for i in xrange(0, len(s), 2))", "response": "Decode id as a bytes.\n    The inverse of did is eid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, content_id, feature_names=None):\n        '''Retrieve a feature collection.\n\n        If a feature collection with the given id does not\n        exist, then ``None`` is returned.\n\n        :param str content_id: Content identifier.\n        :param [str] feature_names:\n          A list of feature names to retrieve. When ``None``, all\n          features are retrieved. Wildcards are allowed.\n        :rtype: :class:`dossier.fc.FeatureCollection` or ``None``\n        '''\n        try:\n            resp = self.conn.get(index=self.index, doc_type=self.type,\n                                 id=eid(content_id),\n                                 _source=self._source(feature_names))\n            return self.fc_from_dict(resp['_source']['fc'])\n        except NotFoundError:\n            return None\n        except:\n            raise", "response": "Retrieve a feature collection with the given id."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_many(self, content_ids, feature_names=None):\n        '''Returns an iterable of feature collections.\n\n        This efficiently retrieves multiple FCs corresponding to the\n        list of ids given. Tuples of identifier and feature collection\n        are yielded. If the feature collection for a given id does not\n        exist, then ``None`` is returned as the second element of the\n        tuple.\n\n        :param [str] content_ids: List of content ids.\n        :param [str] feature_names:\n          A list of feature names to retrieve. When ``None``, all\n          features are retrieved. Wildcards are allowed.\n        :rtype: Iterable of ``(content_id, FC)``\n        '''\n        try:\n            resp = self.conn.mget(index=self.index, doc_type=self.type,\n                                  _source=self._source(feature_names),\n                                  body={'ids': map(eid, content_ids)})\n        except TransportError:\n            return\n        for doc in resp['docs']:\n            fc = None\n            if doc['found']:\n                fc = self.fc_from_dict(doc['_source']['fc'])\n            yield did(doc['_id']), fc", "response": "Returns an iterable of feature collections corresponding to the content_ids given."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef put(self, items, indexes=True):\n        '''Adds feature collections to the store.\n\n        This efficiently adds multiple FCs to the store. The iterable\n        of ``items`` given should yield tuples of ``(content_id, FC)``.\n\n        :param items: Iterable of ``(content_id, FC)``.\n        :param [str] feature_names:\n          A list of feature names to retrieve. When ``None``, all\n          features are retrieved. Wildcards are allowed.\n        '''\n        actions = []\n        for cid, fc in items:\n            # TODO: If we store features in a columnar order, then we\n            # could tell ES to index the feature values directly. ---AG\n            # (But is problematic because we want to preserve the ability\n            # to selectively index FCs. So we'd probably need two distinct\n            # doc types.)\n            idxs = defaultdict(list)\n            if indexes:\n                for fname in self.indexed_features:\n                    if fname in fc:\n                        idxs[fname_to_idx_name(fname)].extend(fc[fname])\n                for fname in self.fulltext_indexed_features:\n                    if fname not in fc:\n                        continue\n                    if isinstance(fc[fname], basestring):\n                        idxs[fname_to_full_idx_name(fname)] = fc[fname]\n                    else:\n                        idxs[fname_to_full_idx_name(fname)].extend(fc[fname])\n            actions.append({\n                '_index': self.index,\n                '_type': self.type,\n                '_id': eid(cid),\n                '_op_type': 'index',\n                '_source': dict(idxs, **{\n                    'fc': self.fc_to_dict(fc),\n                }),\n            })\n        bulk(self.conn, actions, timeout=60, request_timeout=60)", "response": "Adds multiple FCs to the store. This efficiently adds multiple FCs to the store. The iterable items given should yield tuples of content_id FC names and FCs names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, content_id):\n        '''Deletes the corresponding feature collection.\n\n        If the FC does not exist, then this is a no-op.\n        '''\n        try:\n            self.conn.delete(index=self.index, doc_type=self.type,\n                             id=eid(content_id))\n        except NotFoundError:\n            pass", "response": "Deletes the corresponding feature collection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_all(self):\n        '''Deletes all feature collections.\n\n        This does not destroy the ES index, but instead only\n        deletes all FCs with the configured document type\n        (defaults to ``fc``).\n        '''\n        try:\n            self.conn.indices.delete_mapping(\n                index=self.index, doc_type=self.type)\n        except TransportError:\n            logger.warn('type %r in index %r already deleted',\n                        self.index, self.type, exc_info=True)", "response": "Deletes all feature collections."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes the underlying ES index.", "response": "def delete_index(self):\n        '''Deletes the underlying ES index.\n\n        Only use this if you know what you're doing. This destroys\n        the entire underlying ES index, which could be shared by\n        multiple distinct ElasticStore instances.\n        '''\n        if self.conn.indices.exists(index=self.index):\n            self.conn.indices.delete(index=self.index)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nscanning for FCs in the given id ranges.", "response": "def scan(self, *key_ranges, **kwargs):\n        '''Scan for FCs in the given id ranges.\n\n        :param key_ranges:\n          ``key_ranges`` should be a list of pairs of ranges. The first\n          value is the lower bound id and the second value is the\n          upper bound id. Use ``()`` in either position to leave it\n          unbounded. If no ``key_ranges`` are given, then all FCs in\n          the store are returned.\n        :param [str] feature_names:\n          A list of feature names to retrieve. When ``None``, all\n          features are retrieved. Wildcards are allowed.\n        :rtype: Iterable of ``(content_id, FC)``\n        '''\n        for hit in self._scan(*key_ranges, **kwargs):\n            yield did(hit['_id']), self.fc_from_dict(hit['_source']['fc'])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scan_ids(self, *key_ranges, **kwargs):\n        '''Scan for ids only in the given id ranges.\n\n        :param key_ranges:\n          ``key_ranges`` should be a list of pairs of ranges. The first\n          value is the lower bound id and the second value is the\n          upper bound id. Use ``()`` in either position to leave it\n          unbounded. If no ``key_ranges`` are given, then all FCs in\n          the store are returned.\n        :param [str] feature_names:\n          A list of feature names to retrieve. When ``None``, all\n          features are retrieved. Wildcards are allowed.\n        :rtype: Iterable of ``content_id``\n        '''\n        kwargs['feature_names'] = False\n        for hit in self._scan(*key_ranges, **kwargs):\n            yield did(hit['_id'])", "response": "Scan for ids only in the given id ranges."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nscanning for FCs with a given prefix.", "response": "def scan_prefix(self, prefix, feature_names=None):\n        '''Scan for FCs with a given prefix.\n\n        :param str prefix: Identifier prefix.\n        :param [str] feature_names:\n          A list of feature names to retrieve. When ``None``, all\n          features are retrieved. Wildcards are allowed.\n        :rtype: Iterable of ``(content_id, FC)``\n        '''\n        resp = self._scan_prefix(prefix, feature_names=feature_names)\n        for hit in resp:\n            yield did(hit['_id']), self.fc_from_dict(hit['_source']['fc'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef scan_prefix_ids(self, prefix):\n        '''Scan for ids with a given prefix.\n\n        :param str prefix: Identifier prefix.\n        :param [str] feature_names:\n          A list of feature names to retrieve. When ``None``, all\n          features are retrieved. Wildcards are allowed.\n        :rtype: Iterable of ``content_id``\n        '''\n        resp = self._scan_prefix(prefix, feature_names=False)\n        for hit in resp:\n            yield did(hit['_id'])", "response": "Scan for ids with a given prefix."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fulltext_scan(self, query_id=None, query_fc=None, feature_names=None,\n                      preserve_order=True, indexes=None):\n        '''Fulltext search.\n\n        Yields an iterable of triples (score, identifier, FC)\n        corresponding to the search results of the fulltext search\n        in ``query``. This will only search text indexed under the\n        given feature named ``fname``.\n\n        Note that, unless ``preserve_order`` is set to True, the\n        ``score`` will always be 0.0, and the results will be\n        unordered. ``preserve_order`` set to True will cause the\n        results to be scored and be ordered by score, but you should\n        expect to see a decrease in performance.\n\n        :param str fname:\n          The feature to search.\n        :param unicode query:\n          The query.\n        :param [str] feature_names:\n          A list of feature names to retrieve. When ``None``, all\n          features are retrieved. Wildcards are allowed.\n        :rtype: Iterable of ``(score, content_id, FC)``\n        '''\n        it = self._fulltext_scan(query_id, query_fc,\n                                 feature_names=feature_names,\n                                 preserve_order=preserve_order,\n                                 indexes=indexes)\n        for hit in it:\n            fc = self.fc_from_dict(hit['_source']['fc'])\n            yield hit['_score'], did(hit['_id']), fc", "response": "Fulltext search.\n\n        Yields an iterable of triples (score, identifier, FC)\n        corresponding to the search results of the fulltext search\n        in ``query``. This will only search text indexed under the\n        given feature named ``fname``.\n\n        Note that, unless ``preserve_order`` is set to True, the\n        ``score`` will always be 0.0, and the results will be\n        unordered. ``preserve_order`` set to True will cause the\n        results to be scored and be ordered by score, but you should\n        expect to see a decrease in performance.\n\n        :param str fname:\n          The feature to search.\n        :param unicode query:\n          The query.\n        :param [str] feature_names:\n          A list of feature names to retrieve. When ``None``, all\n          features are retrieved. Wildcards are allowed.\n        :rtype: Iterable of ``(score, content_id, FC)``"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlow - level keyword index scan for ids.", "response": "def index_scan_ids(self, fname, val):\n        '''Low-level keyword index scan for ids.\n\n        Retrieves identifiers of FCs that have a feature value\n        ``val`` in the feature named ``fname``. Note that\n        ``fname`` must be indexed.\n\n        :param str fname: Feature name.\n        :param str val: Feature value.\n        :rtype: Iterable of ``content_id``\n        '''\n        disj = []\n        for fname2 in self.indexes[fname]['feature_names']:\n            disj.append({'term': {fname_to_idx_name(fname2): val}})\n        query = {\n            'constant_score': {\n                'filter': {'or': disj},\n            },\n        }\n        hits = scan(self.conn, index=self.index, doc_type=self.type, query={\n            '_source': False,\n            'query': query,\n        })\n        for hit in hits:\n            yield did(hit['_id'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmap feature names to ES s _source field.", "response": "def _source(self, feature_names):\n        '''Maps feature names to ES's \"_source\" field.'''\n        if feature_names is None:\n            return True\n        elif isinstance(feature_names, bool):\n            return feature_names\n        else:\n            return map(lambda n: 'fc.' + n, feature_names)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating ES filters for key ranges used in scanning.", "response": "def _range_filters(self, *key_ranges):\n        'Creates ES filters for key ranges used in scanning.'\n        filters = []\n        for s, e in key_ranges:\n            if isinstance(s, basestring):\n                s = eid(s)\n            if isinstance(e, basestring):\n                # Make the range inclusive.\n                # We need a valid codepoint, so use the max.\n                e += u'\\U0010FFFF'\n                e = eid(e)\n\n            if s == () and e == ():\n                filters.append({'match_all': {}})\n            elif e == ():\n                filters.append({'range': {'_id': {'gte': s}}})\n            elif s == ():\n                filters.append({'range': {'_id': {'lte': e}}})\n            else:\n                filters.append({'range': {'_id': {'gte': s, 'lte': e}}})\n        if len(filters) == 0:\n            return [{'match_all': {}}]\n        else:\n            return filters"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate the field type mapping.", "response": "def _create_mappings(self):\n        'Create the field type mapping.'\n        self.conn.indices.put_mapping(\n            index=self.index, doc_type=self.type,\n            timeout=60, request_timeout=60,\n            body={\n                self.type: {\n                    'dynamic_templates': [{\n                        'default_no_analyze_fc': {\n                            'match': 'fc.*',\n                            'mapping': {'index': 'no'},\n                        },\n                    }],\n                    '_all': {\n                        'enabled': False,\n                    },\n                    '_id': {\n                        'index': 'not_analyzed',  # allows range queries\n                    },\n                    'properties': self._get_index_mappings(),\n                },\n            })\n        # It is possible to create an index and quickly launch a request\n        # that will fail because the index hasn't been set up yet. Usually,\n        # you'll get a \"no active shards available\" error.\n        #\n        # Since index creation is a very rare operation (it only happens\n        # when the index doesn't already exist), we sit and wait for the\n        # cluster to become healthy.\n        self.conn.cluster.health(index=self.index, wait_for_status='yellow')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the field mappings. Useful for debugging.", "response": "def _get_index_mappings(self):\n        'Retrieve the field mappings. Useful for debugging.'\n        maps = {}\n        for fname in self.indexed_features:\n            config = self.indexes.get(fname, {})\n            print(fname, config)\n            maps[fname_to_idx_name(fname)] = {\n                'type': config.get('es_index_type', 'integer'),\n                'store': False,\n                'index': 'not_analyzed',\n            }\n        for fname in self.fulltext_indexed_features:\n            maps[fname_to_full_idx_name(fname)] = {\n                'type': 'string',\n                'store': False,\n                'index': 'analyzed',\n            }\n        return maps"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the field types. Useful for debugging.", "response": "def _get_field_types(self):\n        'Retrieve the field types. Useful for debugging.'\n        mapping = self.conn.indices.get_mapping(\n            index=self.index, doc_type=self.type)\n        return mapping[self.index]['mappings'][self.type]['properties']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _fc_index_disjunction_from_query(self, query_fc, fname):\n        'Creates a disjunction for keyword scan queries.'\n        if len(query_fc.get(fname, [])) == 0:\n            return []\n        terms = query_fc[fname].keys()\n\n        disj = []\n        for fname in self.indexes[fname]['feature_names']:\n            disj.append({'terms': {fname_to_idx_name(fname): terms}})\n        return disj", "response": "Creates a disjunction for keyword scan queries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fc_bytes(self, fc_dict):\n        '''Take a feature collection in dict form and count its size in bytes.\n\n        '''\n        num_bytes = 0\n        for _, feat in fc_dict.iteritems():\n            num_bytes += len(feat)\n        return num_bytes", "response": "Take a feature collection in dict form and count its size in bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncounting the number of bytes of all feature collections whose key satisfies one of the predicates in filter_preds.", "response": "def count_bytes(self, filter_preds):\n        '''Count bytes of all feature collections whose key satisfies one of\n        the predicates in ``filter_preds``. The byte counts are binned\n        by filter predicate.\n        '''\n        num_bytes = defaultdict(int)\n        for hit in self._scan():\n            for filter_pred in filter_preds:\n                if filter_pred(did(hit['_id'])):\n                    num_bytes[filter_pred] += self.fc_bytes(\n                        hit['_source']['fc'])\n        return num_bytes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing a nice looking string for an FC", "response": "def pretty_string(fc):\n    '''construct a nice looking string for an FC\n    '''\n    s = []\n    for fname, feature in sorted(fc.items()):\n        if isinstance(feature, StringCounter):\n            feature = [u'%s: %d' % (k, v)\n                       for (k,v) in feature.most_common()]\n            feature = u'\\n\\t' + u'\\n\\t'.join(feature)\n        s.append(fname + u': ' + feature)\n    return u'\\n'.join(s)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_lib_ffi_resource(module_name, libpath, c_hdr):\n    '''\n    module_name-->str: module name to retrieve resource\n    libpath-->str: shared library filename with optional path\n    c_hdr-->str: C-style header definitions for functions to wrap\n    Returns-->(ffi, lib)\n\n    Use this method when you are loading a package-specific shared library\n    If you want to load a system-wide shared library, use get_lib_ffi_shared\n    instead\n    '''\n    lib = SharedLibWrapper(libpath, c_hdr, module_name=module_name)\n    ffi = lib.ffi\n    return (ffi, lib)", "response": "Returns the shared library and the resource for the given module_name and libpath."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the shared library and the C - style header definitions for functions to wrap.", "response": "def get_lib_ffi_shared(libpath, c_hdr):\n    '''\n    libpath-->str: shared library filename with optional path\n    c_hdr-->str: C-style header definitions for functions to wrap\n    Returns-->(ffi, lib)\n    '''\n    lib = SharedLibWrapper(libpath, c_hdr)\n    ffi = lib.ffi\n    return (ffi, lib)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __openlib(self):\n        '''\n        Actual (lazy) dlopen() only when an attribute is accessed\n        '''\n        if self.__getattribute__('_libloaded'):\n            return\n        libpath_list = self.__get_libres()\n        for p in libpath_list:\n            try:\n                libres = resource_filename(self._module_name, p)\n                self.lib = self.ffi.dlopen(libres)\n                return\n            except:\n                continue\n        # Try self._libpath if nothing in libpath_list worked - will work\n        # only if self._module_name is set\n        try:\n            libres = resource_filename(self._module_name, self._libpath)\n            self.lib = self.ffi.dlopen(libres)\n        except:\n            # If self._module_name is in sys.modules, try self._libpath\n            # in the same dir as sys.modules[self._module_name].__file__\n            # This is allows get_lib_ffi_shared to work in REPL\n            try:\n                # We set _libloaded to indicate all options have been tried\n                self._libloaded = True\n\n                libdir = ''\n                if self._module_name is not None:\n                    mod = sys.modules.get(self._module_name, None)\n                    if mod is not None:\n                        libdir = os.path.dirname(mod.__file__) or os.getcwd()\n\n                libres = os.path.join(libdir, self._libpath)\n                self.lib = self.ffi.dlopen(libres)\n            except:\n                return None", "response": "Internal method to open the lib file for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the libpath of the shared library for the current module.", "response": "def __get_libres(self):\n        '''\n        Computes libpath based on whether module_name is set or not\n        Returns-->list of str lib paths to try\n\n        PEP3140: ABI version tagged .so files:\n            https://www.python.org/dev/peps/pep-3149/\n\n        There's still one unexplained bit: pypy adds '-' + sys._multiarch()\n        at the end (looks like 'x86_64-linux-gnu'), but neither py2 or py3 do\n\n        Additionally, in older releases of pypy (e.g. build f3ad1e1e1d62\n        Aug-28-2015), sysconfig.get_config_var('SOABI') returns '' but\n        shared library still has '.pypy-26' in the name!\n\n        So for pypy we try this this variant anyway!\n\n        _I_ think Py2 and Py3 _MAY_ start adding sys._multiarch at some time\n\n        So, we generate three forms:\n            1. With sys._multiarch\n            2. Without sys._multiarch\n            3. libpath as-is - always tried by self.__openlib anyway\n        For different versions we try in different order (for efficiency):\n            Python2                 Python3                 Pypy\n\n            2 --> 1 --> 3           2 --> 1 --> 3           1 --> 2 --> 3\n        '''\n        if self._module_name is None:\n            return []\n        ending = '.so'\n        base = self._libpath.rsplit(ending, 1)[0]\n        abi = sysconfig.get_config_var('SOABI')\n        if abi is not None:\n            abi = '.' + abi\n        else:\n            abi = ''\n\n        multi_arch = sysconfig.get_config_var('MULTIARCH')\n        if multi_arch is None:\n            multi_arch = ''\n        else:\n            multi_arch = '-' + multi_arch\n\n        if PYPY:\n            n1 = base + abi + multi_arch + ending\n            n2 = base + abi + ending\n        else:\n            n1 = base + abi + ending\n            n2 = base + abi + multi_arch + ending\n        if PYPY:\n            n3 = base + '.pypy-26' + ending\n            return [n1, n2, n3]\n        else:\n            return [n1, n2]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses command line options and go to the next section.", "response": "def process_docopts():  # type: ()->None\n    \"\"\"\n    Take care of command line options\n    \"\"\"\n\n    arguments = docopt(__doc__, version=\"Find Known Secrets {0}\".format(__version__))\n\n    logger.debug(arguments)\n    # print(arguments)\n    if arguments[\"here\"]:\n        # all default\n        go()\n    else:\n        # user config\n        files = arguments[\"--secrets\"]\n\n        searcher = Searcher(source=arguments[\"--source\"], files=files)\n        searcher.go()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets data from a postcode.", "response": "async def api_postcode(request):\n    \"\"\"\n    Gets data from a postcode.\n    :param request: The aiohttp request.\n    \"\"\"\n    postcode: Optional[str] = request.match_info.get('postcode', None)\n\n    try:\n        coroutine = get_postcode_random() if postcode == \"random\" else get_postcode(postcode)\n        postcode: Optional[Postcode] = await coroutine\n    except CachingError as e:\n        return web.HTTPInternalServerError(body=e.status)\n    except CircuitBreakerError as e:\n        pass\n    else:\n        if postcode is not None:\n            return str_json_response(postcode.serialize())\n        else:\n            return web.HTTPNotFound(body=\"Invalid Postcode\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget wikipedia articles near a given postcode.", "response": "async def api_nearby(request):\n    \"\"\"\n    Gets wikipedia articles near a given postcode.\n    :param request: The aiohttp request.\n    \"\"\"\n    postcode: Optional[str] = request.match_info.get('postcode', None)\n\n    try:\n        limit = int(request.match_info.get('limit', 10))\n    except ValueError:\n        raise web.HTTPBadRequest(text=\"Invalid Limit\")\n\n    try:\n        coroutine = get_postcode_random() if postcode == \"random\" else get_postcode(postcode)\n        postcode: Optional[Postcode] = await coroutine\n    except CachingError as e:\n        raise web.HTTPInternalServerError(body=e.status)\n\n    if postcode is None:\n        raise web.HTTPNotFound(text=\"Invalid Postcode\")\n\n    try:\n        nearby_items = await fetch_nearby(postcode.lat, postcode.long, limit)\n    except ApiError:\n        return web.HTTPInternalServerError(text=f\"No nearby locations cached, and can't be retrieved.\")\n\n    if nearby_items is None:\n        raise web.HTTPNotFound(text=\"No Results\")\n    else:\n        return str_json_response(nearby_items)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nescape the error and wrap it in a span with class error - message", "response": "def default_formatter(error):\n    \"\"\"Escape the error, and wrap it in a span with class ``error-message``\"\"\"\n    quoted = formencode.htmlfill.escape_formatter(error)\n    return u'<span class=\"error-message\">{0}</span>'.format(quoted)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pretty_to_link(inst, link):\n    '''\n    Create a human-readable representation of a link on the 'TO'-side\n    '''\n    values = ''\n    prefix = ''\n    metaclass = xtuml.get_metaclass(inst)\n\n    for name, ty in metaclass.attributes:\n        if name in link.key_map:\n            value = getattr(inst, name)\n            value = xtuml.serialize_value(value, ty)\n            name = link.key_map[name]\n            values += '%s%s=%s' % (prefix, name, value)\n            prefix = ', '\n                \n    return '%s(%s)' % (link.kind, values)", "response": "Create a human - readable representation of a link on the TO - side\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pretty_unique_identifier(inst, identifier):\n    '''\n    Create a human-readable representation a unique identifier.\n    '''\n    values = ''\n    prefix = ''\n    metaclass = xtuml.get_metaclass(inst)\n    \n    for name, ty in metaclass.attributes:\n        if name in metaclass.identifying_attributes:\n            value = getattr(inst, name)\n            value = xtuml.serialize_value(value, ty)\n            values += '%s%s=%s' % (prefix, name, value)\n            prefix = ', '\n                    \n    return '%s(%s)' % (identifier, values)", "response": "Create a human - readable representation a unique identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_uniqueness_constraint(m, kind=None):\n    '''\n    Check the model for uniqueness constraint violations.\n    '''\n    if kind is None:\n        metaclasses = m.metaclasses.values()\n    else:\n        metaclasses = [m.find_metaclass(kind)]\n    \n    res = 0\n    for metaclass in metaclasses:\n        id_map = dict()\n        for identifier in metaclass.indices:\n            id_map[identifier] = dict()\n                \n        for inst in metaclass.select_many():\n            # Check for null-values\n            for name, ty in metaclass.attributes:\n                if name not in metaclass.identifying_attributes:\n                    continue\n                \n                value = getattr(inst, name)\n                isnull = value is None\n                isnull |= (ty == 'UNIQUE_ID' and not value)\n                if isnull:\n                    res += 1 \n                    logger.warning('%s.%s is part of an identifier and is null' \n                                   % (metaclass.kind, name))\n\n            # Check uniqueness\n            for identifier in metaclass.indices:\n                kwargs = dict()\n                for name in metaclass.indices[identifier]:\n                    kwargs[name] = getattr(inst, name)\n\n                index_key = frozenset(kwargs.items())\n                if index_key in id_map[identifier]:\n                    res += 1\n                    id_string = pretty_unique_identifier(inst, identifier)\n                    logger.warning('uniqueness constraint violation in %s, %s' \n                                   % (metaclass.kind, id_string))\n\n                id_map[identifier][index_key] = inst\n\n    return res", "response": "Check the model for uniqueness constraint violations."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks the model for integrity violations on an association in a particular direction.", "response": "def check_link_integrity(m, link):\n    '''\n    Check the model for integrity violations on an association in a particular direction.\n    '''\n    res = 0\n    for inst in link.from_metaclass.select_many():\n        q_set = list(link.navigate(inst))\n\n        if(len(q_set) < 1 and not link.conditional) or (\n          (len(q_set) > 1 and not link.many)):\n            res += 1\n            logger.warning('integrity violation in '\n                           '%s --(%s)--> %s' % (pretty_from_link(inst, link),\n                                                link.rel_id,\n                                                pretty_to_link(inst, link)))\n    \n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking the model for integrity violations across a subtype association.", "response": "def check_subtype_integrity(m, super_kind, rel_id):\n    '''\n    Check the model for integrity violations across a subtype association.\n    '''\n    if isinstance(rel_id, int):\n        rel_id = 'R%d' % rel_id\n\n    res = 0\n    for inst in m.select_many(super_kind):\n        if not xtuml.navigate_subtype(inst, rel_id):\n            res += 1\n            logger.warning('integrity violation across '\n                           '%s[%s]' % (super_kind, rel_id))\n        \n    return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks the model for integrity violations on association ( s.", "response": "def check_association_integrity(m, rel_id=None):\n    '''\n    Check the model for integrity violations on association(s).\n    '''\n    if isinstance(rel_id, int):\n        rel_id = 'R%d' % rel_id\n            \n    res = 0\n    for ass in m.associations:\n        if rel_id in [ass.rel_id, None]:\n            res += check_link_integrity(m, ass.source_link)\n            res += check_link_integrity(m, ass.target_link)\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef only_module(*modules):\n    modules = (modules and isinstance(modules[0], list)) and \\\n              modules[0] or modules\n    for module in modules:\n        if not module in ONLY_MODULES:\n            ONLY_MODULES.append(module)\n    traceback.extract_tb = _new_extract_tb", "response": "This will exclude all modules from the traceback except these modules"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef skip_path(*paths):\n    paths = (paths and isinstance(paths[0], list)) and paths[0] or paths\n    for path in paths:\n        if not path in SKIPPED_PATHS:\n            SKIPPED_PATHS.append(path)\n    traceback.extract_tb = _new_extract_tb", "response": "This will exclude all modules that start from this path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef feature_index(*feature_names):\n    '''Returns a index creation function.\n\n    Returns a valid index ``create`` function for the feature names\n    given. This can be used with the :meth:`Store.define_index`\n    method to create indexes on any combination of features in a\n    feature collection.\n\n    :type feature_names: list(unicode)\n    :rtype: ``(val -> index val)\n              -> (content_id, FeatureCollection)\n              -> generator of [index val]``\n    '''\n    def _(trans, (cid, fc)):\n        for fname in feature_names:\n            feat = fc.get(fname)\n            if feat is None:\n                continue\n            elif isinstance(feat, unicode):\n                yield trans(feat)\n            else:  # string counter, sparse/dense vector\n                for val in feat.iterkeys():\n                    yield trans(val)\n    return _", "response": "Returns a valid index creation function for the feature names\n    given."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, content_id):\n        '''Retrieve a feature collection from the store.  This is the same as\n        get_many([content_id])\n\n        If the feature collection does not exist ``None`` is\n        returned.\n\n        :type content_id: str\n        :rtype: :class:`dossier.fc.FeatureCollection`\n\n        '''\n        rows = list(self.kvl.get(self.TABLE, (content_id,)))\n        assert len(rows) < 2, 'more than one FC with the same content id'\n        if len(rows) == 0 or rows[0][1] is None:\n            return None\n        return fc_loads(rows[0][1])", "response": "Retrieve a feature collection from the store. This is the same as get_one [ content_id ]."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nyielding content_id and data for a list of content_ids.", "response": "def get_many(self, content_id_list):\n        '''Yield (content_id, data) tuples for ids in list.\n\n        As with :meth:`get`, if a content_id in the list is missing,\n        then it is yielded with a data value of `None`.\n\n        :type content_id_list: list<str>\n        :rtype: yields tuple(str, :class:`dossier.fc.FeatureCollection`)\n\n        '''\n        content_id_keys = [tuplify(x) for x in content_id_list]\n        for row in self.kvl.get(self.TABLE, *content_id_keys):\n            content_id = row[0][0]\n            data = row[1]\n            if data is not None:\n                data = fc_loads(data)\n            yield (content_id, data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds feature collections to the store.", "response": "def put(self, items, indexes=True):\n        '''Add feature collections to the store.\n\n        Given an iterable of tuples of the form\n        ``(content_id, feature collection)``, add each to the store\n        and overwrite any that already exist.\n\n        This method optionally accepts a keyword argument `indexes`,\n        which by default is set to ``True``. When it is ``True``,\n        it will *create* new indexes for each content object for all\n        indexes defined on this store.\n\n        Note that this will not update existing indexes. (There is\n        currently no way to do this without running some sort of\n        garbage collection process.)\n\n        :param iterable items: iterable of\n                               ``(content_id, FeatureCollection)``.\n        :type fc: :class:`dossier.fc.FeatureCollection`\n        '''\n        # So why accept an iterable? Ideally, some day, `kvlayer.put` would\n        # accept an iterable, so we should too.\n        #\n        # But we have to transform it to a list in order to update indexes\n        # anyway. Well, if we don't have to update indexes, then we can avoid\n        # loading everything into memory, which seems like an optimization\n        # worth having even if it's only some of the time.\n        #\n        # N.B. If you're thinking, \"Just use itertools.tee\", then you should\n        # heed this warning from Python docs: \"This itertool may require\n        # significant auxiliary storage (depending on how much temporary data\n        # needs to be stored). In general, if one iterator uses most or all of\n        # the data before another iterator starts, it is faster to use list()\n        # instead of tee().\"\n        #\n        # i.e., `tee` has to store everything into memory because `kvlayer`\n        # will exhaust the first iterator before indexes get updated.\n        items = list(items)\n        self.kvl.put(self.TABLE,\n                     *imap(lambda (cid, fc): ((cid,), fc_dumps(fc)), items))\n        if indexes:\n            for idx_name in self._indexes:\n                self._index_put(idx_name, *items)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scan(self, *key_ranges):\n        '''Retrieve feature collections in a range of ids.\n\n        Returns a generator of content objects corresponding to the\n        content identifier ranges given. `key_ranges` can be a possibly\n        empty list of 2-tuples, where the first element of the tuple\n        is the beginning of a range and the second element is the end\n        of a range. To specify the beginning or end of the table, use\n        an empty tuple `()`.\n\n        If the list is empty, then this yields all content objects in\n        the storage.\n\n        :param key_ranges: as described in\n                           :meth:`kvlayer._abstract_storage.AbstractStorage`\n        :rtype: generator of\n                (``content_id``, :class:`dossier.fc.FeatureCollection`).\n        '''\n        # (id, id) -> ((id,), (id,))\n        key_ranges = [(tuplify(s), tuplify(e)) for s, e in key_ranges]\n        return imap(lambda (cid, fc): (cid[0], fc_loads(fc)),\n                    self.kvl.scan(self.TABLE, *key_ranges))", "response": "Retrieve feature collections in a range of ids."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scan_ids(self, *key_ranges):\n        '''Retrieve content ids in a range of ids.\n\n        Returns a generator of ``content_id`` corresponding to the\n        content identifier ranges given. `key_ranges` can be a possibly\n        empty list of 2-tuples, where the first element of the tuple\n        is the beginning of a range and the second element is the end\n        of a range. To specify the beginning or end of the table, use\n        an empty tuple `()`.\n\n        If the list is empty, then this yields all content ids in\n        the storage.\n\n        :param key_ranges: as described in\n                           :meth:`kvlayer._abstract_storage.AbstractStorage`\n        :rtype: generator of ``content_id``\n        '''\n        # (id, id) -> ((id,), (id,))\n        key_ranges = [(tuplify(s), tuplify(e)) for s, e in key_ranges]\n        scanner = self.kvl.scan_keys(self.TABLE, *key_ranges)\n        return imap(itemgetter(0), scanner)", "response": "Retrieve content ids in a range of ids."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a generator of content identifiers that have an entry in the index with the value val.", "response": "def index_scan(self, idx_name, val):\n        '''Returns ids that match an indexed value.\n\n        Returns a generator of content identifiers that have an entry\n        in the index ``idx_name`` with value ``val`` (after index\n        transforms are applied).\n\n        If the index named by ``idx_name`` is not registered, then a\n        :exc:`~exceptions.KeyError` is raised.\n\n        :param unicode idx_name: name of index\n        :param val: the value to use to search the index\n        :type val: unspecified (depends on the index, usually ``unicode``)\n        :rtype: generator of ``content_id``\n        :raises: :exc:`~exceptions.KeyError`\n        '''\n        idx = self._index(idx_name)['transform']\n        key = (idx(val), idx_name.encode('utf-8'))\n        keys = self.kvl.scan_keys(self.INDEX_TABLE, (key, key))\n        return imap(lambda k: k[2], keys)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef index_scan_prefix(self, idx_name, val_prefix):\n        '''Returns ids that match a prefix of an indexed value.\n\n        Returns a generator of content identifiers that have an entry\n        in the index ``idx_name`` with prefix ``val_prefix`` (after\n        index transforms are applied).\n\n        If the index named by ``idx_name`` is not registered, then a\n        :exc:`~exceptions.KeyError` is raised.\n\n        :param unicode idx_name: name of index\n        :param val_prefix: the value to use to search the index\n        :type val: unspecified (depends on the index, usually ``unicode``)\n        :rtype: generator of ``content_id``\n        :raises: :exc:`~exceptions.KeyError`\n        '''\n        return self._index_scan_prefix_impl(\n            idx_name, val_prefix, lambda k: k[2])", "response": "Returns a generator of content_id s that match a prefix of an indexed value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning ids that match a prefix of an indexed value and the specific key that matched the search prefix.", "response": "def index_scan_prefix_and_return_key(self, idx_name, val_prefix):\n        '''Returns ids that match a prefix of an indexed value, and the\n        specific key that matched the search prefix.\n\n        Returns a generator of (index key, content identifier) that\n        have an entry in the index ``idx_name`` with prefix\n        ``val_prefix`` (after index transforms are applied).\n\n        If the index named by ``idx_name`` is not registered, then a\n        :exc:`~exceptions.KeyError` is raised.\n\n        :param unicode idx_name: name of index\n        :param val_prefix: the value to use to search the index\n        :type val: unspecified (depends on the index, usually ``unicode``)\n        :rtype: generator of (``index key``, ``content_id``)\n        :raises: :exc:`~exceptions.KeyError`\n\n        '''\n        return self._index_scan_prefix_impl(\n            idx_name, val_prefix, lambda k: (k[0], k[2]))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _index_scan_prefix_impl(self, idx_name, val_prefix, retfunc):\n        '''Implementation for index_scan_prefix and\n        index_scan_prefix_and_return_key, parameterized on return\n        value function.\n\n        retfunc gets passed a key tuple from the index:\n        (index name, index value, content_id)\n        '''\n        idx = self._index(idx_name)['transform']\n        val_prefix = idx(val_prefix)\n\n        idx_name = idx_name.encode('utf-8')\n        s = (val_prefix, idx_name)\n        e = (val_prefix + '\\xff', idx_name)\n        keys = self.kvl.scan_keys(self.INDEX_TABLE, (s, e))\n        return imap(retfunc, keys)", "response": "Implementation for index_scan_prefix and index_scan_prefix_and_return_key parameterized on return\n        value function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef define_index(self, idx_name, create, transform):\n        '''Add an index to this store instance.\n\n        Adds an index transform to the current FC store. Once an index\n        with name ``idx_name`` is added, it will be available in all\n        ``index_*`` methods. Additionally, the index will be automatically\n        updated on calls to :meth:`~dossier.fc.store.Store.put`.\n\n        If an index with name ``idx_name`` already exists, then it is\n        overwritten.\n\n        Note that indexes do *not* persist. They must be re-defined for\n        each instance of :class:`Store`.\n\n        For example, to add an index on the ``boNAME`` feature, you can\n        use the ``feature_index`` helper function:\n\n        .. code-block:: python\n\n            store.define_index('boNAME',\n                               feature_index('boNAME'),\n                               lambda s: s.encode('utf-8'))\n\n        Another example for creating an index on names:\n\n        .. code-block:: python\n\n            store.define_index('NAME',\n                               feature_index('canonical_name', 'NAME'),\n                               lambda s: s.lower().encode('utf-8'))\n\n        :param idx_name: The name of the index. Must be UTF-8 encodable.\n        :type idx_name: unicode\n        :param create: A function that accepts the ``transform`` function and\n                       a pair of ``(content_id, fc)`` and produces a generator\n                       of index values from the pair given using ``transform``.\n        :param transform: A function that accepts an arbitrary value and\n                          applies a transform to it. This transforms the\n                          *stored* value to the *index* value. This *must*\n                          produce a value with type `str` (or `bytes`).\n        '''\n        assert isinstance(idx_name, (str, unicode))\n        idx_name = idx_name.decode('utf-8')\n        self._indexes[idx_name] = {'create': create, 'transform': transform}", "response": "Add an index to this store instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd new index values for index idx_name for the pairs given.", "response": "def _index_put(self, idx_name, *ids_and_fcs):\n        '''Add new index values.\n\n        Adds new index values for index ``idx_name`` for the pairs\n        given. Each pair should be a content identifier and a\n        :class:`dossier.fc.FeatureCollection`.\n\n        :type idx_name: unicode\n        :type ids_and_fcs: ``[(content_id, FeatureCollection)]``\n        '''\n        keys = self._index_keys_for(idx_name, *ids_and_fcs)\n        with_vals = map(lambda k: (k, '0'), keys)\n        # TODO: use imap when kvl.put takes an iterable\n        self.kvl.put(self.INDEX_TABLE, *with_vals)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _index_put_raw(self, idx_name, content_id, val):\n        '''Add new raw index values.\n\n        Adds a new index key corresponding to\n        ``(idx_name, transform(val), content_id)``.\n\n        This method bypasses the *creation* of indexes from content\n        objects, but values are still transformed.\n\n        :type idx_name: unicode\n        :type content_id: str\n        :type val: unspecified (depends on the index, usually ``unicode``)\n        '''\n        idx = self._index(idx_name)['transform']\n        key = (idx(val), idx_name.encode('utf-8'), content_id)\n        self.kvl.put(self.INDEX_TABLE, (key, '0'))", "response": "Add new raw index values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a generator of index keys for the ids_and_fcs pairs given.", "response": "def _index_keys_for(self, idx_name, *ids_and_fcs):\n        '''Returns a generator of index triples.\n\n        Returns a generator of index keys for the ``ids_and_fcs`` pairs\n        given. The index keys have the form ``(idx_name, idx_val,\n        content_id)``.\n\n        :type idx_name: unicode\n        :type ids_and_fcs: ``[(content_id, FeatureCollection)]``\n        :rtype: generator of ``(str, str, str)``\n        '''\n        idx = self._index(idx_name)\n        icreate, itrans = idx['create'], idx['transform']\n        if isinstance(idx_name, unicode):\n            idx_name = idx_name.encode('utf-8')\n\n        for cid_fc in ids_and_fcs:\n            content_id = cid_fc[0]\n\n            # Be sure to dedup index_values or else we may\n            # suffer duplicate_pkey errors down the line.\n            seen_values = set()\n            for index_value in icreate(itrans, cid_fc):\n                if index_value and index_value not in seen_values:\n                    yield (index_value, idx_name, content_id)\n                    seen_values.add(index_value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _index(self, name):\n        '''Returns index transforms for ``name``.\n\n        :type name: unicode\n        :rtype: ``{ create |--> function, transform |--> function }``\n        '''\n        name = name.decode('utf-8')\n        try:\n            return self._indexes[name]\n        except KeyError:\n            raise KeyError('Index \"%s\" has not been registered with '\n                           'this FC store.' % name)", "response": "Returns index transforms for name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def fetch_twitter(handle: str) -> List:\n    async with ClientSession() as session:\n        try:\n            async with session.get(f\"http://twitrss.me/twitter_user_to_rss/?user={handle}\") as request:\n                text = await request.text()\n        except ClientConnectionError as con_err:\n            logger.debug(f\"Could not connect to {con_err.host}\")\n            raise ApiError(f\"Could not connect to {con_err.host}\")\n        else:\n            feed = parse(text)\n            for x in feed.entries:\n                x[\"image\"] = feed.feed[\"image\"][\"href\"]\n            return feed.entries", "response": "Fetches the twitter feed for a given user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def fetch_nearby(lat: float, long: float, limit: int = 10) -> Optional[List[Dict]]:\n    request_url = f\"https://en.wikipedia.org/w/api.php?action=query\" \\\n                  f\"&list=geosearch\" \\\n                  f\"&gscoord={lat}%7C{long}\" \\\n                  f\"&gsradius=10000\" \\\n                  f\"&gslimit={limit}\" \\\n                  f\"&format=json\"\n\n    async with ClientSession() as session:\n        try:\n            async with session.get(request_url) as request:\n                if request.status == 404:\n                    return None\n                data = (await request.json())[\"query\"][\"geosearch\"]\n\n        except ClientConnectionError as con_err:\n            logger.debug(f\"Could not connect to {con_err.host}\")\n            raise ApiError(f\"Could not connect to {con_err.host}\")\n        except JSONDecodeError as dec_err:\n            logger.error(f\"Could not decode data: {dec_err}\")\n            raise ApiError(f\"Could not decode data: {dec_err}\")\n        except KeyError:\n            return None\n        else:\n            for location in data:\n                location.pop(\"ns\")\n                location.pop(\"primary\")\n            return data", "response": "Get the wikipedia articles near a given set of coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting shell command and return stdout txt", "response": "def execute_get_text(command):  # type: (str) ->str\n    \"\"\"\n    Execute shell command and return stdout txt\n    :param command:\n    :return:\n    \"\"\"\n    try:\n        completed = subprocess.run(\n            command,\n            check=True,\n            shell=True,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE\n        )\n    except subprocess.CalledProcessError as err:\n        raise\n    else:\n\n        print(completed.stdout.decode('utf-8') + str(\":\") + completed.stderr.decode(\"utf-8\"))\n        return completed.stdout.decode('utf-8')  + completed.stderr.decode(\"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_source_code_tree_changed(self):\n        global CURRENT_HASH\n        directory = self.where\n\n        # if CURRENT_HASH is None:\n        # print(\"hashing \" + directory)\n        # print(os.listdir(directory))\n        CURRENT_HASH = dirhash(directory, 'md5', ignore_hidden=True,\n                               # changing these exclusions can cause dirhas to skip EVERYTHING\n                               excluded_files=[\".coverage\", \"lint.txt\"],\n                               excluded_extensions=[\".pyc\"]\n                               )\n\n        print(\"Searching \" + self.state_file_name)\n        if os.path.isfile(self.state_file_name):\n            with open(self.state_file_name, \"r+\") as file:\n                last_hash = file.read()\n                if last_hash != CURRENT_HASH:\n                    file.seek(0)\n                    file.write(CURRENT_HASH)\n                    file.truncate()\n                    return True\n                else:\n                    return False\n\n        # no previous file, by definition not the same.\n        with open(self.state_file_name, \"w\") as file:\n            file.write(CURRENT_HASH)\n            return True", "response": "Returns True if the source code tree has changed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if a package name exists on pypi.", "response": "def check_pypi_name(pypi_package_name, pypi_registry_host=None):\n    \"\"\"\n    Check if a package name exists on pypi.\n\n    TODO: Document the Registry URL construction.\n        It may not be obvious how pypi_package_name and pypi_registry_host are used\n        I'm appending the simple HTTP API parts of the registry standard specification.\n\n    It will return True if the package name, or any equivalent variation as defined by PEP 503 normalisation\n     rules (https://www.python.org/dev/peps/pep-0503/#normalized-names) is registered in the PyPI registry.\n\n    >>> check_pypi_name('pip')\n    True\n    >>> check_pypi_name('Pip')\n    True\n\n    It will return False if the package name, or any equivalent variation as defined by PEP 503 normalisation\n     rules (https://www.python.org/dev/peps/pep-0503/#normalized-names) is not registered in the PyPI registry.\n\n    >>> check_pypi_name('testy_mc-test_case-has.a.cousin_who_should_never_write_a_package')\n    False\n\n    :param pypi_package_name:\n    :param pypi_registry_host:\n    :return:\n    \"\"\"\n    if pypi_registry_host is None:\n        pypi_registry_host = 'pypi.python.org'\n\n    # Just a helpful reminder why this bytearray size was chosen.\n    #                            HTTP/1.1 200 OK\n    #                            HTTP/1.1 404 Not Found\n    receive_buffer = bytearray(b'------------')\n    context = ssl.create_default_context()\n    ssl_http_socket = context.wrap_socket(socket.socket(socket.AF_INET), server_hostname=pypi_registry_host)\n    ssl_http_socket.connect((pypi_registry_host, 443))\n    ssl_http_socket.send(b''.join([\n        b\"HEAD /simple/\", pypi_package_name.encode('ascii'), b\"/ HTTP/1.0\", b\"\\r\\n\",\n        b\"Host: \", pypi_registry_host.encode('ascii'), b\"\\r\\n\",\n        b\"\\r\\n\\r\\n\"\n    ]))\n    ssl_http_socket.recv_into(receive_buffer)\n\n    # Early return when possible.\n    if b'HTTP/1.1 200' in receive_buffer:\n        ssl_http_socket.shutdown(1)\n        ssl_http_socket.close()\n        return True\n    elif b'HTTP/1.1 404' in receive_buffer:\n        ssl_http_socket.shutdown(1)\n        ssl_http_socket.close()\n        return False\n\n    remaining_bytes = ssl_http_socket.recv(2048)\n    redirect_path_location_start = remaining_bytes.find(b'Location:') + 10\n    redirect_path_location_end = remaining_bytes.find(b'\\r\\n', redirect_path_location_start)\n    # Append the trailing slash to avoid a needless extra redirect.\n    redirect_path = remaining_bytes[redirect_path_location_start:redirect_path_location_end] + b'/'\n\n    ssl_http_socket.shutdown(1)\n    ssl_http_socket.close()\n\n    # Reset the bytearray to empty\n    # receive_buffer = bytearray(b'------------')\n\n    ssl_http_socket = context.wrap_socket(socket.socket(socket.AF_INET), server_hostname=pypi_registry_host)\n    ssl_http_socket.connect((pypi_registry_host, 443))\n\n    ssl_http_socket.send(b''.join([\n        b\"HEAD \", redirect_path, b\" HTTP/1.0\", b\"\\r\\n\",\n        b\"Host: \", pypi_registry_host.encode('ascii'), b\"\\r\\n\",\n        b\"\\r\\n\\r\\n\"]))\n    ssl_http_socket.recv_into(receive_buffer)\n\n    if b'HTTP/1.1 200' in receive_buffer:\n        return True\n    elif b'HTTP/1.1 404' in receive_buffer:\n        return False\n    else:\n        NotImplementedError('A definitive answer was not found by primary or secondary lookups.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_direction(value, arg=u\"rtl_only\"):\n\n    if arg == u'rtl_only':\n        directions = (u'', u'_rtl')\n    elif arg == u'both':\n        directions = (u'_ltr', u'_rtl')\n    elif arg == u'ltr_only':\n        directions = (u'_ltr', u'')\n    else:\n        raise template.TemplateSyntaxError('add_direction can use arg with one of [\"rtl_only\", \"both\", \"ltr_only\"]')\n\n    parts = value.rsplit('.', 1)\n    if not len(parts):\n        return value\n    elif len(parts) == 1:\n        return value + directions[translation.get_language_bidi()]\n    else:\n        return '.'.join((parts[0]+directions[translation.get_language_bidi()],parts[1]))", "response": "Adds the direction to the element tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a list of postcodes from the latitude and longitude.", "response": "async def fetch_postcodes_from_coordinates(lat: float, long: float) -> Optional[List[Postcode]]:\n    \"\"\"\n    Gets a postcode object from the lat and long.\n    :param lat: The latitude to look up.\n    :param long: The longitude to look up.\n    :return: The mapping corresponding to the lat and long or none if the postcode does not exist.\n    :raises ApiError: When there was an error connecting to the API.\n    :raises CircuitBreakerError: When the circuit breaker is open.\n    \"\"\"\n    postcode_lookup = f\"/postcodes?lat={lat}&lon={long}\"\n    return await _get_postcode_from_url(postcode_lookup)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the xsd name of a S_DT", "response": "def get_type_name(s_dt):\n    '''\n    get the xsd name of a S_DT\n    '''\n    s_cdt = nav_one(s_dt).S_CDT[17]()\n    if s_cdt and s_cdt.Core_Typ in range(1, 6):\n        return s_dt.Name\n    \n    s_edt = nav_one(s_dt).S_EDT[17]()\n    if s_edt:\n        return s_dt.Name\n    \n    s_udt = nav_one(s_dt).S_UDT[17]()\n    if s_udt:\n        return s_dt.Name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the referred attribute.", "response": "def get_refered_attribute(o_attr):\n    '''\n    Get the the referred attribute.\n    '''\n    o_attr_ref = nav_one(o_attr).O_RATTR[106].O_BATTR[113].O_ATTR[106]()\n    if o_attr_ref:\n        return get_refered_attribute(o_attr_ref)\n    else:\n        return o_attr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_core_type(s_cdt):\n    '''\n    Build an xsd simpleType out of a S_CDT.\n    '''\n    s_dt = nav_one(s_cdt).S_DT[17]()\n    \n    if s_dt.name == 'void':\n        type_name = None\n    \n    elif s_dt.name == 'boolean':\n        type_name = 'xs:boolean'\n    \n    elif s_dt.name == 'integer':\n        type_name = 'xs:integer'\n    \n    elif s_dt.name == 'real':\n        type_name = 'xs:decimal'\n    \n    elif s_dt.name == 'string':\n        type_name = 'xs:string'\n    \n    elif s_dt.name == 'unique_id':\n        type_name = 'xs:integer'\n    \n    else:\n        type_name = None\n    \n    if type_name:\n        mapped_type = ET.Element('xs:simpleType', name=s_dt.name)\n        ET.SubElement(mapped_type, 'xs:restriction', base=type_name)\n        return mapped_type", "response": "Builds an xsd simpleType out of a S_CDT."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild an xsd simpleType out of a S_EDT.", "response": "def build_enum_type(s_edt):\n    '''\n    Build an xsd simpleType out of a S_EDT.\n    '''\n    s_dt = nav_one(s_edt).S_DT[17]()\n    enum = ET.Element('xs:simpleType', name=s_dt.name)\n    enum_list = ET.SubElement(enum, 'xs:restriction', base='xs:string')\n    \n    first_filter = lambda selected: not nav_one(selected).S_ENUM[56, 'succeeds']()\n    \n    s_enum = nav_any(s_edt).S_ENUM[27](first_filter)\n    while s_enum:\n        ET.SubElement(enum_list, 'xs:enumeration', value=s_enum.name)\n        s_enum = nav_one(s_enum).S_ENUM[56, 'precedes']()\n    \n    return enum"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_struct_type(s_sdt):\n    '''\n    Build an xsd complexType out of a S_SDT.\n    '''\n    s_dt = nav_one(s_sdt).S_DT[17]()\n    struct = ET.Element('xs:complexType', name=s_dt.name)\n    \n    first_filter = lambda selected: not nav_one(selected).S_MBR[46, 'succeeds']()\n    \n    s_mbr = nav_any(s_sdt).S_MBR[44](first_filter)\n    while s_mbr:\n        s_dt = nav_one(s_mbr).S_DT[45]()\n        type_name = get_type_name(s_dt)\n        ET.SubElement(struct, 'xs:attribute', name=s_mbr.name, type=type_name)\n        s_mbr = nav_one(s_mbr).S_MBR[46, 'precedes']()\n    \n    return struct", "response": "Builds an xsd complexType out of a S_SDT."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_user_type(s_udt):\n    '''\n    Build an xsd simpleType out of a S_UDT.\n    '''\n    s_dt_user = nav_one(s_udt).S_DT[17]()\n    s_dt_base = nav_one(s_udt).S_DT[18]()\n    \n    base_name = get_type_name(s_dt_base)\n    if base_name:\n        user = ET.Element('xs:simpleType', name=s_dt_user.name)\n        ET.SubElement(user, 'xs:restriction', base=base_name)\n        \n        return user", "response": "Builds an xsd simpleType out of a S_UDT."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_type(s_dt):\n    '''\n    Build a partial xsd tree out of a S_DT and its sub types S_CDT, S_EDT, S_SDT and S_UDT.\n    '''\n    s_cdt = nav_one(s_dt).S_CDT[17]()\n    if s_cdt:\n        return build_core_type(s_cdt)\n    \n    s_edt = nav_one(s_dt).S_EDT[17]()\n    if s_edt:\n        return build_enum_type(s_edt)\n    \n    s_udt = nav_one(s_dt).S_UDT[17]()\n    if s_udt:\n        return build_user_type(s_udt)", "response": "Builds a partial xsd tree out of a S_DT and its subtypes S_CDT S_EDT and S_SDT and S_UDT."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_class(o_obj):\n    '''\n    Build an xsd complex element out of a O_OBJ, including its O_ATTR.\n    '''\n    cls = ET.Element('xs:element', name=o_obj.key_lett, minOccurs='0', maxOccurs='unbounded')\n    attributes = ET.SubElement(cls, 'xs:complexType')\n    for o_attr in nav_many(o_obj).O_ATTR[102]():\n        o_attr_ref = get_refered_attribute(o_attr)\n        s_dt = nav_one(o_attr_ref).S_DT[114]()\n        while nav_one(s_dt).S_UDT[17]():\n            s_dt = nav_one(s_dt).S_UDT[17].S_DT[18]()\n        \n        type_name = get_type_name(s_dt)\n        if type_name and not nav_one(o_attr).O_BATTR[106].O_DBATTR[107]():\n            ET.SubElement(attributes, 'xs:attribute', name=o_attr.name, type=type_name)\n        else:\n            logger.warning('Omitting %s.%s' % (o_obj.key_lett, o_attr.Name))\n    return cls", "response": "Build an xsd complex element out of a O_OBJ including its O_ATTR."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_component(m, c_c):\n    '''\n    Build an xsd complex element out of a C_C, including its packaged S_DT and O_OBJ.\n    '''\n    component = ET.Element('xs:element', name=c_c.name)\n    \n    classes = ET.SubElement(component, 'xs:complexType')\n    classes = ET.SubElement(classes, 'xs:sequence')\n    \n    scope_filter = lambda selected: ooaofooa.is_contained_in(selected, c_c)\n    \n    for o_obj in m.select_many('O_OBJ', scope_filter):\n        cls = build_class(o_obj)\n        classes.append(cls)\n    \n    return component", "response": "Builds an xsd complex element out of a C_C including its packaged S_DT and O_OBJ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding an xsd schema from a bridgepoint component.", "response": "def build_schema(m, c_c):\n    '''\n    Build an xsd schema from a bridgepoint component.\n    '''\n    schema = ET.Element('xs:schema')\n    schema.set('xmlns:xs', 'http://www.w3.org/2001/XMLSchema')\n\n    global_filter = lambda selected: ooaofooa.is_global(selected)\n    for s_dt in m.select_many('S_DT', global_filter):\n        datatype = build_type(s_dt)\n        if datatype is not None:\n            schema.append(datatype)\n    \n    scope_filter = lambda selected: ooaofooa.is_contained_in(selected, c_c)\n    for s_dt in m.select_many('S_DT', scope_filter):\n        datatype = build_type(s_dt)\n        if datatype is not None:\n            schema.append(datatype)\n            \n    component = build_component(m, c_c)\n    schema.append(component)\n    \n    return schema"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prettify(xml_string):\n    '''\n    Indent an xml string with four spaces, and add an additional line break after each node.\n    '''\n    reparsed = xml.dom.minidom.parseString(xml_string)\n    return reparsed.toprettyxml(indent=\"    \")", "response": "Prettify an xml string with four spaces and add an additional line break after each node."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch the full list of bikes from the bikeregister site.", "response": "async def fetch_bikes() -> List[dict]:\n    \"\"\"\n    Gets the full list of bikes from the bikeregister site.\n    The data is hidden behind a form post request and so\n    we need to extract an xsrf and session token with bs4.\n\n    todo add pytest tests\n\n    :return: All the currently registered bikes.\n    :raise ApiError: When there was an error connecting to the API.\n    \"\"\"\n    async with ClientSession() as session:\n        try:\n            async with session.get('https://www.bikeregister.com/stolen-bikes') as request:\n                document = document_fromstring(await request.text())\n        except ClientConnectionError as con_err:\n            logger.debug(f\"Could not connect to {con_err.host}\")\n            raise ApiError(f\"Could not connect to {con_err.host}\")\n\n        token = document.xpath(\"//input[@name='_token']\")\n        if len(token) != 1:\n            raise ApiError(f\"Couldn't extract token from page.\")\n        else:\n            token = token[0].value\n        xsrf_token = request.cookies[\"XSRF-TOKEN\"]\n        laravel_session = request.cookies[\"laravel_session\"]\n\n        # get the bike data\n        headers = {\n            'cookie': f'XSRF-TOKEN={xsrf_token}; laravel_session={laravel_session}',\n            'origin': 'https://www.bikeregister.com',\n            'accept-encoding': 'gzip, deflate, br',\n            'accept-language': 'en-GB,en-US;q=0.9,en;q=0.8',\n            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:61.0) Gecko/20100101 Firefox/61.0',\n            'content-type': 'application/x-www-form-urlencoded; charset=UTF-8',\n            'accept': '*/*',\n            'referer': 'https://www.bikeregister.com/stolen-bikes',\n            'authority': 'www.bikeregister.com',\n            'x-requested-with': 'XMLHttpRequest',\n        }\n\n        data = [\n            ('_token', token),\n            ('make', ''),\n            ('model', ''),\n            ('colour', ''),\n            ('reporting_period', '1'),\n        ]\n\n        try:\n            async with session.post('https://www.bikeregister.com/stolen-bikes', headers=headers, data=data) as request:\n                bikes = json.loads(await request.text())\n        except ClientConnectionError as con_err:\n            logger.debug(f\"Could not connect to {con_err.host}\")\n            raise ApiError(f\"Could not connect to {con_err.host}\")\n        except json.JSONDecodeError as dec_err:\n            logger.error(f\"Could not decode data: {dec_err.msg}\")\n            raise ApiError(f\"Could not decode data: {dec_err.msg}\")\n\n        return bikes\n\n    # if cant open a session\n    return []"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_positional_info(node, p):\n    '''\n    set positional information on a node\n    '''\n    node.position = Position()\n    node.position.label = p.lexer.label\n    node.position.start_stream = p.lexpos(1)\n    node.position.start_line = p.lineno(1)\n    node.position.start_column = find_column(p.lexer.lexdata,\n                                             node.position.start_stream)\n    \n    _, node.position.end_stream = p.lexspan(len(p) - 1)\n    _, node.position.end_line = p.linespan(len(p) - 1)\n    node.position.end_column = find_column(p.lexer.lexdata,\n                                             node.position.end_stream) - 1\n    \n    node.character_stream = p.lexer.lexdata[node.position.start_stream:\n                                            node.position.end_stream]", "response": "set positional information on a node\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef track_production(f):\n    '''\n    decorator for adding positional information to returning nodes\n    '''\n    @wraps(f)\n    def wrapper(self, p):\n        r = f(self, p)\n        node = p[0]\n        if isinstance(node, Node) and len(p) > 1:\n            set_positional_info(node, p)\n        return r\n    \n    return wrapper", "response": "Decorator for adding positional information to returning nodes\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef t_TICKED_PHRASE(self, t):\n        r\"\\'[^\\']*\\'\"\n        t.endlexpos = t.lexpos + len(t.value)\n        return t", "response": "r \\ S + \\ S + \\ S"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a namespace identifier", "response": "def t_NAMESPACE(self, t):\n        r\"([0-9a-zA-Z_])+(?=::)\"\n        t.endlexpos = t.lexpos + len(t.value)\n        return t"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef t_ID(self, t):\n        r\"[a-zA-Z_][0-9a-zA-Z_]*|[a-zA-Z][0-9a-zA-Z_]*[0-9a-zA-Z_]+\"\n        t.endlexpos = t.lexpos + len(t.value)\n        \n        value = t.value.upper()\n        if value in self.keywords:\n            t.type = value\n            \n        return t", "response": "r A tag is a sequence of two characters. Each character is a letter and the next bit is set to the type of the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef t_NOTEQUAL(self, t):\n        r\"!\\=\"\n        t.endlexpos = t.lexpos + len(t.value)\n        return t", "response": "r! =\n        r! =\n        r! =\n        r! =\n        r! =\n        r! =\n        r! =\n        r! =\n        r! =\n        r! =\n        r! =\n        r! =\n        r! =\n        r! =\n        r! =\n        r! =\n        r! =\n        r! =\n        r! =\n        r! =\n"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef t_LE(self, t):\n        r\"\\<\\=\"\n        t.endlexpos = t.lexpos + len(t.value)\n        return t", "response": "t is a LE token"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef t_DOT(self, t):\n        r\"\\.\"\n        t.endlexpos = t.lexpos + len(t.value)\n        return t", "response": "t is a tag that is a dot - delimited list of names"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the TIMES section of a time stamp.", "response": "def t_TIMES(self, t):\n        r\"\\*\"\n        t.endlexpos = t.lexpos + len(t.value)\n        return t"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef t_COLON(self, t):\n        r\":\"\n        t.endlexpos = t.lexpos + len(t.value)\n        return t", "response": "t_COLON is a colon"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef t_DIV(self, t):\n        r\"/\"\n        t.endlexpos = t.lexpos + len(t.value)\n        return t", "response": "r DIV t. value = ID"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_statement_list_1(self, p):\n        '''statement_list : statement SEMICOLON statement_list'''\n        p[0] = p[3]\n        if p[1] is not None:\n            p[0].children.insert(0, p[1])", "response": "statement_list : statement SEMICOLON statement_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_bridge_assignment_statement(self, p):\n        '''statement : BRIDGE variable_access EQUAL implicit_invocation'''\n        p[4].__class__ = BridgeInvocationNode\n        p[0] = AssignmentNode(variable_access=p[2],\n                              expression=p[4])", "response": "Statement for bridge assignment."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the port invocation assignment statement.", "response": "def p_port_invocation_assignment_statement(self, p):\n        '''statement : SEND variable_access EQUAL implicit_invocation'''\n        p[4].__class__ = PortInvocationNode\n        p[0] = AssignmentNode(variable_access=p[2],\n                              expression=p[4])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_port_event_generation(self, p):\n        '''statement : SEND namespace DOUBLECOLON identifier LPAREN parameter_list RPAREN TO expression'''\n        p[0] = GeneratePortEventNode(port_name=p[2],\n                                     action_name=p[4],\n                                     parameter_list=p[6],\n                                     expression=p[9])", "response": "P - port event generation section."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_create_class_event_statement(self, p):\n        '''statement : CREATE EVENT INSTANCE variable_name OF event_specification TO identifier CLASS'''\n        p[0] = CreateClassEventNode(variable_name=p[4],\n                                    event_specification=p[6],\n                                    key_letter=p[8])", "response": "parse CREATE CLASS EVENT INSTANCE variable_name OF event_specification TO identifier CLASS"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing ASSIGNER EVENT INSTANCE variable_name OF event_specification TO identifier ASSIGNER", "response": "def p_create_assigner_event_statement(self, p):\n        '''statement : CREATE EVENT INSTANCE variable_name OF event_specification TO identifier ASSIGNER'''\n        p[0] = CreateClassEventNode(variable_name=p[4],\n                                    event_specification=p[6],\n                                    key_letter=p[8])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse CREATE EVENT INSTANCE variable_name OF event_specification TO identifier CREATOR", "response": "def p_create_creator_event_statement(self, p):\n        '''statement : CREATE EVENT INSTANCE variable_name OF event_specification TO identifier CREATOR'''\n        p[0] = CreateCreatorEventNode(variable_name=p[4],\n                                      event_specification=p[6],\n                                      key_letter=p[8])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_create_instance_event_statement_1(self, p):\n        '''statement : CREATE EVENT INSTANCE variable_name OF event_specification TO variable_access'''\n        p[0] = CreateInstanceEventNode(variable_name=p[4],\n                                       event_specification=p[6],\n                                       to_variable_access=p[8])", "response": "Statement for create instance event"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_create_instance_event_statement_2(self, p):\n        '''statement : CREATE EVENT INSTANCE variable_name OF event_specification TO self_access'''\n        p[0] = CreateInstanceEventNode(variable_name=p[4],\n                                       event_specification=p[6],\n                                       to_variable_access=p[8])", "response": "statement : CREATE INSTANCE variable_name OF event_specification TO self_access"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_event_specification(self, p):\n        '''event_specification : identifier event_meaning event_data'''\n        p[0] = EventSpecNode(identifier=p[1],\n                             meaning=p[2],\n                             event_data=p[3])", "response": "event_specification : identifier event_meaning event_data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_if_statement(self, p):\n        '''statement : IF expression block elif_list else_clause END_IF'''\n        p[0] = IfNode(expression=p[2],\n                      block=p[3],\n                      elif_list=p[4],\n                      else_clause=p[5])", "response": "P_IF statement | END_IF"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_relate_using_statement_1(self, p):\n        '''statement : RELATE instance_name TO instance_name ACROSS rel_id USING instance_name'''\n        p[0] = RelateUsingNode(from_variable_name=p[2],\n                               to_variable_name=p[4],\n                               rel_id=p[6],\n                               phrase=None,\n                               using_variable_name=p[8])", "response": "RFC 3339 section 7. 1. 3. 1. 1."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_unrelate_statement_1(self, p):\n        '''statement : UNRELATE instance_name FROM instance_name ACROSS rel_id'''\n        p[0] = UnrelateNode(from_variable_name=p[2],\n                            to_variable_name=p[4],\n                            rel_id=p[6],\n                            phrase=None)", "response": "Unrelate a node from one node to another."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_unrelate_statement_2(self, p):\n        '''statement : UNRELATE instance_name FROM instance_name ACROSS rel_id DOT phrase'''\n        p[0] = UnrelateNode(from_variable_name=p[2],\n                            to_variable_name=p[4],\n                            rel_id=p[6],\n                            phrase=p[8])", "response": "statement : UNRELATE instance_name FROM instance_name ACROSS rel_id DOT phrase"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_unrelate_statement_using_1(self, p):\n        '''statement : UNRELATE instance_name FROM instance_name ACROSS rel_id USING instance_name'''\n        p[0] = UnrelateUsingNode(from_variable_name=p[2],\n                                 to_variable_name=p[4],\n                                 rel_id=p[6],\n                                 phrase=None,\n                                 using_variable_name=p[8])", "response": "Unrelate instance_name FROM instance_name ACROSS rel_id USING instance_name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_select_from_statement_2(self, p):\n        '''\n        statement : SELECT ANY variable_name FROM identifier\n                  | SELECT MANY variable_name FROM identifier\n        '''\n        p[0] = SelectFromNode(cardinality=p[2],\n                              variable_name=p[3],\n                              key_letter=p[5])", "response": "p = statement p [ 1 ] = select_from_statement_2"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_select_from_where_statement_1(self, p):\n        '''\n        statement : SELECT ANY variable_name FROM INSTANCES OF identifier WHERE expression\n                  | SELECT MANY variable_name FROM INSTANCES OF identifier WHERE expression\n        '''\n        p[0] = SelectFromWhereNode(cardinality=p[2],\n                                   variable_name=p[3],\n                                   key_letter=p[7],\n                                   where_clause=p[9])", "response": "A select_from_where_clause is a wrapper around SelectFromWhereNode"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_select_from_where_statement_2(self, p):\n        '''\n        statement : SELECT ANY variable_name FROM identifier WHERE expression\n                  | SELECT MANY variable_name FROM identifier WHERE expression\n        '''\n        p[0] = SelectFromWhereNode(cardinality=p[2],\n                                   variable_name=p[3],\n                                   key_letter=p[5],\n                                   where_clause=p[7])", "response": "p = statement p [ 1 ] = select_from_where_node"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse SELECT related WHERE statement", "response": "def p_select_related_where_statement(self, p):\n        '''\n        statement : SELECT ONE  variable_name RELATED BY navigation_hook navigation_chain WHERE expression\n                  | SELECT ANY  variable_name RELATED BY navigation_hook navigation_chain WHERE expression\n                  | SELECT MANY variable_name RELATED BY navigation_hook navigation_chain WHERE expression\n        '''\n        p[0] = SelectRelatedWhereNode(cardinality=p[2],\n                                      variable_name=p[3],\n                                      handle=p[6],\n                                      navigation_chain=p[7],\n                                      where_clause=p[9])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the navigation step 1", "response": "def p_navigation_step_1(self, p):\n        '''navigation_step : ARROW identifier LSQBR identifier RSQBR'''\n        p[0] = NavigationStepNode(key_letter=p[2],\n                                  rel_id=p[4],\n                                  phrase=None)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_navigation_step_2(self, p):\n        '''navigation_step : ARROW identifier LSQBR identifier DOT phrase RSQBR'''\n        p[0] = NavigationStepNode(key_letter=p[2],\n                                  rel_id=p[4],\n                                  phrase=p[6])", "response": "p_navigation_step_2 - > navigation_step"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_implicit_invocation(self, p):\n        '''implicit_invocation : namespace DOUBLECOLON identifier LPAREN parameter_list RPAREN'''\n        p[0] = ImplicitInvocationNode(namespace=p[1],\n                                      action_name=p[3],\n                                      parameter_list=p[5])", "response": "A implicit invocation is a simple node."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses an operation invocation.", "response": "def p_operation_invocation_1(self, p):\n        '''instance_invocation : structure DOT identifier LPAREN parameter_list RPAREN'''\n        p[0] = InstanceInvocationNode(handle=p[1],\n                                      action_name=p[3],\n                                      parameter_list=p[5])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_arithmetic_expression(self, p):\n        '''\n        expression : expression PLUS  expression\n                   | expression MINUS expression\n                   | expression TIMES expression\n                   | expression DIV   expression\n                   | expression MOD   expression\n        '''\n        p[0] = BinaryOperationNode(left=p[1],\n                                   operator=p[2],\n                                   right=p[3])", "response": "Parse the arithmetic expression."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_boolean_expression(self, p):\n        '''\n        expression : expression LE          expression\n                   | expression LESSTHAN    expression\n                   | expression DOUBLEEQUAL expression\n                   | expression NOTEQUAL    expression\n                   | expression GE          expression\n                   | expression GT          expression\n                   | expression AND         expression\n                   | expression OR          expression\n        '''\n        p[0] = BinaryOperationNode(left=p[1],\n                                   operator=p[2],\n                                   right=p[3])", "response": "expression : expression LE          expression\n                   | expression LESSTHAN    expression\n                   | expression DOUBLEEQUAL expression\n                   | expression NOTEQUAL    expression\n                   | expression GE          expression\n                   | expression GT          expression\n                   | expression AND         expression\n                   | expression OR          expression"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps exceptions in the context with a MalformedMessage.", "response": "def wrap(cls, message_parts):\n        \"\"\"Wraps exceptions in the context with :exc:`MalformedMessage`.\"\"\"\n        try:\n            yield\n        except BaseException as exception:\n            __, __, tb = sys.exc_info()\n            reraise(cls, cls(exception, message_parts), tb)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the crime nearby to a given postcode.", "response": "async def api_crime(request):\n    \"\"\"\n    Gets the crime nearby to a given postcode.\n    :param request: The aiohttp request.\n    :return: A json representation of the crimes near the postcode.\n    \"\"\"\n    postcode: Optional[str] = request.match_info.get('postcode', None)\n\n    try:\n        coroutine = get_postcode_random() if postcode == \"random\" else get_postcode(postcode)\n        postcode: Optional[Postcode] = await coroutine\n    except CachingError as e:\n        return web.Response(body=e.status, status=500)\n\n    try:\n        crime = await fetch_crime(postcode.lat, postcode.long)\n    except (ApiError, CircuitBreakerError):\n        raise web.HTTPInternalServerError(body=f\"Requested crime is not cached, and can't be retrieved.\")\n\n    if crime is None:\n        return web.HTTPNotFound(body=\"No Police Data\")\n    else:\n        return str_json_response(crime)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the neighbourhood data for a given post code.", "response": "async def api_neighbourhood(request):\n    \"\"\"\n    Gets police data about a neighbourhood.\n    :param request: The aiohttp request.\n    :return: The police data for that post code.\n    \"\"\"\n    postcode: Optional[str] = request.match_info.get('postcode', None)\n\n    try:\n        postcode = (await get_postcode_random()) if postcode == \"random\" else postcode\n        neighbourhood = await get_neighbourhood(postcode)\n    except CachingError as e:\n        raise web.HTTPInternalServerError(text=e.status)\n\n    if neighbourhood is None:\n        raise web.HTTPNotFound(text=\"No Police Data\")\n    else:\n        return str_json_response(neighbourhood.serialize())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_queue(self, name, strict=True, auto_delete=False, auto_delete_timeout=0):\n        content = {\"_object_id\": {\"_object_name\": self.object_name},\n                   \"_method_name\": \"create\",\n                   \"_arguments\": {\"type\": \"queue\",\n                                  \"name\": name,\n                                  \"strict\": strict,\n                                  \"properties\": {\"auto-delete\": auto_delete,\n                                                 \"qpid.auto_delete_timeout\": auto_delete_timeout}}}\n        logger.debug(\"Message content -> {0}\".format(content))\n\n        return content, self.method_properties", "response": "Create a new queue with the given name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_queue(self, name):\n        content = {\"_object_id\": {\"_object_name\": self.object_name},\n                   \"_method_name\": \"delete\",\n                   \"_arguments\": {\"type\": \"queue\",\n                                  \"name\": name,\n                                  \"options\": dict()}}  # \"A nested map with the key options. This is presently unused.\"\n        logger.debug(\"Message content -> {0}\".format(content))\n\n        return content, self.method_properties", "response": "Create message content and method properties to delete a queue with QMFv2\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_queues(self):\n        content = {\"_what\": \"OBJECT\",\n                   \"_schema_id\": {\"_class_name\": \"queue\"}}\n        logger.debug(\"Message content -> {0}\".format(content))\n\n        return content, self.query_properties", "response": "Create message content and query properties to list all queues with QMFv2\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate message content and query properties to list all exchanges with QMFv2", "response": "def list_exchanges(self):\n        \"\"\"Create message content and properties to list all exchanges with QMFv2\n\n        :returns: Tuple containing content and query properties\n        \"\"\"\n        content = {\"_what\": \"OBJECT\",\n                   \"_schema_id\": {\"_class_name\": \"exchange\"}}\n        logger.debug(\"Message content -> {0}\".format(content))\n\n        return content, self.query_properties"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate message content and method properties to purge a queue with QMFv2", "response": "def purge_queue(self, name):\n        \"\"\"Create message content and properties to purge queue with QMFv2\n\n        :param name: Name of queue to purge\n        :type name: str\n\n        :returns: Tuple containing content and method properties\n        \"\"\"\n        content = {\"_object_id\": {\"_object_name\": \"org.apache.qpid.broker:queue:{0}\".format(name)},\n                   \"_method_name\": \"purge\",\n                   \"_arguments\": {\"type\": \"queue\",\n                                  \"name\": name,\n                                  \"filter\": dict()}}\n        logger.debug(\"Message content -> {0}\".format(content))\n\n        return content, self.method_properties"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a message with the given parameters.", "response": "def _create_msg(self, to, subject, msgHtml, msgPlain, attachments=None):\n        '''\n        attachments should be a list of paths\n        '''\n        sender = self.sender\n        if attachments and isinstance(attachments, str):\n            attachments = [attachments]\n        else:\n            attachments = list(attachments or [])\n\n        msg = MIMEMultipart('alternative')\n        msg['Subject'] = subject\n        msg['From'] = sender\n        msg['To'] = to\n        msg.attach(MIMEText(msgPlain, 'plain'))\n        msg.attach(MIMEText(msgHtml, 'html'))\n\n        # append attachments if any\n        for path in attachments:\n            _attachment = self._prep_attachment(path)\n            msg.attach(_attachment)\n\n        raw = base64.urlsafe_b64encode(msg.as_bytes()).decode()\n        #raw = raw.decode()\n        body = {'raw': raw}\n        return body"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nraise an exception as a : exc. RemoteException.", "response": "def set_remote_exception(self, remote_exc_info):\n        \"\"\"Raises an exception as a :exc:`RemoteException`.\"\"\"\n        exc_type, exc_str, filename, lineno = remote_exc_info[:4]\n        exc_type = RemoteException.compose(exc_type)\n        exc = exc_type(exc_str, filename, lineno, self.worker_info)\n        if len(remote_exc_info) > 4:\n            state = remote_exc_info[4]\n            exc.__setstate__(state)\n        self.set_exception(exc)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the text from an image at a given url.", "response": "def read(self):\n        \"\"\"\n        Returns the text from an image at a given url.\n        \"\"\"\n\n        # Only download the image if it has changed\n        if self.connection.has_changed():\n            image_path = self.connection.download_image()\n            image = Image.open(image_path)\n            self.text_cache = pytesseract.image_to_string(image)\n            image.close()\n\n        return self.text_cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True or false based on if the OCR process has read actual words.", "response": "def text_visible(self):\n        \"\"\"\n        Returns true or false based on if the OCR process has read\n        actual words. This is needed to prevent non-words from being\n        added to the queue since the ocr process can sometimes return\n        values that are not meaningfull.\n        \"\"\"\n\n        # Split the input string at points with any amount of whitespace\n        words = self.read().split()\n\n        # Light weight check to see if a word exists\n        for word in words:\n\n            # If the word is a numeric value\n            if word.lstrip('-').replace('.', '', 1).isdigit():\n                return True\n\n            # If the word contains only letters with a length from 2 to 20\n            if word.isalpha() and (len(word) > 1 or len(word) <= 20):\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_most_recent_bike() -> Optional['Bike']:\n        try:\n            return Bike.select().order_by(Bike.cached_date.desc()).get()\n        except pw.DoesNotExist:\n            return None", "response": "Gets the most recently cached bike from the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse command line options and launch the interpreter", "response": "def main():\n    '''\n    Parse command line options and launch the interpreter\n    '''\n    parser = optparse.OptionParser(usage=\"%prog [options] <model_path> [another_model_path..]\",\n                                   version=xtuml.version.complete_string,\n                                   formatter=optparse.TitledHelpFormatter())\n\n    parser.add_option(\"-v\", \"--verbosity\", dest='verbosity', action=\"count\",\n                      default=1, help=\"increase debug logging level\")\n    \n    parser.add_option(\"-f\", \"--function\", dest='function', action=\"store\",\n                      help=\"invoke function named NAME\", metavar='NAME')\n    \n    parser.add_option(\"-c\", \"--component\", dest='component', action=\"store\",\n                      help=\"look for the function in a component named NAME\",\n                      metavar='NAME', default=None)\n    \n    (opts, args) = parser.parse_args()\n    if len(args) == 0 or not opts.function:\n        parser.print_help()\n        sys.exit(1)\n        \n    levels = {\n              0: logging.ERROR,\n              1: logging.WARNING,\n              2: logging.INFO,\n              3: logging.DEBUG,\n    }\n    logging.basicConfig(level=levels.get(opts.verbosity, logging.DEBUG))\n    \n    from bridgepoint import ooaofooa\n    mm = ooaofooa.load_metamodel(args)\n    c_c = mm.select_any('C_C', where(Name=opts.component))\n    domain = ooaofooa.mk_component(mm, c_c, derived_attributes=False)\n    \n    func = domain.find_symbol(opts.function)\n    return func()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse argv for options and arguments, and start schema generation.", "response": "def main():\n    '''\n    Parse argv for options and arguments, and start schema generation.\n    '''\n    parser = optparse.OptionParser(usage=\"%prog [options] <model_path> [another_model_path...]\",\n                                   version=xtuml.version.complete_string,\n                                   formatter=optparse.TitledHelpFormatter())\n                                   \n    parser.set_description(__doc__.strip())\n    \n    parser.add_option(\"-c\", \"--component\", dest=\"component\", metavar=\"NAME\",\n                      help=\"export sql schema for the component named NAME\",\n                      action=\"store\", default=None)\n    \n    parser.add_option(\"-d\", \"--derived-attributes\", dest=\"derived\",\n                      help=\"include derived attributes in the schema\",\n                      action=\"store_true\", default=False)\n    \n    parser.add_option(\"-o\", \"--output\", dest='output', metavar=\"PATH\",\n                      help=\"save sql schema to PATH (required)\",\n                      action=\"store\", default=None)\n    \n    parser.add_option(\"-v\", \"--verbosity\", dest='verbosity', action=\"count\", \n                      help=\"increase debug logging level\", default=2)\n\n    \n    (opts, args) = parser.parse_args()\n    if len(args) == 0 or opts.output is None:\n        parser.print_help()\n        sys.exit(1)\n\n    levels = {\n              0: logging.ERROR,\n              1: logging.WARNING,\n              2: logging.INFO,\n              3: logging.DEBUG,\n    }\n    logging.basicConfig(level=levels.get(opts.verbosity, logging.DEBUG))\n\n    loader = ooaofooa.Loader()\n    for filename in args:\n        loader.filename_input(filename)\n\n    c = loader.build_component(opts.component, opts.derived)\n    xtuml.persist_database(c, opts.output)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_token(client_id, client_secret, client_access_token, page=None):\n    payload = {\n        'grant_type': 'client_credentials',\n        'client_id': client_id,\n        'client_secret': client_secret,\n    }\n\n    if client_access_token:\n        payload['grant_type'] = 'fb_exchange_token'\n        payload['fb_exchange_token'] = client_access_token\n\n    # response {\"access_token\":\" ... \", \"token_type\":\"bearer\", \"expires_in\":..}\n    response = requests.post(\n        'https://graph.facebook.com/oauth/access_token?',\n        params=payload)\n    access_token = response.json()['access_token']\n    return access_token", "response": "Get an access token from Facebook."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_page_api(client_access_token, page_id):\n    graph = GraphAPI(client_access_token)\n    # Get page token to post as the page. You can skip\n    # the following if you want to post as yourself.\n    resp = graph.get('me/accounts')\n    page_access_token = None\n\n    for page in resp['data']:\n        if page['id'] == page_id:\n            page_access_token = page['access_token']\n            break\n\n    return GraphAPI(page_access_token)", "response": "Get the GraphAPI object for the given page."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serialize_value(value, ty):\n    '''\n    Serialize a value from an xtuml metamodel instance.\n    '''\n    ty = ty.upper()\n    \n    null_value = {\n        'BOOLEAN'   : False,\n        'INTEGER'   : 0,\n        'REAL'      : 0.0,\n        'STRING'    : '',\n        'UNIQUE_ID' : 0\n    }\n    \n    transfer_fn = {\n        'BOOLEAN'     : lambda v: '%d' % int(v),\n        'INTEGER'     : lambda v: '%d' % v,\n        'REAL'        : lambda v: '%f' % v,\n        'STRING'      : lambda v: \"'%s'\" % v.replace(\"'\", \"''\"),\n        'UNIQUE_ID'   : lambda v: '\"%s\"' % uuid.UUID(int=v)\n    }\n\n    if value is None:\n        value = null_value[ty]\n    \n    return transfer_fn[ty](value)", "response": "Serialize a value from an xtuml metamodel instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nserializing an instance from a metamodel.", "response": "def serialize_instance(instance):\n    '''\n    Serialize an *instance* from a metamodel.\n    '''\n    attr_count = 0\n    metaclass = xtuml.get_metaclass(instance)\n    s = 'INSERT INTO %s VALUES (' % metaclass.kind\n    for name, ty in metaclass.attributes:\n        value = getattr(instance, name)\n            \n        s += '\\n    '\n        s += serialize_value(value, ty)\n\n        attr_count += 1\n        if attr_count < len(metaclass.attributes):\n            s += ', -- %s : %s' % (name, ty)\n        else:\n            s += ' -- %s : %s' % (name, ty)\n\n    s += '\\n);\\n'\n\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef serialize_instances(metamodel):\n    '''\n    Serialize all instances in a *metamodel*.\n    '''\n    s = ''\n    for inst in metamodel.instances:\n        s += serialize_instance(inst)\n    \n    return s", "response": "Serialize all instances in a metamodel."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nserialize an xtuml metamodel association.", "response": "def serialize_association(ass):\n    '''\n    Serialize an xtuml metamodel association.\n    '''\n    s1 = '%s %s (%s)' % (ass.source_link.cardinality,\n                         ass.source_link.to_metaclass.kind,\n                         ', '.join(ass.source_keys))\n\n    if ass.target_link.phrase:\n        s1 += \" PHRASE '%s'\" % ass.target_link.phrase\n\n    s2 = '%s %s (%s)' % (ass.target_link.cardinality,\n                         ass.target_link.to_metaclass.kind,\n                         ', '.join(ass.target_keys))\n    \n    if ass.source_link.phrase:\n        s2 += \" PHRASE '%s'\" % ass.source_link.phrase\n\n    return 'CREATE ROP REF_ID %s FROM %s TO %s;\\n' % (ass.rel_id,\n                                                      s1,\n                                                      s2)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nserialize an xtUML metamodel class.", "response": "def serialize_class(Cls):\n    '''\n    Serialize an xtUML metamodel class.\n    '''\n    metaclass = xtuml.get_metaclass(Cls)\n    attributes = ['%s %s' % (name, ty.upper()) for name, ty in metaclass.attributes]\n    \n    s = 'CREATE TABLE %s (\\n    ' % metaclass.kind\n    s += ',\\n    '.join(attributes)\n    s += '\\n);\\n'\n\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nserializing all metaclasses and associations in a given metamodel.", "response": "def serialize_schema(metamodel):\n    '''\n    Serialize all class and association definitions in a *metamodel*.\n    '''\n    s = ''\n    for kind in sorted(metamodel.metaclasses.keys()):\n        s += serialize_class(metamodel.metaclasses[kind].clazz)\n    \n    for ass in sorted(metamodel.associations, key=lambda x: x.rel_id):\n        s += serialize_association(ass)\n    \n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nserialize the database into a string.", "response": "def serialize_database(metamodel):\n    '''\n    Serialize all instances, class definitions, association definitions, and\n    unique identifiers  in a *metamodel*.\n    '''\n    schema = serialize_schema(metamodel)\n    instances = serialize_instances(metamodel)\n    identifiers = serialize_unique_identifiers(metamodel)\n    \n    return ''.join([schema, instances, identifiers])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serialize(resource):\n    '''\n    Serialize some xtuml *resource*, e.g. an instance or a complete metamodel.\n    '''\n    if isinstance(resource, xtuml.MetaModel):\n        return serialize_database(resource)\n\n    elif isinstance(resource, type) and issubclass(resource, xtuml.Class):\n        return serialize_class(resource)\n    \n    elif isinstance(resource, xtuml.Association):\n        return serialize_association(resource)\n\n    elif isinstance(resource, xtuml.Class):\n        return serialize_instance(resource)", "response": "Serialize some xtuml resource e. g. an instance or a complete metamodel."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npersisting all instances in a given metamodel to disk.", "response": "def persist_instances(metamodel, path, mode='w'):\n    '''\n    Persist all instances in a *metamodel* by serializing them and saving to a \n    *path* on disk.\n    '''\n    with open(path, mode) as f:\n        for inst in metamodel.instances:\n            s = serialize_instance(inst)\n            f.write(s)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npersisting all class and association definitions in a given metamodel to a file on disk.", "response": "def persist_schema(metamodel, path, mode='w'):\n    '''\n    Persist all class and association definitions in a *metamodel* by \n    serializing them and saving to a *path* on disk.\n    '''\n    with open(path, mode) as f:\n        for kind in sorted(metamodel.metaclasses.keys()):\n            s = serialize_class(metamodel.metaclasses[kind].clazz)\n            f.write(s)\n            \n        for ass in sorted(metamodel.associations, key=lambda x: x.rel_id):\n            s = serialize_association(ass)\n            f.write(s)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npersist all unique identifiers in a metamodel to a file on disk.", "response": "def persist_unique_identifiers(metamodel, path, mode='w'):\n    '''\n    Persist all unique identifiers in a *metamodel* by serializing them and\n    saving to a *path* on disk.\n    '''\n    with open(path, mode) as f:\n        for metaclass in metamodel.metaclasses.values():\n            for index_name, attribute_names in metaclass.indices.items():\n                attribute_names = ', '.join(attribute_names)\n                s = 'CREATE UNIQUE INDEX %s ON %s (%s);\\n' % (index_name,\n                                                              metaclass.kind,\n                                                              attribute_names)\n                f.write(s)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npersist all instances class definitions association definitions in a given metamodel to a file on disk.", "response": "def persist_database(metamodel, path, mode='w'):\n    '''\n    Persist all instances, class definitions and association definitions in a\n    *metamodel* by serializing them and saving to a *path* on disk.\n    '''\n    with open(path, mode) as f:\n        for kind in sorted(metamodel.metaclasses.keys()):\n            metaclass = metamodel.metaclasses[kind]\n            s = serialize_class(metaclass.clazz)\n            f.write(s)\n            \n            for index_name, attribute_names in metaclass.indices.items():\n                attribute_names = ', '.join(attribute_names)\n                s = 'CREATE UNIQUE INDEX %s ON %s (%s);\\n' % (index_name,\n                                                              metaclass.kind,\n                                                              attribute_names)\n                f.write(s)\n                \n        for ass in sorted(metamodel.associations, key=lambda x: x.rel_id):\n            s = serialize_association(ass)\n            f.write(s)\n\n        for inst in metamodel.instances:\n            s = serialize_instance(inst)\n            f.write(s)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave a variable on given path using Pickle", "response": "def save(variable, filename):\n    \"\"\"Save variable on given path using Pickle\n    \n    Args:\n        variable: what to save\n        path (str): path of the output\n    \"\"\"\n    fileObj = open(filename, 'wb')\n    pickle.dump(variable, fileObj)\n    fileObj.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load(filename):\n    fileObj = open(filename, 'rb')\n    variable = pickle.load(fileObj)\n    fileObj.close()\n    return variable", "response": "Load a pickle file into a dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction for command line execution", "response": "def main():\n    \"\"\"Function for command line execution\"\"\"\n\n    parser = ArgumentParser(description=\"search files using n-grams\")\n    parser.add_argument('--path', dest='path', help=\"where to search\", nargs=1, action=\"store\", default=getcwd())\n    parser.add_argument('--update', dest='update', help=\"update the index\", action='store_true', default=True)\n    parser.add_argument('--filetype', dest='filetype', help=\"any, images, documents, code, audio, video\", nargs=1, action=\"store\", default=[\"any\"])\n    parser.add_argument('--verbose', dest='verbose', help=\"extended output\", action='store_true', default=False)\n    parser.add_argument('--results', dest='results', help=\"number of results to display\", action=\"store\", default=10)\n    parser.add_argument('query', nargs='+', help=\"what to search\", action=\"store\")\n    args = parser.parse_args()\n\n    if args.verbose:\n        verbose = 2\n        pprint(args)\n    else:\n        verbose = 0\n \n    query = args.query[0]\n    for arg in args.query[1:]:\n        query = query + \" \" + arg\n    slb = min([len(w) for w in query.split(\" \")])\n\n    files = Files(path=args.path, filetype=args.filetype[0], exclude=[], update=args.update, verbose=verbose)\n    index = Index(files, slb=slb, verbose=verbose)\n    results = index.search(query, verbose=verbose)\n    Handler(results, results_number=int(args.results))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching the database for the files satisfying a query.", "response": "def search(self, query, verbose=0):\n        \"\"\"Searches files satisfying query\n\n        It first decompose the query in ngrams, then score each document containing\n        at least one ngram with the number. The ten document having the most ngrams\n        in common with the query are selected.\n        \n        Args:\n             query (str): what to search;\n             results_number (int): number of results to return (default: 10)\n        \"\"\"\n        if verbose > 0:\n            print(\"searching \" + query)\n        query = query.lower()\n        qgram = ng(query, self.slb)\n        qocument = set()\n        for q in qgram:\n            if q in self.ngrams.keys():\n                for i in self.ngrams[q]:\n                    qocument.add(i)\n        self.qocument = qocument\n        results = {}\n        for i in qocument:\n           for j in self.D[i].keys():\n                if not j in results.keys():\n                    results[j] = 0\n                results[j] = results[j] + self.D[i][j]\n        sorted_results = sorted(results.items(), key=operator.itemgetter(1), reverse=True)\n        return [self.elements[f[0]] for f in sorted_results]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef partition(condition, collection) -> Tuple[List, List]:\n    succeed, fail = [], []\n\n    for x in collection:\n        if condition(x):\n            succeed.append(x)\n        else:\n            fail.append(x)\n\n    return succeed, fail", "response": "Partitions a list into two based on a condition."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def cli(location_strings: Tuple[str], random_postcodes_count: int, *,\n              bikes: bool = False, crime: bool = False,\n              nearby: bool = False, as_json: bool = False):\n    \"\"\"\n    Runs the CLI app.\n    Tries to execute as many steps as possible to give the user\n    the best understanding of the errors (if there are any).\n\n    :param location_strings: A list of desired postcodes or coordinates.\n    :param random_postcodes_count: A number of random postcodes to fetch..\n    :param bikes: A flag to include bikes.\n    :param crime: A flag to include crime.\n    :param nearby: A flag to include nearby.\n    :param as_json: A flag to make json output.\n    \"\"\"\n\n    def match_getter(location) -> Optional[PostcodeGetter]:\n        for getter in getters:\n            if getter.can_provide(location):\n                return getter(location)\n        else:\n            return None\n\n    async def handle_getter(exception_list, getter):\n        try:\n            return await getter.get_postcodes()\n        except (CachingError, ApiError):\n            exception_list.append(f\"Could not get data for {getter}\")\n\n    async def handle_datas(exception_list, postcode):\n        postcode_data, new_exceptions = await get_postcode_data(postcode, bikes, crime, nearby)\n        exception_list += new_exceptions\n        return postcode_data\n\n    exception_list: List[Exception] = []\n\n    handle_getter = partial(handle_getter, exception_list)\n    handle_datas = partial(handle_datas, exception_list)\n\n    postcode_getters = {location: match_getter(location) for location in\n                        set(location_strings) | ({random_postcodes_count} if random_postcodes_count > 0 else set())}\n\n    matched, unmatched = partition(lambda k_v: k_v[1] is not None, postcode_getters.items())\n\n    for location, getter in unmatched:\n        echo(f\"Invalid input for {location}\")\n\n    postcodes_collection = [await handle_getter(getter) for location, getter in matched]\n\n    if len(exception_list) > 0:\n        for f in exception_list:\n            echo(str(f))\n        return 1\n\n    postcode_datas = [await handle_datas(postcode) for entry in postcodes_collection for postcode in entry]\n    serializer = (PostcodeSerializerJSON if as_json else PostcodeSerializerHuman)(postcode_datas)\n    echo(serializer.serialize())", "response": "Runs the CLI app."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the neighbourhood from the API.", "response": "async def fetch_neighbourhood(lat: float, long: float) -> Optional[dict]:\n    \"\"\"\n    Gets the neighbourhood from the fetch that is associated with the given postcode.\n    :return: A neighbourhood object parsed from the fetch.\n    :raise ApiError: When there was an error connecting to the API.\n    \"\"\"\n\n    lookup_url = f\"https://data.police.uk/api/locate-neighbourhood?q={lat},{long}\"\n\n    async with ClientSession() as session:\n        try:\n            async with session.get(lookup_url) as request:\n                if request.status == 404:\n                    return None\n                neighbourhood = await request.json()\n        except ClientConnectionError as con_err:\n            logger.debug(f\"Could not connect to {con_err.host}\")\n            raise ApiError(f\"Could not connect to {con_err.host}\")\n        except JSONDecodeError as dec_err:\n            logger.error(f\"Could not decode data: {dec_err}\")\n            raise ApiError(f\"Could not decode data: {dec_err}\")\n\n        neighbourhood_url = f\"https://data.police.uk/api/{neighbourhood['force']}/{neighbourhood['neighbourhood']}\"\n\n        try:\n            async with session.get(neighbourhood_url) as request:\n                neighbourhood_data = await request.json()\n        except ConnectionError as con_err:\n            logger.debug(f\"Could not connect to {con_err.args[0].pool.host}\")\n            raise ApiError(f\"Could not connect to {con_err.args[0].pool.host}\")\n        except JSONDecodeError as dec_err:\n            logger.error(f\"Could not decode data: {dec_err}\")\n            raise ApiError(f\"Could not decode data: {dec_err}\")\n\n        return neighbourhood_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def fetch_crime(lat: float, long: float) -> List[Dict]:\n    crime_lookup = f\"https://data.police.uk/api/crimes-street/all-crime?lat={lat}&lng={long}\"\n    async with ClientSession() as session:\n        try:\n            async with session.get(crime_lookup) as request:\n                crime_request = await request.json()\n        except ClientConnectionError as con_err:\n            logger.debug(f\"Could not connect to {con_err.args[0].pool.host}\")\n            raise ApiError(f\"Could not connect to {con_err.args[0].pool.host}\")\n        except JSONDecodeError as dec_err:\n            logger.error(f\"Could not decode data: {dec_err}\")\n            raise ApiError(f\"Could not decode data: {dec_err}\")\n        else:\n            return crime_request", "response": "Get crime for a given latitude and longitude."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(locations, random, bikes, crime, nearby, json, update_bikes, api_server, cross_origin, host, port, db_path,\n        verbose):\n    \"\"\"\n    Runs the program. Takes a list of postcodes or coordinates and\n    returns various information about them. If using the cli, make\n    sure to update the bikes database with the -u command.\n\n    Locations can be either a specific postcode, or a pair of coordinates.\n    Coordinates are passed in the form \"55.948824,-3.196425\".\n\n    :param locations: The list of postcodes or coordinates to search.\n    :param random: The number of random postcodes to include.\n    :param bikes: Includes a list of stolen bikes in that area.\n    :param crime: Includes a list of committed crimes in that area.\n    :param nearby: Includes a list of wikipedia articles in that area.\n    :param json: Returns the data in json format.\n    :param update_bikes: Whether to force update bikes.\n    :param api_server: If given, the program will instead run a rest api.\n    :param cross_origin:\n    :param host:\n    :param port: Defines the port to run the rest api on.\n    :param db_path: The path to the sqlite db to use.\n    :param verbose: The verbosity.\n    \"\"\"\n\n    log_levels = [logging.WARNING, logging.INFO, logging.DEBUG]\n    logging.basicConfig(level=log_levels[min(verbose, 2)])\n\n    initialize_database(db_path)\n\n    loop = get_event_loop()\n\n    if update_bikes:\n        logger.info(\"Force updating bikes.\")\n        loop.run_until_complete(util.update_bikes())\n\n    if api_server:\n        if cross_origin:\n            enable_cross_origin(app)\n\n        try:\n            web.run_app(app, host=host, port=port)\n        except CancelledError as e:\n            if e.__context__ is not None:\n                click.echo(Fore.RED + (\n                    f\"Could not bind to address {host}:{port}\" if e.__context__.errno == 48 else e.__context__))\n                exit(1)\n            else:\n                click.echo(\"Goodbye!\")\n\n    elif len(locations) > 0 or random > 0:\n        exit(loop.run_until_complete(cli(locations, random, bikes=bikes, crime=crime, nearby=nearby, as_json=json)))\n    else:\n        click.echo(Fore.RED + \"Either include a post code, or the --api-server flag.\")", "response": "Runs the program. Takes a list of postcodes or coordinates and\n    returns various information about them. If using the cli, make\n    sure to update the bikes database with the -u command.\n\n    Locations can be either a specific postcode, or a pair of coordinates.\n    Coordinates are passed in the form \"55.948824,-3.196425\".\n\n    :param locations: The list of postcodes or coordinates to search.\n    :param random: The number of random postcodes to include.\n    :param bikes: Includes a list of stolen bikes in that area.\n    :param crime: Includes a list of committed crimes in that area.\n    :param nearby: Includes a list of wikipedia articles in that area.\n    :param json: Returns the data in json format.\n    :param update_bikes: Whether to force update bikes.\n    :param api_server: If given, the program will instead run a rest api.\n    :param cross_origin:\n    :param host:\n    :param port: Defines the port to run the rest api on.\n    :param db_path: The path to the sqlite db to use.\n    :param verbose: The verbosity."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the BiDi context for the current language.", "response": "def bidi(request):\n    \"\"\"Adds to the context BiDi related variables\n\n    LANGUAGE_DIRECTION -- Direction of current language ('ltr' or 'rtl')\n    LANGUAGE_START -- Start of language layout ('right' for rtl, 'left'\n                      for 'ltr')\n    LANGUAGE_END -- End of language layout ('left' for rtl, 'right'\n                      for 'ltr')\n    LANGUAGE_MARKER -- Language marker entity ('&rlm;' for rtl, '&lrm'\n                       for ltr)\n\n    \"\"\"\n    from django.utils import translation\n    from django.utils.safestring import mark_safe\n\n    if translation.get_language_bidi():\n        extra_context = {\n            'LANGUAGE_DIRECTION':'rtl',\n            'LANGUAGE_START':'right',\n            'LANGUAGE_END':'left',\n            'LANGUAGE_MARKER': mark_safe('&rlm;'),\n        }\n    else:\n        extra_context = {\n            'LANGUAGE_DIRECTION':'ltr',\n            'LANGUAGE_START':'left',\n            'LANGUAGE_END':'right',\n            'LANGUAGE_MARKER': mark_safe('&lrm;'),\n        }\n\n    return extra_context"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines if an attribute of an instance with a specific name* is null.", "response": "def _is_null(instance, name):\n    '''\n    Determine if an attribute of an *instance* with a specific *name* \n    is null.\n    '''\n    if name in instance.__dict__:\n        value = instance.__dict__[name]\n    else:\n        value = getattr(instance, name)\n\n    if value:\n        return False\n    \n    elif value is None:\n        return True\n\n    name = name.upper()\n    metaclass = get_metaclass(instance)\n    for attr_name, attr_ty in metaclass.attributes:\n        if attr_name.upper() != name:\n            continue\n\n        attr_ty = attr_ty.upper()\n        if attr_ty == 'UNIQUE_ID':\n            # UUID(int=0) is reserved for null\n            return value == 0\n\n        elif attr_ty == 'STRING':\n            # empty string is reserved for null\n            return len(value) == 0\n\n        else:\n            #null-values for integer, boolean and real are not supported\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply_query_operators(iterable, ops):\n    '''\n    Apply a series of query operators to a sequence of instances, e.g.\n    where_eq(), order_by() or filter functions.\n    '''\n    for op in ops:\n        if isinstance(op, WhereEqual):\n            iterable = op(iterable)\n            \n        elif isinstance(op, OrderBy):\n            iterable = op(iterable)\n            \n        elif isinstance(op, dict):\n            iterable = WhereEqual(op)(iterable)\n            \n        else:\n            iterable = filter(op, iterable)\n\n    return iterable", "response": "Apply a series of query operators to a sequence of instances e. g.\n    where_eq ( where_eq ) order_by ( orderBy ) or filter functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef navigate_subtype(supertype, rel_id):\n    '''\n    Perform a navigation from *supertype* to its subtype across *rel_id*. The\n    navigated association must be modeled as a subtype-supertype association.\n    \n    The return value will an instance or None.\n    '''\n    if not supertype:\n        return\n    \n    if isinstance(rel_id, int):\n        rel_id = 'R%d' % rel_id\n\n    metaclass = get_metaclass(supertype)\n    for kind, rel_id_candidate, _ in metaclass.links:\n        if rel_id != rel_id_candidate:\n            continue\n        \n        subtype = navigate_one(supertype).nav(kind, rel_id)()\n        if subtype:\n            return subtype", "response": "Perform a navigation from a supertype to its subtype across a rel_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsorts a set of instances in the order they appear across a conditional and reflexive association.", "response": "def sort_reflexive(set_of_instances, rel_id, phrase):\n    '''\n    Sort a *set of instances* in the order they appear across a conditional and\n    reflexive association. The first instance in the resulting ordered set is\n    **not** associated to an instance across the given *phrase*.\n    '''\n    if not isinstance(set_of_instances, QuerySet):\n        raise MetaException('The collection to sort must be a QuerySet')\n    \n    if not set_of_instances.first:\n        return QuerySet()\n    \n    if isinstance(rel_id, int):\n        rel_id = 'R%d' % rel_id\n    \n    # Figure out the phrase in the other direction\n    metaclass = get_metaclass(set_of_instances.first)\n    for link in metaclass.links.values():\n        if link.to_metaclass != metaclass:\n            continue\n        \n        if link.rel_id != rel_id:\n            continue\n\n        if link.phrase == phrase:\n            continue\n\n        other_phrase = link.phrase\n        break\n    else:\n        raise UnknownLinkException(metaclass.kind, metaclass.kind, rel_id, phrase)\n    \n    first_filt = lambda sel: not navigate_one(sel).nav(metaclass.kind, rel_id, phrase)()\n    first_instances = list(filter(first_filt, set_of_instances))\n    if not first_instances:\n        #the instance sequence is recursive, start anywhere\n        first_instances = [set_of_instances.first]\n    \n    def sequence_generator():\n        for first in first_instances:\n            inst = first\n            while inst:\n                if inst in set_of_instances:\n                    yield inst\n                inst = navigate_one(inst).nav(metaclass.kind, rel_id, other_phrase)()\n                if inst is first:\n                    break\n                \n    return QuerySet(sequence_generator())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _find_link(inst1, inst2, rel_id, phrase):\n    '''\n    Find links that correspond to the given arguments.\n    '''\n    metaclass1 = get_metaclass(inst1)\n    metaclass2 = get_metaclass(inst2)\n\n    if isinstance(rel_id, int):\n        rel_id = 'R%d' % rel_id\n        \n    for ass in metaclass1.metamodel.associations:\n        if ass.rel_id != rel_id:\n            continue\n\n        if (ass.source_link.from_metaclass.kind == metaclass1.kind and\n            ass.source_link.to_metaclass.kind == metaclass2.kind and\n            ass.source_link.phrase == phrase):\n            return inst1, inst2, ass\n\n        if (ass.target_link.from_metaclass.kind == metaclass1.kind and\n            ass.target_link.to_metaclass.kind == metaclass2.kind and\n            ass.target_link.phrase == phrase):\n            return inst2, inst1, ass\n\n    raise UnknownLinkException(metaclass1.kind, metaclass2.kind, rel_id, phrase)", "response": "Find links that correspond to the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrelating from_instance to to_instance across the relationship_id.", "response": "def relate(from_instance, to_instance, rel_id, phrase=''):\n    '''\n    Relate *from_instance* to *to_instance* across *rel_id*. For reflexive\n    association, a *phrase* indicating the direction must also be provided.\n    \n    The two instances are related to each other by copying the identifying \n    attributes from the instance on the TO side of a association to the instance\n    n the FROM side. Updated values which affect existing associations are \n    propagated. A set of all affected instances will be returned.\n    '''\n    if None in [from_instance, to_instance]:\n        return False\n\n    inst1, inst2, ass = _find_link(from_instance, to_instance, rel_id, phrase)\n    if not ass.source_link.connect(inst1, inst2):\n        raise RelateException(from_instance, to_instance, rel_id, phrase)\n\n    if not ass.target_link.connect(inst2, inst1):\n        raise RelateException(from_instance, to_instance, rel_id, phrase)\n    \n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_metaclass(class_or_instance):\n    '''\n    Get the metaclass for a *class_or_instance*.\n    '''\n    if isinstance(class_or_instance, Class):\n        return class_or_instance.__metaclass__\n    \n    elif issubclass(class_or_instance, Class):\n        return class_or_instance.__metaclass__\n    \n    raise MetaException(\"the provided argument is not an xtuml class or instance\")", "response": "Get the metaclass for a class or instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(instance, disconnect=True):\n    '''\n    Delete an *instance* from its metaclass instance pool and optionally\n    *disconnect* it from any links it might be connected to.\n    '''\n    if not isinstance(instance, Class):\n        raise DeleteException(\"the provided argument is not an xtuml instance\")\n            \n    return get_metaclass(instance).delete(instance, disconnect)", "response": "Delete an instance from its metaclass instance pool and optionally delete it from any links it might be connected to."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef formalize(self):\n        '''\n        Formalize the association and expose referential attributes\n        on instances.\n        '''\n        source_class = self.source_link.to_metaclass\n        target_class = self.target_link.to_metaclass\n        \n        source_class.referential_attributes |= set(self.source_keys)\n        target_class.identifying_attributes |= set(self.target_keys)\n\n        def fget(inst, ref_name, alt_prop):\n            other_inst = self.target_link.navigate_one(inst)\n            if other_inst is None and alt_prop:\n                return alt_prop.fget(inst)\n            \n            return getattr(other_inst, ref_name, None)\n\n        def fset(inst, value, name, ref_name, alt_prop):\n            kind = get_metaclass(inst).kind\n            raise MetaException('%s.%s is a referential attribute '\\\n                                'and cannot be assigned directly'% (kind, name))\n        \n            #other_inst = self.target_link.navigate_one(inst)\n            #if other_inst is None and alt_prop:\n            #    return alt_prop.fset(inst, value)\n            #\n            #elif other_inst:\n            #    return setattr(other_inst, ref_name, value)\n        \n        for ref_key, primary_key in zip(self.source_keys, self.target_keys):\n            prop = getattr(source_class.clazz, ref_key, None)\n            prop = property(partial(fget, ref_name=primary_key, alt_prop=prop), \n                            partial(fset, name=ref_key, ref_name=primary_key, alt_prop=prop))\n            setattr(source_class.clazz, ref_key, prop)", "response": "Formalize the association and expose referential attributes on instances."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cardinality(self):\n        '''\n        Obtain the cardinality string.\n        \n        Example: '1C' for a conditional link with a single instance [0..1]\n                 'MC' for a link with any number of instances [0..*]\n                 'M'  for a more than one instance [1..*]\n                 'M'  for a link with exactly one instance [1]\n        '''\n        if self.many:\n            s = 'M'\n        else:\n            s = '1'\n            \n        if self.conditional:\n            s += 'C'\n            \n        return s", "response": "Obtain the cardinality string."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconnects an instance to another_instance.", "response": "def connect(self, instance, another_instance, check=True):\n        '''\n        Connect an *instance* to *another_instance*.\n        \n        Optionally, disable any cardinality *check* that would prevent the two\n        instances from being connected.\n        '''\n        if instance not in self:\n            self[instance] = xtuml.OrderedSet()\n        \n        if another_instance in self[instance]:\n            return True\n        \n        if self[instance] and not self.many and check:\n            return False  \n\n        self[instance].add(another_instance)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndisconnect an instance from another_instance.", "response": "def disconnect(self, instance, another_instance):\n        '''\n        Disconnect an *instance* from *another_instance*.\n        '''\n        if instance not in self:\n            return False\n        \n        if another_instance not in self[instance]: \n            return False\n\n        self[instance].remove(another_instance)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the lookup key for an instance i. e. a foreign key that can be used to identify an instance at the end of the link.", "response": "def compute_lookup_key(self, from_instance):\n        '''\n        Compute the lookup key for an instance, i.e. a foreign key that\n        can be used to identify an instance at the end of the link.\n        '''\n        kwargs = dict()\n        for attr, other_attr in self.key_map.items():\n            if _is_null(from_instance, attr):\n                return None\n            \n            if attr in from_instance.__dict__:\n                kwargs[other_attr] = from_instance.__dict__[attr]\n            else:\n                kwargs[other_attr] = getattr(from_instance, attr)\n\n        return frozenset(tuple(kwargs.items()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compute_index_key(self, to_instance):\n        '''\n        Compute the index key that can be used to identify an instance\n        on the link.\n        '''\n        kwargs = dict()\n        for attr in self.key_map.values():\n            if _is_null(to_instance, attr):\n                return None\n            \n            if attr in to_instance.__dict__:\n                kwargs[attr] = to_instance.__dict__[attr]\n            else:\n                kwargs[attr] = getattr(to_instance, attr)\n\n        return frozenset(tuple(kwargs.items()))", "response": "Compute the index key that can be used to identify an instance\n            on the link."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nobtain the type of an attribute.", "response": "def attribute_type(self, attribute_name):\n        '''\n        Obtain the type of an attribute.\n        '''\n        attribute_name = attribute_name.upper()\n        for name, ty in self.attributes:\n            if name.upper() == attribute_name:\n                return ty"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a new link from self to metaclass.", "response": "def add_link(self, metaclass, rel_id, phrase, conditional, many):\n        '''\n        Add a new link from *self* to *metaclass*.\n        '''\n        link = Link(self, rel_id, metaclass, phrase, conditional, many)\n        key = (metaclass.kind.upper(), rel_id, phrase)\n        self.links[key] = link\n\n        return link"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef append_attribute(self, name, type_name):\n        '''\n        Append an attribute with a given *name* and *type name* at the end of\n        the list of attributes.\n        '''\n        attr = (name, type_name)\n        self.attributes.append(attr)", "response": "Append an attribute with a given name and type name to the end of the list of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef insert_attribute(self, index, name, type_name):\n        '''\n        Insert an attribute with a given *name* and *type name* at some *index*\n        in the list of attributes.\n        '''\n        attr = (name, type_name)\n        self.attributes.insert(index, attr)", "response": "Insert an attribute with a given name and type name at some index in the list of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_attribute(self, name):\n        '''\n        Delete an attribute with a given *name* from the list of attributes.\n        '''\n        for idx, attr in enumerate(self.attributes):\n            attr_name, _ = attr\n            if attr_name == name:\n                del self.attributes[idx]\n                return", "response": "Delete an attribute with a given name from the list of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef default_value(self, type_name):\n        '''\n        Obtain the default value for some *type name*.\n        '''\n        uname = type_name.upper()\n        if   uname == 'BOOLEAN':\n            return False\n            \n        elif uname == 'INTEGER':\n            return 0\n            \n        elif uname == 'REAL':\n            return 0.0\n            \n        elif uname == 'STRING':\n            return ''\n            \n        elif uname == 'UNIQUE_ID':\n            if self.metamodel:\n                return next(self.metamodel.id_generator)\n            else:\n                return None\n        else:\n            raise MetaException(\"Unknown type named '%s'\" % type_name)", "response": "Obtain the default value for some type name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef new(self, *args, **kwargs):\n        '''\n        Create and return a new instance.\n        '''\n        inst = self.clazz()\n        self.storage.append(inst)\n        \n        # set all attributes with an initial default value\n        referential_attributes = dict()\n        for name, ty in self.attributes:\n            if name not in self.referential_attributes:\n                value = self.default_value(ty)\n                setattr(inst, name, value)\n            \n        # set all positional arguments\n        for attr, value in zip(self.attributes, args):\n            name, ty = attr\n            if name not in self.referential_attributes:\n                setattr(inst, name, value)\n            else:\n                referential_attributes[name] = value\n            \n        # set all named arguments\n        for name, value in kwargs.items():\n            if name not in self.referential_attributes:\n                setattr(inst, name, value)\n            else:\n                referential_attributes[name] = value\n        \n        if not referential_attributes:\n            return inst\n        \n        # batch relate referential attributes \n        for link in self.links.values():\n            if set(link.key_map.values()) - set(referential_attributes.keys()):\n                continue\n             \n            kwargs = dict()\n            for key, value in link.key_map.items():\n                kwargs[key] = referential_attributes[value]\n            \n            if not kwargs:\n                continue\n            \n            for other_inst in link.to_metaclass.query(kwargs):\n                relate(other_inst, inst, link.rel_id, link.phrase)\n        \n        for name, value in referential_attributes.items():\n            if getattr(inst, name) != value:\n                logger.warning('unable to assign %s to %s', name, inst)\n                \n        return inst", "response": "Create and return a new instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clone(self, instance):\n        '''\n        Create a shallow clone of an *instance*.\n        \n        **Note:** the clone and the original instance **does not** have to be\n        part of the same metaclass. \n        '''\n        args = list()\n        for name, _ in get_metaclass(instance).attributes:\n            value = getattr(instance, name)\n            args.append(value)\n            \n        return self.new(*args)", "response": "Create a shallow clone of an instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete an instance from the instance pool and optionally disconnects it from any links it might be connected to.", "response": "def delete(self, instance, disconnect=True):\n        '''\n        Delete an *instance* from the instance pool and optionally *disconnect*\n        it from any links it might be connected to. If the *instance* is not\n        part of the metaclass, a *MetaException* is thrown.\n        '''\n        if instance in self.storage:\n            self.storage.remove(instance)\n        else:\n            raise DeleteException(\"Instance not found in the instance pool\")\n\n        if not disconnect:\n            return\n        \n        for link in self.links.values():\n            if instance not in link:\n                continue\n        \n            for other in link[instance]:\n                unrelate(instance, other, link.rel_id, link.phrase)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef select_one(self, *args):\n        '''\n        Select a single instance from the instance pool. Query operators such as\n        where_eq(), order_by() or filter functions may be passed as optional\n        arguments.\n        '''\n        s = apply_query_operators(self.storage, args)\n        return next(iter(s), None)", "response": "Select a single instance from the instance pool."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select_many(self, *args):\n        '''\n        Select several instances from the instance pool. Query operators such as\n        where_eq(), order_by() or filter functions may be passed as optional\n        arguments.\n        '''\n        s = apply_query_operators(self.storage, args)\n        if isinstance(s, QuerySet):\n            return s\n        else:\n            return QuerySet(s)", "response": "Select several instances from the instance pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nnavigates across a link with some rel_id and phrase that yields instances of some kind.", "response": "def navigate(self, inst, kind, rel_id, phrase=''):\n        '''\n        Navigate across a link with some *rel_id* and *phrase* that yields\n        instances of some *kind*.\n        '''\n        key = (kind.upper(), rel_id, phrase)\n        if key in self.links:\n            link = self.links[key]\n            return link.navigate(inst)\n        \n        link1, link2 = self._find_assoc_links(kind, rel_id, phrase)\n        inst_set = xtuml.OrderedSet()\n        for inst in link1.navigate(inst):\n            inst_set |= link2.navigate(inst)\n        \n        return inst_set"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a sequence of all instances in the metamodel.", "response": "def instances(self):\n        '''\n        Obtain a sequence of all instances in the metamodel.\n        '''\n        for metaclass in self.metaclasses.values():\n            for inst in metaclass.storage:\n                yield inst"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef define_class(self, kind, attributes, doc=''):\n        '''\n        Define a new class in the metamodel, and return its metaclass.\n        '''\n        ukind = kind.upper()\n        if ukind in self.metaclasses:\n            raise MetaModelException('A class with the name %s is already defined' % kind)\n\n        metaclass = MetaClass(kind, self)\n        for name, ty in attributes:\n            metaclass.append_attribute(name, ty)\n            \n        self.metaclasses[ukind] = metaclass\n        \n        return metaclass", "response": "Define a new class in the metamodel and return its metaclass."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_metaclass(self, kind):\n        '''\n        Find a metaclass of some *kind* in the metamodel.\n        '''\n        ukind = kind.upper()\n        if ukind in self.metaclasses:\n            return self.metaclasses[ukind]\n        else:\n            raise UnknownClassException(kind)", "response": "Find a metaclass of some kind in the metamodel."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate and return a new instance of some kind.", "response": "def new(self, kind, *args, **kwargs):\n        '''\n        Create and return a new instance in the metamodel of some *kind*.\n        \n        Optionally, initial attribute values may be assigned to the new instance\n        by passing them as positional or keyword arguments. Positional arguments\n        are assigned in the order in which they appear in the metaclass.\n        '''\n        metaclass = self.find_metaclass(kind)\n        return metaclass.new(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clone(self, instance):\n        '''\n        Create a shallow clone of an *instance*.\n        \n        **Note:** the clone and the original instance **does not** have to be\n        part of the same metaclass. \n        '''\n        metaclass = get_metaclass(instance)\n        metaclass = self.find_metaclass(metaclass.kind)\n        return metaclass.clone(instance)", "response": "Create a shallow clone of an instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef define_association(self, rel_id, source_kind, source_keys, source_many,\n                           source_conditional, source_phrase, target_kind, \n                           target_keys, target_many, target_conditional, \n                           target_phrase):\n        '''\n        Define and return an association from one kind of class (the source \n        kind) to some other kind of class (the target kind).\n        '''\n        if isinstance(rel_id, int):\n            rel_id = 'R%d' % rel_id\n            \n        source_metaclass = self.find_metaclass(source_kind)\n        target_metaclass = self.find_metaclass(target_kind)\n\n        source_link = target_metaclass.add_link(source_metaclass, rel_id,\n                                                many=source_many,\n                                                phrase=target_phrase,\n                                                conditional=source_conditional)\n                \n        target_link = source_metaclass.add_link(target_metaclass, rel_id,\n                                                many=target_many,\n                                                phrase=source_phrase,\n                                                conditional=target_conditional)\n        \n        ass = Association(rel_id,\n                          source_keys, source_link,\n                          target_keys, target_link)\n        \n        source_link.key_map = dict(zip(source_keys, target_keys))\n        target_link.key_map = dict(zip(target_keys, source_keys))\n        \n        self.associations.append(ass)\n\n        return ass", "response": "Define and return an association from one kind of class to another kind of class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndefining a unique identifier for some kind of class based on its name and named attributes.", "response": "def define_unique_identifier(self, kind, name, *named_attributes):\n        '''\n        Define a unique identifier for some *kind* of class based on its\n        *named attributes*.\n        '''\n        if not named_attributes:\n            return\n        \n        if isinstance(name, int):\n            name = 'I%d' % name\n        \n        metaclass = self.find_metaclass(kind)\n        metaclass.indices[name] = tuple(named_attributes)\n        metaclass.identifying_attributes |= set(named_attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nquery the metamodel for a set of instances of some kind.", "response": "def select_many(self, kind, *args):\n        '''\n        Query the metamodel for a set of instances of some *kind*. Query\n        operators such as where_eq(), order_by() or filter functions may be\n        passed as optional arguments.\n        \n        Usage example:\n        \n        >>> m = xtuml.load_metamodel('db.sql')\n        >>> inst_set = m.select_many('My_Class', lambda sel: sel.number > 5)\n        '''\n        metaclass = self.find_metaclass(kind)\n        return metaclass.select_many(*args)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquery the metamodel for a single instance of some kind.", "response": "def select_one(self, kind, *args):\n        '''\n        Query the metamodel for a single instance of some *kind*. Query\n        operators such as where_eq(), order_by() or filter functions may be\n        passed as optional arguments.\n        \n        Usage example:\n        \n        >>> m = xtuml.load_metamodel('db.sql')\n        >>> inst = m.select_one('My_Class', lambda sel: sel.name == 'Test')\n        '''\n        metaclass = self.find_metaclass(kind)\n        return metaclass.select_one(*args)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def api_twitter(request):\n    handle = request.match_info.get('handle', None)\n    if handle is None:\n        raise web.HTTPNotFound(body=\"Not found.\")\n\n    try:\n        posts = await fetch_twitter(handle)\n    except ApiError as e:\n        raise web.HTTPInternalServerError(body=e.status)\n    return str_json_response(posts)", "response": "Get the twitter feed from a given handle."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send(socket, header, payload, topics=(), flags=0):\n    msgs = []\n    msgs.extend(topics)\n    msgs.append(SEAM)\n    msgs.extend(header)\n    msgs.append(payload)\n    return eintr_retry_zmq(socket.send_multipart, msgs, flags)", "response": "Sends header payload and topics through a ZeroMQ socket."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef recv(socket, flags=0, capture=(lambda msgs: None)):\n    msgs = eintr_retry_zmq(socket.recv_multipart, flags)\n    capture(msgs)\n    return parse(msgs)", "response": "Receives header payload and topics through a ZeroMQ socket."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntakes a string or list of strings and try to extract all the emails", "response": "def parse_emails(values):\n    '''\n    Take a string or list of strings and try to extract all the emails\n    '''\n    emails = []\n    if isinstance(values, str):\n        values = [values]\n    # now we know we have a list of strings\n    for value in values:\n        matches = re_emails.findall(value)\n        emails.extend([match[2] for match in matches])\n    return emails"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmarking a method as RPC.", "response": "def rpc(f=None, **kwargs):\n    \"\"\"Marks a method as RPC.\"\"\"\n    if f is not None:\n        if isinstance(f, six.string_types):\n            if 'name' in kwargs:\n                raise ValueError('name option duplicated')\n            kwargs['name'] = f\n        else:\n            return rpc(**kwargs)(f)\n    return functools.partial(_rpc, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rpc_spec_table(app):\n    table = {}\n    for attr, value in inspect.getmembers(app):\n        rpc_spec = get_rpc_spec(value, default=None)\n        if rpc_spec is None:\n            continue\n        table[rpc_spec.name] = (value, rpc_spec)\n    return table", "response": "Collects methods which are speced as RPC."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def normalize_postcode_middleware(request, handler):\n    postcode: Optional[str] = request.match_info.get('postcode', None)\n\n    if postcode is None or postcode == \"random\":\n        return await handler(request)\n    elif not is_uk_postcode(postcode):\n        raise web.HTTPNotFound(text=\"Invalid Postcode\")\n\n    postcode_processed = postcode.upper().replace(\" \", \"\")\n    if postcode_processed == postcode:\n        return await handler(request)\n    else:\n        url_name = request.match_info.route.name\n        url = request.app.router[url_name]\n        params = dict(request.match_info)\n        params['postcode'] = postcode_processed\n        raise web.HTTPMovedPermanently(str(url.url_for(**params)))", "response": "This is the main middleware that handles the normalizing of the postcode in the url."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_repr(obj, params=None, keywords=None, data=None, name=None,\n              reprs=None):\n    \"\"\"Generates a string of object initialization code style.  It is useful\n    for custom __repr__ methods::\n\n       class Example(object):\n\n           def __init__(self, param, keyword=None):\n               self.param = param\n               self.keyword = keyword\n\n           def __repr__(self):\n               return make_repr(self, ['param'], ['keyword'])\n\n    See the representation of example object::\n\n       >>> Example('hello', keyword='world')\n       Example('hello', keyword='world')\n    \"\"\"\n    opts = []\n    if params is not None:\n        opts.append(', '.join(\n            _repr_attr(obj, attr, data, reprs) for attr in params))\n    if keywords is not None:\n        opts.append(', '.join(\n            '%s=%s' % (attr, _repr_attr(obj, attr, data, reprs))\n            for attr in keywords))\n    if name is None:\n        name = class_name(obj)\n    return '%s(%s)' % (name, ', '.join(opts))", "response": "Generates a string of object initialization code style."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretries a function in a node with the given exception type.", "response": "def eintr_retry(exc_type, f, *args, **kwargs):\n    \"\"\"Calls a function.  If an error of the given exception type with\n    interrupted system call (EINTR) occurs calls the function again.\n    \"\"\"\n    while True:\n        try:\n            return f(*args, **kwargs)\n        except exc_type as exc:\n            if exc.errno != EINTR:\n                raise\n        else:\n            break"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef eintr_retry_zmq(f, *args, **kwargs):\n    return eintr_retry(zmq.ZMQError, f, *args, **kwargs)", "response": "A wrapper for eintr_retry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef next(self):\n        '''\n        Progress to the next identifier, and return the current one.\n        '''\n        val = self._current\n        self._current = self.readfunc()\n        return val", "response": "Returns the next identifier."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef enter(self, node):\n        '''\n        Tries to invoke a method matching the pattern *enter_<type name>*, where\n        <type name> is the name of the type of the *node*.\n        '''\n        name = 'enter_' + node.__class__.__name__\n        fn = getattr(self, name, self.default_enter)\n        fn(node)", "response": "Tries to invoke a method matching the pattern enter_<type name >* where\n        <type name > is the name of the node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef leave(self, node):\n        '''\n        Tries to invoke a method matching the pattern *leave_<type name>*, where\n        <type name> is the name of the type of the *node*.\n        '''\n        name = 'leave_' + node.__class__.__name__\n        fn = getattr(self, name, self.default_leave)\n        fn(node)", "response": "Tries to invoke a method matching the pattern leave_<type name >* where\n        <type name > is the name of the node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninvoke the visitors before and after decending down the tree.", "response": "def accept(self, node, **kwargs):\n        '''\n        Invoke the visitors before and after decending down the tree. \n        The walker will also try to invoke a method matching the pattern \n        *accept_<type name>*, where <type name> is the name of the accepted\n        *node*.\n        '''\n        if node is None:\n            return\n        \n        for v in self.visitors:\n            v.enter(node)\n        \n        name = 'accept_' + node.__class__.__name__\n        fn = getattr(self, name, self.default_accept)\n        r = fn(node, **kwargs)\n        \n        for v in self.visitors:\n            v.leave(node)\n        \n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef default_accept(self, node, **kwargs):\n        '''\n        The default accept behaviour is to decend into the iterable member\n        *node.children* (if available).\n        '''\n        if not hasattr(node, 'children'):\n            return\n        \n        for child in node.children:\n            self.accept(child, **kwargs)", "response": "Default accept behaviour is to decend into the iterable member\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrying to invoke a method matching the pattern render_<type name >* where <type name > is the name of the rendering node.", "response": "def render(self, node):\n        '''\n        Try to invoke a method matching the pattern *render_<type name>*, where\n        <type name> is the name of the rendering *node*.\n        '''\n        name = 'render_' + type(node).__name__\n        fn = getattr(self, name, self.default_render)\n        return fn(node)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef accept_S_SYS(self, inst):\n        '''\n        A System Model contains top-level packages\n        '''\n        for child in many(inst).EP_PKG[1401]():\n            self.accept(child)", "response": "Accept the S_SYS related objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\naccepts the C component.", "response": "def accept_C_C(self, inst):\n        '''\n        A Component contains packageable elements\n        '''\n        for child in many(inst).PE_PE[8003]():\n            self.accept(child)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef accept_EP_PKG(self, inst):\n        '''\n        A Package contains packageable elements\n        '''\n        for child in many(inst).PE_PE[8000]():\n            self.accept(child)", "response": "Accept all the EEP - PKG elements in the given instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def update_bikes(delta: Optional[timedelta] = None):\n\n    async def update(delta: timedelta):\n        logger.info(\"Fetching bike data.\")\n        if await should_update_bikes(delta):\n            try:\n                bike_data = await fetch_bikes()\n            except ApiError:\n                logger.debug(f\"Failed to fetch bikes.\")\n            except CircuitBreakerError:\n                logger.debug(f\"Failed to fetch bikes (circuit breaker open).\")\n            else:\n                # save only bikes that aren't in the db\n                most_recent_bike = Bike.get_most_recent_bike()\n                new_bikes = (\n                    Bike.from_dict(bike) for index, bike in enumerate(bike_data)\n                    if index > (most_recent_bike.id if most_recent_bike is not None else -1)\n                )\n\n                counter = 0\n                with Bike._meta.database.atomic():\n                    for bike in new_bikes:\n                        bike.save()\n                        counter += 1\n                logger.info(f\"Saved {counter} new entries.\")\n        else:\n            logger.info(\"Bike data up to date.\")\n\n    if delta is None:\n        await update(timedelta(days=1000))\n    else:\n        while True:\n            await update(delta)\n            await asyncio.sleep(delta.total_seconds())", "response": "A background task that retrieves bike data and saves them to the database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck the most recently cached bike and returns true if it exists and if it is not yet updated.", "response": "async def should_update_bikes(delta: timedelta):\n    \"\"\"\n    Checks the most recently cached bike and returns true if\n    it either doesn't exist or\n    :return: Whether the cache should be updated.\n\n    todo what if there are no bikes added for a week? ... every request will be triggered.\n    \"\"\"\n    bike = Bike.get_most_recent_bike()\n    if bike is not None:\n        return bike.cached_date < datetime.now() - delta\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget stolen bikes from the database within certain radius of a given postcode.", "response": "async def get_bikes(postcode: PostCodeLike, kilometers=1) -> Optional[List[Bike]]:\n    \"\"\"\n    Gets stolen bikes from the database within a\n    certain radius (km) of a given postcode. Selects\n    a square from the database and then filters out\n    the corners of the square.\n    :param postcode: The postcode to look up.\n    :param kilometers: The radius (km) of the search.\n    :return: The bikes in that radius or None if the postcode doesn't exist.\n    \"\"\"\n\n    try:\n        postcode_opt = await get_postcode(postcode)\n    except CachingError as e:\n        raise e\n\n    if postcode_opt is None:\n        return None\n    else:\n        postcode = postcode_opt\n\n    # create point and distance\n    center = Point(postcode.lat, postcode.long)\n    distance = geodesic(kilometers=kilometers)\n\n    # calculate edges of a square and retrieve\n    lat_end = distance.destination(point=center, bearing=0).latitude\n    lat_start = distance.destination(point=center, bearing=180).latitude\n    long_start = distance.destination(point=center, bearing=270).longitude\n    long_end = distance.destination(point=center, bearing=90).longitude\n\n    bikes_in_area = Bike.select().where(\n        lat_start <= Bike.latitude,\n        Bike.latitude <= lat_end,\n        long_start <= Bike.longitude,\n        Bike.longitude <= long_end\n    )\n\n    # filter out items in square that aren't within the radius and return\n    return [\n        bike for bike in bikes_in_area\n        if geodesic(Point(bike.latitude, bike.longitude), center).kilometers < kilometers\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def get_postcode_random() -> Postcode:\n    try:\n        postcode = await fetch_postcode_random()\n    except (ApiError, CircuitBreakerError):\n        raise CachingError(f\"Requested postcode is not cached, and can't be retrieved.\")\n\n    if postcode is not None:\n        postcode.save()\n    return postcode", "response": "Gets a random postcode object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def get_postcode(postcode_like: PostCodeLike) -> Optional[Postcode]:\n    if isinstance(postcode_like, Postcode):\n        return postcode_like\n\n    postcode_like = postcode_like.replace(\" \", \"\").upper()\n\n    try:\n        postcode = Postcode.get(Postcode.postcode == postcode_like)\n    except DoesNotExist:\n        try:\n            postcode = await fetch_postcode_from_string(postcode_like)\n        except (ApiError, CircuitBreakerError):\n            raise CachingError(f\"Requested postcode is not cached, and can't be retrieved.\")\n        if postcode is not None:\n            postcode.save()\n\n    return postcode", "response": "Gets the postcode object for a given postcode string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def get_neighbourhood(postcode_like: PostCodeLike) -> Optional[Neighbourhood]:\n    try:\n        postcode = await get_postcode(postcode_like)\n    except CachingError as e:\n        raise e\n    else:\n        if postcode is None:\n            return None\n        elif postcode.neighbourhood is not None:\n            return postcode.neighbourhood\n\n    try:\n        data = await fetch_neighbourhood(postcode.lat, postcode.long)\n    except ApiError as e:\n        raise CachingError(f\"Neighbourhood not in cache, and could not reach API: {e.status}\")\n\n    if data is not None:\n        neighbourhood = Neighbourhood.from_dict(data)\n        locations = [Location.from_dict(neighbourhood, postcode, location) for location in data[\"locations\"]]\n        links = [Link.from_dict(neighbourhood, link) for link in data[\"links\"]]\n\n        with Neighbourhood._meta.database.atomic():\n            neighbourhood.save()\n            postcode.neighbourhood = neighbourhood\n            postcode.save()\n            for location in locations:\n                location.save()\n            for link in links:\n                link.save()\n    else:\n        neighbourhood = None\n    return neighbourhood", "response": "Gets a neighbourhood from the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_cdata(self, *args):\n        '''\n        all args-->_cffi_backend.buffer\n        Returns-->cdata (if a SINGLE argument was provided)\n                  LIST of cdata (if a args was a tuple or list)\n        '''\n        res = tuple([\n            self.from_buffer(x) for x in args\n        ])\n\n        if len(res) == 0:\n            return None\n        elif len(res) == 1:\n            return res[0]\n        else:\n            return res", "response": "get_cdata - Returns a tuple of cdata"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a buffer from the list of arguments.", "response": "def get_buffer(self, *args):\n        '''\n        all args-->_cffi_backend.CDataOwn\n        Must be a pointer or an array\n        Returns-->buffer (if a SINGLE argument was provided)\n                  LIST of buffer (if a args was a tuple or list)\n        '''\n        res = tuple([\n            self.buffer(x) for x in args\n        ])\n\n        if len(res) == 0:\n            return None\n        elif len(res) == 1:\n            return res[0]\n        else:\n            return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_bytes(self, *args):\n        '''\n        all args-->_cffi_backend.CDataOwn\n        Must be a pointer or an array\n        Returns-->bytes (if a SINGLE argument was provided)\n                  LIST of bytes (if a args was a tuple or list)\n        '''\n        res = tuple([\n            bytes(self.buffer(x)) for x in args\n        ])\n\n        if len(res) == 0:\n            return None\n        elif len(res) == 1:\n            return res[0]\n        else:\n            return res", "response": "Get the bytes for the current cffi entry set."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the average brightness of the image.", "response": "def get_brightness(self):\n        \"\"\"\n        Return the average brightness of the image.\n        \"\"\"\n        # Only download the image if it has changed\n        if not self.connection.has_changed():\n            return self.image_brightness\n\n        image_path = self.connection.download_image()\n\n        converted_image = Image.open(image_path).convert('L')\n        statistics = ImageStat.Stat(converted_image)\n\n        self.image_brightness = statistics.mean[0]\n        return self.image_brightness"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_file (filename, contents):\n    contents = \"\\n\".join(contents)\n    if sys.version_info >= (3,):\n        contents = contents.encode(\"utf-8\")\n    f = open(filename, \"wb\")        # always write POSIX-style manifest\n    f.write(contents)\n    f.close()", "response": "Write contents to a file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_file(self, what, filename, data):\n        log.info(\"writing %s to %s\", what, filename)\n        if sys.version_info >= (3,):\n            data = data.encode(\"utf-8\")\n        if not self.dry_run:\n            f = open(filename, 'wb')\n            f.write(data)\n            f.close()", "response": "Write data to filename."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting the file list in self. filelist to the manifest file named by self. manifest.", "response": "def write_manifest (self):\n        \"\"\"Write the file list in 'self.filelist' (presumably as filled in\n        by 'add_defaults()' and 'read_template()') to the manifest file\n        named by 'self.manifest'.\n        \"\"\"\n        # The manifest must be UTF-8 encodable. See #303.\n        if sys.version_info >= (3,):\n            files = []\n            for file in self.filelist.files:\n                try:\n                    file.encode(\"utf-8\")\n                except UnicodeEncodeError:\n                    log.warn(\"'%s' not UTF-8 encodable -- skipping\" % file)\n                else:\n                    files.append(file)\n            self.filelist.files = files\n\n        files = self.filelist.files\n        if os.sep!='/':\n            files = [f.replace(os.sep,'/') for f in files]\n        self.execute(write_file, (self.manifest, files),\n                     \"writing manifest file '%s'\" % self.manifest)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nindicates whether or not to enter a case suite. usage: ``` py for case in switch(value): if case('A'): pass elif case(1, 3): pass # for mulit-match. else: pass # for default. ```", "response": "def match(self, *args):\n        \"\"\"\n        Indicate whether or not to enter a case suite.\n\n        usage:\n\n        ``` py\n        for case in switch(value):\n            if case('A'):\n                pass\n            elif case(1, 3):\n                pass # for mulit-match.\n            else:\n                pass # for default.\n        ```\n        \"\"\"\n        if not args:\n            raise SyntaxError('cannot case empty pattern.')\n\n        return self.match_args(self._value, args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _find_match(self, position):\n        # Decide what character to search for and what direction to search in.\n        document = self._text_edit.document()\n        start_char = document.characterAt(position)\n        search_char = self._opening_map.get(start_char)\n        if search_char:\n            increment = 1\n        else:\n            search_char = self._closing_map.get(start_char)\n            if search_char:\n                increment = -1\n            else:\n                return -1\n\n        # Search for the character.\n        char = start_char\n        depth = 0\n        while position >= 0 and position < document.characterCount():\n            if char == start_char:\n                depth += 1\n            elif char == search_char:\n                depth -= 1\n            if depth == 0:\n                break\n            position += increment\n            char = document.characterAt(position)\n        else:\n            position = -1\n        return position", "response": "Given a valid position in the text document try to find the next bracket. Returns - 1 if unsuccessful."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _selection_for_character(self, position):\n        selection = QtGui.QTextEdit.ExtraSelection()\n        cursor = self._text_edit.textCursor()\n        cursor.setPosition(position)\n        cursor.movePosition(QtGui.QTextCursor.NextCharacter,\n                            QtGui.QTextCursor.KeepAnchor)\n        selection.cursor = cursor\n        selection.format = self.format\n        return selection", "response": "Returns a selection object for the current character at the given position."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _cursor_position_changed(self):\n        # Clear out the old formatting.\n        self._text_edit.setExtraSelections([])\n\n        # Attempt to match a bracket for the new cursor position.\n        cursor = self._text_edit.textCursor()\n        if not cursor.hasSelection():\n            position = cursor.position() - 1\n            match_position = self._find_match(position)\n            if match_position != -1:\n                extra_selections = [ self._selection_for_character(pos)\n                                     for pos in (position, match_position) ]\n                self._text_edit.setExtraSelections(extra_selections)", "response": "Updates the document formatting based on the new cursor position."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _exc_info(self):\n        e = self.exc_info()\n        if sys.platform == 'cli':\n            if isinstance(e[0], StringException):\n                # IronPython throws these StringExceptions, but\n                # traceback checks type(etype) == str. Make a real\n                # string here.\n                e = (str(e[0]), e[1], e[2])\n\n        return e", "response": "Bottleneck to fix up IronPython string exceptions\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self, result):\n        # proxy the result for myself\n        log.debug(\"suite %s (%s) run called, tests: %s\", id(self), self, self._tests)\n        #import pdb\n        #pdb.set_trace()\n        if self.resultProxy:\n            result, orig = self.resultProxy(result, self), result\n        else:\n            result, orig = result, result\n        try:\n            self.setUp()\n        except KeyboardInterrupt:\n            raise\n        except:\n            self.error_context = 'setup'\n            result.addError(self, self._exc_info())\n            return\n        try:\n            for test in self._tests:\n                if result.shouldStop:\n                    log.debug(\"stopping\")\n                    break\n                # each nose.case.Test will create its own result proxy\n                # so the cases need the original result, to avoid proxy\n                # chains\n                test(orig)\n        finally:\n            self.has_run = True\n            try:\n                self.tearDown()\n            except KeyboardInterrupt:\n                raise\n            except:\n                self.error_context = 'teardown'\n                result.addError(self, self._exc_info())", "response": "Run the tests in the suite inside of the suite fixtures."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the ancestry of the specified context.", "response": "def ancestry(self, context):\n        \"\"\"Return the ancestry of the context (that is, all of the\n        packages and modules containing the context), in order of\n        descent with the outermost ancestor last.\n        This method is a generator.\n        \"\"\"\n        log.debug(\"get ancestry %s\", context)\n        if context is None:\n            return\n        # Methods include reference to module they are defined in, we\n        # don't want that, instead want the module the class is in now\n        # (classes are re-ancestored elsewhere).\n        if hasattr(context, 'im_class'):\n            context = context.im_class\n        elif hasattr(context, '__self__'):\n            context = context.__self__.__class__\n        if hasattr(context, '__module__'):\n            ancestors = context.__module__.split('.')\n        elif hasattr(context, '__name__'):\n            ancestors = context.__name__.split('.')[:-1]\n        else:\n            raise TypeError(\"%s has no ancestors?\" % context)\n        while ancestors:\n            log.debug(\" %s ancestors %s\", context, ancestors)\n            yield resolve_name('.'.join(ancestors))\n            ancestors.pop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_inputhook_qt4(mgr, app=None):\n\n    if app is None:\n        app = QtCore.QCoreApplication.instance()\n        if app is None:\n            app = QtGui.QApplication([\" \"])\n\n    # Re-use previously created inputhook if any\n    ip = InteractiveShell.instance()\n    if hasattr(ip, '_inputhook_qt4'):\n        return app, ip._inputhook_qt4\n\n    # Otherwise create the inputhook_qt4/preprompthook_qt4 pair of\n    # hooks (they both share the got_kbdint flag)\n\n    got_kbdint = [False]\n\n    def inputhook_qt4():\n        \"\"\"PyOS_InputHook python hook for Qt4.\n\n        Process pending Qt events and if there's no pending keyboard\n        input, spend a short slice of time (50ms) running the Qt event\n        loop.\n\n        As a Python ctypes callback can't raise an exception, we catch\n        the KeyboardInterrupt and temporarily deactivate the hook,\n        which will let a *second* CTRL+C be processed normally and go\n        back to a clean prompt line.\n        \"\"\"\n        try:\n            allow_CTRL_C()\n            app = QtCore.QCoreApplication.instance()\n            if not app: # shouldn't happen, but safer if it happens anyway...\n                return 0\n            app.processEvents(QtCore.QEventLoop.AllEvents, 300)\n            if not stdin_ready():\n                timer = QtCore.QTimer()\n                timer.timeout.connect(app.quit)\n                while not stdin_ready():\n                    timer.start(50)\n                    app.exec_()\n                    timer.stop()\n        except KeyboardInterrupt:\n            ignore_CTRL_C()\n            got_kbdint[0] = True\n            print(\"\\nKeyboardInterrupt - Ctrl-C again for new prompt\")\n            mgr.clear_inputhook()\n        except: # NO exceptions are allowed to escape from a ctypes callback\n            ignore_CTRL_C()\n            from traceback import print_exc\n            print_exc()\n            print(\"Got exception from inputhook_qt4, unregistering.\")\n            mgr.clear_inputhook()\n        finally:\n            allow_CTRL_C()\n        return 0\n\n    def preprompthook_qt4(ishell):\n        \"\"\"'pre_prompt_hook' used to restore the Qt4 input hook\n\n        (in case the latter was temporarily deactivated after a\n        CTRL+C)\n        \"\"\"\n        if got_kbdint[0]:\n            mgr.set_inputhook(inputhook_qt4)\n        got_kbdint[0] = False\n\n    ip._inputhook_qt4 = inputhook_qt4\n    ip.set_hook('pre_prompt_hook', preprompthook_qt4)\n\n    return app, inputhook_qt4", "response": "Create an inputhook for running the Qt4 application event loop."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(cls, name=__name__):\n        if not isinstance(name, str):\n            raise TypeError('A mapper name must be a string')\n\n        if name not in cls.__instances:\n            cls.__instances[name] = cls()\n            cls.__instances[name]._name = name\n\n        return cls.__instances[name]", "response": "Returns a new instance of the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef url(self, pattern, method=None, type_cast=None):\n        if not type_cast:\n            type_cast = {}\n\n        def decorator(function):\n            self.add(pattern, function, method, type_cast)\n            return function\n\n        return decorator", "response": "Decorator for registering a path pattern."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef s_url(self, path, method=None, type_cast=None):\n        if not type_cast:\n            type_cast = {}\n\n        def decorator(function):\n            self.s_add(path, function, method, type_cast)\n            return function\n\n        return decorator", "response": "Decorator for registering a simple url."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add(self, pattern, function, method=None, type_cast=None):\n        if not type_cast:\n            type_cast = {}\n\n        with self._lock:\n            self._data_store.append({\n                'pattern': pattern,\n                'function': function,\n                'method': method,\n                'type_cast': type_cast,\n            })", "response": "Function for registering a path pattern."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning for registering a simple path.", "response": "def s_add(self, path, function, method=None, type_cast=None):\n        \"\"\"Function for registering a simple path.\n\n        Args:\n            path (str): Path to be matched.\n            function (function): Function to associate with this path.\n            method (str, optional): Usually used to define one of GET, POST,\n                PUT, DELETE. You may use whatever fits your situation though.\n                Defaults to None.\n            type_cast (dict, optional): Mapping between the param name and\n                one of `int`, `float` or `bool`. The value reflected by the\n                provided param name will than be casted to the given type.\n                Defaults to None.\n        \"\"\"\n        with self._lock:\n            try:\n                path = '^/{}'.format(path.lstrip('/'))\n                path = '{}/$'.format(path.rstrip('/'))\n                path = path.replace('<', '(?P<')\n                path = path.replace('>', '>[^/]*)')\n\n                self.add(path, function, method, type_cast)\n            except Exception:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall the first function matching the urls pattern and method.", "response": "def call(self, url, method=None, args=None):\n        \"\"\"Calls the first function matching the urls pattern and method.\n\n        Args:\n            url (str): Url for which to call a matching function.\n            method (str, optional): The method used while registering a\n                function.\n                Defaults to None\n            args (dict, optional): Additional args to be passed to the\n                matching function.\n\n        Returns:\n            The functions return value or `None` if no function was called.\n        \"\"\"\n        if not args:\n            args = {}\n\n        if sys.version_info.major == 3:\n            data = urllib.parse.urlparse(url)\n            path = data.path.rstrip('/') + '/'\n            _args = dict(urllib.parse.parse_qs(data.query,\n                                               keep_blank_values=True))\n        elif sys.version_info.major == 2:\n            data = urlparse.urlparse(url)\n            path = data.path.rstrip('/') + '/'\n            _args = dict(urlparse.parse_qs(data.query,\n                                           keep_blank_values=True))\n\n        for elem in self._data_store:\n            pattern = elem['pattern']\n            function = elem['function']\n            _method = elem['method']\n            type_cast = elem['type_cast']\n\n            result = re.match(pattern, path)\n\n            # Found matching method\n            if result and _method == method:\n                _args = dict(_args, **result.groupdict())\n\n                # Unpack value lists (due to urllib.parse.parse_qs) in case\n                # theres only one value available\n                for key, val in _args.items():\n                    if isinstance(_args[key], list) and len(_args[key]) == 1:\n                        _args[key] = _args[key][0]\n\n                # Apply typ-casting if necessary\n                for key, val in type_cast.items():\n\n                    # Not within available _args, no type-cast required\n                    if key not in _args:\n                        continue\n\n                    # Is None or empty, no type-cast required\n                    if not _args[key]:\n                        continue\n\n                    # Try and cast the values\n                    if isinstance(_args[key], list):\n                        for i, _val in enumerate(_args[key]):\n                            _args[key][i] = self._cast(_val, val)\n                    else:\n                        _args[key] = self._cast(_args[key], val)\n\n                requiered_args = self._get_function_args(function)\n                for key, val in args.items():\n                    if key in requiered_args:\n                        _args[key] = val\n\n                return function(**_args)\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute(self, source=None, hidden=False, interactive=False):\n        if not hidden:\n            history = self.input_buffer if source is None else source\n\n        executed = super(HistoryConsoleWidget, self).execute(\n            source, hidden, interactive)\n\n        if executed and not hidden:\n            # Save the command unless it was an empty string or was identical\n            # to the previous command.\n            history = history.rstrip()\n            if history and (not self._history or self._history[-1] != history):\n                self._history.append(history)\n\n            # Emulate readline: reset all history edits.\n            self._history_edits = {}\n\n            # Move the history index to the most recent item.\n            self._history_index = len(self._history)\n\n        return executed", "response": "Reimplemented to the store history."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls when the up key is pressed. Returns True if the event should be handled otherwise False.", "response": "def _up_pressed(self, shift_modifier):\n        \"\"\" Called when the up key is pressed. Returns whether to continue\n            processing the event.\n        \"\"\"\n        prompt_cursor = self._get_prompt_cursor()\n        if self._get_cursor().blockNumber() == prompt_cursor.blockNumber():\n            # Bail out if we're locked.\n            if self._history_locked() and not shift_modifier:\n                return False\n\n            # Set a search prefix based on the cursor position.\n            col = self._get_input_buffer_cursor_column()\n            input_buffer = self.input_buffer\n            if self._history_index == len(self._history) or \\\n                    (self._history_prefix and col != len(self._history_prefix)):\n                self._history_index = len(self._history)\n                self._history_prefix = input_buffer[:col]\n\n            # Perform the search.\n            self.history_previous(self._history_prefix,\n                                    as_prefix=not shift_modifier)\n\n            # Go to the first line of the prompt for seemless history scrolling.\n            # Emulate readline: keep the cursor position fixed for a prefix\n            # search.\n            cursor = self._get_prompt_cursor()\n            if self._history_prefix:\n                cursor.movePosition(QtGui.QTextCursor.Right,\n                                    n=len(self._history_prefix))\n            else:\n                cursor.movePosition(QtGui.QTextCursor.EndOfLine)\n            self._set_cursor(cursor)\n\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _down_pressed(self, shift_modifier):\n        end_cursor = self._get_end_cursor()\n        if self._get_cursor().blockNumber() == end_cursor.blockNumber():\n            # Bail out if we're locked.\n            if self._history_locked() and not shift_modifier:\n                return False\n\n            # Perform the search.\n            replaced = self.history_next(self._history_prefix,\n                                            as_prefix=not shift_modifier)\n\n            # Emulate readline: keep the cursor position fixed for a prefix\n            # search. (We don't need to move the cursor to the end of the buffer\n            # in the other case because this happens automatically when the\n            # input buffer is set.)\n            if self._history_prefix and replaced:\n                cursor = self._get_prompt_cursor()\n                cursor.movePosition(QtGui.QTextCursor.Right,\n                                    n=len(self._history_prefix))\n                self._set_cursor(cursor)\n\n            return False\n\n        return True", "response": "Called when the down key is pressed. Returns whether to continue processing the event."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching for a previous history item. If as_prefix is True then set the input buffer to the previous history item. Otherwise return False.", "response": "def history_previous(self, substring='', as_prefix=True):\n        \"\"\" If possible, set the input buffer to a previous history item.\n\n        Parameters:\n        -----------\n        substring : str, optional\n            If specified, search for an item with this substring.\n        as_prefix : bool, optional\n            If True, the substring must match at the beginning (default).\n\n        Returns:\n        --------\n        Whether the input buffer was changed.\n        \"\"\"\n        index = self._history_index\n        replace = False\n        while index > 0:\n            index -= 1\n            history = self._get_edited_history(index)\n            if (as_prefix and history.startswith(substring)) \\\n                or (not as_prefix and substring in history):\n                replace = True\n                break\n\n        if replace:\n            self._store_edits()\n            self._history_index = index\n            self.input_buffer = history\n\n        return replace"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef history_next(self, substring='', as_prefix=True):\n        index = self._history_index\n        replace = False\n        while self._history_index < len(self._history):\n            index += 1\n            history = self._get_edited_history(index)\n            if (as_prefix and history.startswith(substring)) \\\n                or (not as_prefix and substring in history):\n                replace = True\n                break\n\n        if replace:\n            self._store_edits()\n            self._history_index = index\n            self.input_buffer = history\n\n        return replace", "response": "Search for a subsequent entry in the history."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _handle_execute_reply(self, msg):\n        msg_id = msg['parent_header']['msg_id']\n        info = self._request_info['execute'].pop(msg_id,None)\n        if info and info.kind == 'save_magic' and not self._hidden:\n            content = msg['content']\n            status = content['status']\n            if status == 'ok':\n                self._max_session_history=(int(content['user_expressions']['hlen']))", "response": "Handles replies for code execution"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _history_locked(self):\n        return (self.history_lock and\n                (self._get_edited_history(self._history_index) !=\n                 self.input_buffer) and\n                (self._get_prompt_cursor().blockNumber() !=\n                 self._get_end_cursor().blockNumber()))", "response": "Returns whether history is locked."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_edited_history(self, index):\n        if index in self._history_edits:\n            return self._history_edits[index]\n        elif index == len(self._history):\n            return unicode()\n        return self._history[index]", "response": "Retrieves a history item possibly with temporary edits."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_history(self, history):\n        self._history = list(history)\n        self._history_edits = {}\n        self._history_index = len(self._history)", "response": "Replace the current history with a sequence of history items."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _store_edits(self):\n        current = self.input_buffer\n        if self._history_index == len(self._history) or \\\n                self._history[self._history_index] != current:\n            self._history_edits[self._history_index] = current", "response": "Store the edits in the history."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef t_NAME(t):\n    r'[A-Za-z_][A-Za-z0-9_]*'\n    # to simplify lexing, we match identifiers and keywords as a single thing\n    # if it's a keyword, we change the type to the name of that keyword\n    if t.value.upper() in reserved:\n        t.type = t.value.upper()\n        t.value = t.value.upper()\n    return t", "response": "A simple name match for identifiers and keywords"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef t_STRING(t):\n    r\"'([^'\\\\]+|\\\\'|\\\\\\\\)*'\"\n    t.value = t.value.replace(r'\\\\', chr(92)).replace(r\"\\'\", r\"'\")[1:-1]\n    return t", "response": "r \"'([^'\\\\]+|\\\\'|\\\\\\\\ ) *'\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse postpositions parameter into a single object", "response": "def p_postpositions(p):\n    '''\n    postpositions : LIMIT NUMBER postpositions\n                  | ORDER BY colspec postpositions\n                  | empty\n    '''\n    if len(p) > 2:\n        if p[1] == \"LIMIT\":\n            postposition = {\n                \"limit\": p[2]\n            }\n            rest = p[3] if p[3] else {}\n        elif p[1:3] == [\"ORDER\", \"BY\"]:\n            postposition = {\n                \"order by\": p[3]\n            }\n            rest = p[4] if p[4] else {}\n        else:\n            breakpoint()\n        p[0] = {**postposition, **rest}\n    else:\n        p[0] = {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_expression(p):\n    '''\n    expression : value\n               | expression AND expression\n               | expression OR expression\n               | expression EQUALS expression\n               | NOT expression\n               | LPAREN expression RPAREN\n    '''\n    if len(p) < 3:\n        p[0] = p[1]\n    elif len(p) == 3:  # not\n        p[0] = {\n            \"op\": \"not\",\n            \"args\": [p[2]],\n        }\n    elif p[1] == \"(\":\n        p[0] = p[2]\n    else:\n        p[0] = {\n            \"op\": p[2].lower(),\n            \"args\": [p[1], p[3]],\n        }", "response": "A function to parse the expression part of a sequence."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef upgrade_dir(srcdir, tgtdir):\n\n    def pr(s):\n        print s\n    junk = ['.svn','ipythonrc*','*.pyc', '*.pyo', '*~', '.hg']\n    \n    def ignorable(p):\n        for pat in junk:\n            if p.startswith(pat) or p.fnmatch(pat):\n                return True\n        return False\n\n    modded = []\n    files = [path(srcdir).relpathto(p) for p in path(srcdir).walkfiles()]\n    #print files\n    rep = tgtdir / '.upgrade_report'\n    try:\n        rpt = pickle.load(rep.open())\n    except:\n        rpt = {}\n\n    for f in files:\n        if ignorable(f):\n            continue\n        src = srcdir / f\n        tgt = tgtdir / f\n        if not tgt.isfile():\n            pr(\"Creating %s\" % str(tgt))\n\n            tgt.write_text(src.text())\n            rpt[str(tgt)] = hashlib.md5(tgt.text()).hexdigest()\n        else:\n            cont = tgt.text()\n            sum = rpt.get(str(tgt), None)\n            #print sum\n            if sum and hashlib.md5(cont).hexdigest() == sum:\n                pr(\"%s: Unedited, installing new version\" % tgt)\n                tgt.write_text(src.text())\n                rpt[str(tgt)] = hashlib.md5(tgt.text()).hexdigest()\n            else:\n                pr(' == Modified, skipping %s, diffs below == ' % tgt)\n                #rpt[str(tgt)] = hashlib.md5(tgt.bytes()).hexdigest()\n                real = showdiff(tgt,src)\n                pr('') # empty line\n                if not real:\n                    pr(\"(Ok, it was identical, only upgrading checksum)\")\n                    rpt[str(tgt)] = hashlib.md5(tgt.text()).hexdigest()\n                else:\n                    modded.append(tgt)\n\n        #print rpt\n    pickle.dump(rpt, rep.open('w'))\n    if modded:\n        print \"\\n\\nDelete the following files manually (and rerun %upgrade)\\nif you need a full upgrade:\"\n        for m in modded:\n            print m", "response": "Copy all files in srcdir to tgtdir and create a new version of the target."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prepare_files(self, finder):\n        from pip.index import Link\n\n        unnamed = list(self.unnamed_requirements)\n        reqs = list(self.requirements.values())\n        while reqs or unnamed:\n            if unnamed:\n                req_to_install = unnamed.pop(0)\n            else:\n                req_to_install = reqs.pop(0)\n            install = True\n            best_installed = False\n            not_found = None\n\n            # ############################################# #\n            # # Search for archive to fulfill requirement # #\n            # ############################################# #\n\n            if not self.ignore_installed and not req_to_install.editable:\n                req_to_install.check_if_exists()\n                if req_to_install.satisfied_by:\n                    if self.upgrade:\n                        if not self.force_reinstall and not req_to_install.url:\n                            try:\n                                url = finder.find_requirement(\n                                    req_to_install, self.upgrade)\n                            except BestVersionAlreadyInstalled:\n                                best_installed = True\n                                install = False\n                            except DistributionNotFound as exc:\n                                not_found = exc\n                            else:\n                                # Avoid the need to call find_requirement again\n                                req_to_install.url = url.url\n\n                        if not best_installed:\n                            # don't uninstall conflict if user install and\n                            # conflict is not user install\n                            if not (self.use_user_site\n                                    and not dist_in_usersite(\n                                        req_to_install.satisfied_by\n                                    )):\n                                req_to_install.conflicts_with = \\\n                                    req_to_install.satisfied_by\n                            req_to_install.satisfied_by = None\n                    else:\n                        install = False\n                if req_to_install.satisfied_by:\n                    if best_installed:\n                        logger.info(\n                            'Requirement already up-to-date: %s',\n                            req_to_install,\n                        )\n                    else:\n                        logger.info(\n                            'Requirement already satisfied (use --upgrade to '\n                            'upgrade): %s',\n                            req_to_install,\n                        )\n            if req_to_install.editable:\n                logger.info('Obtaining %s', req_to_install)\n            elif install:\n                if (req_to_install.url\n                        and req_to_install.url.lower().startswith('file:')):\n                    path = url_to_path(req_to_install.url)\n                    logger.info('Processing %s', display_path(path))\n                else:\n                    logger.info('Collecting %s', req_to_install)\n\n            with indent_log():\n                # ################################ #\n                # # vcs update or unpack archive # #\n                # ################################ #\n\n                is_wheel = False\n                if req_to_install.editable:\n                    if req_to_install.source_dir is None:\n                        location = req_to_install.build_location(self.src_dir)\n                        req_to_install.source_dir = location\n                    else:\n                        location = req_to_install.source_dir\n                    if not os.path.exists(self.build_dir):\n                        _make_build_dir(self.build_dir)\n                    req_to_install.update_editable(not self.is_download)\n                    if self.is_download:\n                        req_to_install.run_egg_info()\n                        req_to_install.archive(self.download_dir)\n                    else:\n                        req_to_install.run_egg_info()\n                elif install:\n                    # @@ if filesystem packages are not marked\n                    # editable in a req, a non deterministic error\n                    # occurs when the script attempts to unpack the\n                    # build directory\n\n                    # NB: This call can result in the creation of a temporary\n                    # build directory\n                    location = req_to_install.build_location(\n                        self.build_dir,\n                    )\n                    unpack = True\n                    url = None\n\n                    # If a checkout exists, it's unwise to keep going.  version\n                    # inconsistencies are logged later, but do not fail the\n                    # installation.\n                    if os.path.exists(os.path.join(location, 'setup.py')):\n                        raise PreviousBuildDirError(\n                            \"pip can't proceed with requirements '%s' due to a\"\n                            \" pre-existing build directory (%s). This is \"\n                            \"likely due to a previous installation that failed\"\n                            \". pip is being responsible and not assuming it \"\n                            \"can delete this. Please delete it and try again.\"\n                            % (req_to_install, location)\n                        )\n                    else:\n                        # FIXME: this won't upgrade when there's an existing\n                        # package unpacked in `location`\n                        if req_to_install.url is None:\n                            if not_found:\n                                raise not_found\n                            url = finder.find_requirement(\n                                req_to_install,\n                                upgrade=self.upgrade,\n                            )\n                        else:\n                            # FIXME: should req_to_install.url already be a\n                            # link?\n                            url = Link(req_to_install.url)\n                            assert url\n                        if url:\n                            try:\n\n                                if (\n                                    url.filename.endswith(wheel_ext)\n                                    and self.wheel_download_dir\n                                ):\n                                    # when doing 'pip wheel`\n                                    download_dir = self.wheel_download_dir\n                                    do_download = True\n                                else:\n                                    download_dir = self.download_dir\n                                    do_download = self.is_download\n                                unpack_url(\n                                    url, location, download_dir,\n                                    do_download, session=self.session,\n                                )\n                            except requests.HTTPError as exc:\n                                logger.critical(\n                                    'Could not install requirement %s because '\n                                    'of error %s',\n                                    req_to_install,\n                                    exc,\n                                )\n                                raise InstallationError(\n                                    'Could not install requirement %s because '\n                                    'of HTTP error %s for URL %s' %\n                                    (req_to_install, exc, url)\n                                )\n                        else:\n                            unpack = False\n                    if unpack:\n                        is_wheel = url and url.filename.endswith(wheel_ext)\n                        if self.is_download:\n                            req_to_install.source_dir = location\n                            if not is_wheel:\n                                # FIXME:https://github.com/pypa/pip/issues/1112\n                                req_to_install.run_egg_info()\n                            if url and url.scheme in vcs.all_schemes:\n                                req_to_install.archive(self.download_dir)\n                        elif is_wheel:\n                            req_to_install.source_dir = location\n                            req_to_install.url = url.url\n                        else:\n                            req_to_install.source_dir = location\n                            req_to_install.run_egg_info()\n                            req_to_install.assert_source_matches_version()\n                        # req_to_install.req is only avail after unpack for URL\n                        # pkgs repeat check_if_exists to uninstall-on-upgrade\n                        # (#14)\n                        if not self.ignore_installed:\n                            req_to_install.check_if_exists()\n                        if req_to_install.satisfied_by:\n                            if self.upgrade or self.ignore_installed:\n                                # don't uninstall conflict if user install and\n                                # conflict is not user install\n                                if not (self.use_user_site\n                                        and not dist_in_usersite(\n                                            req_to_install.satisfied_by)):\n                                    req_to_install.conflicts_with = \\\n                                        req_to_install.satisfied_by\n                                req_to_install.satisfied_by = None\n                            else:\n                                logger.info(\n                                    'Requirement already satisfied (use '\n                                    '--upgrade to upgrade): %s',\n                                    req_to_install,\n                                )\n                                install = False\n\n                # ###################### #\n                # # parse dependencies # #\n                # ###################### #\n                if (req_to_install.extras):\n                    logger.debug(\n                        \"Installing extra requirements: %r\",\n                        ','.join(req_to_install.extras),\n                    )\n\n                if is_wheel:\n                    dist = list(\n                        pkg_resources.find_distributions(location)\n                    )[0]\n                else:  # sdists\n                    if req_to_install.satisfied_by:\n                        dist = req_to_install.satisfied_by\n                    else:\n                        dist = req_to_install.get_dist()\n                    # FIXME: shouldn't be globally added:\n                    if dist.has_metadata('dependency_links.txt'):\n                        finder.add_dependency_links(\n                            dist.get_metadata_lines('dependency_links.txt')\n                        )\n\n                if not self.ignore_dependencies:\n                    for subreq in dist.requires(\n                            req_to_install.extras):\n                        if self.has_requirement(\n                                subreq.project_name):\n                            # FIXME: check for conflict\n                            continue\n                        subreq = InstallRequirement(\n                            str(subreq),\n                            req_to_install,\n                            isolated=self.isolated,\n                        )\n                        reqs.append(subreq)\n                        self.add_requirement(subreq)\n\n                if not self.has_requirement(req_to_install.name):\n                    # 'unnamed' requirements will get added here\n                    self.add_requirement(req_to_install)\n\n                # cleanup tmp src\n                if (self.is_download or\n                        req_to_install._temp_build_dir is not None):\n                    self.reqs_to_cleanup.append(req_to_install)\n\n                if install:\n                    self.successfully_downloaded.append(req_to_install)", "response": "Prepare the archive for the current version of the user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cleanup_files(self):\n        logger.debug('Cleaning up...')\n        with indent_log():\n            for req in self.reqs_to_cleanup:\n                req.remove_temporary_source()\n\n            if self._pip_has_created_build_dir():\n                logger.debug('Removing temporary dir %s...', self.build_dir)\n                rmtree(self.build_dir)", "response": "Clean up files remove builds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninstall all packages in this set.", "response": "def install(self, install_options, global_options=(), *args, **kwargs):\n        \"\"\"\n        Install everything in this set (after having downloaded and unpacked\n        the packages)\n        \"\"\"\n        to_install = [r for r in self.requirements.values()[::-1]\n                      if not r.satisfied_by]\n\n        # DISTRIBUTE TO SETUPTOOLS UPGRADE HACK (1 of 3 parts)\n        # move the distribute-0.7.X wrapper to the end because it does not\n        # install a setuptools package. by moving it to the end, we ensure it's\n        # setuptools dependency is handled first, which will provide the\n        # setuptools package\n        # TODO: take this out later\n        distribute_req = pkg_resources.Requirement.parse(\"distribute>=0.7\")\n        for req in to_install:\n            if (req.name == 'distribute'\n                    and req.installed_version is not None\n                    and req.installed_version in distribute_req):\n                to_install.remove(req)\n                to_install.append(req)\n\n        if to_install:\n            logger.info(\n                'Installing collected packages: %s',\n                ', '.join([req.name for req in to_install]),\n            )\n\n        with indent_log():\n            for requirement in to_install:\n\n                # DISTRIBUTE TO SETUPTOOLS UPGRADE HACK (1 of 3 parts)\n                # when upgrading from distribute-0.6.X to the new merged\n                # setuptools in py2, we need to force setuptools to uninstall\n                # distribute. In py3, which is always using distribute, this\n                # conversion is already happening in distribute's\n                # pkg_resources. It's ok *not* to check if setuptools>=0.7\n                # because if someone were actually trying to ugrade from\n                # distribute to setuptools 0.6.X, then all this could do is\n                # actually help, although that upgade path was certainly never\n                # \"supported\"\n                # TODO: remove this later\n                if requirement.name == 'setuptools':\n                    try:\n                        # only uninstall distribute<0.7. For >=0.7, setuptools\n                        # will also be present, and that's what we need to\n                        # uninstall\n                        distribute_requirement = \\\n                            pkg_resources.Requirement.parse(\"distribute<0.7\")\n                        existing_distribute = \\\n                            pkg_resources.get_distribution(\"distribute\")\n                        if existing_distribute in distribute_requirement:\n                            requirement.conflicts_with = existing_distribute\n                    except pkg_resources.DistributionNotFound:\n                        # distribute wasn't installed, so nothing to do\n                        pass\n\n                if requirement.conflicts_with:\n                    logger.info(\n                        'Found existing installation: %s',\n                        requirement.conflicts_with,\n                    )\n                    with indent_log():\n                        requirement.uninstall(auto_confirm=True)\n                try:\n                    requirement.install(\n                        install_options,\n                        global_options,\n                        *args,\n                        **kwargs\n                    )\n                except:\n                    # if install did not succeed, rollback previous uninstall\n                    if (requirement.conflicts_with\n                            and not requirement.install_succeeded):\n                        requirement.rollback_uninstall()\n                    raise\n                else:\n                    if (requirement.conflicts_with\n                            and requirement.install_succeeded):\n                        requirement.commit_uninstall()\n                requirement.remove_temporary_source()\n\n        self.successfully_installed = to_install"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_record(index_series_tuple, kwargs):\n    '''\n    Generates an instance of Record() from a tuple of the form (index, pandas.Series) \n    with associated parameters kwargs\n\n    Paremeters\n    ----------\n    index_series_tuple : tuple\n        tuple consisting of (index, pandas.Series)\n    kwargs : dict\n        aditional arguments\n\n    Returns\n    -------\n    Record : object\n\n    '''\n\n    index_record = index_series_tuple[0]\n    series = index_series_tuple[1]\n    record = Record()\n    record.series = series\n    record.index_record = index_record\n    record.set_attributes(kwargs)\n    return record", "response": "Returns an instance of Record from a tuple of the form index series."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a list of Record objects given a DataFrame.", "response": "def build_collection(df, **kwargs):\n    '''\n    Generates a list of Record objects given a DataFrame.\n    Each Record instance has a series attribute which is a pandas.Series of the same attributes \n    in the DataFrame.\n    Optional data can be passed in through kwargs which will be included by the name of each object.\n\n    parameters\n    ----------\n    df : pandas.DataFrame\n    kwargs : alternate arguments to be saved by name to the series of each object\n\n    Returns\n    -------\n    collection : list\n        list of Record objects where each Record represents one row from a dataframe\n\n    Examples\n    --------\n    This is how we generate a Record Collection from a DataFrame.\n\n    >>> import pandas as pd\n    >>> import turntable\n    >>>\n    >>> df = pd.DataFrame({'Artist':\"\"\"Michael Jackson, Pink Floyd, Whitney Houston, Meat Loaf, \n        Eagles, Fleetwood Mac, Bee Gees, AC/DC\"\"\".split(', '),\n    >>> 'Album' :\"\"\"Thriller, The Dark Side of the Moon, The Bodyguard, Bat Out of Hell, \n        Their Greatest Hits (1971-1975), Rumours, Saturday Night Fever, Back in Black\"\"\".split(', ')})\n    >>> collection = turntable.press.build_collection(df, my_favorite_record = 'nevermind')\n    >>> record = collection[0]\n    >>> print record.series\n\n    '''\n\n    print 'Generating the Record Collection...\\n'\n\n    df['index_original'] = df.index\n    df.reset_index(drop=True, inplace=True)\n\n    if pd.__version__ >= '0.15.0':\n        d = df.T.to_dict(orient='series')\n    else:\n        d = df.T.to_dict(outtype='series')\n\n    collection = [load_record(item, kwargs) for item in d.items()]\n    return collection"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a collection back into a pandas DataFrame", "response": "def collection_to_df(collection):\n    ''' \n    Converts a collection back into a pandas DataFrame\n\n    parameters\n    ----------\n    collection : list\n        list of Record objects where each Record represents one row from a dataframe\n\n    Returns\n    -------\n    df : pandas.DataFrame\n        DataFrame of length=len(collection) where each row represents one Record \n\n    '''\n\n    return pd.concat([record.series for record in collection], axis=1).T"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef spin_frame(df, method):\n    ''' \n    Runs the full turntable process on a pandas DataFrame\n\n    parameters\n    ----------\n    df : pandas.DataFrame\n        each row represents a record\n    method : def method(record)\n        function used to process each row\n\n    Returns\n    -------\n    df : pandas.DataFrame\n        DataFrame processed by method\n\n    Example\n    -------\n    >>> import pandas as pd\n    >>> import turntable\n    >>>\n    >>> df = pd.DataFrame({'Artist':\"\"\"Michael Jackson, Pink Floyd, Whitney Houston, Meat Loaf, Eagles, Fleetwood Mac, Bee Gees, AC/DC\"\"\".split(', '), 'Album':\"\"\"Thriller, The Dark Side of the Moon, The Bodyguard, Bat Out of Hell, Their Greatest Hits (1971\u20131975), Rumours, Saturday Night Fever, Back in Black\"\"\".split(', ')})\n    >>>\n    >>> def method(record):\n    >>>    record.cost = 40\n    >>>    return record\n    >>>\n    >>> turntable.press.spin_frame(df, method)\n    \n\n    '''\n    collection = build_collection(df)\n    collection = turntable.spin.batch(collection, method)\n    return collection_to_df(collection)", "response": "Runs the full turntable process on a pandas DataFrame df"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_attributes(self, kwargs):\n        '''\n        Initalizes the given argument structure as properties of the class\n        to be used by name in specific method execution.\n\n        Parameters\n        ----------\n        kwargs : dictionary\n            Dictionary of extra attributes,\n            where keys are attributes names and values attributes values.\n\n        '''\n\n        for key, value in kwargs.items():\n            setattr(self, key, value)", "response": "Sets the attributes of the class object as properties of the class object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef subscribe(self):\n        self.stream.setsockopt(zmq.UNSUBSCRIBE, '')\n        if '' in self.topics:\n            self.log.debug(\"Subscribing to: everything\")\n            self.stream.setsockopt(zmq.SUBSCRIBE, '')\n        else:\n            for topic in self.topics:\n                self.log.debug(\"Subscribing to: %r\"%(topic))\n                self.stream.setsockopt(zmq.SUBSCRIBE, topic)", "response": "Update our SUB socket s subscriptions."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _extract_level(self, topic_str):\n        topics = topic_str.split('.')\n        for idx,t in enumerate(topics):\n            level = getattr(logging, t, None)\n            if level is not None:\n                break\n        \n        if level is None:\n            level = logging.INFO\n        else:\n            topics.pop(idx)\n        \n        return level, '.'.join(topics)", "response": "Turn engine. 0. INFO. extra into ( logging. INFO"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log_message(self, raw):\n        if len(raw) != 2 or '.' not in raw[0]:\n            self.log.error(\"Invalid log message: %s\"%raw)\n            return\n        else:\n            topic, msg = raw\n            # don't newline, since log messages always newline:\n            topic,level_name = topic.rsplit('.',1)\n            level,topic = self._extract_level(topic)\n            if msg[-1] == '\\n':\n                msg = msg[:-1]\n            self.log.log(level, \"[%s] %s\" % (topic, msg))", "response": "receive and parse a message then log it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform an N - way merge on a list of lists.", "response": "def mergesort(list_of_lists, key=None):\n    \"\"\" Perform an N-way merge operation on sorted lists.\n\n    @param list_of_lists: (really iterable of iterable) of sorted elements\n    (either by naturally or by C{key})\n    @param key: specify sort key function (like C{sort()}, C{sorted()})\n\n    Yields tuples of the form C{(item, iterator)}, where the iterator is the\n    built-in list iterator or something you pass in, if you pre-generate the\n    iterators.\n\n    This is a stable merge; complexity O(N lg N)\n\n    Examples::\n\n    >>> print list(mergesort([[1,2,3,4],\n    ...                      [2,3.25,3.75,4.5,6,7],\n    ...                      [2.625,3.625,6.625,9]]))\n    [1, 2, 2, 2.625, 3, 3.25, 3.625, 3.75, 4, 4.5, 6, 6.625, 7, 9]\n\n    # note stability\n    >>> print list(mergesort([[1,2,3,4],\n    ...                      [2,3.25,3.75,4.5,6,7],\n    ...                      [2.625,3.625,6.625,9]],\n    ...                      key=int))\n    [1, 2, 2, 2.625, 3, 3.25, 3.75, 3.625, 4, 4.5, 6, 6.625, 7, 9]\n\n\n    >>> print list(mergesort([[4, 3, 2, 1],\n    ...                      [7, 6, 4.5, 3.75, 3.25, 2],\n    ...                      [9, 6.625, 3.625, 2.625]],\n    ...                      key=lambda x: -x))\n    [9, 7, 6.625, 6, 4.5, 4, 3.75, 3.625, 3.25, 3, 2.625, 2, 2, 1]\n    \"\"\"\n\n    heap = []\n    for i, itr in enumerate(iter(pl) for pl in list_of_lists):\n        try:\n            item = itr.next()\n            if key:\n                toadd = (key(item), i, item, itr)\n            else:\n                toadd = (item, i, itr)\n            heap.append(toadd)\n        except StopIteration:\n            pass\n    heapq.heapify(heap)\n\n    if key:\n        while heap:\n            _, idx, item, itr = heap[0]\n            yield item\n            try:\n                item = itr.next()\n                heapq.heapreplace(heap, (key(item), idx, item, itr) )\n            except StopIteration:\n                heapq.heappop(heap)\n\n    else:\n        while heap:\n            item, idx, itr = heap[0]\n            yield item\n            try:\n                heapq.heapreplace(heap, (itr.next(), idx, itr))\n            except StopIteration:\n                heapq.heappop(heap)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remote_iterator(view,name):\n    view.execute('it%s=iter(%s)'%(name,name), block=True)\n    while True:\n        try:\n            result = view.apply_sync(lambda x: x.next(), Reference('it'+name))\n        # This causes the StopIteration exception to be raised.\n        except RemoteError as e:\n            if e.ename == 'StopIteration':\n                raise StopIteration\n            else:\n                raise e\n        else:\n            yield result", "response": "Return an iterator on an object living on a remote engine."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_to_this_nbformat(nb, orig_version=1):\n    if orig_version == 1:\n        newnb = new_notebook()\n        ws = new_worksheet()\n        for cell in nb.cells:\n            if cell.cell_type == u'code':\n                newcell = new_code_cell(input=cell.get('code'),prompt_number=cell.get('prompt_number'))\n            elif cell.cell_type == u'text':\n                newcell = new_text_cell(u'markdown',source=cell.get('text'))\n            ws.cells.append(newcell)\n        newnb.worksheets.append(ws)\n        return newnb\n    else:\n        raise ValueError('Cannot convert a notebook from v%s to v2' % orig_version)", "response": "Convert a notebook to the v2 format."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_supported_platform():\n    plat = get_build_platform(); m = macosVersionString.match(plat)\n    if m is not None and sys.platform == \"darwin\":\n        try:\n            plat = 'macosx-%s-%s' % ('.'.join(_macosx_vers()[:2]), m.group(3))\n        except ValueError:\n            pass    # not Mac OS X\n    return plat", "response": "Return this platform s maximum compatible version."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_importer(path_item):\n    try:\n        importer = sys.path_importer_cache[path_item]\n    except KeyError:\n        for hook in sys.path_hooks:\n            try:\n                importer = hook(path_item)\n            except ImportError:\n                pass\n            else:\n                break\n        else:\n            importer = None\n\n    sys.path_importer_cache.setdefault(path_item,importer)\n    if importer is None:\n        try:\n            importer = ImpWrapper(path_item)\n        except ImportError:\n            pass\n    return importer", "response": "Retrieve a PEP 302 importer for the given path item."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a version string into a chronologically - sortable keybase grammar.", "response": "def parse_version(s):\n    \"\"\"Convert a version string to a chronologically-sortable key\n\n    This is a rough cross between distutils' StrictVersion and LooseVersion;\n    if you give it versions that would work with StrictVersion, then it behaves\n    the same; otherwise it acts like a slightly-smarter LooseVersion. It is\n    *possible* to create pathological version coding schemes that will fool\n    this parser, but they should be very rare in practice.\n\n    The returned value will be a tuple of strings.  Numeric portions of the\n    version are padded to 8 digits so they will compare numerically, but\n    without relying on how numbers compare relative to strings.  Dots are\n    dropped, but dashes are retained.  Trailing zeros between alpha segments\n    or dashes are suppressed, so that e.g. \"2.4.0\" is considered the same as\n    \"2.4\". Alphanumeric parts are lower-cased.\n\n    The algorithm assumes that strings like \"-\" and any alpha string that\n    alphabetically follows \"final\"  represents a \"patch level\".  So, \"2.4-1\"\n    is assumed to be a branch or patch of \"2.4\", and therefore \"2.4.1\" is\n    considered newer than \"2.4-1\", which in turn is newer than \"2.4\".\n\n    Strings like \"a\", \"b\", \"c\", \"alpha\", \"beta\", \"candidate\" and so on (that\n    come before \"final\" alphabetically) are assumed to be pre-release versions,\n    so that the version \"2.4\" is considered newer than \"2.4a1\".\n\n    Finally, to handle miscellaneous cases, the strings \"pre\", \"preview\", and\n    \"rc\" are treated as if they were \"c\", i.e. as though they were release\n    candidates, and therefore are not as new as a version string that does not\n    contain them, and \"dev\" is replaced with an '@' so that it sorts lower than\n    than any other pre-release tag.\n    \"\"\"\n    parts = []\n    for part in _parse_version_parts(s.lower()):\n        if part.startswith('*'):\n            # remove trailing zeros from each series of numeric parts\n            while parts and parts[-1]=='00000000':\n                parts.pop()\n        parts.append(part)\n    return tuple(parts)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _override_setuptools(req):\n    if req.project_name == 'setuptools':\n        if not len(req.specs):\n            # Just setuptools: ok\n            return True\n        for comparator, version in req.specs:\n            if comparator in ['==', '>=', '>']:\n                if '0.7' in version:\n                    # We want some setuptools not from the 0.6 series.\n                    return False\n        return True\n    return False", "response": "Return True when distribute wants to override a setuptools dependency."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a distribution to the set.", "response": "def add(self, dist, entry=None, insert=True, replace=False):\n        \"\"\"Add `dist` to working set, associated with `entry`\n\n        If `entry` is unspecified, it defaults to the ``.location`` of `dist`.\n        On exit from this routine, `entry` is added to the end of the working\n        set's ``.entries`` (if it wasn't already present).\n\n        `dist` is only added to the working set if it's for a project that\n        doesn't already have a distribution in the set, unless `replace=True`.\n        If it's added, any callbacks registered with the ``subscribe()`` method\n        will be called.\n        \"\"\"\n        if insert:\n            dist.insert_on(self.entries, entry)\n\n        if entry is None:\n            entry = dist.location\n        keys = self.entry_keys.setdefault(entry,[])\n        keys2 = self.entry_keys.setdefault(dist.location,[])\n        if not replace and dist.key in self.by_key:\n            return      # ignore hidden distros\n\n        self.by_key[dist.key] = dist\n        if dist.key not in keys:\n            keys.append(dist.key)\n        if dist.key not in keys2:\n            keys2.append(dist.key)\n        self._added_new(dist)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resolve(self, requirements, env=None, installer=None,\n                replacement=True, replace_conflicting=False):\n        \"\"\"List all distributions needed to (recursively) meet `requirements`\n\n        `requirements` must be a sequence of ``Requirement`` objects.  `env`,\n        if supplied, should be an ``Environment`` instance.  If\n        not supplied, it defaults to all distributions available within any\n        entry or distribution in the working set.  `installer`, if supplied,\n        will be invoked with each requirement that cannot be met by an\n        already-installed distribution; it should return a ``Distribution`` or\n        ``None``.\n\n        Unless `replace_conflicting=True`, raises a VersionConflict exception if\n        any requirements are found on the path that have the correct name but\n        the wrong version.  Otherwise, if an `installer` is supplied it will be\n        invoked to obtain the correct version of the requirement and activate\n        it.\n        \"\"\"\n\n        requirements = list(requirements)[::-1]  # set up the stack\n        processed = {}  # set of processed requirements\n        best = {}  # key -> dist\n        to_activate = []\n\n        while requirements:\n            req = requirements.pop(0)   # process dependencies breadth-first\n            if _override_setuptools(req) and replacement:\n                req = Requirement.parse('distribute')\n\n            if req in processed:\n                # Ignore cyclic or redundant dependencies\n                continue\n            dist = best.get(req.key)\n            if dist is None:\n                # Find the best distribution and add it to the map\n                dist = self.by_key.get(req.key)\n                if dist is None or (dist not in req and replace_conflicting):\n                    ws = self\n                    if env is None:\n                        if dist is None:\n                            env = Environment(self.entries)\n                        else:\n                            # Use an empty environment and workingset to avoid\n                            # any further conflicts with the conflicting\n                            # distribution\n                            env = Environment([])\n                            ws = WorkingSet([])\n                    dist = best[req.key] = env.best_match(req, ws, installer)\n                    if dist is None:\n                        #msg = (\"The '%s' distribution was not found on this \"\n                        #       \"system, and is required by this application.\")\n                        #raise DistributionNotFound(msg % req)\n\n                        # unfortunately, zc.buildout uses a str(err)\n                        # to get the name of the distribution here..\n                        raise DistributionNotFound(req)\n                to_activate.append(dist)\n            if dist not in req:\n                # Oops, the \"best\" so far conflicts with a dependency\n                raise VersionConflict(dist,req) # XXX put more info here\n            requirements.extend(dist.requires(req.extras)[::-1])\n            processed[req] = True\n\n        return to_activate", "response": "Resolves the given set of requirements and returns a Distribution instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind all activatable plugins in plugin_env.", "response": "def find_plugins(self,\n        plugin_env, full_env=None, installer=None, fallback=True\n    ):\n        \"\"\"Find all activatable distributions in `plugin_env`\n\n        Example usage::\n\n            distributions, errors = working_set.find_plugins(\n                Environment(plugin_dirlist)\n            )\n            map(working_set.add, distributions)  # add plugins+libs to sys.path\n            print 'Could not load', errors        # display errors\n\n        The `plugin_env` should be an ``Environment`` instance that contains\n        only distributions that are in the project's \"plugin directory\" or\n        directories. The `full_env`, if supplied, should be an ``Environment``\n        contains all currently-available distributions.  If `full_env` is not\n        supplied, one is created automatically from the ``WorkingSet`` this\n        method is called on, which will typically mean that every directory on\n        ``sys.path`` will be scanned for distributions.\n\n        `installer` is a standard installer callback as used by the\n        ``resolve()`` method. The `fallback` flag indicates whether we should\n        attempt to resolve older versions of a plugin if the newest version\n        cannot be resolved.\n\n        This method returns a 2-tuple: (`distributions`, `error_info`), where\n        `distributions` is a list of the distributions found in `plugin_env`\n        that were loadable, along with any other distributions that are needed\n        to resolve their dependencies.  `error_info` is a dictionary mapping\n        unloadable plugin distributions to an exception instance describing the\n        error that occurred. Usually this will be a ``DistributionNotFound`` or\n        ``VersionConflict`` instance.\n        \"\"\"\n\n        plugin_projects = list(plugin_env)\n        plugin_projects.sort()  # scan project names in alphabetic order\n\n        error_info = {}\n        distributions = {}\n\n        if full_env is None:\n            env = Environment(self.entries)\n            env += plugin_env\n        else:\n            env = full_env + plugin_env\n\n        shadow_set = self.__class__([])\n        map(shadow_set.add, self)   # put all our entries in shadow_set\n\n        for project_name in plugin_projects:\n\n            for dist in plugin_env[project_name]:\n\n                req = [dist.as_requirement()]\n\n                try:\n                    resolvees = shadow_set.resolve(req, env, installer)\n\n                except ResolutionError,v:\n                    error_info[dist] = v    # save error info\n                    if fallback:\n                        continue    # try the next older version of project\n                    else:\n                        break       # give up on this project, keep going\n\n                else:\n                    map(shadow_set.add, resolvees)\n                    distributions.update(dict.fromkeys(resolvees))\n\n                    # success, no need to try any more versions of this project\n                    break\n\n        distributions = list(distributions)\n        distributions.sort()\n\n        return distributions, error_info"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds dist if we can add it and it isn t already added", "response": "def add(self,dist):\n        \"\"\"Add `dist` if we ``can_add()`` it and it isn't already added\"\"\"\n        if self.can_add(dist) and dist.has_version():\n            dists = self._distmap.setdefault(dist.key,[])\n            if dist not in dists:\n                dists.append(dist)\n                if dist.key in self._cache:\n                    _sort_dists(self._cache[dist.key])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning absolute location in cache for archive_name and names", "response": "def get_cache_path(self, archive_name, names=()):\n        \"\"\"Return absolute location in cache for `archive_name` and `names`\n\n        The parent directory of the resulting path will be created if it does\n        not already exist.  `archive_name` should be the base filename of the\n        enclosing egg (which may not be the name of the enclosing zipfile!),\n        including its \".egg\" extension.  `names`, if provided, should be a\n        sequence of path name parts \"under\" the egg's extraction location.\n\n        This method should only be called by resource providers that need to\n        obtain an extraction location, and only for names they intend to\n        extract, as it tracks the generated names for possible cleanup later.\n        \"\"\"\n        extract_path = self.extraction_path or get_default_cache()\n        target_path = os.path.join(extract_path, archive_name+'-tmp', *names)\n        try:\n            _bypass_ensure_directory(target_path)\n        except:\n            self.extraction_error()\n\n        self.cached_files[target_path] = 1\n        return target_path"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a single entry point from a string src.", "response": "def parse(cls, src, dist=None):\n        \"\"\"Parse a single entry point from string `src`\n\n        Entry point syntax follows the form::\n\n            name = some.module:some.attr [extra1,extra2]\n\n        The entry name and module name are required, but the ``:attrs`` and\n        ``[extras]`` parts are optional\n        \"\"\"\n        try:\n            attrs = extras = ()\n            name,value = src.split('=',1)\n            if '[' in value:\n                value,extras = value.split('[',1)\n                req = Requirement.parse(\"x[\"+extras)\n                if req.specs: raise ValueError\n                extras = req.extras\n            if ':' in value:\n                value,attrs = value.split(':',1)\n                if not MODULE(attrs.rstrip()):\n                    raise ValueError\n                attrs = attrs.rstrip().split('.')\n        except ValueError:\n            raise ValueError(\n                \"EntryPoint must be in 'name=module:attrs [extras]' format\",\n                src\n            )\n        else:\n            return cls(name.strip(), value.strip(), attrs, extras, dist)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef activate(self,path=None):\n        if path is None: path = sys.path\n        self.insert_on(path)\n        if path is sys.path:\n            fixup_namespace_packages(self.location)\n            map(declare_namespace, self._get_metadata('namespace_packages.txt'))", "response": "Ensure distribution is importable on path ( default = sys. path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninserting self. location in path before its nearest parent directory.", "response": "def insert_on(self, path, loc = None):\n        \"\"\"Insert self.location in path before its nearest parent directory\"\"\"\n\n        loc = loc or self.location\n\n        if self.project_name == 'setuptools':\n            try:\n                version = self.version\n            except ValueError:\n                version = ''\n            if '0.7' in version:\n                raise ValueError(\n                    \"A 0.7-series setuptools cannot be installed \"\n                    \"with distribute. Found one at %s\" % str(self.location))\n\n        if not loc:\n            return\n\n        if path is sys.path:\n            self.check_version_conflict()\n\n        nloc = _normalize_cached(loc)\n        bdir = os.path.dirname(nloc)\n        npath= map(_normalize_cached, path)\n\n        bp = None\n        for p, item in enumerate(npath):\n            if item==nloc:\n                break\n            elif item==bdir and self.precedence==EGG_DIST:\n                # if it's an .egg, give it precedence over its directory\n                path.insert(p, loc)\n                npath.insert(p, nloc)\n                break\n        else:\n            path.append(loc)\n            return\n\n        # p is the spot where we found or inserted loc; now remove duplicates\n        while 1:\n            try:\n                np = npath.index(nloc, p+1)\n            except ValueError:\n                break\n            else:\n                del npath[np], path[np]\n                p = np  # ha!\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse and cache metadata", "response": "def _parsed_pkg_info(self):\n        \"\"\"Parse and cache metadata\"\"\"\n        try:\n            return self._pkg_info\n        except AttributeError:\n            from email.parser import Parser\n            self._pkg_info = Parser().parsestr(self.get_metadata(self.PKG_INFO))\n            return self._pkg_info"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a notebook filename and return the name and format.", "response": "def parse_filename(fname):\n    \"\"\"Parse a notebook filename.\n\n    This function takes a notebook filename and returns the notebook\n    format (json/py) and the notebook name. This logic can be\n    summarized as follows:\n\n    * notebook.ipynb -> (notebook.ipynb, notebook, json)\n    * notebook.json  -> (notebook.json, notebook, json)\n    * notebook.py    -> (notebook.py, notebook, py)\n    * notebook       -> (notebook.ipynb, notebook, json)\n\n    Parameters\n    ----------\n    fname : unicode\n        The notebook filename. The filename can use a specific filename\n        extention (.ipynb, .json, .py) or none, in which case .ipynb will\n        be assumed.\n\n    Returns\n    -------\n    (fname, name, format) : (unicode, unicode, unicode)\n        The filename, notebook name and format.\n    \"\"\"\n    if fname.endswith(u'.ipynb'):\n        format = u'json'\n    elif fname.endswith(u'.json'):\n        format = u'json'\n    elif fname.endswith(u'.py'):\n        format = u'py'\n    else:\n        fname = fname + u'.ipynb'\n        format = u'json'\n    name = fname.split('.')[0]\n    return fname, name, format"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _collapse_leading_ws(header, txt):\n    if header.lower() == 'description':  # preserve newlines\n        return '\\n'.join([x[8:] if x.startswith(' ' * 8) else x\n                          for x in txt.strip().splitlines()])\n    else:\n        return ' '.join([x.strip() for x in txt.splitlines()])", "response": "collapse leading ws in a string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_refs(self, location):\n        output = call_subprocess([self.cmd, 'show-ref'],\n                                 show_stdout=False, cwd=location)\n        rv = {}\n        for line in output.strip().splitlines():\n            commit, ref = line.split(' ', 1)\n            ref = ref.strip()\n            ref_name = None\n            if ref.startswith('refs/remotes/'):\n                ref_name = ref[len('refs/remotes/'):]\n            elif ref.startswith('refs/heads/'):\n                ref_name = ref[len('refs/heads/'):]\n            elif ref.startswith('refs/tags/'):\n                ref_name = ref[len('refs/tags/'):]\n            if ref_name is not None:\n                rv[ref_name] = commit.strip()\n        return rv", "response": "Return a map of named refs to commit hashes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef eventFilter(self, obj, event):\n        if obj == self._text_edit:\n            etype = event.type()\n\n            if etype == QtCore.QEvent.KeyPress:\n                key, text = event.key(), event.text()\n                if key in (QtCore.Qt.Key_Return, QtCore.Qt.Key_Enter,\n                           QtCore.Qt.Key_Tab):\n                    self._complete_current()\n                    return True\n                elif key == QtCore.Qt.Key_Escape:\n                    self.hide()\n                    return True\n                elif key in (QtCore.Qt.Key_Up, QtCore.Qt.Key_Down,\n                             QtCore.Qt.Key_PageUp, QtCore.Qt.Key_PageDown,\n                             QtCore.Qt.Key_Home, QtCore.Qt.Key_End):\n                    self.keyPressEvent(event)\n                    return True\n\n            elif etype == QtCore.QEvent.FocusOut:\n                self.hide()\n\n        return super(CompletionWidget, self).eventFilter(obj, event)", "response": "Reimplemented to handle keyboard input and auto - hide when the text edit loses focus."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndisconnects signal handlers and event filter.", "response": "def hideEvent(self, event):\n        \"\"\" Reimplemented to disconnect signal handlers and event filter.\n        \"\"\"\n        super(CompletionWidget, self).hideEvent(event)\n        self._text_edit.cursorPositionChanged.disconnect(self._update_current)\n        self._text_edit.removeEventFilter(self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconnects signal handlers and event filter.", "response": "def showEvent(self, event):\n        \"\"\" Reimplemented to connect signal handlers and event filter.\n        \"\"\"\n        super(CompletionWidget, self).showEvent(event)\n        self._text_edit.cursorPositionChanged.connect(self._update_current)\n        self._text_edit.installEventFilter(self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing the completion widget with items at the position specified by cursor.", "response": "def show_items(self, cursor, items):\n        \"\"\" Shows the completion widget with 'items' at the position specified\n            by 'cursor'.\n        \"\"\"\n        text_edit = self._text_edit\n        point = text_edit.cursorRect(cursor).bottomRight()\n        point = text_edit.mapToGlobal(point)\n        height = self.sizeHint().height()\n        screen_rect = QtGui.QApplication.desktop().availableGeometry(self)\n        if screen_rect.size().height() - point.y() - height < 0:\n            point = text_edit.mapToGlobal(text_edit.cursorRect().topRight())\n            point.setY(point.y() - height)\n        self.move(point)\n\n        self._start_position = cursor.position()\n        self.clear()\n        self.addItems(items)\n        self.setCurrentRow(0)\n        self.show()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _complete_current(self):\n        self._current_text_cursor().insertText(self.currentItem().text())\n        self.hide()", "response": "Perform the completion with the currently selected item."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _current_text_cursor(self):\n        cursor = self._text_edit.textCursor()\n        if cursor.position() >= self._start_position:\n            cursor.setPosition(self._start_position,\n                               QtGui.QTextCursor.KeepAnchor)\n        return cursor", "response": "Returns a cursor with text between the start position and the the\n            current position selected."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the current item based on the current text.", "response": "def _update_current(self):\n        \"\"\" Updates the current item based on the current text.\n        \"\"\"\n        prefix = self._current_text_cursor().selection().toPlainText()\n        if prefix:\n            items = self.findItems(prefix, (QtCore.Qt.MatchStartsWith |\n                                            QtCore.Qt.MatchCaseSensitive))\n            if items:\n                self.setCurrentItem(items[0])\n            else:\n                self.hide()\n        else:\n            self.hide()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering the models of the app with the given appName for the admin site.", "response": "def registerAdminSite(appName, excludeModels=[]):\n    \"\"\"Registers the models of the app with the given \"appName\" for the admin site\"\"\"\n    for model in apps.get_app_config(appName).get_models():\n        if model not in excludeModels:\n            admin.site.register(model)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nswap system memory as a tuple.", "response": "def swap_memory():\n    \"\"\"Swap system memory as a (total, used, free, sin, sout) tuple.\"\"\"\n    mem = _psutil_mswindows.get_virtual_mem()\n    total = mem[2]\n    free = mem[3]\n    used = total - free\n    percent = usage_percent(used, total, _round=1)\n    return nt_swapmeminfo(total, used, free, percent, 0, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_disk_usage(path):\n    try:\n        total, free = _psutil_mswindows.get_disk_usage(path)\n    except WindowsError:\n        err = sys.exc_info()[1]\n        if not os.path.exists(path):\n            raise OSError(errno.ENOENT, \"No such file or directory: '%s'\" % path)\n        raise\n    used = total - free\n    percent = usage_percent(used, total, _round=1)\n    return nt_diskinfo(total, used, free, percent)", "response": "Return disk usage associated with path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn system CPU times as a named tuple.", "response": "def get_system_cpu_times():\n    \"\"\"Return system CPU times as a named tuple.\"\"\"\n    user, system, idle = 0, 0, 0\n    # computes system global times summing each processor value\n    for cpu_time in _psutil_mswindows.get_system_cpu_times():\n        user += cpu_time[0]\n        system += cpu_time[1]\n        idle += cpu_time[2]\n    return _cputimes_ntuple(user, system, idle)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_system_per_cpu_times():\n    ret = []\n    for cpu_t in _psutil_mswindows.get_system_cpu_times():\n        user, system, idle = cpu_t\n        item = _cputimes_ntuple(user, system, idle)\n        ret.append(item)\n    return ret", "response": "Return system per - CPU times as a list of named tuples."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_system_users():\n    retlist = []\n    rawlist = _psutil_mswindows.get_system_users()\n    for item in rawlist:\n        user, hostname, tstamp = item\n        nt = nt_user(user, None, hostname, tstamp)\n        retlist.append(nt)\n    return retlist", "response": "Return currently connected users as a list of namedtuples."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef system(cmd):\n    with AvoidUNCPath() as path:\n        if path is not None:\n            cmd = '\"pushd %s &&\"%s' % (path, cmd)\n        with Win32ShellCommandController(cmd) as scc:\n            scc.run()", "response": "Win32 version of os. system that works with network shares."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the process using the provided functions for I / O.", "response": "def run(self, stdout_func = None, stdin_func = None, stderr_func = None):\n        \"\"\"Runs the process, using the provided functions for I/O.\n\n        The function stdin_func should return strings whenever a\n        character or characters become available.\n        The functions stdout_func and stderr_func are called whenever\n        something is printed to stdout or stderr, respectively.\n        These functions are called from different threads (but not\n        concurrently, because of the GIL).\n        \"\"\"\n        if stdout_func == None and stdin_func == None and stderr_func == None:\n            return self._run_stdio()\n\n        if stderr_func != None and self.mergeout:\n            raise RuntimeError(\"Shell command was initiated with \"\n                    \"merged stdin/stdout, but a separate stderr_func \"\n                    \"was provided to the run() method\")\n\n        # Create a thread for each input/output handle\n        stdin_thread = None\n        threads = []\n        if stdin_func:\n            stdin_thread = threading.Thread(target=self._stdin_thread,\n                                args=(self.hstdin, self.piProcInfo.hProcess,\n                                stdin_func, stdout_func))\n        threads.append(threading.Thread(target=self._stdout_thread,\n                                    args=(self.hstdout, stdout_func)))\n        if not self.mergeout:\n            if stderr_func == None:\n                stderr_func = stdout_func\n            threads.append(threading.Thread(target=self._stdout_thread,\n                                        args=(self.hstderr, stderr_func)))\n        # Start the I/O threads and the process\n        if ResumeThread(self.piProcInfo.hThread) == 0xFFFFFFFF:\n            raise ctypes.WinError()\n        if stdin_thread is not None:\n            stdin_thread.start()\n        for thread in threads:\n            thread.start()\n        # Wait for the process to complete\n        if WaitForSingleObject(self.piProcInfo.hProcess, INFINITE) == \\\n                    WAIT_FAILED:\n            raise ctypes.WinError()\n        # Wait for the I/O threads to complete\n        for thread in threads:\n            thread.join()\n\n        # Wait for the stdin thread to complete\n        if stdin_thread is not None:\n            stdin_thread.join()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _stdin_raw_nonblock(self):\n        # WARNING: This is experimental, and produces inconsistent results.\n        #          It's possible for the handle not to be appropriate for use\n        #          with WaitForSingleObject, among other things.\n        handle = msvcrt.get_osfhandle(sys.stdin.fileno())\n        result = WaitForSingleObject(handle, 100)\n        if result == WAIT_FAILED:\n            raise ctypes.WinError()\n        elif result == WAIT_TIMEOUT:\n            print(\".\", end='')\n            return None\n        else:\n            data = ctypes.create_string_buffer(256)\n            bytesRead = DWORD(0)\n            print('?', end='')\n\n            if not ReadFile(handle, data, 256,\n                        ctypes.byref(bytesRead), None):\n                raise ctypes.WinError()\n            # This ensures the non-blocking works with an actual console\n            # Not checking the error, so the processing will still work with\n            # other handle types\n            FlushConsoleInputBuffer(handle)\n\n            data = data.value\n            data = data.replace('\\r\\n', '\\n')\n            data = data.replace('\\r', '\\n')\n            print(repr(data) + \" \", end='')\n            return data", "response": "Use the raw Win32 handle of sys. stdin to do non - blocking reads."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nuse a blocking stdin read to get the current version of the entry.", "response": "def _stdin_raw_block(self):\n        \"\"\"Use a blocking stdin read\"\"\"\n        # The big problem with the blocking read is that it doesn't\n        # exit when it's supposed to in all contexts. An extra\n        # key-press may be required to trigger the exit.\n        try:\n            data = sys.stdin.read(1)\n            data = data.replace('\\r', '\\n')\n            return data\n        except WindowsError as we:\n            if we.winerror == ERROR_NO_DATA:\n                # This error occurs when the pipe is closed\n                return None\n            else:\n                # Otherwise let the error propagate\n                raise we"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _stdout_raw(self, s):\n        print(s, end='', file=sys.stdout)\n        sys.stdout.flush()", "response": "Writes the string s to stdout"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _stderr_raw(self, s):\n        print(s, end='', file=sys.stderr)\n        sys.stderr.flush()", "response": "Writes the string to stderr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the process using the system standard I/O.", "response": "def _run_stdio(self):\n        \"\"\"Runs the process using the system standard I/O.\n\n        IMPORTANT: stdin needs to be asynchronous, so the Python\n                   sys.stdin object is not used. Instead,\n                   msvcrt.kbhit/getwch are used asynchronously.\n        \"\"\"\n        # Disable Line and Echo mode\n        #lpMode = DWORD()\n        #handle = msvcrt.get_osfhandle(sys.stdin.fileno())\n        #if GetConsoleMode(handle, ctypes.byref(lpMode)):\n        #    set_console_mode = True\n        #    if not SetConsoleMode(handle, lpMode.value &\n        #            ~(ENABLE_ECHO_INPUT | ENABLE_LINE_INPUT | ENABLE_PROCESSED_INPUT)):\n        #        raise ctypes.WinError()\n\n        if self.mergeout:\n            return self.run(stdout_func = self._stdout_raw,\n                    stdin_func = self._stdin_raw_block)\n        else:\n            return self.run(stdout_func = self._stdout_raw,\n                    stdin_func = self._stdin_raw_block,\n                    stderr_func = self._stderr_raw)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_tab_bar_visibility(self):\n        if self.tab_widget.count() <= 1:\n            self.tab_widget.tabBar().setVisible(False)\n        else:\n            self.tab_widget.tabBar().setVisible(True)\n        if self.tab_widget.count()==0 :\n            self.close()", "response": "update visibility of the tabBar depending of the number of tabs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_tab_with_current_kernel(self):\n        current_widget = self.tab_widget.currentWidget()\n        current_widget_index = self.tab_widget.indexOf(current_widget)\n        current_widget_name = self.tab_widget.tabText(current_widget_index)\n        widget = self.slave_frontend_factory(current_widget)\n        if 'slave' in current_widget_name:\n            # don't keep stacking slaves\n            name = current_widget_name\n        else:\n            name = '(%s) slave' % current_widget_name\n        self.add_tab_with_frontend(widget,name=name)", "response": "create a new tab with the same kernel as the current tab"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall when you need to try to close a tab. It takes the number of the tab to be closed as argument, or a reference to the widget inside this tab", "response": "def close_tab(self,current_tab):\n        \"\"\" Called when you need to try to close a tab.\n\n        It takes the number of the tab to be closed as argument, or a reference\n        to the widget inside this tab\n        \"\"\"\n\n        # let's be sure \"tab\" and \"closing widget\" are respectively the index\n        # of the tab to close and a reference to the frontend to close\n        if type(current_tab) is not int :\n            current_tab = self.tab_widget.indexOf(current_tab)\n        closing_widget=self.tab_widget.widget(current_tab)\n\n\n        # when trying to be closed, widget might re-send a request to be\n        # closed again, but will be deleted when event will be processed. So\n        # need to check that widget still exists and skip if not. One example\n        # of this is when 'exit' is sent in a slave tab. 'exit' will be\n        # re-sent by this function on the master widget, which ask all slave\n        # widgets to exit\n        if closing_widget==None:\n            return\n\n        #get a list of all slave widgets on the same kernel.\n        slave_tabs = self.find_slave_widgets(closing_widget)\n\n        keepkernel = None #Use the prompt by default\n        if hasattr(closing_widget,'_keep_kernel_on_exit'): #set by exit magic\n            keepkernel = closing_widget._keep_kernel_on_exit\n            # If signal sent by exit magic (_keep_kernel_on_exit, exist and not None)\n            # we set local slave tabs._hidden to True to avoid prompting for kernel\n            # restart when they get the signal. and then \"forward\" the 'exit'\n            # to the main window\n            if keepkernel is not None:\n                for tab in slave_tabs:\n                    tab._hidden = True\n                if closing_widget in slave_tabs:\n                    try :\n                        self.find_master_tab(closing_widget).execute('exit')\n                    except AttributeError:\n                        self.log.info(\"Master already closed or not local, closing only current tab\")\n                        self.tab_widget.removeTab(current_tab)\n                    self.update_tab_bar_visibility()\n                    return\n\n        kernel_manager = closing_widget.kernel_manager\n\n        if keepkernel is None and not closing_widget._confirm_exit:\n            # don't prompt, just terminate the kernel if we own it\n            # or leave it alone if we don't\n            keepkernel = closing_widget._existing\n        if keepkernel is None: #show prompt\n            if kernel_manager and kernel_manager.channels_running:\n                title = self.window().windowTitle()\n                cancel = QtGui.QMessageBox.Cancel\n                okay = QtGui.QMessageBox.Ok\n                if closing_widget._may_close:\n                    msg = \"You are closing the tab : \"+'\"'+self.tab_widget.tabText(current_tab)+'\"'\n                    info = \"Would you like to quit the Kernel and close all attached Consoles as well?\"\n                    justthis = QtGui.QPushButton(\"&No, just this Tab\", self)\n                    justthis.setShortcut('N')\n                    closeall = QtGui.QPushButton(\"&Yes, close all\", self)\n                    closeall.setShortcut('Y')\n                    # allow ctrl-d ctrl-d exit, like in terminal\n                    closeall.setShortcut('Ctrl+D')\n                    box = QtGui.QMessageBox(QtGui.QMessageBox.Question,\n                                            title, msg)\n                    box.setInformativeText(info)\n                    box.addButton(cancel)\n                    box.addButton(justthis, QtGui.QMessageBox.NoRole)\n                    box.addButton(closeall, QtGui.QMessageBox.YesRole)\n                    box.setDefaultButton(closeall)\n                    box.setEscapeButton(cancel)\n                    pixmap = QtGui.QPixmap(self._app.icon.pixmap(QtCore.QSize(64,64)))\n                    box.setIconPixmap(pixmap)\n                    reply = box.exec_()\n                    if reply == 1: # close All\n                        for slave in slave_tabs:\n                            background(slave.kernel_manager.stop_channels)\n                            self.tab_widget.removeTab(self.tab_widget.indexOf(slave))\n                        closing_widget.execute(\"exit\")\n                        self.tab_widget.removeTab(current_tab)\n                        background(kernel_manager.stop_channels)\n                    elif reply == 0: # close Console\n                        if not closing_widget._existing:\n                            # Have kernel: don't quit, just close the tab\n                            closing_widget.execute(\"exit True\")\n                        self.tab_widget.removeTab(current_tab)\n                        background(kernel_manager.stop_channels)\n                else:\n                    reply = QtGui.QMessageBox.question(self, title,\n                        \"Are you sure you want to close this Console?\"+\n                        \"\\nThe Kernel and other Consoles will remain active.\",\n                        okay|cancel,\n                        defaultButton=okay\n                        )\n                    if reply == okay:\n                        self.tab_widget.removeTab(current_tab)\n        elif keepkernel: #close console but leave kernel running (no prompt)\n            self.tab_widget.removeTab(current_tab)\n            background(kernel_manager.stop_channels)\n        else: #close console and kernel (no prompt)\n            self.tab_widget.removeTab(current_tab)\n            if kernel_manager and kernel_manager.channels_running:\n                for slave in slave_tabs:\n                    background(slave.kernel_manager.stop_channels)\n                    self.tab_widget.removeTab(self.tab_widget.indexOf(slave))\n                kernel_manager.shutdown_kernel()\n                background(kernel_manager.stop_channels)\n        \n        self.update_tab_bar_visibility()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_tab_with_frontend(self,frontend,name=None):\n        if not name:\n            name = 'kernel %i' % self.next_kernel_id\n        self.tab_widget.addTab(frontend,name)\n        self.update_tab_bar_visibility()\n        self.make_frontend_visible(frontend)\n        frontend.exit_requested.connect(self.close_tab)", "response": "insert a tab with a given frontend in the tab bar and give it a name"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_master_tab(self,tab,as_list=False):\n\n        #convert from/to int/richIpythonWidget if needed\n        if isinstance(tab, int):\n            tab = self.tab_widget.widget(tab)\n        km=tab.kernel_manager\n\n        #build list of all widgets\n        widget_list = [self.tab_widget.widget(i) for i in range(self.tab_widget.count())]\n\n        # widget that are candidate to be the owner of the kernel does have all the same port of the curent widget\n        # And should have a _may_close attribute\n        filtered_widget_list = [ widget for widget in widget_list if\n                                widget.kernel_manager.connection_file == km.connection_file and\n                                hasattr(widget,'_may_close') ]\n        # the master widget is the one that may close the kernel\n        master_widget= [ widget for widget in filtered_widget_list if widget._may_close]\n        if as_list:\n            return master_widget\n        assert(len(master_widget)<=1 )\n        if len(master_widget)==0:\n            return None\n\n        return master_widget[0]", "response": "Try to return the master widget that owns the kernel attached to the given tab."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_slave_widgets(self,tab):\n        #convert from/to int/richIpythonWidget if needed\n        if isinstance(tab, int):\n            tab = self.tab_widget.widget(tab)\n        km=tab.kernel_manager\n\n        #build list of all widgets\n        widget_list = [self.tab_widget.widget(i) for i in range(self.tab_widget.count())]\n\n        # widget that are candidate not to be the owner of the kernel does have all the same port of the curent widget\n        filtered_widget_list = ( widget for widget in widget_list if\n                                widget.kernel_manager.connection_file == km.connection_file)\n        # Get a list of all widget owning the same kernel and removed it from\n        # the previous cadidate. (better using sets ?)\n        master_widget_list = self.find_master_tab(tab, as_list=True)\n        slave_list = [widget for widget in filtered_widget_list if widget not in master_widget_list]\n\n        return slave_list", "response": "return all the frontends that do not own the kernel attached to the given widget."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_menu_action(self, menu, action, defer_shortcut=False):\n        menu.addAction(action)\n        self.addAction(action)\n\n        if defer_shortcut:\n            action.setShortcutContext(QtCore.Qt.WidgetShortcut)", "response": "Add action to menu and self as well as self."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a function that will execute the magic on the active frontend.", "response": "def _make_dynamic_magic(self,magic):\n        \"\"\"Return a function `fun` that will execute `magic` on active frontend.\n\n        Parameters\n        ----------\n        magic : string\n            string that will be executed as is when the returned function is called\n\n        Returns\n        -------\n        fun : function\n            function with no parameters, when called will execute `magic` on the\n            current active frontend at call time\n\n        See Also\n        --------\n        populate_all_magic_menu : generate the \"All Magics...\" menu\n\n        Notes\n        -----\n        `fun` executes `magic` in active frontend at the moment it is triggered,\n        not the active frontend at the moment it was created.\n\n        This function is mostly used to create the \"All Magics...\" Menu at run time.\n        \"\"\"\n        # need two level nested function to be sure to pass magic\n        # to active frontend **at run time**.\n        def inner_dynamic_magic():\n            self.active_frontend.execute(magic)\n        inner_dynamic_magic.__name__ = \"dynamics_magic_s\"\n        return inner_dynamic_magic"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclean All Magics... menu and repopulate it with listofmagic", "response": "def populate_all_magic_menu(self, listofmagic=None):\n        \"\"\"Clean \"All Magics...\" menu and repopulate it with `listofmagic`\n\n        Parameters\n        ----------\n        listofmagic : string,\n            repr() of a list of strings, send back by the kernel\n\n        Notes\n        -----\n        `listofmagic`is a repr() of list because it is fed with the result of\n        a 'user_expression'\n        \"\"\"\n        for k,v in self._magic_menu_dict.items():\n            v.clear()\n        self.all_magic_menu.clear()\n\n\n        protected_magic = set([\"more\",\"less\",\"load_ext\",\"pycat\",\"loadpy\",\"load\",\"save\",\"psource\"])\n        mlist=ast.literal_eval(listofmagic)\n        for magic in mlist:\n            cell = (magic['type'] == 'cell')\n            name = magic['name']\n            mclass = magic['class']\n            if cell :\n                prefix='%%'\n            else :\n                prefix='%'\n            magic_menu = self._get_magic_menu(mclass)\n\n            if name in protected_magic:\n                suffix = '?'\n            else :\n                suffix = ''\n            pmagic = '%s%s%s'%(prefix,name,suffix)\n\n            xaction = QtGui.QAction(pmagic,\n                self,\n                triggered=self._make_dynamic_magic(pmagic)\n                )\n            magic_menu.addAction(xaction)\n            self.all_magic_menu.addAction(xaction)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a submagic menu by name and create it if needed", "response": "def _get_magic_menu(self,menuidentifier, menulabel=None):\n        \"\"\"return a submagic menu by name, and create it if needed\n       \n        parameters:\n        -----------\n\n        menulabel : str\n            Label for the menu\n\n        Will infere the menu name from the identifier at creation if menulabel not given.\n        To do so you have too give menuidentifier as a CamelCassedString\n        \"\"\"\n        menu = self._magic_menu_dict.get(menuidentifier,None)\n        if not menu :\n            if not menulabel:\n                menulabel = re.sub(\"([a-zA-Z]+)([A-Z][a-z])\",\"\\g<1> \\g<2>\",menuidentifier)\n            menu = QtGui.QMenu(menulabel,self.magic_menu)\n            self._magic_menu_dict[menuidentifier]=menu\n            self.magic_menu.insertMenu(self.magic_menu_separator,menu)\n        return menu"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nforward the close event to every tab that contains the windows .", "response": "def closeEvent(self, event):\n        \"\"\" Forward the close event to every tabs contained by the windows\n        \"\"\"\n        if self.tab_widget.count() == 0:\n            # no tabs, just close\n            event.accept()\n            return\n        # Do Not loop on the widget count as it change while closing\n        title = self.window().windowTitle()\n        cancel = QtGui.QMessageBox.Cancel\n        okay = QtGui.QMessageBox.Ok\n        \n        if self.confirm_exit:\n            if self.tab_widget.count() > 1:\n                msg = \"Close all tabs, stop all kernels, and Quit?\"\n            else:\n                msg = \"Close console, stop kernel, and Quit?\"\n            info = \"Kernels not started here (e.g. notebooks) will be left alone.\"\n            closeall = QtGui.QPushButton(\"&Quit\", self)\n            closeall.setShortcut('Q')\n            box = QtGui.QMessageBox(QtGui.QMessageBox.Question,\n                                    title, msg)\n            box.setInformativeText(info)\n            box.addButton(cancel)\n            box.addButton(closeall, QtGui.QMessageBox.YesRole)\n            box.setDefaultButton(closeall)\n            box.setEscapeButton(cancel)\n            pixmap = QtGui.QPixmap(self._app.icon.pixmap(QtCore.QSize(64,64)))\n            box.setIconPixmap(pixmap)\n            reply = box.exec_()\n        else:\n            reply = okay\n        \n        if reply == cancel:\n            event.ignore()\n            return\n        if reply == okay:\n            while self.tab_widget.count() >= 1:\n                # prevent further confirmations:\n                widget = self.active_frontend\n                widget._confirm_exit = False\n                self.close_tab(widget)\n            event.accept()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef passwd(passphrase=None, algorithm='sha1'):\n    if passphrase is None:\n        for i in range(3):\n            p0 = getpass.getpass('Enter password: ')\n            p1 = getpass.getpass('Verify password: ')\n            if p0 == p1:\n                passphrase = p0\n                break\n            else:\n                print('Passwords do not match.')\n        else:\n            raise UsageError('No matching passwords found. Giving up.')\n\n    h = hashlib.new(algorithm)\n    salt = ('%0' + str(salt_len) + 'x') % random.getrandbits(4 * salt_len)\n    h.update(cast_bytes(passphrase, 'utf-8') + str_to_bytes(salt, 'ascii'))\n\n    return ':'.join((algorithm, salt, h.hexdigest()))", "response": "Generate hashed password and salt for use in notebook app configuration."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nverify that a given passphrase matches its hashed version.", "response": "def passwd_check(hashed_passphrase, passphrase):\n    \"\"\"Verify that a given passphrase matches its hashed version.\n\n    Parameters\n    ----------\n    hashed_passphrase : str\n        Hashed password, in the format returned by `passwd`.\n    passphrase : str\n        Passphrase to validate.\n\n    Returns\n    -------\n    valid : bool\n        True if the passphrase matches the hash.\n\n    Examples\n    --------\n    In [1]: from IPython.lib.security import passwd_check\n\n    In [2]: passwd_check('sha1:0e112c3ddfce:a68df677475c2b47b6e86d0467eec97ac5f4b85a',\n       ...:              'mypassword')\n    Out[2]: True\n\n    In [3]: passwd_check('sha1:0e112c3ddfce:a68df677475c2b47b6e86d0467eec97ac5f4b85a',\n       ...:              'anotherpassword')\n    Out[3]: False\n\n    \"\"\"\n    try:\n        algorithm, salt, pw_digest = hashed_passphrase.split(':', 2)\n    except (ValueError, TypeError):\n        return False\n\n    try:\n        h = hashlib.new(algorithm)\n    except ValueError:\n        return False\n\n    if len(pw_digest) == 0:\n        return False\n\n    h.update(cast_bytes(passphrase, 'utf-8') + str_to_bytes(salt, 'ascii'))\n\n    return h.hexdigest() == pw_digest"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef django_boolean_icon(field_val, alt_text=None, title=None):\n\n    # Origin: contrib/admin/templatetags/admin_list.py\n    BOOLEAN_MAPPING = {True: 'yes', False: 'no', None: 'unknown'}\n    alt_text = alt_text or BOOLEAN_MAPPING[field_val]\n    if title is not None:\n        title = 'title=\"%s\" ' % title\n    else:\n        title = ''\n    return mark_safe(u'<img src=\"%simg/icon-%s.gif\" alt=\"%s\" %s/>' %\n                     (settings.STATIC_URL, BOOLEAN_MAPPING[field_val], alt_text, title))", "response": "Returns HTML code for a nice representation of true or false."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _build_tree_structure(cls):\n    all_nodes = {}\n\n    for p_id, parent_id in cls.objects.order_by(cls._mptt_meta.tree_id_attr, cls._mptt_meta.left_attr).values_list(\n            \"pk\", \"%s_id\" % cls._mptt_meta.parent_attr\n    ):\n        all_nodes[p_id] = []\n\n        if parent_id:\n            if not all_nodes.has_key(parent_id):\n                # This happens very rarely, but protect against parents that\n                # we have yet to iteratove over.\n                all_nodes[parent_id] = []\n            all_nodes[parent_id].append(p_id)\n\n    return all_nodes", "response": "Build an in - memory representation of the item tree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ajax_editable_boolean_cell(item, attr, text='', override=None):\n    if text:\n        text = '&nbsp;(%s)' % unicode(text)\n\n    if override is not None:\n        a = [django_boolean_icon(override, text), text]\n    else:\n        value = getattr(item, attr)\n        a = [\n            '<input type=\"checkbox\"',\n            value and ' checked=\"checked\"' or '',\n            ' onclick=\"return inplace_toggle_boolean(%d, \\'%s\\')\";' % (item.id, attr),\n            ' />',\n            text,\n        ]\n\n    a.insert(0, '<div id=\"wrap_%s_%d\">' % ( attr, item.id ))\n    a.append('</div>')\n    return unicode(''.join(a))", "response": "Generates an editable boolean cell in the admin page."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a short title for an object in the HTML.", "response": "def indented_short_title(self, item):\n        r = \"\"\n        \"\"\"\n        Generate a short title for an object, indent it depending on\n        the object's depth in the hierarchy.\n        \"\"\"\n        if hasattr(item, 'get_absolute_url'):\n            r = '<input type=\"hidden\" class=\"medialibrary_file_path\" value=\"%s\" />' % item.get_absolute_url()\n\n        editable_class = ''\n        if not getattr(item, 'feincms_editable', True):\n            editable_class = ' tree-item-not-editable'\n\n        r += '<span id=\"page_marker-%d\" class=\"page_marker%s\" style=\"width: %dpx;\">&nbsp;</span>&nbsp;' % (\n            item.id, editable_class, 14 + item.level * 18)\n        #        r += '<span tabindex=\"0\">'\n        if hasattr(item, 'short_title'):\n            r += item.short_title()\n        else:\n            r += unicode(item)\n            #        r += '</span>'\n        return mark_safe(r)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _collect_editable_booleans(self):\n        if hasattr(self, '_ajax_editable_booleans'):\n            return\n\n        self._ajax_editable_booleans = {}\n\n        for field in self.list_display:\n            # The ajax_editable_boolean return value has to be assigned\n            # to the ModelAdmin class\n            item = getattr(self.__class__, field, None)\n            if not item:\n                continue\n\n            attr = getattr(item, 'editable_boolean_field', None)\n            if attr:\n                def _fn(self, instance):\n                    return [ajax_editable_boolean_cell(instance, _fn.attr)]\n\n                _fn.attr = attr\n                result_func = getattr(item, 'editable_boolean_result', _fn)\n                self._ajax_editable_booleans[attr] = result_func", "response": "Collect all fields marked as editable booleans."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _toggle_boolean(self, request):\n        try:\n            item_id = int(request.POST.get('item_id', None))\n            attr = str(request.POST.get('attr', None))\n        except:\n            return HttpResponseBadRequest(\"Malformed request\")\n\n        if not request.user.is_staff:\n            logging.warning(\"Denied AJAX request by non-staff %s to toggle boolean %s for object #%s\", request.user,\n                            attr, item_id)\n            return HttpResponseForbidden(\"You do not have permission to access this object\")\n\n        self._collect_editable_booleans()\n\n        if not self._ajax_editable_booleans.has_key(attr):\n            return HttpResponseBadRequest(\"not a valid attribute %s\" % attr)\n\n        try:\n            obj = self.model._default_manager.get(pk=item_id)\n        except self.model.DoesNotExist:\n            return HttpResponseNotFound(\"Object does not exist\")\n\n        can_change = False\n\n        if hasattr(obj, \"user_can\") and obj.user_can(request.user, change_page=True):\n            # Was added in c7f04dfb5d, but I've no idea what user_can is about.\n            can_change = True\n        else:\n            can_change = self.has_change_permission(request, obj=obj)\n\n        if not can_change:\n            logging.warning(\"Denied AJAX request by %s to toggle boolean %s for object %s\", request.user, attr, item_id)\n            return HttpResponseForbidden(\"You do not have permission to access this object\")\n\n        logging.info(\"Processing request by %s to toggle %s on %s\", request.user, attr, obj)\n\n        try:\n            before_data = self._ajax_editable_booleans[attr](self, obj)\n\n            setattr(obj, attr, not getattr(obj, attr))\n            obj.save()\n\n            self._refresh_changelist_caches() # ???: Perhaps better a post_save signal?\n\n            # Construct html snippets to send back to client for status update\n            data = self._ajax_editable_booleans[attr](self, obj)\n\n        except Exception:#, e:\n            logging.exception(\"Unhandled exception while toggling %s on %s\", attr, obj)\n            return HttpResponseServerError(\"Unable to toggle %s on %s\" % (attr, obj))\n\n        # Weed out unchanged cells to keep the updates small. This assumes\n        # that the order a possible get_descendents() returns does not change\n        # before and after toggling this attribute. Unlikely, but still...\n        d = []\n        for a, b in zip(before_data, data):\n            if a != b:\n                d.append(b)\n\n        # TODO: Shorter: [ y for x,y in zip(a,b) if x!=y ]\n        return HttpResponse(json.dumps(d), mimetype=\"application/json\")", "response": "Handle an AJAX toggle_boolean request"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle the changelist view for the model instances", "response": "def changelist_view(self, request, extra_context=None, *args, **kwargs):\n        \"\"\"\n        Handle the changelist view, the django view for the model instances\n        change list/actions page.\n        \"\"\"\n\n        if 'actions_column' not in self.list_display:\n            self.list_display.append('actions_column')\n\n        # handle common AJAX requests\n        if request.is_ajax():\n            cmd = request.POST.get('__cmd')\n            if cmd == 'toggle_boolean':\n                return self._toggle_boolean(request)\n            elif cmd == 'move_node':\n                return self._move_node(request)\n            else:\n                return HttpResponseBadRequest('Oops. AJAX request not understood.')\n\n        self._refresh_changelist_caches()\n\n        extra_context = extra_context or {}\n        extra_context['STATIC_URL'] = settings.STATIC_URL\n        extra_context['JQUERY_LIB'] = settings.JQUERY_LIB\n        extra_context['JQUERYUI_LIB'] = settings.JQUERYUI_LIB\n        extra_context['tree_structure'] = mark_safe(json.dumps(\n            _build_tree_structure(self.model)))\n\n        return super(TreeEditor, self).changelist_view(request, extra_context, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimplement a lookup for object level permissions. Basically the same as ModelAdmin. has_change_permission but also passes the obj parameter in.", "response": "def has_change_permission(self, request, obj=None):\n        \"\"\"\n        Implement a lookup for object level permissions. Basically the same as\n        ModelAdmin.has_change_permission, but also passes the obj parameter in.\n        \"\"\"\n        if settings.TREE_EDITOR_OBJECT_PERMISSIONS:\n            opts = self.opts\n            r = request.user.has_perm(opts.app_label + '.' + opts.get_change_permission(), obj)\n        else:\n            r = True\n\n        return r and super(TreeEditor, self).has_change_permission(request, obj)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has_delete_permission(self, request, obj=None):\n        if settings.TREE_EDITOR_OBJECT_PERMISSIONS:\n            opts = self.opts\n            r = request.user.has_perm(opts.app_label + '.' + opts.get_delete_permission(), obj)\n        else:\n            r = True\n\n        return r and super(TreeEditor, self).has_delete_permission(request, obj)", "response": "Implement a lookup for object level permissions. Basically the same as ModelAdmin. has_delete_permission but also passes the obj parameter in."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a random Directed Acyclic Graph with a given number of nodes and edges.", "response": "def random_dag(nodes, edges):\n    \"\"\"Generate a random Directed Acyclic Graph (DAG) with a given number of nodes and edges.\"\"\"\n    G = nx.DiGraph()\n    for i in range(nodes):\n        G.add_node(i)\n    while edges > 0:\n        a = randint(0,nodes-1)\n        b=a\n        while b==a:\n            b = randint(0,nodes-1)\n        G.add_edge(a,b)\n        if nx.is_directed_acyclic_graph(G):\n            edges -= 1\n        else:\n            # we closed a loop!\n            G.remove_edge(a,b)\n    return G"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_children(G, parent, level, n=2):\n    if level == 0:\n        return\n    for i in range(n):\n        child = parent+str(i)\n        G.add_node(child)\n        G.add_edge(parent,child)\n        add_children(G, child, level-1, n)", "response": "Add children recursively to a binary tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake a symmetrical binary tree with @levels", "response": "def make_bintree(levels):\n    \"\"\"Make a symmetrical binary tree with @levels\"\"\"\n    G = nx.DiGraph()\n    root = '0'\n    G.add_node(root)\n    add_children(G, root, levels, 2)\n    return G"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsubmits jobs via client where G describes the time dependencies.", "response": "def submit_jobs(view, G, jobs):\n    \"\"\"Submit jobs via client where G describes the time dependencies.\"\"\"\n    results = {}\n    for node in nx.topological_sort(G):\n        with view.temp_flags(after=[ results[n] for n in G.predecessors(node) ]):\n            results[node] = view.apply(jobs[node])\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_tree(G, results):\n    for node in G:\n        started = results[node].metadata.started\n        for parent in G.predecessors(node):\n            finished = results[parent].metadata.completed\n            assert started > finished, \"%s should have happened after %s\"%(node, parent)", "response": "Validate that jobs executed after their dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main(nodes, edges):\n    from matplotlib import pyplot as plt\n    from matplotlib.dates import date2num\n    from matplotlib.cm import gist_rainbow\n    print(\"building DAG\")\n    G = random_dag(nodes, edges)\n    jobs = {}\n    pos = {}\n    colors = {}\n    for node in G:\n        jobs[node] = randomwait\n    \n    client = parallel.Client()\n    view = client.load_balanced_view()\n    print(\"submitting %i tasks with %i dependencies\"%(nodes,edges))\n    results = submit_jobs(view, G, jobs)\n    print(\"waiting for results\")\n    view.wait()\n    print(\"done\")\n    for node in G:\n        md = results[node].metadata\n        start = date2num(md.started)\n        runtime = date2num(md.completed) - start\n        pos[node] = (start, runtime)\n        colors[node] = md.engine_id\n    validate_tree(G, results)\n    nx.draw(G, pos, node_list=colors.keys(), node_color=colors.values(), cmap=gist_rainbow,\n            with_labels=False)\n    x,y = zip(*pos.values())\n    xmin,ymin = map(min, (x,y))\n    xmax,ymax = map(max, (x,y))\n    xscale = xmax-xmin\n    yscale = ymax-ymin\n    plt.xlim(xmin-xscale*.1,xmax+xscale*.1)\n    plt.ylim(ymin-yscale*.1,ymax+yscale*.1)\n    return G,results", "response": "Generate a random graph submit jobs then validate that the dependency order was enforced."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_color_table(in_class):\n\n    for name,value in color_templates:\n        setattr(in_class,name,in_class._base % value)", "response": "Build a set of color attributes in a class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a full copy of the object optionally renaming it.", "response": "def copy(self,name=None):\n        \"\"\"Return a full copy of the object, optionally renaming it.\"\"\"\n        if name is None:\n            name = self.name\n        return ColorScheme(name, self.colors.dict())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a new color scheme to the table.", "response": "def add_scheme(self,new_scheme):\n        \"\"\"Add a new color scheme to the table.\"\"\"\n        if not isinstance(new_scheme,ColorScheme):\n            raise ValueError,'ColorSchemeTable only accepts ColorScheme instances'\n        self[new_scheme.name] = new_scheme"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_active_scheme(self,scheme,case_sensitive=0):\n\n        scheme_names = self.keys()\n        if case_sensitive:\n            valid_schemes = scheme_names\n            scheme_test = scheme\n        else:\n            valid_schemes = [s.lower() for s in scheme_names]\n            scheme_test = scheme.lower()\n        try:\n            scheme_idx = valid_schemes.index(scheme_test)\n        except ValueError:\n            raise ValueError,'Unrecognized color scheme: ' + scheme + \\\n                  '\\nValid schemes: '+str(scheme_names).replace(\"'', \",'')\n        else:\n            active = scheme_names[scheme_idx]\n            self.active_scheme_name = active\n            self.active_colors = self[active].colors\n            # Now allow using '' as an index for the current active scheme\n            self[''] = self[active]", "response": "Set the currently active color scheme."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the lib dir under the home installation scheme", "response": "def home_lib(home):\n    \"\"\"Return the lib dir under the 'home' installation scheme\"\"\"\n    if hasattr(sys, 'pypy_version_info'):\n        lib = 'site-packages'\n    else:\n        lib = os.path.join('lib', 'python')\n    return os.path.join(home, lib)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cache(descriptor=None, *, store: IStore = None):\n    '''\n    usage:\n\n    ``` py\n    @cache\n    @property\n    def name(self): pass\n    ```\n    '''\n\n    if descriptor is None:\n        return functools.partial(cache, store=store)\n\n    hasattrs = {\n        'get': hasattr(descriptor, '__get__'),\n        'set': hasattr(descriptor, '__set__'),\n        'del': hasattr(descriptor, '__delete__')\n    }\n\n    descriptor_name = get_descriptor_name(descriptor)\n\n    # pylint: disable=R0903,C0111\n    class CacheDescriptor(ICacheDescriptor):\n        def __init__(self):\n            if descriptor_name is not None:\n                self.__name__ = descriptor_name\n\n    cache_descriptor = CacheDescriptor()\n\n    if store is None:\n        store = FieldStore(cache_descriptor)\n    elif not isinstance(store, IStore):\n        raise TypeError(f'store must be a {IStore}.')\n\n    if hasattrs['get']:\n        def get(self, obj, objtype):\n            if obj is None:\n                return descriptor.__get__(obj, objtype)\n            value = store.get(self, obj, defval=NOVALUE)\n            if value is NOVALUE:\n                value = descriptor.__get__(obj, objtype)\n                store.set(self, obj, value)\n            return value\n\n        CacheDescriptor.__get__ = get\n\n    if hasattrs['set']:\n        def set(self, obj, value):\n            store.pop(self, obj)\n            descriptor.__set__(obj, value)\n\n        CacheDescriptor.__set__ = set\n\n    if hasattrs['del']:\n        def delete(self, obj):\n            store.pop(self, obj)\n            descriptor.__delete__(obj)\n\n        CacheDescriptor.__delete__ = delete\n\n    return cache_descriptor", "response": "A simple cache for the given object descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init_completer(self):\n        from IPython.core.completerlib import (module_completer,\n                                               magic_run_completer, cd_completer)\n        \n        self.Completer = ZMQCompleter(self, self.km)\n        \n\n        self.set_hook('complete_command', module_completer, str_key = 'import')\n        self.set_hook('complete_command', module_completer, str_key = 'from')\n        self.set_hook('complete_command', magic_run_completer, str_key = '%run')\n        self.set_hook('complete_command', cd_completer, str_key = '%cd')\n\n        # Only configure readline if we truly are using readline.  IPython can\n        # do tab-completion over the network, in GUIs, etc, where readline\n        # itself may be absent\n        if self.has_readline:\n            self.set_readline_completer()", "response": "Initialize the completer machinery."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_cell(self, cell, store_history=True):\n        if (not cell) or cell.isspace():\n            return\n\n        if cell.strip() == 'exit':\n            # explicitly handle 'exit' command\n            return self.ask_exit()\n\n        self._executing = True\n        # flush stale replies, which could have been ignored, due to missed heartbeats\n        while self.km.shell_channel.msg_ready():\n            self.km.shell_channel.get_msg()\n        # shell_channel.execute takes 'hidden', which is the inverse of store_hist\n        msg_id = self.km.shell_channel.execute(cell, not store_history)\n        while not self.km.shell_channel.msg_ready() and self.km.is_alive:\n            try:\n                self.handle_stdin_request(timeout=0.05)\n            except Empty:\n                # display intermediate print statements, etc.\n                self.handle_iopub()\n                pass\n        if self.km.shell_channel.msg_ready():\n            self.handle_execute_reply(msg_id)\n        self._executing = False", "response": "Runs a complete IPython cell."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_iopub(self):\n        while self.km.sub_channel.msg_ready():\n            sub_msg = self.km.sub_channel.get_msg()\n            msg_type = sub_msg['header']['msg_type']\n            parent = sub_msg[\"parent_header\"]\n            if (not parent) or self.session_id == parent['session']:\n                if msg_type == 'status' :\n                    if sub_msg[\"content\"][\"execution_state\"] == \"busy\" :\n                        pass\n\n                elif msg_type == 'stream' :\n                    if sub_msg[\"content\"][\"name\"] == \"stdout\":\n                        print(sub_msg[\"content\"][\"data\"], file=io.stdout, end=\"\")\n                        io.stdout.flush()\n                    elif sub_msg[\"content\"][\"name\"] == \"stderr\" :\n                        print(sub_msg[\"content\"][\"data\"], file=io.stderr, end=\"\")\n                        io.stderr.flush()\n\n                elif msg_type == 'pyout':\n                    self.execution_count = int(sub_msg[\"content\"][\"execution_count\"])\n                    format_dict = sub_msg[\"content\"][\"data\"]\n                    # taken from DisplayHook.__call__:\n                    hook = self.displayhook\n                    hook.start_displayhook()\n                    hook.write_output_prompt()\n                    hook.write_format_data(format_dict)\n                    hook.log_output(format_dict)\n                    hook.finish_displayhook()", "response": "Method to process the messages in different calendars from the kernel manager."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle_stdin_request(self, timeout=0.1):\n        msg_rep = self.km.stdin_channel.get_msg(timeout=timeout)\n        # in case any iopub came while we were waiting:\n        self.handle_iopub()\n        if self.session_id == msg_rep[\"parent_header\"].get(\"session\"):\n            # wrap SIGINT handler\n            real_handler = signal.getsignal(signal.SIGINT)\n            def double_int(sig,frame):\n                # call real handler (forwards sigint to kernel),\n                # then raise local interrupt, stopping local raw_input\n                real_handler(sig,frame)\n                raise KeyboardInterrupt\n            signal.signal(signal.SIGINT, double_int)\n            \n            try:\n                raw_data = raw_input(msg_rep[\"content\"][\"prompt\"])\n            except EOFError:\n                # turn EOFError into EOF character\n                raw_data = '\\x04'\n            except KeyboardInterrupt:\n                sys.stdout.write('\\n')\n                return\n            finally:\n                # restore SIGINT handler\n                signal.signal(signal.SIGINT, real_handler)\n            \n            # only send stdin reply if there *was not* another request\n            # or execution finished while we were reading.\n            if not (self.km.stdin_channel.msg_ready() or self.km.shell_channel.msg_ready()):\n                self.km.stdin_channel.input(raw_data)", "response": "Method to capture raw_input_is_stdin_request"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_tokens_unprocessed(self, text, stack=('root',)):\n    pos = 0\n    tokendefs = self._tokens\n    if hasattr(self, '_saved_state_stack'):\n        statestack = list(self._saved_state_stack)\n    else:\n        statestack = list(stack)\n    statetokens = tokendefs[statestack[-1]]\n    while 1:\n        for rexmatch, action, new_state in statetokens:\n            m = rexmatch(text, pos)\n            if m:\n                if type(action) is _TokenType:\n                    yield pos, action, m.group()\n                else:\n                    for item in action(self, m):\n                        yield item\n                pos = m.end()\n                if new_state is not None:\n                    # state transition\n                    if isinstance(new_state, tuple):\n                        for state in new_state:\n                            if state == '#pop':\n                                statestack.pop()\n                            elif state == '#push':\n                                statestack.append(statestack[-1])\n                            else:\n                                statestack.append(state)\n                    elif isinstance(new_state, int):\n                        # pop\n                        del statestack[new_state:]\n                    elif new_state == '#push':\n                        statestack.append(statestack[-1])\n                    else:\n                        assert False, \"wrong state def: %r\" % new_state\n                    statetokens = tokendefs[statestack[-1]]\n                break\n        else:\n            try:\n                if text[pos] == '\\n':\n                    # at EOL, reset state to \"root\"\n                    pos += 1\n                    statestack = ['root']\n                    statetokens = tokendefs['root']\n                    yield pos, Text, u'\\n'\n                    continue\n                yield pos, Error, text[pos]\n                pos += 1\n            except IndexError:\n                break\n    self._saved_state_stack = list(statestack)", "response": "Yields a list of tokens that are not in the stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the style of the log entry.", "response": "def set_style(self, style):\n        \"\"\" Sets the style to the specified Pygments style.\n        \"\"\"\n        if isinstance(style, basestring):\n            style = get_style_by_name(style)\n        self._style = style\n        self._clear_caches()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a QTextCharFormat for token or None.", "response": "def _get_format(self, token):\n        \"\"\" Returns a QTextCharFormat for token or None.\n        \"\"\"\n        if token in self._formats:\n            return self._formats[token]\n\n        if self._style is None:\n            result = self._get_format_from_document(token, self._document)\n        else:\n            result = self._get_format_from_style(token, self._style)\n\n        self._formats[token] = result\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a QTextCharFormat for the given token by the given document.", "response": "def _get_format_from_document(self, token, document):\n        \"\"\" Returns a QTextCharFormat for token by\n        \"\"\"\n        code, html = self._formatter._format_lines([(token, u'dummy')]).next()\n        self._document.setHtml(html)\n        return QtGui.QTextCursor(self._document).charFormat()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_format_from_style(self, token, style):\n        result = QtGui.QTextCharFormat()\n        for key, value in style.style_for_token(token).items():\n            if value:\n                if key == 'color':\n                    result.setForeground(self._get_brush(value))\n                elif key == 'bgcolor':\n                    result.setBackground(self._get_brush(value))\n                elif key == 'bold':\n                    result.setFontWeight(QtGui.QFont.Bold)\n                elif key == 'italic':\n                    result.setFontItalic(True)\n                elif key == 'underline':\n                    result.setUnderlineStyle(\n                        QtGui.QTextCharFormat.SingleUnderline)\n                elif key == 'sans':\n                    result.setFontStyleHint(QtGui.QFont.SansSerif)\n                elif key == 'roman':\n                    result.setFontStyleHint(QtGui.QFont.Times)\n                elif key == 'mono':\n                    result.setFontStyleHint(QtGui.QFont.TypeWriter)\n        return result", "response": "Returns a QTextCharFormat for the given token by reading a Pygments style."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch the PATH for the given command and returns its path", "response": "def find_command(cmd, paths=None, pathext=None):\n    \"\"\"Searches the PATH for the given command and returns its path\"\"\"\n    if paths is None:\n        paths = os.environ.get('PATH', '').split(os.pathsep)\n    if isinstance(paths, six.string_types):\n        paths = [paths]\n    # check if there are funny path extensions for executables, e.g. Windows\n    if pathext is None:\n        pathext = get_pathext()\n    pathext = [ext for ext in pathext.lower().split(os.pathsep) if len(ext)]\n    # don't use extensions if the command ends with one of them\n    if os.path.splitext(cmd)[1].lower() in pathext:\n        pathext = ['']\n    # check if we find the command on PATH\n    for path in paths:\n        # try without extension first\n        cmd_path = os.path.join(path, cmd)\n        for ext in pathext:\n            # then including the extension\n            cmd_path_ext = cmd_path + ext\n            if os.path.isfile(cmd_path_ext):\n                return cmd_path_ext\n        if os.path.isfile(cmd_path):\n            return cmd_path\n    raise BadCommand('Cannot find command %r' % cmd)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalize_path(path):\n    return os.path.normcase(os.path.realpath(os.path.expanduser(path)))", "response": "Convert a path to its canonical case - normalized absolute version."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify that namespace packages are valid.", "response": "def check_nsp(dist, attr, value):\n    \"\"\"Verify that namespace packages are valid\"\"\"\n    assert_string_list(dist,attr,value)\n    for nsp in value:\n        if not dist.has_contents_for(nsp):\n            raise DistutilsSetupError(\n                \"Distribution contains no modules or packages for \" +\n                \"namespace package %r\" % nsp\n            )\n        if '.' in nsp:\n            parent = '.'.join(nsp.split('.')[:-1])\n            if parent not in value:\n                distutils.log.warn(\n                    \"%r is declared as a package namespace, but %r is not:\"\n                    \" please correct this in setup.py\", nsp, parent\n                )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies that extras_require mapping is valid.", "response": "def check_extras(dist, attr, value):\n    \"\"\"Verify that extras_require mapping is valid\"\"\"\n    try:\n        for k,v in value.items():\n            list(pkg_resources.parse_requirements(v))\n    except (TypeError,ValueError,AttributeError):\n        raise DistutilsSetupError(\n            \"'extras_require' must be a dictionary whose values are \"\n            \"strings or lists of strings containing valid project/version \"\n            \"requirement specifiers.\"\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_entry_points(dist, attr, value):\n    try:\n        pkg_resources.EntryPoint.parse_map(value)\n    except ValueError, e:\n        raise DistutilsSetupError(e)", "response": "Verify that entry_points map is parseable"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_display_options(self, option_order):\n        import sys\n\n        if sys.version_info < (3,) or self.help_commands:\n            return _Distribution.handle_display_options(self, option_order)\n\n        # Stdout may be StringIO (e.g. in tests)\n        import io\n        if not isinstance(sys.stdout, io.TextIOWrapper):\n            return _Distribution.handle_display_options(self, option_order)\n\n        # Don't wrap stdout if utf-8 is already the encoding. Provides\n        #  workaround for #334.\n        if sys.stdout.encoding.lower() in ('utf-8', 'utf8'):\n            return _Distribution.handle_display_options(self, option_order)\n\n        # Print metadata in UTF-8 no matter the platform\n        encoding = sys.stdout.encoding\n        errors = sys.stdout.errors\n        newline = sys.platform != 'win32' and '\\n' or None\n        line_buffering = sys.stdout.line_buffering\n\n        sys.stdout = io.TextIOWrapper(\n            sys.stdout.detach(), 'utf-8', errors, newline, line_buffering)\n        try:\n            return _Distribution.handle_display_options(self, option_order)\n        finally:\n            sys.stdout = io.TextIOWrapper(\n                sys.stdout.detach(), encoding, errors, newline, line_buffering)", "response": "Handles display - only options on the command - line and returns true if any display - only options are present on the command - line and return false otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines if the input source ends in a blank.", "response": "def last_blank(src):\n    \"\"\"Determine if the input source ends in a blank.\n\n    A blank is either a newline or a line consisting of whitespace.\n\n    Parameters\n    ----------\n    src : string\n      A single or multiline string.\n    \"\"\"\n    if not src: return False\n    ll  = src.splitlines()[-1]\n    return (ll == '') or ll.isspace()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef last_two_blanks(src):\n    if not src: return False\n    # The logic here is tricky: I couldn't get a regexp to work and pass all\n    # the tests, so I took a different approach: split the source by lines,\n    # grab the last two and prepend '###\\n' as a stand-in for whatever was in\n    # the body before the last two lines.  Then, with that structure, it's\n    # possible to analyze with two regexps.  Not the most elegant solution, but\n    # it works.  If anyone tries to change this logic, make sure to validate\n    # the whole test suite first!\n    new_src = '\\n'.join(['###\\n'] + src.splitlines()[-2:])\n    return (bool(last_two_blanks_re.match(new_src)) or\n            bool(last_two_blanks_re2.match(new_src)) )", "response": "Determine if the input source ends in two blanks."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nindicate whether an input line ends in a comment.", "response": "def has_comment(src):\n    \"\"\"Indicate whether an input line has (i.e. ends in, or is) a comment.\n    \n    This uses tokenize, so it can distinguish comments from # inside strings.\n    \n    Parameters\n    ----------\n    src : string\n      A single line input string.\n    \n    Returns\n    -------\n    Boolean: True if source has a comment.\n    \"\"\"\n    readline = StringIO(src).readline\n    toktypes = set()\n    try:\n        for t in tokenize.generate_tokens(readline):\n            toktypes.add(t[0])\n    except tokenize.TokenError:\n        pass\n    return(tokenize.COMMENT in toktypes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles the files =!ls syntax.", "response": "def transform_assign_system(line):\n    \"\"\"Handle the `files = !ls` syntax.\"\"\"\n    m = _assign_system_re.match(line)\n    if m is not None:\n        cmd = m.group('cmd')\n        lhs = m.group('lhs')\n        new_line = '%s = get_ipython().getoutput(%r)' % (lhs, cmd)\n        return new_line\n    return line"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transform_assign_magic(line):\n    m = _assign_magic_re.match(line)\n    if m is not None:\n        cmd = m.group('cmd')\n        lhs = m.group('lhs')\n        new_line = '%s = get_ipython().magic(%r)' % (lhs, cmd)\n        return new_line\n    return line", "response": "Handle the a = %who syntax."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle inputs that start with >>> syntax.", "response": "def transform_classic_prompt(line):\n    \"\"\"Handle inputs that start with '>>> ' syntax.\"\"\"\n\n    if not line or line.isspace():\n        return line\n    m = _classic_prompt_re.match(line)\n    if m:\n        return line[len(m.group(0)):]\n    else:\n        return line"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transform_ipy_prompt(line):\n\n    if not line or line.isspace():\n        return line\n    #print 'LINE:  %r' % line # dbg\n    m = _ipy_prompt_re.match(line)\n    if m:\n        #print 'MATCH! %r -> %r' % (line, line[len(m.group(0)):]) # dbg\n        return line[len(m.group(0)):]\n    else:\n        return line", "response": "Handle inputs that start classic IPython prompt syntax."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npreparing a help call from a target name and the escape", "response": "def _make_help_call(target, esc, lspace, next_input=None):\n    \"\"\"Prepares a pinfo(2)/psearch call from a target name and the escape\n    (i.e. ? or ??)\"\"\"\n    method  = 'pinfo2' if esc == '??' \\\n                else 'psearch' if '*' in target \\\n                else 'pinfo'\n    arg = \" \".join([method, target])\n    if next_input is None:\n        return '%sget_ipython().magic(%r)' % (lspace, arg)\n    else:\n        return '%sget_ipython().set_next_input(%r);get_ipython().magic(%r)' % \\\n           (lspace, next_input, arg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntranslates lines with? or? at the end of help line", "response": "def transform_help_end(line):\n    \"\"\"Translate lines with ?/?? at the end\"\"\"\n    m = _help_end_re.search(line)\n    if m is None or has_comment(line):\n        return line\n    target = m.group(1)\n    esc = m.group(3)\n    lspace = _initial_space_re.match(line).group(0)\n    \n    # If we're mid-command, put it back on the next prompt for the user.\n    next_input = line.rstrip('?') if line.strip() != m.group(0) else None\n        \n    return _make_help_call(target, esc, lspace, next_input)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reset(self):\n        self.indent_spaces = 0\n        self._buffer[:] = []\n        self.source = ''\n        self.code = None\n        self._is_complete = False\n        self._full_dedent = False", "response": "Reset the input buffer and associated state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef push(self, lines):\n        if self.input_mode == 'cell':\n            self.reset()\n        \n        self._store(lines)\n        source = self.source\n\n        # Before calling _compile(), reset the code object to None so that if an\n        # exception is raised in compilation, we don't mislead by having\n        # inconsistent code/source attributes.\n        self.code, self._is_complete = None, None\n\n        # Honor termination lines properly\n        if source.rstrip().endswith('\\\\'):\n            return False\n\n        self._update_indent(lines)\n        try:\n            self.code = self._compile(source, symbol=\"exec\")\n        # Invalid syntax can produce any of a number of different errors from\n        # inside the compiler, so we have to catch them all.  Syntax errors\n        # immediately produce a 'ready' block, so the invalid Python can be\n        # sent to the kernel for evaluation with possible ipython\n        # special-syntax conversion.\n        except (SyntaxError, OverflowError, ValueError, TypeError,\n                MemoryError):\n            self._is_complete = True\n        else:\n            # Compilation didn't produce any exceptions (though it may not have\n            # given a complete code object)\n            self._is_complete = self.code is not None\n\n        return self._is_complete", "response": "Push one or more lines of input into the internal code object and returns a status code indicating whether the code forms a complete Python execution block or not."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef push_accepts_more(self):\n\n        # With incomplete input, unconditionally accept more\n        if not self._is_complete:\n            return True\n\n        # If we already have complete input and we're flush left, the answer\n        # depends.  In line mode, if there hasn't been any indentation,\n        # that's it. If we've come back from some indentation, we need\n        # the blank final line to finish.\n        # In cell mode, we need to check how many blocks the input so far\n        # compiles into, because if there's already more than one full\n        # independent block of input, then the client has entered full\n        # 'cell' mode and is feeding lines that each is complete.  In this\n        # case we should then keep accepting. The Qt terminal-like console\n        # does precisely this, to provide the convenience of terminal-like\n        # input of single expressions, but allowing the user (with a\n        # separate keystroke) to switch to 'cell' mode and type multiple\n        # expressions in one shot.\n        if self.indent_spaces==0:\n            if self.input_mode=='line':\n                if not self._full_dedent:\n                    return False\n            else:\n                try:\n                    code_ast = ast.parse(u''.join(self._buffer))\n                except Exception:\n                    return False\n                else:\n                    if len(code_ast.body) == 1:\n                        return False\n\n        # When input is complete, then termination is marked by an extra blank\n        # line at the end.\n        last_line = self.source.splitlines()[-1]\n        return bool(last_line and not last_line.isspace())", "response": "Return whether a block of interactive input can accept more input."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _find_indent(self, line):\n        indent_spaces = self.indent_spaces\n        full_dedent = self._full_dedent\n        \n        inisp = num_ini_spaces(line)\n        if inisp < indent_spaces:\n            indent_spaces = inisp\n            if indent_spaces <= 0:\n                #print 'Full dedent in text',self.source # dbg\n                full_dedent = True\n\n        if line.rstrip()[-1] == ':':\n            indent_spaces += 4\n        elif dedent_re.match(line):\n            indent_spaces -= 4\n            if indent_spaces <= 0:\n                full_dedent = True\n\n        # Safety\n        if indent_spaces < 0:\n            indent_spaces = 0\n            #print 'safety' # dbg\n            \n        return indent_spaces, full_dedent", "response": "Compute the new indentation level for a single line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _store(self, lines, buffer=None, store='source'):\n        \n        if buffer is None:\n            buffer = self._buffer\n            \n        if lines.endswith('\\n'):\n            buffer.append(lines)\n        else:\n            buffer.append(lines+'\\n')\n        setattr(self, store, self._set_source(buffer))", "response": "Store one or more lines of input."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _tr_system(line_info):\n        \"Translate lines escaped with: !\"\n        cmd = line_info.line.lstrip().lstrip(ESC_SHELL)\n        return '%sget_ipython().system(%r)' % (line_info.pre, cmd)", "response": "Translate lines escaped with :!\""}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _tr_help(line_info):\n        \"Translate lines escaped with: ?/??\"\n        # A naked help line should just fire the intro help screen\n        if not line_info.line[1:]:\n            return 'get_ipython().show_usage()'\n        \n        return _make_help_call(line_info.ifun, line_info.esc, line_info.pre)", "response": "Translate lines escaped with?/???"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _tr_magic(line_info):\n        \"Translate lines escaped with: %\"\n        tpl = '%sget_ipython().magic(%r)'\n        cmd = ' '.join([line_info.ifun, line_info.the_rest]).strip()\n        return tpl % (line_info.pre, cmd)", "response": "Translate lines escaped with : %"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntranslating lines escaped with :,", "response": "def _tr_quote(line_info):\n        \"Translate lines escaped with: ,\"\n        return '%s%s(\"%s\")' % (line_info.pre, line_info.ifun,\n                             '\", \"'.join(line_info.the_rest.split()) )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntranslates lines escaped with : /", "response": "def _tr_paren(line_info):\n        \"Translate lines escaped with: /\"\n        return '%s%s(%s)' % (line_info.pre, line_info.ifun,\n                             \", \".join(line_info.the_rest.split()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresetting the input buffer and associated state.", "response": "def reset(self):\n        \"\"\"Reset the input buffer and associated state.\"\"\"\n        super(IPythonInputSplitter, self).reset()\n        self._buffer_raw[:] = []\n        self.source_raw = ''\n        self.cell_magic_parts = []\n        self.processing_cell_magic = False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn input and raw source and perform a full reset.", "response": "def source_raw_reset(self):\n        \"\"\"Return input and raw source and perform a full reset.\n        \"\"\"\n        out = self.source\n        out_r = self.source_raw\n        self.reset()\n        return out, out_r"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _handle_cell_magic(self, lines):\n        self.processing_cell_magic = True\n        first, _, body = lines.partition('\\n')\n        magic_name, _, line = first.partition(' ')\n        magic_name = magic_name.lstrip(ESC_MAGIC)\n        # We store the body of the cell and create a call to a method that\n        # will use this stored value. This is ugly, but it's a first cut to\n        # get it all working, as right now changing the return API of our\n        # methods would require major refactoring.\n        self.cell_magic_parts = [body]\n        tpl = 'get_ipython()._run_cached_cell_magic(%r, %r)'\n        tlines = tpl % (magic_name, line)\n        self._store(tlines)\n        self._store(lines, self._buffer_raw, 'source_raw')\n        # We can actually choose whether to allow for single blank lines here\n        # during input for clients that use cell mode to decide when to stop\n        # pushing input (currently only the Qt console).\n        # My first implementation did that, and then I realized it wasn't\n        # consistent with the terminal behavior, so I've reverted it to one\n        # line.  But I'm leaving it here so we can easily test both behaviors,\n        # I kind of liked having full blank lines allowed in the cell magics...\n        #self._is_complete = last_two_blanks(lines)\n        self._is_complete = last_blank(lines)\n        return self._is_complete", "response": "Process lines when they start with %%, which marks cell magics."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nappends new content to the cell magic pieces.", "response": "def _line_mode_cell_append(self, lines):\n        \"\"\"Append new content for a cell magic in line mode.\n        \"\"\"\n        # Only store the raw input.  Lines beyond the first one are only only\n        # stored for history purposes; for execution the caller will grab the\n        # magic pieces from cell_magic_parts and will assemble the cell body\n        self._store(lines, self._buffer_raw, 'source_raw')\n        self.cell_magic_parts.append(lines)\n        # Find out if the last stored block has a whitespace line as its\n        # last line and also this line is whitespace, case in which we're\n        # done (two contiguous blank lines signal termination).  Note that\n        # the storage logic *enforces* that every stored block is\n        # newline-terminated, so we grab everything but the last character\n        # so we can have the body of the block alone.\n        last_block = self.cell_magic_parts[-1]\n        self._is_complete = last_blank(last_block) and lines.isspace()\n        return self._is_complete"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transform_cell(self, cell):\n        self.reset()\n        self.push(cell)\n        return self.source_reset()", "response": "Process and translate a cell of input."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npush one or more lines of IPython input into the internal state.", "response": "def push(self, lines):\n        \"\"\"Push one or more lines of IPython input.\n\n        This stores the given lines and returns a status code indicating\n        whether the code forms a complete Python block or not, after processing\n        all input lines for special IPython syntax.\n\n        Any exceptions generated in compilation are swallowed, but if an\n        exception was produced, the method returns True.\n\n        Parameters\n        ----------\n        lines : string\n          One or more lines of Python input.\n\n        Returns\n        -------\n        is_complete : boolean\n          True if the current input source (the result of the current input\n        plus prior inputs) forms a complete Python execution block.  Note that\n        this value is also stored as a private attribute (_is_complete), so it\n        can be queried at any time.\n        \"\"\"\n        if not lines:\n            return super(IPythonInputSplitter, self).push(lines)\n\n        # We must ensure all input is pure unicode\n        lines = cast_unicode(lines, self.encoding)\n\n        # If the entire input block is a cell magic, return after handling it\n        # as the rest of the transformation logic should be skipped.\n        if lines.startswith('%%') and not \\\n          (len(lines.splitlines()) == 1 and lines.strip().endswith('?')):\n            return self._handle_cell_magic(lines)\n\n        # In line mode, a cell magic can arrive in separate pieces\n        if self.input_mode == 'line' and self.processing_cell_magic:\n            return self._line_mode_cell_append(lines)\n\n        # The rest of the processing is for 'normal' content, i.e. IPython\n        # source that we process through our transformations pipeline.\n        lines_list = lines.splitlines()\n\n        transforms = [transform_ipy_prompt, transform_classic_prompt,\n                      transform_help_end, transform_escaped,\n                      transform_assign_system, transform_assign_magic]\n\n        # Transform logic\n        #\n        # We only apply the line transformers to the input if we have either no\n        # input yet, or complete input, or if the last line of the buffer ends\n        # with ':' (opening an indented block).  This prevents the accidental\n        # transformation of escapes inside multiline expressions like\n        # triple-quoted strings or parenthesized expressions.\n        #\n        # The last heuristic, while ugly, ensures that the first line of an\n        # indented block is correctly transformed.\n        #\n        # FIXME: try to find a cleaner approach for this last bit.\n\n        # If we were in 'block' mode, since we're going to pump the parent\n        # class by hand line by line, we need to temporarily switch out to\n        # 'line' mode, do a single manual reset and then feed the lines one\n        # by one.  Note that this only matters if the input has more than one\n        # line.\n        changed_input_mode = False\n\n        if self.input_mode == 'cell':\n            self.reset()\n            changed_input_mode = True\n            saved_input_mode = 'cell'\n            self.input_mode = 'line'\n\n        # Store raw source before applying any transformations to it.  Note\n        # that this must be done *after* the reset() call that would otherwise\n        # flush the buffer.\n        self._store(lines, self._buffer_raw, 'source_raw')\n        \n        try:\n            push = super(IPythonInputSplitter, self).push\n            buf = self._buffer\n            for line in lines_list:\n                if self._is_complete or not buf or \\\n                       (buf and buf[-1].rstrip().endswith((':', ','))):\n                    for f in transforms:\n                        line = f(line)\n\n                out = push(line)\n        finally:\n            if changed_input_mode:\n                self.input_mode = saved_input_mode\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef post_notification(self, ntype, sender, *args, **kwargs):\n\n        if(ntype==None or sender==None):\n            raise NotificationError(\n                \"Notification type and sender are required.\")\n\n        # If there are no registered observers for the type/sender pair\n        if((ntype not in self.registered_types and\n                None not in self.registered_types) or\n            (sender not in self.registered_senders and\n                None not in self.registered_senders)):\n            return\n\n        for o in self._observers_for_notification(ntype, sender):\n            o(ntype, sender, *args, **kwargs)", "response": "Post a notification to all registered observers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _observers_for_notification(self, ntype, sender):\n\n        keys = (\n                   (ntype,sender),\n                   (ntype, None),\n                   (None, sender),\n                   (None,None)\n               )\n\n        obs = set()\n        for k in keys:\n            obs.update(self.observers.get(k, set()))\n\n        return obs", "response": "Find all registered observers that should recieve a notification"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_observer(self, callback, ntype, sender):\n        assert(callback != None)\n        self.registered_types.add(ntype)\n        self.registered_senders.add(sender)\n        self.observers.setdefault((ntype,sender), set()).add(callback)", "response": "Add an observer callback to this notification center."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef new(self, func_or_exp, *args, **kwargs):\n        \n        if callable(func_or_exp):\n            kw  = kwargs.get('kw',{})\n            job = BackgroundJobFunc(func_or_exp,*args,**kw)\n        elif isinstance(func_or_exp, basestring):\n            if not args:\n                frame = sys._getframe(1)\n                glob, loc = frame.f_globals, frame.f_locals\n            elif len(args)==1:\n                glob = loc = args[0]\n            elif len(args)==2:\n                glob,loc = args\n            else:\n                raise ValueError(\n                      'Expression jobs take at most 2 args (globals,locals)')\n            job = BackgroundJobExpr(func_or_exp, glob, loc)\n        else:\n            raise TypeError('invalid args for new job')\n\n        if kwargs.get('daemon', False):\n            job.daemon = True\n        job.num = len(self.all)+1 if self.all else 0\n        self.running.append(job)\n        self.all[job.num] = job\n        print 'Starting job # %s in a separate thread.' % job.num\n        job.start()\n        return job", "response": "Add a new background job and start it in a separate thread."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the status of the jobs in the list that have been completed and dead.", "response": "def _update_status(self):\n        \"\"\"Update the status of the job lists.\n\n        This method moves finished jobs to one of two lists:\n          - self.completed: jobs which completed successfully\n          - self.dead: jobs which finished but died.\n\n        It also copies those jobs to corresponding _report lists.  These lists\n        are used to report jobs completed/dead since the last update, and are\n        then cleared by the reporting function after each call.\"\"\"\n\n        # Status codes\n        srun, scomp, sdead = self._s_running, self._s_completed, self._s_dead\n        # State lists, use the actual lists b/c the public names are properties\n        # that call this very function on access\n        running, completed, dead = self._running, self._completed, self._dead\n\n        # Now, update all state lists\n        for num, job in enumerate(running):\n            stat = job.stat_code\n            if stat == srun:\n                continue\n            elif stat == scomp:\n                completed.append(job)\n                self._comp_report.append(job)\n                running[num] = False\n            elif stat == sdead:\n                dead.append(job)\n                self._dead_report.append(job)\n                running[num] = False\n        # Remove dead/completed jobs from running list\n        running[:] = filter(None, running)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _group_report(self,group,name):\n\n        if group:\n            print '%s jobs:' % name\n            for job in group:\n                print '%s : %s' % (job.num,job)\n            print\n            return True", "response": "Report summary for a given job group. Return True if the group had any elements."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nflush a given job group Return True if the group had any elements.", "response": "def _group_flush(self,group,name):\n        \"\"\"Flush a given job group\n\n        Return True if the group had any elements.\"\"\"\n\n        njobs = len(group)\n        if njobs:\n            plural = {1:''}.setdefault(njobs,'s')\n            print 'Flushing %s %s job%s.' % (njobs,name,plural)\n            group[:] = []\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting the status of newly finished jobs. Return True if any new jobs are reported.", "response": "def _status_new(self):\n        \"\"\"Print the status of newly finished jobs.\n\n        Return True if any new jobs are reported.\n\n        This call resets its own state every time, so it only reports jobs\n        which have finished since the last time it was called.\"\"\"\n\n        self._update_status()\n        new_comp = self._group_report(self._comp_report, 'Completed')\n        new_dead = self._group_report(self._dead_report,\n                                      'Dead, call jobs.traceback() for details')\n        self._comp_report[:] = []\n        self._dead_report[:] = []\n        return new_comp or new_dead"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef status(self,verbose=0):\n\n        self._update_status()\n        self._group_report(self.running,'Running')\n        self._group_report(self.completed,'Completed')\n        self._group_report(self.dead,'Dead')\n        # Also flush the report queues\n        self._comp_report[:] = []\n        self._dead_report[:] = []", "response": "Print a status of all currently being managed jobs."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves a finished or dead job.", "response": "def remove(self,num):\n        \"\"\"Remove a finished (completed or dead) job.\"\"\"\n\n        try:\n            job = self.all[num]\n        except KeyError:\n            error('Job #%s not found' % num)\n        else:\n            stat_code = job.stat_code\n            if stat_code == self._s_running:\n                error('Job #%s is still running, it can not be removed.' % num)\n                return\n            elif stat_code == self._s_completed:\n                self.completed.remove(job)\n            elif stat_code == self._s_dead:\n                self.dead.remove(job)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nflush all finished and dead jobs from lists.", "response": "def flush(self):\n        \"\"\"Flush all finished jobs (completed and dead) from lists.\n\n        Running jobs are never flushed.\n\n        It first calls _status_new(), to update info. If any jobs have\n        completed since the last _status_new() call, the flush operation\n        aborts.\"\"\"\n\n        # Remove the finished jobs from the master dict\n        alljobs = self.all\n        for job in self.completed+self.dead:\n            del(alljobs[job.num])\n\n        # Now flush these lists completely\n        fl_comp = self._group_flush(self.completed, 'Completed')\n        fl_dead = self._group_flush(self.dead, 'Dead')\n        if not (fl_comp or fl_dead):\n            print 'No jobs to flush.'"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef result(self,num):\n        try:\n            return self.all[num].result\n        except KeyError:\n            error('Job #%s not found' % num)", "response": "result ( N ) - > return the result of job N"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _init(self):\n        \n        for attr in ['call','strform']:\n            assert hasattr(self,attr), \"Missing attribute <%s>\" % attr\n        \n        # The num tag can be set by an external job manager\n        self.num = None\n      \n        self.status    = BackgroundJobBase.stat_created\n        self.stat_code = BackgroundJobBase.stat_created_c\n        self.finished  = False\n        self.result    = '<BackgroundJob has not completed>'\n        \n        # reuse the ipython traceback handler if we can get to it, otherwise\n        # make a new one\n        try:\n            make_tb = get_ipython().InteractiveTB.text\n        except:\n            make_tb = AutoFormattedTB(mode = 'Context',\n                                      color_scheme='NoColor',\n                                      tb_offset = 1).text\n        # Note that the actual API for text() requires the three args to be\n        # passed in, so we wrap it in a simple lambda.\n        self._make_tb = lambda : make_tb(None, None, None)\n\n        # Hold a formatted traceback if one is generated.\n        self._tb = None\n        \n        threading.Thread.__init__(self)", "response": "Common initialization for all BackgroundJob objects"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninserting a value into the list variable at an appropriate index.", "response": "def insert(self, idx, value):\n        \"\"\"\n        Inserts a value in the ``ListVariable`` at an appropriate index.\n\n        :param idx: The index before which to insert the new value.\n        :param value: The value to insert.\n        \"\"\"\n\n        self._value.insert(idx, value)\n        self._rebuild()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a shallow copy of the Environment.", "response": "def copy(self):\n        \"\"\"\n        Retrieve a copy of the Environment.  Note that this is a shallow\n        copy.\n        \"\"\"\n\n        return self.__class__(self._data.copy(), self._sensitive.copy(),\n                              self._cwd)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndeclare an environment variable as a special variable.", "response": "def _declare_special(self, name, sep, klass):\n        \"\"\"\n        Declare an environment variable as a special variable.  This can\n        be used even if the environment variable is not present.\n\n        :param name: The name of the environment variable that should\n                     be considered special.\n        :param sep: The separator to be used.\n        :param klass: The subclass of ``SpecialVariable`` used to\n                      represent the variable.\n        \"\"\"\n\n        # First, has it already been declared?\n        if name in self._special:\n            special = self._special[name]\n            if not isinstance(special, klass) or sep != special._sep:\n                raise ValueError('variable %s already declared as %s '\n                                 'with separator \"%s\"' %\n                                 (name, special.__class__.__name__,\n                                  special._sep))\n\n        # OK, it's new; declare it\n        else:\n            self._special[name] = klass(self, name, sep)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef declare_list(self, name, sep=os.pathsep):\n\n        self._declare_special(name, sep, ListVariable)", "response": "Declare an environment variable as a list - like special variable. This is a no - op if the environment variable is not present."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef declare_set(self, name, sep=os.pathsep):\n\n        self._declare_special(name, sep, SetVariable)", "response": "Declare an environment variable as a set - like special variable. This is a no - op if the environment variable is not set - like."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cwd(self, value):\n\n        self._cwd = utils.canonicalize_path(self._cwd, value)", "response": "Change the working directory that processes should be executed in."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef move(self, state=None):\n        state = self.state if state is None else state\n        route = state\n        a = random.randint(self.locked_range, len(route) - 1)\n        b = random.randint(self.locked_range, len(route) - 1)\n        route[a], route[b] = route[b], route[a]", "response": "Swaps two cities in the route."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the length of the route.", "response": "def energy(self, state=None):\n        \"\"\"Calculates the length of the route.\"\"\"\n        state = self.state if state is None else state\n        route = state\n        e = 0\n        if self.distance_matrix:\n            for i in range(len(route)):\n                e += self.distance_matrix[\"{},{}\".format(route[i-1], route[i])]\n        else:\n            for i in range(len(route)):\n                e += distance(self.cities[route[i-1]], self.cities[route[i]])\n        return e"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndivide the cities of a TSP problem into a list of routes.", "response": "def divide(cls, divisions, problem_data):\n        \"\"\"divide\n\n        :type problem_data: dict\n        \"\"\"\n        tspp = TSPProblem(**problem_data)\n\n        def routes_for_subgroup(cs):\n            for city in cs:\n                if city == tspp.start_city:\n                    continue\n                cities = tspp.cities.keys()\n                cities.remove(tspp.start_city)\n                cities.remove(city)\n                random.shuffle(cities)\n                route = [tspp.start_city, city] + cities\n                assert len(set(route)) == len(route)\n                assert len(route) == len(tspp.cities)\n                yield json.dumps(route)\n\n        if divisions:\n            chunk_size = int(math.ceil(len(tspp.cities) / divisions))\n        else:\n            chunk_size = 1\n        for subgroup in chunks(tspp.cities.keys(), chunk_size):\n            routes = list(routes_for_subgroup(subgroup))\n            if routes:\n                yield routes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an empty record", "response": "def _defaults(self, keys=None):\n        \"\"\"create an empty record\"\"\"\n        d = {}\n        keys = self._keys if keys is None else keys\n        for key in keys:\n            d[key] = None\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nensures that an incorrect table exists return True", "response": "def _check_table(self):\n        \"\"\"Ensure that an incorrect table doesn't exist\n\n        If a bad (old) table does exist, return False\n        \"\"\"\n        cursor = self._db.execute(\"PRAGMA table_info(%s)\"%self.table)\n        lines = cursor.fetchall()\n        if not lines:\n            # table does not exist\n            return True\n        types = {}\n        keys = []\n        for line in lines:\n            keys.append(line[1])\n            types[line[1]] = line[2]\n        if self._keys != keys:\n            # key mismatch\n            self.log.warn('keys mismatch')\n            return False\n        for key in self._keys:\n            if types[key] != self._types[key]:\n                self.log.warn(\n                    'type mismatch: %s: %s != %s'%(key,types[key],self._types[key])\n                )\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconnecting to the database and get new session number.", "response": "def _init_db(self):\n        \"\"\"Connect to the database and get new session number.\"\"\"\n        # register adapters\n        sqlite3.register_adapter(dict, _adapt_dict)\n        sqlite3.register_converter('dict', _convert_dict)\n        sqlite3.register_adapter(list, _adapt_bufs)\n        sqlite3.register_converter('bufs', _convert_bufs)\n        # connect to the db\n        dbfile = os.path.join(self.location, self.filename)\n        self._db = sqlite3.connect(dbfile, detect_types=sqlite3.PARSE_DECLTYPES,\n            # isolation_level = None)#,\n             cached_statements=64)\n        # print dir(self._db)\n        first_table = previous_table = self.table\n        i=0\n        while not self._check_table():\n            i+=1\n            self.table = first_table+'_%i'%i\n            self.log.warn(\n                \"Table %s exists and doesn't match db format, trying %s\"%\n                (previous_table, self.table)\n            )\n            previous_table = self.table\n\n        self._db.execute(\"\"\"CREATE TABLE IF NOT EXISTS %s\n                (msg_id text PRIMARY KEY,\n                header dict text,\n                content dict text,\n                buffers bufs blob,\n                submitted timestamp,\n                client_uuid text,\n                engine_uuid text,\n                started timestamp,\n                completed timestamp,\n                resubmitted text,\n                received timestamp,\n                result_header dict text,\n                result_content dict text,\n                result_buffers bufs blob,\n                queue text,\n                pyin text,\n                pyout text,\n                pyerr text,\n                stdout text,\n                stderr text)\n                \"\"\"%self.table)\n        self._db.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _render_expression(self, check):\n        expressions = []\n        args = []\n\n        skeys = set(check.keys())\n        skeys.difference_update(set(self._keys))\n        skeys.difference_update(set(['buffers', 'result_buffers']))\n        if skeys:\n            raise KeyError(\"Illegal testing key(s): %s\"%skeys)\n\n        for name,sub_check in check.iteritems():\n            if isinstance(sub_check, dict):\n                for test,value in sub_check.iteritems():\n                    try:\n                        op = operators[test]\n                    except KeyError:\n                        raise KeyError(\"Unsupported operator: %r\"%test)\n                    if isinstance(op, tuple):\n                        op, join = op\n\n                    if value is None and op in null_operators:\n                        expr = \"%s %s\" % (name, null_operators[op])\n                    else:\n                        expr = \"%s %s ?\"%(name, op)\n                        if isinstance(value, (tuple,list)):\n                            if op in null_operators and any([v is None for v in value]):\n                                # equality tests don't work with NULL\n                                raise ValueError(\"Cannot use %r test with NULL values on SQLite backend\"%test)\n                            expr = '( %s )'%( join.join([expr]*len(value)) )\n                            args.extend(value)\n                        else:\n                            args.append(value)\n                    expressions.append(expr)\n            else:\n                # it's an equality check\n                if sub_check is None:\n                    expressions.append(\"%s IS NULL\" % name)\n                else:\n                    expressions.append(\"%s = ?\"%name)\n                    args.append(sub_check)\n\n        expr = \" AND \".join(expressions)\n        return expr, args", "response": "Turn a mongodb - style search dict into an SQL query."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_record(self, msg_id, rec):\n        d = self._defaults()\n        d.update(rec)\n        d['msg_id'] = msg_id\n        line = self._dict_to_list(d)\n        tups = '(%s)'%(','.join(['?']*len(line)))\n        self._db.execute(\"INSERT INTO %s VALUES %s\"%(self.table, tups), line)", "response": "Add a new Task Record by msg_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a specific Task Record by msg_id.", "response": "def get_record(self, msg_id):\n        \"\"\"Get a specific Task Record, by msg_id.\"\"\"\n        cursor = self._db.execute(\"\"\"SELECT * FROM %s WHERE msg_id==?\"\"\"%self.table, (msg_id,))\n        line = cursor.fetchone()\n        if line is None:\n            raise KeyError(\"No such msg: %r\"%msg_id)\n        return self._list_to_dict(line)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the data in an existing record.", "response": "def update_record(self, msg_id, rec):\n        \"\"\"Update the data in an existing record.\"\"\"\n        query = \"UPDATE %s SET \"%self.table\n        sets = []\n        keys = sorted(rec.keys())\n        values = []\n        for key in keys:\n            sets.append('%s = ?'%key)\n            values.append(rec[key])\n        query += ', '.join(sets)\n        query += ' WHERE msg_id == ?'\n        values.append(msg_id)\n        self._db.execute(query, values)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove a record from the DB.", "response": "def drop_matching_records(self, check):\n        \"\"\"Remove a record from the DB.\"\"\"\n        expr,args = self._render_expression(check)\n        query = \"DELETE FROM %s WHERE %s\"%(self.table, expr)\n        self._db.execute(query,args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds records matching a query dict optionally extracting subset of keys.", "response": "def find_records(self, check, keys=None):\n        \"\"\"Find records matching a query dict, optionally extracting subset of keys.\n\n        Returns list of matching records.\n\n        Parameters\n        ----------\n\n        check: dict\n            mongodb-style query argument\n        keys: list of strs [optional]\n            if specified, the subset of keys to extract.  msg_id will *always* be\n            included.\n        \"\"\"\n        if keys:\n            bad_keys = [ key for key in keys if key not in self._keys ]\n            if bad_keys:\n                raise KeyError(\"Bad record key(s): %s\"%bad_keys)\n\n        if keys:\n            # ensure msg_id is present and first:\n            if 'msg_id' in keys:\n                keys.remove('msg_id')\n            keys.insert(0, 'msg_id')\n            req = ', '.join(keys)\n        else:\n            req = '*'\n        expr,args = self._render_expression(check)\n        query = \"\"\"SELECT %s FROM %s WHERE %s\"\"\"%(req, self.table, expr)\n        cursor = self._db.execute(query, args)\n        matches = cursor.fetchall()\n        records = []\n        for line in matches:\n            rec = self._list_to_dict(line, keys)\n            records.append(rec)\n        return records"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all msg_ids ordered by time submitted.", "response": "def get_history(self):\n        \"\"\"get all msg_ids, ordered by time submitted.\"\"\"\n        query = \"\"\"SELECT msg_id FROM %s ORDER by submitted ASC\"\"\"%self.table\n        cursor = self._db.execute(query)\n        # will be a list of length 1 tuples\n        return [ tup[0] for tup in cursor.fetchall()]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a config file check validity with a JSON Schema as specs and get default values from default_file.", "response": "def parse(self, config_file=None, specs=None, default_file=None):\n        \"\"\"Read a config_file, check the validity with a JSON Schema as specs\n        and get default values from default_file if asked.\n\n        All parameters are optionnal.\n\n        If there is no config_file defined, read the venv base\n        dir and try to get config/app.yml.\n\n        If no specs, don't validate anything.\n\n        If no default_file, don't merge with default values.\"\"\"\n\n        self._config_exists(config_file)\n        self._specs_exists(specs)\n\n        self.loaded_config = anyconfig.load(self.config_file, ac_parser='yaml')\n\n        if default_file is not None:\n            self._merge_default(default_file)\n\n        if self.specs is None:\n            return self.loaded_config\n\n        self._validate()\n\n        return self.loaded_config"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef table(rows):\n    '''\n    Output a simple table with several columns.\n    '''\n\n    output = '<table>'\n\n    for row in rows:\n        output += '<tr>'\n        for column in row:\n            output += '<td>{s}</td>'.format(s=column)\n        output += '</tr>'\n\n    output += '</table>'\n\n    return output", "response": "Output a simple table with several columns."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef link(url, text='', classes='', target='', get=\"\", **kwargs):\n    '''\n    Output a link tag.\n    '''\n\n    if not (url.startswith('http') or url.startswith('/')):\n        # Handle additional reverse args.\n        urlargs = {}\n\n        for arg, val in kwargs.items():\n            if arg[:4] == \"url_\":\n                urlargs[arg[4:]] = val\n\n        url = reverse(url, kwargs=urlargs)\n        if get:\n            url += '?' + get\n\n    return html.tag('a', text or url, {\n        'class': classes, 'target': target, 'href': url})", "response": "Output a link tag."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef jsfile(url):\n    '''\n    Output a script tag to a js file.\n    '''\n\n    if not url.startswith('http://') and not url[:1] == '/':\n        #add media_url for relative paths\n        url = settings.STATIC_URL + url\n\n    return '<script type=\"text/javascript\" src=\"{src}\"></script>'.format(\n        src=url)", "response": "Output a script tag to a js file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cssfile(url):\n    '''\n    Output a link tag to a css stylesheet.\n    '''\n\n    if not url.startswith('http://') and not url[:1] == '/':\n        #add media_url for relative paths\n        url = settings.STATIC_URL + url\n\n    return '<link href=\"{src}\" rel=\"stylesheet\">'.format(src=url)", "response": "Output a link tag to a css stylesheet."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sub(value, arg):\n    try:\n        return valid_numeric(value) - valid_numeric(arg)\n    except (ValueError, TypeError):\n        try:\n            return value - arg\n        except Exception:\n            return ''", "response": "Subtract the arg from the value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mul(value, arg):\n    try:\n        return valid_numeric(value) * valid_numeric(arg)\n    except (ValueError, TypeError):\n        try:\n            return value * arg\n        except Exception:\n            return ''", "response": "Multiply the value with the arg."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef div(value, arg):\n    try:\n        return valid_numeric(value) / valid_numeric(arg)\n    except (ValueError, TypeError):\n        try:\n            return value / arg\n        except Exception:\n            return ''", "response": "Divide the value by the arg."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the modulo value.", "response": "def mod(value, arg):\n    \"\"\"Return the modulo value.\"\"\"\n    try:\n        return valid_numeric(value) % valid_numeric(arg)\n    except (ValueError, TypeError):\n        try:\n            return value % arg\n        except Exception:\n            return ''"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef model_verbose(obj, capitalize=True):\n\n    if isinstance(obj, ModelForm):\n        name = obj._meta.model._meta.verbose_name\n    elif isinstance(obj, Model):\n        name = obj._meta.verbose_name\n    else:\n        raise Exception('Unhandled type: ' + type(obj))\n\n    return name.capitalize() if capitalize else name", "response": "Return the verbose name of a model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing as a class decorator to add extra methods to your model manager. Example usage: class Article(django.db.models.Model): published = models.DateTimeField() ... @extendManager class objects(object): def getPublished(self): return self.filter(published__lte = django.utils.timezone.now()).order_by('-published') ... publishedArticles = Article.objects.getPublished()", "response": "def extendManager(mixinClass):\n\t'''\n\tUse as a class decorator to add extra methods to your model manager.\n\tExample usage:\n\n\t\tclass Article(django.db.models.Model):\n\t\t\tpublished = models.DateTimeField()\n\t\t\t...\n\n\t\t\t@extendManager\n\t\t\tclass objects(object):\n\t\t\t\tdef getPublished(self):\n\t\t\t\t\treturn self.filter(published__lte = django.utils.timezone.now()).order_by('-published')\n\n\t\t...\n\n\t\tpublishedArticles = Article.objects.getPublished()\n\t'''\n\n\tclass MixinManager(models.Manager, mixinClass):\n\t\tclass MixinQuerySet(models.query.QuerySet, mixinClass):\n\t\t\tpass\n\t\tdef get_queryset(self):\n\t\t\treturn self.MixinQuerySet(self.model, using = self._db)\n\n\treturn MixinManager()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run():\n    \n    config_option_help=\"'show' - displays configured options, 'set [section] [name] [value]' - sets config under a section,'set [name] [value]' - sets configuration globally\" \n\n    parser = OptionParser()\n    \n    parser.add_option(\"-a\", \"--add\", action=\"store\", type=\"string\", dest=\"addfile\", help=\"adds a notes\")\n    parser.add_option(\"-c\", \"--config\", action=\"store\", type=\"string\", dest=\"config\", help=config_option_help)\n    parser.add_option(\"-e\", \"--edit\", action=\"store\", type=\"string\", dest=\"editfile\", help=\"edits a notes\")\n    parser.add_option(\"-o\", \"--open\", action=\"store\", type=\"string\", dest=\"openfile\", help=\"opens a notes\")\n    parser.add_option(\"-r\", \"--remove\", action=\"store\", type=\"string\", dest=\"remove\", help=\"removes a notes\")\n\n    options, args = parser.parse_args()\n    \n    if options.config:\n        if options.config == \"show\":\n            config_option_list=''\n            config_sections = config.sections()\n            for section in config_sections:\n                config_option_list=config_option_list+section+\"\\n\"\n                section_items =config.items(section)\n                for item in section_items:\n                    config_option_list=config_option_list+\"    \"+item[0]+\"    \"+item[1]+\"\\n\" \n            print config_option_list\n            quit()\n        \n    def add_notes(note_name,existing_tags):\n       call([editor,environ[\"HOME\"] + \"/.mypy/myhelp/notes/\"+note_name+\".note\"])\n       definedtags = raw_input(\"Define Tags (separated by spaces): \").split(\" \")\n       definedtags.append(note_name)\n       print definedtags\n       print existing_tags\n       definedtags=list(set(definedtags)-set(existing_tags))\n       print definedtags\n       if len(definedtags)>0:\n           modify_tags_xml(note_name,definedtags,files,rootfiles,tags,roottags,tree,TAGS_XML_DIR)  \n\n    def get_tags_from_file(note_name):\n        fil = get_file_from_files(note_name)       \n        filetags = fil.iter('tag')\n        filetaglist=[]\n        for tag in filetags:\n            filetaglist.append(tag.text)\n        return filetaglist\n\n    if options.addfile:\n       existing_tags=[]\n       if isFile(options.addfile,files):\n           existing_tags=get_tags_from_file(options.addfile)\n           raw_input(\"Note exists with tags - \"+\" \".join(existing_tags)+\"\\nDo you want to edit the notes ? [Press enter to continue]\\n\") \n       add_notes(options.addfile,existing_tags)\n       quit()\n\n    if options.editfile:\n        if isFile(options.editfile,files):\n            add_notes(note_name,[])\n        else:\n           raw_input(\"Note doesn't exist.\\nDo you want add note ? [Press enter to continue]\")     \n           add_notes(note_name)\n        \n    if options.remove:\n        pass\n    \n    if len(args) != 1:\n        print \"Please use a search term\\n example : myhelp <some tag word> \"\n        quit()\n    _key_File = \"Note\"\n    _key_Results = \"    Results                                     \"\n    table={_key_Results:[]}\n    for tag in tags:\n        if tag.attrib[\"value\"] == args[0]:\n            fileelements = tag.iter(\"file\")\n            for fileelement in fileelements:\n                f = open(\n                    environ[\"HOME\"] + \"/.mypy/myhelp/notes/\" + fileelement.text+\".note\", \"r\")\n\t\ttable[_key_Results].append(f.read()+\"\\r\\n\\tfile: ~/.mypy/myhelp/notes/\"+fileelement.text+\".note\")\n                f.close()\n\n    print tabulate(table,headers=[],tablefmt=\"rst\")", "response": "Main function for the main function of the main function of the main function of the main function of the main function of the main function of the main function of the main function of the main function of the main function of the main function of the main function of the main function of the main function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef split_user_input(line, pattern=None):\n    # We need to ensure that the rest of this routine deals only with unicode\n    encoding = get_stream_enc(sys.stdin, 'utf-8')\n    line = py3compat.cast_unicode(line, encoding)\n\n    if pattern is None:\n        pattern = line_split\n    match = pattern.match(line)\n    if not match:\n        # print \"match failed for line '%s'\" % line\n        try:\n            ifun, the_rest = line.split(None,1)\n        except ValueError:\n            # print \"split failed for line '%s'\" % line\n            ifun, the_rest = line, u''\n        pre = re.match('^(\\s*)(.*)',line).groups()[0]\n        esc = \"\"\n    else:\n        pre, esc, ifun, the_rest = match.groups()\n\n    #print 'line:<%s>' % line # dbg\n    #print 'pre <%s> ifun <%s> rest <%s>' % (pre,ifun.strip(),the_rest) # dbg\n    return pre, esc or '', ifun.strip(), the_rest.lstrip()", "response": "Split user input into initial whitespace escape character function part\n    and the rest."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a class name if the current URL matches the route name specified in urlName.", "response": "def current(context, urlName, className = 'active', **kwargs):\n\t'''\n\tReturn a class name (string) if the current URL matches the route name specified in ``className``.\n\tIf any URL keyword arguments are provided, they must be matched as well.\n\n\t:param urlName: The route name that the current URL should match. Example: 'accounts:login'.\n\t:param className: The string that is returned if the current URL matches the specified one.\n\t:param kwargs: Any extra URL keyword arguments that must also be present in the current URL for it to match.\n\t:returns: ``className`` if the current URL matches, or an empty string otherwise.\n\t'''\n\tmatches = pathMatches(context['request'].path, urlName, **kwargs)\n\treturn className if matches else ''"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if a path matches a URL.", "response": "def pathMatches(path, urlName, **kwargs):\n\t'''\n\t:param path: str\n\t:param urlName: str\n\t:returns: bool.\n\t'''\n\tresolved = urlresolvers.resolve(path)\n\n\t# Different URL name => the current URL cannot match.\n\tresolvedName = '{r.namespace}:{r.url_name}'.format(r = resolved) if resolved.namespace else resolved.url_name\n\tif urlName != resolvedName:\n\t\treturn False\n\n\t# If any of the current keyword args is missing or different, the URL cannot match.\n\tfor key, value in kwargs.items():\n\t\tcurrentArg = resolved.kwargs.get(key)\n\t\tif currentArg is None or str(value) != str(currentArg):\n\t\t\treturn False\n\n\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters command - line options.", "response": "def options(self, parser, env):\n        \"\"\"\n        Register command-line options.\n        \"\"\"\n        parser.add_option(\"--processes\", action=\"store\",\n                          default=env.get('NOSE_PROCESSES', 0),\n                          dest=\"multiprocess_workers\",\n                          metavar=\"NUM\",\n                          help=\"Spread test run among this many processes. \"\n                          \"Set a number equal to the number of processors \"\n                          \"or cores in your machine for best results. \"\n                          \"[NOSE_PROCESSES]\")\n        parser.add_option(\"--process-timeout\", action=\"store\",\n                          default=env.get('NOSE_PROCESS_TIMEOUT', 10),\n                          dest=\"multiprocess_timeout\",\n                          metavar=\"SECONDS\",\n                          help=\"Set timeout for return of results from each \"\n                          \"test runner process. [NOSE_PROCESS_TIMEOUT]\")\n        parser.add_option(\"--process-restartworker\", action=\"store_true\",\n                          default=env.get('NOSE_PROCESS_RESTARTWORKER', False),\n                          dest=\"multiprocess_restartworker\",\n                          help=\"If set, will restart each worker process once\"\n                          \" their tests are done, this helps control memory \"\n                          \"leaks from killing the system. \"\n                          \"[NOSE_PROCESS_RESTARTWORKER]\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the tests in the test queue inside of the suite fixtures.", "response": "def run(self, result):\n        \"\"\"Run tests in suite inside of suite fixtures.\n        \"\"\"\n        # proxy the result for myself\n        log.debug(\"suite %s (%s) run called, tests: %s\",\n                  id(self), self, self._tests)\n        if self.resultProxy:\n            result, orig = self.resultProxy(result, self), result\n        else:\n            result, orig = result, result\n        try:\n            #log.debug('setUp for %s', id(self));\n            self.setUp()\n        except KeyboardInterrupt:\n            raise\n        except:\n            self.error_context = 'setup'\n            result.addError(self, self._exc_info())\n            return\n        try:\n            for test in self._tests:\n                if (isinstance(test,nose.case.Test)\n                    and self.arg is not None):\n                    test.test.arg = self.arg\n                else:\n                    test.arg = self.arg\n                test.testQueue = self.testQueue\n                test.tasks = self.tasks\n                if result.shouldStop:\n                    log.debug(\"stopping\")\n                    break\n                # each nose.case.Test will create its own result proxy\n                # so the cases need the original result, to avoid proxy\n                # chains\n                #log.debug('running test %s in suite %s', test, self);\n                try:\n                    test(orig)\n                except KeyboardInterrupt, e:\n                    timeout = isinstance(e, TimedOutException)\n                    if timeout:\n                        msg = 'Timeout when running test %s in suite %s'\n                    else:\n                        msg = 'KeyboardInterrupt when running test %s in suite %s'\n                    log.debug(msg, test, self)\n                    err = (TimedOutException,TimedOutException(str(test)),\n                           sys.exc_info()[2])\n                    test.config.plugins.addError(test,err)\n                    orig.addError(test,err)\n                    if not timeout:\n                        raise\n        finally:\n            self.has_run = True\n            try:\n                #log.debug('tearDown for %s', id(self));\n                self.tearDown()\n            except KeyboardInterrupt:\n                raise\n            except:\n                self.error_context = 'teardown'\n                result.addError(self, self._exc_info())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a builtin and save the original.", "response": "def add_builtin(self, key, value):\n        \"\"\"Add a builtin and save the original.\"\"\"\n        bdict = __builtin__.__dict__\n        orig = bdict.get(key, BuiltinUndefined)\n        if value is HideBuiltin:\n            if orig is not BuiltinUndefined: #same as 'key in bdict'\n                self._orig_builtins[key] = orig\n                del bdict[key]\n        else:\n            self._orig_builtins[key] = orig\n            bdict[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_builtin(self, key, orig):\n        if orig is BuiltinUndefined:\n            del __builtin__.__dict__[key]\n        else:\n            __builtin__.__dict__[key] = orig", "response": "Remove an added builtin and re - set the original."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstore ipython references in the __builtin__ namespace.", "response": "def activate(self):\n        \"\"\"Store ipython references in the __builtin__ namespace.\"\"\"\n\n        add_builtin = self.add_builtin\n        for name, func in self.auto_builtins.iteritems():\n            add_builtin(name, func)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndeactivate the current state of the object.", "response": "def deactivate(self):\n        \"\"\"Remove any builtins which might have been added by add_builtins, or\n        restore overwritten ones to their previous values.\"\"\"\n        remove_builtin = self.remove_builtin\n        for key, val in self._orig_builtins.iteritems():\n            remove_builtin(key, val)\n        self._orig_builtins.clear()\n        self._builtins_added = False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the true URL name of a package when the given name isn t quite correct.", "response": "def _find_url_name(self, index_url, url_name, req):\n        \"\"\"\n        Finds the true URL name of a package, when the given name isn't quite\n        correct.\n        This is usually used to implement case-insensitivity.\n        \"\"\"\n        if not index_url.url.endswith('/'):\n            # Vaguely part of the PyPI API... weird but true.\n            # FIXME: bad to modify this?\n            index_url.url += '/'\n        page = self._get_page(index_url, req)\n        if page is None:\n            logger.critical('Cannot fetch index base URL %s', index_url)\n            return\n        norm_name = normalize_name(req.url_name)\n        for link in page.links:\n            base = posixpath.basename(link.path.rstrip('/'))\n            if norm_name == normalize_name(base):\n                logger.debug(\n                    'Real name of requirement %s is %s', url_name, base,\n                )\n                return base\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _link_package_versions(self, link, search_name):\n        platform = get_platform()\n\n        version = None\n        if link.egg_fragment:\n            egg_info = link.egg_fragment\n        else:\n            egg_info, ext = link.splitext()\n            if not ext:\n                if link not in self.logged_links:\n                    logger.debug('Skipping link %s; not a file', link)\n                    self.logged_links.add(link)\n                return\n            if egg_info.endswith('.tar'):\n                # Special double-extension case:\n                egg_info = egg_info[:-4]\n                ext = '.tar' + ext\n            if ext not in self._known_extensions():\n                if link not in self.logged_links:\n                    logger.debug(\n                        'Skipping link %s; unknown archive format: %s',\n                        link,\n                        ext,\n                    )\n                    self.logged_links.add(link)\n                return\n            if \"macosx10\" in link.path and ext == '.zip':\n                if link not in self.logged_links:\n                    logger.debug('Skipping link %s; macosx10 one', link)\n                    self.logged_links.add(link)\n                return\n            if ext == wheel_ext:\n                try:\n                    wheel = Wheel(link.filename)\n                except InvalidWheelFilename:\n                    logger.debug(\n                        'Skipping %s because the wheel filename is invalid',\n                        link\n                    )\n                    return\n                if (pkg_resources.safe_name(wheel.name).lower()\n                        != pkg_resources.safe_name(search_name).lower()):\n                    logger.debug(\n                        'Skipping link %s; wrong project name (not %s)',\n                        link,\n                        search_name,\n                    )\n                    return\n                if not wheel.supported():\n                    logger.debug(\n                        'Skipping %s because it is not compatible with this '\n                        'Python',\n                        link,\n                    )\n                    return\n                # This is a dirty hack to prevent installing Binary Wheels from\n                # PyPI unless it is a Windows or Mac Binary Wheel. This is\n                # paired with a change to PyPI disabling uploads for the\n                # same. Once we have a mechanism for enabling support for\n                # binary wheels on linux that deals with the inherent problems\n                # of binary distribution this can be removed.\n                comes_from = getattr(link, \"comes_from\", None)\n                if (\n                        (\n                            not platform.startswith('win')\n                            and not platform.startswith('macosx')\n                            and not platform == 'cli'\n                        )\n                        and comes_from is not None\n                        and urllib_parse.urlparse(\n                            comes_from.url\n                        ).netloc.endswith(PyPI.netloc)):\n                    if not wheel.supported(tags=supported_tags_noarch):\n                        logger.debug(\n                            \"Skipping %s because it is a pypi-hosted binary \"\n                            \"Wheel on an unsupported platform\",\n                            link,\n                        )\n                        return\n                version = wheel.version\n\n        if not version:\n            version = self._egg_info_matches(egg_info, search_name, link)\n        if version is None:\n            logger.debug(\n                'Skipping link %s; wrong project name (not %s)',\n                link,\n                search_name,\n            )\n            return\n\n        if (link.internal is not None\n                and not link.internal\n                and not normalize_name(search_name).lower()\n                in self.allow_external\n                and not self.allow_all_external):\n            # We have a link that we are sure is external, so we should skip\n            #   it unless we are allowing externals\n            logger.debug(\"Skipping %s because it is externally hosted.\", link)\n            self.need_warn_external = True\n            return\n\n        if (link.verifiable is not None\n                and not link.verifiable\n                and not (normalize_name(search_name).lower()\n                         in self.allow_unverified)):\n            # We have a link that we are sure we cannot verify its integrity,\n            #   so we should skip it unless we are allowing unsafe installs\n            #   for this requirement.\n            logger.debug(\n                \"Skipping %s because it is an insecure and unverifiable file.\",\n                link,\n            )\n            self.need_warn_unverified = True\n            return\n\n        match = self._py_version_re.search(version)\n        if match:\n            version = version[:match.start()]\n            py_version = match.group(1)\n            if py_version != sys.version[:3]:\n                logger.debug(\n                    'Skipping %s because Python version is incorrect', link\n                )\n                return\n        logger.debug('Found link %s, version: %s', link, version)\n\n        return InstallationCandidate(search_name, version, link)", "response": "Return an iterable of triples that can be extracted from the given pkg_resources. Link object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef explicit_rel_links(self, rels=('homepage', 'download')):\n        rels = set(rels)\n\n        for anchor in self.parsed.findall(\".//a\"):\n            if anchor.get(\"rel\") and anchor.get(\"href\"):\n                found_rels = set(anchor.get(\"rel\").split())\n                # Determine the intersection between what rels were found and\n                #   what rels were being looked for\n                if found_rels & rels:\n                    href = anchor.get(\"href\")\n                    url = self.clean_link(\n                        urllib_parse.urljoin(self.base_url, href)\n                    )\n                    yield Link(url, self, trusted=False)", "response": "Yields all links with the given relations"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_multi_alt_email(\n    subject,  # single line with no line-breaks\n    text_content,\n    to_emails,\n    html_content=None,\n    from_email=DEFAULT_FROM_EMAIL,\n    fail_silently=True\n    ):\n    \"\"\" \n    Send a message to one more email address(s).\n    With text content as primary and html content as alternative.\n    \"\"\"\n    messenger = EmailMultiAlternatives(subject, text_content, from_email, to_emails)\n    if html_content:\n        messenger.attach_alternative(html_content, \"text/html\")\n    try:\n        messenger.send()\n    except Exception as e:\n        if not fail_silently:\n            raise", "response": "Sends a message to one more email addresses."}
